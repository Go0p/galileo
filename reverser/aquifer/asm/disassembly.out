function_0:
    mov64 r6, r1                                    r6 = r1
    jeq r3, 82, lbb_19                              if r3 == (82 as i32 as i64 as u64) { pc += 17 }
    mov64 r1, 3                                     r1 = 3 as i32 as i64 as u64
    stxw [r10-0x50], r1                     
lbb_4:
    ldxdw r1, [r10-0x38]                    
    stxdw [r10-0x60], r1                    
    ldxdw r2, [r10-0x40]                    
    stxdw [r10-0x68], r2                    
    ldxdw r3, [r10-0x48]                    
    stxdw [r10-0x70], r3                    
    ldxdw r4, [r10-0x50]                    
    stxdw [r10-0x78], r4                    
    stxdw [r6+0x20], r1                     
    stxdw [r6+0x18], r2                     
    stxdw [r6+0x10], r3                     
    stxdw [r6+0x8], r4                      
    mov64 r1, 2                                     r1 = 2 as i32 as i64 as u64
    stxw [r6+0x0], r1                       
    ja lbb_71                                       if true { pc += 52 }
lbb_19:
    mov64 r1, r10                                   r1 = r10
    add64 r1, -88                                   r1 += -88   ///  r1 = r1.wrapping_add(-88 as i32 as i64 as u64)
    mov64 r3, 82                                    r3 = 82 as i32 as i64 as u64
    call function_32490                     
    ldxw r8, [r10-0x58]                     
    jeq r8, 2, lbb_4                                if r8 == (2 as i32 as i64 as u64) { pc += -21 }
    mov64 r7, r10                                   r7 = r10
    add64 r7, -124                                  r7 += -124   ///  r7 = r7.wrapping_add(-124 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -84                                   r2 += -84   ///  r2 = r2.wrapping_add(-84 as i32 as i64 as u64)
    mov64 r1, r7                                    r1 = r7
    mov64 r3, 36                                    r3 = 36 as i32 as i64 as u64
    call function_48190                     
    ldxdw r1, [r10-0x30]                    
    stxdw [r10-0xb0], r1                    
    ldxb r1, [r10-0x28]                     
    stxb [r10-0xa8], r1                     
    ldxb r9, [r10-0x27]                     
    mov64 r1, r10                                   r1 = r10
    add64 r1, -214                                  r1 += -214   ///  r1 = r1.wrapping_add(-214 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -38                                   r2 += -38   ///  r2 = r2.wrapping_add(-38 as i32 as i64 as u64)
    mov64 r3, 38                                    r3 = 38 as i32 as i64 as u64
    call function_48190                     
    mov64 r1, r10                                   r1 = r10
    add64 r1, -160                                  r1 += -160   ///  r1 = r1.wrapping_add(-160 as i32 as i64 as u64)
    mov64 r2, r7                                    r2 = r7
    mov64 r3, 36                                    r3 = 36 as i32 as i64 as u64
    call function_48190                     
    jeq r9, 0, lbb_67                               if r9 == (0 as i32 as i64 as u64) { pc += 18 }
    mov64 r1, r6                                    r1 = r6
    add64 r1, 4                                     r1 += 4   ///  r1 = r1.wrapping_add(4 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -160                                  r2 += -160   ///  r2 = r2.wrapping_add(-160 as i32 as i64 as u64)
    mov64 r3, 36                                    r3 = 36 as i32 as i64 as u64
    call function_48190                     
    ldxdw r1, [r10-0xb0]                    
    stxdw [r6+0x28], r1                     
    ldxb r1, [r10-0xa8]                     
    stxb [r6+0x30], r1                      
    mov64 r1, r6                                    r1 = r6
    add64 r1, 50                                    r1 += 50   ///  r1 = r1.wrapping_add(50 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -214                                  r2 += -214   ///  r2 = r2.wrapping_add(-214 as i32 as i64 as u64)
    mov64 r3, 38                                    r3 = 38 as i32 as i64 as u64
    call function_48190                     
    stxb [r6+0x31], r9                      
    ja lbb_70                                       if true { pc += 3 }
lbb_67:
    mov64 r1, 9                                     r1 = 9 as i32 as i64 as u64
    stxw [r6+0x8], r1                       
    mov64 r8, 2                                     r8 = 2 as i32 as i64 as u64
lbb_70:
    stxw [r6+0x0], r8                       
lbb_71:
    exit                                    

function_72:
    ldxdw r3, [r2+0x10]                     
    stxdw [r1+0x8], r3                      
    ldxdw r2, [r2+0x0]                      
    stxdw [r1+0x0], r2                      
    exit                                    

function_77:
    lddw r2, 0x300000000                            r2 load str located at 12884901888
    ldxdw r3, [r2+0x0]                      
    mov64 r2, r3                                    r2 = r3
    add64 r2, -24                                   r2 += -24   ///  r2 = r2.wrapping_add(-24 as i32 as i64 as u64)
    mov64 r4, 0                                     r4 = 0 as i32 as i64 as u64
    mov64 r5, 1                                     r5 = 1 as i32 as i64 as u64
    jgt r2, r3, lbb_86                              if r2 > r3 { pc += 1 }
    mov64 r5, 0                                     r5 = 0 as i32 as i64 as u64
lbb_86:
    jne r5, 0, lbb_88                               if r5 != (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r4, r2                                    r4 = r2
lbb_88:
    lddw r2, 0x300007fe8                            r2 load str located at 12884934632
    jeq r3, 0, lbb_93                               if r3 == (0 as i32 as i64 as u64) { pc += 2 }
    and64 r4, -8                                    r4 &= -8   ///  r4 = r4.and(-8)
    mov64 r2, r4                                    r2 = r4
lbb_93:
    lddw r3, 0x300000007                            r3 load str located at 12884901895
    jgt r2, r3, lbb_100                             if r2 > r3 { pc += 4 }
    mov64 r1, 8                                     r1 = 8 as i32 as i64 as u64
    mov64 r2, 24                                    r2 = 24 as i32 as i64 as u64
    call function_43400                     
    syscall [invalid]                       
lbb_100:
    lddw r3, 0x300000000                            r3 load str located at 12884901888
    stxdw [r3+0x0], r2                      
    ldxdw r3, [r1+0x10]                     
    stxdw [r2+0x10], r3                     
    ldxdw r3, [r1+0x8]                      
    stxdw [r2+0x8], r3                      
    ldxdw r1, [r1+0x0]                      
    stxdw [r2+0x0], r1                      
    mov64 r1, 21                                    r1 = 21 as i32 as i64 as u64
    lddw r3, 0x100064a28 --> b"\x00\x00\x00\x00(\x0c\x00\x00\x18\x00\x00\x00\x00\x00\x00\x00\x08\x00\x00…        r3 load str located at 4295379496
    call function_42719                     
    exit                                    

function_114:
    mov64 r6, r2                                    r6 = r2
    mov64 r2, r1                                    r2 = r1
    mov64 r8, 1                                     r8 = 1 as i32 as i64 as u64
    mov64 r7, 1                                     r7 = 1 as i32 as i64 as u64
    jeq r6, 0, lbb_142                              if r6 == (0 as i32 as i64 as u64) { pc += 23 }
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    jsgt r1, r6, lbb_178                            if (r1 as i64) > (r6 as i64) { pc += 57 }
    lddw r1, 0x300000000                            r1 load str located at 12884901888
    ldxdw r1, [r1+0x0]                      
    lddw r3, 0x300008000                            r3 load str located at 12884934656
    jeq r1, 0, lbb_128                              if r1 == (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r3, r1                                    r3 = r1
lbb_128:
    mov64 r1, r3                                    r1 = r3
    sub64 r1, r6                                    r1 -= r6   ///  r1 = r1.wrapping_sub(r6)
    mov64 r7, 0                                     r7 = 0 as i32 as i64 as u64
    mov64 r4, 1                                     r4 = 1 as i32 as i64 as u64
    jgt r1, r3, lbb_134                             if r1 > r3 { pc += 1 }
    mov64 r4, 0                                     r4 = 0 as i32 as i64 as u64
lbb_134:
    jne r4, 0, lbb_136                              if r4 != (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r7, r1                                    r7 = r1
lbb_136:
    lddw r1, 0x300000008                            r1 load str located at 12884901896
    jgt r1, r7, lbb_180                             if r1 > r7 { pc += 41 }
    lddw r1, 0x300000000                            r1 load str located at 12884901888
    stxdw [r1+0x0], r7                      
lbb_142:
    mov64 r1, r7                                    r1 = r7
    mov64 r3, r6                                    r3 = r6
    call function_48190                     
    lddw r1, 0x300000000                            r1 load str located at 12884901888
    ldxdw r1, [r1+0x0]                      
    mov64 r2, r1                                    r2 = r1
    add64 r2, -24                                   r2 += -24   ///  r2 = r2.wrapping_add(-24 as i32 as i64 as u64)
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
    jgt r2, r1, lbb_153                             if r2 > r1 { pc += 1 }
    mov64 r8, 0                                     r8 = 0 as i32 as i64 as u64
lbb_153:
    jne r8, 0, lbb_155                              if r8 != (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r3, r2                                    r3 = r2
lbb_155:
    lddw r2, 0x300007fe8                            r2 load str located at 12884934632
    jeq r1, 0, lbb_160                              if r1 == (0 as i32 as i64 as u64) { pc += 2 }
    and64 r3, -8                                    r3 &= -8   ///  r3 = r3.and(-8)
    mov64 r2, r3                                    r2 = r3
lbb_160:
    lddw r1, 0x300000007                            r1 load str located at 12884901895
    jgt r2, r1, lbb_167                             if r2 > r1 { pc += 4 }
    mov64 r1, 8                                     r1 = 8 as i32 as i64 as u64
    mov64 r2, 24                                    r2 = 24 as i32 as i64 as u64
    call function_43400                     
    syscall [invalid]                       
lbb_167:
    lddw r1, 0x300000000                            r1 load str located at 12884901888
    stxdw [r1+0x0], r2                      
    stxdw [r2+0x10], r6                     
    stxdw [r2+0x8], r6                      
    stxdw [r2+0x0], r7                      
    mov64 r1, 21                                    r1 = 21 as i32 as i64 as u64
    lddw r3, 0x100064a28 --> b"\x00\x00\x00\x00(\x0c\x00\x00\x18\x00\x00\x00\x00\x00\x00\x00\x08\x00\x00…        r3 load str located at 4295379496
    call function_42719                     
    exit                                    
lbb_178:
    call function_43383                     
    syscall [invalid]                       
lbb_180:
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    mov64 r2, r6                                    r2 = r6
    call function_43400                     
    syscall [invalid]                       
    call function_46176                     
    exit                                    

function_186:
    ldxdw r1, [r1+0x0]                      
    call function_29947                     
    exit                                    

function_189:
    ldxdw r1, [r1+0x0]                      
    mov64 r3, r1                                    r3 = r1
    add64 r3, 2                                     r3 += 2   ///  r3 = r3.wrapping_add(2 as i32 as i64 as u64)
    stxdw [r10-0x8], r3                     
    mov64 r3, r10                                   r3 = r10
    add64 r3, -8                                    r3 += -8   ///  r3 = r3.wrapping_add(-8 as i32 as i64 as u64)
    stxdw [r10-0xfb8], r3                   
    lddw r3, 0x100064b90 --> b"\x00\x00\x00\x00\xa0\x0c\x00\x00\x08\x00\x00\x00\x00\x00\x00\x00\x08\x00\…        r3 load str located at 4295379856
    stxdw [r10-0xfb0], r3                   
    lddw r3, 0x10005fc78 --> b"overfill_portionDivision by zeroentity not found\x00\x00"        r3 load str located at 4295359608
    stxdw [r10-0xfc8], r3                   
    lddw r3, 0x100064b70 --> b"\x00\x00\x00\x000\x0c\x00\x00\x01\x00\x00\x00\x00\x00\x00\x00\x01\x00\x00…        r3 load str located at 4295379824
    stxdw [r10-0xfd0], r3                   
    mov64 r3, r1                                    r3 = r1
    add64 r3, 1                                     r3 += 1   ///  r3 = r3.wrapping_add(1 as i32 as i64 as u64)
    stxdw [r10-0xfd8], r3                   
    mov64 r3, 23                                    r3 = 23 as i32 as i64 as u64
    stxdw [r10-0xfe0], r3                   
    lddw r3, 0x10005fdf8 --> b"excess_shitlist_badness>src/internal.rssdk/src/err"        r3 load str located at 4295359992
    stxdw [r10-0xfe8], r3                   
    lddw r3, 0x100064b50 --> b"\x00\x00\x00\x000\x0c\x00\x00\x01\x00\x00\x00\x00\x00\x00\x00\x01\x00\x00…        r3 load str located at 4295379792
    stxdw [r10-0xff0], r3                   
    stxdw [r10-0xff8], r1                   
    mov64 r1, 16                                    r1 = 16 as i32 as i64 as u64
    stxdw [r10-0xfc0], r1                   
    stxdw [r10-0x1000], r1                  
    mov64 r5, r10                                   r5 = r10
    mov64 r1, r2                                    r1 = r2
    lddw r2, 0x10005fd58 --> b"BadTraderActions"        r2 load str located at 4295359832
    mov64 r3, 16                                    r3 = 16 as i32 as i64 as u64
    lddw r4, 0x10005fd48 --> b"cancel_remainingBadTraderActionstoxicity fee is De"        r4 load str located at 4295359816
    call function_46026                     
    exit                                    

function_229:
    ldxdw r1, [r1+0x0]                      
    call function_39452                     
    exit                                    

function_232:
    mov64 r3, r2                                    r3 = r2
    ldxdw r2, [r1+0x8]                      
    ldxdw r1, [r1+0x0]                      
    call function_46428                     
    exit                                    

function_237:
    ldxdw r1, [r1+0x0]                      
    call function_44108                     
    exit                                    

function_240:
    ldxdw r1, [r1+0x0]                      
    call function_39452                     
    exit                                    

function_243:
    ldxdw r1, [r1+0x0]                      
    call function_44140                     
    exit                                    

function_246:
    ldxw r3, [r2+0x34]                      
    mov64 r4, r3                                    r4 = r3
    and64 r4, 16                                    r4 &= 16   ///  r4 = r4.and(16)
    jne r4, 0, lbb_255                              if r4 != (0 as i32 as i64 as u64) { pc += 5 }
    and64 r3, 32                                    r3 &= 32   ///  r3 = r3.and(32)
    jeq r3, 0, lbb_253                              if r3 == (0 as i32 as i64 as u64) { pc += 1 }
    ja lbb_257                                      if true { pc += 4 }
lbb_253:
    call function_48047                     
    ja lbb_258                                      if true { pc += 3 }
lbb_255:
    call function_47475                     
    ja lbb_258                                      if true { pc += 1 }
lbb_257:
    call function_47521                     
lbb_258:
    exit                                    

function_259:
    mov64 r0, r5                                    r0 = r5
    add64 r0, 1                                     r0 += 1   ///  r0 = r0.wrapping_add(1 as i32 as i64 as u64)
    jgt r3, r0, lbb_270                             if r3 > r0 { pc += 8 }
    jgt r5, r3, lbb_270                             if r5 > r3 { pc += 7 }
    mov64 r0, 0                                     r0 = 0 as i32 as i64 as u64
    stxdw [r1+0x20], r0                     
    stxdw [r1+0x8], r3                      
    stxdw [r1+0x0], r2                      
    stxdw [r1+0x18], r5                     
    stxdw [r1+0x10], r4                     
    exit                                    
lbb_270:
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    stxdw [r10-0x28], r1                    
    lddw r1, 0x100064ab0 --> b"\x00\x00\x00\x00\xc5\xfa\x05\x00\x0c\x00\x00\x00\x00\x00\x00\x00\x00\x00\…        r1 load str located at 4295379632
    stxdw [r10-0x30], r1                    
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    stxdw [r10-0x10], r1                    
    stxdw [r10-0x18], r1                    
    lddw r1, 0x10005fa70 --> b"src/arithmetic_impls.rsSubtraction overflowedsrc/d"        r1 load str located at 4295359088
    stxdw [r10-0x20], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -48                                   r1 += -48   ///  r1 = r1.wrapping_add(-48 as i32 as i64 as u64)
    lddw r2, 0x100064ac0 --> b"\x00\x00\x00\x00\xd1\xfa\x05\x00T\x00\x00\x00\x00\x00\x00\x00M\x01\x00\x0…        r2 load str located at 4295379648
    call function_44240                     
    syscall [invalid]                       

function_287:
    mov64 r8, r3                                    r8 = r3
    mov64 r7, r2                                    r7 = r2
    mov64 r6, r1                                    r6 = r1
    ldxdw r1, [r7+0x0]                      
    ldxb r1, [r1+0x0]                       
    stxb [r8+0x418], r1                     
    ldxdw r1, [r7+0x8]                      
    ldxb r1, [r1+0x0]                       
    stxb [r8+0x419], r1                     
    ldxdw r1, [r7+0x10]                     
    ldxb r1, [r1+0x0]                       
    stxb [r8+0x41a], r1                     
    ldxdw r9, [r7+0x18]                     
    ldxdw r1, [r9+0x18]                     
    stxdw [r8+0x3d0], r1                    
    ldxdw r1, [r9+0x10]                     
    stxdw [r8+0x3c8], r1                    
    ldxdw r1, [r9+0x8]                      
    stxdw [r8+0x3c0], r1                    
    ldxdw r1, [r9+0x0]                      
    stxdw [r8+0x3b8], r1                    
    ldxdw r1, [r7+0x20]                     
    ldxdw r2, [r1+0x0]                      
    stxdw [r8+0x3d8], r2                    
    ldxdw r2, [r1+0x8]                      
    stxdw [r8+0x3e0], r2                    
    ldxdw r2, [r1+0x10]                     
    stxdw [r8+0x3e8], r2                    
    ldxdw r1, [r1+0x18]                     
    stxdw [r8+0x3f0], r1                    
    ldxdw r1, [r7+0x28]                     
    ldxdw r2, [r1+0x0]                      
    stxdw [r8+0x3f8], r2                    
    ldxdw r2, [r1+0x8]                      
    stxdw [r8+0x400], r2                    
    ldxdw r2, [r1+0x10]                     
    stxdw [r8+0x408], r2                    
    ldxdw r1, [r1+0x18]                     
    stxdw [r8+0x410], r1                    
    ldxdw r1, [r7+0x30]                     
    ldxdw r2, [r1+0x18]                     
    stxdw [r8+0x3b0], r2                    
    ldxdw r2, [r1+0x10]                     
    stxdw [r8+0x3a8], r2                    
    ldxdw r2, [r1+0x8]                      
    stxdw [r8+0x3a0], r2                    
    ldxdw r1, [r1+0x0]                      
    stxdw [r8+0x398], r1                    
    mov64 r1, r8                                    r1 = r8
    add64 r1, 80                                    r1 += 80   ///  r1 = r1.wrapping_add(80 as i32 as i64 as u64)
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
    mov64 r3, 64                                    r3 = 64 as i32 as i64 as u64
    call function_48291                     
    mov64 r1, r8                                    r1 = r8
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
    mov64 r3, 72                                    r3 = 72 as i32 as i64 as u64
    call function_48291                     
    lddw r1, 0xf14004a80b5                          r1 load str located at 16578578645173
    stxdw [r8+0x48], r1                     
    ldxdw r1, [r7+0x38]                     
    ldxdw r2, [r1+0x0]                      
    mov64 r1, r6                                    r1 = r6
    mov64 r3, r9                                    r3 = r9
    call function_24892                     
    exit                                    

function_353:
    exit                                    

function_354:
    exit                                    

function_355:
    ldxdw r2, [r1+0x0]                      
    mov64 r1, r2                                    r1 = r2
    and64 r1, 3                                     r1 &= 3   ///  r1 = r1.and(3)
    mov64 r3, r1                                    r3 = r1
    add64 r3, -2                                    r3 += -2   ///  r3 = r3.wrapping_add(-2 as i32 as i64 as u64)
    mov64 r4, 2                                     r4 = 2 as i32 as i64 as u64
    jgt r4, r3, lbb_367                             if r4 > r3 { pc += 5 }
    jeq r1, 0, lbb_367                              if r1 == (0 as i32 as i64 as u64) { pc += 4 }
    ldxdw r1, [r2-0x1]                      
    ldxdw r2, [r2+0x7]                      
    ldxdw r2, [r2+0x0]                      
    callx r2                                
lbb_367:
    exit                                    

function_368:
    exit                                    

function_369:
    ldxdw r2, [r1+0x10]                     
    ldxdw r3, [r1+0x8]                      
    ldxdw r4, [r3+0x0]                      
    add64 r4, -1                                    r4 += -1   ///  r4 = r4.wrapping_add(-1 as i32 as i64 as u64)
    stxdw [r3+0x0], r4                      
    jne r4, 0, lbb_378                              if r4 != (0 as i32 as i64 as u64) { pc += 3 }
    ldxdw r4, [r3+0x8]                      
    add64 r4, -1                                    r4 += -1   ///  r4 = r4.wrapping_add(-1 as i32 as i64 as u64)
    stxdw [r3+0x8], r4                      
lbb_378:
    ldxdw r3, [r2+0x0]                      
    add64 r3, -1                                    r3 += -1   ///  r3 = r3.wrapping_add(-1 as i32 as i64 as u64)
    stxdw [r2+0x0], r3                      
    jne r3, 0, lbb_385                              if r3 != (0 as i32 as i64 as u64) { pc += 3 }
    ldxdw r3, [r2+0x8]                      
    add64 r3, -1                                    r3 += -1   ///  r3 = r3.wrapping_add(-1 as i32 as i64 as u64)
    stxdw [r2+0x8], r3                      
lbb_385:
    ldxdw r2, [r1+0x40]                     
    ldxdw r3, [r1+0x38]                     
    ldxdw r4, [r3+0x0]                      
    add64 r4, -1                                    r4 += -1   ///  r4 = r4.wrapping_add(-1 as i32 as i64 as u64)
    stxdw [r3+0x0], r4                      
    jne r4, 0, lbb_394                              if r4 != (0 as i32 as i64 as u64) { pc += 3 }
    ldxdw r4, [r3+0x8]                      
    add64 r4, -1                                    r4 += -1   ///  r4 = r4.wrapping_add(-1 as i32 as i64 as u64)
    stxdw [r3+0x8], r4                      
lbb_394:
    ldxdw r3, [r2+0x0]                      
    add64 r3, -1                                    r3 += -1   ///  r3 = r3.wrapping_add(-1 as i32 as i64 as u64)
    stxdw [r2+0x0], r3                      
    jne r3, 0, lbb_401                              if r3 != (0 as i32 as i64 as u64) { pc += 3 }
    ldxdw r3, [r2+0x8]                      
    add64 r3, -1                                    r3 += -1   ///  r3 = r3.wrapping_add(-1 as i32 as i64 as u64)
    stxdw [r2+0x8], r3                      
lbb_401:
    ldxdw r2, [r1+0x70]                     
    ldxdw r3, [r1+0x68]                     
    ldxdw r4, [r3+0x0]                      
    add64 r4, -1                                    r4 += -1   ///  r4 = r4.wrapping_add(-1 as i32 as i64 as u64)
    stxdw [r3+0x0], r4                      
    jne r4, 0, lbb_410                              if r4 != (0 as i32 as i64 as u64) { pc += 3 }
    ldxdw r4, [r3+0x8]                      
    add64 r4, -1                                    r4 += -1   ///  r4 = r4.wrapping_add(-1 as i32 as i64 as u64)
    stxdw [r3+0x8], r4                      
lbb_410:
    ldxdw r3, [r2+0x0]                      
    add64 r3, -1                                    r3 += -1   ///  r3 = r3.wrapping_add(-1 as i32 as i64 as u64)
    stxdw [r2+0x0], r3                      
    jne r3, 0, lbb_417                              if r3 != (0 as i32 as i64 as u64) { pc += 3 }
    ldxdw r3, [r2+0x8]                      
    add64 r3, -1                                    r3 += -1   ///  r3 = r3.wrapping_add(-1 as i32 as i64 as u64)
    stxdw [r2+0x8], r3                      
lbb_417:
    ldxdw r2, [r1+0xa0]                     
    ldxdw r1, [r1+0x98]                     
    ldxdw r3, [r1+0x0]                      
    add64 r3, -1                                    r3 += -1   ///  r3 = r3.wrapping_add(-1 as i32 as i64 as u64)
    stxdw [r1+0x0], r3                      
    jne r3, 0, lbb_426                              if r3 != (0 as i32 as i64 as u64) { pc += 3 }
    ldxdw r3, [r1+0x8]                      
    add64 r3, -1                                    r3 += -1   ///  r3 = r3.wrapping_add(-1 as i32 as i64 as u64)
    stxdw [r1+0x8], r3                      
lbb_426:
    ldxdw r1, [r2+0x0]                      
    add64 r1, -1                                    r1 += -1   ///  r1 = r1.wrapping_add(-1 as i32 as i64 as u64)
    stxdw [r2+0x0], r1                      
    jne r1, 0, lbb_433                              if r1 != (0 as i32 as i64 as u64) { pc += 3 }
    ldxdw r1, [r2+0x8]                      
    add64 r1, -1                                    r1 += -1   ///  r1 = r1.wrapping_add(-1 as i32 as i64 as u64)
    stxdw [r2+0x8], r1                      
lbb_433:
    exit                                    

function_434:
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
    stxdw [r1+0x0], r2                      
    exit                                    

function_437:
    exit                                    

function_438:
    lddw r2, 0x6c0d57f90468015e                     r2 load str located at 7785976057825853790
    stxdw [r1+0x8], r2                      
    lddw r2, 0xc9041a0db6177351                     r2 load str located at -3962013125987306671
    stxdw [r1+0x0], r2                      
    exit                                    

function_445:
    mov64 r3, r2                                    r3 = r2
    mov64 r6, r1                                    r6 = r1
    ldxdw r1, [r3+0x18]                     
    ldxdw r2, [r3+0x8]                      
    jeq r2, 1, lbb_460                              if r2 == (1 as i32 as i64 as u64) { pc += 10 }
    jne r2, 0, lbb_456                              if r2 != (0 as i32 as i64 as u64) { pc += 5 }
    mov64 r7, 1                                     r7 = 1 as i32 as i64 as u64
    mov64 r8, 0                                     r8 = 0 as i32 as i64 as u64
    lddw r2, 0x10005fa70 --> b"src/arithmetic_impls.rsSubtraction overflowedsrc/d"        r2 load str located at 4295359088
    jeq r1, 0, lbb_492                              if r1 == (0 as i32 as i64 as u64) { pc += 36 }
lbb_456:
    mov64 r1, r6                                    r1 = r6
    mov64 r2, r3                                    r2 = r3
    call function_43415                     
    ja lbb_498                                      if true { pc += 38 }
lbb_460:
    jeq r1, 0, lbb_462                              if r1 == (0 as i32 as i64 as u64) { pc += 1 }
    ja lbb_456                                      if true { pc += -6 }
lbb_462:
    ldxdw r1, [r3+0x0]                      
    mov64 r7, 1                                     r7 = 1 as i32 as i64 as u64
    mov64 r8, 0                                     r8 = 0 as i32 as i64 as u64
    ldxdw r2, [r1+0x0]                      
    ldxdw r3, [r1+0x8]                      
    jeq r3, 0, lbb_492                              if r3 == (0 as i32 as i64 as u64) { pc += 24 }
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    jsgt r1, r3, lbb_499                            if (r1 as i64) > (r3 as i64) { pc += 29 }
    lddw r1, 0x300000000                            r1 load str located at 12884901888
    ldxdw r1, [r1+0x0]                      
    lddw r4, 0x300008000                            r4 load str located at 12884934656
    jeq r1, 0, lbb_477                              if r1 == (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r4, r1                                    r4 = r1
lbb_477:
    mov64 r1, r4                                    r1 = r4
    sub64 r1, r3                                    r1 -= r3   ///  r1 = r1.wrapping_sub(r3)
    mov64 r7, 0                                     r7 = 0 as i32 as i64 as u64
    mov64 r5, 1                                     r5 = 1 as i32 as i64 as u64
    jgt r1, r4, lbb_483                             if r1 > r4 { pc += 1 }
    mov64 r5, 0                                     r5 = 0 as i32 as i64 as u64
lbb_483:
    jne r5, 0, lbb_485                              if r5 != (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r7, r1                                    r7 = r1
lbb_485:
    lddw r1, 0x300000008                            r1 load str located at 12884901896
    jgt r1, r7, lbb_501                             if r1 > r7 { pc += 13 }
    lddw r1, 0x300000000                            r1 load str located at 12884901888
    stxdw [r1+0x0], r7                      
    mov64 r8, r3                                    r8 = r3
lbb_492:
    mov64 r1, r7                                    r1 = r7
    mov64 r3, r8                                    r3 = r8
    call function_48190                     
    stxdw [r6+0x10], r8                     
    stxdw [r6+0x8], r8                      
    stxdw [r6+0x0], r7                      
lbb_498:
    exit                                    
lbb_499:
    call function_43383                     
    syscall [invalid]                       
lbb_501:
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    mov64 r2, r3                                    r2 = r3
    call function_43400                     
    syscall [invalid]                       

function_505:
    mov64 r7, r3                                    r7 = r3
    mov64 r6, r1                                    r6 = r1
    jeq r2, 0, lbb_534                              if r2 == (0 as i32 as i64 as u64) { pc += 26 }
    ldxdw r1, [r4+0x8]                      
    jeq r1, 0, lbb_564                              if r1 == (0 as i32 as i64 as u64) { pc += 54 }
    ldxdw r3, [r4+0x10]                     
    jne r3, 0, lbb_539                              if r3 != (0 as i32 as i64 as u64) { pc += 27 }
    mov64 r8, 1                                     r8 = 1 as i32 as i64 as u64
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    jeq r7, 0, lbb_589                              if r7 == (0 as i32 as i64 as u64) { pc += 74 }
    lddw r1, 0x300000000                            r1 load str located at 12884901888
    ldxdw r1, [r1+0x0]                      
    lddw r2, 0x300008000                            r2 load str located at 12884934656
    jeq r1, 0, lbb_522                              if r1 == (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r2, r1                                    r2 = r1
lbb_522:
    mov64 r1, r2                                    r1 = r2
    sub64 r1, r7                                    r1 -= r7   ///  r1 = r1.wrapping_sub(r7)
    mov64 r8, 0                                     r8 = 0 as i32 as i64 as u64
    mov64 r3, 1                                     r3 = 1 as i32 as i64 as u64
    jgt r1, r2, lbb_528                             if r1 > r2 { pc += 1 }
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
lbb_528:
    jne r3, 0, lbb_530                              if r3 != (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r8, r1                                    r8 = r1
lbb_530:
    lddw r1, 0x300000008                            r1 load str located at 12884901896
    jgt r1, r8, lbb_593                             if r1 > r8 { pc += 60 }
    ja lbb_585                                      if true { pc += 51 }
lbb_534:
    stxdw [r6+0x10], r7                     
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    stxdw [r6+0x8], r1                      
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    ja lbb_596                                      if true { pc += 57 }
lbb_539:
    lddw r1, 0x300000000                            r1 load str located at 12884901888
    ldxdw r1, [r1+0x0]                      
    lddw r2, 0x300008000                            r2 load str located at 12884934656
    jeq r1, 0, lbb_546                              if r1 == (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r2, r1                                    r2 = r1
lbb_546:
    mov64 r1, r2                                    r1 = r2
    sub64 r1, r7                                    r1 -= r7   ///  r1 = r1.wrapping_sub(r7)
    mov64 r8, 0                                     r8 = 0 as i32 as i64 as u64
    mov64 r5, 1                                     r5 = 1 as i32 as i64 as u64
    jgt r1, r2, lbb_552                             if r1 > r2 { pc += 1 }
    mov64 r5, 0                                     r5 = 0 as i32 as i64 as u64
lbb_552:
    jne r5, 0, lbb_554                              if r5 != (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r8, r1                                    r8 = r1
lbb_554:
    lddw r1, 0x300000008                            r1 load str located at 12884901896
    jgt r1, r8, lbb_593                             if r1 > r8 { pc += 36 }
    ldxdw r2, [r4+0x0]                      
    lddw r1, 0x300000000                            r1 load str located at 12884901888
    stxdw [r1+0x0], r8                      
    mov64 r1, r8                                    r1 = r8
    call function_48190                     
    ja lbb_588                                      if true { pc += 24 }
lbb_564:
    mov64 r8, 1                                     r8 = 1 as i32 as i64 as u64
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    jeq r7, 0, lbb_589                              if r7 == (0 as i32 as i64 as u64) { pc += 22 }
    lddw r1, 0x300000000                            r1 load str located at 12884901888
    ldxdw r1, [r1+0x0]                      
    lddw r2, 0x300008000                            r2 load str located at 12884934656
    jeq r1, 0, lbb_574                              if r1 == (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r2, r1                                    r2 = r1
lbb_574:
    mov64 r1, r2                                    r1 = r2
    sub64 r1, r7                                    r1 -= r7   ///  r1 = r1.wrapping_sub(r7)
    mov64 r8, 0                                     r8 = 0 as i32 as i64 as u64
    mov64 r3, 1                                     r3 = 1 as i32 as i64 as u64
    jgt r1, r2, lbb_580                             if r1 > r2 { pc += 1 }
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
lbb_580:
    jne r3, 0, lbb_582                              if r3 != (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r8, r1                                    r8 = r1
lbb_582:
    lddw r1, 0x300000008                            r1 load str located at 12884901896
    jgt r1, r8, lbb_593                             if r1 > r8 { pc += 8 }
lbb_585:
    lddw r1, 0x300000000                            r1 load str located at 12884901888
    stxdw [r1+0x0], r8                      
lbb_588:
    mov64 r1, r7                                    r1 = r7
lbb_589:
    stxdw [r6+0x10], r1                     
    stxdw [r6+0x8], r8                      
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    ja lbb_596                                      if true { pc += 3 }
lbb_593:
    stxdw [r6+0x10], r7                     
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    stxdw [r6+0x8], r1                      
lbb_596:
    stxdw [r6+0x0], r1                      
    exit                                    

function_598:
    mov64 r6, r1                                    r6 = r1
    add64 r2, 1                                     r2 += 1   ///  r2 = r2.wrapping_add(1 as i32 as i64 as u64)
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    jeq r2, 0, lbb_603                              if r2 == (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
lbb_603:
    and64 r1, 1                                     r1 &= 1   ///  r1 = r1.and(1)
    jne r1, 0, lbb_644                              if r1 != (0 as i32 as i64 as u64) { pc += 39 }
    ldxdw r1, [r6+0x8]                      
    mov64 r7, r1                                    r7 = r1
    lsh64 r7, 1                                     r7 <<= 1   ///  r7 = r7.wrapping_shl(1)
    jgt r7, r2, lbb_610                             if r7 > r2 { pc += 1 }
    mov64 r7, r2                                    r7 = r2
lbb_610:
    jgt r7, 4, lbb_612                              if r7 > (4 as i32 as i64 as u64) { pc += 1 }
    mov64 r7, 4                                     r7 = 4 as i32 as i64 as u64
lbb_612:
    mov64 r2, 1                                     r2 = 1 as i32 as i64 as u64
    lddw r3, 0x400000000000000                      r3 load str located at 288230376151711744
    jgt r3, r7, lbb_617                             if r3 > r7 { pc += 1 }
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
lbb_617:
    mov64 r3, r7                                    r3 = r7
    lsh64 r3, 5                                     r3 <<= 5   ///  r3 = r3.wrapping_shl(5)
    jne r1, 0, lbb_623                              if r1 != (0 as i32 as i64 as u64) { pc += 3 }
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    stxdw [r10-0x10], r1                    
    ja lbb_629                                      if true { pc += 6 }
lbb_623:
    ldxdw r4, [r6+0x0]                      
    lsh64 r1, 5                                     r1 <<= 5   ///  r1 = r1.wrapping_shl(5)
    stxdw [r10-0x8], r1                     
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    stxdw [r10-0x10], r1                    
    stxdw [r10-0x18], r4                    
lbb_629:
    mov64 r1, r10                                   r1 = r10
    add64 r1, -48                                   r1 += -48   ///  r1 = r1.wrapping_add(-48 as i32 as i64 as u64)
    mov64 r4, r10                                   r4 = r10
    add64 r4, -24                                   r4 += -24   ///  r4 = r4.wrapping_add(-24 as i32 as i64 as u64)
    call function_505                       
    ldxdw r1, [r10-0x28]                    
    ldxdw r2, [r10-0x30]                    
    jne r2, 0, lbb_640                              if r2 != (0 as i32 as i64 as u64) { pc += 3 }
    stxdw [r6+0x8], r7                      
    stxdw [r6+0x0], r1                      
lbb_639:
    exit                                    
lbb_640:
    lddw r2, 0x8000000000000001                     r2 load str located at -9223372036854775807
    jeq r1, r2, lbb_639                             if r1 == r2 { pc += -4 }
    jne r1, 0, lbb_646                              if r1 != (0 as i32 as i64 as u64) { pc += 2 }
lbb_644:
    call function_43383                     
    syscall [invalid]                       
lbb_646:
    ldxdw r2, [r10-0x20]                    
    call function_43400                     
    syscall [invalid]                       

function_649:
    mov64 r6, r1                                    r6 = r1
    mov64 r4, r2                                    r4 = r2
    add64 r4, r3                                    r4 += r3   ///  r4 = r4.wrapping_add(r3)
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    jgt r2, r4, lbb_655                             if r2 > r4 { pc += 1 }
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
lbb_655:
    and64 r1, 1                                     r1 &= 1   ///  r1 = r1.and(1)
    jne r1, 0, lbb_692                              if r1 != (0 as i32 as i64 as u64) { pc += 35 }
    ldxdw r1, [r6+0x8]                      
    mov64 r7, r1                                    r7 = r1
    lsh64 r7, 1                                     r7 <<= 1   ///  r7 = r7.wrapping_shl(1)
    jgt r7, r4, lbb_662                             if r7 > r4 { pc += 1 }
    mov64 r7, r4                                    r7 = r4
lbb_662:
    jgt r7, 8, lbb_664                              if r7 > (8 as i32 as i64 as u64) { pc += 1 }
    mov64 r7, 8                                     r7 = 8 as i32 as i64 as u64
lbb_664:
    mov64 r2, r7                                    r2 = r7
    xor64 r2, -1                                    r2 ^= -1   ///  r2 = r2.xor(-1)
    rsh64 r2, 63                                    r2 >>= 63   ///  r2 = r2.wrapping_shr(63)
    jne r1, 0, lbb_671                              if r1 != (0 as i32 as i64 as u64) { pc += 3 }
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    stxdw [r10-0x10], r1                    
    ja lbb_676                                      if true { pc += 5 }
lbb_671:
    ldxdw r3, [r6+0x0]                      
    stxdw [r10-0x8], r1                     
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    stxdw [r10-0x10], r1                    
    stxdw [r10-0x18], r3                    
lbb_676:
    mov64 r1, r10                                   r1 = r10
    add64 r1, -48                                   r1 += -48   ///  r1 = r1.wrapping_add(-48 as i32 as i64 as u64)
    mov64 r4, r10                                   r4 = r10
    add64 r4, -24                                   r4 += -24   ///  r4 = r4.wrapping_add(-24 as i32 as i64 as u64)
    mov64 r3, r7                                    r3 = r7
    call function_505                       
    ldxdw r1, [r10-0x28]                    
    ldxdw r2, [r10-0x30]                    
    jne r2, 0, lbb_688                              if r2 != (0 as i32 as i64 as u64) { pc += 3 }
    stxdw [r6+0x8], r7                      
    stxdw [r6+0x0], r1                      
lbb_687:
    exit                                    
lbb_688:
    lddw r2, 0x8000000000000001                     r2 load str located at -9223372036854775807
    jeq r1, r2, lbb_687                             if r1 == r2 { pc += -4 }
    jne r1, 0, lbb_694                              if r1 != (0 as i32 as i64 as u64) { pc += 2 }
lbb_692:
    call function_43383                     
    syscall [invalid]                       
lbb_694:
    ldxdw r2, [r10-0x20]                    
    call function_43400                     
    syscall [invalid]                       

function_697:
    mov64 r6, r1                                    r6 = r1
    ldxdw r8, [r2+0x8]                      
    mov64 r1, 4                                     r1 = 4 as i32 as i64 as u64
    jgt r1, r8, lbb_738                             if r1 > r8 { pc += 37 }
    add64 r8, -4                                    r8 += -4   ///  r8 = r8.wrapping_add(-4 as i32 as i64 as u64)
    ldxdw r4, [r2+0x0]                      
    ldxw r5, [r4+0x0]                       
    stxdw [r2+0x8], r8                      
    add64 r4, 4                                     r4 += 4   ///  r4 = r4.wrapping_add(4 as i32 as i64 as u64)
    stxdw [r2+0x0], r4                      
    jeq r5, 0, lbb_858                              if r5 == (0 as i32 as i64 as u64) { pc += 150 }
    stxdw [r10-0x48], r6                    
    mov64 r1, 1048576                               r1 = 1048576 as i32 as i64 as u64
    mov64 r3, r5                                    r3 = r5
    mov64 r6, r5                                    r6 = r5
    jgt r1, r6, lbb_714                             if r1 > r6 { pc += 1 }
    mov64 r3, 1048576                               r3 = 1048576 as i32 as i64 as u64
lbb_714:
    stxdw [r10-0x30], r2                    
    lddw r1, 0x300000000                            r1 load str located at 12884901888
    ldxdw r1, [r1+0x0]                      
    lddw r2, 0x300008000                            r2 load str located at 12884934656
    jeq r1, 0, lbb_722                              if r1 == (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r2, r1                                    r2 = r1
lbb_722:
    mov64 r0, r2                                    r0 = r2
    sub64 r0, r3                                    r0 -= r3   ///  r0 = r0.wrapping_sub(r3)
    mov64 r9, 0                                     r9 = 0 as i32 as i64 as u64
    mov64 r5, 1                                     r5 = 1 as i32 as i64 as u64
    jgt r0, r2, lbb_728                             if r0 > r2 { pc += 1 }
    mov64 r5, 0                                     r5 = 0 as i32 as i64 as u64
lbb_728:
    jne r5, 0, lbb_730                              if r5 != (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r9, r0                                    r9 = r0
lbb_730:
    stxdw [r10-0x28], r4                    
    lddw r2, 0x300000007                            r2 load str located at 12884901895
    jgt r9, r2, lbb_745                             if r9 > r2 { pc += 11 }
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    mov64 r2, r3                                    r2 = r3
    call function_43400                     
    syscall [invalid]                       
lbb_738:
    lddw r1, 0x100064a98 --> b"\x00\x00\x00\x00\xaa\xfa\x05\x00\x1b\x00\x00\x00\x00\x00\x00\x00%\x00\x00…        r1 load str located at 4295379608
    call function_42270                     
    stxdw [r6+0x8], r0                      
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    stxdw [r6+0x0], r1                      
    ja lbb_872                                      if true { pc += 127 }
lbb_745:
    lddw r2, 0x300000000                            r2 load str located at 12884901888
    stxdw [r2+0x0], r9                      
    mov64 r1, r9                                    r1 = r9
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
    mov64 r7, r3                                    r7 = r3
    call function_48291                     
    mov64 r0, r9                                    r0 = r9
    mov64 r5, r7                                    r5 = r7
    stxdw [r10-0x8], r5                     
    stxdw [r10-0x10], r5                    
    stxdw [r10-0x18], r0                    
    mov64 r7, 0                                     r7 = 0 as i32 as i64 as u64
    ldxdw r3, [r10-0x30]                    
    ldxdw r4, [r10-0x28]                    
    stxdw [r10-0x38], r6                    
    ja lbb_784                                      if true { pc += 22 }
lbb_762:
    mov64 r2, r4                                    r2 = r4
    mov64 r3, r9                                    r3 = r9
    stxdw [r10-0x28], r8                    
    mov64 r8, r4                                    r8 = r4
    mov64 r6, r5                                    r6 = r5
    stxdw [r10-0x20], r0                    
    call function_48190                     
    ldxdw r0, [r10-0x20]                    
    mov64 r5, r6                                    r5 = r6
    mov64 r4, r8                                    r4 = r8
    ldxdw r8, [r10-0x28]                    
    ldxdw r6, [r10-0x38]                    
    ldxdw r3, [r10-0x30]                    
    sub64 r8, r9                                    r8 -= r9   ///  r8 = r8.wrapping_sub(r9)
    stxdw [r3+0x8], r8                      
    add64 r4, r9                                    r4 += r9   ///  r4 = r4.wrapping_add(r9)
    stxdw [r3+0x0], r4                      
    jeq r9, 0, lbb_864                              if r9 == (0 as i32 as i64 as u64) { pc += 84 }
lbb_780:
    add64 r9, r7                                    r9 += r7   ///  r9 = r9.wrapping_add(r7)
    mov64 r7, r9                                    r7 = r9
    jgt r6, r9, lbb_784                             if r6 > r9 { pc += 1 }
    ja lbb_852                                      if true { pc += 68 }
lbb_784:
    jne r7, r5, lbb_830                             if r7 != r5 { pc += 45 }
    mov64 r9, r5                                    r9 = r5
    lsh64 r9, 1                                     r9 <<= 1   ///  r9 = r9.wrapping_shl(1)
    jsgt r5, -1, lbb_789                            if (r5 as i64) > (-1 as i32 as i64) { pc += 1 }
    mov64 r9, -1                                    r9 = -1 as i32 as i64 as u64
lbb_789:
    jgt r6, r9, lbb_791                             if r6 > r9 { pc += 1 }
    mov64 r9, r6                                    r9 = r6
lbb_791:
    jge r5, r9, lbb_828                             if r5 >= r9 { pc += 36 }
    sub64 r9, r5                                    r9 -= r5   ///  r9 = r9.wrapping_sub(r5)
    ldxdw r1, [r10-0x10]                    
    sub64 r1, r5                                    r1 -= r5   ///  r1 = r1.wrapping_sub(r5)
    jge r1, r9, lbb_807                             if r1 >= r9 { pc += 11 }
    mov64 r1, r10                                   r1 = r10
    add64 r1, -24                                   r1 += -24   ///  r1 = r1.wrapping_add(-24 as i32 as i64 as u64)
    mov64 r2, r5                                    r2 = r5
    mov64 r3, r9                                    r3 = r9
    mov64 r6, r4                                    r6 = r4
    call function_649                       
    mov64 r4, r6                                    r4 = r6
    ldxdw r6, [r10-0x38]                    
    ldxdw r3, [r10-0x30]                    
    ldxdw r0, [r10-0x18]                    
    ldxdw r5, [r10-0x8]                     
lbb_807:
    mov64 r1, r0                                    r1 = r0
    add64 r1, r5                                    r1 += r5   ///  r1 = r1.wrapping_add(r5)
    mov64 r2, 2                                     r2 = 2 as i32 as i64 as u64
    jgt r2, r9, lbb_824                             if r2 > r9 { pc += 13 }
    add64 r9, -1                                    r9 += -1   ///  r9 = r9.wrapping_add(-1 as i32 as i64 as u64)
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
    mov64 r3, r9                                    r3 = r9
    stxdw [r10-0x28], r4                    
    stxdw [r10-0x40], r5                    
    stxdw [r10-0x20], r0                    
    call function_48291                     
    ldxdw r5, [r10-0x40]                    
    ldxdw r4, [r10-0x28]                    
    ldxdw r3, [r10-0x30]                    
    add64 r5, r9                                    r5 += r9   ///  r5 = r5.wrapping_add(r9)
    ldxdw r1, [r10-0x20]                    
    add64 r1, r5                                    r1 += r5   ///  r1 = r1.wrapping_add(r5)
lbb_824:
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
    stxb [r1+0x0], r2                       
    add64 r5, 1                                     r5 += 1   ///  r5 = r5.wrapping_add(1 as i32 as i64 as u64)
    mov64 r9, r5                                    r9 = r5
lbb_828:
    stxdw [r10-0x8], r9                     
    mov64 r5, r9                                    r5 = r9
lbb_830:
    jge r5, r7, lbb_837                             if r5 >= r7 { pc += 6 }
    mov64 r1, r7                                    r1 = r7
    mov64 r2, r5                                    r2 = r5
    lddw r3, 0x100064ad8 --> b"\x00\x00\x00\x00\x9d\xfa\x05\x00\x0d\x00\x00\x00\x00\x00\x00\x00\xab\x00\…        r3 load str located at 4295379672
    call function_46508                     
    syscall [invalid]                       
lbb_837:
    mov64 r9, r5                                    r9 = r5
    sub64 r9, r7                                    r9 -= r7   ///  r9 = r9.wrapping_sub(r7)
    jgt r8, r9, lbb_841                             if r8 > r9 { pc += 1 }
    mov64 r9, r8                                    r9 = r8
lbb_841:
    ldxdw r0, [r10-0x18]                    
    mov64 r1, r0                                    r1 = r0
    add64 r1, r7                                    r1 += r7   ///  r1 = r1.wrapping_add(r7)
    jne r9, 1, lbb_762                              if r9 != (1 as i32 as i64 as u64) { pc += -83 }
    ldxb r2, [r4+0x0]                       
    stxb [r1+0x0], r2                       
    add64 r8, -1                                    r8 += -1   ///  r8 = r8.wrapping_add(-1 as i32 as i64 as u64)
    stxdw [r3+0x8], r8                      
    add64 r4, 1                                     r4 += 1   ///  r4 = r4.wrapping_add(1 as i32 as i64 as u64)
    stxdw [r3+0x0], r4                      
    ja lbb_780                                      if true { pc += -72 }
lbb_852:
    ldxdw r1, [r10-0x10]                    
    ldxdw r2, [r10-0x48]                    
    stxdw [r2+0x10], r5                     
    stxdw [r2+0x8], r1                      
    stxdw [r2+0x0], r0                      
    ja lbb_872                                      if true { pc += 14 }
lbb_858:
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    stxdw [r6+0x0], r1                      
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    stxdw [r6+0x8], r1                      
    stxdw [r6+0x10], r1                     
    ja lbb_872                                      if true { pc += 8 }
lbb_864:
    lddw r1, 0x10005fb25 --> b"Unexpected length of input"        r1 load str located at 4295359269
    mov64 r2, 26                                    r2 = 26 as i32 as i64 as u64
    call function_114                       
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    ldxdw r2, [r10-0x48]                    
    stxdw [r2+0x0], r1                      
    stxdw [r2+0x8], r0                      
lbb_872:
    exit                                    

function_873:
    mov64 r6, r2                                    r6 = r2
    mov64 r7, r1                                    r7 = r1
    ldxdw r3, [r6+0x8]                      
    ldxdw r2, [r6+0x10]                     
    ldxb r8, [r7+0x0]                       
    jne r8, 2, lbb_888                              if r8 != (2 as i32 as i64 as u64) { pc += 9 }
    jne r3, r2, lbb_884                             if r3 != r2 { pc += 4 }
    mov64 r1, r6                                    r1 = r6
    mov64 r3, 1                                     r3 = 1 as i32 as i64 as u64
    call function_649                       
    ldxdw r2, [r6+0x10]                     
lbb_884:
    ldxdw r1, [r6+0x0]                      
    add64 r1, r2                                    r1 += r2   ///  r1 = r1.wrapping_add(r2)
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
    ja lbb_951                                      if true { pc += 63 }
lbb_888:
    jne r3, r2, lbb_894                             if r3 != r2 { pc += 5 }
    mov64 r1, r6                                    r1 = r6
    mov64 r3, 1                                     r3 = 1 as i32 as i64 as u64
    call function_649                       
    ldxdw r3, [r6+0x8]                      
    ldxdw r2, [r6+0x10]                     
lbb_894:
    ldxdw r1, [r6+0x0]                      
    mov64 r4, r1                                    r4 = r1
    add64 r4, r2                                    r4 += r2   ///  r4 = r4.wrapping_add(r2)
    mov64 r5, 1                                     r5 = 1 as i32 as i64 as u64
    stxb [r4+0x0], r5                       
    add64 r2, 1                                     r2 += 1   ///  r2 = r2.wrapping_add(1 as i32 as i64 as u64)
    stxdw [r6+0x10], r2                     
    jne r3, r2, lbb_908                             if r3 != r2 { pc += 6 }
    mov64 r1, r6                                    r1 = r6
    mov64 r2, r3                                    r2 = r3
    mov64 r3, 1                                     r3 = 1 as i32 as i64 as u64
    call function_649                       
    ldxdw r1, [r6+0x0]                      
    ldxdw r2, [r6+0x10]                     
lbb_908:
    mov64 r3, r1                                    r3 = r1
    add64 r3, r2                                    r3 += r2   ///  r3 = r3.wrapping_add(r2)
    stxb [r3+0x0], r8                       
    add64 r2, 1                                     r2 += 1   ///  r2 = r2.wrapping_add(1 as i32 as i64 as u64)
    stxdw [r6+0x10], r2                     
    jeq r8, 0, lbb_954                              if r8 == (0 as i32 as i64 as u64) { pc += 40 }
    ldxb r8, [r7+0x1]                       
    ldxdw r3, [r6+0x8]                      
    jne r3, r2, lbb_923                             if r3 != r2 { pc += 6 }
    mov64 r1, r6                                    r1 = r6
    mov64 r3, 1                                     r3 = 1 as i32 as i64 as u64
    call function_649                       
    ldxdw r1, [r6+0x0]                      
    ldxdw r3, [r6+0x8]                      
    ldxdw r2, [r6+0x10]                     
lbb_923:
    mov64 r4, r1                                    r4 = r1
    add64 r4, r2                                    r4 += r2   ///  r4 = r4.wrapping_add(r2)
    stxb [r4+0x0], r8                       
    add64 r2, 1                                     r2 += 1   ///  r2 = r2.wrapping_add(1 as i32 as i64 as u64)
    stxdw [r6+0x10], r2                     
    jne r3, r2, lbb_936                             if r3 != r2 { pc += 7 }
    mov64 r1, r6                                    r1 = r6
    mov64 r2, r3                                    r2 = r3
    mov64 r3, 1                                     r3 = 1 as i32 as i64 as u64
    call function_649                       
    ldxdw r3, [r6+0x8]                      
    ldxdw r1, [r6+0x0]                      
    ldxdw r2, [r6+0x10]                     
lbb_936:
    mov64 r4, r1                                    r4 = r1
    add64 r4, r2                                    r4 += r2   ///  r4 = r4.wrapping_add(r2)
    ldxb r5, [r7+0x2]                       
    stxb [r4+0x0], r5                       
    add64 r2, 1                                     r2 += 1   ///  r2 = r2.wrapping_add(1 as i32 as i64 as u64)
    stxdw [r6+0x10], r2                     
    jne r3, r2, lbb_949                             if r3 != r2 { pc += 6 }
    mov64 r1, r6                                    r1 = r6
    mov64 r2, r3                                    r2 = r3
    mov64 r3, 1                                     r3 = 1 as i32 as i64 as u64
    call function_649                       
    ldxdw r1, [r6+0x0]                      
    ldxdw r2, [r6+0x10]                     
lbb_949:
    add64 r1, r2                                    r1 += r2   ///  r1 = r1.wrapping_add(r2)
    ldxb r3, [r7+0x3]                       
lbb_951:
    stxb [r1+0x0], r3                       
    add64 r2, 1                                     r2 += 1   ///  r2 = r2.wrapping_add(1 as i32 as i64 as u64)
    stxdw [r6+0x10], r2                     
lbb_954:
    exit                                    

function_955:
    mov64 r6, r2                                    r6 = r2
    mov64 r7, r1                                    r7 = r1
    ldxdw r1, [r6+0x8]                      
    ldxdw r2, [r6+0x10]                     
    mov64 r3, r1                                    r3 = r1
    sub64 r3, r2                                    r3 -= r2   ///  r3 = r3.wrapping_sub(r2)
    ldxw r8, [r7+0x0]                       
    jgt r3, 3, lbb_968                              if r3 > (3 as i32 as i64 as u64) { pc += 5 }
    mov64 r1, r6                                    r1 = r6
    mov64 r3, 4                                     r3 = 4 as i32 as i64 as u64
    call function_649                       
    ldxdw r1, [r6+0x8]                      
    ldxdw r2, [r6+0x10]                     
lbb_968:
    ldxdw r3, [r6+0x0]                      
    mov64 r4, r3                                    r4 = r3
    add64 r4, r2                                    r4 += r2   ///  r4 = r4.wrapping_add(r2)
    stxw [r4+0x0], r8                       
    add64 r2, 4                                     r2 += 4   ///  r2 = r2.wrapping_add(4 as i32 as i64 as u64)
    stxdw [r6+0x10], r2                     
    mov64 r4, r1                                    r4 = r1
    sub64 r4, r2                                    r4 -= r2   ///  r4 = r4.wrapping_sub(r2)
    ldxw r8, [r7+0x4]                       
    jgt r4, 3, lbb_984                              if r4 > (3 as i32 as i64 as u64) { pc += 6 }
    mov64 r1, r6                                    r1 = r6
    mov64 r3, 4                                     r3 = 4 as i32 as i64 as u64
    call function_649                       
    ldxdw r1, [r6+0x8]                      
    ldxdw r3, [r6+0x0]                      
    ldxdw r2, [r6+0x10]                     
lbb_984:
    mov64 r4, r3                                    r4 = r3
    add64 r4, r2                                    r4 += r2   ///  r4 = r4.wrapping_add(r2)
    stxw [r4+0x0], r8                       
    add64 r2, 4                                     r2 += 4   ///  r2 = r2.wrapping_add(4 as i32 as i64 as u64)
    stxdw [r6+0x10], r2                     
    sub64 r1, r2                                    r1 -= r2   ///  r1 = r1.wrapping_sub(r2)
    ldxw r8, [r7+0x8]                       
    jgt r1, 3, lbb_997                              if r1 > (3 as i32 as i64 as u64) { pc += 5 }
    mov64 r1, r6                                    r1 = r6
    mov64 r3, 4                                     r3 = 4 as i32 as i64 as u64
    call function_649                       
    ldxdw r3, [r6+0x0]                      
    ldxdw r2, [r6+0x10]                     
lbb_997:
    add64 r3, r2                                    r3 += r2   ///  r3 = r3.wrapping_add(r2)
    stxw [r3+0x0], r8                       
    add64 r2, 4                                     r2 += 4   ///  r2 = r2.wrapping_add(4 as i32 as i64 as u64)
    stxdw [r6+0x10], r2                     
    ldxdw r1, [r6+0x8]                      
    sub64 r1, r2                                    r1 -= r2   ///  r1 = r1.wrapping_sub(r2)
    ldxw r7, [r7+0xc]                       
    jgt r1, 3, lbb_1009                             if r1 > (3 as i32 as i64 as u64) { pc += 4 }
    mov64 r1, r6                                    r1 = r6
    mov64 r3, 4                                     r3 = 4 as i32 as i64 as u64
    call function_649                       
    ldxdw r2, [r6+0x10]                     
lbb_1009:
    ldxdw r1, [r6+0x0]                      
    add64 r1, r2                                    r1 += r2   ///  r1 = r1.wrapping_add(r2)
    stxw [r1+0x0], r7                       
    add64 r2, 4                                     r2 += 4   ///  r2 = r2.wrapping_add(4 as i32 as i64 as u64)
    stxdw [r6+0x10], r2                     
    exit                                    

function_1015:
    ldxb r3, [r1+0x0]                       
    jne r3, 0, lbb_1023                             if r3 != (0 as i32 as i64 as u64) { pc += 6 }
    mov64 r1, r2                                    r1 = r2
    lddw r2, 0x10005fbb8 --> b"Good"                r2 load str located at 4295359416
    mov64 r3, 4                                     r3 = 4 as i32 as i64 as u64
    call function_45901                     
    ja lbb_1034                                     if true { pc += 11 }
lbb_1023:
    add64 r1, 1                                     r1 += 1   ///  r1 = r1.wrapping_add(1 as i32 as i64 as u64)
    stxdw [r10-0x8], r1                     
    mov64 r4, r10                                   r4 = r10
    add64 r4, -8                                    r4 += -8   ///  r4 = r4.wrapping_add(-8 as i32 as i64 as u64)
    mov64 r1, r2                                    r1 = r2
    lddw r2, 0x10005fbec --> b"Bad"                 r2 load str located at 4295359468
    mov64 r3, 3                                     r3 = 3 as i32 as i64 as u64
    lddw r5, 0x100064b20 --> b"\x00\x00\x00\x00\xa0\x0c\x00\x00\x08\x00\x00\x00\x00\x00\x00\x00\x08\x00\…        r5 load str located at 4295379744
    call function_46104                     
lbb_1034:
    exit                                    

function_1035:
    ldxdw r3, [r2+0x8]                      
    ldxdw r5, [r3+0x0]                      
    add64 r5, 1                                     r5 += 1   ///  r5 = r5.wrapping_add(1 as i32 as i64 as u64)
    mov64 r0, 1                                     r0 = 1 as i32 as i64 as u64
    jeq r5, 0, lbb_1041                             if r5 == (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r0, 0                                     r0 = 0 as i32 as i64 as u64
lbb_1041:
    ldxdw r4, [r2+0x0]                      
    stxdw [r3+0x0], r5                      
    jne r0, 1, lbb_1046                             if r0 != (1 as i32 as i64 as u64) { pc += 2 }
lbb_1044:
    syscall [invalid]                       
    syscall [invalid]                       
lbb_1046:
    ldxdw r5, [r2+0x10]                     
    ldxdw r0, [r5+0x0]                      
    add64 r0, 1                                     r0 += 1   ///  r0 = r0.wrapping_add(1 as i32 as i64 as u64)
    mov64 r6, 1                                     r6 = 1 as i32 as i64 as u64
    jeq r0, 0, lbb_1052                             if r0 == (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r6, 0                                     r6 = 0 as i32 as i64 as u64
lbb_1052:
    stxdw [r5+0x0], r0                      
    jne r6, 1, lbb_1055                             if r6 != (1 as i32 as i64 as u64) { pc += 1 }
    ja lbb_1044                                     if true { pc += -11 }
lbb_1055:
    ldxdw r0, [r2+0x18]                     
    ldxdw r6, [r2+0x20]                     
    ldxb r7, [r2+0x28]                      
    ldxb r8, [r2+0x29]                      
    ldxb r2, [r2+0x2a]                      
    stxb [r1+0x2a], r2                      
    stxb [r1+0x29], r8                      
    stxb [r1+0x28], r7                      
    stxdw [r1+0x20], r6                     
    stxdw [r1+0x18], r0                     
    stxdw [r1+0x10], r5                     
    stxdw [r1+0x8], r3                      
    stxdw [r1+0x0], r4                      
    exit                                    

function_1069:
    mov64 r2, 14                                    r2 = 14 as i32 as i64 as u64
    stxdw [r10-0x60], r2                    
    lddw r2, 0x100060515 --> b"from_bytes_mutFailed to add pubkey to shitlist, li"        r2 load str located at 4295361813
    stxdw [r10-0x68], r2                    
    stxb [r10-0x51], r1                     
    lddw r1, 0x100052288 --> b"\xbf#\x00\x00\x00\x00\x00\x00{\x1a\x88\xff\x00\x00\x00\x00\xb7\x01\x00\x0…        r1 load str located at 4295303816
    stxdw [r10-0x8], r1                     
    mov64 r1, r10                                   r1 = r10
    add64 r1, -81                                   r1 += -81   ///  r1 = r1.wrapping_add(-81 as i32 as i64 as u64)
    stxdw [r10-0x10], r1                    
    lddw r1, 0x100000860 --> b"\xbf#\x00\x00\x00\x00\x00\x00y\x12\x08\x00\x00\x00\x00\x00y\x11\x00\x00\x…        r1 load str located at 4294969440
    stxdw [r10-0x18], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -104                                  r1 += -104   ///  r1 = r1.wrapping_add(-104 as i32 as i64 as u64)
    stxdw [r10-0x20], r1                    
    mov64 r6, r10                                   r6 = r10
    add64 r6, -80                                   r6 += -80   ///  r6 = r6.wrapping_add(-80 as i32 as i64 as u64)
    mov64 r4, r10                                   r4 = r10
    add64 r4, -32                                   r4 += -32   ///  r4 = r4.wrapping_add(-32 as i32 as i64 as u64)
    mov64 r1, r6                                    r1 = r6
    lddw r2, 0x100064bb0 --> b"\x00\x00"            r2 load str located at 4295379888
    mov64 r3, 2                                     r3 = 2 as i32 as i64 as u64
    mov64 r5, 2                                     r5 = 2 as i32 as i64 as u64
    call function_259                       
    mov64 r1, r6                                    r1 = r6
    lddw r2, 0x100064bd0 --> b"\x00\x00\x00\x00\x10\xfe\x05\x00\x0f\x00\x00\x00\x00\x00\x00\x00!\x00\x00…        r2 load str located at 4295379920
    call function_44240                     
    syscall [invalid]                       

function_1102:
    mov64 r6, r1                                    r6 = r1
    mov64 r1, 37                                    r1 = 37 as i32 as i64 as u64
    stxdw [r10-0xa8], r1                    
    lddw r1, 0x10006063c --> b"Improperly formatted instruction dataSwap instruct"        r1 load str located at 4295362108
    stxdw [r10-0xb0], r1                    
    ldxdw r1, [r2+0x0]                      
    jeq r1, 0, lbb_1118                             if r1 == (0 as i32 as i64 as u64) { pc += 8 }
    add64 r2, 8                                     r2 += 8   ///  r2 = r2.wrapping_add(8 as i32 as i64 as u64)
    mov64 r1, r6                                    r1 = r6
    add64 r1, 8                                     r1 += 8   ///  r1 = r1.wrapping_add(8 as i32 as i64 as u64)
    mov64 r7, 56                                    r7 = 56 as i32 as i64 as u64
    mov64 r3, 56                                    r3 = 56 as i32 as i64 as u64
    call function_48190                     
    stxb [r6+0x0], r7                       
    ja lbb_1187                                     if true { pc += 69 }
lbb_1118:
    lddw r1, 0x100064be8 --> b"\x00\x00\x00\x00\x1f\xfe\x05\x00\x1b\x00\x00\x00\x00\x00\x00\x00~\x00\x00…        r1 load str located at 4295379944
    stxdw [r10-0xa0], r1                    
    lddw r1, 0x100064c00 --> b"\x00\x00\x00\x00p\xfa\x05\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00…        r1 load str located at 4295379968
    stxdw [r10-0x80], r1                    
    mov64 r1, 2                                     r1 = 2 as i32 as i64 as u64
    stxdw [r10-0x78], r1                    
    stxdw [r10-0x68], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -80                                   r1 += -80   ///  r1 = r1.wrapping_add(-80 as i32 as i64 as u64)
    stxdw [r10-0x70], r1                    
    lddw r1, 0x100000888 --> b"y\x11\x00\x00\x00\x00\x00\x00\x85\x10\x00\x00]\xab\x00\x00\x95\x00\x00\x0…        r1 load str located at 4294969480
    stxdw [r10-0x38], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -160                                  r1 += -160   ///  r1 = r1.wrapping_add(-160 as i32 as i64 as u64)
    stxdw [r10-0x40], r1                    
    lddw r1, 0x100000860 --> b"\xbf#\x00\x00\x00\x00\x00\x00y\x12\x08\x00\x00\x00\x00\x00y\x11\x00\x00\x…        r1 load str located at 4294969440
    stxdw [r10-0x48], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -176                                  r1 += -176   ///  r1 = r1.wrapping_add(-176 as i32 as i64 as u64)
    stxdw [r10-0x50], r1                    
    mov64 r8, 0                                     r8 = 0 as i32 as i64 as u64
    stxdw [r10-0x60], r8                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -152                                  r1 += -152   ///  r1 = r1.wrapping_add(-152 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -128                                  r2 += -128   ///  r2 = r2.wrapping_add(-128 as i32 as i64 as u64)
    call function_43415                     
    ldxdw r1, [r10-0x98]                    
    ldxdw r2, [r10-0x88]                    
    syscall [invalid]                       
    lddw r1, 0x300000000                            r1 load str located at 12884901888
    ldxdw r1, [r1+0x0]                      
    mov64 r3, 1                                     r3 = 1 as i32 as i64 as u64
    mov64 r2, r1                                    r2 = r1
    add64 r2, -37                                   r2 += -37   ///  r2 = r2.wrapping_add(-37 as i32 as i64 as u64)
    jgt r2, r1, lbb_1160                            if r2 > r1 { pc += 1 }
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
lbb_1160:
    jne r3, 0, lbb_1162                             if r3 != (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r8, r2                                    r8 = r2
lbb_1162:
    lddw r7, 0x300007fdb                            r7 load str located at 12884934619
    jeq r1, 0, lbb_1166                             if r1 == (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r7, r8                                    r7 = r8
lbb_1166:
    lddw r1, 0x300000007                            r1 load str located at 12884901895
    jgt r7, r1, lbb_1173                            if r7 > r1 { pc += 4 }
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    mov64 r2, 37                                    r2 = 37 as i32 as i64 as u64
    call function_43400                     
    syscall [invalid]                       
lbb_1173:
    lddw r1, 0x300000000                            r1 load str located at 12884901888
    stxdw [r1+0x0], r7                      
    mov64 r8, 37                                    r8 = 37 as i32 as i64 as u64
    mov64 r1, r7                                    r1 = r7
    lddw r2, 0x10006063c --> b"Improperly formatted instruction data"        r2 load str located at 4295362108
    mov64 r3, 37                                    r3 = 37 as i32 as i64 as u64
    call function_48190                     
    stxdw [r6+0x18], r8                     
    stxdw [r6+0x10], r8                     
    stxdw [r6+0x8], r7                      
    mov64 r1, 29                                    r1 = 29 as i32 as i64 as u64
    stxb [r6+0x0], r1                       
lbb_1187:
    exit                                    

function_1188:
    mov64 r6, r1                                    r6 = r1
    mov64 r1, 16                                    r1 = 16 as i32 as i64 as u64
    stxdw [r10-0xc0], r1                    
    lddw r1, 0x10005fc38 --> b"Bad instructionsconnection reset) when slicing `)."        r1 load str located at 4295359544
    stxdw [r10-0xc8], r1                    
    ldxdw r1, [r2+0x0]                      
    jne r1, 0, lbb_1203                             if r1 != (0 as i32 as i64 as u64) { pc += 7 }
    add64 r2, 8                                     r2 += 8   ///  r2 = r2.wrapping_add(8 as i32 as i64 as u64)
    mov64 r1, r6                                    r1 = r6
    add64 r1, 8                                     r1 += 8   ///  r1 = r1.wrapping_add(8 as i32 as i64 as u64)
    mov64 r3, 72                                    r3 = 72 as i32 as i64 as u64
    call function_48190                     
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    ja lbb_1294                                     if true { pc += 91 }
lbb_1203:
    ldxdw r1, [r2+0x8]                      
    stxdw [r10-0xb8], r1                    
    lddw r1, 0x100064c20 --> b"\x00\x00\x00\x00\x1f\xfe\x05\x00\x1b\x00\x00\x00\x00\x00\x00\x00k\x00\x00…        r1 load str located at 4295380000
    stxdw [r10-0xb0], r1                    
    lddw r1, 0x100064c38 --> b"\x00\x00\x00\x00p\xfa\x05\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00…        r1 load str located at 4295380024
    stxdw [r10-0x90], r1                    
    mov64 r1, 3                                     r1 = 3 as i32 as i64 as u64
    stxdw [r10-0x88], r1                    
    stxdw [r10-0x78], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -96                                   r1 += -96   ///  r1 = r1.wrapping_add(-96 as i32 as i64 as u64)
    stxdw [r10-0x80], r1                    
    lddw r1, 0x100000888 --> b"y\x11\x00\x00\x00\x00\x00\x00\x85\x10\x00\x00]\xab\x00\x00\x95\x00\x00\x0…        r1 load str located at 4294969480
    stxdw [r10-0x38], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -176                                  r1 += -176   ///  r1 = r1.wrapping_add(-176 as i32 as i64 as u64)
    stxdw [r10-0x40], r1                    
    lddw r1, 0x100053d80 --> b"\xbf&\x00\x00\x00\x00\x00\x00y\x11\x00\x00\x00\x00\x00\x00\xbf\x12\x00\x0…        r1 load str located at 4295310720
    stxdw [r10-0x48], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -184                                  r1 += -184   ///  r1 = r1.wrapping_add(-184 as i32 as i64 as u64)
    stxdw [r10-0x50], r1                    
    lddw r1, 0x100000860 --> b"\xbf#\x00\x00\x00\x00\x00\x00y\x12\x08\x00\x00\x00\x00\x00y\x11\x00\x00\x…        r1 load str located at 4294969440
    stxdw [r10-0x58], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -200                                  r1 += -200   ///  r1 = r1.wrapping_add(-200 as i32 as i64 as u64)
    stxdw [r10-0x60], r1                    
    mov64 r8, 0                                     r8 = 0 as i32 as i64 as u64
    stxdw [r10-0x70], r8                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -168                                  r1 += -168   ///  r1 = r1.wrapping_add(-168 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -144                                  r2 += -144   ///  r2 = r2.wrapping_add(-144 as i32 as i64 as u64)
    call function_43415                     
    ldxdw r1, [r10-0xa8]                    
    ldxdw r2, [r10-0x98]                    
    syscall [invalid]                       
    lddw r1, 0x300000000                            r1 load str located at 12884901888
    ldxdw r1, [r1+0x0]                      
    mov64 r3, 1                                     r3 = 1 as i32 as i64 as u64
    mov64 r2, r1                                    r2 = r1
    add64 r2, -16                                   r2 += -16   ///  r2 = r2.wrapping_add(-16 as i32 as i64 as u64)
    jgt r2, r1, lbb_1253                            if r2 > r1 { pc += 1 }
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
lbb_1253:
    jne r3, 0, lbb_1255                             if r3 != (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r8, r2                                    r8 = r2
lbb_1255:
    lddw r7, 0x300007ff0                            r7 load str located at 12884934640
    jeq r1, 0, lbb_1259                             if r1 == (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r7, r8                                    r7 = r8
lbb_1259:
    lddw r1, 0x300000007                            r1 load str located at 12884901895
    jgt r7, r1, lbb_1266                            if r7 > r1 { pc += 4 }
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    mov64 r2, 16                                    r2 = 16 as i32 as i64 as u64
    call function_43400                     
    syscall [invalid]                       
lbb_1266:
    ldxdw r2, [r10-0xb8]                    
    lddw r1, 0x300000000                            r1 load str located at 12884901888
    stxdw [r1+0x0], r7                      
    lddw r1, 0x736e6f6974637572                     r1 load str located at 8317708060514809202
    stxdw [r7+0x8], r1                      
    lddw r1, 0x74736e6920646142                     r1 load str located at 8391171928515436866
    stxdw [r7+0x0], r1                      
    mov64 r1, r2                                    r1 = r2
    and64 r1, 3                                     r1 &= 3   ///  r1 = r1.and(3)
    mov64 r3, r1                                    r3 = r1
    add64 r3, -2                                    r3 += -2   ///  r3 = r3.wrapping_add(-2 as i32 as i64 as u64)
    mov64 r4, 2                                     r4 = 2 as i32 as i64 as u64
    jgt r4, r3, lbb_1287                            if r4 > r3 { pc += 5 }
    jeq r1, 0, lbb_1287                             if r1 == (0 as i32 as i64 as u64) { pc += 4 }
    ldxdw r1, [r2-0x1]                      
    ldxdw r2, [r2+0x7]                      
    ldxdw r2, [r2+0x0]                      
    callx r2                                
lbb_1287:
    mov64 r1, 16                                    r1 = 16 as i32 as i64 as u64
    stxdw [r6+0x20], r1                     
    stxdw [r6+0x18], r1                     
    stxdw [r6+0x10], r7                     
    mov64 r1, 29                                    r1 = 29 as i32 as i64 as u64
    stxb [r6+0x8], r1                       
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
lbb_1294:
    stxdw [r6+0x0], r1                      
    exit                                    

function_1296:
    mov64 r6, r1                                    r6 = r1
    mov64 r1, 24                                    r1 = 24 as i32 as i64 as u64
    stxdw [r10-0xd8], r1                    
    lddw r1, 0x100060b14 --> b"Bad token account passedWrong oracle passed for co"        r1 load str located at 4295363348
    stxdw [r10-0xe0], r1                    
    ldxw r1, [r2+0x88]                      
    jeq r1, 2, lbb_1308                             if r1 == (2 as i32 as i64 as u64) { pc += 4 }
    mov64 r1, r6                                    r1 = r6
    mov64 r3, 176                                   r3 = 176 as i32 as i64 as u64
    call function_48190                     
    ja lbb_1397                                     if true { pc += 89 }
lbb_1308:
    ldxdw r1, [r2+0x18]                     
    stxdw [r10-0xb8], r1                    
    ldxdw r1, [r2+0x10]                     
    stxdw [r10-0xc0], r1                    
    ldxdw r1, [r2+0x8]                      
    stxdw [r10-0xc8], r1                    
    ldxdw r1, [r2+0x0]                      
    stxdw [r10-0xd0], r1                    
    lddw r1, 0x100064c20 --> b"\x00\x00\x00\x00\x1f\xfe\x05\x00\x1b\x00\x00\x00\x00\x00\x00\x00k\x00\x00…        r1 load str located at 4295380000
    stxdw [r10-0xb0], r1                    
    lddw r1, 0x100064c38 --> b"\x00\x00\x00\x00p\xfa\x05\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00…        r1 load str located at 4295380024
    stxdw [r10-0x90], r1                    
    mov64 r1, 3                                     r1 = 3 as i32 as i64 as u64
    stxdw [r10-0x88], r1                    
    stxdw [r10-0x78], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -96                                   r1 += -96   ///  r1 = r1.wrapping_add(-96 as i32 as i64 as u64)
    stxdw [r10-0x80], r1                    
    lddw r1, 0x100000888 --> b"y\x11\x00\x00\x00\x00\x00\x00\x85\x10\x00\x00]\xab\x00\x00\x95\x00\x00\x0…        r1 load str located at 4294969480
    stxdw [r10-0x38], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -176                                  r1 += -176   ///  r1 = r1.wrapping_add(-176 as i32 as i64 as u64)
    stxdw [r10-0x40], r1                    
    lddw r1, 0x100051998 --> b"\xbf#\x00\x00\x00\x00\x00\x00a\x12\x00\x00\x00\x00\x00\x00e\x02\x09\x00\x…        r1 load str located at 4295301528
    stxdw [r10-0x48], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -208                                  r1 += -208   ///  r1 = r1.wrapping_add(-208 as i32 as i64 as u64)
    stxdw [r10-0x50], r1                    
    lddw r1, 0x100000860 --> b"\xbf#\x00\x00\x00\x00\x00\x00y\x12\x08\x00\x00\x00\x00\x00y\x11\x00\x00\x…        r1 load str located at 4294969440
    stxdw [r10-0x58], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -224                                  r1 += -224   ///  r1 = r1.wrapping_add(-224 as i32 as i64 as u64)
    stxdw [r10-0x60], r1                    
    mov64 r7, 0                                     r7 = 0 as i32 as i64 as u64
    stxdw [r10-0x70], r7                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -168                                  r1 += -168   ///  r1 = r1.wrapping_add(-168 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -144                                  r2 += -144   ///  r2 = r2.wrapping_add(-144 as i32 as i64 as u64)
    call function_43415                     
    ldxdw r1, [r10-0xa8]                    
    ldxdw r2, [r10-0x98]                    
    syscall [invalid]                       
    lddw r1, 0x300000000                            r1 load str located at 12884901888
    ldxdw r2, [r1+0x0]                      
    mov64 r3, 1                                     r3 = 1 as i32 as i64 as u64
    mov64 r1, r2                                    r1 = r2
    add64 r1, -24                                   r1 += -24   ///  r1 = r1.wrapping_add(-24 as i32 as i64 as u64)
    jgt r1, r2, lbb_1364                            if r1 > r2 { pc += 1 }
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
lbb_1364:
    jne r3, 0, lbb_1366                             if r3 != (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r7, r1                                    r7 = r1
lbb_1366:
    lddw r1, 0x300007fe8                            r1 load str located at 12884934632
    jeq r2, 0, lbb_1370                             if r2 == (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r1, r7                                    r1 = r7
lbb_1370:
    lddw r2, 0x300000007                            r2 load str located at 12884901895
    jgt r1, r2, lbb_1377                            if r1 > r2 { pc += 4 }
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    mov64 r2, 24                                    r2 = 24 as i32 as i64 as u64
    call function_43400                     
    syscall [invalid]                       
lbb_1377:
    lddw r2, 0x300000000                            r2 load str located at 12884901888
    stxdw [r2+0x0], r1                      
    lddw r2, 0x6465737361702074                     r2 load str located at 7234315315833741428
    stxdw [r1+0x10], r2                     
    lddw r2, 0x6e756f636361206e                     r2 load str located at 7959390389106974830
    stxdw [r1+0x8], r2                      
    lddw r2, 0x656b6f7420646142                     r2 load str located at 7308057364889100610
    stxdw [r1+0x0], r2                      
    mov64 r2, 2                                     r2 = 2 as i32 as i64 as u64
    stxw [r6+0x88], r2                      
    mov64 r2, 24                                    r2 = 24 as i32 as i64 as u64
    stxdw [r6+0x18], r2                     
    stxdw [r6+0x10], r2                     
    stxdw [r6+0x8], r1                      
    mov64 r1, 29                                    r1 = 29 as i32 as i64 as u64
    stxb [r6+0x0], r1                       
lbb_1397:
    exit                                    

function_1398:
    mov64 r7, r1                                    r7 = r1
    mov64 r6, 0                                     r6 = 0 as i32 as i64 as u64
    stxdw [r10-0x8], r6                     
    ldxdw r3, [r2+0x8]                      
    jgt r3, 3, lbb_1410                             if r3 > (3 as i32 as i64 as u64) { pc += 7 }
    lddw r1, 0x100064a98 --> b"\x00\x00\x00\x00\xaa\xfa\x05\x00\x1b\x00\x00\x00\x00\x00\x00\x00%\x00\x00…        r1 load str located at 4295379608
    call function_42270                     
lbb_1406:
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    stxw [r7+0x0], r1                       
    stxdw [r7+0x8], r0                      
    ja lbb_1745                                     if true { pc += 335 }
lbb_1410:
    stxdw [r10-0x188], r7                   
    ldxdw r1, [r2+0x0]                      
    stxdw [r10-0x180], r1                   
    mov64 r1, 4                                     r1 = 4 as i32 as i64 as u64
    mov64 r9, 0                                     r9 = 0 as i32 as i64 as u64
    stxdw [r10-0x190], r3                   
    mov64 r7, r3                                    r7 = r3
    mov64 r0, 0                                     r0 = 0 as i32 as i64 as u64
    ja lbb_1423                                     if true { pc += 4 }
lbb_1419:
    add64 r6, -4                                    r6 += -4   ///  r6 = r6.wrapping_add(-4 as i32 as i64 as u64)
    add64 r7, -4                                    r7 += -4   ///  r7 = r7.wrapping_add(-4 as i32 as i64 as u64)
    mov64 r9, r0                                    r9 = r0
    jgt r1, r7, lbb_1769                            if r1 > r7 { pc += 346 }
lbb_1423:
    mov64 r4, r10                                   r4 = r10
    add64 r4, -136                                  r4 += -136   ///  r4 = r4.wrapping_add(-136 as i32 as i64 as u64)
    add64 r4, r9                                    r4 += r9   ///  r4 = r4.wrapping_add(r9)
    ldxdw r3, [r10-0x180]                   
    add64 r3, r9                                    r3 += r9   ///  r3 = r3.wrapping_add(r9)
    ldxw r5, [r3+0x0]                       
    stxw [r4+0x0], r5                       
    ldxdw r8, [r10-0x8]                     
    add64 r8, 1                                     r8 += 1   ///  r8 = r8.wrapping_add(1 as i32 as i64 as u64)
    stxdw [r10-0x8], r8                     
    add64 r0, 4                                     r0 += 4   ///  r0 = r0.wrapping_add(4 as i32 as i64 as u64)
    jeq r0, 128, lbb_1436                           if r0 == (128 as i32 as i64 as u64) { pc += 1 }
    ja lbb_1419                                     if true { pc += -17 }
lbb_1436:
    ldxdw r8, [r10-0x190]                   
    mov64 r1, r8                                    r1 = r8
    sub64 r1, r9                                    r1 -= r9   ///  r1 = r1.wrapping_sub(r9)
    add64 r1, -4                                    r1 += -4   ///  r1 = r1.wrapping_add(-4 as i32 as i64 as u64)
    stxdw [r10-0x1a8], r1                   
    stxdw [r2+0x8], r1                      
    add64 r3, 4                                     r3 += 4   ///  r3 = r3.wrapping_add(4 as i32 as i64 as u64)
    stxdw [r10-0x198], r2                   
    stxdw [r2+0x0], r3                      
    ldxdw r1, [r10-0x84]                    
    stxdw [r10-0x1b0], r1                   
    ldxw r1, [r10-0x88]                     
    stxdw [r10-0x1a0], r1                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -376                                  r1 += -376   ///  r1 = r1.wrapping_add(-376 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -124                                  r2 += -124   ///  r2 = r2.wrapping_add(-124 as i32 as i64 as u64)
    mov64 r3, 116                                   r3 = 116 as i32 as i64 as u64
    call function_48190                     
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    stxdw [r10-0x68], r1                    
    add64 r8, -4                                    r8 += -4   ///  r8 = r8.wrapping_add(-4 as i32 as i64 as u64)
    jeq r8, r9, lbb_1719                            if r8 == r9 { pc += 260 }
    ldxdw r2, [r10-0x1a0]                   
    ldxdw r2, [r10-0x180]                   
    add64 r2, r9                                    r2 += r9   ///  r2 = r2.wrapping_add(r9)
    ldxdw r0, [r10-0x198]                   
    ldxdw r5, [r10-0x1a8]                   
    ja lbb_1467                                     if true { pc += 2 }
lbb_1465:
    add64 r1, 1                                     r1 += 1   ///  r1 = r1.wrapping_add(1 as i32 as i64 as u64)
    jeq r5, r1, lbb_1725                            if r5 == r1 { pc += 258 }
lbb_1467:
    mov64 r3, r10                                   r3 = r10
    add64 r3, -136                                  r3 += -136   ///  r3 = r3.wrapping_add(-136 as i32 as i64 as u64)
    add64 r3, r1                                    r3 += r1   ///  r3 = r3.wrapping_add(r1)
    mov64 r4, r2                                    r4 = r2
    add64 r4, r1                                    r4 += r1   ///  r4 = r4.wrapping_add(r1)
    ldxb r4, [r4+0x4]                       
    stxb [r3+0x0], r4                       
    ldxdw r8, [r10-0x68]                    
    add64 r8, 1                                     r8 += 1   ///  r8 = r8.wrapping_add(1 as i32 as i64 as u64)
    stxdw [r10-0x68], r8                    
    jeq r1, 31, lbb_1479                            if r1 == (31 as i32 as i64 as u64) { pc += 1 }
    ja lbb_1465                                     if true { pc += -14 }
lbb_1479:
    add64 r9, r1                                    r9 += r1   ///  r9 = r9.wrapping_add(r1)
    mov64 r2, r9                                    r2 = r9
    ldxdw r3, [r10-0x180]                   
    add64 r2, r3                                    r2 += r3   ///  r2 = r2.wrapping_add(r3)
    add64 r2, 5                                     r2 += 5   ///  r2 = r2.wrapping_add(5 as i32 as i64 as u64)
    stxdw [r0+0x0], r2                      
    sub64 r7, r1                                    r7 -= r1   ///  r7 = r7.wrapping_sub(r1)
    add64 r7, -5                                    r7 += -5   ///  r7 = r7.wrapping_add(-5 as i32 as i64 as u64)
    stxdw [r0+0x8], r7                      
    ldxb r4, [r10-0x69]                     
    ldxb r5, [r10-0x6a]                     
    ldxb r8, [r10-0x6b]                     
    ldxb r2, [r10-0x6c]                     
    stxdw [r10-0x1a8], r2                   
    ldxb r2, [r10-0x6d]                     
    stxdw [r10-0x1b8], r2                   
    ldxb r2, [r10-0x6e]                     
    stxdw [r10-0x1c0], r2                   
    ldxb r2, [r10-0x6f]                     
    stxdw [r10-0x1c8], r2                   
    ldxb r2, [r10-0x70]                     
    stxdw [r10-0x1d0], r2                   
    ldxb r2, [r10-0x71]                     
    stxdw [r10-0x1d8], r2                   
    ldxb r2, [r10-0x72]                     
    stxdw [r10-0x1e0], r2                   
    ldxb r2, [r10-0x73]                     
    stxdw [r10-0x1e8], r2                   
    ldxb r2, [r10-0x74]                     
    stxdw [r10-0x1f0], r2                   
    ldxb r2, [r10-0x75]                     
    stxdw [r10-0x1f8], r2                   
    ldxb r2, [r10-0x76]                     
    stxdw [r10-0x200], r2                   
    ldxb r2, [r10-0x77]                     
    stxdw [r10-0x208], r2                   
    ldxb r2, [r10-0x78]                     
    stxdw [r10-0x210], r2                   
    ldxb r2, [r10-0x79]                     
    stxdw [r10-0x218], r2                   
    ldxb r2, [r10-0x7a]                     
    stxdw [r10-0x220], r2                   
    ldxb r2, [r10-0x7b]                     
    stxdw [r10-0x228], r2                   
    ldxb r2, [r10-0x7c]                     
    stxdw [r10-0x230], r2                   
    ldxb r2, [r10-0x7d]                     
    stxdw [r10-0x238], r2                   
    ldxb r2, [r10-0x7e]                     
    stxdw [r10-0x240], r2                   
    ldxb r2, [r10-0x7f]                     
    stxdw [r10-0x248], r2                   
    ldxb r2, [r10-0x80]                     
    stxdw [r10-0x290], r2                   
    ldxb r2, [r10-0x81]                     
    stxdw [r10-0x288], r2                   
    ldxb r2, [r10-0x82]                     
    stxdw [r10-0x280], r2                   
    ldxb r2, [r10-0x83]                     
    stxdw [r10-0x278], r2                   
    ldxb r2, [r10-0x84]                     
    stxdw [r10-0x270], r2                   
    ldxb r2, [r10-0x85]                     
    stxdw [r10-0x268], r2                   
    ldxb r2, [r10-0x86]                     
    stxdw [r10-0x260], r2                   
    ldxb r2, [r10-0x87]                     
    stxdw [r10-0x258], r2                   
    ldxb r2, [r10-0x88]                     
    stxdw [r10-0x250], r2                   
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
    stxdw [r10-0x8], r2                     
    mov64 r3, 4                                     r3 = 4 as i32 as i64 as u64
    jgt r3, r7, lbb_1738                            if r3 > r7 { pc += 185 }
    stxdw [r10-0x2a8], r8                   
    stxdw [r10-0x2a0], r5                   
    stxdw [r10-0x298], r4                   
    sub64 r6, r1                                    r6 -= r1   ///  r6 = r6.wrapping_sub(r1)
    ldxdw r1, [r10-0x190]                   
    add64 r1, -9                                    r1 += -9   ///  r1 = r1.wrapping_add(-9 as i32 as i64 as u64)
    ja lbb_1566                                     if true { pc += 6 }
lbb_1560:
    add64 r6, -4                                    r6 += -4   ///  r6 = r6.wrapping_add(-4 as i32 as i64 as u64)
    mov64 r4, r1                                    r4 = r1
    add64 r4, r6                                    r4 += r6   ///  r4 = r4.wrapping_add(r6)
    add64 r9, 4                                     r9 += 4   ///  r9 = r9.wrapping_add(4 as i32 as i64 as u64)
    add64 r4, 4                                     r4 += 4   ///  r4 = r4.wrapping_add(4 as i32 as i64 as u64)
    jgt r3, r4, lbb_1746                            if r3 > r4 { pc += 180 }
lbb_1566:
    mov64 r4, r10                                   r4 = r10
    add64 r4, -136                                  r4 += -136   ///  r4 = r4.wrapping_add(-136 as i32 as i64 as u64)
    add64 r4, r2                                    r4 += r2   ///  r4 = r4.wrapping_add(r2)
    ldxdw r7, [r10-0x180]                   
    add64 r7, r9                                    r7 += r9   ///  r7 = r7.wrapping_add(r9)
    ldxw r5, [r7+0x5]                       
    stxw [r4+0x0], r5                       
    ldxdw r8, [r10-0x8]                     
    add64 r8, 1                                     r8 += 1   ///  r8 = r8.wrapping_add(1 as i32 as i64 as u64)
    stxdw [r10-0x8], r8                     
    add64 r2, 4                                     r2 += 4   ///  r2 = r2.wrapping_add(4 as i32 as i64 as u64)
    jeq r2, 128, lbb_1579                           if r2 == (128 as i32 as i64 as u64) { pc += 1 }
    ja lbb_1560                                     if true { pc += -19 }
lbb_1579:
    ldxdw r6, [r10-0x190]                   
    mov64 r1, r6                                    r1 = r6
    sub64 r1, r9                                    r1 -= r9   ///  r1 = r1.wrapping_sub(r9)
    add64 r1, -9                                    r1 += -9   ///  r1 = r1.wrapping_add(-9 as i32 as i64 as u64)
    stxdw [r0+0x8], r1                      
    add64 r7, 9                                     r7 += 9   ///  r7 = r7.wrapping_add(9 as i32 as i64 as u64)
    stxdw [r0+0x0], r7                      
    ldxdw r1, [r10-0x84]                    
    stxdw [r10-0x180], r1                   
    ldxw r8, [r10-0x88]                     
    mov64 r1, r10                                   r1 = r10
    add64 r1, -256                                  r1 += -256   ///  r1 = r1.wrapping_add(-256 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -124                                  r2 += -124   ///  r2 = r2.wrapping_add(-124 as i32 as i64 as u64)
    mov64 r3, 116                                   r3 = 116 as i32 as i64 as u64
    call function_48190                     
    sub64 r9, r6                                    r9 -= r6   ///  r9 = r9.wrapping_sub(r6)
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    stxdw [r10-0x68], r1                    
    jeq r9, -9, lbb_1738                            if r9 == (-9 as i32 as i64 as u64) { pc += 139 }
    stxdw [r10-0x190], r8                   
    add64 r9, 10                                    r9 += 10   ///  r9 = r9.wrapping_add(10 as i32 as i64 as u64)
    ldxdw r4, [r10-0x198]                   
    ja lbb_1607                                     if true { pc += 4 }
lbb_1603:
    add64 r7, 1                                     r7 += 1   ///  r7 = r7.wrapping_add(1 as i32 as i64 as u64)
    add64 r1, 1                                     r1 += 1   ///  r1 = r1.wrapping_add(1 as i32 as i64 as u64)
    add64 r9, 1                                     r9 += 1   ///  r9 = r9.wrapping_add(1 as i32 as i64 as u64)
    jeq r9, 1, lbb_1760                             if r9 == (1 as i32 as i64 as u64) { pc += 153 }
lbb_1607:
    mov64 r2, r10                                   r2 = r10
    add64 r2, -136                                  r2 += -136   ///  r2 = r2.wrapping_add(-136 as i32 as i64 as u64)
    add64 r2, r1                                    r2 += r1   ///  r2 = r2.wrapping_add(r1)
    ldxb r3, [r7+0x0]                       
    stxb [r2+0x0], r3                       
    ldxdw r8, [r10-0x68]                    
    add64 r8, 1                                     r8 += 1   ///  r8 = r8.wrapping_add(1 as i32 as i64 as u64)
    stxdw [r10-0x68], r8                    
    jeq r1, 31, lbb_1617                            if r1 == (31 as i32 as i64 as u64) { pc += 1 }
    ja lbb_1603                                     if true { pc += -14 }
lbb_1617:
    neg64 r9                                        r9 = -r9   ///  r9 = (r9 as i64).wrapping_neg() as u64
    stxdw [r4+0x8], r9                      
    add64 r7, 1                                     r7 += 1   ///  r7 = r7.wrapping_add(1 as i32 as i64 as u64)
    stxdw [r4+0x0], r7                      
    ldxdw r1, [r10-0x88]                    
    stxdw [r10-0x198], r1                   
    ldxdw r8, [r10-0x80]                    
    ldxdw r9, [r10-0x78]                    
    ldxdw r6, [r10-0x70]                    
    ldxdw r7, [r10-0x188]                   
    mov64 r1, r7                                    r1 = r7
    add64 r1, 16                                    r1 += 16   ///  r1 = r1.wrapping_add(16 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -376                                  r2 += -376   ///  r2 = r2.wrapping_add(-376 as i32 as i64 as u64)
    mov64 r3, 116                                   r3 = 116 as i32 as i64 as u64
    call function_48190                     
    mov64 r1, r7                                    r1 = r7
    add64 r1, 176                                   r1 += 176   ///  r1 = r1.wrapping_add(176 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -256                                  r2 += -256   ///  r2 = r2.wrapping_add(-256 as i32 as i64 as u64)
    mov64 r3, 116                                   r3 = 116 as i32 as i64 as u64
    call function_48190                     
    stxdw [r7+0x13c], r6                    
    stxdw [r7+0x134], r9                    
    stxdw [r7+0x12c], r8                    
    ldxdw r1, [r10-0x198]                   
    stxdw [r7+0x124], r1                    
    ldxdw r1, [r10-0x290]                   
    stxb [r7+0x8c], r1                      
    ldxdw r1, [r10-0x288]                   
    stxb [r7+0x8b], r1                      
    ldxdw r1, [r10-0x280]                   
    stxb [r7+0x8a], r1                      
    ldxdw r1, [r10-0x278]                   
    stxb [r7+0x89], r1                      
    ldxdw r1, [r10-0x270]                   
    stxb [r7+0x88], r1                      
    ldxdw r1, [r10-0x268]                   
    stxb [r7+0x87], r1                      
    ldxdw r1, [r10-0x260]                   
    stxb [r7+0x86], r1                      
    ldxdw r1, [r10-0x258]                   
    stxb [r7+0x85], r1                      
    ldxdw r1, [r10-0x250]                   
    stxb [r7+0x84], r1                      
    ldxdw r1, [r10-0x180]                   
    stxdw [r7+0xa8], r1                     
    ldxdw r1, [r10-0x190]                   
    stxw [r7+0xa4], r1                      
    ldxdw r1, [r10-0x1b0]                   
    stxdw [r7+0x8], r1                      
    ldxdw r1, [r10-0x1a0]                   
    stxw [r7+0x4], r1                       
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    stxw [r7+0x0], r1                       
    ldxdw r1, [r10-0x248]                   
    stxb [r7+0x8d], r1                      
    ldxdw r1, [r10-0x240]                   
    stxb [r7+0x8e], r1                      
    ldxdw r1, [r10-0x238]                   
    stxb [r7+0x8f], r1                      
    ldxdw r1, [r10-0x230]                   
    stxb [r7+0x90], r1                      
    ldxdw r1, [r10-0x228]                   
    stxb [r7+0x91], r1                      
    ldxdw r1, [r10-0x220]                   
    stxb [r7+0x92], r1                      
    ldxdw r1, [r10-0x218]                   
    stxb [r7+0x93], r1                      
    ldxdw r1, [r10-0x210]                   
    stxb [r7+0x94], r1                      
    ldxdw r1, [r10-0x208]                   
    stxb [r7+0x95], r1                      
    ldxdw r1, [r10-0x200]                   
    stxb [r7+0x96], r1                      
    ldxdw r1, [r10-0x1f8]                   
    stxb [r7+0x97], r1                      
    ldxdw r1, [r10-0x1f0]                   
    stxb [r7+0x98], r1                      
    ldxdw r1, [r10-0x1e8]                   
    stxb [r7+0x99], r1                      
    ldxdw r1, [r10-0x1e0]                   
    stxb [r7+0x9a], r1                      
    ldxdw r1, [r10-0x1d8]                   
    stxb [r7+0x9b], r1                      
    ldxdw r1, [r10-0x1d0]                   
    stxb [r7+0x9c], r1                      
    ldxdw r1, [r10-0x1c8]                   
    stxb [r7+0x9d], r1                      
    ldxdw r1, [r10-0x1c0]                   
    stxb [r7+0x9e], r1                      
    ldxdw r1, [r10-0x1b8]                   
    stxb [r7+0x9f], r1                      
    ldxdw r1, [r10-0x1a8]                   
    stxb [r7+0xa0], r1                      
    ldxdw r1, [r10-0x2a8]                   
    stxb [r7+0xa1], r1                      
    ldxdw r1, [r10-0x2a0]                   
    stxb [r7+0xa2], r1                      
    ldxdw r1, [r10-0x298]                   
    stxb [r7+0xa3], r1                      
    ja lbb_1745                                     if true { pc += 26 }
lbb_1719:
    lddw r1, 0x100064a98 --> b"\x00\x00\x00\x00\xaa\xfa\x05\x00\x1b\x00\x00\x00\x00\x00\x00\x00%\x00\x00…        r1 load str located at 4295379608
    call function_42270                     
lbb_1722:
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    ldxdw r2, [r10-0x188]                   
    ja lbb_1743                                     if true { pc += 18 }
lbb_1725:
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
    stxdw [r0+0x8], r2                      
    ldxdw r2, [r10-0x180]                   
    add64 r2, r9                                    r2 += r9   ///  r2 = r2.wrapping_add(r9)
    add64 r2, r1                                    r2 += r1   ///  r2 = r2.wrapping_add(r1)
    add64 r2, 4                                     r2 += 4   ///  r2 = r2.wrapping_add(4 as i32 as i64 as u64)
    stxdw [r0+0x0], r2                      
    lddw r1, 0x100064a98 --> b"\x00\x00\x00\x00\xaa\xfa\x05\x00\x1b\x00\x00\x00\x00\x00\x00\x00%\x00\x00…        r1 load str located at 4295379608
    call function_42270                     
    mov64 r1, 33                                    r1 = 33 as i32 as i64 as u64
    jgt r1, r8, lbb_1722                            if r1 > r8 { pc += -15 }
    ja lbb_1779                                     if true { pc += 41 }
lbb_1738:
    lddw r1, 0x100064a98 --> b"\x00\x00\x00\x00\xaa\xfa\x05\x00\x1b\x00\x00\x00\x00\x00\x00\x00%\x00\x00…        r1 load str located at 4295379608
    call function_42270                     
lbb_1741:
    ldxdw r2, [r10-0x188]                   
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
lbb_1743:
    stxw [r2+0x0], r1                       
    stxdw [r2+0x8], r0                      
lbb_1745:
    exit                                    
lbb_1746:
    ldxdw r1, [r10-0x190]                   
    add64 r1, r6                                    r1 += r6   ///  r1 = r1.wrapping_add(r6)
    add64 r1, -5                                    r1 += -5   ///  r1 = r1.wrapping_add(-5 as i32 as i64 as u64)
    stxdw [r0+0x8], r1                      
    ldxdw r1, [r10-0x180]                   
    add64 r1, r9                                    r1 += r9   ///  r1 = r1.wrapping_add(r9)
    add64 r1, 5                                     r1 += 5   ///  r1 = r1.wrapping_add(5 as i32 as i64 as u64)
    stxdw [r0+0x0], r1                      
    lddw r1, 0x100064a98 --> b"\x00\x00\x00\x00\xaa\xfa\x05\x00\x1b\x00\x00\x00\x00\x00\x00\x00%\x00\x00…        r1 load str located at 4295379608
    call function_42270                     
    mov64 r1, 33                                    r1 = 33 as i32 as i64 as u64
    jgt r1, r8, lbb_1741                            if r1 > r8 { pc += -18 }
    ja lbb_1779                                     if true { pc += 19 }
lbb_1760:
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    stxdw [r4+0x8], r1                      
    stxdw [r4+0x0], r7                      
    lddw r1, 0x100064a98 --> b"\x00\x00\x00\x00\xaa\xfa\x05\x00\x1b\x00\x00\x00\x00\x00\x00\x00%\x00\x00…        r1 load str located at 4295379608
    call function_42270                     
    mov64 r1, 33                                    r1 = 33 as i32 as i64 as u64
    jgt r1, r8, lbb_1741                            if r1 > r8 { pc += -27 }
    ja lbb_1779                                     if true { pc += 10 }
lbb_1769:
    stxdw [r2+0x8], r7                      
    ldxdw r1, [r10-0x180]                   
    add64 r1, r0                                    r1 += r0   ///  r1 = r1.wrapping_add(r0)
    stxdw [r2+0x0], r1                      
    lddw r1, 0x100064a98 --> b"\x00\x00\x00\x00\xaa\xfa\x05\x00\x1b\x00\x00\x00\x00\x00\x00\x00%\x00\x00…        r1 load str located at 4295379608
    call function_42270                     
    mov64 r1, 33                                    r1 = 33 as i32 as i64 as u64
    ldxdw r7, [r10-0x188]                   
    jgt r1, r8, lbb_1406                            if r1 > r8 { pc += -373 }
lbb_1779:
    mov64 r1, r8                                    r1 = r8
    mov64 r2, 32                                    r2 = 32 as i32 as i64 as u64
    lddw r3, 0x100064a80 --> b"\x00\x00\x00\x00\x9d\xfa\x05\x00\x0d\x00\x00\x00\x00\x00\x00\x00\x12\x03\…        r3 load str located at 4295379584
    call function_46535                     
    syscall [invalid]                       

function_1785:
    mov64 r8, r3                                    r8 = r3
    mov64 r7, r2                                    r7 = r2
    mov64 r9, r1                                    r9 = r1
    mov64 r1, r7                                    r1 = r7
    mov64 r2, r8                                    r2 = r8
    call function_26233                     
    mov64 r1, 8                                     r1 = 8 as i32 as i64 as u64
    jgt r1, r8, lbb_2116                            if r1 > r8 { pc += 323 }
    mov64 r2, r8                                    r2 = r8
    and64 r2, -8                                    r2 &= -8   ///  r2 = r2.and(-8)
    jeq r2, 8, lbb_2123                             if r2 == (8 as i32 as i64 as u64) { pc += 327 }
    jeq r2, 16, lbb_2123                            if r2 == (16 as i32 as i64 as u64) { pc += 326 }
    add64 r8, -24                                   r8 += -24   ///  r8 = r8.wrapping_add(-24 as i32 as i64 as u64)
    mov64 r1, 32                                    r1 = 32 as i32 as i64 as u64
    jgt r1, r8, lbb_2123                            if r1 > r8 { pc += 323 }
    ldxdw r1, [r7+0x0]                      
    stxdw [r10-0x80], r1                    
    ldxdw r1, [r7+0x8]                      
    stxdw [r10-0x88], r1                    
    ldxdw r1, [r7+0x10]                     
    stxdw [r10-0x90], r1                    
    ldxb r1, [r7+0x33]                      
    lsh64 r1, 8                                     r1 <<= 8   ///  r1 = r1.wrapping_shl(8)
    ldxb r3, [r7+0x32]                      
    or64 r3, r1                                     r3 |= r1   ///  r3 = r3.or(r1)
    stxdw [r10-0x40], r3                    
    ldxb r1, [r7+0x2f]                      
    lsh64 r1, 8                                     r1 <<= 8   ///  r1 = r1.wrapping_shl(8)
    ldxb r3, [r7+0x2e]                      
    or64 r3, r1                                     r3 |= r1   ///  r3 = r3.or(r1)
    stxdw [r10-0x48], r3                    
    ldxb r1, [r7+0x21]                      
    lsh64 r1, 8                                     r1 <<= 8   ///  r1 = r1.wrapping_shl(8)
    ldxb r5, [r7+0x20]                      
    or64 r5, r1                                     r5 |= r1   ///  r5 = r5.or(r1)
    ldxb r1, [r7+0x28]                      
    lsh64 r1, 16                                    r1 <<= 16   ///  r1 = r1.wrapping_shl(16)
    ldxb r3, [r7+0x29]                      
    lsh64 r3, 24                                    r3 <<= 24   ///  r3 = r3.wrapping_shl(24)
    or64 r3, r1                                     r3 |= r1   ///  r3 = r3.or(r1)
    stxdw [r10-0x58], r3                    
    ldxb r1, [r7+0x27]                      
    lsh64 r1, 8                                     r1 <<= 8   ///  r1 = r1.wrapping_shl(8)
    ldxb r3, [r7+0x26]                      
    or64 r3, r1                                     r3 |= r1   ///  r3 = r3.or(r1)
    stxdw [r10-0x50], r3                    
    ldxb r4, [r7+0x34]                      
    lsh64 r4, 16                                    r4 <<= 16   ///  r4 = r4.wrapping_shl(16)
    ldxb r0, [r7+0x35]                      
    lsh64 r0, 24                                    r0 <<= 24   ///  r0 = r0.wrapping_shl(24)
    or64 r0, r4                                     r0 |= r4   ///  r0 = r0.or(r4)
    ldxb r4, [r7+0x30]                      
    lsh64 r4, 16                                    r4 <<= 16   ///  r4 = r4.wrapping_shl(16)
    ldxb r3, [r7+0x31]                      
    lsh64 r3, 24                                    r3 <<= 24   ///  r3 = r3.wrapping_shl(24)
    or64 r3, r4                                     r3 |= r4   ///  r3 = r3.or(r4)
    ldxb r8, [r7+0x22]                      
    lsh64 r8, 16                                    r8 <<= 16   ///  r8 = r8.wrapping_shl(16)
    ldxb r4, [r7+0x23]                      
    lsh64 r4, 24                                    r4 <<= 24   ///  r4 = r4.wrapping_shl(24)
    or64 r4, r8                                     r4 |= r8   ///  r4 = r4.or(r8)
    ldxb r8, [r7+0x2c]                      
    lsh64 r8, 16                                    r8 <<= 16   ///  r8 = r8.wrapping_shl(16)
    ldxb r1, [r7+0x2d]                      
    lsh64 r1, 24                                    r1 <<= 24   ///  r1 = r1.wrapping_shl(24)
    or64 r1, r8                                     r1 |= r8   ///  r1 = r1.or(r8)
    ldxb r6, [r7+0x2b]                      
    lsh64 r6, 8                                     r6 <<= 8   ///  r6 = r6.wrapping_shl(8)
    ldxb r8, [r7+0x2a]                      
    or64 r8, r6                                     r8 |= r6   ///  r8 = r8.or(r6)
    and64 r8, 65535                                 r8 &= 65535   ///  r8 = r8.and(65535)
    or64 r8, r1                                     r8 |= r1   ///  r8 = r8.or(r1)
    and64 r5, 65535                                 r5 &= 65535   ///  r5 = r5.and(65535)
    or64 r5, r4                                     r5 |= r4   ///  r5 = r5.or(r4)
    ldxdw r1, [r10-0x48]                    
    and64 r1, 65535                                 r1 &= 65535   ///  r1 = r1.and(65535)
    or64 r1, r3                                     r1 |= r3   ///  r1 = r1.or(r3)
    stxdw [r10-0x48], r1                    
    ldxdw r1, [r10-0x40]                    
    and64 r1, 65535                                 r1 &= 65535   ///  r1 = r1.and(65535)
    or64 r1, r0                                     r1 |= r0   ///  r1 = r1.or(r0)
    stxdw [r10-0x40], r1                    
    ldxb r1, [r7+0x37]                      
    lsh64 r1, 8                                     r1 <<= 8   ///  r1 = r1.wrapping_shl(8)
    ldxb r3, [r7+0x36]                      
    or64 r3, r1                                     r3 |= r1   ///  r3 = r3.or(r1)
    stxdw [r10-0x60], r3                    
    ldxdw r1, [r10-0x50]                    
    and64 r1, 65535                                 r1 &= 65535   ///  r1 = r1.and(65535)
    ldxdw r3, [r10-0x58]                    
    or64 r1, r3                                     r1 |= r3   ///  r1 = r1.or(r3)
    stxdw [r10-0x50], r1                    
    ldxb r1, [r7+0x1d]                      
    lsh64 r1, 8                                     r1 <<= 8   ///  r1 = r1.wrapping_shl(8)
    ldxb r3, [r7+0x1c]                      
    or64 r3, r1                                     r3 |= r1   ///  r3 = r3.or(r1)
    stxdw [r10-0x70], r3                    
    ldxb r3, [r7+0x24]                      
    lsh64 r3, 32                                    r3 <<= 32   ///  r3 = r3.wrapping_shl(32)
    ldxb r1, [r7+0x25]                      
    lsh64 r1, 40                                    r1 <<= 40   ///  r1 = r1.wrapping_shl(40)
    or64 r1, r3                                     r1 |= r3   ///  r1 = r1.or(r3)
    ldxb r0, [r7+0x1f]                      
    ldxb r3, [r7+0x1e]                      
    stxdw [r10-0x58], r3                    
    ldxb r6, [r7+0x18]                      
    ldxb r3, [r7+0x19]                      
    stxdw [r10-0x68], r3                    
    ldxb r4, [r7+0x1b]                      
    ldxb r3, [r7+0x1a]                      
    stxdw [r10-0x78], r3                    
    ldxdw r3, [r10-0x60]                    
    stxh [r10-0x2], r3                      
    stxdw [r10-0x60], r9                    
    ldxdw r9, [r10-0x40]                    
    lsh64 r9, 32                                    r9 <<= 32   ///  r9 = r9.wrapping_shl(32)
    ldxdw r3, [r10-0x48]                    
    lsh64 r3, 32                                    r3 <<= 32   ///  r3 = r3.wrapping_shl(32)
    rsh64 r3, 32                                    r3 >>= 32   ///  r3 = r3.wrapping_shr(32)
    or64 r3, r9                                     r3 |= r9   ///  r3 = r3.or(r9)
    ldxdw r9, [r10-0x60]                    
    lsh64 r5, 32                                    r5 <<= 32   ///  r5 = r5.wrapping_shl(32)
    rsh64 r5, 32                                    r5 >>= 32   ///  r5 = r5.wrapping_shr(32)
    or64 r5, r1                                     r5 |= r1   ///  r5 = r5.or(r1)
    ldxdw r1, [r10-0x70]                    
    stxh [r10-0x1c], r1                     
    lsh64 r8, 32                                    r8 <<= 32   ///  r8 = r8.wrapping_shl(32)
    ldxdw r1, [r10-0x50]                    
    lsh64 r1, 32                                    r1 <<= 32   ///  r1 = r1.wrapping_shl(32)
    rsh64 r1, 32                                    r1 >>= 32   ///  r1 = r1.wrapping_shr(32)
    or64 r1, r8                                     r1 |= r8   ///  r1 = r1.or(r8)
    ldxdw r8, [r10-0x78]                    
    lsh64 r8, 16                                    r8 <<= 16   ///  r8 = r8.wrapping_shl(16)
    lsh64 r4, 24                                    r4 <<= 24   ///  r4 = r4.wrapping_shl(24)
    or64 r4, r8                                     r4 |= r8   ///  r4 = r4.or(r8)
    ldxdw r8, [r10-0x68]                    
    lsh64 r8, 8                                     r8 <<= 8   ///  r8 = r8.wrapping_shl(8)
    or64 r6, r8                                     r6 |= r8   ///  r6 = r6.or(r8)
    ldxdw r8, [r10-0x58]                    
    lsh64 r8, 48                                    r8 <<= 48   ///  r8 = r8.wrapping_shl(48)
    lsh64 r0, 56                                    r0 <<= 56   ///  r0 = r0.wrapping_shl(56)
    or64 r0, r8                                     r0 |= r8   ///  r0 = r0.or(r8)
    lsh64 r5, 16                                    r5 <<= 16   ///  r5 = r5.wrapping_shl(16)
    rsh64 r0, 48                                    r0 >>= 48   ///  r0 = r0.wrapping_shr(48)
    or64 r0, r5                                     r0 |= r5   ///  r0 = r0.or(r5)
    and64 r6, 65535                                 r6 &= 65535   ///  r6 = r6.and(65535)
    or64 r6, r4                                     r6 |= r4   ///  r6 = r6.or(r4)
    stxw [r10-0x20], r6                     
    stxdw [r10-0xa], r3                     
    stxdw [r10-0x12], r1                    
    stxdw [r10-0x1a], r0                    
    jeq r2, 56, lbb_2123                            if r2 == (56 as i32 as i64 as u64) { pc += 186 }
    ldxb r1, [r10-0x1]                      
    stxdw [r10-0xc0], r1                    
    ldxb r1, [r10-0x2]                      
    stxdw [r10-0xb0], r1                    
    ldxb r8, [r10-0x1b]                     
    ldxb r1, [r10-0x1c]                     
    stxdw [r10-0x58], r1                    
    ldxb r6, [r10-0x1d]                     
    ldxb r1, [r10-0x1e]                     
    stxdw [r10-0x98], r1                    
    ldxb r5, [r10-0x1f]                     
    ldxb r1, [r10-0x20]                     
    stxdw [r10-0x70], r1                    
    ldxb r3, [r10-0x3]                      
    stxdw [r10-0xe8], r3                    
    ldxb r3, [r10-0x4]                      
    stxdw [r10-0xd8], r3                    
    ldxb r3, [r10-0x5]                      
    stxdw [r10-0xe0], r3                    
    ldxb r3, [r10-0x6]                      
    stxdw [r10-0xa8], r3                    
    ldxb r3, [r10-0x7]                      
    stxdw [r10-0xd0], r3                    
    ldxb r3, [r10-0x8]                      
    stxdw [r10-0xb8], r3                    
    ldxb r3, [r10-0x9]                      
    stxdw [r10-0xc8], r3                    
    ldxb r3, [r10-0xa]                      
    stxdw [r10-0x108], r3                   
    ldxb r3, [r10-0xb]                      
    stxdw [r10-0x128], r3                   
    ldxb r3, [r10-0xc]                      
    stxdw [r10-0x118], r3                   
    ldxb r3, [r10-0xd]                      
    stxdw [r10-0x120], r3                   
    ldxb r3, [r10-0xe]                      
    stxdw [r10-0xf0], r3                    
    ldxb r3, [r10-0xf]                      
    stxdw [r10-0x110], r3                   
    ldxb r3, [r10-0x10]                     
    stxdw [r10-0xf8], r3                    
    ldxb r3, [r10-0x11]                     
    stxdw [r10-0x100], r3                   
    ldxb r4, [r10-0x12]                     
    ldxb r1, [r10-0x13]                     
    stxdw [r10-0x48], r1                    
    ldxb r1, [r10-0x14]                     
    stxdw [r10-0x50], r1                    
    ldxb r3, [r10-0x15]                     
    ldxb r1, [r10-0x16]                     
    stxdw [r10-0xa0], r1                    
    ldxb r0, [r10-0x17]                     
    ldxb r1, [r10-0x18]                     
    stxdw [r10-0x78], r1                    
    ldxb r1, [r10-0x19]                     
    stxdw [r10-0x40], r1                    
    ldxb r1, [r10-0x1a]                     
    stxdw [r10-0x68], r1                    
    ldxdw r1, [r10-0x98]                    
    lsh64 r1, 16                                    r1 <<= 16   ///  r1 = r1.wrapping_shl(16)
    lsh64 r6, 24                                    r6 <<= 24   ///  r6 = r6.wrapping_shl(24)
    or64 r6, r1                                     r6 |= r1   ///  r6 = r6.or(r1)
    ldxdw r1, [r10-0x70]                    
    lsh64 r5, 8                                     r5 <<= 8   ///  r5 = r5.wrapping_shl(8)
    or64 r1, r5                                     r1 |= r5   ///  r1 = r1.or(r5)
    and64 r1, 65535                                 r1 &= 65535   ///  r1 = r1.and(65535)
    or64 r1, r6                                     r1 |= r6   ///  r1 = r1.or(r6)
    ldxdw r5, [r10-0x58]                    
    mov64 r6, r5                                    r6 = r5
    lsh64 r8, 8                                     r8 <<= 8   ///  r8 = r8.wrapping_shl(8)
    or64 r6, r8                                     r6 |= r8   ///  r6 = r6.or(r8)
    ldxdw r5, [r10-0xa0]                    
    lsh64 r5, 16                                    r5 <<= 16   ///  r5 = r5.wrapping_shl(16)
    lsh64 r3, 24                                    r3 <<= 24   ///  r3 = r3.wrapping_shl(24)
    or64 r3, r5                                     r3 |= r5   ///  r3 = r3.or(r5)
    ldxdw r5, [r10-0x78]                    
    lsh64 r0, 8                                     r0 <<= 8   ///  r0 = r0.wrapping_shl(8)
    or64 r5, r0                                     r5 |= r0   ///  r5 = r5.or(r0)
    ldxdw r0, [r7+0x38]                     
    ldxdw r8, [r10-0x68]                    
    stxb [r10-0x2a], r8                     
    stxw [r10-0x30], r1                     
    and64 r5, 65535                                 r5 &= 65535   ///  r5 = r5.and(65535)
    or64 r5, r3                                     r5 |= r3   ///  r5 = r5.or(r3)
    stxh [r10-0x2c], r6                     
    ldxdw r1, [r10-0x50]                    
    ldxdw r3, [r10-0x48]                    
    lsh64 r3, 8                                     r3 <<= 8   ///  r3 = r3.wrapping_shl(8)
    or64 r1, r3                                     r1 |= r3   ///  r1 = r1.or(r3)
    and64 r1, 65535                                 r1 &= 65535   ///  r1 = r1.and(65535)
    lsh64 r1, 40                                    r1 <<= 40   ///  r1 = r1.wrapping_shl(40)
    lsh64 r4, 56                                    r4 <<= 56   ///  r4 = r4.wrapping_shl(56)
    or64 r4, r1                                     r4 |= r1   ///  r4 = r4.or(r1)
    lsh64 r5, 32                                    r5 <<= 32   ///  r5 = r5.wrapping_shl(32)
    rsh64 r5, 32                                    r5 >>= 32   ///  r5 = r5.wrapping_shr(32)
    lsh64 r5, 8                                     r5 <<= 8   ///  r5 = r5.wrapping_shl(8)
    or64 r4, r5                                     r4 |= r5   ///  r4 = r4.or(r5)
    ldxdw r1, [r10-0x40]                    
    or64 r1, r4                                     r1 |= r4   ///  r1 = r1.or(r4)
    stxdw [r10-0x29], r1                    
    ldxw r1, [r10-0x28]                     
    stxw [r10-0x38], r1                     
    ldxw r1, [r10-0x25]                     
    stxw [r10-0x35], r1                     
    jeq r2, 64, lbb_2123                            if r2 == (64 as i32 as i64 as u64) { pc += 81 }
    ldxdw r1, [r10-0x30]                    
    ldxdw r2, [r7+0x40]                     
    ldxw r3, [r10-0x35]                     
    stxw [r9+0x1b], r3                      
    ldxw r3, [r10-0x38]                     
    stxw [r9+0x18], r3                      
    stxdw [r9+0x48], r2                     
    stxdw [r9+0x40], r0                     
    ldxdw r2, [r10-0x90]                    
    stxdw [r9+0x38], r2                     
    ldxdw r2, [r10-0x88]                    
    stxdw [r9+0x30], r2                     
    stxdw [r9+0x10], r1                     
    ldxdw r1, [r10-0x80]                    
    stxdw [r9+0x8], r1                      
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    stxdw [r9+0x0], r1                      
    ldxdw r1, [r10-0x128]                   
    lsh64 r1, 16                                    r1 <<= 16   ///  r1 = r1.wrapping_shl(16)
    ldxdw r2, [r10-0x108]                   
    lsh64 r2, 24                                    r2 <<= 24   ///  r2 = r2.wrapping_shl(24)
    or64 r2, r1                                     r2 |= r1   ///  r2 = r2.or(r1)
    ldxdw r1, [r10-0x120]                   
    ldxdw r3, [r10-0x118]                   
    lsh64 r3, 8                                     r3 <<= 8   ///  r3 = r3.wrapping_shl(8)
    or64 r1, r3                                     r1 |= r3   ///  r1 = r1.or(r3)
    and64 r1, 65535                                 r1 &= 65535   ///  r1 = r1.and(65535)
    or64 r1, r2                                     r1 |= r2   ///  r1 = r1.or(r2)
    ldxdw r2, [r10-0x110]                   
    lsh64 r2, 16                                    r2 <<= 16   ///  r2 = r2.wrapping_shl(16)
    ldxdw r3, [r10-0xf0]                    
    lsh64 r3, 24                                    r3 <<= 24   ///  r3 = r3.wrapping_shl(24)
    or64 r3, r2                                     r3 |= r2   ///  r3 = r3.or(r2)
    ldxdw r2, [r10-0x100]                   
    ldxdw r4, [r10-0xf8]                    
    lsh64 r4, 8                                     r4 <<= 8   ///  r4 = r4.wrapping_shl(8)
    or64 r2, r4                                     r2 |= r4   ///  r2 = r2.or(r4)
    and64 r2, 65535                                 r2 &= 65535   ///  r2 = r2.and(65535)
    or64 r2, r3                                     r2 |= r3   ///  r2 = r2.or(r3)
    lsh64 r2, 32                                    r2 <<= 32   ///  r2 = r2.wrapping_shl(32)
    rsh64 r2, 32                                    r2 >>= 32   ///  r2 = r2.wrapping_shr(32)
    lsh64 r1, 32                                    r1 <<= 32   ///  r1 = r1.wrapping_shl(32)
    or64 r2, r1                                     r2 |= r1   ///  r2 = r2.or(r1)
    ldxdw r1, [r10-0xe8]                    
    lsh64 r1, 16                                    r1 <<= 16   ///  r1 = r1.wrapping_shl(16)
    ldxdw r3, [r10-0xb0]                    
    lsh64 r3, 24                                    r3 <<= 24   ///  r3 = r3.wrapping_shl(24)
    or64 r3, r1                                     r3 |= r1   ///  r3 = r3.or(r1)
    ldxdw r1, [r10-0xe0]                    
    ldxdw r4, [r10-0xd8]                    
    lsh64 r4, 8                                     r4 <<= 8   ///  r4 = r4.wrapping_shl(8)
    or64 r1, r4                                     r1 |= r4   ///  r1 = r1.or(r4)
    stxdw [r9+0x1f], r2                     
    ldxdw r2, [r10-0xc0]                    
    stxb [r9+0x2f], r2                      
    and64 r1, 65535                                 r1 &= 65535   ///  r1 = r1.and(65535)
    or64 r1, r3                                     r1 |= r3   ///  r1 = r1.or(r3)
    ldxdw r2, [r10-0xd0]                    
    lsh64 r2, 16                                    r2 <<= 16   ///  r2 = r2.wrapping_shl(16)
    ldxdw r3, [r10-0xa8]                    
    lsh64 r3, 24                                    r3 <<= 24   ///  r3 = r3.wrapping_shl(24)
    or64 r3, r2                                     r3 |= r2   ///  r3 = r3.or(r2)
    ldxdw r2, [r10-0xc8]                    
    ldxdw r4, [r10-0xb8]                    
    lsh64 r4, 8                                     r4 <<= 8   ///  r4 = r4.wrapping_shl(8)
    or64 r2, r4                                     r2 |= r4   ///  r2 = r2.or(r4)
    and64 r2, 65535                                 r2 &= 65535   ///  r2 = r2.and(65535)
    or64 r2, r3                                     r2 |= r3   ///  r2 = r2.or(r3)
    lsh64 r2, 32                                    r2 <<= 32   ///  r2 = r2.wrapping_shl(32)
    rsh64 r2, 32                                    r2 >>= 32   ///  r2 = r2.wrapping_shr(32)
    lsh64 r1, 32                                    r1 <<= 32   ///  r1 = r1.wrapping_shl(32)
    or64 r2, r1                                     r2 |= r1   ///  r2 = r2.or(r1)
    stxdw [r9+0x27], r2                     
    ja lbb_2129                                     if true { pc += 13 }
lbb_2116:
    lddw r1, 0x100064a98 --> b"\x00\x00\x00\x00\xaa\xfa\x05\x00\x1b\x00\x00\x00\x00\x00\x00\x00%\x00\x00…        r1 load str located at 4295379608
    call function_42270                     
    stxdw [r9+0x8], r0                      
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    stxdw [r9+0x0], r1                      
    ja lbb_2129                                     if true { pc += 6 }
lbb_2123:
    lddw r1, 0x100064a98 --> b"\x00\x00\x00\x00\xaa\xfa\x05\x00\x1b\x00\x00\x00\x00\x00\x00\x00%\x00\x00…        r1 load str located at 4295379608
    call function_42270                     
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    stxdw [r9+0x0], r1                      
    stxdw [r9+0x8], r0                      
lbb_2129:
    exit                                    

function_2130:
    mov64 r2, r1                                    r2 = r1
    mov64 r1, r10                                   r1 = r10
    add64 r1, -400                                  r1 += -400   ///  r1 = r1.wrapping_add(-400 as i32 as i64 as u64)
    mov64 r3, 392                                   r3 = 392 as i32 as i64 as u64
    call function_48190                     
    lddw r5, 0xf1357aea2e62a9c5                     r5 load str located at -1065810590584100411
    ldxdw r2, [r10-0x138]                   
    mul64 r2, r5                                    r2 *= r5   ///  r2 = r2.wrapping_mul(r5)
    ldxdw r1, [r10-0x140]                   
    mov64 r8, r1                                    r8 = r1
    add64 r8, r2                                    r8 += r2   ///  r8 = r8.wrapping_add(r2)
    mul64 r8, r5                                    r8 *= r5   ///  r8 = r8.wrapping_mul(r5)
    jeq r1, 0, lbb_2199                             if r1 == (0 as i32 as i64 as u64) { pc += 55 }
    mul64 r1, 40                                    r1 *= 40   ///  r1 = r1.wrapping_mul(40 as u64)
    ldxdw r6, [r10-0x150]                   
    mov64 r2, r6                                    r2 = r6
    add64 r2, r1                                    r2 += r1   ///  r2 = r2.wrapping_add(r1)
    stxdw [r10-0x408], r2                   
lbb_2149:
    mov64 r1, r10                                   r1 = r10
    add64 r1, -808                                  r1 += -808   ///  r1 = r1.wrapping_add(-808 as i32 as i64 as u64)
    mov64 r2, r6                                    r2 = r6
    call function_33565                     
    ldxw r1, [r10-0x328]                    
    stxdw [r10-0x3f0], r1                   
    ldxw r1, [r10-0x324]                    
    stxdw [r10-0x400], r1                   
    ldxw r9, [r10-0x31c]                    
    ldxw r7, [r10-0x320]                    
    ldxb r1, [r6+0x10]                      
    stxdw [r10-0x3f8], r1                   
    mov64 r2, r6                                    r2 = r6
    add64 r2, 20                                    r2 += 20   ///  r2 = r2.wrapping_add(20 as i32 as i64 as u64)
    mov64 r1, r10                                   r1 = r10
    add64 r1, -808                                  r1 += -808   ///  r1 = r1.wrapping_add(-808 as i32 as i64 as u64)
    call function_33565                     
    lddw r5, 0xf1357aea2e62a9c5                     r5 load str located at -1065810590584100411
    add64 r8, r7                                    r8 += r7   ///  r8 = r8.wrapping_add(r7)
    mul64 r8, r5                                    r8 *= r5   ///  r8 = r8.wrapping_mul(r5)
    add64 r8, r9                                    r8 += r9   ///  r8 = r8.wrapping_add(r9)
    mul64 r8, r5                                    r8 *= r5   ///  r8 = r8.wrapping_mul(r5)
    ldxdw r1, [r10-0x400]                   
    add64 r8, r1                                    r8 += r1   ///  r8 = r8.wrapping_add(r1)
    mul64 r8, r5                                    r8 *= r5   ///  r8 = r8.wrapping_mul(r5)
    ldxdw r1, [r10-0x3f0]                   
    add64 r8, r1                                    r8 += r1   ///  r8 = r8.wrapping_add(r1)
    mul64 r8, r5                                    r8 *= r5   ///  r8 = r8.wrapping_mul(r5)
    ldxdw r1, [r10-0x3f8]                   
    add64 r8, r1                                    r8 += r1   ///  r8 = r8.wrapping_add(r1)
    mul64 r8, r5                                    r8 *= r5   ///  r8 = r8.wrapping_mul(r5)
    ldxw r1, [r10-0x320]                    
    add64 r8, r1                                    r8 += r1   ///  r8 = r8.wrapping_add(r1)
    mul64 r8, r5                                    r8 *= r5   ///  r8 = r8.wrapping_mul(r5)
    ldxw r1, [r10-0x31c]                    
    add64 r8, r1                                    r8 += r1   ///  r8 = r8.wrapping_add(r1)
    mul64 r8, r5                                    r8 *= r5   ///  r8 = r8.wrapping_mul(r5)
    ldxw r1, [r10-0x324]                    
    add64 r8, r1                                    r8 += r1   ///  r8 = r8.wrapping_add(r1)
    mul64 r8, r5                                    r8 *= r5   ///  r8 = r8.wrapping_mul(r5)
    ldxw r1, [r10-0x328]                    
    add64 r8, r1                                    r8 += r1   ///  r8 = r8.wrapping_add(r1)
    mul64 r8, r5                                    r8 *= r5   ///  r8 = r8.wrapping_mul(r5)
    ldxb r1, [r6+0x24]                      
    add64 r8, r1                                    r8 += r1   ///  r8 = r8.wrapping_add(r1)
    mul64 r8, r5                                    r8 *= r5   ///  r8 = r8.wrapping_mul(r5)
    add64 r6, 40                                    r6 += 40   ///  r6 = r6.wrapping_add(40 as i32 as i64 as u64)
    ldxdw r1, [r10-0x408]                   
    jne r6, r1, lbb_2149                            if r6 != r1 { pc += -50 }
lbb_2199:
    ldxdw r1, [r10-0x130]                   
    add64 r1, r8                                    r1 += r8   ///  r1 = r1.wrapping_add(r8)
    mul64 r1, r5                                    r1 *= r5   ///  r1 = r1.wrapping_mul(r5)
    ldxdw r2, [r10-0x128]                   
    add64 r1, r2                                    r1 += r2   ///  r1 = r1.wrapping_add(r2)
    mul64 r1, r5                                    r1 *= r5   ///  r1 = r1.wrapping_mul(r5)
    ldxdw r2, [r10-0x120]                   
    add64 r1, r2                                    r1 += r2   ///  r1 = r1.wrapping_add(r2)
    mul64 r1, r5                                    r1 *= r5   ///  r1 = r1.wrapping_mul(r5)
    ldxdw r2, [r10-0x118]                   
    add64 r1, r2                                    r1 += r2   ///  r1 = r1.wrapping_add(r2)
    mov64 r3, 1                                     r3 = 1 as i32 as i64 as u64
    ldxb r2, [r10-0x30]                     
    jne r2, 2, lbb_2214                             if r2 != (2 as i32 as i64 as u64) { pc += 1 }
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
lbb_2214:
    mul64 r1, r5                                    r1 *= r5   ///  r1 = r1.wrapping_mul(r5)
    ldxdw r4, [r10-0x110]                   
    add64 r1, r4                                    r1 += r4   ///  r1 = r1.wrapping_add(r4)
    mul64 r1, r5                                    r1 *= r5   ///  r1 = r1.wrapping_mul(r5)
    ldxdw r4, [r10-0x108]                   
    add64 r1, r4                                    r1 += r4   ///  r1 = r1.wrapping_add(r4)
    mul64 r1, r5                                    r1 *= r5   ///  r1 = r1.wrapping_mul(r5)
    ldxb r4, [r10-0xb]                      
    add64 r1, r4                                    r1 += r4   ///  r1 = r1.wrapping_add(r4)
    mul64 r1, r5                                    r1 *= r5   ///  r1 = r1.wrapping_mul(r5)
    add64 r1, r3                                    r1 += r3   ///  r1 = r1.wrapping_add(r3)
    mul64 r1, r5                                    r1 *= r5   ///  r1 = r1.wrapping_mul(r5)
    jeq r2, 2, lbb_2232                             if r2 == (2 as i32 as i64 as u64) { pc += 5 }
    add64 r1, r2                                    r1 += r2   ///  r1 = r1.wrapping_add(r2)
    lddw r3, 0xf1357aea2e62a9c5                     r3 load str located at -1065810590584100411
    mul64 r1, r3                                    r1 *= r3   ///  r1 = r1.wrapping_mul(r3)
    jne r2, 0, lbb_3161                             if r2 != (0 as i32 as i64 as u64) { pc += 929 }
lbb_2232:
    ldxw r2, [r10-0x180]                    
    add64 r1, r2                                    r1 += r2   ///  r1 = r1.wrapping_add(r2)
    lddw r2, 0xf1357aea2e62a9c5                     r2 load str located at -1065810590584100411
    mul64 r1, r2                                    r1 *= r2   ///  r1 = r1.wrapping_mul(r2)
    ldxdw r3, [r10-0x190]                   
    add64 r1, r3                                    r1 += r3   ///  r1 = r1.wrapping_add(r3)
    mul64 r1, r2                                    r1 *= r2   ///  r1 = r1.wrapping_mul(r2)
    jeq r3, 0, lbb_2244                             if r3 == (0 as i32 as i64 as u64) { pc += 3 }
    ldxdw r3, [r10-0x188]                   
    add64 r1, r3                                    r1 += r3   ///  r1 = r1.wrapping_add(r3)
    mul64 r1, r2                                    r1 *= r2   ///  r1 = r1.wrapping_mul(r2)
lbb_2244:
    mov64 r4, 1                                     r4 = 1 as i32 as i64 as u64
    ldxb r3, [r10-0x158]                    
    jne r3, 2, lbb_2248                             if r3 != (2 as i32 as i64 as u64) { pc += 1 }
    mov64 r4, 0                                     r4 = 0 as i32 as i64 as u64
lbb_2248:
    ldxdw r5, [r10-0x160]                   
    add64 r1, r5                                    r1 += r5   ///  r1 = r1.wrapping_add(r5)
    mul64 r1, r2                                    r1 *= r2   ///  r1 = r1.wrapping_mul(r2)
    add64 r1, r4                                    r1 += r4   ///  r1 = r1.wrapping_add(r4)
    mul64 r1, r2                                    r1 *= r2   ///  r1 = r1.wrapping_mul(r2)
    jeq r3, 2, lbb_2257                             if r3 == (2 as i32 as i64 as u64) { pc += 3 }
    add64 r1, r3                                    r1 += r3   ///  r1 = r1.wrapping_add(r3)
    mul64 r1, r2                                    r1 *= r2   ///  r1 = r1.wrapping_mul(r2)
    jne r3, 0, lbb_3171                             if r3 != (0 as i32 as i64 as u64) { pc += 914 }
lbb_2257:
    ldxdw r2, [r10-0x168]                   
    mov64 r6, r2                                    r6 = r2
    add64 r6, r1                                    r6 += r1   ///  r6 = r6.wrapping_add(r1)
    lddw r1, 0xf1357aea2e62a9c5                     r1 load str located at -1065810590584100411
    mul64 r6, r1                                    r6 *= r1   ///  r6 = r6.wrapping_mul(r1)
    jeq r2, 0, lbb_2310                             if r2 == (0 as i32 as i64 as u64) { pc += 46 }
    lsh64 r2, 5                                     r2 <<= 5   ///  r2 = r2.wrapping_shl(5)
    ldxdw r7, [r10-0x178]                   
    mov64 r9, r7                                    r9 = r7
    add64 r9, r2                                    r9 += r2   ///  r9 = r9.wrapping_add(r2)
    lddw r8, 0x84f765a6ed363320                     r8 load str located at -8865505573836803296
lbb_2270:
    ldxdw r2, [r7+0x8]                      
    lddw r1, 0xa4093822299f31d0                     r1 load str located at -6626703657320631856
    xor64 r2, r1                                    r2 ^= r1   ///  r2 = r2.xor(r1)
    ldxdw r4, [r7+0x0]                      
    lddw r1, 0x243f6a8885a308d3                     r1 load str located at 2611923443488327891
    xor64 r4, r1                                    r4 ^= r1   ///  r4 = r4.xor(r1)
    mov64 r1, r10                                   r1 = r10
    add64 r1, -824                                  r1 += -824   ///  r1 = r1.wrapping_add(-824 as i32 as i64 as u64)
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
    mov64 r5, 0                                     r5 = 0 as i32 as i64 as u64
    call function_48384                     
    ldxdw r4, [r7+0x10]                     
    lddw r1, 0x13198a2e03707344                     r1 load str located at 1376283091369227076
    xor64 r4, r1                                    r4 ^= r1   ///  r4 = r4.xor(r1)
    ldxdw r1, [r10-0x338]                   
    ldxdw r3, [r10-0x330]                   
    xor64 r3, r1                                    r3 ^= r1   ///  r3 = r3.xor(r1)
    ldxdw r2, [r7+0x18]                     
    xor64 r2, r3                                    r2 ^= r3   ///  r2 = r2.xor(r3)
    mov64 r1, r10                                   r1 = r10
    add64 r1, -840                                  r1 += -840   ///  r1 = r1.wrapping_add(-840 as i32 as i64 as u64)
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
    mov64 r5, 0                                     r5 = 0 as i32 as i64 as u64
    call function_48384                     
    ldxdw r1, [r10-0x348]                   
    ldxdw r2, [r10-0x340]                   
    xor64 r2, r1                                    r2 ^= r1   ///  r2 = r2.xor(r1)
    lddw r1, 0xf1357aea2e62a9c5                     r1 load str located at -1065810590584100411
    mul64 r6, r1                                    r6 *= r1   ///  r6 = r6.wrapping_mul(r1)
    xor64 r2, 32                                    r2 ^= 32   ///  r2 = r2.xor(32)
    add64 r6, r2                                    r6 += r2   ///  r6 = r6.wrapping_add(r2)
    mul64 r6, r1                                    r6 *= r1   ///  r6 = r6.wrapping_mul(r1)
    add64 r6, r8                                    r6 += r8   ///  r6 = r6.wrapping_add(r8)
    add64 r7, 32                                    r7 += 32   ///  r7 = r7.wrapping_add(32 as i32 as i64 as u64)
    jeq r7, r9, lbb_2310                            if r7 == r9 { pc += 1 }
    ja lbb_2270                                     if true { pc += -40 }
lbb_2310:
    mov64 r1, r10                                   r1 = r10
    add64 r1, -808                                  r1 += -808   ///  r1 = r1.wrapping_add(-808 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -256                                  r2 += -256   ///  r2 = r2.wrapping_add(-256 as i32 as i64 as u64)
    call function_33565                     
    ldxw r1, [r10-0x328]                    
    stxdw [r10-0x3f8], r1                   
    ldxw r1, [r10-0x324]                    
    stxdw [r10-0x400], r1                   
    ldxw r1, [r10-0x31c]                    
    stxdw [r10-0x408], r1                   
    ldxw r1, [r10-0x320]                    
    stxdw [r10-0x410], r1                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -808                                  r1 += -808   ///  r1 = r1.wrapping_add(-808 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -240                                  r2 += -240   ///  r2 = r2.wrapping_add(-240 as i32 as i64 as u64)
    call function_33565                     
    lddw r7, 0xa4093822299f31d0                     r7 load str located at -6626703657320631856
    ldxdw r2, [r10-0xd8]                    
    xor64 r2, r7                                    r2 ^= r7   ///  r2 = r2.xor(r7)
    lddw r8, 0x243f6a8885a308d3                     r8 load str located at 2611923443488327891
    ldxdw r4, [r10-0xe0]                    
    xor64 r4, r8                                    r4 ^= r8   ///  r4 = r4.xor(r8)
    mov64 r1, r10                                   r1 = r10
    add64 r1, -920                                  r1 += -920   ///  r1 = r1.wrapping_add(-920 as i32 as i64 as u64)
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
    stxdw [r10-0x3f0], r3                   
    mov64 r5, 0                                     r5 = 0 as i32 as i64 as u64
    call function_48384                     
    ldxdw r1, [r10-0x398]                   
    ldxdw r3, [r10-0x390]                   
    xor64 r3, r1                                    r3 ^= r1   ///  r3 = r3.xor(r1)
    ldxdw r2, [r10-0xc8]                    
    xor64 r2, r3                                    r2 ^= r3   ///  r2 = r2.xor(r3)
    lddw r9, 0x13198a2e03707344                     r9 load str located at 1376283091369227076
    ldxdw r4, [r10-0xd0]                    
    xor64 r4, r9                                    r4 ^= r9   ///  r4 = r4.xor(r9)
    mov64 r1, r10                                   r1 = r10
    add64 r1, -936                                  r1 += -936   ///  r1 = r1.wrapping_add(-936 as i32 as i64 as u64)
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
    mov64 r5, 0                                     r5 = 0 as i32 as i64 as u64
    call function_48384                     
    ldxdw r2, [r10-0xb8]                    
    xor64 r2, r7                                    r2 ^= r7   ///  r2 = r2.xor(r7)
    ldxdw r4, [r10-0xc0]                    
    xor64 r4, r8                                    r4 ^= r8   ///  r4 = r4.xor(r8)
    mov64 r1, r10                                   r1 = r10
    add64 r1, -888                                  r1 += -888   ///  r1 = r1.wrapping_add(-888 as i32 as i64 as u64)
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
    mov64 r5, 0                                     r5 = 0 as i32 as i64 as u64
    call function_48384                     
    ldxdw r1, [r10-0x378]                   
    ldxdw r3, [r10-0x370]                   
    xor64 r3, r1                                    r3 ^= r1   ///  r3 = r3.xor(r1)
    ldxdw r2, [r10-0xa8]                    
    xor64 r2, r3                                    r2 ^= r3   ///  r2 = r2.xor(r3)
    ldxdw r4, [r10-0xb0]                    
    xor64 r4, r9                                    r4 ^= r9   ///  r4 = r4.xor(r9)
    mov64 r1, r10                                   r1 = r10
    add64 r1, -904                                  r1 += -904   ///  r1 = r1.wrapping_add(-904 as i32 as i64 as u64)
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
    mov64 r5, 0                                     r5 = 0 as i32 as i64 as u64
    call function_48384                     
    ldxdw r2, [r10-0x98]                    
    xor64 r2, r7                                    r2 ^= r7   ///  r2 = r2.xor(r7)
    ldxdw r4, [r10-0xa0]                    
    xor64 r4, r8                                    r4 ^= r8   ///  r4 = r4.xor(r8)
    mov64 r1, r10                                   r1 = r10
    add64 r1, -856                                  r1 += -856   ///  r1 = r1.wrapping_add(-856 as i32 as i64 as u64)
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
    mov64 r5, 0                                     r5 = 0 as i32 as i64 as u64
    call function_48384                     
    ldxdw r4, [r10-0x90]                    
    xor64 r4, r9                                    r4 ^= r9   ///  r4 = r4.xor(r9)
    ldxdw r1, [r10-0x358]                   
    ldxdw r3, [r10-0x350]                   
    xor64 r3, r1                                    r3 ^= r1   ///  r3 = r3.xor(r1)
    ldxdw r2, [r10-0x88]                    
    xor64 r2, r3                                    r2 ^= r3   ///  r2 = r2.xor(r3)
    mov64 r1, r10                                   r1 = r10
    add64 r1, -872                                  r1 += -872   ///  r1 = r1.wrapping_add(-872 as i32 as i64 as u64)
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
    mov64 r5, 0                                     r5 = 0 as i32 as i64 as u64
    call function_48384                     
    ldxw r1, [r10-0x328]                    
    stxdw [r10-0x440], r1                   
    ldxw r9, [r10-0x324]                    
    ldxw r7, [r10-0x31c]                    
    ldxw r8, [r10-0x320]                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -808                                  r1 += -808   ///  r1 = r1.wrapping_add(-808 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -128                                  r2 += -128   ///  r2 = r2.wrapping_add(-128 as i32 as i64 as u64)
    call function_33565                     
    ldxw r1, [r10-0x328]                    
    stxdw [r10-0x418], r1                   
    ldxw r1, [r10-0x324]                    
    stxdw [r10-0x428], r1                   
    ldxw r1, [r10-0x31c]                    
    stxdw [r10-0x430], r1                   
    ldxw r1, [r10-0x320]                    
    stxdw [r10-0x438], r1                   
    ldxdw r1, [r10-0x70]                    
    stxdw [r10-0x420], r1                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -808                                  r1 += -808   ///  r1 = r1.wrapping_add(-808 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -104                                  r2 += -104   ///  r2 = r2.wrapping_add(-104 as i32 as i64 as u64)
    call function_33565                     
    ldxdw r1, [r10-0x410]                   
    add64 r6, r1                                    r6 += r1   ///  r6 = r6.wrapping_add(r1)
    lddw r3, 0xf1357aea2e62a9c5                     r3 load str located at -1065810590584100411
    mul64 r6, r3                                    r6 *= r3   ///  r6 = r6.wrapping_mul(r3)
    ldxdw r1, [r10-0x408]                   
    add64 r6, r1                                    r6 += r1   ///  r6 = r6.wrapping_add(r1)
    mul64 r6, r3                                    r6 *= r3   ///  r6 = r6.wrapping_mul(r3)
    ldxdw r1, [r10-0x400]                   
    add64 r6, r1                                    r6 += r1   ///  r6 = r6.wrapping_add(r1)
    mul64 r6, r3                                    r6 *= r3   ///  r6 = r6.wrapping_mul(r3)
    ldxdw r1, [r10-0x3f8]                   
    add64 r6, r1                                    r6 += r1   ///  r6 = r6.wrapping_add(r1)
    mul64 r6, r3                                    r6 *= r3   ///  r6 = r6.wrapping_mul(r3)
    add64 r6, r8                                    r6 += r8   ///  r6 = r6.wrapping_add(r8)
    lddw r8, 0x243f6a8885a308d3                     r8 load str located at 2611923443488327891
    ldxdw r2, [r10-0x3a8]                   
    ldxdw r1, [r10-0x3a0]                   
    xor64 r1, r2                                    r1 ^= r2   ///  r1 = r1.xor(r2)
    mul64 r6, r3                                    r6 *= r3   ///  r6 = r6.wrapping_mul(r3)
    add64 r6, r7                                    r6 += r7   ///  r6 = r6.wrapping_add(r7)
    lddw r7, 0xa4093822299f31d0                     r7 load str located at -6626703657320631856
    mul64 r6, r3                                    r6 *= r3   ///  r6 = r6.wrapping_mul(r3)
    add64 r6, r9                                    r6 += r9   ///  r6 = r6.wrapping_add(r9)
    lddw r9, 0x13198a2e03707344                     r9 load str located at 1376283091369227076
    mul64 r6, r3                                    r6 *= r3   ///  r6 = r6.wrapping_mul(r3)
    ldxdw r2, [r10-0x440]                   
    add64 r6, r2                                    r6 += r2   ///  r6 = r6.wrapping_add(r2)
    lddw r4, 0x1427bb2d3769b199                     r4 load str located at 1452335207727870361
    mul64 r6, r4                                    r6 *= r4   ///  r6 = r6.wrapping_mul(r4)
    xor64 r1, 32                                    r1 ^= 32   ///  r1 = r1.xor(32)
    add64 r6, r1                                    r6 += r1   ///  r6 = r6.wrapping_add(r1)
    ldxdw r1, [r10-0x388]                   
    ldxdw r2, [r10-0x380]                   
    xor64 r2, r1                                    r2 ^= r1   ///  r2 = r2.xor(r1)
    mul64 r6, r4                                    r6 *= r4   ///  r6 = r6.wrapping_mul(r4)
    xor64 r2, 32                                    r2 ^= 32   ///  r2 = r2.xor(32)
    add64 r6, r2                                    r6 += r2   ///  r6 = r6.wrapping_add(r2)
    ldxdw r1, [r10-0x368]                   
    ldxdw r2, [r10-0x360]                   
    xor64 r2, r1                                    r2 ^= r1   ///  r2 = r2.xor(r1)
    mul64 r6, r4                                    r6 *= r4   ///  r6 = r6.wrapping_mul(r4)
    xor64 r2, 32                                    r2 ^= 32   ///  r2 = r2.xor(32)
    add64 r6, r2                                    r6 += r2   ///  r6 = r6.wrapping_add(r2)
    mul64 r6, r3                                    r6 *= r3   ///  r6 = r6.wrapping_mul(r3)
    ldxdw r1, [r10-0x438]                   
    add64 r6, r1                                    r6 += r1   ///  r6 = r6.wrapping_add(r1)
    mul64 r6, r3                                    r6 *= r3   ///  r6 = r6.wrapping_mul(r3)
    ldxdw r1, [r10-0x430]                   
    add64 r6, r1                                    r6 += r1   ///  r6 = r6.wrapping_add(r1)
    mul64 r6, r3                                    r6 *= r3   ///  r6 = r6.wrapping_mul(r3)
    ldxdw r1, [r10-0x428]                   
    add64 r6, r1                                    r6 += r1   ///  r6 = r6.wrapping_add(r1)
    mul64 r6, r3                                    r6 *= r3   ///  r6 = r6.wrapping_mul(r3)
    ldxdw r1, [r10-0x418]                   
    add64 r6, r1                                    r6 += r1   ///  r6 = r6.wrapping_add(r1)
    mul64 r6, r3                                    r6 *= r3   ///  r6 = r6.wrapping_mul(r3)
    ldxdw r1, [r10-0x420]                   
    add64 r6, r1                                    r6 += r1   ///  r6 = r6.wrapping_add(r1)
    mul64 r6, r3                                    r6 *= r3   ///  r6 = r6.wrapping_mul(r3)
    ldxw r1, [r10-0x320]                    
    add64 r6, r1                                    r6 += r1   ///  r6 = r6.wrapping_add(r1)
    mul64 r6, r3                                    r6 *= r3   ///  r6 = r6.wrapping_mul(r3)
    ldxw r1, [r10-0x31c]                    
    add64 r6, r1                                    r6 += r1   ///  r6 = r6.wrapping_add(r1)
    mul64 r6, r3                                    r6 *= r3   ///  r6 = r6.wrapping_mul(r3)
    ldxw r1, [r10-0x324]                    
    add64 r6, r1                                    r6 += r1   ///  r6 = r6.wrapping_add(r1)
    mul64 r6, r3                                    r6 *= r3   ///  r6 = r6.wrapping_mul(r3)
    ldxw r1, [r10-0x328]                    
    add64 r6, r1                                    r6 += r1   ///  r6 = r6.wrapping_add(r1)
    mul64 r6, r3                                    r6 *= r3   ///  r6 = r6.wrapping_mul(r3)
    ldxdw r1, [r10-0x58]                    
    add64 r6, r1                                    r6 += r1   ///  r6 = r6.wrapping_add(r1)
    mul64 r6, r3                                    r6 *= r3   ///  r6 = r6.wrapping_mul(r3)
    ldxb r1, [r10-0x2c]                     
    add64 r6, r1                                    r6 += r1   ///  r6 = r6.wrapping_add(r1)
    lddw r2, 0x46b11a5d67ed6f60                     r2 load str located at 5093881642010636128
    add64 r6, r2                                    r6 += r2   ///  r6 = r6.wrapping_add(r2)
    jeq r1, 0, lbb_2540                             if r1 == (0 as i32 as i64 as u64) { pc += 32 }
    ldxdw r2, [r10-0x23]                    
    xor64 r2, r7                                    r2 ^= r7   ///  r2 = r2.xor(r7)
    ldxdw r4, [r10-0x2b]                    
    xor64 r4, r8                                    r4 ^= r8   ///  r4 = r4.xor(r8)
    mov64 r1, r10                                   r1 = r10
    add64 r1, -952                                  r1 += -952   ///  r1 = r1.wrapping_add(-952 as i32 as i64 as u64)
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
    mov64 r5, 0                                     r5 = 0 as i32 as i64 as u64
    call function_48384                     
    ldxdw r4, [r10-0x1b]                    
    xor64 r4, r9                                    r4 ^= r9   ///  r4 = r4.xor(r9)
    ldxdw r1, [r10-0x3b8]                   
    ldxdw r3, [r10-0x3b0]                   
    xor64 r3, r1                                    r3 ^= r1   ///  r3 = r3.xor(r1)
    ldxdw r2, [r10-0x13]                    
    xor64 r2, r3                                    r2 ^= r3   ///  r2 = r2.xor(r3)
    mov64 r1, r10                                   r1 = r10
    add64 r1, -968                                  r1 += -968   ///  r1 = r1.wrapping_add(-968 as i32 as i64 as u64)
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
    mov64 r5, 0                                     r5 = 0 as i32 as i64 as u64
    call function_48384                     
    lddw r1, 0x1427bb2d3769b199                     r1 load str located at 1452335207727870361
    mul64 r6, r1                                    r6 *= r1   ///  r6 = r6.wrapping_mul(r1)
    ldxdw r1, [r10-0x3c8]                   
    ldxdw r2, [r10-0x3c0]                   
    xor64 r2, r1                                    r2 ^= r1   ///  r2 = r2.xor(r1)
    xor64 r2, 32                                    r2 ^= 32   ///  r2 = r2.xor(32)
    add64 r6, r2                                    r6 += r2   ///  r6 = r6.wrapping_add(r2)
    lddw r1, 0x26af5d45cc5538a0                     r1 load str located at 2787549248727890080
    add64 r6, r1                                    r6 += r1   ///  r6 = r6.wrapping_add(r1)
lbb_2540:
    ldxdw r2, [r10-0x48]                    
    xor64 r2, r7                                    r2 ^= r7   ///  r2 = r2.xor(r7)
    ldxdw r4, [r10-0x50]                    
    xor64 r4, r8                                    r4 ^= r8   ///  r4 = r4.xor(r8)
    mov64 r1, r10                                   r1 = r10
    add64 r1, -984                                  r1 += -984   ///  r1 = r1.wrapping_add(-984 as i32 as i64 as u64)
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
    mov64 r5, 0                                     r5 = 0 as i32 as i64 as u64
    call function_48384                     
    ldxdw r4, [r10-0x40]                    
    xor64 r4, r9                                    r4 ^= r9   ///  r4 = r4.xor(r9)
    ldxdw r1, [r10-0x3d8]                   
    ldxdw r3, [r10-0x3d0]                   
    xor64 r3, r1                                    r3 ^= r1   ///  r3 = r3.xor(r1)
    ldxdw r2, [r10-0x38]                    
    xor64 r2, r3                                    r2 ^= r3   ///  r2 = r2.xor(r3)
    mov64 r1, r10                                   r1 = r10
    add64 r1, -1000                                 r1 += -1000   ///  r1 = r1.wrapping_add(-1000 as i32 as i64 as u64)
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
    mov64 r5, 0                                     r5 = 0 as i32 as i64 as u64
    call function_48384                     
    mov64 r1, r10                                   r1 = r10
    add64 r1, -808                                  r1 += -808   ///  r1 = r1.wrapping_add(-808 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -400                                  r2 += -400   ///  r2 = r2.wrapping_add(-400 as i32 as i64 as u64)
    mov64 r3, 392                                   r3 = 392 as i32 as i64 as u64
    call function_48190                     
    lddw r1, 0x1427bb2d3769b199                     r1 load str located at 1452335207727870361
    mul64 r6, r1                                    r6 *= r1   ///  r6 = r6.wrapping_mul(r1)
    ldxdw r1, [r10-0x3e8]                   
    ldxdw r2, [r10-0x3e0]                   
    xor64 r2, r1                                    r2 ^= r1   ///  r2 = r2.xor(r1)
    xor64 r2, 32                                    r2 ^= 32   ///  r2 = r2.xor(32)
    add64 r6, r2                                    r6 += r2   ///  r6 = r6.wrapping_add(r2)
    lddw r1, 0xf1357aea2e62a9c5                     r1 load str located at -1065810590584100411
    mul64 r6, r1                                    r6 *= r1   ///  r6 = r6.wrapping_mul(r1)
    lddw r1, 0x84f765a6ed363320                     r1 load str located at -8865505573836803296
    add64 r6, r1                                    r6 += r1   ///  r6 = r6.wrapping_add(r1)
    mov64 r1, r6                                    r1 = r6
    rsh64 r1, 38                                    r1 >>= 38   ///  r1 = r1.wrapping_shr(38)
    lsh64 r6, 26                                    r6 <<= 26   ///  r6 = r6.wrapping_shl(26)
    or64 r6, r1                                     r6 |= r1   ///  r6 = r6.or(r1)
    lddw r1, 0xfd74c63348a7c25f                     r1 load str located at -183303761250762145
    mov64 r2, r6                                    r2 = r6
    mul64 r2, r1                                    r2 *= r1   ///  r2 = r2.wrapping_mul(r1)
    lddw r1, 0x14057b7ef767814f                     r1 load str located at 1442695040888963407
    add64 r2, r1                                    r2 += r1   ///  r2 = r2.wrapping_add(r1)
    stxdw [r10-0x198], r2                   
    stxdw [r10-0x1a0], r6                   
    lddw r1, 0x300000000                            r1 load str located at 12884901888
    ldxdw r1, [r1+0x0]                      
    mov64 r3, 1                                     r3 = 1 as i32 as i64 as u64
    mov64 r2, r1                                    r2 = r1
    add64 r2, -392                                  r2 += -392   ///  r2 = r2.wrapping_add(-392 as i32 as i64 as u64)
    jgt r2, r1, lbb_2602                            if r2 > r1 { pc += 1 }
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
lbb_2602:
    jne r3, 0, lbb_2604                             if r3 != (0 as i32 as i64 as u64) { pc += 1 }
    stxdw [r10-0x3f0], r2                   
lbb_2604:
    lddw r2, 0x300007e78                            r2 load str located at 12884934264
    jeq r1, 0, lbb_2608                             if r1 == (0 as i32 as i64 as u64) { pc += 1 }
    ldxdw r2, [r10-0x3f0]                   
lbb_2608:
    lddw r1, 0x300000007                            r1 load str located at 12884901895
    jgt r2, r1, lbb_2615                            if r2 > r1 { pc += 4 }
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    mov64 r2, 392                                   r2 = 392 as i32 as i64 as u64
    call function_43400                     
    syscall [invalid]                       
lbb_2615:
    lddw r1, 0x300000000                            r1 load str located at 12884901888
    stxdw [r1+0x0], r2                      
    mov64 r1, 392                                   r1 = 392 as i32 as i64 as u64
    stxdw [r10-0x188], r1                   
    stxdw [r10-0x190], r2                   
    stxdw [r2+0x0], r6                      
    mov64 r2, 8                                     r2 = 8 as i32 as i64 as u64
    stxdw [r10-0x180], r2                   
    ldxdw r6, [r10-0x2d0]                   
    ldxdw r1, [r10-0x188]                   
    and64 r1, -8                                    r1 &= -8   ///  r1 = r1.and(-8)
    jne r1, 8, lbb_2633                             if r1 != (8 as i32 as i64 as u64) { pc += 5 }
    mov64 r1, r10                                   r1 = r10
    add64 r1, -400                                  r1 += -400   ///  r1 = r1.wrapping_add(-400 as i32 as i64 as u64)
    mov64 r3, 8                                     r3 = 8 as i32 as i64 as u64
    call function_649                       
    ldxdw r2, [r10-0x180]                   
lbb_2633:
    ldxdw r1, [r10-0x190]                   
    add64 r1, r2                                    r1 += r2   ///  r1 = r1.wrapping_add(r2)
    stxdw [r1+0x0], r6                      
    add64 r2, 8                                     r2 += 8   ///  r2 = r2.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x180], r2                   
    ldxdw r8, [r10-0x2d8]                   
    lddw r1, 0xffffffff                             r1 load str located at 4294967295
    jgt r8, r1, lbb_3181                            if r8 > r1 { pc += 539 }
    ldxdw r6, [r10-0x2e8]                   
    ldxdw r1, [r10-0x188]                   
    sub64 r1, r2                                    r1 -= r2   ///  r1 = r1.wrapping_sub(r2)
    jgt r1, 3, lbb_2651                             if r1 > (3 as i32 as i64 as u64) { pc += 5 }
    mov64 r1, r10                                   r1 = r10
    add64 r1, -400                                  r1 += -400   ///  r1 = r1.wrapping_add(-400 as i32 as i64 as u64)
    mov64 r3, 4                                     r3 = 4 as i32 as i64 as u64
    call function_649                       
    ldxdw r2, [r10-0x180]                   
lbb_2651:
    ldxdw r1, [r10-0x190]                   
    add64 r1, r2                                    r1 += r2   ///  r1 = r1.wrapping_add(r2)
    stxw [r1+0x0], r8                       
    add64 r2, 4                                     r2 += 4   ///  r2 = r2.wrapping_add(4 as i32 as i64 as u64)
    stxdw [r10-0x180], r2                   
    jeq r8, 0, lbb_2688                             if r8 == (0 as i32 as i64 as u64) { pc += 31 }
    mul64 r8, 40                                    r8 *= 40   ///  r8 = r8.wrapping_mul(40 as u64)
    mov64 r7, r6                                    r7 = r6
    add64 r7, r8                                    r7 += r8   ///  r7 = r7.wrapping_add(r8)
    ja lbb_2698                                     if true { pc += 37 }
lbb_2661:
    ldxdw r1, [r10-0x190]                   
    add64 r1, r2                                    r1 += r2   ///  r1 = r1.wrapping_add(r2)
    ldxb r3, [r6+0x10]                      
    stxb [r1+0x0], r3                       
    add64 r2, 1                                     r2 += 1   ///  r2 = r2.wrapping_add(1 as i32 as i64 as u64)
    stxdw [r10-0x180], r2                   
    add64 r6, 20                                    r6 += 20   ///  r6 = r6.wrapping_add(20 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -400                                  r2 += -400   ///  r2 = r2.wrapping_add(-400 as i32 as i64 as u64)
    mov64 r1, r6                                    r1 = r6
    call function_955                       
    ldxdw r2, [r10-0x180]                   
    ldxdw r1, [r10-0x188]                   
    jne r1, r2, lbb_2680                            if r1 != r2 { pc += 5 }
    mov64 r1, r10                                   r1 = r10
    add64 r1, -400                                  r1 += -400   ///  r1 = r1.wrapping_add(-400 as i32 as i64 as u64)
    mov64 r3, 1                                     r3 = 1 as i32 as i64 as u64
    call function_649                       
    ldxdw r2, [r10-0x180]                   
lbb_2680:
    ldxdw r1, [r10-0x190]                   
    add64 r1, r2                                    r1 += r2   ///  r1 = r1.wrapping_add(r2)
    ldxb r3, [r6+0x10]                      
    stxb [r1+0x0], r3                       
    add64 r2, 1                                     r2 += 1   ///  r2 = r2.wrapping_add(1 as i32 as i64 as u64)
    stxdw [r10-0x180], r2                   
    add64 r6, 20                                    r6 += 20   ///  r6 = r6.wrapping_add(20 as i32 as i64 as u64)
    jne r6, r7, lbb_2698                            if r6 != r7 { pc += 10 }
lbb_2688:
    ldxdw r1, [r10-0x188]                   
    sub64 r1, r2                                    r1 -= r2   ///  r1 = r1.wrapping_sub(r2)
    ldxdw r6, [r10-0x2c8]                   
    jgt r1, 7, lbb_2711                             if r1 > (7 as i32 as i64 as u64) { pc += 19 }
    mov64 r1, r10                                   r1 = r10
    add64 r1, -400                                  r1 += -400   ///  r1 = r1.wrapping_add(-400 as i32 as i64 as u64)
    mov64 r3, 8                                     r3 = 8 as i32 as i64 as u64
    call function_649                       
    ldxdw r2, [r10-0x180]                   
    ja lbb_2711                                     if true { pc += 13 }
lbb_2698:
    mov64 r2, r10                                   r2 = r10
    add64 r2, -400                                  r2 += -400   ///  r2 = r2.wrapping_add(-400 as i32 as i64 as u64)
    mov64 r1, r6                                    r1 = r6
    call function_955                       
    ldxdw r2, [r10-0x180]                   
    ldxdw r1, [r10-0x188]                   
    jne r1, r2, lbb_2661                            if r1 != r2 { pc += -44 }
    mov64 r1, r10                                   r1 = r10
    add64 r1, -400                                  r1 += -400   ///  r1 = r1.wrapping_add(-400 as i32 as i64 as u64)
    mov64 r3, 1                                     r3 = 1 as i32 as i64 as u64
    call function_649                       
    ldxdw r2, [r10-0x180]                   
    ja lbb_2661                                     if true { pc += -50 }
lbb_2711:
    ldxdw r1, [r10-0x190]                   
    add64 r1, r2                                    r1 += r2   ///  r1 = r1.wrapping_add(r2)
    stxdw [r1+0x0], r6                      
    add64 r2, 8                                     r2 += 8   ///  r2 = r2.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x180], r2                   
    ldxdw r1, [r10-0x188]                   
    sub64 r1, r2                                    r1 -= r2   ///  r1 = r1.wrapping_sub(r2)
    ldxdw r6, [r10-0x2c0]                   
    jgt r1, 7, lbb_2725                             if r1 > (7 as i32 as i64 as u64) { pc += 5 }
    mov64 r1, r10                                   r1 = r10
    add64 r1, -400                                  r1 += -400   ///  r1 = r1.wrapping_add(-400 as i32 as i64 as u64)
    mov64 r3, 8                                     r3 = 8 as i32 as i64 as u64
    call function_649                       
    ldxdw r2, [r10-0x180]                   
lbb_2725:
    ldxdw r1, [r10-0x190]                   
    add64 r1, r2                                    r1 += r2   ///  r1 = r1.wrapping_add(r2)
    stxdw [r1+0x0], r6                      
    add64 r2, 8                                     r2 += 8   ///  r2 = r2.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x180], r2                   
    ldxdw r1, [r10-0x188]                   
    sub64 r1, r2                                    r1 -= r2   ///  r1 = r1.wrapping_sub(r2)
    ldxdw r6, [r10-0x2b8]                   
    jgt r1, 7, lbb_2739                             if r1 > (7 as i32 as i64 as u64) { pc += 5 }
    mov64 r1, r10                                   r1 = r10
    add64 r1, -400                                  r1 += -400   ///  r1 = r1.wrapping_add(-400 as i32 as i64 as u64)
    mov64 r3, 8                                     r3 = 8 as i32 as i64 as u64
    call function_649                       
    ldxdw r2, [r10-0x180]                   
lbb_2739:
    ldxdw r1, [r10-0x190]                   
    add64 r1, r2                                    r1 += r2   ///  r1 = r1.wrapping_add(r2)
    stxdw [r1+0x0], r6                      
    add64 r2, 8                                     r2 += 8   ///  r2 = r2.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x180], r2                   
    ldxdw r1, [r10-0x188]                   
    sub64 r1, r2                                    r1 -= r2   ///  r1 = r1.wrapping_sub(r2)
    ldxdw r6, [r10-0x2b0]                   
    jgt r1, 7, lbb_2753                             if r1 > (7 as i32 as i64 as u64) { pc += 5 }
    mov64 r1, r10                                   r1 = r10
    add64 r1, -400                                  r1 += -400   ///  r1 = r1.wrapping_add(-400 as i32 as i64 as u64)
    mov64 r3, 8                                     r3 = 8 as i32 as i64 as u64
    call function_649                       
    ldxdw r2, [r10-0x180]                   
lbb_2753:
    ldxdw r1, [r10-0x190]                   
    add64 r1, r2                                    r1 += r2   ///  r1 = r1.wrapping_add(r2)
    stxdw [r1+0x0], r6                      
    add64 r2, 8                                     r2 += 8   ///  r2 = r2.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x180], r2                   
    ldxdw r1, [r10-0x188]                   
    sub64 r1, r2                                    r1 -= r2   ///  r1 = r1.wrapping_sub(r2)
    ldxdw r6, [r10-0x2a8]                   
    jgt r1, 7, lbb_2767                             if r1 > (7 as i32 as i64 as u64) { pc += 5 }
    mov64 r1, r10                                   r1 = r10
    add64 r1, -400                                  r1 += -400   ///  r1 = r1.wrapping_add(-400 as i32 as i64 as u64)
    mov64 r3, 8                                     r3 = 8 as i32 as i64 as u64
    call function_649                       
    ldxdw r2, [r10-0x180]                   
lbb_2767:
    ldxdw r1, [r10-0x190]                   
    add64 r1, r2                                    r1 += r2   ///  r1 = r1.wrapping_add(r2)
    stxdw [r1+0x0], r6                      
    add64 r2, 8                                     r2 += 8   ///  r2 = r2.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x180], r2                   
    ldxdw r1, [r10-0x188]                   
    sub64 r1, r2                                    r1 -= r2   ///  r1 = r1.wrapping_sub(r2)
    ldxdw r6, [r10-0x2a0]                   
    jgt r1, 7, lbb_2781                             if r1 > (7 as i32 as i64 as u64) { pc += 5 }
    mov64 r1, r10                                   r1 = r10
    add64 r1, -400                                  r1 += -400   ///  r1 = r1.wrapping_add(-400 as i32 as i64 as u64)
    mov64 r3, 8                                     r3 = 8 as i32 as i64 as u64
    call function_649                       
    ldxdw r2, [r10-0x180]                   
lbb_2781:
    ldxdw r1, [r10-0x190]                   
    add64 r1, r2                                    r1 += r2   ///  r1 = r1.wrapping_add(r2)
    stxdw [r1+0x0], r6                      
    ldxb r6, [r10-0x1a3]                    
    add64 r2, 8                                     r2 += 8   ///  r2 = r2.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x180], r2                   
    ldxdw r1, [r10-0x188]                   
    jne r1, r2, lbb_2794                            if r1 != r2 { pc += 5 }
    mov64 r1, r10                                   r1 = r10
    add64 r1, -400                                  r1 += -400   ///  r1 = r1.wrapping_add(-400 as i32 as i64 as u64)
    mov64 r3, 1                                     r3 = 1 as i32 as i64 as u64
    call function_649                       
    ldxdw r2, [r10-0x180]                   
lbb_2794:
    ldxdw r1, [r10-0x190]                   
    add64 r1, r2                                    r1 += r2   ///  r1 = r1.wrapping_add(r2)
    stxb [r1+0x0], r6                       
    add64 r2, 1                                     r2 += 1   ///  r2 = r2.wrapping_add(1 as i32 as i64 as u64)
    stxdw [r10-0x180], r2                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -456                                  r1 += -456   ///  r1 = r1.wrapping_add(-456 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -400                                  r2 += -400   ///  r2 = r2.wrapping_add(-400 as i32 as i64 as u64)
    call function_873                       
    ldxdw r3, [r10-0x188]                   
    ldxdw r2, [r10-0x180]                   
    mov64 r1, r3                                    r1 = r3
    sub64 r1, r2                                    r1 -= r2   ///  r1 = r1.wrapping_sub(r2)
    ldxw r6, [r10-0x318]                    
    jgt r1, 3, lbb_2816                             if r1 > (3 as i32 as i64 as u64) { pc += 6 }
    mov64 r1, r10                                   r1 = r10
    add64 r1, -400                                  r1 += -400   ///  r1 = r1.wrapping_add(-400 as i32 as i64 as u64)
    mov64 r3, 4                                     r3 = 4 as i32 as i64 as u64
    call function_649                       
    ldxdw r3, [r10-0x188]                   
    ldxdw r2, [r10-0x180]                   
lbb_2816:
    ldxdw r1, [r10-0x190]                   
    mov64 r4, r1                                    r4 = r1
    add64 r4, r2                                    r4 += r2   ///  r4 = r4.wrapping_add(r2)
    stxw [r4+0x0], r6                       
    add64 r2, 4                                     r2 += 4   ///  r2 = r2.wrapping_add(4 as i32 as i64 as u64)
    stxdw [r10-0x180], r2                   
    ldxdw r4, [r10-0x328]                   
    jne r4, 0, lbb_2837                             if r4 != (0 as i32 as i64 as u64) { pc += 13 }
    jne r3, r2, lbb_2832                            if r3 != r2 { pc += 7 }
    mov64 r1, r10                                   r1 = r10
    add64 r1, -400                                  r1 += -400   ///  r1 = r1.wrapping_add(-400 as i32 as i64 as u64)
    mov64 r2, r3                                    r2 = r3
    mov64 r3, 1                                     r3 = 1 as i32 as i64 as u64
    call function_649                       
    ldxdw r1, [r10-0x190]                   
    ldxdw r2, [r10-0x180]                   
lbb_2832:
    add64 r1, r2                                    r1 += r2   ///  r1 = r1.wrapping_add(r2)
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
    stxb [r1+0x0], r3                       
    add64 r2, 1                                     r2 += 1   ///  r2 = r2.wrapping_add(1 as i32 as i64 as u64)
    ja lbb_2864                                     if true { pc += 27 }
lbb_2837:
    ldxdw r6, [r10-0x320]                   
    jne r3, r2, lbb_2847                            if r3 != r2 { pc += 8 }
    mov64 r1, r10                                   r1 = r10
    add64 r1, -400                                  r1 += -400   ///  r1 = r1.wrapping_add(-400 as i32 as i64 as u64)
    mov64 r2, r3                                    r2 = r3
    mov64 r3, 1                                     r3 = 1 as i32 as i64 as u64
    call function_649                       
    ldxdw r1, [r10-0x190]                   
    ldxdw r3, [r10-0x188]                   
    ldxdw r2, [r10-0x180]                   
lbb_2847:
    mov64 r4, r1                                    r4 = r1
    add64 r4, r2                                    r4 += r2   ///  r4 = r4.wrapping_add(r2)
    mov64 r5, 1                                     r5 = 1 as i32 as i64 as u64
    stxb [r4+0x0], r5                       
    add64 r2, 1                                     r2 += 1   ///  r2 = r2.wrapping_add(1 as i32 as i64 as u64)
    stxdw [r10-0x180], r2                   
    sub64 r3, r2                                    r3 -= r2   ///  r3 = r3.wrapping_sub(r2)
    jgt r3, 7, lbb_2861                             if r3 > (7 as i32 as i64 as u64) { pc += 6 }
    mov64 r1, r10                                   r1 = r10
    add64 r1, -400                                  r1 += -400   ///  r1 = r1.wrapping_add(-400 as i32 as i64 as u64)
    mov64 r3, 8                                     r3 = 8 as i32 as i64 as u64
    call function_649                       
    ldxdw r1, [r10-0x190]                   
    ldxdw r2, [r10-0x180]                   
lbb_2861:
    add64 r1, r2                                    r1 += r2   ///  r1 = r1.wrapping_add(r2)
    stxdw [r1+0x0], r6                      
    add64 r2, 8                                     r2 += 8   ///  r2 = r2.wrapping_add(8 as i32 as i64 as u64)
lbb_2864:
    stxdw [r10-0x180], r2                   
    ldxdw r1, [r10-0x188]                   
    sub64 r1, r2                                    r1 -= r2   ///  r1 = r1.wrapping_sub(r2)
    ldxdw r6, [r10-0x2f8]                   
    jgt r1, 7, lbb_2874                             if r1 > (7 as i32 as i64 as u64) { pc += 5 }
    mov64 r1, r10                                   r1 = r10
    add64 r1, -400                                  r1 += -400   ///  r1 = r1.wrapping_add(-400 as i32 as i64 as u64)
    mov64 r3, 8                                     r3 = 8 as i32 as i64 as u64
    call function_649                       
    ldxdw r2, [r10-0x180]                   
lbb_2874:
    ldxdw r1, [r10-0x190]                   
    add64 r1, r2                                    r1 += r2   ///  r1 = r1.wrapping_add(r2)
    stxdw [r1+0x0], r6                      
    add64 r2, 8                                     r2 += 8   ///  r2 = r2.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x180], r2                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -752                                  r1 += -752   ///  r1 = r1.wrapping_add(-752 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -400                                  r2 += -400   ///  r2 = r2.wrapping_add(-400 as i32 as i64 as u64)
    call function_873                       
    ldxdw r6, [r10-0x300]                   
    lddw r1, 0xffffffff                             r1 load str located at 4294967295
    jgt r6, r1, lbb_3181                            if r6 > r1 { pc += 293 }
    ldxdw r7, [r10-0x310]                   
    ldxdw r2, [r10-0x180]                   
    ldxdw r1, [r10-0x188]                   
    sub64 r1, r2                                    r1 -= r2   ///  r1 = r1.wrapping_sub(r2)
    jgt r1, 3, lbb_2898                             if r1 > (3 as i32 as i64 as u64) { pc += 5 }
    mov64 r1, r10                                   r1 = r10
    add64 r1, -400                                  r1 += -400   ///  r1 = r1.wrapping_add(-400 as i32 as i64 as u64)
    mov64 r3, 4                                     r3 = 4 as i32 as i64 as u64
    call function_649                       
    ldxdw r2, [r10-0x180]                   
lbb_2898:
    ldxdw r1, [r10-0x190]                   
    mov64 r3, r1                                    r3 = r1
    add64 r3, r2                                    r3 += r2   ///  r3 = r3.wrapping_add(r2)
    stxw [r3+0x0], r6                       
    add64 r2, 4                                     r2 += 4   ///  r2 = r2.wrapping_add(4 as i32 as i64 as u64)
    stxdw [r10-0x180], r2                   
    jeq r6, 0, lbb_2924                             if r6 == (0 as i32 as i64 as u64) { pc += 19 }
    lsh64 r6, 5                                     r6 <<= 5   ///  r6 = r6.wrapping_shl(5)
    ja lbb_2948                                     if true { pc += 41 }
lbb_2907:
    mov64 r3, r7                                    r3 = r7
    add64 r3, 32                                    r3 += 32   ///  r3 = r3.wrapping_add(32 as i32 as i64 as u64)
    mov64 r4, r1                                    r4 = r1
    add64 r4, r2                                    r4 += r2   ///  r4 = r4.wrapping_add(r2)
    ldxdw r5, [r7+0x18]                     
    stxdw [r4+0x18], r5                     
    ldxdw r5, [r7+0x10]                     
    stxdw [r4+0x10], r5                     
    ldxdw r5, [r7+0x8]                      
    stxdw [r4+0x8], r5                      
    ldxdw r5, [r7+0x0]                      
    stxdw [r4+0x0], r5                      
    add64 r2, 32                                    r2 += 32   ///  r2 = r2.wrapping_add(32 as i32 as i64 as u64)
    stxdw [r10-0x180], r2                   
    add64 r6, -32                                   r6 += -32   ///  r6 = r6.wrapping_add(-32 as i32 as i64 as u64)
    mov64 r7, r3                                    r7 = r3
    jne r6, 0, lbb_2948                             if r6 != (0 as i32 as i64 as u64) { pc += 24 }
lbb_2924:
    mov64 r1, r10                                   r1 = r10
    add64 r1, -664                                  r1 += -664   ///  r1 = r1.wrapping_add(-664 as i32 as i64 as u64)
    mov64 r6, r10                                   r6 = r10
    add64 r6, -400                                  r6 += -400   ///  r6 = r6.wrapping_add(-400 as i32 as i64 as u64)
    mov64 r2, r6                                    r2 = r6
    call function_955                       
    mov64 r1, r10                                   r1 = r10
    add64 r1, -648                                  r1 += -648   ///  r1 = r1.wrapping_add(-648 as i32 as i64 as u64)
    mov64 r2, r6                                    r2 = r6
    call function_955                       
    mov64 r6, r10                                   r6 = r10
    add64 r6, -632                                  r6 += -632   ///  r6 = r6.wrapping_add(-632 as i32 as i64 as u64)
    ldxdw r3, [r10-0x188]                   
    ldxdw r2, [r10-0x180]                   
    mov64 r1, r3                                    r1 = r3
    sub64 r1, r2                                    r1 -= r2   ///  r1 = r1.wrapping_sub(r2)
    jgt r1, 31, lbb_2958                            if r1 > (31 as i32 as i64 as u64) { pc += 17 }
    mov64 r1, r10                                   r1 = r10
    add64 r1, -400                                  r1 += -400   ///  r1 = r1.wrapping_add(-400 as i32 as i64 as u64)
    mov64 r3, 32                                    r3 = 32 as i32 as i64 as u64
    call function_649                       
    ldxdw r3, [r10-0x188]                   
    ldxdw r2, [r10-0x180]                   
    ja lbb_2958                                     if true { pc += 10 }
lbb_2948:
    ldxdw r3, [r10-0x188]                   
    sub64 r3, r2                                    r3 -= r2   ///  r3 = r3.wrapping_sub(r2)
    jgt r3, 31, lbb_2907                            if r3 > (31 as i32 as i64 as u64) { pc += -44 }
    mov64 r1, r10                                   r1 = r10
    add64 r1, -400                                  r1 += -400   ///  r1 = r1.wrapping_add(-400 as i32 as i64 as u64)
    mov64 r3, 32                                    r3 = 32 as i32 as i64 as u64
    call function_649                       
    ldxdw r1, [r10-0x190]                   
    ldxdw r2, [r10-0x180]                   
    ja lbb_2907                                     if true { pc += -51 }
lbb_2958:
    ldxdw r1, [r10-0x190]                   
    mov64 r4, r1                                    r4 = r1
    add64 r4, r2                                    r4 += r2   ///  r4 = r4.wrapping_add(r2)
    ldxdw r5, [r6+0x18]                     
    stxdw [r4+0x18], r5                     
    ldxdw r5, [r6+0x10]                     
    stxdw [r4+0x10], r5                     
    ldxdw r5, [r6+0x8]                      
    stxdw [r4+0x8], r5                      
    ldxdw r5, [r6+0x0]                      
    stxdw [r4+0x0], r5                      
    mov64 r6, r10                                   r6 = r10
    add64 r6, -600                                  r6 += -600   ///  r6 = r6.wrapping_add(-600 as i32 as i64 as u64)
    add64 r2, 32                                    r2 += 32   ///  r2 = r2.wrapping_add(32 as i32 as i64 as u64)
    stxdw [r10-0x180], r2                   
    mov64 r4, r3                                    r4 = r3
    sub64 r4, r2                                    r4 -= r2   ///  r4 = r4.wrapping_sub(r2)
    jgt r4, 31, lbb_2983                            if r4 > (31 as i32 as i64 as u64) { pc += 7 }
    mov64 r1, r10                                   r1 = r10
    add64 r1, -400                                  r1 += -400   ///  r1 = r1.wrapping_add(-400 as i32 as i64 as u64)
    mov64 r3, 32                                    r3 = 32 as i32 as i64 as u64
    call function_649                       
    ldxdw r3, [r10-0x188]                   
    ldxdw r1, [r10-0x190]                   
    ldxdw r2, [r10-0x180]                   
lbb_2983:
    mov64 r4, r1                                    r4 = r1
    add64 r4, r2                                    r4 += r2   ///  r4 = r4.wrapping_add(r2)
    ldxdw r5, [r6+0x18]                     
    stxdw [r4+0x18], r5                     
    ldxdw r5, [r6+0x10]                     
    stxdw [r4+0x10], r5                     
    ldxdw r5, [r6+0x8]                      
    stxdw [r4+0x8], r5                      
    ldxdw r5, [r6+0x0]                      
    stxdw [r4+0x0], r5                      
    mov64 r6, r10                                   r6 = r10
    add64 r6, -568                                  r6 += -568   ///  r6 = r6.wrapping_add(-568 as i32 as i64 as u64)
    add64 r2, 32                                    r2 += 32   ///  r2 = r2.wrapping_add(32 as i32 as i64 as u64)
    stxdw [r10-0x180], r2                   
    sub64 r3, r2                                    r3 -= r2   ///  r3 = r3.wrapping_sub(r2)
    jgt r3, 31, lbb_3005                            if r3 > (31 as i32 as i64 as u64) { pc += 6 }
    mov64 r1, r10                                   r1 = r10
    add64 r1, -400                                  r1 += -400   ///  r1 = r1.wrapping_add(-400 as i32 as i64 as u64)
    mov64 r3, 32                                    r3 = 32 as i32 as i64 as u64
    call function_649                       
    ldxdw r1, [r10-0x190]                   
    ldxdw r2, [r10-0x180]                   
lbb_3005:
    add64 r1, r2                                    r1 += r2   ///  r1 = r1.wrapping_add(r2)
    ldxdw r3, [r6+0x18]                     
    stxdw [r1+0x18], r3                     
    ldxdw r3, [r6+0x10]                     
    stxdw [r1+0x10], r3                     
    ldxdw r3, [r6+0x8]                      
    stxdw [r1+0x8], r3                      
    ldxdw r3, [r6+0x0]                      
    stxdw [r1+0x0], r3                      
    add64 r2, 32                                    r2 += 32   ///  r2 = r2.wrapping_add(32 as i32 as i64 as u64)
    stxdw [r10-0x180], r2                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -536                                  r1 += -536   ///  r1 = r1.wrapping_add(-536 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -400                                  r2 += -400   ///  r2 = r2.wrapping_add(-400 as i32 as i64 as u64)
    call function_955                       
    ldxdw r2, [r10-0x180]                   
    ldxdw r1, [r10-0x188]                   
    sub64 r1, r2                                    r1 -= r2   ///  r1 = r1.wrapping_sub(r2)
    ldxdw r6, [r10-0x208]                   
    jgt r1, 7, lbb_3031                             if r1 > (7 as i32 as i64 as u64) { pc += 5 }
    mov64 r1, r10                                   r1 = r10
    add64 r1, -400                                  r1 += -400   ///  r1 = r1.wrapping_add(-400 as i32 as i64 as u64)
    mov64 r3, 8                                     r3 = 8 as i32 as i64 as u64
    call function_649                       
    ldxdw r2, [r10-0x180]                   
lbb_3031:
    ldxdw r1, [r10-0x190]                   
    add64 r1, r2                                    r1 += r2   ///  r1 = r1.wrapping_add(r2)
    stxdw [r1+0x0], r6                      
    add64 r2, 8                                     r2 += 8   ///  r2 = r2.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x180], r2                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -512                                  r1 += -512   ///  r1 = r1.wrapping_add(-512 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -400                                  r2 += -400   ///  r2 = r2.wrapping_add(-400 as i32 as i64 as u64)
    call function_955                       
    ldxdw r2, [r10-0x180]                   
    ldxdw r1, [r10-0x188]                   
    sub64 r1, r2                                    r1 -= r2   ///  r1 = r1.wrapping_sub(r2)
    ldxdw r6, [r10-0x1f0]                   
    jgt r1, 7, lbb_3051                             if r1 > (7 as i32 as i64 as u64) { pc += 5 }
    mov64 r1, r10                                   r1 = r10
    add64 r1, -400                                  r1 += -400   ///  r1 = r1.wrapping_add(-400 as i32 as i64 as u64)
    mov64 r3, 8                                     r3 = 8 as i32 as i64 as u64
    call function_649                       
    ldxdw r2, [r10-0x180]                   
lbb_3051:
    ldxdw r1, [r10-0x190]                   
    add64 r1, r2                                    r1 += r2   ///  r1 = r1.wrapping_add(r2)
    stxdw [r1+0x0], r6                      
    add64 r2, 8                                     r2 += 8   ///  r2 = r2.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x180], r2                   
    ldxdw r1, [r10-0x188]                   
    ldxb r3, [r10-0x1c4]                    
    jne r3, 0, lbb_3071                             if r3 != (0 as i32 as i64 as u64) { pc += 12 }
    jne r1, r2, lbb_3065                            if r1 != r2 { pc += 5 }
    mov64 r1, r10                                   r1 = r10
    add64 r1, -400                                  r1 += -400   ///  r1 = r1.wrapping_add(-400 as i32 as i64 as u64)
    mov64 r3, 1                                     r3 = 1 as i32 as i64 as u64
    call function_649                       
    ldxdw r2, [r10-0x180]                   
lbb_3065:
    ldxdw r1, [r10-0x190]                   
    add64 r1, r2                                    r1 += r2   ///  r1 = r1.wrapping_add(r2)
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
    stxb [r1+0x0], r3                       
    add64 r2, 1                                     r2 += 1   ///  r2 = r2.wrapping_add(1 as i32 as i64 as u64)
    ja lbb_3105                                     if true { pc += 34 }
lbb_3071:
    jne r1, r2, lbb_3078                            if r1 != r2 { pc += 6 }
    mov64 r1, r10                                   r1 = r10
    add64 r1, -400                                  r1 += -400   ///  r1 = r1.wrapping_add(-400 as i32 as i64 as u64)
    mov64 r3, 1                                     r3 = 1 as i32 as i64 as u64
    call function_649                       
    ldxdw r1, [r10-0x188]                   
    ldxdw r2, [r10-0x180]                   
lbb_3078:
    ldxdw r3, [r10-0x190]                   
    mov64 r4, r3                                    r4 = r3
    add64 r4, r2                                    r4 += r2   ///  r4 = r4.wrapping_add(r2)
    mov64 r5, 1                                     r5 = 1 as i32 as i64 as u64
    stxb [r4+0x0], r5                       
    mov64 r6, r10                                   r6 = r10
    add64 r6, -451                                  r6 += -451   ///  r6 = r6.wrapping_add(-451 as i32 as i64 as u64)
    add64 r2, 1                                     r2 += 1   ///  r2 = r2.wrapping_add(1 as i32 as i64 as u64)
    stxdw [r10-0x180], r2                   
    sub64 r1, r2                                    r1 -= r2   ///  r1 = r1.wrapping_sub(r2)
    jgt r1, 31, lbb_3095                            if r1 > (31 as i32 as i64 as u64) { pc += 6 }
    mov64 r1, r10                                   r1 = r10
    add64 r1, -400                                  r1 += -400   ///  r1 = r1.wrapping_add(-400 as i32 as i64 as u64)
    mov64 r3, 32                                    r3 = 32 as i32 as i64 as u64
    call function_649                       
    ldxdw r3, [r10-0x190]                   
    ldxdw r2, [r10-0x180]                   
lbb_3095:
    add64 r3, r2                                    r3 += r2   ///  r3 = r3.wrapping_add(r2)
    ldxdw r1, [r6+0x18]                     
    stxdw [r3+0x18], r1                     
    ldxdw r1, [r6+0x10]                     
    stxdw [r3+0x10], r1                     
    ldxdw r1, [r6+0x8]                      
    stxdw [r3+0x8], r1                      
    ldxdw r1, [r6+0x0]                      
    stxdw [r3+0x0], r1                      
    add64 r2, 32                                    r2 += 32   ///  r2 = r2.wrapping_add(32 as i32 as i64 as u64)
lbb_3105:
    stxdw [r10-0x180], r2                   
    ldxdw r1, [r10-0x188]                   
    mov64 r3, r1                                    r3 = r1
    sub64 r3, r2                                    r3 -= r2   ///  r3 = r3.wrapping_sub(r2)
    mov64 r6, r10                                   r6 = r10
    add64 r6, -488                                  r6 += -488   ///  r6 = r6.wrapping_add(-488 as i32 as i64 as u64)
    jgt r3, 31, lbb_3118                            if r3 > (31 as i32 as i64 as u64) { pc += 6 }
    mov64 r1, r10                                   r1 = r10
    add64 r1, -400                                  r1 += -400   ///  r1 = r1.wrapping_add(-400 as i32 as i64 as u64)
    mov64 r3, 32                                    r3 = 32 as i32 as i64 as u64
    call function_649                       
    ldxdw r1, [r10-0x188]                   
    ldxdw r2, [r10-0x180]                   
lbb_3118:
    ldxdw r3, [r10-0x190]                   
    mov64 r4, r3                                    r4 = r3
    add64 r4, r2                                    r4 += r2   ///  r4 = r4.wrapping_add(r2)
    ldxdw r5, [r6+0x18]                     
    stxdw [r4+0x18], r5                     
    ldxdw r5, [r6+0x10]                     
    stxdw [r4+0x10], r5                     
    ldxdw r5, [r6+0x8]                      
    stxdw [r4+0x8], r5                      
    ldxdw r5, [r6+0x0]                      
    stxdw [r4+0x0], r5                      
    add64 r2, 32                                    r2 += 32   ///  r2 = r2.wrapping_add(32 as i32 as i64 as u64)
    stxdw [r10-0x180], r2                   
    sub64 r1, r2                                    r1 -= r2   ///  r1 = r1.wrapping_sub(r2)
    ldxdw r6, [r10-0x198]                   
    jgt r1, 7, lbb_3140                             if r1 > (7 as i32 as i64 as u64) { pc += 6 }
    mov64 r1, r10                                   r1 = r10
    add64 r1, -400                                  r1 += -400   ///  r1 = r1.wrapping_add(-400 as i32 as i64 as u64)
    mov64 r3, 8                                     r3 = 8 as i32 as i64 as u64
    call function_649                       
    ldxdw r3, [r10-0x190]                   
    ldxdw r2, [r10-0x180]                   
lbb_3140:
    add64 r3, r2                                    r3 += r2   ///  r3 = r3.wrapping_add(r2)
    stxdw [r3+0x0], r6                      
    add64 r2, 8                                     r2 += 8   ///  r2 = r2.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x180], r2                   
    ldxdw r1, [r10-0x190]                   
    call function_26122                     
    ldxdw r1, [r10-0x190]                   
    ldxdw r2, [r10-0x180]                   
    stxdw [r10-0x178], r2                   
    stxdw [r10-0x180], r1                   
    mov64 r1, 6                                     r1 = 6 as i32 as i64 as u64
    stxdw [r10-0x188], r1                   
    lddw r1, 0x10005ff90 --> b"\x04\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\…        r1 load str located at 4295360400
    add64 r1, 24                                    r1 += 24   ///  r1 = r1.wrapping_add(24 as i32 as i64 as u64)
    stxdw [r10-0x190], r1                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -400                                  r1 += -400   ///  r1 = r1.wrapping_add(-400 as i32 as i64 as u64)
    mov64 r2, 2                                     r2 = 2 as i32 as i64 as u64
    call function_40367                     
    exit                                    
lbb_3161:
    ldxb r2, [r10-0x2f]                     
    add64 r1, r2                                    r1 += r2   ///  r1 = r1.wrapping_add(r2)
    mul64 r1, r3                                    r1 *= r3   ///  r1 = r1.wrapping_mul(r3)
    ldxb r2, [r10-0x2e]                     
    add64 r1, r2                                    r1 += r2   ///  r1 = r1.wrapping_add(r2)
    mul64 r1, r3                                    r1 *= r3   ///  r1 = r1.wrapping_mul(r3)
    ldxb r2, [r10-0x2d]                     
    add64 r1, r2                                    r1 += r2   ///  r1 = r1.wrapping_add(r2)
    mul64 r1, r3                                    r1 *= r3   ///  r1 = r1.wrapping_mul(r3)
    ja lbb_2232                                     if true { pc += -939 }
lbb_3171:
    ldxb r3, [r10-0x157]                    
    add64 r1, r3                                    r1 += r3   ///  r1 = r1.wrapping_add(r3)
    mul64 r1, r2                                    r1 *= r2   ///  r1 = r1.wrapping_mul(r2)
    ldxb r3, [r10-0x156]                    
    add64 r1, r3                                    r1 += r3   ///  r1 = r1.wrapping_add(r3)
    mul64 r1, r2                                    r1 *= r2   ///  r1 = r1.wrapping_mul(r2)
    ldxb r3, [r10-0x155]                    
    add64 r1, r3                                    r1 += r3   ///  r1 = r1.wrapping_add(r3)
    mul64 r1, r2                                    r1 *= r2   ///  r1 = r1.wrapping_mul(r2)
    ja lbb_2257                                     if true { pc += -924 }
lbb_3181:
    lddw r1, 0x1500000003                           r1 load str located at 90194313219
    stxdw [r10-0x8], r1                     
    mov64 r3, r10                                   r3 = r10
    add64 r3, -8                                    r3 += -8   ///  r3 = r3.wrapping_add(-8 as i32 as i64 as u64)
    lddw r1, 0x10005fa30 --> b"called `Result::unwrap()` on an `Err` value"        r1 load str located at 4295359024
    mov64 r2, 43                                    r2 = 43 as i32 as i64 as u64
    lddw r4, 0x100064cb8 --> b"\x00\x00\x00\x008\x0c\x00\x00\x08\x00\x00\x00\x00\x00\x00\x00\x08\x00\x00…        r4 load str located at 4295380152
    lddw r5, 0x100064cd8 --> b"\x00\x00\x00\x00^\xfe\x05\x00\x11\x00\x00\x00\x00\x00\x00\x00n\x00\x00\x0…        r5 load str located at 4295380184
    call function_44299                     
    syscall [invalid]                       

function_3195:
    mov64 r7, r3                                    r7 = r3
    mov64 r3, r2                                    r3 = r2
    mov64 r6, r1                                    r6 = r1
    mov64 r1, r10                                   r1 = r10
    add64 r1, -80                                   r1 += -80   ///  r1 = r1.wrapping_add(-80 as i32 as i64 as u64)
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
    call function_41644                     
    ldxdw r1, [r10-0x50]                    
    jeq r1, 0, lbb_3223                             if r1 == (0 as i32 as i64 as u64) { pc += 19 }
    mov64 r1, r10                                   r1 = r10
    add64 r1, -120                                  r1 += -120   ///  r1 = r1.wrapping_add(-120 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -40                                   r2 += -40   ///  r2 = r2.wrapping_add(-40 as i32 as i64 as u64)
    mov64 r3, 40                                    r3 = 40 as i32 as i64 as u64
    call function_48190                     
    ldxdw r1, [r10-0x58]                    
    stxdw [r10-0x38], r1                    
    ldxdw r1, [r10-0x60]                    
    stxdw [r10-0x40], r1                    
    ldxdw r1, [r10-0x68]                    
    stxdw [r10-0x48], r1                    
    ldxdw r1, [r10-0x70]                    
    stxdw [r10-0x50], r1                    
    lddw r2, 0xc56bbfed2dd57904                     r2 load str located at -4221069200332588796
    jeq r1, r2, lbb_3232                            if r1 == r2 { pc += 11 }
lbb_3221:
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    ja lbb_3245                                     if true { pc += 22 }
lbb_3223:
    ldxdw r1, [r10-0x48]                    
    ldxdw r2, [r10-0x40]                    
    ldxdw r3, [r10-0x38]                    
    ldxdw r4, [r10-0x30]                    
    stxdw [r6+0x18], r4                     
    stxdw [r6+0x10], r3                     
    stxdw [r6+0x8], r2                      
    stxdw [r6+0x0], r1                      
    ja lbb_3318                                     if true { pc += 86 }
lbb_3232:
    lddw r1, 0xae344a53849dd0ec                     r1 load str located at -5894004289753460500
    ldxdw r2, [r10-0x48]                    
    jne r2, r1, lbb_3221                            if r2 != r1 { pc += -15 }
    lddw r1, 0xcdf74fb9435097a5                     r1 load str located at -3605325319569893467
    ldxdw r2, [r10-0x40]                    
    jne r2, r1, lbb_3221                            if r2 != r1 { pc += -19 }
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    lddw r2, 0x60920f050e384241                     r2 load str located at 6958640888628658753
    ldxdw r3, [r10-0x38]                    
    jne r3, r2, lbb_3221                            if r3 != r2 { pc += -24 }
lbb_3245:
    jeq r1, 0, lbb_3314                             if r1 == (0 as i32 as i64 as u64) { pc += 68 }
    lddw r1, 0x6ec031f25bd57904                     r1 load str located at 7980433456693082372
    ldxdw r2, [r10-0x50]                    
    jeq r2, r1, lbb_3252                            if r2 == r1 { pc += 2 }
lbb_3250:
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    ja lbb_3265                                     if true { pc += 13 }
lbb_3252:
    lddw r1, 0x71568ce6ec574ee                      r1 load str located at 510429368607405294
    ldxdw r2, [r10-0x48]                    
    jne r2, r1, lbb_3250                            if r2 != r1 { pc += -6 }
    lddw r1, 0x518ef4a3deb2b1fd                     r1 load str located at 5876903548418175485
    ldxdw r2, [r10-0x40]                    
    jne r2, r1, lbb_3250                            if r2 != r1 { pc += -10 }
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    lddw r2, 0x8f13bc56a2cdb102                     r2 load str located at -8136953021443755774
    ldxdw r3, [r10-0x38]                    
    jne r3, r2, lbb_3250                            if r3 != r2 { pc += -15 }
lbb_3265:
    jeq r1, 0, lbb_3314                             if r1 == (0 as i32 as i64 as u64) { pc += 48 }
    lddw r1, 0xbb0ee7126e9ca906                     r1 load str located at -4967779272591890170
    ldxdw r2, [r10-0x50]                    
    jeq r2, r1, lbb_3272                            if r2 == r1 { pc += 2 }
lbb_3270:
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    ja lbb_3285                                     if true { pc += 13 }
lbb_3272:
    lddw r1, 0x6e904b4c145c1835                     r1 load str located at 7966950530949584949
    ldxdw r2, [r10-0x48]                    
    jne r2, r1, lbb_3270                            if r2 != r1 { pc += -6 }
    lddw r1, 0x2a2f74470ab0ff18                     r1 load str located at 3039776121969245976
    ldxdw r2, [r10-0x40]                    
    jne r2, r1, lbb_3270                            if r2 != r1 { pc += -10 }
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    lddw r2, 0xd4c988690b11045e                     r2 load str located at -3113807682611379106
    ldxdw r3, [r10-0x38]                    
    jne r3, r2, lbb_3270                            if r3 != r2 { pc += -15 }
lbb_3285:
    jeq r1, 0, lbb_3314                             if r1 == (0 as i32 as i64 as u64) { pc += 28 }
    lddw r1, 0x4873bce2144ae3b5                     r1 load str located at 5220724072241619893
    ldxdw r2, [r10-0x50]                    
    jeq r2, r1, lbb_3299                            if r2 == r1 { pc += 9 }
lbb_3290:
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    jeq r1, 0, lbb_3314                             if r1 == (0 as i32 as i64 as u64) { pc += 22 }
lbb_3292:
    ldxdw r1, [r7+0x0]                      
    ldxdw r2, [r10-0x50]                    
    jeq r2, r1, lbb_3319                            if r2 == r1 { pc += 24 }
lbb_3295:
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    jeq r1, 0, lbb_3331                             if r1 == (0 as i32 as i64 as u64) { pc += 34 }
lbb_3297:
    mov64 r1, 2                                     r1 = 2 as i32 as i64 as u64
    ja lbb_3315                                     if true { pc += 16 }
lbb_3299:
    lddw r1, 0xd6ee5daff5e10e69                     r1 load str located at -2959324894810010007
    ldxdw r2, [r10-0x48]                    
    jne r2, r1, lbb_3290                            if r2 != r1 { pc += -13 }
    lddw r1, 0x60b8aa6da3403855                     r1 load str located at 6969507811222894677
    ldxdw r2, [r10-0x40]                    
    jne r2, r1, lbb_3290                            if r2 != r1 { pc += -17 }
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    lddw r2, 0x103cc0bd736050b0                     r2 load str located at 1170021923126530224
    ldxdw r3, [r10-0x38]                    
    jne r3, r2, lbb_3290                            if r3 != r2 { pc += -22 }
    jeq r1, 0, lbb_3314                             if r1 == (0 as i32 as i64 as u64) { pc += 1 }
    ja lbb_3292                                     if true { pc += -22 }
lbb_3314:
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
lbb_3315:
    stxb [r6+0x4], r1                       
    mov64 r1, 24                                    r1 = 24 as i32 as i64 as u64
    stxw [r6+0x0], r1                       
lbb_3318:
    exit                                    
lbb_3319:
    ldxdw r1, [r7+0x8]                      
    ldxdw r2, [r10-0x48]                    
    jne r2, r1, lbb_3295                            if r2 != r1 { pc += -27 }
    ldxdw r1, [r7+0x10]                     
    ldxdw r2, [r10-0x40]                    
    jne r2, r1, lbb_3295                            if r2 != r1 { pc += -30 }
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    ldxdw r2, [r7+0x18]                     
    ldxdw r3, [r10-0x38]                    
    jne r3, r2, lbb_3295                            if r3 != r2 { pc += -34 }
    jeq r1, 0, lbb_3331                             if r1 == (0 as i32 as i64 as u64) { pc += 1 }
    ja lbb_3297                                     if true { pc += -34 }
lbb_3331:
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    ja lbb_3315                                     if true { pc += -18 }

function_3333:
    stxdw [r10-0x120], r3                   
    stxdw [r10-0x158], r1                   
    lddw r1, 0x300000000                            r1 load str located at 12884901888
    ldxdw r1, [r1+0x0]                      
    mov64 r4, r1                                    r4 = r1
    add64 r4, -64                                   r4 += -64   ///  r4 = r4.wrapping_add(-64 as i32 as i64 as u64)
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
    mov64 r5, 1                                     r5 = 1 as i32 as i64 as u64
    jgt r4, r1, lbb_3344                            if r4 > r1 { pc += 1 }
    mov64 r5, 0                                     r5 = 0 as i32 as i64 as u64
lbb_3344:
    jne r5, 0, lbb_3346                             if r5 != (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r3, r4                                    r3 = r4
lbb_3346:
    lddw r9, 0x300007fc0                            r9 load str located at 12884934592
    jeq r1, 0, lbb_3350                             if r1 == (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r9, r3                                    r9 = r3
lbb_3350:
    lddw r1, 0x300000007                            r1 load str located at 12884901895
    jgt r9, r1, lbb_3357                            if r9 > r1 { pc += 4 }
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    mov64 r2, 64                                    r2 = 64 as i32 as i64 as u64
    call function_43400                     
    syscall [invalid]                       
lbb_3357:
    lddw r1, 0x300000000                            r1 load str located at 12884901888
    stxdw [r1+0x0], r9                      
    mov64 r1, 200000                                r1 = 200000 as i32 as i64 as u64
    stxw [r10-0x108], r1                    
    mov64 r1, 2                                     r1 = 2 as i32 as i64 as u64
    stxb [r10-0xe0], r1                     
    stxdw [r10-0xf8], r1                    
    stxdw [r10-0x100], r9                   
    mov64 r8, 0                                     r8 = 0 as i32 as i64 as u64
    stxdw [r10-0xe8], r8                    
    stxdw [r10-0x118], r8                   
    stxdw [r10-0xf0], r8                    
    stxdw [r10-0xd0], r8                    
    stxdw [r10-0xd8], r2                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -200                                  r1 += -200   ///  r1 = r1.wrapping_add(-200 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -216                                  r2 += -216   ///  r2 = r2.wrapping_add(-216 as i32 as i64 as u64)
    call function_3730                      
    ldxdw r1, [r10-0xc8]                    
    jeq r1, 0, lbb_3711                             if r1 == (0 as i32 as i64 as u64) { pc += 332 }
    mov64 r1, r10                                   r1 = r10
    add64 r1, -256                                  r1 += -256   ///  r1 = r1.wrapping_add(-256 as i32 as i64 as u64)
    stxdw [r10-0x128], r1                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -72                                   r1 += -72   ///  r1 = r1.wrapping_add(-72 as i32 as i64 as u64)
    stxdw [r10-0x140], r1                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -104                                  r1 += -104   ///  r1 = r1.wrapping_add(-104 as i32 as i64 as u64)
    stxdw [r10-0x148], r1                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -152                                  r1 += -152   ///  r1 = r1.wrapping_add(-152 as i32 as i64 as u64)
    stxdw [r10-0x150], r1                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -184                                  r1 += -184   ///  r1 = r1.wrapping_add(-184 as i32 as i64 as u64)
    stxdw [r10-0x138], r1                   
    ja lbb_3403                                     if true { pc += 8 }
lbb_3395:
    jgt r1, 11, lbb_3706                            if r1 > (11 as i32 as i64 as u64) { pc += 310 }
lbb_3396:
    mov64 r1, r10                                   r1 = r10
    add64 r1, -200                                  r1 += -200   ///  r1 = r1.wrapping_add(-200 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -216                                  r2 += -216   ///  r2 = r2.wrapping_add(-216 as i32 as i64 as u64)
    call function_3730                      
    ldxdw r1, [r10-0xc8]                    
    jeq r1, 0, lbb_3711                             if r1 == (0 as i32 as i64 as u64) { pc += 308 }
lbb_3403:
    ldxdw r1, [r10-0xc0]                    
    stxdw [r10-0x130], r1                   
    jeq r1, 0, lbb_3717                             if r1 == (0 as i32 as i64 as u64) { pc += 311 }
    ldxdw r1, [r10-0x140]                   
    ldxdw r2, [r10-0x150]                   
    mov64 r3, 40                                    r3 = 40 as i32 as i64 as u64
    call function_48190                     
    ldxdw r2, [r10-0x138]                   
    ldxdw r1, [r2+0x18]                     
    ldxdw r3, [r10-0x148]                   
    stxdw [r3+0x18], r1                     
    ldxdw r1, [r2+0x10]                     
    stxdw [r3+0x10], r1                     
    ldxdw r1, [r2+0x8]                      
    stxdw [r3+0x8], r1                      
    ldxdw r1, [r2+0x0]                      
    stxdw [r3+0x0], r1                      
    ldxdw r7, [r10-0x60]                    
    jeq r7, 0, lbb_3478                             if r7 == (0 as i32 as i64 as u64) { pc += 56 }
    mul64 r7, 34                                    r7 *= 34   ///  r7 = r7.wrapping_mul(34 as u64)
    ldxdw r6, [r10-0x130]                   
    ja lbb_3431                                     if true { pc += 6 }
lbb_3425:
    mov64 r2, r0                                    r2 = r0
    call function_24511                     
    stxw [r10-0xe0], r0                     
lbb_3428:
    add64 r6, 34                                    r6 += 34   ///  r6 = r6.wrapping_add(34 as i32 as i64 as u64)
    add64 r7, -34                                   r7 += -34   ///  r7 = r7.wrapping_add(-34 as i32 as i64 as u64)
    jeq r7, 0, lbb_3478                             if r7 == (0 as i32 as i64 as u64) { pc += 47 }
lbb_3431:
    ldxb r1, [r6+0x20]                      
    jeq r1, 0, lbb_3428                             if r1 == (0 as i32 as i64 as u64) { pc += -5 }
    ldxdw r1, [r6+0x18]                     
    stxdw [r10-0x8], r1                     
    ldxdw r1, [r6+0x10]                     
    stxdw [r10-0x10], r1                    
    ldxdw r1, [r6+0x8]                      
    stxdw [r10-0x18], r1                    
    ldxdw r1, [r6+0x0]                      
    stxdw [r10-0x20], r1                    
    ldxdw r1, [r10-0xf8]                    
    jne r8, r1, lbb_3448                            if r8 != r1 { pc += 5 }
    ldxdw r1, [r10-0x128]                   
    mov64 r2, r8                                    r2 = r8
    call function_598                       
    ldxdw r9, [r10-0x100]                   
    ldxdw r8, [r10-0xf0]                    
lbb_3448:
    mov64 r1, r8                                    r1 = r8
    lsh64 r1, 5                                     r1 <<= 5   ///  r1 = r1.wrapping_shl(5)
    mov64 r2, r9                                    r2 = r9
    add64 r2, r1                                    r2 += r1   ///  r2 = r2.wrapping_add(r1)
    ldxdw r1, [r10-0x8]                     
    stxdw [r2+0x18], r1                     
    ldxdw r1, [r10-0x10]                    
    stxdw [r2+0x10], r1                     
    ldxdw r1, [r10-0x18]                    
    stxdw [r2+0x8], r1                      
    ldxdw r1, [r10-0x20]                    
    stxdw [r2+0x0], r1                      
    add64 r8, 1                                     r8 += 1   ///  r8 = r8.wrapping_add(1 as i32 as i64 as u64)
    stxdw [r10-0xf0], r8                    
    mov64 r1, r6                                    r1 = r6
    ldxdw r2, [r10-0x120]                   
    call function_24576                     
    mov64 r1, r0                                    r1 = r0
    and64 r1, 255                                   r1 &= 255   ///  r1 = r1.and(255)
    jeq r1, 2, lbb_3428                             if r1 == (2 as i32 as i64 as u64) { pc += -40 }
    ldxb r2, [r10-0xe0]                     
    mov64 r1, r0                                    r1 = r0
    jeq r2, 2, lbb_3425                             if r2 == (2 as i32 as i64 as u64) { pc += -46 }
    ldxh r3, [r10-0xdf]                     
    lsh64 r3, 8                                     r3 <<= 8   ///  r3 = r3.wrapping_shl(8)
    ldxb r1, [r10-0xdd]                     
    lsh64 r1, 24                                    r1 <<= 24   ///  r1 = r1.wrapping_shl(24)
    or64 r1, r3                                     r1 |= r3   ///  r1 = r1.or(r3)
    or64 r1, r2                                     r1 |= r2   ///  r1 = r1.or(r2)
    ja lbb_3425                                     if true { pc += -53 }
lbb_3478:
    ldxdw r1, [r10-0x40]                    
    lddw r2, 0x321721e56f460603                     r2 load str located at 3609390895658829315
    jeq r1, r2, lbb_3484                            if r1 == r2 { pc += 2 }
lbb_3482:
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    ja lbb_3497                                     if true { pc += 13 }
lbb_3484:
    ldxdw r1, [r10-0x38]                    
    lddw r2, 0xe79bc372baadecff                     r2 load str located at -1757596332032398081
    jne r1, r2, lbb_3482                            if r1 != r2 { pc += -6 }
    ldxdw r1, [r10-0x30]                    
    lddw r2, 0x6b12f7c5bbe58cbc                     r2 load str located at 7715501540272082108
    jne r1, r2, lbb_3482                            if r1 != r2 { pc += -10 }
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    ldxdw r2, [r10-0x28]                    
    lddw r3, 0x403a9b432c                           r3 load str located at 275861160748
    jne r2, r3, lbb_3482                            if r2 != r3 { pc += -15 }
lbb_3497:
    jne r1, 0, lbb_3515                             if r1 != (0 as i32 as i64 as u64) { pc += 17 }
    ldxdw r2, [r10-0x48]                    
    jeq r2, 0, lbb_3515                             if r2 == (0 as i32 as i64 as u64) { pc += 15 }
    ldxdw r1, [r10-0x58]                    
    ldxb r3, [r1+0x0]                       
    jeq r3, 3, lbb_3509                             if r3 == (3 as i32 as i64 as u64) { pc += 6 }
    jne r3, 2, lbb_3515                             if r3 != (2 as i32 as i64 as u64) { pc += 11 }
    jgt r2, 4, lbb_3506                             if r2 > (4 as i32 as i64 as u64) { pc += 1 }
    ja lbb_3515                                     if true { pc += 9 }
lbb_3506:
    ldxw r1, [r1+0x1]                       
    stxw [r10-0x108], r1                    
    ja lbb_3515                                     if true { pc += 6 }
lbb_3509:
    jgt r2, 8, lbb_3511                             if r2 > (8 as i32 as i64 as u64) { pc += 1 }
    ja lbb_3515                                     if true { pc += 4 }
lbb_3511:
    ldxdw r1, [r1+0x1]                      
    stxdw [r10-0x110], r1                   
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    stxdw [r10-0x118], r1                   
lbb_3515:
    ldxdw r1, [r10-0x40]                    
    jeq r1, 0, lbb_3519                             if r1 == (0 as i32 as i64 as u64) { pc += 2 }
lbb_3517:
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    ja lbb_3526                                     if true { pc += 7 }
lbb_3519:
    ldxdw r1, [r10-0x38]                    
    jne r1, 0, lbb_3517                             if r1 != (0 as i32 as i64 as u64) { pc += -4 }
    ldxdw r1, [r10-0x30]                    
    jne r1, 0, lbb_3517                             if r1 != (0 as i32 as i64 as u64) { pc += -6 }
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    ldxdw r2, [r10-0x28]                    
    jne r2, 0, lbb_3517                             if r2 != (0 as i32 as i64 as u64) { pc += -9 }
lbb_3526:
    jne r1, 0, lbb_3396                             if r1 != (0 as i32 as i64 as u64) { pc += -131 }
    ldxdw r1, [r10-0x48]                    
    jeq r1, 0, lbb_3396                             if r1 == (0 as i32 as i64 as u64) { pc += -133 }
    ldxdw r2, [r10-0x60]                    
    mov64 r3, 2                                     r3 = 2 as i32 as i64 as u64
    jgt r3, r2, lbb_3396                            if r3 > r2 { pc += -136 }
    ldxdw r2, [r10-0x58]                    
    ldxb r3, [r2+0x0]                       
    jne r3, 2, lbb_3396                             if r3 != (2 as i32 as i64 as u64) { pc += -139 }
    ldxdw r4, [r10-0x130]                   
    ldxdw r3, [r4+0x3a]                     
    stxdw [r10-0x8], r3                     
    ldxdw r3, [r4+0x32]                     
    stxdw [r10-0x10], r3                    
    ldxdw r3, [r4+0x2a]                     
    stxdw [r10-0x18], r3                    
    ldxdw r3, [r4+0x22]                     
    stxdw [r10-0x20], r3                    
    lddw r4, 0x85bbce79b11c5278                     r4 load str located at -8810221223962455432
    jeq r3, r4, lbb_3549                            if r3 == r4 { pc += 2 }
lbb_3547:
    mov64 r3, 1                                     r3 = 1 as i32 as i64 as u64
    ja lbb_3562                                     if true { pc += 13 }
lbb_3549:
    ldxdw r3, [r10-0x18]                    
    lddw r4, 0xd294ecd5a256b589                     r4 load str located at -3272730626895727223
    jne r3, r4, lbb_3547                            if r3 != r4 { pc += -6 }
    ldxdw r3, [r10-0x10]                    
    lddw r4, 0xf52abbf9fd828649                     r4 load str located at -780604903020919223
    jne r3, r4, lbb_3547                            if r3 != r4 { pc += -10 }
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
    ldxdw r4, [r10-0x8]                     
    lddw r5, 0xda5341cc91e464ad                     r5 load str located at -2714753803497478995
    jne r4, r5, lbb_3547                            if r4 != r5 { pc += -15 }
lbb_3562:
    jeq r3, 0, lbb_3395                             if r3 == (0 as i32 as i64 as u64) { pc += -168 }
    ldxdw r3, [r10-0x20]                    
    lddw r4, 0xcb45f7d187ec87f1                     r4 load str located at -3799358231316494351
    jeq r3, r4, lbb_3569                            if r3 == r4 { pc += 2 }
lbb_3567:
    mov64 r3, 1                                     r3 = 1 as i32 as i64 as u64
    ja lbb_3582                                     if true { pc += 13 }
lbb_3569:
    ldxdw r3, [r10-0x18]                    
    lddw r4, 0xda9ea6264a38033a                     r4 load str located at -2693532843736825030
    jne r3, r4, lbb_3567                            if r3 != r4 { pc += -6 }
    ldxdw r3, [r10-0x10]                    
    lddw r4, 0x24e4410faad1a20c                     r4 load str located at 2658321215601615372
    jne r3, r4, lbb_3567                            if r3 != r4 { pc += -10 }
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
    ldxdw r4, [r10-0x8]                     
    lddw r5, 0x315d5bff917e3716                     r5 load str located at 3557100433908315926
    jne r4, r5, lbb_3567                            if r4 != r5 { pc += -15 }
lbb_3582:
    jeq r3, 0, lbb_3395                             if r3 == (0 as i32 as i64 as u64) { pc += -188 }
    ldxdw r3, [r10-0x20]                    
    lddw r4, 0x86ba9f5ee50d4eb1                     r4 load str located at -8738496897040429391
    jeq r3, r4, lbb_3589                            if r3 == r4 { pc += 2 }
lbb_3587:
    mov64 r3, 1                                     r3 = 1 as i32 as i64 as u64
    ja lbb_3602                                     if true { pc += 13 }
lbb_3589:
    ldxdw r3, [r10-0x18]                    
    lddw r4, 0xc9f8cf48d5bf6e39                     r4 load str located at -3893133966131106247
    jne r3, r4, lbb_3587                            if r3 != r4 { pc += -6 }
    ldxdw r3, [r10-0x10]                    
    lddw r4, 0x9baa5bb7c7ea1120                     r4 load str located at -7229865406898761440
    jne r3, r4, lbb_3587                            if r3 != r4 { pc += -10 }
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
    ldxdw r4, [r10-0x8]                     
    lddw r5, 0x4171a1f5866a9c2d                     r5 load str located at 4715728360727813165
    jne r4, r5, lbb_3587                            if r4 != r5 { pc += -15 }
lbb_3602:
    jeq r3, 0, lbb_3395                             if r3 == (0 as i32 as i64 as u64) { pc += -208 }
    ldxdw r3, [r10-0x20]                    
    lddw r4, 0x17e6dfa2a3fff188                     r4 load str located at 1722309797144949128
    jeq r3, r4, lbb_3609                            if r3 == r4 { pc += 2 }
lbb_3607:
    mov64 r3, 1                                     r3 = 1 as i32 as i64 as u64
    ja lbb_3622                                     if true { pc += 13 }
lbb_3609:
    ldxdw r3, [r10-0x18]                    
    lddw r4, 0x22a3513257e3c4bd                     r4 load str located at 2495927895158146237
    jne r3, r4, lbb_3607                            if r3 != r4 { pc += -6 }
    ldxdw r3, [r10-0x10]                    
    lddw r4, 0x3957a4e581aefce3                     r4 load str located at 4131952488765914339
    jne r3, r4, lbb_3607                            if r3 != r4 { pc += -10 }
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
    ldxdw r4, [r10-0x8]                     
    lddw r5, 0xe265a4001c75640e                     r5 load str located at -2133118528105651186
    jne r4, r5, lbb_3607                            if r4 != r5 { pc += -15 }
lbb_3622:
    jeq r3, 0, lbb_3395                             if r3 == (0 as i32 as i64 as u64) { pc += -228 }
    ldxdw r3, [r10-0x20]                    
    lddw r4, 0x66ddf15e06572bbc                     r4 load str located at 7412345947857300412
    jeq r3, r4, lbb_3629                            if r3 == r4 { pc += 2 }
lbb_3627:
    mov64 r3, 1                                     r3 = 1 as i32 as i64 as u64
    ja lbb_3642                                     if true { pc += 13 }
lbb_3629:
    ldxdw r3, [r10-0x18]                    
    lddw r4, 0x6c59a66b60be3054                     r4 load str located at 7807454409138253908
    jne r3, r4, lbb_3627                            if r3 != r4 { pc += -6 }
    ldxdw r3, [r10-0x10]                    
    lddw r4, 0x5a8befad1b309502                     r4 load str located at 6524572011940844802
    jne r3, r4, lbb_3627                            if r3 != r4 { pc += -10 }
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
    ldxdw r4, [r10-0x8]                     
    lddw r5, 0x7412f450410141fc                     r5 load str located at 8364016083505594876
    jne r4, r5, lbb_3627                            if r4 != r5 { pc += -15 }
lbb_3642:
    jeq r3, 0, lbb_3395                             if r3 == (0 as i32 as i64 as u64) { pc += -248 }
    ldxdw r3, [r10-0x20]                    
    lddw r4, 0x3013bba5557d0789                     r4 load str located at 3464318857156298633
    jeq r3, r4, lbb_3649                            if r3 == r4 { pc += 2 }
lbb_3647:
    mov64 r3, 1                                     r3 = 1 as i32 as i64 as u64
    ja lbb_3662                                     if true { pc += 13 }
lbb_3649:
    ldxdw r3, [r10-0x18]                    
    lddw r4, 0x77c05ef567b73e76                     r4 load str located at 8629001294141931126
    jne r3, r4, lbb_3647                            if r3 != r4 { pc += -6 }
    ldxdw r3, [r10-0x10]                    
    lddw r4, 0xd7e17d5f070d1ab4                     r4 load str located at -2890891638701483340
    jne r3, r4, lbb_3647                            if r3 != r4 { pc += -10 }
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
    ldxdw r4, [r10-0x8]                     
    lddw r5, 0x7154d5633ccaba3f                     r5 load str located at 8166386646527949375
    jne r4, r5, lbb_3647                            if r4 != r5 { pc += -15 }
lbb_3662:
    jeq r3, 0, lbb_3395                             if r3 == (0 as i32 as i64 as u64) { pc += -268 }
    ldxdw r3, [r10-0x20]                    
    lddw r4, 0x855b8b10591b97bf                     r4 load str located at -8837316941453748289
    jeq r3, r4, lbb_3669                            if r3 == r4 { pc += 2 }
lbb_3667:
    mov64 r3, 1                                     r3 = 1 as i32 as i64 as u64
    ja lbb_3682                                     if true { pc += 13 }
lbb_3669:
    ldxdw r3, [r10-0x18]                    
    lddw r4, 0x4e1be2f193b04fa0                     r4 load str located at 5628341686522367904
    jne r3, r4, lbb_3667                            if r3 != r4 { pc += -6 }
    ldxdw r3, [r10-0x10]                    
    lddw r4, 0x9dd87f4c8c4d43f                      r4 load str located at 710873801604518975
    jne r3, r4, lbb_3667                            if r3 != r4 { pc += -10 }
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
    ldxdw r4, [r10-0x8]                     
    lddw r5, 0xc3d80d9f765257b9                     r5 load str located at -4334699662808033351
    jne r4, r5, lbb_3667                            if r4 != r5 { pc += -15 }
lbb_3682:
    jeq r3, 0, lbb_3395                             if r3 == (0 as i32 as i64 as u64) { pc += -288 }
    ldxdw r3, [r10-0x20]                    
    lddw r4, 0x962803c21e102620                     r4 load str located at -7626841836689021408
    jeq r3, r4, lbb_3689                            if r3 == r4 { pc += 2 }
lbb_3687:
    mov64 r3, 1                                     r3 = 1 as i32 as i64 as u64
    ja lbb_3702                                     if true { pc += 13 }
lbb_3689:
    ldxdw r3, [r10-0x18]                    
    lddw r4, 0x5546c13abab324a                      r4 load str located at 384050699973636682
    jne r3, r4, lbb_3687                            if r3 != r4 { pc += -6 }
    ldxdw r3, [r10-0x10]                    
    lddw r4, 0x4cf6e48ee33a1fb9                     r4 load str located at 5545871293502070713
    jne r3, r4, lbb_3687                            if r3 != r4 { pc += -10 }
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
    ldxdw r4, [r10-0x8]                     
    lddw r5, 0xd23868b879e8bdb6                     r5 load str located at -3298771585520321098
    jne r4, r5, lbb_3687                            if r4 != r5 { pc += -15 }
lbb_3702:
    mov64 r4, 12                                    r4 = 12 as i32 as i64 as u64
    jgt r4, r1, lbb_3396                            if r4 > r1 { pc += -308 }
    jeq r3, 0, lbb_3706                             if r3 == (0 as i32 as i64 as u64) { pc += 1 }
    ja lbb_3396                                     if true { pc += -310 }
lbb_3706:
    ldxdw r1, [r2+0x4]                      
    ldxdw r2, [r10-0xe8]                    
    add64 r2, r1                                    r2 += r1   ///  r2 = r2.wrapping_add(r1)
    stxdw [r10-0xe8], r2                    
    ja lbb_3396                                     if true { pc += -315 }
lbb_3711:
    mov64 r2, r10                                   r2 = r10
    add64 r2, -280                                  r2 += -280   ///  r2 = r2.wrapping_add(-280 as i32 as i64 as u64)
    ldxdw r1, [r10-0x158]                   
    mov64 r3, 64                                    r3 = 64 as i32 as i64 as u64
    call function_48190                     
    ja lbb_3729                                     if true { pc += 12 }
lbb_3717:
    ldxdw r3, [r10-0x138]                   
    ldxdw r1, [r3+0x18]                     
    ldxdw r2, [r10-0x158]                   
    stxdw [r2+0x20], r1                     
    ldxdw r1, [r3+0x10]                     
    stxdw [r2+0x18], r1                     
    ldxdw r1, [r3+0x8]                      
    stxdw [r2+0x10], r1                     
    ldxdw r1, [r3+0x0]                      
    stxdw [r2+0x8], r1                      
    mov64 r1, 2                                     r1 = 2 as i32 as i64 as u64
    stxdw [r2+0x0], r1                      
lbb_3729:
    exit                                    

function_3730:
    mov64 r8, r2                                    r8 = r2
    mov64 r6, r1                                    r6 = r1
    ldxdw r3, [r8+0x0]                      
    ldxdw r7, [r8+0x8]                      
    mov64 r1, r10                                   r1 = r10
    add64 r1, -112                                  r1 += -112   ///  r1 = r1.wrapping_add(-112 as i32 as i64 as u64)
    mov64 r2, r7                                    r2 = r7
    call function_41577                     
    ldxdw r1, [r10-0x70]                    
    jne r1, 0, lbb_3748                             if r1 != (0 as i32 as i64 as u64) { pc += 8 }
    add64 r7, 1                                     r7 += 1   ///  r7 = r7.wrapping_add(1 as i32 as i64 as u64)
    stxdw [r8+0x8], r7                      
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    jgt r7, 1, lbb_3880                             if r7 > (1 as i32 as i64 as u64) { pc += 136 }
    stxdw [r6+0x8], r1                      
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    stxdw [r6+0x10], r1                     
    ja lbb_3880                                     if true { pc += 132 }
lbb_3748:
    stxdw [r10-0x88], r8                    
    stxdw [r10-0xa0], r7                    
    stxdw [r10-0x98], r6                    
    ldxdw r2, [r10-0x48]                    
    stxdw [r10-0xa8], r2                    
    ldxdw r2, [r10-0x58]                    
    stxdw [r10-0xb0], r2                    
    ldxdw r2, [r10-0x60]                    
    ldxdw r3, [r10-0x28]                    
    stxdw [r10-0x8], r3                     
    ldxdw r3, [r10-0x30]                    
    stxdw [r10-0x10], r3                    
    ldxdw r3, [r10-0x38]                    
    stxdw [r10-0x18], r3                    
    ldxdw r3, [r10-0x40]                    
    stxdw [r10-0x20], r3                    
    mov64 r3, 1                                     r3 = 1 as i32 as i64 as u64
    stxdw [r10-0x90], r2                    
    jeq r2, 0, lbb_3826                             if r2 == (0 as i32 as i64 as u64) { pc += 59 }
    lddw r3, 0x3c3c3c3c3c3c3c4                      r3 load str located at 271275648142787524
    ldxdw r2, [r10-0x90]                    
    jgt r3, r2, lbb_3773                            if r3 > r2 { pc += 2 }
lbb_3771:
    call function_43383                     
    syscall [invalid]                       
lbb_3773:
    mov64 r4, r2                                    r4 = r2
    mul64 r4, 34                                    r4 *= 34   ///  r4 = r4.wrapping_mul(34 as u64)
    mov64 r3, 1                                     r3 = 1 as i32 as i64 as u64
    stxdw [r10-0x80], r4                    
    jeq r4, 0, lbb_3800                             if r4 == (0 as i32 as i64 as u64) { pc += 22 }
    lddw r4, 0x300000000                            r4 load str located at 12884901888
    ldxdw r4, [r4+0x0]                      
    lddw r5, 0x300008000                            r5 load str located at 12884934656
    jeq r4, 0, lbb_3785                             if r4 == (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r5, r4                                    r5 = r4
lbb_3785:
    mov64 r4, r5                                    r4 = r5
    ldxdw r3, [r10-0x80]                    
    sub64 r4, r3                                    r4 -= r3   ///  r4 = r4.wrapping_sub(r3)
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
    mov64 r0, 1                                     r0 = 1 as i32 as i64 as u64
    jgt r4, r5, lbb_3792                            if r4 > r5 { pc += 1 }
    mov64 r0, 0                                     r0 = 0 as i32 as i64 as u64
lbb_3792:
    jne r0, 0, lbb_3794                             if r0 != (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r3, r4                                    r3 = r4
lbb_3794:
    lddw r4, 0x300000008                            r4 load str located at 12884901896
    jgt r4, r3, lbb_3886                            if r4 > r3 { pc += 89 }
    lddw r4, 0x300000000                            r4 load str located at 12884901888
    stxdw [r4+0x0], r3                      
lbb_3800:
    mov64 r4, 0                                     r4 = 0 as i32 as i64 as u64
    mov64 r5, r2                                    r5 = r2
lbb_3802:
    ldxdw r2, [r10-0x80]                    
    jeq r2, r4, lbb_3826                            if r2 == r4 { pc += 22 }
    mov64 r0, r3                                    r0 = r3
    add64 r0, r4                                    r0 += r4   ///  r0 = r0.wrapping_add(r4)
    ldxdw r2, [r1+0x0]                      
    stxdw [r10-0x78], r2                    
    ldxdw r7, [r1+0x8]                      
    ldxdw r6, [r1+0x10]                     
    ldxdw r8, [r1+0x18]                     
    mov64 r2, r3                                    r2 = r3
    ldxb r3, [r1+0x21]                      
    ldxb r9, [r1+0x20]                      
    stxb [r0+0x20], r9                      
    stxb [r0+0x21], r3                      
    mov64 r3, r2                                    r3 = r2
    stxdw [r0+0x18], r8                     
    stxdw [r0+0x10], r6                     
    stxdw [r0+0x8], r7                      
    ldxdw r2, [r10-0x78]                    
    stxdw [r0+0x0], r2                      
    add64 r4, 34                                    r4 += 34   ///  r4 = r4.wrapping_add(34 as i32 as i64 as u64)
    add64 r1, 34                                    r1 += 34   ///  r1 = r1.wrapping_add(34 as i32 as i64 as u64)
    add64 r5, -1                                    r5 += -1   ///  r5 = r5.wrapping_add(-1 as i32 as i64 as u64)
    jne r5, 0, lbb_3802                             if r5 != (0 as i32 as i64 as u64) { pc += -24 }
lbb_3826:
    stxdw [r10-0x78], r3                    
    ldxdw r6, [r10-0x98]                    
    ldxdw r7, [r10-0xa0]                    
    ldxdw r1, [r10-0x88]                    
    ldxdw r9, [r10-0xa8]                    
    mov64 r8, 1                                     r8 = 1 as i32 as i64 as u64
    jeq r9, 0, lbb_3856                             if r9 == (0 as i32 as i64 as u64) { pc += 23 }
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    jsgt r1, r9, lbb_3771                           if (r1 as i64) > (r9 as i64) { pc += -64 }
    lddw r1, 0x300000000                            r1 load str located at 12884901888
    ldxdw r1, [r1+0x0]                      
    lddw r3, 0x300008000                            r3 load str located at 12884934656
    jeq r1, 0, lbb_3842                             if r1 == (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r3, r1                                    r3 = r1
lbb_3842:
    mov64 r2, r3                                    r2 = r3
    sub64 r2, r9                                    r2 -= r9   ///  r2 = r2.wrapping_sub(r9)
    mov64 r8, 0                                     r8 = 0 as i32 as i64 as u64
    mov64 r4, 1                                     r4 = 1 as i32 as i64 as u64
    jgt r2, r3, lbb_3848                            if r2 > r3 { pc += 1 }
    mov64 r4, 0                                     r4 = 0 as i32 as i64 as u64
lbb_3848:
    jne r4, 0, lbb_3850                             if r4 != (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r8, r2                                    r8 = r2
lbb_3850:
    lddw r2, 0x300000008                            r2 load str located at 12884901896
    jgt r2, r8, lbb_3882                            if r2 > r8 { pc += 29 }
    lddw r2, 0x300000000                            r2 load str located at 12884901888
    stxdw [r2+0x0], r8                      
lbb_3856:
    mov64 r1, r8                                    r1 = r8
    ldxdw r2, [r10-0xb0]                    
    mov64 r3, r9                                    r3 = r9
    call function_48190                     
    ldxdw r1, [r10-0x20]                    
    stxdw [r6+0x38], r1                     
    ldxdw r1, [r10-0x18]                    
    stxdw [r6+0x40], r1                     
    ldxdw r1, [r10-0x10]                    
    stxdw [r6+0x48], r1                     
    ldxdw r1, [r10-0x8]                     
    stxdw [r6+0x50], r1                     
    add64 r7, 1                                     r7 += 1   ///  r7 = r7.wrapping_add(1 as i32 as i64 as u64)
    ldxdw r1, [r10-0x88]                    
    stxdw [r1+0x8], r7                      
    stxdw [r6+0x30], r9                     
    stxdw [r6+0x28], r9                     
    stxdw [r6+0x20], r8                     
    ldxdw r1, [r10-0x90]                    
    stxdw [r6+0x18], r1                     
    stxdw [r6+0x10], r1                     
    ldxdw r1, [r10-0x78]                    
    stxdw [r6+0x8], r1                      
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
lbb_3880:
    stxdw [r6+0x0], r1                      
    exit                                    
lbb_3882:
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    mov64 r2, r9                                    r2 = r9
    call function_43400                     
    syscall [invalid]                       
lbb_3886:
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    ldxdw r2, [r10-0x80]                    
    call function_43400                     
    syscall [invalid]                       

function_3890:
    mov64 r8, r3                                    r8 = r3
    mov64 r7, r2                                    r7 = r2
    mov64 r9, r1                                    r9 = r1
    stxdw [r10-0x8b0], r7                   
    jne r4, 11, lbb_3949                            if r4 != (11 as i32 as i64 as u64) { pc += 54 }
    ldxb r4, [r8+0x28]                      
    jeq r4, 0, lbb_3968                             if r4 == (0 as i32 as i64 as u64) { pc += 71 }
    ldxdw r6, [r8+0x30]                     
    ldxb r1, [r8+0x58]                      
    mov64 r2, 37                                    r2 = 37 as i32 as i64 as u64
    stxdw [r10-0x7b8], r2                   
    lddw r2, 0x10005ffef --> b"Market maker account must be a signerIncorrect sys"        r2 load str located at 4295360495
    stxdw [r10-0x7c0], r2                   
    jne r1, 0, lbb_3996                             if r1 != (0 as i32 as i64 as u64) { pc += 91 }
    lddw r1, 0x100064d10 --> b"\x00\x00\x00\x00p\xfe\x05\x00 \x00\x00\x00\x00\x00\x00\x00-\x00\x00\x00\x…        r1 load str located at 4295380240
    stxdw [r10-0x728], r1                   
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    stxdw [r10-0x470], r1                   
    lddw r1, 0x100064c98 --> b"\x00\x00\x00\x00p\xfa\x05\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00…        r1 load str located at 4295380120
    stxdw [r10-0x490], r1                   
    mov64 r1, 2                                     r1 = 2 as i32 as i64 as u64
    stxdw [r10-0x488], r1                   
    stxdw [r10-0x478], r1                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -1544                                 r1 += -1544   ///  r1 = r1.wrapping_add(-1544 as i32 as i64 as u64)
    stxdw [r10-0x480], r1                   
    lddw r1, 0x100000888 --> b"y\x11\x00\x00\x00\x00\x00\x00\x85\x10\x00\x00]\xab\x00\x00\x95\x00\x00\x0…        r1 load str located at 4294969480
    stxdw [r10-0x5f0], r1                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -1832                                 r1 += -1832   ///  r1 = r1.wrapping_add(-1832 as i32 as i64 as u64)
    stxdw [r10-0x5f8], r1                   
    lddw r1, 0x100000860 --> b"\xbf#\x00\x00\x00\x00\x00\x00y\x12\x08\x00\x00\x00\x00\x00y\x11\x00\x00\x…        r1 load str located at 4294969440
    stxdw [r10-0x600], r1                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -1984                                 r1 += -1984   ///  r1 = r1.wrapping_add(-1984 as i32 as i64 as u64)
    stxdw [r10-0x608], r1                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -1336                                 r1 += -1336   ///  r1 = r1.wrapping_add(-1336 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -1168                                 r2 += -1168   ///  r2 = r2.wrapping_add(-1168 as i32 as i64 as u64)
    call function_43415                     
    ldxdw r1, [r10-0x538]                   
    ldxdw r2, [r10-0x528]                   
    syscall [invalid]                       
    ldxdw r1, [r6+0x18]                     
    stxdw [r10-0x477], r1                   
    ldxdw r1, [r6+0x10]                     
    stxdw [r10-0x47f], r1                   
    ldxdw r1, [r6+0x8]                      
    stxdw [r10-0x487], r1                   
    ldxdw r1, [r6+0x0]                      
    stxdw [r10-0x48f], r1                   
    mov64 r1, 43                                    r1 = 43 as i32 as i64 as u64
    ja lbb_3990                                     if true { pc += 41 }
lbb_3949:
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    stxdw [r10-0x5e8], r1                   
    lddw r1, 0x100064f90 --> b"\x00\x00\x00\x00\xc2\x02\x06\x00\x1a\x00\x00\x00\x00\x00\x00\x00\x00\x00\…        r1 load str located at 4295380880
    stxdw [r10-0x608], r1                   
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    stxdw [r10-0x600], r1                   
    stxdw [r10-0x5f0], r1                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -1336                                 r1 += -1336   ///  r1 = r1.wrapping_add(-1336 as i32 as i64 as u64)
    stxdw [r10-0x5f8], r1                   
    lddw r1, 0x10005df58 --> b"\xbf#\x00\x00\x00\x00\x00\x00y\x11\x00\x00\x00\x00\x00\x00\xb7\x02\x00\x0…        r1 load str located at 4295352152
    stxdw [r10-0x530], r1                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -1984                                 r1 += -1984   ///  r1 = r1.wrapping_add(-1984 as i32 as i64 as u64)
    stxdw [r10-0x538], r1                   
    stxdw [r10-0x7c0], r4                   
    ja lbb_3984                                     if true { pc += 16 }
lbb_3968:
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    stxdw [r10-0x5e8], r1                   
    mov64 r1, 2                                     r1 = 2 as i32 as i64 as u64
    stxdw [r10-0x600], r1                   
    lddw r1, 0x100064cf0 --> b"\x00\x00\x00\x00\xd0\xff\x05\x00\x0e\x00\x00\x00\x00\x00\x00\x00\x00\x00\…        r1 load str located at 4295380208
    stxdw [r10-0x608], r1                   
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    stxdw [r10-0x5f0], r1                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -1336                                 r1 += -1336   ///  r1 = r1.wrapping_add(-1336 as i32 as i64 as u64)
    stxdw [r10-0x5f8], r1                   
    lddw r1, 0x1000008a0 --> b"y\x11\x00\x00\x00\x00\x00\x00\x85\x10\x00\x00*\x99\x00\x00\x95\x00\x00\x0…        r1 load str located at 4294969504
    stxdw [r10-0x530], r1                   
    stxdw [r10-0x538], r8                   
lbb_3984:
    mov64 r1, r10                                   r1 = r10
    add64 r1, -1160                                 r1 += -1160   ///  r1 = r1.wrapping_add(-1160 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -1544                                 r2 += -1544   ///  r2 = r2.wrapping_add(-1544 as i32 as i64 as u64)
    call function_43415                     
lbb_3989:
    mov64 r1, 29                                    r1 = 29 as i32 as i64 as u64
lbb_3990:
    stxb [r10-0x490], r1                    
lbb_3991:
    mov64 r2, r10                                   r2 = r10
    add64 r2, -1168                                 r2 += -1168   ///  r2 = r2.wrapping_add(-1168 as i32 as i64 as u64)
    mov64 r1, r9                                    r1 = r9
    call function_26067                     
    ja lbb_4783                                     if true { pc += 787 }
lbb_3996:
    ldxdw r0, [r8+0x1b0]                    
    ldxdw r1, [r0+0x0]                      
    jeq r1, 0, lbb_4001                             if r1 == (0 as i32 as i64 as u64) { pc += 2 }
lbb_3999:
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    ja lbb_4008                                     if true { pc += 7 }
lbb_4001:
    ldxdw r1, [r0+0x8]                      
    jne r1, 0, lbb_3999                             if r1 != (0 as i32 as i64 as u64) { pc += -4 }
    ldxdw r1, [r0+0x10]                     
    jne r1, 0, lbb_3999                             if r1 != (0 as i32 as i64 as u64) { pc += -6 }
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    ldxdw r2, [r0+0x18]                     
    jne r2, 0, lbb_3999                             if r2 != (0 as i32 as i64 as u64) { pc += -9 }
lbb_4008:
    jeq r1, 0, lbb_4044                             if r1 == (0 as i32 as i64 as u64) { pc += 35 }
    lddw r1, 0x300000000                            r1 load str located at 12884901888
    ldxdw r1, [r1+0x0]                      
    mov64 r3, r1                                    r3 = r1
    add64 r3, -41                                   r3 += -41   ///  r3 = r3.wrapping_add(-41 as i32 as i64 as u64)
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
    mov64 r4, 1                                     r4 = 1 as i32 as i64 as u64
    jgt r3, r1, lbb_4018                            if r3 > r1 { pc += 1 }
    mov64 r4, 0                                     r4 = 0 as i32 as i64 as u64
lbb_4018:
    jne r4, 0, lbb_4020                             if r4 != (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r2, r3                                    r2 = r3
lbb_4020:
    lddw r6, 0x300007fd7                            r6 load str located at 12884934615
    jeq r1, 0, lbb_4024                             if r1 == (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r6, r2                                    r6 = r2
lbb_4024:
    lddw r1, 0x300000007                            r1 load str located at 12884901895
    jgt r6, r1, lbb_4031                            if r6 > r1 { pc += 4 }
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    mov64 r2, 41                                    r2 = 41 as i32 as i64 as u64
    call function_43400                     
    syscall [invalid]                       
lbb_4031:
    lddw r1, 0x300000000                            r1 load str located at 12884901888
    stxdw [r1+0x0], r6                      
    mov64 r7, 41                                    r7 = 41 as i32 as i64 as u64
    mov64 r1, r6                                    r1 = r6
    lddw r2, 0x100060014 --> b"Incorrect system program account provided"        r2 load str located at 4295360532
    mov64 r3, 41                                    r3 = 41 as i32 as i64 as u64
lbb_4039:
    call function_48190                     
    stxdw [r10-0x478], r7                   
    stxdw [r10-0x480], r7                   
    stxdw [r10-0x488], r6                   
    ja lbb_3989                                     if true { pc += -55 }
lbb_4044:
    ldxdw r1, [r8+0x1e0]                    
    ldxdw r2, [r1+0x0]                      
    lddw r3, 0x515c2c1917d5a706                     r3 load str located at 5862609301215225606
    jeq r2, r3, lbb_4051                            if r2 == r3 { pc += 2 }
lbb_4049:
    mov64 r2, 1                                     r2 = 1 as i32 as i64 as u64
    ja lbb_4064                                     if true { pc += 13 }
lbb_4051:
    ldxdw r2, [r1+0x8]                      
    lddw r3, 0x7ff14a3d4cc98c21                     r3 load str located at 9219231539345853473
    jne r2, r3, lbb_4049                            if r2 != r3 { pc += -6 }
    ldxdw r2, [r1+0x10]                     
    lddw r3, 0x44fda19b08eeda58                     r3 load str located at 4971307250928769624
    jne r2, r3, lbb_4049                            if r2 != r3 { pc += -10 }
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
    ldxdw r1, [r1+0x18]                     
    lddw r3, 0x8ad9dbe3                             r3 load str located at 2329533411
    jne r1, r3, lbb_4049                            if r1 != r3 { pc += -15 }
lbb_4064:
    jeq r2, 0, lbb_4107                             if r2 == (0 as i32 as i64 as u64) { pc += 42 }
    lddw r1, 0x300000000                            r1 load str located at 12884901888
    ldxdw r2, [r1+0x0]                      
    mov64 r1, r2                                    r1 = r2
    add64 r1, -31                                   r1 += -31   ///  r1 = r1.wrapping_add(-31 as i32 as i64 as u64)
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
    mov64 r4, 1                                     r4 = 1 as i32 as i64 as u64
    jgt r1, r2, lbb_4074                            if r1 > r2 { pc += 1 }
    mov64 r4, 0                                     r4 = 0 as i32 as i64 as u64
lbb_4074:
    jne r4, 0, lbb_4076                             if r4 != (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r3, r1                                    r3 = r1
lbb_4076:
    lddw r1, 0x300007fe1                            r1 load str located at 12884934625
    jeq r2, 0, lbb_4080                             if r2 == (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r1, r3                                    r1 = r3
lbb_4080:
    lddw r2, 0x300000007                            r2 load str located at 12884901895
    jgt r1, r2, lbb_4087                            if r1 > r2 { pc += 4 }
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    mov64 r2, 31                                    r2 = 31 as i32 as i64 as u64
    call function_43400                     
    syscall [invalid]                       
lbb_4087:
    lddw r2, 0x300000000                            r2 load str located at 12884901888
    stxdw [r2+0x0], r1                      
    lddw r2, 0x64656469766f7270                     r2 load str located at 7234298780561928816
    stxdw [r1+0x17], r2                     
    lddw r2, 0x7020746e756f6363                     r2 load str located at 8079585749268128611
    stxdw [r1+0x10], r2                     
    lddw r2, 0x6120746e65722074                     r2 load str located at 6998721838430953588
    stxdw [r1+0x8], r2                      
    lddw r2, 0x636572726f636e49                     r2 load str located at 7162256618223267401
    stxdw [r1+0x0], r2                      
    mov64 r2, 31                                    r2 = 31 as i32 as i64 as u64
    stxdw [r10-0x478], r2                   
    stxdw [r10-0x480], r2                   
    stxdw [r10-0x488], r1                   
    ja lbb_3989                                     if true { pc += -118 }
lbb_4107:
    ldxdw r1, [r8+0x180]                    
    ldxdw r2, [r1+0x0]                      
    lddw r3, 0x93a165d7e1f6dd06                     r3 load str located at -7808848301000303354
    jeq r2, r3, lbb_4114                            if r2 == r3 { pc += 2 }
lbb_4112:
    mov64 r2, 1                                     r2 = 1 as i32 as i64 as u64
    ja lbb_4127                                     if true { pc += 13 }
lbb_4114:
    ldxdw r2, [r1+0x8]                      
    lddw r3, 0xac79ebce46e1cbd9                     r3 load str located at -6018520155818964007
    jne r2, r3, lbb_4112                            if r2 != r3 { pc += -6 }
    ldxdw r2, [r1+0x10]                     
    lddw r3, 0x91375b5fed85b41c                     r3 load str located at -7982811346925931492
    jne r2, r3, lbb_4112                            if r2 != r3 { pc += -10 }
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
    ldxdw r1, [r1+0x18]                     
    lddw r3, 0xa900ff7e85f58c3a                     r3 load str located at -6268729762421306310
    jne r1, r3, lbb_4112                            if r1 != r3 { pc += -15 }
lbb_4127:
    jeq r2, 0, lbb_4150                             if r2 == (0 as i32 as i64 as u64) { pc += 22 }
    lddw r1, 0x300000000                            r1 load str located at 12884901888
    ldxdw r1, [r1+0x0]                      
    mov64 r3, r1                                    r3 = r1
    add64 r3, -40                                   r3 += -40   ///  r3 = r3.wrapping_add(-40 as i32 as i64 as u64)
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
    mov64 r4, 1                                     r4 = 1 as i32 as i64 as u64
    jgt r3, r1, lbb_4137                            if r3 > r1 { pc += 1 }
    mov64 r4, 0                                     r4 = 0 as i32 as i64 as u64
lbb_4137:
    jne r4, 0, lbb_4139                             if r4 != (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r2, r3                                    r2 = r3
lbb_4139:
    lddw r6, 0x300007fd8                            r6 load str located at 12884934616
    jeq r1, 0, lbb_4143                             if r1 == (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r6, r2                                    r6 = r2
lbb_4143:
    lddw r1, 0x300000007                            r1 load str located at 12884901895
    jgt r6, r1, lbb_4418                            if r6 > r1 { pc += 272 }
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    mov64 r2, 40                                    r2 = 40 as i32 as i64 as u64
    call function_43400                     
    syscall [invalid]                       
lbb_4150:
    stxdw [r10-0x8c8], r6                   
    stxdw [r10-0x8e0], r0                   
    stxdw [r10-0x8d8], r4                   
    mov64 r3, r8                                    r3 = r8
    add64 r3, 96                                    r3 += 96   ///  r3 = r3.wrapping_add(96 as i32 as i64 as u64)
    mov64 r1, r10                                   r1 = r10
    add64 r1, -1544                                 r1 += -1544   ///  r1 = r1.wrapping_add(-1544 as i32 as i64 as u64)
    mov64 r2, r7                                    r2 = r7
    call function_16885                     
    ldxb r6, [r10-0x608]                    
    jne r6, 56, lbb_4427                            if r6 != (56 as i32 as i64 as u64) { pc += 266 }
    stxdw [r10-0x8b8], r9                   
    ldxdw r1, [r10-0x5f8]                   
    stxdw [r10-0x8a0], r1                   
    ldxdw r9, [r10-0x600]                   
    stxdw [r10-0x8a8], r9                   
    ldxdw r6, [r10-0x5f0]                   
    stxdw [r10-0x898], r6                   
    stxdw [r10-0x8c0], r8                   
    add64 r8, 144                                   r8 += 144   ///  r8 = r8.wrapping_add(144 as i32 as i64 as u64)
    mov64 r1, r10                                   r1 = r10
    add64 r1, -1544                                 r1 += -1544   ///  r1 = r1.wrapping_add(-1544 as i32 as i64 as u64)
    stxdw [r10-0x8d0], r7                   
    mov64 r2, r7                                    r2 = r7
    mov64 r3, r8                                    r3 = r8
    mov64 r4, r9                                    r4 = r9
    mov64 r5, r6                                    r5 = r6
    call function_17301                     
    ldxb r8, [r10-0x608]                    
    jeq r8, 56, lbb_4181                            if r8 == (56 as i32 as i64 as u64) { pc += 1 }
    ja lbb_4451                                     if true { pc += 270 }
lbb_4181:
    ldxdw r1, [r10-0x600]                   
    stxdw [r10-0x890], r1                   
    ldxdw r1, [r10-0x5f8]                   
    stxdw [r10-0x888], r1                   
    ldxdw r1, [r10-0x5f0]                   
    stxdw [r10-0x880], r1                   
    ldxdw r3, [r10-0x8c8]                   
    ldxdw r1, [r3+0x0]                      
    ldxdw r2, [r9+0x28]                     
    jeq r2, r1, lbb_4193                            if r2 == r1 { pc += 2 }
lbb_4191:
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    ja lbb_4203                                     if true { pc += 10 }
lbb_4193:
    ldxdw r1, [r3+0x8]                      
    ldxdw r2, [r9+0x30]                     
    jne r2, r1, lbb_4191                            if r2 != r1 { pc += -5 }
    ldxdw r1, [r3+0x10]                     
    ldxdw r2, [r9+0x38]                     
    jne r2, r1, lbb_4191                            if r2 != r1 { pc += -8 }
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    ldxdw r2, [r3+0x18]                     
    ldxdw r3, [r9+0x40]                     
    jne r3, r2, lbb_4191                            if r3 != r2 { pc += -12 }
lbb_4203:
    ldxdw r7, [r10-0x8b8]                   
    ldxdw r3, [r10-0x8c0]                   
    jeq r1, 0, lbb_4238                             if r1 == (0 as i32 as i64 as u64) { pc += 32 }
    add64 r3, 48                                    r3 += 48   ///  r3 = r3.wrapping_add(48 as i32 as i64 as u64)
    mov64 r1, r10                                   r1 = r10
    add64 r1, -2200                                 r1 += -2200   ///  r1 = r1.wrapping_add(-2200 as i32 as i64 as u64)
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
    stxdw [r10-0x5e8], r2                   
    lddw r2, 0x100064d28 --> b"\x00\x00\x00\x00e\x00\x06\x00\x0b\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00…        r2 load str located at 4295380264
    stxdw [r10-0x608], r2                   
    mov64 r2, 2                                     r2 = 2 as i32 as i64 as u64
    stxdw [r10-0x600], r2                   
    stxdw [r10-0x5f0], r2                   
    mov64 r2, r10                                   r2 = r10
    add64 r2, -1336                                 r2 += -1336   ///  r2 = r2.wrapping_add(-1336 as i32 as i64 as u64)
    stxdw [r10-0x5f8], r2                   
    stxdw [r10-0x528], r1                   
    lddw r1, 0x1000008a0 --> b"y\x11\x00\x00\x00\x00\x00\x00\x85\x10\x00\x00*\x99\x00\x00\x95\x00\x00\x0…        r1 load str located at 4294969504
    stxdw [r10-0x520], r1                   
    stxdw [r10-0x530], r1                   
    stxdw [r10-0x538], r3                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -1160                                 r1 += -1160   ///  r1 = r1.wrapping_add(-1160 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -1544                                 r2 += -1544   ///  r2 = r2.wrapping_add(-1544 as i32 as i64 as u64)
    call function_43415                     
    mov64 r1, 29                                    r1 = 29 as i32 as i64 as u64
    stxb [r10-0x490], r1                    
    mov64 r2, r10                                   r2 = r10
    add64 r2, -1168                                 r2 += -1168   ///  r2 = r2.wrapping_add(-1168 as i32 as i64 as u64)
    mov64 r1, r7                                    r1 = r7
    call function_26067                     
    ja lbb_4775                                     if true { pc += 537 }
lbb_4238:
    ldxdw r8, [r3+0xc0]                     
    stxdw [r10-0x1000], r6                  
    stxdw [r10-0xff8], r8                   
    add64 r3, 288                                   r3 += 288   ///  r3 = r3.wrapping_add(288 as i32 as i64 as u64)
    mov64 r1, r10                                   r1 = r10
    add64 r1, -1544                                 r1 += -1544   ///  r1 = r1.wrapping_add(-1544 as i32 as i64 as u64)
    mov64 r5, r10                                   r5 = r10
    mov64 r4, r9                                    r4 = r9
    call function_17733                     
    ldxb r6, [r10-0x608]                    
    jeq r6, 56, lbb_4250                            if r6 == (56 as i32 as i64 as u64) { pc += 1 }
    ja lbb_4479                                     if true { pc += 229 }
lbb_4250:
    ldxdw r7, [r10-0x5f0]                   
    ldxdw r9, [r10-0x5f8]                   
    ldxdw r1, [r10-0x600]                   
    stxdw [r10-0x8e8], r1                   
    ldxdw r2, [r10-0x880]                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -1544                                 r1 += -1544   ///  r1 = r1.wrapping_add(-1544 as i32 as i64 as u64)
    stxdw [r10-0x8c8], r8                   
    mov64 r3, r8                                    r3 = r8
    ldxdw r8, [r10-0x8d0]                   
    mov64 r4, r8                                    r4 = r8
    call function_22197                     
    ldxb r6, [r10-0x608]                    
    jeq r6, 56, lbb_4265                            if r6 == (56 as i32 as i64 as u64) { pc += 1 }
    ja lbb_4392                                     if true { pc += 127 }
lbb_4265:
    ldxdw r1, [r10-0x5ef]                   
    stxdw [r10-0x520], r1                   
    ldxdw r2, [r10-0x5f7]                   
    stxdw [r10-0x528], r2                   
    ldxdw r3, [r10-0x5ff]                   
    stxdw [r10-0x530], r3                   
    ldxdw r4, [r10-0x607]                   
    stxdw [r10-0x538], r4                   
    ldxb r5, [r10-0x5e7]                    
    stxdw [r10-0x860], r1                   
    stxdw [r10-0x868], r2                   
    stxdw [r10-0x870], r3                   
    stxdw [r10-0x878], r4                   
    stxb [r10-0x851], r5                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -1544                                 r1 += -1544   ///  r1 = r1.wrapping_add(-1544 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -2168                                 r2 += -2168   ///  r2 = r2.wrapping_add(-2168 as i32 as i64 as u64)
    mov64 r3, r8                                    r3 = r8
    call function_21963                     
    ldxb r6, [r10-0x608]                    
    jeq r6, 56, lbb_4288                            if r6 == (56 as i32 as i64 as u64) { pc += 1 }
    ja lbb_4392                                     if true { pc += 104 }
lbb_4288:
    stxdw [r10-0x8f0], r7                   
    ldxdw r1, [r10-0x5ef]                   
    stxdw [r10-0x520], r1                   
    ldxdw r2, [r10-0x5f7]                   
    stxdw [r10-0x528], r2                   
    ldxdw r3, [r10-0x5ff]                   
    stxdw [r10-0x530], r3                   
    ldxdw r4, [r10-0x607]                   
    stxdw [r10-0x538], r4                   
    ldxb r5, [r10-0x5e7]                    
    stxdw [r10-0x838], r1                   
    stxdw [r10-0x840], r2                   
    stxdw [r10-0x848], r3                   
    stxdw [r10-0x850], r4                   
    stxb [r10-0x829], r5                    
    ldxdw r4, [r10-0x8c0]                   
    ldxdw r5, [r4+0x150]                    
    ldxdw r1, [r5+0x0]                      
    ldxdw r2, [r10-0x878]                   
    jeq r1, r2, lbb_4310                            if r1 == r2 { pc += 2 }
lbb_4308:
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    ja lbb_4320                                     if true { pc += 10 }
lbb_4310:
    ldxdw r1, [r5+0x8]                      
    ldxdw r2, [r10-0x870]                   
    jne r1, r2, lbb_4308                            if r1 != r2 { pc += -5 }
    ldxdw r1, [r5+0x10]                     
    ldxdw r2, [r10-0x868]                   
    jne r1, r2, lbb_4308                            if r1 != r2 { pc += -8 }
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    ldxdw r2, [r5+0x18]                     
    ldxdw r3, [r10-0x860]                   
    jne r2, r3, lbb_4308                            if r2 != r3 { pc += -12 }
lbb_4320:
    ldxdw r7, [r10-0x880]                   
    mov64 r2, 36                                    r2 = 36 as i32 as i64 as u64
    stxdw [r10-0x7b8], r2                   
    lddw r2, 0x100060082 --> b"Coin PDA address derivation mismatchToken account "        r2 load str located at 4295360642
    stxdw [r10-0x7c0], r2                   
    jeq r1, 0, lbb_4623                             if r1 == (0 as i32 as i64 as u64) { pc += 296 }
    mov64 r8, r5                                    r8 = r5
    lddw r1, 0x100064d48 --> b"\x00\x00\x00\x00p\xfe\x05\x00 \x00\x00\x00\x00\x00\x00\x00^\x00\x00\x00\x…        r1 load str located at 4295380296
    stxdw [r10-0x728], r1                   
    lddw r1, 0x100064c98 --> b"\x00\x00\x00\x00p\xfa\x05\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00…        r1 load str located at 4295380120
    stxdw [r10-0x490], r1                   
    mov64 r1, 2                                     r1 = 2 as i32 as i64 as u64
    stxdw [r10-0x488], r1                   
    stxdw [r10-0x478], r1                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -1544                                 r1 += -1544   ///  r1 = r1.wrapping_add(-1544 as i32 as i64 as u64)
    stxdw [r10-0x480], r1                   
    lddw r1, 0x100000888 --> b"y\x11\x00\x00\x00\x00\x00\x00\x85\x10\x00\x00]\xab\x00\x00\x95\x00\x00\x0…        r1 load str located at 4294969480
    stxdw [r10-0x5f0], r1                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -1832                                 r1 += -1832   ///  r1 = r1.wrapping_add(-1832 as i32 as i64 as u64)
    stxdw [r10-0x5f8], r1                   
    lddw r1, 0x100000860 --> b"\xbf#\x00\x00\x00\x00\x00\x00y\x12\x08\x00\x00\x00\x00\x00y\x11\x00\x00\x…        r1 load str located at 4294969440
    stxdw [r10-0x600], r1                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -1984                                 r1 += -1984   ///  r1 = r1.wrapping_add(-1984 as i32 as i64 as u64)
    stxdw [r10-0x608], r1                   
    mov64 r6, 0                                     r6 = 0 as i32 as i64 as u64
    stxdw [r10-0x470], r6                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -1336                                 r1 += -1336   ///  r1 = r1.wrapping_add(-1336 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -1168                                 r2 += -1168   ///  r2 = r2.wrapping_add(-1168 as i32 as i64 as u64)
    call function_43415                     
    ldxdw r1, [r10-0x538]                   
    ldxdw r2, [r10-0x528]                   
    syscall [invalid]                       
    ldxdw r2, [r10-0x8c8]                   
    ldxdw r1, [r2+0x18]                     
    stxdw [r10-0x478], r1                   
    ldxdw r1, [r2+0x10]                     
    stxdw [r10-0x480], r1                   
    ldxdw r1, [r2+0x8]                      
    stxdw [r10-0x488], r1                   
    ldxdw r1, [r2+0x0]                      
    stxdw [r10-0x490], r1                   
    lddw r1, 0x300000000                            r1 load str located at 12884901888
    ldxdw r2, [r1+0x0]                      
    mov64 r3, 1                                     r3 = 1 as i32 as i64 as u64
    mov64 r1, r2                                    r1 = r2
    add64 r1, -32                                   r1 += -32   ///  r1 = r1.wrapping_add(-32 as i32 as i64 as u64)
    jgt r1, r2, lbb_4379                            if r1 > r2 { pc += 1 }
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
lbb_4379:
    jne r3, 0, lbb_4381                             if r3 != (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r6, r1                                    r6 = r1
lbb_4381:
    lddw r1, 0x300007fe0                            r1 load str located at 12884934624
    jeq r2, 0, lbb_4385                             if r2 == (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r1, r6                                    r1 = r6
lbb_4385:
    lddw r2, 0x300000007                            r2 load str located at 12884901895
    jgt r1, r2, lbb_4501                            if r1 > r2 { pc += 113 }
lbb_4388:
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    mov64 r2, 32                                    r2 = 32 as i32 as i64 as u64
    call function_43400                     
    syscall [invalid]                       
lbb_4392:
    ldxdw r1, [r10-0x5ef]                   
    stxdw [r10-0x520], r1                   
    ldxdw r1, [r10-0x5f7]                   
    stxdw [r10-0x528], r1                   
    ldxdw r1, [r10-0x5ff]                   
    stxdw [r10-0x530], r1                   
    ldxdw r1, [r10-0x607]                   
    stxdw [r10-0x538], r1                   
    ldxb r7, [r10-0x5e7]                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -1134                                 r1 += -1134   ///  r1 = r1.wrapping_add(-1134 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -1510                                 r2 += -1510   ///  r2 = r2.wrapping_add(-1510 as i32 as i64 as u64)
    mov64 r3, 38                                    r3 = 38 as i32 as i64 as u64
    call function_48190                     
    stxb [r10-0x46f], r7                    
    stxb [r10-0x490], r6                    
    ldxdw r1, [r10-0x538]                   
    stxdw [r10-0x48f], r1                   
    ldxdw r1, [r10-0x530]                   
    stxdw [r10-0x487], r1                   
    ldxdw r1, [r10-0x528]                   
    stxdw [r10-0x47f], r1                   
    ldxdw r1, [r10-0x520]                   
    stxdw [r10-0x477], r1                   
    ja lbb_4618                                     if true { pc += 200 }
lbb_4418:
    lddw r1, 0x300000000                            r1 load str located at 12884901888
    stxdw [r1+0x0], r6                      
    mov64 r7, 40                                    r7 = 40 as i32 as i64 as u64
    mov64 r1, r6                                    r1 = r6
    lddw r2, 0x10006003d --> b"Incorrect token program account provided"        r2 load str located at 4295360573
    mov64 r3, 40                                    r3 = 40 as i32 as i64 as u64
    ja lbb_4039                                     if true { pc += -388 }
lbb_4427:
    ldxdw r1, [r10-0x5f0]                   
    stxdw [r10-0x521], r1                   
    ldxdw r1, [r10-0x5f7]                   
    stxdw [r10-0x528], r1                   
    ldxdw r1, [r10-0x5ff]                   
    stxdw [r10-0x530], r1                   
    ldxdw r1, [r10-0x607]                   
    stxdw [r10-0x538], r1                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -1136                                 r1 += -1136   ///  r1 = r1.wrapping_add(-1136 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -1512                                 r2 += -1512   ///  r2 = r2.wrapping_add(-1512 as i32 as i64 as u64)
    mov64 r3, 40                                    r3 = 40 as i32 as i64 as u64
    call function_48190                     
    stxb [r10-0x490], r6                    
    ldxdw r1, [r10-0x538]                   
    stxdw [r10-0x48f], r1                   
    ldxdw r1, [r10-0x530]                   
    stxdw [r10-0x487], r1                   
    ldxdw r1, [r10-0x528]                   
    stxdw [r10-0x47f], r1                   
    ldxdw r1, [r10-0x521]                   
    stxdw [r10-0x478], r1                   
    ja lbb_3991                                     if true { pc += -460 }
lbb_4451:
    ldxdw r1, [r10-0x5f0]                   
    stxdw [r10-0x521], r1                   
    ldxdw r1, [r10-0x5f7]                   
    stxdw [r10-0x528], r1                   
    ldxdw r1, [r10-0x5ff]                   
    stxdw [r10-0x530], r1                   
    ldxdw r1, [r10-0x607]                   
    stxdw [r10-0x538], r1                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -1136                                 r1 += -1136   ///  r1 = r1.wrapping_add(-1136 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -1512                                 r2 += -1512   ///  r2 = r2.wrapping_add(-1512 as i32 as i64 as u64)
    mov64 r3, 40                                    r3 = 40 as i32 as i64 as u64
    call function_48190                     
    stxb [r10-0x490], r8                    
    ldxdw r1, [r10-0x538]                   
    stxdw [r10-0x48f], r1                   
    ldxdw r1, [r10-0x530]                   
    stxdw [r10-0x487], r1                   
    ldxdw r1, [r10-0x528]                   
    stxdw [r10-0x47f], r1                   
    ldxdw r1, [r10-0x521]                   
    stxdw [r10-0x478], r1                   
    mov64 r2, r10                                   r2 = r10
    add64 r2, -1168                                 r2 += -1168   ///  r2 = r2.wrapping_add(-1168 as i32 as i64 as u64)
    ldxdw r1, [r10-0x8b8]                   
    call function_26067                     
    ja lbb_4779                                     if true { pc += 300 }
lbb_4479:
    ldxw r1, [r10-0x604]                    
    stxw [r10-0x48c], r1                    
    ldxw r1, [r10-0x607]                    
    stxw [r10-0x48f], r1                    
    ldxdw r7, [r10-0x600]                   
    ldxdw r8, [r10-0x5f8]                   
    ldxdw r9, [r10-0x5f0]                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -1136                                 r1 += -1136   ///  r1 = r1.wrapping_add(-1136 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -1512                                 r2 += -1512   ///  r2 = r2.wrapping_add(-1512 as i32 as i64 as u64)
    mov64 r3, 40                                    r3 = 40 as i32 as i64 as u64
    call function_48190                     
    stxdw [r10-0x478], r9                   
    stxdw [r10-0x480], r8                   
    stxdw [r10-0x488], r7                   
    stxb [r10-0x490], r6                    
    mov64 r2, r10                                   r2 = r10
    add64 r2, -1168                                 r2 += -1168   ///  r2 = r2.wrapping_add(-1168 as i32 as i64 as u64)
    ldxdw r1, [r10-0x8b8]                   
    call function_26067                     
    ja lbb_4775                                     if true { pc += 274 }
lbb_4501:
    lddw r2, 0x300000000                            r2 load str located at 12884901888
    stxdw [r2+0x0], r1                      
    ldxdw r3, [r10-0x478]                   
    stxdw [r1+0x18], r3                     
    ldxdw r3, [r10-0x480]                   
    stxdw [r1+0x10], r3                     
    ldxdw r3, [r10-0x488]                   
    stxdw [r1+0x8], r3                      
    ldxdw r3, [r10-0x490]                   
    stxdw [r1+0x0], r3                      
    ldxdw r3, [r7+0x18]                     
    stxdw [r10-0x478], r3                   
    ldxdw r3, [r7+0x10]                     
    stxdw [r10-0x480], r3                   
    ldxdw r3, [r7+0x8]                      
    stxdw [r10-0x488], r3                   
    ldxdw r3, [r7+0x0]                      
    stxdw [r10-0x490], r3                   
    ldxdw r3, [r2+0x0]                      
    mov64 r4, 0                                     r4 = 0 as i32 as i64 as u64
    mov64 r5, 1                                     r5 = 1 as i32 as i64 as u64
    mov64 r2, r3                                    r2 = r3
    add64 r2, -32                                   r2 += -32   ///  r2 = r2.wrapping_add(-32 as i32 as i64 as u64)
    jgt r2, r3, lbb_4527                            if r2 > r3 { pc += 1 }
    mov64 r5, 0                                     r5 = 0 as i32 as i64 as u64
lbb_4527:
    jne r5, 0, lbb_4529                             if r5 != (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r4, r2                                    r4 = r2
lbb_4529:
    lddw r2, 0x300007fe0                            r2 load str located at 12884934624
    jeq r3, 0, lbb_4533                             if r3 == (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r2, r4                                    r2 = r4
lbb_4533:
    lddw r3, 0x300000007                            r3 load str located at 12884901895
    jgt r2, r3, lbb_4537                            if r2 > r3 { pc += 1 }
    ja lbb_4388                                     if true { pc += -149 }
lbb_4537:
    lddw r3, 0x300000000                            r3 load str located at 12884901888
    stxdw [r3+0x0], r2                      
    ldxdw r4, [r10-0x478]                   
    stxdw [r2+0x18], r4                     
    ldxdw r4, [r10-0x480]                   
    stxdw [r2+0x10], r4                     
    ldxdw r4, [r10-0x488]                   
    stxdw [r2+0x8], r4                      
    ldxdw r4, [r10-0x490]                   
    stxdw [r2+0x0], r4                      
    ldxdw r4, [r8+0x18]                     
    stxdw [r10-0x478], r4                   
    ldxdw r4, [r8+0x10]                     
    stxdw [r10-0x480], r4                   
    ldxdw r4, [r8+0x8]                      
    stxdw [r10-0x488], r4                   
    ldxdw r4, [r8+0x0]                      
    stxdw [r10-0x490], r4                   
    ldxdw r4, [r3+0x0]                      
    mov64 r5, 0                                     r5 = 0 as i32 as i64 as u64
    mov64 r0, 1                                     r0 = 1 as i32 as i64 as u64
    mov64 r3, r4                                    r3 = r4
    add64 r3, -32                                   r3 += -32   ///  r3 = r3.wrapping_add(-32 as i32 as i64 as u64)
    jgt r3, r4, lbb_4563                            if r3 > r4 { pc += 1 }
    mov64 r0, 0                                     r0 = 0 as i32 as i64 as u64
lbb_4563:
    jne r0, 0, lbb_4565                             if r0 != (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r5, r3                                    r5 = r3
lbb_4565:
    lddw r3, 0x300007fe0                            r3 load str located at 12884934624
    jeq r4, 0, lbb_4569                             if r4 == (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r3, r5                                    r3 = r5
lbb_4569:
    lddw r4, 0x300000007                            r4 load str located at 12884901895
    jgt r3, r4, lbb_4573                            if r3 > r4 { pc += 1 }
    ja lbb_4388                                     if true { pc += -185 }
lbb_4573:
    lddw r4, 0x300000000                            r4 load str located at 12884901888
    stxdw [r4+0x0], r3                      
    ldxdw r5, [r10-0x478]                   
    stxdw [r3+0x18], r5                     
    ldxdw r5, [r10-0x480]                   
    stxdw [r3+0x10], r5                     
    ldxdw r5, [r10-0x488]                   
    stxdw [r3+0x8], r5                      
    ldxdw r5, [r10-0x490]                   
    stxdw [r3+0x0], r5                      
    ldxdw r5, [r4+0x0]                      
    mov64 r4, r5                                    r4 = r5
    add64 r4, -32                                   r4 += -32   ///  r4 = r4.wrapping_add(-32 as i32 as i64 as u64)
    mov64 r0, 0                                     r0 = 0 as i32 as i64 as u64
    mov64 r6, 1                                     r6 = 1 as i32 as i64 as u64
    jgt r4, r5, lbb_4591                            if r4 > r5 { pc += 1 }
    mov64 r6, 0                                     r6 = 0 as i32 as i64 as u64
lbb_4591:
    jne r6, 0, lbb_4593                             if r6 != (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r0, r4                                    r0 = r4
lbb_4593:
    lddw r4, 0x300007fe0                            r4 load str located at 12884934624
    jeq r5, 0, lbb_4597                             if r5 == (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r4, r0                                    r4 = r0
lbb_4597:
    lddw r5, 0x300000007                            r5 load str located at 12884901895
    jgt r4, r5, lbb_4601                            if r4 > r5 { pc += 1 }
    ja lbb_4388                                     if true { pc += -213 }
lbb_4601:
    lddw r5, 0x300000000                            r5 load str located at 12884901888
    stxdw [r5+0x0], r4                      
    ldxdw r5, [r10-0x878]                   
    ldxdw r0, [r10-0x870]                   
    ldxdw r6, [r10-0x868]                   
    ldxdw r7, [r10-0x860]                   
    stxdw [r4+0x18], r7                     
    stxdw [r4+0x10], r6                     
    stxdw [r4+0x8], r0                      
    stxdw [r4+0x0], r5                      
    stxdw [r10-0x470], r4                   
    stxdw [r10-0x478], r3                   
    stxdw [r10-0x480], r1                   
    stxdw [r10-0x488], r2                   
    mov64 r1, 9                                     r1 = 9 as i32 as i64 as u64
lbb_4617:
    stxb [r10-0x490], r1                    
lbb_4618:
    mov64 r2, r10                                   r2 = r10
    add64 r2, -1168                                 r2 += -1168   ///  r2 = r2.wrapping_add(-1168 as i32 as i64 as u64)
    ldxdw r1, [r10-0x8b8]                   
    call function_26067                     
    ja lbb_4772                                     if true { pc += 149 }
lbb_4623:
    ldxdw r8, [r4+0xf0]                     
    ldxdw r1, [r8+0x0]                      
    ldxdw r2, [r10-0x850]                   
    jeq r1, r2, lbb_4629                            if r1 == r2 { pc += 2 }
lbb_4627:
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    ja lbb_4639                                     if true { pc += 10 }
lbb_4629:
    ldxdw r1, [r8+0x8]                      
    ldxdw r2, [r10-0x848]                   
    jne r1, r2, lbb_4627                            if r1 != r2 { pc += -5 }
    ldxdw r1, [r8+0x10]                     
    ldxdw r2, [r10-0x840]                   
    jne r1, r2, lbb_4627                            if r1 != r2 { pc += -8 }
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    ldxdw r2, [r8+0x18]                     
    ldxdw r3, [r10-0x838]                   
    jne r2, r3, lbb_4627                            if r2 != r3 { pc += -12 }
lbb_4639:
    mov64 r2, 41                                    r2 = 41 as i32 as i64 as u64
    stxdw [r10-0x7b8], r2                   
    lddw r2, 0x1000600a6 --> b"Token account address derivation mismatchToken acc"        r2 load str located at 4295360678
    stxdw [r10-0x7c0], r2                   
    jeq r1, 0, lbb_4697                             if r1 == (0 as i32 as i64 as u64) { pc += 52 }
    lddw r1, 0x100064d60 --> b"\x00\x00\x00\x00p\xfe\x05\x00 \x00\x00\x00\x00\x00\x00\x00i\x00\x00\x00\x…        r1 load str located at 4295380320
    stxdw [r10-0x728], r1                   
    lddw r1, 0x100064c98 --> b"\x00\x00\x00\x00p\xfa\x05\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00…        r1 load str located at 4295380120
    stxdw [r10-0x490], r1                   
    mov64 r1, 2                                     r1 = 2 as i32 as i64 as u64
    stxdw [r10-0x488], r1                   
    stxdw [r10-0x478], r1                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -1544                                 r1 += -1544   ///  r1 = r1.wrapping_add(-1544 as i32 as i64 as u64)
    stxdw [r10-0x480], r1                   
    lddw r1, 0x100000888 --> b"y\x11\x00\x00\x00\x00\x00\x00\x85\x10\x00\x00]\xab\x00\x00\x95\x00\x00\x0…        r1 load str located at 4294969480
    stxdw [r10-0x5f0], r1                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -1832                                 r1 += -1832   ///  r1 = r1.wrapping_add(-1832 as i32 as i64 as u64)
    stxdw [r10-0x5f8], r1                   
    lddw r1, 0x100000860 --> b"\xbf#\x00\x00\x00\x00\x00\x00y\x12\x08\x00\x00\x00\x00\x00y\x11\x00\x00\x…        r1 load str located at 4294969440
    stxdw [r10-0x600], r1                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -1984                                 r1 += -1984   ///  r1 = r1.wrapping_add(-1984 as i32 as i64 as u64)
    stxdw [r10-0x608], r1                   
    mov64 r6, 0                                     r6 = 0 as i32 as i64 as u64
    stxdw [r10-0x470], r6                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -1336                                 r1 += -1336   ///  r1 = r1.wrapping_add(-1336 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -1168                                 r2 += -1168   ///  r2 = r2.wrapping_add(-1168 as i32 as i64 as u64)
    call function_43415                     
    ldxdw r1, [r10-0x538]                   
    ldxdw r2, [r10-0x528]                   
    syscall [invalid]                       
    lddw r1, 0x300000000                            r1 load str located at 12884901888
    ldxdw r2, [r1+0x0]                      
    mov64 r3, 1                                     r3 = 1 as i32 as i64 as u64
    mov64 r1, r2                                    r1 = r2
    add64 r1, -32                                   r1 += -32   ///  r1 = r1.wrapping_add(-32 as i32 as i64 as u64)
    jgt r1, r2, lbb_4687                            if r1 > r2 { pc += 1 }
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
lbb_4687:
    jne r3, 0, lbb_4689                             if r3 != (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r6, r1                                    r6 = r1
lbb_4689:
    lddw r0, 0x300007fe0                            r0 load str located at 12884934624
    jeq r2, 0, lbb_4693                             if r2 == (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r0, r6                                    r0 = r6
lbb_4693:
    lddw r2, 0x300000007                            r2 load str located at 12884901895
    jgt r0, r2, lbb_4995                            if r0 > r2 { pc += 299 }
    ja lbb_4388                                     if true { pc += -309 }
lbb_4697:
    ldxdw r2, [r10-0x8c8]                   
    ldxdw r1, [r2+0x18]                     
    stxdw [r10-0x810], r1                   
    ldxdw r1, [r2+0x10]                     
    stxdw [r10-0x818], r1                   
    ldxdw r1, [r2+0x8]                      
    stxdw [r10-0x820], r1                   
    ldxdw r1, [r2+0x0]                      
    stxdw [r10-0x828], r1                   
    ldxdw r1, [r8+0x18]                     
    stxdw [r10-0x7f0], r1                   
    ldxdw r1, [r8+0x10]                     
    stxdw [r10-0x7f8], r1                   
    ldxdw r1, [r8+0x8]                      
    stxdw [r10-0x800], r1                   
    ldxdw r1, [r8+0x0]                      
    stxdw [r10-0x808], r1                   
    stxdw [r10-0x7e8], r7                   
    ldxdw r1, [r4+0x120]                    
    ldxdw r2, [r1+0x18]                     
    stxdw [r10-0x7c8], r2                   
    ldxdw r2, [r1+0x10]                     
    stxdw [r10-0x7d0], r2                   
    ldxdw r2, [r1+0x8]                      
    stxdw [r10-0x7d8], r2                   
    ldxdw r1, [r1+0x0]                      
    stxdw [r10-0x7e0], r1                   
    ldxdw r6, [r4+0xd0]                     
    ldxdw r1, [r6+0x10]                     
    lddw r2, 0x7fffffffffffffff                     r2 load str located at 9223372036854775807
    jgt r2, r1, lbb_4730                            if r2 > r1 { pc += 1 }
    ja lbb_6096                                     if true { pc += 1366 }
lbb_4730:
    add64 r1, 1                                     r1 += 1   ///  r1 = r1.wrapping_add(1 as i32 as i64 as u64)
    stxdw [r6+0x10], r1                     
    mov64 r1, 3                                     r1 = 3 as i32 as i64 as u64
    ldxdw r2, [r6+0x20]                     
    jne r2, 82, lbb_4746                            if r2 != (82 as i32 as i64 as u64) { pc += 11 }
    stxdw [r10-0x900], r5                   
    stxdw [r10-0x8f8], r9                   
    ldxdw r2, [r6+0x18]                     
    mov64 r1, r10                                   r1 = r10
    add64 r1, -1168                                 r1 += -1168   ///  r1 = r1.wrapping_add(-1168 as i32 as i64 as u64)
    mov64 r3, 82                                    r3 = 82 as i32 as i64 as u64
    call function_32490                     
    ldxw r9, [r10-0x490]                    
    jne r9, 2, lbb_4784                             if r9 != (2 as i32 as i64 as u64) { pc += 40 }
    ldxw r1, [r10-0x488]                    
    ldxdw r9, [r10-0x8f8]                   
lbb_4746:
    ldxdw r2, [r10-0x484]                   
    stxdw [r10-0x538], r2                   
    ldxdw r2, [r10-0x47c]                   
    stxdw [r10-0x530], r2                   
    ldxdw r2, [r10-0x474]                   
    stxdw [r10-0x528], r2                   
    ldxw r2, [r10-0x46c]                    
    stxw [r10-0x710], r2                    
    stxw [r10-0x520], r2                    
lbb_4755:
    ldxw r2, [r10-0x520]                    
    stxw [r10-0x620], r2                    
    ldxdw r3, [r10-0x528]                   
    stxdw [r10-0x628], r3                   
    ldxdw r4, [r10-0x530]                   
    stxdw [r10-0x630], r4                   
    ldxdw r5, [r10-0x538]                   
    stxdw [r10-0x638], r5                   
    ldxdw r0, [r10-0x8b8]                   
    stxw [r0+0x1c], r2                      
    stxdw [r0+0x14], r3                     
    stxdw [r0+0xc], r4                      
    stxdw [r0+0x4], r5                      
    stxw [r0+0x0], r1                       
    ldxdw r1, [r6+0x10]                     
    add64 r1, -1                                    r1 += -1   ///  r1 = r1.wrapping_add(-1 as i32 as i64 as u64)
    stxdw [r6+0x10], r1                     
lbb_4772:
    ldxdw r1, [r9+0x0]                      
    add64 r1, -1                                    r1 += -1   ///  r1 = r1.wrapping_add(-1 as i32 as i64 as u64)
    stxdw [r9+0x0], r1                      
lbb_4775:
    ldxdw r1, [r10-0x888]                   
    ldxdw r2, [r1+0x0]                      
    add64 r2, 1                                     r2 += 1   ///  r2 = r2.wrapping_add(1 as i32 as i64 as u64)
    stxdw [r1+0x0], r2                      
lbb_4779:
    ldxdw r1, [r10-0x8a0]                   
    ldxdw r2, [r1+0x0]                      
    add64 r2, -1                                    r2 += -1   ///  r2 = r2.wrapping_add(-1 as i32 as i64 as u64)
    stxdw [r1+0x0], r2                      
lbb_4783:
    exit                                    
lbb_4784:
    stxdw [r10-0x920], r7                   
    ldxdw r1, [r10-0x484]                   
    stxdw [r10-0x728], r1                   
    ldxdw r1, [r10-0x47c]                   
    stxdw [r10-0x720], r1                   
    ldxdw r1, [r10-0x474]                   
    stxdw [r10-0x718], r1                   
    ldxw r1, [r10-0x46c]                    
    stxw [r10-0x710], r1                    
    ldxdw r1, [r10-0x468]                   
    stxdw [r10-0x668], r1                   
    ldxb r1, [r10-0x460]                    
    stxb [r10-0x660], r1                    
    ldxw r1, [r10-0x488]                    
    stxdw [r10-0x910], r1                   
    ldxw r1, [r10-0x48c]                    
    stxdw [r10-0x908], r1                   
    ldxb r7, [r10-0x45f]                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -1544                                 r1 += -1544   ///  r1 = r1.wrapping_add(-1544 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -1118                                 r2 += -1118   ///  r2 = r2.wrapping_add(-1118 as i32 as i64 as u64)
    mov64 r3, 38                                    r3 = 38 as i32 as i64 as u64
    call function_48190                     
    ldxdw r1, [r10-0x728]                   
    stxdw [r10-0x3c0], r1                   
    ldxdw r1, [r10-0x720]                   
    stxdw [r10-0x3b8], r1                   
    ldxdw r1, [r10-0x718]                   
    stxdw [r10-0x3b0], r1                   
    ldxw r1, [r10-0x710]                    
    stxw [r10-0x3a8], r1                    
    stxdw [r10-0x918], r7                   
    jne r7, 0, lbb_4821                             if r7 != (0 as i32 as i64 as u64) { pc += 3 }
    mov64 r1, 9                                     r1 = 9 as i32 as i64 as u64
    ldxdw r9, [r10-0x8f8]                   
    ja lbb_4755                                     if true { pc += -66 }
lbb_4821:
    stxdw [r10-0x938], r8                   
    ldxdw r1, [r10-0x8b8]                   
    ldxdw r1, [r10-0x8c0]                   
    mov64 r8, r1                                    r8 = r1
    add64 r8, 336                                   r8 += 336   ///  r8 = r8.wrapping_add(336 as i32 as i64 as u64)
    add64 r1, 240                                   r1 += 240   ///  r1 = r1.wrapping_add(240 as i32 as i64 as u64)
    stxdw [r10-0x928], r1                   
    ldxw r1, [r10-0x3a8]                    
    stxw [r10-0x520], r1                    
    ldxdw r1, [r10-0x3b0]                   
    stxdw [r10-0x528], r1                   
    ldxdw r1, [r10-0x3b8]                   
    stxdw [r10-0x530], r1                   
    ldxdw r1, [r10-0x3c0]                   
    stxdw [r10-0x538], r1                   
    ldxdw r1, [r10-0x668]                   
    stxdw [r10-0x51c], r1                   
    ldxb r1, [r10-0x660]                    
    stxb [r10-0x514], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -1934                                 r1 += -1934   ///  r1 = r1.wrapping_add(-1934 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -1544                                 r2 += -1544   ///  r2 = r2.wrapping_add(-1544 as i32 as i64 as u64)
    mov64 r3, 38                                    r3 = 38 as i32 as i64 as u64
    call function_48190                     
    ldxdw r1, [r10-0x51c]                   
    stxdw [r10-0x798], r1                   
    ldxb r1, [r10-0x514]                    
    stxb [r10-0x790], r1                    
    ldxdw r1, [r10-0x538]                   
    stxdw [r10-0x638], r1                   
    stxdw [r10-0x7b4], r1                   
    ldxdw r1, [r10-0x530]                   
    stxdw [r10-0x630], r1                   
    stxdw [r10-0x7ac], r1                   
    ldxdw r1, [r10-0x528]                   
    stxdw [r10-0x628], r1                   
    stxdw [r10-0x7a4], r1                   
    ldxw r1, [r10-0x520]                    
    stxw [r10-0x620], r1                    
    stxw [r10-0x79c], r1                    
    ldxdw r1, [r10-0x918]                   
    stxb [r10-0x78f], r1                    
    ldxdw r1, [r10-0x910]                   
    stxw [r10-0x7b8], r1                    
    ldxdw r1, [r10-0x908]                   
    stxw [r10-0x7bc], r1                    
    stxw [r10-0x7c0], r9                    
    ldxdw r1, [r6+0x10]                     
    add64 r1, -1                                    r1 += -1   ///  r1 = r1.wrapping_add(-1 as i32 as i64 as u64)
    stxdw [r6+0x10], r1                     
    mov64 r6, r8                                    r6 = r8
    mov64 r1, r10                                   r1 = r10
    add64 r1, -2192                                 r1 += -2192   ///  r1 = r1.wrapping_add(-2192 as i32 as i64 as u64)
    stxdw [r10-0x730], r1                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -2016                                 r1 += -2016   ///  r1 = r1.wrapping_add(-2016 as i32 as i64 as u64)
    stxdw [r10-0x738], r1                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -2056                                 r1 += -2056   ///  r1 = r1.wrapping_add(-2056 as i32 as i64 as u64)
    stxdw [r10-0x748], r1                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -2089                                 r1 += -2089   ///  r1 = r1.wrapping_add(-2089 as i32 as i64 as u64)
    stxdw [r10-0x760], r1                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -2129                                 r1 += -2129   ///  r1 = r1.wrapping_add(-2129 as i32 as i64 as u64)
    stxdw [r10-0x768], r1                   
    ldxdw r3, [r10-0x920]                   
    stxdw [r10-0x740], r3                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -2088                                 r1 += -2088   ///  r1 = r1.wrapping_add(-2088 as i32 as i64 as u64)
    stxdw [r10-0x750], r1                   
    mov64 r2, r10                                   r2 = r10
    add64 r2, -1936                                 r2 += -1936   ///  r2 = r2.wrapping_add(-1936 as i32 as i64 as u64)
    stxdw [r10-0x908], r2                   
    stxdw [r10-0x758], r2                   
    mov64 r2, 1                                     r2 = 1 as i32 as i64 as u64
    stxdw [r10-0x6f0], r2                   
    mov64 r2, r10                                   r2 = r10
    add64 r2, -1761                                 r2 += -1761   ///  r2 = r2.wrapping_add(-1761 as i32 as i64 as u64)
    stxdw [r10-0x6f8], r2                   
    stxdw [r10-0x708], r1                   
    mov64 r1, 32                                    r1 = 32 as i32 as i64 as u64
    stxdw [r10-0x700], r1                   
    stxdw [r10-0x710], r1                   
    stxdw [r10-0x718], r3                   
    mov64 r1, 4                                     r1 = 4 as i32 as i64 as u64
    stxdw [r10-0x720], r1                   
    lddw r1, 0x10005fbb0 --> b"coin\x1c\x00\x00\x00GoodKindkindbids != Some <= x1e-true to No"        r1 load str located at 4295359408
    stxdw [r10-0x728], r1                   
    ldxb r1, [r10-0x851]                    
    stxb [r10-0x6e1], r1                    
    mov64 r1, r6                                    r1 = r6
    call function_39132                     
    stxdw [r10-0x930], r6                   
    jne r0, 0, lbb_4936                             if r0 != (0 as i32 as i64 as u64) { pc += 18 }
    mov64 r1, r6                                    r1 = r6
    call function_39148                     
    jeq r0, 0, lbb_4936                             if r0 == (0 as i32 as i64 as u64) { pc += 15 }
    mov64 r1, 1056                                  r1 = 1056 as i32 as i64 as u64
    stxdw [r10-0x6e0], r1                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -1168                                 r1 += -1168   ///  r1 = r1.wrapping_add(-1168 as i32 as i64 as u64)
    call function_41981                     
    ldxw r1, [r10-0x490]                    
    ldxdw r9, [r10-0x8f8]                   
    ldxdw r8, [r10-0x8b8]                   
    jeq r1, 24, lbb_5109                            if r1 == (24 as i32 as i64 as u64) { pc += 179 }
    mov64 r0, 55                                    r0 = 55 as i32 as i64 as u64
    ldxdw r3, [r10-0x478]                   
    ldxdw r2, [r10-0x480]                   
    ldxdw r4, [r10-0x488]                   
    ldxw r5, [r10-0x48c]                    
    ja lbb_6072                                     if true { pc += 1136 }
lbb_4936:
    ldxdw r8, [r10-0x928]                   
    mov64 r1, r8                                    r1 = r8
    call function_39132                     
    ldxdw r9, [r10-0x8f8]                   
    ldxdw r1, [r10-0x8b8]                   
    ldxdw r7, [r10-0x8f0]                   
    jeq r0, 0, lbb_4944                             if r0 == (0 as i32 as i64 as u64) { pc += 1 }
    ja lbb_4947                                     if true { pc += 3 }
lbb_4944:
    mov64 r1, r8                                    r1 = r8
    call function_39148                     
    jne r0, 0, lbb_5910                             if r0 != (0 as i32 as i64 as u64) { pc += 963 }
lbb_4947:
    ldxdw r2, [r10-0x8b0]                   
    ldxdw r3, [r10-0x890]                   
    ldxdw r4, [r10-0x880]                   
    stxdw [r10-0xff0], r6                   
    stxdw [r10-0xfe8], r8                   
    stxdw [r10-0xff8], r7                   
    ldxdw r1, [r10-0x8e8]                   
    stxdw [r10-0x1000], r1                  
    mov64 r1, r10                                   r1 = r10
    add64 r1, -1168                                 r1 += -1168   ///  r1 = r1.wrapping_add(-1168 as i32 as i64 as u64)
    mov64 r5, r10                                   r5 = r10
    call function_15899                     
    ldxw r7, [r10-0x3e8]                    
    jeq r7, 2, lbb_5807                             if r7 == (2 as i32 as i64 as u64) { pc += 846 }
    mov64 r6, r10                                   r6 = r10
    add64 r6, -1336                                 r6 += -1336   ///  r6 = r6.wrapping_add(-1336 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -1168                                 r2 += -1168   ///  r2 = r2.wrapping_add(-1168 as i32 as i64 as u64)
    mov64 r1, r6                                    r1 = r6
    mov64 r3, 168                                   r3 = 168 as i32 as i64 as u64
    call function_48190                     
    mov64 r1, r10                                   r1 = r10
    add64 r1, -1372                                 r1 += -1372   ///  r1 = r1.wrapping_add(-1372 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -996                                  r2 += -996   ///  r2 = r2.wrapping_add(-996 as i32 as i64 as u64)
    mov64 r3, 36                                    r3 = 36 as i32 as i64 as u64
    call function_48190                     
    mov64 r1, r10                                   r1 = r10
    add64 r1, -1544                                 r1 += -1544   ///  r1 = r1.wrapping_add(-1544 as i32 as i64 as u64)
    mov64 r2, r6                                    r2 = r6
    mov64 r3, 168                                   r3 = 168 as i32 as i64 as u64
    call function_48190                     
    stxw [r10-0x560], r7                    
    ldxdw r2, [r10-0x890]                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -1336                                 r1 += -1336   ///  r1 = r1.wrapping_add(-1336 as i32 as i64 as u64)
    mov64 r3, r10                                   r3 = r10
    add64 r3, -2088                                 r3 += -2088   ///  r3 = r3.wrapping_add(-2088 as i32 as i64 as u64)
    call function_24960                     
    ldxb r6, [r10-0x538]                    
    jne r6, 56, lbb_5824                            if r6 != (56 as i32 as i64 as u64) { pc += 836 }
    ldxdw r1, [r10-0x5f8]                   
    ldxdw r2, [r1+0x0]                      
    ldxdw r3, [r2+0x0]                      
    ldxdw r4, [r10-0x878]                   
    jeq r3, r4, lbb_5043                            if r3 == r4 { pc += 50 }
lbb_4993:
    mov64 r3, 1                                     r3 = 1 as i32 as i64 as u64
    ja lbb_5053                                     if true { pc += 58 }
lbb_4995:
    lddw r2, 0x300000000                            r2 load str located at 12884901888
    stxdw [r2+0x0], r0                      
    ldxdw r3, [r8+0x18]                     
    stxdw [r0+0x18], r3                     
    ldxdw r3, [r8+0x10]                     
    stxdw [r0+0x10], r3                     
    ldxdw r3, [r8+0x8]                      
    stxdw [r0+0x8], r3                      
    ldxdw r3, [r8+0x0]                      
    stxdw [r0+0x0], r3                      
    ldxdw r3, [r2+0x0]                      
    mov64 r2, r3                                    r2 = r3
    add64 r2, -32                                   r2 += -32   ///  r2 = r2.wrapping_add(-32 as i32 as i64 as u64)
    mov64 r4, 0                                     r4 = 0 as i32 as i64 as u64
    mov64 r5, 1                                     r5 = 1 as i32 as i64 as u64
    ldxdw r1, [r10-0x8b8]                   
    jgt r2, r3, lbb_5014                            if r2 > r3 { pc += 1 }
    mov64 r5, 0                                     r5 = 0 as i32 as i64 as u64
lbb_5014:
    jne r5, 0, lbb_5016                             if r5 != (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r4, r2                                    r4 = r2
lbb_5016:
    lddw r2, 0x300007fe0                            r2 load str located at 12884934624
    jeq r3, 0, lbb_5020                             if r3 == (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r2, r4                                    r2 = r4
lbb_5020:
    lddw r3, 0x300000007                            r3 load str located at 12884901895
    jgt r2, r3, lbb_5024                            if r2 > r3 { pc += 1 }
    ja lbb_4388                                     if true { pc += -636 }
lbb_5024:
    lddw r3, 0x300000000                            r3 load str located at 12884901888
    stxdw [r3+0x0], r2                      
    ldxdw r3, [r10-0x838]                   
    stxdw [r2+0x18], r3                     
    ldxdw r3, [r10-0x840]                   
    stxdw [r2+0x10], r3                     
    ldxdw r3, [r10-0x848]                   
    stxdw [r2+0x8], r3                      
    ldxdw r3, [r10-0x850]                   
    stxdw [r2+0x0], r3                      
    stxdw [r10-0x480], r2                   
    stxdw [r10-0x488], r0                   
    mov64 r2, 8                                     r2 = 8 as i32 as i64 as u64
    stxb [r10-0x490], r2                    
    mov64 r2, r10                                   r2 = r10
    add64 r2, -1168                                 r2 += -1168   ///  r2 = r2.wrapping_add(-1168 as i32 as i64 as u64)
    call function_26067                     
    ja lbb_4772                                     if true { pc += -271 }
lbb_5043:
    ldxdw r3, [r2+0x8]                      
    ldxdw r4, [r10-0x870]                   
    jne r3, r4, lbb_4993                            if r3 != r4 { pc += -53 }
    ldxdw r3, [r2+0x10]                     
    ldxdw r4, [r10-0x868]                   
    jne r3, r4, lbb_4993                            if r3 != r4 { pc += -56 }
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
    ldxdw r4, [r2+0x18]                     
    ldxdw r5, [r10-0x860]                   
    jne r4, r5, lbb_4993                            if r4 != r5 { pc += -60 }
lbb_5053:
    ldxdw r0, [r10-0x930]                   
    jeq r3, 0, lbb_5056                             if r3 == (0 as i32 as i64 as u64) { pc += 1 }
    ja lbb_5832                                     if true { pc += 776 }
lbb_5056:
    ldxdw r1, [r10-0x608]                   
    ldxb r3, [r1+0x418]                     
    ldxb r4, [r10-0x851]                    
    jeq r3, r4, lbb_5080                            if r3 == r4 { pc += 20 }
    add64 r1, 1048                                  r1 += 1048   ///  r1 = r1.wrapping_add(1048 as i32 as i64 as u64)
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
    stxdw [r10-0x3a0], r2                   
    lddw r2, 0x100064de8 --> b"\x00\x00\x00\x00X\x01\x06\x00\x09\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00…        r2 load str located at 4295380456
    stxdw [r10-0x3c0], r2                   
    mov64 r2, 3                                     r2 = 3 as i32 as i64 as u64
    stxdw [r10-0x3b8], r2                   
    stxdw [r10-0x3a8], r2                   
    mov64 r2, r10                                   r2 = r10
    add64 r2, -1336                                 r2 += -1336   ///  r2 = r2.wrapping_add(-1336 as i32 as i64 as u64)
    stxdw [r10-0x3b0], r2                   
    stxdw [r10-0x518], r1                   
    lddw r1, 0x10005de98 --> b"\xbf#\x00\x00\x00\x00\x00\x00q\x11\x00\x00\x00\x00\x00\x00\xb7\x02\x00\x0…        r1 load str located at 4295351960
    stxdw [r10-0x510], r1                   
    stxdw [r10-0x520], r1                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -2129                                 r1 += -2129   ///  r1 = r1.wrapping_add(-2129 as i32 as i64 as u64)
    ja lbb_6324                                     if true { pc += 1244 }
lbb_5080:
    ldxb r3, [r1+0x419]                     
    ldxb r4, [r10-0x829]                    
    jeq r3, r4, lbb_6108                            if r3 == r4 { pc += 1025 }
    add64 r1, 1049                                  r1 += 1049   ///  r1 = r1.wrapping_add(1049 as i32 as i64 as u64)
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
    stxdw [r10-0x3a0], r2                   
    lddw r2, 0x100064e18 --> b"\x00\x00\x00\x00\xcf\x00\x06\x00\x0e\x00\x00\x00\x00\x00\x00\x00\x00\x00\…        r2 load str located at 4295380504
    stxdw [r10-0x3c0], r2                   
    mov64 r2, 3                                     r2 = 3 as i32 as i64 as u64
    stxdw [r10-0x3b8], r2                   
    stxdw [r10-0x3a8], r2                   
    mov64 r2, r10                                   r2 = r10
    add64 r2, -1336                                 r2 += -1336   ///  r2 = r2.wrapping_add(-1336 as i32 as i64 as u64)
    stxdw [r10-0x3b0], r2                   
    stxdw [r10-0x518], r1                   
    lddw r1, 0x10005de98 --> b"\xbf#\x00\x00\x00\x00\x00\x00q\x11\x00\x00\x00\x00\x00\x00\xb7\x02\x00\x0…        r1 load str located at 4295351960
    stxdw [r10-0x510], r1                   
    stxdw [r10-0x520], r1                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -2089                                 r1 += -2089   ///  r1 = r1.wrapping_add(-2089 as i32 as i64 as u64)
    stxdw [r10-0x528], r1                   
    lddw r1, 0x1000008a0 --> b"y\x11\x00\x00\x00\x00\x00\x00\x85\x10\x00\x00*\x99\x00\x00\x95\x00\x00\x0…        r1 load str located at 4294969504
    stxdw [r10-0x530], r1                   
    ldxdw r1, [r10-0x928]                   
    stxdw [r10-0x538], r1                   
    ja lbb_6329                                     if true { pc += 1220 }
lbb_5109:
    ldxdw r1, [r10-0x488]                   
    mul64 r1, 1184                                  r1 *= 1184   ///  r1 = r1.wrapping_mul(1184 as u64)
    call function_48833                     
    ldxdw r1, [r10-0x480]                   
    mov64 r2, r0                                    r2 = r0
    call function_48576                     
    mov64 r7, r0                                    r7 = r0
    mov64 r8, 0                                     r8 = 0 as i32 as i64 as u64
    mov64 r1, r7                                    r1 = r7
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
    call function_48350                     
    mov64 r9, r0                                    r9 = r0
    mov64 r1, r7                                    r1 = r7
    call function_48326                     
    mov64 r6, 0                                     r6 = 0 as i32 as i64 as u64
    jsgt r8, r9, lbb_5126                           if (r8 as i64) > (r9 as i64) { pc += 1 }
    mov64 r6, r0                                    r6 = r0
lbb_5126:
    mov64 r1, r7                                    r1 = r7
    lddw r2, 0x43efffffffffffff                     r2 load str located at 4895412794951729151
    call function_48896                     
    mov64 r4, -1                                    r4 = -1 as i32 as i64 as u64
    jsgt r0, 0, lbb_5133                            if (r0 as i64) > (0 as i32 as i64) { pc += 1 }
    mov64 r4, r6                                    r4 = r6
lbb_5133:
    ldxdw r6, [r10-0x8c0]                   
    ldxdw r8, [r6+0x0]                      
    mov64 r1, 1056                                  r1 = 1056 as i32 as i64 as u64
    stxdw [r10-0x1000], r1                  
    ldxdw r1, [r10-0x8d0]                   
    stxdw [r10-0xff8], r1                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -1544                                 r1 += -1544   ///  r1 = r1.wrapping_add(-1544 as i32 as i64 as u64)
    mov64 r5, r10                                   r5 = r10
    mov64 r2, r8                                    r2 = r8
    ldxdw r3, [r10-0x900]                   
    call function_40993                     
    mov64 r0, r6                                    r0 = r6
    ldxdw r4, [r0+0x8]                      
    ldxdw r1, [r4+0x0]                      
    add64 r1, 1                                     r1 += 1   ///  r1 = r1.wrapping_add(1 as i32 as i64 as u64)
    mov64 r2, 1                                     r2 = 1 as i32 as i64 as u64
    jeq r1, 0, lbb_5152                             if r1 == (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
lbb_5152:
    stxdw [r4+0x0], r1                      
    jne r2, 1, lbb_5156                             if r2 != (1 as i32 as i64 as u64) { pc += 2 }
lbb_5154:
    syscall [invalid]                       
    syscall [invalid]                       
lbb_5156:
    ldxdw r5, [r0+0x10]                     
    ldxdw r1, [r5+0x0]                      
    add64 r1, 1                                     r1 += 1   ///  r1 = r1.wrapping_add(1 as i32 as i64 as u64)
    mov64 r2, 1                                     r2 = 1 as i32 as i64 as u64
    jeq r1, 0, lbb_5162                             if r1 == (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
lbb_5162:
    stxdw [r5+0x0], r1                      
    jne r2, 1, lbb_5165                             if r2 != (1 as i32 as i64 as u64) { pc += 1 }
    ja lbb_5154                                     if true { pc += -11 }
lbb_5165:
    ldxdw r3, [r0+0x158]                    
    ldxdw r1, [r3+0x0]                      
    add64 r1, 1                                     r1 += 1   ///  r1 = r1.wrapping_add(1 as i32 as i64 as u64)
    mov64 r2, 1                                     r2 = 1 as i32 as i64 as u64
    jeq r1, 0, lbb_5171                             if r1 == (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
lbb_5171:
    ldxb r6, [r0+0x2a]                      
    stxdw [r10-0x910], r6                   
    ldxb r6, [r0+0x29]                      
    stxdw [r10-0x8d0], r6                   
    ldxdw r9, [r0+0x20]                     
    ldxdw r6, [r0+0x18]                     
    stxdw [r3+0x0], r1                      
    jne r2, 1, lbb_5180                             if r2 != (1 as i32 as i64 as u64) { pc += 1 }
    ja lbb_5154                                     if true { pc += -26 }
lbb_5180:
    ldxdw r7, [r0+0x160]                    
    ldxdw r1, [r7+0x0]                      
    add64 r1, 1                                     r1 += 1   ///  r1 = r1.wrapping_add(1 as i32 as i64 as u64)
    mov64 r2, 1                                     r2 = 1 as i32 as i64 as u64
    jeq r1, 0, lbb_5186                             if r1 == (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
lbb_5186:
    stxdw [r10-0x920], r9                   
    stxdw [r10-0x918], r8                   
    stxdw [r7+0x0], r1                      
    jne r2, 1, lbb_5191                             if r2 != (1 as i32 as i64 as u64) { pc += 1 }
    ja lbb_5154                                     if true { pc += -37 }
lbb_5191:
    ldxdw r9, [r0+0x1b8]                    
    ldxdw r2, [r9+0x0]                      
    add64 r2, 1                                     r2 += 1   ///  r2 = r2.wrapping_add(1 as i32 as i64 as u64)
    mov64 r8, 1                                     r8 = 1 as i32 as i64 as u64
    jeq r2, 0, lbb_5197                             if r2 == (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r8, 0                                     r8 = 0 as i32 as i64 as u64
lbb_5197:
    ldxb r1, [r0+0x17a]                     
    stxdw [r10-0x960], r1                   
    ldxb r1, [r0+0x179]                     
    stxdw [r10-0x958], r1                   
    ldxb r1, [r0+0x178]                     
    stxdw [r10-0x950], r1                   
    ldxdw r1, [r0+0x170]                    
    stxdw [r10-0x948], r1                   
    ldxdw r1, [r0+0x168]                    
    stxdw [r10-0x940], r1                   
    stxdw [r9+0x0], r2                      
    jne r8, 1, lbb_5210                             if r8 != (1 as i32 as i64 as u64) { pc += 1 }
    ja lbb_5154                                     if true { pc += -56 }
lbb_5210:
    stxdw [r10-0x970], r6                   
    stxdw [r10-0x968], r3                   
    ldxdw r2, [r0+0x1c0]                    
    ldxdw r8, [r2+0x0]                      
    add64 r8, 1                                     r8 += 1   ///  r8 = r8.wrapping_add(1 as i32 as i64 as u64)
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    jeq r8, 0, lbb_5218                             if r8 == (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
lbb_5218:
    mov64 r3, r5                                    r3 = r5
    mov64 r6, r4                                    r6 = r4
    stxdw [r2+0x0], r8                      
    jne r1, 1, lbb_5223                             if r1 != (1 as i32 as i64 as u64) { pc += 1 }
    ja lbb_5154                                     if true { pc += -69 }
lbb_5223:
    ldxdw r1, [r0+0x1c8]                    
    ldxdw r8, [r0+0x1d0]                    
    ldxb r4, [r0+0x1d8]                     
    ldxb r5, [r0+0x1d9]                     
    ldxb r0, [r0+0x1da]                     
    stxb [r10-0x406], r0                    
    stxb [r10-0x407], r5                    
    stxb [r10-0x408], r4                    
    stxdw [r10-0x410], r8                   
    stxdw [r10-0x418], r1                   
    stxdw [r10-0x420], r2                   
    stxdw [r10-0x428], r9                   
    ldxdw r1, [r10-0x8e0]                   
    stxdw [r10-0x430], r1                   
    ldxdw r1, [r10-0x960]                   
    stxb [r10-0x436], r1                    
    ldxdw r1, [r10-0x958]                   
    stxb [r10-0x437], r1                    
    ldxdw r1, [r10-0x950]                   
    stxb [r10-0x438], r1                    
    ldxdw r1, [r10-0x948]                   
    stxdw [r10-0x440], r1                   
    ldxdw r1, [r10-0x940]                   
    stxdw [r10-0x448], r1                   
    stxdw [r10-0x450], r7                   
    ldxdw r1, [r10-0x968]                   
    stxdw [r10-0x458], r1                   
    ldxdw r1, [r10-0x900]                   
    stxdw [r10-0x460], r1                   
    ldxdw r1, [r10-0x910]                   
    stxb [r10-0x466], r1                    
    ldxdw r1, [r10-0x8d0]                   
    stxb [r10-0x467], r1                    
    ldxdw r1, [r10-0x8d8]                   
    stxb [r10-0x468], r1                    
    ldxdw r1, [r10-0x920]                   
    stxdw [r10-0x470], r1                   
    ldxdw r1, [r10-0x970]                   
    stxdw [r10-0x478], r1                   
    stxdw [r10-0x480], r3                   
    stxdw [r10-0x488], r6                   
    ldxdw r1, [r10-0x918]                   
    stxdw [r10-0x490], r1                   
    mov64 r1, 4                                     r1 = 4 as i32 as i64 as u64
    stxdw [r10-0x660], r1                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -1832                                 r1 += -1832   ///  r1 = r1.wrapping_add(-1832 as i32 as i64 as u64)
    stxdw [r10-0x668], r1                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -1640                                 r1 += -1640   ///  r1 = r1.wrapping_add(-1640 as i32 as i64 as u64)
    stxdw [r10-0x1000], r1                  
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    stxdw [r10-0xff8], r1                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -1336                                 r1 += -1336   ///  r1 = r1.wrapping_add(-1336 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -1544                                 r2 += -1544   ///  r2 = r2.wrapping_add(-1544 as i32 as i64 as u64)
    mov64 r3, r10                                   r3 = r10
    add64 r3, -1168                                 r3 += -1168   ///  r3 = r3.wrapping_add(-1168 as i32 as i64 as u64)
    mov64 r5, r10                                   r5 = r10
    mov64 r4, 3                                     r4 = 3 as i32 as i64 as u64
    call function_40377                     
    ldxw r1, [r10-0x538]                    
    jne r1, 24, lbb_5971                            if r1 != (24 as i32 as i64 as u64) { pc += 684 }
    ldxdw r1, [r10-0x480]                   
    ldxdw r2, [r10-0x488]                   
    ldxdw r3, [r2+0x0]                      
    add64 r3, -1                                    r3 += -1   ///  r3 = r3.wrapping_add(-1 as i32 as i64 as u64)
    stxdw [r2+0x0], r3                      
    ldxdw r8, [r10-0x8b8]                   
    jne r3, 0, lbb_5297                             if r3 != (0 as i32 as i64 as u64) { pc += 3 }
    ldxdw r3, [r2+0x8]                      
    add64 r3, -1                                    r3 += -1   ///  r3 = r3.wrapping_add(-1 as i32 as i64 as u64)
    stxdw [r2+0x8], r3                      
lbb_5297:
    ldxdw r2, [r1+0x0]                      
    add64 r2, -1                                    r2 += -1   ///  r2 = r2.wrapping_add(-1 as i32 as i64 as u64)
    stxdw [r1+0x0], r2                      
    ldxdw r6, [r10-0x930]                   
    jne r2, 0, lbb_5305                             if r2 != (0 as i32 as i64 as u64) { pc += 3 }
    ldxdw r2, [r1+0x8]                      
    add64 r2, -1                                    r2 += -1   ///  r2 = r2.wrapping_add(-1 as i32 as i64 as u64)
    stxdw [r1+0x8], r2                      
lbb_5305:
    ldxdw r1, [r10-0x450]                   
    ldxdw r2, [r10-0x458]                   
    ldxdw r3, [r2+0x0]                      
    add64 r3, -1                                    r3 += -1   ///  r3 = r3.wrapping_add(-1 as i32 as i64 as u64)
    stxdw [r2+0x0], r3                      
    jne r3, 0, lbb_5314                             if r3 != (0 as i32 as i64 as u64) { pc += 3 }
    ldxdw r3, [r2+0x8]                      
    add64 r3, -1                                    r3 += -1   ///  r3 = r3.wrapping_add(-1 as i32 as i64 as u64)
    stxdw [r2+0x8], r3                      
lbb_5314:
    ldxdw r2, [r1+0x0]                      
    add64 r2, -1                                    r2 += -1   ///  r2 = r2.wrapping_add(-1 as i32 as i64 as u64)
    stxdw [r1+0x0], r2                      
    jne r2, 0, lbb_5321                             if r2 != (0 as i32 as i64 as u64) { pc += 3 }
    ldxdw r2, [r1+0x8]                      
    add64 r2, -1                                    r2 += -1   ///  r2 = r2.wrapping_add(-1 as i32 as i64 as u64)
    stxdw [r1+0x8], r2                      
lbb_5321:
    ldxdw r1, [r10-0x420]                   
    ldxdw r2, [r10-0x428]                   
    ldxdw r3, [r2+0x0]                      
    add64 r3, -1                                    r3 += -1   ///  r3 = r3.wrapping_add(-1 as i32 as i64 as u64)
    stxdw [r2+0x0], r3                      
    jne r3, 0, lbb_5330                             if r3 != (0 as i32 as i64 as u64) { pc += 3 }
    ldxdw r3, [r2+0x8]                      
    add64 r3, -1                                    r3 += -1   ///  r3 = r3.wrapping_add(-1 as i32 as i64 as u64)
    stxdw [r2+0x8], r3                      
lbb_5330:
    ldxdw r2, [r1+0x0]                      
    add64 r2, -1                                    r2 += -1   ///  r2 = r2.wrapping_add(-1 as i32 as i64 as u64)
    stxdw [r1+0x0], r2                      
    jne r2, 0, lbb_5337                             if r2 != (0 as i32 as i64 as u64) { pc += 3 }
    ldxdw r2, [r1+0x8]                      
    add64 r2, -1                                    r2 += -1   ///  r2 = r2.wrapping_add(-1 as i32 as i64 as u64)
    stxdw [r1+0x8], r2                      
lbb_5337:
    mov64 r1, r10                                   r1 = r10
    add64 r1, -1168                                 r1 += -1168   ///  r1 = r1.wrapping_add(-1168 as i32 as i64 as u64)
    mov64 r2, r6                                    r2 = r6
    call function_39192                     
    ldxw r1, [r10-0x490]                    
    jeq r1, 24, lbb_5344                            if r1 == (24 as i32 as i64 as u64) { pc += 1 }
    ja lbb_6027                                     if true { pc += 683 }
lbb_5344:
    ldxdw r7, [r10-0x480]                   
    ldxdw r9, [r10-0x488]                   
    ldxdw r3, [r9+0x8]                      
    ldxdw r1, [r10-0x6e0]                   
    jeq r3, r1, lbb_5390                            if r3 == r1 { pc += 41 }
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    stxdw [r10-0x518], r1                   
    lddw r1, 0x1000656d8 --> b"\x00\x00\x00\x00\x80\x09\x06\x00\x08\x00\x00\x00\x00\x00\x00\x00\x00\x00\…        r1 load str located at 4295382744
    stxdw [r10-0x538], r1                   
    mov64 r1, 3                                     r1 = 3 as i32 as i64 as u64
    stxdw [r10-0x530], r1                   
    stxdw [r10-0x520], r1                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -1168                                 r1 += -1168   ///  r1 = r1.wrapping_add(-1168 as i32 as i64 as u64)
    stxdw [r10-0x528], r1                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -1760                                 r1 += -1760   ///  r1 = r1.wrapping_add(-1760 as i32 as i64 as u64)
    stxdw [r10-0x470], r1                   
    lddw r1, 0x10005df58 --> b"\xbf#\x00\x00\x00\x00\x00\x00y\x11\x00\x00\x00\x00\x00\x00\xb7\x02\x00\x0…        r1 load str located at 4295352152
    stxdw [r10-0x468], r1                   
    stxdw [r10-0x478], r1                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -1640                                 r1 += -1640   ///  r1 = r1.wrapping_add(-1640 as i32 as i64 as u64)
    stxdw [r10-0x480], r1                   
    lddw r1, 0x1000008a0 --> b"y\x11\x00\x00\x00\x00\x00\x00\x85\x10\x00\x00*\x99\x00\x00\x95\x00\x00\x0…        r1 load str located at 4294969504
    stxdw [r10-0x488], r1                   
    stxdw [r10-0x490], r6                   
    stxdw [r10-0x668], r3                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -1592                                 r1 += -1592   ///  r1 = r1.wrapping_add(-1592 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -1336                                 r2 += -1336   ///  r2 = r2.wrapping_add(-1336 as i32 as i64 as u64)
    call function_445                       
    ldxw r1, [r10-0x688]                    
    stxw [r10-0x6a8], r1                    
    ldxh r1, [r10-0x684]                    
    stxh [r10-0x6a4], r1                    
    mov64 r0, 29                                    r0 = 29 as i32 as i64 as u64
    ldxdw r2, [r10-0x628]                   
    ldxdw r4, [r10-0x630]                   
    ldxw r5, [r10-0x634]                    
    ldxw r1, [r10-0x638]                    
    ja lbb_6067                                     if true { pc += 677 }
lbb_5390:
    mov64 r6, 2                                     r6 = 2 as i32 as i64 as u64
    jeq r3, 0, lbb_6100                             if r3 == (0 as i32 as i64 as u64) { pc += 708 }
    ldxdw r1, [r9+0x0]                      
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
    call function_48291                     
    ldxdw r1, [r9+0x8]                      
    jne r1, 1056, lbb_6100                          if r1 != (1056 as i32 as i64 as u64) { pc += 703 }
    ldxdw r3, [r9+0x0]                      
    mov64 r1, r3                                    r1 = r3
    and64 r1, 7                                     r1 &= 7   ///  r1 = r1.and(7)
    mov64 r6, 0                                     r6 = 0 as i32 as i64 as u64
    jeq r1, 0, lbb_5403                             if r1 == (0 as i32 as i64 as u64) { pc += 1 }
    ja lbb_6100                                     if true { pc += 697 }
lbb_5403:
    mov64 r1, r10                                   r1 = r10
    add64 r1, -1168                                 r1 += -1168   ///  r1 = r1.wrapping_add(-1168 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -1896                                 r2 += -1896   ///  r2 = r2.wrapping_add(-1896 as i32 as i64 as u64)
    call function_287                       
    ldxb r0, [r10-0x490]                    
    jeq r0, 56, lbb_5411                            if r0 == (56 as i32 as i64 as u64) { pc += 1 }
    ja lbb_6049                                     if true { pc += 638 }
lbb_5411:
    ldxdw r1, [r7+0x0]                      
    add64 r1, 1                                     r1 += 1   ///  r1 = r1.wrapping_add(1 as i32 as i64 as u64)
    stxdw [r7+0x0], r1                      
    ldxdw r6, [r10-0x928]                   
    mov64 r1, r6                                    r1 = r6
    call function_39132                     
    ldxdw r9, [r10-0x8f8]                   
    jeq r0, 0, lbb_5420                             if r0 == (0 as i32 as i64 as u64) { pc += 1 }
    ja lbb_5933                                     if true { pc += 513 }
lbb_5420:
    mov64 r1, r6                                    r1 = r6
    call function_39148                     
    jne r0, 0, lbb_5424                             if r0 != (0 as i32 as i64 as u64) { pc += 1 }
    ja lbb_5933                                     if true { pc += 509 }
lbb_5424:
    mov64 r1, r10                                   r1 = r10
    add64 r1, -1168                                 r1 += -1168   ///  r1 = r1.wrapping_add(-1168 as i32 as i64 as u64)
    call function_41981                     
    ldxw r1, [r10-0x490]                    
    jne r1, 24, lbb_5503                            if r1 != (24 as i32 as i64 as u64) { pc += 74 }
    ldxdw r1, [r10-0x488]                   
    mul64 r1, 293                                   r1 *= 293   ///  r1 = r1.wrapping_mul(293 as u64)
    call function_48833                     
    ldxdw r1, [r10-0x480]                   
    mov64 r2, r0                                    r2 = r0
    call function_48576                     
    mov64 r6, r0                                    r6 = r0
    mov64 r9, 0                                     r9 = 0 as i32 as i64 as u64
    mov64 r1, r6                                    r1 = r6
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
    call function_48350                     
    mov64 r7, r0                                    r7 = r0
    mov64 r1, r6                                    r1 = r6
    call function_48326                     
    mov64 r8, 0                                     r8 = 0 as i32 as i64 as u64
    jsgt r9, r7, lbb_5446                           if (r9 as i64) > (r7 as i64) { pc += 1 }
    mov64 r8, r0                                    r8 = r0
lbb_5446:
    mov64 r1, r6                                    r1 = r6
    lddw r2, 0x43efffffffffffff                     r2 load str located at 4895412794951729151
    call function_48896                     
    mov64 r4, -1                                    r4 = -1 as i32 as i64 as u64
    jsgt r0, 0, lbb_5453                            if (r0 as i64) > (0 as i32 as i64) { pc += 1 }
    mov64 r4, r8                                    r4 = r8
lbb_5453:
    mov64 r1, r10                                   r1 = r10
    add64 r1, -1705                                 r1 += -1705   ///  r1 = r1.wrapping_add(-1705 as i32 as i64 as u64)
    stxdw [r10-0x6c0], r1                   
    mov64 r1, 32                                    r1 = 32 as i32 as i64 as u64
    stxdw [r10-0x6c8], r1                   
    ldxdw r1, [r10-0x900]                   
    stxdw [r10-0x6d0], r1                   
    mov64 r1, 15                                    r1 = 15 as i32 as i64 as u64
    stxdw [r10-0x6d8], r1                   
    lddw r1, 0x100060149 --> b"coin_managed_taCoin PDA  mismatch. Expected , got "        r1 load str located at 4295360841
    stxdw [r10-0x6e0], r1                   
    ldxb r1, [r10-0x829]                    
    stxb [r10-0x6a9], r1                    
    mov64 r6, 1                                     r6 = 1 as i32 as i64 as u64
    stxdw [r10-0x6b8], r6                   
    ldxdw r7, [r10-0x8c0]                   
    ldxdw r8, [r7+0x0]                      
    lddw r1, 0xa900ff7e85f58c3a                     r1 load str located at -6268729762421306310
    stxdw [r10-0x520], r1                   
    lddw r1, 0x91375b5fed85b41c                     r1 load str located at -7982811346925931492
    stxdw [r10-0x528], r1                   
    lddw r1, 0xac79ebce46e1cbd9                     r1 load str located at -6018520155818964007
    stxdw [r10-0x530], r1                   
    lddw r1, 0x93a165d7e1f6dd06                     r1 load str located at -7808848301000303354
    stxdw [r10-0x538], r1                   
    mov64 r1, 165                                   r1 = 165 as i32 as i64 as u64
    stxdw [r10-0x1000], r1                  
    mov64 r1, r10                                   r1 = r10
    add64 r1, -1336                                 r1 += -1336   ///  r1 = r1.wrapping_add(-1336 as i32 as i64 as u64)
    stxdw [r10-0xff8], r1                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -1544                                 r1 += -1544   ///  r1 = r1.wrapping_add(-1544 as i32 as i64 as u64)
    mov64 r5, r10                                   r5 = r10
    mov64 r2, r8                                    r2 = r8
    ldxdw r3, [r10-0x938]                   
    call function_40993                     
    mov64 r0, r7                                    r0 = r7
    ldxdw r4, [r0+0x8]                      
    ldxdw r1, [r4+0x0]                      
    add64 r1, 1                                     r1 += 1   ///  r1 = r1.wrapping_add(1 as i32 as i64 as u64)
    jeq r1, 0, lbb_5500                             if r1 == (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r6, 0                                     r6 = 0 as i32 as i64 as u64
lbb_5500:
    stxdw [r4+0x0], r1                      
    jne r6, 1, lbb_5513                             if r6 != (1 as i32 as i64 as u64) { pc += 11 }
    ja lbb_5154                                     if true { pc += -349 }
lbb_5503:
    ldxw r2, [r10-0x48c]                    
    ldxdw r3, [r10-0x488]                   
    ldxdw r4, [r10-0x480]                   
    ldxdw r5, [r10-0x478]                   
    stxdw [r8+0x18], r5                     
    stxdw [r8+0x10], r4                     
    stxdw [r8+0x8], r3                      
    stxw [r8+0x4], r2                       
    stxw [r8+0x0], r1                       
    ja lbb_4772                                     if true { pc += -741 }
lbb_5513:
    ldxdw r5, [r0+0x10]                     
    ldxdw r1, [r5+0x0]                      
    add64 r1, 1                                     r1 += 1   ///  r1 = r1.wrapping_add(1 as i32 as i64 as u64)
    mov64 r2, 1                                     r2 = 1 as i32 as i64 as u64
    jeq r1, 0, lbb_5519                             if r1 == (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
lbb_5519:
    stxdw [r5+0x0], r1                      
    jne r2, 1, lbb_5522                             if r2 != (1 as i32 as i64 as u64) { pc += 1 }
    ja lbb_5154                                     if true { pc += -368 }
lbb_5522:
    ldxdw r3, [r0+0xf8]                     
    ldxdw r1, [r3+0x0]                      
    add64 r1, 1                                     r1 += 1   ///  r1 = r1.wrapping_add(1 as i32 as i64 as u64)
    mov64 r2, 1                                     r2 = 1 as i32 as i64 as u64
    jeq r1, 0, lbb_5528                             if r1 == (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
lbb_5528:
    ldxb r6, [r0+0x2a]                      
    stxdw [r10-0x900], r6                   
    ldxb r6, [r0+0x29]                      
    stxdw [r10-0x8d0], r6                   
    ldxdw r6, [r0+0x20]                     
    ldxdw r7, [r0+0x18]                     
    stxdw [r3+0x0], r1                      
    jne r2, 1, lbb_5537                             if r2 != (1 as i32 as i64 as u64) { pc += 1 }
    ja lbb_5154                                     if true { pc += -383 }
lbb_5537:
    ldxdw r9, [r0+0x100]                    
    ldxdw r1, [r9+0x0]                      
    add64 r1, 1                                     r1 += 1   ///  r1 = r1.wrapping_add(1 as i32 as i64 as u64)
    mov64 r2, 1                                     r2 = 1 as i32 as i64 as u64
    jeq r1, 0, lbb_5543                             if r1 == (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
lbb_5543:
    stxdw [r10-0x918], r6                   
    stxdw [r10-0x910], r8                   
    stxdw [r9+0x0], r1                      
    jne r2, 1, lbb_5548                             if r2 != (1 as i32 as i64 as u64) { pc += 1 }
    ja lbb_5154                                     if true { pc += -394 }
lbb_5548:
    ldxdw r6, [r0+0x1b8]                    
    ldxdw r2, [r6+0x0]                      
    add64 r2, 1                                     r2 += 1   ///  r2 = r2.wrapping_add(1 as i32 as i64 as u64)
    mov64 r8, 1                                     r8 = 1 as i32 as i64 as u64
    jeq r2, 0, lbb_5554                             if r2 == (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r8, 0                                     r8 = 0 as i32 as i64 as u64
lbb_5554:
    ldxb r1, [r0+0x11a]                     
    stxdw [r10-0x958], r1                   
    ldxb r1, [r0+0x119]                     
    stxdw [r10-0x950], r1                   
    ldxb r1, [r0+0x118]                     
    stxdw [r10-0x948], r1                   
    ldxdw r1, [r0+0x110]                    
    stxdw [r10-0x940], r1                   
    ldxdw r1, [r0+0x108]                    
    stxdw [r10-0x920], r1                   
    stxdw [r6+0x0], r2                      
    jne r8, 1, lbb_5567                             if r8 != (1 as i32 as i64 as u64) { pc += 1 }
    ja lbb_5154                                     if true { pc += -413 }
lbb_5567:
    stxdw [r10-0x968], r7                   
    stxdw [r10-0x960], r3                   
    ldxdw r2, [r0+0x1c0]                    
    ldxdw r8, [r2+0x0]                      
    add64 r8, 1                                     r8 += 1   ///  r8 = r8.wrapping_add(1 as i32 as i64 as u64)
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    jeq r8, 0, lbb_5575                             if r8 == (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
lbb_5575:
    mov64 r3, r5                                    r3 = r5
    mov64 r7, r4                                    r7 = r4
    stxdw [r2+0x0], r8                      
    jne r1, 1, lbb_5580                             if r1 != (1 as i32 as i64 as u64) { pc += 1 }
    ja lbb_5154                                     if true { pc += -426 }
lbb_5580:
    ldxdw r1, [r0+0x1c8]                    
    ldxdw r8, [r0+0x1d0]                    
    ldxb r4, [r0+0x1d8]                     
    ldxb r5, [r0+0x1d9]                     
    ldxb r0, [r0+0x1da]                     
    stxb [r10-0x406], r0                    
    stxb [r10-0x407], r5                    
    stxb [r10-0x408], r4                    
    stxdw [r10-0x410], r8                   
    stxdw [r10-0x418], r1                   
    stxdw [r10-0x420], r2                   
    stxdw [r10-0x428], r6                   
    ldxdw r1, [r10-0x8e0]                   
    stxdw [r10-0x430], r1                   
    ldxdw r1, [r10-0x958]                   
    stxb [r10-0x436], r1                    
    ldxdw r1, [r10-0x950]                   
    stxb [r10-0x437], r1                    
    ldxdw r1, [r10-0x948]                   
    stxb [r10-0x438], r1                    
    ldxdw r1, [r10-0x940]                   
    stxdw [r10-0x440], r1                   
    ldxdw r1, [r10-0x920]                   
    stxdw [r10-0x448], r1                   
    stxdw [r10-0x450], r9                   
    ldxdw r1, [r10-0x960]                   
    stxdw [r10-0x458], r1                   
    ldxdw r6, [r10-0x938]                   
    stxdw [r10-0x460], r6                   
    ldxdw r1, [r10-0x900]                   
    stxb [r10-0x466], r1                    
    ldxdw r1, [r10-0x8d0]                   
    stxb [r10-0x467], r1                    
    ldxdw r1, [r10-0x8d8]                   
    stxb [r10-0x468], r1                    
    ldxdw r1, [r10-0x918]                   
    stxdw [r10-0x470], r1                   
    ldxdw r1, [r10-0x968]                   
    stxdw [r10-0x478], r1                   
    stxdw [r10-0x480], r3                   
    stxdw [r10-0x488], r7                   
    ldxdw r1, [r10-0x910]                   
    stxdw [r10-0x490], r1                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -1760                                 r1 += -1760   ///  r1 = r1.wrapping_add(-1760 as i32 as i64 as u64)
    stxdw [r10-0x638], r1                   
    mov64 r1, 3                                     r1 = 3 as i32 as i64 as u64
    stxdw [r10-0x630], r1                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -1592                                 r1 += -1592   ///  r1 = r1.wrapping_add(-1592 as i32 as i64 as u64)
    stxdw [r10-0x1000], r1                  
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    stxdw [r10-0xff8], r1                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -960                                  r1 += -960   ///  r1 = r1.wrapping_add(-960 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -1544                                 r2 += -1544   ///  r2 = r2.wrapping_add(-1544 as i32 as i64 as u64)
    mov64 r3, r10                                   r3 = r10
    add64 r3, -1168                                 r3 += -1168   ///  r3 = r3.wrapping_add(-1168 as i32 as i64 as u64)
    mov64 r5, r10                                   r5 = r10
    mov64 r4, 3                                     r4 = 3 as i32 as i64 as u64
    call function_40377                     
    ldxw r1, [r10-0x3c0]                    
    jeq r1, 24, lbb_5645                            if r1 == (24 as i32 as i64 as u64) { pc += 1 }
    ja lbb_5850                                     if true { pc += 205 }
lbb_5645:
    ldxdw r1, [r10-0x480]                   
    ldxdw r2, [r10-0x488]                   
    ldxdw r3, [r2+0x0]                      
    add64 r3, -1                                    r3 += -1   ///  r3 = r3.wrapping_add(-1 as i32 as i64 as u64)
    stxdw [r2+0x0], r3                      
    ldxdw r7, [r10-0x8b8]                   
    jne r3, 0, lbb_5655                             if r3 != (0 as i32 as i64 as u64) { pc += 3 }
    ldxdw r3, [r2+0x8]                      
    add64 r3, -1                                    r3 += -1   ///  r3 = r3.wrapping_add(-1 as i32 as i64 as u64)
    stxdw [r2+0x8], r3                      
lbb_5655:
    ldxdw r2, [r1+0x0]                      
    add64 r2, -1                                    r2 += -1   ///  r2 = r2.wrapping_add(-1 as i32 as i64 as u64)
    stxdw [r1+0x0], r2                      
    ldxdw r9, [r10-0x928]                   
    jne r2, 0, lbb_5663                             if r2 != (0 as i32 as i64 as u64) { pc += 3 }
    ldxdw r2, [r1+0x8]                      
    add64 r2, -1                                    r2 += -1   ///  r2 = r2.wrapping_add(-1 as i32 as i64 as u64)
    stxdw [r1+0x8], r2                      
lbb_5663:
    ldxdw r1, [r10-0x450]                   
    ldxdw r2, [r10-0x458]                   
    ldxdw r3, [r2+0x0]                      
    add64 r3, -1                                    r3 += -1   ///  r3 = r3.wrapping_add(-1 as i32 as i64 as u64)
    stxdw [r2+0x0], r3                      
    jne r3, 0, lbb_5672                             if r3 != (0 as i32 as i64 as u64) { pc += 3 }
    ldxdw r3, [r2+0x8]                      
    add64 r3, -1                                    r3 += -1   ///  r3 = r3.wrapping_add(-1 as i32 as i64 as u64)
    stxdw [r2+0x8], r3                      
lbb_5672:
    ldxdw r2, [r1+0x0]                      
    add64 r2, -1                                    r2 += -1   ///  r2 = r2.wrapping_add(-1 as i32 as i64 as u64)
    stxdw [r1+0x0], r2                      
    jne r2, 0, lbb_5679                             if r2 != (0 as i32 as i64 as u64) { pc += 3 }
    ldxdw r2, [r1+0x8]                      
    add64 r2, -1                                    r2 += -1   ///  r2 = r2.wrapping_add(-1 as i32 as i64 as u64)
    stxdw [r1+0x8], r2                      
lbb_5679:
    ldxdw r1, [r10-0x420]                   
    ldxdw r2, [r10-0x428]                   
    ldxdw r3, [r2+0x0]                      
    add64 r3, -1                                    r3 += -1   ///  r3 = r3.wrapping_add(-1 as i32 as i64 as u64)
    stxdw [r2+0x0], r3                      
    jne r3, 0, lbb_5688                             if r3 != (0 as i32 as i64 as u64) { pc += 3 }
    ldxdw r3, [r2+0x8]                      
    add64 r3, -1                                    r3 += -1   ///  r3 = r3.wrapping_add(-1 as i32 as i64 as u64)
    stxdw [r2+0x8], r3                      
lbb_5688:
    ldxdw r2, [r1+0x0]                      
    add64 r2, -1                                    r2 += -1   ///  r2 = r2.wrapping_add(-1 as i32 as i64 as u64)
    stxdw [r1+0x0], r2                      
    jne r2, 0, lbb_5695                             if r2 != (0 as i32 as i64 as u64) { pc += 3 }
    ldxdw r2, [r1+0x8]                      
    add64 r2, -1                                    r2 += -1   ///  r2 = r2.wrapping_add(-1 as i32 as i64 as u64)
    stxdw [r1+0x8], r2                      
lbb_5695:
    mov64 r1, r10                                   r1 = r10
    add64 r1, -1168                                 r1 += -1168   ///  r1 = r1.wrapping_add(-1168 as i32 as i64 as u64)
    mov64 r5, r10                                   r5 = r10
    add64 r5, -2168                                 r5 += -2168   ///  r5 = r5.wrapping_add(-2168 as i32 as i64 as u64)
    lddw r2, 0x10005ff30 --> b"\x06\xdd\xf6\xe1\xd7e\xa1\x93\xd9\xcb\xe1F\xce\xeby\xac\x1c\xb4\x85\xed_[…        r2 load str located at 4295360304
    mov64 r3, r6                                    r3 = r6
    ldxdw r4, [r10-0x8c8]                   
    call function_31977                     
    ldxdw r6, [r10-0x490]                   
    jeq r6, 0, lbb_5957                             if r6 == (0 as i32 as i64 as u64) { pc += 251 }
    ldxdw r8, [r10-0x8c0]                   
    mov64 r7, r8                                    r7 = r8
    add64 r7, 432                                   r7 += 432   ///  r7 = r7.wrapping_add(432 as i32 as i64 as u64)
    mov64 r1, r8                                    r1 = r8
    add64 r1, 480                                   r1 += 480   ///  r1 = r1.wrapping_add(480 as i32 as i64 as u64)
    stxdw [r10-0x8c8], r1                   
    add64 r8, 192                                   r8 += 192   ///  r8 = r8.wrapping_add(192 as i32 as i64 as u64)
    ldxdw r1, [r10-0x470]                   
    stxdw [r10-0x670], r1                   
    ldxdw r1, [r10-0x478]                   
    stxdw [r10-0x678], r1                   
    ldxdw r1, [r10-0x480]                   
    stxdw [r10-0x680], r1                   
    ldxdw r1, [r10-0x488]                   
    stxdw [r10-0x688], r1                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -1504                                 r1 += -1504   ///  r1 = r1.wrapping_add(-1504 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -1128                                 r2 += -1128   ///  r2 = r2.wrapping_add(-1128 as i32 as i64 as u64)
    mov64 r3, 40                                    r3 = 40 as i32 as i64 as u64
    call function_48190                     
    stxdw [r10-0x608], r6                   
    ldxdw r1, [r10-0x688]                   
    stxdw [r10-0x600], r1                   
    ldxdw r1, [r10-0x680]                   
    stxdw [r10-0x5f8], r1                   
    ldxdw r1, [r10-0x678]                   
    stxdw [r10-0x5f0], r1                   
    ldxdw r1, [r10-0x670]                   
    stxdw [r10-0x5e8], r1                   
    mov64 r6, r10                                   r6 = r10
    add64 r6, -1640                                 r6 += -1640   ///  r6 = r6.wrapping_add(-1640 as i32 as i64 as u64)
    mov64 r1, r6                                    r1 = r6
    mov64 r2, r9                                    r2 = r9
    call function_1035                      
    mov64 r9, r10                                   r9 = r10
    add64 r9, -1592                                 r9 += -1592   ///  r9 = r9.wrapping_add(-1592 as i32 as i64 as u64)
    mov64 r1, r9                                    r1 = r9
    mov64 r2, r8                                    r2 = r8
    call function_1035                      
    mov64 r8, r10                                   r8 = r10
    add64 r8, -960                                  r8 += -960   ///  r8 = r8.wrapping_add(-960 as i32 as i64 as u64)
    mov64 r1, r8                                    r1 = r8
    mov64 r2, r7                                    r2 = r7
    call function_1035                      
    mov64 r7, r10                                   r7 = r10
    add64 r7, -1336                                 r7 += -1336   ///  r7 = r7.wrapping_add(-1336 as i32 as i64 as u64)
    mov64 r1, r7                                    r1 = r7
    ldxdw r2, [r10-0x8c8]                   
    call function_1035                      
    mov64 r1, r10                                   r1 = r10
    add64 r1, -1168                                 r1 += -1168   ///  r1 = r1.wrapping_add(-1168 as i32 as i64 as u64)
    stxdw [r10-0x8c0], r1                   
    mov64 r2, r6                                    r2 = r6
    mov64 r3, 48                                    r3 = 48 as i32 as i64 as u64
    call function_48190                     
    mov64 r1, r10                                   r1 = r10
    add64 r1, -1120                                 r1 += -1120   ///  r1 = r1.wrapping_add(-1120 as i32 as i64 as u64)
    mov64 r2, r9                                    r2 = r9
    mov64 r3, 48                                    r3 = 48 as i32 as i64 as u64
    call function_48190                     
    mov64 r1, r10                                   r1 = r10
    add64 r1, -1072                                 r1 += -1072   ///  r1 = r1.wrapping_add(-1072 as i32 as i64 as u64)
    mov64 r2, r8                                    r2 = r8
    mov64 r3, 48                                    r3 = 48 as i32 as i64 as u64
    call function_48190                     
    mov64 r1, r10                                   r1 = r10
    add64 r1, -1024                                 r1 += -1024   ///  r1 = r1.wrapping_add(-1024 as i32 as i64 as u64)
    mov64 r2, r7                                    r2 = r7
    mov64 r3, 48                                    r3 = 48 as i32 as i64 as u64
    call function_48190                     
    mov64 r1, 3                                     r1 = 3 as i32 as i64 as u64
    stxdw [r10-0x530], r1                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -1760                                 r1 += -1760   ///  r1 = r1.wrapping_add(-1760 as i32 as i64 as u64)
    stxdw [r10-0x538], r1                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -1336                                 r1 += -1336   ///  r1 = r1.wrapping_add(-1336 as i32 as i64 as u64)
    stxdw [r10-0x1000], r1                  
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    stxdw [r10-0xff8], r1                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -1704                                 r1 += -1704   ///  r1 = r1.wrapping_add(-1704 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -1544                                 r2 += -1544   ///  r2 = r2.wrapping_add(-1544 as i32 as i64 as u64)
    mov64 r5, r10                                   r5 = r10
    ldxdw r3, [r10-0x8c0]                   
    mov64 r4, 4                                     r4 = 4 as i32 as i64 as u64
    call function_40377                     
    ldxw r1, [r10-0x6a8]                    
    jeq r1, 24, lbb_5798                            if r1 == (24 as i32 as i64 as u64) { pc += 1 }
    ja lbb_6034                                     if true { pc += 236 }
lbb_5798:
    mov64 r1, r10                                   r1 = r10
    add64 r1, -1168                                 r1 += -1168   ///  r1 = r1.wrapping_add(-1168 as i32 as i64 as u64)
    call function_369                       
    ldxdw r1, [r10-0x8b8]                   
    ldxdw r9, [r10-0x8f8]                   
    ldxdw r6, [r10-0x930]                   
    ldxdw r7, [r10-0x8f0]                   
    ldxdw r8, [r10-0x928]                   
    ja lbb_4947                                     if true { pc += -860 }
lbb_5807:
    mov64 r6, r10                                   r6 = r10
    add64 r6, -1336                                 r6 += -1336   ///  r6 = r6.wrapping_add(-1336 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -1168                                 r2 += -1168   ///  r2 = r2.wrapping_add(-1168 as i32 as i64 as u64)
    mov64 r1, r6                                    r1 = r6
    mov64 r3, 72                                    r3 = 72 as i32 as i64 as u64
    call function_48190                     
    mov64 r7, r10                                   r7 = r10
    add64 r7, -1168                                 r7 += -1168   ///  r7 = r7.wrapping_add(-1168 as i32 as i64 as u64)
    mov64 r1, r7                                    r1 = r7
    mov64 r2, r6                                    r2 = r6
    mov64 r3, 72                                    r3 = 72 as i32 as i64 as u64
    call function_48190                     
    ldxdw r1, [r10-0x8b8]                   
    mov64 r2, r7                                    r2 = r7
    call function_26067                     
    ja lbb_4772                                     if true { pc += -1052 }
lbb_5824:
    mov64 r1, r10                                   r1 = r10
    add64 r1, -1167                                 r1 += -1167   ///  r1 = r1.wrapping_add(-1167 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -1335                                 r2 += -1335   ///  r2 = r2.wrapping_add(-1335 as i32 as i64 as u64)
    mov64 r3, 71                                    r3 = 71 as i32 as i64 as u64
    call function_48190                     
    stxb [r10-0x490], r6                    
    ja lbb_6336                                     if true { pc += 504 }
lbb_5832:
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
    stxdw [r10-0x3a0], r2                   
    lddw r2, 0x100064db8 --> b"\x00\x00\x00\x00X\x01\x06\x00\x09\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00…        r2 load str located at 4295380408
    stxdw [r10-0x3c0], r2                   
    mov64 r2, 3                                     r2 = 3 as i32 as i64 as u64
    stxdw [r10-0x3b8], r2                   
    stxdw [r10-0x3a8], r2                   
    mov64 r2, r10                                   r2 = r10
    add64 r2, -1336                                 r2 += -1336   ///  r2 = r2.wrapping_add(-1336 as i32 as i64 as u64)
    stxdw [r10-0x3b0], r2                   
    stxdw [r10-0x518], r1                   
    lddw r1, 0x10004d200 --> b"\xbf&\x00\x00\x00\x00\x00\x00y\x12\x00\x00\x00\x00\x00\x00y\x13\x08\x00\x…        r1 load str located at 4295283200
    stxdw [r10-0x520], r1                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -2168                                 r1 += -2168   ///  r1 = r1.wrapping_add(-2168 as i32 as i64 as u64)
    ja lbb_6103                                     if true { pc += 253 }
lbb_5850:
    ldxw r2, [r10-0x3a4]                    
    ldxdw r3, [r10-0x8b8]                   
    stxw [r3+0x1c], r2                      
    ldxdw r2, [r10-0x3ac]                   
    stxdw [r3+0x14], r2                     
    ldxdw r2, [r10-0x3b4]                   
    stxdw [r3+0xc], r2                      
    ldxdw r2, [r10-0x3bc]                   
    stxdw [r3+0x4], r2                      
    stxw [r3+0x0], r1                       
    ldxdw r1, [r10-0x480]                   
    ldxdw r2, [r10-0x488]                   
    ldxdw r3, [r2+0x0]                      
    add64 r3, -1                                    r3 += -1   ///  r3 = r3.wrapping_add(-1 as i32 as i64 as u64)
    stxdw [r2+0x0], r3                      
    ldxdw r9, [r10-0x8f8]                   
    jne r3, 0, lbb_5870                             if r3 != (0 as i32 as i64 as u64) { pc += 3 }
    ldxdw r3, [r2+0x8]                      
    add64 r3, -1                                    r3 += -1   ///  r3 = r3.wrapping_add(-1 as i32 as i64 as u64)
    stxdw [r2+0x8], r3                      
lbb_5870:
    ldxdw r2, [r1+0x0]                      
    add64 r2, -1                                    r2 += -1   ///  r2 = r2.wrapping_add(-1 as i32 as i64 as u64)
    stxdw [r1+0x0], r2                      
    jne r2, 0, lbb_5877                             if r2 != (0 as i32 as i64 as u64) { pc += 3 }
    ldxdw r2, [r1+0x8]                      
    add64 r2, -1                                    r2 += -1   ///  r2 = r2.wrapping_add(-1 as i32 as i64 as u64)
    stxdw [r1+0x8], r2                      
lbb_5877:
    ldxdw r1, [r10-0x450]                   
    ldxdw r2, [r10-0x458]                   
    ldxdw r3, [r2+0x0]                      
    add64 r3, -1                                    r3 += -1   ///  r3 = r3.wrapping_add(-1 as i32 as i64 as u64)
    stxdw [r2+0x0], r3                      
    jne r3, 0, lbb_5886                             if r3 != (0 as i32 as i64 as u64) { pc += 3 }
    ldxdw r3, [r2+0x8]                      
    add64 r3, -1                                    r3 += -1   ///  r3 = r3.wrapping_add(-1 as i32 as i64 as u64)
    stxdw [r2+0x8], r3                      
lbb_5886:
    ldxdw r2, [r1+0x0]                      
    add64 r2, -1                                    r2 += -1   ///  r2 = r2.wrapping_add(-1 as i32 as i64 as u64)
    stxdw [r1+0x0], r2                      
    jne r2, 0, lbb_5893                             if r2 != (0 as i32 as i64 as u64) { pc += 3 }
    ldxdw r2, [r1+0x8]                      
    add64 r2, -1                                    r2 += -1   ///  r2 = r2.wrapping_add(-1 as i32 as i64 as u64)
    stxdw [r1+0x8], r2                      
lbb_5893:
    ldxdw r1, [r10-0x420]                   
    ldxdw r2, [r10-0x428]                   
    ldxdw r3, [r2+0x0]                      
    add64 r3, -1                                    r3 += -1   ///  r3 = r3.wrapping_add(-1 as i32 as i64 as u64)
    stxdw [r2+0x0], r3                      
    jne r3, 0, lbb_5902                             if r3 != (0 as i32 as i64 as u64) { pc += 3 }
    ldxdw r3, [r2+0x8]                      
    add64 r3, -1                                    r3 += -1   ///  r3 = r3.wrapping_add(-1 as i32 as i64 as u64)
    stxdw [r2+0x8], r3                      
lbb_5902:
    ldxdw r2, [r1+0x0]                      
    add64 r2, -1                                    r2 += -1   ///  r2 = r2.wrapping_add(-1 as i32 as i64 as u64)
    stxdw [r1+0x0], r2                      
    jne r2, 0, lbb_4772                             if r2 != (0 as i32 as i64 as u64) { pc += -1134 }
    ldxdw r2, [r1+0x8]                      
    add64 r2, -1                                    r2 += -1   ///  r2 = r2.wrapping_add(-1 as i32 as i64 as u64)
    stxdw [r1+0x8], r2                      
    ja lbb_4772                                     if true { pc += -1138 }
lbb_5910:
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    stxdw [r10-0x5e8], r1                   
    mov64 r1, 2                                     r1 = 2 as i32 as i64 as u64
    stxdw [r10-0x600], r1                   
    lddw r1, 0x100064d78 --> b"\x00\x00\x00\x00\xcf\x00\x06\x00\x0e\x00\x00\x00\x00\x00\x00\x00\x00\x00\…        r1 load str located at 4295380344
    stxdw [r10-0x608], r1                   
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    stxdw [r10-0x5f0], r1                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -1336                                 r1 += -1336   ///  r1 = r1.wrapping_add(-1336 as i32 as i64 as u64)
    stxdw [r10-0x5f8], r1                   
    lddw r1, 0x1000008a0 --> b"y\x11\x00\x00\x00\x00\x00\x00\x85\x10\x00\x00*\x99\x00\x00\x95\x00\x00\x0…        r1 load str located at 4294969504
    stxdw [r10-0x530], r1                   
    stxdw [r10-0x538], r8                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -1160                                 r1 += -1160   ///  r1 = r1.wrapping_add(-1160 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -1544                                 r2 += -1544   ///  r2 = r2.wrapping_add(-1544 as i32 as i64 as u64)
    call function_445                       
    mov64 r1, 29                                    r1 = 29 as i32 as i64 as u64
    ja lbb_4617                                     if true { pc += -1316 }
lbb_5933:
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    stxdw [r10-0x5e8], r1                   
    mov64 r1, 2                                     r1 = 2 as i32 as i64 as u64
    stxdw [r10-0x600], r1                   
    lddw r1, 0x100064d98 --> b"\x00\x00\x00\x00\xcf\x00\x06\x00\x0e\x00\x00\x00\x00\x00\x00\x00\x00\x00\…        r1 load str located at 4295380376
    stxdw [r10-0x608], r1                   
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    stxdw [r10-0x5f0], r1                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -1336                                 r1 += -1336   ///  r1 = r1.wrapping_add(-1336 as i32 as i64 as u64)
    stxdw [r10-0x5f8], r1                   
    lddw r1, 0x1000008a0 --> b"y\x11\x00\x00\x00\x00\x00\x00\x85\x10\x00\x00*\x99\x00\x00\x95\x00\x00\x0…        r1 load str located at 4294969504
    stxdw [r10-0x530], r1                   
    stxdw [r10-0x538], r6                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -1160                                 r1 += -1160   ///  r1 = r1.wrapping_add(-1160 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -1544                                 r2 += -1544   ///  r2 = r2.wrapping_add(-1544 as i32 as i64 as u64)
    call function_445                       
    mov64 r1, 29                                    r1 = 29 as i32 as i64 as u64
    stxb [r10-0x490], r1                    
    ja lbb_6091                                     if true { pc += 134 }
lbb_5957:
    ldxdw r1, [r10-0x470]                   
    stxdw [r10-0x670], r1                   
    ldxdw r2, [r10-0x478]                   
    stxdw [r10-0x678], r2                   
    ldxdw r3, [r10-0x480]                   
    stxdw [r10-0x680], r3                   
    ldxdw r4, [r10-0x488]                   
    stxdw [r10-0x688], r4                   
    stxdw [r7+0x18], r1                     
    stxdw [r7+0x10], r2                     
    stxdw [r7+0x8], r3                      
    stxdw [r7+0x0], r4                      
    ldxdw r9, [r10-0x8f8]                   
    ja lbb_4772                                     if true { pc += -1199 }
lbb_5971:
    ldxdw r0, [r10-0x480]                   
    ldxdw r3, [r10-0x520]                   
    ldxdw r2, [r10-0x528]                   
    ldxdw r4, [r10-0x530]                   
    ldxw r5, [r10-0x534]                    
    ldxdw r6, [r10-0x488]                   
    ldxdw r7, [r6+0x0]                      
    add64 r7, -1                                    r7 += -1   ///  r7 = r7.wrapping_add(-1 as i32 as i64 as u64)
    stxdw [r6+0x0], r7                      
    ldxdw r8, [r10-0x8b8]                   
    ldxdw r9, [r10-0x8f8]                   
    jne r7, 0, lbb_5986                             if r7 != (0 as i32 as i64 as u64) { pc += 3 }
    ldxdw r7, [r6+0x8]                      
    add64 r7, -1                                    r7 += -1   ///  r7 = r7.wrapping_add(-1 as i32 as i64 as u64)
    stxdw [r6+0x8], r7                      
lbb_5986:
    ldxdw r6, [r0+0x0]                      
    add64 r6, -1                                    r6 += -1   ///  r6 = r6.wrapping_add(-1 as i32 as i64 as u64)
    stxdw [r0+0x0], r6                      
    jne r6, 0, lbb_5993                             if r6 != (0 as i32 as i64 as u64) { pc += 3 }
    ldxdw r6, [r0+0x8]                      
    add64 r6, -1                                    r6 += -1   ///  r6 = r6.wrapping_add(-1 as i32 as i64 as u64)
    stxdw [r0+0x8], r6                      
lbb_5993:
    ldxdw r0, [r10-0x450]                   
    ldxdw r6, [r10-0x458]                   
    ldxdw r7, [r6+0x0]                      
    add64 r7, -1                                    r7 += -1   ///  r7 = r7.wrapping_add(-1 as i32 as i64 as u64)
    stxdw [r6+0x0], r7                      
    jne r7, 0, lbb_6002                             if r7 != (0 as i32 as i64 as u64) { pc += 3 }
    ldxdw r7, [r6+0x8]                      
    add64 r7, -1                                    r7 += -1   ///  r7 = r7.wrapping_add(-1 as i32 as i64 as u64)
    stxdw [r6+0x8], r7                      
lbb_6002:
    ldxdw r6, [r0+0x0]                      
    add64 r6, -1                                    r6 += -1   ///  r6 = r6.wrapping_add(-1 as i32 as i64 as u64)
    stxdw [r0+0x0], r6                      
    jne r6, 0, lbb_6009                             if r6 != (0 as i32 as i64 as u64) { pc += 3 }
    ldxdw r6, [r0+0x8]                      
    add64 r6, -1                                    r6 += -1   ///  r6 = r6.wrapping_add(-1 as i32 as i64 as u64)
    stxdw [r0+0x8], r6                      
lbb_6009:
    ldxdw r0, [r10-0x420]                   
    ldxdw r6, [r10-0x428]                   
    ldxdw r7, [r6+0x0]                      
    add64 r7, -1                                    r7 += -1   ///  r7 = r7.wrapping_add(-1 as i32 as i64 as u64)
    stxdw [r6+0x0], r7                      
    jne r7, 0, lbb_6018                             if r7 != (0 as i32 as i64 as u64) { pc += 3 }
    ldxdw r7, [r6+0x8]                      
    add64 r7, -1                                    r7 += -1   ///  r7 = r7.wrapping_add(-1 as i32 as i64 as u64)
    stxdw [r6+0x8], r7                      
lbb_6018:
    ldxdw r6, [r0+0x0]                      
    add64 r6, -1                                    r6 += -1   ///  r6 = r6.wrapping_add(-1 as i32 as i64 as u64)
    stxdw [r0+0x0], r6                      
    jne r6, 0, lbb_6025                             if r6 != (0 as i32 as i64 as u64) { pc += 3 }
    ldxdw r6, [r0+0x8]                      
    add64 r6, -1                                    r6 += -1   ///  r6 = r6.wrapping_add(-1 as i32 as i64 as u64)
    stxdw [r0+0x8], r6                      
lbb_6025:
    mov64 r0, 55                                    r0 = 55 as i32 as i64 as u64
    ja lbb_6072                                     if true { pc += 45 }
lbb_6027:
    mov64 r0, 55                                    r0 = 55 as i32 as i64 as u64
    ldxdw r2, [r10-0x480]                   
    ldxdw r4, [r10-0x488]                   
    ldxdw r3, [r10-0x478]                   
    ldxw r5, [r10-0x48c]                    
    ldxdw r9, [r10-0x8f8]                   
    ja lbb_6072                                     if true { pc += 38 }
lbb_6034:
    ldxw r2, [r10-0x68c]                    
    ldxdw r3, [r10-0x8b8]                   
    stxw [r3+0x1c], r2                      
    ldxdw r2, [r10-0x694]                   
    stxdw [r3+0x14], r2                     
    ldxdw r2, [r10-0x69c]                   
    stxdw [r3+0xc], r2                      
    ldxdw r2, [r10-0x6a4]                   
    stxdw [r3+0x4], r2                      
    stxw [r3+0x0], r1                       
    mov64 r1, r10                                   r1 = r10
    add64 r1, -1168                                 r1 += -1168   ///  r1 = r1.wrapping_add(-1168 as i32 as i64 as u64)
    call function_369                       
    ldxdw r9, [r10-0x8f8]                   
    ja lbb_4772                                     if true { pc += -1277 }
lbb_6049:
    ldxw r1, [r10-0x48e]                    
    stxw [r10-0x6a8], r1                    
    ldxh r1, [r10-0x48a]                    
    stxh [r10-0x6a4], r1                    
    ldxdw r1, [r10-0x468]                   
    stxdw [r10-0x3c0], r1                   
    ldxdw r1, [r10-0x460]                   
    stxdw [r10-0x3b8], r1                   
    ldxdw r1, [r10-0x458]                   
    stxdw [r10-0x3b0], r1                   
    ldxdw r1, [r10-0x450]                   
    stxdw [r10-0x3a8], r1                   
    ldxdw r3, [r10-0x470]                   
    ldxdw r2, [r10-0x478]                   
    ldxdw r4, [r10-0x480]                   
    ldxw r5, [r10-0x484]                    
    ldxw r1, [r10-0x488]                    
    ldxb r6, [r10-0x48f]                    
lbb_6067:
    ldxdw r9, [r10-0x8f8]                   
    ldxdw r8, [r7+0x0]                      
    add64 r8, 1                                     r8 += 1   ///  r8 = r8.wrapping_add(1 as i32 as i64 as u64)
    stxdw [r7+0x0], r8                      
    ldxdw r8, [r10-0x8b8]                   
lbb_6072:
    ldxh r7, [r10-0x6a4]                    
    stxh [r10-0x48a], r7                    
    ldxw r7, [r10-0x6a8]                    
    stxw [r10-0x48e], r7                    
    ldxdw r7, [r10-0x3c0]                   
    stxdw [r10-0x468], r7                   
    ldxdw r7, [r10-0x3b8]                   
    stxdw [r10-0x460], r7                   
    ldxdw r7, [r10-0x3b0]                   
    stxdw [r10-0x458], r7                   
    ldxdw r7, [r10-0x3a8]                   
    stxdw [r10-0x450], r7                   
    stxdw [r10-0x470], r3                   
    stxdw [r10-0x478], r2                   
    stxdw [r10-0x480], r4                   
    stxw [r10-0x484], r5                    
    stxw [r10-0x488], r1                    
    stxb [r10-0x48f], r6                    
    stxb [r10-0x490], r0                    
lbb_6091:
    mov64 r2, r10                                   r2 = r10
    add64 r2, -1168                                 r2 += -1168   ///  r2 = r2.wrapping_add(-1168 as i32 as i64 as u64)
    mov64 r1, r8                                    r1 = r8
    call function_26067                     
    ja lbb_4772                                     if true { pc += -1324 }
lbb_6096:
    lddw r1, 0x100064f78 --> b"\x00\x00\x00\x00p\xfe\x05\x00 \x00\x00\x00\x00\x00\x00\x00w\x00\x00\x00H\…        r1 load str located at 4295380856
    call function_43759                     
    syscall [invalid]                       
lbb_6100:
    mov64 r1, r6                                    r1 = r6
    call function_1069                      
    syscall [invalid]                       
lbb_6103:
    stxdw [r10-0x528], r1                   
    lddw r1, 0x1000008a0 --> b"y\x11\x00\x00\x00\x00\x00\x00\x85\x10\x00\x00*\x99\x00\x00\x95\x00\x00\x0…        r1 load str located at 4294969504
    stxdw [r10-0x510], r1                   
    ja lbb_6327                                     if true { pc += 219 }
lbb_6108:
    ldxdw r3, [r10-0x828]                   
    ldxdw r4, [r10-0x5e8]                   
    jeq r4, r3, lbb_6113                            if r4 == r3 { pc += 2 }
lbb_6111:
    mov64 r3, 1                                     r3 = 1 as i32 as i64 as u64
    ja lbb_6123                                     if true { pc += 10 }
lbb_6113:
    ldxdw r3, [r10-0x820]                   
    ldxdw r4, [r10-0x5e0]                   
    jne r4, r3, lbb_6111                            if r4 != r3 { pc += -5 }
    ldxdw r3, [r10-0x818]                   
    ldxdw r4, [r10-0x5d8]                   
    jne r4, r3, lbb_6111                            if r4 != r3 { pc += -8 }
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
    ldxdw r4, [r10-0x810]                   
    ldxdw r5, [r10-0x5d0]                   
    jne r5, r4, lbb_6111                            if r5 != r4 { pc += -12 }
lbb_6123:
    jeq r3, 0, lbb_6145                             if r3 == (0 as i32 as i64 as u64) { pc += 21 }
    mov64 r1, r10                                   r1 = r10
    add64 r1, -1512                                 r1 += -1512   ///  r1 = r1.wrapping_add(-1512 as i32 as i64 as u64)
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
    stxdw [r10-0x3a0], r2                   
    lddw r2, 0x100064e48 --> b"\x00\x00\x00\x00X\x01\x06\x00\x09\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00…        r2 load str located at 4295380552
    stxdw [r10-0x3c0], r2                   
    mov64 r2, 3                                     r2 = 3 as i32 as i64 as u64
    stxdw [r10-0x3b8], r2                   
    stxdw [r10-0x3a8], r2                   
    mov64 r2, r10                                   r2 = r10
    add64 r2, -1336                                 r2 += -1336   ///  r2 = r2.wrapping_add(-1336 as i32 as i64 as u64)
    stxdw [r10-0x3b0], r2                   
    stxdw [r10-0x518], r1                   
    lddw r1, 0x10004d200 --> b"\xbf&\x00\x00\x00\x00\x00\x00y\x12\x00\x00\x00\x00\x00\x00y\x13\x08\x00\x…        r1 load str located at 4295283200
    stxdw [r10-0x510], r1                   
    stxdw [r10-0x520], r1                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -2088                                 r1 += -2088   ///  r1 = r1.wrapping_add(-2088 as i32 as i64 as u64)
    ja lbb_6324                                     if true { pc += 179 }
lbb_6145:
    ldxdw r3, [r2+0x0]                      
    ldxdw r4, [r10-0x5c8]                   
    jeq r4, r3, lbb_6150                            if r4 == r3 { pc += 2 }
lbb_6148:
    mov64 r3, 1                                     r3 = 1 as i32 as i64 as u64
    ja lbb_6160                                     if true { pc += 10 }
lbb_6150:
    ldxdw r3, [r2+0x8]                      
    ldxdw r4, [r10-0x5c0]                   
    jne r4, r3, lbb_6148                            if r4 != r3 { pc += -5 }
    ldxdw r3, [r2+0x10]                     
    ldxdw r4, [r10-0x5b8]                   
    jne r4, r3, lbb_6148                            if r4 != r3 { pc += -8 }
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
    ldxdw r2, [r2+0x18]                     
    ldxdw r4, [r10-0x5b0]                   
    jne r4, r2, lbb_6148                            if r4 != r2 { pc += -12 }
lbb_6160:
    jeq r3, 0, lbb_6189                             if r3 == (0 as i32 as i64 as u64) { pc += 28 }
    mov64 r1, r10                                   r1 = r10
    add64 r1, -1480                                 r1 += -1480   ///  r1 = r1.wrapping_add(-1480 as i32 as i64 as u64)
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
    stxdw [r10-0x518], r2                   
    lddw r2, 0x100064e78 --> b"\x00\x00\x00\x00\xbc\x01\x06\x003\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00…        r2 load str located at 4295380600
    stxdw [r10-0x538], r2                   
    mov64 r2, 2                                     r2 = 2 as i32 as i64 as u64
    stxdw [r10-0x530], r2                   
    stxdw [r10-0x520], r2                   
    mov64 r2, r10                                   r2 = r10
    add64 r2, -960                                  r2 += -960   ///  r2 = r2.wrapping_add(-960 as i32 as i64 as u64)
    stxdw [r10-0x528], r2                   
    lddw r2, 0x10004d200 --> b"\xbf&\x00\x00\x00\x00\x00\x00y\x12\x00\x00\x00\x00\x00\x00y\x13\x08\x00\x…        r2 load str located at 4295283200
    stxdw [r10-0x3a8], r2                   
    stxdw [r10-0x3b0], r1                   
    lddw r1, 0x1000008a0 --> b"y\x11\x00\x00\x00\x00\x00\x00\x85\x10\x00\x00*\x99\x00\x00\x95\x00\x00\x0…        r1 load str located at 4294969504
    stxdw [r10-0x3b8], r1                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -2224                                 r1 += -2224   ///  r1 = r1.wrapping_add(-2224 as i32 as i64 as u64)
    stxdw [r10-0x3c0], r1                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -1160                                 r1 += -1160   ///  r1 = r1.wrapping_add(-1160 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -1336                                 r2 += -1336   ///  r2 = r2.wrapping_add(-1336 as i32 as i64 as u64)
    ja lbb_6333                                     if true { pc += 144 }
lbb_6189:
    ldxdw r2, [r10-0x5f0]                   
    ldxdw r3, [r2+0x0]                      
    ldxdw r4, [r3+0x0]                      
    ldxdw r5, [r10-0x808]                   
    jeq r4, r5, lbb_6196                            if r4 == r5 { pc += 2 }
lbb_6194:
    mov64 r4, 1                                     r4 = 1 as i32 as i64 as u64
    ja lbb_6206                                     if true { pc += 10 }
lbb_6196:
    ldxdw r4, [r3+0x8]                      
    ldxdw r5, [r10-0x800]                   
    jne r4, r5, lbb_6194                            if r4 != r5 { pc += -5 }
    ldxdw r4, [r3+0x10]                     
    ldxdw r5, [r10-0x7f8]                   
    jne r4, r5, lbb_6194                            if r4 != r5 { pc += -8 }
    mov64 r4, 0                                     r4 = 0 as i32 as i64 as u64
    ldxdw r3, [r3+0x18]                     
    ldxdw r5, [r10-0x7f0]                   
    jne r3, r5, lbb_6194                            if r3 != r5 { pc += -12 }
lbb_6206:
    jeq r4, 0, lbb_6225                             if r4 == (0 as i32 as i64 as u64) { pc += 18 }
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    stxdw [r10-0x3a0], r1                   
    lddw r1, 0x100064e98 --> b"\x00\x00\x00\x00X\x01\x06\x00\x09\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00…        r1 load str located at 4295380632
    stxdw [r10-0x3c0], r1                   
    mov64 r1, 3                                     r1 = 3 as i32 as i64 as u64
    stxdw [r10-0x3b8], r1                   
    stxdw [r10-0x3a8], r1                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -1336                                 r1 += -1336   ///  r1 = r1.wrapping_add(-1336 as i32 as i64 as u64)
    stxdw [r10-0x3b0], r1                   
    stxdw [r10-0x518], r2                   
    lddw r1, 0x10004d200 --> b"\xbf&\x00\x00\x00\x00\x00\x00y\x12\x00\x00\x00\x00\x00\x00y\x13\x08\x00\x…        r1 load str located at 4295283200
    stxdw [r10-0x520], r1                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -2056                                 r1 += -2056   ///  r1 = r1.wrapping_add(-2056 as i32 as i64 as u64)
    ja lbb_6103                                     if true { pc += -122 }
lbb_6225:
    mov64 r2, r1                                    r2 = r1
    add64 r2, 1016                                  r2 += 1016   ///  r2 = r2.wrapping_add(1016 as i32 as i64 as u64)
    ldxdw r3, [r10-0x7e8]                   
    ldxdw r4, [r3+0x0]                      
    ldxdw r5, [r1+0x3f8]                    
    jeq r5, r4, lbb_6233                            if r5 == r4 { pc += 2 }
lbb_6231:
    mov64 r4, 1                                     r4 = 1 as i32 as i64 as u64
    ja lbb_6243                                     if true { pc += 10 }
lbb_6233:
    ldxdw r4, [r3+0x8]                      
    ldxdw r5, [r2+0x8]                      
    jne r5, r4, lbb_6231                            if r5 != r4 { pc += -5 }
    ldxdw r4, [r3+0x10]                     
    ldxdw r5, [r2+0x10]                     
    jne r5, r4, lbb_6231                            if r5 != r4 { pc += -8 }
    mov64 r4, 0                                     r4 = 0 as i32 as i64 as u64
    ldxdw r3, [r3+0x18]                     
    ldxdw r5, [r2+0x18]                     
    jne r5, r3, lbb_6231                            if r5 != r3 { pc += -12 }
lbb_6243:
    jeq r4, 0, lbb_6266                             if r4 == (0 as i32 as i64 as u64) { pc += 22 }
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    stxdw [r10-0x3a0], r1                   
    lddw r1, 0x100064ec8 --> b"\x00\x00\x00\x00X\x01\x06\x00\x09\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00…        r1 load str located at 4295380680
    stxdw [r10-0x3c0], r1                   
    mov64 r1, 3                                     r1 = 3 as i32 as i64 as u64
    stxdw [r10-0x3b8], r1                   
    stxdw [r10-0x3a8], r1                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -1336                                 r1 += -1336   ///  r1 = r1.wrapping_add(-1336 as i32 as i64 as u64)
    stxdw [r10-0x3b0], r1                   
    lddw r1, 0x10004d200 --> b"\xbf&\x00\x00\x00\x00\x00\x00y\x12\x00\x00\x00\x00\x00\x00y\x13\x08\x00\x…        r1 load str located at 4295283200
    stxdw [r10-0x510], r1                   
    stxdw [r10-0x518], r2                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -2024                                 r1 += -2024   ///  r1 = r1.wrapping_add(-2024 as i32 as i64 as u64)
    stxdw [r10-0x528], r1                   
    lddw r1, 0x1000008a0 --> b"y\x11\x00\x00\x00\x00\x00\x00\x85\x10\x00\x00*\x99\x00\x00\x95\x00\x00\x0…        r1 load str located at 4294969504
    stxdw [r10-0x520], r1                   
    ja lbb_6327                                     if true { pc += 61 }
lbb_6266:
    mov64 r2, r1                                    r2 = r1
    add64 r2, 920                                   r2 += 920   ///  r2 = r2.wrapping_add(920 as i32 as i64 as u64)
    ldxdw r3, [r1+0x398]                    
    ldxdw r4, [r10-0x7e0]                   
    jeq r3, r4, lbb_6273                            if r3 == r4 { pc += 2 }
lbb_6271:
    mov64 r3, 1                                     r3 = 1 as i32 as i64 as u64
    ja lbb_6283                                     if true { pc += 10 }
lbb_6273:
    ldxdw r3, [r2+0x8]                      
    ldxdw r4, [r10-0x7d8]                   
    jne r3, r4, lbb_6271                            if r3 != r4 { pc += -5 }
    ldxdw r3, [r2+0x10]                     
    ldxdw r4, [r10-0x7d0]                   
    jne r3, r4, lbb_6271                            if r3 != r4 { pc += -8 }
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
    ldxdw r4, [r2+0x18]                     
    ldxdw r5, [r10-0x7c8]                   
    jne r4, r5, lbb_6271                            if r4 != r5 { pc += -12 }
lbb_6283:
    jeq r3, 0, lbb_6303                             if r3 == (0 as i32 as i64 as u64) { pc += 19 }
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    stxdw [r10-0x3a0], r1                   
    lddw r1, 0x100064ef8 --> b"\x00\x00\x00\x00X\x01\x06\x00\x09\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00…        r1 load str located at 4295380728
    stxdw [r10-0x3c0], r1                   
    mov64 r1, 3                                     r1 = 3 as i32 as i64 as u64
    stxdw [r10-0x3b8], r1                   
    stxdw [r10-0x3a8], r1                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -1336                                 r1 += -1336   ///  r1 = r1.wrapping_add(-1336 as i32 as i64 as u64)
    stxdw [r10-0x3b0], r1                   
    stxdw [r10-0x518], r2                   
    lddw r1, 0x10004d200 --> b"\xbf&\x00\x00\x00\x00\x00\x00y\x12\x00\x00\x00\x00\x00\x00y\x13\x08\x00\x…        r1 load str located at 4295283200
    stxdw [r10-0x510], r1                   
    stxdw [r10-0x520], r1                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -2016                                 r1 += -2016   ///  r1 = r1.wrapping_add(-2016 as i32 as i64 as u64)
    ja lbb_6324                                     if true { pc += 21 }
lbb_6303:
    ldxb r2, [r1+0x41a]                     
    ldxb r3, [r10-0x790]                    
    jeq r2, r3, lbb_6341                            if r2 == r3 { pc += 35 }
    add64 r1, 1050                                  r1 += 1050   ///  r1 = r1.wrapping_add(1050 as i32 as i64 as u64)
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
    stxdw [r10-0x3a0], r2                   
    lddw r2, 0x100064f28 --> b"\x00\x00\x00\x00X\x01\x06\x00\x09\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00…        r2 load str located at 4295380776
    stxdw [r10-0x3c0], r2                   
    mov64 r2, 3                                     r2 = 3 as i32 as i64 as u64
    stxdw [r10-0x3b8], r2                   
    stxdw [r10-0x3a8], r2                   
    mov64 r2, r10                                   r2 = r10
    add64 r2, -1336                                 r2 += -1336   ///  r2 = r2.wrapping_add(-1336 as i32 as i64 as u64)
    stxdw [r10-0x3b0], r2                   
    stxdw [r10-0x518], r1                   
    lddw r1, 0x10005de98 --> b"\xbf#\x00\x00\x00\x00\x00\x00q\x11\x00\x00\x00\x00\x00\x00\xb7\x02\x00\x0…        r1 load str located at 4295351960
    stxdw [r10-0x510], r1                   
    stxdw [r10-0x520], r1                   
    ldxdw r1, [r10-0x908]                   
lbb_6324:
    stxdw [r10-0x528], r1                   
    lddw r1, 0x1000008a0 --> b"y\x11\x00\x00\x00\x00\x00\x00\x85\x10\x00\x00*\x99\x00\x00\x95\x00\x00\x0…        r1 load str located at 4294969504
lbb_6327:
    stxdw [r10-0x530], r1                   
    stxdw [r10-0x538], r0                   
lbb_6329:
    mov64 r1, r10                                   r1 = r10
    add64 r1, -1160                                 r1 += -1160   ///  r1 = r1.wrapping_add(-1160 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -960                                  r2 += -960   ///  r2 = r2.wrapping_add(-960 as i32 as i64 as u64)
lbb_6333:
    call function_445                       
    mov64 r1, 29                                    r1 = 29 as i32 as i64 as u64
    stxb [r10-0x490], r1                    
lbb_6336:
    mov64 r2, r10                                   r2 = r10
    add64 r2, -1168                                 r2 += -1168   ///  r2 = r2.wrapping_add(-1168 as i32 as i64 as u64)
    ldxdw r1, [r10-0x8b8]                   
    call function_26067                     
    ja lbb_6373                                     if true { pc += 32 }
lbb_6341:
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    stxdw [r10-0x470], r1                   
    lddw r1, 0x100064f58 --> b"\x00\x00\x00\x00\x86\x02\x06\x00-\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00…        r1 load str located at 4295380824
    stxdw [r10-0x490], r1                   
    mov64 r1, 2                                     r1 = 2 as i32 as i64 as u64
    stxdw [r10-0x488], r1                   
    stxdw [r10-0x478], r1                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -1336                                 r1 += -1336   ///  r1 = r1.wrapping_add(-1336 as i32 as i64 as u64)
    stxdw [r10-0x480], r1                   
    lddw r1, 0x1000008a0 --> b"y\x11\x00\x00\x00\x00\x00\x00\x85\x10\x00\x00*\x99\x00\x00\x95\x00\x00\x0…        r1 load str located at 4294969504
    stxdw [r10-0x520], r1                   
    stxdw [r10-0x528], r0                   
    lddw r1, 0x10004d200 --> b"\xbf&\x00\x00\x00\x00\x00\x00y\x12\x00\x00\x00\x00\x00\x00y\x13\x08\x00\x…        r1 load str located at 4295283200
    stxdw [r10-0x530], r1                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -2088                                 r1 += -2088   ///  r1 = r1.wrapping_add(-2088 as i32 as i64 as u64)
    stxdw [r10-0x538], r1                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -960                                  r1 += -960   ///  r1 = r1.wrapping_add(-960 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -1168                                 r2 += -1168   ///  r2 = r2.wrapping_add(-1168 as i32 as i64 as u64)
    call function_43415                     
    ldxdw r1, [r10-0x3c0]                   
    ldxdw r2, [r10-0x3b0]                   
    syscall [invalid]                       
    mov64 r1, 24                                    r1 = 24 as i32 as i64 as u64
    ldxdw r2, [r10-0x8b8]                   
    stxw [r2+0x0], r1                       
lbb_6373:
    ldxdw r1, [r10-0x600]                   
    ldxdw r2, [r1+0x0]                      
    add64 r2, -1                                    r2 += -1   ///  r2 = r2.wrapping_add(-1 as i32 as i64 as u64)
    stxdw [r1+0x0], r2                      
    ja lbb_4772                                     if true { pc += -1606 }

function_6378:
    mov64 r7, r3                                    r7 = r3
    mov64 r5, r2                                    r5 = r2
    mov64 r8, r1                                    r8 = r1
    jne r4, 10, lbb_6435                            if r4 != (10 as i32 as i64 as u64) { pc += 53 }
    ldxdw r4, [r7+0x30]                     
    ldxb r1, [r7+0x58]                      
    mov64 r2, 37                                    r2 = 37 as i32 as i64 as u64
    stxdw [r10-0x158], r2                   
    lddw r2, 0x10005ffef --> b"Market maker account must be a signerIncorrect sys"        r2 load str located at 4295360495
    stxdw [r10-0x160], r2                   
    jne r1, 0, lbb_6459                             if r1 != (0 as i32 as i64 as u64) { pc += 69 }
    lddw r1, 0x100064fa0 --> b"\x00\x00\x00\x00p\xfe\x05\x00 \x00\x00\x00\x00\x00\x00\x00)\x01\x00\x00\x…        r1 load str located at 4295380896
    stxdw [r10-0x308], r1                   
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    stxdw [r10-0x4d0], r1                   
    lddw r1, 0x100064c98 --> b"\x00\x00\x00\x00p\xfa\x05\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00…        r1 load str located at 4295380120
    stxdw [r10-0x4f0], r1                   
    mov64 r1, 2                                     r1 = 2 as i32 as i64 as u64
    stxdw [r10-0x4e8], r1                   
    stxdw [r10-0x4d8], r1                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -1056                                 r1 += -1056   ///  r1 = r1.wrapping_add(-1056 as i32 as i64 as u64)
    stxdw [r10-0x4e0], r1                   
    lddw r1, 0x100000888 --> b"y\x11\x00\x00\x00\x00\x00\x00\x85\x10\x00\x00]\xab\x00\x00\x95\x00\x00\x0…        r1 load str located at 4294969480
    stxdw [r10-0x408], r1                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -776                                  r1 += -776   ///  r1 = r1.wrapping_add(-776 as i32 as i64 as u64)
    stxdw [r10-0x410], r1                   
    lddw r1, 0x100000860 --> b"\xbf#\x00\x00\x00\x00\x00\x00y\x12\x08\x00\x00\x00\x00\x00y\x11\x00\x00\x…        r1 load str located at 4294969440
    stxdw [r10-0x418], r1                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -352                                  r1 += -352   ///  r1 = r1.wrapping_add(-352 as i32 as i64 as u64)
    stxdw [r10-0x420], r1                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -248                                  r1 += -248   ///  r1 = r1.wrapping_add(-248 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -1264                                 r2 += -1264   ///  r2 = r2.wrapping_add(-1264 as i32 as i64 as u64)
    mov64 r6, r4                                    r6 = r4
    call function_43415                     
    ldxdw r1, [r10-0xf8]                    
    ldxdw r2, [r10-0xe8]                    
    syscall [invalid]                       
    ldxdw r1, [r6+0x18]                     
    stxdw [r10-0x4d7], r1                   
    ldxdw r1, [r6+0x10]                     
    stxdw [r10-0x4df], r1                   
    ldxdw r1, [r6+0x8]                      
    stxdw [r10-0x4e7], r1                   
    ldxdw r1, [r6+0x0]                      
    stxdw [r10-0x4ef], r1                   
    mov64 r1, 43                                    r1 = 43 as i32 as i64 as u64
    ja lbb_6507                                     if true { pc += 72 }
lbb_6435:
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    stxdw [r10-0x400], r1                   
    lddw r1, 0x100065050 --> b"\x00\x00\x00\x00S\x03\x06\x00\x1a\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00…        r1 load str located at 4295381072
    stxdw [r10-0x420], r1                   
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    stxdw [r10-0x418], r1                   
    stxdw [r10-0x408], r1                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -248                                  r1 += -248   ///  r1 = r1.wrapping_add(-248 as i32 as i64 as u64)
    stxdw [r10-0x410], r1                   
    lddw r1, 0x10005df58 --> b"\xbf#\x00\x00\x00\x00\x00\x00y\x11\x00\x00\x00\x00\x00\x00\xb7\x02\x00\x0…        r1 load str located at 4295352152
    stxdw [r10-0xf0], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -352                                  r1 += -352   ///  r1 = r1.wrapping_add(-352 as i32 as i64 as u64)
    stxdw [r10-0xf8], r1                    
    stxdw [r10-0x160], r4                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -1256                                 r1 += -1256   ///  r1 = r1.wrapping_add(-1256 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -1056                                 r2 += -1056   ///  r2 = r2.wrapping_add(-1056 as i32 as i64 as u64)
    call function_43415                     
    ja lbb_6506                                     if true { pc += 47 }
lbb_6459:
    ldxdw r1, [r7+0x1b0]                    
    ldxdw r2, [r1+0x0]                      
    jeq r2, 0, lbb_6464                             if r2 == (0 as i32 as i64 as u64) { pc += 2 }
lbb_6462:
    mov64 r2, 1                                     r2 = 1 as i32 as i64 as u64
    ja lbb_6471                                     if true { pc += 7 }
lbb_6464:
    ldxdw r2, [r1+0x8]                      
    jne r2, 0, lbb_6462                             if r2 != (0 as i32 as i64 as u64) { pc += -4 }
    ldxdw r2, [r1+0x10]                     
    jne r2, 0, lbb_6462                             if r2 != (0 as i32 as i64 as u64) { pc += -6 }
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
    ldxdw r1, [r1+0x18]                     
    jne r1, 0, lbb_6462                             if r1 != (0 as i32 as i64 as u64) { pc += -9 }
lbb_6471:
    jeq r2, 0, lbb_6513                             if r2 == (0 as i32 as i64 as u64) { pc += 41 }
    lddw r1, 0x300000000                            r1 load str located at 12884901888
    ldxdw r1, [r1+0x0]                      
    mov64 r3, r1                                    r3 = r1
    add64 r3, -41                                   r3 += -41   ///  r3 = r3.wrapping_add(-41 as i32 as i64 as u64)
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
    mov64 r4, 1                                     r4 = 1 as i32 as i64 as u64
    jgt r3, r1, lbb_6481                            if r3 > r1 { pc += 1 }
    mov64 r4, 0                                     r4 = 0 as i32 as i64 as u64
lbb_6481:
    jne r4, 0, lbb_6483                             if r4 != (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r2, r3                                    r2 = r3
lbb_6483:
    lddw r6, 0x300007fd7                            r6 load str located at 12884934615
    jeq r1, 0, lbb_6487                             if r1 == (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r6, r2                                    r6 = r2
lbb_6487:
    lddw r1, 0x300000007                            r1 load str located at 12884901895
    jgt r6, r1, lbb_6494                            if r6 > r1 { pc += 4 }
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    mov64 r2, 41                                    r2 = 41 as i32 as i64 as u64
    call function_43400                     
    syscall [invalid]                       
lbb_6494:
    lddw r1, 0x300000000                            r1 load str located at 12884901888
    stxdw [r1+0x0], r6                      
    mov64 r7, 41                                    r7 = 41 as i32 as i64 as u64
    mov64 r1, r6                                    r1 = r6
    lddw r2, 0x100060014 --> b"Incorrect system program account provided"        r2 load str located at 4295360532
    mov64 r3, 41                                    r3 = 41 as i32 as i64 as u64
lbb_6502:
    call function_48190                     
    stxdw [r10-0x4d8], r7                   
    stxdw [r10-0x4e0], r7                   
    stxdw [r10-0x4e8], r6                   
lbb_6506:
    mov64 r1, 29                                    r1 = 29 as i32 as i64 as u64
lbb_6507:
    stxb [r10-0x4f0], r1                    
    mov64 r2, r10                                   r2 = r10
    add64 r2, -1264                                 r2 += -1264   ///  r2 = r2.wrapping_add(-1264 as i32 as i64 as u64)
    mov64 r1, r8                                    r1 = r8
lbb_6511:
    call function_26067                     
    ja lbb_7032                                     if true { pc += 519 }
lbb_6513:
    ldxdw r9, [r7+0x180]                    
    ldxdw r1, [r9+0x0]                      
    lddw r2, 0x93a165d7e1f6dd06                     r2 load str located at -7808848301000303354
    jeq r1, r2, lbb_6520                            if r1 == r2 { pc += 2 }
lbb_6518:
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    ja lbb_6533                                     if true { pc += 13 }
lbb_6520:
    ldxdw r1, [r9+0x8]                      
    lddw r2, 0xac79ebce46e1cbd9                     r2 load str located at -6018520155818964007
    jne r1, r2, lbb_6518                            if r1 != r2 { pc += -6 }
    ldxdw r1, [r9+0x10]                     
    lddw r2, 0x91375b5fed85b41c                     r2 load str located at -7982811346925931492
    jne r1, r2, lbb_6518                            if r1 != r2 { pc += -10 }
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    ldxdw r2, [r9+0x18]                     
    lddw r3, 0xa900ff7e85f58c3a                     r3 load str located at -6268729762421306310
    jne r2, r3, lbb_6518                            if r2 != r3 { pc += -15 }
lbb_6533:
    jeq r1, 0, lbb_6556                             if r1 == (0 as i32 as i64 as u64) { pc += 22 }
    lddw r1, 0x300000000                            r1 load str located at 12884901888
    ldxdw r1, [r1+0x0]                      
    mov64 r3, r1                                    r3 = r1
    add64 r3, -40                                   r3 += -40   ///  r3 = r3.wrapping_add(-40 as i32 as i64 as u64)
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
    mov64 r4, 1                                     r4 = 1 as i32 as i64 as u64
    jgt r3, r1, lbb_6543                            if r3 > r1 { pc += 1 }
    mov64 r4, 0                                     r4 = 0 as i32 as i64 as u64
lbb_6543:
    jne r4, 0, lbb_6545                             if r4 != (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r2, r3                                    r2 = r3
lbb_6545:
    lddw r6, 0x300007fd8                            r6 load str located at 12884934616
    jeq r1, 0, lbb_6549                             if r1 == (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r6, r2                                    r6 = r2
lbb_6549:
    lddw r1, 0x300000007                            r1 load str located at 12884901895
    jgt r6, r1, lbb_6823                            if r6 > r1 { pc += 271 }
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    mov64 r2, 40                                    r2 = 40 as i32 as i64 as u64
    call function_43400                     
    syscall [invalid]                       
lbb_6556:
    stxdw [r10-0x580], r4                   
    stxdw [r10-0x570], r8                   
    mov64 r3, r7                                    r3 = r7
    add64 r3, 96                                    r3 += 96   ///  r3 = r3.wrapping_add(96 as i32 as i64 as u64)
    mov64 r1, r10                                   r1 = r10
    add64 r1, -1056                                 r1 += -1056   ///  r1 = r1.wrapping_add(-1056 as i32 as i64 as u64)
    mov64 r2, r5                                    r2 = r5
    mov64 r8, r5                                    r8 = r5
    call function_16885                     
    ldxb r6, [r10-0x420]                    
    jne r6, 56, lbb_6832                            if r6 != (56 as i32 as i64 as u64) { pc += 265 }
    stxdw [r10-0x5b0], r9                   
    ldxdw r1, [r10-0x570]                   
    ldxdw r1, [r10-0x410]                   
    stxdw [r10-0x560], r1                   
    ldxdw r6, [r10-0x418]                   
    stxdw [r10-0x568], r6                   
    ldxdw r9, [r10-0x408]                   
    stxdw [r10-0x558], r9                   
    mov64 r3, r7                                    r3 = r7
    add64 r3, 144                                   r3 += 144   ///  r3 = r3.wrapping_add(144 as i32 as i64 as u64)
    mov64 r1, r10                                   r1 = r10
    add64 r1, -1056                                 r1 += -1056   ///  r1 = r1.wrapping_add(-1056 as i32 as i64 as u64)
    stxdw [r10-0x578], r8                   
    mov64 r2, r8                                    r2 = r8
    mov64 r4, r6                                    r4 = r6
    mov64 r5, r9                                    r5 = r9
    call function_17301                     
    ldxb r8, [r10-0x420]                    
    jeq r8, 56, lbb_6587                            if r8 == (56 as i32 as i64 as u64) { pc += 1 }
    ja lbb_6859                                     if true { pc += 272 }
lbb_6587:
    ldxdw r3, [r10-0x580]                   
    ldxdw r1, [r3+0x0]                      
    ldxdw r2, [r6+0x28]                     
    jeq r2, r1, lbb_6593                            if r2 == r1 { pc += 2 }
lbb_6591:
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    ja lbb_6603                                     if true { pc += 10 }
lbb_6593:
    ldxdw r1, [r3+0x8]                      
    ldxdw r2, [r6+0x30]                     
    jne r2, r1, lbb_6591                            if r2 != r1 { pc += -5 }
    ldxdw r1, [r3+0x10]                     
    ldxdw r2, [r6+0x38]                     
    jne r2, r1, lbb_6591                            if r2 != r1 { pc += -8 }
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    ldxdw r2, [r3+0x18]                     
    ldxdw r3, [r6+0x40]                     
    jne r3, r2, lbb_6591                            if r3 != r2 { pc += -12 }
lbb_6603:
    ldxdw r8, [r10-0x410]                   
    jeq r1, 0, lbb_6637                             if r1 == (0 as i32 as i64 as u64) { pc += 32 }
    add64 r7, 48                                    r7 += 48   ///  r7 = r7.wrapping_add(48 as i32 as i64 as u64)
    mov64 r1, r10                                   r1 = r10
    add64 r1, -1368                                 r1 += -1368   ///  r1 = r1.wrapping_add(-1368 as i32 as i64 as u64)
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
    stxdw [r10-0x400], r2                   
    lddw r2, 0x100064d28 --> b"\x00\x00\x00\x00e\x00\x06\x00\x0b\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00…        r2 load str located at 4295380264
    stxdw [r10-0x420], r2                   
    mov64 r2, 2                                     r2 = 2 as i32 as i64 as u64
    stxdw [r10-0x418], r2                   
    stxdw [r10-0x408], r2                   
    mov64 r2, r10                                   r2 = r10
    add64 r2, -248                                  r2 += -248   ///  r2 = r2.wrapping_add(-248 as i32 as i64 as u64)
    stxdw [r10-0x410], r2                   
    stxdw [r10-0xe8], r1                    
    lddw r1, 0x1000008a0 --> b"y\x11\x00\x00\x00\x00\x00\x00\x85\x10\x00\x00*\x99\x00\x00\x95\x00\x00\x0…        r1 load str located at 4294969504
    stxdw [r10-0xe0], r1                    
    stxdw [r10-0xf0], r1                    
    stxdw [r10-0xf8], r7                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -1256                                 r1 += -1256   ///  r1 = r1.wrapping_add(-1256 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -1056                                 r2 += -1056   ///  r2 = r2.wrapping_add(-1056 as i32 as i64 as u64)
    call function_43415                     
    mov64 r1, 29                                    r1 = 29 as i32 as i64 as u64
    stxb [r10-0x4f0], r1                    
    mov64 r2, r10                                   r2 = r10
    add64 r2, -1264                                 r2 += -1264   ///  r2 = r2.wrapping_add(-1264 as i32 as i64 as u64)
    ldxdw r1, [r10-0x570]                   
    call function_26067                     
    ja lbb_7025                                     if true { pc += 388 }
lbb_6637:
    stxdw [r10-0x580], r8                   
    mov64 r3, r7                                    r3 = r7
    ldxdw r7, [r10-0x408]                   
    ldxdw r1, [r10-0x418]                   
    stxdw [r10-0x590], r1                   
    ldxdw r8, [r3+0xc0]                     
    stxdw [r10-0x1000], r9                  
    stxdw [r10-0xff8], r8                   
    mov64 r9, r3                                    r9 = r3
    add64 r3, 240                                   r3 += 240   ///  r3 = r3.wrapping_add(240 as i32 as i64 as u64)
    mov64 r1, r10                                   r1 = r10
    add64 r1, -1056                                 r1 += -1056   ///  r1 = r1.wrapping_add(-1056 as i32 as i64 as u64)
    mov64 r5, r10                                   r5 = r10
    mov64 r4, r6                                    r4 = r6
    call function_17733                     
    ldxb r6, [r10-0x420]                    
    jeq r6, 56, lbb_6655                            if r6 == (56 as i32 as i64 as u64) { pc += 1 }
    ja lbb_6881                                     if true { pc += 226 }
lbb_6655:
    ldxdw r1, [r10-0x408]                   
    stxdw [r10-0x5a0], r1                   
    ldxdw r1, [r10-0x410]                   
    stxdw [r10-0x588], r1                   
    ldxdw r1, [r10-0x418]                   
    stxdw [r10-0x5a8], r1                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -1056                                 r1 += -1056   ///  r1 = r1.wrapping_add(-1056 as i32 as i64 as u64)
    stxdw [r10-0x598], r7                   
    mov64 r2, r7                                    r2 = r7
    mov64 r3, r8                                    r3 = r8
    ldxdw r7, [r10-0x578]                   
    mov64 r4, r7                                    r4 = r7
    call function_22197                     
    ldxb r6, [r10-0x420]                    
    jeq r6, 56, lbb_6672                            if r6 == (56 as i32 as i64 as u64) { pc += 1 }
    ja lbb_6797                                     if true { pc += 125 }
lbb_6672:
    ldxdw r1, [r10-0x407]                   
    stxdw [r10-0xe0], r1                    
    ldxdw r2, [r10-0x40f]                   
    stxdw [r10-0xe8], r2                    
    ldxdw r3, [r10-0x417]                   
    stxdw [r10-0xf0], r3                    
    ldxdw r4, [r10-0x41f]                   
    stxdw [r10-0xf8], r4                    
    ldxb r5, [r10-0x3ff]                    
    stxdw [r10-0x5c0], r5                   
    stxdw [r10-0x538], r1                   
    stxdw [r10-0x540], r2                   
    stxdw [r10-0x548], r3                   
    stxdw [r10-0x550], r4                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -1056                                 r1 += -1056   ///  r1 = r1.wrapping_add(-1056 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -1360                                 r2 += -1360   ///  r2 = r2.wrapping_add(-1360 as i32 as i64 as u64)
    mov64 r3, r7                                    r3 = r7
    call function_21963                     
    ldxb r6, [r10-0x420]                    
    jeq r6, 56, lbb_6695                            if r6 == (56 as i32 as i64 as u64) { pc += 1 }
    ja lbb_6797                                     if true { pc += 102 }
lbb_6695:
    ldxdw r1, [r10-0x407]                   
    stxdw [r10-0xe0], r1                    
    ldxdw r2, [r10-0x40f]                   
    stxdw [r10-0xe8], r2                    
    ldxdw r3, [r10-0x417]                   
    stxdw [r10-0xf0], r3                    
    ldxdw r4, [r10-0x41f]                   
    stxdw [r10-0xf8], r4                    
    ldxb r5, [r10-0x3ff]                    
    stxdw [r10-0x518], r1                   
    stxdw [r10-0x520], r2                   
    stxdw [r10-0x528], r3                   
    stxdw [r10-0x530], r4                   
    mov64 r7, r9                                    r7 = r9
    ldxdw r6, [r7+0x120]                    
    ldxdw r1, [r6+0x0]                      
    ldxdw r2, [r10-0x550]                   
    jeq r1, r2, lbb_6715                            if r1 == r2 { pc += 2 }
lbb_6713:
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    ja lbb_6725                                     if true { pc += 10 }
lbb_6715:
    ldxdw r1, [r6+0x8]                      
    ldxdw r2, [r10-0x548]                   
    jne r1, r2, lbb_6713                            if r1 != r2 { pc += -5 }
    ldxdw r1, [r6+0x10]                     
    ldxdw r2, [r10-0x540]                   
    jne r1, r2, lbb_6713                            if r1 != r2 { pc += -8 }
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    ldxdw r2, [r6+0x18]                     
    ldxdw r3, [r10-0x538]                   
    jne r2, r3, lbb_6713                            if r2 != r3 { pc += -12 }
lbb_6725:
    mov64 r2, 36                                    r2 = 36 as i32 as i64 as u64
    stxdw [r10-0x158], r2                   
    lddw r2, 0x100060082 --> b"Coin PDA address derivation mismatchToken account "        r2 load str located at 4295360642
    stxdw [r10-0x160], r2                   
    jeq r1, 0, lbb_7033                             if r1 == (0 as i32 as i64 as u64) { pc += 302 }
    mov64 r7, r6                                    r7 = r6
    lddw r1, 0x100064fb8 --> b"\x00\x00\x00\x00p\xfe\x05\x00 \x00\x00\x00\x00\x00\x00\x00V\x01\x00\x00\x…        r1 load str located at 4295380920
    stxdw [r10-0x308], r1                   
    lddw r1, 0x100064c98 --> b"\x00\x00\x00\x00p\xfa\x05\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00…        r1 load str located at 4295380120
    stxdw [r10-0x4f0], r1                   
    mov64 r1, 2                                     r1 = 2 as i32 as i64 as u64
    stxdw [r10-0x4e8], r1                   
    stxdw [r10-0x4d8], r1                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -1056                                 r1 += -1056   ///  r1 = r1.wrapping_add(-1056 as i32 as i64 as u64)
    stxdw [r10-0x4e0], r1                   
    lddw r1, 0x100000888 --> b"y\x11\x00\x00\x00\x00\x00\x00\x85\x10\x00\x00]\xab\x00\x00\x95\x00\x00\x0…        r1 load str located at 4294969480
    stxdw [r10-0x408], r1                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -776                                  r1 += -776   ///  r1 = r1.wrapping_add(-776 as i32 as i64 as u64)
    stxdw [r10-0x410], r1                   
    lddw r1, 0x100000860 --> b"\xbf#\x00\x00\x00\x00\x00\x00y\x12\x08\x00\x00\x00\x00\x00y\x11\x00\x00\x…        r1 load str located at 4294969440
    stxdw [r10-0x418], r1                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -352                                  r1 += -352   ///  r1 = r1.wrapping_add(-352 as i32 as i64 as u64)
    stxdw [r10-0x420], r1                   
    mov64 r6, 0                                     r6 = 0 as i32 as i64 as u64
    stxdw [r10-0x4d0], r6                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -248                                  r1 += -248   ///  r1 = r1.wrapping_add(-248 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -1264                                 r2 += -1264   ///  r2 = r2.wrapping_add(-1264 as i32 as i64 as u64)
    call function_43415                     
    ldxdw r1, [r10-0xf8]                    
    ldxdw r2, [r10-0xe8]                    
    syscall [invalid]                       
    ldxdw r1, [r8+0x18]                     
    stxdw [r10-0x4d8], r1                   
    ldxdw r1, [r8+0x10]                     
    stxdw [r10-0x4e0], r1                   
    ldxdw r1, [r8+0x8]                      
    stxdw [r10-0x4e8], r1                   
    ldxdw r1, [r8+0x0]                      
    stxdw [r10-0x4f0], r1                   
    lddw r1, 0x300000000                            r1 load str located at 12884901888
    ldxdw r2, [r1+0x0]                      
    mov64 r3, 1                                     r3 = 1 as i32 as i64 as u64
    mov64 r4, r2                                    r4 = r2
    add64 r4, -32                                   r4 += -32   ///  r4 = r4.wrapping_add(-32 as i32 as i64 as u64)
    jgt r4, r2, lbb_6782                            if r4 > r2 { pc += 1 }
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
lbb_6782:
    ldxdw r1, [r10-0x570]                   
    ldxdw r5, [r10-0x598]                   
    jne r3, 0, lbb_6786                             if r3 != (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r6, r4                                    r6 = r4
lbb_6786:
    lddw r8, 0x300007fe0                            r8 load str located at 12884934624
    jeq r2, 0, lbb_6790                             if r2 == (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r8, r6                                    r8 = r6
lbb_6790:
    lddw r2, 0x300000007                            r2 load str located at 12884901895
    jgt r8, r2, lbb_6904                            if r8 > r2 { pc += 111 }
lbb_6793:
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    mov64 r2, 32                                    r2 = 32 as i32 as i64 as u64
    call function_43400                     
    syscall [invalid]                       
lbb_6797:
    ldxdw r1, [r10-0x407]                   
    stxdw [r10-0xe0], r1                    
    ldxdw r1, [r10-0x40f]                   
    stxdw [r10-0xe8], r1                    
    ldxdw r1, [r10-0x417]                   
    stxdw [r10-0xf0], r1                    
    ldxdw r1, [r10-0x41f]                   
    stxdw [r10-0xf8], r1                    
    ldxb r7, [r10-0x3ff]                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -1230                                 r1 += -1230   ///  r1 = r1.wrapping_add(-1230 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -1022                                 r2 += -1022   ///  r2 = r2.wrapping_add(-1022 as i32 as i64 as u64)
    mov64 r3, 38                                    r3 = 38 as i32 as i64 as u64
    call function_48190                     
    stxb [r10-0x4cf], r7                    
    stxb [r10-0x4f0], r6                    
    ldxdw r1, [r10-0xf8]                    
    stxdw [r10-0x4ef], r1                   
    ldxdw r1, [r10-0xf0]                    
    stxdw [r10-0x4e7], r1                   
    ldxdw r1, [r10-0xe8]                    
    stxdw [r10-0x4df], r1                   
    ldxdw r1, [r10-0xe0]                    
    stxdw [r10-0x4d7], r1                   
    ja lbb_7779                                     if true { pc += 956 }
lbb_6823:
    lddw r1, 0x300000000                            r1 load str located at 12884901888
    stxdw [r1+0x0], r6                      
    mov64 r7, 40                                    r7 = 40 as i32 as i64 as u64
    mov64 r1, r6                                    r1 = r6
    lddw r2, 0x10006003d --> b"Incorrect token program account provided"        r2 load str located at 4295360573
    mov64 r3, 40                                    r3 = 40 as i32 as i64 as u64
    ja lbb_6502                                     if true { pc += -330 }
lbb_6832:
    ldxdw r1, [r10-0x408]                   
    stxdw [r10-0xe1], r1                    
    ldxdw r1, [r10-0x40f]                   
    stxdw [r10-0xe8], r1                    
    ldxdw r1, [r10-0x417]                   
    stxdw [r10-0xf0], r1                    
    ldxdw r1, [r10-0x41f]                   
    stxdw [r10-0xf8], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -1232                                 r1 += -1232   ///  r1 = r1.wrapping_add(-1232 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -1024                                 r2 += -1024   ///  r2 = r2.wrapping_add(-1024 as i32 as i64 as u64)
    mov64 r3, 40                                    r3 = 40 as i32 as i64 as u64
    call function_48190                     
    stxb [r10-0x4f0], r6                    
    ldxdw r1, [r10-0xf8]                    
    stxdw [r10-0x4ef], r1                   
    ldxdw r1, [r10-0xf0]                    
    stxdw [r10-0x4e7], r1                   
    ldxdw r1, [r10-0xe8]                    
    stxdw [r10-0x4df], r1                   
    ldxdw r1, [r10-0xe1]                    
    stxdw [r10-0x4d8], r1                   
    mov64 r2, r10                                   r2 = r10
    add64 r2, -1264                                 r2 += -1264   ///  r2 = r2.wrapping_add(-1264 as i32 as i64 as u64)
    ldxdw r1, [r10-0x570]                   
    ja lbb_6511                                     if true { pc += -348 }
lbb_6859:
    ldxw r1, [r10-0x41c]                    
    stxw [r10-0x4ec], r1                    
    ldxw r1, [r10-0x41f]                    
    stxw [r10-0x4ef], r1                    
    ldxdw r6, [r10-0x418]                   
    ldxdw r7, [r10-0x410]                   
    ldxdw r9, [r10-0x408]                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -1232                                 r1 += -1232   ///  r1 = r1.wrapping_add(-1232 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -1024                                 r2 += -1024   ///  r2 = r2.wrapping_add(-1024 as i32 as i64 as u64)
    mov64 r3, 40                                    r3 = 40 as i32 as i64 as u64
    call function_48190                     
    stxdw [r10-0x4d8], r9                   
    stxdw [r10-0x4e0], r7                   
    stxdw [r10-0x4e8], r6                   
    stxb [r10-0x4f0], r8                    
    mov64 r2, r10                                   r2 = r10
    add64 r2, -1264                                 r2 += -1264   ///  r2 = r2.wrapping_add(-1264 as i32 as i64 as u64)
    ldxdw r1, [r10-0x570]                   
    call function_26067                     
    ja lbb_7028                                     if true { pc += 147 }
lbb_6881:
    ldxw r1, [r10-0x41c]                    
    stxw [r10-0x4ec], r1                    
    ldxw r1, [r10-0x41f]                    
    stxw [r10-0x4ef], r1                    
    ldxdw r7, [r10-0x418]                   
    ldxdw r8, [r10-0x410]                   
    ldxdw r9, [r10-0x408]                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -1232                                 r1 += -1232   ///  r1 = r1.wrapping_add(-1232 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -1024                                 r2 += -1024   ///  r2 = r2.wrapping_add(-1024 as i32 as i64 as u64)
    mov64 r3, 40                                    r3 = 40 as i32 as i64 as u64
    call function_48190                     
    stxdw [r10-0x4d8], r9                   
    stxdw [r10-0x4e0], r8                   
    stxdw [r10-0x4e8], r7                   
    stxb [r10-0x4f0], r6                    
    mov64 r2, r10                                   r2 = r10
    add64 r2, -1264                                 r2 += -1264   ///  r2 = r2.wrapping_add(-1264 as i32 as i64 as u64)
    ldxdw r1, [r10-0x570]                   
    call function_26067                     
    ldxdw r8, [r10-0x580]                   
    ja lbb_7025                                     if true { pc += 121 }
lbb_6904:
    lddw r2, 0x300000000                            r2 load str located at 12884901888
    stxdw [r2+0x0], r8                      
    ldxdw r3, [r10-0x4d8]                   
    stxdw [r8+0x18], r3                     
    ldxdw r3, [r10-0x4e0]                   
    stxdw [r8+0x10], r3                     
    ldxdw r3, [r10-0x4e8]                   
    stxdw [r8+0x8], r3                      
    ldxdw r3, [r10-0x4f0]                   
    stxdw [r8+0x0], r3                      
    ldxdw r3, [r5+0x18]                     
    stxdw [r10-0x4d8], r3                   
    ldxdw r3, [r5+0x10]                     
    stxdw [r10-0x4e0], r3                   
    ldxdw r3, [r5+0x8]                      
    stxdw [r10-0x4e8], r3                   
    ldxdw r3, [r5+0x0]                      
    stxdw [r10-0x4f0], r3                   
    ldxdw r3, [r2+0x0]                      
    mov64 r4, 0                                     r4 = 0 as i32 as i64 as u64
    mov64 r5, 1                                     r5 = 1 as i32 as i64 as u64
    mov64 r2, r3                                    r2 = r3
    add64 r2, -32                                   r2 += -32   ///  r2 = r2.wrapping_add(-32 as i32 as i64 as u64)
    jgt r2, r3, lbb_6930                            if r2 > r3 { pc += 1 }
    mov64 r5, 0                                     r5 = 0 as i32 as i64 as u64
lbb_6930:
    jne r5, 0, lbb_6932                             if r5 != (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r4, r2                                    r4 = r2
lbb_6932:
    lddw r2, 0x300007fe0                            r2 load str located at 12884934624
    jeq r3, 0, lbb_6936                             if r3 == (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r2, r4                                    r2 = r4
lbb_6936:
    lddw r3, 0x300000007                            r3 load str located at 12884901895
    jgt r2, r3, lbb_6940                            if r2 > r3 { pc += 1 }
    ja lbb_6793                                     if true { pc += -147 }
lbb_6940:
    lddw r3, 0x300000000                            r3 load str located at 12884901888
    stxdw [r3+0x0], r2                      
    ldxdw r4, [r10-0x4d8]                   
    stxdw [r2+0x18], r4                     
    ldxdw r4, [r10-0x4e0]                   
    stxdw [r2+0x10], r4                     
    ldxdw r4, [r10-0x4e8]                   
    stxdw [r2+0x8], r4                      
    ldxdw r4, [r10-0x4f0]                   
    stxdw [r2+0x0], r4                      
    ldxdw r4, [r7+0x18]                     
    stxdw [r10-0x4d8], r4                   
    ldxdw r4, [r7+0x10]                     
    stxdw [r10-0x4e0], r4                   
    ldxdw r4, [r7+0x8]                      
    stxdw [r10-0x4e8], r4                   
    ldxdw r4, [r7+0x0]                      
    stxdw [r10-0x4f0], r4                   
    ldxdw r4, [r3+0x0]                      
    mov64 r5, 0                                     r5 = 0 as i32 as i64 as u64
    mov64 r0, 1                                     r0 = 1 as i32 as i64 as u64
    mov64 r3, r4                                    r3 = r4
    add64 r3, -32                                   r3 += -32   ///  r3 = r3.wrapping_add(-32 as i32 as i64 as u64)
    jgt r3, r4, lbb_6966                            if r3 > r4 { pc += 1 }
    mov64 r0, 0                                     r0 = 0 as i32 as i64 as u64
lbb_6966:
    jne r0, 0, lbb_6968                             if r0 != (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r5, r3                                    r5 = r3
lbb_6968:
    lddw r3, 0x300007fe0                            r3 load str located at 12884934624
    jeq r4, 0, lbb_6972                             if r4 == (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r3, r5                                    r3 = r5
lbb_6972:
    lddw r4, 0x300000007                            r4 load str located at 12884901895
    jgt r3, r4, lbb_6976                            if r3 > r4 { pc += 1 }
    ja lbb_6793                                     if true { pc += -183 }
lbb_6976:
    lddw r4, 0x300000000                            r4 load str located at 12884901888
    stxdw [r4+0x0], r3                      
    ldxdw r5, [r10-0x4d8]                   
    stxdw [r3+0x18], r5                     
    ldxdw r5, [r10-0x4e0]                   
    stxdw [r3+0x10], r5                     
    ldxdw r5, [r10-0x4e8]                   
    stxdw [r3+0x8], r5                      
    ldxdw r5, [r10-0x4f0]                   
    stxdw [r3+0x0], r5                      
    ldxdw r5, [r4+0x0]                      
    mov64 r4, r5                                    r4 = r5
    add64 r4, -32                                   r4 += -32   ///  r4 = r4.wrapping_add(-32 as i32 as i64 as u64)
    mov64 r0, 0                                     r0 = 0 as i32 as i64 as u64
    mov64 r6, 1                                     r6 = 1 as i32 as i64 as u64
    jgt r4, r5, lbb_6994                            if r4 > r5 { pc += 1 }
    mov64 r6, 0                                     r6 = 0 as i32 as i64 as u64
lbb_6994:
    jne r6, 0, lbb_6996                             if r6 != (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r0, r4                                    r0 = r4
lbb_6996:
    lddw r4, 0x300007fe0                            r4 load str located at 12884934624
    jeq r5, 0, lbb_7000                             if r5 == (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r4, r0                                    r4 = r0
lbb_7000:
    lddw r5, 0x300000007                            r5 load str located at 12884901895
    jgt r4, r5, lbb_7004                            if r4 > r5 { pc += 1 }
    ja lbb_6793                                     if true { pc += -211 }
lbb_7004:
    lddw r5, 0x300000000                            r5 load str located at 12884901888
    stxdw [r5+0x0], r4                      
    ldxdw r5, [r10-0x550]                   
    ldxdw r0, [r10-0x548]                   
    ldxdw r6, [r10-0x540]                   
    ldxdw r7, [r10-0x538]                   
    stxdw [r4+0x18], r7                     
    stxdw [r4+0x10], r6                     
    stxdw [r4+0x8], r0                      
    stxdw [r4+0x0], r5                      
    stxdw [r10-0x4d0], r4                   
    stxdw [r10-0x4d8], r3                   
    stxdw [r10-0x4e0], r8                   
    stxdw [r10-0x4e8], r2                   
    mov64 r2, 9                                     r2 = 9 as i32 as i64 as u64
    stxb [r10-0x4f0], r2                    
    mov64 r2, r10                                   r2 = r10
    add64 r2, -1264                                 r2 += -1264   ///  r2 = r2.wrapping_add(-1264 as i32 as i64 as u64)
    call function_26067                     
    ja lbb_7783                                     if true { pc += 758 }
lbb_7025:
    ldxdw r1, [r8+0x0]                      
    add64 r1, 1                                     r1 += 1   ///  r1 = r1.wrapping_add(1 as i32 as i64 as u64)
    stxdw [r8+0x0], r1                      
lbb_7028:
    ldxdw r1, [r10-0x560]                   
    ldxdw r2, [r1+0x0]                      
    add64 r2, -1                                    r2 += -1   ///  r2 = r2.wrapping_add(-1 as i32 as i64 as u64)
    stxdw [r1+0x0], r2                      
lbb_7032:
    exit                                    
lbb_7033:
    ldxdw r4, [r7+0x150]                    
    ldxdw r1, [r4+0x0]                      
    ldxdw r2, [r10-0x530]                   
    jeq r1, r2, lbb_7039                            if r1 == r2 { pc += 2 }
lbb_7037:
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    ja lbb_7049                                     if true { pc += 10 }
lbb_7039:
    ldxdw r1, [r4+0x8]                      
    ldxdw r2, [r10-0x528]                   
    jne r1, r2, lbb_7037                            if r1 != r2 { pc += -5 }
    ldxdw r1, [r4+0x10]                     
    ldxdw r2, [r10-0x520]                   
    jne r1, r2, lbb_7037                            if r1 != r2 { pc += -8 }
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    ldxdw r2, [r4+0x18]                     
    ldxdw r3, [r10-0x518]                   
    jne r2, r3, lbb_7037                            if r2 != r3 { pc += -12 }
lbb_7049:
    stxdw [r10-0x5b8], r4                   
    mov64 r2, 41                                    r2 = 41 as i32 as i64 as u64
    stxdw [r10-0x158], r2                   
    lddw r2, 0x1000600a6 --> b"Token account address derivation mismatchToken acc"        r2 load str located at 4295360678
    stxdw [r10-0x160], r2                   
    jeq r1, 0, lbb_7110                             if r1 == (0 as i32 as i64 as u64) { pc += 54 }
    lddw r1, 0x100064fd0 --> b"\x00\x00\x00\x00p\xfe\x05\x00 \x00\x00\x00\x00\x00\x00\x00a\x01\x00\x00\x…        r1 load str located at 4295380944
    stxdw [r10-0x308], r1                   
    lddw r1, 0x100064c98 --> b"\x00\x00\x00\x00p\xfa\x05\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00…        r1 load str located at 4295380120
    stxdw [r10-0x4f0], r1                   
    mov64 r1, 2                                     r1 = 2 as i32 as i64 as u64
    stxdw [r10-0x4e8], r1                   
    stxdw [r10-0x4d8], r1                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -1056                                 r1 += -1056   ///  r1 = r1.wrapping_add(-1056 as i32 as i64 as u64)
    stxdw [r10-0x4e0], r1                   
    lddw r1, 0x100000888 --> b"y\x11\x00\x00\x00\x00\x00\x00\x85\x10\x00\x00]\xab\x00\x00\x95\x00\x00\x0…        r1 load str located at 4294969480
    stxdw [r10-0x408], r1                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -776                                  r1 += -776   ///  r1 = r1.wrapping_add(-776 as i32 as i64 as u64)
    stxdw [r10-0x410], r1                   
    lddw r1, 0x100000860 --> b"\xbf#\x00\x00\x00\x00\x00\x00y\x12\x08\x00\x00\x00\x00\x00y\x11\x00\x00\x…        r1 load str located at 4294969440
    stxdw [r10-0x418], r1                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -352                                  r1 += -352   ///  r1 = r1.wrapping_add(-352 as i32 as i64 as u64)
    stxdw [r10-0x420], r1                   
    mov64 r6, 0                                     r6 = 0 as i32 as i64 as u64
    stxdw [r10-0x4d0], r6                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -248                                  r1 += -248   ///  r1 = r1.wrapping_add(-248 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -1264                                 r2 += -1264   ///  r2 = r2.wrapping_add(-1264 as i32 as i64 as u64)
    call function_43415                     
    ldxdw r1, [r10-0xf8]                    
    ldxdw r2, [r10-0xe8]                    
    syscall [invalid]                       
    lddw r1, 0x300000000                            r1 load str located at 12884901888
    ldxdw r2, [r1+0x0]                      
    mov64 r3, 1                                     r3 = 1 as i32 as i64 as u64
    mov64 r4, r2                                    r4 = r2
    add64 r4, -32                                   r4 += -32   ///  r4 = r4.wrapping_add(-32 as i32 as i64 as u64)
    jgt r4, r2, lbb_7098                            if r4 > r2 { pc += 1 }
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
lbb_7098:
    ldxdw r1, [r10-0x570]                   
    ldxdw r8, [r10-0x580]                   
    jne r3, 0, lbb_7102                             if r3 != (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r6, r4                                    r6 = r4
lbb_7102:
    lddw r0, 0x300007fe0                            r0 load str located at 12884934624
    jeq r2, 0, lbb_7106                             if r2 == (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r0, r6                                    r0 = r6
lbb_7106:
    lddw r2, 0x300000007                            r2 load str located at 12884901895
    jgt r0, r2, lbb_7635                            if r0 > r2 { pc += 526 }
    ja lbb_6793                                     if true { pc += -317 }
lbb_7110:
    stxdw [r10-0x5c8], r5                   
    mov64 r3, r7                                    r3 = r7
    add64 r3, 288                                   r3 += 288   ///  r3 = r3.wrapping_add(288 as i32 as i64 as u64)
    mov64 r1, r7                                    r1 = r7
    add64 r1, 336                                   r1 += 336   ///  r1 = r1.wrapping_add(336 as i32 as i64 as u64)
    ldxdw r2, [r8+0x18]                     
    stxdw [r10-0x4f8], r2                   
    ldxdw r2, [r8+0x10]                     
    stxdw [r10-0x500], r2                   
    ldxdw r2, [r8+0x8]                      
    stxdw [r10-0x508], r2                   
    ldxdw r2, [r8+0x0]                      
    stxdw [r10-0x510], r2                   
    stxdw [r10-0x5d0], r3                   
    stxdw [r10-0xff0], r3                   
    stxdw [r10-0xfe8], r1                   
    ldxdw r1, [r10-0x5a0]                   
    stxdw [r10-0xff8], r1                   
    ldxdw r1, [r10-0x5a8]                   
    stxdw [r10-0x1000], r1                  
    mov64 r1, r10                                   r1 = r10
    add64 r1, -1264                                 r1 += -1264   ///  r1 = r1.wrapping_add(-1264 as i32 as i64 as u64)
    mov64 r5, r10                                   r5 = r10
    ldxdw r2, [r10-0x578]                   
    ldxdw r3, [r10-0x590]                   
    ldxdw r4, [r10-0x598]                   
    call function_15899                     
    ldxdw r8, [r10-0x4e8]                   
    ldxw r1, [r10-0x448]                    
    jeq r1, 2, lbb_7683                             if r1 == (2 as i32 as i64 as u64) { pc += 543 }
    ldxdw r1, [r8+0x0]                      
    add64 r1, -1                                    r1 += -1   ///  r1 = r1.wrapping_add(-1 as i32 as i64 as u64)
    stxdw [r8+0x0], r1                      
    ldxdw r9, [r7+0x160]                    
    ldxdw r1, [r9+0x10]                     
    lddw r2, 0x7ffffffffffffffe                     r2 load str located at 9223372036854775806
    jgt r1, r2, lbb_7789                            if r1 > r2 { pc += 641 }
    add64 r1, 1                                     r1 += 1   ///  r1 = r1.wrapping_add(1 as i32 as i64 as u64)
    stxdw [r9+0x10], r1                     
    mov64 r8, 3                                     r8 = 3 as i32 as i64 as u64
    ldxdw r1, [r9+0x20]                     
    jne r1, 165, lbb_7161                           if r1 != (165 as i32 as i64 as u64) { pc += 8 }
    ldxdw r2, [r9+0x18]                     
    mov64 r1, r10                                   r1 = r10
    add64 r1, -1264                                 r1 += -1264   ///  r1 = r1.wrapping_add(-1264 as i32 as i64 as u64)
    mov64 r3, 165                                   r3 = 165 as i32 as i64 as u64
    call function_32610                     
    ldxw r8, [r10-0x4f0]                    
    ldxw r1, [r10-0x468]                    
    jne r1, 2, lbb_7188                             if r1 != (2 as i32 as i64 as u64) { pc += 27 }
lbb_7161:
    ldxdw r1, [r10-0x4ec]                   
    stxdw [r10-0x308], r1                   
    ldxdw r1, [r10-0x4e4]                   
    stxdw [r10-0x300], r1                   
    ldxdw r1, [r10-0x4dc]                   
    stxdw [r10-0x2f8], r1                   
    ldxw r1, [r10-0x4d4]                    
    stxw [r10-0xe0], r1                     
    stxw [r10-0x2f0], r1                    
lbb_7170:
    ldxw r1, [r10-0x2f0]                    
    stxw [r10-0x358], r1                    
    ldxdw r2, [r10-0x2f8]                   
    stxdw [r10-0x360], r2                   
    ldxdw r3, [r10-0x300]                   
    stxdw [r10-0x368], r3                   
    ldxdw r4, [r10-0x308]                   
    stxdw [r10-0x370], r4                   
    ldxdw r5, [r10-0x570]                   
    stxw [r5+0x1c], r1                      
    stxdw [r5+0x14], r2                     
    stxdw [r5+0xc], r3                      
    stxdw [r5+0x4], r4                      
    stxw [r5+0x0], r8                       
    ldxdw r1, [r9+0x10]                     
    add64 r1, -1                                    r1 += -1   ///  r1 = r1.wrapping_add(-1 as i32 as i64 as u64)
    stxdw [r9+0x10], r1                     
    ja lbb_7783                                     if true { pc += 595 }
lbb_7188:
    stxdw [r10-0x5a8], r1                   
    stxdw [r10-0x5a0], r6                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -248                                  r1 += -248   ///  r1 = r1.wrapping_add(-248 as i32 as i64 as u64)
    stxdw [r10-0x578], r1                   
    mov64 r2, r10                                   r2 = r10
    add64 r2, -1260                                 r2 += -1260   ///  r2 = r2.wrapping_add(-1260 as i32 as i64 as u64)
    mov64 r3, 104                                   r3 = 104 as i32 as i64 as u64
    call function_48190                     
    ldxdw r1, [r10-0x483]                   
    stxdw [r10-0x180], r1                   
    ldxdw r1, [r10-0x47b]                   
    stxdw [r10-0x178], r1                   
    ldxdw r1, [r10-0x473]                   
    stxdw [r10-0x170], r1                   
    ldxw r1, [r10-0x46c]                    
    stxw [r10-0x169], r1                    
    ldxb r6, [r10-0x484]                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -424                                  r1 += -424   ///  r1 = r1.wrapping_add(-424 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -1124                                 r2 += -1124   ///  r2 = r2.wrapping_add(-1124 as i32 as i64 as u64)
    mov64 r3, 36                                    r3 = 36 as i32 as i64 as u64
    call function_48190                     
    mov64 r1, r10                                   r1 = r10
    add64 r1, -352                                  r1 += -352   ///  r1 = r1.wrapping_add(-352 as i32 as i64 as u64)
    ldxdw r2, [r10-0x578]                   
    mov64 r3, 104                                   r3 = 104 as i32 as i64 as u64
    call function_48190                     
    stxdw [r10-0x578], r6                   
    jne r6, 0, lbb_7221                             if r6 != (0 as i32 as i64 as u64) { pc += 2 }
    mov64 r8, 9                                     r8 = 9 as i32 as i64 as u64
    ja lbb_7170                                     if true { pc += -51 }
lbb_7221:
    mov64 r1, r10                                   r1 = r10
    add64 r1, -776                                  r1 += -776   ///  r1 = r1.wrapping_add(-776 as i32 as i64 as u64)
    stxdw [r10-0x5d8], r1                   
    mov64 r2, r10                                   r2 = r10
    add64 r2, -352                                  r2 += -352   ///  r2 = r2.wrapping_add(-352 as i32 as i64 as u64)
    mov64 r3, 104                                   r3 = 104 as i32 as i64 as u64
    call function_48190                     
    ldxdw r1, [r10-0x180]                   
    stxdw [r10-0x3b3], r1                   
    ldxdw r1, [r10-0x178]                   
    stxdw [r10-0x3ab], r1                   
    ldxdw r1, [r10-0x170]                   
    stxdw [r10-0x3a3], r1                   
    ldxw r1, [r10-0x169]                    
    stxw [r10-0x39c], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -916                                  r1 += -916   ///  r1 = r1.wrapping_add(-916 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -424                                  r2 += -424   ///  r2 = r2.wrapping_add(-424 as i32 as i64 as u64)
    mov64 r3, 36                                    r3 = 36 as i32 as i64 as u64
    call function_48190                     
    mov64 r6, r10                                   r6 = r10
    add64 r6, -880                                  r6 += -880   ///  r6 = r6.wrapping_add(-880 as i32 as i64 as u64)
    mov64 r1, r6                                    r1 = r6
    ldxdw r2, [r10-0x5d8]                   
    mov64 r3, 104                                   r3 = 104 as i32 as i64 as u64
    call function_48190                     
    mov64 r1, r10                                   r1 = r10
    add64 r1, -1052                                 r1 += -1052   ///  r1 = r1.wrapping_add(-1052 as i32 as i64 as u64)
    mov64 r2, r6                                    r2 = r6
    mov64 r3, 104                                   r3 = 104 as i32 as i64 as u64
    call function_48190                     
    ldxdw r1, [r10-0x5a8]                   
    stxw [r10-0x398], r1                    
    ldxdw r1, [r10-0x578]                   
    stxb [r10-0x3b4], r1                    
    stxw [r10-0x420], r8                    
    ldxdw r1, [r9+0x10]                     
    add64 r1, -1                                    r1 += -1   ///  r1 = r1.wrapping_add(-1 as i32 as i64 as u64)
    stxdw [r9+0x10], r1                     
    ldxdw r1, [r10-0x3e0]                   
    jeq r1, 0, lbb_7264                             if r1 == (0 as i32 as i64 as u64) { pc += 1 }
    ja lbb_7737                                     if true { pc += 473 }
lbb_7264:
    ldxdw r1, [r10-0x590]                   
    add64 r1, 32                                    r1 += 32   ///  r1 = r1.wrapping_add(32 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -1296                                 r2 += -1296   ///  r2 = r2.wrapping_add(-1296 as i32 as i64 as u64)
    call function_23846                     
    jne r0, 0, lbb_7271                             if r0 != (0 as i32 as i64 as u64) { pc += 1 }
    ja lbb_7754                                     if true { pc += 483 }
lbb_7271:
    mov64 r1, r10                                   r1 = r10
    add64 r1, -665                                  r1 += -665   ///  r1 = r1.wrapping_add(-665 as i32 as i64 as u64)
    stxdw [r10-0x2e8], r1                   
    mov64 r1, 15                                    r1 = 15 as i32 as i64 as u64
    stxdw [r10-0x300], r1                   
    lddw r1, 0x100060149 --> b"coin_managed_taCoin PDA  mismatch. Expected , got "        r1 load str located at 4295360841
    stxdw [r10-0x308], r1                   
    ldxdw r1, [r10-0x5c8]                   
    stxb [r10-0x299], r1                    
    mov64 r6, 1                                     r6 = 1 as i32 as i64 as u64
    stxdw [r10-0x2e0], r6                   
    mov64 r1, 32                                    r1 = 32 as i32 as i64 as u64
    stxdw [r10-0x2f0], r1                   
    ldxdw r3, [r10-0x5a0]                   
    stxdw [r10-0x2f8], r3                   
    mov64 r2, r10                                   r2 = r10
    add64 r2, -384                                  r2 += -384   ///  r2 = r2.wrapping_add(-384 as i32 as i64 as u64)
    stxdw [r10-0x130], r2                   
    mov64 r2, r10                                   r2 = r10
    add64 r2, -1296                                 r2 += -1296   ///  r2 = r2.wrapping_add(-1296 as i32 as i64 as u64)
    stxdw [r10-0x140], r2                   
    stxdw [r10-0x138], r1                   
    stxdw [r10-0x148], r1                   
    ldxdw r1, [r10-0x598]                   
    stxdw [r10-0x150], r1                   
    mov64 r1, 4                                     r1 = 4 as i32 as i64 as u64
    stxdw [r10-0x158], r1                   
    lddw r1, 0x10005fbb0 --> b"coin\x1c\x00\x00\x00GoodKindkindbids != Some <= x1e-true to No"        r1 load str located at 4295359408
    stxdw [r10-0x160], r1                   
    ldxdw r1, [r10-0x5c0]                   
    stxb [r10-0x180], r1                    
    stxdw [r10-0x128], r6                   
    ldxdw r4, [r7+0x0]                      
    stxdw [r10-0x1a8], r3                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -424                                  r1 += -424   ///  r1 = r1.wrapping_add(-424 as i32 as i64 as u64)
    stxdw [r10-0xff8], r1                   
    stxdw [r10-0xff0], r6                   
    stxdw [r10-0x1000], r3                  
    mov64 r1, r10                                   r1 = r10
    add64 r1, -1264                                 r1 += -1264   ///  r1 = r1.wrapping_add(-1264 as i32 as i64 as u64)
    mov64 r5, r10                                   r5 = r10
    lddw r2, 0x10005ff30 --> b"\x06\xdd\xf6\xe1\xd7e\xa1\x93\xd9\xcb\xe1F\xce\xeby\xac\x1c\xb4\x85\xed_[…        r2 load str located at 4295360304
    ldxdw r3, [r10-0x5b8]                   
    stxdw [r10-0x598], r4                   
    call function_32281                     
    ldxdw r8, [r10-0x4f0]                   
    jeq r8, 0, lbb_7699                             if r8 == (0 as i32 as i64 as u64) { pc += 377 }
    ldxdw r1, [r10-0x4d0]                   
    stxdw [r10-0x358], r1                   
    ldxdw r1, [r10-0x4d8]                   
    stxdw [r10-0x360], r1                   
    ldxdw r1, [r10-0x4e0]                   
    stxdw [r10-0x368], r1                   
    ldxdw r1, [r10-0x4e8]                   
    stxdw [r10-0x370], r1                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -208                                  r1 += -208   ///  r1 = r1.wrapping_add(-208 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -1224                                 r2 += -1224   ///  r2 = r2.wrapping_add(-1224 as i32 as i64 as u64)
    mov64 r3, 40                                    r3 = 40 as i32 as i64 as u64
    call function_48190                     
    stxdw [r10-0xf8], r8                    
    ldxdw r1, [r10-0x370]                   
    stxdw [r10-0xf0], r1                    
    ldxdw r1, [r10-0x368]                   
    stxdw [r10-0xe8], r1                    
    ldxdw r1, [r10-0x360]                   
    stxdw [r10-0xe0], r1                    
    ldxdw r1, [r10-0x358]                   
    stxdw [r10-0xd8], r1                    
    ldxdw r4, [r7+0x158]                    
    ldxdw r1, [r4+0x0]                      
    add64 r1, 1                                     r1 += 1   ///  r1 = r1.wrapping_add(1 as i32 as i64 as u64)
    jeq r1, 0, lbb_7350                             if r1 == (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r6, 0                                     r6 = 0 as i32 as i64 as u64
lbb_7350:
    stxdw [r4+0x0], r1                      
    jne r6, 1, lbb_7354                             if r6 != (1 as i32 as i64 as u64) { pc += 2 }
lbb_7352:
    syscall [invalid]                       
    syscall [invalid]                       
lbb_7354:
    ldxdw r2, [r9+0x0]                      
    add64 r2, 1                                     r2 += 1   ///  r2 = r2.wrapping_add(1 as i32 as i64 as u64)
    stxdw [r9+0x0], r2                      
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    jeq r2, 0, lbb_7360                             if r2 == (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
lbb_7360:
    jne r1, 1, lbb_7362                             if r1 != (1 as i32 as i64 as u64) { pc += 1 }
    ja lbb_7352                                     if true { pc += -10 }
lbb_7362:
    ldxdw r6, [r7+0x8]                      
    ldxdw r1, [r6+0x0]                      
    add64 r1, 1                                     r1 += 1   ///  r1 = r1.wrapping_add(1 as i32 as i64 as u64)
    mov64 r2, 1                                     r2 = 1 as i32 as i64 as u64
    jeq r1, 0, lbb_7368                             if r1 == (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
lbb_7368:
    ldxb r3, [r7+0x17a]                     
    stxdw [r10-0x5a8], r3                   
    ldxb r5, [r7+0x179]                     
    ldxb r0, [r7+0x178]                     
    ldxdw r3, [r7+0x170]                    
    ldxdw r8, [r7+0x168]                    
    stxdw [r6+0x0], r1                      
    jne r2, 1, lbb_7377                             if r2 != (1 as i32 as i64 as u64) { pc += 1 }
    ja lbb_7352                                     if true { pc += -25 }
lbb_7377:
    stxdw [r10-0x590], r8                   
    ldxdw r1, [r7+0x10]                     
    stxdw [r10-0x578], r1                   
    ldxdw r1, [r1+0x0]                      
    add64 r1, 1                                     r1 += 1   ///  r1 = r1.wrapping_add(1 as i32 as i64 as u64)
    mov64 r2, 1                                     r2 = 1 as i32 as i64 as u64
    jeq r1, 0, lbb_7385                             if r1 == (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
lbb_7385:
    ldxdw r8, [r10-0x578]                   
    stxdw [r8+0x0], r1                      
    jne r2, 1, lbb_7389                             if r2 != (1 as i32 as i64 as u64) { pc += 1 }
    ja lbb_7352                                     if true { pc += -37 }
lbb_7389:
    ldxdw r8, [r7+0x128]                    
    ldxdw r1, [r8+0x0]                      
    add64 r1, 1                                     r1 += 1   ///  r1 = r1.wrapping_add(1 as i32 as i64 as u64)
    mov64 r2, 1                                     r2 = 1 as i32 as i64 as u64
    jeq r1, 0, lbb_7395                             if r1 == (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
lbb_7395:
    stxdw [r10-0x5c0], r5                   
    ldxb r5, [r7+0x2a]                      
    stxdw [r10-0x5f0], r5                   
    ldxb r5, [r7+0x29]                      
    stxdw [r10-0x5e8], r5                   
    ldxb r5, [r7+0x28]                      
    stxdw [r10-0x5e0], r5                   
    ldxdw r5, [r7+0x20]                     
    stxdw [r10-0x5d8], r5                   
    ldxdw r5, [r7+0x18]                     
    stxdw [r10-0x5c8], r5                   
    stxdw [r8+0x0], r1                      
    jne r2, 1, lbb_7409                             if r2 != (1 as i32 as i64 as u64) { pc += 1 }
    ja lbb_7352                                     if true { pc += -57 }
lbb_7409:
    ldxdw r5, [r7+0x130]                    
    ldxdw r1, [r5+0x0]                      
    add64 r1, 1                                     r1 += 1   ///  r1 = r1.wrapping_add(1 as i32 as i64 as u64)
    mov64 r2, 1                                     r2 = 1 as i32 as i64 as u64
    jeq r1, 0, lbb_7415                             if r1 == (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
lbb_7415:
    stxdw [r10-0x5f8], r0                   
    stxdw [r5+0x0], r1                      
    jne r2, 1, lbb_7419                             if r2 != (1 as i32 as i64 as u64) { pc += 1 }
    ja lbb_7352                                     if true { pc += -67 }
lbb_7419:
    ldxdw r0, [r7+0x188]                    
    ldxdw r1, [r0+0x0]                      
    add64 r1, 1                                     r1 += 1   ///  r1 = r1.wrapping_add(1 as i32 as i64 as u64)
    mov64 r2, 1                                     r2 = 1 as i32 as i64 as u64
    jeq r1, 0, lbb_7425                             if r1 == (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
lbb_7425:
    stxdw [r10-0x600], r3                   
    ldxb r3, [r7+0x14a]                     
    stxdw [r10-0x628], r3                   
    ldxb r3, [r7+0x149]                     
    stxdw [r10-0x620], r3                   
    ldxb r3, [r7+0x148]                     
    stxdw [r10-0x618], r3                   
    ldxdw r3, [r7+0x140]                    
    stxdw [r10-0x610], r3                   
    ldxdw r3, [r7+0x138]                    
    stxdw [r10-0x608], r3                   
    stxdw [r0+0x0], r1                      
    jne r2, 1, lbb_7439                             if r2 != (1 as i32 as i64 as u64) { pc += 1 }
    ja lbb_7352                                     if true { pc += -87 }
lbb_7439:
    ldxdw r1, [r7+0x190]                    
    ldxdw r2, [r1+0x0]                      
    add64 r2, 1                                     r2 += 1   ///  r2 = r2.wrapping_add(1 as i32 as i64 as u64)
    mov64 r3, 1                                     r3 = 1 as i32 as i64 as u64
    jeq r2, 0, lbb_7445                             if r2 == (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
lbb_7445:
    stxdw [r10-0x640], r8                   
    ldxdw r8, [r10-0x590]                   
    stxdw [r10-0x638], r6                   
    stxdw [r10-0x630], r4                   
    stxdw [r1+0x0], r2                      
    jne r3, 1, lbb_7452                             if r3 != (1 as i32 as i64 as u64) { pc += 1 }
    ja lbb_7352                                     if true { pc += -100 }
lbb_7452:
    ldxdw r2, [r7+0x198]                    
    ldxdw r3, [r7+0x1a0]                    
    ldxb r6, [r7+0x1a8]                     
    ldxb r8, [r7+0x1a9]                     
    ldxb r4, [r7+0x1aa]                     
    stxb [r10-0x436], r4                    
    stxb [r10-0x437], r8                    
    stxb [r10-0x438], r6                    
    stxdw [r10-0x440], r3                   
    stxdw [r10-0x448], r2                   
    stxdw [r10-0x450], r1                   
    stxdw [r10-0x458], r0                   
    ldxdw r1, [r10-0x5b0]                   
    stxdw [r10-0x460], r1                   
    ldxdw r1, [r10-0x628]                   
    stxb [r10-0x466], r1                    
    ldxdw r1, [r10-0x620]                   
    stxb [r10-0x467], r1                    
    ldxdw r1, [r10-0x618]                   
    stxb [r10-0x468], r1                    
    ldxdw r1, [r10-0x610]                   
    stxdw [r10-0x470], r1                   
    ldxdw r1, [r10-0x608]                   
    stxdw [r10-0x478], r1                   
    stxdw [r10-0x480], r5                   
    ldxdw r1, [r10-0x640]                   
    stxdw [r10-0x488], r1                   
    ldxdw r1, [r10-0x5a0]                   
    stxdw [r10-0x490], r1                   
    ldxdw r1, [r10-0x5f0]                   
    stxb [r10-0x496], r1                    
    ldxdw r1, [r10-0x5e8]                   
    stxb [r10-0x497], r1                    
    ldxdw r1, [r10-0x5e0]                   
    stxb [r10-0x498], r1                    
    ldxdw r1, [r10-0x5d8]                   
    stxdw [r10-0x4a0], r1                   
    ldxdw r1, [r10-0x5c8]                   
    stxdw [r10-0x4a8], r1                   
    ldxdw r1, [r10-0x578]                   
    stxdw [r10-0x4b0], r1                   
    ldxdw r1, [r10-0x638]                   
    stxdw [r10-0x4b8], r1                   
    ldxdw r1, [r10-0x598]                   
    stxdw [r10-0x4c0], r1                   
    ldxdw r1, [r10-0x5a8]                   
    stxb [r10-0x4c6], r1                    
    ldxdw r1, [r10-0x5c0]                   
    stxb [r10-0x4c7], r1                    
    ldxdw r1, [r10-0x5f8]                   
    stxb [r10-0x4c8], r1                    
    ldxdw r1, [r10-0x600]                   
    stxdw [r10-0x4d0], r1                   
    ldxdw r1, [r10-0x590]                   
    stxdw [r10-0x4d8], r1                   
    stxdw [r10-0x4e0], r9                   
    ldxdw r1, [r10-0x630]                   
    stxdw [r10-0x4e8], r1                   
    ldxdw r1, [r10-0x5b8]                   
    stxdw [r10-0x4f0], r1                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -352                                  r1 += -352   ///  r1 = r1.wrapping_add(-352 as i32 as i64 as u64)
    stxdw [r10-0x360], r1                   
    mov64 r1, 3                                     r1 = 3 as i32 as i64 as u64
    stxdw [r10-0x368], r1                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -776                                  r1 += -776   ///  r1 = r1.wrapping_add(-776 as i32 as i64 as u64)
    stxdw [r10-0x370], r1                   
    mov64 r1, 4                                     r1 = 4 as i32 as i64 as u64
    stxdw [r10-0x358], r1                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -880                                  r1 += -880   ///  r1 = r1.wrapping_add(-880 as i32 as i64 as u64)
    stxdw [r10-0x1000], r1                  
    mov64 r1, 2                                     r1 = 2 as i32 as i64 as u64
    stxdw [r10-0xff8], r1                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -424                                  r1 += -424   ///  r1 = r1.wrapping_add(-424 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -248                                  r2 += -248   ///  r2 = r2.wrapping_add(-248 as i32 as i64 as u64)
    mov64 r3, r10                                   r3 = r10
    add64 r3, -1264                                 r3 += -1264   ///  r3 = r3.wrapping_add(-1264 as i32 as i64 as u64)
    mov64 r5, r10                                   r5 = r10
    mov64 r4, 4                                     r4 = 4 as i32 as i64 as u64
    call function_40377                     
    ldxw r1, [r10-0x1a8]                    
    jeq r1, 24, lbb_7539                            if r1 == (24 as i32 as i64 as u64) { pc += 1 }
    ja lbb_7713                                     if true { pc += 174 }
lbb_7539:
    mov64 r1, r10                                   r1 = r10
    add64 r1, -1264                                 r1 += -1264   ///  r1 = r1.wrapping_add(-1264 as i32 as i64 as u64)
    call function_369                       
    ldxdw r9, [r10-0x5d0]                   
    mov64 r1, r9                                    r1 = r9
    call function_39132                     
    mov64 r6, r0                                    r6 = r0
    mov64 r1, r10                                   r1 = r10
    add64 r1, -1264                                 r1 += -1264   ///  r1 = r1.wrapping_add(-1264 as i32 as i64 as u64)
    mov64 r2, r9                                    r2 = r9
    call function_39162                     
    ldxw r1, [r10-0x4f0]                    
    ldxdw r8, [r10-0x570]                   
    jeq r1, 24, lbb_7554                            if r1 == (24 as i32 as i64 as u64) { pc += 1 }
    ja lbb_7727                                     if true { pc += 173 }
lbb_7554:
    ldxdw r1, [r10-0x4e0]                   
    ldxdw r2, [r10-0x4e8]                   
    ldxdw r2, [r2+0x0]                      
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
    stxdw [r2+0x0], r3                      
    ldxdw r2, [r1+0x0]                      
    add64 r2, 1                                     r2 += 1   ///  r2 = r2.wrapping_add(1 as i32 as i64 as u64)
    stxdw [r1+0x0], r2                      
    mov64 r1, r10                                   r1 = r10
    add64 r1, -1264                                 r1 += -1264   ///  r1 = r1.wrapping_add(-1264 as i32 as i64 as u64)
    mov64 r2, r7                                    r2 = r7
    call function_39162                     
    ldxw r1, [r10-0x4f0]                    
    jeq r1, 24, lbb_7569                            if r1 == (24 as i32 as i64 as u64) { pc += 1 }
    ja lbb_7727                                     if true { pc += 158 }
lbb_7569:
    ldxdw r1, [r10-0x4e0]                   
    ldxdw r2, [r10-0x4e8]                   
    ldxdw r2, [r2+0x0]                      
    ldxdw r3, [r2+0x0]                      
    add64 r3, r6                                    r3 += r6   ///  r3 = r3.wrapping_add(r6)
    stxdw [r2+0x0], r3                      
    ldxdw r2, [r1+0x0]                      
    add64 r2, 1                                     r2 += 1   ///  r2 = r2.wrapping_add(1 as i32 as i64 as u64)
    stxdw [r1+0x0], r2                      
    mov64 r1, r10                                   r1 = r10
    add64 r1, -1264                                 r1 += -1264   ///  r1 = r1.wrapping_add(-1264 as i32 as i64 as u64)
    mov64 r2, r9                                    r2 = r9
    call function_39192                     
    ldxw r1, [r10-0x4f0]                    
    jeq r1, 24, lbb_7585                            if r1 == (24 as i32 as i64 as u64) { pc += 1 }
    ja lbb_7727                                     if true { pc += 142 }
lbb_7585:
    ldxdw r6, [r10-0x4e0]                   
    ldxdw r1, [r10-0x4e8]                   
    ldxdw r3, [r1+0x8]                      
    jeq r3, 0, lbb_7592                             if r3 == (0 as i32 as i64 as u64) { pc += 3 }
    ldxdw r1, [r1+0x0]                      
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
    call function_48291                     
lbb_7592:
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    stxdw [r10-0x4d0], r1                   
    lddw r1, 0x100065008 --> b"\x00\x00\x00\x00\x00\x03\x06\x00#\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00…        r1 load str located at 4295381000
    stxdw [r10-0x4f0], r1                   
    mov64 r1, 2                                     r1 = 2 as i32 as i64 as u64
    stxdw [r10-0x4e8], r1                   
    stxdw [r10-0x4d8], r1                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -880                                  r1 += -880   ///  r1 = r1.wrapping_add(-880 as i32 as i64 as u64)
    stxdw [r10-0x4e0], r1                   
    lddw r1, 0x1000008a0 --> b"y\x11\x00\x00\x00\x00\x00\x00\x85\x10\x00\x00*\x99\x00\x00\x95\x00\x00\x0…        r1 load str located at 4294969504
    stxdw [r10-0x358], r1                   
    stxdw [r10-0x360], r9                   
    lddw r1, 0x10004d200 --> b"\xbf&\x00\x00\x00\x00\x00\x00y\x12\x00\x00\x00\x00\x00\x00y\x13\x08\x00\x…        r1 load str located at 4295283200
    stxdw [r10-0x368], r1                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -1296                                 r1 += -1296   ///  r1 = r1.wrapping_add(-1296 as i32 as i64 as u64)
    stxdw [r10-0x370], r1                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -424                                  r1 += -424   ///  r1 = r1.wrapping_add(-424 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -1264                                 r2 += -1264   ///  r2 = r2.wrapping_add(-1264 as i32 as i64 as u64)
    call function_445                       
    ldxdw r1, [r10-0x1a8]                   
    ldxdw r2, [r10-0x198]                   
    syscall [invalid]                       
    mov64 r1, 24                                    r1 = 24 as i32 as i64 as u64
    stxw [r8+0x0], r1                       
    ldxdw r1, [r6+0x0]                      
    add64 r1, 1                                     r1 += 1   ///  r1 = r1.wrapping_add(1 as i32 as i64 as u64)
    stxdw [r6+0x0], r1                      
    ldxdw r2, [r10-0x588]                   
    ldxdw r1, [r2+0x0]                      
    add64 r1, -1                                    r1 += -1   ///  r1 = r1.wrapping_add(-1 as i32 as i64 as u64)
    stxdw [r2+0x0], r1                      
    ldxdw r2, [r10-0x580]                   
    ldxdw r1, [r2+0x0]                      
    add64 r1, 1                                     r1 += 1   ///  r1 = r1.wrapping_add(1 as i32 as i64 as u64)
    stxdw [r2+0x0], r1                      
    ja lbb_7028                                     if true { pc += -607 }
lbb_7635:
    lddw r2, 0x300000000                            r2 load str located at 12884901888
    stxdw [r2+0x0], r0                      
    ldxdw r4, [r10-0x5b8]                   
    ldxdw r3, [r4+0x18]                     
    stxdw [r0+0x18], r3                     
    ldxdw r3, [r4+0x10]                     
    stxdw [r0+0x10], r3                     
    ldxdw r3, [r4+0x8]                      
    stxdw [r0+0x8], r3                      
    ldxdw r3, [r4+0x0]                      
    stxdw [r0+0x0], r3                      
    ldxdw r3, [r2+0x0]                      
    mov64 r2, r3                                    r2 = r3
    add64 r2, -32                                   r2 += -32   ///  r2 = r2.wrapping_add(-32 as i32 as i64 as u64)
    mov64 r4, 0                                     r4 = 0 as i32 as i64 as u64
    mov64 r5, 1                                     r5 = 1 as i32 as i64 as u64
    jgt r2, r3, lbb_7654                            if r2 > r3 { pc += 1 }
    mov64 r5, 0                                     r5 = 0 as i32 as i64 as u64
lbb_7654:
    jne r5, 0, lbb_7656                             if r5 != (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r4, r2                                    r4 = r2
lbb_7656:
    lddw r2, 0x300007fe0                            r2 load str located at 12884934624
    jeq r3, 0, lbb_7660                             if r3 == (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r2, r4                                    r2 = r4
lbb_7660:
    lddw r3, 0x300000007                            r3 load str located at 12884901895
    jgt r2, r3, lbb_7664                            if r2 > r3 { pc += 1 }
    ja lbb_6793                                     if true { pc += -871 }
lbb_7664:
    lddw r3, 0x300000000                            r3 load str located at 12884901888
    stxdw [r3+0x0], r2                      
    ldxdw r3, [r10-0x518]                   
    stxdw [r2+0x18], r3                     
    ldxdw r3, [r10-0x520]                   
    stxdw [r2+0x10], r3                     
    ldxdw r3, [r10-0x528]                   
    stxdw [r2+0x8], r3                      
    ldxdw r3, [r10-0x530]                   
    stxdw [r2+0x0], r3                      
    stxdw [r10-0x4e0], r2                   
    stxdw [r10-0x4e8], r0                   
    mov64 r2, 8                                     r2 = 8 as i32 as i64 as u64
    stxb [r10-0x4f0], r2                    
    mov64 r2, r10                                   r2 = r10
    add64 r2, -1264                                 r2 += -1264   ///  r2 = r2.wrapping_add(-1264 as i32 as i64 as u64)
    call function_26067                     
    ja lbb_7784                                     if true { pc += 101 }
lbb_7683:
    ldxdw r7, [r10-0x4f0]                   
    mov64 r6, r10                                   r6 = r10
    add64 r6, -1056                                 r6 += -1056   ///  r6 = r6.wrapping_add(-1056 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -1248                                 r2 += -1248   ///  r2 = r2.wrapping_add(-1248 as i32 as i64 as u64)
    mov64 r1, r6                                    r1 = r6
    mov64 r3, 56                                    r3 = 56 as i32 as i64 as u64
    call function_48190                     
    mov64 r1, r10                                   r1 = r10
    add64 r1, -1248                                 r1 += -1248   ///  r1 = r1.wrapping_add(-1248 as i32 as i64 as u64)
    mov64 r2, r6                                    r2 = r6
    mov64 r3, 56                                    r3 = 56 as i32 as i64 as u64
    call function_48190                     
    stxdw [r10-0x4e8], r8                   
    stxdw [r10-0x4f0], r7                   
    ja lbb_7779                                     if true { pc += 80 }
lbb_7699:
    ldxdw r1, [r10-0x4d0]                   
    stxdw [r10-0x358], r1                   
    ldxdw r2, [r10-0x4d8]                   
    stxdw [r10-0x360], r2                   
    ldxdw r3, [r10-0x4e0]                   
    stxdw [r10-0x368], r3                   
    ldxdw r4, [r10-0x4e8]                   
    stxdw [r10-0x370], r4                   
    ldxdw r5, [r10-0x570]                   
    stxdw [r5+0x18], r1                     
    stxdw [r5+0x10], r2                     
    stxdw [r5+0x8], r3                      
    stxdw [r5+0x0], r4                      
    ja lbb_7783                                     if true { pc += 70 }
lbb_7713:
    ldxw r2, [r10-0x18c]                    
    ldxdw r3, [r10-0x570]                   
    stxw [r3+0x1c], r2                      
    ldxdw r2, [r10-0x194]                   
    stxdw [r3+0x14], r2                     
    ldxdw r2, [r10-0x19c]                   
    stxdw [r3+0xc], r2                      
    ldxdw r2, [r10-0x1a4]                   
    stxdw [r3+0x4], r2                      
    stxw [r3+0x0], r1                       
    mov64 r1, r10                                   r1 = r10
    add64 r1, -1264                                 r1 += -1264   ///  r1 = r1.wrapping_add(-1264 as i32 as i64 as u64)
    call function_369                       
    ja lbb_7783                                     if true { pc += 56 }
lbb_7727:
    ldxw r2, [r10-0x4ec]                    
    ldxdw r3, [r10-0x4e8]                   
    ldxdw r4, [r10-0x4e0]                   
    ldxdw r5, [r10-0x4d8]                   
    stxdw [r8+0x18], r5                     
    stxdw [r8+0x10], r4                     
    stxdw [r8+0x8], r3                      
    stxw [r8+0x4], r2                       
    stxw [r8+0x0], r1                       
    ja lbb_7783                                     if true { pc += 46 }
lbb_7737:
    mov64 r1, r10                                   r1 = r10
    add64 r1, -992                                  r1 += -992   ///  r1 = r1.wrapping_add(-992 as i32 as i64 as u64)
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
    stxdw [r10-0xd8], r2                    
    lddw r2, 0x100065028 --> b"\x00\x00\x00\x00#\x03\x06\x000\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x0…        r2 load str located at 4295381032
    stxdw [r10-0xf8], r2                    
    mov64 r2, 1                                     r2 = 1 as i32 as i64 as u64
    stxdw [r10-0xf0], r2                    
    stxdw [r10-0xe0], r2                    
    mov64 r2, r10                                   r2 = r10
    add64 r2, -352                                  r2 += -352   ///  r2 = r2.wrapping_add(-352 as i32 as i64 as u64)
    stxdw [r10-0xe8], r2                    
    lddw r2, 0x10005df58 --> b"\xbf#\x00\x00\x00\x00\x00\x00y\x11\x00\x00\x00\x00\x00\x00\xb7\x02\x00\x0…        r2 load str located at 4295352152
    stxdw [r10-0x158], r2                   
    ja lbb_7771                                     if true { pc += 17 }
lbb_7754:
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    stxdw [r10-0xd8], r1                    
    mov64 r1, 2                                     r1 = 2 as i32 as i64 as u64
    stxdw [r10-0xf0], r1                    
    lddw r1, 0x100064fe8 --> b"\x00\x00\x00\x00\xdc\x02\x06\x00\x05\x00\x00\x00\x00\x00\x00\x00\x00\x00\…        r1 load str located at 4295380968
    stxdw [r10-0xf8], r1                    
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    stxdw [r10-0xe0], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -352                                  r1 += -352   ///  r1 = r1.wrapping_add(-352 as i32 as i64 as u64)
    stxdw [r10-0xe8], r1                    
    lddw r1, 0x10004d200 --> b"\xbf&\x00\x00\x00\x00\x00\x00y\x12\x00\x00\x00\x00\x00\x00y\x13\x08\x00\x…        r1 load str located at 4295283200
    stxdw [r10-0x158], r1                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -1296                                 r1 += -1296   ///  r1 = r1.wrapping_add(-1296 as i32 as i64 as u64)
lbb_7771:
    stxdw [r10-0x160], r1                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -1256                                 r1 += -1256   ///  r1 = r1.wrapping_add(-1256 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -248                                  r2 += -248   ///  r2 = r2.wrapping_add(-248 as i32 as i64 as u64)
    call function_445                       
    mov64 r1, 29                                    r1 = 29 as i32 as i64 as u64
    stxb [r10-0x4f0], r1                    
lbb_7779:
    mov64 r2, r10                                   r2 = r10
    add64 r2, -1264                                 r2 += -1264   ///  r2 = r2.wrapping_add(-1264 as i32 as i64 as u64)
    ldxdw r1, [r10-0x570]                   
    call function_26067                     
lbb_7783:
    ldxdw r8, [r10-0x580]                   
lbb_7784:
    ldxdw r2, [r10-0x588]                   
    ldxdw r1, [r2+0x0]                      
    add64 r1, -1                                    r1 += -1   ///  r1 = r1.wrapping_add(-1 as i32 as i64 as u64)
    stxdw [r2+0x0], r1                      
    ja lbb_7025                                     if true { pc += -764 }
lbb_7789:
    lddw r1, 0x100065038 --> b"\x00\x00\x00\x00p\xfe\x05\x00 \x00\x00\x00\x00\x00\x00\x00x\x01\x00\x00H\…        r1 load str located at 4295381048
    call function_43759                     
    syscall [invalid]                       

function_7793:
    mov64 r8, r3                                    r8 = r3
    mov64 r5, r2                                    r5 = r2
    mov64 r9, r1                                    r9 = r1
    jne r4, 5, lbb_7846                             if r4 != (5 as i32 as i64 as u64) { pc += 49 }
    ldxb r6, [r8+0x28]                      
    jeq r6, 0, lbb_7820                             if r6 == (0 as i32 as i64 as u64) { pc += 21 }
    mov64 r1, r8                                    r1 = r8
    add64 r1, 48                                    r1 += 48   ///  r1 = r1.wrapping_add(48 as i32 as i64 as u64)
    ldxb r2, [r8+0x58]                      
    jne r2, 0, lbb_7876                             if r2 != (0 as i32 as i64 as u64) { pc += 73 }
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
    stxdw [r10-0x100], r2                   
    mov64 r2, 2                                     r2 = 2 as i32 as i64 as u64
    stxdw [r10-0x118], r2                   
    lddw r2, 0x100065060 --> b"\x00\x00\x00\x00m\x03\x06\x00\x13\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00…        r2 load str located at 4295381088
    stxdw [r10-0x120], r2                   
    mov64 r2, 1                                     r2 = 1 as i32 as i64 as u64
    stxdw [r10-0x108], r2                   
    mov64 r2, r10                                   r2 = r10
    add64 r2, -96                                   r2 += -96   ///  r2 = r2.wrapping_add(-96 as i32 as i64 as u64)
    stxdw [r10-0x110], r2                   
    lddw r2, 0x1000008a0 --> b"y\x11\x00\x00\x00\x00\x00\x00\x85\x10\x00\x00*\x99\x00\x00\x95\x00\x00\x0…        r2 load str located at 4294969504
    stxdw [r10-0x58], r2                    
    stxdw [r10-0x60], r1                    
    ja lbb_7836                                     if true { pc += 16 }
lbb_7820:
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    stxdw [r10-0x100], r1                   
    mov64 r1, 2                                     r1 = 2 as i32 as i64 as u64
    stxdw [r10-0x118], r1                   
    lddw r1, 0x100064cf0 --> b"\x00\x00\x00\x00\xd0\xff\x05\x00\x0e\x00\x00\x00\x00\x00\x00\x00\x00\x00\…        r1 load str located at 4295380208
    stxdw [r10-0x120], r1                   
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    stxdw [r10-0x108], r1                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -96                                   r1 += -96   ///  r1 = r1.wrapping_add(-96 as i32 as i64 as u64)
    stxdw [r10-0x110], r1                   
    lddw r1, 0x1000008a0 --> b"y\x11\x00\x00\x00\x00\x00\x00\x85\x10\x00\x00*\x99\x00\x00\x95\x00\x00\x0…        r1 load str located at 4294969504
    stxdw [r10-0x58], r1                    
    stxdw [r10-0x60], r8                    
lbb_7836:
    mov64 r1, r10                                   r1 = r10
    add64 r1, -368                                  r1 += -368   ///  r1 = r1.wrapping_add(-368 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -288                                  r2 += -288   ///  r2 = r2.wrapping_add(-288 as i32 as i64 as u64)
    call function_43415                     
    ldxdw r1, [r10-0x170]                   
    ldxdw r2, [r10-0x160]                   
    syscall [invalid]                       
    mov64 r1, 7                                     r1 = 7 as i32 as i64 as u64
    ja lbb_7929                                     if true { pc += 83 }
lbb_7846:
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    stxdw [r10-0x150], r1                   
    lddw r1, 0x1000650c0 --> b"\x00\x00\x00\x00\xef\x03\x06\x00'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00…        r1 load str located at 4295381184
    stxdw [r10-0x170], r1                   
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    stxdw [r10-0x168], r1                   
    stxdw [r10-0x158], r1                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -96                                   r1 += -96   ///  r1 = r1.wrapping_add(-96 as i32 as i64 as u64)
    stxdw [r10-0x160], r1                   
    lddw r1, 0x10005df58 --> b"\xbf#\x00\x00\x00\x00\x00\x00y\x11\x00\x00\x00\x00\x00\x00\xb7\x02\x00\x0…        r1 load str located at 4295352152
    stxdw [r10-0x58], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -672                                  r1 += -672   ///  r1 = r1.wrapping_add(-672 as i32 as i64 as u64)
    stxdw [r10-0x60], r1                    
    stxdw [r10-0x2a0], r4                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -280                                  r1 += -280   ///  r1 = r1.wrapping_add(-280 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -368                                  r2 += -368   ///  r2 = r2.wrapping_add(-368 as i32 as i64 as u64)
    call function_43415                     
    mov64 r1, 29                                    r1 = 29 as i32 as i64 as u64
lbb_7870:
    stxb [r10-0x120], r1                    
lbb_7871:
    mov64 r2, r10                                   r2 = r10
    add64 r2, -288                                  r2 += -288   ///  r2 = r2.wrapping_add(-288 as i32 as i64 as u64)
    mov64 r1, r9                                    r1 = r9
    call function_26067                     
    ja lbb_7930                                     if true { pc += 54 }
lbb_7876:
    ldxdw r7, [r8+0xc0]                     
    ldxdw r2, [r7+0x0]                      
    jeq r2, 0, lbb_7881                             if r2 == (0 as i32 as i64 as u64) { pc += 2 }
lbb_7879:
    mov64 r2, 1                                     r2 = 1 as i32 as i64 as u64
    ja lbb_7888                                     if true { pc += 7 }
lbb_7881:
    ldxdw r2, [r7+0x8]                      
    jne r2, 0, lbb_7879                             if r2 != (0 as i32 as i64 as u64) { pc += -4 }
    ldxdw r2, [r7+0x10]                     
    jne r2, 0, lbb_7879                             if r2 != (0 as i32 as i64 as u64) { pc += -6 }
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
    ldxdw r3, [r7+0x18]                     
    jne r3, 0, lbb_7879                             if r3 != (0 as i32 as i64 as u64) { pc += -9 }
lbb_7888:
    mov64 r3, 41                                    r3 = 41 as i32 as i64 as u64
    stxdw [r10-0x298], r3                   
    lddw r3, 0x100060014 --> b"Incorrect system program account providedIncorrect"        r3 load str located at 4295360532
    stxdw [r10-0x2a0], r3                   
    jeq r2, 0, lbb_7931                             if r2 == (0 as i32 as i64 as u64) { pc += 37 }
    lddw r1, 0x100065080 --> b"\x00\x00\x00\x00\x80\x03\x06\x00\x1f\x00\x00\x00\x00\x00\x00\x00$\x00\x00…        r1 load str located at 4295381120
    stxdw [r10-0x2c8], r1                   
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    stxdw [r10-0x100], r1                   
    lddw r1, 0x100064c98 --> b"\x00\x00\x00\x00p\xfa\x05\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00…        r1 load str located at 4295380120
    stxdw [r10-0x120], r1                   
    mov64 r1, 2                                     r1 = 2 as i32 as i64 as u64
    stxdw [r10-0x118], r1                   
    stxdw [r10-0x108], r1                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -368                                  r1 += -368   ///  r1 = r1.wrapping_add(-368 as i32 as i64 as u64)
    stxdw [r10-0x110], r1                   
    lddw r1, 0x100000888 --> b"y\x11\x00\x00\x00\x00\x00\x00\x85\x10\x00\x00]\xab\x00\x00\x95\x00\x00\x0…        r1 load str located at 4294969480
    stxdw [r10-0x158], r1                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -712                                  r1 += -712   ///  r1 = r1.wrapping_add(-712 as i32 as i64 as u64)
    stxdw [r10-0x160], r1                   
    lddw r1, 0x100000860 --> b"\xbf#\x00\x00\x00\x00\x00\x00y\x12\x08\x00\x00\x00\x00\x00y\x11\x00\x00\x…        r1 load str located at 4294969440
    stxdw [r10-0x168], r1                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -672                                  r1 += -672   ///  r1 = r1.wrapping_add(-672 as i32 as i64 as u64)
    stxdw [r10-0x170], r1                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -96                                   r1 += -96   ///  r1 = r1.wrapping_add(-96 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -288                                  r2 += -288   ///  r2 = r2.wrapping_add(-288 as i32 as i64 as u64)
    call function_43415                     
    ldxdw r1, [r10-0x60]                    
    ldxdw r2, [r10-0x50]                    
    syscall [invalid]                       
    mov64 r1, 6                                     r1 = 6 as i32 as i64 as u64
lbb_7929:
    stxw [r9+0x0], r1                       
lbb_7930:
    exit                                    
lbb_7931:
    stxdw [r10-0x2f8], r9                   
    ldxdw r2, [r1+0x0]                      
    mov64 r1, r10                                   r1 = r10
    add64 r1, -368                                  r1 += -368   ///  r1 = r1.wrapping_add(-368 as i32 as i64 as u64)
    stxdw [r10-0x2f0], r2                   
    stxdw [r10-0x300], r5                   
    mov64 r3, r5                                    r3 = r5
    call function_24054                     
    ldxb r9, [r10-0x170]                    
    jne r9, 56, lbb_8655                            if r9 != (56 as i32 as i64 as u64) { pc += 714 }
    ldxdw r1, [r10-0x157]                   
    stxdw [r10-0x48], r1                    
    ldxdw r2, [r10-0x15f]                   
    stxdw [r10-0x50], r2                    
    ldxdw r3, [r10-0x167]                   
    stxdw [r10-0x58], r3                    
    ldxdw r4, [r10-0x16f]                   
    stxdw [r10-0x60], r4                    
    ldxb r0, [r10-0x14f]                    
    stxdw [r10-0x2d0], r1                   
    stxdw [r10-0x2d8], r2                   
    stxdw [r10-0x2e0], r3                   
    stxdw [r10-0x2e8], r4                   
    ldxdw r5, [r8+0x90]                     
    ldxdw r1, [r5+0x0]                      
    jeq r1, r4, lbb_7959                            if r1 == r4 { pc += 2 }
lbb_7957:
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    ja lbb_7969                                     if true { pc += 10 }
lbb_7959:
    ldxdw r1, [r5+0x8]                      
    ldxdw r2, [r10-0x2e0]                   
    jne r1, r2, lbb_7957                            if r1 != r2 { pc += -5 }
    ldxdw r1, [r5+0x10]                     
    ldxdw r2, [r10-0x2d8]                   
    jne r1, r2, lbb_7957                            if r1 != r2 { pc += -8 }
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    ldxdw r2, [r5+0x18]                     
    ldxdw r3, [r10-0x2d0]                   
    jne r2, r3, lbb_7957                            if r2 != r3 { pc += -12 }
lbb_7969:
    stxdw [r10-0x318], r5                   
    mov64 r2, 35                                    r2 = 35 as i32 as i64 as u64
    stxdw [r10-0x2c0], r2                   
    lddw r2, 0x10006039f --> b"Dex PDA address derivation mismatchdexBump mismatc"        r2 load str located at 4295361439
    stxdw [r10-0x2c8], r2                   
    ldxdw r9, [r10-0x2f8]                   
    jeq r1, 0, lbb_8036                             if r1 == (0 as i32 as i64 as u64) { pc += 59 }
    lddw r1, 0x100065098 --> b"\x00\x00\x00\x00\x80\x03\x06\x00\x1f\x00\x00\x00\x00\x00\x00\x00-\x00\x00…        r1 load str located at 4295381144
    stxdw [r10-0x78], r1                    
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    stxdw [r10-0x100], r1                   
    lddw r1, 0x100064c98 --> b"\x00\x00\x00\x00p\xfa\x05\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00…        r1 load str located at 4295380120
    stxdw [r10-0x120], r1                   
    mov64 r1, 2                                     r1 = 2 as i32 as i64 as u64
    stxdw [r10-0x118], r1                   
    stxdw [r10-0x108], r1                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -96                                   r1 += -96   ///  r1 = r1.wrapping_add(-96 as i32 as i64 as u64)
    stxdw [r10-0x110], r1                   
    lddw r1, 0x100000888 --> b"y\x11\x00\x00\x00\x00\x00\x00\x85\x10\x00\x00]\xab\x00\x00\x95\x00\x00\x0…        r1 load str located at 4294969480
    stxdw [r10-0x48], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -120                                  r1 += -120   ///  r1 = r1.wrapping_add(-120 as i32 as i64 as u64)
    stxdw [r10-0x50], r1                    
    lddw r1, 0x100000860 --> b"\xbf#\x00\x00\x00\x00\x00\x00y\x12\x08\x00\x00\x00\x00\x00y\x11\x00\x00\x…        r1 load str located at 4294969440
    stxdw [r10-0x58], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -712                                  r1 += -712   ///  r1 = r1.wrapping_add(-712 as i32 as i64 as u64)
    stxdw [r10-0x60], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -672                                  r1 += -672   ///  r1 = r1.wrapping_add(-672 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -288                                  r2 += -288   ///  r2 = r2.wrapping_add(-288 as i32 as i64 as u64)
    call function_43415                     
    ldxdw r1, [r10-0x2a0]                   
    ldxdw r2, [r10-0x290]                   
    syscall [invalid]                       
    ldxdw r1, [r10-0x2d0]                   
    stxdw [r10-0x158], r1                   
    ldxdw r1, [r10-0x2d8]                   
    stxdw [r10-0x160], r1                   
    ldxdw r1, [r10-0x2e0]                   
    stxdw [r10-0x168], r1                   
    ldxdw r1, [r10-0x2e8]                   
    stxdw [r10-0x170], r1                   
    ldxdw r2, [r10-0x318]                   
    ldxdw r1, [r2+0x0]                      
    stxdw [r10-0x150], r1                   
    ldxdw r1, [r2+0x8]                      
    stxdw [r10-0x148], r1                   
    ldxdw r1, [r2+0x10]                     
    stxdw [r10-0x140], r1                   
    ldxdw r1, [r2+0x18]                     
    stxdw [r10-0x138], r1                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -287                                  r1 += -287   ///  r1 = r1.wrapping_add(-287 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -368                                  r2 += -368   ///  r2 = r2.wrapping_add(-368 as i32 as i64 as u64)
    mov64 r3, 71                                    r3 = 71 as i32 as i64 as u64
    call function_48190                     
    mov64 r1, 18                                    r1 = 18 as i32 as i64 as u64
    ja lbb_7870                                     if true { pc += -166 }
lbb_8036:
    mov64 r9, r8                                    r9 = r8
    add64 r9, 144                                   r9 += 144   ///  r9 = r9.wrapping_add(144 as i32 as i64 as u64)
    ldxdw r1, [r8+0x60]                     
    stxdw [r10-0x310], r1                   
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    stxdw [r10-0x278], r1                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -617                                  r1 += -617   ///  r1 = r1.wrapping_add(-617 as i32 as i64 as u64)
    stxdw [r10-0x280], r1                   
    mov64 r1, 32                                    r1 = 32 as i32 as i64 as u64
    stxdw [r10-0x288], r1                   
    ldxdw r1, [r10-0x2f0]                   
    stxdw [r10-0x290], r1                   
    mov64 r1, 3                                     r1 = 3 as i32 as i64 as u64
    stxdw [r10-0x298], r1                   
    lddw r1, 0x1000603c2 --> b"dexBump mismatch even after validated loadingInval"        r1 load str located at 4295361474
    stxdw [r10-0x2a0], r1                   
    stxdw [r10-0x308], r0                   
    stxb [r10-0x269], r0                    
    mov64 r1, r9                                    r1 = r9
    call function_39132                     
    jne r0, 0, lbb_8400                             if r0 != (0 as i32 as i64 as u64) { pc += 341 }
    mov64 r1, r9                                    r1 = r9
    call function_39148                     
    jeq r0, 0, lbb_8400                             if r0 == (0 as i32 as i64 as u64) { pc += 338 }
    stxdw [r10-0x320], r9                   
    mov64 r1, 8552                                  r1 = 8552 as i32 as i64 as u64
    stxdw [r10-0x178], r1                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -288                                  r1 += -288   ///  r1 = r1.wrapping_add(-288 as i32 as i64 as u64)
    call function_41981                     
    ldxw r1, [r10-0x120]                    
    jeq r1, 24, lbb_8077                            if r1 == (24 as i32 as i64 as u64) { pc += 7 }
    mov64 r0, 55                                    r0 = 55 as i32 as i64 as u64
    ldxdw r5, [r10-0x108]                   
    ldxdw r2, [r10-0x110]                   
    ldxdw r3, [r10-0x118]                   
    ldxw r4, [r10-0x11c]                    
    ldxdw r9, [r10-0x2f8]                   
    ja lbb_8786                                     if true { pc += 709 }
lbb_8077:
    ldxdw r1, [r10-0x118]                   
    mul64 r1, 8680                                  r1 *= 8680   ///  r1 = r1.wrapping_mul(8680 as u64)
    call function_48833                     
    ldxdw r1, [r10-0x110]                   
    mov64 r2, r0                                    r2 = r0
    call function_48576                     
    mov64 r9, r0                                    r9 = r0
    mov64 r1, r9                                    r1 = r9
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
    call function_48350                     
    stxdw [r10-0x330], r0                   
    stxdw [r10-0x328], r9                   
    mov64 r1, r9                                    r1 = r9
    call function_48326                     
    mov64 r9, 0                                     r9 = 0 as i32 as i64 as u64
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    ldxdw r2, [r10-0x330]                   
    jsgt r1, r2, lbb_8096                           if (r1 as i64) > (r2 as i64) { pc += 1 }
    mov64 r9, r0                                    r9 = r0
lbb_8096:
    ldxdw r1, [r10-0x328]                   
    lddw r2, 0x43efffffffffffff                     r2 load str located at 4895412794951729151
    call function_48896                     
    mov64 r4, -1                                    r4 = -1 as i32 as i64 as u64
    jsgt r0, 0, lbb_8103                            if (r0 as i64) > (0 as i32 as i64) { pc += 1 }
    mov64 r4, r9                                    r4 = r9
lbb_8103:
    ldxdw r9, [r8+0x0]                      
    mov64 r1, 8552                                  r1 = 8552 as i32 as i64 as u64
    stxdw [r10-0x1000], r1                  
    ldxdw r1, [r10-0x300]                   
    stxdw [r10-0xff8], r1                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -368                                  r1 += -368   ///  r1 = r1.wrapping_add(-368 as i32 as i64 as u64)
    mov64 r5, r10                                   r5 = r10
    mov64 r2, r9                                    r2 = r9
    ldxdw r3, [r10-0x318]                   
    call function_40993                     
    ldxdw r3, [r8+0x8]                      
    ldxdw r1, [r3+0x0]                      
    add64 r1, 1                                     r1 += 1   ///  r1 = r1.wrapping_add(1 as i32 as i64 as u64)
    mov64 r2, 1                                     r2 = 1 as i32 as i64 as u64
    jeq r1, 0, lbb_8120                             if r1 == (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
lbb_8120:
    stxdw [r3+0x0], r1                      
    jne r2, 1, lbb_8124                             if r2 != (1 as i32 as i64 as u64) { pc += 2 }
lbb_8122:
    syscall [invalid]                       
    syscall [invalid]                       
lbb_8124:
    ldxdw r0, [r8+0x10]                     
    ldxdw r1, [r0+0x0]                      
    add64 r1, 1                                     r1 += 1   ///  r1 = r1.wrapping_add(1 as i32 as i64 as u64)
    mov64 r2, 1                                     r2 = 1 as i32 as i64 as u64
    jeq r1, 0, lbb_8130                             if r1 == (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
lbb_8130:
    stxdw [r0+0x0], r1                      
    jne r2, 1, lbb_8133                             if r2 != (1 as i32 as i64 as u64) { pc += 1 }
    ja lbb_8122                                     if true { pc += -11 }
lbb_8133:
    ldxdw r4, [r8+0x98]                     
    ldxdw r1, [r4+0x0]                      
    add64 r1, 1                                     r1 += 1   ///  r1 = r1.wrapping_add(1 as i32 as i64 as u64)
    mov64 r2, 1                                     r2 = 1 as i32 as i64 as u64
    jeq r1, 0, lbb_8139                             if r1 == (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
lbb_8139:
    ldxb r5, [r8+0x2a]                      
    stxdw [r10-0x340], r5                   
    ldxb r5, [r8+0x29]                      
    stxdw [r10-0x338], r5                   
    ldxdw r5, [r8+0x20]                     
    stxdw [r10-0x330], r5                   
    ldxdw r5, [r8+0x18]                     
    stxdw [r10-0x328], r5                   
    stxdw [r4+0x0], r1                      
    jne r2, 1, lbb_8150                             if r2 != (1 as i32 as i64 as u64) { pc += 1 }
    ja lbb_8122                                     if true { pc += -28 }
lbb_8150:
    ldxdw r5, [r8+0xa0]                     
    ldxdw r1, [r5+0x0]                      
    add64 r1, 1                                     r1 += 1   ///  r1 = r1.wrapping_add(1 as i32 as i64 as u64)
    mov64 r2, 1                                     r2 = 1 as i32 as i64 as u64
    jeq r1, 0, lbb_8156                             if r1 == (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
lbb_8156:
    stxdw [r10-0x350], r4                   
    stxdw [r10-0x348], r9                   
    stxdw [r5+0x0], r1                      
    jne r2, 1, lbb_8161                             if r2 != (1 as i32 as i64 as u64) { pc += 1 }
    ja lbb_8122                                     if true { pc += -39 }
lbb_8161:
    ldxdw r4, [r8+0xc8]                     
    ldxdw r1, [r4+0x0]                      
    add64 r1, 1                                     r1 += 1   ///  r1 = r1.wrapping_add(1 as i32 as i64 as u64)
    mov64 r9, 1                                     r9 = 1 as i32 as i64 as u64
    jeq r1, 0, lbb_8167                             if r1 == (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r9, 0                                     r9 = 0 as i32 as i64 as u64
lbb_8167:
    ldxb r2, [r8+0xba]                      
    stxdw [r10-0x378], r2                   
    ldxb r2, [r8+0xb9]                      
    stxdw [r10-0x370], r2                   
    ldxb r2, [r8+0xb8]                      
    stxdw [r10-0x368], r2                   
    ldxdw r2, [r8+0xb0]                     
    stxdw [r10-0x360], r2                   
    ldxdw r2, [r8+0xa8]                     
    stxdw [r10-0x358], r2                   
    stxdw [r4+0x0], r1                      
    jne r9, 1, lbb_8180                             if r9 != (1 as i32 as i64 as u64) { pc += 1 }
    ja lbb_8122                                     if true { pc += -58 }
lbb_8180:
    ldxdw r1, [r8+0xd0]                     
    ldxdw r9, [r1+0x0]                      
    add64 r9, 1                                     r9 += 1   ///  r9 = r9.wrapping_add(1 as i32 as i64 as u64)
    mov64 r2, 1                                     r2 = 1 as i32 as i64 as u64
    jeq r9, 0, lbb_8186                             if r9 == (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
lbb_8186:
    stxdw [r10-0x388], r0                   
    stxdw [r10-0x380], r3                   
    stxdw [r1+0x0], r9                      
    jne r2, 1, lbb_8191                             if r2 != (1 as i32 as i64 as u64) { pc += 1 }
    ja lbb_8122                                     if true { pc += -69 }
lbb_8191:
    ldxdw r2, [r8+0xd8]                     
    ldxdw r9, [r8+0xe0]                     
    ldxb r0, [r8+0xe8]                      
    ldxb r3, [r8+0xe9]                      
    ldxb r8, [r8+0xea]                      
    stxb [r10-0x96], r8                     
    stxb [r10-0x97], r3                     
    stxb [r10-0x98], r0                     
    stxdw [r10-0xa0], r9                    
    stxdw [r10-0xa8], r2                    
    stxdw [r10-0xb0], r1                    
    stxdw [r10-0xb8], r4                    
    stxdw [r10-0xc0], r7                    
    ldxdw r1, [r10-0x378]                   
    stxb [r10-0xc6], r1                     
    ldxdw r1, [r10-0x370]                   
    stxb [r10-0xc7], r1                     
    ldxdw r1, [r10-0x368]                   
    stxb [r10-0xc8], r1                     
    ldxdw r1, [r10-0x360]                   
    stxdw [r10-0xd0], r1                    
    ldxdw r1, [r10-0x358]                   
    stxdw [r10-0xd8], r1                    
    stxdw [r10-0xe0], r5                    
    ldxdw r1, [r10-0x350]                   
    stxdw [r10-0xe8], r1                    
    ldxdw r1, [r10-0x318]                   
    stxdw [r10-0xf0], r1                    
    ldxdw r1, [r10-0x340]                   
    stxb [r10-0xf6], r1                     
    ldxdw r1, [r10-0x338]                   
    stxb [r10-0xf7], r1                     
    stxb [r10-0xf8], r6                     
    ldxdw r1, [r10-0x330]                   
    stxdw [r10-0x100], r1                   
    ldxdw r1, [r10-0x328]                   
    stxdw [r10-0x108], r1                   
    ldxdw r1, [r10-0x388]                   
    stxdw [r10-0x110], r1                   
    ldxdw r1, [r10-0x380]                   
    stxdw [r10-0x118], r1                   
    ldxdw r1, [r10-0x348]                   
    stxdw [r10-0x120], r1                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -672                                  r1 += -672   ///  r1 = r1.wrapping_add(-672 as i32 as i64 as u64)
    stxdw [r10-0x90], r1                    
    mov64 r1, 3                                     r1 = 3 as i32 as i64 as u64
    stxdw [r10-0x88], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -144                                  r1 += -144   ///  r1 = r1.wrapping_add(-144 as i32 as i64 as u64)
    stxdw [r10-0x1000], r1                  
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    stxdw [r10-0xff8], r1                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -96                                   r1 += -96   ///  r1 = r1.wrapping_add(-96 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -368                                  r2 += -368   ///  r2 = r2.wrapping_add(-368 as i32 as i64 as u64)
    mov64 r3, r10                                   r3 = r10
    add64 r3, -288                                  r3 += -288   ///  r3 = r3.wrapping_add(-288 as i32 as i64 as u64)
    mov64 r5, r10                                   r5 = r10
    mov64 r4, 3                                     r4 = 3 as i32 as i64 as u64
    call function_40377                     
    ldxw r1, [r10-0x60]                     
    jne r1, 24, lbb_8726                            if r1 != (24 as i32 as i64 as u64) { pc += 471 }
    ldxdw r1, [r10-0x110]                   
    ldxdw r2, [r10-0x118]                   
    ldxdw r3, [r2+0x0]                      
    add64 r3, -1                                    r3 += -1   ///  r3 = r3.wrapping_add(-1 as i32 as i64 as u64)
    stxdw [r2+0x0], r3                      
    ldxdw r9, [r10-0x2f8]                   
    jne r3, 0, lbb_8265                             if r3 != (0 as i32 as i64 as u64) { pc += 3 }
    ldxdw r3, [r2+0x8]                      
    add64 r3, -1                                    r3 += -1   ///  r3 = r3.wrapping_add(-1 as i32 as i64 as u64)
    stxdw [r2+0x8], r3                      
lbb_8265:
    ldxdw r2, [r1+0x0]                      
    add64 r2, -1                                    r2 += -1   ///  r2 = r2.wrapping_add(-1 as i32 as i64 as u64)
    stxdw [r1+0x0], r2                      
    ldxdw r8, [r10-0x320]                   
    jne r2, 0, lbb_8273                             if r2 != (0 as i32 as i64 as u64) { pc += 3 }
    ldxdw r2, [r1+0x8]                      
    add64 r2, -1                                    r2 += -1   ///  r2 = r2.wrapping_add(-1 as i32 as i64 as u64)
    stxdw [r1+0x8], r2                      
lbb_8273:
    ldxdw r1, [r10-0xe0]                    
    ldxdw r2, [r10-0xe8]                    
    ldxdw r3, [r2+0x0]                      
    add64 r3, -1                                    r3 += -1   ///  r3 = r3.wrapping_add(-1 as i32 as i64 as u64)
    stxdw [r2+0x0], r3                      
    jne r3, 0, lbb_8282                             if r3 != (0 as i32 as i64 as u64) { pc += 3 }
    ldxdw r3, [r2+0x8]                      
    add64 r3, -1                                    r3 += -1   ///  r3 = r3.wrapping_add(-1 as i32 as i64 as u64)
    stxdw [r2+0x8], r3                      
lbb_8282:
    ldxdw r2, [r1+0x0]                      
    add64 r2, -1                                    r2 += -1   ///  r2 = r2.wrapping_add(-1 as i32 as i64 as u64)
    stxdw [r1+0x0], r2                      
    jne r2, 0, lbb_8289                             if r2 != (0 as i32 as i64 as u64) { pc += 3 }
    ldxdw r2, [r1+0x8]                      
    add64 r2, -1                                    r2 += -1   ///  r2 = r2.wrapping_add(-1 as i32 as i64 as u64)
    stxdw [r1+0x8], r2                      
lbb_8289:
    ldxdw r1, [r10-0xb0]                    
    ldxdw r2, [r10-0xb8]                    
    ldxdw r3, [r2+0x0]                      
    add64 r3, -1                                    r3 += -1   ///  r3 = r3.wrapping_add(-1 as i32 as i64 as u64)
    stxdw [r2+0x0], r3                      
    jne r3, 0, lbb_8298                             if r3 != (0 as i32 as i64 as u64) { pc += 3 }
    ldxdw r3, [r2+0x8]                      
    add64 r3, -1                                    r3 += -1   ///  r3 = r3.wrapping_add(-1 as i32 as i64 as u64)
    stxdw [r2+0x8], r3                      
lbb_8298:
    ldxdw r2, [r1+0x0]                      
    add64 r2, -1                                    r2 += -1   ///  r2 = r2.wrapping_add(-1 as i32 as i64 as u64)
    stxdw [r1+0x0], r2                      
    jne r2, 0, lbb_8305                             if r2 != (0 as i32 as i64 as u64) { pc += 3 }
    ldxdw r2, [r1+0x8]                      
    add64 r2, -1                                    r2 += -1   ///  r2 = r2.wrapping_add(-1 as i32 as i64 as u64)
    stxdw [r1+0x8], r2                      
lbb_8305:
    mov64 r1, r10                                   r1 = r10
    add64 r1, -288                                  r1 += -288   ///  r1 = r1.wrapping_add(-288 as i32 as i64 as u64)
    mov64 r2, r8                                    r2 = r8
    call function_39192                     
    ldxw r1, [r10-0x120]                    
    jeq r1, 24, lbb_8312                            if r1 == (24 as i32 as i64 as u64) { pc += 1 }
    ja lbb_8781                                     if true { pc += 469 }
lbb_8312:
    ldxdw r6, [r10-0x110]                   
    ldxdw r7, [r10-0x118]                   
    ldxdw r3, [r7+0x8]                      
    ldxdw r1, [r10-0x178]                   
    jeq r3, r1, lbb_8361                            if r3 == r1 { pc += 44 }
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    stxdw [r10-0x40], r1                    
    lddw r1, 0x1000656d8 --> b"\x00\x00\x00\x00\x80\x09\x06\x00\x08\x00\x00\x00\x00\x00\x00\x00\x00\x00\…        r1 load str located at 4295382744
    stxdw [r10-0x60], r1                    
    mov64 r1, 3                                     r1 = 3 as i32 as i64 as u64
    stxdw [r10-0x58], r1                    
    stxdw [r10-0x48], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -288                                  r1 += -288   ///  r1 = r1.wrapping_add(-288 as i32 as i64 as u64)
    stxdw [r10-0x50], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -376                                  r1 += -376   ///  r1 = r1.wrapping_add(-376 as i32 as i64 as u64)
    stxdw [r10-0x100], r1                   
    lddw r1, 0x10005df58 --> b"\xbf#\x00\x00\x00\x00\x00\x00y\x11\x00\x00\x00\x00\x00\x00\xb7\x02\x00\x0…        r1 load str located at 4295352152
    stxdw [r10-0xf8], r1                    
    stxdw [r10-0x108], r1                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -144                                  r1 += -144   ///  r1 = r1.wrapping_add(-144 as i32 as i64 as u64)
    stxdw [r10-0x110], r1                   
    lddw r1, 0x1000008a0 --> b"y\x11\x00\x00\x00\x00\x00\x00\x85\x10\x00\x00*\x99\x00\x00\x95\x00\x00\x0…        r1 load str located at 4294969504
    stxdw [r10-0x118], r1                   
    stxdw [r10-0x120], r8                   
    stxdw [r10-0x90], r3                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -120                                  r1 += -120   ///  r1 = r1.wrapping_add(-120 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -96                                   r2 += -96   ///  r2 = r2.wrapping_add(-96 as i32 as i64 as u64)
    call function_445                       
    ldxw r1, [r10-0x7e]                     
    stxw [r10-0x2a8], r1                    
    ldxh r1, [r10-0x7a]                     
    stxh [r10-0x2a4], r1                    
    ldxdw r5, [r6+0x0]                      
    add64 r5, 1                                     r5 += 1   ///  r5 = r5.wrapping_add(1 as i32 as i64 as u64)
    ldxw r1, [r10-0x78]                     
    ldxw r4, [r10-0x74]                     
    ldxdw r3, [r10-0x70]                    
    ldxdw r2, [r10-0x68]                    
    stxdw [r6+0x0], r5                      
    mov64 r0, 29                                    r0 = 29 as i32 as i64 as u64
    ja lbb_8786                                     if true { pc += 425 }
lbb_8361:
    mov64 r8, 2                                     r8 = 2 as i32 as i64 as u64
    jeq r3, 0, lbb_8373                             if r3 == (0 as i32 as i64 as u64) { pc += 10 }
    ldxdw r1, [r7+0x0]                      
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
    call function_48291                     
    ldxdw r1, [r7+0x8]                      
    jne r1, 8552, lbb_8373                          if r1 != (8552 as i32 as i64 as u64) { pc += 5 }
    ldxdw r1, [r7+0x0]                      
    mov64 r2, r1                                    r2 = r1
    and64 r2, 7                                     r2 &= 7   ///  r2 = r2.and(7)
    mov64 r8, 0                                     r8 = 0 as i32 as i64 as u64
    jeq r2, 0, lbb_8376                             if r2 == (0 as i32 as i64 as u64) { pc += 3 }
lbb_8373:
    mov64 r1, r8                                    r1 = r8
    call function_1069                      
    syscall [invalid]                       
lbb_8376:
    ldxdw r3, [r10-0x2f0]                   
    ldxdw r2, [r3+0x18]                     
    stxdw [r1+0x20], r2                     
    ldxdw r2, [r3+0x10]                     
    stxdw [r1+0x18], r2                     
    ldxdw r2, [r3+0x8]                      
    stxdw [r1+0x10], r2                     
    ldxdw r2, [r3+0x0]                      
    stxdw [r1+0x8], r2                      
    ldxdw r3, [r10-0x310]                   
    ldxdw r2, [r3+0x0]                      
    stxdw [r1+0x28], r2                     
    ldxdw r2, [r3+0x8]                      
    stxdw [r1+0x30], r2                     
    ldxdw r2, [r3+0x10]                     
    stxdw [r1+0x38], r2                     
    ldxdw r2, [r3+0x18]                     
    stxdw [r1+0x40], r2                     
    ldxdw r2, [r10-0x308]                   
    stxb [r1+0x214c], r2                    
    ldxdw r1, [r6+0x0]                      
    add64 r1, 1                                     r1 += 1   ///  r1 = r1.wrapping_add(1 as i32 as i64 as u64)
    stxdw [r6+0x0], r1                      
    ldxdw r9, [r10-0x320]                   
lbb_8400:
    mov64 r1, r10                                   r1 = r10
    add64 r1, -368                                  r1 += -368   ///  r1 = r1.wrapping_add(-368 as i32 as i64 as u64)
    ldxdw r2, [r10-0x300]                   
    mov64 r3, r9                                    r3 = r9
    call function_16885                     
    ldxb r6, [r10-0x170]                    
    jeq r6, 56, lbb_8408                            if r6 == (56 as i32 as i64 as u64) { pc += 1 }
    ja lbb_8681                                     if true { pc += 273 }
lbb_8408:
    ldxdw r7, [r10-0x160]                   
    ldxdw r3, [r10-0x168]                   
    ldxdw r1, [r10-0x308]                   
    ldxb r2, [r3+0x214c]                    
    ldxdw r9, [r10-0x2f8]                   
    jeq r2, r1, lbb_8415                            if r2 == r1 { pc += 1 }
    ja lbb_8703                                     if true { pc += 288 }
lbb_8415:
    mov64 r2, r3                                    r2 = r3
    add64 r2, 8                                     r2 += 8   ///  r2 = r2.wrapping_add(8 as i32 as i64 as u64)
    ldxdw r1, [r10-0x2f0]                   
    ldxdw r1, [r1+0x0]                      
    ldxdw r4, [r3+0x8]                      
    jeq r4, r1, lbb_8423                            if r4 == r1 { pc += 2 }
lbb_8421:
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    ja lbb_8436                                     if true { pc += 13 }
lbb_8423:
    ldxdw r1, [r10-0x2f0]                   
    ldxdw r1, [r1+0x8]                      
    ldxdw r4, [r2+0x8]                      
    jne r4, r1, lbb_8421                            if r4 != r1 { pc += -6 }
    ldxdw r1, [r10-0x2f0]                   
    ldxdw r1, [r1+0x10]                     
    ldxdw r4, [r2+0x10]                     
    jne r4, r1, lbb_8421                            if r4 != r1 { pc += -10 }
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    ldxdw r4, [r10-0x2f0]                   
    ldxdw r4, [r4+0x18]                     
    ldxdw r5, [r2+0x18]                     
    jne r5, r4, lbb_8421                            if r5 != r4 { pc += -15 }
lbb_8436:
    ldxdw r6, [r10-0x310]                   
    jeq r1, 0, lbb_8439                             if r1 == (0 as i32 as i64 as u64) { pc += 1 }
    ja lbb_8461                                     if true { pc += 22 }
lbb_8439:
    ldxdw r1, [r6+0x0]                      
    ldxdw r4, [r3+0x28]                     
    jeq r4, r1, lbb_8444                            if r4 == r1 { pc += 2 }
lbb_8442:
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    ja lbb_8454                                     if true { pc += 10 }
lbb_8444:
    ldxdw r1, [r6+0x8]                      
    ldxdw r4, [r3+0x30]                     
    jne r4, r1, lbb_8442                            if r4 != r1 { pc += -5 }
    ldxdw r1, [r6+0x10]                     
    ldxdw r4, [r3+0x38]                     
    jne r4, r1, lbb_8442                            if r4 != r1 { pc += -8 }
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    ldxdw r4, [r6+0x18]                     
    ldxdw r5, [r3+0x40]                     
    jne r5, r4, lbb_8442                            if r5 != r4 { pc += -12 }
lbb_8454:
    jne r1, 0, lbb_8461                             if r1 != (0 as i32 as i64 as u64) { pc += 6 }
    mov64 r1, 24                                    r1 = 24 as i32 as i64 as u64
    stxw [r9+0x0], r1                       
lbb_8457:
    ldxdw r1, [r7+0x0]                      
    add64 r1, -1                                    r1 += -1   ///  r1 = r1.wrapping_add(-1 as i32 as i64 as u64)
    stxdw [r7+0x0], r1                      
    ja lbb_7930                                     if true { pc += -531 }
lbb_8461:
    ldxdw r4, [r10-0x318]                   
    ldxdw r1, [r4+0x18]                     
    stxdw [r10-0x108], r1                   
    ldxdw r1, [r4+0x10]                     
    stxdw [r10-0x110], r1                   
    ldxdw r1, [r4+0x8]                      
    stxdw [r10-0x118], r1                   
    ldxdw r1, [r4+0x0]                      
    stxdw [r10-0x120], r1                   
    lddw r1, 0x300000000                            r1 load str located at 12884901888
    ldxdw r4, [r1+0x0]                      
    mov64 r1, r4                                    r1 = r4
    add64 r1, -32                                   r1 += -32   ///  r1 = r1.wrapping_add(-32 as i32 as i64 as u64)
    mov64 r5, 0                                     r5 = 0 as i32 as i64 as u64
    mov64 r0, 1                                     r0 = 1 as i32 as i64 as u64
    jgt r1, r4, lbb_8479                            if r1 > r4 { pc += 1 }
    mov64 r0, 0                                     r0 = 0 as i32 as i64 as u64
lbb_8479:
    jne r0, 0, lbb_8481                             if r0 != (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r5, r1                                    r5 = r1
lbb_8481:
    lddw r1, 0x300007fe0                            r1 load str located at 12884934624
    jeq r4, 0, lbb_8485                             if r4 == (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r1, r5                                    r1 = r5
lbb_8485:
    lddw r4, 0x300000007                            r4 load str located at 12884901895
    jgt r1, r4, lbb_8492                            if r1 > r4 { pc += 4 }
lbb_8488:
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    mov64 r2, 32                                    r2 = 32 as i32 as i64 as u64
    call function_43400                     
    syscall [invalid]                       
lbb_8492:
    lddw r4, 0x300000000                            r4 load str located at 12884901888
    stxdw [r4+0x0], r1                      
    ldxdw r5, [r10-0x108]                   
    stxdw [r1+0x18], r5                     
    ldxdw r5, [r10-0x110]                   
    stxdw [r1+0x10], r5                     
    ldxdw r5, [r10-0x118]                   
    stxdw [r1+0x8], r5                      
    ldxdw r5, [r10-0x120]                   
    stxdw [r1+0x0], r5                      
    ldxdw r5, [r3+0x40]                     
    stxdw [r10-0x108], r5                   
    ldxdw r5, [r3+0x38]                     
    stxdw [r10-0x110], r5                   
    ldxdw r5, [r3+0x30]                     
    stxdw [r10-0x118], r5                   
    ldxdw r3, [r3+0x28]                     
    stxdw [r10-0x120], r3                   
    ldxdw r4, [r4+0x0]                      
    mov64 r5, 0                                     r5 = 0 as i32 as i64 as u64
    mov64 r0, 1                                     r0 = 1 as i32 as i64 as u64
    mov64 r3, r4                                    r3 = r4
    add64 r3, -32                                   r3 += -32   ///  r3 = r3.wrapping_add(-32 as i32 as i64 as u64)
    jgt r3, r4, lbb_8518                            if r3 > r4 { pc += 1 }
    mov64 r0, 0                                     r0 = 0 as i32 as i64 as u64
lbb_8518:
    jne r0, 0, lbb_8520                             if r0 != (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r5, r3                                    r5 = r3
lbb_8520:
    lddw r3, 0x300007fe0                            r3 load str located at 12884934624
    jeq r4, 0, lbb_8524                             if r4 == (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r3, r5                                    r3 = r5
lbb_8524:
    lddw r4, 0x300000007                            r4 load str located at 12884901895
    jgt r3, r4, lbb_8528                            if r3 > r4 { pc += 1 }
    ja lbb_8488                                     if true { pc += -40 }
lbb_8528:
    lddw r4, 0x300000000                            r4 load str located at 12884901888
    stxdw [r4+0x0], r3                      
    ldxdw r5, [r10-0x108]                   
    stxdw [r3+0x18], r5                     
    ldxdw r5, [r10-0x110]                   
    stxdw [r3+0x10], r5                     
    ldxdw r5, [r10-0x118]                   
    stxdw [r3+0x8], r5                      
    ldxdw r5, [r10-0x120]                   
    stxdw [r3+0x0], r5                      
    ldxdw r5, [r2+0x18]                     
    stxdw [r10-0x108], r5                   
    ldxdw r5, [r2+0x10]                     
    stxdw [r10-0x110], r5                   
    ldxdw r5, [r2+0x8]                      
    stxdw [r10-0x118], r5                   
    ldxdw r2, [r2+0x0]                      
    stxdw [r10-0x120], r2                   
    ldxdw r4, [r4+0x0]                      
    mov64 r5, 0                                     r5 = 0 as i32 as i64 as u64
    mov64 r0, 1                                     r0 = 1 as i32 as i64 as u64
    mov64 r2, r4                                    r2 = r4
    add64 r2, -32                                   r2 += -32   ///  r2 = r2.wrapping_add(-32 as i32 as i64 as u64)
    jgt r2, r4, lbb_8554                            if r2 > r4 { pc += 1 }
    mov64 r0, 0                                     r0 = 0 as i32 as i64 as u64
lbb_8554:
    jne r0, 0, lbb_8556                             if r0 != (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r5, r2                                    r5 = r2
lbb_8556:
    lddw r2, 0x300007fe0                            r2 load str located at 12884934624
    jeq r4, 0, lbb_8560                             if r4 == (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r2, r5                                    r2 = r5
lbb_8560:
    lddw r4, 0x300000007                            r4 load str located at 12884901895
    jgt r2, r4, lbb_8564                            if r2 > r4 { pc += 1 }
    ja lbb_8488                                     if true { pc += -76 }
lbb_8564:
    lddw r4, 0x300000000                            r4 load str located at 12884901888
    stxdw [r4+0x0], r2                      
    ldxdw r5, [r10-0x108]                   
    stxdw [r2+0x18], r5                     
    ldxdw r5, [r10-0x110]                   
    stxdw [r2+0x10], r5                     
    ldxdw r5, [r10-0x118]                   
    stxdw [r2+0x8], r5                      
    ldxdw r5, [r10-0x120]                   
    stxdw [r2+0x0], r5                      
    ldxdw r5, [r6+0x18]                     
    stxdw [r10-0x108], r5                   
    ldxdw r5, [r6+0x10]                     
    stxdw [r10-0x110], r5                   
    ldxdw r5, [r6+0x8]                      
    stxdw [r10-0x118], r5                   
    ldxdw r5, [r6+0x0]                      
    stxdw [r10-0x120], r5                   
    ldxdw r5, [r4+0x0]                      
    mov64 r0, 0                                     r0 = 0 as i32 as i64 as u64
    mov64 r6, 1                                     r6 = 1 as i32 as i64 as u64
    mov64 r4, r5                                    r4 = r5
    add64 r4, -32                                   r4 += -32   ///  r4 = r4.wrapping_add(-32 as i32 as i64 as u64)
    jgt r4, r5, lbb_8590                            if r4 > r5 { pc += 1 }
    mov64 r6, 0                                     r6 = 0 as i32 as i64 as u64
lbb_8590:
    jne r6, 0, lbb_8592                             if r6 != (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r0, r4                                    r0 = r4
lbb_8592:
    lddw r4, 0x300007fe0                            r4 load str located at 12884934624
    jeq r5, 0, lbb_8596                             if r5 == (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r4, r0                                    r4 = r0
lbb_8596:
    lddw r5, 0x300000007                            r5 load str located at 12884901895
    jgt r4, r5, lbb_8600                            if r4 > r5 { pc += 1 }
    ja lbb_8488                                     if true { pc += -112 }
lbb_8600:
    lddw r5, 0x300000000                            r5 load str located at 12884901888
    stxdw [r5+0x0], r4                      
    ldxdw r0, [r10-0x108]                   
    stxdw [r4+0x18], r0                     
    ldxdw r0, [r10-0x110]                   
    stxdw [r4+0x10], r0                     
    ldxdw r0, [r10-0x118]                   
    stxdw [r4+0x8], r0                      
    ldxdw r0, [r10-0x120]                   
    stxdw [r4+0x0], r0                      
    ldxdw r6, [r10-0x2f0]                   
    ldxdw r0, [r6+0x18]                     
    stxdw [r10-0x158], r0                   
    ldxdw r0, [r6+0x10]                     
    stxdw [r10-0x160], r0                   
    ldxdw r0, [r6+0x8]                      
    stxdw [r10-0x168], r0                   
    ldxdw r0, [r6+0x0]                      
    stxdw [r10-0x170], r0                   
    ldxdw r0, [r5+0x0]                      
    mov64 r6, 0                                     r6 = 0 as i32 as i64 as u64
    mov64 r8, 1                                     r8 = 1 as i32 as i64 as u64
    mov64 r5, r0                                    r5 = r0
    add64 r5, -32                                   r5 += -32   ///  r5 = r5.wrapping_add(-32 as i32 as i64 as u64)
    jgt r5, r0, lbb_8627                            if r5 > r0 { pc += 1 }
    mov64 r8, 0                                     r8 = 0 as i32 as i64 as u64
lbb_8627:
    jne r8, 0, lbb_8629                             if r8 != (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r6, r5                                    r6 = r5
lbb_8629:
    lddw r5, 0x300007fe0                            r5 load str located at 12884934624
    jeq r0, 0, lbb_8633                             if r0 == (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r5, r6                                    r5 = r6
lbb_8633:
    lddw r0, 0x300000007                            r0 load str located at 12884901895
    jgt r5, r0, lbb_8637                            if r5 > r0 { pc += 1 }
    ja lbb_8488                                     if true { pc += -149 }
lbb_8637:
    lddw r0, 0x300000000                            r0 load str located at 12884901888
    stxdw [r0+0x0], r5                      
    ldxdw r0, [r10-0x158]                   
    stxdw [r5+0x18], r0                     
    ldxdw r0, [r10-0x160]                   
    stxdw [r5+0x10], r0                     
    ldxdw r0, [r10-0x168]                   
    stxdw [r5+0x8], r0                      
    ldxdw r0, [r10-0x170]                   
    stxdw [r5+0x0], r0                      
    stxdw [r10-0xf8], r5                    
    stxdw [r10-0x100], r4                   
    stxdw [r10-0x108], r2                   
    stxdw [r10-0x110], r3                   
    stxdw [r10-0x118], r1                   
    mov64 r1, 36                                    r1 = 36 as i32 as i64 as u64
    ja lbb_8720                                     if true { pc += 65 }
lbb_8655:
    ldxdw r1, [r10-0x157]                   
    stxdw [r10-0x48], r1                    
    ldxdw r1, [r10-0x15f]                   
    stxdw [r10-0x50], r1                    
    ldxdw r1, [r10-0x167]                   
    stxdw [r10-0x58], r1                    
    ldxdw r1, [r10-0x16f]                   
    stxdw [r10-0x60], r1                    
    ldxb r6, [r10-0x14f]                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -254                                  r1 += -254   ///  r1 = r1.wrapping_add(-254 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -334                                  r2 += -334   ///  r2 = r2.wrapping_add(-334 as i32 as i64 as u64)
    mov64 r3, 38                                    r3 = 38 as i32 as i64 as u64
    call function_48190                     
    stxb [r10-0xff], r6                     
    stxb [r10-0x120], r9                    
    ldxdw r1, [r10-0x60]                    
    stxdw [r10-0x11f], r1                   
    ldxdw r1, [r10-0x58]                    
    stxdw [r10-0x117], r1                   
    ldxdw r1, [r10-0x50]                    
    stxdw [r10-0x10f], r1                   
    ldxdw r1, [r10-0x48]                    
    stxdw [r10-0x107], r1                   
    ja lbb_8698                                     if true { pc += 17 }
lbb_8681:
    ldxw r1, [r10-0x16c]                    
    stxw [r10-0x11c], r1                    
    ldxw r1, [r10-0x16f]                    
    stxw [r10-0x11f], r1                    
    ldxdw r7, [r10-0x168]                   
    ldxdw r8, [r10-0x160]                   
    ldxdw r9, [r10-0x158]                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -256                                  r1 += -256   ///  r1 = r1.wrapping_add(-256 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -336                                  r2 += -336   ///  r2 = r2.wrapping_add(-336 as i32 as i64 as u64)
    mov64 r3, 40                                    r3 = 40 as i32 as i64 as u64
    call function_48190                     
    stxdw [r10-0x108], r9                   
    stxdw [r10-0x110], r8                   
    stxdw [r10-0x118], r7                   
    stxb [r10-0x120], r6                    
lbb_8698:
    mov64 r2, r10                                   r2 = r10
    add64 r2, -288                                  r2 += -288   ///  r2 = r2.wrapping_add(-288 as i32 as i64 as u64)
    ldxdw r1, [r10-0x2f8]                   
    call function_26067                     
    ja lbb_7930                                     if true { pc += -773 }
lbb_8703:
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    stxdw [r10-0x168], r1                   
    lddw r1, 0x1000650b0 --> b"\x00\x00\x00\x00\xc5\x03\x06\x00*\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00…        r1 load str located at 4295381168
    stxdw [r10-0x170], r1                   
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    stxdw [r10-0x150], r1                   
    stxdw [r10-0x158], r1                   
    lddw r1, 0x10005fa70 --> b"src/arithmetic_impls.rsSubtraction overflowedsrc/d"        r1 load str located at 4295359088
    stxdw [r10-0x160], r1                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -280                                  r1 += -280   ///  r1 = r1.wrapping_add(-280 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -368                                  r2 += -368   ///  r2 = r2.wrapping_add(-368 as i32 as i64 as u64)
    call function_445                       
    mov64 r1, 29                                    r1 = 29 as i32 as i64 as u64
lbb_8720:
    stxb [r10-0x120], r1                    
    mov64 r2, r10                                   r2 = r10
    add64 r2, -288                                  r2 += -288   ///  r2 = r2.wrapping_add(-288 as i32 as i64 as u64)
    mov64 r1, r9                                    r1 = r9
    call function_26067                     
    ja lbb_8457                                     if true { pc += -269 }
lbb_8726:
    ldxdw r0, [r10-0x110]                   
    ldxdw r5, [r10-0x48]                    
    ldxdw r2, [r10-0x50]                    
    ldxdw r3, [r10-0x58]                    
    ldxw r4, [r10-0x5c]                     
    ldxdw r6, [r10-0x118]                   
    ldxdw r7, [r6+0x0]                      
    add64 r7, -1                                    r7 += -1   ///  r7 = r7.wrapping_add(-1 as i32 as i64 as u64)
    stxdw [r6+0x0], r7                      
    ldxdw r9, [r10-0x2f8]                   
    jne r7, 0, lbb_8740                             if r7 != (0 as i32 as i64 as u64) { pc += 3 }
    ldxdw r7, [r6+0x8]                      
    add64 r7, -1                                    r7 += -1   ///  r7 = r7.wrapping_add(-1 as i32 as i64 as u64)
    stxdw [r6+0x8], r7                      
lbb_8740:
    ldxdw r6, [r0+0x0]                      
    add64 r6, -1                                    r6 += -1   ///  r6 = r6.wrapping_add(-1 as i32 as i64 as u64)
    stxdw [r0+0x0], r6                      
    jne r6, 0, lbb_8747                             if r6 != (0 as i32 as i64 as u64) { pc += 3 }
    ldxdw r6, [r0+0x8]                      
    add64 r6, -1                                    r6 += -1   ///  r6 = r6.wrapping_add(-1 as i32 as i64 as u64)
    stxdw [r0+0x8], r6                      
lbb_8747:
    ldxdw r0, [r10-0xe0]                    
    ldxdw r6, [r10-0xe8]                    
    ldxdw r7, [r6+0x0]                      
    add64 r7, -1                                    r7 += -1   ///  r7 = r7.wrapping_add(-1 as i32 as i64 as u64)
    stxdw [r6+0x0], r7                      
    jne r7, 0, lbb_8756                             if r7 != (0 as i32 as i64 as u64) { pc += 3 }
    ldxdw r7, [r6+0x8]                      
    add64 r7, -1                                    r7 += -1   ///  r7 = r7.wrapping_add(-1 as i32 as i64 as u64)
    stxdw [r6+0x8], r7                      
lbb_8756:
    ldxdw r6, [r0+0x0]                      
    add64 r6, -1                                    r6 += -1   ///  r6 = r6.wrapping_add(-1 as i32 as i64 as u64)
    stxdw [r0+0x0], r6                      
    jne r6, 0, lbb_8763                             if r6 != (0 as i32 as i64 as u64) { pc += 3 }
    ldxdw r6, [r0+0x8]                      
    add64 r6, -1                                    r6 += -1   ///  r6 = r6.wrapping_add(-1 as i32 as i64 as u64)
    stxdw [r0+0x8], r6                      
lbb_8763:
    ldxdw r0, [r10-0xb0]                    
    ldxdw r6, [r10-0xb8]                    
    ldxdw r7, [r6+0x0]                      
    add64 r7, -1                                    r7 += -1   ///  r7 = r7.wrapping_add(-1 as i32 as i64 as u64)
    stxdw [r6+0x0], r7                      
    jne r7, 0, lbb_8772                             if r7 != (0 as i32 as i64 as u64) { pc += 3 }
    ldxdw r7, [r6+0x8]                      
    add64 r7, -1                                    r7 += -1   ///  r7 = r7.wrapping_add(-1 as i32 as i64 as u64)
    stxdw [r6+0x8], r7                      
lbb_8772:
    ldxdw r6, [r0+0x0]                      
    add64 r6, -1                                    r6 += -1   ///  r6 = r6.wrapping_add(-1 as i32 as i64 as u64)
    stxdw [r0+0x0], r6                      
    jne r6, 0, lbb_8779                             if r6 != (0 as i32 as i64 as u64) { pc += 3 }
    ldxdw r6, [r0+0x8]                      
    add64 r6, -1                                    r6 += -1   ///  r6 = r6.wrapping_add(-1 as i32 as i64 as u64)
    stxdw [r0+0x8], r6                      
lbb_8779:
    mov64 r0, 55                                    r0 = 55 as i32 as i64 as u64
    ja lbb_8786                                     if true { pc += 5 }
lbb_8781:
    mov64 r0, 55                                    r0 = 55 as i32 as i64 as u64
    ldxdw r2, [r10-0x110]                   
    ldxdw r3, [r10-0x118]                   
    ldxdw r5, [r10-0x108]                   
    ldxw r4, [r10-0x11c]                    
lbb_8786:
    ldxh r6, [r10-0x2a4]                    
    stxh [r10-0x11a], r6                    
    ldxw r6, [r10-0x2a8]                    
    stxw [r10-0x11e], r6                    
    ldxdw r6, [r10-0x2c8]                   
    stxdw [r10-0xf8], r6                    
    ldxdw r6, [r10-0x2c0]                   
    stxdw [r10-0xf0], r6                    
    ldxdw r6, [r10-0x2b8]                   
    stxdw [r10-0xe8], r6                    
    ldxdw r6, [r10-0x2b0]                   
    stxdw [r10-0xe0], r6                    
    stxdw [r10-0x100], r5                   
    stxdw [r10-0x108], r2                   
    stxdw [r10-0x110], r3                   
    stxw [r10-0x114], r4                    
    stxw [r10-0x118], r1                    
    stxb [r10-0x120], r0                    
    ja lbb_7871                                     if true { pc += -934 }

function_8805:
    mov64 r6, r3                                    r6 = r3
    stxdw [r10-0x240], r2                   
    stxdw [r10-0x250], r1                   
    jne r4, 5, lbb_8855                             if r4 != (5 as i32 as i64 as u64) { pc += 46 }
    stxdw [r10-0x258], r5                   
    mov64 r9, 0                                     r9 = 0 as i32 as i64 as u64
    stxdw [r10-0xd0], r9                    
    lddw r1, 0x1000650d0 --> b"\x00\x00\x00\x00\x16\x04\x06\x00"\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00…        r1 load str located at 4295381200
    stxdw [r10-0xf0], r1                    
    mov64 r7, 2                                     r7 = 2 as i32 as i64 as u64
    stxdw [r10-0xe8], r7                    
    stxdw [r10-0xd8], r7                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -320                                  r1 += -320   ///  r1 = r1.wrapping_add(-320 as i32 as i64 as u64)
    stxdw [r10-0xe0], r1                    
    lddw r1, 0x100000848 --> b"y\x11\x00\x00\x00\x00\x00\x00\x85\x10\x00\x005\x99\x00\x00\x95\x00\x00\x0…        r1 load str located at 4294969416
    stxdw [r10-0x128], r1                   
    stxdw [r10-0x138], r1                   
    mov64 r1, r6                                    r1 = r6
    add64 r1, 144                                   r1 += 144   ///  r1 = r1.wrapping_add(144 as i32 as i64 as u64)
    stxdw [r10-0x260], r1                   
    stxdw [r10-0x130], r1                   
    mov64 r8, r6                                    r8 = r6
    add64 r8, 96                                    r8 += 96   ///  r8 = r8.wrapping_add(96 as i32 as i64 as u64)
    stxdw [r10-0x140], r8                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -496                                  r1 += -496   ///  r1 = r1.wrapping_add(-496 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -240                                  r2 += -240   ///  r2 = r2.wrapping_add(-240 as i32 as i64 as u64)
    call function_43415                     
    ldxdw r1, [r10-0x1f0]                   
    ldxdw r2, [r10-0x1e0]                   
    syscall [invalid]                       
    ldxb r3, [r6+0x28]                      
    jeq r3, 0, lbb_8874                             if r3 == (0 as i32 as i64 as u64) { pc += 32 }
    ldxb r1, [r6+0x58]                      
    jne r1, 0, lbb_8900                             if r1 != (0 as i32 as i64 as u64) { pc += 56 }
    ldxdw r1, [r6+0x30]                     
    ldxdw r2, [r1+0x18]                     
    stxdw [r10-0xd7], r2                    
    ldxdw r2, [r1+0x10]                     
    stxdw [r10-0xdf], r2                    
    ldxdw r2, [r1+0x8]                      
    stxdw [r10-0xe7], r2                    
    ldxdw r1, [r1+0x0]                      
    stxdw [r10-0xef], r1                    
    mov64 r1, 12                                    r1 = 12 as i32 as i64 as u64
    ja lbb_8894                                     if true { pc += 39 }
lbb_8855:
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    stxdw [r10-0x120], r1                   
    lddw r1, 0x1000650c0 --> b"\x00\x00\x00\x00\xef\x03\x06\x00'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00…        r1 load str located at 4295381184
    stxdw [r10-0x140], r1                   
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    stxdw [r10-0x138], r1                   
    stxdw [r10-0x128], r1                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -496                                  r1 += -496   ///  r1 = r1.wrapping_add(-496 as i32 as i64 as u64)
    stxdw [r10-0x130], r1                   
    lddw r1, 0x10005df58 --> b"\xbf#\x00\x00\x00\x00\x00\x00y\x11\x00\x00\x00\x00\x00\x00\xb7\x02\x00\x0…        r1 load str located at 4295352152
    stxdw [r10-0x1e8], r1                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -48                                   r1 += -48   ///  r1 = r1.wrapping_add(-48 as i32 as i64 as u64)
    stxdw [r10-0x1f0], r1                   
    stxdw [r10-0x30], r4                    
    ja lbb_8888                                     if true { pc += 14 }
lbb_8874:
    stxdw [r10-0x120], r9                   
    stxdw [r10-0x138], r7                   
    lddw r1, 0x100064cf0 --> b"\x00\x00\x00\x00\xd0\xff\x05\x00\x0e\x00\x00\x00\x00\x00\x00\x00\x00\x00\…        r1 load str located at 4295380208
    stxdw [r10-0x140], r1                   
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    stxdw [r10-0x128], r1                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -496                                  r1 += -496   ///  r1 = r1.wrapping_add(-496 as i32 as i64 as u64)
    stxdw [r10-0x130], r1                   
    lddw r1, 0x1000008a0 --> b"y\x11\x00\x00\x00\x00\x00\x00\x85\x10\x00\x00*\x99\x00\x00\x95\x00\x00\x0…        r1 load str located at 4294969504
    stxdw [r10-0x1e8], r1                   
    stxdw [r10-0x1f0], r6                   
lbb_8888:
    mov64 r1, r10                                   r1 = r10
    add64 r1, -232                                  r1 += -232   ///  r1 = r1.wrapping_add(-232 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -320                                  r2 += -320   ///  r2 = r2.wrapping_add(-320 as i32 as i64 as u64)
    call function_43415                     
lbb_8893:
    mov64 r1, 29                                    r1 = 29 as i32 as i64 as u64
lbb_8894:
    stxb [r10-0xf0], r1                     
lbb_8895:
    mov64 r2, r10                                   r2 = r10
    add64 r2, -240                                  r2 += -240   ///  r2 = r2.wrapping_add(-240 as i32 as i64 as u64)
    ldxdw r1, [r10-0x250]                   
    call function_26067                     
    ja lbb_10077                                    if true { pc += 1177 }
lbb_8900:
    ldxdw r7, [r6+0xc0]                     
    ldxdw r1, [r7+0x0]                      
    jeq r1, 0, lbb_8905                             if r1 == (0 as i32 as i64 as u64) { pc += 2 }
lbb_8903:
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    ja lbb_8912                                     if true { pc += 7 }
lbb_8905:
    ldxdw r1, [r7+0x8]                      
    jne r1, 0, lbb_8903                             if r1 != (0 as i32 as i64 as u64) { pc += -4 }
    ldxdw r1, [r7+0x10]                     
    jne r1, 0, lbb_8903                             if r1 != (0 as i32 as i64 as u64) { pc += -6 }
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    ldxdw r2, [r7+0x18]                     
    jne r2, 0, lbb_8903                             if r2 != (0 as i32 as i64 as u64) { pc += -9 }
lbb_8912:
    jeq r1, 0, lbb_8935                             if r1 == (0 as i32 as i64 as u64) { pc += 22 }
    lddw r1, 0x300000000                            r1 load str located at 12884901888
    ldxdw r1, [r1+0x0]                      
    mov64 r3, r1                                    r3 = r1
    add64 r3, -41                                   r3 += -41   ///  r3 = r3.wrapping_add(-41 as i32 as i64 as u64)
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
    mov64 r4, 1                                     r4 = 1 as i32 as i64 as u64
    jgt r3, r1, lbb_8922                            if r3 > r1 { pc += 1 }
    mov64 r4, 0                                     r4 = 0 as i32 as i64 as u64
lbb_8922:
    jne r4, 0, lbb_8924                             if r4 != (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r2, r3                                    r2 = r3
lbb_8924:
    lddw r6, 0x300007fd7                            r6 load str located at 12884934615
    jeq r1, 0, lbb_8928                             if r1 == (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r6, r2                                    r6 = r2
lbb_8928:
    lddw r1, 0x300000007                            r1 load str located at 12884901895
    jgt r6, r1, lbb_9571                            if r6 > r1 { pc += 640 }
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    mov64 r2, 41                                    r2 = 41 as i32 as i64 as u64
    call function_43400                     
    syscall [invalid]                       
lbb_8935:
    stxdw [r10-0x280], r3                   
    mov64 r1, r8                                    r1 = r8
    call function_39132                     
    jne r0, 0, lbb_8942                             if r0 != (0 as i32 as i64 as u64) { pc += 3 }
    mov64 r1, r8                                    r1 = r8
    call function_39148                     
    jne r0, 0, lbb_9909                             if r0 != (0 as i32 as i64 as u64) { pc += 967 }
lbb_8942:
    ldxb r1, [r6+0x89]                      
    jeq r1, 0, lbb_9599                             if r1 == (0 as i32 as i64 as u64) { pc += 655 }
    mov64 r1, r10                                   r1 = r10
    add64 r1, -240                                  r1 += -240   ///  r1 = r1.wrapping_add(-240 as i32 as i64 as u64)
    mov64 r2, r8                                    r2 = r8
    call function_39192                     
    ldxw r2, [r10-0xf0]                     
    jne r2, 24, lbb_9606                            if r2 != (24 as i32 as i64 as u64) { pc += 656 }
    ldxdw r4, [r10-0xe0]                    
    ldxdw r3, [r10-0xe8]                    
    ldxdw r2, [r8+0x0]                      
    ldxdw r1, [r3+0x8]                      
    jne r1, 8552, lbb_8959                          if r1 != (8552 as i32 as i64 as u64) { pc += 4 }
    ldxdw r9, [r3+0x0]                      
    mov64 r3, r9                                    r3 = r9
    and64 r3, 7                                     r3 &= 7   ///  r3 = r3.and(7)
    jeq r3, 0, lbb_8972                             if r3 == (0 as i32 as i64 as u64) { pc += 13 }
lbb_8959:
    ldxdw r3, [r2+0x8]                      
    ldxdw r5, [r2+0x0]                      
    ldxdw r0, [r2+0x18]                     
    stxdw [r10-0x28], r0                    
    ldxdw r2, [r2+0x10]                     
    stxdw [r10-0x30], r2                    
    ldxdw r2, [r4+0x0]                      
    add64 r2, 1                                     r2 += 1   ///  r2 = r2.wrapping_add(1 as i32 as i64 as u64)
    stxdw [r4+0x0], r2                      
    mov64 r4, 0                                     r4 = 0 as i32 as i64 as u64
    mov64 r2, 8552                                  r2 = 8552 as i32 as i64 as u64
    mov64 r0, 35                                    r0 = 35 as i32 as i64 as u64
    ja lbb_9921                                     if true { pc += 949 }
lbb_8972:
    stxdw [r10-0x268], r4                   
    ldxb r3, [r9+0x214c]                    
    stxdw [r10-0x270], r9                   
    add64 r9, 8                                     r9 += 8   ///  r9 = r9.wrapping_add(8 as i32 as i64 as u64)
    mov64 r1, r10                                   r1 = r10
    add64 r1, -240                                  r1 += -240   ///  r1 = r1.wrapping_add(-240 as i32 as i64 as u64)
    stxdw [r10-0x248], r2                   
    mov64 r4, r9                                    r4 = r9
    ldxdw r5, [r10-0x240]                   
    call function_24091                     
    ldxb r8, [r10-0xf0]                     
    jeq r8, 56, lbb_8985                            if r8 == (56 as i32 as i64 as u64) { pc += 1 }
    ja lbb_9612                                     if true { pc += 627 }
lbb_8985:
    ldxdw r1, [r9+0x0]                      
    ldxdw r8, [r6+0x30]                     
    ldxdw r2, [r8+0x0]                      
    jeq r1, r2, lbb_8991                            if r1 == r2 { pc += 2 }
lbb_8989:
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    ja lbb_9001                                     if true { pc += 10 }
lbb_8991:
    ldxdw r1, [r8+0x8]                      
    ldxdw r2, [r9+0x8]                      
    jne r2, r1, lbb_8989                            if r2 != r1 { pc += -5 }
    ldxdw r1, [r8+0x10]                     
    ldxdw r2, [r9+0x10]                     
    jne r2, r1, lbb_8989                            if r2 != r1 { pc += -8 }
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    ldxdw r2, [r8+0x18]                     
    ldxdw r3, [r9+0x18]                     
    jne r3, r2, lbb_8989                            if r3 != r2 { pc += -12 }
lbb_9001:
    mov64 r2, 18                                    r2 = 18 as i32 as i64 as u64
    stxdw [r10-0x210], r2                   
    lddw r2, 0x10006044b --> b"Dex owner mismatchprogram/src/instructions/dex_ins"        r2 load str located at 4295361611
    stxdw [r10-0x218], r2                   
    jeq r1, 0, lbb_9008                             if r1 == (0 as i32 as i64 as u64) { pc += 1 }
    ja lbb_9630                                     if true { pc += 622 }
lbb_9008:
    stxdw [r10-0x288], r7                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -320                                  r1 += -320   ///  r1 = r1.wrapping_add(-320 as i32 as i64 as u64)
    ldxdw r2, [r10-0x248]                   
    ldxdw r8, [r10-0x258]                   
    mov64 r3, r8                                    r3 = r8
    ldxdw r4, [r10-0x240]                   
    call function_24274                     
    ldxb r7, [r10-0x140]                    
    jeq r7, 56, lbb_9019                            if r7 == (56 as i32 as i64 as u64) { pc += 1 }
    ja lbb_9689                                     if true { pc += 670 }
lbb_9019:
    ldxdw r1, [r10-0x127]                   
    stxdw [r10-0x1d8], r1                   
    ldxdw r2, [r10-0x12f]                   
    stxdw [r10-0x1e0], r2                   
    ldxdw r3, [r10-0x137]                   
    stxdw [r10-0x1e8], r3                   
    ldxdw r4, [r10-0x13f]                   
    stxdw [r10-0x1f0], r4                   
    ldxb r5, [r10-0x11f]                    
    stxdw [r10-0x220], r1                   
    stxdw [r10-0x228], r2                   
    stxdw [r10-0x230], r3                   
    stxdw [r10-0x238], r4                   
    ldxdw r7, [r10-0x260]                   
    ldxdw r9, [r7+0x0]                      
    ldxdw r1, [r9+0x0]                      
    jeq r1, r4, lbb_9038                            if r1 == r4 { pc += 2 }
lbb_9036:
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    ja lbb_9048                                     if true { pc += 10 }
lbb_9038:
    ldxdw r1, [r9+0x8]                      
    ldxdw r2, [r10-0x230]                   
    jne r1, r2, lbb_9036                            if r1 != r2 { pc += -5 }
    ldxdw r1, [r9+0x10]                     
    ldxdw r2, [r10-0x228]                   
    jne r1, r2, lbb_9036                            if r1 != r2 { pc += -8 }
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    ldxdw r2, [r9+0x18]                     
    ldxdw r3, [r10-0x220]                   
    jne r2, r3, lbb_9036                            if r2 != r3 { pc += -12 }
lbb_9048:
    mov64 r2, 44                                    r2 = 44 as i32 as i64 as u64
    stxdw [r10-0x210], r2                   
    lddw r2, 0x100060485 --> b"Dex instance PDA address derivation mismatchdex_in"        r2 load str located at 4295361669
    stxdw [r10-0x218], r2                   
    jeq r1, 0, lbb_9055                             if r1 == (0 as i32 as i64 as u64) { pc += 1 }
    ja lbb_9715                                     if true { pc += 660 }
lbb_9055:
    stxb [r10-0x1aa], r8                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -425                                  r1 += -425   ///  r1 = r1.wrapping_add(-425 as i32 as i64 as u64)
    stxdw [r10-0x1c0], r1                   
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    stxdw [r10-0x1b8], r1                   
    stxdw [r10-0x1c8], r1                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -426                                  r1 += -426   ///  r1 = r1.wrapping_add(-426 as i32 as i64 as u64)
    stxdw [r10-0x1d0], r1                   
    mov64 r1, 32                                    r1 = 32 as i32 as i64 as u64
    stxdw [r10-0x1d8], r1                   
    ldxdw r8, [r10-0x248]                   
    stxdw [r10-0x1e0], r8                   
    mov64 r1, 12                                    r1 = 12 as i32 as i64 as u64
    stxdw [r10-0x1e8], r1                   
    lddw r1, 0x1000604b1 --> b"dex_instanceInstance ID mismatch after loadingOwne"        r1 load str located at 4295361713
    stxdw [r10-0x1f0], r1                   
    stxdw [r10-0x278], r5                   
    stxb [r10-0x1a9], r5                    
    mov64 r1, r7                                    r1 = r7
    call function_39132                     
    jne r0, 0, lbb_9371                             if r0 != (0 as i32 as i64 as u64) { pc += 292 }
    mov64 r1, r7                                    r1 = r7
    call function_39148                     
    jeq r0, 0, lbb_9371                             if r0 == (0 as i32 as i64 as u64) { pc += 289 }
    mov64 r1, 8492                                  r1 = 8492 as i32 as i64 as u64
    stxdw [r10-0x148], r1                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -240                                  r1 += -240   ///  r1 = r1.wrapping_add(-240 as i32 as i64 as u64)
    call function_41981                     
    ldxw r1, [r10-0xf0]                     
    jeq r1, 24, lbb_9094                            if r1 == (24 as i32 as i64 as u64) { pc += 5 }
    mov64 r0, 55                                    r0 = 55 as i32 as i64 as u64
    ldxdw r3, [r10-0xd8]                    
    ldxdw r2, [r10-0xe0]                    
    ldxdw r4, [r10-0xe8]                    
    ja lbb_10136                                    if true { pc += 1042 }
lbb_9094:
    stxdw [r10-0x290], r9                   
    ldxdw r1, [r10-0xe8]                    
    mul64 r1, 8620                                  r1 *= 8620   ///  r1 = r1.wrapping_mul(8620 as u64)
    call function_48833                     
    ldxdw r1, [r10-0xe0]                    
    mov64 r2, r0                                    r2 = r0
    call function_48576                     
    mov64 r9, r0                                    r9 = r0
    mov64 r8, 0                                     r8 = 0 as i32 as i64 as u64
    mov64 r1, r9                                    r1 = r9
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
    call function_48350                     
    stxdw [r10-0x298], r0                   
    mov64 r1, r9                                    r1 = r9
    call function_48326                     
    mov64 r7, 0                                     r7 = 0 as i32 as i64 as u64
    ldxdw r1, [r10-0x298]                   
    jsgt r8, r1, lbb_9113                           if (r8 as i64) > (r1 as i64) { pc += 1 }
    mov64 r7, r0                                    r7 = r0
lbb_9113:
    mov64 r1, r9                                    r1 = r9
    lddw r2, 0x43efffffffffffff                     r2 load str located at 4895412794951729151
    call function_48896                     
    mov64 r4, -1                                    r4 = -1 as i32 as i64 as u64
    jsgt r0, 0, lbb_9120                            if (r0 as i64) > (0 as i32 as i64) { pc += 1 }
    mov64 r4, r7                                    r4 = r7
lbb_9120:
    ldxdw r7, [r6+0x0]                      
    mov64 r1, 8492                                  r1 = 8492 as i32 as i64 as u64
    stxdw [r10-0x1000], r1                  
    ldxdw r1, [r10-0x240]                   
    stxdw [r10-0xff8], r1                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -320                                  r1 += -320   ///  r1 = r1.wrapping_add(-320 as i32 as i64 as u64)
    mov64 r5, r10                                   r5 = r10
    mov64 r2, r7                                    r2 = r7
    ldxdw r3, [r10-0x290]                   
    call function_40993                     
    ldxdw r5, [r6+0x8]                      
    ldxdw r1, [r5+0x0]                      
    add64 r1, 1                                     r1 += 1   ///  r1 = r1.wrapping_add(1 as i32 as i64 as u64)
    mov64 r2, 1                                     r2 = 1 as i32 as i64 as u64
    jeq r1, 0, lbb_9137                             if r1 == (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
lbb_9137:
    stxdw [r5+0x0], r1                      
    jne r2, 1, lbb_9141                             if r2 != (1 as i32 as i64 as u64) { pc += 2 }
lbb_9139:
    syscall [invalid]                       
    syscall [invalid]                       
lbb_9141:
    ldxdw r0, [r6+0x10]                     
    ldxdw r1, [r0+0x0]                      
    add64 r1, 1                                     r1 += 1   ///  r1 = r1.wrapping_add(1 as i32 as i64 as u64)
    mov64 r2, 1                                     r2 = 1 as i32 as i64 as u64
    jeq r1, 0, lbb_9147                             if r1 == (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
lbb_9147:
    stxdw [r0+0x0], r1                      
    jne r2, 1, lbb_9150                             if r2 != (1 as i32 as i64 as u64) { pc += 1 }
    ja lbb_9139                                     if true { pc += -11 }
lbb_9150:
    ldxdw r3, [r6+0x98]                     
    ldxdw r1, [r3+0x0]                      
    add64 r1, 1                                     r1 += 1   ///  r1 = r1.wrapping_add(1 as i32 as i64 as u64)
    mov64 r2, 1                                     r2 = 1 as i32 as i64 as u64
    jeq r1, 0, lbb_9156                             if r1 == (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
lbb_9156:
    ldxb r4, [r6+0x2a]                      
    stxdw [r10-0x2a0], r4                   
    ldxb r4, [r6+0x29]                      
    stxdw [r10-0x298], r4                   
    ldxdw r4, [r6+0x20]                     
    ldxdw r9, [r6+0x18]                     
    stxdw [r3+0x0], r1                      
    jne r2, 1, lbb_9165                             if r2 != (1 as i32 as i64 as u64) { pc += 1 }
    ja lbb_9139                                     if true { pc += -26 }
lbb_9165:
    ldxdw r8, [r6+0xa0]                     
    ldxdw r1, [r8+0x0]                      
    add64 r1, 1                                     r1 += 1   ///  r1 = r1.wrapping_add(1 as i32 as i64 as u64)
    mov64 r2, 1                                     r2 = 1 as i32 as i64 as u64
    jeq r1, 0, lbb_9171                             if r1 == (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
lbb_9171:
    stxdw [r10-0x2a8], r4                   
    stxdw [r8+0x0], r1                      
    jne r2, 1, lbb_9175                             if r2 != (1 as i32 as i64 as u64) { pc += 1 }
    ja lbb_9139                                     if true { pc += -36 }
lbb_9175:
    stxdw [r10-0x2b0], r7                   
    ldxdw r4, [r6+0xc8]                     
    ldxdw r7, [r4+0x0]                      
    add64 r7, 1                                     r7 += 1   ///  r7 = r7.wrapping_add(1 as i32 as i64 as u64)
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    jeq r7, 0, lbb_9182                             if r7 == (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
lbb_9182:
    ldxb r2, [r6+0xba]                      
    stxdw [r10-0x2d8], r2                   
    ldxb r2, [r6+0xb9]                      
    stxdw [r10-0x2d0], r2                   
    ldxb r2, [r6+0xb8]                      
    stxdw [r10-0x2c8], r2                   
    ldxdw r2, [r6+0xb0]                     
    stxdw [r10-0x2c0], r2                   
    ldxdw r2, [r6+0xa8]                     
    stxdw [r10-0x2b8], r2                   
    stxdw [r4+0x0], r7                      
    jne r1, 1, lbb_9195                             if r1 != (1 as i32 as i64 as u64) { pc += 1 }
    ja lbb_9139                                     if true { pc += -56 }
lbb_9195:
    stxdw [r10-0x2e8], r9                   
    stxdw [r10-0x2e0], r3                   
    ldxdw r7, [r6+0xd0]                     
    ldxdw r1, [r7+0x0]                      
    add64 r1, 1                                     r1 += 1   ///  r1 = r1.wrapping_add(1 as i32 as i64 as u64)
    mov64 r2, 1                                     r2 = 1 as i32 as i64 as u64
    jeq r1, 0, lbb_9203                             if r1 == (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
lbb_9203:
    mov64 r3, r0                                    r3 = r0
    mov64 r9, r5                                    r9 = r5
    stxdw [r7+0x0], r1                      
    jne r2, 1, lbb_9208                             if r2 != (1 as i32 as i64 as u64) { pc += 1 }
    ja lbb_9139                                     if true { pc += -69 }
lbb_9208:
    ldxdw r1, [r6+0xd8]                     
    ldxdw r2, [r6+0xe0]                     
    ldxb r5, [r6+0xe8]                      
    ldxb r0, [r6+0xe9]                      
    ldxb r6, [r6+0xea]                      
    stxb [r10-0x66], r6                     
    stxb [r10-0x67], r0                     
    stxb [r10-0x68], r5                     
    stxdw [r10-0x70], r2                    
    stxdw [r10-0x78], r1                    
    stxdw [r10-0x80], r7                    
    stxdw [r10-0x88], r4                    
    ldxdw r1, [r10-0x288]                   
    stxdw [r10-0x90], r1                    
    ldxdw r1, [r10-0x2d8]                   
    stxb [r10-0x96], r1                     
    ldxdw r1, [r10-0x2d0]                   
    stxb [r10-0x97], r1                     
    ldxdw r1, [r10-0x2c8]                   
    stxb [r10-0x98], r1                     
    ldxdw r1, [r10-0x2c0]                   
    stxdw [r10-0xa0], r1                    
    ldxdw r1, [r10-0x2b8]                   
    stxdw [r10-0xa8], r1                    
    stxdw [r10-0xb0], r8                    
    ldxdw r1, [r10-0x2e0]                   
    stxdw [r10-0xb8], r1                    
    ldxdw r1, [r10-0x290]                   
    stxdw [r10-0xc0], r1                    
    ldxdw r1, [r10-0x2a0]                   
    stxb [r10-0xc6], r1                     
    ldxdw r1, [r10-0x298]                   
    stxb [r10-0xc7], r1                     
    ldxdw r1, [r10-0x280]                   
    stxb [r10-0xc8], r1                     
    ldxdw r1, [r10-0x2a8]                   
    stxdw [r10-0xd0], r1                    
    ldxdw r1, [r10-0x2e8]                   
    stxdw [r10-0xd8], r1                    
    stxdw [r10-0xe0], r3                    
    stxdw [r10-0xe8], r9                    
    ldxdw r1, [r10-0x2b0]                   
    stxdw [r10-0xf0], r1                    
    mov64 r1, 4                                     r1 = 4 as i32 as i64 as u64
    stxdw [r10-0x58], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -496                                  r1 += -496   ///  r1 = r1.wrapping_add(-496 as i32 as i64 as u64)
    stxdw [r10-0x60], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -96                                   r1 += -96   ///  r1 = r1.wrapping_add(-96 as i32 as i64 as u64)
    stxdw [r10-0x1000], r1                  
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    stxdw [r10-0xff8], r1                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -48                                   r1 += -48   ///  r1 = r1.wrapping_add(-48 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -320                                  r2 += -320   ///  r2 = r2.wrapping_add(-320 as i32 as i64 as u64)
    mov64 r3, r10                                   r3 = r10
    add64 r3, -240                                  r3 += -240   ///  r3 = r3.wrapping_add(-240 as i32 as i64 as u64)
    mov64 r5, r10                                   r5 = r10
    mov64 r4, 3                                     r4 = 3 as i32 as i64 as u64
    call function_40377                     
    ldxw r1, [r10-0x30]                     
    jne r1, 24, lbb_10078                           if r1 != (24 as i32 as i64 as u64) { pc += 806 }
    ldxdw r1, [r10-0xe0]                    
    ldxdw r2, [r10-0xe8]                    
    ldxdw r3, [r2+0x0]                      
    add64 r3, -1                                    r3 += -1   ///  r3 = r3.wrapping_add(-1 as i32 as i64 as u64)
    stxdw [r2+0x0], r3                      
    jne r3, 0, lbb_9281                             if r3 != (0 as i32 as i64 as u64) { pc += 3 }
    ldxdw r3, [r2+0x8]                      
    add64 r3, -1                                    r3 += -1   ///  r3 = r3.wrapping_add(-1 as i32 as i64 as u64)
    stxdw [r2+0x8], r3                      
lbb_9281:
    ldxdw r3, [r1+0x0]                      
    add64 r3, -1                                    r3 += -1   ///  r3 = r3.wrapping_add(-1 as i32 as i64 as u64)
    stxdw [r1+0x0], r3                      
    ldxdw r8, [r10-0x258]                   
    ldxdw r2, [r10-0x260]                   
    jne r3, 0, lbb_9290                             if r3 != (0 as i32 as i64 as u64) { pc += 3 }
    ldxdw r3, [r1+0x8]                      
    add64 r3, -1                                    r3 += -1   ///  r3 = r3.wrapping_add(-1 as i32 as i64 as u64)
    stxdw [r1+0x8], r3                      
lbb_9290:
    ldxdw r1, [r10-0xb0]                    
    ldxdw r4, [r10-0xb8]                    
    ldxdw r3, [r4+0x0]                      
    add64 r3, -1                                    r3 += -1   ///  r3 = r3.wrapping_add(-1 as i32 as i64 as u64)
    stxdw [r4+0x0], r3                      
    jne r3, 0, lbb_9299                             if r3 != (0 as i32 as i64 as u64) { pc += 3 }
    ldxdw r3, [r4+0x8]                      
    add64 r3, -1                                    r3 += -1   ///  r3 = r3.wrapping_add(-1 as i32 as i64 as u64)
    stxdw [r4+0x8], r3                      
lbb_9299:
    ldxdw r3, [r1+0x0]                      
    add64 r3, -1                                    r3 += -1   ///  r3 = r3.wrapping_add(-1 as i32 as i64 as u64)
    stxdw [r1+0x0], r3                      
    jne r3, 0, lbb_9306                             if r3 != (0 as i32 as i64 as u64) { pc += 3 }
    ldxdw r3, [r1+0x8]                      
    add64 r3, -1                                    r3 += -1   ///  r3 = r3.wrapping_add(-1 as i32 as i64 as u64)
    stxdw [r1+0x8], r3                      
lbb_9306:
    ldxdw r1, [r10-0x80]                    
    ldxdw r4, [r10-0x88]                    
    ldxdw r3, [r4+0x0]                      
    add64 r3, -1                                    r3 += -1   ///  r3 = r3.wrapping_add(-1 as i32 as i64 as u64)
    stxdw [r4+0x0], r3                      
    jne r3, 0, lbb_9315                             if r3 != (0 as i32 as i64 as u64) { pc += 3 }
    ldxdw r3, [r4+0x8]                      
    add64 r3, -1                                    r3 += -1   ///  r3 = r3.wrapping_add(-1 as i32 as i64 as u64)
    stxdw [r4+0x8], r3                      
lbb_9315:
    ldxdw r3, [r1+0x0]                      
    add64 r3, -1                                    r3 += -1   ///  r3 = r3.wrapping_add(-1 as i32 as i64 as u64)
    stxdw [r1+0x0], r3                      
    jne r3, 0, lbb_9322                             if r3 != (0 as i32 as i64 as u64) { pc += 3 }
    ldxdw r3, [r1+0x8]                      
    add64 r3, -1                                    r3 += -1   ///  r3 = r3.wrapping_add(-1 as i32 as i64 as u64)
    stxdw [r1+0x8], r3                      
lbb_9322:
    mov64 r1, r10                                   r1 = r10
    add64 r1, -240                                  r1 += -240   ///  r1 = r1.wrapping_add(-240 as i32 as i64 as u64)
    call function_39192                     
    ldxw r1, [r10-0xf0]                     
    jeq r1, 24, lbb_9328                            if r1 == (24 as i32 as i64 as u64) { pc += 1 }
    ja lbb_10132                                    if true { pc += 804 }
lbb_9328:
    ldxdw r9, [r10-0xe0]                    
    ldxdw r7, [r10-0xe8]                    
    ldxdw r3, [r7+0x8]                      
    ldxdw r1, [r10-0x148]                   
    jeq r3, r1, lbb_9334                            if r3 == r1 { pc += 1 }
    ja lbb_10138                                    if true { pc += 804 }
lbb_9334:
    mov64 r6, 2                                     r6 = 2 as i32 as i64 as u64
    jeq r3, 0, lbb_10221                            if r3 == (0 as i32 as i64 as u64) { pc += 885 }
    ldxdw r1, [r7+0x0]                      
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
    call function_48291                     
    ldxdw r1, [r7+0x8]                      
    jne r1, 8492, lbb_10221                         if r1 != (8492 as i32 as i64 as u64) { pc += 880 }
    ldxdw r3, [r7+0x0]                      
    mov64 r1, r3                                    r1 = r3
    and64 r1, 3                                     r1 &= 3   ///  r1 = r1.and(3)
    mov64 r6, 0                                     r6 = 0 as i32 as i64 as u64
    jeq r1, 0, lbb_9347                             if r1 == (0 as i32 as i64 as u64) { pc += 1 }
    ja lbb_10221                                    if true { pc += 874 }
lbb_9347:
    stxb [r3+0x2125], r8                    
    ldxdw r1, [r10-0x278]                   
    stxb [r3+0x2124], r1                    
    ldxdw r8, [r10-0x248]                   
    ldxdw r1, [r8+0x0]                      
    ldxdw r2, [r8+0x8]                      
    ldxdw r4, [r8+0x10]                     
    ldxdw r5, [r8+0x18]                     
    stxdw [r3+0x18], r5                     
    stxdw [r3+0x10], r4                     
    stxdw [r3+0x8], r2                      
    stxdw [r3+0x0], r1                      
    mov64 r1, r10                                   r1 = r10
    add64 r1, -240                                  r1 += -240   ///  r1 = r1.wrapping_add(-240 as i32 as i64 as u64)
    ldxdw r2, [r10-0x270]                   
    call function_24868                     
    ldxb r0, [r10-0xf0]                     
    jeq r0, 56, lbb_9366                            if r0 == (56 as i32 as i64 as u64) { pc += 1 }
    ja lbb_10180                                    if true { pc += 814 }
lbb_9366:
    ldxdw r1, [r9+0x0]                      
    add64 r1, 1                                     r1 += 1   ///  r1 = r1.wrapping_add(1 as i32 as i64 as u64)
    stxdw [r9+0x0], r1                      
    ldxdw r7, [r10-0x260]                   
    ldxdw r9, [r10-0x290]                   
lbb_9371:
    mov64 r1, r7                                    r1 = r7
    call function_39132                     
    jne r0, 0, lbb_9377                             if r0 != (0 as i32 as i64 as u64) { pc += 3 }
    mov64 r1, r7                                    r1 = r7
    call function_39148                     
    jne r0, 0, lbb_10004                            if r0 != (0 as i32 as i64 as u64) { pc += 627 }
lbb_9377:
    mov64 r1, r10                                   r1 = r10
    add64 r1, -240                                  r1 += -240   ///  r1 = r1.wrapping_add(-240 as i32 as i64 as u64)
    mov64 r2, r7                                    r2 = r7
    call function_39176                     
    ldxw r2, [r10-0xf0]                     
    jeq r2, 24, lbb_9384                            if r2 == (24 as i32 as i64 as u64) { pc += 1 }
    ja lbb_9774                                     if true { pc += 390 }
lbb_9384:
    ldxdw r7, [r10-0xe0]                    
    ldxdw r2, [r10-0xe8]                    
    ldxdw r1, [r2+0x8]                      
    jne r1, 8492, lbb_9392                          if r1 != (8492 as i32 as i64 as u64) { pc += 4 }
    ldxdw r6, [r2+0x0]                      
    mov64 r2, r6                                    r2 = r6
    and64 r2, 3                                     r2 &= 3   ///  r2 = r2.and(3)
    jeq r2, 0, lbb_9405                             if r2 == (0 as i32 as i64 as u64) { pc += 13 }
lbb_9392:
    ldxdw r4, [r9+0x8]                      
    ldxdw r5, [r9+0x0]                      
    ldxdw r2, [r9+0x18]                     
    stxdw [r10-0x28], r2                    
    ldxdw r2, [r9+0x10]                     
    stxdw [r10-0x30], r2                    
    ldxdw r2, [r7+0x0]                      
    add64 r2, -1                                    r2 += -1   ///  r2 = r2.wrapping_add(-1 as i32 as i64 as u64)
    stxdw [r7+0x0], r2                      
    mov64 r0, 35                                    r0 = 35 as i32 as i64 as u64
    mov64 r2, 8492                                  r2 = 8492 as i32 as i64 as u64
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
    ja lbb_10015                                    if true { pc += 610 }
lbb_9405:
    ldxb r3, [r6+0x2124]                    
    ldxb r1, [r6+0x2125]                    
    stxdw [r10-0x1000], r1                  
    ldxdw r1, [r10-0x240]                   
    stxdw [r10-0xff8], r1                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -240                                  r1 += -240   ///  r1 = r1.wrapping_add(-240 as i32 as i64 as u64)
    mov64 r5, r10                                   r5 = r10
    mov64 r2, r9                                    r2 = r9
    mov64 r4, r8                                    r4 = r8
    call function_24320                     
    ldxb r9, [r10-0xf0]                     
    jeq r9, 56, lbb_9419                            if r9 == (56 as i32 as i64 as u64) { pc += 1 }
    ja lbb_9584                                     if true { pc += 165 }
lbb_9419:
    ldxdw r1, [r6+0x0]                      
    ldxdw r2, [r8+0x0]                      
    jeq r2, r1, lbb_9424                            if r2 == r1 { pc += 2 }
lbb_9422:
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    ja lbb_9434                                     if true { pc += 10 }
lbb_9424:
    ldxdw r1, [r6+0x8]                      
    ldxdw r2, [r8+0x8]                      
    jne r2, r1, lbb_9422                            if r2 != r1 { pc += -5 }
    ldxdw r1, [r6+0x10]                     
    ldxdw r2, [r8+0x10]                     
    jne r2, r1, lbb_9422                            if r2 != r1 { pc += -8 }
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    ldxdw r2, [r6+0x18]                     
    ldxdw r3, [r8+0x18]                     
    jne r3, r2, lbb_9422                            if r3 != r2 { pc += -12 }
lbb_9434:
    mov64 r2, 40                                    r2 = 40 as i32 as i64 as u64
    stxdw [r10-0x210], r2                   
    lddw r2, 0x100060c15 --> b"Instance dex does not match expected dexprogram/sr"        r2 load str located at 4295363605
    stxdw [r10-0x218], r2                   
    jeq r1, 0, lbb_9495                             if r1 == (0 as i32 as i64 as u64) { pc += 55 }
    lddw r1, 0x100065518 --> b"\x00\x00\x00\x00=\x0c\x06\x00\x1f\x00\x00\x00\x00\x00\x00\x00d\x00\x00\x0…        r1 load str located at 4295382296
    stxdw [r10-0x48], r1                    
    lddw r1, 0x100064c98 --> b"\x00\x00\x00\x00p\xfa\x05\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00…        r1 load str located at 4295380120
    stxdw [r10-0xf0], r1                    
    mov64 r1, 2                                     r1 = 2 as i32 as i64 as u64
    stxdw [r10-0xe8], r1                    
    stxdw [r10-0xd8], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -320                                  r1 += -320   ///  r1 = r1.wrapping_add(-320 as i32 as i64 as u64)
    stxdw [r10-0xe0], r1                    
    lddw r1, 0x100000888 --> b"y\x11\x00\x00\x00\x00\x00\x00\x85\x10\x00\x00]\xab\x00\x00\x95\x00\x00\x0…        r1 load str located at 4294969480
    stxdw [r10-0x128], r1                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -72                                   r1 += -72   ///  r1 = r1.wrapping_add(-72 as i32 as i64 as u64)
    stxdw [r10-0x130], r1                   
    lddw r1, 0x100000860 --> b"\xbf#\x00\x00\x00\x00\x00\x00y\x12\x08\x00\x00\x00\x00\x00y\x11\x00\x00\x…        r1 load str located at 4294969440
    stxdw [r10-0x138], r1                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -536                                  r1 += -536   ///  r1 = r1.wrapping_add(-536 as i32 as i64 as u64)
    stxdw [r10-0x140], r1                   
    mov64 r8, 0                                     r8 = 0 as i32 as i64 as u64
    stxdw [r10-0xd0], r8                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -48                                   r1 += -48   ///  r1 = r1.wrapping_add(-48 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -240                                  r2 += -240   ///  r2 = r2.wrapping_add(-240 as i32 as i64 as u64)
    call function_43415                     
    ldxdw r1, [r10-0x30]                    
    ldxdw r2, [r10-0x20]                    
    syscall [invalid]                       
    lddw r1, 0x300000000                            r1 load str located at 12884901888
    ldxdw r1, [r1+0x0]                      
    mov64 r3, 1                                     r3 = 1 as i32 as i64 as u64
    mov64 r2, r1                                    r2 = r1
    add64 r2, -32                                   r2 += -32   ///  r2 = r2.wrapping_add(-32 as i32 as i64 as u64)
    jgt r2, r1, lbb_9482                            if r2 > r1 { pc += 1 }
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
lbb_9482:
    jne r3, 0, lbb_9484                             if r3 != (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r8, r2                                    r8 = r2
lbb_9484:
    lddw r4, 0x300007fe0                            r4 load str located at 12884934624
    jeq r1, 0, lbb_9488                             if r1 == (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r4, r8                                    r4 = r8
lbb_9488:
    lddw r1, 0x300000007                            r1 load str located at 12884901895
    jgt r4, r1, lbb_9780                            if r4 > r1 { pc += 289 }
lbb_9491:
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    mov64 r2, 32                                    r2 = 32 as i32 as i64 as u64
    call function_43400                     
    syscall [invalid]                       
lbb_9495:
    ldxb r3, [r6+0x2125]                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -240                                  r1 += -240   ///  r1 = r1.wrapping_add(-240 as i32 as i64 as u64)
    ldxdw r8, [r10-0x270]                   
    mov64 r2, r8                                    r2 = r8
    call function_24666                     
    ldxb r9, [r10-0xf0]                     
    jeq r9, 56, lbb_9504                            if r9 == (56 as i32 as i64 as u64) { pc += 1 }
    ja lbb_9584                                     if true { pc += 80 }
lbb_9504:
    ldxb r3, [r6+0x2125]                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -320                                  r1 += -320   ///  r1 = r1.wrapping_add(-320 as i32 as i64 as u64)
    mov64 r2, r8                                    r2 = r8
    call function_24666                     
    ldxb r8, [r10-0x140]                    
    jeq r8, 56, lbb_9512                            if r8 == (56 as i32 as i64 as u64) { pc += 1 }
    ja lbb_9835                                     if true { pc += 323 }
lbb_9512:
    ldxdw r1, [r10-0x278]                   
    ldxb r2, [r6+0x2124]                    
    jeq r2, r1, lbb_9516                            if r2 == r1 { pc += 1 }
    ja lbb_9843                                     if true { pc += 327 }
lbb_9516:
    ldxdw r2, [r10-0x258]                   
    and64 r2, 255                                   r2 &= 255   ///  r2 = r2.and(255)
    ldxb r1, [r6+0x2125]                    
    jeq r1, r2, lbb_9521                            if r1 == r2 { pc += 1 }
    ja lbb_9874                                     if true { pc += 353 }
lbb_9521:
    ldxdw r3, [r10-0x248]                   
    ldxdw r1, [r3+0x0]                      
    ldxdw r2, [r6+0x0]                      
    jeq r2, r1, lbb_9527                            if r2 == r1 { pc += 2 }
lbb_9525:
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    ja lbb_9537                                     if true { pc += 10 }
lbb_9527:
    ldxdw r1, [r3+0x8]                      
    ldxdw r2, [r6+0x8]                      
    jne r2, r1, lbb_9525                            if r2 != r1 { pc += -5 }
    ldxdw r1, [r3+0x10]                     
    ldxdw r2, [r6+0x10]                     
    jne r2, r1, lbb_9525                            if r2 != r1 { pc += -8 }
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    ldxdw r2, [r3+0x18]                     
    ldxdw r3, [r6+0x18]                     
    jne r3, r2, lbb_9525                            if r3 != r2 { pc += -12 }
lbb_9537:
    ldxdw r3, [r10-0x268]                   
    jeq r1, 0, lbb_9561                             if r1 == (0 as i32 as i64 as u64) { pc += 22 }
    lddw r1, 0x300000000                            r1 load str located at 12884901888
    ldxdw r2, [r1+0x0]                      
    mov64 r1, r2                                    r1 = r2
    add64 r1, -26                                   r1 += -26   ///  r1 = r1.wrapping_add(-26 as i32 as i64 as u64)
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
    mov64 r4, 1                                     r4 = 1 as i32 as i64 as u64
    jgt r1, r2, lbb_9548                            if r1 > r2 { pc += 1 }
    mov64 r4, 0                                     r4 = 0 as i32 as i64 as u64
lbb_9548:
    jne r4, 0, lbb_9550                             if r4 != (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r3, r1                                    r3 = r1
lbb_9550:
    lddw r1, 0x300007fe6                            r1 load str located at 12884934630
    jeq r2, 0, lbb_9554                             if r2 == (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r1, r3                                    r1 = r3
lbb_9554:
    lddw r2, 0x300000007                            r2 load str located at 12884901895
    jgt r1, r2, lbb_9976                            if r1 > r2 { pc += 419 }
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    mov64 r2, 26                                    r2 = 26 as i32 as i64 as u64
    call function_43400                     
    syscall [invalid]                       
lbb_9561:
    mov64 r1, 24                                    r1 = 24 as i32 as i64 as u64
    ldxdw r2, [r10-0x250]                   
    stxw [r2+0x0], r1                       
    ldxdw r1, [r7+0x0]                      
    add64 r1, -1                                    r1 += -1   ///  r1 = r1.wrapping_add(-1 as i32 as i64 as u64)
    stxdw [r7+0x0], r1                      
    ldxdw r1, [r3+0x0]                      
    add64 r1, 1                                     r1 += 1   ///  r1 = r1.wrapping_add(1 as i32 as i64 as u64)
    stxdw [r3+0x0], r1                      
    ja lbb_10077                                    if true { pc += 506 }
lbb_9571:
    lddw r1, 0x300000000                            r1 load str located at 12884901888
    stxdw [r1+0x0], r6                      
    mov64 r7, 41                                    r7 = 41 as i32 as i64 as u64
    mov64 r1, r6                                    r1 = r6
    lddw r2, 0x100060014 --> b"Incorrect system program account provided"        r2 load str located at 4295360532
    mov64 r3, 41                                    r3 = 41 as i32 as i64 as u64
    call function_48190                     
    stxdw [r10-0xd8], r7                    
    stxdw [r10-0xe0], r7                    
    stxdw [r10-0xe8], r6                    
    ja lbb_8893                                     if true { pc += -691 }
lbb_9584:
    ldxw r1, [r10-0xec]                     
    stxw [r10-0x5d], r1                     
    ldxw r1, [r10-0xef]                     
    stxw [r10-0x60], r1                     
    ldxdw r1, [r10-0xe8]                    
    stxdw [r10-0x240], r1                   
    ldxdw r6, [r10-0xe0]                    
    ldxdw r8, [r10-0xd8]                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -496                                  r1 += -496   ///  r1 = r1.wrapping_add(-496 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -208                                  r2 += -208   ///  r2 = r2.wrapping_add(-208 as i32 as i64 as u64)
    mov64 r3, 40                                    r3 = 40 as i32 as i64 as u64
    call function_48190                     
    ja lbb_9830                                     if true { pc += 231 }
lbb_9599:
    ldxdw r2, [r8+0x0]                      
    ldxw r1, [r2+0x3]                       
    stxw [r10-0x215], r1                    
    ldxw r1, [r2+0x0]                       
    stxw [r10-0x218], r1                    
    mov64 r0, 40                                    r0 = 40 as i32 as i64 as u64
    ja lbb_9915                                     if true { pc += 309 }
lbb_9606:
    mov64 r0, 55                                    r0 = 55 as i32 as i64 as u64
    ldxdw r1, [r10-0xe8]                    
    ldxdw r3, [r10-0xd8]                    
    ldxdw r5, [r10-0xe0]                    
    ldxw r4, [r10-0xec]                     
    ja lbb_9921                                     if true { pc += 309 }
lbb_9612:
    ldxw r1, [r10-0xec]                     
    stxw [r10-0x235], r1                    
    ldxw r1, [r10-0xef]                     
    stxw [r10-0x238], r1                    
    ldxdw r6, [r10-0xe8]                    
    ldxdw r7, [r10-0xe0]                    
    ldxdw r9, [r10-0xd8]                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -496                                  r1 += -496   ///  r1 = r1.wrapping_add(-496 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -208                                  r2 += -208   ///  r2 = r2.wrapping_add(-208 as i32 as i64 as u64)
    mov64 r3, 40                                    r3 = 40 as i32 as i64 as u64
    call function_48190                     
    ldxdw r2, [r10-0x268]                   
    ldxdw r1, [r2+0x0]                      
    add64 r1, 1                                     r1 += 1   ///  r1 = r1.wrapping_add(1 as i32 as i64 as u64)
    stxdw [r2+0x0], r1                      
    ja lbb_9961                                     if true { pc += 331 }
lbb_9630:
    lddw r1, 0x1000650f0 --> b"\x00\x00\x00\x00]\x04\x06\x00(\x00\x00\x00\x00\x00\x00\x008\x00\x00\x00\x…        r1 load str located at 4295381232
    stxdw [r10-0x238], r1                   
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    stxdw [r10-0xd0], r1                    
    lddw r1, 0x100064c98 --> b"\x00\x00\x00\x00p\xfa\x05\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00…        r1 load str located at 4295380120
    stxdw [r10-0xf0], r1                    
    mov64 r1, 2                                     r1 = 2 as i32 as i64 as u64
    stxdw [r10-0xe8], r1                    
    stxdw [r10-0xd8], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -496                                  r1 += -496   ///  r1 = r1.wrapping_add(-496 as i32 as i64 as u64)
    stxdw [r10-0xe0], r1                    
    lddw r1, 0x100000888 --> b"y\x11\x00\x00\x00\x00\x00\x00\x85\x10\x00\x00]\xab\x00\x00\x95\x00\x00\x0…        r1 load str located at 4294969480
    stxdw [r10-0x1d8], r1                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -568                                  r1 += -568   ///  r1 = r1.wrapping_add(-568 as i32 as i64 as u64)
    stxdw [r10-0x1e0], r1                   
    lddw r1, 0x100000860 --> b"\xbf#\x00\x00\x00\x00\x00\x00y\x12\x08\x00\x00\x00\x00\x00y\x11\x00\x00\x…        r1 load str located at 4294969440
    stxdw [r10-0x1e8], r1                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -536                                  r1 += -536   ///  r1 = r1.wrapping_add(-536 as i32 as i64 as u64)
    stxdw [r10-0x1f0], r1                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -48                                   r1 += -48   ///  r1 = r1.wrapping_add(-48 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -240                                  r2 += -240   ///  r2 = r2.wrapping_add(-240 as i32 as i64 as u64)
    call function_43415                     
    ldxdw r1, [r10-0x30]                    
    ldxdw r2, [r10-0x20]                    
    syscall [invalid]                       
    ldxdw r1, [r9+0x18]                     
    stxdw [r10-0x108], r1                   
    ldxdw r1, [r9+0x10]                     
    stxdw [r10-0x110], r1                   
    ldxdw r1, [r9+0x8]                      
    stxdw [r10-0x118], r1                   
    ldxdw r1, [r9+0x0]                      
    stxdw [r10-0x120], r1                   
    ldxdw r1, [r8+0x0]                      
    stxdw [r10-0x140], r1                   
    ldxdw r1, [r8+0x8]                      
    stxdw [r10-0x138], r1                   
    ldxdw r1, [r8+0x10]                     
    stxdw [r10-0x130], r1                   
    ldxdw r1, [r8+0x18]                     
    stxdw [r10-0x128], r1                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -239                                  r1 += -239   ///  r1 = r1.wrapping_add(-239 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -320                                  r2 += -320   ///  r2 = r2.wrapping_add(-320 as i32 as i64 as u64)
    mov64 r3, 71                                    r3 = 71 as i32 as i64 as u64
    call function_48190                     
    mov64 r1, 17                                    r1 = 17 as i32 as i64 as u64
    stxb [r10-0xf0], r1                     
    ja lbb_10069                                    if true { pc += 380 }
lbb_9689:
    ldxdw r1, [r10-0x127]                   
    stxdw [r10-0x1d8], r1                   
    ldxdw r1, [r10-0x12f]                   
    stxdw [r10-0x1e0], r1                   
    ldxdw r1, [r10-0x137]                   
    stxdw [r10-0x1e8], r1                   
    ldxdw r1, [r10-0x13f]                   
    stxdw [r10-0x1f0], r1                   
    ldxb r6, [r10-0x11f]                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -206                                  r1 += -206   ///  r1 = r1.wrapping_add(-206 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -286                                  r2 += -286   ///  r2 = r2.wrapping_add(-286 as i32 as i64 as u64)
    mov64 r3, 38                                    r3 = 38 as i32 as i64 as u64
    call function_48190                     
    stxb [r10-0xcf], r6                     
    stxb [r10-0xf0], r7                     
    ldxdw r1, [r10-0x1f0]                   
    stxdw [r10-0xef], r1                    
    ldxdw r1, [r10-0x1e8]                   
    stxdw [r10-0xe7], r1                    
    ldxdw r1, [r10-0x1e0]                   
    stxdw [r10-0xdf], r1                    
    ldxdw r1, [r10-0x1d8]                   
    stxdw [r10-0xd7], r1                    
    ja lbb_10069                                    if true { pc += 354 }
lbb_9715:
    lddw r1, 0x100065108 --> b"\x00\x00\x00\x00]\x04\x06\x00(\x00\x00\x00\x00\x00\x00\x00D\x00\x00\x00\x…        r1 load str located at 4295381256
    stxdw [r10-0x48], r1                    
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    stxdw [r10-0xd0], r1                    
    lddw r1, 0x100064c98 --> b"\x00\x00\x00\x00p\xfa\x05\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00…        r1 load str located at 4295380120
    stxdw [r10-0xf0], r1                    
    mov64 r1, 2                                     r1 = 2 as i32 as i64 as u64
    stxdw [r10-0xe8], r1                    
    stxdw [r10-0xd8], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -496                                  r1 += -496   ///  r1 = r1.wrapping_add(-496 as i32 as i64 as u64)
    stxdw [r10-0xe0], r1                    
    lddw r1, 0x100000888 --> b"y\x11\x00\x00\x00\x00\x00\x00\x85\x10\x00\x00]\xab\x00\x00\x95\x00\x00\x0…        r1 load str located at 4294969480
    stxdw [r10-0x1d8], r1                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -72                                   r1 += -72   ///  r1 = r1.wrapping_add(-72 as i32 as i64 as u64)
    stxdw [r10-0x1e0], r1                   
    lddw r1, 0x100000860 --> b"\xbf#\x00\x00\x00\x00\x00\x00y\x12\x08\x00\x00\x00\x00\x00y\x11\x00\x00\x…        r1 load str located at 4294969440
    stxdw [r10-0x1e8], r1                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -536                                  r1 += -536   ///  r1 = r1.wrapping_add(-536 as i32 as i64 as u64)
    stxdw [r10-0x1f0], r1                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -48                                   r1 += -48   ///  r1 = r1.wrapping_add(-48 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -240                                  r2 += -240   ///  r2 = r2.wrapping_add(-240 as i32 as i64 as u64)
    call function_43415                     
    ldxdw r1, [r10-0x30]                    
    ldxdw r2, [r10-0x20]                    
    syscall [invalid]                       
    ldxdw r1, [r10-0x220]                   
    stxdw [r10-0x128], r1                   
    ldxdw r1, [r10-0x228]                   
    stxdw [r10-0x130], r1                   
    ldxdw r1, [r10-0x230]                   
    stxdw [r10-0x138], r1                   
    ldxdw r1, [r10-0x238]                   
    stxdw [r10-0x140], r1                   
    ldxdw r1, [r9+0x0]                      
    stxdw [r10-0x120], r1                   
    ldxdw r1, [r9+0x8]                      
    stxdw [r10-0x118], r1                   
    ldxdw r1, [r9+0x10]                     
    stxdw [r10-0x110], r1                   
    ldxdw r1, [r9+0x18]                     
    stxdw [r10-0x108], r1                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -239                                  r1 += -239   ///  r1 = r1.wrapping_add(-239 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -320                                  r2 += -320   ///  r2 = r2.wrapping_add(-320 as i32 as i64 as u64)
    mov64 r3, 71                                    r3 = 71 as i32 as i64 as u64
    call function_48190                     
    mov64 r1, 25                                    r1 = 25 as i32 as i64 as u64
    stxb [r10-0xf0], r1                     
    ja lbb_10069                                    if true { pc += 295 }
lbb_9774:
    mov64 r0, 55                                    r0 = 55 as i32 as i64 as u64
    ldxdw r1, [r10-0xe8]                    
    ldxdw r4, [r10-0xd8]                    
    ldxdw r5, [r10-0xe0]                    
    ldxw r3, [r10-0xec]                     
    ja lbb_10015                                    if true { pc += 235 }
lbb_9780:
    lddw r1, 0x300000000                            r1 load str located at 12884901888
    stxdw [r1+0x0], r4                      
    ldxdw r3, [r10-0x248]                   
    ldxdw r2, [r3+0x18]                     
    stxdw [r4+0x18], r2                     
    ldxdw r2, [r3+0x10]                     
    stxdw [r4+0x10], r2                     
    ldxdw r2, [r3+0x8]                      
    stxdw [r4+0x8], r2                      
    ldxdw r2, [r3+0x0]                      
    stxdw [r10-0x240], r4                   
    stxdw [r4+0x0], r2                      
    ldxdw r2, [r6+0x18]                     
    stxdw [r10-0xd8], r2                    
    ldxdw r2, [r6+0x10]                     
    stxdw [r10-0xe0], r2                    
    ldxdw r2, [r6+0x8]                      
    stxdw [r10-0xe8], r2                    
    ldxdw r2, [r6+0x0]                      
    stxdw [r10-0xf0], r2                    
    ldxdw r1, [r1+0x0]                      
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
    mov64 r4, 1                                     r4 = 1 as i32 as i64 as u64
    mov64 r3, r1                                    r3 = r1
    add64 r3, -32                                   r3 += -32   ///  r3 = r3.wrapping_add(-32 as i32 as i64 as u64)
    jgt r3, r1, lbb_9808                            if r3 > r1 { pc += 1 }
    mov64 r4, 0                                     r4 = 0 as i32 as i64 as u64
lbb_9808:
    jne r4, 0, lbb_9810                             if r4 != (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r2, r3                                    r2 = r3
lbb_9810:
    lddw r6, 0x300007fe0                            r6 load str located at 12884934624
    jeq r1, 0, lbb_9814                             if r1 == (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r6, r2                                    r6 = r2
lbb_9814:
    lddw r1, 0x300000007                            r1 load str located at 12884901895
    jgt r6, r1, lbb_9818                            if r6 > r1 { pc += 1 }
    ja lbb_9491                                     if true { pc += -327 }
lbb_9818:
    lddw r1, 0x300000000                            r1 load str located at 12884901888
    stxdw [r1+0x0], r6                      
    ldxdw r1, [r10-0xd8]                    
    stxdw [r6+0x18], r1                     
    ldxdw r1, [r10-0xe0]                    
    stxdw [r6+0x10], r1                     
    ldxdw r1, [r10-0xe8]                    
    stxdw [r6+0x8], r1                      
    ldxdw r1, [r10-0xf0]                    
    stxdw [r6+0x0], r1                      
    mov64 r9, 26                                    r9 = 26 as i32 as i64 as u64
lbb_9830:
    ldxdw r1, [r7+0x0]                      
    add64 r1, -1                                    r1 += -1   ///  r1 = r1.wrapping_add(-1 as i32 as i64 as u64)
    stxdw [r7+0x0], r1                      
    ldxdw r7, [r10-0x240]                   
    ja lbb_10055                                    if true { pc += 220 }
lbb_9835:
    mov64 r1, r10                                   r1 = r10
    add64 r1, -239                                  r1 += -239   ///  r1 = r1.wrapping_add(-239 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -319                                  r2 += -319   ///  r2 = r2.wrapping_add(-319 as i32 as i64 as u64)
    mov64 r3, 71                                    r3 = 71 as i32 as i64 as u64
    call function_48190                     
    stxb [r10-0xf0], r8                     
    ja lbb_9996                                     if true { pc += 153 }
lbb_9843:
    lddw r1, 0x300000000                            r1 load str located at 12884901888
    ldxdw r1, [r1+0x0]                      
    mov64 r3, r1                                    r3 = r1
    add64 r3, -42                                   r3 += -42   ///  r3 = r3.wrapping_add(-42 as i32 as i64 as u64)
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
    mov64 r4, 1                                     r4 = 1 as i32 as i64 as u64
    jgt r3, r1, lbb_9852                            if r3 > r1 { pc += 1 }
    mov64 r4, 0                                     r4 = 0 as i32 as i64 as u64
lbb_9852:
    jne r4, 0, lbb_9854                             if r4 != (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r2, r3                                    r2 = r3
lbb_9854:
    lddw r6, 0x300007fd6                            r6 load str located at 12884934614
    jeq r1, 0, lbb_9858                             if r1 == (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r6, r2                                    r6 = r2
lbb_9858:
    lddw r1, 0x300000007                            r1 load str located at 12884901895
    jgt r6, r1, lbb_9865                            if r6 > r1 { pc += 4 }
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    mov64 r2, 42                                    r2 = 42 as i32 as i64 as u64
    call function_43400                     
    syscall [invalid]                       
lbb_9865:
    lddw r1, 0x300000000                            r1 load str located at 12884901888
    stxdw [r1+0x0], r6                      
    mov64 r8, 42                                    r8 = 42 as i32 as i64 as u64
    mov64 r1, r6                                    r1 = r6
    lddw r2, 0x1000603c5 --> b"Bump mismatch even after validated loading"        r2 load str located at 4295361477
    mov64 r3, 42                                    r3 = 42 as i32 as i64 as u64
    ja lbb_9904                                     if true { pc += 30 }
lbb_9874:
    lddw r1, 0x300000000                            r1 load str located at 12884901888
    ldxdw r1, [r1+0x0]                      
    mov64 r3, r1                                    r3 = r1
    add64 r3, -34                                   r3 += -34   ///  r3 = r3.wrapping_add(-34 as i32 as i64 as u64)
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
    mov64 r4, 1                                     r4 = 1 as i32 as i64 as u64
    jgt r3, r1, lbb_9883                            if r3 > r1 { pc += 1 }
    mov64 r4, 0                                     r4 = 0 as i32 as i64 as u64
lbb_9883:
    jne r4, 0, lbb_9885                             if r4 != (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r2, r3                                    r2 = r3
lbb_9885:
    lddw r6, 0x300007fde                            r6 load str located at 12884934622
    jeq r1, 0, lbb_9889                             if r1 == (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r6, r2                                    r6 = r2
lbb_9889:
    lddw r1, 0x300000007                            r1 load str located at 12884901895
    jgt r6, r1, lbb_9896                            if r6 > r1 { pc += 4 }
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    mov64 r2, 34                                    r2 = 34 as i32 as i64 as u64
    call function_43400                     
    syscall [invalid]                       
lbb_9896:
    lddw r1, 0x300000000                            r1 load str located at 12884901888
    stxdw [r1+0x0], r6                      
    mov64 r8, 34                                    r8 = 34 as i32 as i64 as u64
    mov64 r1, r6                                    r1 = r6
    lddw r2, 0x1000604bd --> b"Instance ID mismatch after loading"        r2 load str located at 4295361725
    mov64 r3, 34                                    r3 = 34 as i32 as i64 as u64
lbb_9904:
    call function_48190                     
    stxdw [r10-0xd8], r8                    
    stxdw [r10-0xe0], r8                    
    stxdw [r10-0xe8], r6                    
    ja lbb_9994                                     if true { pc += 85 }
lbb_9909:
    ldxdw r2, [r8+0x0]                      
    ldxw r1, [r2+0x3]                       
    stxw [r10-0x215], r1                    
    ldxw r1, [r2+0x0]                       
    stxw [r10-0x218], r1                    
    mov64 r0, 37                                    r0 = 37 as i32 as i64 as u64
lbb_9915:
    ldxb r3, [r2+0x1f]                      
    ldxdw r5, [r2+0x17]                     
    ldxdw r1, [r2+0xf]                      
    ldxdw r2, [r2+0x7]                      
    mov64 r4, r2                                    r4 = r2
    rsh64 r4, 32                                    r4 >>= 32   ///  r4 = r4.wrapping_shr(32)
lbb_9921:
    stxb [r10-0xf0], r0                     
    ldxw r0, [r10-0x218]                    
    stxw [r10-0xef], r0                     
    ldxw r0, [r10-0x215]                    
    stxw [r10-0xec], r0                     
    stxdw [r10-0xd0], r3                    
    stxdw [r10-0xd8], r5                    
    stxdw [r10-0xe0], r1                    
    ldxdw r1, [r10-0x30]                    
    stxdw [r10-0xc8], r1                    
    ldxdw r1, [r10-0x28]                    
    stxdw [r10-0xc0], r1                    
    ldxdw r1, [r10-0x20]                    
    stxdw [r10-0xb8], r1                    
    ldxdw r1, [r10-0x18]                    
    stxdw [r10-0xb0], r1                    
    lsh64 r4, 32                                    r4 <<= 32   ///  r4 = r4.wrapping_shl(32)
    lsh64 r2, 32                                    r2 <<= 32   ///  r2 = r2.wrapping_shl(32)
    rsh64 r2, 32                                    r2 >>= 32   ///  r2 = r2.wrapping_shr(32)
    or64 r4, r2                                     r4 |= r2   ///  r4 = r4.or(r2)
    stxdw [r10-0xe8], r4                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -312                                  r1 += -312   ///  r1 = r1.wrapping_add(-312 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -240                                  r2 += -240   ///  r2 = r2.wrapping_add(-240 as i32 as i64 as u64)
    call function_26067                     
    ldxw r1, [r10-0x13f]                    
    stxw [r10-0x238], r1                    
    ldxw r1, [r10-0x13c]                    
    stxw [r10-0x235], r1                    
    ldxdw r6, [r10-0x138]                   
    ldxdw r7, [r10-0x130]                   
    ldxdw r9, [r10-0x128]                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -496                                  r1 += -496   ///  r1 = r1.wrapping_add(-496 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -288                                  r2 += -288   ///  r2 = r2.wrapping_add(-288 as i32 as i64 as u64)
    mov64 r3, 40                                    r3 = 40 as i32 as i64 as u64
    call function_48190                     
    mov64 r8, 55                                    r8 = 55 as i32 as i64 as u64
lbb_9961:
    ldxw r1, [r10-0x235]                    
    stxw [r10-0xec], r1                     
    ldxw r1, [r10-0x238]                    
    stxw [r10-0xef], r1                     
    mov64 r1, r10                                   r1 = r10
    add64 r1, -208                                  r1 += -208   ///  r1 = r1.wrapping_add(-208 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -496                                  r2 += -496   ///  r2 = r2.wrapping_add(-496 as i32 as i64 as u64)
    mov64 r3, 40                                    r3 = 40 as i32 as i64 as u64
    call function_48190                     
    stxdw [r10-0xd8], r9                    
    stxdw [r10-0xe0], r7                    
    stxdw [r10-0xe8], r6                    
    stxb [r10-0xf0], r8                     
    ja lbb_8895                                     if true { pc += -1081 }
lbb_9976:
    lddw r2, 0x300000000                            r2 load str located at 12884901888
    stxdw [r2+0x0], r1                      
    mov64 r2, 26478                                 r2 = 26478 as i32 as i64 as u64
    stxh [r1+0x18], r2                      
    lddw r2, 0x6964616f6c207265                     r2 load str located at 7594302002836828773
    stxdw [r1+0x10], r2                     
    lddw r2, 0x7466612068637461                     r2 load str located at 8387498147842323553
    stxdw [r1+0x8], r2                      
    lddw r2, 0x6d73696d20786544                     r2 load str located at 7886763289872983364
    stxdw [r1+0x0], r2                      
    mov64 r2, 26                                    r2 = 26 as i32 as i64 as u64
    stxdw [r10-0xd8], r2                    
    stxdw [r10-0xe0], r2                    
    stxdw [r10-0xe8], r1                    
lbb_9994:
    mov64 r1, 29                                    r1 = 29 as i32 as i64 as u64
    stxb [r10-0xf0], r1                     
lbb_9996:
    mov64 r2, r10                                   r2 = r10
    add64 r2, -240                                  r2 += -240   ///  r2 = r2.wrapping_add(-240 as i32 as i64 as u64)
    ldxdw r1, [r10-0x250]                   
    call function_26067                     
    ldxdw r1, [r7+0x0]                      
    add64 r1, -1                                    r1 += -1   ///  r1 = r1.wrapping_add(-1 as i32 as i64 as u64)
    stxdw [r7+0x0], r1                      
    ja lbb_10073                                    if true { pc += 69 }
lbb_10004:
    ldxw r1, [r9+0x3]                       
    stxw [r10-0x215], r1                    
    ldxw r1, [r9+0x0]                       
    stxw [r10-0x218], r1                    
    mov64 r0, 37                                    r0 = 37 as i32 as i64 as u64
    ldxb r4, [r9+0x1f]                      
    ldxdw r5, [r9+0x17]                     
    ldxdw r1, [r9+0xf]                      
    ldxdw r2, [r9+0x7]                      
    mov64 r3, r2                                    r3 = r2
    rsh64 r3, 32                                    r3 >>= 32   ///  r3 = r3.wrapping_shr(32)
lbb_10015:
    stxb [r10-0xf0], r0                     
    ldxw r0, [r10-0x218]                    
    stxw [r10-0xef], r0                     
    ldxw r0, [r10-0x215]                    
    stxw [r10-0xec], r0                     
    stxdw [r10-0xd0], r4                    
    stxdw [r10-0xd8], r5                    
    stxdw [r10-0xe0], r1                    
    ldxdw r1, [r10-0x30]                    
    stxdw [r10-0xc8], r1                    
    ldxdw r1, [r10-0x28]                    
    stxdw [r10-0xc0], r1                    
    ldxdw r1, [r10-0x20]                    
    stxdw [r10-0xb8], r1                    
    ldxdw r1, [r10-0x18]                    
    stxdw [r10-0xb0], r1                    
    lsh64 r3, 32                                    r3 <<= 32   ///  r3 = r3.wrapping_shl(32)
    lsh64 r2, 32                                    r2 <<= 32   ///  r2 = r2.wrapping_shl(32)
    rsh64 r2, 32                                    r2 >>= 32   ///  r2 = r2.wrapping_shr(32)
    or64 r3, r2                                     r3 |= r2   ///  r3 = r3.or(r2)
    stxdw [r10-0xe8], r3                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -312                                  r1 += -312   ///  r1 = r1.wrapping_add(-312 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -240                                  r2 += -240   ///  r2 = r2.wrapping_add(-240 as i32 as i64 as u64)
    call function_26067                     
    ldxw r1, [r10-0x13f]                    
    stxw [r10-0x60], r1                     
    ldxw r1, [r10-0x13c]                    
    stxw [r10-0x5d], r1                     
    ldxdw r7, [r10-0x138]                   
    ldxdw r6, [r10-0x130]                   
    ldxdw r8, [r10-0x128]                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -496                                  r1 += -496   ///  r1 = r1.wrapping_add(-496 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -288                                  r2 += -288   ///  r2 = r2.wrapping_add(-288 as i32 as i64 as u64)
    mov64 r3, 40                                    r3 = 40 as i32 as i64 as u64
    call function_48190                     
    mov64 r9, 55                                    r9 = 55 as i32 as i64 as u64
lbb_10055:
    ldxw r1, [r10-0x5d]                     
    stxw [r10-0xec], r1                     
    ldxw r1, [r10-0x60]                     
    stxw [r10-0xef], r1                     
    mov64 r1, r10                                   r1 = r10
    add64 r1, -208                                  r1 += -208   ///  r1 = r1.wrapping_add(-208 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -496                                  r2 += -496   ///  r2 = r2.wrapping_add(-496 as i32 as i64 as u64)
    mov64 r3, 40                                    r3 = 40 as i32 as i64 as u64
    call function_48190                     
    stxdw [r10-0xd8], r8                    
    stxdw [r10-0xe0], r6                    
    stxdw [r10-0xe8], r7                    
    stxb [r10-0xf0], r9                     
lbb_10069:
    mov64 r2, r10                                   r2 = r10
    add64 r2, -240                                  r2 += -240   ///  r2 = r2.wrapping_add(-240 as i32 as i64 as u64)
    ldxdw r1, [r10-0x250]                   
    call function_26067                     
lbb_10073:
    ldxdw r2, [r10-0x268]                   
    ldxdw r1, [r2+0x0]                      
    add64 r1, 1                                     r1 += 1   ///  r1 = r1.wrapping_add(1 as i32 as i64 as u64)
    stxdw [r2+0x0], r1                      
lbb_10077:
    exit                                    
lbb_10078:
    ldxdw r0, [r10-0xe0]                    
    ldxdw r3, [r10-0x18]                    
    ldxdw r2, [r10-0x20]                    
    ldxdw r4, [r10-0x28]                    
    ldxw r5, [r10-0x2c]                     
    ldxdw r6, [r10-0xe8]                    
    ldxdw r7, [r6+0x0]                      
    add64 r7, -1                                    r7 += -1   ///  r7 = r7.wrapping_add(-1 as i32 as i64 as u64)
    stxdw [r6+0x0], r7                      
    jne r7, 0, lbb_10091                            if r7 != (0 as i32 as i64 as u64) { pc += 3 }
    ldxdw r7, [r6+0x8]                      
    add64 r7, -1                                    r7 += -1   ///  r7 = r7.wrapping_add(-1 as i32 as i64 as u64)
    stxdw [r6+0x8], r7                      
lbb_10091:
    ldxdw r6, [r0+0x0]                      
    add64 r6, -1                                    r6 += -1   ///  r6 = r6.wrapping_add(-1 as i32 as i64 as u64)
    stxdw [r0+0x0], r6                      
    jne r6, 0, lbb_10098                            if r6 != (0 as i32 as i64 as u64) { pc += 3 }
    ldxdw r6, [r0+0x8]                      
    add64 r6, -1                                    r6 += -1   ///  r6 = r6.wrapping_add(-1 as i32 as i64 as u64)
    stxdw [r0+0x8], r6                      
lbb_10098:
    ldxdw r0, [r10-0xb0]                    
    ldxdw r6, [r10-0xb8]                    
    ldxdw r7, [r6+0x0]                      
    add64 r7, -1                                    r7 += -1   ///  r7 = r7.wrapping_add(-1 as i32 as i64 as u64)
    stxdw [r6+0x0], r7                      
    jne r7, 0, lbb_10107                            if r7 != (0 as i32 as i64 as u64) { pc += 3 }
    ldxdw r7, [r6+0x8]                      
    add64 r7, -1                                    r7 += -1   ///  r7 = r7.wrapping_add(-1 as i32 as i64 as u64)
    stxdw [r6+0x8], r7                      
lbb_10107:
    ldxdw r6, [r0+0x0]                      
    add64 r6, -1                                    r6 += -1   ///  r6 = r6.wrapping_add(-1 as i32 as i64 as u64)
    stxdw [r0+0x0], r6                      
    jne r6, 0, lbb_10114                            if r6 != (0 as i32 as i64 as u64) { pc += 3 }
    ldxdw r6, [r0+0x8]                      
    add64 r6, -1                                    r6 += -1   ///  r6 = r6.wrapping_add(-1 as i32 as i64 as u64)
    stxdw [r0+0x8], r6                      
lbb_10114:
    ldxdw r0, [r10-0x80]                    
    ldxdw r6, [r10-0x88]                    
    ldxdw r7, [r6+0x0]                      
    add64 r7, -1                                    r7 += -1   ///  r7 = r7.wrapping_add(-1 as i32 as i64 as u64)
    stxdw [r6+0x0], r7                      
    jne r7, 0, lbb_10123                            if r7 != (0 as i32 as i64 as u64) { pc += 3 }
    ldxdw r7, [r6+0x8]                      
    add64 r7, -1                                    r7 += -1   ///  r7 = r7.wrapping_add(-1 as i32 as i64 as u64)
    stxdw [r6+0x8], r7                      
lbb_10123:
    ldxdw r6, [r0+0x0]                      
    add64 r6, -1                                    r6 += -1   ///  r6 = r6.wrapping_add(-1 as i32 as i64 as u64)
    stxdw [r0+0x0], r6                      
    jne r6, 0, lbb_10130                            if r6 != (0 as i32 as i64 as u64) { pc += 3 }
    ldxdw r6, [r0+0x8]                      
    add64 r6, -1                                    r6 += -1   ///  r6 = r6.wrapping_add(-1 as i32 as i64 as u64)
    stxdw [r0+0x8], r6                      
lbb_10130:
    mov64 r0, 55                                    r0 = 55 as i32 as i64 as u64
    ja lbb_10137                                    if true { pc += 5 }
lbb_10132:
    mov64 r0, 55                                    r0 = 55 as i32 as i64 as u64
    ldxdw r2, [r10-0xe0]                    
    ldxdw r4, [r10-0xe8]                    
    ldxdw r3, [r10-0xd8]                    
lbb_10136:
    ldxw r5, [r10-0xec]                     
lbb_10137:
    ja lbb_10201                                    if true { pc += 63 }
lbb_10138:
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    stxdw [r10-0x10], r1                    
    lddw r1, 0x1000656d8 --> b"\x00\x00\x00\x00\x80\x09\x06\x00\x08\x00\x00\x00\x00\x00\x00\x00\x00\x00\…        r1 load str located at 4295382744
    stxdw [r10-0x30], r1                    
    mov64 r1, 3                                     r1 = 3 as i32 as i64 as u64
    stxdw [r10-0x28], r1                    
    stxdw [r10-0x18], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -240                                  r1 += -240   ///  r1 = r1.wrapping_add(-240 as i32 as i64 as u64)
    stxdw [r10-0x20], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -328                                  r1 += -328   ///  r1 = r1.wrapping_add(-328 as i32 as i64 as u64)
    stxdw [r10-0xd0], r1                    
    lddw r1, 0x10005df58 --> b"\xbf#\x00\x00\x00\x00\x00\x00y\x11\x00\x00\x00\x00\x00\x00\xb7\x02\x00\x0…        r1 load str located at 4295352152
    stxdw [r10-0xc8], r1                    
    stxdw [r10-0xd8], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -96                                   r1 += -96   ///  r1 = r1.wrapping_add(-96 as i32 as i64 as u64)
    stxdw [r10-0xe0], r1                    
    lddw r1, 0x1000008a0 --> b"y\x11\x00\x00\x00\x00\x00\x00\x85\x10\x00\x00*\x99\x00\x00\x95\x00\x00\x0…        r1 load str located at 4294969504
    stxdw [r10-0xe8], r1                    
    ldxdw r1, [r10-0x260]                   
    stxdw [r10-0xf0], r1                    
    stxdw [r10-0x60], r3                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -72                                   r1 += -72   ///  r1 = r1.wrapping_add(-72 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -48                                   r2 += -48   ///  r2 = r2.wrapping_add(-48 as i32 as i64 as u64)
    call function_445                       
    ldxw r1, [r10-0x4e]                     
    stxw [r10-0x1f8], r1                    
    ldxh r1, [r10-0x4a]                     
    stxh [r10-0x1f4], r1                    
    mov64 r0, 29                                    r0 = 29 as i32 as i64 as u64
    ldxdw r2, [r10-0x38]                    
    ldxdw r4, [r10-0x40]                    
    ldxw r5, [r10-0x44]                     
    ldxw r1, [r10-0x48]                     
    ja lbb_10198                                    if true { pc += 18 }
lbb_10180:
    ldxw r1, [r10-0xee]                     
    stxw [r10-0x1f8], r1                    
    ldxh r1, [r10-0xea]                     
    stxh [r10-0x1f4], r1                    
    ldxdw r1, [r10-0xc8]                    
    stxdw [r10-0x218], r1                   
    ldxdw r1, [r10-0xc0]                    
    stxdw [r10-0x210], r1                   
    ldxdw r1, [r10-0xb8]                    
    stxdw [r10-0x208], r1                   
    ldxdw r1, [r10-0xb0]                    
    stxdw [r10-0x200], r1                   
    ldxdw r3, [r10-0xd0]                    
    ldxdw r2, [r10-0xd8]                    
    ldxdw r4, [r10-0xe0]                    
    ldxw r5, [r10-0xe4]                     
    ldxw r1, [r10-0xe8]                     
    ldxb r6, [r10-0xef]                     
lbb_10198:
    ldxdw r7, [r9+0x0]                      
    add64 r7, 1                                     r7 += 1   ///  r7 = r7.wrapping_add(1 as i32 as i64 as u64)
    stxdw [r9+0x0], r7                      
lbb_10201:
    ldxh r7, [r10-0x1f4]                    
    stxh [r10-0xea], r7                     
    ldxw r7, [r10-0x1f8]                    
    stxw [r10-0xee], r7                     
    ldxdw r7, [r10-0x218]                   
    stxdw [r10-0xc8], r7                    
    ldxdw r7, [r10-0x210]                   
    stxdw [r10-0xc0], r7                    
    ldxdw r7, [r10-0x208]                   
    stxdw [r10-0xb8], r7                    
    ldxdw r7, [r10-0x200]                   
    stxdw [r10-0xb0], r7                    
    stxdw [r10-0xd0], r3                    
    stxdw [r10-0xd8], r2                    
    stxdw [r10-0xe0], r4                    
    stxw [r10-0xe4], r5                     
    stxw [r10-0xe8], r1                     
    stxb [r10-0xef], r6                     
    stxb [r10-0xf0], r0                     
    ja lbb_10069                                    if true { pc += -152 }
lbb_10221:
    mov64 r1, r6                                    r1 = r6
    call function_1069                      
    syscall [invalid]                       

function_10224:
    mov64 r8, r5                                    r8 = r5
    mov64 r9, r4                                    r9 = r4
    mov64 r7, r2                                    r7 = r2
    mov64 r6, r1                                    r6 = r1
    jeq r3, 0, lbb_10235                            if r3 == (0 as i32 as i64 as u64) { pc += 6 }
    mov64 r2, r7                                    r2 = r7
    add64 r2, 48                                    r2 += 48   ///  r2 = r2.wrapping_add(48 as i32 as i64 as u64)
    jeq r3, 1, lbb_10233                            if r3 == (1 as i32 as i64 as u64) { pc += 1 }
    ja lbb_10239                                    if true { pc += 6 }
lbb_10233:
    stxdw [r6+0x8], r2                      
    ja lbb_10236                                    if true { pc += 1 }
lbb_10235:
    stxdw [r6+0x8], r7                      
lbb_10236:
    mov64 r1, 10                                    r1 = 10 as i32 as i64 as u64
lbb_10237:
    stxw [r6+0x0], r1                       
lbb_10238:
    exit                                    
lbb_10239:
    ldxb r1, [r7+0x28]                      
    jeq r1, 0, lbb_10264                            if r1 == (0 as i32 as i64 as u64) { pc += 23 }
    mov64 r1, r10                                   r1 = r10
    add64 r1, -168                                  r1 += -168   ///  r1 = r1.wrapping_add(-168 as i32 as i64 as u64)
    call function_39192                     
    ldxw r1, [r10-0xa8]                     
    jne r1, 24, lbb_10290                           if r1 != (24 as i32 as i64 as u64) { pc += 44 }
    mov64 r1, 2                                     r1 = 2 as i32 as i64 as u64
    ldxdw r2, [r10-0xa0]                    
    ldxdw r3, [r2+0x8]                      
    jne r3, 8552, lbb_10299                         if r3 != (8552 as i32 as i64 as u64) { pc += 49 }
    ldxdw r3, [r2+0x0]                      
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    mov64 r2, r3                                    r2 = r3
    and64 r2, 7                                     r2 &= 7   ///  r2 = r2.and(7)
    jeq r2, 0, lbb_10256                            if r2 == (0 as i32 as i64 as u64) { pc += 1 }
    ja lbb_10299                                    if true { pc += 43 }
lbb_10256:
    mov64 r5, r3                                    r5 = r3
    add64 r5, 8                                     r5 += 8   ///  r5 = r5.wrapping_add(8 as i32 as i64 as u64)
    ldxdw r1, [r3+0x8]                      
    ldxdw r0, [r7+0x0]                      
    ldxdw r2, [r0+0x0]                      
    jeq r1, r2, lbb_10301                           if r1 == r2 { pc += 39 }
lbb_10262:
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    ja lbb_10311                                    if true { pc += 47 }
lbb_10264:
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    stxdw [r10-0x88], r1                    
    mov64 r1, 2                                     r1 = 2 as i32 as i64 as u64
    stxdw [r10-0xa0], r1                    
    lddw r1, 0x100065120 --> b"\x00\x00\x00\x00\xdf\x04\x06\x00\x0e\x00\x00\x00\x00\x00\x00\x00\x00\x00\…        r1 load str located at 4295381280
    stxdw [r10-0xa8], r1                    
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    stxdw [r10-0x90], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -240                                  r1 += -240   ///  r1 = r1.wrapping_add(-240 as i32 as i64 as u64)
    stxdw [r10-0x98], r1                    
    lddw r1, 0x1000008a0 --> b"y\x11\x00\x00\x00\x00\x00\x00\x85\x10\x00\x00*\x99\x00\x00\x95\x00\x00\x0…        r1 load str located at 4294969504
    stxdw [r10-0xe8], r1                    
    stxdw [r10-0xf0], r7                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -216                                  r1 += -216   ///  r1 = r1.wrapping_add(-216 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -168                                  r2 += -168   ///  r2 = r2.wrapping_add(-168 as i32 as i64 as u64)
    call function_43415                     
    ldxdw r1, [r10-0xd8]                    
    ldxdw r2, [r10-0xc8]                    
    syscall [invalid]                       
    mov64 r1, 7                                     r1 = 7 as i32 as i64 as u64
    ja lbb_10237                                    if true { pc += -53 }
lbb_10290:
    ldxw r2, [r10-0xa4]                     
    ldxdw r3, [r10-0xa0]                    
    ldxdw r4, [r10-0x98]                    
    ldxdw r5, [r10-0x90]                    
    stxdw [r6+0x18], r5                     
    stxdw [r6+0x10], r4                     
    stxdw [r6+0x8], r3                      
    stxw [r6+0x4], r2                       
    ja lbb_10237                                    if true { pc += -62 }
lbb_10299:
    call function_1069                      
    syscall [invalid]                       
lbb_10301:
    ldxdw r1, [r0+0x8]                      
    ldxdw r2, [r5+0x8]                      
    jne r2, r1, lbb_10262                           if r2 != r1 { pc += -42 }
    ldxdw r1, [r0+0x10]                     
    ldxdw r2, [r5+0x10]                     
    jne r2, r1, lbb_10262                           if r2 != r1 { pc += -45 }
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    ldxdw r2, [r0+0x18]                     
    ldxdw r4, [r5+0x18]                     
    jne r4, r2, lbb_10262                           if r4 != r2 { pc += -49 }
lbb_10311:
    stxdw [r10-0x100], r5                   
    ldxdw r2, [r10-0x98]                    
    stxdw [r10-0xf8], r2                    
    jeq r1, 0, lbb_10323                            if r1 == (0 as i32 as i64 as u64) { pc += 8 }
    mov64 r1, r3                                    r1 = r3
    add64 r1, 40                                    r1 += 40   ///  r1 = r1.wrapping_add(40 as i32 as i64 as u64)
    ldxdw r2, [r0+0x0]                      
    ldxdw r4, [r1+0x0]                      
    jeq r4, r2, lbb_10331                           if r4 == r2 { pc += 11 }
lbb_10320:
    mov64 r2, 1                                     r2 = 1 as i32 as i64 as u64
    jeq r2, 0, lbb_10323                            if r2 == (0 as i32 as i64 as u64) { pc += 1 }
    ja lbb_10342                                    if true { pc += 19 }
lbb_10323:
    mov64 r1, r6                                    r1 = r6
    mov64 r2, r9                                    r2 = r9
    callx r8                                
lbb_10326:
    ldxdw r2, [r10-0xf8]                    
    ldxdw r1, [r2+0x0]                      
    add64 r1, 1                                     r1 += 1   ///  r1 = r1.wrapping_add(1 as i32 as i64 as u64)
    stxdw [r2+0x0], r1                      
    ja lbb_10238                                    if true { pc += -93 }
lbb_10331:
    ldxdw r2, [r0+0x8]                      
    ldxdw r4, [r1+0x8]                      
    jne r4, r2, lbb_10320                           if r4 != r2 { pc += -14 }
    ldxdw r2, [r0+0x10]                     
    ldxdw r4, [r1+0x10]                     
    jne r4, r2, lbb_10320                           if r4 != r2 { pc += -17 }
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
    ldxdw r4, [r0+0x18]                     
    ldxdw r5, [r1+0x18]                     
    jne r5, r4, lbb_10320                           if r5 != r4 { pc += -21 }
    jeq r2, 0, lbb_10323                            if r2 == (0 as i32 as i64 as u64) { pc += -19 }
lbb_10342:
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
    stxdw [r10-0xb8], r2                    
    lddw r2, 0x100065140 --> b"\x00\x00\x00\x00\xed\x04\x06\x00\x0a\x00\x00\x00\x00\x00\x00\x00\x00\x00\…        r2 load str located at 4295381312
    stxdw [r10-0xd8], r2                    
    mov64 r2, 3                                     r2 = 3 as i32 as i64 as u64
    stxdw [r10-0xd0], r2                    
    stxdw [r10-0xc0], r2                    
    mov64 r2, r10                                   r2 = r10
    add64 r2, -168                                  r2 += -168   ///  r2 = r2.wrapping_add(-168 as i32 as i64 as u64)
    stxdw [r10-0xc8], r2                    
    lddw r2, 0x1000008a0 --> b"y\x11\x00\x00\x00\x00\x00\x00\x85\x10\x00\x00*\x99\x00\x00\x95\x00\x00\x0…        r2 load str located at 4294969504
    stxdw [r10-0x80], r2                    
    stxdw [r10-0x88], r7                    
    stxdw [r10-0x98], r1                    
    lddw r1, 0x10004d200 --> b"\xbf&\x00\x00\x00\x00\x00\x00y\x12\x00\x00\x00\x00\x00\x00y\x13\x08\x00\x…        r1 load str located at 4295283200
    stxdw [r10-0x90], r1                    
    stxdw [r10-0xa0], r1                    
    ldxdw r8, [r10-0x100]                   
    stxdw [r10-0xa8], r8                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -240                                  r1 += -240   ///  r1 = r1.wrapping_add(-240 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -216                                  r2 += -216   ///  r2 = r2.wrapping_add(-216 as i32 as i64 as u64)
    mov64 r7, r0                                    r7 = r0
    call function_445                       
    ldxdw r1, [r10-0xf0]                    
    ldxdw r2, [r10-0xe0]                    
    syscall [invalid]                       
    ldxdw r1, [r8+0x18]                     
    stxdw [r10-0x8f], r1                    
    ldxdw r1, [r8+0x10]                     
    stxdw [r10-0x97], r1                    
    ldxdw r1, [r8+0x8]                      
    stxdw [r10-0x9f], r1                    
    ldxdw r1, [r8+0x0]                      
    stxdw [r10-0xa7], r1                    
    ldxdw r1, [r7+0x0]                      
    stxdw [r10-0x87], r1                    
    ldxdw r1, [r7+0x8]                      
    stxdw [r10-0x7f], r1                    
    ldxdw r1, [r7+0x10]                     
    stxdw [r10-0x77], r1                    
    ldxdw r1, [r7+0x18]                     
    stxdw [r10-0x6f], r1                    
    mov64 r1, 17                                    r1 = 17 as i32 as i64 as u64
    stxb [r10-0xa8], r1                     
    mov64 r2, r10                                   r2 = r10
    add64 r2, -168                                  r2 += -168   ///  r2 = r2.wrapping_add(-168 as i32 as i64 as u64)
    mov64 r1, r6                                    r1 = r6
    call function_26067                     
    ja lbb_10326                                    if true { pc += -70 }

function_10396:
    mov64 r4, r3                                    r4 = r3
    mov64 r6, r1                                    r6 = r1
    mov64 r3, 1                                     r3 = 1 as i32 as i64 as u64
    ldxdw r8, [r2+0x8]                      
    ldxw r1, [r8+0x0]                       
    mov64 r5, r1                                    r5 = r1
    and64 r5, 1                                     r5 &= 1   ///  r5 = r5.and(1)
    jeq r5, 0, lbb_10414                            if r5 == (0 as i32 as i64 as u64) { pc += 10 }
    mov64 r5, r1                                    r5 = r1
    rsh64 r5, 14                                    r5 >>= 14   ///  r5 = r5.wrapping_shr(14)
    and64 r5, 28                                    r5 &= 28   ///  r5 = r5.and(28)
    mov64 r3, r1                                    r3 = r1
    rsh64 r3, 7                                     r3 >>= 7   ///  r3 = r3.wrapping_shr(7)
    and64 r3, 2                                     r3 &= 2   ///  r3 = r3.and(2)
    or64 r3, r5                                     r3 |= r5   ///  r3 = r3.or(r5)
    rsh64 r1, 24                                    r1 >>= 24   ///  r1 = r1.wrapping_shr(24)
    and64 r1, 224                                   r1 &= 224   ///  r1 = r1.and(224)
    or64 r3, r1                                     r3 |= r1   ///  r3 = r3.or(r1)
lbb_10414:
    ldxdw r7, [r2+0x0]                      
    add64 r4, 72                                    r4 += 72   ///  r4 = r4.wrapping_add(72 as i32 as i64 as u64)
    mov64 r1, r4                                    r1 = r4
    mov64 r2, r7                                    r2 = r7
    call function_23928                     
    jne r0, 0, lbb_10442                            if r0 != (0 as i32 as i64 as u64) { pc += 22 }
    lddw r1, 0x300000000                            r1 load str located at 12884901888
    ldxdw r1, [r1+0x0]                      
    mov64 r3, r1                                    r3 = r1
    add64 r3, -50                                   r3 += -50   ///  r3 = r3.wrapping_add(-50 as i32 as i64 as u64)
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
    mov64 r4, 1                                     r4 = 1 as i32 as i64 as u64
    jgt r3, r1, lbb_10429                           if r3 > r1 { pc += 1 }
    mov64 r4, 0                                     r4 = 0 as i32 as i64 as u64
lbb_10429:
    jne r4, 0, lbb_10431                            if r4 != (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r2, r3                                    r2 = r3
lbb_10431:
    lddw r7, 0x300007fce                            r7 load str located at 12884934606
    jeq r1, 0, lbb_10435                            if r1 == (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r7, r2                                    r7 = r2
lbb_10435:
    lddw r1, 0x300000007                            r1 load str located at 12884901895
    jgt r7, r1, lbb_10472                           if r7 > r1 { pc += 34 }
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    mov64 r2, 50                                    r2 = 50 as i32 as i64 as u64
    call function_43400                     
    syscall [invalid]                       
lbb_10442:
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    stxdw [r10-0x90], r1                    
    lddw r1, 0x100065170 --> b"\x00\x00\x00\x00U\x05\x06\x00\x1a\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00…        r1 load str located at 4295381360
    stxdw [r10-0xb0], r1                    
    mov64 r1, 2                                     r1 = 2 as i32 as i64 as u64
    stxdw [r10-0xa8], r1                    
    stxdw [r10-0x98], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -80                                   r1 += -80   ///  r1 = r1.wrapping_add(-80 as i32 as i64 as u64)
    stxdw [r10-0xa0], r1                    
    lddw r1, 0x1000020d8 --> b"q\x13\x00\x00\x00\x00\x00\x00U\x03\x06\x00\x00\x00\x00\x00\xbf!\x00\x00\x…        r1 load str located at 4294975704
    stxdw [r10-0x38], r1                    
    stxdw [r10-0x40], r8                    
    lddw r1, 0x10004d200 --> b"\xbf&\x00\x00\x00\x00\x00\x00y\x12\x00\x00\x00\x00\x00\x00y\x13\x08\x00\x…        r1 load str located at 4295283200
    stxdw [r10-0x48], r1                    
    stxdw [r10-0x50], r7                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -104                                  r1 += -104   ///  r1 = r1.wrapping_add(-104 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -176                                  r2 += -176   ///  r2 = r2.wrapping_add(-176 as i32 as i64 as u64)
    call function_43415                     
    ldxdw r1, [r10-0x68]                    
    ldxdw r2, [r10-0x58]                    
    syscall [invalid]                       
    mov64 r1, 24                                    r1 = 24 as i32 as i64 as u64
    stxw [r6+0x0], r1                       
lbb_10471:
    exit                                    
lbb_10472:
    lddw r1, 0x300000000                            r1 load str located at 12884901888
    stxdw [r1+0x0], r7                      
    mov64 r1, r7                                    r1 = r7
    lddw r2, 0x100060523 --> b"Failed to add pubkey to shitlist, list may be full"        r2 load str located at 4295361827
    mov64 r3, 50                                    r3 = 50 as i32 as i64 as u64
    call function_48190                     
    mov64 r1, r7                                    r1 = r7
    mov64 r2, 50                                    r2 = 50 as i32 as i64 as u64
    syscall [invalid]                       
    mov64 r1, 19                                    r1 = 19 as i32 as i64 as u64
    stxb [r10-0xb0], r1                     
    mov64 r2, r10                                   r2 = r10
    add64 r2, -176                                  r2 += -176   ///  r2 = r2.wrapping_add(-176 as i32 as i64 as u64)
    mov64 r1, r6                                    r1 = r6
    call function_26067                     
    ja lbb_10471                                    if true { pc += -19 }

function_10490:
    mov64 r6, r1                                    r6 = r1
    ldxdw r7, [r2+0x0]                      
    add64 r3, 72                                    r3 += 72   ///  r3 = r3.wrapping_add(72 as i32 as i64 as u64)
    mov64 r1, r3                                    r1 = r3
    mov64 r2, r7                                    r2 = r7
    call function_23846                     
    jne r0, 0, lbb_10519                            if r0 != (0 as i32 as i64 as u64) { pc += 22 }
    lddw r1, 0x300000000                            r1 load str located at 12884901888
    ldxdw r1, [r1+0x0]                      
    mov64 r3, r1                                    r3 = r1
    add64 r3, -55                                   r3 += -55   ///  r3 = r3.wrapping_add(-55 as i32 as i64 as u64)
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
    mov64 r4, 1                                     r4 = 1 as i32 as i64 as u64
    jgt r3, r1, lbb_10506                           if r3 > r1 { pc += 1 }
    mov64 r4, 0                                     r4 = 0 as i32 as i64 as u64
lbb_10506:
    jne r4, 0, lbb_10508                            if r4 != (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r2, r3                                    r2 = r3
lbb_10508:
    lddw r8, 0x300007fc9                            r8 load str located at 12884934601
    jeq r1, 0, lbb_10512                            if r1 == (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r8, r2                                    r8 = r2
lbb_10512:
    lddw r1, 0x300000007                            r1 load str located at 12884901895
    jgt r8, r1, lbb_10546                           if r8 > r1 { pc += 31 }
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    mov64 r2, 55                                    r2 = 55 as i32 as i64 as u64
    call function_43400                     
    syscall [invalid]                       
lbb_10519:
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    stxdw [r10-0x80], r1                    
    mov64 r1, 2                                     r1 = 2 as i32 as i64 as u64
    stxdw [r10-0x98], r1                    
    lddw r1, 0x100065190 --> b"\x00\x00\x00\x00\xbd\x05\x06\x00\x1c\x00\x00\x00\x00\x00\x00\x00\x00\x00\…        r1 load str located at 4295381392
    stxdw [r10-0xa0], r1                    
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    stxdw [r10-0x88], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -64                                   r1 += -64   ///  r1 = r1.wrapping_add(-64 as i32 as i64 as u64)
    stxdw [r10-0x90], r1                    
    lddw r1, 0x10004d200 --> b"\xbf&\x00\x00\x00\x00\x00\x00y\x12\x00\x00\x00\x00\x00\x00y\x13\x08\x00\x…        r1 load str located at 4295283200
    stxdw [r10-0x38], r1                    
    stxdw [r10-0x40], r7                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -88                                   r1 += -88   ///  r1 = r1.wrapping_add(-88 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -160                                  r2 += -160   ///  r2 = r2.wrapping_add(-160 as i32 as i64 as u64)
    call function_43415                     
    ldxdw r1, [r10-0x58]                    
    ldxdw r2, [r10-0x48]                    
    syscall [invalid]                       
    mov64 r1, 24                                    r1 = 24 as i32 as i64 as u64
    stxw [r6+0x0], r1                       
lbb_10545:
    exit                                    
lbb_10546:
    lddw r1, 0x300000000                            r1 load str located at 12884901888
    stxdw [r1+0x0], r8                      
    mov64 r1, r8                                    r1 = r8
    lddw r2, 0x100060586 --> b"Failed to remove pubkey from shitlist, pubkey not found"        r2 load str located at 4295361926
    mov64 r3, 55                                    r3 = 55 as i32 as i64 as u64
    call function_48190                     
    mov64 r1, r8                                    r1 = r8
    mov64 r2, 55                                    r2 = 55 as i32 as i64 as u64
    syscall [invalid]                       
    ldxdw r1, [r7+0x18]                     
    stxdw [r10-0x87], r1                    
    ldxdw r1, [r7+0x10]                     
    stxdw [r10-0x8f], r1                    
    ldxdw r1, [r7+0x8]                      
    stxdw [r10-0x97], r1                    
    ldxdw r1, [r7+0x0]                      
    stxdw [r10-0x9f], r1                    
    mov64 r1, 20                                    r1 = 20 as i32 as i64 as u64
    stxb [r10-0xa0], r1                     
    mov64 r2, r10                                   r2 = r10
    add64 r2, -160                                  r2 += -160   ///  r2 = r2.wrapping_add(-160 as i32 as i64 as u64)
    mov64 r1, r6                                    r1 = r6
    call function_26067                     
    ja lbb_10545                                    if true { pc += -27 }

function_10572:
    mov64 r6, r1                                    r6 = r1
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    stxw [r3+0x2148], r1                    
    lddw r2, 0x300000000                            r2 load str located at 12884901888
    ldxdw r2, [r2+0x0]                      
    mov64 r3, r2                                    r3 = r2
    add64 r3, -36                                   r3 += -36   ///  r3 = r3.wrapping_add(-36 as i32 as i64 as u64)
    mov64 r4, 1                                     r4 = 1 as i32 as i64 as u64
    jgt r3, r2, lbb_10583                           if r3 > r2 { pc += 1 }
    mov64 r4, 0                                     r4 = 0 as i32 as i64 as u64
lbb_10583:
    jne r4, 0, lbb_10585                            if r4 != (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r1, r3                                    r1 = r3
lbb_10585:
    lddw r7, 0x300007fdc                            r7 load str located at 12884934620
    jeq r2, 0, lbb_10589                            if r2 == (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r7, r1                                    r7 = r1
lbb_10589:
    lddw r1, 0x300000007                            r1 load str located at 12884901895
    jgt r7, r1, lbb_10596                           if r7 > r1 { pc += 4 }
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    mov64 r2, 36                                    r2 = 36 as i32 as i64 as u64
    call function_43400                     
    syscall [invalid]                       
lbb_10596:
    lddw r1, 0x300000000                            r1 load str located at 12884901888
    stxdw [r1+0x0], r7                      
    mov64 r1, r7                                    r1 = r7
    lddw r2, 0x1000605e7 --> b"Successfully cleared entire shitlist"        r2 load str located at 4295362023
    mov64 r3, 36                                    r3 = 36 as i32 as i64 as u64
    call function_48190                     
    mov64 r1, r7                                    r1 = r7
    mov64 r2, 36                                    r2 = 36 as i32 as i64 as u64
    syscall [invalid]                       
    mov64 r1, 24                                    r1 = 24 as i32 as i64 as u64
    stxw [r6+0x0], r1                       
    exit                                    

function_10610:
    stxdw [r10-0xa8], r1                    
    stxdw [r10-0xa0], r3                    
    ldxw r9, [r3+0x2148]                    
    mov64 r8, 0                                     r8 = 0 as i32 as i64 as u64
    jeq r9, 0, lbb_10646                            if r9 == (0 as i32 as i64 as u64) { pc += 31 }
    ldxdw r6, [r10-0xa0]                    
    mov64 r1, r6                                    r1 = r6
    add64 r1, 72                                    r1 += 72   ///  r1 = r1.wrapping_add(72 as i32 as i64 as u64)
    stxdw [r10-0x98], r1                    
    add64 r6, 104                                   r6 += 104   ///  r6 = r6.wrapping_add(104 as i32 as i64 as u64)
    mov64 r7, 0                                     r7 = 0 as i32 as i64 as u64
    ja lbb_10627                                    if true { pc += 5 }
lbb_10622:
    add64 r8, 1                                     r8 += 1   ///  r8 = r8.wrapping_add(1 as i32 as i64 as u64)
lbb_10623:
    add64 r7, 1                                     r7 += 1   ///  r7 = r7.wrapping_add(1 as i32 as i64 as u64)
    add64 r6, 33                                    r6 += 33   ///  r6 = r6.wrapping_add(33 as i32 as i64 as u64)
    jgt r9, r7, lbb_10627                           if r9 > r7 { pc += 1 }
    ja lbb_10646                                    if true { pc += 19 }
lbb_10627:
    jeq r7, 256, lbb_10680                          if r7 == (256 as i32 as i64 as u64) { pc += 52 }
    ldxb r1, [r6+0x0]                       
    call function_24557                     
    and64 r0, 1                                     r0 &= 1   ///  r0 = r0.and(1)
    jeq r0, 0, lbb_10633                            if r0 == (0 as i32 as i64 as u64) { pc += 1 }
    ja lbb_10623                                    if true { pc += -10 }
lbb_10633:
    jeq r7, r8, lbb_10622                           if r7 == r8 { pc += -12 }
    mov64 r1, 256                                   r1 = 256 as i32 as i64 as u64
    jgt r1, r8, lbb_10637                           if r1 > r8 { pc += 1 }
    ja lbb_10686                                    if true { pc += 49 }
lbb_10637:
    mov64 r2, r6                                    r2 = r6
    add64 r2, -32                                   r2 += -32   ///  r2 = r2.wrapping_add(-32 as i32 as i64 as u64)
    mov64 r3, r8                                    r3 = r8
    mul64 r3, 33                                    r3 *= 33   ///  r3 = r3.wrapping_mul(33 as u64)
    ldxdw r1, [r10-0x98]                    
    add64 r1, r3                                    r1 += r3   ///  r1 = r1.wrapping_add(r3)
    mov64 r3, 33                                    r3 = 33 as i32 as i64 as u64
    call function_48224                     
    ja lbb_10622                                    if true { pc += -24 }
lbb_10646:
    ldxdw r1, [r10-0xa0]                    
    stxw [r1+0x2148], r8                    
    sub64 r9, r8                                    r9 -= r8   ///  r9 = r9.wrapping_sub(r8)
    stxdw [r10-0x90], r9                    
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    stxdw [r10-0x50], r1                    
    mov64 r1, 2                                     r1 = 2 as i32 as i64 as u64
    stxdw [r10-0x68], r1                    
    lddw r1, 0x1000651b0 --> b"\x00\x00\x00\x00\x0b\x06\x06\x00\x15\x00\x00\x00\x00\x00\x00\x00\x00\x00\…        r1 load str located at 4295381424
    stxdw [r10-0x70], r1                    
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    stxdw [r10-0x58], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -64                                   r1 += -64   ///  r1 = r1.wrapping_add(-64 as i32 as i64 as u64)
    stxdw [r10-0x60], r1                    
    lddw r1, 0x10005df58 --> b"\xbf#\x00\x00\x00\x00\x00\x00y\x11\x00\x00\x00\x00\x00\x00\xb7\x02\x00\x0…        r1 load str located at 4295352152
    stxdw [r10-0x38], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -144                                  r1 += -144   ///  r1 = r1.wrapping_add(-144 as i32 as i64 as u64)
    stxdw [r10-0x40], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -136                                  r1 += -136   ///  r1 = r1.wrapping_add(-136 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -112                                  r2 += -112   ///  r2 = r2.wrapping_add(-112 as i32 as i64 as u64)
    call function_43415                     
    ldxdw r1, [r10-0x88]                    
    ldxdw r2, [r10-0x78]                    
    syscall [invalid]                       
    mov64 r1, 24                                    r1 = 24 as i32 as i64 as u64
    ldxdw r2, [r10-0xa8]                    
    stxw [r2+0x0], r1                       
    exit                                    
lbb_10680:
    mov64 r1, 256                                   r1 = 256 as i32 as i64 as u64
    mov64 r2, 256                                   r2 = 256 as i32 as i64 as u64
    lddw r3, 0x100064c68 --> b"\x00\x00\x00\x00G\xfe\x05\x00\x17\x00\x00\x00\x00\x00\x00\x00\x8b\x00\x00…        r3 load str located at 4295380072
    call function_44272                     
    syscall [invalid]                       
lbb_10686:
    mov64 r1, r8                                    r1 = r8
    mov64 r2, 256                                   r2 = 256 as i32 as i64 as u64
    lddw r3, 0x100064c80 --> b"\x00\x00\x00\x00G\xfe\x05\x00\x17\x00\x00\x00\x00\x00\x00\x00\x8d\x00\x00…        r3 load str located at 4295380096
    call function_44272                     
    syscall [invalid]                       

function_10692:
    mov64 r6, r4                                    r6 = r4
    mov64 r8, r3                                    r8 = r3
    stxdw [r10-0x198], r2                   
    mov64 r9, r1                                    r9 = r1
    ldxdw r3, [r5+0x10]                     
    ldxdw r2, [r5+0x0]                      
    mov64 r7, r10                                   r7 = r10
    add64 r7, -272                                  r7 += -272   ///  r7 = r7.wrapping_add(-272 as i32 as i64 as u64)
    mov64 r1, r7                                    r1 = r7
    call function_1785                      
    mov64 r1, r10                                   r1 = r10
    add64 r1, -352                                  r1 += -352   ///  r1 = r1.wrapping_add(-352 as i32 as i64 as u64)
    mov64 r2, r7                                    r2 = r7
    call function_1188                      
    ldxdw r1, [r10-0x160]                   
    jne r1, 0, lbb_10899                            if r1 != (0 as i32 as i64 as u64) { pc += 191 }
    stxdw [r10-0x1a8], r8                   
    stxdw [r10-0x1a0], r6                   
    stxdw [r10-0x188], r9                   
    lddw r1, 0xa4093822299f31d0                     r1 load str located at -6626703657320631856
    ldxdw r2, [r10-0x148]                   
    stxdw [r10-0x190], r2                   
    xor64 r2, r1                                    r2 ^= r1   ///  r2 = r2.xor(r1)
    lddw r1, 0x243f6a8885a308d3                     r1 load str located at 2611923443488327891
    ldxdw r8, [r10-0x150]                   
    mov64 r4, r8                                    r4 = r8
    xor64 r4, r1                                    r4 ^= r1   ///  r4 = r4.xor(r1)
    mov64 r1, r10                                   r1 = r10
    add64 r1, -368                                  r1 += -368   ///  r1 = r1.wrapping_add(-368 as i32 as i64 as u64)
    mov64 r9, 0                                     r9 = 0 as i32 as i64 as u64
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
    mov64 r5, 0                                     r5 = 0 as i32 as i64 as u64
    call function_48384                     
    ldxdw r1, [r10-0x170]                   
    ldxdw r2, [r10-0x168]                   
    xor64 r2, r1                                    r2 ^= r1   ///  r2 = r2.xor(r1)
    lddw r1, 0x13198a2e03707344                     r1 load str located at 1376283091369227076
    ldxdw r6, [r10-0x140]                   
    mov64 r4, r6                                    r4 = r6
    xor64 r4, r1                                    r4 ^= r1   ///  r4 = r4.xor(r1)
    ldxdw r7, [r10-0x138]                   
    xor64 r2, r7                                    r2 ^= r7   ///  r2 = r2.xor(r7)
    mov64 r1, r10                                   r1 = r10
    add64 r1, -384                                  r1 += -384   ///  r1 = r1.wrapping_add(-384 as i32 as i64 as u64)
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
    mov64 r5, 0                                     r5 = 0 as i32 as i64 as u64
    call function_48384                     
    lddw r5, 0xf1357aea2e62a9c5                     r5 load str located at -1065810590584100411
    ldxdw r1, [r10-0x130]                   
    mov64 r3, r1                                    r3 = r1
    mul64 r3, r5                                    r3 *= r5   ///  r3 = r3.wrapping_mul(r5)
    ldxdw r2, [r10-0x128]                   
    add64 r3, r2                                    r3 += r2   ///  r3 = r3.wrapping_add(r2)
    lddw r4, 0x1427bb2d3769b199                     r4 load str located at 1452335207727870361
    mul64 r3, r4                                    r3 *= r4   ///  r3 = r3.wrapping_mul(r4)
    ldxdw r4, [r10-0x180]                   
    ldxdw r0, [r10-0x178]                   
    xor64 r0, r4                                    r0 ^= r4   ///  r0 = r0.xor(r4)
    xor64 r0, 32                                    r0 ^= 32   ///  r0 = r0.xor(32)
    add64 r3, r0                                    r3 += r0   ///  r3 = r3.wrapping_add(r0)
    mul64 r3, r5                                    r3 *= r5   ///  r3 = r3.wrapping_mul(r5)
    ldxdw r4, [r10-0x120]                   
    add64 r3, r4                                    r3 += r4   ///  r3 = r3.wrapping_add(r4)
    mul64 r3, r5                                    r3 *= r5   ///  r3 = r3.wrapping_mul(r5)
    lddw r5, 0xea8af33ca4b577a0                     r5 load str located at -1546156080261400672
    add64 r3, r5                                    r3 += r5   ///  r3 = r3.wrapping_add(r5)
    mov64 r5, r3                                    r5 = r3
    rsh64 r5, 38                                    r5 >>= 38   ///  r5 = r5.wrapping_shr(38)
    lsh64 r3, 26                                    r3 <<= 26   ///  r3 = r3.wrapping_shl(26)
    or64 r3, r5                                     r3 |= r5   ///  r3 = r3.or(r5)
    ldxdw r5, [r10-0x158]                   
    jne r3, r5, lbb_10787                           if r3 != r5 { pc += 17 }
    lddw r5, 0xfd74c63348a7c25f                     r5 load str located at -183303761250762145
    mul64 r3, r5                                    r3 *= r5   ///  r3 = r3.wrapping_mul(r5)
    lddw r5, 0x14057b7ef767814f                     r5 load str located at 1442695040888963407
    add64 r3, r5                                    r3 += r5   ///  r3 = r3.wrapping_add(r5)
    ldxdw r5, [r10-0x118]                   
    jne r3, r5, lbb_10787                           if r3 != r5 { pc += 9 }
    stxdw [r10-0x128], r4                   
    stxdw [r10-0x130], r2                   
    stxdw [r10-0x138], r1                   
    stxdw [r10-0x140], r7                   
    stxdw [r10-0x148], r6                   
    ldxdw r1, [r10-0x190]                   
    stxdw [r10-0x150], r1                   
    stxdw [r10-0x158], r8                   
    mov64 r9, 1                                     r9 = 1 as i32 as i64 as u64
lbb_10787:
    stxdw [r10-0x160], r9                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -272                                  r1 += -272   ///  r1 = r1.wrapping_add(-272 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -352                                  r2 += -352   ///  r2 = r2.wrapping_add(-352 as i32 as i64 as u64)
    call function_1102                      
    ldxb r6, [r10-0x110]                    
    jeq r6, 56, lbb_10796                           if r6 == (56 as i32 as i64 as u64) { pc += 1 }
    ja lbb_10922                                    if true { pc += 126 }
lbb_10796:
    mov64 r7, r10                                   r7 = r10
    add64 r7, -129                                  r7 += -129   ///  r7 = r7.wrapping_add(-129 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -264                                  r2 += -264   ///  r2 = r2.wrapping_add(-264 as i32 as i64 as u64)
    mov64 r1, r7                                    r1 = r7
    mov64 r3, 56                                    r3 = 56 as i32 as i64 as u64
    call function_48190                     
    mov64 r1, r10                                   r1 = r10
    add64 r1, -192                                  r1 += -192   ///  r1 = r1.wrapping_add(-192 as i32 as i64 as u64)
    mov64 r2, r7                                    r2 = r7
    mov64 r3, 56                                    r3 = 56 as i32 as i64 as u64
    call function_48190                     
    ldxdw r6, [r10-0x90]                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -272                                  r1 += -272   ///  r1 = r1.wrapping_add(-272 as i32 as i64 as u64)
    call function_41956                     
    ldxdw r1, [r10-0x110]                   
    jeq r1, 0, lbb_10824                            if r1 == (0 as i32 as i64 as u64) { pc += 10 }
    ldxdw r1, [r10-0x108]                   
    ldxdw r2, [r10-0x100]                   
    ldxdw r3, [r10-0xf8]                    
    ldxdw r4, [r10-0xf0]                    
    ldxdw r5, [r10-0x188]                   
    stxdw [r5+0x18], r4                     
    stxdw [r5+0x10], r3                     
    stxdw [r5+0x8], r2                      
    stxdw [r5+0x0], r1                      
    ja lbb_10898                                    if true { pc += 74 }
lbb_10824:
    ldxdw r1, [r10-0x108]                   
    mov64 r2, 28                                    r2 = 28 as i32 as i64 as u64
    stxdw [r10-0x40], r2                    
    lddw r2, 0x100060661 --> b"Swap instruction has expiredUser account does not "        r2 load str located at 4295362145
    stxdw [r10-0x48], r2                    
    add64 r6, 20                                    r6 += 20   ///  r6 = r6.wrapping_add(20 as i32 as i64 as u64)
    ldxdw r7, [r10-0x188]                   
    jge r6, r1, lbb_10882                           if r6 >= r1 { pc += 49 }
    lddw r1, 0x1000651d0 --> b"\x00\x00\x00\x00\xf0\xfe\x05\x00 \x00\x00\x00\x00\x00\x00\x00M\x00\x00\x0…        r1 load str located at 4295381456
    stxdw [r10-0x38], r1                    
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    stxdw [r10-0xf0], r1                    
    lddw r1, 0x100064c98 --> b"\x00\x00\x00\x00p\xfa\x05\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00…        r1 load str located at 4295380120
    stxdw [r10-0x110], r1                   
    mov64 r1, 2                                     r1 = 2 as i32 as i64 as u64
    stxdw [r10-0x108], r1                   
    stxdw [r10-0xf8], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -352                                  r1 += -352   ///  r1 = r1.wrapping_add(-352 as i32 as i64 as u64)
    stxdw [r10-0x100], r1                   
    lddw r1, 0x100000888 --> b"y\x11\x00\x00\x00\x00\x00\x00\x85\x10\x00\x00]\xab\x00\x00\x95\x00\x00\x0…        r1 load str located at 4294969480
    stxdw [r10-0x148], r1                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -56                                   r1 += -56   ///  r1 = r1.wrapping_add(-56 as i32 as i64 as u64)
    stxdw [r10-0x150], r1                   
    lddw r1, 0x100000860 --> b"\xbf#\x00\x00\x00\x00\x00\x00y\x12\x08\x00\x00\x00\x00\x00y\x11\x00\x00\x…        r1 load str located at 4294969440
    stxdw [r10-0x158], r1                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -72                                   r1 += -72   ///  r1 = r1.wrapping_add(-72 as i32 as i64 as u64)
    stxdw [r10-0x160], r1                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -136                                  r1 += -136   ///  r1 = r1.wrapping_add(-136 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -272                                  r2 += -272   ///  r2 = r2.wrapping_add(-272 as i32 as i64 as u64)
    call function_43415                     
    ldxdw r1, [r10-0x88]                    
    ldxdw r2, [r10-0x78]                    
    syscall [invalid]                       
    ldxdw r1, [r10-0xa8]                    
    stxdw [r10-0xf7], r1                    
    ldxdw r1, [r10-0xb0]                    
    stxdw [r10-0xff], r1                    
    ldxdw r1, [r10-0xb8]                    
    stxdw [r10-0x107], r1                   
    ldxdw r1, [r10-0xc0]                    
    stxdw [r10-0x10f], r1                   
    mov64 r1, 53                                    r1 = 53 as i32 as i64 as u64
    stxb [r10-0x110], r1                    
    mov64 r2, r10                                   r2 = r10
    add64 r2, -272                                  r2 += -272   ///  r2 = r2.wrapping_add(-272 as i32 as i64 as u64)
    mov64 r1, r7                                    r1 = r7
    call function_26067                     
    ja lbb_10898                                    if true { pc += 16 }
lbb_10882:
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    stxb [r10-0xf8], r1                     
    mov64 r1, r10                                   r1 = r10
    add64 r1, -192                                  r1 += -192   ///  r1 = r1.wrapping_add(-192 as i32 as i64 as u64)
    stxdw [r10-0x100], r1                   
    ldxdw r1, [r10-0x98]                    
    stxdw [r10-0x108], r1                   
    ldxdw r1, [r10-0xa0]                    
    stxdw [r10-0x110], r1                   
    mov64 r5, r10                                   r5 = r10
    add64 r5, -272                                  r5 += -272   ///  r5 = r5.wrapping_add(-272 as i32 as i64 as u64)
    mov64 r1, r7                                    r1 = r7
    ldxdw r2, [r10-0x198]                   
    ldxdw r3, [r10-0x1a8]                   
    ldxdw r4, [r10-0x1a0]                   
    call function_11116                     
lbb_10898:
    exit                                    
lbb_10899:
    ldxdw r1, [r10-0x158]                   
    ldxdw r2, [r10-0x150]                   
    ldxdw r3, [r10-0x148]                   
    ldxdw r4, [r10-0x140]                   
    ldxdw r5, [r10-0x138]                   
    ldxdw r0, [r10-0x130]                   
    ldxdw r6, [r10-0x128]                   
    ldxdw r7, [r10-0x120]                   
    ldxdw r8, [r10-0x118]                   
    stxdw [r10-0xd0], r8                    
    stxdw [r10-0xd8], r7                    
    stxdw [r10-0xe0], r6                    
    stxdw [r10-0xe8], r0                    
    stxdw [r10-0xf0], r5                    
    stxdw [r10-0xf8], r4                    
    stxdw [r10-0x100], r3                   
    stxdw [r10-0x108], r2                   
    stxdw [r10-0x110], r1                   
    mov64 r2, r10                                   r2 = r10
    add64 r2, -272                                  r2 += -272   ///  r2 = r2.wrapping_add(-272 as i32 as i64 as u64)
    mov64 r1, r9                                    r1 = r9
    call function_26067                     
    ja lbb_10898                                    if true { pc += -24 }
lbb_10922:
    mov64 r7, r10                                   r7 = r10
    add64 r7, -136                                  r7 += -136   ///  r7 = r7.wrapping_add(-136 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -271                                  r2 += -271   ///  r2 = r2.wrapping_add(-271 as i32 as i64 as u64)
    mov64 r1, r7                                    r1 = r7
    mov64 r3, 63                                    r3 = 63 as i32 as i64 as u64
    call function_48190                     
    ldxdw r8, [r10-0xd0]                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -271                                  r1 += -271   ///  r1 = r1.wrapping_add(-271 as i32 as i64 as u64)
    mov64 r2, r7                                    r2 = r7
    mov64 r3, 63                                    r3 = 63 as i32 as i64 as u64
    call function_48190                     
    stxdw [r10-0xd0], r8                    
    stxb [r10-0x110], r6                    
    mov64 r2, r10                                   r2 = r10
    add64 r2, -272                                  r2 += -272   ///  r2 = r2.wrapping_add(-272 as i32 as i64 as u64)
    ldxdw r1, [r10-0x188]                   
    call function_26067                     
    ja lbb_10898                                    if true { pc += -44 }

function_10942:
    mov64 r7, r4                                    r7 = r4
    mov64 r8, r3                                    r8 = r3
    stxdw [r10-0x148], r2                   
    mov64 r9, r1                                    r9 = r1
    ldxdw r3, [r5+0x10]                     
    ldxdw r2, [r5+0x0]                      
    mov64 r6, r10                                   r6 = r10
    add64 r6, -200                                  r6 += -200   ///  r6 = r6.wrapping_add(-200 as i32 as i64 as u64)
    mov64 r1, r6                                    r1 = r6
    call function_1785                      
    mov64 r1, r10                                   r1 = r10
    add64 r1, -280                                  r1 += -280   ///  r1 = r1.wrapping_add(-280 as i32 as i64 as u64)
    mov64 r2, r6                                    r2 = r6
    call function_1188                      
    ldxdw r1, [r10-0x118]                   
    jne r1, 0, lbb_11074                            if r1 != (0 as i32 as i64 as u64) { pc += 116 }
    stxdw [r10-0x158], r8                   
    stxdw [r10-0x150], r7                   
    stxdw [r10-0x140], r9                   
    lddw r1, 0xa4093822299f31d0                     r1 load str located at -6626703657320631856
    ldxdw r2, [r10-0x100]                   
    stxdw [r10-0x160], r2                   
    xor64 r2, r1                                    r2 ^= r1   ///  r2 = r2.xor(r1)
    lddw r1, 0x243f6a8885a308d3                     r1 load str located at 2611923443488327891
    ldxdw r7, [r10-0x108]                   
    mov64 r4, r7                                    r4 = r7
    xor64 r4, r1                                    r4 ^= r1   ///  r4 = r4.xor(r1)
    mov64 r1, r10                                   r1 = r10
    add64 r1, -296                                  r1 += -296   ///  r1 = r1.wrapping_add(-296 as i32 as i64 as u64)
    mov64 r8, 0                                     r8 = 0 as i32 as i64 as u64
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
    mov64 r5, 0                                     r5 = 0 as i32 as i64 as u64
    call function_48384                     
    ldxdw r1, [r10-0x128]                   
    ldxdw r2, [r10-0x120]                   
    xor64 r2, r1                                    r2 ^= r1   ///  r2 = r2.xor(r1)
    lddw r1, 0x13198a2e03707344                     r1 load str located at 1376283091369227076
    ldxdw r9, [r10-0xf8]                    
    mov64 r4, r9                                    r4 = r9
    xor64 r4, r1                                    r4 ^= r1   ///  r4 = r4.xor(r1)
    ldxdw r6, [r10-0xf0]                    
    xor64 r2, r6                                    r2 ^= r6   ///  r2 = r2.xor(r6)
    mov64 r1, r10                                   r1 = r10
    add64 r1, -312                                  r1 += -312   ///  r1 = r1.wrapping_add(-312 as i32 as i64 as u64)
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
    mov64 r5, 0                                     r5 = 0 as i32 as i64 as u64
    call function_48384                     
    lddw r5, 0xf1357aea2e62a9c5                     r5 load str located at -1065810590584100411
    ldxdw r1, [r10-0xe8]                    
    mov64 r3, r1                                    r3 = r1
    mul64 r3, r5                                    r3 *= r5   ///  r3 = r3.wrapping_mul(r5)
    ldxdw r2, [r10-0xe0]                    
    add64 r3, r2                                    r3 += r2   ///  r3 = r3.wrapping_add(r2)
    lddw r4, 0x1427bb2d3769b199                     r4 load str located at 1452335207727870361
    mul64 r3, r4                                    r3 *= r4   ///  r3 = r3.wrapping_mul(r4)
    ldxdw r4, [r10-0x138]                   
    ldxdw r0, [r10-0x130]                   
    xor64 r0, r4                                    r0 ^= r4   ///  r0 = r0.xor(r4)
    xor64 r0, 32                                    r0 ^= 32   ///  r0 = r0.xor(32)
    add64 r3, r0                                    r3 += r0   ///  r3 = r3.wrapping_add(r0)
    mul64 r3, r5                                    r3 *= r5   ///  r3 = r3.wrapping_mul(r5)
    ldxdw r4, [r10-0xd8]                    
    add64 r3, r4                                    r3 += r4   ///  r3 = r3.wrapping_add(r4)
    mul64 r3, r5                                    r3 *= r5   ///  r3 = r3.wrapping_mul(r5)
    lddw r5, 0xea8af33ca4b577a0                     r5 load str located at -1546156080261400672
    add64 r3, r5                                    r3 += r5   ///  r3 = r3.wrapping_add(r5)
    mov64 r5, r3                                    r5 = r3
    rsh64 r5, 38                                    r5 >>= 38   ///  r5 = r5.wrapping_shr(38)
    lsh64 r3, 26                                    r3 <<= 26   ///  r3 = r3.wrapping_shl(26)
    or64 r3, r5                                     r3 |= r5   ///  r3 = r3.or(r5)
    ldxdw r5, [r10-0x110]                   
    jne r3, r5, lbb_11037                           if r3 != r5 { pc += 17 }
    lddw r5, 0xfd74c63348a7c25f                     r5 load str located at -183303761250762145
    mul64 r3, r5                                    r3 *= r5   ///  r3 = r3.wrapping_mul(r5)
    lddw r5, 0x14057b7ef767814f                     r5 load str located at 1442695040888963407
    add64 r3, r5                                    r3 += r5   ///  r3 = r3.wrapping_add(r5)
    ldxdw r5, [r10-0xd0]                    
    jne r3, r5, lbb_11037                           if r3 != r5 { pc += 9 }
    stxdw [r10-0xe0], r4                    
    stxdw [r10-0xe8], r2                    
    stxdw [r10-0xf0], r1                    
    stxdw [r10-0xf8], r6                    
    stxdw [r10-0x100], r9                   
    ldxdw r1, [r10-0x160]                   
    stxdw [r10-0x108], r1                   
    stxdw [r10-0x110], r7                   
    mov64 r8, 1                                     r8 = 1 as i32 as i64 as u64
lbb_11037:
    stxdw [r10-0x118], r8                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -200                                  r1 += -200   ///  r1 = r1.wrapping_add(-200 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -280                                  r2 += -280   ///  r2 = r2.wrapping_add(-280 as i32 as i64 as u64)
    call function_1102                      
    ldxb r7, [r10-0xc8]                     
    jeq r7, 56, lbb_11046                           if r7 == (56 as i32 as i64 as u64) { pc += 1 }
    ja lbb_11096                                    if true { pc += 50 }
lbb_11046:
    mov64 r6, r10                                   r6 = r10
    add64 r6, -56                                   r6 += -56   ///  r6 = r6.wrapping_add(-56 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -192                                  r2 += -192   ///  r2 = r2.wrapping_add(-192 as i32 as i64 as u64)
    mov64 r1, r6                                    r1 = r6
    mov64 r3, 56                                    r3 = 56 as i32 as i64 as u64
    call function_48190                     
    mov64 r7, r10                                   r7 = r10
    add64 r7, -120                                  r7 += -120   ///  r7 = r7.wrapping_add(-120 as i32 as i64 as u64)
    mov64 r1, r7                                    r1 = r7
    mov64 r2, r6                                    r2 = r6
    mov64 r3, 56                                    r3 = 56 as i32 as i64 as u64
    call function_48190                     
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    stxb [r10-0xb0], r1                     
    stxdw [r10-0xb8], r7                    
    ldxdw r1, [r10-0x50]                    
    stxdw [r10-0xc0], r1                    
    ldxdw r1, [r10-0x58]                    
    stxdw [r10-0xc8], r1                    
    mov64 r5, r10                                   r5 = r10
    add64 r5, -200                                  r5 += -200   ///  r5 = r5.wrapping_add(-200 as i32 as i64 as u64)
    ldxdw r1, [r10-0x140]                   
    ldxdw r2, [r10-0x148]                   
    ldxdw r3, [r10-0x158]                   
    ldxdw r4, [r10-0x150]                   
    call function_11116                     
lbb_11073:
    exit                                    
lbb_11074:
    ldxdw r1, [r10-0x110]                   
    ldxdw r2, [r10-0x108]                   
    ldxdw r3, [r10-0x100]                   
    ldxdw r4, [r10-0xf8]                    
    ldxdw r5, [r10-0xf0]                    
    ldxdw r0, [r10-0xe8]                    
    ldxdw r6, [r10-0xe0]                    
    ldxdw r7, [r10-0xd8]                    
    ldxdw r8, [r10-0xd0]                    
    stxdw [r10-0x88], r8                    
    stxdw [r10-0x90], r7                    
    stxdw [r10-0x98], r6                    
    stxdw [r10-0xa0], r0                    
    stxdw [r10-0xa8], r5                    
    stxdw [r10-0xb0], r4                    
    stxdw [r10-0xb8], r3                    
    stxdw [r10-0xc0], r2                    
    stxdw [r10-0xc8], r1                    
    mov64 r2, r10                                   r2 = r10
    add64 r2, -200                                  r2 += -200   ///  r2 = r2.wrapping_add(-200 as i32 as i64 as u64)
    mov64 r1, r9                                    r1 = r9
    ja lbb_11114                                    if true { pc += 18 }
lbb_11096:
    mov64 r6, r10                                   r6 = r10
    add64 r6, -63                                   r6 += -63   ///  r6 = r6.wrapping_add(-63 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -199                                  r2 += -199   ///  r2 = r2.wrapping_add(-199 as i32 as i64 as u64)
    mov64 r1, r6                                    r1 = r6
    mov64 r3, 63                                    r3 = 63 as i32 as i64 as u64
    call function_48190                     
    ldxdw r8, [r10-0x88]                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -199                                  r1 += -199   ///  r1 = r1.wrapping_add(-199 as i32 as i64 as u64)
    mov64 r2, r6                                    r2 = r6
    mov64 r3, 63                                    r3 = 63 as i32 as i64 as u64
    call function_48190                     
    stxdw [r10-0x88], r8                    
    stxb [r10-0xc8], r7                     
    mov64 r2, r10                                   r2 = r10
    add64 r2, -200                                  r2 += -200   ///  r2 = r2.wrapping_add(-200 as i32 as i64 as u64)
    ldxdw r1, [r10-0x140]                   
lbb_11114:
    call function_26067                     
    ja lbb_11073                                    if true { pc += -43 }

function_11116:
    stxdw [r10-0xbd0], r5                   
    mov64 r8, r3                                    r8 = r3
    mov64 r7, r2                                    r7 = r2
    jne r4, 0, lbb_11123                            if r4 != (0 as i32 as i64 as u64) { pc += 3 }
    mov64 r2, 3                                     r2 = 3 as i32 as i64 as u64
    stxw [r1+0x0], r2                       
    ja lbb_11585                                    if true { pc += 462 }
lbb_11123:
    stxdw [r10-0xc00], r1                   
    mov64 r2, r8                                    r2 = r8
    add64 r2, 48                                    r2 += 48   ///  r2 = r2.wrapping_add(48 as i32 as i64 as u64)
    add64 r4, -1                                    r4 += -1   ///  r4 = r4.wrapping_add(-1 as i32 as i64 as u64)
    mov64 r1, r10                                   r1 = r10
    add64 r1, -2408                                 r1 += -2408   ///  r1 = r1.wrapping_add(-2408 as i32 as i64 as u64)
    mov64 r3, r4                                    r3 = r4
    call function_18534                     
    ldxw r6, [r10-0x968]                    
    jeq r6, 2, lbb_11432                            if r6 == (2 as i32 as i64 as u64) { pc += 299 }
    stxdw [r10-0xc30], r8                   
    stxdw [r10-0xbc8], r7                   
    mov64 r7, r10                                   r7 = r10
    add64 r7, -600                                  r7 += -600   ///  r7 = r7.wrapping_add(-600 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -2404                                 r2 += -2404   ///  r2 = r2.wrapping_add(-2404 as i32 as i64 as u64)
    mov64 r1, r7                                    r1 = r7
    mov64 r3, 76                                    r3 = 76 as i32 as i64 as u64
    call function_48190                     
    mov64 r1, r10                                   r1 = r10
    add64 r1, -2896                                 r1 += -2896   ///  r1 = r1.wrapping_add(-2896 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -2328                                 r2 += -2328   ///  r2 = r2.wrapping_add(-2328 as i32 as i64 as u64)
    mov64 r3, 488                                   r3 = 488 as i32 as i64 as u64
    call function_48190                     
    ldxdw r8, [r10-0x730]                   
    ldxdw r9, [r10-0x728]                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -2972                                 r1 += -2972   ///  r1 = r1.wrapping_add(-2972 as i32 as i64 as u64)
    mov64 r2, r7                                    r2 = r7
    mov64 r3, 76                                    r3 = 76 as i32 as i64 as u64
    call function_48190                     
    stxw [r10-0xba0], r6                    
    ldxdw r1, [r10-0xbd0]                   
    ldxdw r1, [r1+0x10]                     
    jeq r1, 0, lbb_11226                            if r1 == (0 as i32 as i64 as u64) { pc += 67 }
    ldxdw r2, [r1+0x0]                      
    ldxdw r3, [r10-0x990]                   
    ldxdw r6, [r3+0x0]                      
    ldxdw r3, [r6+0x0]                      
    jeq r3, r2, lbb_11166                           if r3 == r2 { pc += 2 }
lbb_11164:
    mov64 r2, 1                                     r2 = 1 as i32 as i64 as u64
    ja lbb_11176                                    if true { pc += 10 }
lbb_11166:
    ldxdw r2, [r1+0x8]                      
    ldxdw r3, [r6+0x8]                      
    jne r3, r2, lbb_11164                           if r3 != r2 { pc += -5 }
    ldxdw r2, [r1+0x10]                     
    ldxdw r3, [r6+0x10]                     
    jne r3, r2, lbb_11164                           if r3 != r2 { pc += -8 }
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
    ldxdw r1, [r1+0x18]                     
    ldxdw r3, [r6+0x18]                     
    jne r3, r1, lbb_11164                           if r3 != r1 { pc += -12 }
lbb_11176:
    mov64 r1, 41                                    r1 = 41 as i32 as i64 as u64
    stxdw [r10-0x690], r1                   
    lddw r1, 0x10006067d --> b"User account does not match expected userUser is n"        r1 load str located at 4295362173
    stxdw [r10-0x698], r1                   
    jeq r2, 0, lbb_11226                            if r2 == (0 as i32 as i64 as u64) { pc += 44 }
    lddw r1, 0x1000651e8 --> b"\x00\x00\x00\x00\xf0\xfe\x05\x00 \x00\x00\x00\x00\x00\x00\x00\x95\x00\x00…        r1 load str located at 4295381480
    stxdw [r10-0x720], r1                   
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    stxdw [r10-0x948], r1                   
    lddw r1, 0x100064c98 --> b"\x00\x00\x00\x00p\xfa\x05\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00…        r1 load str located at 4295380120
    stxdw [r10-0x968], r1                   
    mov64 r1, 2                                     r1 = 2 as i32 as i64 as u64
    stxdw [r10-0x960], r1                   
    stxdw [r10-0x950], r1                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -600                                  r1 += -600   ///  r1 = r1.wrapping_add(-600 as i32 as i64 as u64)
    stxdw [r10-0x958], r1                   
    lddw r1, 0x100000888 --> b"y\x11\x00\x00\x00\x00\x00\x00\x85\x10\x00\x00]\xab\x00\x00\x95\x00\x00\x0…        r1 load str located at 4294969480
    stxdw [r10-0x240], r1                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -1824                                 r1 += -1824   ///  r1 = r1.wrapping_add(-1824 as i32 as i64 as u64)
    stxdw [r10-0x248], r1                   
    lddw r1, 0x100000860 --> b"\xbf#\x00\x00\x00\x00\x00\x00y\x12\x08\x00\x00\x00\x00\x00y\x11\x00\x00\x…        r1 load str located at 4294969440
    stxdw [r10-0x250], r1                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -1688                                 r1 += -1688   ///  r1 = r1.wrapping_add(-1688 as i32 as i64 as u64)
    stxdw [r10-0x258], r1                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -736                                  r1 += -736   ///  r1 = r1.wrapping_add(-736 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -2408                                 r2 += -2408   ///  r2 = r2.wrapping_add(-2408 as i32 as i64 as u64)
    call function_43415                     
    ldxdw r1, [r10-0x2e0]                   
    ldxdw r2, [r10-0x2d0]                   
    syscall [invalid]                       
    ldxdw r1, [r6+0x18]                     
    stxdw [r10-0x94f], r1                   
    ldxdw r1, [r6+0x10]                     
    stxdw [r10-0x957], r1                   
    ldxdw r1, [r6+0x8]                      
    stxdw [r10-0x95f], r1                   
    ldxdw r1, [r6+0x0]                      
    stxdw [r10-0x967], r1                   
    mov64 r1, 53                                    r1 = 53 as i32 as i64 as u64
    ja lbb_11469                                    if true { pc += 243 }
lbb_11226:
    mov64 r1, r10                                   r1 = r10
    add64 r1, -600                                  r1 += -600   ///  r1 = r1.wrapping_add(-600 as i32 as i64 as u64)
    ldxdw r2, [r10-0xbc8]                   
    mov64 r3, r8                                    r3 = r8
    mov64 r4, r9                                    r4 = r9
    call function_17594                     
    ldxb r1, [r10-0x258]                    
    jeq r1, 56, lbb_11235                           if r1 == (56 as i32 as i64 as u64) { pc += 1 }
    ja lbb_11449                                    if true { pc += 214 }
lbb_11235:
    ldxdw r4, [r10-0x218]                   
    ldxdw r3, [r10-0x220]                   
    ldxdw r9, [r10-0x228]                   
    ldxdw r1, [r10-0x230]                   
    stxdw [r10-0xc08], r1                   
    ldxdw r1, [r10-0x238]                   
    stxdw [r10-0xbd8], r1                   
    ldxdw r8, [r10-0x240]                   
    ldxdw r0, [r10-0x248]                   
    ldxdw r7, [r10-0x250]                   
    ldxdw r1, [r10-0xbd0]                   
    ldxb r1, [r1+0x18]                      
    jeq r1, 0, lbb_11266                            if r1 == (0 as i32 as i64 as u64) { pc += 18 }
    ldxdw r1, [r7+0x8]                      
    ldxdw r2, [r10-0x990]                   
    ldxdw r6, [r2+0x0]                      
    ldxdw r2, [r6+0x0]                      
    jeq r2, r1, lbb_11255                           if r2 == r1 { pc += 2 }
lbb_11253:
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    ja lbb_11265                                    if true { pc += 10 }
lbb_11255:
    ldxdw r1, [r7+0x10]                     
    ldxdw r2, [r6+0x8]                      
    jne r2, r1, lbb_11253                           if r2 != r1 { pc += -5 }
    ldxdw r1, [r7+0x18]                     
    ldxdw r2, [r6+0x10]                     
    jne r2, r1, lbb_11253                           if r2 != r1 { pc += -8 }
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    ldxdw r2, [r7+0x20]                     
    ldxdw r5, [r6+0x18]                     
    jne r5, r2, lbb_11253                           if r5 != r2 { pc += -12 }
lbb_11265:
    jne r1, 0, lbb_11507                            if r1 != (0 as i32 as i64 as u64) { pc += 241 }
lbb_11266:
    stxdw [r10-0xc18], r0                   
    stxdw [r10-0xff8], r8                   
    stxdw [r10-0x1000], r7                  
    mov64 r6, r10                                   r6 = r10
    add64 r6, -2800                                 r6 += -2800   ///  r6 = r6.wrapping_add(-2800 as i32 as i64 as u64)
    stxdw [r10-0xff0], r6                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -2408                                 r1 += -2408   ///  r1 = r1.wrapping_add(-2408 as i32 as i64 as u64)
    mov64 r5, r10                                   r5 = r10
    call function_18436                     
    ldxb r1, [r10-0x968]                    
    jne r1, 56, lbb_11475                           if r1 != (56 as i32 as i64 as u64) { pc += 197 }
    stxdw [r10-0xc38], r6                   
    ldxdw r6, [r10-0x950]                   
    ldxdw r1, [r10-0x958]                   
    stxdw [r10-0xc28], r1                   
    mov64 r2, r7                                    r2 = r7
    ldxdw r7, [r10-0x960]                   
    ldxdw r4, [r10-0x940]                   
    ldxdw r3, [r10-0x948]                   
    stxdw [r10-0xff8], r8                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -2624                                 r1 += -2624   ///  r1 = r1.wrapping_add(-2624 as i32 as i64 as u64)
    stxdw [r10-0xff0], r1                   
    stxdw [r10-0xc68], r2                   
    stxdw [r10-0x1000], r2                  
    mov64 r1, r10                                   r1 = r10
    add64 r1, -2408                                 r1 += -2408   ///  r1 = r1.wrapping_add(-2408 as i32 as i64 as u64)
    mov64 r5, r10                                   r5 = r10
    call function_18436                     
    ldxb r1, [r10-0x968]                    
    jeq r1, 56, lbb_11317                           if r1 == (56 as i32 as i64 as u64) { pc += 19 }
    ldxw r2, [r10-0x964]                    
    stxw [r10-0x255], r2                    
    ldxw r2, [r10-0x967]                    
    stxw [r10-0x258], r2                    
    ldxdw r2, [r10-0x960]                   
    stxdw [r10-0xbc8], r2                   
    ldxdw r3, [r10-0x958]                   
    ldxdw r4, [r10-0x950]                   
    ldxdw r5, [r10-0x948]                   
    ldxdw r0, [r10-0x940]                   
    ldxdw r6, [r10-0x938]                   
    ldxdw r7, [r10-0x930]                   
    ldxdw r8, [r10-0x928]                   
    ldxdw r2, [r10-0xc28]                   
    ldxdw r9, [r2+0x0]                      
    add64 r9, -1                                    r9 += -1   ///  r9 = r9.wrapping_add(-1 as i32 as i64 as u64)
    stxdw [r2+0x0], r9                      
    ldxdw r2, [r10-0xbc8]                   
    ja lbb_11487                                    if true { pc += 170 }
lbb_11317:
    ldxdw r8, [r10-0x950]                   
    ldxdw r1, [r10-0x958]                   
    stxdw [r10-0xc40], r1                   
    ldxdw r1, [r10-0x960]                   
    stxdw [r10-0xbf0], r1                   
    ldxdw r4, [r10-0x940]                   
    ldxdw r3, [r10-0x948]                   
    stxdw [r10-0xc48], r7                   
    stxdw [r10-0xff0], r7                   
    stxdw [r10-0xfe8], r6                   
    stxdw [r10-0xff8], r9                   
    ldxdw r7, [r10-0xbd8]                   
    stxdw [r10-0x1000], r7                  
    mov64 r1, r10                                   r1 = r10
    add64 r1, -2408                                 r1 += -2408   ///  r1 = r1.wrapping_add(-2408 as i32 as i64 as u64)
    mov64 r5, r10                                   r5 = r10
    ldxdw r6, [r10-0xbc8]                   
    mov64 r2, r6                                    r2 = r6
    call function_16236                     
    ldxdw r1, [r10-0x950]                   
    stxdw [r10-0xbe8], r1                   
    ldxdw r1, [r10-0x958]                   
    stxdw [r10-0xbe0], r1                   
    ldxdw r1, [r10-0x960]                   
    stxdw [r10-0xbf8], r1                   
    ldxdw r1, [r10-0x968]                   
    stxdw [r10-0xc10], r1                   
    ldxw r1, [r10-0x8c0]                    
    jne r1, 2, lbb_11362                            if r1 != (2 as i32 as i64 as u64) { pc += 16 }
    ldxb r9, [r10-0x948]                    
    mov64 r6, r10                                   r6 = r10
    add64 r6, -600                                  r6 += -600   ///  r6 = r6.wrapping_add(-600 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -2375                                 r2 += -2375   ///  r2 = r2.wrapping_add(-2375 as i32 as i64 as u64)
    mov64 r1, r6                                    r1 = r6
    mov64 r3, 39                                    r3 = 39 as i32 as i64 as u64
    call function_48190                     
    mov64 r1, r10                                   r1 = r10
    add64 r1, -1688                                 r1 += -1688   ///  r1 = r1.wrapping_add(-1688 as i32 as i64 as u64)
    mov64 r2, r6                                    r2 = r6
    mov64 r3, 39                                    r3 = 39 as i32 as i64 as u64
    call function_48190                     
    ldxdw r7, [r10-0xbf8]                   
    ldxdw r8, [r10-0xc10]                   
    ja lbb_11716                                    if true { pc += 354 }
lbb_11362:
    stxdw [r10-0xc58], r1                   
    ldxdw r1, [r10-0xc38]                   
    ldxb r1, [r10-0x948]                    
    stxdw [r10-0xc60], r1                   
    mov64 r7, r10                                   r7 = r10
    add64 r7, -600                                  r7 += -600   ///  r7 = r7.wrapping_add(-600 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -2375                                 r2 += -2375   ///  r2 = r2.wrapping_add(-2375 as i32 as i64 as u64)
    mov64 r1, r7                                    r1 = r7
    mov64 r3, 135                                   r3 = 135 as i32 as i64 as u64
    call function_48190                     
    mov64 r1, r10                                   r1 = r10
    add64 r1, -776                                  r1 += -776   ///  r1 = r1.wrapping_add(-776 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -2236                                 r2 += -2236   ///  r2 = r2.wrapping_add(-2236 as i32 as i64 as u64)
    mov64 r3, 36                                    r3 = 36 as i32 as i64 as u64
    call function_48190                     
    mov64 r6, r8                                    r6 = r8
    ldxdw r8, [r10-0xbf0]                   
    ldxdw r1, [r10-0x898]                   
    stxdw [r10-0xc50], r1                   
    ldxdw r1, [r10-0x890]                   
    stxdw [r10-0xc20], r1                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -736                                  r1 += -736   ///  r1 = r1.wrapping_add(-736 as i32 as i64 as u64)
    mov64 r2, r7                                    r2 = r7
    mov64 r3, 135                                   r3 = 135 as i32 as i64 as u64
    call function_48190                     
    stxdw [r10-0xff0], r8                   
    stxdw [r10-0xfe8], r6                   
    stxdw [r10-0xc88], r9                   
    stxdw [r10-0xff8], r9                   
    ldxdw r1, [r10-0xbd8]                   
    stxdw [r10-0x1000], r1                  
    mov64 r1, r10                                   r1 = r10
    add64 r1, -2408                                 r1 += -2408   ///  r1 = r1.wrapping_add(-2408 as i32 as i64 as u64)
    mov64 r5, r10                                   r5 = r10
    ldxdw r2, [r10-0xbc8]                   
    ldxdw r3, [r10-0xc50]                   
    ldxdw r4, [r10-0xc20]                   
    call function_16236                     
    ldxb r1, [r10-0x948]                    
    stxdw [r10-0xc50], r1                   
    ldxdw r8, [r10-0x950]                   
    ldxdw r7, [r10-0x958]                   
    ldxdw r1, [r10-0x960]                   
    stxdw [r10-0xc20], r1                   
    ldxdw r1, [r10-0x968]                   
    stxdw [r10-0xbd8], r1                   
    ldxw r9, [r10-0x8c0]                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -1128                                 r1 += -1128   ///  r1 = r1.wrapping_add(-1128 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -2375                                 r2 += -2375   ///  r2 = r2.wrapping_add(-2375 as i32 as i64 as u64)
    mov64 r3, 39                                    r3 = 39 as i32 as i64 as u64
    call function_48190                     
    jne r9, 2, lbb_11586                            if r9 != (2 as i32 as i64 as u64) { pc += 167 }
    mov64 r1, r10                                   r1 = r10
    add64 r1, -1688                                 r1 += -1688   ///  r1 = r1.wrapping_add(-1688 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -1128                                 r2 += -1128   ///  r2 = r2.wrapping_add(-1128 as i32 as i64 as u64)
    mov64 r3, 39                                    r3 = 39 as i32 as i64 as u64
    call function_48190                     
    ldxdw r1, [r10-0xbd8]                   
    stxdw [r10-0xbe8], r8                   
    mov64 r8, r1                                    r8 = r1
    stxdw [r10-0xbe0], r7                   
    ldxdw r7, [r10-0xc20]                   
    ldxdw r9, [r10-0xc50]                   
    ja lbb_11712                                    if true { pc += 280 }
lbb_11432:
    mov64 r6, r10                                   r6 = r10
    add64 r6, -596                                  r6 += -596   ///  r6 = r6.wrapping_add(-596 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -2400                                 r2 += -2400   ///  r2 = r2.wrapping_add(-2400 as i32 as i64 as u64)
    mov64 r1, r6                                    r1 = r6
    mov64 r3, 72                                    r3 = 72 as i32 as i64 as u64
    call function_48190                     
    mov64 r7, r10                                   r7 = r10
    add64 r7, -2408                                 r7 += -2408   ///  r7 = r7.wrapping_add(-2408 as i32 as i64 as u64)
    mov64 r1, r7                                    r1 = r7
    mov64 r2, r6                                    r2 = r6
    mov64 r3, 72                                    r3 = 72 as i32 as i64 as u64
    call function_48190                     
    ldxdw r1, [r10-0xc00]                   
    mov64 r2, r7                                    r2 = r7
    call function_26067                     
    ja lbb_11585                                    if true { pc += 136 }
lbb_11449:
    ldxw r2, [r10-0x254]                    
    stxw [r10-0x964], r2                    
    ldxw r2, [r10-0x257]                    
    stxw [r10-0x967], r2                    
    ldxdw r2, [r10-0x218]                   
    stxdw [r10-0x928], r2                   
    ldxdw r2, [r10-0x220]                   
    stxdw [r10-0x930], r2                   
    ldxdw r2, [r10-0x228]                   
    stxdw [r10-0x938], r2                   
    ldxdw r2, [r10-0x230]                   
    stxdw [r10-0x940], r2                   
    ldxdw r2, [r10-0x238]                   
    stxdw [r10-0x948], r2                   
    ldxdw r2, [r10-0x240]                   
    stxdw [r10-0x950], r2                   
    ldxdw r2, [r10-0x248]                   
    stxdw [r10-0x958], r2                   
    ldxdw r2, [r10-0x250]                   
    stxdw [r10-0x960], r2                   
lbb_11469:
    stxb [r10-0x968], r1                    
    mov64 r2, r10                                   r2 = r10
    add64 r2, -2408                                 r2 += -2408   ///  r2 = r2.wrapping_add(-2408 as i32 as i64 as u64)
    ldxdw r1, [r10-0xc00]                   
    call function_26067                     
    ja lbb_11585                                    if true { pc += 110 }
lbb_11475:
    ldxw r2, [r10-0x964]                    
    stxw [r10-0x255], r2                    
    ldxw r2, [r10-0x967]                    
    stxw [r10-0x258], r2                    
    ldxdw r8, [r10-0x928]                   
    ldxdw r7, [r10-0x930]                   
    ldxdw r6, [r10-0x938]                   
    ldxdw r0, [r10-0x940]                   
    ldxdw r5, [r10-0x948]                   
    ldxdw r4, [r10-0x950]                   
    ldxdw r3, [r10-0x958]                   
    ldxdw r2, [r10-0x960]                   
lbb_11487:
    ldxw r9, [r10-0x255]                    
    stxw [r10-0x964], r9                    
    ldxw r9, [r10-0x258]                    
    stxw [r10-0x967], r9                    
    stxdw [r10-0x928], r8                   
    stxdw [r10-0x930], r7                   
    stxdw [r10-0x938], r6                   
    stxdw [r10-0x940], r0                   
    stxdw [r10-0x948], r5                   
    stxdw [r10-0x950], r4                   
    stxdw [r10-0x958], r3                   
    stxdw [r10-0x960], r2                   
    stxb [r10-0x968], r1                    
    mov64 r2, r10                                   r2 = r10
    add64 r2, -2408                                 r2 += -2408   ///  r2 = r2.wrapping_add(-2408 as i32 as i64 as u64)
    ldxdw r1, [r10-0xc00]                   
    call function_26067                     
    ldxdw r2, [r10-0xc18]                   
lbb_11505:
    ldxdw r3, [r10-0xc08]                   
    ja lbb_11579                                    if true { pc += 72 }
lbb_11507:
    ldxdw r1, [r7+0x28]                     
    ldxdw r2, [r6+0x0]                      
    jeq r2, r1, lbb_11512                           if r2 == r1 { pc += 2 }
lbb_11510:
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    ja lbb_11522                                    if true { pc += 10 }
lbb_11512:
    ldxdw r1, [r7+0x30]                     
    ldxdw r2, [r6+0x8]                      
    jne r2, r1, lbb_11510                           if r2 != r1 { pc += -5 }
    ldxdw r1, [r7+0x38]                     
    ldxdw r2, [r6+0x10]                     
    jne r2, r1, lbb_11510                           if r2 != r1 { pc += -8 }
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    ldxdw r2, [r7+0x40]                     
    ldxdw r5, [r6+0x18]                     
    jne r5, r2, lbb_11510                           if r5 != r2 { pc += -12 }
lbb_11522:
    mov64 r2, 36                                    r2 = 36 as i32 as i64 as u64
    stxdw [r10-0x690], r2                   
    lddw r2, 0x1000606a6 --> b"User is not dex owner or approved mmBase token min"        r2 load str located at 4295362214
    stxdw [r10-0x698], r2                   
    jeq r1, 0, lbb_11266                            if r1 == (0 as i32 as i64 as u64) { pc += -262 }
    lddw r1, 0x100065200 --> b"\x00\x00\x00\x00\xf0\xfe\x05\x00 \x00\x00\x00\x00\x00\x00\x00\xa2\x00\x00…        r1 load str located at 4295381504
    stxdw [r10-0x720], r1                   
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    stxdw [r10-0x948], r1                   
    lddw r1, 0x100064c98 --> b"\x00\x00\x00\x00p\xfa\x05\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00…        r1 load str located at 4295380120
    stxdw [r10-0x968], r1                   
    mov64 r1, 2                                     r1 = 2 as i32 as i64 as u64
    stxdw [r10-0x960], r1                   
    stxdw [r10-0x950], r1                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -600                                  r1 += -600   ///  r1 = r1.wrapping_add(-600 as i32 as i64 as u64)
    stxdw [r10-0x958], r1                   
    lddw r1, 0x100000888 --> b"y\x11\x00\x00\x00\x00\x00\x00\x85\x10\x00\x00]\xab\x00\x00\x95\x00\x00\x0…        r1 load str located at 4294969480
    stxdw [r10-0x240], r1                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -1824                                 r1 += -1824   ///  r1 = r1.wrapping_add(-1824 as i32 as i64 as u64)
    stxdw [r10-0x248], r1                   
    lddw r1, 0x100000860 --> b"\xbf#\x00\x00\x00\x00\x00\x00y\x12\x08\x00\x00\x00\x00\x00y\x11\x00\x00\x…        r1 load str located at 4294969440
    stxdw [r10-0x250], r1                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -1688                                 r1 += -1688   ///  r1 = r1.wrapping_add(-1688 as i32 as i64 as u64)
    stxdw [r10-0x258], r1                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -736                                  r1 += -736   ///  r1 = r1.wrapping_add(-736 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -2408                                 r2 += -2408   ///  r2 = r2.wrapping_add(-2408 as i32 as i64 as u64)
    mov64 r7, r0                                    r7 = r0
    call function_43415                     
    ldxdw r1, [r10-0x2e0]                   
    ldxdw r2, [r10-0x2d0]                   
    syscall [invalid]                       
    ldxdw r1, [r6+0x18]                     
    stxdw [r10-0x94f], r1                   
    ldxdw r1, [r6+0x10]                     
    stxdw [r10-0x957], r1                   
    ldxdw r1, [r6+0x8]                      
    stxdw [r10-0x95f], r1                   
    ldxdw r1, [r6+0x0]                      
    stxdw [r10-0x967], r1                   
    mov64 r1, 53                                    r1 = 53 as i32 as i64 as u64
    stxb [r10-0x968], r1                    
    mov64 r2, r10                                   r2 = r10
    add64 r2, -2408                                 r2 += -2408   ///  r2 = r2.wrapping_add(-2408 as i32 as i64 as u64)
    ldxdw r1, [r10-0xc00]                   
    call function_26067                     
    mov64 r2, r7                                    r2 = r7
    ja lbb_11505                                    if true { pc += -74 }
lbb_11579:
    ldxdw r1, [r3+0x0]                      
    add64 r1, -1                                    r1 += -1   ///  r1 = r1.wrapping_add(-1 as i32 as i64 as u64)
    stxdw [r3+0x0], r1                      
    ldxdw r1, [r2+0x0]                      
    add64 r1, -1                                    r1 += -1   ///  r1 = r1.wrapping_add(-1 as i32 as i64 as u64)
    stxdw [r2+0x0], r1                      
lbb_11585:
    exit                                    
lbb_11586:
    mov64 r1, r10                                   r1 = r10
    add64 r1, -600                                  r1 += -600   ///  r1 = r1.wrapping_add(-600 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -2336                                 r2 += -2336   ///  r2 = r2.wrapping_add(-2336 as i32 as i64 as u64)
    mov64 r3, 96                                    r3 = 96 as i32 as i64 as u64
    call function_48190                     
    mov64 r1, r10                                   r1 = r10
    add64 r1, -464                                  r1 += -464   ///  r1 = r1.wrapping_add(-464 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -2236                                 r2 += -2236   ///  r2 = r2.wrapping_add(-2236 as i32 as i64 as u64)
    mov64 r3, 36                                    r3 = 36 as i32 as i64 as u64
    call function_48190                     
    ldxdw r1, [r10-0x898]                   
    stxdw [r10-0xc80], r1                   
    ldxdw r1, [r10-0x890]                   
    stxdw [r10-0xc78], r1                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -424                                  r1 += -424   ///  r1 = r1.wrapping_add(-424 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -1128                                 r2 += -1128   ///  r2 = r2.wrapping_add(-1128 as i32 as i64 as u64)
    mov64 r3, 39                                    r3 = 39 as i32 as i64 as u64
    call function_48190                     
    ldxdw r1, [r7+0x0]                      
    ldxdw r2, [r1+0x0]                      
    ldxdw r3, [r10-0xbe0]                   
    ldxdw r6, [r3+0x0]                      
    ldxdw r3, [r6+0x0]                      
    jeq r3, r2, lbb_11616                           if r3 == r2 { pc += 2 }
lbb_11614:
    mov64 r2, 1                                     r2 = 1 as i32 as i64 as u64
    ja lbb_11626                                    if true { pc += 10 }
lbb_11616:
    ldxdw r2, [r1+0x8]                      
    ldxdw r3, [r6+0x8]                      
    jne r3, r2, lbb_11614                           if r3 != r2 { pc += -5 }
    ldxdw r2, [r1+0x10]                     
    ldxdw r3, [r6+0x10]                     
    jne r3, r2, lbb_11614                           if r3 != r2 { pc += -8 }
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
    ldxdw r1, [r1+0x18]                     
    ldxdw r3, [r6+0x18]                     
    jne r3, r1, lbb_11614                           if r3 != r1 { pc += -12 }
lbb_11626:
    mov64 r1, 45                                    r1 = 45 as i32 as i64 as u64
    stxdw [r10-0x148], r1                   
    lddw r1, 0x100060bba --> b"Base and quote coin accounts must be distinctBase "        r1 load str located at 4295363514
    stxdw [r10-0x150], r1                   
    jne r2, 0, lbb_11635                            if r2 != (0 as i32 as i64 as u64) { pc += 3 }
    lddw r1, 0x1000654e8 --> b"\x00\x00\x00\x00\xca\x0a\x06\x00&\x00\x00\x00\x00\x00\x00\x00\xc0\x00\x00…        r1 load str located at 4295382248
    ja lbb_11661                                    if true { pc += 26 }
lbb_11635:
    ldxdw r1, [r8+0x0]                      
    ldxdw r2, [r1+0x0]                      
    ldxdw r3, [r10-0xbe8]                   
    ldxdw r6, [r3+0x0]                      
    ldxdw r3, [r6+0x0]                      
    jeq r3, r2, lbb_11643                           if r3 == r2 { pc += 2 }
lbb_11641:
    mov64 r2, 1                                     r2 = 1 as i32 as i64 as u64
    ja lbb_11653                                    if true { pc += 10 }
lbb_11643:
    ldxdw r2, [r1+0x8]                      
    ldxdw r3, [r6+0x8]                      
    jne r3, r2, lbb_11641                           if r3 != r2 { pc += -5 }
    ldxdw r2, [r1+0x10]                     
    ldxdw r3, [r6+0x10]                     
    jne r3, r2, lbb_11641                           if r3 != r2 { pc += -8 }
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
    ldxdw r1, [r1+0x18]                     
    ldxdw r3, [r6+0x18]                     
    jne r3, r1, lbb_11641                           if r3 != r1 { pc += -12 }
lbb_11653:
    mov64 r1, 46                                    r1 = 46 as i32 as i64 as u64
    stxdw [r10-0x148], r1                   
    lddw r1, 0x100060be7 --> b"Base and quote token accounts must be distinctInst"        r1 load str located at 4295363559
    stxdw [r10-0x150], r1                   
    jne r2, 0, lbb_11744                            if r2 != (0 as i32 as i64 as u64) { pc += 85 }
    lddw r1, 0x100065500 --> b"\x00\x00\x00\x00\xca\x0a\x06\x00&\x00\x00\x00\x00\x00\x00\x00\xc8\x00\x00…        r1 load str located at 4295382272
lbb_11661:
    stxdw [r10-0x140], r1                   
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    stxdw [r10-0x948], r1                   
    lddw r1, 0x100064c98 --> b"\x00\x00\x00\x00p\xfa\x05\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00…        r1 load str located at 4295380120
    stxdw [r10-0x968], r1                   
    mov64 r1, 2                                     r1 = 2 as i32 as i64 as u64
    stxdw [r10-0x960], r1                   
    stxdw [r10-0x950], r1                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -1128                                 r1 += -1128   ///  r1 = r1.wrapping_add(-1128 as i32 as i64 as u64)
    stxdw [r10-0x958], r1                   
    lddw r1, 0x100000888 --> b"y\x11\x00\x00\x00\x00\x00\x00\x85\x10\x00\x00]\xab\x00\x00\x95\x00\x00\x0…        r1 load str located at 4294969480
    stxdw [r10-0x450], r1                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -320                                  r1 += -320   ///  r1 = r1.wrapping_add(-320 as i32 as i64 as u64)
    stxdw [r10-0x458], r1                   
    lddw r1, 0x100000860 --> b"\xbf#\x00\x00\x00\x00\x00\x00y\x12\x08\x00\x00\x00\x00\x00y\x11\x00\x00\x…        r1 load str located at 4294969440
    stxdw [r10-0x460], r1                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -336                                  r1 += -336   ///  r1 = r1.wrapping_add(-336 as i32 as i64 as u64)
    stxdw [r10-0x468], r1                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -312                                  r1 += -312   ///  r1 = r1.wrapping_add(-312 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -2408                                 r2 += -2408   ///  r2 = r2.wrapping_add(-2408 as i32 as i64 as u64)
    call function_43415                     
    ldxdw r1, [r10-0x138]                   
    ldxdw r2, [r10-0x128]                   
    syscall [invalid]                       
    ldxh r1, [r6+0x4]                       
    lsh64 r1, 32                                    r1 <<= 32   ///  r1 = r1.wrapping_shl(32)
    ldxb r2, [r6+0x6]                       
    lsh64 r2, 48                                    r2 <<= 48   ///  r2 = r2.wrapping_shl(48)
    or64 r2, r1                                     r2 |= r1   ///  r2 = r2.or(r1)
    ldxw r8, [r6+0x0]                       
    or64 r8, r2                                     r8 |= r2   ///  r8 = r8.or(r2)
    ldxb r9, [r6+0x1f]                      
    ldxdw r1, [r6+0x17]                     
    stxdw [r10-0xbe8], r1                   
    ldxdw r1, [r6+0xf]                      
    stxdw [r10-0xbe0], r1                   
    ldxdw r7, [r6+0x7]                      
    ldxdw r2, [r10-0xc20]                   
    ldxdw r1, [r2+0x0]                      
    add64 r1, 1                                     r1 += 1   ///  r1 = r1.wrapping_add(1 as i32 as i64 as u64)
    stxdw [r2+0x0], r1                      
    lsh64 r8, 8                                     r8 <<= 8   ///  r8 = r8.wrapping_shl(8)
    or64 r8, 6                                      r8 |= 6   ///  r8 = r8.or(6)
lbb_11712:
    ldxdw r2, [r10-0xbf8]                   
    ldxdw r1, [r2+0x0]                      
    add64 r1, 1                                     r1 += 1   ///  r1 = r1.wrapping_add(1 as i32 as i64 as u64)
    stxdw [r2+0x0], r1                      
lbb_11716:
    mov64 r6, r10                                   r6 = r10
    add64 r6, -1824                                 r6 += -1824   ///  r6 = r6.wrapping_add(-1824 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -1688                                 r2 += -1688   ///  r2 = r2.wrapping_add(-1688 as i32 as i64 as u64)
    mov64 r1, r6                                    r1 = r6
    mov64 r3, 39                                    r3 = 39 as i32 as i64 as u64
    call function_48190                     
    mov64 r1, r10                                   r1 = r10
    add64 r1, -2375                                 r1 += -2375   ///  r1 = r1.wrapping_add(-2375 as i32 as i64 as u64)
    mov64 r2, r6                                    r2 = r6
    mov64 r3, 39                                    r3 = 39 as i32 as i64 as u64
    call function_48190                     
    stxb [r10-0x948], r9                    
    ldxdw r1, [r10-0xbe8]                   
    stxdw [r10-0x950], r1                   
    ldxdw r1, [r10-0xbe0]                   
    stxdw [r10-0x958], r1                   
    stxdw [r10-0x960], r7                   
    stxdw [r10-0x968], r8                   
    mov64 r2, r10                                   r2 = r10
    add64 r2, -2408                                 r2 += -2408   ///  r2 = r2.wrapping_add(-2408 as i32 as i64 as u64)
    ldxdw r1, [r10-0xc00]                   
    call function_26067                     
    ldxdw r2, [r10-0xc18]                   
    ldxdw r3, [r10-0xc08]                   
    ldxdw r4, [r10-0xc28]                   
    ldxdw r5, [r10-0xc40]                   
    ja lbb_12547                                    if true { pc += 803 }
lbb_11744:
    stxdw [r10-0xc70], r8                   
    mov64 r8, r10                                   r8 = r10
    add64 r8, -1688                                 r8 += -1688   ///  r8 = r8.wrapping_add(-1688 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -736                                  r2 += -736   ///  r2 = r2.wrapping_add(-736 as i32 as i64 as u64)
    mov64 r1, r8                                    r1 = r8
    mov64 r3, 135                                   r3 = 135 as i32 as i64 as u64
    call function_48190                     
    mov64 r1, r10                                   r1 = r10
    add64 r1, -2236                                 r1 += -2236   ///  r1 = r1.wrapping_add(-2236 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -776                                  r2 += -776   ///  r2 = r2.wrapping_add(-776 as i32 as i64 as u64)
    mov64 r3, 36                                    r3 = 36 as i32 as i64 as u64
    call function_48190                     
    mov64 r1, r10                                   r1 = r10
    add64 r1, -2167                                 r1 += -2167   ///  r1 = r1.wrapping_add(-2167 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -424                                  r2 += -424   ///  r2 = r2.wrapping_add(-424 as i32 as i64 as u64)
    mov64 r3, 39                                    r3 = 39 as i32 as i64 as u64
    call function_48190                     
    mov64 r1, r10                                   r1 = r10
    add64 r1, -2128                                 r1 += -2128   ///  r1 = r1.wrapping_add(-2128 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -600                                  r2 += -600   ///  r2 = r2.wrapping_add(-600 as i32 as i64 as u64)
    mov64 r3, 96                                    r3 = 96 as i32 as i64 as u64
    call function_48190                     
    mov64 r1, r10                                   r1 = r10
    add64 r1, -2028                                 r1 += -2028   ///  r1 = r1.wrapping_add(-2028 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -464                                  r2 += -464   ///  r2 = r2.wrapping_add(-464 as i32 as i64 as u64)
    mov64 r3, 36                                    r3 = 36 as i32 as i64 as u64
    call function_48190                     
    mov64 r6, r10                                   r6 = r10
    add64 r6, -1824                                 r6 += -1824   ///  r6 = r6.wrapping_add(-1824 as i32 as i64 as u64)
    mov64 r1, r6                                    r1 = r6
    mov64 r2, r8                                    r2 = r8
    mov64 r3, 135                                   r3 = 135 as i32 as i64 as u64
    call function_48190                     
    mov64 r1, r10                                   r1 = r10
    add64 r1, -2375                                 r1 += -2375   ///  r1 = r1.wrapping_add(-2375 as i32 as i64 as u64)
    mov64 r2, r6                                    r2 = r6
    mov64 r3, 135                                   r3 = 135 as i32 as i64 as u64
    call function_48190                     
    ldxdw r1, [r10-0xc60]                   
    stxb [r10-0x948], r1                    
    ldxdw r1, [r10-0xbe8]                   
    stxdw [r10-0x950], r1                   
    ldxdw r1, [r10-0xbe0]                   
    stxdw [r10-0x958], r1                   
    ldxdw r1, [r10-0xbf8]                   
    stxdw [r10-0x960], r1                   
    ldxdw r1, [r10-0xc10]                   
    stxdw [r10-0x968], r1                   
    stxw [r10-0x7f0], r9                    
    ldxdw r1, [r10-0xc50]                   
    stxb [r10-0x878], r1                    
    ldxdw r1, [r10-0xc70]                   
    stxdw [r10-0x880], r1                   
    stxdw [r10-0x888], r7                   
    ldxdw r7, [r10-0xc20]                   
    stxdw [r10-0x890], r7                   
    ldxdw r1, [r10-0xbd8]                   
    stxdw [r10-0x898], r1                   
    ldxdw r1, [r10-0xc58]                   
    stxw [r10-0x8c0], r1                    
    ldxdw r3, [r10-0xc48]                   
    ldxdw r1, [r3+0x18]                     
    ldxdw r2, [r10-0x948]                   
    jeq r2, r1, lbb_11815                           if r2 == r1 { pc += 2 }
lbb_11813:
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    ja lbb_11825                                    if true { pc += 10 }
lbb_11815:
    ldxdw r1, [r3+0x20]                     
    ldxdw r2, [r10-0x940]                   
    jne r2, r1, lbb_11813                           if r2 != r1 { pc += -5 }
    ldxdw r1, [r3+0x28]                     
    ldxdw r2, [r10-0x938]                   
    jne r2, r1, lbb_11813                           if r2 != r1 { pc += -8 }
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    ldxdw r2, [r3+0x30]                     
    ldxdw r3, [r10-0x930]                   
    jne r3, r2, lbb_11813                           if r3 != r2 { pc += -12 }
lbb_11825:
    ldxdw r3, [r10-0xbc8]                   
    ldxdw r4, [r10-0xbf0]                   
    ldxdw r8, [r10-0xc30]                   
    jeq r1, 0, lbb_11874                            if r1 == (0 as i32 as i64 as u64) { pc += 45 }
    lddw r1, 0x300000000                            r1 load str located at 12884901888
    ldxdw r2, [r1+0x0]                      
    mov64 r1, r2                                    r1 = r2
    add64 r1, -24                                   r1 += -24   ///  r1 = r1.wrapping_add(-24 as i32 as i64 as u64)
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
    mov64 r4, 1                                     r4 = 1 as i32 as i64 as u64
    jgt r1, r2, lbb_11838                           if r1 > r2 { pc += 1 }
    mov64 r4, 0                                     r4 = 0 as i32 as i64 as u64
lbb_11838:
    jne r4, 0, lbb_11840                            if r4 != (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r3, r1                                    r3 = r1
lbb_11840:
    lddw r1, 0x300007fe8                            r1 load str located at 12884934632
    jeq r2, 0, lbb_11844                            if r2 == (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r1, r3                                    r1 = r3
lbb_11844:
    lddw r2, 0x300000007                            r2 load str located at 12884901895
    jgt r1, r2, lbb_11851                           if r1 > r2 { pc += 4 }
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    mov64 r2, 24                                    r2 = 24 as i32 as i64 as u64
    call function_43400                     
    syscall [invalid]                       
lbb_11851:
    lddw r2, 0x300000000                            r2 load str located at 12884901888
    stxdw [r2+0x0], r1                      
    lddw r2, 0x686374616d73696d                     r2 load str located at 7521983764435790189
    stxdw [r1+0x10], r2                     
    lddw r2, 0x20746e696d206e65                     r2 load str located at 2338615505593593445
    stxdw [r1+0x8], r2                      
    lddw r2, 0x6b6f742065736142                     r2 load str located at 7741533966963007810
    stxdw [r1+0x0], r2                      
    mov64 r2, 24                                    r2 = 24 as i32 as i64 as u64
lbb_11864:
    stxdw [r10-0x240], r2                   
    stxdw [r10-0x248], r2                   
    stxdw [r10-0x250], r1                   
lbb_11867:
    mov64 r1, 29                                    r1 = 29 as i32 as i64 as u64
lbb_11868:
    stxb [r10-0x258], r1                    
    mov64 r2, r10                                   r2 = r10
    add64 r2, -600                                  r2 += -600   ///  r2 = r2.wrapping_add(-600 as i32 as i64 as u64)
    ldxdw r1, [r10-0xc00]                   
    call function_26067                     
    ja lbb_12095                                    if true { pc += 221 }
lbb_11874:
    ldxdw r1, [r4+0x18]                     
    ldxdw r2, [r10-0x878]                   
    jeq r2, r1, lbb_11879                           if r2 == r1 { pc += 2 }
lbb_11877:
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    ja lbb_11889                                    if true { pc += 10 }
lbb_11879:
    ldxdw r1, [r4+0x20]                     
    ldxdw r2, [r10-0x870]                   
    jne r2, r1, lbb_11877                           if r2 != r1 { pc += -5 }
    ldxdw r1, [r4+0x28]                     
    ldxdw r2, [r10-0x868]                   
    jne r2, r1, lbb_11877                           if r2 != r1 { pc += -8 }
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    ldxdw r2, [r4+0x30]                     
    ldxdw r4, [r10-0x860]                   
    jne r4, r2, lbb_11877                           if r4 != r2 { pc += -12 }
lbb_11889:
    jeq r1, 0, lbb_11912                            if r1 == (0 as i32 as i64 as u64) { pc += 22 }
    lddw r1, 0x300000000                            r1 load str located at 12884901888
    ldxdw r2, [r1+0x0]                      
    mov64 r1, r2                                    r1 = r2
    add64 r1, -25                                   r1 += -25   ///  r1 = r1.wrapping_add(-25 as i32 as i64 as u64)
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
    mov64 r4, 1                                     r4 = 1 as i32 as i64 as u64
    jgt r1, r2, lbb_11899                           if r1 > r2 { pc += 1 }
    mov64 r4, 0                                     r4 = 0 as i32 as i64 as u64
lbb_11899:
    jne r4, 0, lbb_11901                            if r4 != (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r3, r1                                    r3 = r1
lbb_11901:
    lddw r1, 0x300007fe7                            r1 load str located at 12884934631
    jeq r2, 0, lbb_11905                            if r2 == (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r1, r3                                    r1 = r3
lbb_11905:
    lddw r2, 0x300000007                            r2 load str located at 12884901895
    jgt r1, r2, lbb_12407                           if r1 > r2 { pc += 499 }
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    mov64 r2, 25                                    r2 = 25 as i32 as i64 as u64
    call function_43400                     
    syscall [invalid]                       
lbb_11912:
    ldxdw r2, [r10-0xc78]                   
    jeq r2, 1, lbb_11917                            if r2 == (1 as i32 as i64 as u64) { pc += 3 }
    jne r2, 0, lbb_12678                            if r2 != (0 as i32 as i64 as u64) { pc += 763 }
    mov64 r6, 0                                     r6 = 0 as i32 as i64 as u64
    ja lbb_11980                                    if true { pc += 63 }
lbb_11917:
    ldxdw r4, [r10-0xc80]                   
    ldxdw r6, [r4+0x0]                      
    ldxb r1, [r4+0x28]                      
    mov64 r2, 30                                    r2 = 30 as i32 as i64 as u64
    stxdw [r10-0x718], r2                   
    lddw r2, 0x1000606fb --> b"Signer account is not a signerSomehow cannot get c"        r2 load str located at 4295362299
    stxdw [r10-0x720], r2                   
    jne r1, 0, lbb_11970                            if r1 != (0 as i32 as i64 as u64) { pc += 44 }
    lddw r1, 0x100065218 --> b"\x00\x00\x00\x00\xf0\xfe\x05\x00 \x00\x00\x00\x00\x00\x00\x00\xce\x00\x00…        r1 load str located at 4295381528
    stxdw [r10-0x468], r1                   
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    stxdw [r10-0x238], r1                   
    lddw r1, 0x100064c98 --> b"\x00\x00\x00\x00p\xfa\x05\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00…        r1 load str located at 4295380120
    stxdw [r10-0x258], r1                   
    mov64 r1, 2                                     r1 = 2 as i32 as i64 as u64
    stxdw [r10-0x250], r1                   
    stxdw [r10-0x240], r1                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -736                                  r1 += -736   ///  r1 = r1.wrapping_add(-736 as i32 as i64 as u64)
    stxdw [r10-0x248], r1                   
    lddw r1, 0x100000888 --> b"y\x11\x00\x00\x00\x00\x00\x00\x85\x10\x00\x00]\xab\x00\x00\x95\x00\x00\x0…        r1 load str located at 4294969480
    stxdw [r10-0x2c8], r1                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -1128                                 r1 += -1128   ///  r1 = r1.wrapping_add(-1128 as i32 as i64 as u64)
    stxdw [r10-0x2d0], r1                   
    lddw r1, 0x100000860 --> b"\xbf#\x00\x00\x00\x00\x00\x00y\x12\x08\x00\x00\x00\x00\x00y\x11\x00\x00\x…        r1 load str located at 4294969440
    stxdw [r10-0x2d8], r1                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -1824                                 r1 += -1824   ///  r1 = r1.wrapping_add(-1824 as i32 as i64 as u64)
    stxdw [r10-0x2e0], r1                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -1688                                 r1 += -1688   ///  r1 = r1.wrapping_add(-1688 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -600                                  r2 += -600   ///  r2 = r2.wrapping_add(-600 as i32 as i64 as u64)
    call function_43415                     
    ldxdw r1, [r10-0x698]                   
    ldxdw r2, [r10-0x688]                   
    syscall [invalid]                       
    ldxdw r1, [r6+0x18]                     
    stxdw [r10-0x23f], r1                   
    ldxdw r1, [r6+0x10]                     
    stxdw [r10-0x247], r1                   
    ldxdw r1, [r6+0x8]                      
    stxdw [r10-0x24f], r1                   
    ldxdw r1, [r6+0x0]                      
    stxdw [r10-0x257], r1                   
    mov64 r1, 12                                    r1 = 12 as i32 as i64 as u64
    ja lbb_11868                                    if true { pc += -102 }
lbb_11970:
    ldxdw r1, [r4+0x0]                      
    ldxdw r2, [r1+0x18]                     
    stxdw [r10-0x450], r2                   
    ldxdw r2, [r1+0x10]                     
    stxdw [r10-0x458], r2                   
    ldxdw r2, [r1+0x8]                      
    stxdw [r10-0x460], r2                   
    ldxdw r1, [r1+0x0]                      
    stxdw [r10-0x468], r1                   
    mov64 r6, 1                                     r6 = 1 as i32 as i64 as u64
lbb_11980:
    mov64 r1, r10                                   r1 = r10
    add64 r1, -1824                                 r1 += -1824   ///  r1 = r1.wrapping_add(-1824 as i32 as i64 as u64)
    mov64 r2, r8                                    r2 = r8
    call function_3195                      
    mov64 r1, 38                                    r1 = 38 as i32 as i64 as u64
    stxdw [r10-0x1c8], r1                   
    lddw r1, 0x100060719 --> b"Somehow cannot get current instructionUser passed "        r1 load str located at 4295362329
    stxdw [r10-0x1d0], r1                   
    ldxw r1, [r10-0x720]                    
    jeq r1, 24, lbb_12060                           if r1 == (24 as i32 as i64 as u64) { pc += 69 }
    ldxdw r1, [r10-0x708]                   
    stxdw [r10-0x680], r1                   
    ldxdw r1, [r10-0x710]                   
    stxdw [r10-0x688], r1                   
    ldxdw r1, [r10-0x718]                   
    stxdw [r10-0x690], r1                   
    ldxdw r1, [r10-0x720]                   
    stxdw [r10-0x698], r1                   
    lddw r1, 0x100064c20 --> b"\x00\x00\x00\x00\x1f\xfe\x05\x00\x1b\x00\x00\x00\x00\x00\x00\x00k\x00\x00…        r1 load str located at 4295380000
    stxdw [r10-0x308], r1                   
    lddw r1, 0x100064c38 --> b"\x00\x00\x00\x00p\xfa\x05\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00…        r1 load str located at 4295380024
    stxdw [r10-0x2e0], r1                   
    mov64 r1, 3                                     r1 = 3 as i32 as i64 as u64
    stxdw [r10-0x2d8], r1                   
    stxdw [r10-0x2c8], r1                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -600                                  r1 += -600   ///  r1 = r1.wrapping_add(-600 as i32 as i64 as u64)
    stxdw [r10-0x2d0], r1                   
    lddw r1, 0x100000888 --> b"y\x11\x00\x00\x00\x00\x00\x00\x85\x10\x00\x00]\xab\x00\x00\x95\x00\x00\x0…        r1 load str located at 4294969480
    stxdw [r10-0x230], r1                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -776                                  r1 += -776   ///  r1 = r1.wrapping_add(-776 as i32 as i64 as u64)
    stxdw [r10-0x238], r1                   
    lddw r1, 0x100051998 --> b"\xbf#\x00\x00\x00\x00\x00\x00a\x12\x00\x00\x00\x00\x00\x00e\x02\x09\x00\x…        r1 load str located at 4295301528
    stxdw [r10-0x240], r1                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -1688                                 r1 += -1688   ///  r1 = r1.wrapping_add(-1688 as i32 as i64 as u64)
    stxdw [r10-0x248], r1                   
    lddw r1, 0x100000860 --> b"\xbf#\x00\x00\x00\x00\x00\x00y\x12\x08\x00\x00\x00\x00\x00y\x11\x00\x00\x…        r1 load str located at 4294969440
    stxdw [r10-0x250], r1                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -464                                  r1 += -464   ///  r1 = r1.wrapping_add(-464 as i32 as i64 as u64)
    stxdw [r10-0x258], r1                   
    mov64 r7, 0                                     r7 = 0 as i32 as i64 as u64
    stxdw [r10-0x2c0], r7                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -424                                  r1 += -424   ///  r1 = r1.wrapping_add(-424 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -736                                  r2 += -736   ///  r2 = r2.wrapping_add(-736 as i32 as i64 as u64)
    call function_43415                     
    ldxdw r1, [r10-0x1a8]                   
    ldxdw r2, [r10-0x198]                   
    syscall [invalid]                       
    lddw r1, 0x300000000                            r1 load str located at 12884901888
    ldxdw r1, [r1+0x0]                      
    mov64 r3, 1                                     r3 = 1 as i32 as i64 as u64
    mov64 r2, r1                                    r2 = r1
    add64 r2, -38                                   r2 += -38   ///  r2 = r2.wrapping_add(-38 as i32 as i64 as u64)
    jgt r2, r1, lbb_12047                           if r2 > r1 { pc += 1 }
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
lbb_12047:
    jne r3, 0, lbb_12049                            if r3 != (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r7, r2                                    r7 = r2
lbb_12049:
    lddw r6, 0x300007fda                            r6 load str located at 12884934618
    jeq r1, 0, lbb_12053                            if r1 == (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r6, r7                                    r6 = r7
lbb_12053:
    lddw r1, 0x300000007                            r1 load str located at 12884901895
    jgt r6, r1, lbb_12423                           if r6 > r1 { pc += 367 }
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    mov64 r2, 38                                    r2 = 38 as i32 as i64 as u64
    call function_43400                     
    syscall [invalid]                       
lbb_12060:
    ldxb r9, [r10-0x71c]                    
    ldxdw r3, [r10-0xc68]                   
    add64 r3, 72                                    r3 += 72   ///  r3 = r3.wrapping_add(72 as i32 as i64 as u64)
    mov64 r1, r10                                   r1 = r10
    add64 r1, -600                                  r1 += -600   ///  r1 = r1.wrapping_add(-600 as i32 as i64 as u64)
    mov64 r2, r8                                    r2 = r8
    call function_3333                      
    ldxdw r2, [r10-0x258]                   
    jeq r2, 2, lbb_12086                            if r2 == (2 as i32 as i64 as u64) { pc += 17 }
    ldxw r3, [r10-0x220]                    
    mov64 r1, r3                                    r1 = r3
    and64 r1, 255                                   r1 &= 255   ///  r1 = r1.and(255)
    jeq r1, 0, lbb_12100                            if r1 == (0 as i32 as i64 as u64) { pc += 27 }
    mov64 r7, 0                                     r7 = 0 as i32 as i64 as u64
    jeq r1, 2, lbb_12082                            if r1 == (2 as i32 as i64 as u64) { pc += 7 }
    mov64 r7, r3                                    r7 = r3
    rsh64 r7, 16                                    r7 >>= 16   ///  r7 = r7.wrapping_shr(16)
    and64 r7, 255                                   r7 &= 255   ///  r7 = r7.and(255)
    jne r9, 0, lbb_12082                            if r9 != (0 as i32 as i64 as u64) { pc += 3 }
    mov64 r1, r3                                    r1 = r3
    and64 r1, 1                                     r1 &= 1   ///  r1 = r1.and(1)
    jne r1, 0, lbb_12105                            if r1 != (0 as i32 as i64 as u64) { pc += 23 }
lbb_12082:
    jeq r9, 0, lbb_12102                            if r9 == (0 as i32 as i64 as u64) { pc += 19 }
    jeq r9, 1, lbb_12104                            if r9 == (1 as i32 as i64 as u64) { pc += 20 }
    add64 r7, 2                                     r7 += 2   ///  r7 = r7.wrapping_add(2 as i32 as i64 as u64)
    ja lbb_12105                                    if true { pc += 19 }
lbb_12086:
    ldxdw r1, [r10-0x250]                   
    ldxdw r2, [r10-0x248]                   
    ldxdw r3, [r10-0x240]                   
    ldxdw r4, [r10-0x238]                   
    ldxdw r5, [r10-0xc00]                   
    stxdw [r5+0x18], r4                     
    stxdw [r5+0x10], r3                     
    stxdw [r5+0x8], r2                      
    stxdw [r5+0x0], r1                      
lbb_12095:
    ldxdw r2, [r10-0xc18]                   
    ldxdw r3, [r10-0xc08]                   
    ldxdw r4, [r10-0xc28]                   
    ldxdw r5, [r10-0xc40]                   
    ja lbb_12540                                    if true { pc += 440 }
lbb_12100:
    mov64 r7, -1                                    r7 = -1 as i32 as i64 as u64
    ja lbb_12082                                    if true { pc += -20 }
lbb_12102:
    add64 r7, -1                                    r7 += -1   ///  r7 = r7.wrapping_add(-1 as i32 as i64 as u64)
    ja lbb_12105                                    if true { pc += 1 }
lbb_12104:
    add64 r7, 1                                     r7 += 1   ///  r7 = r7.wrapping_add(1 as i32 as i64 as u64)
lbb_12105:
    stxdw [r10-0xc60], r9                   
    ldxdw r5, [r10-0x228]                   
    ldxw r4, [r10-0x248]                    
    ldxdw r0, [r10-0x250]                   
    mov64 r9, 0                                     r9 = 0 as i32 as i64 as u64
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    jeq r2, 0, lbb_12113                            if r2 == (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r1, r0                                    r1 = r0
lbb_12113:
    stxdw [r10-0xc30], r2                   
    mul64 r1, r4                                    r1 *= r4   ///  r1 = r1.wrapping_mul(r4)
    div64 r1, 1000000                               r1 /= 1000000   ///  r1 = r1 / (1000000 as u64)
    jgt r1, r5, lbb_12118                           if r1 > r5 { pc += 1 }
    mov64 r1, r5                                    r1 = r5
lbb_12118:
    stxdw [r10-0xc50], r5                   
    mov64 r2, 1000001                               r2 = 1000001 as i32 as i64 as u64
    jgt r2, r1, lbb_12149                           if r2 > r1 { pc += 28 }
    mov64 r9, 1                                     r9 = 1 as i32 as i64 as u64
    mov64 r2, 2000001                               r2 = 2000001 as i32 as i64 as u64
    jgt r2, r1, lbb_12149                           if r2 > r1 { pc += 25 }
    mov64 r9, 2                                     r9 = 2 as i32 as i64 as u64
    mov64 r2, 5000001                               r2 = 5000001 as i32 as i64 as u64
    jgt r2, r1, lbb_12149                           if r2 > r1 { pc += 22 }
    mov64 r9, 3                                     r9 = 3 as i32 as i64 as u64
    mov64 r2, 10000001                              r2 = 10000001 as i32 as i64 as u64
    jgt r2, r1, lbb_12149                           if r2 > r1 { pc += 19 }
    mov64 r9, 4                                     r9 = 4 as i32 as i64 as u64
    mov64 r2, 20000001                              r2 = 20000001 as i32 as i64 as u64
    jgt r2, r1, lbb_12149                           if r2 > r1 { pc += 16 }
    mov64 r9, 5                                     r9 = 5 as i32 as i64 as u64
    mov64 r2, 50000001                              r2 = 50000001 as i32 as i64 as u64
    jgt r2, r1, lbb_12149                           if r2 > r1 { pc += 13 }
    mov64 r9, 6                                     r9 = 6 as i32 as i64 as u64
    mov64 r2, 100000001                             r2 = 100000001 as i32 as i64 as u64
    jgt r2, r1, lbb_12149                           if r2 > r1 { pc += 10 }
    mov64 r9, 7                                     r9 = 7 as i32 as i64 as u64
    mov64 r2, 200000001                             r2 = 200000001 as i32 as i64 as u64
    jgt r2, r1, lbb_12149                           if r2 > r1 { pc += 7 }
    mov64 r9, 8                                     r9 = 8 as i32 as i64 as u64
    mov64 r2, 500000001                             r2 = 500000001 as i32 as i64 as u64
    jgt r2, r1, lbb_12149                           if r2 > r1 { pc += 4 }
    mov64 r9, 9                                     r9 = 9 as i32 as i64 as u64
    mov64 r2, 1000000001                            r2 = 1000000001 as i32 as i64 as u64
    jgt r2, r1, lbb_12149                           if r2 > r1 { pc += 1 }
    mov64 r9, 10                                    r9 = 10 as i32 as i64 as u64
lbb_12149:
    stxdw [r10-0xc80], r0                   
    stxdw [r10-0xc78], r4                   
    stxdw [r10-0xc68], r3                   
    stxdw [r10-0xc58], r6                   
    ldxw r1, [r10-0x21c]                    
    stxdw [r10-0xc90], r1                   
    ldxdw r1, [r10-0x230]                   
    stxdw [r10-0xca0], r1                   
    ldxdw r1, [r10-0x238]                   
    stxdw [r10-0xca8], r1                   
    ldxdw r1, [r10-0x240]                   
    stxdw [r10-0xcb0], r1                   
    ldxw r1, [r10-0x244]                    
    stxdw [r10-0xc98], r1                   
    mov64 r1, 5                                     r1 = 5 as i32 as i64 as u64
    stxdw [r10-0xff8], r1                   
    mov64 r6, 0                                     r6 = 0 as i32 as i64 as u64
    stxdw [r10-0x1000], r6                  
    mov64 r8, r10                                   r8 = r10
    add64 r8, -600                                  r8 += -600   ///  r8 = r8.wrapping_add(-600 as i32 as i64 as u64)
    mov64 r5, r10                                   r5 = r10
    mov64 r1, r8                                    r1 = r8
    mov64 r2, 99995                                 r2 = 99995 as i32 as i64 as u64
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
    mov64 r4, 0                                     r4 = 0 as i32 as i64 as u64
    call function_33183                     
    ldxdw r2, [r10-0xc50]                   
    ldxdw r1, [r10-0xc30]                   
    or64 r2, r1                                     r2 |= r1   ///  r2 = r2.or(r1)
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    jeq r2, 0, lbb_12181                            if r2 == (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
lbb_12181:
    add64 r7, r1                                    r7 += r1   ///  r7 = r7.wrapping_add(r1)
    add64 r7, r9                                    r7 += r9   ///  r7 = r7.wrapping_add(r9)
    mov64 r2, 10                                    r2 = 10 as i32 as i64 as u64
    mov64 r1, r7                                    r1 = r7
    jgt r2, r7, lbb_12187                           if r2 > r7 { pc += 1 }
    mov64 r1, 10                                    r1 = 10 as i32 as i64 as u64
lbb_12187:
    ldxdw r9, [r10-0xbd8]                   
    jsgt r6, r7, lbb_12190                          if (r6 as i64) > (r7 as i64) { pc += 1 }
    mov64 r6, r1                                    r6 = r1
lbb_12190:
    mov64 r1, r10                                   r1 = r10
    add64 r1, -336                                  r1 += -336   ///  r1 = r1.wrapping_add(-336 as i32 as i64 as u64)
    mov64 r2, r8                                    r2 = r8
    mov64 r3, r6                                    r3 = r6
    call function_38094                     
    ldxdw r1, [r10-0xbd0]                   
    ldxdw r6, [r1+0x0]                      
    ldxdw r7, [r10-0xa00]                   
    mov64 r1, 43                                    r1 = 43 as i32 as i64 as u64
    stxdw [r10-0x718], r1                   
    lddw r1, 0x10006073f --> b"User passed insufficient quote token amountQuote t"        r1 load str located at 4295362367
    stxdw [r10-0x720], r1                   
    jge r7, r6, lbb_12242                           if r7 >= r6 { pc += 38 }
    lddw r1, 0x100065230 --> b"\x00\x00\x00\x00\xf0\xfe\x05\x00 \x00\x00\x00\x00\x00\x00\x00\xee\x00\x00…        r1 load str located at 4295381552
    stxdw [r10-0x1a8], r1                   
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    stxdw [r10-0x238], r1                   
    lddw r1, 0x100064c98 --> b"\x00\x00\x00\x00p\xfa\x05\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00…        r1 load str located at 4295380120
    stxdw [r10-0x258], r1                   
    mov64 r1, 2                                     r1 = 2 as i32 as i64 as u64
    stxdw [r10-0x250], r1                   
    stxdw [r10-0x240], r1                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -736                                  r1 += -736   ///  r1 = r1.wrapping_add(-736 as i32 as i64 as u64)
    stxdw [r10-0x248], r1                   
    lddw r1, 0x100000888 --> b"y\x11\x00\x00\x00\x00\x00\x00\x85\x10\x00\x00]\xab\x00\x00\x95\x00\x00\x0…        r1 load str located at 4294969480
    stxdw [r10-0x2c8], r1                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -424                                  r1 += -424   ///  r1 = r1.wrapping_add(-424 as i32 as i64 as u64)
    stxdw [r10-0x2d0], r1                   
    lddw r1, 0x100000860 --> b"\xbf#\x00\x00\x00\x00\x00\x00y\x12\x08\x00\x00\x00\x00\x00y\x11\x00\x00\x…        r1 load str located at 4294969440
    stxdw [r10-0x2d8], r1                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -1824                                 r1 += -1824   ///  r1 = r1.wrapping_add(-1824 as i32 as i64 as u64)
    stxdw [r10-0x2e0], r1                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -1688                                 r1 += -1688   ///  r1 = r1.wrapping_add(-1688 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -600                                  r2 += -600   ///  r2 = r2.wrapping_add(-600 as i32 as i64 as u64)
    call function_43415                     
    ldxdw r1, [r10-0x698]                   
    ldxdw r2, [r10-0x688]                   
    syscall [invalid]                       
    stxdw [r10-0x248], r7                   
    stxdw [r10-0x250], r6                   
    mov64 r1, 23                                    r1 = 23 as i32 as i64 as u64
    ja lbb_12436                                    if true { pc += 194 }
lbb_12242:
    ldxb r1, [r9+0x41a]                     
    ldxb r7, [r10-0xb18]                    
    jeq r7, r1, lbb_12261                           if r7 == r1 { pc += 16 }
    mov64 r1, r10                                   r1 = r10
    add64 r1, -2840                                 r1 += -2840   ///  r1 = r1.wrapping_add(-2840 as i32 as i64 as u64)
    add64 r9, 1050                                  r9 += 1050   ///  r9 = r9.wrapping_add(1050 as i32 as i64 as u64)
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
    stxdw [r10-0x2c0], r2                   
    lddw r2, 0x100065248 --> b"\x00\x00\x00\x00j\x07\x06\x00)\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x0…        r2 load str located at 4295381576
    stxdw [r10-0x2e0], r2                   
    mov64 r2, 2                                     r2 = 2 as i32 as i64 as u64
    stxdw [r10-0x2d8], r2                   
    stxdw [r10-0x2c8], r2                   
    mov64 r2, r10                                   r2 = r10
    add64 r2, -1688                                 r2 += -1688   ///  r2 = r2.wrapping_add(-1688 as i32 as i64 as u64)
    stxdw [r10-0x2d0], r2                   
    stxdw [r10-0x688], r9                   
    ja lbb_12280                                    if true { pc += 19 }
lbb_12261:
    ldxdw r3, [r10-0xc10]                   
    ldxb r1, [r3+0x41a]                     
    ldxb r2, [r10-0xb70]                    
    jeq r2, r1, lbb_12291                           if r2 == r1 { pc += 26 }
    mov64 r1, r10                                   r1 = r10
    add64 r1, -2928                                 r1 += -2928   ///  r1 = r1.wrapping_add(-2928 as i32 as i64 as u64)
    add64 r3, 1050                                  r3 += 1050   ///  r3 = r3.wrapping_add(1050 as i32 as i64 as u64)
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
    stxdw [r10-0x2c0], r2                   
    lddw r2, 0x100065268 --> b"\x00\x00\x00\x00\x93\x07\x06\x00(\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00…        r2 load str located at 4295381608
    stxdw [r10-0x2e0], r2                   
    mov64 r2, 2                                     r2 = 2 as i32 as i64 as u64
    stxdw [r10-0x2d8], r2                   
    stxdw [r10-0x2c8], r2                   
    mov64 r2, r10                                   r2 = r10
    add64 r2, -1688                                 r2 += -1688   ///  r2 = r2.wrapping_add(-1688 as i32 as i64 as u64)
    stxdw [r10-0x2d0], r2                   
    stxdw [r10-0x688], r3                   
lbb_12280:
    lddw r2, 0x10005de98 --> b"\xbf#\x00\x00\x00\x00\x00\x00q\x11\x00\x00\x00\x00\x00\x00\xb7\x02\x00\x0…        r2 load str located at 4295351960
    stxdw [r10-0x680], r2                   
    stxdw [r10-0x690], r2                   
    stxdw [r10-0x698], r1                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -592                                  r1 += -592   ///  r1 = r1.wrapping_add(-592 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -736                                  r2 += -736   ///  r2 = r2.wrapping_add(-736 as i32 as i64 as u64)
    call function_445                       
    ja lbb_12435                                    if true { pc += 144 }
lbb_12291:
    mov64 r1, r10                                   r1 = r10
    add64 r1, -1824                                 r1 += -1824   ///  r1 = r1.wrapping_add(-1824 as i32 as i64 as u64)
    mov64 r2, r6                                    r2 = r6
    mov64 r3, r7                                    r3 = r7
    call function_33100                     
    stxb [r10-0x708], r7                    
    stxdw [r10-0x710], r6                   
    ldxdw r7, [r10-0x908]                   
    ldxb r8, [r10-0xb70]                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -1688                                 r1 += -1688   ///  r1 = r1.wrapping_add(-1688 as i32 as i64 as u64)
    mov64 r2, r7                                    r2 = r7
    mov64 r3, r8                                    r3 = r8
    call function_33100                     
    stxb [r10-0x680], r8                    
    stxdw [r10-0x688], r7                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -600                                  r1 += -600   ///  r1 = r1.wrapping_add(-600 as i32 as i64 as u64)
    call function_41956                     
    ldxdw r1, [r10-0x258]                   
    jne r1, 0, lbb_12383                            if r1 != (0 as i32 as i64 as u64) { pc += 71 }
    ldxdw r1, [r10-0x250]                   
    stxdw [r10-0xcb8], r1                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -736                                  r1 += -736   ///  r1 = r1.wrapping_add(-736 as i32 as i64 as u64)
    ldxdw r8, [r10-0xc10]                   
    mov64 r2, r8                                    r2 = r8
    call function_22586                     
    ldxb r7, [r10-0x2e0]                    
    jeq r7, 56, lbb_12322                           if r7 == (56 as i32 as i64 as u64) { pc += 1 }
    ja lbb_12524                                    if true { pc += 202 }
lbb_12322:
    mov64 r1, r10                                   r1 = r10
    add64 r1, -736                                  r1 += -736   ///  r1 = r1.wrapping_add(-736 as i32 as i64 as u64)
    mov64 r2, r9                                    r2 = r9
    call function_22586                     
    ldxb r7, [r10-0x2e0]                    
    jeq r7, 56, lbb_12329                           if r7 == (56 as i32 as i64 as u64) { pc += 1 }
    ja lbb_12524                                    if true { pc += 195 }
lbb_12329:
    stxdw [r10-0xcc0], r6                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -736                                  r1 += -736   ///  r1 = r1.wrapping_add(-736 as i32 as i64 as u64)
    mov64 r2, r8                                    r2 = r8
    ldxdw r6, [r10-0xcb8]                   
    mov64 r3, r6                                    r3 = r6
    call function_22757                     
    ldxb r7, [r10-0x2e0]                    
    jeq r7, 56, lbb_12339                           if r7 == (56 as i32 as i64 as u64) { pc += 1 }
    ja lbb_12524                                    if true { pc += 185 }
lbb_12339:
    mov64 r1, r10                                   r1 = r10
    add64 r1, -736                                  r1 += -736   ///  r1 = r1.wrapping_add(-736 as i32 as i64 as u64)
    mov64 r2, r9                                    r2 = r9
    mov64 r3, r6                                    r3 = r6
    call function_22757                     
    ldxb r7, [r10-0x2e0]                    
    jeq r7, 56, lbb_12347                           if r7 == (56 as i32 as i64 as u64) { pc += 1 }
    ja lbb_12524                                    if true { pc += 177 }
lbb_12347:
    mov64 r7, r10                                   r7 = r10
    add64 r7, -1552                                 r7 += -1552   ///  r7 = r7.wrapping_add(-1552 as i32 as i64 as u64)
    mov64 r6, 1                                     r6 = 1 as i32 as i64 as u64
    mov64 r1, r7                                    r1 = r7
    mov64 r2, r8                                    r2 = r8
    mov64 r3, 1                                     r3 = 1 as i32 as i64 as u64
    call function_23676                     
    mov64 r8, r10                                   r8 = r10
    add64 r8, -1536                                 r8 += -1536   ///  r8 = r8.wrapping_add(-1536 as i32 as i64 as u64)
    mov64 r2, r9                                    r2 = r9
    mov64 r9, 0                                     r9 = 0 as i32 as i64 as u64
    mov64 r1, r8                                    r1 = r8
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
    call function_23676                     
    mov64 r1, r10                                   r1 = r10
    add64 r1, -736                                  r1 += -736   ///  r1 = r1.wrapping_add(-736 as i32 as i64 as u64)
    mov64 r2, r7                                    r2 = r7
    mov64 r3, r8                                    r3 = r8
    call function_34119                     
    ldxw r1, [r10-0x2e0]                    
    jeq r1, 0, lbb_12393                            if r1 == (0 as i32 as i64 as u64) { pc += 25 }
    stxdw [r10-0x250], r6                   
    lddw r1, 0x1000649b8 --> b"\x00\x00\x00\x00[\xfa\x05\x00\x13\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00…        r1 load str located at 4295379384
    stxdw [r10-0x258], r1                   
    stxdw [r10-0x238], r9                   
    stxdw [r10-0x240], r9                   
    lddw r1, 0x10005fa70 --> b"src/arithmetic_impls.rsSubtraction overflowedsrc/d"        r1 load str located at 4295359088
    stxdw [r10-0x248], r1                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -600                                  r1 += -600   ///  r1 = r1.wrapping_add(-600 as i32 as i64 as u64)
    lddw r2, 0x1000649c8 --> b"\x00\x00\x00\x00p\xfa\x05\x00\x17\x00\x00\x00\x00\x00\x00\x00\xa1\x00\x00…        r2 load str located at 4295379400
    call function_44240                     
    syscall [invalid]                       
lbb_12383:
    ldxdw r1, [r10-0x250]                   
    ldxdw r2, [r10-0x248]                   
    ldxdw r3, [r10-0x240]                   
    ldxdw r4, [r10-0x238]                   
    ldxdw r5, [r10-0xc00]                   
    stxdw [r5+0x18], r4                     
    stxdw [r5+0x10], r3                     
    stxdw [r5+0x8], r2                      
    stxdw [r5+0x0], r1                      
    ja lbb_12535                                    if true { pc += 142 }
lbb_12393:
    ldxdw r1, [r10-0x2d4]                   
    stxdw [r10-0x130], r1                   
    ldxdw r1, [r10-0x2dc]                   
    stxdw [r10-0x138], r1                   
    lddw r1, 0x1000607bb --> b"\x8b\xbc\x13%\x8a\x81u\xd1\xc8\xf9\x18\xd1\x1du\xbb\x9d\xf3\xa2&\x0b\x8c\…        r1 load str located at 4295362491
    ldxdw r2, [r10-0xbc8]                   
    call function_30170                     
    ldxdw r6, [r10-0xcc0]                   
    jne r0, 0, lbb_12438                            if r0 != (0 as i32 as i64 as u64) { pc += 35 }
    ldxdw r1, [r10-0x148]                   
    stxdw [r10-0x300], r1                   
    ldxdw r1, [r10-0x150]                   
    ja lbb_12508                                    if true { pc += 101 }
lbb_12407:
    lddw r2, 0x300000000                            r2 load str located at 12884901888
    stxdw [r2+0x0], r1                      
    mov64 r2, 104                                   r2 = 104 as i32 as i64 as u64
    stxb [r1+0x18], r2                      
    lddw r2, 0x6374616d73696d20                     r2 load str located at 7166460029768920352
    stxdw [r1+0x10], r2                     
    lddw r2, 0x746e696d206e656b                     r2 load str located at 8389759073254270315
    stxdw [r1+0x8], r2                      
    lddw r2, 0x6f742065746f7551                     r2 load str located at 8031079655625684305
    stxdw [r1+0x0], r2                      
    mov64 r2, 25                                    r2 = 25 as i32 as i64 as u64
    ja lbb_11864                                    if true { pc += -559 }
lbb_12423:
    lddw r1, 0x300000000                            r1 load str located at 12884901888
    stxdw [r1+0x0], r6                      
    mov64 r7, 38                                    r7 = 38 as i32 as i64 as u64
    mov64 r1, r6                                    r1 = r6
    lddw r2, 0x100060719 --> b"Somehow cannot get current instruction"        r2 load str located at 4295362329
    mov64 r3, 38                                    r3 = 38 as i32 as i64 as u64
    call function_48190                     
    stxdw [r10-0x240], r7                   
    stxdw [r10-0x248], r7                   
    stxdw [r10-0x250], r6                   
lbb_12435:
    mov64 r1, 29                                    r1 = 29 as i32 as i64 as u64
lbb_12436:
    stxb [r10-0x258], r1                    
    ja lbb_12531                                    if true { pc += 93 }
lbb_12438:
    lddw r1, 0x100065288 --> b"\x00\x00\x00\x00h\xfd\x05\x00\x10\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00…        r1 load str located at 4295381640
    stxdw [r10-0x258], r1                   
    mov64 r1, 2                                     r1 = 2 as i32 as i64 as u64
    stxdw [r10-0x250], r1                   
    stxdw [r10-0x240], r1                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -736                                  r1 += -736   ///  r1 = r1.wrapping_add(-736 as i32 as i64 as u64)
    stxdw [r10-0x248], r1                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -312                                  r1 += -312   ///  r1 = r1.wrapping_add(-312 as i32 as i64 as u64)
    stxdw [r10-0x2d0], r1                   
    lddw r1, 0x100042518 --> b"\x85\x10\x00\x00~\xff\xff\xff\x95\x00\x00\x00\x00\x00\x00\x00\xbf#\x00\x0…        r1 load str located at 4295238936
    stxdw [r10-0x2c8], r1                   
    stxdw [r10-0x2d8], r1                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -336                                  r1 += -336   ///  r1 = r1.wrapping_add(-336 as i32 as i64 as u64)
    stxdw [r10-0x2e0], r1                   
    mov64 r8, 0                                     r8 = 0 as i32 as i64 as u64
    stxdw [r10-0x238], r8                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -424                                  r1 += -424   ///  r1 = r1.wrapping_add(-424 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -600                                  r2 += -600   ///  r2 = r2.wrapping_add(-600 as i32 as i64 as u64)
    call function_43415                     
    ldxdw r1, [r10-0x1a8]                   
    ldxdw r2, [r10-0x198]                   
    syscall [invalid]                       
    mov64 r9, 1                                     r9 = 1 as i32 as i64 as u64
    stxdw [r10-0xff8], r9                   
    stxdw [r10-0x1000], r8                  
    mov64 r7, r10                                   r7 = r10
    add64 r7, -464                                  r7 += -464   ///  r7 = r7.wrapping_add(-464 as i32 as i64 as u64)
    mov64 r5, r10                                   r5 = r10
    mov64 r1, r7                                    r1 = r7
    mov64 r2, 10                                    r2 = 10 as i32 as i64 as u64
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
    mov64 r4, 0                                     r4 = 0 as i32 as i64 as u64
    call function_33183                     
    ldxdw r1, [r10-0x130]                   
    stxdw [r10-0x1a0], r1                   
    ldxdw r1, [r10-0x138]                   
    stxdw [r10-0x1a8], r1                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -736                                  r1 += -736   ///  r1 = r1.wrapping_add(-736 as i32 as i64 as u64)
    mov64 r3, r10                                   r3 = r10
    add64 r3, -424                                  r3 += -424   ///  r3 = r3.wrapping_add(-424 as i32 as i64 as u64)
    mov64 r2, r7                                    r2 = r7
    call function_34122                     
    ldxw r1, [r10-0x2e0]                    
    jeq r1, 0, lbb_12505                            if r1 == (0 as i32 as i64 as u64) { pc += 15 }
    stxdw [r10-0x250], r9                   
    lddw r1, 0x1000649e0 --> b"\x00\x00\x00\x00\x87\xfa\x05\x00\x16\x00\x00\x00\x00\x00\x00\x00\x00\x00\…        r1 load str located at 4295379424
    stxdw [r10-0x258], r1                   
    stxdw [r10-0x238], r8                   
    stxdw [r10-0x240], r8                   
    lddw r1, 0x10005fa70 --> b"src/arithmetic_impls.rsSubtraction overflowedsrc/d"        r1 load str located at 4295359088
    stxdw [r10-0x248], r1                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -600                                  r1 += -600   ///  r1 = r1.wrapping_add(-600 as i32 as i64 as u64)
    lddw r2, 0x1000649f0 --> b"\x00\x00\x00\x00p\xfa\x05\x00\x17\x00\x00\x00\x00\x00\x00\x00\x03\x01\x00…        r2 load str located at 4295379440
    call function_44240                     
    syscall [invalid]                       
lbb_12505:
    ldxdw r1, [r10-0x2d4]                   
    stxdw [r10-0x300], r1                   
    ldxdw r1, [r10-0x2dc]                   
lbb_12508:
    stxdw [r10-0x308], r1                   
    ldxdw r8, [r10-0xc10]                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -736                                  r1 += -736   ///  r1 = r1.wrapping_add(-736 as i32 as i64 as u64)
    mov64 r2, r8                                    r2 = r8
    call function_22586                     
    ldxb r7, [r10-0x2e0]                    
    ldxdw r1, [r10-0xc48]                   
    jne r7, 56, lbb_12524                           if r7 != (56 as i32 as i64 as u64) { pc += 7 }
    mov64 r1, r10                                   r1 = r10
    add64 r1, -736                                  r1 += -736   ///  r1 = r1.wrapping_add(-736 as i32 as i64 as u64)
    ldxdw r9, [r10-0xbd8]                   
    mov64 r2, r9                                    r2 = r9
    call function_22586                     
    ldxb r7, [r10-0x2e0]                    
    jeq r7, 56, lbb_12554                           if r7 == (56 as i32 as i64 as u64) { pc += 30 }
lbb_12524:
    mov64 r1, r10                                   r1 = r10
    add64 r1, -599                                  r1 += -599   ///  r1 = r1.wrapping_add(-599 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -735                                  r2 += -735   ///  r2 = r2.wrapping_add(-735 as i32 as i64 as u64)
    mov64 r3, 71                                    r3 = 71 as i32 as i64 as u64
    call function_48190                     
    stxb [r10-0x258], r7                    
lbb_12531:
    mov64 r2, r10                                   r2 = r10
    add64 r2, -600                                  r2 += -600   ///  r2 = r2.wrapping_add(-600 as i32 as i64 as u64)
    ldxdw r1, [r10-0xc00]                   
    call function_26067                     
lbb_12535:
    ldxdw r2, [r10-0xc18]                   
    ldxdw r3, [r10-0xc08]                   
    ldxdw r4, [r10-0xc28]                   
    ldxdw r5, [r10-0xc40]                   
    ldxdw r7, [r10-0xc20]                   
lbb_12540:
    ldxdw r0, [r10-0xbf8]                   
    ldxdw r1, [r0+0x0]                      
    add64 r1, 1                                     r1 += 1   ///  r1 = r1.wrapping_add(1 as i32 as i64 as u64)
    stxdw [r0+0x0], r1                      
    ldxdw r1, [r7+0x0]                      
    add64 r1, 1                                     r1 += 1   ///  r1 = r1.wrapping_add(1 as i32 as i64 as u64)
    stxdw [r7+0x0], r1                      
lbb_12547:
    ldxdw r1, [r4+0x0]                      
    add64 r1, -1                                    r1 += -1   ///  r1 = r1.wrapping_add(-1 as i32 as i64 as u64)
    stxdw [r4+0x0], r1                      
    ldxdw r1, [r5+0x0]                      
    add64 r1, -1                                    r1 += -1   ///  r1 = r1.wrapping_add(-1 as i32 as i64 as u64)
    stxdw [r5+0x0], r1                      
    ja lbb_11579                                    if true { pc += -975 }
lbb_12554:
    ldxdw r1, [r10-0x300]                   
    stxdw [r10-0x24c], r1                   
    ldxdw r1, [r10-0x308]                   
    stxdw [r10-0x254], r1                   
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    stxw [r10-0x258], r1                    
    ldxdw r1, [r10-0xcb8]                   
    stxdw [r10-0xfe8], r1                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -600                                  r1 += -600   ///  r1 = r1.wrapping_add(-600 as i32 as i64 as u64)
    stxdw [r10-0xfe0], r1                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -1688                                 r1 += -1688   ///  r1 = r1.wrapping_add(-1688 as i32 as i64 as u64)
    stxdw [r10-0xff0], r1                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -1824                                 r1 += -1824   ///  r1 = r1.wrapping_add(-1824 as i32 as i64 as u64)
    stxdw [r10-0xff8], r1                   
    ldxdw r1, [r10-0xbf0]                   
    stxdw [r10-0x1000], r1                  
    mov64 r1, r10                                   r1 = r10
    add64 r1, -736                                  r1 += -736   ///  r1 = r1.wrapping_add(-736 as i32 as i64 as u64)
    mov64 r5, r10                                   r5 = r10
    mov64 r2, r8                                    r2 = r8
    mov64 r3, r9                                    r3 = r9
    ldxdw r4, [r10-0xc48]                   
    call function_27980                     
    ldxb r1, [r10-0x2e0]                    
    jeq r1, 56, lbb_12583                           if r1 == (56 as i32 as i64 as u64) { pc += 1 }
    ja lbb_13168                                    if true { pc += 585 }
lbb_12583:
    ldxdw r1, [r10-0x2b8]                   
    stxdw [r10-0x438], r1                   
    ldxdw r1, [r10-0x2b0]                   
    stxdw [r10-0x430], r1                   
    ldxdw r9, [r10-0x2c0]                   
    ldxdw r1, [r10-0x2c8]                   
    stxdw [r10-0xbc8], r1                   
    ldxdw r1, [r10-0x2d0]                   
    stxdw [r10-0xc10], r1                   
    ldxdw r1, [r10-0x2d8]                   
    stxdw [r10-0xcb8], r1                   
    ldxb r1, [r10-0x2a8]                    
    stxdw [r10-0xcc8], r1                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -736                                  r1 += -736   ///  r1 = r1.wrapping_add(-736 as i32 as i64 as u64)
    mov64 r3, r10                                   r3 = r10
    add64 r3, -1080                                 r3 += -1080   ///  r3 = r3.wrapping_add(-1080 as i32 as i64 as u64)
    mov64 r2, r8                                    r2 = r8
    mov64 r4, 1                                     r4 = 1 as i32 as i64 as u64
    call function_23213                     
    ldxb r7, [r10-0x2e0]                    
    jeq r7, 56, lbb_12606                           if r7 == (56 as i32 as i64 as u64) { pc += 1 }
    ja lbb_12524                                    if true { pc += -82 }
lbb_12606:
    ldxdw r1, [r10-0x718]                   
    stxdw [r10-0x250], r1                   
    ldxdw r1, [r10-0x720]                   
    stxdw [r10-0x258], r1                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -736                                  r1 += -736   ///  r1 = r1.wrapping_add(-736 as i32 as i64 as u64)
    mov64 r3, r10                                   r3 = r10
    add64 r3, -600                                  r3 += -600   ///  r3 = r3.wrapping_add(-600 as i32 as i64 as u64)
    ldxdw r2, [r10-0xbd8]                   
    mov64 r4, 0                                     r4 = 0 as i32 as i64 as u64
    call function_23213                     
    ldxb r7, [r10-0x2e0]                    
    jeq r7, 56, lbb_12620                           if r7 == (56 as i32 as i64 as u64) { pc += 1 }
    ja lbb_12524                                    if true { pc += -96 }
lbb_12620:
    mov64 r1, r10                                   r1 = r10
    add64 r1, -736                                  r1 += -736   ///  r1 = r1.wrapping_add(-736 as i32 as i64 as u64)
    mov64 r2, r8                                    r2 = r8
    call function_22586                     
    ldxb r7, [r10-0x2e0]                    
    jeq r7, 56, lbb_12627                           if r7 == (56 as i32 as i64 as u64) { pc += 1 }
    ja lbb_12524                                    if true { pc += -103 }
lbb_12627:
    mov64 r1, r10                                   r1 = r10
    add64 r1, -736                                  r1 += -736   ///  r1 = r1.wrapping_add(-736 as i32 as i64 as u64)
    ldxdw r2, [r10-0xbd8]                   
    call function_22586                     
    ldxb r7, [r10-0x2e0]                    
    jeq r7, 56, lbb_12634                           if r7 == (56 as i32 as i64 as u64) { pc += 1 }
    ja lbb_12524                                    if true { pc += -110 }
lbb_12634:
    stxdw [r10-0xbd8], r9                   
    ldxdw r1, [r10-0x148]                   
    stxdw [r10-0x1c8], r1                   
    ldxdw r1, [r10-0x150]                   
    stxdw [r10-0x1d0], r1                   
    ldxdw r1, [r10-0x130]                   
    stxdw [r10-0x1a0], r1                   
    ldxdw r1, [r10-0x138]                   
    stxdw [r10-0x1a8], r1                   
    ldxdw r1, [r10-0x718]                   
    stxdw [r10-0x2d8], r1                   
    ldxdw r1, [r10-0x720]                   
    stxdw [r10-0x2e0], r1                   
    ldxdw r1, [r10-0xbf0]                   
    ldxdw r2, [r1+0x0]                      
    stxdw [r10-0xc20], r2                   
    ldxdw r2, [r1+0x10]                     
    stxdw [r10-0xbf8], r2                   
    ldxdw r8, [r1+0x8]                      
    ldxdw r1, [r10-0xc48]                   
    ldxdw r9, [r1+0x0]                      
    ldxdw r2, [r1+0x10]                     
    stxdw [r10-0xcd0], r2                   
    ldxdw r7, [r1+0x8]                      
    ldxdw r1, [r10-0x710]                   
    stxdw [r10-0xbf0], r1                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -600                                  r1 += -600   ///  r1 = r1.wrapping_add(-600 as i32 as i64 as u64)
    call function_41956                     
    ldxdw r1, [r10-0x258]                   
    jeq r1, 0, lbb_12702                            if r1 == (0 as i32 as i64 as u64) { pc += 37 }
    ldxdw r1, [r10-0x250]                   
    ldxdw r2, [r10-0x248]                   
    ldxdw r3, [r10-0x240]                   
    ldxdw r4, [r10-0x238]                   
    ldxdw r5, [r10-0xc00]                   
    stxdw [r5+0x18], r4                     
    stxdw [r5+0x10], r3                     
    stxdw [r5+0x8], r2                      
    stxdw [r5+0x0], r1                      
lbb_12674:
    ldxdw r7, [r10-0x890]                   
    ldxdw r1, [r10-0x960]                   
    stxdw [r10-0xbf8], r1                   
    ja lbb_12095                                    if true { pc += -583 }
lbb_12678:
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    stxdw [r10-0x2c0], r1                   
    lddw r1, 0x1000652d8 --> b"\x00\x00\x00\x00E\x08\x06\x00&\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x0…        r1 load str located at 4295381720
    stxdw [r10-0x2e0], r1                   
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    stxdw [r10-0x2d8], r1                   
    stxdw [r10-0x2c8], r1                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -1688                                 r1 += -1688   ///  r1 = r1.wrapping_add(-1688 as i32 as i64 as u64)
    stxdw [r10-0x2d0], r1                   
    lddw r1, 0x10005df58 --> b"\xbf#\x00\x00\x00\x00\x00\x00y\x11\x00\x00\x00\x00\x00\x00\xb7\x02\x00\x0…        r1 load str located at 4295352152
    stxdw [r10-0x690], r1                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -1824                                 r1 += -1824   ///  r1 = r1.wrapping_add(-1824 as i32 as i64 as u64)
    stxdw [r10-0x698], r1                   
    stxdw [r10-0x720], r2                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -592                                  r1 += -592   ///  r1 = r1.wrapping_add(-592 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -736                                  r2 += -736   ///  r2 = r2.wrapping_add(-736 as i32 as i64 as u64)
    call function_445                       
    ja lbb_11867                                    if true { pc += -835 }
lbb_12702:
    mov64 r2, r10                                   r2 = r10
    add64 r2, -2168                                 r2 += -2168   ///  r2 = r2.wrapping_add(-2168 as i32 as i64 as u64)
    mov64 r1, r10                                   r1 = r10
    add64 r1, -2376                                 r1 += -2376   ///  r1 = r1.wrapping_add(-2376 as i32 as i64 as u64)
    ldxdw r3, [r10-0x230]                   
    ldxdw r5, [r10-0xc88]                   
    ldxdw r4, [r5+0x0]                      
    stxdw [r10-0x540], r4                   
    ldxdw r4, [r5+0x8]                      
    stxdw [r10-0x538], r4                   
    ldxdw r4, [r5+0x10]                     
    stxdw [r10-0x530], r4                   
    ldxdw r4, [r5+0x18]                     
    stxdw [r10-0x528], r4                   
    ldxdw r4, [r10-0x990]                   
    ldxdw r4, [r4+0x0]                      
    ldxdw r5, [r4+0x18]                     
    stxdw [r10-0x498], r5                   
    ldxdw r5, [r4+0x10]                     
    stxdw [r10-0x4a0], r5                   
    ldxdw r5, [r4+0x8]                      
    stxdw [r10-0x4a8], r5                   
    ldxdw r4, [r4+0x0]                      
    stxdw [r10-0x4b0], r4                   
    stxdw [r10-0x598], r3                   
    ldxdw r3, [r10-0xcb8]                   
    stxdw [r10-0x5b0], r3                   
    ldxdw r3, [r10-0xc10]                   
    stxdw [r10-0x5a8], r3                   
    ldxdw r3, [r10-0xbc8]                   
    stxdw [r10-0x5a0], r3                   
    stxdw [r10-0x590], r8                   
    stxdw [r10-0x588], r7                   
    ldxdw r3, [r10-0xc20]                   
    stxdw [r10-0x580], r3                   
    stxdw [r10-0x578], r9                   
    ldxdw r3, [r10-0xbf8]                   
    stxdw [r10-0x570], r3                   
    ldxdw r3, [r10-0xcd0]                   
    stxdw [r10-0x568], r3                   
    ldxdw r3, [r10-0xc60]                   
    stxb [r10-0x46b], r3                    
    ldxdw r3, [r10-0x450]                   
    stxdw [r10-0x473], r3                   
    ldxdw r3, [r10-0x458]                   
    stxdw [r10-0x47b], r3                   
    ldxdw r3, [r10-0x460]                   
    stxdw [r10-0x483], r3                   
    ldxdw r3, [r10-0x468]                   
    stxdw [r10-0x48b], r3                   
    ldxdw r3, [r10-0xc68]                   
    stxw [r10-0x5b8], r3                    
    stxw [r10-0x490], r3                    
    ldxdw r3, [r10-0xc30]                   
    stxdw [r10-0x5f0], r3                   
    ldxdw r3, [r10-0xc80]                   
    stxdw [r10-0x5e8], r3                   
    ldxdw r3, [r10-0xcb0]                   
    stxdw [r10-0x5d8], r3                   
    ldxdw r3, [r10-0xca8]                   
    stxdw [r10-0x5d0], r3                   
    ldxdw r3, [r10-0xca0]                   
    stxdw [r10-0x5c8], r3                   
    ldxdw r3, [r10-0xc50]                   
    stxdw [r10-0x5c0], r3                   
    ldxdw r3, [r10-0xc90]                   
    stxw [r10-0x5b4], r3                    
    ldxdw r3, [r10-0xc98]                   
    stxw [r10-0x5dc], r3                    
    ldxdw r3, [r10-0xc78]                   
    stxw [r10-0x5e0], r3                    
    ldxdw r3, [r10-0x1d0]                   
    stxdw [r10-0x560], r3                   
    ldxdw r3, [r10-0x1c8]                   
    stxdw [r10-0x558], r3                   
    ldxdw r3, [r10-0x1a0]                   
    stxdw [r10-0x548], r3                   
    ldxdw r3, [r10-0x1a8]                   
    stxdw [r10-0x550], r3                   
    ldxdw r3, [r2+0x18]                     
    stxdw [r10-0x508], r3                   
    ldxdw r3, [r2+0x10]                     
    stxdw [r10-0x510], r3                   
    ldxdw r3, [r2+0x8]                      
    stxdw [r10-0x518], r3                   
    ldxdw r2, [r2+0x0]                      
    stxdw [r10-0x520], r2                   
    ldxdw r2, [r1+0x18]                     
    stxdw [r10-0x4e8], r2                   
    ldxdw r2, [r1+0x10]                     
    stxdw [r10-0x4f0], r2                   
    ldxdw r2, [r1+0x8]                      
    stxdw [r10-0x4f8], r2                   
    ldxdw r1, [r1+0x0]                      
    stxdw [r10-0x500], r1                   
    ldxdw r1, [r10-0x2d8]                   
    stxdw [r10-0x4d8], r1                   
    ldxdw r1, [r10-0x2e0]                   
    stxdw [r10-0x4e0], r1                   
    ldxdw r1, [r10-0xbf0]                   
    stxdw [r10-0x4d0], r1                   
    ldxdw r1, [r10-0x430]                   
    stxdw [r10-0x4c0], r1                   
    ldxdw r1, [r10-0x438]                   
    stxdw [r10-0x4c8], r1                   
    ldxdw r1, [r10-0xc58]                   
    stxb [r10-0x48c], r1                    
    ldxdw r8, [r10-0xbd8]                   
    stxdw [r10-0x4b8], r8                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -1520                                 r1 += -1520   ///  r1 = r1.wrapping_add(-1520 as i32 as i64 as u64)
    call function_2130                      
    ldxdw r2, [r10-0xc38]                   
    ldxdw r1, [r2+0x0]                      
    stxdw [r10-0xbc0], r1                   
    ldxdw r1, [r2+0x8]                      
    stxdw [r10-0xbb8], r1                   
    ldxdw r1, [r2+0x10]                     
    stxdw [r10-0xbb0], r1                   
    ldxdw r1, [r2+0x18]                     
    stxdw [r10-0xba8], r1                   
    ldxdw r1, [r10-0xbd0]                   
    ldxdw r1, [r1+0x8]                      
    ldxdw r2, [r10-0x968]                   
    ldxb r3, [r2+0x418]                     
    ldxdw r2, [r10-0x990]                   
    stxdw [r10-0xbd0], r2                   
    ldxdw r2, [r10-0x980]                   
    stxdw [r10-0xbf0], r2                   
    ldxdw r4, [r10-0x988]                   
    ldxdw r2, [r10-0x970]                   
    stxdw [r10-0xbc8], r2                   
    ldxdw r5, [r10-0x978]                   
    mov64 r2, 17                                    r2 = 17 as i32 as i64 as u64
    stxdw [r10-0x1c8], r2                   
    lddw r2, 0x10006080c --> b"not enough tokensExhausted available liquidity in "        r2 load str located at 4295362572
    stxdw [r10-0x1d0], r2                   
    jge r8, r1, lbb_12844                           if r8 >= r1 { pc += 3 }
    lddw r1, 0x1000652a8 --> b"\x00\x00\x00\x00\xf0\xfe\x05\x00 \x00\x00\x00\x00\x00\x00\x00\x82\x01\x00…        r1 load str located at 4295381672
    ja lbb_12854                                    if true { pc += 10 }
lbb_12844:
    ldxdw r2, [r10-0xcc8]                   
    and64 r2, 1                                     r2 &= 1   ///  r2 = r2.and(1)
    mov64 r1, 40                                    r1 = 40 as i32 as i64 as u64
    stxdw [r10-0x1c8], r1                   
    lddw r1, 0x10006081d --> b"Exhausted available liquidity in the dexExpected 0"        r1 load str located at 4295362589
    stxdw [r10-0x1d0], r1                   
    jeq r2, 0, lbb_12894                            if r2 == (0 as i32 as i64 as u64) { pc += 42 }
    lddw r1, 0x1000652c0 --> b"\x00\x00\x00\x00\xf0\xfe\x05\x00 \x00\x00\x00\x00\x00\x00\x00\x8a\x01\x00…        r1 load str located at 4295381696
lbb_12854:
    stxdw [r10-0x140], r1                   
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    stxdw [r10-0x238], r1                   
    lddw r1, 0x100064c98 --> b"\x00\x00\x00\x00p\xfa\x05\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00…        r1 load str located at 4295380120
    stxdw [r10-0x258], r1                   
    mov64 r1, 2                                     r1 = 2 as i32 as i64 as u64
    stxdw [r10-0x250], r1                   
    stxdw [r10-0x240], r1                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -736                                  r1 += -736   ///  r1 = r1.wrapping_add(-736 as i32 as i64 as u64)
    stxdw [r10-0x248], r1                   
    lddw r1, 0x100000888 --> b"y\x11\x00\x00\x00\x00\x00\x00\x85\x10\x00\x00]\xab\x00\x00\x95\x00\x00\x0…        r1 load str located at 4294969480
    stxdw [r10-0x2c8], r1                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -320                                  r1 += -320   ///  r1 = r1.wrapping_add(-320 as i32 as i64 as u64)
    stxdw [r10-0x2d0], r1                   
    lddw r1, 0x100000860 --> b"\xbf#\x00\x00\x00\x00\x00\x00y\x12\x08\x00\x00\x00\x00\x00y\x11\x00\x00\x…        r1 load str located at 4294969440
    stxdw [r10-0x2d8], r1                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -464                                  r1 += -464   ///  r1 = r1.wrapping_add(-464 as i32 as i64 as u64)
    stxdw [r10-0x2e0], r1                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -424                                  r1 += -424   ///  r1 = r1.wrapping_add(-424 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -600                                  r2 += -600   ///  r2 = r2.wrapping_add(-600 as i32 as i64 as u64)
    call function_43415                     
    ldxdw r1, [r10-0x1a8]                   
    ldxdw r2, [r10-0x198]                   
    syscall [invalid]                       
    stxdw [r10-0x250], r8                   
    mov64 r1, 54                                    r1 = 54 as i32 as i64 as u64
    stxb [r10-0x258], r1                    
    mov64 r2, r10                                   r2 = r10
    add64 r2, -600                                  r2 += -600   ///  r2 = r2.wrapping_add(-600 as i32 as i64 as u64)
    ldxdw r1, [r10-0xc00]                   
    call function_26067                     
    ja lbb_12674                                    if true { pc += -220 }
lbb_12894:
    stxdw [r10-0xbf8], r3                   
    ldxdw r1, [r10-0x960]                   
    ldxdw r2, [r1+0x0]                      
    add64 r2, 1                                     r2 += 1   ///  r2 = r2.wrapping_add(1 as i32 as i64 as u64)
    ldxdw r3, [r10-0x890]                   
    stxdw [r1+0x0], r2                      
    ldxdw r1, [r3+0x0]                      
    add64 r1, 1                                     r1 += 1   ///  r1 = r1.wrapping_add(1 as i32 as i64 as u64)
    stxdw [r3+0x0], r1                      
    ldxdw r2, [r10-0xc28]                   
    ldxdw r1, [r2+0x0]                      
    add64 r1, -1                                    r1 += -1   ///  r1 = r1.wrapping_add(-1 as i32 as i64 as u64)
    stxdw [r2+0x0], r1                      
    ldxdw r2, [r10-0xc40]                   
    ldxdw r1, [r2+0x0]                      
    add64 r1, -1                                    r1 += -1   ///  r1 = r1.wrapping_add(-1 as i32 as i64 as u64)
    stxdw [r2+0x0], r1                      
    ldxdw r2, [r10-0xc08]                   
    ldxdw r1, [r2+0x0]                      
    add64 r1, -1                                    r1 += -1   ///  r1 = r1.wrapping_add(-1 as i32 as i64 as u64)
    stxdw [r2+0x0], r1                      
    ldxdw r2, [r10-0xc18]                   
    ldxdw r1, [r2+0x0]                      
    add64 r1, -1                                    r1 += -1   ///  r1 = r1.wrapping_add(-1 as i32 as i64 as u64)
    stxdw [r2+0x0], r1                      
    stxdw [r10-0xc10], r4                   
    ldxdw r4, [r4+0x0]                      
    ldxdw r1, [r10-0xbe8]                   
    ldxdw r3, [r1+0x0]                      
    stxdw [r10-0xc08], r5                   
    ldxdw r2, [r5+0x0]                      
    ldxdw r1, [r10-0xbe0]                   
    ldxdw r1, [r1+0x0]                      
    mov64 r7, 0                                     r7 = 0 as i32 as i64 as u64
    stxdw [r10-0xff0], r7                   
    stxdw [r10-0xfe8], r8                   
    lddw r8, 0x10005fa70 --> b"src/arithmetic_impls.rsSubtraction overflowedsrc/d"        r8 load str located at 4295359088
    stxdw [r10-0xff8], r8                   
    stxdw [r10-0x1000], r1                  
    mov64 r1, r10                                   r1 = r10
    add64 r1, -2408                                 r1 += -2408   ///  r1 = r1.wrapping_add(-2408 as i32 as i64 as u64)
    mov64 r5, r10                                   r5 = r10
    call function_32068                     
    ldxdw r9, [r10-0x968]                   
    jeq r9, 0, lbb_13145                            if r9 == (0 as i32 as i64 as u64) { pc += 205 }
    ldxdw r1, [r10-0x948]                   
    stxdw [r10-0xb88], r1                   
    ldxdw r1, [r10-0x950]                   
    stxdw [r10-0xb90], r1                   
    ldxdw r1, [r10-0x958]                   
    stxdw [r10-0xb98], r1                   
    ldxdw r1, [r10-0x960]                   
    stxdw [r10-0xba0], r1                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -560                                  r1 += -560   ///  r1 = r1.wrapping_add(-560 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -2368                                 r2 += -2368   ///  r2 = r2.wrapping_add(-2368 as i32 as i64 as u64)
    mov64 r3, 40                                    r3 = 40 as i32 as i64 as u64
    call function_48190                     
    stxdw [r10-0x258], r9                   
    ldxdw r1, [r10-0xba0]                   
    stxdw [r10-0x250], r1                   
    ldxdw r1, [r10-0xb98]                   
    stxdw [r10-0x248], r1                   
    ldxdw r1, [r10-0xb90]                   
    stxdw [r10-0x240], r1                   
    ldxdw r1, [r10-0xb88]                   
    stxdw [r10-0x238], r1                   
    ldxdw r1, [r10-0xc70]                   
    ldxdw r4, [r1+0x0]                      
    ldxdw r1, [r10-0xbf0]                   
    ldxdw r3, [r1+0x0]                      
    ldxdw r1, [r10-0xbc8]                   
    ldxdw r2, [r1+0x0]                      
    ldxdw r1, [r10-0xbd0]                   
    ldxdw r1, [r1+0x0]                      
    stxdw [r10-0xff0], r7                   
    stxdw [r10-0xfe8], r6                   
    stxdw [r10-0xff8], r8                   
    stxdw [r10-0x1000], r1                  
    mov64 r1, r10                                   r1 = r10
    add64 r1, -2408                                 r1 += -2408   ///  r1 = r1.wrapping_add(-2408 as i32 as i64 as u64)
    mov64 r5, r10                                   r5 = r10
    call function_32068                     
    ldxdw r6, [r10-0x968]                   
    jeq r6, 0, lbb_13200                            if r6 == (0 as i32 as i64 as u64) { pc += 219 }
    ldxdw r1, [r10-0x948]                   
    stxdw [r10-0x2c8], r1                   
    ldxdw r1, [r10-0x950]                   
    stxdw [r10-0x2d0], r1                   
    ldxdw r1, [r10-0x958]                   
    stxdw [r10-0x2d8], r1                   
    ldxdw r1, [r10-0x960]                   
    stxdw [r10-0x2e0], r1                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -2936                                 r1 += -2936   ///  r1 = r1.wrapping_add(-2936 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -2368                                 r2 += -2368   ///  r2 = r2.wrapping_add(-2368 as i32 as i64 as u64)
    mov64 r3, 40                                    r3 = 40 as i32 as i64 as u64
    call function_48190                     
    stxdw [r10-0xba0], r6                   
    ldxdw r1, [r10-0x2e0]                   
    stxdw [r10-0xb98], r1                   
    ldxdw r1, [r10-0x2d8]                   
    stxdw [r10-0xb90], r1                   
    ldxdw r1, [r10-0x2d0]                   
    stxdw [r10-0xb88], r1                   
    ldxdw r1, [r10-0x2c8]                   
    stxdw [r10-0xb80], r1                   
    mov64 r6, r10                                   r6 = r10
    add64 r6, -1128                                 r6 += -1128   ///  r6 = r6.wrapping_add(-1128 as i32 as i64 as u64)
    mov64 r1, r6                                    r1 = r6
    ldxdw r2, [r10-0xbe8]                   
    call function_1035                      
    mov64 r7, r10                                   r7 = r10
    add64 r7, -1824                                 r7 += -1824   ///  r7 = r7.wrapping_add(-1824 as i32 as i64 as u64)
    mov64 r1, r7                                    r1 = r7
    ldxdw r2, [r10-0xc10]                   
    call function_1035                      
    mov64 r9, r10                                   r9 = r10
    add64 r9, -1688                                 r9 += -1688   ///  r9 = r9.wrapping_add(-1688 as i32 as i64 as u64)
    mov64 r1, r9                                    r1 = r9
    ldxdw r2, [r10-0xbe0]                   
    call function_1035                      
    mov64 r8, r10                                   r8 = r10
    add64 r8, -736                                  r8 += -736   ///  r8 = r8.wrapping_add(-736 as i32 as i64 as u64)
    mov64 r1, r8                                    r1 = r8
    ldxdw r2, [r10-0xc08]                   
    call function_1035                      
    mov64 r1, r10                                   r1 = r10
    add64 r1, -2408                                 r1 += -2408   ///  r1 = r1.wrapping_add(-2408 as i32 as i64 as u64)
    stxdw [r10-0xbd8], r1                   
    mov64 r2, r6                                    r2 = r6
    mov64 r3, 48                                    r3 = 48 as i32 as i64 as u64
    call function_48190                     
    mov64 r1, r10                                   r1 = r10
    add64 r1, -2360                                 r1 += -2360   ///  r1 = r1.wrapping_add(-2360 as i32 as i64 as u64)
    mov64 r2, r7                                    r2 = r7
    mov64 r3, 48                                    r3 = 48 as i32 as i64 as u64
    call function_48190                     
    mov64 r1, r10                                   r1 = r10
    add64 r1, -2312                                 r1 += -2312   ///  r1 = r1.wrapping_add(-2312 as i32 as i64 as u64)
    mov64 r2, r9                                    r2 = r9
    mov64 r3, 48                                    r3 = 48 as i32 as i64 as u64
    call function_48190                     
    mov64 r1, r10                                   r1 = r10
    add64 r1, -2264                                 r1 += -2264   ///  r1 = r1.wrapping_add(-2264 as i32 as i64 as u64)
    mov64 r2, r8                                    r2 = r8
    mov64 r3, 48                                    r3 = 48 as i32 as i64 as u64
    call function_48190                     
    mov64 r1, r10                                   r1 = r10
    add64 r1, -736                                  r1 += -736   ///  r1 = r1.wrapping_add(-736 as i32 as i64 as u64)
    stxdw [r10-0x698], r1                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -1824                                 r1 += -1824   ///  r1 = r1.wrapping_add(-1824 as i32 as i64 as u64)
    stxdw [r10-0x2b0], r1                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -3008                                 r1 += -3008   ///  r1 = r1.wrapping_add(-3008 as i32 as i64 as u64)
    stxdw [r10-0x2c0], r1                   
    mov64 r1, 32                                    r1 = 32 as i32 as i64 as u64
    stxdw [r10-0x2b8], r1                   
    stxdw [r10-0x2c8], r1                   
    ldxdw r1, [r10-0xc88]                   
    stxdw [r10-0x2d0], r1                   
    lddw r1, 0x10005fbb0 --> b"coin\x1c\x00\x00\x00GoodKindkindbids != Some <= x1e-true to No"        r1 load str located at 4295359408
    stxdw [r10-0x2e0], r1                   
    ldxdw r1, [r10-0xbf8]                   
    stxb [r10-0x720], r1                    
    mov64 r1, 4                                     r1 = 4 as i32 as i64 as u64
    stxdw [r10-0x690], r1                   
    mov64 r2, 1                                     r2 = 1 as i32 as i64 as u64
    stxdw [r10-0x2a8], r2                   
    stxdw [r10-0x2d8], r1                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -1688                                 r1 += -1688   ///  r1 = r1.wrapping_add(-1688 as i32 as i64 as u64)
    stxdw [r10-0x1000], r1                  
    stxdw [r10-0xff8], r2                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -424                                  r1 += -424   ///  r1 = r1.wrapping_add(-424 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -600                                  r2 += -600   ///  r2 = r2.wrapping_add(-600 as i32 as i64 as u64)
    mov64 r5, r10                                   r5 = r10
    ldxdw r3, [r10-0xbd8]                   
    mov64 r4, 4                                     r4 = 4 as i32 as i64 as u64
    call function_40377                     
    ldxw r1, [r10-0x1a8]                    
    jeq r1, 24, lbb_13084                           if r1 == (24 as i32 as i64 as u64) { pc += 1 }
    ja lbb_13154                                    if true { pc += 70 }
lbb_13084:
    mov64 r1, r10                                   r1 = r10
    add64 r1, -2408                                 r1 += -2408   ///  r1 = r1.wrapping_add(-2408 as i32 as i64 as u64)
    call function_369                       
    mov64 r6, r10                                   r6 = r10
    add64 r6, -1128                                 r6 += -1128   ///  r6 = r6.wrapping_add(-1128 as i32 as i64 as u64)
    mov64 r1, r6                                    r1 = r6
    ldxdw r2, [r10-0xbf0]                   
    call function_1035                      
    mov64 r9, r10                                   r9 = r10
    add64 r9, -1824                                 r9 += -1824   ///  r9 = r9.wrapping_add(-1824 as i32 as i64 as u64)
    mov64 r1, r9                                    r1 = r9
    ldxdw r2, [r10-0xc70]                   
    call function_1035                      
    mov64 r8, r10                                   r8 = r10
    add64 r8, -1688                                 r8 += -1688   ///  r8 = r8.wrapping_add(-1688 as i32 as i64 as u64)
    mov64 r1, r8                                    r1 = r8
    ldxdw r2, [r10-0xbd0]                   
    call function_1035                      
    mov64 r7, r10                                   r7 = r10
    add64 r7, -736                                  r7 += -736   ///  r7 = r7.wrapping_add(-736 as i32 as i64 as u64)
    mov64 r1, r7                                    r1 = r7
    ldxdw r2, [r10-0xbc8]                   
    call function_1035                      
    mov64 r1, r10                                   r1 = r10
    add64 r1, -2408                                 r1 += -2408   ///  r1 = r1.wrapping_add(-2408 as i32 as i64 as u64)
    stxdw [r10-0xbc8], r1                   
    mov64 r2, r6                                    r2 = r6
    mov64 r3, 48                                    r3 = 48 as i32 as i64 as u64
    call function_48190                     
    mov64 r1, r10                                   r1 = r10
    add64 r1, -2360                                 r1 += -2360   ///  r1 = r1.wrapping_add(-2360 as i32 as i64 as u64)
    mov64 r2, r9                                    r2 = r9
    mov64 r3, 48                                    r3 = 48 as i32 as i64 as u64
    call function_48190                     
    mov64 r1, r10                                   r1 = r10
    add64 r1, -2312                                 r1 += -2312   ///  r1 = r1.wrapping_add(-2312 as i32 as i64 as u64)
    mov64 r2, r8                                    r2 = r8
    mov64 r3, 48                                    r3 = 48 as i32 as i64 as u64
    call function_48190                     
    mov64 r1, r10                                   r1 = r10
    add64 r1, -2264                                 r1 += -2264   ///  r1 = r1.wrapping_add(-2264 as i32 as i64 as u64)
    mov64 r2, r7                                    r2 = r7
    mov64 r3, 48                                    r3 = 48 as i32 as i64 as u64
    call function_48190                     
    mov64 r1, r10                                   r1 = r10
    add64 r1, -424                                  r1 += -424   ///  r1 = r1.wrapping_add(-424 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -2976                                 r2 += -2976   ///  r2 = r2.wrapping_add(-2976 as i32 as i64 as u64)
    ldxdw r3, [r10-0xbc8]                   
    mov64 r4, 4                                     r4 = 4 as i32 as i64 as u64
    call function_40369                     
    ldxw r1, [r10-0x1a8]                    
    jeq r1, 24, lbb_13138                           if r1 == (24 as i32 as i64 as u64) { pc += 1 }
    ja lbb_13154                                    if true { pc += 16 }
lbb_13138:
    mov64 r1, r10                                   r1 = r10
    add64 r1, -2408                                 r1 += -2408   ///  r1 = r1.wrapping_add(-2408 as i32 as i64 as u64)
    call function_369                       
    mov64 r1, 24                                    r1 = 24 as i32 as i64 as u64
    ldxdw r2, [r10-0xc00]                   
    stxw [r2+0x0], r1                       
    ja lbb_11585                                    if true { pc += -1560 }
lbb_13145:
    ldxdw r1, [r10-0x948]                   
    stxdw [r10-0xb88], r1                   
    ldxdw r2, [r10-0x950]                   
    stxdw [r10-0xb90], r2                   
    ldxdw r3, [r10-0x958]                   
    stxdw [r10-0xb98], r3                   
    ldxdw r4, [r10-0x960]                   
    stxdw [r10-0xba0], r4                   
    ja lbb_13208                                    if true { pc += 54 }
lbb_13154:
    ldxw r2, [r10-0x18c]                    
    ldxdw r3, [r10-0xc00]                   
    stxw [r3+0x1c], r2                      
    ldxdw r2, [r10-0x194]                   
    stxdw [r3+0x14], r2                     
    ldxdw r2, [r10-0x19c]                   
    stxdw [r3+0xc], r2                      
    ldxdw r2, [r10-0x1a4]                   
    stxdw [r3+0x4], r2                      
    stxw [r3+0x0], r1                       
    mov64 r1, r10                                   r1 = r10
    add64 r1, -2408                                 r1 += -2408   ///  r1 = r1.wrapping_add(-2408 as i32 as i64 as u64)
    call function_369                       
    ja lbb_11585                                    if true { pc += -1583 }
lbb_13168:
    ldxw r2, [r10-0x2dc]                    
    stxw [r10-0x254], r2                    
    ldxw r2, [r10-0x2df]                    
    stxw [r10-0x257], r2                    
    ldxdw r2, [r10-0x2b8]                   
    stxdw [r10-0x1a8], r2                   
    ldxdw r2, [r10-0x2b0]                   
    stxdw [r10-0x1a0], r2                   
    ldxdw r2, [r10-0x2a7]                   
    stxdw [r10-0x1d0], r2                   
    ldxdw r2, [r10-0x2a0]                   
    stxdw [r10-0x1c9], r2                   
    ldxdw r2, [r10-0x2d8]                   
    ldxdw r3, [r10-0x2d0]                   
    ldxdw r4, [r10-0x2c8]                   
    ldxdw r5, [r10-0x2c0]                   
    ldxb r0, [r10-0x2a8]                    
    stxb [r10-0x220], r0                    
    stxdw [r10-0x238], r5                   
    stxdw [r10-0x240], r4                   
    stxdw [r10-0x248], r3                   
    stxb [r10-0x258], r1                    
    stxdw [r10-0x250], r2                   
    ldxdw r1, [r10-0x1a0]                   
    stxdw [r10-0x228], r1                   
    ldxdw r1, [r10-0x1a8]                   
    stxdw [r10-0x230], r1                   
    ldxdw r1, [r10-0x1c9]                   
    stxdw [r10-0x218], r1                   
    ldxdw r1, [r10-0x1d0]                   
    stxdw [r10-0x21f], r1                   
    ja lbb_12531                                    if true { pc += -669 }
lbb_13200:
    ldxdw r1, [r10-0x948]                   
    stxdw [r10-0x2c8], r1                   
    ldxdw r2, [r10-0x950]                   
    stxdw [r10-0x2d0], r2                   
    ldxdw r3, [r10-0x958]                   
    stxdw [r10-0x2d8], r3                   
    ldxdw r4, [r10-0x960]                   
    stxdw [r10-0x2e0], r4                   
lbb_13208:
    ldxdw r5, [r10-0xc00]                   
    stxdw [r5+0x18], r1                     
    stxdw [r5+0x10], r2                     
    stxdw [r5+0x8], r3                      
    stxdw [r5+0x0], r4                      
    ja lbb_11585                                    if true { pc += -1629 }

function_13214:
    mov64 r6, r3                                    r6 = r3
    mov64 r9, r2                                    r9 = r2
    mov64 r7, r1                                    r7 = r1
    jne r4, 5, lbb_13513                            if r4 != (5 as i32 as i64 as u64) { pc += 295 }
    ldxdw r1, [r6+0x0]                      
    stxdw [r10-0x188], r1                   
    ldxb r1, [r6+0x28]                      
    mov64 r2, 37                                    r2 = 37 as i32 as i64 as u64
    stxdw [r10-0x88], r2                    
    lddw r2, 0x10005ffef --> b"Market maker account must be a signerIncorrect sys"        r2 load str located at 4295360495
    stxdw [r10-0x90], r2                    
    jne r1, 0, lbb_13272                            if r1 != (0 as i32 as i64 as u64) { pc += 45 }
    lddw r1, 0x1000652e8 --> b"\x00\x00\x00\x00k\x08\x06\x00.\x00\x00\x00\x00\x00\x00\x00\x19\x00\x00\x0…        r1 load str located at 4295381736
    stxdw [r10-0x80], r1                    
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    stxdw [r10-0x118], r1                   
    lddw r1, 0x100064c98 --> b"\x00\x00\x00\x00p\xfa\x05\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00…        r1 load str located at 4295380120
    stxdw [r10-0x138], r1                   
    mov64 r1, 2                                     r1 = 2 as i32 as i64 as u64
    stxdw [r10-0x130], r1                   
    stxdw [r10-0x120], r1                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -384                                  r1 += -384   ///  r1 = r1.wrapping_add(-384 as i32 as i64 as u64)
    stxdw [r10-0x128], r1                   
    lddw r1, 0x100000888 --> b"y\x11\x00\x00\x00\x00\x00\x00\x85\x10\x00\x00]\xab\x00\x00\x95\x00\x00\x0…        r1 load str located at 4294969480
    stxdw [r10-0x168], r1                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -128                                  r1 += -128   ///  r1 = r1.wrapping_add(-128 as i32 as i64 as u64)
    stxdw [r10-0x170], r1                   
    lddw r1, 0x100000860 --> b"\xbf#\x00\x00\x00\x00\x00\x00y\x12\x08\x00\x00\x00\x00\x00y\x11\x00\x00\x…        r1 load str located at 4294969440
    stxdw [r10-0x178], r1                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -144                                  r1 += -144   ///  r1 = r1.wrapping_add(-144 as i32 as i64 as u64)
    stxdw [r10-0x180], r1                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -120                                  r1 += -120   ///  r1 = r1.wrapping_add(-120 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -312                                  r2 += -312   ///  r2 = r2.wrapping_add(-312 as i32 as i64 as u64)
    call function_43415                     
    ldxdw r1, [r10-0x78]                    
    ldxdw r2, [r10-0x68]                    
    syscall [invalid]                       
    ldxdw r2, [r10-0x188]                   
    ldxdw r1, [r2+0x18]                     
    stxdw [r10-0x11f], r1                   
    ldxdw r1, [r2+0x10]                     
    stxdw [r10-0x127], r1                   
    ldxdw r1, [r2+0x8]                      
    stxdw [r10-0x12f], r1                   
    ldxdw r1, [r2+0x0]                      
    stxdw [r10-0x137], r1                   
    mov64 r1, 43                                    r1 = 43 as i32 as i64 as u64
    ja lbb_13537                                    if true { pc += 265 }
lbb_13272:
    stxdw [r10-0x1a0], r5                   
    stxdw [r10-0x190], r7                   
    mov64 r3, r6                                    r3 = r6
    add64 r3, 48                                    r3 += 48   ///  r3 = r3.wrapping_add(48 as i32 as i64 as u64)
    mov64 r1, r10                                   r1 = r10
    add64 r1, -384                                  r1 += -384   ///  r1 = r1.wrapping_add(-384 as i32 as i64 as u64)
    mov64 r2, r9                                    r2 = r9
    call function_16885                     
    ldxb r8, [r10-0x180]                    
    jne r8, 56, lbb_13542                           if r8 != (56 as i32 as i64 as u64) { pc += 260 }
    ldxdw r1, [r10-0x170]                   
    stxdw [r10-0x198], r1                   
    ldxdw r5, [r10-0x168]                   
    ldxdw r8, [r10-0x178]                   
    mov64 r3, r6                                    r3 = r6
    add64 r3, 96                                    r3 += 96   ///  r3 = r3.wrapping_add(96 as i32 as i64 as u64)
    mov64 r1, r10                                   r1 = r10
    add64 r1, -384                                  r1 += -384   ///  r1 = r1.wrapping_add(-384 as i32 as i64 as u64)
    mov64 r2, r9                                    r2 = r9
    mov64 r4, r8                                    r4 = r8
    call function_17016                     
    ldxb r7, [r10-0x180]                    
    jeq r7, 56, lbb_13296                           if r7 == (56 as i32 as i64 as u64) { pc += 1 }
    ja lbb_13564                                    if true { pc += 268 }
lbb_13296:
    ldxdw r3, [r10-0x188]                   
    ldxdw r1, [r3+0x0]                      
    ldxdw r2, [r8+0x28]                     
    add64 r8, 40                                    r8 += 40   ///  r8 = r8.wrapping_add(40 as i32 as i64 as u64)
    jeq r2, r1, lbb_13303                           if r2 == r1 { pc += 2 }
lbb_13301:
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    ja lbb_13313                                    if true { pc += 10 }
lbb_13303:
    ldxdw r1, [r3+0x8]                      
    ldxdw r2, [r8+0x8]                      
    jne r2, r1, lbb_13301                           if r2 != r1 { pc += -5 }
    ldxdw r1, [r3+0x10]                     
    ldxdw r2, [r8+0x10]                     
    jne r2, r1, lbb_13301                           if r2 != r1 { pc += -8 }
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    ldxdw r2, [r3+0x18]                     
    ldxdw r3, [r8+0x18]                     
    jne r3, r2, lbb_13301                           if r3 != r2 { pc += -12 }
lbb_13313:
    ldxdw r4, [r10-0x168]                   
    ldxdw r7, [r10-0x170]                   
    ldxdw r3, [r10-0x178]                   
    ldxdw r5, [r6+0x90]                     
    mov64 r2, 27                                    r2 = 27 as i32 as i64 as u64
    stxdw [r10-0x88], r2                    
    lddw r2, 0x100060899 --> b"Signing mm is not MM on dexStale sequence number o"        r2 load str located at 4295362713
    stxdw [r10-0x90], r2                    
    jeq r1, 0, lbb_13390                            if r1 == (0 as i32 as i64 as u64) { pc += 67 }
    mov64 r9, r5                                    r9 = r5
    lddw r1, 0x100065300 --> b"\x00\x00\x00\x00k\x08\x06\x00.\x00\x00\x00\x00\x00\x00\x00(\x00\x00\x00\x…        r1 load str located at 4295381760
    stxdw [r10-0x80], r1                    
    lddw r1, 0x100064c98 --> b"\x00\x00\x00\x00p\xfa\x05\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00…        r1 load str located at 4295380120
    stxdw [r10-0x138], r1                   
    mov64 r1, 2                                     r1 = 2 as i32 as i64 as u64
    stxdw [r10-0x130], r1                   
    stxdw [r10-0x120], r1                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -384                                  r1 += -384   ///  r1 = r1.wrapping_add(-384 as i32 as i64 as u64)
    stxdw [r10-0x128], r1                   
    lddw r1, 0x100000888 --> b"y\x11\x00\x00\x00\x00\x00\x00\x85\x10\x00\x00]\xab\x00\x00\x95\x00\x00\x0…        r1 load str located at 4294969480
    stxdw [r10-0x168], r1                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -128                                  r1 += -128   ///  r1 = r1.wrapping_add(-128 as i32 as i64 as u64)
    stxdw [r10-0x170], r1                   
    lddw r1, 0x100000860 --> b"\xbf#\x00\x00\x00\x00\x00\x00y\x12\x08\x00\x00\x00\x00\x00y\x11\x00\x00\x…        r1 load str located at 4294969440
    stxdw [r10-0x178], r1                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -144                                  r1 += -144   ///  r1 = r1.wrapping_add(-144 as i32 as i64 as u64)
    stxdw [r10-0x180], r1                   
    mov64 r6, 0                                     r6 = 0 as i32 as i64 as u64
    stxdw [r10-0x118], r6                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -120                                  r1 += -120   ///  r1 = r1.wrapping_add(-120 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -312                                  r2 += -312   ///  r2 = r2.wrapping_add(-312 as i32 as i64 as u64)
    call function_43415                     
    ldxdw r1, [r10-0x78]                    
    ldxdw r2, [r10-0x68]                    
    syscall [invalid]                       
    ldxdw r1, [r8+0x18]                     
    stxdw [r10-0x120], r1                   
    ldxdw r1, [r8+0x10]                     
    stxdw [r10-0x128], r1                   
    ldxdw r1, [r8+0x8]                      
    stxdw [r10-0x130], r1                   
    ldxdw r1, [r8+0x0]                      
    stxdw [r10-0x138], r1                   
    lddw r1, 0x300000000                            r1 load str located at 12884901888
    ldxdw r2, [r1+0x0]                      
    mov64 r3, 1                                     r3 = 1 as i32 as i64 as u64
    mov64 r4, r2                                    r4 = r2
    add64 r4, -32                                   r4 += -32   ///  r4 = r4.wrapping_add(-32 as i32 as i64 as u64)
    jgt r4, r2, lbb_13374                           if r4 > r2 { pc += 1 }
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
lbb_13374:
    mov64 r8, r7                                    r8 = r7
    ldxdw r1, [r10-0x190]                   
    jne r3, 0, lbb_13378                            if r3 != (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r6, r4                                    r6 = r4
lbb_13378:
    lddw r7, 0x300007fe0                            r7 load str located at 12884934624
    ldxdw r4, [r10-0x188]                   
    jeq r2, 0, lbb_13383                            if r2 == (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r7, r6                                    r7 = r6
lbb_13383:
    lddw r2, 0x300000007                            r2 load str located at 12884901895
    jgt r7, r2, lbb_13586                           if r7 > r2 { pc += 200 }
lbb_13386:
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    mov64 r2, 32                                    r2 = 32 as i32 as i64 as u64
    call function_43400                     
    syscall [invalid]                       
lbb_13390:
    ldxdw r1, [r6+0xc0]                     
    add64 r6, 144                                   r6 += 144   ///  r6 = r6.wrapping_add(144 as i32 as i64 as u64)
    stxdw [r10-0x1000], r1                  
    stxdw [r10-0xff8], r6                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -384                                  r1 += -384   ///  r1 = r1.wrapping_add(-384 as i32 as i64 as u64)
    mov64 r5, r10                                   r5 = r10
    mov64 r2, r9                                    r2 = r9
    call function_14847                     
    ldxb r6, [r10-0x180]                    
    jeq r6, 56, lbb_13402                           if r6 == (56 as i32 as i64 as u64) { pc += 1 }
    ja lbb_13680                                    if true { pc += 278 }
lbb_13402:
    ldxdw r8, [r10-0x170]                   
    ldxdw r6, [r10-0x178]                   
    ldxdw r2, [r10-0x1a0]                   
    ldxdw r9, [r2+0x2c0]                    
    ldxdw r1, [r6+0x350]                    
    mov64 r3, 43                                    r3 = 43 as i32 as i64 as u64
    stxdw [r10-0x88], r3                    
    lddw r3, 0x1000608b4 --> b"Stale sequence number on order block updateExpecte"        r3 load str located at 4295362740
    stxdw [r10-0x90], r3                    
    jgt r9, r1, lbb_13453                           if r9 > r1 { pc += 40 }
    lddw r1, 0x100065318 --> b"\x00\x00\x00\x00k\x08\x06\x00.\x00\x00\x00\x00\x00\x00\x009\x00\x00\x00\x…        r1 load str located at 4295381784
    stxdw [r10-0x80], r1                    
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    stxdw [r10-0x118], r1                   
    lddw r1, 0x100064c98 --> b"\x00\x00\x00\x00p\xfa\x05\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00…        r1 load str located at 4295380120
    stxdw [r10-0x138], r1                   
    mov64 r1, 2                                     r1 = 2 as i32 as i64 as u64
    stxdw [r10-0x130], r1                   
    stxdw [r10-0x120], r1                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -384                                  r1 += -384   ///  r1 = r1.wrapping_add(-384 as i32 as i64 as u64)
    stxdw [r10-0x128], r1                   
    lddw r1, 0x100000888 --> b"y\x11\x00\x00\x00\x00\x00\x00\x85\x10\x00\x00]\xab\x00\x00\x95\x00\x00\x0…        r1 load str located at 4294969480
    stxdw [r10-0x168], r1                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -128                                  r1 += -128   ///  r1 = r1.wrapping_add(-128 as i32 as i64 as u64)
    stxdw [r10-0x170], r1                   
    lddw r1, 0x100000860 --> b"\xbf#\x00\x00\x00\x00\x00\x00y\x12\x08\x00\x00\x00\x00\x00y\x11\x00\x00\x…        r1 load str located at 4294969440
    stxdw [r10-0x178], r1                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -144                                  r1 += -144   ///  r1 = r1.wrapping_add(-144 as i32 as i64 as u64)
    stxdw [r10-0x180], r1                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -120                                  r1 += -120   ///  r1 = r1.wrapping_add(-120 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -312                                  r2 += -312   ///  r2 = r2.wrapping_add(-312 as i32 as i64 as u64)
    call function_43415                     
    ldxdw r1, [r10-0x78]                    
    ldxdw r2, [r10-0x68]                    
    syscall [invalid]                       
    ldxdw r1, [r6+0x350]                    
    stxdw [r10-0x128], r1                   
    stxdw [r10-0x130], r9                   
    mov64 r1, 44                                    r1 = 44 as i32 as i64 as u64
    stxb [r10-0x138], r1                    
    ja lbb_13722                                    if true { pc += 269 }
lbb_13453:
    stxdw [r10-0x188], r8                   
    mov64 r9, r7                                    r9 = r7
    mov64 r1, r10                                   r1 = r10
    add64 r1, -384                                  r1 += -384   ///  r1 = r1.wrapping_add(-384 as i32 as i64 as u64)
    mov64 r8, r2                                    r8 = r2
    call function_29910                     
    ldxb r7, [r10-0x180]                    
    jne r7, 56, lbb_13702                           if r7 != (56 as i32 as i64 as u64) { pc += 241 }
    mov64 r1, r6                                    r1 = r6
    add64 r1, 144                                   r1 += 144   ///  r1 = r1.wrapping_add(144 as i32 as i64 as u64)
    mov64 r2, r8                                    r2 = r8
    mov64 r3, 776                                   r3 = 776 as i32 as i64 as u64
    call function_48190                     
    mov64 r1, r10                                   r1 = r10
    add64 r1, -312                                  r1 += -312   ///  r1 = r1.wrapping_add(-312 as i32 as i64 as u64)
    call function_41956                     
    ldxdw r1, [r10-0x138]                   
    mov64 r7, r9                                    r7 = r9
    jeq r1, 0, lbb_13490                            if r1 == (0 as i32 as i64 as u64) { pc += 18 }
    ldxdw r1, [r10-0x130]                   
    ldxdw r2, [r10-0x128]                   
    ldxdw r3, [r10-0x120]                   
    ldxdw r4, [r10-0x118]                   
    ldxdw r5, [r10-0x190]                   
    stxdw [r5+0x18], r4                     
    stxdw [r5+0x10], r3                     
    stxdw [r5+0x8], r2                      
    stxdw [r5+0x0], r1                      
lbb_13481:
    ldxdw r8, [r10-0x188]                   
lbb_13482:
    ldxdw r1, [r8+0x0]                      
    add64 r1, 1                                     r1 += 1   ///  r1 = r1.wrapping_add(1 as i32 as i64 as u64)
    stxdw [r8+0x0], r1                      
lbb_13485:
    ldxdw r2, [r10-0x198]                   
lbb_13486:
    ldxdw r1, [r7+0x0]                      
    add64 r1, -1                                    r1 += -1   ///  r1 = r1.wrapping_add(-1 as i32 as i64 as u64)
    stxdw [r7+0x0], r1                      
    ja lbb_13509                                    if true { pc += 19 }
lbb_13490:
    ldxdw r3, [r10-0x130]                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -384                                  r1 += -384   ///  r1 = r1.wrapping_add(-384 as i32 as i64 as u64)
    mov64 r2, r6                                    r2 = r6
    call function_22757                     
    ldxb r6, [r10-0x180]                    
    ldxdw r8, [r10-0x188]                   
    jeq r6, 56, lbb_13499                           if r6 == (56 as i32 as i64 as u64) { pc += 1 }
    ja lbb_13715                                    if true { pc += 216 }
lbb_13499:
    mov64 r1, 24                                    r1 = 24 as i32 as i64 as u64
    ldxdw r2, [r10-0x190]                   
    stxw [r2+0x0], r1                       
    ldxdw r1, [r8+0x0]                      
    add64 r1, 1                                     r1 += 1   ///  r1 = r1.wrapping_add(1 as i32 as i64 as u64)
    stxdw [r8+0x0], r1                      
    ldxdw r1, [r7+0x0]                      
    add64 r1, -1                                    r1 += -1   ///  r1 = r1.wrapping_add(-1 as i32 as i64 as u64)
    stxdw [r7+0x0], r1                      
lbb_13508:
    ldxdw r2, [r10-0x198]                   
lbb_13509:
    ldxdw r1, [r2+0x0]                      
    add64 r1, -1                                    r1 += -1   ///  r1 = r1.wrapping_add(-1 as i32 as i64 as u64)
    stxdw [r2+0x0], r1                      
lbb_13512:
    exit                                    
lbb_13513:
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    stxdw [r10-0x160], r1                   
    lddw r1, 0x100065330 --> b"\x00\x00\x00\x00\xdf\x08\x06\x00\x19\x00\x00\x00\x00\x00\x00\x00\x00\x00\…        r1 load str located at 4295381808
    stxdw [r10-0x180], r1                   
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    stxdw [r10-0x178], r1                   
    stxdw [r10-0x168], r1                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -120                                  r1 += -120   ///  r1 = r1.wrapping_add(-120 as i32 as i64 as u64)
    stxdw [r10-0x170], r1                   
    lddw r1, 0x10005df58 --> b"\xbf#\x00\x00\x00\x00\x00\x00y\x11\x00\x00\x00\x00\x00\x00\xb7\x02\x00\x0…        r1 load str located at 4295352152
    stxdw [r10-0x70], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -144                                  r1 += -144   ///  r1 = r1.wrapping_add(-144 as i32 as i64 as u64)
    stxdw [r10-0x78], r1                    
    stxdw [r10-0x90], r4                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -304                                  r1 += -304   ///  r1 = r1.wrapping_add(-304 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -384                                  r2 += -384   ///  r2 = r2.wrapping_add(-384 as i32 as i64 as u64)
    call function_43415                     
    mov64 r1, 29                                    r1 = 29 as i32 as i64 as u64
lbb_13537:
    stxb [r10-0x138], r1                    
    mov64 r2, r10                                   r2 = r10
    add64 r2, -312                                  r2 += -312   ///  r2 = r2.wrapping_add(-312 as i32 as i64 as u64)
    mov64 r1, r7                                    r1 = r7
    ja lbb_13562                                    if true { pc += 20 }
lbb_13542:
    ldxw r1, [r10-0x17c]                    
    stxw [r10-0x134], r1                    
    ldxw r1, [r10-0x17f]                    
    stxw [r10-0x137], r1                    
    ldxdw r6, [r10-0x178]                   
    ldxdw r7, [r10-0x170]                   
    ldxdw r9, [r10-0x168]                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -280                                  r1 += -280   ///  r1 = r1.wrapping_add(-280 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -352                                  r2 += -352   ///  r2 = r2.wrapping_add(-352 as i32 as i64 as u64)
    mov64 r3, 40                                    r3 = 40 as i32 as i64 as u64
    call function_48190                     
    stxdw [r10-0x120], r9                   
    stxdw [r10-0x128], r7                   
    stxdw [r10-0x130], r6                   
    stxb [r10-0x138], r8                    
    mov64 r2, r10                                   r2 = r10
    add64 r2, -312                                  r2 += -312   ///  r2 = r2.wrapping_add(-312 as i32 as i64 as u64)
    ldxdw r1, [r10-0x190]                   
lbb_13562:
    call function_26067                     
    ja lbb_13512                                    if true { pc += -52 }
lbb_13564:
    ldxw r1, [r10-0x17c]                    
    stxw [r10-0x134], r1                    
    ldxw r1, [r10-0x17f]                    
    stxw [r10-0x137], r1                    
    ldxdw r6, [r10-0x178]                   
    ldxdw r8, [r10-0x170]                   
    ldxdw r9, [r10-0x168]                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -280                                  r1 += -280   ///  r1 = r1.wrapping_add(-280 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -352                                  r2 += -352   ///  r2 = r2.wrapping_add(-352 as i32 as i64 as u64)
    mov64 r3, 40                                    r3 = 40 as i32 as i64 as u64
    call function_48190                     
    stxdw [r10-0x120], r9                   
    stxdw [r10-0x128], r8                   
    stxdw [r10-0x130], r6                   
    stxb [r10-0x138], r7                    
    mov64 r2, r10                                   r2 = r10
    add64 r2, -312                                  r2 += -312   ///  r2 = r2.wrapping_add(-312 as i32 as i64 as u64)
    ldxdw r1, [r10-0x190]                   
    call function_26067                     
    ja lbb_13508                                    if true { pc += -78 }
lbb_13586:
    lddw r2, 0x300000000                            r2 load str located at 12884901888
    stxdw [r2+0x0], r7                      
    ldxdw r3, [r10-0x120]                   
    stxdw [r7+0x18], r3                     
    ldxdw r3, [r10-0x128]                   
    stxdw [r7+0x10], r3                     
    ldxdw r3, [r10-0x130]                   
    stxdw [r7+0x8], r3                      
    ldxdw r3, [r10-0x138]                   
    stxdw [r7+0x0], r3                      
    ldxdw r3, [r4+0x18]                     
    stxdw [r10-0x120], r3                   
    ldxdw r3, [r4+0x10]                     
    stxdw [r10-0x128], r3                   
    ldxdw r3, [r4+0x8]                      
    stxdw [r10-0x130], r3                   
    ldxdw r3, [r4+0x0]                      
    stxdw [r10-0x138], r3                   
    ldxdw r3, [r2+0x0]                      
    mov64 r4, 0                                     r4 = 0 as i32 as i64 as u64
    mov64 r5, 1                                     r5 = 1 as i32 as i64 as u64
    mov64 r2, r3                                    r2 = r3
    add64 r2, -32                                   r2 += -32   ///  r2 = r2.wrapping_add(-32 as i32 as i64 as u64)
    jgt r2, r3, lbb_13612                           if r2 > r3 { pc += 1 }
    mov64 r5, 0                                     r5 = 0 as i32 as i64 as u64
lbb_13612:
    jne r5, 0, lbb_13614                            if r5 != (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r4, r2                                    r4 = r2
lbb_13614:
    lddw r2, 0x300007fe0                            r2 load str located at 12884934624
    jeq r3, 0, lbb_13618                            if r3 == (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r2, r4                                    r2 = r4
lbb_13618:
    lddw r3, 0x300000007                            r3 load str located at 12884901895
    jgt r2, r3, lbb_13622                           if r2 > r3 { pc += 1 }
    ja lbb_13386                                    if true { pc += -236 }
lbb_13622:
    lddw r3, 0x300000000                            r3 load str located at 12884901888
    stxdw [r3+0x0], r2                      
    ldxdw r4, [r10-0x120]                   
    stxdw [r2+0x18], r4                     
    ldxdw r4, [r10-0x128]                   
    stxdw [r2+0x10], r4                     
    ldxdw r4, [r10-0x130]                   
    stxdw [r2+0x8], r4                      
    ldxdw r4, [r10-0x138]                   
    stxdw [r2+0x0], r4                      
    ldxdw r4, [r9+0x18]                     
    stxdw [r10-0x120], r4                   
    ldxdw r4, [r9+0x10]                     
    stxdw [r10-0x128], r4                   
    ldxdw r4, [r9+0x8]                      
    stxdw [r10-0x130], r4                   
    ldxdw r4, [r9+0x0]                      
    stxdw [r10-0x138], r4                   
    ldxdw r4, [r3+0x0]                      
    mov64 r5, 0                                     r5 = 0 as i32 as i64 as u64
    mov64 r0, 1                                     r0 = 1 as i32 as i64 as u64
    mov64 r3, r4                                    r3 = r4
    add64 r3, -32                                   r3 += -32   ///  r3 = r3.wrapping_add(-32 as i32 as i64 as u64)
    jgt r3, r4, lbb_13648                           if r3 > r4 { pc += 1 }
    mov64 r0, 0                                     r0 = 0 as i32 as i64 as u64
lbb_13648:
    jne r0, 0, lbb_13650                            if r0 != (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r5, r3                                    r5 = r3
lbb_13650:
    lddw r3, 0x300007fe0                            r3 load str located at 12884934624
    jeq r4, 0, lbb_13654                            if r4 == (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r3, r5                                    r3 = r5
lbb_13654:
    lddw r4, 0x300000007                            r4 load str located at 12884901895
    jgt r3, r4, lbb_13658                           if r3 > r4 { pc += 1 }
    ja lbb_13386                                    if true { pc += -272 }
lbb_13658:
    lddw r4, 0x300000000                            r4 load str located at 12884901888
    stxdw [r4+0x0], r3                      
    ldxdw r4, [r10-0x120]                   
    stxdw [r3+0x18], r4                     
    ldxdw r4, [r10-0x128]                   
    stxdw [r3+0x10], r4                     
    ldxdw r4, [r10-0x130]                   
    stxdw [r3+0x8], r4                      
    ldxdw r4, [r10-0x138]                   
    stxdw [r3+0x0], r4                      
    stxdw [r10-0x120], r3                   
    stxdw [r10-0x128], r2                   
    stxdw [r10-0x130], r7                   
    mov64 r2, 24                                    r2 = 24 as i32 as i64 as u64
    stxb [r10-0x138], r2                    
    mov64 r2, r10                                   r2 = r10
    add64 r2, -312                                  r2 += -312   ///  r2 = r2.wrapping_add(-312 as i32 as i64 as u64)
    call function_26067                     
    ldxdw r2, [r10-0x198]                   
    mov64 r7, r8                                    r7 = r8
    ja lbb_13486                                    if true { pc += -194 }
lbb_13680:
    ldxw r1, [r10-0x17c]                    
    stxw [r10-0x134], r1                    
    ldxw r1, [r10-0x17f]                    
    stxw [r10-0x137], r1                    
    mov64 r9, r7                                    r9 = r7
    ldxdw r7, [r10-0x178]                   
    ldxdw r8, [r10-0x170]                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -288                                  r1 += -288   ///  r1 = r1.wrapping_add(-288 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -360                                  r2 += -360   ///  r2 = r2.wrapping_add(-360 as i32 as i64 as u64)
    mov64 r3, 48                                    r3 = 48 as i32 as i64 as u64
    call function_48190                     
    stxdw [r10-0x128], r8                   
    stxdw [r10-0x130], r7                   
    mov64 r7, r9                                    r7 = r9
    stxb [r10-0x138], r6                    
    mov64 r2, r10                                   r2 = r10
    add64 r2, -312                                  r2 += -312   ///  r2 = r2.wrapping_add(-312 as i32 as i64 as u64)
    ldxdw r1, [r10-0x190]                   
    call function_26067                     
    ja lbb_13485                                    if true { pc += -217 }
lbb_13702:
    mov64 r1, r10                                   r1 = r10
    add64 r1, -311                                  r1 += -311   ///  r1 = r1.wrapping_add(-311 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -383                                  r2 += -383   ///  r2 = r2.wrapping_add(-383 as i32 as i64 as u64)
    mov64 r3, 71                                    r3 = 71 as i32 as i64 as u64
    call function_48190                     
    stxb [r10-0x138], r7                    
    mov64 r2, r10                                   r2 = r10
    add64 r2, -312                                  r2 += -312   ///  r2 = r2.wrapping_add(-312 as i32 as i64 as u64)
    ldxdw r1, [r10-0x190]                   
    call function_26067                     
    mov64 r7, r9                                    r7 = r9
    ja lbb_13481                                    if true { pc += -234 }
lbb_13715:
    mov64 r1, r10                                   r1 = r10
    add64 r1, -311                                  r1 += -311   ///  r1 = r1.wrapping_add(-311 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -383                                  r2 += -383   ///  r2 = r2.wrapping_add(-383 as i32 as i64 as u64)
    mov64 r3, 71                                    r3 = 71 as i32 as i64 as u64
    call function_48190                     
    stxb [r10-0x138], r6                    
lbb_13722:
    mov64 r2, r10                                   r2 = r10
    add64 r2, -312                                  r2 += -312   ///  r2 = r2.wrapping_add(-312 as i32 as i64 as u64)
    ldxdw r1, [r10-0x190]                   
    call function_26067                     
    ja lbb_13482                                    if true { pc += -245 }

function_13727:
    mov64 r7, r3                                    r7 = r3
    mov64 r8, r2                                    r8 = r2
    mov64 r9, r1                                    r9 = r1
    jne r4, 0, lbb_13755                            if r4 != (0 as i32 as i64 as u64) { pc += 24 }
    lddw r1, 0x100065340 --> b"\x00\x00\x00\x00\xf8\x08\x06\x00\x1a\x00\x00\x00\x00\x00\x00\x00\x00\x00\…        r1 load str located at 4295381824
    stxdw [r10-0x6d0], r1                   
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    stxdw [r10-0x6c8], r1                   
    stxdw [r10-0x6b8], r1                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -1232                                 r1 += -1232   ///  r1 = r1.wrapping_add(-1232 as i32 as i64 as u64)
    stxdw [r10-0x6c0], r1                   
    lddw r1, 0x10005df58 --> b"\xbf#\x00\x00\x00\x00\x00\x00y\x11\x00\x00\x00\x00\x00\x00\xb7\x02\x00\x0…        r1 load str located at 4295352152
    stxdw [r10-0x4c8], r1                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -1368                                 r1 += -1368   ///  r1 = r1.wrapping_add(-1368 as i32 as i64 as u64)
    stxdw [r10-0x4d0], r1                   
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    stxdw [r10-0x6b0], r1                   
    stxdw [r10-0x558], r1                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -672                                  r1 += -672   ///  r1 = r1.wrapping_add(-672 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -1744                                 r2 += -1744   ///  r2 = r2.wrapping_add(-1744 as i32 as i64 as u64)
    call function_43415                     
    ja lbb_13962                                    if true { pc += 207 }
lbb_13755:
    ldxb r1, [r7+0x28]                      
    jeq r1, 0, lbb_13922                            if r1 == (0 as i32 as i64 as u64) { pc += 165 }
    ldxdw r6, [r5-0xff8]                    
    ldxdw r1, [r5-0x1000]                   
    stxdw [r10-0x708], r1                   
    mov64 r3, r7                                    r3 = r7
    add64 r3, 48                                    r3 += 48   ///  r3 = r3.wrapping_add(48 as i32 as i64 as u64)
    add64 r4, -1                                    r4 += -1   ///  r4 = r4.wrapping_add(-1 as i32 as i64 as u64)
    mov64 r1, r10                                   r1 = r10
    add64 r1, -1744                                 r1 += -1744   ///  r1 = r1.wrapping_add(-1744 as i32 as i64 as u64)
    mov64 r2, r8                                    r2 = r8
    call function_17594                     
    ldxb r1, [r10-0x6d0]                    
    jne r1, 56, lbb_13964                           if r1 != (56 as i32 as i64 as u64) { pc += 195 }
    ldxdw r5, [r10-0x6c8]                   
    ldxdw r2, [r5+0x8]                      
    add64 r5, 8                                     r5 += 8   ///  r5 = r5.wrapping_add(8 as i32 as i64 as u64)
    ldxdw r1, [r7+0x0]                      
    ldxdw r3, [r1+0x0]                      
    jeq r2, r3, lbb_13777                           if r2 == r3 { pc += 2 }
lbb_13775:
    mov64 r2, 1                                     r2 = 1 as i32 as i64 as u64
    ja lbb_13787                                    if true { pc += 10 }
lbb_13777:
    ldxdw r2, [r1+0x8]                      
    ldxdw r3, [r5+0x8]                      
    jne r3, r2, lbb_13775                           if r3 != r2 { pc += -5 }
    ldxdw r2, [r1+0x10]                     
    ldxdw r3, [r5+0x10]                     
    jne r3, r2, lbb_13775                           if r3 != r2 { pc += -8 }
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
    ldxdw r1, [r1+0x18]                     
    ldxdw r3, [r5+0x18]                     
    jne r3, r1, lbb_13775                           if r3 != r1 { pc += -12 }
lbb_13787:
    ldxdw r4, [r10-0x6a8]                   
    ldxdw r3, [r10-0x6c0]                   
    jeq r2, 0, lbb_13791                            if r2 == (0 as i32 as i64 as u64) { pc += 1 }
    ja lbb_13990                                    if true { pc += 199 }
lbb_13791:
    ldxdw r2, [r10-0x690]                   
    jeq r2, 0, lbb_14010                            if r2 == (0 as i32 as i64 as u64) { pc += 217 }
    stxdw [r10-0x6e0], r4                   
    stxdw [r10-0x6d8], r3                   
    mov64 r1, r2                                    r1 = r2
    add64 r1, -1                                    r1 += -1   ///  r1 = r1.wrapping_add(-1 as i32 as i64 as u64)
    jgt r1, 1, lbb_13837                            if r1 > (1 as i32 as i64 as u64) { pc += 39 }
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
    stxdw [r10-0x288], r2                   
    mov64 r2, 2                                     r2 = 2 as i32 as i64 as u64
    stxdw [r10-0x2a0], r2                   
    lddw r2, 0x1000654c8 --> b"\x00\x00\x00\x00y\x0b\x06\x00-\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x0…        r2 load str located at 4295382216
    stxdw [r10-0x2a8], r2                   
    mov64 r2, 1                                     r2 = 1 as i32 as i64 as u64
    stxdw [r10-0x290], r2                   
    mov64 r2, r10                                   r2 = r10
    add64 r2, -1744                                 r2 += -1744   ///  r2 = r2.wrapping_add(-1744 as i32 as i64 as u64)
    stxdw [r10-0x298], r2                   
    lddw r2, 0x10005df58 --> b"\xbf#\x00\x00\x00\x00\x00\x00y\x11\x00\x00\x00\x00\x00\x00\xb7\x02\x00\x0…        r2 load str located at 4295352152
    stxdw [r10-0x6c8], r2                   
    mov64 r2, r10                                   r2 = r10
    add64 r2, -1232                                 r2 += -1232   ///  r2 = r2.wrapping_add(-1232 as i32 as i64 as u64)
    stxdw [r10-0x6d0], r2                   
    stxdw [r10-0x4d0], r1                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -704                                  r1 += -704   ///  r1 = r1.wrapping_add(-704 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -680                                  r2 += -680   ///  r2 = r2.wrapping_add(-680 as i32 as i64 as u64)
    call function_43415                     
    ldxdw r1, [r10-0x2c0]                   
    stxdw [r10-0x419], r1                   
    ldxdw r1, [r10-0x2b8]                   
    stxdw [r10-0x411], r1                   
    ldxdw r1, [r10-0x2b0]                   
    stxdw [r10-0x409], r1                   
    stxdw [r10-0x101], r1                   
    ldxdw r1, [r10-0x420]                   
    stxdw [r10-0x118], r1                   
    ldxdw r1, [r10-0x418]                   
    stxdw [r10-0x110], r1                   
    ldxdw r1, [r10-0x410]                   
    stxdw [r10-0x108], r1                   
    mov64 r8, 29                                    r8 = 29 as i32 as i64 as u64
    ja lbb_13886                                    if true { pc += 49 }
lbb_13837:
    stxdw [r10-0x700], r2                   
    stxdw [r10-0x710], r5                   
    stxdw [r10-0x718], r6                   
    ldxdw r6, [r10-0x698]                   
    ldxdw r7, [r10-0x6a0]                   
    ldxdw r3, [r10-0x6b0]                   
    mov64 r1, r6                                    r1 = r6
    add64 r1, 48                                    r1 += 48   ///  r1 = r1.wrapping_add(48 as i32 as i64 as u64)
    stxdw [r10-0x1000], r1                  
    mov64 r1, r6                                    r1 = r6
    add64 r1, 96                                    r1 += 96   ///  r1 = r1.wrapping_add(96 as i32 as i64 as u64)
    stxdw [r10-0xff8], r1                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -680                                  r1 += -680   ///  r1 = r1.wrapping_add(-680 as i32 as i64 as u64)
    mov64 r5, r10                                   r5 = r10
    mov64 r2, r8                                    r2 = r8
    mov64 r4, r7                                    r4 = r7
    call function_15275                     
    ldxdw r1, [r10-0x2a7]                   
    stxdw [r10-0x3b8], r1                   
    ldxdw r1, [r10-0x29f]                   
    stxdw [r10-0x3b0], r1                   
    ldxdw r1, [r10-0x297]                   
    stxdw [r10-0x3a8], r1                   
    ldxdw r1, [r10-0x290]                   
    stxdw [r10-0x3a1], r1                   
    mov64 r2, r10                                   r2 = r10
    add64 r2, -648                                  r2 += -648   ///  r2 = r2.wrapping_add(-648 as i32 as i64 as u64)
    ldxb r8, [r10-0x2a8]                    
    ldxw r1, [r10-0x200]                    
    jne r1, 2, lbb_14044                            if r1 != (2 as i32 as i64 as u64) { pc += 176 }
    mov64 r7, r10                                   r7 = r10
    add64 r7, -1232                                 r7 += -1232   ///  r7 = r7.wrapping_add(-1232 as i32 as i64 as u64)
    mov64 r1, r7                                    r1 = r7
    mov64 r3, 40                                    r3 = 40 as i32 as i64 as u64
    call function_48190                     
    ldxdw r1, [r10-0x3b8]                   
    stxdw [r10-0x118], r1                   
    ldxdw r1, [r10-0x3b0]                   
    stxdw [r10-0x110], r1                   
    ldxdw r1, [r10-0x3a8]                   
    stxdw [r10-0x108], r1                   
    ldxdw r1, [r10-0x3a1]                   
    stxdw [r10-0x101], r1                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -1368                                 r1 += -1368   ///  r1 = r1.wrapping_add(-1368 as i32 as i64 as u64)
    mov64 r2, r7                                    r2 = r7
    mov64 r3, 40                                    r3 = 40 as i32 as i64 as u64
    call function_48190                     
lbb_13886:
    ldxdw r1, [r10-0x118]                   
    stxdw [r10-0x578], r1                   
    ldxdw r1, [r10-0x110]                   
    stxdw [r10-0x570], r1                   
    ldxdw r1, [r10-0x108]                   
    stxdw [r10-0x568], r1                   
    ldxdw r1, [r10-0x101]                   
    stxdw [r10-0x561], r1                   
    mov64 r7, r10                                   r7 = r10
    add64 r7, -1536                                 r7 += -1536   ///  r7 = r7.wrapping_add(-1536 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -1368                                 r2 += -1368   ///  r2 = r2.wrapping_add(-1368 as i32 as i64 as u64)
    mov64 r1, r7                                    r1 = r7
    mov64 r3, 40                                    r3 = 40 as i32 as i64 as u64
    call function_48190                     
    ldxdw r1, [r10-0x561]                   
    stxdw [r10-0x290], r1                   
    ldxdw r1, [r10-0x568]                   
    stxdw [r10-0x297], r1                   
    ldxdw r1, [r10-0x570]                   
    stxdw [r10-0x29f], r1                   
    ldxdw r1, [r10-0x578]                   
    stxdw [r10-0x2a7], r1                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -648                                  r1 += -648   ///  r1 = r1.wrapping_add(-648 as i32 as i64 as u64)
    mov64 r2, r7                                    r2 = r7
    mov64 r3, 40                                    r3 = 40 as i32 as i64 as u64
    call function_48190                     
    stxb [r10-0x2a8], r8                    
    mov64 r2, r10                                   r2 = r10
    add64 r2, -680                                  r2 += -680   ///  r2 = r2.wrapping_add(-680 as i32 as i64 as u64)
    mov64 r1, r9                                    r1 = r9
    call function_26067                     
    ldxdw r3, [r10-0x6d8]                   
    ldxdw r4, [r10-0x6e0]                   
    ja lbb_14298                                    if true { pc += 376 }
lbb_13922:
    lddw r1, 0x300000000                            r1 load str located at 12884901888
    ldxdw r2, [r1+0x0]                      
    mov64 r1, r2                                    r1 = r2
    add64 r1, -26                                   r1 += -26   ///  r1 = r1.wrapping_add(-26 as i32 as i64 as u64)
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
    mov64 r4, 1                                     r4 = 1 as i32 as i64 as u64
    jgt r1, r2, lbb_13931                           if r1 > r2 { pc += 1 }
    mov64 r4, 0                                     r4 = 0 as i32 as i64 as u64
lbb_13931:
    jne r4, 0, lbb_13933                            if r4 != (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r3, r1                                    r3 = r1
lbb_13933:
    lddw r1, 0x300007fe6                            r1 load str located at 12884934630
    jeq r2, 0, lbb_13937                            if r2 == (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r1, r3                                    r1 = r3
lbb_13937:
    lddw r2, 0x300000007                            r2 load str located at 12884901895
    jgt r1, r2, lbb_13944                           if r1 > r2 { pc += 4 }
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    mov64 r2, 26                                    r2 = 26 as i32 as i64 as u64
    call function_43400                     
    syscall [invalid]                       
lbb_13944:
    lddw r2, 0x300000000                            r2 load str located at 12884901888
    stxdw [r2+0x0], r1                      
    mov64 r2, 29285                                 r2 = 29285 as i32 as i64 as u64
    stxh [r1+0x18], r2                      
    lddw r2, 0x6e67697320612065                     r2 load str located at 7955443209958662245
    stxdw [r1+0x10], r2                     
    lddw r2, 0x62207473756d2079                     r2 load str located at 7070779454211825785
    stxdw [r1+0x8], r2                      
    lddw r2, 0x656b2072656e774f                     r2 load str located at 7307970496038860623
    stxdw [r1+0x0], r2                      
    mov64 r2, 26                                    r2 = 26 as i32 as i64 as u64
    stxdw [r10-0x290], r2                   
    stxdw [r10-0x298], r2                   
    stxdw [r10-0x2a0], r1                   
lbb_13962:
    mov64 r1, 29                                    r1 = 29 as i32 as i64 as u64
    ja lbb_13984                                    if true { pc += 20 }
lbb_13964:
    ldxw r2, [r10-0x6cc]                    
    stxw [r10-0x2a4], r2                    
    ldxw r2, [r10-0x6cf]                    
    stxw [r10-0x2a7], r2                    
    ldxdw r2, [r10-0x690]                   
    stxdw [r10-0x268], r2                   
    ldxdw r2, [r10-0x698]                   
    stxdw [r10-0x270], r2                   
    ldxdw r2, [r10-0x6a0]                   
    stxdw [r10-0x278], r2                   
    ldxdw r2, [r10-0x6a8]                   
    stxdw [r10-0x280], r2                   
    ldxdw r2, [r10-0x6b0]                   
    stxdw [r10-0x288], r2                   
    ldxdw r2, [r10-0x6b8]                   
    stxdw [r10-0x290], r2                   
    ldxdw r2, [r10-0x6c0]                   
    stxdw [r10-0x298], r2                   
    ldxdw r2, [r10-0x6c8]                   
    stxdw [r10-0x2a0], r2                   
lbb_13984:
    stxb [r10-0x2a8], r1                    
    mov64 r2, r10                                   r2 = r10
    add64 r2, -680                                  r2 += -680   ///  r2 = r2.wrapping_add(-680 as i32 as i64 as u64)
    mov64 r1, r9                                    r1 = r9
    call function_26067                     
    ja lbb_14304                                    if true { pc += 314 }
lbb_13990:
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    stxdw [r10-0x6b0], r1                   
    lddw r1, 0x100065350 --> b"\x00\x00\x00\x00\x12\x09\x06\x00\x1e\x00\x00\x00\x00\x00\x00\x00\x00\x00\…        r1 load str located at 4295381840
    stxdw [r10-0x6d0], r1                   
    mov64 r1, 2                                     r1 = 2 as i32 as i64 as u64
    stxdw [r10-0x6c8], r1                   
    stxdw [r10-0x6b8], r1                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -1232                                 r1 += -1232   ///  r1 = r1.wrapping_add(-1232 as i32 as i64 as u64)
    stxdw [r10-0x6c0], r1                   
    lddw r1, 0x1000008a0 --> b"y\x11\x00\x00\x00\x00\x00\x00\x85\x10\x00\x00*\x99\x00\x00\x95\x00\x00\x0…        r1 load str located at 4294969504
    stxdw [r10-0x4b8], r1                   
    stxdw [r10-0x4c0], r7                   
    lddw r1, 0x10004d200 --> b"\xbf&\x00\x00\x00\x00\x00\x00y\x12\x00\x00\x00\x00\x00\x00y\x13\x08\x00\x…        r1 load str located at 4295283200
    stxdw [r10-0x4c8], r1                   
    stxdw [r10-0x4d0], r5                   
    ja lbb_14028                                    if true { pc += 18 }
lbb_14010:
    lddw r1, 0x100065370 --> b"\x00\x00\x00\x00\x88\x09\x06\x00#\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00…        r1 load str located at 4295381872
    stxdw [r10-0x6d0], r1                   
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    stxdw [r10-0x6c8], r1                   
    stxdw [r10-0x6b8], r1                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -1232                                 r1 += -1232   ///  r1 = r1.wrapping_add(-1232 as i32 as i64 as u64)
    stxdw [r10-0x6c0], r1                   
    lddw r1, 0x10005df58 --> b"\xbf#\x00\x00\x00\x00\x00\x00y\x11\x00\x00\x00\x00\x00\x00\xb7\x02\x00\x0…        r1 load str located at 4295352152
    stxdw [r10-0x4c8], r1                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -1368                                 r1 += -1368   ///  r1 = r1.wrapping_add(-1368 as i32 as i64 as u64)
    stxdw [r10-0x4d0], r1                   
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    stxdw [r10-0x6b0], r1                   
    stxdw [r10-0x558], r1                   
lbb_14028:
    mov64 r1, r10                                   r1 = r10
    add64 r1, -672                                  r1 += -672   ///  r1 = r1.wrapping_add(-672 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -1744                                 r2 += -1744   ///  r2 = r2.wrapping_add(-1744 as i32 as i64 as u64)
    mov64 r6, r3                                    r6 = r3
    mov64 r7, r4                                    r7 = r4
    call function_43415                     
    mov64 r1, 29                                    r1 = 29 as i32 as i64 as u64
    stxb [r10-0x2a8], r1                    
    mov64 r2, r10                                   r2 = r10
    add64 r2, -680                                  r2 += -680   ///  r2 = r2.wrapping_add(-680 as i32 as i64 as u64)
    mov64 r1, r9                                    r1 = r9
    call function_26067                     
    mov64 r4, r7                                    r4 = r7
    mov64 r3, r6                                    r3 = r6
    ja lbb_14298                                    if true { pc += 254 }
lbb_14044:
    stxdw [r10-0x720], r7                   
    stxdw [r10-0x6e8], r9                   
    stxdw [r10-0x6f0], r8                   
    mov64 r8, r10                                   r8 = r10
    add64 r8, -1232                                 r8 += -1232   ///  r8 = r8.wrapping_add(-1232 as i32 as i64 as u64)
    stxdw [r10-0x6f8], r1                   
    mov64 r1, r8                                    r1 = r8
    mov64 r3, 136                                   r3 = 136 as i32 as i64 as u64
    call function_48190                     
    mov64 r1, r10                                   r1 = r10
    add64 r1, -1572                                 r1 += -1572   ///  r1 = r1.wrapping_add(-1572 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -508                                  r2 += -508   ///  r2 = r2.wrapping_add(-508 as i32 as i64 as u64)
    mov64 r3, 36                                    r3 = 36 as i32 as i64 as u64
    call function_48190                     
    ldxdw r1, [r10-0x3b8]                   
    stxdw [r10-0x118], r1                   
    ldxdw r1, [r10-0x3b0]                   
    stxdw [r10-0x110], r1                   
    ldxdw r1, [r10-0x3a8]                   
    stxdw [r10-0x108], r1                   
    ldxdw r1, [r10-0x3a1]                   
    stxdw [r10-0x101], r1                   
    mov64 r9, r10                                   r9 = r10
    add64 r9, -1368                                 r9 += -1368   ///  r9 = r9.wrapping_add(-1368 as i32 as i64 as u64)
    mov64 r1, r9                                    r1 = r9
    mov64 r2, r8                                    r2 = r8
    mov64 r3, 136                                   r3 = 136 as i32 as i64 as u64
    call function_48190                     
    ldxdw r1, [r10-0x118]                   
    stxdw [r10-0x578], r1                   
    ldxdw r1, [r10-0x110]                   
    stxdw [r10-0x570], r1                   
    ldxdw r1, [r10-0x108]                   
    stxdw [r10-0x568], r1                   
    ldxdw r1, [r10-0x101]                   
    stxdw [r10-0x561], r1                   
    mov64 r7, r10                                   r7 = r10
    add64 r7, -1536                                 r7 += -1536   ///  r7 = r7.wrapping_add(-1536 as i32 as i64 as u64)
    mov64 r1, r7                                    r1 = r7
    mov64 r2, r9                                    r2 = r9
    mov64 r3, 136                                   r3 = 136 as i32 as i64 as u64
    call function_48190                     
    ldxdw r1, [r10-0x578]                   
    stxdw [r10-0x6cf], r1                   
    ldxdw r1, [r10-0x570]                   
    stxdw [r10-0x6c7], r1                   
    ldxdw r1, [r10-0x568]                   
    stxdw [r10-0x6bf], r1                   
    ldxdw r1, [r10-0x561]                   
    stxdw [r10-0x6b8], r1                   
    mov64 r8, r10                                   r8 = r10
    add64 r8, -1712                                 r8 += -1712   ///  r8 = r8.wrapping_add(-1712 as i32 as i64 as u64)
    mov64 r1, r8                                    r1 = r8
    mov64 r2, r7                                    r2 = r7
    mov64 r3, 136                                   r3 = 136 as i32 as i64 as u64
    call function_48190                     
    ldxdw r1, [r10-0x6f0]                   
    stxb [r10-0x6d0], r1                    
    ldxdw r1, [r10-0x6f8]                   
    stxw [r10-0x628], r1                    
    ldxdw r9, [r10-0x6d0]                   
    ldxdw r2, [r9+0x3b8]                    
    add64 r9, 952                                   r9 += 952   ///  r9 = r9.wrapping_add(952 as i32 as i64 as u64)
    ldxdw r1, [r6+0x0]                      
    ldxdw r3, [r1+0x0]                      
    jeq r2, r3, lbb_14113                           if r2 == r3 { pc += 2 }
lbb_14111:
    mov64 r2, 1                                     r2 = 1 as i32 as i64 as u64
    ja lbb_14123                                    if true { pc += 10 }
lbb_14113:
    ldxdw r2, [r1+0x8]                      
    ldxdw r3, [r9+0x8]                      
    jne r3, r2, lbb_14111                           if r3 != r2 { pc += -5 }
    ldxdw r2, [r1+0x10]                     
    ldxdw r3, [r9+0x10]                     
    jne r3, r2, lbb_14111                           if r3 != r2 { pc += -8 }
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
    ldxdw r3, [r1+0x18]                     
    ldxdw r4, [r9+0x18]                     
    jne r4, r3, lbb_14111                           if r4 != r3 { pc += -12 }
lbb_14123:
    jeq r2, 0, lbb_14144                            if r2 == (0 as i32 as i64 as u64) { pc += 20 }
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    stxdw [r10-0x4b0], r1                   
    lddw r1, 0x100065380 --> b"\x00\x00\x00\x00\x90\xfe\x05\x00 \x00\x00\x00\x00\x00\x00\x00\x00\x00\x00…        r1 load str located at 4295381888
    stxdw [r10-0x4d0], r1                   
    mov64 r1, 2                                     r1 = 2 as i32 as i64 as u64
    stxdw [r10-0x4c8], r1                   
    stxdw [r10-0x4b8], r1                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -1368                                 r1 += -1368   ///  r1 = r1.wrapping_add(-1368 as i32 as i64 as u64)
    stxdw [r10-0x4c0], r1                   
    lddw r1, 0x1000008a0 --> b"y\x11\x00\x00\x00\x00\x00\x00\x85\x10\x00\x00*\x99\x00\x00\x95\x00\x00\x0…        r1 load str located at 4294969504
    stxdw [r10-0x540], r1                   
    stxdw [r10-0x548], r6                   
    lddw r1, 0x10004d200 --> b"\xbf&\x00\x00\x00\x00\x00\x00y\x12\x00\x00\x00\x00\x00\x00y\x13\x08\x00\x…        r1 load str located at 4295283200
    stxdw [r10-0x550], r1                   
    stxdw [r10-0x558], r9                   
    ja lbb_14281                                    if true { pc += 137 }
lbb_14144:
    ldxdw r2, [r1+0x0]                      
    ldxdw r3, [r10-0x6b0]                   
    jeq r3, r2, lbb_14200                           if r3 == r2 { pc += 53 }
lbb_14147:
    mov64 r2, 1                                     r2 = 1 as i32 as i64 as u64
    jeq r2, 0, lbb_14150                            if r2 == (0 as i32 as i64 as u64) { pc += 1 }
    ja lbb_14211                                    if true { pc += 61 }
lbb_14150:
    ldxdw r2, [r10-0x700]                   
    add64 r2, -3                                    r2 += -3   ///  r2 = r2.wrapping_add(-3 as i32 as i64 as u64)
    jne r2, 2, lbb_14263                            if r2 != (2 as i32 as i64 as u64) { pc += 110 }
    stxdw [r10-0x6f0], r6                   
    ldxdw r6, [r6+0xa0]                     
    ldxdw r1, [r6+0x10]                     
    lddw r2, 0x7fffffffffffffff                     r2 load str located at 9223372036854775807
    jgt r2, r1, lbb_14160                           if r2 > r1 { pc += 1 }
    ja lbb_14305                                    if true { pc += 145 }
lbb_14160:
    add64 r1, 1                                     r1 += 1   ///  r1 = r1.wrapping_add(1 as i32 as i64 as u64)
    stxdw [r6+0x10], r1                     
    mov64 r7, 3                                     r7 = 3 as i32 as i64 as u64
    ldxdw r1, [r6+0x20]                     
    jne r1, 165, lbb_14173                          if r1 != (165 as i32 as i64 as u64) { pc += 8 }
    ldxdw r2, [r6+0x18]                     
    mov64 r1, r10                                   r1 = r10
    add64 r1, -680                                  r1 += -680   ///  r1 = r1.wrapping_add(-680 as i32 as i64 as u64)
    mov64 r3, 165                                   r3 = 165 as i32 as i64 as u64
    call function_32610                     
    ldxw r7, [r10-0x2a8]                    
    ldxw r1, [r10-0x220]                    
    jne r1, 2, lbb_14231                            if r1 != (2 as i32 as i64 as u64) { pc += 58 }
lbb_14173:
    ldxdw r1, [r10-0x2a4]                   
    stxdw [r10-0x3b8], r1                   
    ldxdw r1, [r10-0x29c]                   
    stxdw [r10-0x3b0], r1                   
    ldxdw r1, [r10-0x294]                   
    stxdw [r10-0x3a8], r1                   
    ldxw r1, [r10-0x28c]                    
    stxw [r10-0x540], r1                    
    stxw [r10-0x3a0], r1                    
lbb_14182:
    ldxw r1, [r10-0x3a0]                    
    stxw [r10-0x408], r1                    
    ldxdw r2, [r10-0x3a8]                   
    stxdw [r10-0x410], r2                   
    ldxdw r3, [r10-0x3b0]                   
    stxdw [r10-0x418], r3                   
    ldxdw r4, [r10-0x3b8]                   
    stxdw [r10-0x420], r4                   
    ldxdw r5, [r10-0x6e8]                   
    stxw [r5+0x1c], r1                      
    stxdw [r5+0x14], r2                     
    stxdw [r5+0xc], r3                      
    stxdw [r5+0x4], r4                      
    stxw [r5+0x0], r7                       
    ldxdw r1, [r6+0x10]                     
    add64 r1, -1                                    r1 += -1   ///  r1 = r1.wrapping_add(-1 as i32 as i64 as u64)
    stxdw [r6+0x10], r1                     
    ja lbb_14292                                    if true { pc += 92 }
lbb_14200:
    ldxdw r2, [r1+0x8]                      
    ldxdw r3, [r10-0x6a8]                   
    jne r3, r2, lbb_14147                           if r3 != r2 { pc += -56 }
    ldxdw r2, [r1+0x10]                     
    ldxdw r3, [r10-0x6a0]                   
    jne r3, r2, lbb_14147                           if r3 != r2 { pc += -59 }
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
    ldxdw r1, [r1+0x18]                     
    ldxdw r3, [r10-0x698]                   
    jne r3, r1, lbb_14147                           if r3 != r1 { pc += -63 }
    jeq r2, 0, lbb_14150                            if r2 == (0 as i32 as i64 as u64) { pc += -61 }
lbb_14211:
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    stxdw [r10-0x4b0], r1                   
    lddw r1, 0x1000653a0 --> b"\x00\x00\x00\x00\x90\xfe\x05\x00 \x00\x00\x00\x00\x00\x00\x00\x00\x00\x00…        r1 load str located at 4295381920
    stxdw [r10-0x4d0], r1                   
    mov64 r1, 2                                     r1 = 2 as i32 as i64 as u64
    stxdw [r10-0x4c8], r1                   
    stxdw [r10-0x4b8], r1                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -1368                                 r1 += -1368   ///  r1 = r1.wrapping_add(-1368 as i32 as i64 as u64)
    stxdw [r10-0x4c0], r1                   
    lddw r1, 0x10004d200 --> b"\xbf&\x00\x00\x00\x00\x00\x00y\x12\x00\x00\x00\x00\x00\x00y\x13\x08\x00\x…        r1 load str located at 4295283200
    stxdw [r10-0x540], r1                   
    stxdw [r10-0x548], r8                   
    lddw r1, 0x1000008a0 --> b"y\x11\x00\x00\x00\x00\x00\x00\x85\x10\x00\x00*\x99\x00\x00\x95\x00\x00\x0…        r1 load str located at 4294969504
    stxdw [r10-0x550], r1                   
    stxdw [r10-0x558], r6                   
    ja lbb_14281                                    if true { pc += 50 }
lbb_14231:
    stxdw [r10-0x700], r1                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -1368                                 r1 += -1368   ///  r1 = r1.wrapping_add(-1368 as i32 as i64 as u64)
    stxdw [r10-0x6f8], r1                   
    mov64 r2, r10                                   r2 = r10
    add64 r2, -676                                  r2 += -676   ///  r2 = r2.wrapping_add(-676 as i32 as i64 as u64)
    mov64 r3, 104                                   r3 = 104 as i32 as i64 as u64
    call function_48190                     
    ldxdw r1, [r10-0x23b]                   
    stxdw [r10-0x578], r1                   
    ldxdw r1, [r10-0x233]                   
    stxdw [r10-0x570], r1                   
    ldxdw r1, [r10-0x22b]                   
    stxdw [r10-0x568], r1                   
    ldxw r1, [r10-0x224]                    
    stxw [r10-0x561], r1                    
    ldxb r8, [r10-0x23c]                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -280                                  r1 += -280   ///  r1 = r1.wrapping_add(-280 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -540                                  r2 += -540   ///  r2 = r2.wrapping_add(-540 as i32 as i64 as u64)
    mov64 r3, 36                                    r3 = 36 as i32 as i64 as u64
    call function_48190                     
    mov64 r1, r10                                   r1 = r10
    add64 r1, -1536                                 r1 += -1536   ///  r1 = r1.wrapping_add(-1536 as i32 as i64 as u64)
    ldxdw r2, [r10-0x6f8]                   
    mov64 r3, 104                                   r3 = 104 as i32 as i64 as u64
    call function_48190                     
    stxdw [r10-0x6f8], r8                   
    jne r8, 0, lbb_14309                            if r8 != (0 as i32 as i64 as u64) { pc += 48 }
    mov64 r7, 9                                     r7 = 9 as i32 as i64 as u64
    ja lbb_14182                                    if true { pc += -81 }
lbb_14263:
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    stxdw [r10-0x4b0], r1                   
    lddw r1, 0x100065438 --> b"\x00\x00\x00\x00k\x0a\x06\x00*\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x0…        r1 load str located at 4295382072
    stxdw [r10-0x4d0], r1                   
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    stxdw [r10-0x4c8], r1                   
    stxdw [r10-0x4b8], r1                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -1368                                 r1 += -1368   ///  r1 = r1.wrapping_add(-1368 as i32 as i64 as u64)
    stxdw [r10-0x4c0], r1                   
    lddw r1, 0x10005df58 --> b"\xbf#\x00\x00\x00\x00\x00\x00y\x11\x00\x00\x00\x00\x00\x00\xb7\x02\x00\x0…        r1 load str located at 4295352152
    stxdw [r10-0x550], r1                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -1536                                 r1 += -1536   ///  r1 = r1.wrapping_add(-1536 as i32 as i64 as u64)
    stxdw [r10-0x558], r1                   
    stxdw [r10-0x600], r2                   
lbb_14281:
    mov64 r1, r10                                   r1 = r10
    add64 r1, -672                                  r1 += -672   ///  r1 = r1.wrapping_add(-672 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -1232                                 r2 += -1232   ///  r2 = r2.wrapping_add(-1232 as i32 as i64 as u64)
    call function_43415                     
lbb_14286:
    mov64 r1, 29                                    r1 = 29 as i32 as i64 as u64
    stxb [r10-0x2a8], r1                    
    mov64 r2, r10                                   r2 = r10
    add64 r2, -680                                  r2 += -680   ///  r2 = r2.wrapping_add(-680 as i32 as i64 as u64)
    ldxdw r1, [r10-0x6e8]                   
lbb_14291:
    call function_26067                     
lbb_14292:
    ldxdw r3, [r10-0x6d8]                   
    ldxdw r4, [r10-0x6e0]                   
    ldxdw r1, [r10-0x6c8]                   
    ldxdw r2, [r1+0x0]                      
    add64 r2, -1                                    r2 += -1   ///  r2 = r2.wrapping_add(-1 as i32 as i64 as u64)
    stxdw [r1+0x0], r2                      
lbb_14298:
    ldxdw r1, [r4+0x0]                      
    add64 r1, -1                                    r1 += -1   ///  r1 = r1.wrapping_add(-1 as i32 as i64 as u64)
    stxdw [r4+0x0], r1                      
    ldxdw r1, [r3+0x0]                      
    add64 r1, -1                                    r1 += -1   ///  r1 = r1.wrapping_add(-1 as i32 as i64 as u64)
    stxdw [r3+0x0], r1                      
lbb_14304:
    exit                                    
lbb_14305:
    lddw r1, 0x100065420 --> b"\x00\x00\x00\x00G\x0a\x06\x00$\x00\x00\x00\x00\x00\x00\x00:\x00\x00\x00K\…        r1 load str located at 4295382048
    call function_43759                     
    syscall [invalid]                       
lbb_14309:
    mov64 r1, r10                                   r1 = r10
    add64 r1, -952                                  r1 += -952   ///  r1 = r1.wrapping_add(-952 as i32 as i64 as u64)
    stxdw [r10-0x728], r1                   
    mov64 r2, r10                                   r2 = r10
    add64 r2, -1536                                 r2 += -1536   ///  r2 = r2.wrapping_add(-1536 as i32 as i64 as u64)
    mov64 r3, 104                                   r3 = 104 as i32 as i64 as u64
    call function_48190                     
    ldxdw r1, [r10-0x578]                   
    stxdw [r10-0x463], r1                   
    ldxdw r1, [r10-0x570]                   
    stxdw [r10-0x45b], r1                   
    ldxdw r1, [r10-0x568]                   
    stxdw [r10-0x453], r1                   
    ldxw r1, [r10-0x561]                    
    stxw [r10-0x44c], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -1092                                 r1 += -1092   ///  r1 = r1.wrapping_add(-1092 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -280                                  r2 += -280   ///  r2 = r2.wrapping_add(-280 as i32 as i64 as u64)
    mov64 r3, 36                                    r3 = 36 as i32 as i64 as u64
    call function_48190                     
    mov64 r8, r10                                   r8 = r10
    add64 r8, -1056                                 r8 += -1056   ///  r8 = r8.wrapping_add(-1056 as i32 as i64 as u64)
    mov64 r1, r8                                    r1 = r8
    ldxdw r2, [r10-0x728]                   
    mov64 r3, 104                                   r3 = 104 as i32 as i64 as u64
    call function_48190                     
    mov64 r1, r10                                   r1 = r10
    add64 r1, -1228                                 r1 += -1228   ///  r1 = r1.wrapping_add(-1228 as i32 as i64 as u64)
    mov64 r2, r8                                    r2 = r8
    mov64 r3, 104                                   r3 = 104 as i32 as i64 as u64
    call function_48190                     
    ldxdw r1, [r10-0x700]                   
    stxw [r10-0x448], r1                    
    ldxdw r1, [r10-0x6f8]                   
    stxb [r10-0x464], r1                    
    stxw [r10-0x4d0], r7                    
    ldxdw r1, [r6+0x10]                     
    add64 r1, -1                                    r1 += -1   ///  r1 = r1.wrapping_add(-1 as i32 as i64 as u64)
    stxdw [r6+0x10], r1                     
    ldxdw r1, [r9+0x0]                      
    ldxdw r2, [r10-0x4d0]                   
    jeq r2, r1, lbb_14354                           if r2 == r1 { pc += 2 }
lbb_14352:
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    ja lbb_14364                                    if true { pc += 10 }
lbb_14354:
    ldxdw r1, [r9+0x8]                      
    ldxdw r2, [r10-0x4c8]                   
    jne r2, r1, lbb_14352                           if r2 != r1 { pc += -5 }
    ldxdw r1, [r9+0x10]                     
    ldxdw r2, [r10-0x4c0]                   
    jne r2, r1, lbb_14352                           if r2 != r1 { pc += -8 }
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    ldxdw r2, [r9+0x18]                     
    ldxdw r3, [r10-0x4b8]                   
    jne r3, r2, lbb_14352                           if r3 != r2 { pc += -12 }
lbb_14364:
    ldxdw r5, [r10-0x6f0]                   
    ldxdw r4, [r10-0x710]                   
    jeq r1, 0, lbb_14392                            if r1 == (0 as i32 as i64 as u64) { pc += 25 }
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    stxdw [r10-0x538], r1                   
    lddw r1, 0x100065380 --> b"\x00\x00\x00\x00\x90\xfe\x05\x00 \x00\x00\x00\x00\x00\x00\x00\x00\x00\x00…        r1 load str located at 4295381888
    stxdw [r10-0x558], r1                   
    mov64 r1, 2                                     r1 = 2 as i32 as i64 as u64
    stxdw [r10-0x550], r1                   
    stxdw [r10-0x540], r1                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -1536                                 r1 += -1536   ///  r1 = r1.wrapping_add(-1536 as i32 as i64 as u64)
    stxdw [r10-0x548], r1                   
    stxdw [r10-0x5f0], r9                   
    lddw r1, 0x10004d200 --> b"\xbf&\x00\x00\x00\x00\x00\x00y\x12\x00\x00\x00\x00\x00\x00y\x13\x08\x00\x…        r1 load str located at 4295283200
    stxdw [r10-0x5e8], r1                   
    stxdw [r10-0x5f8], r1                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -1232                                 r1 += -1232   ///  r1 = r1.wrapping_add(-1232 as i32 as i64 as u64)
    stxdw [r10-0x600], r1                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -672                                  r1 += -672   ///  r1 = r1.wrapping_add(-672 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -1368                                 r2 += -1368   ///  r2 = r2.wrapping_add(-1368 as i32 as i64 as u64)
    call function_445                       
    ja lbb_14286                                    if true { pc += -106 }
lbb_14392:
    ldxdw r1, [r4+0x0]                      
    ldxdw r2, [r10-0x4b0]                   
    jeq r2, r1, lbb_14397                           if r2 == r1 { pc += 2 }
lbb_14395:
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    ja lbb_14407                                    if true { pc += 10 }
lbb_14397:
    ldxdw r1, [r4+0x8]                      
    ldxdw r2, [r10-0x4a8]                   
    jne r2, r1, lbb_14395                           if r2 != r1 { pc += -5 }
    ldxdw r1, [r4+0x10]                     
    ldxdw r2, [r10-0x4a0]                   
    jne r2, r1, lbb_14395                           if r2 != r1 { pc += -8 }
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    ldxdw r2, [r4+0x18]                     
    ldxdw r3, [r10-0x498]                   
    jne r3, r2, lbb_14395                           if r3 != r2 { pc += -12 }
lbb_14407:
    ldxdw r8, [r10-0x6e8]                   
    jeq r1, 0, lbb_14439                            if r1 == (0 as i32 as i64 as u64) { pc += 30 }
    mov64 r1, r10                                   r1 = r10
    add64 r1, -1200                                 r1 += -1200   ///  r1 = r1.wrapping_add(-1200 as i32 as i64 as u64)
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
    stxdw [r10-0x538], r2                   
    lddw r2, 0x1000653c0 --> b"\x00\x00\x00\x00\xcc\x09\x06\x002\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00…        r2 load str located at 4295381952
    stxdw [r10-0x558], r2                   
    mov64 r2, 2                                     r2 = 2 as i32 as i64 as u64
    stxdw [r10-0x550], r2                   
    stxdw [r10-0x540], r2                   
    mov64 r2, r10                                   r2 = r10
    add64 r2, -1536                                 r2 += -1536   ///  r2 = r2.wrapping_add(-1536 as i32 as i64 as u64)
    stxdw [r10-0x548], r2                   
    stxdw [r10-0x5f0], r4                   
    lddw r2, 0x10004d200 --> b"\xbf&\x00\x00\x00\x00\x00\x00y\x12\x00\x00\x00\x00\x00\x00y\x13\x08\x00\x…        r2 load str located at 4295283200
    stxdw [r10-0x5e8], r2                   
    stxdw [r10-0x5f8], r2                   
lbb_14427:
    stxdw [r10-0x600], r1                   
lbb_14428:
    mov64 r1, r10                                   r1 = r10
    add64 r1, -672                                  r1 += -672   ///  r1 = r1.wrapping_add(-672 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -1368                                 r2 += -1368   ///  r2 = r2.wrapping_add(-1368 as i32 as i64 as u64)
    call function_445                       
    mov64 r1, 29                                    r1 = 29 as i32 as i64 as u64
    stxb [r10-0x2a8], r1                    
    mov64 r2, r10                                   r2 = r10
    add64 r2, -680                                  r2 += -680   ///  r2 = r2.wrapping_add(-680 as i32 as i64 as u64)
    mov64 r1, r8                                    r1 = r8
    ja lbb_14291                                    if true { pc += -148 }
lbb_14439:
    ldxdw r2, [r5+0xc0]                     
    ldxdw r3, [r2+0x0]                      
    ldxdw r1, [r5+0xa8]                     
    ldxdw r4, [r1+0x0]                      
    jeq r4, r3, lbb_14446                           if r4 == r3 { pc += 2 }
lbb_14444:
    mov64 r3, 1                                     r3 = 1 as i32 as i64 as u64
    ja lbb_14456                                    if true { pc += 10 }
lbb_14446:
    ldxdw r3, [r2+0x8]                      
    ldxdw r4, [r1+0x8]                      
    jne r4, r3, lbb_14444                           if r4 != r3 { pc += -5 }
    ldxdw r3, [r2+0x10]                     
    ldxdw r4, [r1+0x10]                     
    jne r4, r3, lbb_14444                           if r4 != r3 { pc += -8 }
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
    ldxdw r4, [r2+0x18]                     
    ldxdw r1, [r1+0x18]                     
    jne r1, r4, lbb_14444                           if r1 != r4 { pc += -12 }
lbb_14456:
    mov64 r1, r5                                    r1 = r5
    add64 r1, 192                                   r1 += 192   ///  r1 = r1.wrapping_add(192 as i32 as i64 as u64)
    jeq r3, 0, lbb_14478                            if r3 == (0 as i32 as i64 as u64) { pc += 19 }
    add64 r5, 168                                   r5 += 168   ///  r5 = r5.wrapping_add(168 as i32 as i64 as u64)
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
    stxdw [r10-0x538], r2                   
    lddw r2, 0x1000653e0 --> b"\x00\x00\x00\x00\xcc\x09\x06\x002\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00…        r2 load str located at 4295381984
    stxdw [r10-0x558], r2                   
    mov64 r2, 2                                     r2 = 2 as i32 as i64 as u64
    stxdw [r10-0x550], r2                   
    stxdw [r10-0x540], r2                   
    mov64 r2, r10                                   r2 = r10
    add64 r2, -1536                                 r2 += -1536   ///  r2 = r2.wrapping_add(-1536 as i32 as i64 as u64)
    stxdw [r10-0x548], r2                   
    stxdw [r10-0x5f0], r1                   
    lddw r1, 0x1000008a0 --> b"y\x11\x00\x00\x00\x00\x00\x00\x85\x10\x00\x00*\x99\x00\x00\x95\x00\x00\x0…        r1 load str located at 4294969504
    stxdw [r10-0x5e8], r1                   
    stxdw [r10-0x5f8], r1                   
    stxdw [r10-0x600], r5                   
    ja lbb_14428                                    if true { pc += -50 }
lbb_14478:
    ldxdw r6, [r10-0x6b8]                   
    ldxdw r4, [r2+0x0]                      
    ldxdw r3, [r6+0x18]                     
    ldxdw r5, [r3+0x0]                      
    jeq r5, r4, lbb_14485                           if r5 == r4 { pc += 2 }
lbb_14483:
    mov64 r4, 1                                     r4 = 1 as i32 as i64 as u64
    ja lbb_14495                                    if true { pc += 10 }
lbb_14485:
    ldxdw r4, [r2+0x8]                      
    ldxdw r5, [r3+0x8]                      
    jne r5, r4, lbb_14483                           if r5 != r4 { pc += -5 }
    ldxdw r4, [r2+0x10]                     
    ldxdw r5, [r3+0x10]                     
    jne r5, r4, lbb_14483                           if r5 != r4 { pc += -8 }
    mov64 r4, 0                                     r4 = 0 as i32 as i64 as u64
    ldxdw r5, [r2+0x18]                     
    ldxdw r3, [r3+0x18]                     
    jne r3, r5, lbb_14483                           if r3 != r5 { pc += -12 }
lbb_14495:
    jeq r4, 0, lbb_14515                            if r4 == (0 as i32 as i64 as u64) { pc += 19 }
    add64 r6, 24                                    r6 += 24   ///  r6 = r6.wrapping_add(24 as i32 as i64 as u64)
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
    stxdw [r10-0x538], r2                   
    lddw r2, 0x1000653e0 --> b"\x00\x00\x00\x00\xcc\x09\x06\x002\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00…        r2 load str located at 4295381984
    stxdw [r10-0x558], r2                   
    mov64 r2, 2                                     r2 = 2 as i32 as i64 as u64
    stxdw [r10-0x550], r2                   
    stxdw [r10-0x540], r2                   
    mov64 r2, r10                                   r2 = r10
    add64 r2, -1536                                 r2 += -1536   ///  r2 = r2.wrapping_add(-1536 as i32 as i64 as u64)
    stxdw [r10-0x548], r2                   
    stxdw [r10-0x5f0], r1                   
    lddw r1, 0x1000008a0 --> b"y\x11\x00\x00\x00\x00\x00\x00\x85\x10\x00\x00*\x99\x00\x00\x95\x00\x00\x0…        r1 load str located at 4294969504
    stxdw [r10-0x5e8], r1                   
    stxdw [r10-0x5f8], r1                   
    stxdw [r10-0x600], r6                   
    ja lbb_14428                                    if true { pc += -87 }
lbb_14515:
    ldxdw r3, [r10-0x670]                   
    mov64 r1, r3                                    r1 = r3
    ldxdw r4, [r10-0x708]                   
    jeq r4, 0, lbb_14520                            if r4 == (0 as i32 as i64 as u64) { pc += 1 }
    ldxdw r1, [r10-0x718]                   
lbb_14520:
    stxdw [r10-0x118], r1                   
    ldxdw r4, [r10-0x6f0]                   
    jge r3, r1, lbb_14544                           if r3 >= r1 { pc += 21 }
    mov64 r1, r10                                   r1 = r10
    add64 r1, -1648                                 r1 += -1648   ///  r1 = r1.wrapping_add(-1648 as i32 as i64 as u64)
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
    stxdw [r10-0x538], r2                   
    lddw r2, 0x100065400 --> b"\x00\x00\x00\x00\x0a\x0a\x06\x00&\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00…        r2 load str located at 4295382016
    stxdw [r10-0x558], r2                   
    mov64 r2, 2                                     r2 = 2 as i32 as i64 as u64
    stxdw [r10-0x550], r2                   
    stxdw [r10-0x540], r2                   
    mov64 r2, r10                                   r2 = r10
    add64 r2, -1536                                 r2 += -1536   ///  r2 = r2.wrapping_add(-1536 as i32 as i64 as u64)
    stxdw [r10-0x548], r2                   
    stxdw [r10-0x5f0], r1                   
    lddw r1, 0x10005df58 --> b"\xbf#\x00\x00\x00\x00\x00\x00y\x11\x00\x00\x00\x00\x00\x00\xb7\x02\x00\x0…        r1 load str located at 4295352152
    stxdw [r10-0x5e8], r1                   
    stxdw [r10-0x5f8], r1                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -280                                  r1 += -280   ///  r1 = r1.wrapping_add(-280 as i32 as i64 as u64)
    ja lbb_14427                                    if true { pc += -117 }
lbb_14544:
    ldxdw r4, [r4+0x90]                     
    ldxdw r3, [r6+0x0]                      
    ldxdw r5, [r10-0x6c0]                   
    ldxdw r5, [r5+0x0]                      
    mov64 r0, 0                                     r0 = 0 as i32 as i64 as u64
    stxdw [r10-0xff0], r0                   
    stxdw [r10-0xfe8], r1                   
    lddw r1, 0x10005fa70 --> b"src/arithmetic_impls.rsSubtraction overflowedsrc/d"        r1 load str located at 4295359088
    stxdw [r10-0xff8], r1                   
    stxdw [r10-0x1000], r5                  
    mov64 r1, r10                                   r1 = r10
    add64 r1, -680                                  r1 += -680   ///  r1 = r1.wrapping_add(-680 as i32 as i64 as u64)
    mov64 r5, r10                                   r5 = r10
    call function_32068                     
    ldxdw r7, [r10-0x2a8]                   
    jeq r7, 0, lbb_14820                            if r7 == (0 as i32 as i64 as u64) { pc += 259 }
    ldxdw r1, [r10-0x288]                   
    stxdw [r10-0x5e8], r1                   
    ldxdw r1, [r10-0x290]                   
    stxdw [r10-0x5f0], r1                   
    ldxdw r1, [r10-0x298]                   
    stxdw [r10-0x5f8], r1                   
    ldxdw r1, [r10-0x2a0]                   
    stxdw [r10-0x600], r1                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -1328                                 r1 += -1328   ///  r1 = r1.wrapping_add(-1328 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -640                                  r2 += -640   ///  r2 = r2.wrapping_add(-640 as i32 as i64 as u64)
    mov64 r3, 40                                    r3 = 40 as i32 as i64 as u64
    call function_48190                     
    stxdw [r10-0x558], r7                   
    ldxdw r1, [r10-0x600]                   
    stxdw [r10-0x550], r1                   
    ldxdw r1, [r10-0x5f8]                   
    stxdw [r10-0x548], r1                   
    ldxdw r1, [r10-0x5f0]                   
    stxdw [r10-0x540], r1                   
    ldxdw r1, [r10-0x5e8]                   
    stxdw [r10-0x538], r1                   
    ldxdw r4, [r6+0x8]                      
    ldxdw r1, [r4+0x0]                      
    add64 r1, 1                                     r1 += 1   ///  r1 = r1.wrapping_add(1 as i32 as i64 as u64)
    mov64 r2, 1                                     r2 = 1 as i32 as i64 as u64
    jeq r1, 0, lbb_14590                            if r1 == (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
lbb_14590:
    ldxdw r8, [r6+0x0]                      
    stxdw [r4+0x0], r1                      
    ldxdw r5, [r10-0x6f0]                   
    jne r2, 1, lbb_14596                            if r2 != (1 as i32 as i64 as u64) { pc += 2 }
lbb_14594:
    syscall [invalid]                       
    syscall [invalid]                       
lbb_14596:
    ldxdw r9, [r6+0x10]                     
    ldxdw r1, [r9+0x0]                      
    add64 r1, 1                                     r1 += 1   ///  r1 = r1.wrapping_add(1 as i32 as i64 as u64)
    mov64 r2, 1                                     r2 = 1 as i32 as i64 as u64
    jeq r1, 0, lbb_14602                            if r1 == (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
lbb_14602:
    stxdw [r9+0x0], r1                      
    jne r2, 1, lbb_14605                            if r2 != (1 as i32 as i64 as u64) { pc += 1 }
    ja lbb_14594                                    if true { pc += -11 }
lbb_14605:
    ldxdw r0, [r5+0x98]                     
    ldxdw r1, [r0+0x0]                      
    add64 r1, 1                                     r1 += 1   ///  r1 = r1.wrapping_add(1 as i32 as i64 as u64)
    mov64 r2, 1                                     r2 = 1 as i32 as i64 as u64
    jeq r1, 0, lbb_14611                            if r1 == (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
lbb_14611:
    ldxdw r3, [r5+0x90]                     
    stxdw [r10-0x710], r3                   
    ldxb r3, [r6+0x2a]                      
    stxdw [r10-0x708], r3                   
    ldxb r3, [r6+0x29]                      
    stxdw [r10-0x700], r3                   
    ldxb r7, [r6+0x28]                      
    ldxdw r3, [r6+0x20]                     
    ldxdw r6, [r6+0x18]                     
    stxdw [r0+0x0], r1                      
    jne r2, 1, lbb_14623                            if r2 != (1 as i32 as i64 as u64) { pc += 1 }
    ja lbb_14594                                    if true { pc += -29 }
lbb_14623:
    ldxdw r1, [r5+0xa0]                     
    stxdw [r10-0x6f8], r1                   
    ldxdw r1, [r1+0x0]                      
    add64 r1, 1                                     r1 += 1   ///  r1 = r1.wrapping_add(1 as i32 as i64 as u64)
    mov64 r2, 1                                     r2 = 1 as i32 as i64 as u64
    jeq r1, 0, lbb_14630                            if r1 == (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
lbb_14630:
    stxdw [r10-0x728], r7                   
    stxdw [r10-0x718], r3                   
    ldxdw r3, [r10-0x6f8]                   
    stxdw [r3+0x0], r1                      
    jne r2, 1, lbb_14636                            if r2 != (1 as i32 as i64 as u64) { pc += 1 }
    ja lbb_14594                                    if true { pc += -42 }
lbb_14636:
    ldxdw r7, [r10-0x6c0]                   
    ldxdw r2, [r7+0x8]                      
    ldxdw r1, [r2+0x0]                      
    add64 r1, 1                                     r1 += 1   ///  r1 = r1.wrapping_add(1 as i32 as i64 as u64)
    mov64 r3, 1                                     r3 = 1 as i32 as i64 as u64
    jeq r1, 0, lbb_14643                            if r1 == (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
lbb_14643:
    stxdw [r10-0x730], r0                   
    ldxb r0, [r5+0xba]                      
    stxdw [r10-0x758], r0                   
    ldxb r0, [r5+0xb9]                      
    stxdw [r10-0x750], r0                   
    ldxb r0, [r5+0xb8]                      
    stxdw [r10-0x748], r0                   
    ldxdw r0, [r5+0xb0]                     
    stxdw [r10-0x740], r0                   
    ldxdw r0, [r5+0xa8]                     
    stxdw [r10-0x738], r0                   
    ldxdw r0, [r7+0x0]                      
    stxdw [r10-0x760], r0                   
    stxdw [r2+0x0], r1                      
    jne r3, 1, lbb_14659                            if r3 != (1 as i32 as i64 as u64) { pc += 1 }
    ja lbb_14594                                    if true { pc += -65 }
lbb_14659:
    ldxdw r0, [r7+0x10]                     
    ldxdw r1, [r0+0x0]                      
    add64 r1, 1                                     r1 += 1   ///  r1 = r1.wrapping_add(1 as i32 as i64 as u64)
    mov64 r3, 1                                     r3 = 1 as i32 as i64 as u64
    jeq r1, 0, lbb_14665                            if r1 == (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
lbb_14665:
    stxdw [r10-0x768], r6                   
    stxdw [r0+0x0], r1                      
    jne r3, 1, lbb_14669                            if r3 != (1 as i32 as i64 as u64) { pc += 1 }
    ja lbb_14594                                    if true { pc += -75 }
lbb_14669:
    stxdw [r10-0x778], r9                   
    stxdw [r10-0x770], r8                   
    ldxdw r8, [r5+0xc8]                     
    ldxdw r6, [r8+0x0]                      
    add64 r6, 1                                     r6 += 1   ///  r6 = r6.wrapping_add(1 as i32 as i64 as u64)
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    jeq r6, 0, lbb_14677                            if r6 == (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
lbb_14677:
    ldxdw r3, [r5+0xc0]                     
    stxdw [r10-0x7a0], r3                   
    ldxb r3, [r7+0x2a]                      
    stxdw [r10-0x798], r3                   
    ldxb r3, [r7+0x29]                      
    stxdw [r10-0x790], r3                   
    ldxb r3, [r7+0x28]                      
    stxdw [r10-0x788], r3                   
    ldxdw r3, [r7+0x20]                     
    stxdw [r10-0x780], r3                   
    ldxdw r9, [r7+0x18]                     
    stxdw [r8+0x0], r6                      
    jne r1, 1, lbb_14691                            if r1 != (1 as i32 as i64 as u64) { pc += 1 }
    ja lbb_14594                                    if true { pc += -97 }
lbb_14691:
    ldxdw r6, [r5+0xd0]                     
    ldxdw r1, [r6+0x0]                      
    add64 r1, 1                                     r1 += 1   ///  r1 = r1.wrapping_add(1 as i32 as i64 as u64)
    mov64 r3, 1                                     r3 = 1 as i32 as i64 as u64
    jeq r1, 0, lbb_14697                            if r1 == (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
lbb_14697:
    stxdw [r10-0x7a8], r4                   
    stxdw [r6+0x0], r1                      
    jne r3, 1, lbb_14701                            if r3 != (1 as i32 as i64 as u64) { pc += 1 }
    ja lbb_14594                                    if true { pc += -107 }
lbb_14701:
    ldxdw r1, [r5+0xd8]                     
    ldxdw r3, [r5+0xe0]                     
    ldxb r4, [r5+0xe8]                      
    mov64 r7, r5                                    r7 = r5
    ldxb r5, [r7+0xe9]                      
    ldxb r7, [r7+0xea]                      
    stxb [r10-0x1ee], r7                    
    stxb [r10-0x1ef], r5                    
    stxb [r10-0x1f0], r4                    
    stxdw [r10-0x1f8], r3                   
    stxdw [r10-0x200], r1                   
    stxdw [r10-0x208], r6                   
    stxdw [r10-0x210], r8                   
    ldxdw r1, [r10-0x7a0]                   
    stxdw [r10-0x218], r1                   
    ldxdw r1, [r10-0x798]                   
    stxb [r10-0x21e], r1                    
    ldxdw r1, [r10-0x790]                   
    stxb [r10-0x21f], r1                    
    ldxdw r1, [r10-0x788]                   
    stxb [r10-0x220], r1                    
    ldxdw r1, [r10-0x780]                   
    stxdw [r10-0x228], r1                   
    stxdw [r10-0x230], r9                   
    stxdw [r10-0x238], r0                   
    stxdw [r10-0x240], r2                   
    ldxdw r1, [r10-0x760]                   
    stxdw [r10-0x248], r1                   
    ldxdw r1, [r10-0x758]                   
    stxb [r10-0x24e], r1                    
    ldxdw r1, [r10-0x750]                   
    stxb [r10-0x24f], r1                    
    ldxdw r1, [r10-0x748]                   
    stxb [r10-0x250], r1                    
    ldxdw r1, [r10-0x740]                   
    stxdw [r10-0x258], r1                   
    ldxdw r1, [r10-0x738]                   
    stxdw [r10-0x260], r1                   
    ldxdw r1, [r10-0x6f8]                   
    stxdw [r10-0x268], r1                   
    ldxdw r1, [r10-0x730]                   
    stxdw [r10-0x270], r1                   
    ldxdw r1, [r10-0x710]                   
    stxdw [r10-0x278], r1                   
    ldxdw r1, [r10-0x708]                   
    stxb [r10-0x27e], r1                    
    ldxdw r1, [r10-0x700]                   
    stxb [r10-0x27f], r1                    
    ldxdw r1, [r10-0x728]                   
    stxb [r10-0x280], r1                    
    ldxdw r1, [r10-0x718]                   
    stxdw [r10-0x288], r1                   
    ldxdw r1, [r10-0x768]                   
    stxdw [r10-0x290], r1                   
    ldxdw r1, [r10-0x778]                   
    stxdw [r10-0x298], r1                   
    ldxdw r1, [r10-0x7a8]                   
    stxdw [r10-0x2a0], r1                   
    ldxdw r1, [r10-0x770]                   
    stxdw [r10-0x2a8], r1                   
    ldxdw r1, [r10-0x6d0]                   
    ldxb r2, [r1+0x418]                     
    mov64 r3, r10                                   r3 = r10
    add64 r3, -1400                                 r3 += -1400   ///  r3 = r3.wrapping_add(-1400 as i32 as i64 as u64)
    stxdw [r10-0x5d0], r3                   
    add64 r1, 952                                   r1 += 952   ///  r1 = r1.wrapping_add(952 as i32 as i64 as u64)
    stxdw [r10-0x5e0], r1                   
    mov64 r1, 32                                    r1 = 32 as i32 as i64 as u64
    stxdw [r10-0x5d8], r1                   
    stxdw [r10-0x5e8], r1                   
    ldxdw r1, [r10-0x720]                   
    stxdw [r10-0x5f0], r1                   
    lddw r1, 0x10005fbb0 --> b"coin\x1c\x00\x00\x00GoodKindkindbids != Some <= x1e-true to No"        r1 load str located at 4295359408
    stxdw [r10-0x600], r1                   
    stxb [r10-0x578], r2                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -1536                                 r1 += -1536   ///  r1 = r1.wrapping_add(-1536 as i32 as i64 as u64)
    stxdw [r10-0x420], r1                   
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    stxdw [r10-0x5c8], r1                   
    mov64 r2, 4                                     r2 = 4 as i32 as i64 as u64
    stxdw [r10-0x5f8], r2                   
    stxdw [r10-0x418], r2                   
    mov64 r2, r10                                   r2 = r10
    add64 r2, -1056                                 r2 += -1056   ///  r2 = r2.wrapping_add(-1056 as i32 as i64 as u64)
    stxdw [r10-0x1000], r2                  
    stxdw [r10-0xff8], r1                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -952                                  r1 += -952   ///  r1 = r1.wrapping_add(-952 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -1368                                 r2 += -1368   ///  r2 = r2.wrapping_add(-1368 as i32 as i64 as u64)
    mov64 r3, r10                                   r3 = r10
    add64 r3, -680                                  r3 += -680   ///  r3 = r3.wrapping_add(-680 as i32 as i64 as u64)
    mov64 r5, r10                                   r5 = r10
    mov64 r4, 4                                     r4 = 4 as i32 as i64 as u64
    call function_40377                     
    ldxw r1, [r10-0x3b8]                    
    jeq r1, 24, lbb_14801                           if r1 == (24 as i32 as i64 as u64) { pc += 1 }
    ja lbb_14833                                    if true { pc += 32 }
lbb_14801:
    mov64 r1, r10                                   r1 = r10
    add64 r1, -680                                  r1 += -680   ///  r1 = r1.wrapping_add(-680 as i32 as i64 as u64)
    call function_369                       
    mov64 r1, 24                                    r1 = 24 as i32 as i64 as u64
    ldxdw r2, [r10-0x6e8]                   
    stxw [r2+0x0], r1                       
    ldxdw r1, [r10-0x6c8]                   
    ldxdw r2, [r1+0x0]                      
    add64 r2, -1                                    r2 += -1   ///  r2 = r2.wrapping_add(-1 as i32 as i64 as u64)
    stxdw [r1+0x0], r2                      
    ldxdw r2, [r10-0x6e0]                   
    ldxdw r1, [r2+0x0]                      
    add64 r1, -1                                    r1 += -1   ///  r1 = r1.wrapping_add(-1 as i32 as i64 as u64)
    stxdw [r2+0x0], r1                      
    ldxdw r2, [r10-0x6d8]                   
    ldxdw r1, [r2+0x0]                      
    add64 r1, -1                                    r1 += -1   ///  r1 = r1.wrapping_add(-1 as i32 as i64 as u64)
    stxdw [r2+0x0], r1                      
    ja lbb_14304                                    if true { pc += -516 }
lbb_14820:
    ldxdw r1, [r10-0x288]                   
    stxdw [r10-0x5e8], r1                   
    ldxdw r2, [r10-0x290]                   
    stxdw [r10-0x5f0], r2                   
    ldxdw r3, [r10-0x298]                   
    stxdw [r10-0x5f8], r3                   
    ldxdw r4, [r10-0x2a0]                   
    stxdw [r10-0x600], r4                   
    stxdw [r8+0x18], r1                     
    stxdw [r8+0x10], r2                     
    stxdw [r8+0x8], r3                      
    stxdw [r8+0x0], r4                      
    ja lbb_14292                                    if true { pc += -541 }
lbb_14833:
    ldxw r2, [r10-0x39c]                    
    ldxdw r3, [r10-0x6e8]                   
    stxw [r3+0x1c], r2                      
    ldxdw r2, [r10-0x3a4]                   
    stxdw [r3+0x14], r2                     
    ldxdw r2, [r10-0x3ac]                   
    stxdw [r3+0xc], r2                      
    ldxdw r2, [r10-0x3b4]                   
    stxdw [r3+0x4], r2                      
    stxw [r3+0x0], r1                       
    mov64 r1, r10                                   r1 = r10
    add64 r1, -680                                  r1 += -680   ///  r1 = r1.wrapping_add(-680 as i32 as i64 as u64)
    call function_369                       
    ja lbb_14292                                    if true { pc += -555 }

function_14847:
    mov64 r7, r5                                    r7 = r5
    stxdw [r10-0x100], r4                   
    mov64 r8, r3                                    r8 = r3
    stxdw [r10-0x108], r2                   
    mov64 r6, r1                                    r6 = r1
    ldxdw r9, [r7-0xff8]                    
    mov64 r1, r9                                    r1 = r9
    call function_39132                     
    ldxdw r7, [r7-0x1000]                   
    jne r0, 0, lbb_14860                            if r0 != (0 as i32 as i64 as u64) { pc += 3 }
    mov64 r1, r9                                    r1 = r9
    call function_39148                     
    jne r0, 0, lbb_14903                            if r0 != (0 as i32 as i64 as u64) { pc += 43 }
lbb_14860:
    ldxb r1, [r9+0x29]                      
    jeq r1, 0, lbb_14890                            if r1 == (0 as i32 as i64 as u64) { pc += 28 }
    mov64 r1, r10                                   r1 = r10
    add64 r1, -248                                  r1 += -248   ///  r1 = r1.wrapping_add(-248 as i32 as i64 as u64)
    mov64 r2, r9                                    r2 = r9
    call function_39192                     
    ldxw r4, [r10-0xf8]                     
    jne r4, 24, lbb_14897                           if r4 != (24 as i32 as i64 as u64) { pc += 29 }
    ldxdw r0, [r10-0xe8]                    
    ldxdw r2, [r10-0xf0]                    
    ldxdw r4, [r9+0x0]                      
    ldxdw r1, [r2+0x8]                      
    jne r1, 1056, lbb_14877                         if r1 != (1056 as i32 as i64 as u64) { pc += 4 }
    ldxdw r9, [r2+0x0]                      
    mov64 r2, r9                                    r2 = r9
    and64 r2, 7                                     r2 &= 7   ///  r2 = r2.and(7)
    jeq r2, 0, lbb_14937                            if r2 == (0 as i32 as i64 as u64) { pc += 60 }
lbb_14877:
    ldxdw r3, [r4+0x8]                      
    ldxdw r5, [r4+0x0]                      
    ldxdw r2, [r4+0x18]                     
    stxdw [r10-0x48], r2                    
    ldxdw r2, [r4+0x10]                     
    stxdw [r10-0x50], r2                    
    ldxdw r2, [r0+0x0]                      
    add64 r2, 1                                     r2 += 1   ///  r2 = r2.wrapping_add(1 as i32 as i64 as u64)
    stxdw [r0+0x0], r2                      
    mov64 r2, 35                                    r2 = 35 as i32 as i64 as u64
    mov64 r4, 1056                                  r4 = 1056 as i32 as i64 as u64
    mov64 r0, 0                                     r0 = 0 as i32 as i64 as u64
    ja lbb_14915                                    if true { pc += 25 }
lbb_14890:
    ldxdw r4, [r9+0x0]                      
    ldxw r1, [r4+0x3]                       
    stxw [r10-0x65], r1                     
    ldxw r1, [r4+0x0]                       
    stxw [r10-0x68], r1                     
    mov64 r2, 40                                    r2 = 40 as i32 as i64 as u64
    ja lbb_14909                                    if true { pc += 12 }
lbb_14897:
    mov64 r2, 55                                    r2 = 55 as i32 as i64 as u64
    ldxdw r1, [r10-0xf0]                    
    ldxdw r3, [r10-0xe0]                    
    ldxdw r5, [r10-0xe8]                    
    ldxw r0, [r10-0xf4]                     
    ja lbb_14915                                    if true { pc += 12 }
lbb_14903:
    ldxdw r4, [r9+0x0]                      
    ldxw r1, [r4+0x3]                       
    stxw [r10-0x65], r1                     
    ldxw r1, [r4+0x0]                       
    stxw [r10-0x68], r1                     
    mov64 r2, 37                                    r2 = 37 as i32 as i64 as u64
lbb_14909:
    ldxb r3, [r4+0x1f]                      
    ldxdw r5, [r4+0x17]                     
    ldxdw r1, [r4+0xf]                      
    ldxdw r4, [r4+0x7]                      
    mov64 r0, r4                                    r0 = r4
    rsh64 r0, 32                                    r0 >>= 32   ///  r0 = r0.wrapping_shr(32)
lbb_14915:
    ldxw r7, [r10-0x65]                     
    stxw [r6+0x4], r7                       
    ldxw r7, [r10-0x68]                     
    stxw [r6+0x1], r7                       
    ldxdw r7, [r10-0x50]                    
    stxdw [r6+0x28], r7                     
    ldxdw r7, [r10-0x48]                    
    stxdw [r6+0x30], r7                     
    ldxdw r7, [r10-0x40]                    
    stxdw [r6+0x38], r7                     
    ldxdw r7, [r10-0x38]                    
    stxdw [r6+0x40], r7                     
    stxdw [r6+0x20], r3                     
    stxdw [r6+0x18], r5                     
    stxdw [r6+0x10], r1                     
    lsh64 r0, 32                                    r0 <<= 32   ///  r0 = r0.wrapping_shl(32)
    lsh64 r4, 32                                    r4 <<= 32   ///  r4 = r4.wrapping_shl(32)
    rsh64 r4, 32                                    r4 >>= 32   ///  r4 = r4.wrapping_shr(32)
    or64 r0, r4                                     r0 |= r4   ///  r0 = r0.or(r4)
    stxdw [r6+0x8], r0                      
    stxb [r6+0x0], r2                       
lbb_14936:
    exit                                    
lbb_14937:
    stxdw [r10-0x110], r0                   
    stxdw [r10-0x118], r4                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -248                                  r1 += -248   ///  r1 = r1.wrapping_add(-248 as i32 as i64 as u64)
    mov64 r2, r8                                    r2 = r8
    mov64 r3, r7                                    r3 = r7
    call function_24960                     
    ldxb r8, [r10-0xf8]                     
    jeq r8, 56, lbb_14947                           if r8 == (56 as i32 as i64 as u64) { pc += 1 }
    ja lbb_15263                                    if true { pc += 316 }
lbb_14947:
    mov64 r8, r9                                    r8 = r9
    add64 r8, 1016                                  r8 += 1016   ///  r8 = r8.wrapping_add(1016 as i32 as i64 as u64)
    ldxdw r4, [r10-0x100]                   
    ldxdw r1, [r4+0x0]                      
    ldxdw r2, [r9+0x3f8]                    
    jeq r2, r1, lbb_14955                           if r2 == r1 { pc += 2 }
lbb_14953:
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    ja lbb_14965                                    if true { pc += 10 }
lbb_14955:
    ldxdw r1, [r4+0x8]                      
    ldxdw r2, [r8+0x8]                      
    jne r2, r1, lbb_14953                           if r2 != r1 { pc += -5 }
    ldxdw r1, [r4+0x10]                     
    ldxdw r2, [r8+0x10]                     
    jne r2, r1, lbb_14953                           if r2 != r1 { pc += -8 }
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    ldxdw r2, [r4+0x18]                     
    ldxdw r3, [r8+0x18]                     
    jne r3, r2, lbb_14953                           if r3 != r2 { pc += -12 }
lbb_14965:
    mov64 r2, 53                                    r2 = 53 as i32 as i64 as u64
    stxdw [r10-0x78], r2                    
    lddw r2, 0x100060a95 --> b"Coin dex account does not match expected dex insta"        r2 load str located at 4295363221
    stxdw [r10-0x80], r2                    
    jeq r1, 0, lbb_15117                            if r1 == (0 as i32 as i64 as u64) { pc += 146 }
    lddw r1, 0x100065448 --> b"\x00\x00\x00\x00\xca\x0a\x06\x00&\x00\x00\x00\x00\x00\x00\x00"\x00\x00\x0…        r1 load str located at 4295382088
    stxdw [r10-0x70], r1                    
    lddw r1, 0x100064c98 --> b"\x00\x00\x00\x00p\xfa\x05\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00…        r1 load str located at 4295380120
    stxdw [r10-0xf8], r1                    
    mov64 r1, 2                                     r1 = 2 as i32 as i64 as u64
    stxdw [r10-0xf0], r1                    
    stxdw [r10-0xe0], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -80                                   r1 += -80   ///  r1 = r1.wrapping_add(-80 as i32 as i64 as u64)
    stxdw [r10-0xe8], r1                    
    lddw r1, 0x100000888 --> b"y\x11\x00\x00\x00\x00\x00\x00\x85\x10\x00\x00]\xab\x00\x00\x95\x00\x00\x0…        r1 load str located at 4294969480
    stxdw [r10-0x38], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -112                                  r1 += -112   ///  r1 = r1.wrapping_add(-112 as i32 as i64 as u64)
    stxdw [r10-0x40], r1                    
    lddw r1, 0x100000860 --> b"\xbf#\x00\x00\x00\x00\x00\x00y\x12\x08\x00\x00\x00\x00\x00y\x11\x00\x00\x…        r1 load str located at 4294969440
    stxdw [r10-0x48], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -128                                  r1 += -128   ///  r1 = r1.wrapping_add(-128 as i32 as i64 as u64)
    stxdw [r10-0x50], r1                    
    mov64 r9, 0                                     r9 = 0 as i32 as i64 as u64
    stxdw [r10-0xd8], r9                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -104                                  r1 += -104   ///  r1 = r1.wrapping_add(-104 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -248                                  r2 += -248   ///  r2 = r2.wrapping_add(-248 as i32 as i64 as u64)
    call function_43415                     
    ldxdw r1, [r10-0x68]                    
    ldxdw r2, [r10-0x58]                    
    syscall [invalid]                       
    lddw r1, 0x300000000                            r1 load str located at 12884901888
    ldxdw r2, [r1+0x0]                      
    mov64 r3, 1                                     r3 = 1 as i32 as i64 as u64
    mov64 r1, r2                                    r1 = r2
    add64 r1, -32                                   r1 += -32   ///  r1 = r1.wrapping_add(-32 as i32 as i64 as u64)
    jgt r1, r2, lbb_15013                           if r1 > r2 { pc += 1 }
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
lbb_15013:
    jne r3, 0, lbb_15015                            if r3 != (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r9, r1                                    r9 = r1
lbb_15015:
    lddw r1, 0x300007fe0                            r1 load str located at 12884934624
    ldxdw r4, [r10-0x100]                   
    jeq r2, 0, lbb_15020                            if r2 == (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r1, r9                                    r1 = r9
lbb_15020:
    lddw r2, 0x300000007                            r2 load str located at 12884901895
    jgt r1, r2, lbb_15027                           if r1 > r2 { pc += 4 }
lbb_15023:
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    mov64 r2, 32                                    r2 = 32 as i32 as i64 as u64
    call function_43400                     
    syscall [invalid]                       
lbb_15027:
    lddw r2, 0x300000000                            r2 load str located at 12884901888
    stxdw [r2+0x0], r1                      
    ldxdw r3, [r4+0x18]                     
    stxdw [r1+0x18], r3                     
    ldxdw r3, [r4+0x10]                     
    stxdw [r1+0x10], r3                     
    ldxdw r3, [r4+0x8]                      
    stxdw [r1+0x8], r3                      
    ldxdw r3, [r4+0x0]                      
    stxdw [r1+0x0], r3                      
    ldxdw r3, [r8+0x18]                     
    stxdw [r10-0xe0], r3                    
    ldxdw r3, [r8+0x10]                     
    stxdw [r10-0xe8], r3                    
    ldxdw r3, [r8+0x8]                      
    stxdw [r10-0xf0], r3                    
    ldxdw r3, [r8+0x0]                      
    stxdw [r10-0xf8], r3                    
    ldxdw r3, [r2+0x0]                      
    mov64 r4, 0                                     r4 = 0 as i32 as i64 as u64
    mov64 r5, 1                                     r5 = 1 as i32 as i64 as u64
    mov64 r2, r3                                    r2 = r3
    add64 r2, -32                                   r2 += -32   ///  r2 = r2.wrapping_add(-32 as i32 as i64 as u64)
    jgt r2, r3, lbb_15053                           if r2 > r3 { pc += 1 }
    mov64 r5, 0                                     r5 = 0 as i32 as i64 as u64
lbb_15053:
    jne r5, 0, lbb_15055                            if r5 != (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r4, r2                                    r4 = r2
lbb_15055:
    lddw r2, 0x300007fe0                            r2 load str located at 12884934624
    jeq r3, 0, lbb_15059                            if r3 == (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r2, r4                                    r2 = r4
lbb_15059:
    lddw r3, 0x300000007                            r3 load str located at 12884901895
    jgt r2, r3, lbb_15063                           if r2 > r3 { pc += 1 }
    ja lbb_15023                                    if true { pc += -40 }
lbb_15063:
    lddw r3, 0x300000000                            r3 load str located at 12884901888
    stxdw [r3+0x0], r2                      
    ldxdw r4, [r10-0xe0]                    
    stxdw [r2+0x18], r4                     
    ldxdw r4, [r10-0xe8]                    
    stxdw [r2+0x10], r4                     
    ldxdw r4, [r10-0xf0]                    
    stxdw [r2+0x8], r4                      
    ldxdw r4, [r10-0xf8]                    
    stxdw [r2+0x0], r4                      
    ldxdw r5, [r10-0x118]                   
    ldxdw r4, [r5+0x18]                     
    stxdw [r10-0xe0], r4                    
    ldxdw r4, [r5+0x10]                     
    stxdw [r10-0xe8], r4                    
    ldxdw r4, [r5+0x8]                      
    stxdw [r10-0xf0], r4                    
    ldxdw r4, [r5+0x0]                      
    stxdw [r10-0xf8], r4                    
    ldxdw r4, [r3+0x0]                      
    mov64 r5, 0                                     r5 = 0 as i32 as i64 as u64
    mov64 r0, 1                                     r0 = 1 as i32 as i64 as u64
    mov64 r3, r4                                    r3 = r4
    add64 r3, -32                                   r3 += -32   ///  r3 = r3.wrapping_add(-32 as i32 as i64 as u64)
    jgt r3, r4, lbb_15090                           if r3 > r4 { pc += 1 }
    mov64 r0, 0                                     r0 = 0 as i32 as i64 as u64
lbb_15090:
    jne r0, 0, lbb_15092                            if r0 != (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r5, r3                                    r5 = r3
lbb_15092:
    lddw r3, 0x300007fe0                            r3 load str located at 12884934624
    jeq r4, 0, lbb_15096                            if r4 == (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r3, r5                                    r3 = r5
lbb_15096:
    lddw r4, 0x300000007                            r4 load str located at 12884901895
    ldxdw r0, [r10-0x110]                   
    jgt r3, r4, lbb_15101                           if r3 > r4 { pc += 1 }
    ja lbb_15023                                    if true { pc += -78 }
lbb_15101:
    lddw r4, 0x300000000                            r4 load str located at 12884901888
    stxdw [r4+0x0], r3                      
    ldxdw r4, [r10-0xe0]                    
    stxdw [r3+0x18], r4                     
    ldxdw r4, [r10-0xe8]                    
    stxdw [r3+0x10], r4                     
    ldxdw r4, [r10-0xf0]                    
    stxdw [r3+0x8], r4                      
    ldxdw r4, [r10-0xf8]                    
    stxdw [r3+0x0], r4                      
    stxdw [r6+0x18], r3                     
    stxdw [r6+0x10], r2                     
    stxdw [r6+0x8], r1                      
    mov64 r1, 21                                    r1 = 21 as i32 as i64 as u64
    ja lbb_15244                                    if true { pc += 127 }
lbb_15117:
    mov64 r8, r9                                    r8 = r9
    add64 r8, 952                                   r8 += 952   ///  r8 = r8.wrapping_add(952 as i32 as i64 as u64)
    ldxdw r1, [r7+0x0]                      
    ldxdw r2, [r9+0x3b8]                    
    jeq r2, r1, lbb_15124                           if r2 == r1 { pc += 2 }
lbb_15122:
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    ja lbb_15134                                    if true { pc += 10 }
lbb_15124:
    ldxdw r1, [r7+0x8]                      
    ldxdw r2, [r8+0x8]                      
    jne r2, r1, lbb_15122                           if r2 != r1 { pc += -5 }
    ldxdw r1, [r7+0x10]                     
    ldxdw r2, [r8+0x10]                     
    jne r2, r1, lbb_15122                           if r2 != r1 { pc += -8 }
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    ldxdw r2, [r7+0x18]                     
    ldxdw r3, [r8+0x18]                     
    jne r3, r2, lbb_15122                           if r3 != r2 { pc += -12 }
lbb_15134:
    mov64 r2, 36                                    r2 = 36 as i32 as i64 as u64
    stxdw [r10-0x78], r2                    
    lddw r2, 0x100060af0 --> b"Oracle mint does not match coin mintBad token acco"        r2 load str located at 4295363312
    stxdw [r10-0x80], r2                    
    ldxdw r2, [r10-0x118]                   
    jeq r1, 0, lbb_15246                            if r1 == (0 as i32 as i64 as u64) { pc += 105 }
    lddw r1, 0x100065460 --> b"\x00\x00\x00\x00\xca\x0a\x06\x00&\x00\x00\x00\x00\x00\x00\x00,\x00\x00\x0…        r1 load str located at 4295382112
    stxdw [r10-0x70], r1                    
    lddw r1, 0x100064c98 --> b"\x00\x00\x00\x00p\xfa\x05\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00…        r1 load str located at 4295380120
    stxdw [r10-0xf8], r1                    
    mov64 r1, 2                                     r1 = 2 as i32 as i64 as u64
    stxdw [r10-0xf0], r1                    
    stxdw [r10-0xe0], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -80                                   r1 += -80   ///  r1 = r1.wrapping_add(-80 as i32 as i64 as u64)
    stxdw [r10-0xe8], r1                    
    lddw r1, 0x100000888 --> b"y\x11\x00\x00\x00\x00\x00\x00\x85\x10\x00\x00]\xab\x00\x00\x95\x00\x00\x0…        r1 load str located at 4294969480
    stxdw [r10-0x38], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -112                                  r1 += -112   ///  r1 = r1.wrapping_add(-112 as i32 as i64 as u64)
    stxdw [r10-0x40], r1                    
    lddw r1, 0x100000860 --> b"\xbf#\x00\x00\x00\x00\x00\x00y\x12\x08\x00\x00\x00\x00\x00y\x11\x00\x00\x…        r1 load str located at 4294969440
    stxdw [r10-0x48], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -128                                  r1 += -128   ///  r1 = r1.wrapping_add(-128 as i32 as i64 as u64)
    stxdw [r10-0x50], r1                    
    mov64 r9, 0                                     r9 = 0 as i32 as i64 as u64
    stxdw [r10-0xd8], r9                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -104                                  r1 += -104   ///  r1 = r1.wrapping_add(-104 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -248                                  r2 += -248   ///  r2 = r2.wrapping_add(-248 as i32 as i64 as u64)
    call function_43415                     
    ldxdw r1, [r10-0x68]                    
    ldxdw r2, [r10-0x58]                    
    syscall [invalid]                       
    lddw r1, 0x300000000                            r1 load str located at 12884901888
    ldxdw r2, [r1+0x0]                      
    mov64 r3, 1                                     r3 = 1 as i32 as i64 as u64
    mov64 r1, r2                                    r1 = r2
    add64 r1, -32                                   r1 += -32   ///  r1 = r1.wrapping_add(-32 as i32 as i64 as u64)
    jgt r1, r2, lbb_15183                           if r1 > r2 { pc += 1 }
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
lbb_15183:
    ldxdw r0, [r10-0x110]                   
    jne r3, 0, lbb_15186                            if r3 != (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r9, r1                                    r9 = r1
lbb_15186:
    lddw r1, 0x300007fe0                            r1 load str located at 12884934624
    jeq r2, 0, lbb_15190                            if r2 == (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r1, r9                                    r1 = r9
lbb_15190:
    lddw r2, 0x300000007                            r2 load str located at 12884901895
    jgt r1, r2, lbb_15194                           if r1 > r2 { pc += 1 }
    ja lbb_15023                                    if true { pc += -171 }
lbb_15194:
    lddw r2, 0x300000000                            r2 load str located at 12884901888
    stxdw [r2+0x0], r1                      
    ldxdw r3, [r7+0x18]                     
    stxdw [r1+0x18], r3                     
    ldxdw r3, [r7+0x10]                     
    stxdw [r1+0x10], r3                     
    ldxdw r3, [r7+0x8]                      
    stxdw [r1+0x8], r3                      
    ldxdw r3, [r7+0x0]                      
    stxdw [r1+0x0], r3                      
    ldxdw r3, [r8+0x18]                     
    stxdw [r10-0xe0], r3                    
    ldxdw r3, [r8+0x10]                     
    stxdw [r10-0xe8], r3                    
    ldxdw r3, [r8+0x8]                      
    stxdw [r10-0xf0], r3                    
    ldxdw r3, [r8+0x0]                      
    stxdw [r10-0xf8], r3                    
    ldxdw r3, [r2+0x0]                      
    mov64 r4, 0                                     r4 = 0 as i32 as i64 as u64
    mov64 r5, 1                                     r5 = 1 as i32 as i64 as u64
    mov64 r2, r3                                    r2 = r3
    add64 r2, -32                                   r2 += -32   ///  r2 = r2.wrapping_add(-32 as i32 as i64 as u64)
    jgt r2, r3, lbb_15220                           if r2 > r3 { pc += 1 }
    mov64 r5, 0                                     r5 = 0 as i32 as i64 as u64
lbb_15220:
    jne r5, 0, lbb_15222                            if r5 != (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r4, r2                                    r4 = r2
lbb_15222:
    lddw r2, 0x300007fe0                            r2 load str located at 12884934624
    jeq r3, 0, lbb_15226                            if r3 == (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r2, r4                                    r2 = r4
lbb_15226:
    lddw r3, 0x300000007                            r3 load str located at 12884901895
    jgt r2, r3, lbb_15230                           if r2 > r3 { pc += 1 }
    ja lbb_15023                                    if true { pc += -207 }
lbb_15230:
    lddw r3, 0x300000000                            r3 load str located at 12884901888
    stxdw [r3+0x0], r2                      
    ldxdw r3, [r10-0xe0]                    
    stxdw [r2+0x18], r3                     
    ldxdw r3, [r10-0xe8]                    
    stxdw [r2+0x10], r3                     
    ldxdw r3, [r10-0xf0]                    
    stxdw [r2+0x8], r3                      
    ldxdw r3, [r10-0xf8]                    
    stxdw [r2+0x0], r3                      
    stxdw [r6+0x10], r2                     
    stxdw [r6+0x8], r1                      
    mov64 r1, 2                                     r1 = 2 as i32 as i64 as u64
lbb_15244:
    stxb [r6+0x0], r1                       
    ja lbb_15271                                    if true { pc += 25 }
lbb_15246:
    ldxb r3, [r9+0x418]                     
    stxdw [r10-0x1000], r7                  
    ldxdw r1, [r10-0x108]                   
    stxdw [r10-0xff8], r1                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -248                                  r1 += -248   ///  r1 = r1.wrapping_add(-248 as i32 as i64 as u64)
    mov64 r5, r10                                   r5 = r10
    call function_22239                     
    ldxb r8, [r10-0xf8]                     
    jeq r8, 56, lbb_15257                           if r8 == (56 as i32 as i64 as u64) { pc += 1 }
    ja lbb_15263                                    if true { pc += 6 }
lbb_15257:
    ldxdw r1, [r10-0x110]                   
    stxdw [r6+0x10], r1                     
    stxdw [r6+0x8], r9                      
    mov64 r1, 56                                    r1 = 56 as i32 as i64 as u64
    stxb [r6+0x0], r1                       
    ja lbb_14936                                    if true { pc += -327 }
lbb_15263:
    mov64 r1, r6                                    r1 = r6
    add64 r1, 1                                     r1 += 1   ///  r1 = r1.wrapping_add(1 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -247                                  r2 += -247   ///  r2 = r2.wrapping_add(-247 as i32 as i64 as u64)
    mov64 r3, 71                                    r3 = 71 as i32 as i64 as u64
    call function_48190                     
    stxb [r6+0x0], r8                       
    ldxdw r0, [r10-0x110]                   
lbb_15271:
    ldxdw r1, [r0+0x0]                      
    add64 r1, 1                                     r1 += 1   ///  r1 = r1.wrapping_add(1 as i32 as i64 as u64)
    stxdw [r0+0x0], r1                      
    ja lbb_14936                                    if true { pc += -339 }

function_15275:
    mov64 r7, r3                                    r7 = r3
    stxdw [r10-0x4f0], r2                   
    ldxdw r2, [r5-0xff8]                    
    stxdw [r10-0x4f8], r2                   
    ldxdw r9, [r2+0x10]                     
    ldxdw r3, [r9+0x10]                     
    lddw r2, 0x7ffffffffffffffe                     r2 load str located at 9223372036854775806
    jgt r3, r2, lbb_15687                           if r3 > r2 { pc += 403 }
    stxdw [r10-0x4e8], r4                   
    mov64 r8, r1                                    r8 = r1
    ldxdw r1, [r5-0x1000]                   
    stxdw [r10-0x4d8], r1                   
    add64 r3, 1                                     r3 += 1   ///  r3 = r3.wrapping_add(1 as i32 as i64 as u64)
    stxdw [r9+0x10], r3                     
    ldxdw r1, [r9+0x20]                     
    jeq r1, 165, lbb_15295                          if r1 == (165 as i32 as i64 as u64) { pc += 3 }
    mov64 r1, 3                                     r1 = 3 as i32 as i64 as u64
    stxw [r10-0x110], r1                    
    ja lbb_15302                                    if true { pc += 7 }
lbb_15295:
    ldxdw r2, [r9+0x18]                     
    mov64 r1, r10                                   r1 = r10
    add64 r1, -272                                  r1 += -272   ///  r1 = r1.wrapping_add(-272 as i32 as i64 as u64)
    mov64 r3, 165                                   r3 = 165 as i32 as i64 as u64
    call function_32610                     
    ldxw r1, [r10-0x88]                     
    jne r1, 2, lbb_15313                            if r1 != (2 as i32 as i64 as u64) { pc += 11 }
lbb_15302:
    ldxdw r1, [r10-0x110]                   
    stxdw [r10-0x2e8], r1                   
    ldxdw r1, [r10-0x108]                   
    stxdw [r10-0x2e0], r1                   
    ldxdw r1, [r10-0x100]                   
    stxdw [r10-0x2d8], r1                   
    ldxdw r1, [r10-0xf8]                    
    stxdw [r10-0x2d0], r1                   
    mov64 r1, 2                                     r1 = 2 as i32 as i64 as u64
    stxw [r10-0x260], r1                    
    ja lbb_15372                                    if true { pc += 59 }
lbb_15313:
    stxdw [r10-0x500], r1                   
    stxdw [r10-0x4e0], r7                   
    mov64 r7, r10                                   r7 = r10
    add64 r7, -384                                  r7 += -384   ///  r7 = r7.wrapping_add(-384 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -272                                  r2 += -272   ///  r2 = r2.wrapping_add(-272 as i32 as i64 as u64)
    mov64 r1, r7                                    r1 = r7
    mov64 r3, 108                                   r3 = 108 as i32 as i64 as u64
    call function_48190                     
    ldxdw r1, [r10-0xa3]                    
    stxdw [r10-0x210], r1                   
    ldxdw r1, [r10-0x9b]                    
    stxdw [r10-0x208], r1                   
    ldxdw r1, [r10-0x93]                    
    stxdw [r10-0x200], r1                   
    ldxw r1, [r10-0x8c]                     
    stxw [r10-0x1f9], r1                    
    ldxb r6, [r10-0xa4]                     
    mov64 r1, r10                                   r1 = r10
    add64 r1, -564                                  r1 += -564   ///  r1 = r1.wrapping_add(-564 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -132                                  r2 += -132   ///  r2 = r2.wrapping_add(-132 as i32 as i64 as u64)
    mov64 r3, 36                                    r3 = 36 as i32 as i64 as u64
    call function_48190                     
    mov64 r1, r10                                   r1 = r10
    add64 r1, -496                                  r1 += -496   ///  r1 = r1.wrapping_add(-496 as i32 as i64 as u64)
    mov64 r2, r7                                    r2 = r7
    mov64 r3, 108                                   r3 = 108 as i32 as i64 as u64
    call function_48190                     
    jne r6, 0, lbb_15348                            if r6 != (0 as i32 as i64 as u64) { pc += 5 }
    mov64 r1, 2                                     r1 = 2 as i32 as i64 as u64
    stxw [r10-0x260], r1                    
    mov64 r1, 9                                     r1 = 9 as i32 as i64 as u64
    stxw [r10-0x2e8], r1                    
    ja lbb_15371                                    if true { pc += 23 }
lbb_15348:
    mov64 r1, r10                                   r1 = r10
    add64 r1, -744                                  r1 += -744   ///  r1 = r1.wrapping_add(-744 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -496                                  r2 += -496   ///  r2 = r2.wrapping_add(-496 as i32 as i64 as u64)
    mov64 r3, 108                                   r3 = 108 as i32 as i64 as u64
    call function_48190                     
    ldxdw r1, [r10-0x210]                   
    stxdw [r10-0x27b], r1                   
    ldxdw r1, [r10-0x208]                   
    stxdw [r10-0x273], r1                   
    ldxdw r1, [r10-0x200]                   
    stxdw [r10-0x26b], r1                   
    ldxw r1, [r10-0x1f9]                    
    stxw [r10-0x264], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -604                                  r1 += -604   ///  r1 = r1.wrapping_add(-604 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -564                                  r2 += -564   ///  r2 = r2.wrapping_add(-564 as i32 as i64 as u64)
    mov64 r3, 36                                    r3 = 36 as i32 as i64 as u64
    call function_48190                     
    ldxdw r1, [r10-0x500]                   
    stxw [r10-0x260], r1                    
    stxb [r10-0x27c], r6                    
lbb_15371:
    ldxdw r7, [r10-0x4e0]                   
lbb_15372:
    mov64 r1, r10                                   r1 = r10
    add64 r1, -920                                  r1 += -920   ///  r1 = r1.wrapping_add(-920 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -744                                  r2 += -744   ///  r2 = r2.wrapping_add(-744 as i32 as i64 as u64)
    call function_1296                      
    ldxw r6, [r10-0x310]                    
    jeq r6, 2, lbb_15380                            if r6 == (2 as i32 as i64 as u64) { pc += 1 }
    ja lbb_15397                                    if true { pc += 17 }
lbb_15380:
    mov64 r7, r10                                   r7 = r10
    add64 r7, -1056                                 r7 += -1056   ///  r7 = r7.wrapping_add(-1056 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -920                                  r2 += -920   ///  r2 = r2.wrapping_add(-920 as i32 as i64 as u64)
    mov64 r1, r7                                    r1 = r7
    mov64 r3, 72                                    r3 = 72 as i32 as i64 as u64
    call function_48190                     
    mov64 r1, r8                                    r1 = r8
    mov64 r2, r7                                    r2 = r7
    mov64 r3, 72                                    r3 = 72 as i32 as i64 as u64
    call function_48190                     
    mov64 r1, 2                                     r1 = 2 as i32 as i64 as u64
    stxw [r8+0xa8], r1                      
    ldxdw r1, [r9+0x10]                     
    add64 r1, -1                                    r1 += -1   ///  r1 = r1.wrapping_add(-1 as i32 as i64 as u64)
    stxdw [r9+0x10], r1                     
    ja lbb_15527                                    if true { pc += 130 }
lbb_15397:
    stxdw [r10-0x4e0], r7                   
    mov64 r7, r10                                   r7 = r10
    add64 r7, -1056                                 r7 += -1056   ///  r7 = r7.wrapping_add(-1056 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -920                                  r2 += -920   ///  r2 = r2.wrapping_add(-920 as i32 as i64 as u64)
    mov64 r1, r7                                    r1 = r7
    mov64 r3, 136                                   r3 = 136 as i32 as i64 as u64
    call function_48190                     
    mov64 r1, r10                                   r1 = r10
    add64 r1, -1092                                 r1 += -1092   ///  r1 = r1.wrapping_add(-1092 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -780                                  r2 += -780   ///  r2 = r2.wrapping_add(-780 as i32 as i64 as u64)
    mov64 r3, 36                                    r3 = 36 as i32 as i64 as u64
    call function_48190                     
    mov64 r1, r10                                   r1 = r10
    add64 r1, -1232                                 r1 += -1232   ///  r1 = r1.wrapping_add(-1232 as i32 as i64 as u64)
    mov64 r2, r7                                    r2 = r7
    mov64 r3, 136                                   r3 = 136 as i32 as i64 as u64
    call function_48190                     
    stxw [r10-0x448], r6                    
    ldxdw r1, [r9+0x10]                     
    add64 r1, -1                                    r1 += -1   ///  r1 = r1.wrapping_add(-1 as i32 as i64 as u64)
    stxdw [r9+0x10], r1                     
    ldxdw r6, [r10-0x4d8]                   
    mov64 r1, r6                                    r1 = r6
    call function_39132                     
    jne r0, 0, lbb_15427                            if r0 != (0 as i32 as i64 as u64) { pc += 3 }
    mov64 r1, r6                                    r1 = r6
    call function_39148                     
    jne r0, 0, lbb_15480                            if r0 != (0 as i32 as i64 as u64) { pc += 53 }
lbb_15427:
    mov64 r1, r10                                   r1 = r10
    add64 r1, -272                                  r1 += -272   ///  r1 = r1.wrapping_add(-272 as i32 as i64 as u64)
    mov64 r2, r6                                    r2 = r6
    call function_39176                     
    ldxw r0, [r10-0x110]                    
    jeq r0, 24, lbb_15434                           if r0 == (24 as i32 as i64 as u64) { pc += 1 }
    ja lbb_15456                                    if true { pc += 22 }
lbb_15434:
    ldxdw r7, [r10-0x100]                   
    ldxdw r1, [r10-0x108]                   
    ldxdw r6, [r6+0x0]                      
    ldxdw r2, [r1+0x8]                      
    jne r2, 1056, lbb_15443                         if r2 != (1056 as i32 as i64 as u64) { pc += 4 }
    ldxdw r3, [r1+0x0]                      
    mov64 r1, r3                                    r1 = r3
    and64 r1, 7                                     r1 &= 7   ///  r1 = r1.and(7)
    jeq r1, 0, lbb_15462                            if r1 == (0 as i32 as i64 as u64) { pc += 19 }
lbb_15443:
    ldxdw r5, [r6+0x8]                      
    ldxdw r4, [r6+0x0]                      
    ldxdw r1, [r6+0x18]                     
    stxdw [r10-0x2e0], r1                   
    ldxdw r1, [r6+0x10]                     
    stxdw [r10-0x2e8], r1                   
    ldxdw r1, [r7+0x0]                      
    add64 r1, -1                                    r1 += -1   ///  r1 = r1.wrapping_add(-1 as i32 as i64 as u64)
    stxdw [r7+0x0], r1                      
    mov64 r3, 35                                    r3 = 35 as i32 as i64 as u64
    mov64 r0, 1056                                  r0 = 1056 as i32 as i64 as u64
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    ja lbb_15492                                    if true { pc += 36 }
lbb_15456:
    mov64 r3, 55                                    r3 = 55 as i32 as i64 as u64
    ldxdw r2, [r10-0x108]                   
    ldxdw r5, [r10-0xf8]                    
    ldxdw r4, [r10-0x100]                   
    ldxw r1, [r10-0x10c]                    
    ja lbb_15492                                    if true { pc += 30 }
lbb_15462:
    mov64 r9, r3                                    r9 = r3
    mov64 r1, r10                                   r1 = r10
    add64 r1, -272                                  r1 += -272   ///  r1 = r1.wrapping_add(-272 as i32 as i64 as u64)
    mov64 r3, r10                                   r3 = r10
    add64 r3, -1232                                 r3 += -1232   ///  r3 = r3.wrapping_add(-1232 as i32 as i64 as u64)
    ldxdw r2, [r10-0x4e0]                   
    call function_24960                     
    ldxb r3, [r10-0x110]                    
    jeq r3, 56, lbb_15472                           if r3 == (56 as i32 as i64 as u64) { pc += 1 }
    ja lbb_15866                                    if true { pc += 394 }
lbb_15472:
    mov64 r5, r9                                    r5 = r9
    add64 r9, 1016                                  r9 += 1016   ///  r9 = r9.wrapping_add(1016 as i32 as i64 as u64)
    ldxdw r4, [r10-0x4e8]                   
    ldxdw r1, [r4+0x0]                      
    ldxdw r2, [r5+0x3f8]                    
    jeq r2, r1, lbb_15528                           if r2 == r1 { pc += 50 }
lbb_15478:
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    ja lbb_15538                                    if true { pc += 58 }
lbb_15480:
    ldxdw r1, [r6+0x0]                      
    ldxw r2, [r1+0x3]                       
    stxw [r10-0x41d], r2                    
    ldxw r2, [r1+0x0]                       
    stxw [r10-0x420], r2                    
    mov64 r3, 37                                    r3 = 37 as i32 as i64 as u64
    ldxb r5, [r1+0x1f]                      
    ldxdw r4, [r1+0x17]                     
    ldxdw r2, [r1+0xf]                      
    ldxdw r0, [r1+0x7]                      
    mov64 r1, r0                                    r1 = r0
    rsh64 r1, 32                                    r1 >>= 32   ///  r1 = r1.wrapping_shr(32)
lbb_15492:
    ldxw r6, [r10-0x41d]                    
    stxw [r10-0x231], r6                    
    ldxw r6, [r10-0x420]                    
    stxw [r10-0x234], r6                    
    ldxdw r6, [r10-0x2e8]                   
    stxdw [r10-0x398], r6                   
    ldxdw r6, [r10-0x2e0]                   
    stxdw [r10-0x390], r6                   
    ldxdw r6, [r10-0x2d8]                   
    stxdw [r10-0x388], r6                   
    ldxdw r6, [r10-0x2d0]                   
    stxdw [r10-0x380], r6                   
    lsh64 r1, 32                                    r1 <<= 32   ///  r1 = r1.wrapping_shl(32)
    lsh64 r0, 32                                    r0 <<= 32   ///  r0 = r0.wrapping_shl(32)
    rsh64 r0, 32                                    r0 >>= 32   ///  r0 = r0.wrapping_shr(32)
    or64 r1, r0                                     r1 |= r0   ///  r1 = r1.or(r0)
lbb_15508:
    ldxw r0, [r10-0x231]                    
    stxw [r8+0x4], r0                       
    ldxw r0, [r10-0x234]                    
    stxw [r8+0x1], r0                       
    ldxdw r0, [r10-0x398]                   
    stxdw [r8+0x28], r0                     
    ldxdw r0, [r10-0x390]                   
    stxdw [r8+0x30], r0                     
    ldxdw r0, [r10-0x388]                   
    stxdw [r8+0x38], r0                     
    ldxdw r0, [r10-0x380]                   
    stxdw [r8+0x40], r0                     
    mov64 r0, 2                                     r0 = 2 as i32 as i64 as u64
    stxw [r8+0xa8], r0                      
    stxdw [r8+0x20], r5                     
    stxdw [r8+0x18], r4                     
    stxdw [r8+0x10], r2                     
    stxdw [r8+0x8], r1                      
    stxb [r8+0x0], r3                       
lbb_15527:
    exit                                    
lbb_15528:
    ldxdw r1, [r4+0x8]                      
    ldxdw r2, [r9+0x8]                      
    jne r2, r1, lbb_15478                           if r2 != r1 { pc += -53 }
    ldxdw r1, [r4+0x10]                     
    ldxdw r2, [r9+0x10]                     
    jne r2, r1, lbb_15478                           if r2 != r1 { pc += -56 }
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    ldxdw r2, [r4+0x18]                     
    ldxdw r3, [r9+0x18]                     
    jne r3, r2, lbb_15478                           if r3 != r2 { pc += -60 }
lbb_15538:
    mov64 r2, 53                                    r2 = 53 as i32 as i64 as u64
    stxdw [r10-0x178], r2                   
    lddw r2, 0x100060a95 --> b"Coin dex account does not match expected dex insta"        r2 load str located at 4295363221
    stxdw [r10-0x180], r2                   
    jeq r1, 0, lbb_15691                            if r1 == (0 as i32 as i64 as u64) { pc += 147 }
    stxdw [r10-0x4e0], r6                   
    lddw r1, 0x100065448 --> b"\x00\x00\x00\x00\xca\x0a\x06\x00&\x00\x00\x00\x00\x00\x00\x00"\x00\x00\x0…        r1 load str located at 4295382088
    stxdw [r10-0x1f0], r1                   
    lddw r1, 0x100064c98 --> b"\x00\x00\x00\x00p\xfa\x05\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00…        r1 load str located at 4295380120
    stxdw [r10-0x110], r1                   
    mov64 r1, 2                                     r1 = 2 as i32 as i64 as u64
    stxdw [r10-0x108], r1                   
    stxdw [r10-0xf8], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -744                                  r1 += -744   ///  r1 = r1.wrapping_add(-744 as i32 as i64 as u64)
    stxdw [r10-0x100], r1                   
    lddw r1, 0x100000888 --> b"y\x11\x00\x00\x00\x00\x00\x00\x85\x10\x00\x00]\xab\x00\x00\x95\x00\x00\x0…        r1 load str located at 4294969480
    stxdw [r10-0x2d0], r1                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -496                                  r1 += -496   ///  r1 = r1.wrapping_add(-496 as i32 as i64 as u64)
    stxdw [r10-0x2d8], r1                   
    lddw r1, 0x100000860 --> b"\xbf#\x00\x00\x00\x00\x00\x00y\x12\x08\x00\x00\x00\x00\x00y\x11\x00\x00\x…        r1 load str located at 4294969440
    stxdw [r10-0x2e0], r1                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -384                                  r1 += -384   ///  r1 = r1.wrapping_add(-384 as i32 as i64 as u64)
    stxdw [r10-0x2e8], r1                   
    mov64 r6, 0                                     r6 = 0 as i32 as i64 as u64
    stxdw [r10-0xf0], r6                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -1056                                 r1 += -1056   ///  r1 = r1.wrapping_add(-1056 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -272                                  r2 += -272   ///  r2 = r2.wrapping_add(-272 as i32 as i64 as u64)
    call function_43415                     
    ldxdw r1, [r10-0x420]                   
    ldxdw r2, [r10-0x410]                   
    syscall [invalid]                       
    lddw r1, 0x300000000                            r1 load str located at 12884901888
    ldxdw r2, [r1+0x0]                      
    mov64 r3, 1                                     r3 = 1 as i32 as i64 as u64
    mov64 r1, r2                                    r1 = r2
    add64 r1, -32                                   r1 += -32   ///  r1 = r1.wrapping_add(-32 as i32 as i64 as u64)
    jgt r1, r2, lbb_15587                           if r1 > r2 { pc += 1 }
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
lbb_15587:
    jne r3, 0, lbb_15589                            if r3 != (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r6, r1                                    r6 = r1
lbb_15589:
    lddw r1, 0x300007fe0                            r1 load str located at 12884934624
    jeq r2, 0, lbb_15593                            if r2 == (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r1, r6                                    r1 = r6
lbb_15593:
    lddw r2, 0x300000007                            r2 load str located at 12884901895
    jgt r1, r2, lbb_15600                           if r1 > r2 { pc += 4 }
lbb_15596:
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    mov64 r2, 32                                    r2 = 32 as i32 as i64 as u64
    call function_43400                     
    syscall [invalid]                       
lbb_15600:
    lddw r2, 0x300000000                            r2 load str located at 12884901888
    stxdw [r2+0x0], r1                      
    ldxdw r4, [r10-0x4e8]                   
    ldxdw r3, [r4+0x18]                     
    stxdw [r1+0x18], r3                     
    ldxdw r3, [r4+0x10]                     
    stxdw [r1+0x10], r3                     
    ldxdw r3, [r4+0x8]                      
    stxdw [r1+0x8], r3                      
    ldxdw r3, [r4+0x0]                      
    stxdw [r1+0x0], r3                      
    ldxdw r3, [r9+0x18]                     
    stxdw [r10-0xf8], r3                    
    ldxdw r3, [r9+0x10]                     
    stxdw [r10-0x100], r3                   
    ldxdw r3, [r9+0x8]                      
    stxdw [r10-0x108], r3                   
    ldxdw r3, [r9+0x0]                      
    stxdw [r10-0x110], r3                   
    ldxdw r3, [r2+0x0]                      
    mov64 r4, 0                                     r4 = 0 as i32 as i64 as u64
    mov64 r5, 1                                     r5 = 1 as i32 as i64 as u64
    mov64 r2, r3                                    r2 = r3
    add64 r2, -32                                   r2 += -32   ///  r2 = r2.wrapping_add(-32 as i32 as i64 as u64)
    ldxdw r0, [r10-0x4e0]                   
    jgt r2, r3, lbb_15628                           if r2 > r3 { pc += 1 }
    mov64 r5, 0                                     r5 = 0 as i32 as i64 as u64
lbb_15628:
    jne r5, 0, lbb_15630                            if r5 != (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r4, r2                                    r4 = r2
lbb_15630:
    lddw r2, 0x300007fe0                            r2 load str located at 12884934624
    jeq r3, 0, lbb_15634                            if r3 == (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r2, r4                                    r2 = r4
lbb_15634:
    lddw r3, 0x300000007                            r3 load str located at 12884901895
    jgt r2, r3, lbb_15638                           if r2 > r3 { pc += 1 }
    ja lbb_15596                                    if true { pc += -42 }
lbb_15638:
    lddw r3, 0x300000000                            r3 load str located at 12884901888
    stxdw [r3+0x0], r2                      
    ldxdw r4, [r10-0xf8]                    
    stxdw [r2+0x18], r4                     
    ldxdw r4, [r10-0x100]                   
    stxdw [r2+0x10], r4                     
    ldxdw r4, [r10-0x108]                   
    stxdw [r2+0x8], r4                      
    ldxdw r4, [r10-0x110]                   
    stxdw [r2+0x0], r4                      
    ldxdw r4, [r0+0x18]                     
    stxdw [r10-0xf8], r4                    
    ldxdw r4, [r0+0x10]                     
    stxdw [r10-0x100], r4                   
    ldxdw r4, [r0+0x8]                      
    stxdw [r10-0x108], r4                   
    ldxdw r4, [r0+0x0]                      
    stxdw [r10-0x110], r4                   
    ldxdw r3, [r3+0x0]                      
    mov64 r5, 0                                     r5 = 0 as i32 as i64 as u64
    mov64 r0, 1                                     r0 = 1 as i32 as i64 as u64
    mov64 r4, r3                                    r4 = r3
    add64 r4, -32                                   r4 += -32   ///  r4 = r4.wrapping_add(-32 as i32 as i64 as u64)
    jgt r4, r3, lbb_15664                           if r4 > r3 { pc += 1 }
    mov64 r0, 0                                     r0 = 0 as i32 as i64 as u64
lbb_15664:
    jne r0, 0, lbb_15666                            if r0 != (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r5, r4                                    r5 = r4
lbb_15666:
    lddw r4, 0x300007fe0                            r4 load str located at 12884934624
    jeq r3, 0, lbb_15670                            if r3 == (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r4, r5                                    r4 = r5
lbb_15670:
    lddw r3, 0x300000007                            r3 load str located at 12884901895
    jgt r4, r3, lbb_15674                           if r4 > r3 { pc += 1 }
    ja lbb_15596                                    if true { pc += -78 }
lbb_15674:
    lddw r3, 0x300000000                            r3 load str located at 12884901888
    stxdw [r3+0x0], r4                      
    ldxdw r3, [r10-0xf8]                    
    stxdw [r4+0x18], r3                     
    ldxdw r3, [r10-0x100]                   
    stxdw [r4+0x10], r3                     
    ldxdw r3, [r10-0x108]                   
    stxdw [r4+0x8], r3                      
    ldxdw r3, [r10-0x110]                   
    stxdw [r4+0x0], r3                      
    mov64 r3, 21                                    r3 = 21 as i32 as i64 as u64
    ja lbb_15882                                    if true { pc += 195 }
lbb_15687:
    lddw r1, 0x100065478 --> b"\x00\x00\x00\x00\xca\x0a\x06\x00&\x00\x00\x00\x00\x00\x00\x00N\x00\x00\x0…        r1 load str located at 4295382136
    call function_43759                     
    syscall [invalid]                       
lbb_15691:
    mov64 r9, r5                                    r9 = r5
    add64 r9, 952                                   r9 += 952   ///  r9 = r9.wrapping_add(952 as i32 as i64 as u64)
    ldxdw r1, [r5+0x3b8]                    
    ldxdw r2, [r10-0x4d0]                   
    jeq r1, r2, lbb_15698                           if r1 == r2 { pc += 2 }
lbb_15696:
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    ja lbb_15708                                    if true { pc += 10 }
lbb_15698:
    ldxdw r1, [r9+0x8]                      
    ldxdw r2, [r10-0x4c8]                   
    jne r1, r2, lbb_15696                           if r1 != r2 { pc += -5 }
    ldxdw r1, [r9+0x10]                     
    ldxdw r2, [r10-0x4c0]                   
    jne r1, r2, lbb_15696                           if r1 != r2 { pc += -8 }
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    ldxdw r2, [r9+0x18]                     
    ldxdw r3, [r10-0x4b8]                   
    jne r2, r3, lbb_15696                           if r2 != r3 { pc += -12 }
lbb_15708:
    mov64 r2, 36                                    r2 = 36 as i32 as i64 as u64
    stxdw [r10-0x178], r2                   
    lddw r2, 0x100060af0 --> b"Oracle mint does not match coin mintBad token acco"        r2 load str located at 4295363312
    stxdw [r10-0x180], r2                   
    jeq r1, 0, lbb_15815                            if r1 == (0 as i32 as i64 as u64) { pc += 101 }
    lddw r1, 0x100065460 --> b"\x00\x00\x00\x00\xca\x0a\x06\x00&\x00\x00\x00\x00\x00\x00\x00,\x00\x00\x0…        r1 load str located at 4295382112
    stxdw [r10-0x1f0], r1                   
    lddw r1, 0x100064c98 --> b"\x00\x00\x00\x00p\xfa\x05\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00…        r1 load str located at 4295380120
    stxdw [r10-0x110], r1                   
    mov64 r1, 2                                     r1 = 2 as i32 as i64 as u64
    stxdw [r10-0x108], r1                   
    stxdw [r10-0xf8], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -744                                  r1 += -744   ///  r1 = r1.wrapping_add(-744 as i32 as i64 as u64)
    stxdw [r10-0x100], r1                   
    lddw r1, 0x100000888 --> b"y\x11\x00\x00\x00\x00\x00\x00\x85\x10\x00\x00]\xab\x00\x00\x95\x00\x00\x0…        r1 load str located at 4294969480
    stxdw [r10-0x2d0], r1                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -496                                  r1 += -496   ///  r1 = r1.wrapping_add(-496 as i32 as i64 as u64)
    stxdw [r10-0x2d8], r1                   
    lddw r1, 0x100000860 --> b"\xbf#\x00\x00\x00\x00\x00\x00y\x12\x08\x00\x00\x00\x00\x00y\x11\x00\x00\x…        r1 load str located at 4294969440
    stxdw [r10-0x2e0], r1                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -384                                  r1 += -384   ///  r1 = r1.wrapping_add(-384 as i32 as i64 as u64)
    stxdw [r10-0x2e8], r1                   
    mov64 r6, 0                                     r6 = 0 as i32 as i64 as u64
    stxdw [r10-0xf0], r6                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -1056                                 r1 += -1056   ///  r1 = r1.wrapping_add(-1056 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -272                                  r2 += -272   ///  r2 = r2.wrapping_add(-272 as i32 as i64 as u64)
    call function_43415                     
    ldxdw r1, [r10-0x420]                   
    ldxdw r2, [r10-0x410]                   
    syscall [invalid]                       
    lddw r1, 0x300000000                            r1 load str located at 12884901888
    ldxdw r2, [r1+0x0]                      
    mov64 r3, 1                                     r3 = 1 as i32 as i64 as u64
    mov64 r1, r2                                    r1 = r2
    add64 r1, -32                                   r1 += -32   ///  r1 = r1.wrapping_add(-32 as i32 as i64 as u64)
    jgt r1, r2, lbb_15756                           if r1 > r2 { pc += 1 }
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
lbb_15756:
    jne r3, 0, lbb_15758                            if r3 != (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r6, r1                                    r6 = r1
lbb_15758:
    lddw r1, 0x300007fe0                            r1 load str located at 12884934624
    jeq r2, 0, lbb_15762                            if r2 == (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r1, r6                                    r1 = r6
lbb_15762:
    lddw r2, 0x300000007                            r2 load str located at 12884901895
    jgt r1, r2, lbb_15766                           if r1 > r2 { pc += 1 }
    ja lbb_15596                                    if true { pc += -170 }
lbb_15766:
    lddw r2, 0x300000000                            r2 load str located at 12884901888
    stxdw [r2+0x0], r1                      
    ldxdw r3, [r10-0x4b8]                   
    stxdw [r1+0x18], r3                     
    ldxdw r3, [r10-0x4c0]                   
    stxdw [r1+0x10], r3                     
    ldxdw r3, [r10-0x4c8]                   
    stxdw [r1+0x8], r3                      
    ldxdw r3, [r10-0x4d0]                   
    stxdw [r1+0x0], r3                      
    ldxdw r3, [r9+0x18]                     
    stxdw [r10-0xf8], r3                    
    ldxdw r3, [r9+0x10]                     
    stxdw [r10-0x100], r3                   
    ldxdw r3, [r9+0x8]                      
    stxdw [r10-0x108], r3                   
    ldxdw r3, [r9+0x0]                      
    stxdw [r10-0x110], r3                   
    ldxdw r3, [r2+0x0]                      
    mov64 r4, 0                                     r4 = 0 as i32 as i64 as u64
    mov64 r5, 1                                     r5 = 1 as i32 as i64 as u64
    mov64 r2, r3                                    r2 = r3
    add64 r2, -32                                   r2 += -32   ///  r2 = r2.wrapping_add(-32 as i32 as i64 as u64)
    jgt r2, r3, lbb_15792                           if r2 > r3 { pc += 1 }
    mov64 r5, 0                                     r5 = 0 as i32 as i64 as u64
lbb_15792:
    jne r5, 0, lbb_15794                            if r5 != (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r4, r2                                    r4 = r2
lbb_15794:
    lddw r2, 0x300007fe0                            r2 load str located at 12884934624
    jeq r3, 0, lbb_15798                            if r3 == (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r2, r4                                    r2 = r4
lbb_15798:
    lddw r3, 0x300000007                            r3 load str located at 12884901895
    jgt r2, r3, lbb_15802                           if r2 > r3 { pc += 1 }
    ja lbb_15596                                    if true { pc += -206 }
lbb_15802:
    lddw r3, 0x300000000                            r3 load str located at 12884901888
    stxdw [r3+0x0], r2                      
    ldxdw r3, [r10-0xf8]                    
    stxdw [r2+0x18], r3                     
    ldxdw r3, [r10-0x100]                   
    stxdw [r2+0x10], r3                     
    ldxdw r3, [r10-0x108]                   
    stxdw [r2+0x8], r3                      
    ldxdw r3, [r10-0x110]                   
    stxdw [r2+0x0], r3                      
    mov64 r3, 2                                     r3 = 2 as i32 as i64 as u64
    ja lbb_15882                                    if true { pc += 67 }
lbb_15815:
    ldxb r3, [r5+0x418]                     
    mov64 r1, r10                                   r1 = r10
    add64 r1, -1232                                 r1 += -1232   ///  r1 = r1.wrapping_add(-1232 as i32 as i64 as u64)
    stxdw [r10-0x1000], r1                  
    ldxdw r1, [r10-0x4f0]                   
    stxdw [r10-0xff8], r1                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -272                                  r1 += -272   ///  r1 = r1.wrapping_add(-272 as i32 as i64 as u64)
    mov64 r9, r5                                    r9 = r5
    mov64 r5, r10                                   r5 = r10
    mov64 r2, r6                                    r2 = r6
    call function_22239                     
    ldxb r3, [r10-0x110]                    
    jeq r3, 56, lbb_15830                           if r3 == (56 as i32 as i64 as u64) { pc += 1 }
    ja lbb_15866                                    if true { pc += 36 }
lbb_15830:
    stxdw [r10-0x4e0], r6                   
    ldxdw r1, [r10-0x4f8]                   
    ldxdw r4, [r1+0x0]                      
    mov64 r1, r10                                   r1 = r10
    add64 r1, -272                                  r1 += -272   ///  r1 = r1.wrapping_add(-272 as i32 as i64 as u64)
    mov64 r3, r10                                   r3 = r10
    add64 r3, -1232                                 r3 += -1232   ///  r3 = r3.wrapping_add(-1232 as i32 as i64 as u64)
    mov64 r2, r9                                    r2 = r9
    stxdw [r10-0x4e8], r4                   
    call function_22478                     
    ldxb r6, [r10-0x110]                    
    jeq r6, 56, lbb_15843                           if r6 == (56 as i32 as i64 as u64) { pc += 1 }
    ja lbb_15886                                    if true { pc += 43 }
lbb_15843:
    ldxb r3, [r9+0x419]                     
    mov64 r1, r10                                   r1 = r10
    add64 r1, -272                                  r1 += -272   ///  r1 = r1.wrapping_add(-272 as i32 as i64 as u64)
    ldxdw r2, [r10-0x4e8]                   
    ldxdw r4, [r10-0x4e0]                   
    ldxdw r5, [r10-0x4f0]                   
    call function_22000                     
    ldxb r6, [r10-0x110]                    
    jeq r6, 56, lbb_15853                           if r6 == (56 as i32 as i64 as u64) { pc += 1 }
    ja lbb_15886                                    if true { pc += 33 }
lbb_15853:
    mov64 r1, r8                                    r1 = r8
    add64 r1, 32                                    r1 += 32   ///  r1 = r1.wrapping_add(32 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -1232                                 r2 += -1232   ///  r2 = r2.wrapping_add(-1232 as i32 as i64 as u64)
    mov64 r3, 176                                   r3 = 176 as i32 as i64 as u64
    call function_48190                     
    ldxdw r1, [r10-0x4f8]                   
    stxdw [r8+0x18], r1                     
    ldxdw r1, [r10-0x4d8]                   
    stxdw [r8+0x10], r1                     
    stxdw [r8+0x8], r7                      
    stxdw [r8+0x0], r9                      
    ja lbb_15527                                    if true { pc += -339 }
lbb_15866:
    ldxw r1, [r10-0x10c]                    
    stxw [r10-0x231], r1                    
    ldxw r1, [r10-0x10f]                    
    stxw [r10-0x234], r1                    
    ldxdw r1, [r10-0xe8]                    
    stxdw [r10-0x398], r1                   
    ldxdw r1, [r10-0xe0]                    
    stxdw [r10-0x390], r1                   
    ldxdw r1, [r10-0xd8]                    
    stxdw [r10-0x388], r1                   
    ldxdw r1, [r10-0xd0]                    
    stxdw [r10-0x380], r1                   
    ldxdw r5, [r10-0xf0]                    
    ldxdw r4, [r10-0xf8]                    
    ldxdw r2, [r10-0x100]                   
    ldxdw r1, [r10-0x108]                   
lbb_15882:
    ldxdw r0, [r7+0x0]                      
    add64 r0, -1                                    r0 += -1   ///  r0 = r0.wrapping_add(-1 as i32 as i64 as u64)
    stxdw [r7+0x0], r0                      
    ja lbb_15508                                    if true { pc += -378 }
lbb_15886:
    mov64 r1, r8                                    r1 = r8
    add64 r1, 1                                     r1 += 1   ///  r1 = r1.wrapping_add(1 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -271                                  r2 += -271   ///  r2 = r2.wrapping_add(-271 as i32 as i64 as u64)
    mov64 r3, 71                                    r3 = 71 as i32 as i64 as u64
    call function_48190                     
    mov64 r1, 2                                     r1 = 2 as i32 as i64 as u64
    stxw [r8+0xa8], r1                      
    stxb [r8+0x0], r6                       
    ldxdw r1, [r7+0x0]                      
    add64 r1, -1                                    r1 += -1   ///  r1 = r1.wrapping_add(-1 as i32 as i64 as u64)
    stxdw [r7+0x0], r1                      
    ja lbb_15527                                    if true { pc += -372 }

function_15899:
    mov64 r7, r5                                    r7 = r5
    stxdw [r10-0x2d8], r1                   
    ldxdw r6, [r7-0xff0]                    
    stxdw [r10-0x1000], r6                  
    ldxdw r9, [r7-0xfe8]                    
    stxdw [r10-0xff8], r9                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -584                                  r1 += -584   ///  r1 = r1.wrapping_add(-584 as i32 as i64 as u64)
    mov64 r5, r10                                   r5 = r10
    call function_15275                     
    mov64 r2, r10                                   r2 = r10
    add64 r2, -552                                  r2 += -552   ///  r2 = r2.wrapping_add(-552 as i32 as i64 as u64)
    ldxdw r1, [r10-0x240]                   
    ldxdw r8, [r10-0x248]                   
    ldxw r3, [r10-0x1a0]                    
    jne r3, 2, lbb_15939                            if r3 != (2 as i32 as i64 as u64) { pc += 24 }
    stxdw [r10-0x2e8], r8                   
    ldxdw r8, [r10-0x230]                   
    ldxdw r6, [r10-0x2d8]                   
    stxdw [r10-0x2e0], r1                   
    ldxdw r9, [r10-0x238]                   
    mov64 r7, r10                                   r7 = r10
    add64 r7, -720                                  r7 += -720   ///  r7 = r7.wrapping_add(-720 as i32 as i64 as u64)
    mov64 r1, r7                                    r1 = r7
    mov64 r3, 40                                    r3 = 40 as i32 as i64 as u64
    call function_48190                     
    mov64 r1, r6                                    r1 = r6
    add64 r1, 32                                    r1 += 32   ///  r1 = r1.wrapping_add(32 as i32 as i64 as u64)
    mov64 r2, r7                                    r2 = r7
    mov64 r3, 40                                    r3 = 40 as i32 as i64 as u64
    call function_48190                     
    mov64 r1, 2                                     r1 = 2 as i32 as i64 as u64
    stxw [r6+0xa8], r1                      
    stxdw [r6+0x18], r8                     
    stxdw [r6+0x10], r9                     
    ldxdw r1, [r10-0x2e0]                   
    stxdw [r6+0x8], r1                      
    ldxdw r1, [r10-0x2e8]                   
    stxdw [r6+0x0], r1                      
    ja lbb_16213                                    if true { pc += 274 }
lbb_15939:
    stxdw [r10-0x2f8], r3                   
    stxdw [r10-0x2f0], r9                   
    stxdw [r10-0x2e0], r6                   
    mov64 r6, r1                                    r6 = r1
    ldxdw r9, [r7-0xff8]                    
    ldxdw r1, [r7-0x1000]                   
    stxdw [r10-0x2e8], r1                   
    mov64 r7, r10                                   r7 = r10
    add64 r7, -720                                  r7 += -720   ///  r7 = r7.wrapping_add(-720 as i32 as i64 as u64)
    mov64 r1, r7                                    r1 = r7
    mov64 r3, 136                                   r3 = 136 as i32 as i64 as u64
    call function_48190                     
    mov64 r1, r10                                   r1 = r10
    add64 r1, -316                                  r1 += -316   ///  r1 = r1.wrapping_add(-316 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -412                                  r2 += -412   ///  r2 = r2.wrapping_add(-412 as i32 as i64 as u64)
    mov64 r3, 36                                    r3 = 36 as i32 as i64 as u64
    call function_48190                     
    mov64 r1, r10                                   r1 = r10
    add64 r1, -280                                  r1 += -280   ///  r1 = r1.wrapping_add(-280 as i32 as i64 as u64)
    mov64 r2, r7                                    r2 = r7
    mov64 r3, 136                                   r3 = 136 as i32 as i64 as u64
    call function_48190                     
    mov64 r5, r9                                    r5 = r9
    mov64 r7, r8                                    r7 = r8
    add64 r7, 920                                   r7 += 920   ///  r7 = r7.wrapping_add(920 as i32 as i64 as u64)
    ldxdw r1, [r5+0x0]                      
    mov64 r4, r8                                    r4 = r8
    ldxdw r2, [r8+0x398]                    
    jeq r2, r1, lbb_15971                           if r2 == r1 { pc += 2 }
lbb_15969:
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    ja lbb_15981                                    if true { pc += 10 }
lbb_15971:
    ldxdw r1, [r5+0x8]                      
    ldxdw r2, [r7+0x8]                      
    jne r2, r1, lbb_15969                           if r2 != r1 { pc += -5 }
    ldxdw r1, [r5+0x10]                     
    ldxdw r2, [r7+0x10]                     
    jne r2, r1, lbb_15969                           if r2 != r1 { pc += -8 }
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    ldxdw r2, [r5+0x18]                     
    ldxdw r3, [r7+0x18]                     
    jne r3, r2, lbb_15969                           if r3 != r2 { pc += -12 }
lbb_15981:
    ldxdw r2, [r10-0x2e0]                   
    ldxdw r8, [r2+0x0]                      
    mov64 r2, 36                                    r2 = 36 as i32 as i64 as u64
    stxdw [r10-0x88], r2                    
    lddw r2, 0x100060b2c --> b"Wrong oracle passed for coin accountWrong oracle m"        r2 load str located at 4295363372
    stxdw [r10-0x90], r2                    
    mov64 r9, r6                                    r9 = r6
    jeq r1, 0, lbb_16147                            if r1 == (0 as i32 as i64 as u64) { pc += 157 }
    stxdw [r10-0x2e8], r5                   
    stxdw [r10-0x2e0], r9                   
    lddw r1, 0x100065490 --> b"\x00\x00\x00\x00\xca\x0a\x06\x00&\x00\x00\x00\x00\x00\x00\x00y\x00\x00\x0…        r1 load str located at 4295382160
    stxdw [r10-0x80], r1                    
    lddw r1, 0x100064c98 --> b"\x00\x00\x00\x00p\xfa\x05\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00…        r1 load str located at 4295380120
    stxdw [r10-0x248], r1                   
    mov64 r1, 2                                     r1 = 2 as i32 as i64 as u64
    stxdw [r10-0x240], r1                   
    stxdw [r10-0x230], r1                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -720                                  r1 += -720   ///  r1 = r1.wrapping_add(-720 as i32 as i64 as u64)
    stxdw [r10-0x238], r1                   
    lddw r1, 0x100000888 --> b"y\x11\x00\x00\x00\x00\x00\x00\x85\x10\x00\x00]\xab\x00\x00\x95\x00\x00\x0…        r1 load str located at 4294969480
    stxdw [r10-0x2b8], r1                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -128                                  r1 += -128   ///  r1 = r1.wrapping_add(-128 as i32 as i64 as u64)
    stxdw [r10-0x2c0], r1                   
    lddw r1, 0x100000860 --> b"\xbf#\x00\x00\x00\x00\x00\x00y\x12\x08\x00\x00\x00\x00\x00y\x11\x00\x00\x…        r1 load str located at 4294969440
    stxdw [r10-0x2c8], r1                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -144                                  r1 += -144   ///  r1 = r1.wrapping_add(-144 as i32 as i64 as u64)
    stxdw [r10-0x2d0], r1                   
    mov64 r9, 0                                     r9 = 0 as i32 as i64 as u64
    stxdw [r10-0x228], r9                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -120                                  r1 += -120   ///  r1 = r1.wrapping_add(-120 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -584                                  r2 += -584   ///  r2 = r2.wrapping_add(-584 as i32 as i64 as u64)
    call function_43415                     
    ldxdw r1, [r10-0x78]                    
    ldxdw r2, [r10-0x68]                    
    syscall [invalid]                       
    ldxdw r1, [r8+0x18]                     
    stxdw [r10-0x230], r1                   
    ldxdw r1, [r8+0x10]                     
    stxdw [r10-0x238], r1                   
    ldxdw r1, [r8+0x8]                      
    stxdw [r10-0x240], r1                   
    ldxdw r1, [r8+0x0]                      
    stxdw [r10-0x248], r1                   
    lddw r1, 0x300000000                            r1 load str located at 12884901888
    ldxdw r2, [r1+0x0]                      
    mov64 r3, 1                                     r3 = 1 as i32 as i64 as u64
    mov64 r1, r2                                    r1 = r2
    add64 r1, -32                                   r1 += -32   ///  r1 = r1.wrapping_add(-32 as i32 as i64 as u64)
    jgt r1, r2, lbb_16042                           if r1 > r2 { pc += 1 }
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
lbb_16042:
    jne r3, 0, lbb_16044                            if r3 != (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r9, r1                                    r9 = r1
lbb_16044:
    lddw r1, 0x300007fe0                            r1 load str located at 12884934624
    ldxdw r4, [r10-0x2e8]                   
    jeq r2, 0, lbb_16049                            if r2 == (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r1, r9                                    r1 = r9
lbb_16049:
    lddw r2, 0x300000007                            r2 load str located at 12884901895
    jgt r1, r2, lbb_16056                           if r1 > r2 { pc += 4 }
lbb_16052:
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    mov64 r2, 32                                    r2 = 32 as i32 as i64 as u64
    call function_43400                     
    syscall [invalid]                       
lbb_16056:
    lddw r2, 0x300000000                            r2 load str located at 12884901888
    stxdw [r2+0x0], r1                      
    ldxdw r3, [r10-0x230]                   
    stxdw [r1+0x18], r3                     
    ldxdw r3, [r10-0x238]                   
    stxdw [r1+0x10], r3                     
    ldxdw r3, [r10-0x240]                   
    stxdw [r1+0x8], r3                      
    ldxdw r3, [r10-0x248]                   
    stxdw [r1+0x0], r3                      
    ldxdw r3, [r4+0x18]                     
    stxdw [r10-0x230], r3                   
    ldxdw r3, [r4+0x10]                     
    stxdw [r10-0x238], r3                   
    ldxdw r3, [r4+0x8]                      
    stxdw [r10-0x240], r3                   
    ldxdw r3, [r4+0x0]                      
    stxdw [r10-0x248], r3                   
    ldxdw r3, [r2+0x0]                      
    mov64 r4, 0                                     r4 = 0 as i32 as i64 as u64
    mov64 r5, 1                                     r5 = 1 as i32 as i64 as u64
    mov64 r2, r3                                    r2 = r3
    add64 r2, -32                                   r2 += -32   ///  r2 = r2.wrapping_add(-32 as i32 as i64 as u64)
    ldxdw r9, [r10-0x2e0]                   
    jgt r2, r3, lbb_16083                           if r2 > r3 { pc += 1 }
    mov64 r5, 0                                     r5 = 0 as i32 as i64 as u64
lbb_16083:
    jne r5, 0, lbb_16085                            if r5 != (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r4, r2                                    r4 = r2
lbb_16085:
    lddw r2, 0x300007fe0                            r2 load str located at 12884934624
    jeq r3, 0, lbb_16089                            if r3 == (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r2, r4                                    r2 = r4
lbb_16089:
    lddw r3, 0x300000007                            r3 load str located at 12884901895
    jgt r2, r3, lbb_16093                           if r2 > r3 { pc += 1 }
    ja lbb_16052                                    if true { pc += -41 }
lbb_16093:
    lddw r3, 0x300000000                            r3 load str located at 12884901888
    stxdw [r3+0x0], r2                      
    ldxdw r4, [r10-0x230]                   
    stxdw [r2+0x18], r4                     
    ldxdw r4, [r10-0x238]                   
    stxdw [r2+0x10], r4                     
    ldxdw r4, [r10-0x240]                   
    stxdw [r2+0x8], r4                      
    ldxdw r4, [r10-0x248]                   
    stxdw [r2+0x0], r4                      
    ldxdw r4, [r7+0x18]                     
    stxdw [r10-0x230], r4                   
    ldxdw r4, [r7+0x10]                     
    stxdw [r10-0x238], r4                   
    ldxdw r4, [r7+0x8]                      
    stxdw [r10-0x240], r4                   
    ldxdw r4, [r7+0x0]                      
    stxdw [r10-0x248], r4                   
    ldxdw r4, [r3+0x0]                      
    mov64 r5, 0                                     r5 = 0 as i32 as i64 as u64
    mov64 r0, 1                                     r0 = 1 as i32 as i64 as u64
    mov64 r3, r4                                    r3 = r4
    add64 r3, -32                                   r3 += -32   ///  r3 = r3.wrapping_add(-32 as i32 as i64 as u64)
    jgt r3, r4, lbb_16119                           if r3 > r4 { pc += 1 }
    mov64 r0, 0                                     r0 = 0 as i32 as i64 as u64
lbb_16119:
    jne r0, 0, lbb_16121                            if r0 != (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r5, r3                                    r5 = r3
lbb_16121:
    lddw r3, 0x300007fe0                            r3 load str located at 12884934624
    jeq r4, 0, lbb_16125                            if r4 == (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r3, r5                                    r3 = r5
lbb_16125:
    lddw r4, 0x300000007                            r4 load str located at 12884901895
    jgt r3, r4, lbb_16129                           if r3 > r4 { pc += 1 }
    ja lbb_16052                                    if true { pc += -77 }
lbb_16129:
    lddw r4, 0x300000000                            r4 load str located at 12884901888
    stxdw [r4+0x0], r3                      
    ldxdw r4, [r10-0x230]                   
    stxdw [r3+0x18], r4                     
    ldxdw r4, [r10-0x238]                   
    stxdw [r3+0x10], r4                     
    ldxdw r4, [r10-0x240]                   
    stxdw [r3+0x8], r4                      
    ldxdw r4, [r10-0x248]                   
    stxdw [r3+0x0], r4                      
    ldxdw r4, [r10-0x2d8]                   
    stxdw [r4+0x18], r3                     
    stxdw [r4+0x10], r2                     
    stxdw [r4+0x8], r1                      
    mov64 r1, 28                                    r1 = 28 as i32 as i64 as u64
    stxb [r4+0x0], r1                       
    ja lbb_16207                                    if true { pc += 60 }
lbb_16147:
    mov64 r7, r4                                    r7 = r4
    mov64 r1, r7                                    r1 = r7
    add64 r1, 952                                   r1 += 952   ///  r1 = r1.wrapping_add(952 as i32 as i64 as u64)
    ldxdw r5, [r10-0x2e8]                   
    ldxdw r2, [r5+0x18]                     
    add64 r5, 24                                    r5 += 24   ///  r5 = r5.wrapping_add(24 as i32 as i64 as u64)
    ldxdw r3, [r7+0x3b8]                    
    jeq r3, r2, lbb_16157                           if r3 == r2 { pc += 2 }
lbb_16155:
    mov64 r2, 1                                     r2 = 1 as i32 as i64 as u64
    ja lbb_16167                                    if true { pc += 10 }
lbb_16157:
    ldxdw r2, [r5+0x8]                      
    ldxdw r3, [r1+0x8]                      
    jne r3, r2, lbb_16155                           if r3 != r2 { pc += -5 }
    ldxdw r2, [r5+0x10]                     
    ldxdw r3, [r1+0x10]                     
    jne r3, r2, lbb_16155                           if r3 != r2 { pc += -8 }
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
    ldxdw r3, [r5+0x18]                     
    ldxdw r4, [r1+0x18]                     
    jne r4, r3, lbb_16155                           if r4 != r3 { pc += -12 }
lbb_16167:
    jeq r2, 0, lbb_16214                            if r2 == (0 as i32 as i64 as u64) { pc += 46 }
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
    stxdw [r10-0x228], r2                   
    lddw r2, 0x1000654a8 --> b"\x00\x00\x00\x00P\x0b\x06\x00&\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x0…        r2 load str located at 4295382184
    stxdw [r10-0x248], r2                   
    mov64 r2, 2                                     r2 = 2 as i32 as i64 as u64
    stxdw [r10-0x240], r2                   
    stxdw [r10-0x230], r2                   
    mov64 r2, r10                                   r2 = r10
    add64 r2, -720                                  r2 += -720   ///  r2 = r2.wrapping_add(-720 as i32 as i64 as u64)
    stxdw [r10-0x238], r2                   
    stxdw [r10-0x2c0], r5                   
    lddw r2, 0x10004d200 --> b"\xbf&\x00\x00\x00\x00\x00\x00y\x12\x00\x00\x00\x00\x00\x00y\x13\x08\x00\x…        r2 load str located at 4295283200
    stxdw [r10-0x2b8], r2                   
    stxdw [r10-0x2c8], r2                   
    stxdw [r10-0x2d0], r1                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -344                                  r1 += -344   ///  r1 = r1.wrapping_add(-344 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -584                                  r2 += -584   ///  r2 = r2.wrapping_add(-584 as i32 as i64 as u64)
    call function_43415                     
    ldxdw r1, [r10-0x158]                   
    stxdw [r10-0x170], r1                   
    ldxdw r1, [r10-0x150]                   
    stxdw [r10-0x168], r1                   
    ldxdw r1, [r10-0x148]                   
    stxdw [r10-0x160], r1                   
    mov64 r1, 29                                    r1 = 29 as i32 as i64 as u64
    ldxdw r2, [r10-0x2d8]                   
    stxb [r2+0x0], r1                       
    ldxdw r1, [r10-0x177]                   
    stxdw [r2+0x1], r1                      
    ldxdw r1, [r10-0x16f]                   
    stxdw [r2+0x9], r1                      
    ldxdw r1, [r10-0x167]                   
    stxdw [r2+0x11], r1                     
    ldxdw r1, [r10-0x160]                   
    stxdw [r2+0x18], r1                     
lbb_16207:
    mov64 r1, 2                                     r1 = 2 as i32 as i64 as u64
    ldxdw r2, [r10-0x2d8]                   
    stxw [r2+0xa8], r1                      
    ldxdw r1, [r9+0x0]                      
    add64 r1, -1                                    r1 += -1   ///  r1 = r1.wrapping_add(-1 as i32 as i64 as u64)
    stxdw [r9+0x0], r1                      
lbb_16213:
    exit                                    
lbb_16214:
    ldxdw r6, [r10-0x2d8]                   
    mov64 r1, r6                                    r1 = r6
    add64 r1, 32                                    r1 += 32   ///  r1 = r1.wrapping_add(32 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -280                                  r2 += -280   ///  r2 = r2.wrapping_add(-280 as i32 as i64 as u64)
    mov64 r3, 136                                   r3 = 136 as i32 as i64 as u64
    call function_48190                     
    mov64 r1, r6                                    r1 = r6
    add64 r1, 172                                   r1 += 172   ///  r1 = r1.wrapping_add(172 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -316                                  r2 += -316   ///  r2 = r2.wrapping_add(-316 as i32 as i64 as u64)
    mov64 r3, 36                                    r3 = 36 as i32 as i64 as u64
    call function_48190                     
    ldxdw r1, [r10-0x2f8]                   
    stxw [r6+0xa8], r1                      
    ldxdw r1, [r10-0x2f0]                   
    stxdw [r6+0x18], r1                     
    ldxdw r1, [r10-0x2e0]                   
    stxdw [r6+0x10], r1                     
    stxdw [r6+0x8], r9                      
    stxdw [r6+0x0], r7                      
    ja lbb_16213                                    if true { pc += -23 }

function_16236:
    mov64 r0, r2                                    r0 = r2
    mov64 r6, r1                                    r6 = r1
    jgt r4, 1, lbb_16281                            if r4 > (1 as i32 as i64 as u64) { pc += 42 }
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    stxdw [r10-0xc0], r1                    
    lddw r1, 0x1000654c8 --> b"\x00\x00\x00\x00y\x0b\x06\x00-\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x0…        r1 load str located at 4295382216
    stxdw [r10-0xe0], r1                    
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    stxdw [r10-0xc8], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -696                                  r1 += -696   ///  r1 = r1.wrapping_add(-696 as i32 as i64 as u64)
    stxdw [r10-0xd0], r1                    
    lddw r1, 0x10005df58 --> b"\xbf#\x00\x00\x00\x00\x00\x00y\x11\x00\x00\x00\x00\x00\x00\xb7\x02\x00\x0…        r1 load str located at 4295352152
    stxdw [r10-0x2b0], r1                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -872                                  r1 += -872   ///  r1 = r1.wrapping_add(-872 as i32 as i64 as u64)
    stxdw [r10-0x2b8], r1                   
    stxdw [r10-0x368], r4                   
    mov64 r7, 2                                     r7 = 2 as i32 as i64 as u64
    stxdw [r10-0xd8], r7                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -1992                                 r1 += -1992   ///  r1 = r1.wrapping_add(-1992 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -224                                  r2 += -224   ///  r2 = r2.wrapping_add(-224 as i32 as i64 as u64)
    call function_43415                     
    ldxdw r1, [r10-0x7c8]                   
    stxdw [r10-0x7e0], r1                   
    ldxdw r1, [r10-0x7c0]                   
    stxdw [r10-0x7d8], r1                   
    ldxdw r1, [r10-0x7b8]                   
    stxdw [r10-0x7d0], r1                   
    mov64 r1, 29                                    r1 = 29 as i32 as i64 as u64
    stxb [r6+0x0], r1                       
    ldxdw r1, [r10-0x7e7]                   
    stxdw [r6+0x1], r1                      
    ldxdw r1, [r10-0x7df]                   
    stxdw [r6+0x9], r1                      
    ldxdw r1, [r10-0x7d7]                   
    stxdw [r6+0x11], r1                     
    ldxdw r1, [r10-0x7d0]                   
    stxdw [r6+0x18], r1                     
    stxw [r6+0xa8], r7                      
    ja lbb_16616                                    if true { pc += 335 }
lbb_16281:
    ldxdw r7, [r3+0x40]                     
    ldxdw r1, [r7+0x10]                     
    lddw r2, 0x7ffffffffffffffe                     r2 load str located at 9223372036854775806
    jgt r1, r2, lbb_16785                           if r1 > r2 { pc += 499 }
    stxdw [r10-0x800], r3                   
    ldxdw r2, [r5-0xfe8]                    
    stxdw [r10-0x828], r2                   
    ldxdw r2, [r5-0xff0]                    
    stxdw [r10-0x830], r2                   
    ldxdw r2, [r5-0xff8]                    
    stxdw [r10-0x7f0], r2                   
    ldxdw r2, [r5-0x1000]                   
    stxdw [r10-0x820], r2                   
    add64 r1, 1                                     r1 += 1   ///  r1 = r1.wrapping_add(1 as i32 as i64 as u64)
    stxdw [r7+0x10], r1                     
    ldxdw r1, [r7+0x20]                     
    stxdw [r10-0x7f8], r0                   
    stxdw [r10-0x818], r6                   
    stxdw [r10-0x838], r4                   
    stxdw [r10-0x808], r7                   
    jeq r1, 165, lbb_16306                          if r1 == (165 as i32 as i64 as u64) { pc += 3 }
    mov64 r1, 3                                     r1 = 3 as i32 as i64 as u64
    stxw [r10-0xe0], r1                     
    ja lbb_16313                                    if true { pc += 7 }
lbb_16306:
    ldxdw r2, [r7+0x18]                     
    mov64 r1, r10                                   r1 = r10
    add64 r1, -224                                  r1 += -224   ///  r1 = r1.wrapping_add(-224 as i32 as i64 as u64)
    mov64 r3, 165                                   r3 = 165 as i32 as i64 as u64
    call function_32610                     
    ldxw r9, [r10-0x58]                     
    jne r9, 2, lbb_16472                            if r9 != (2 as i32 as i64 as u64) { pc += 159 }
lbb_16313:
    ldxdw r1, [r10-0xe0]                    
    stxdw [r10-0x2b8], r1                   
    ldxdw r1, [r10-0xd8]                    
    stxdw [r10-0x2b0], r1                   
    ldxdw r1, [r10-0xd0]                    
    stxdw [r10-0x2a8], r1                   
    ldxdw r1, [r10-0xc8]                    
    stxdw [r10-0x2a0], r1                   
    mov64 r1, 2                                     r1 = 2 as i32 as i64 as u64
    stxw [r10-0x230], r1                    
lbb_16323:
    mov64 r1, r10                                   r1 = r10
    add64 r1, -872                                  r1 += -872   ///  r1 = r1.wrapping_add(-872 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -696                                  r2 += -696   ///  r2 = r2.wrapping_add(-696 as i32 as i64 as u64)
    call function_1296                      
    ldxw r8, [r10-0x2e0]                    
    ldxdw r9, [r10-0x368]                   
    ldxdw r7, [r10-0x360]                   
    ldxdw r1, [r10-0x358]                   
    stxdw [r10-0x810], r1                   
    ldxdw r6, [r10-0x350]                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -912                                  r1 += -912   ///  r1 = r1.wrapping_add(-912 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -840                                  r2 += -840   ///  r2 = r2.wrapping_add(-840 as i32 as i64 as u64)
    mov64 r3, 40                                    r3 = 40 as i32 as i64 as u64
    call function_48190                     
    jeq r8, 2, lbb_16342                            if r8 == (2 as i32 as i64 as u64) { pc += 1 }
    ja lbb_16357                                    if true { pc += 15 }
lbb_16342:
    stxdw [r10-0x7f8], r7                   
    mov64 r8, r9                                    r8 = r9
    stxdw [r10-0x7f0], r6                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -1472                                 r1 += -1472   ///  r1 = r1.wrapping_add(-1472 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -912                                  r2 += -912   ///  r2 = r2.wrapping_add(-912 as i32 as i64 as u64)
    mov64 r3, 40                                    r3 = 40 as i32 as i64 as u64
    call function_48190                     
    ldxdw r2, [r10-0x808]                   
    ldxdw r1, [r2+0x10]                     
    add64 r1, -1                                    r1 += -1   ///  r1 = r1.wrapping_add(-1 as i32 as i64 as u64)
    stxdw [r2+0x10], r1                     
    ldxdw r9, [r10-0x810]                   
    ja lbb_16583                                    if true { pc += 226 }
lbb_16357:
    mov64 r1, r10                                   r1 = r10
    add64 r1, -1016                                 r1 += -1016   ///  r1 = r1.wrapping_add(-1016 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -800                                  r2 += -800   ///  r2 = r2.wrapping_add(-800 as i32 as i64 as u64)
    mov64 r3, 64                                    r3 = 64 as i32 as i64 as u64
    call function_48190                     
    mov64 r1, r10                                   r1 = r10
    add64 r1, -948                                  r1 += -948   ///  r1 = r1.wrapping_add(-948 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -732                                  r2 += -732   ///  r2 = r2.wrapping_add(-732 as i32 as i64 as u64)
    stxdw [r10-0x840], r1                   
    mov64 r3, 36                                    r3 = 36 as i32 as i64 as u64
    call function_48190                     
    stxdw [r10-0x428], r6                   
    ldxdw r1, [r10-0x810]                   
    stxdw [r10-0x430], r1                   
    stxdw [r10-0x438], r7                   
    stxdw [r10-0x440], r9                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -1056                                 r1 += -1056   ///  r1 = r1.wrapping_add(-1056 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -912                                  r2 += -912   ///  r2 = r2.wrapping_add(-912 as i32 as i64 as u64)
    mov64 r3, 40                                    r3 = 40 as i32 as i64 as u64
    call function_48190                     
    stxw [r10-0x3b8], r8                    
    ldxdw r2, [r10-0x808]                   
    ldxdw r1, [r2+0x10]                     
    add64 r1, -1                                    r1 += -1   ///  r1 = r1.wrapping_add(-1 as i32 as i64 as u64)
    stxdw [r2+0x10], r1                     
    mov64 r1, r10                                   r1 = r10
    add64 r1, -1088                                 r1 += -1088   ///  r1 = r1.wrapping_add(-1088 as i32 as i64 as u64)
    stxdw [r10-0x1000], r1                  
    ldxdw r9, [r10-0x800]                   
    stxdw [r10-0xff8], r9                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -224                                  r1 += -224   ///  r1 = r1.wrapping_add(-224 as i32 as i64 as u64)
    mov64 r5, r10                                   r5 = r10
    ldxdw r2, [r10-0x7f8]                   
    ldxdw r3, [r10-0x820]                   
    ldxdw r4, [r10-0x7f0]                   
    call function_14847                     
    ldxb r7, [r10-0xe0]                     
    jne r7, 56, lbb_16505                           if r7 != (56 as i32 as i64 as u64) { pc += 105 }
    mov64 r1, r9                                    r1 = r9
    add64 r1, 48                                    r1 += 48   ///  r1 = r1.wrapping_add(48 as i32 as i64 as u64)
    ldxdw r8, [r10-0xd0]                    
    ldxdw r6, [r10-0xd8]                    
    stxdw [r10-0x7f0], r1                   
    ldxdw r7, [r1+0x0]                      
    mov64 r1, r10                                   r1 = r10
    add64 r1, -224                                  r1 += -224   ///  r1 = r1.wrapping_add(-224 as i32 as i64 as u64)
    mov64 r3, r10                                   r3 = r10
    add64 r3, -1088                                 r3 += -1088   ///  r3 = r3.wrapping_add(-1088 as i32 as i64 as u64)
    mov64 r2, r6                                    r2 = r6
    mov64 r4, r7                                    r4 = r7
    call function_22478                     
    ldxb r1, [r10-0xe0]                     
    stxdw [r10-0x808], r8                   
    jeq r1, 56, lbb_16417                           if r1 == (56 as i32 as i64 as u64) { pc += 1 }
    ja lbb_16552                                    if true { pc += 135 }
lbb_16417:
    ldxdw r4, [r9+0x0]                      
    mov64 r8, r6                                    r8 = r6
    ldxb r3, [r6+0x419]                     
    mov64 r1, r10                                   r1 = r10
    add64 r1, -224                                  r1 += -224   ///  r1 = r1.wrapping_add(-224 as i32 as i64 as u64)
    mov64 r2, r7                                    r2 = r7
    stxdw [r10-0x810], r4                   
    ldxdw r5, [r10-0x7f8]                   
    call function_22000                     
    ldxb r1, [r10-0xe0]                     
    jeq r1, 56, lbb_16429                           if r1 == (56 as i32 as i64 as u64) { pc += 1 }
    ja lbb_16554                                    if true { pc += 125 }
lbb_16429:
    mov64 r1, r10                                   r1 = r10
    add64 r1, -1472                                 r1 += -1472   ///  r1 = r1.wrapping_add(-1472 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -1088                                 r2 += -1088   ///  r2 = r2.wrapping_add(-1088 as i32 as i64 as u64)
    mov64 r3, 136                                   r3 = 136 as i32 as i64 as u64
    call function_48190                     
    ldxw r6, [r10-0x3b8]                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -1508                                 r1 += -1508   ///  r1 = r1.wrapping_add(-1508 as i32 as i64 as u64)
    ldxdw r2, [r10-0x840]                   
    mov64 r3, 36                                    r3 = 36 as i32 as i64 as u64
    call function_48190                     
    ldxdw r1, [r10-0x808]                   
    stxdw [r10-0x7f8], r1                   
    jeq r6, 2, lbb_16583                            if r6 == (2 as i32 as i64 as u64) { pc += 139 }
    stxdw [r10-0x7f8], r6                   
    mov64 r7, r10                                   r7 = r10
    add64 r7, -1648                                 r7 += -1648   ///  r7 = r7.wrapping_add(-1648 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -1472                                 r2 += -1472   ///  r2 = r2.wrapping_add(-1472 as i32 as i64 as u64)
    mov64 r1, r7                                    r1 = r7
    mov64 r3, 136                                   r3 = 136 as i32 as i64 as u64
    call function_48190                     
    mov64 r1, r10                                   r1 = r10
    add64 r1, -1308                                 r1 += -1308   ///  r1 = r1.wrapping_add(-1308 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -1508                                 r2 += -1508   ///  r2 = r2.wrapping_add(-1508 as i32 as i64 as u64)
    mov64 r3, 36                                    r3 = 36 as i32 as i64 as u64
    call function_48190                     
    mov64 r1, r10                                   r1 = r10
    add64 r1, -1272                                 r1 += -1272   ///  r1 = r1.wrapping_add(-1272 as i32 as i64 as u64)
    mov64 r2, r7                                    r2 = r7
    mov64 r3, 136                                   r3 = 136 as i32 as i64 as u64
    call function_48190                     
    mov64 r5, r8                                    r5 = r8
    mov64 r7, r5                                    r7 = r5
    add64 r7, 920                                   r7 += 920   ///  r7 = r7.wrapping_add(920 as i32 as i64 as u64)
    ldxdw r6, [r10-0x828]                   
    ldxdw r1, [r6+0x0]                      
    ldxdw r2, [r5+0x398]                    
    jeq r2, r1, lbb_16617                           if r2 == r1 { pc += 147 }
lbb_16470:
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    ja lbb_16627                                    if true { pc += 155 }
lbb_16472:
    mov64 r8, r10                                   r8 = r10
    add64 r8, -336                                  r8 += -336   ///  r8 = r8.wrapping_add(-336 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -224                                  r2 += -224   ///  r2 = r2.wrapping_add(-224 as i32 as i64 as u64)
    mov64 r1, r8                                    r1 = r8
    mov64 r3, 108                                   r3 = 108 as i32 as i64 as u64
    call function_48190                     
    ldxdw r1, [r10-0x73]                    
    stxdw [r10-0x1e0], r1                   
    ldxdw r1, [r10-0x6b]                    
    stxdw [r10-0x1d8], r1                   
    ldxdw r1, [r10-0x63]                    
    stxdw [r10-0x1d0], r1                   
    ldxw r1, [r10-0x5c]                     
    stxw [r10-0x1c9], r1                    
    ldxb r6, [r10-0x74]                     
    mov64 r1, r10                                   r1 = r10
    add64 r1, -516                                  r1 += -516   ///  r1 = r1.wrapping_add(-516 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -84                                   r2 += -84   ///  r2 = r2.wrapping_add(-84 as i32 as i64 as u64)
    mov64 r3, 36                                    r3 = 36 as i32 as i64 as u64
    call function_48190                     
    mov64 r1, r10                                   r1 = r10
    add64 r1, -448                                  r1 += -448   ///  r1 = r1.wrapping_add(-448 as i32 as i64 as u64)
    mov64 r2, r8                                    r2 = r8
    mov64 r3, 108                                   r3 = 108 as i32 as i64 as u64
    call function_48190                     
    jne r6, 0, lbb_16529                            if r6 != (0 as i32 as i64 as u64) { pc += 29 }
    mov64 r1, 2                                     r1 = 2 as i32 as i64 as u64
    stxw [r10-0x230], r1                    
    mov64 r1, 9                                     r1 = 9 as i32 as i64 as u64
    stxw [r10-0x2b8], r1                    
    ja lbb_16323                                    if true { pc += -182 }
lbb_16505:
    ldxdw r1, [r10-0xc8]                    
    stxdw [r10-0x7f0], r1                   
    ldxdw r1, [r10-0xd0]                    
    stxdw [r10-0x800], r1                   
    ldxdw r1, [r10-0xd8]                    
    stxdw [r10-0x7f8], r1                   
    ldxw r6, [r10-0xdf]                     
    ldxb r8, [r10-0xd9]                     
    ldxh r9, [r10-0xdb]                     
    mov64 r1, r10                                   r1 = r10
    add64 r1, -1472                                 r1 += -1472   ///  r1 = r1.wrapping_add(-1472 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -192                                  r2 += -192   ///  r2 = r2.wrapping_add(-192 as i32 as i64 as u64)
    mov64 r3, 40                                    r3 = 40 as i32 as i64 as u64
    call function_48190                     
    lsh64 r9, 32                                    r9 <<= 32   ///  r9 = r9.wrapping_shl(32)
    lsh64 r8, 48                                    r8 <<= 48   ///  r8 = r8.wrapping_shl(48)
    or64 r8, r9                                     r8 |= r9   ///  r8 = r8.or(r9)
    ldxdw r9, [r10-0x800]                   
    or64 r6, r8                                     r6 |= r8   ///  r6 = r6.or(r8)
    lsh64 r6, 8                                     r6 <<= 8   ///  r6 = r6.wrapping_shl(8)
    or64 r6, r7                                     r6 |= r7   ///  r6 = r6.or(r7)
    mov64 r8, r6                                    r8 = r6
    ja lbb_16583                                    if true { pc += 54 }
lbb_16529:
    mov64 r1, r10                                   r1 = r10
    add64 r1, -696                                  r1 += -696   ///  r1 = r1.wrapping_add(-696 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -448                                  r2 += -448   ///  r2 = r2.wrapping_add(-448 as i32 as i64 as u64)
    mov64 r3, 108                                   r3 = 108 as i32 as i64 as u64
    call function_48190                     
    ldxdw r1, [r10-0x1e0]                   
    stxdw [r10-0x24b], r1                   
    ldxdw r1, [r10-0x1d8]                   
    stxdw [r10-0x243], r1                   
    ldxdw r1, [r10-0x1d0]                   
    stxdw [r10-0x23b], r1                   
    ldxw r1, [r10-0x1c9]                    
    stxw [r10-0x234], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -556                                  r1 += -556   ///  r1 = r1.wrapping_add(-556 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -516                                  r2 += -516   ///  r2 = r2.wrapping_add(-516 as i32 as i64 as u64)
    mov64 r3, 36                                    r3 = 36 as i32 as i64 as u64
    call function_48190                     
    stxw [r10-0x230], r9                    
    stxb [r10-0x24c], r6                    
    ja lbb_16323                                    if true { pc += -229 }
lbb_16552:
    stxdw [r10-0x800], r1                   
    ja lbb_16556                                    if true { pc += 2 }
lbb_16554:
    stxdw [r10-0x800], r1                   
    ldxdw r1, [r10-0x808]                   
lbb_16556:
    ldxdw r1, [r10-0xc8]                    
    stxdw [r10-0x7f0], r1                   
    ldxdw r9, [r10-0xd0]                    
    ldxdw r1, [r10-0xd8]                    
    stxdw [r10-0x7f8], r1                   
    ldxw r6, [r10-0xdf]                     
    ldxb r7, [r10-0xd9]                     
    ldxh r8, [r10-0xdb]                     
    mov64 r1, r10                                   r1 = r10
    add64 r1, -1472                                 r1 += -1472   ///  r1 = r1.wrapping_add(-1472 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -192                                  r2 += -192   ///  r2 = r2.wrapping_add(-192 as i32 as i64 as u64)
    mov64 r3, 40                                    r3 = 40 as i32 as i64 as u64
    call function_48190                     
    mov64 r3, r6                                    r3 = r6
    lsh64 r8, 32                                    r8 <<= 32   ///  r8 = r8.wrapping_shl(32)
    lsh64 r7, 48                                    r7 <<= 48   ///  r7 = r7.wrapping_shl(48)
    or64 r7, r8                                     r7 |= r8   ///  r7 = r7.or(r8)
    or64 r3, r7                                     r3 |= r7   ///  r3 = r3.or(r7)
    ldxdw r2, [r10-0x808]                   
    ldxdw r1, [r2+0x0]                      
    add64 r1, 1                                     r1 += 1   ///  r1 = r1.wrapping_add(1 as i32 as i64 as u64)
    stxdw [r2+0x0], r1                      
    lsh64 r3, 8                                     r3 <<= 8   ///  r3 = r3.wrapping_shl(8)
    ldxdw r1, [r10-0x800]                   
    or64 r3, r1                                     r3 |= r1   ///  r3 = r3.or(r1)
    mov64 r8, r3                                    r8 = r3
lbb_16583:
    mov64 r7, r10                                   r7 = r10
    add64 r7, -1648                                 r7 += -1648   ///  r7 = r7.wrapping_add(-1648 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -1472                                 r2 += -1472   ///  r2 = r2.wrapping_add(-1472 as i32 as i64 as u64)
    mov64 r1, r7                                    r1 = r7
    mov64 r3, 40                                    r3 = 40 as i32 as i64 as u64
    call function_48190                     
    mov64 r1, r10                                   r1 = r10
    add64 r1, -1832                                 r1 += -1832   ///  r1 = r1.wrapping_add(-1832 as i32 as i64 as u64)
    mov64 r2, r7                                    r2 = r7
    mov64 r3, 40                                    r3 = 40 as i32 as i64 as u64
    call function_48190                     
lbb_16595:
    mov64 r7, r10                                   r7 = r10
    add64 r7, -1968                                 r7 += -1968   ///  r7 = r7.wrapping_add(-1968 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -1832                                 r2 += -1832   ///  r2 = r2.wrapping_add(-1832 as i32 as i64 as u64)
    mov64 r1, r7                                    r1 = r7
    mov64 r3, 40                                    r3 = 40 as i32 as i64 as u64
    call function_48190                     
    ldxdw r6, [r10-0x818]                   
    mov64 r1, r6                                    r1 = r6
    add64 r1, 32                                    r1 += 32   ///  r1 = r1.wrapping_add(32 as i32 as i64 as u64)
    mov64 r2, r7                                    r2 = r7
    mov64 r3, 40                                    r3 = 40 as i32 as i64 as u64
    call function_48190                     
    mov64 r1, 2                                     r1 = 2 as i32 as i64 as u64
    stxw [r6+0xa8], r1                      
    ldxdw r1, [r10-0x7f0]                   
    stxdw [r6+0x18], r1                     
    stxdw [r6+0x10], r9                     
    ldxdw r1, [r10-0x7f8]                   
    stxdw [r6+0x8], r1                      
    stxdw [r6+0x0], r8                      
lbb_16616:
    exit                                    
lbb_16617:
    ldxdw r1, [r6+0x8]                      
    ldxdw r2, [r7+0x8]                      
    jne r2, r1, lbb_16470                           if r2 != r1 { pc += -150 }
    ldxdw r1, [r6+0x10]                     
    ldxdw r2, [r7+0x10]                     
    jne r2, r1, lbb_16470                           if r2 != r1 { pc += -153 }
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    ldxdw r2, [r6+0x18]                     
    ldxdw r3, [r7+0x18]                     
    jne r3, r2, lbb_16470                           if r3 != r2 { pc += -157 }
lbb_16627:
    mov64 r2, 36                                    r2 = 36 as i32 as i64 as u64
    stxdw [r10-0x438], r2                   
    lddw r2, 0x100060b2c --> b"Wrong oracle passed for coin accountWrong oracle m"        r2 load str located at 4295363372
    stxdw [r10-0x440], r2                   
    ldxdw r2, [r10-0x808]                   
    jeq r1, 0, lbb_16789                            if r1 == (0 as i32 as i64 as u64) { pc += 155 }
    lddw r1, 0x100065490 --> b"\x00\x00\x00\x00\xca\x0a\x06\x00&\x00\x00\x00\x00\x00\x00\x00y\x00\x00\x0…        r1 load str located at 4295382160
    stxdw [r10-0x5c0], r1                   
    lddw r1, 0x100064c98 --> b"\x00\x00\x00\x00p\xfa\x05\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00…        r1 load str located at 4295380120
    stxdw [r10-0xe0], r1                    
    mov64 r1, 2                                     r1 = 2 as i32 as i64 as u64
    stxdw [r10-0xd8], r1                    
    stxdw [r10-0xc8], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -696                                  r1 += -696   ///  r1 = r1.wrapping_add(-696 as i32 as i64 as u64)
    stxdw [r10-0xd0], r1                    
    lddw r1, 0x100000888 --> b"y\x11\x00\x00\x00\x00\x00\x00\x85\x10\x00\x00]\xab\x00\x00\x95\x00\x00\x0…        r1 load str located at 4294969480
    stxdw [r10-0x2a0], r1                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -1472                                 r1 += -1472   ///  r1 = r1.wrapping_add(-1472 as i32 as i64 as u64)
    stxdw [r10-0x2a8], r1                   
    lddw r1, 0x100000860 --> b"\xbf#\x00\x00\x00\x00\x00\x00y\x12\x08\x00\x00\x00\x00\x00y\x11\x00\x00\x…        r1 load str located at 4294969440
    stxdw [r10-0x2b0], r1                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -1088                                 r1 += -1088   ///  r1 = r1.wrapping_add(-1088 as i32 as i64 as u64)
    stxdw [r10-0x2b8], r1                   
    mov64 r8, 0                                     r8 = 0 as i32 as i64 as u64
    stxdw [r10-0xc0], r8                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -872                                  r1 += -872   ///  r1 = r1.wrapping_add(-872 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -224                                  r2 += -224   ///  r2 = r2.wrapping_add(-224 as i32 as i64 as u64)
    call function_43415                     
    ldxdw r1, [r10-0x368]                   
    ldxdw r2, [r10-0x358]                   
    syscall [invalid]                       
    ldxdw r2, [r10-0x810]                   
    ldxdw r1, [r2+0x18]                     
    stxdw [r10-0xc8], r1                    
    ldxdw r1, [r2+0x10]                     
    stxdw [r10-0xd0], r1                    
    ldxdw r1, [r2+0x8]                      
    stxdw [r10-0xd8], r1                    
    ldxdw r1, [r2+0x0]                      
    stxdw [r10-0xe0], r1                    
    lddw r1, 0x300000000                            r1 load str located at 12884901888
    ldxdw r1, [r1+0x0]                      
    mov64 r3, 1                                     r3 = 1 as i32 as i64 as u64
    mov64 r2, r1                                    r2 = r1
    add64 r2, -32                                   r2 += -32   ///  r2 = r2.wrapping_add(-32 as i32 as i64 as u64)
    jgt r2, r1, lbb_16685                           if r2 > r1 { pc += 1 }
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
lbb_16685:
    jne r3, 0, lbb_16687                            if r3 != (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r8, r2                                    r8 = r2
lbb_16687:
    lddw r5, 0x300007fe0                            r5 load str located at 12884934624
    jeq r1, 0, lbb_16691                            if r1 == (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r5, r8                                    r5 = r8
lbb_16691:
    lddw r1, 0x300000007                            r1 load str located at 12884901895
    jgt r5, r1, lbb_16698                           if r5 > r1 { pc += 4 }
lbb_16694:
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    mov64 r2, 32                                    r2 = 32 as i32 as i64 as u64
    call function_43400                     
    syscall [invalid]                       
lbb_16698:
    lddw r1, 0x300000000                            r1 load str located at 12884901888
    stxdw [r1+0x0], r5                      
    ldxdw r2, [r10-0xc8]                    
    stxdw [r5+0x18], r2                     
    ldxdw r2, [r10-0xd0]                    
    stxdw [r5+0x10], r2                     
    ldxdw r2, [r10-0xd8]                    
    stxdw [r5+0x8], r2                      
    ldxdw r2, [r10-0xe0]                    
    stxdw [r5+0x0], r2                      
    ldxdw r2, [r6+0x18]                     
    stxdw [r10-0xc8], r2                    
    ldxdw r2, [r6+0x10]                     
    stxdw [r10-0xd0], r2                    
    ldxdw r2, [r6+0x8]                      
    stxdw [r10-0xd8], r2                    
    ldxdw r2, [r6+0x0]                      
    stxdw [r10-0xe0], r2                    
    ldxdw r1, [r1+0x0]                      
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
    mov64 r4, 1                                     r4 = 1 as i32 as i64 as u64
    mov64 r3, r1                                    r3 = r1
    add64 r3, -32                                   r3 += -32   ///  r3 = r3.wrapping_add(-32 as i32 as i64 as u64)
    jgt r3, r1, lbb_16724                           if r3 > r1 { pc += 1 }
    mov64 r4, 0                                     r4 = 0 as i32 as i64 as u64
lbb_16724:
    jne r4, 0, lbb_16726                            if r4 != (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r2, r3                                    r2 = r3
lbb_16726:
    lddw r9, 0x300007fe0                            r9 load str located at 12884934624
    jeq r1, 0, lbb_16730                            if r1 == (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r9, r2                                    r9 = r2
lbb_16730:
    lddw r1, 0x300000007                            r1 load str located at 12884901895
    jgt r9, r1, lbb_16734                           if r9 > r1 { pc += 1 }
    ja lbb_16694                                    if true { pc += -40 }
lbb_16734:
    lddw r1, 0x300000000                            r1 load str located at 12884901888
    stxdw [r1+0x0], r9                      
    ldxdw r2, [r10-0xc8]                    
    stxdw [r9+0x18], r2                     
    ldxdw r2, [r10-0xd0]                    
    stxdw [r9+0x10], r2                     
    ldxdw r2, [r10-0xd8]                    
    stxdw [r9+0x8], r2                      
    ldxdw r2, [r10-0xe0]                    
    stxdw [r9+0x0], r2                      
    ldxdw r2, [r7+0x18]                     
    stxdw [r10-0xc8], r2                    
    ldxdw r2, [r7+0x10]                     
    stxdw [r10-0xd0], r2                    
    ldxdw r2, [r7+0x8]                      
    stxdw [r10-0xd8], r2                    
    ldxdw r2, [r7+0x0]                      
    stxdw [r10-0xe0], r2                    
    ldxdw r1, [r1+0x0]                      
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
    mov64 r4, 1                                     r4 = 1 as i32 as i64 as u64
    mov64 r3, r1                                    r3 = r1
    add64 r3, -32                                   r3 += -32   ///  r3 = r3.wrapping_add(-32 as i32 as i64 as u64)
    jgt r3, r1, lbb_16760                           if r3 > r1 { pc += 1 }
    mov64 r4, 0                                     r4 = 0 as i32 as i64 as u64
lbb_16760:
    jne r4, 0, lbb_16762                            if r4 != (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r2, r3                                    r2 = r3
lbb_16762:
    lddw r3, 0x300007fe0                            r3 load str located at 12884934624
    jeq r1, 0, lbb_16766                            if r1 == (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r3, r2                                    r3 = r2
lbb_16766:
    lddw r1, 0x300000007                            r1 load str located at 12884901895
    jgt r3, r1, lbb_16770                           if r3 > r1 { pc += 1 }
    ja lbb_16694                                    if true { pc += -76 }
lbb_16770:
    stxdw [r10-0x7f8], r5                   
    lddw r1, 0x300000000                            r1 load str located at 12884901888
    stxdw [r1+0x0], r3                      
    ldxdw r1, [r10-0xc8]                    
    stxdw [r3+0x18], r1                     
    ldxdw r1, [r10-0xd0]                    
    stxdw [r3+0x10], r1                     
    ldxdw r1, [r10-0xd8]                    
    stxdw [r3+0x8], r1                      
    ldxdw r1, [r10-0xe0]                    
    stxdw [r10-0x7f0], r3                   
    stxdw [r3+0x0], r1                      
    mov64 r8, 28                                    r8 = 28 as i32 as i64 as u64
    ja lbb_16826                                    if true { pc += 41 }
lbb_16785:
    lddw r1, 0x100065478 --> b"\x00\x00\x00\x00\xca\x0a\x06\x00&\x00\x00\x00\x00\x00\x00\x00N\x00\x00\x0…        r1 load str located at 4295382136
    call function_43759                     
    syscall [invalid]                       
lbb_16789:
    mov64 r1, r5                                    r1 = r5
    add64 r1, 952                                   r1 += 952   ///  r1 = r1.wrapping_add(952 as i32 as i64 as u64)
    ldxdw r0, [r10-0x830]                   
    ldxdw r2, [r0+0x18]                     
    add64 r0, 24                                    r0 += 24   ///  r0 = r0.wrapping_add(24 as i32 as i64 as u64)
    ldxdw r3, [r5+0x3b8]                    
    jeq r3, r2, lbb_16831                           if r3 == r2 { pc += 35 }
lbb_16796:
    mov64 r2, 1                                     r2 = 1 as i32 as i64 as u64
    jeq r2, 0, lbb_16843                            if r2 == (0 as i32 as i64 as u64) { pc += 45 }
lbb_16798:
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
    stxdw [r10-0xc0], r2                    
    lddw r2, 0x1000654a8 --> b"\x00\x00\x00\x00P\x0b\x06\x00&\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x0…        r2 load str located at 4295382184
    stxdw [r10-0xe0], r2                    
    mov64 r2, 2                                     r2 = 2 as i32 as i64 as u64
    stxdw [r10-0xd8], r2                    
    stxdw [r10-0xc8], r2                    
    mov64 r2, r10                                   r2 = r10
    add64 r2, -696                                  r2 += -696   ///  r2 = r2.wrapping_add(-696 as i32 as i64 as u64)
    stxdw [r10-0xd0], r2                    
    stxdw [r10-0x2a8], r0                   
    lddw r2, 0x10004d200 --> b"\xbf&\x00\x00\x00\x00\x00\x00y\x12\x00\x00\x00\x00\x00\x00y\x13\x08\x00\x…        r2 load str located at 4295283200
    stxdw [r10-0x2a0], r2                   
    stxdw [r10-0x2b0], r2                   
    stxdw [r10-0x2b8], r1                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -1336                                 r1 += -1336   ///  r1 = r1.wrapping_add(-1336 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -224                                  r2 += -224   ///  r2 = r2.wrapping_add(-224 as i32 as i64 as u64)
    call function_43415                     
    mov64 r8, 29                                    r8 = 29 as i32 as i64 as u64
    ldxdw r1, [r10-0x528]                   
    stxdw [r10-0x7f0], r1                   
    ldxdw r9, [r10-0x530]                   
    ldxdw r1, [r10-0x538]                   
    stxdw [r10-0x7f8], r1                   
lbb_16826:
    ldxdw r2, [r10-0x808]                   
    ldxdw r1, [r2+0x0]                      
    add64 r1, 1                                     r1 += 1   ///  r1 = r1.wrapping_add(1 as i32 as i64 as u64)
    stxdw [r2+0x0], r1                      
    ja lbb_16595                                    if true { pc += -236 }
lbb_16831:
    ldxdw r2, [r0+0x8]                      
    ldxdw r3, [r1+0x8]                      
    jne r3, r2, lbb_16796                           if r3 != r2 { pc += -38 }
    ldxdw r2, [r0+0x10]                     
    ldxdw r3, [r1+0x10]                     
    jne r3, r2, lbb_16796                           if r3 != r2 { pc += -41 }
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
    ldxdw r3, [r0+0x18]                     
    ldxdw r4, [r1+0x18]                     
    jne r4, r3, lbb_16796                           if r4 != r3 { pc += -45 }
    jeq r2, 0, lbb_16843                            if r2 == (0 as i32 as i64 as u64) { pc += 1 }
    ja lbb_16798                                    if true { pc += -45 }
lbb_16843:
    mov64 r8, r10                                   r8 = r10
    add64 r8, -1832                                 r8 += -1832   ///  r8 = r8.wrapping_add(-1832 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -1272                                 r2 += -1272   ///  r2 = r2.wrapping_add(-1272 as i32 as i64 as u64)
    mov64 r1, r8                                    r1 = r8
    mov64 r3, 136                                   r3 = 136 as i32 as i64 as u64
    stxdw [r10-0x810], r5                   
    call function_48190                     
    ldxdw r6, [r10-0x818]                   
    mov64 r1, r6                                    r1 = r6
    add64 r1, 172                                   r1 += 172   ///  r1 = r1.wrapping_add(172 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -1308                                 r2 += -1308   ///  r2 = r2.wrapping_add(-1308 as i32 as i64 as u64)
    mov64 r3, 36                                    r3 = 36 as i32 as i64 as u64
    call function_48190                     
    mov64 r7, r10                                   r7 = r10
    add64 r7, -1968                                 r7 += -1968   ///  r7 = r7.wrapping_add(-1968 as i32 as i64 as u64)
    mov64 r1, r7                                    r1 = r7
    mov64 r2, r8                                    r2 = r8
    mov64 r3, 136                                   r3 = 136 as i32 as i64 as u64
    call function_48190                     
    mov64 r1, r6                                    r1 = r6
    add64 r1, 32                                    r1 += 32   ///  r1 = r1.wrapping_add(32 as i32 as i64 as u64)
    mov64 r2, r7                                    r2 = r7
    mov64 r3, 136                                   r3 = 136 as i32 as i64 as u64
    call function_48190                     
    ldxdw r1, [r10-0x838]                   
    add64 r1, -2                                    r1 += -2   ///  r1 = r1.wrapping_add(-2 as i32 as i64 as u64)
    stxdw [r6+0xd8], r1                     
    mov64 r1, r9                                    r1 = r9
    add64 r1, 96                                    r1 += 96   ///  r1 = r1.wrapping_add(96 as i32 as i64 as u64)
    stxdw [r6+0xd0], r1                     
    ldxdw r1, [r10-0x7f8]                   
    stxw [r6+0xa8], r1                      
    ldxdw r1, [r10-0x7f0]                   
    stxdw [r6+0x18], r1                     
    stxdw [r6+0x10], r9                     
    ldxdw r1, [r10-0x808]                   
    stxdw [r6+0x8], r1                      
    ldxdw r1, [r10-0x810]                   
    stxdw [r6+0x0], r1                      
    ja lbb_16616                                    if true { pc += -269 }

function_16885:
    mov64 r8, r3                                    r8 = r3
    mov64 r7, r2                                    r7 = r2
    mov64 r9, r1                                    r9 = r1
    mov64 r1, r8                                    r1 = r8
    call function_39132                     
    jne r0, 0, lbb_16894                            if r0 != (0 as i32 as i64 as u64) { pc += 3 }
    mov64 r1, r8                                    r1 = r8
    call function_39148                     
    jne r0, 0, lbb_16961                            if r0 != (0 as i32 as i64 as u64) { pc += 67 }
lbb_16894:
    mov64 r1, r10                                   r1 = r10
    add64 r1, -72                                   r1 += -72   ///  r1 = r1.wrapping_add(-72 as i32 as i64 as u64)
    mov64 r2, r8                                    r2 = r8
    call function_39176                     
    ldxw r2, [r10-0x48]                     
    jeq r2, 24, lbb_16901                           if r2 == (24 as i32 as i64 as u64) { pc += 1 }
    ja lbb_16955                                    if true { pc += 54 }
lbb_16901:
    stxdw [r10-0xc0], r9                    
    ldxdw r9, [r10-0x38]                    
    ldxdw r2, [r10-0x40]                    
    ldxdw r8, [r8+0x0]                      
    ldxdw r1, [r2+0x8]                      
    jne r1, 8552, lbb_16911                         if r1 != (8552 as i32 as i64 as u64) { pc += 4 }
    ldxdw r6, [r2+0x0]                      
    mov64 r2, r6                                    r2 = r6
    and64 r2, 7                                     r2 &= 7   ///  r2 = r2.and(7)
    jeq r2, 0, lbb_16925                            if r2 == (0 as i32 as i64 as u64) { pc += 14 }
lbb_16911:
    ldxdw r4, [r8+0x8]                      
    ldxdw r5, [r8+0x0]                      
    ldxdw r2, [r8+0x18]                     
    stxdw [r10-0xb0], r2                    
    ldxdw r2, [r8+0x10]                     
    stxdw [r10-0xb8], r2                    
    ldxdw r2, [r9+0x0]                      
    add64 r2, -1                                    r2 += -1   ///  r2 = r2.wrapping_add(-1 as i32 as i64 as u64)
    stxdw [r9+0x0], r2                      
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
    mov64 r2, 8552                                  r2 = 8552 as i32 as i64 as u64
    mov64 r0, 35                                    r0 = 35 as i32 as i64 as u64
    ldxdw r9, [r10-0xc0]                    
    ja lbb_16973                                    if true { pc += 48 }
lbb_16925:
    ldxb r3, [r6+0x214c]                    
    mov64 r4, r6                                    r4 = r6
    add64 r4, 8                                     r4 += 8   ///  r4 = r4.wrapping_add(8 as i32 as i64 as u64)
    mov64 r1, r10                                   r1 = r10
    add64 r1, -72                                   r1 += -72   ///  r1 = r1.wrapping_add(-72 as i32 as i64 as u64)
    mov64 r2, r8                                    r2 = r8
    mov64 r5, r7                                    r5 = r7
    call function_24091                     
    ldxb r7, [r10-0x48]                     
    jeq r7, 56, lbb_16936                           if r7 == (56 as i32 as i64 as u64) { pc += 1 }
    ja lbb_16943                                    if true { pc += 7 }
lbb_16936:
    ldxdw r2, [r10-0xc0]                    
    stxdw [r2+0x18], r8                     
    stxdw [r2+0x10], r9                     
    stxdw [r2+0x8], r6                      
    mov64 r1, 56                                    r1 = 56 as i32 as i64 as u64
    stxb [r2+0x0], r1                       
    ja lbb_17015                                    if true { pc += 72 }
lbb_16943:
    ldxdw r6, [r10-0xc0]                    
    mov64 r1, r6                                    r1 = r6
    add64 r1, 1                                     r1 += 1   ///  r1 = r1.wrapping_add(1 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -71                                   r2 += -71   ///  r2 = r2.wrapping_add(-71 as i32 as i64 as u64)
    mov64 r3, 71                                    r3 = 71 as i32 as i64 as u64
    call function_48190                     
    stxb [r6+0x0], r7                       
    ldxdw r1, [r9+0x0]                      
    add64 r1, -1                                    r1 += -1   ///  r1 = r1.wrapping_add(-1 as i32 as i64 as u64)
    stxdw [r9+0x0], r1                      
    ja lbb_17015                                    if true { pc += 60 }
lbb_16955:
    mov64 r0, 55                                    r0 = 55 as i32 as i64 as u64
    ldxdw r1, [r10-0x40]                    
    ldxdw r4, [r10-0x30]                    
    ldxdw r5, [r10-0x38]                    
    ldxw r3, [r10-0x44]                     
    ja lbb_16973                                    if true { pc += 12 }
lbb_16961:
    ldxdw r2, [r8+0x0]                      
    ldxw r1, [r2+0x3]                       
    stxw [r10-0x95], r1                     
    ldxw r1, [r2+0x0]                       
    stxw [r10-0x98], r1                     
    mov64 r0, 37                                    r0 = 37 as i32 as i64 as u64
    ldxb r4, [r2+0x1f]                      
    ldxdw r5, [r2+0x17]                     
    ldxdw r1, [r2+0xf]                      
    ldxdw r2, [r2+0x7]                      
    mov64 r3, r2                                    r3 = r2
    rsh64 r3, 32                                    r3 >>= 32   ///  r3 = r3.wrapping_shr(32)
lbb_16973:
    stxb [r10-0x48], r0                     
    ldxw r0, [r10-0x98]                     
    stxw [r10-0x47], r0                     
    ldxw r0, [r10-0x95]                     
    stxw [r10-0x44], r0                     
    stxdw [r10-0x28], r4                    
    stxdw [r10-0x30], r5                    
    stxdw [r10-0x38], r1                    
    ldxdw r1, [r10-0xb8]                    
    stxdw [r10-0x20], r1                    
    ldxdw r1, [r10-0xb0]                    
    stxdw [r10-0x18], r1                    
    ldxdw r1, [r10-0xa8]                    
    stxdw [r10-0x10], r1                    
    ldxdw r1, [r10-0xa0]                    
    stxdw [r10-0x8], r1                     
    lsh64 r3, 32                                    r3 <<= 32   ///  r3 = r3.wrapping_shl(32)
    lsh64 r2, 32                                    r2 <<= 32   ///  r2 = r2.wrapping_shl(32)
    rsh64 r2, 32                                    r2 >>= 32   ///  r2 = r2.wrapping_shr(32)
    or64 r3, r2                                     r3 |= r2   ///  r3 = r3.or(r2)
    stxdw [r10-0x40], r3                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -136                                  r1 += -136   ///  r1 = r1.wrapping_add(-136 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -72                                   r2 += -72   ///  r2 = r2.wrapping_add(-72 as i32 as i64 as u64)
    call function_26067                     
    ldxw r1, [r10-0x8c]                     
    stxw [r9+0x4], r1                       
    ldxw r1, [r10-0x8f]                     
    stxw [r9+0x1], r1                       
    ldxdw r6, [r10-0x88]                    
    ldxdw r7, [r10-0x80]                    
    mov64 r1, r9                                    r1 = r9
    add64 r1, 24                                    r1 += 24   ///  r1 = r1.wrapping_add(24 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -120                                  r2 += -120   ///  r2 = r2.wrapping_add(-120 as i32 as i64 as u64)
    mov64 r3, 48                                    r3 = 48 as i32 as i64 as u64
    call function_48190                     
    stxdw [r9+0x10], r7                     
    stxdw [r9+0x8], r6                      
    mov64 r1, 55                                    r1 = 55 as i32 as i64 as u64
    stxb [r9+0x0], r1                       
lbb_17015:
    exit                                    

function_17016:
    mov64 r7, r5                                    r7 = r5
    stxdw [r10-0x110], r4                   
    mov64 r9, r3                                    r9 = r3
    mov64 r8, r2                                    r8 = r2
    mov64 r6, r1                                    r6 = r1
    mov64 r1, r9                                    r1 = r9
    call function_39132                     
    jne r0, 0, lbb_17027                            if r0 != (0 as i32 as i64 as u64) { pc += 3 }
    mov64 r1, r9                                    r1 = r9
    call function_39148                     
    jne r0, 0, lbb_17245                            if r0 != (0 as i32 as i64 as u64) { pc += 218 }
lbb_17027:
    mov64 r1, r10                                   r1 = r10
    add64 r1, -72                                   r1 += -72   ///  r1 = r1.wrapping_add(-72 as i32 as i64 as u64)
    mov64 r2, r9                                    r2 = r9
    call function_39176                     
    ldxw r2, [r10-0x48]                     
    jeq r2, 24, lbb_17034                           if r2 == (24 as i32 as i64 as u64) { pc += 1 }
    ja lbb_17239                                    if true { pc += 205 }
lbb_17034:
    stxdw [r10-0x100], r6                   
    ldxdw r3, [r10-0x38]                    
    ldxdw r2, [r10-0x40]                    
    ldxdw r9, [r9+0x0]                      
    ldxdw r1, [r2+0x8]                      
    jne r1, 8492, lbb_17044                         if r1 != (8492 as i32 as i64 as u64) { pc += 4 }
    ldxdw r6, [r2+0x0]                      
    mov64 r2, r6                                    r2 = r6
    and64 r2, 3                                     r2 &= 3   ///  r2 = r2.and(3)
    jeq r2, 0, lbb_17058                            if r2 == (0 as i32 as i64 as u64) { pc += 14 }
lbb_17044:
    ldxdw r4, [r9+0x8]                      
    ldxdw r5, [r9+0x0]                      
    ldxdw r2, [r9+0x18]                     
    stxdw [r10-0xf0], r2                    
    ldxdw r2, [r9+0x10]                     
    stxdw [r10-0xf8], r2                    
    ldxdw r2, [r3+0x0]                      
    add64 r2, -1                                    r2 += -1   ///  r2 = r2.wrapping_add(-1 as i32 as i64 as u64)
    stxdw [r3+0x0], r2                      
    mov64 r0, 35                                    r0 = 35 as i32 as i64 as u64
    mov64 r2, 8492                                  r2 = 8492 as i32 as i64 as u64
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
    ldxdw r6, [r10-0x100]                   
    ja lbb_17257                                    if true { pc += 199 }
lbb_17058:
    stxdw [r10-0x108], r3                   
    ldxb r3, [r6+0x2124]                    
    ldxb r1, [r6+0x2125]                    
    stxdw [r10-0x1000], r1                  
    stxdw [r10-0xff8], r8                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -72                                   r1 += -72   ///  r1 = r1.wrapping_add(-72 as i32 as i64 as u64)
    mov64 r5, r10                                   r5 = r10
    mov64 r2, r9                                    r2 = r9
    mov64 r4, r7                                    r4 = r7
    call function_24320                     
    ldxb r8, [r10-0x48]                     
    jeq r8, 56, lbb_17072                           if r8 == (56 as i32 as i64 as u64) { pc += 1 }
    ja lbb_17077                                    if true { pc += 5 }
lbb_17072:
    ldxdw r1, [r6+0x0]                      
    ldxdw r2, [r7+0x0]                      
    jeq r2, r1, lbb_17086                           if r2 == r1 { pc += 11 }
lbb_17075:
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    ja lbb_17096                                    if true { pc += 19 }
lbb_17077:
    ldxdw r6, [r10-0x100]                   
    mov64 r1, r6                                    r1 = r6
    add64 r1, 1                                     r1 += 1   ///  r1 = r1.wrapping_add(1 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -71                                   r2 += -71   ///  r2 = r2.wrapping_add(-71 as i32 as i64 as u64)
    mov64 r3, 71                                    r3 = 71 as i32 as i64 as u64
    call function_48190                     
    stxb [r6+0x0], r8                       
    ja lbb_17234                                    if true { pc += 148 }
lbb_17086:
    ldxdw r1, [r6+0x8]                      
    ldxdw r2, [r7+0x8]                      
    jne r2, r1, lbb_17075                           if r2 != r1 { pc += -14 }
    ldxdw r1, [r6+0x10]                     
    ldxdw r2, [r7+0x10]                     
    jne r2, r1, lbb_17075                           if r2 != r1 { pc += -17 }
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    ldxdw r2, [r6+0x18]                     
    ldxdw r3, [r7+0x18]                     
    jne r3, r2, lbb_17075                           if r3 != r2 { pc += -21 }
lbb_17096:
    mov64 r2, 40                                    r2 = 40 as i32 as i64 as u64
    stxdw [r10-0xd0], r2                    
    lddw r2, 0x100060c15 --> b"Instance dex does not match expected dexprogram/sr"        r2 load str located at 4295363605
    stxdw [r10-0xd8], r2                    
    jeq r1, 0, lbb_17210                            if r1 == (0 as i32 as i64 as u64) { pc += 108 }
    lddw r1, 0x100065518 --> b"\x00\x00\x00\x00=\x0c\x06\x00\x1f\x00\x00\x00\x00\x00\x00\x00d\x00\x00\x0…        r1 load str located at 4295382296
    stxdw [r10-0xc8], r1                    
    lddw r1, 0x100064c98 --> b"\x00\x00\x00\x00p\xfa\x05\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00…        r1 load str located at 4295380120
    stxdw [r10-0x48], r1                    
    mov64 r1, 2                                     r1 = 2 as i32 as i64 as u64
    stxdw [r10-0x40], r1                    
    stxdw [r10-0x30], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -144                                  r1 += -144   ///  r1 = r1.wrapping_add(-144 as i32 as i64 as u64)
    stxdw [r10-0x38], r1                    
    lddw r1, 0x100000888 --> b"y\x11\x00\x00\x00\x00\x00\x00\x85\x10\x00\x00]\xab\x00\x00\x95\x00\x00\x0…        r1 load str located at 4294969480
    stxdw [r10-0x78], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -200                                  r1 += -200   ///  r1 = r1.wrapping_add(-200 as i32 as i64 as u64)
    stxdw [r10-0x80], r1                    
    lddw r1, 0x100000860 --> b"\xbf#\x00\x00\x00\x00\x00\x00y\x12\x08\x00\x00\x00\x00\x00y\x11\x00\x00\x…        r1 load str located at 4294969440
    stxdw [r10-0x88], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -216                                  r1 += -216   ///  r1 = r1.wrapping_add(-216 as i32 as i64 as u64)
    stxdw [r10-0x90], r1                    
    mov64 r8, 0                                     r8 = 0 as i32 as i64 as u64
    stxdw [r10-0x28], r8                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -248                                  r1 += -248   ///  r1 = r1.wrapping_add(-248 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -72                                   r2 += -72   ///  r2 = r2.wrapping_add(-72 as i32 as i64 as u64)
    call function_43415                     
    ldxdw r1, [r10-0xf8]                    
    ldxdw r2, [r10-0xe8]                    
    syscall [invalid]                       
    lddw r1, 0x300000000                            r1 load str located at 12884901888
    ldxdw r2, [r1+0x0]                      
    mov64 r3, 1                                     r3 = 1 as i32 as i64 as u64
    mov64 r1, r2                                    r1 = r2
    add64 r1, -32                                   r1 += -32   ///  r1 = r1.wrapping_add(-32 as i32 as i64 as u64)
    jgt r1, r2, lbb_17144                           if r1 > r2 { pc += 1 }
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
lbb_17144:
    jne r3, 0, lbb_17146                            if r3 != (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r8, r1                                    r8 = r1
lbb_17146:
    lddw r1, 0x300007fe0                            r1 load str located at 12884934624
    jeq r2, 0, lbb_17150                            if r2 == (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r1, r8                                    r1 = r8
lbb_17150:
    lddw r2, 0x300000007                            r2 load str located at 12884901895
    jgt r1, r2, lbb_17157                           if r1 > r2 { pc += 4 }
lbb_17153:
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    mov64 r2, 32                                    r2 = 32 as i32 as i64 as u64
    call function_43400                     
    syscall [invalid]                       
lbb_17157:
    lddw r2, 0x300000000                            r2 load str located at 12884901888
    stxdw [r2+0x0], r1                      
    ldxdw r3, [r7+0x18]                     
    stxdw [r1+0x18], r3                     
    ldxdw r3, [r7+0x10]                     
    stxdw [r1+0x10], r3                     
    ldxdw r3, [r7+0x8]                      
    stxdw [r1+0x8], r3                      
    ldxdw r3, [r7+0x0]                      
    stxdw [r1+0x0], r3                      
    ldxdw r3, [r6+0x18]                     
    stxdw [r10-0x30], r3                    
    ldxdw r3, [r6+0x10]                     
    stxdw [r10-0x38], r3                    
    ldxdw r3, [r6+0x8]                      
    stxdw [r10-0x40], r3                    
    ldxdw r3, [r6+0x0]                      
    stxdw [r10-0x48], r3                    
    ldxdw r3, [r2+0x0]                      
    mov64 r4, 0                                     r4 = 0 as i32 as i64 as u64
    mov64 r5, 1                                     r5 = 1 as i32 as i64 as u64
    mov64 r2, r3                                    r2 = r3
    add64 r2, -32                                   r2 += -32   ///  r2 = r2.wrapping_add(-32 as i32 as i64 as u64)
    jgt r2, r3, lbb_17183                           if r2 > r3 { pc += 1 }
    mov64 r5, 0                                     r5 = 0 as i32 as i64 as u64
lbb_17183:
    ldxdw r0, [r10-0x100]                   
    jne r5, 0, lbb_17186                            if r5 != (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r4, r2                                    r4 = r2
lbb_17186:
    lddw r2, 0x300007fe0                            r2 load str located at 12884934624
    jeq r3, 0, lbb_17190                            if r3 == (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r2, r4                                    r2 = r4
lbb_17190:
    lddw r3, 0x300000007                            r3 load str located at 12884901895
    jgt r2, r3, lbb_17194                           if r2 > r3 { pc += 1 }
    ja lbb_17153                                    if true { pc += -41 }
lbb_17194:
    lddw r3, 0x300000000                            r3 load str located at 12884901888
    stxdw [r3+0x0], r2                      
    ldxdw r3, [r10-0x30]                    
    stxdw [r2+0x18], r3                     
    ldxdw r3, [r10-0x38]                    
    stxdw [r2+0x10], r3                     
    ldxdw r3, [r10-0x40]                    
    stxdw [r2+0x8], r3                      
    ldxdw r3, [r10-0x48]                    
    stxdw [r2+0x0], r3                      
    stxdw [r0+0x10], r2                     
    stxdw [r0+0x8], r1                      
    mov64 r1, 26                                    r1 = 26 as i32 as i64 as u64
    stxb [r0+0x0], r1                       
    ja lbb_17234                                    if true { pc += 24 }
lbb_17210:
    ldxb r3, [r6+0x2125]                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -72                                   r1 += -72   ///  r1 = r1.wrapping_add(-72 as i32 as i64 as u64)
    ldxdw r2, [r10-0x110]                   
    call function_24666                     
    ldxb r7, [r10-0x48]                     
    jeq r7, 56, lbb_17218                           if r7 == (56 as i32 as i64 as u64) { pc += 1 }
    ja lbb_17226                                    if true { pc += 8 }
lbb_17218:
    ldxdw r2, [r10-0x100]                   
    stxdw [r2+0x18], r9                     
    ldxdw r1, [r10-0x108]                   
    stxdw [r2+0x10], r1                     
    stxdw [r2+0x8], r6                      
    mov64 r1, 56                                    r1 = 56 as i32 as i64 as u64
    stxb [r2+0x0], r1                       
    ja lbb_17238                                    if true { pc += 12 }
lbb_17226:
    ldxdw r6, [r10-0x100]                   
    mov64 r1, r6                                    r1 = r6
    add64 r1, 1                                     r1 += 1   ///  r1 = r1.wrapping_add(1 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -71                                   r2 += -71   ///  r2 = r2.wrapping_add(-71 as i32 as i64 as u64)
    mov64 r3, 71                                    r3 = 71 as i32 as i64 as u64
    call function_48190                     
    stxb [r6+0x0], r7                       
lbb_17234:
    ldxdw r2, [r10-0x108]                   
    ldxdw r1, [r2+0x0]                      
    add64 r1, -1                                    r1 += -1   ///  r1 = r1.wrapping_add(-1 as i32 as i64 as u64)
    stxdw [r2+0x0], r1                      
lbb_17238:
    exit                                    
lbb_17239:
    mov64 r0, 55                                    r0 = 55 as i32 as i64 as u64
    ldxdw r1, [r10-0x40]                    
    ldxdw r4, [r10-0x30]                    
    ldxdw r5, [r10-0x38]                    
    ldxw r3, [r10-0x44]                     
    ja lbb_17257                                    if true { pc += 12 }
lbb_17245:
    ldxdw r2, [r9+0x0]                      
    ldxw r1, [r2+0x3]                       
    stxw [r10-0xd5], r1                     
    ldxw r1, [r2+0x0]                       
    stxw [r10-0xd8], r1                     
    mov64 r0, 37                                    r0 = 37 as i32 as i64 as u64
    ldxb r4, [r2+0x1f]                      
    ldxdw r5, [r2+0x17]                     
    ldxdw r1, [r2+0xf]                      
    ldxdw r2, [r2+0x7]                      
    mov64 r3, r2                                    r3 = r2
    rsh64 r3, 32                                    r3 >>= 32   ///  r3 = r3.wrapping_shr(32)
lbb_17257:
    stxb [r10-0x48], r0                     
    ldxw r0, [r10-0xd8]                     
    stxw [r10-0x47], r0                     
    ldxw r0, [r10-0xd5]                     
    stxw [r10-0x44], r0                     
    stxdw [r10-0x28], r4                    
    stxdw [r10-0x30], r5                    
    stxdw [r10-0x38], r1                    
    ldxdw r1, [r10-0xf8]                    
    stxdw [r10-0x20], r1                    
    ldxdw r1, [r10-0xf0]                    
    stxdw [r10-0x18], r1                    
    ldxdw r1, [r10-0xe8]                    
    stxdw [r10-0x10], r1                    
    ldxdw r1, [r10-0xe0]                    
    stxdw [r10-0x8], r1                     
    lsh64 r3, 32                                    r3 <<= 32   ///  r3 = r3.wrapping_shl(32)
    lsh64 r2, 32                                    r2 <<= 32   ///  r2 = r2.wrapping_shl(32)
    rsh64 r2, 32                                    r2 >>= 32   ///  r2 = r2.wrapping_shr(32)
    or64 r3, r2                                     r3 |= r2   ///  r3 = r3.or(r2)
    stxdw [r10-0x40], r3                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -136                                  r1 += -136   ///  r1 = r1.wrapping_add(-136 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -72                                   r2 += -72   ///  r2 = r2.wrapping_add(-72 as i32 as i64 as u64)
    call function_26067                     
    ldxw r1, [r10-0x8c]                     
    stxw [r6+0x4], r1                       
    ldxw r1, [r10-0x8f]                     
    stxw [r6+0x1], r1                       
    mov64 r8, r6                                    r8 = r6
    ldxdw r6, [r10-0x88]                    
    ldxdw r7, [r10-0x80]                    
    mov64 r1, r8                                    r1 = r8
    add64 r1, 24                                    r1 += 24   ///  r1 = r1.wrapping_add(24 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -120                                  r2 += -120   ///  r2 = r2.wrapping_add(-120 as i32 as i64 as u64)
    mov64 r3, 48                                    r3 = 48 as i32 as i64 as u64
    call function_48190                     
    stxdw [r8+0x10], r7                     
    stxdw [r8+0x8], r6                      
    mov64 r1, 55                                    r1 = 55 as i32 as i64 as u64
    stxb [r8+0x0], r1                       
    ja lbb_17238                                    if true { pc += -63 }

function_17301:
    mov64 r7, r5                                    r7 = r5
    stxdw [r10-0x110], r4                   
    mov64 r9, r3                                    r9 = r3
    mov64 r8, r2                                    r8 = r2
    mov64 r6, r1                                    r6 = r1
    mov64 r1, r9                                    r1 = r9
    call function_39132                     
    jne r0, 0, lbb_17312                            if r0 != (0 as i32 as i64 as u64) { pc += 3 }
    mov64 r1, r9                                    r1 = r9
    call function_39148                     
    jne r0, 0, lbb_17538                            if r0 != (0 as i32 as i64 as u64) { pc += 226 }
lbb_17312:
    ldxb r1, [r9+0x29]                      
    jeq r1, 0, lbb_17525                            if r1 == (0 as i32 as i64 as u64) { pc += 211 }
    mov64 r1, r10                                   r1 = r10
    add64 r1, -72                                   r1 += -72   ///  r1 = r1.wrapping_add(-72 as i32 as i64 as u64)
    mov64 r2, r9                                    r2 = r9
    call function_39192                     
    ldxw r2, [r10-0x48]                     
    jne r2, 24, lbb_17532                           if r2 != (24 as i32 as i64 as u64) { pc += 212 }
    stxdw [r10-0x100], r6                   
    ldxdw r4, [r10-0x38]                    
    ldxdw r2, [r10-0x40]                    
    ldxdw r9, [r9+0x0]                      
    ldxdw r1, [r2+0x8]                      
    jne r1, 8492, lbb_17330                         if r1 != (8492 as i32 as i64 as u64) { pc += 4 }
    ldxdw r6, [r2+0x0]                      
    mov64 r2, r6                                    r2 = r6
    and64 r2, 3                                     r2 &= 3   ///  r2 = r2.and(3)
    jeq r2, 0, lbb_17344                            if r2 == (0 as i32 as i64 as u64) { pc += 14 }
lbb_17330:
    ldxdw r3, [r9+0x8]                      
    ldxdw r5, [r9+0x0]                      
    ldxdw r2, [r9+0x18]                     
    stxdw [r10-0xf0], r2                    
    ldxdw r2, [r9+0x10]                     
    stxdw [r10-0xf8], r2                    
    ldxdw r2, [r4+0x0]                      
    add64 r2, 1                                     r2 += 1   ///  r2 = r2.wrapping_add(1 as i32 as i64 as u64)
    stxdw [r4+0x0], r2                      
    mov64 r0, 35                                    r0 = 35 as i32 as i64 as u64
    mov64 r2, 8492                                  r2 = 8492 as i32 as i64 as u64
    mov64 r4, 0                                     r4 = 0 as i32 as i64 as u64
    ldxdw r6, [r10-0x100]                   
    ja lbb_17550                                    if true { pc += 206 }
lbb_17344:
    stxdw [r10-0x108], r4                   
    ldxb r3, [r6+0x2124]                    
    ldxb r1, [r6+0x2125]                    
    stxdw [r10-0x1000], r1                  
    stxdw [r10-0xff8], r8                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -72                                   r1 += -72   ///  r1 = r1.wrapping_add(-72 as i32 as i64 as u64)
    mov64 r5, r10                                   r5 = r10
    mov64 r2, r9                                    r2 = r9
    mov64 r4, r7                                    r4 = r7
    call function_24320                     
    ldxb r8, [r10-0x48]                     
    jeq r8, 56, lbb_17358                           if r8 == (56 as i32 as i64 as u64) { pc += 1 }
    ja lbb_17363                                    if true { pc += 5 }
lbb_17358:
    ldxdw r1, [r6+0x0]                      
    ldxdw r2, [r7+0x0]                      
    jeq r2, r1, lbb_17372                           if r2 == r1 { pc += 11 }
lbb_17361:
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    ja lbb_17382                                    if true { pc += 19 }
lbb_17363:
    ldxdw r6, [r10-0x100]                   
    mov64 r1, r6                                    r1 = r6
    add64 r1, 1                                     r1 += 1   ///  r1 = r1.wrapping_add(1 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -71                                   r2 += -71   ///  r2 = r2.wrapping_add(-71 as i32 as i64 as u64)
    mov64 r3, 71                                    r3 = 71 as i32 as i64 as u64
    call function_48190                     
    stxb [r6+0x0], r8                       
    ja lbb_17520                                    if true { pc += 148 }
lbb_17372:
    ldxdw r1, [r6+0x8]                      
    ldxdw r2, [r7+0x8]                      
    jne r2, r1, lbb_17361                           if r2 != r1 { pc += -14 }
    ldxdw r1, [r6+0x10]                     
    ldxdw r2, [r7+0x10]                     
    jne r2, r1, lbb_17361                           if r2 != r1 { pc += -17 }
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    ldxdw r2, [r6+0x18]                     
    ldxdw r3, [r7+0x18]                     
    jne r3, r2, lbb_17361                           if r3 != r2 { pc += -21 }
lbb_17382:
    mov64 r2, 40                                    r2 = 40 as i32 as i64 as u64
    stxdw [r10-0xd0], r2                    
    lddw r2, 0x100060c15 --> b"Instance dex does not match expected dexprogram/sr"        r2 load str located at 4295363605
    stxdw [r10-0xd8], r2                    
    jeq r1, 0, lbb_17496                            if r1 == (0 as i32 as i64 as u64) { pc += 108 }
    lddw r1, 0x100065518 --> b"\x00\x00\x00\x00=\x0c\x06\x00\x1f\x00\x00\x00\x00\x00\x00\x00d\x00\x00\x0…        r1 load str located at 4295382296
    stxdw [r10-0xc8], r1                    
    lddw r1, 0x100064c98 --> b"\x00\x00\x00\x00p\xfa\x05\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00…        r1 load str located at 4295380120
    stxdw [r10-0x48], r1                    
    mov64 r1, 2                                     r1 = 2 as i32 as i64 as u64
    stxdw [r10-0x40], r1                    
    stxdw [r10-0x30], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -144                                  r1 += -144   ///  r1 = r1.wrapping_add(-144 as i32 as i64 as u64)
    stxdw [r10-0x38], r1                    
    lddw r1, 0x100000888 --> b"y\x11\x00\x00\x00\x00\x00\x00\x85\x10\x00\x00]\xab\x00\x00\x95\x00\x00\x0…        r1 load str located at 4294969480
    stxdw [r10-0x78], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -200                                  r1 += -200   ///  r1 = r1.wrapping_add(-200 as i32 as i64 as u64)
    stxdw [r10-0x80], r1                    
    lddw r1, 0x100000860 --> b"\xbf#\x00\x00\x00\x00\x00\x00y\x12\x08\x00\x00\x00\x00\x00y\x11\x00\x00\x…        r1 load str located at 4294969440
    stxdw [r10-0x88], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -216                                  r1 += -216   ///  r1 = r1.wrapping_add(-216 as i32 as i64 as u64)
    stxdw [r10-0x90], r1                    
    mov64 r8, 0                                     r8 = 0 as i32 as i64 as u64
    stxdw [r10-0x28], r8                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -248                                  r1 += -248   ///  r1 = r1.wrapping_add(-248 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -72                                   r2 += -72   ///  r2 = r2.wrapping_add(-72 as i32 as i64 as u64)
    call function_43415                     
    ldxdw r1, [r10-0xf8]                    
    ldxdw r2, [r10-0xe8]                    
    syscall [invalid]                       
    lddw r1, 0x300000000                            r1 load str located at 12884901888
    ldxdw r2, [r1+0x0]                      
    mov64 r3, 1                                     r3 = 1 as i32 as i64 as u64
    mov64 r1, r2                                    r1 = r2
    add64 r1, -32                                   r1 += -32   ///  r1 = r1.wrapping_add(-32 as i32 as i64 as u64)
    jgt r1, r2, lbb_17430                           if r1 > r2 { pc += 1 }
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
lbb_17430:
    jne r3, 0, lbb_17432                            if r3 != (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r8, r1                                    r8 = r1
lbb_17432:
    lddw r1, 0x300007fe0                            r1 load str located at 12884934624
    jeq r2, 0, lbb_17436                            if r2 == (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r1, r8                                    r1 = r8
lbb_17436:
    lddw r2, 0x300000007                            r2 load str located at 12884901895
    jgt r1, r2, lbb_17443                           if r1 > r2 { pc += 4 }
lbb_17439:
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    mov64 r2, 32                                    r2 = 32 as i32 as i64 as u64
    call function_43400                     
    syscall [invalid]                       
lbb_17443:
    lddw r2, 0x300000000                            r2 load str located at 12884901888
    stxdw [r2+0x0], r1                      
    ldxdw r3, [r7+0x18]                     
    stxdw [r1+0x18], r3                     
    ldxdw r3, [r7+0x10]                     
    stxdw [r1+0x10], r3                     
    ldxdw r3, [r7+0x8]                      
    stxdw [r1+0x8], r3                      
    ldxdw r3, [r7+0x0]                      
    stxdw [r1+0x0], r3                      
    ldxdw r3, [r6+0x18]                     
    stxdw [r10-0x30], r3                    
    ldxdw r3, [r6+0x10]                     
    stxdw [r10-0x38], r3                    
    ldxdw r3, [r6+0x8]                      
    stxdw [r10-0x40], r3                    
    ldxdw r3, [r6+0x0]                      
    stxdw [r10-0x48], r3                    
    ldxdw r3, [r2+0x0]                      
    mov64 r4, 0                                     r4 = 0 as i32 as i64 as u64
    mov64 r5, 1                                     r5 = 1 as i32 as i64 as u64
    mov64 r2, r3                                    r2 = r3
    add64 r2, -32                                   r2 += -32   ///  r2 = r2.wrapping_add(-32 as i32 as i64 as u64)
    jgt r2, r3, lbb_17469                           if r2 > r3 { pc += 1 }
    mov64 r5, 0                                     r5 = 0 as i32 as i64 as u64
lbb_17469:
    ldxdw r0, [r10-0x100]                   
    jne r5, 0, lbb_17472                            if r5 != (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r4, r2                                    r4 = r2
lbb_17472:
    lddw r2, 0x300007fe0                            r2 load str located at 12884934624
    jeq r3, 0, lbb_17476                            if r3 == (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r2, r4                                    r2 = r4
lbb_17476:
    lddw r3, 0x300000007                            r3 load str located at 12884901895
    jgt r2, r3, lbb_17480                           if r2 > r3 { pc += 1 }
    ja lbb_17439                                    if true { pc += -41 }
lbb_17480:
    lddw r3, 0x300000000                            r3 load str located at 12884901888
    stxdw [r3+0x0], r2                      
    ldxdw r3, [r10-0x30]                    
    stxdw [r2+0x18], r3                     
    ldxdw r3, [r10-0x38]                    
    stxdw [r2+0x10], r3                     
    ldxdw r3, [r10-0x40]                    
    stxdw [r2+0x8], r3                      
    ldxdw r3, [r10-0x48]                    
    stxdw [r2+0x0], r3                      
    stxdw [r0+0x10], r2                     
    stxdw [r0+0x8], r1                      
    mov64 r1, 26                                    r1 = 26 as i32 as i64 as u64
    stxb [r0+0x0], r1                       
    ja lbb_17520                                    if true { pc += 24 }
lbb_17496:
    ldxb r3, [r6+0x2125]                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -72                                   r1 += -72   ///  r1 = r1.wrapping_add(-72 as i32 as i64 as u64)
    ldxdw r2, [r10-0x110]                   
    call function_24666                     
    ldxb r7, [r10-0x48]                     
    jeq r7, 56, lbb_17504                           if r7 == (56 as i32 as i64 as u64) { pc += 1 }
    ja lbb_17512                                    if true { pc += 8 }
lbb_17504:
    ldxdw r2, [r10-0x100]                   
    stxdw [r2+0x18], r9                     
    ldxdw r1, [r10-0x108]                   
    stxdw [r2+0x10], r1                     
    stxdw [r2+0x8], r6                      
    mov64 r1, 56                                    r1 = 56 as i32 as i64 as u64
    stxb [r2+0x0], r1                       
    ja lbb_17524                                    if true { pc += 12 }
lbb_17512:
    ldxdw r6, [r10-0x100]                   
    mov64 r1, r6                                    r1 = r6
    add64 r1, 1                                     r1 += 1   ///  r1 = r1.wrapping_add(1 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -71                                   r2 += -71   ///  r2 = r2.wrapping_add(-71 as i32 as i64 as u64)
    mov64 r3, 71                                    r3 = 71 as i32 as i64 as u64
    call function_48190                     
    stxb [r6+0x0], r7                       
lbb_17520:
    ldxdw r2, [r10-0x108]                   
    ldxdw r1, [r2+0x0]                      
    add64 r1, 1                                     r1 += 1   ///  r1 = r1.wrapping_add(1 as i32 as i64 as u64)
    stxdw [r2+0x0], r1                      
lbb_17524:
    exit                                    
lbb_17525:
    ldxdw r2, [r9+0x0]                      
    ldxw r1, [r2+0x3]                       
    stxw [r10-0xd5], r1                     
    ldxw r1, [r2+0x0]                       
    stxw [r10-0xd8], r1                     
    mov64 r0, 40                                    r0 = 40 as i32 as i64 as u64
    ja lbb_17544                                    if true { pc += 12 }
lbb_17532:
    mov64 r0, 55                                    r0 = 55 as i32 as i64 as u64
    ldxdw r1, [r10-0x40]                    
    ldxdw r3, [r10-0x30]                    
    ldxdw r5, [r10-0x38]                    
    ldxw r4, [r10-0x44]                     
    ja lbb_17550                                    if true { pc += 12 }
lbb_17538:
    ldxdw r2, [r9+0x0]                      
    ldxw r1, [r2+0x3]                       
    stxw [r10-0xd5], r1                     
    ldxw r1, [r2+0x0]                       
    stxw [r10-0xd8], r1                     
    mov64 r0, 37                                    r0 = 37 as i32 as i64 as u64
lbb_17544:
    ldxb r3, [r2+0x1f]                      
    ldxdw r5, [r2+0x17]                     
    ldxdw r1, [r2+0xf]                      
    ldxdw r2, [r2+0x7]                      
    mov64 r4, r2                                    r4 = r2
    rsh64 r4, 32                                    r4 >>= 32   ///  r4 = r4.wrapping_shr(32)
lbb_17550:
    stxb [r10-0x48], r0                     
    ldxw r0, [r10-0xd8]                     
    stxw [r10-0x47], r0                     
    ldxw r0, [r10-0xd5]                     
    stxw [r10-0x44], r0                     
    stxdw [r10-0x28], r3                    
    stxdw [r10-0x30], r5                    
    stxdw [r10-0x38], r1                    
    ldxdw r1, [r10-0xf8]                    
    stxdw [r10-0x20], r1                    
    ldxdw r1, [r10-0xf0]                    
    stxdw [r10-0x18], r1                    
    ldxdw r1, [r10-0xe8]                    
    stxdw [r10-0x10], r1                    
    ldxdw r1, [r10-0xe0]                    
    stxdw [r10-0x8], r1                     
    lsh64 r4, 32                                    r4 <<= 32   ///  r4 = r4.wrapping_shl(32)
    lsh64 r2, 32                                    r2 <<= 32   ///  r2 = r2.wrapping_shl(32)
    rsh64 r2, 32                                    r2 >>= 32   ///  r2 = r2.wrapping_shr(32)
    or64 r4, r2                                     r4 |= r2   ///  r4 = r4.or(r2)
    stxdw [r10-0x40], r4                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -136                                  r1 += -136   ///  r1 = r1.wrapping_add(-136 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -72                                   r2 += -72   ///  r2 = r2.wrapping_add(-72 as i32 as i64 as u64)
    call function_26067                     
    ldxw r1, [r10-0x8c]                     
    stxw [r6+0x4], r1                       
    ldxw r1, [r10-0x8f]                     
    stxw [r6+0x1], r1                       
    mov64 r8, r6                                    r8 = r6
    ldxdw r6, [r10-0x88]                    
    ldxdw r7, [r10-0x80]                    
    mov64 r1, r8                                    r1 = r8
    add64 r1, 24                                    r1 += 24   ///  r1 = r1.wrapping_add(24 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -120                                  r2 += -120   ///  r2 = r2.wrapping_add(-120 as i32 as i64 as u64)
    mov64 r3, 48                                    r3 = 48 as i32 as i64 as u64
    call function_48190                     
    stxdw [r8+0x10], r7                     
    stxdw [r8+0x8], r6                      
    mov64 r1, 55                                    r1 = 55 as i32 as i64 as u64
    stxb [r8+0x0], r1                       
    ja lbb_17524                                    if true { pc += -70 }

function_17594:
    mov64 r7, r4                                    r7 = r4
    mov64 r8, r3                                    r8 = r3
    mov64 r9, r2                                    r9 = r2
    mov64 r6, r1                                    r6 = r1
    jgt r7, 1, lbb_17640                            if r7 > (1 as i32 as i64 as u64) { pc += 41 }
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    stxdw [r10-0x58], r1                    
    mov64 r1, 2                                     r1 = 2 as i32 as i64 as u64
    stxdw [r10-0x70], r1                    
    lddw r1, 0x100065530 --> b"\x00\x00\x00\x00\\x0c\x06\x00,\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x0…        r1 load str located at 4295382320
    stxdw [r10-0x78], r1                    
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    stxdw [r10-0x60], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -152                                  r1 += -152   ///  r1 = r1.wrapping_add(-152 as i32 as i64 as u64)
    stxdw [r10-0x68], r1                    
    lddw r1, 0x10005df58 --> b"\xbf#\x00\x00\x00\x00\x00\x00y\x11\x00\x00\x00\x00\x00\x00\xb7\x02\x00\x0…        r1 load str located at 4295352152
    stxdw [r10-0x90], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -160                                  r1 += -160   ///  r1 = r1.wrapping_add(-160 as i32 as i64 as u64)
    stxdw [r10-0x98], r1                    
    stxdw [r10-0xa0], r7                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -184                                  r1 += -184   ///  r1 = r1.wrapping_add(-184 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -120                                  r2 += -120   ///  r2 = r2.wrapping_add(-120 as i32 as i64 as u64)
    call function_43415                     
    ldxdw r1, [r10-0xb8]                    
    stxdw [r10-0xd0], r1                    
    ldxdw r1, [r10-0xb0]                    
    stxdw [r10-0xc8], r1                    
    ldxdw r1, [r10-0xa8]                    
    stxdw [r10-0xc0], r1                    
    mov64 r1, 29                                    r1 = 29 as i32 as i64 as u64
    stxb [r6+0x0], r1                       
    ldxdw r1, [r10-0xd7]                    
    stxdw [r6+0x1], r1                      
    ldxdw r1, [r10-0xcf]                    
    stxdw [r6+0x9], r1                      
    ldxdw r1, [r10-0xc7]                    
    stxdw [r6+0x11], r1                     
    ldxdw r1, [r10-0xc0]                    
    stxdw [r6+0x18], r1                     
    ja lbb_17732                                    if true { pc += 92 }
lbb_17640:
    mov64 r1, r10                                   r1 = r10
    add64 r1, -120                                  r1 += -120   ///  r1 = r1.wrapping_add(-120 as i32 as i64 as u64)
    mov64 r2, r9                                    r2 = r9
    mov64 r3, r8                                    r3 = r8
    call function_16885                     
    ldxb r1, [r10-0x78]                     
    jeq r1, 56, lbb_17648                           if r1 == (56 as i32 as i64 as u64) { pc += 1 }
    ja lbb_17685                                    if true { pc += 37 }
lbb_17648:
    ldxdw r1, [r10-0x68]                    
    stxdw [r10-0xe0], r1                    
    ldxdw r5, [r10-0x60]                    
    ldxdw r4, [r10-0x70]                    
    mov64 r3, r8                                    r3 = r8
    add64 r3, 48                                    r3 += 48   ///  r3 = r3.wrapping_add(48 as i32 as i64 as u64)
    mov64 r1, r10                                   r1 = r10
    add64 r1, -120                                  r1 += -120   ///  r1 = r1.wrapping_add(-120 as i32 as i64 as u64)
    mov64 r2, r9                                    r2 = r9
    stxdw [r10-0xe8], r4                    
    stxdw [r10-0xf0], r5                    
    call function_17016                     
    ldxb r9, [r10-0x78]                     
    jeq r9, 56, lbb_17663                           if r9 == (56 as i32 as i64 as u64) { pc += 1 }
    ja lbb_17705                                    if true { pc += 42 }
lbb_17663:
    ldxdw r1, [r10-0x60]                    
    stxdw [r10-0x81], r1                    
    ldxdw r2, [r10-0x68]                    
    stxdw [r10-0x89], r2                    
    ldxdw r3, [r10-0x70]                    
    stxdw [r10-0x91], r3                    
    stxdw [r6+0x30], r1                     
    stxdw [r6+0x28], r2                     
    stxdw [r6+0x20], r3                     
    add64 r7, -2                                    r7 += -2   ///  r7 = r7.wrapping_add(-2 as i32 as i64 as u64)
    stxdw [r6+0x40], r7                     
    add64 r8, 96                                    r8 += 96   ///  r8 = r8.wrapping_add(96 as i32 as i64 as u64)
    stxdw [r6+0x38], r8                     
    ldxdw r1, [r10-0xf0]                    
    stxdw [r6+0x18], r1                     
    ldxdw r1, [r10-0xe0]                    
    stxdw [r6+0x10], r1                     
    ldxdw r1, [r10-0xe8]                    
    stxdw [r6+0x8], r1                      
    mov64 r1, 56                                    r1 = 56 as i32 as i64 as u64
    stxb [r6+0x0], r1                       
    ja lbb_17732                                    if true { pc += 47 }
lbb_17685:
    stxdw [r10-0xe0], r1                    
    ldxw r1, [r10-0x74]                     
    stxw [r6+0x4], r1                       
    ldxw r1, [r10-0x77]                     
    stxw [r6+0x1], r1                       
    ldxdw r7, [r10-0x70]                    
    ldxdw r8, [r10-0x68]                    
    ldxdw r9, [r10-0x60]                    
    mov64 r1, r6                                    r1 = r6
    add64 r1, 32                                    r1 += 32   ///  r1 = r1.wrapping_add(32 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -88                                   r2 += -88   ///  r2 = r2.wrapping_add(-88 as i32 as i64 as u64)
    mov64 r3, 40                                    r3 = 40 as i32 as i64 as u64
    call function_48190                     
    stxdw [r6+0x18], r9                     
    stxdw [r6+0x10], r8                     
    stxdw [r6+0x8], r7                      
    ldxdw r1, [r10-0xe0]                    
    stxb [r6+0x0], r1                       
    ja lbb_17732                                    if true { pc += 27 }
lbb_17705:
    ldxdw r1, [r10-0x60]                    
    stxdw [r10-0x81], r1                    
    ldxdw r1, [r10-0x67]                    
    stxdw [r10-0x88], r1                    
    ldxdw r1, [r10-0x6f]                    
    stxdw [r10-0x90], r1                    
    ldxdw r1, [r10-0x77]                    
    stxdw [r10-0x98], r1                    
    mov64 r1, r6                                    r1 = r6
    add64 r1, 32                                    r1 += 32   ///  r1 = r1.wrapping_add(32 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -88                                   r2 += -88   ///  r2 = r2.wrapping_add(-88 as i32 as i64 as u64)
    mov64 r3, 40                                    r3 = 40 as i32 as i64 as u64
    call function_48190                     
    ldxdw r1, [r10-0x81]                    
    stxdw [r6+0x18], r1                     
    ldxdw r1, [r10-0x88]                    
    stxdw [r6+0x11], r1                     
    ldxdw r1, [r10-0x90]                    
    stxdw [r6+0x9], r1                      
    ldxdw r1, [r10-0x98]                    
    stxdw [r6+0x1], r1                      
    stxb [r6+0x0], r9                       
    ldxdw r2, [r10-0xe0]                    
    ldxdw r1, [r2+0x0]                      
    add64 r1, -1                                    r1 += -1   ///  r1 = r1.wrapping_add(-1 as i32 as i64 as u64)
    stxdw [r2+0x0], r1                      
lbb_17732:
    exit                                    

function_17733:
    mov64 r9, r5                                    r9 = r5
    stxdw [r10-0x130], r4                   
    mov64 r7, r3                                    r7 = r3
    mov64 r6, r1                                    r6 = r1
    ldxdw r8, [r9-0xff8]                    
    mov64 r1, r7                                    r1 = r7
    call function_39132                     
    ldxdw r9, [r9-0x1000]                   
    jne r0, 0, lbb_17745                            if r0 != (0 as i32 as i64 as u64) { pc += 3 }
    mov64 r1, r7                                    r1 = r7
    call function_39148                     
    jne r0, 0, lbb_17781                            if r0 != (0 as i32 as i64 as u64) { pc += 36 }
lbb_17745:
    mov64 r1, r10                                   r1 = r10
    add64 r1, -296                                  r1 += -296   ///  r1 = r1.wrapping_add(-296 as i32 as i64 as u64)
    mov64 r2, r7                                    r2 = r7
    call function_39176                     
    ldxw r3, [r10-0x128]                    
    jeq r3, 24, lbb_17752                           if r3 == (24 as i32 as i64 as u64) { pc += 1 }
    ja lbb_17775                                    if true { pc += 23 }
lbb_17752:
    stxdw [r10-0x138], r8                   
    ldxdw r0, [r10-0x118]                   
    ldxdw r2, [r10-0x120]                   
    ldxdw r3, [r7+0x0]                      
    ldxdw r1, [r2+0x8]                      
    jne r1, 128, lbb_17762                          if r1 != (128 as i32 as i64 as u64) { pc += 4 }
    ldxdw r8, [r2+0x0]                      
    mov64 r2, r8                                    r2 = r8
    and64 r2, 7                                     r2 &= 7   ///  r2 = r2.and(7)
    jeq r2, 0, lbb_17815                            if r2 == (0 as i32 as i64 as u64) { pc += 53 }
lbb_17762:
    ldxdw r4, [r3+0x8]                      
    ldxdw r5, [r3+0x0]                      
    ldxdw r2, [r3+0x18]                     
    stxdw [r10-0x48], r2                    
    ldxdw r2, [r3+0x10]                     
    stxdw [r10-0x50], r2                    
    ldxdw r2, [r0+0x0]                      
    add64 r2, -1                                    r2 += -1   ///  r2 = r2.wrapping_add(-1 as i32 as i64 as u64)
    stxdw [r0+0x0], r2                      
    mov64 r2, 35                                    r2 = 35 as i32 as i64 as u64
    mov64 r3, 128                                   r3 = 128 as i32 as i64 as u64
    mov64 r0, 0                                     r0 = 0 as i32 as i64 as u64
    ja lbb_17793                                    if true { pc += 18 }
lbb_17775:
    mov64 r2, 55                                    r2 = 55 as i32 as i64 as u64
    ldxdw r1, [r10-0x120]                   
    ldxdw r4, [r10-0x110]                   
    ldxdw r5, [r10-0x118]                   
    ldxw r0, [r10-0x124]                    
    ja lbb_17793                                    if true { pc += 12 }
lbb_17781:
    ldxdw r3, [r7+0x0]                      
    ldxw r1, [r3+0x3]                       
    stxw [r10-0x65], r1                     
    ldxw r1, [r3+0x0]                       
    stxw [r10-0x68], r1                     
    mov64 r2, 37                                    r2 = 37 as i32 as i64 as u64
    ldxb r4, [r3+0x1f]                      
    ldxdw r5, [r3+0x17]                     
    ldxdw r1, [r3+0xf]                      
    ldxdw r3, [r3+0x7]                      
    mov64 r0, r3                                    r0 = r3
    rsh64 r0, 32                                    r0 >>= 32   ///  r0 = r0.wrapping_shr(32)
lbb_17793:
    ldxw r7, [r10-0x65]                     
    stxw [r6+0x4], r7                       
    ldxw r7, [r10-0x68]                     
    stxw [r6+0x1], r7                       
    ldxdw r7, [r10-0x50]                    
    stxdw [r6+0x28], r7                     
    ldxdw r7, [r10-0x48]                    
    stxdw [r6+0x30], r7                     
    ldxdw r7, [r10-0x40]                    
    stxdw [r6+0x38], r7                     
    ldxdw r7, [r10-0x38]                    
    stxdw [r6+0x40], r7                     
    stxdw [r6+0x20], r4                     
    stxdw [r6+0x18], r5                     
    stxdw [r6+0x10], r1                     
    lsh64 r0, 32                                    r0 <<= 32   ///  r0 = r0.wrapping_shl(32)
    lsh64 r3, 32                                    r3 <<= 32   ///  r3 = r3.wrapping_shl(32)
    rsh64 r3, 32                                    r3 >>= 32   ///  r3 = r3.wrapping_shr(32)
    or64 r0, r3                                     r0 |= r3   ///  r0 = r0.or(r3)
    stxdw [r6+0x8], r0                      
    stxb [r6+0x0], r2                       
    ja lbb_18387                                    if true { pc += 572 }
lbb_17815:
    stxdw [r10-0x148], r9                   
    stxdw [r10-0x140], r3                   
    mov64 r9, r8                                    r9 = r8
    add64 r9, 24                                    r9 += 24   ///  r9 = r9.wrapping_add(24 as i32 as i64 as u64)
    ldxdw r1, [r10-0x138]                   
    ldxdw r1, [r1+0x0]                      
    ldxdw r2, [r8+0x18]                     
    jeq r2, r1, lbb_17825                           if r2 == r1 { pc += 2 }
lbb_17823:
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    ja lbb_17838                                    if true { pc += 13 }
lbb_17825:
    ldxdw r1, [r10-0x138]                   
    ldxdw r1, [r1+0x8]                      
    ldxdw r2, [r9+0x8]                      
    jne r2, r1, lbb_17823                           if r2 != r1 { pc += -6 }
    ldxdw r1, [r10-0x138]                   
    ldxdw r1, [r1+0x10]                     
    ldxdw r2, [r9+0x10]                     
    jne r2, r1, lbb_17823                           if r2 != r1 { pc += -10 }
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    ldxdw r2, [r10-0x138]                   
    ldxdw r2, [r2+0x18]                     
    ldxdw r3, [r9+0x18]                     
    jne r3, r2, lbb_17823                           if r3 != r2 { pc += -15 }
lbb_17838:
    mov64 r2, 35                                    r2 = 35 as i32 as i64 as u64
    stxdw [r10-0x78], r2                    
    lddw r2, 0x100060c9e --> b"Quote account is for incorrect mintprogram/src/loa"        r2 load str located at 4295363742
    stxdw [r10-0x80], r2                    
    jeq r1, 0, lbb_17991                            if r1 == (0 as i32 as i64 as u64) { pc += 147 }
    mov64 r8, r0                                    r8 = r0
    lddw r1, 0x100065550 --> b"\x00\x00\x00\x00\xc1\x0c\x06\x00\x1f\x00\x00\x00\x00\x00\x00\x00\x1f\x00\…        r1 load str located at 4295382352
    stxdw [r10-0x70], r1                    
    lddw r1, 0x100064c98 --> b"\x00\x00\x00\x00p\xfa\x05\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00…        r1 load str located at 4295380120
    stxdw [r10-0x128], r1                   
    mov64 r1, 2                                     r1 = 2 as i32 as i64 as u64
    stxdw [r10-0x120], r1                   
    stxdw [r10-0x110], r1                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -80                                   r1 += -80   ///  r1 = r1.wrapping_add(-80 as i32 as i64 as u64)
    stxdw [r10-0x118], r1                   
    lddw r1, 0x100000888 --> b"y\x11\x00\x00\x00\x00\x00\x00\x85\x10\x00\x00]\xab\x00\x00\x95\x00\x00\x0…        r1 load str located at 4294969480
    stxdw [r10-0x38], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -112                                  r1 += -112   ///  r1 = r1.wrapping_add(-112 as i32 as i64 as u64)
    stxdw [r10-0x40], r1                    
    lddw r1, 0x100000860 --> b"\xbf#\x00\x00\x00\x00\x00\x00y\x12\x08\x00\x00\x00\x00\x00y\x11\x00\x00\x…        r1 load str located at 4294969440
    stxdw [r10-0x48], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -128                                  r1 += -128   ///  r1 = r1.wrapping_add(-128 as i32 as i64 as u64)
    stxdw [r10-0x50], r1                    
    mov64 r7, 0                                     r7 = 0 as i32 as i64 as u64
    stxdw [r10-0x108], r7                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -104                                  r1 += -104   ///  r1 = r1.wrapping_add(-104 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -296                                  r2 += -296   ///  r2 = r2.wrapping_add(-296 as i32 as i64 as u64)
    call function_43415                     
    ldxdw r1, [r10-0x68]                    
    ldxdw r2, [r10-0x58]                    
    syscall [invalid]                       
    ldxdw r2, [r10-0x140]                   
    ldxdw r1, [r2+0x18]                     
    stxdw [r10-0x110], r1                   
    ldxdw r1, [r2+0x10]                     
    stxdw [r10-0x118], r1                   
    ldxdw r1, [r2+0x8]                      
    stxdw [r10-0x120], r1                   
    ldxdw r1, [r2+0x0]                      
    stxdw [r10-0x128], r1                   
    lddw r1, 0x300000000                            r1 load str located at 12884901888
    ldxdw r2, [r1+0x0]                      
    mov64 r3, 1                                     r3 = 1 as i32 as i64 as u64
    mov64 r1, r2                                    r1 = r2
    add64 r1, -32                                   r1 += -32   ///  r1 = r1.wrapping_add(-32 as i32 as i64 as u64)
    jgt r1, r2, lbb_17896                           if r1 > r2 { pc += 1 }
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
lbb_17896:
    jne r3, 0, lbb_17898                            if r3 != (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r7, r1                                    r7 = r1
lbb_17898:
    lddw r1, 0x300007fe0                            r1 load str located at 12884934624
    jeq r2, 0, lbb_17902                            if r2 == (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r1, r7                                    r1 = r7
lbb_17902:
    lddw r2, 0x300000007                            r2 load str located at 12884901895
    jgt r1, r2, lbb_17909                           if r1 > r2 { pc += 4 }
lbb_17905:
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    mov64 r2, 32                                    r2 = 32 as i32 as i64 as u64
    call function_43400                     
    syscall [invalid]                       
lbb_17909:
    lddw r2, 0x300000000                            r2 load str located at 12884901888
    stxdw [r2+0x0], r1                      
    ldxdw r3, [r10-0x110]                   
    stxdw [r1+0x18], r3                     
    ldxdw r3, [r10-0x118]                   
    stxdw [r1+0x10], r3                     
    ldxdw r3, [r10-0x120]                   
    stxdw [r1+0x8], r3                      
    ldxdw r3, [r10-0x128]                   
    stxdw [r1+0x0], r3                      
    ldxdw r3, [r9+0x18]                     
    stxdw [r10-0x110], r3                   
    ldxdw r3, [r9+0x10]                     
    stxdw [r10-0x118], r3                   
    ldxdw r3, [r9+0x8]                      
    stxdw [r10-0x120], r3                   
    ldxdw r3, [r9+0x0]                      
    stxdw [r10-0x128], r3                   
    ldxdw r3, [r2+0x0]                      
    mov64 r4, 0                                     r4 = 0 as i32 as i64 as u64
    mov64 r5, 1                                     r5 = 1 as i32 as i64 as u64
    mov64 r2, r3                                    r2 = r3
    add64 r2, -32                                   r2 += -32   ///  r2 = r2.wrapping_add(-32 as i32 as i64 as u64)
    jgt r2, r3, lbb_17935                           if r2 > r3 { pc += 1 }
    mov64 r5, 0                                     r5 = 0 as i32 as i64 as u64
lbb_17935:
    jne r5, 0, lbb_17937                            if r5 != (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r4, r2                                    r4 = r2
lbb_17937:
    lddw r2, 0x300007fe0                            r2 load str located at 12884934624
    jeq r3, 0, lbb_17941                            if r3 == (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r2, r4                                    r2 = r4
lbb_17941:
    lddw r3, 0x300000007                            r3 load str located at 12884901895
    jgt r2, r3, lbb_17945                           if r2 > r3 { pc += 1 }
    ja lbb_17905                                    if true { pc += -40 }
lbb_17945:
    lddw r3, 0x300000000                            r3 load str located at 12884901888
    stxdw [r3+0x0], r2                      
    ldxdw r4, [r10-0x110]                   
    stxdw [r2+0x18], r4                     
    ldxdw r4, [r10-0x118]                   
    stxdw [r2+0x10], r4                     
    ldxdw r4, [r10-0x120]                   
    stxdw [r2+0x8], r4                      
    ldxdw r4, [r10-0x128]                   
    stxdw [r2+0x0], r4                      
    ldxdw r4, [r3+0x0]                      
    mov64 r3, r4                                    r3 = r4
    add64 r3, -32                                   r3 += -32   ///  r3 = r3.wrapping_add(-32 as i32 as i64 as u64)
    mov64 r5, 0                                     r5 = 0 as i32 as i64 as u64
    mov64 r0, 1                                     r0 = 1 as i32 as i64 as u64
    jgt r3, r4, lbb_17963                           if r3 > r4 { pc += 1 }
    mov64 r0, 0                                     r0 = 0 as i32 as i64 as u64
lbb_17963:
    jne r0, 0, lbb_17965                            if r0 != (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r5, r3                                    r5 = r3
lbb_17965:
    lddw r3, 0x300007fe0                            r3 load str located at 12884934624
    jeq r4, 0, lbb_17969                            if r4 == (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r3, r5                                    r3 = r5
lbb_17969:
    lddw r4, 0x300000007                            r4 load str located at 12884901895
    mov64 r0, r8                                    r0 = r8
    jgt r3, r4, lbb_17974                           if r3 > r4 { pc += 1 }
    ja lbb_17905                                    if true { pc += -69 }
lbb_17974:
    lddw r4, 0x300000000                            r4 load str located at 12884901888
    stxdw [r4+0x0], r3                      
    ldxdw r5, [r10-0x138]                   
    ldxdw r4, [r5+0x18]                     
    stxdw [r3+0x18], r4                     
    ldxdw r4, [r5+0x10]                     
    stxdw [r3+0x10], r4                     
    ldxdw r4, [r5+0x8]                      
    stxdw [r3+0x8], r4                      
    ldxdw r4, [r5+0x0]                      
    stxdw [r3+0x0], r4                      
    stxdw [r6+0x18], r3                     
    stxdw [r6+0x10], r2                     
    stxdw [r6+0x8], r1                      
    mov64 r1, 11                                    r1 = 11 as i32 as i64 as u64
    ja lbb_18383                                    if true { pc += 392 }
lbb_17991:
    mov64 r9, r8                                    r9 = r8
    add64 r9, 56                                    r9 += 56   ///  r9 = r9.wrapping_add(56 as i32 as i64 as u64)
    ldxdw r1, [r10-0x148]                   
    ldxdw r1, [r1+0x0]                      
    ldxdw r2, [r8+0x38]                     
    jeq r2, r1, lbb_17999                           if r2 == r1 { pc += 2 }
lbb_17997:
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    ja lbb_18012                                    if true { pc += 13 }
lbb_17999:
    ldxdw r1, [r10-0x148]                   
    ldxdw r1, [r1+0x8]                      
    ldxdw r2, [r9+0x8]                      
    jne r2, r1, lbb_17997                           if r2 != r1 { pc += -6 }
    ldxdw r1, [r10-0x148]                   
    ldxdw r1, [r1+0x10]                     
    ldxdw r2, [r9+0x10]                     
    jne r2, r1, lbb_17997                           if r2 != r1 { pc += -10 }
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    ldxdw r2, [r10-0x148]                   
    ldxdw r2, [r2+0x18]                     
    ldxdw r3, [r9+0x18]                     
    jne r3, r2, lbb_17997                           if r3 != r2 { pc += -15 }
lbb_18012:
    mov64 r2, 34                                    r2 = 34 as i32 as i64 as u64
    stxdw [r10-0x78], r2                    
    lddw r2, 0x100060ce0 --> b"Quote account is for incorrect dexQuote account is"        r2 load str located at 4295363808
    stxdw [r10-0x80], r2                    
    jeq r1, 0, lbb_18162                            if r1 == (0 as i32 as i64 as u64) { pc += 144 }
    mov64 r8, r0                                    r8 = r0
    lddw r1, 0x100065568 --> b"\x00\x00\x00\x00\xc1\x0c\x06\x00\x1f\x00\x00\x00\x00\x00\x00\x00)\x00\x00…        r1 load str located at 4295382376
    stxdw [r10-0x70], r1                    
    lddw r1, 0x100064c98 --> b"\x00\x00\x00\x00p\xfa\x05\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00…        r1 load str located at 4295380120
    stxdw [r10-0x128], r1                   
    mov64 r1, 2                                     r1 = 2 as i32 as i64 as u64
    stxdw [r10-0x120], r1                   
    stxdw [r10-0x110], r1                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -80                                   r1 += -80   ///  r1 = r1.wrapping_add(-80 as i32 as i64 as u64)
    stxdw [r10-0x118], r1                   
    lddw r1, 0x100000888 --> b"y\x11\x00\x00\x00\x00\x00\x00\x85\x10\x00\x00]\xab\x00\x00\x95\x00\x00\x0…        r1 load str located at 4294969480
    stxdw [r10-0x38], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -112                                  r1 += -112   ///  r1 = r1.wrapping_add(-112 as i32 as i64 as u64)
    stxdw [r10-0x40], r1                    
    lddw r1, 0x100000860 --> b"\xbf#\x00\x00\x00\x00\x00\x00y\x12\x08\x00\x00\x00\x00\x00y\x11\x00\x00\x…        r1 load str located at 4294969440
    stxdw [r10-0x48], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -128                                  r1 += -128   ///  r1 = r1.wrapping_add(-128 as i32 as i64 as u64)
    stxdw [r10-0x50], r1                    
    mov64 r7, 0                                     r7 = 0 as i32 as i64 as u64
    stxdw [r10-0x108], r7                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -104                                  r1 += -104   ///  r1 = r1.wrapping_add(-104 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -296                                  r2 += -296   ///  r2 = r2.wrapping_add(-296 as i32 as i64 as u64)
    call function_43415                     
    ldxdw r1, [r10-0x68]                    
    ldxdw r2, [r10-0x58]                    
    syscall [invalid]                       
    ldxdw r1, [r9+0x18]                     
    stxdw [r10-0x110], r1                   
    ldxdw r1, [r9+0x10]                     
    stxdw [r10-0x118], r1                   
    ldxdw r1, [r9+0x8]                      
    stxdw [r10-0x120], r1                   
    ldxdw r1, [r9+0x0]                      
    stxdw [r10-0x128], r1                   
    lddw r1, 0x300000000                            r1 load str located at 12884901888
    ldxdw r2, [r1+0x0]                      
    mov64 r3, 1                                     r3 = 1 as i32 as i64 as u64
    mov64 r1, r2                                    r1 = r2
    add64 r1, -32                                   r1 += -32   ///  r1 = r1.wrapping_add(-32 as i32 as i64 as u64)
    jgt r1, r2, lbb_18069                           if r1 > r2 { pc += 1 }
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
lbb_18069:
    ldxdw r0, [r10-0x148]                   
    jne r3, 0, lbb_18072                            if r3 != (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r7, r1                                    r7 = r1
lbb_18072:
    lddw r1, 0x300007fe0                            r1 load str located at 12884934624
    jeq r2, 0, lbb_18076                            if r2 == (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r1, r7                                    r1 = r7
lbb_18076:
    lddw r2, 0x300000007                            r2 load str located at 12884901895
    jgt r1, r2, lbb_18080                           if r1 > r2 { pc += 1 }
    ja lbb_17905                                    if true { pc += -175 }
lbb_18080:
    lddw r2, 0x300000000                            r2 load str located at 12884901888
    stxdw [r2+0x0], r1                      
    ldxdw r3, [r10-0x110]                   
    stxdw [r1+0x18], r3                     
    ldxdw r3, [r10-0x118]                   
    stxdw [r1+0x10], r3                     
    ldxdw r3, [r10-0x120]                   
    stxdw [r1+0x8], r3                      
    ldxdw r3, [r10-0x128]                   
    stxdw [r1+0x0], r3                      
    ldxdw r3, [r2+0x0]                      
    mov64 r2, r3                                    r2 = r3
    add64 r2, -32                                   r2 += -32   ///  r2 = r2.wrapping_add(-32 as i32 as i64 as u64)
    mov64 r4, 0                                     r4 = 0 as i32 as i64 as u64
    mov64 r5, 1                                     r5 = 1 as i32 as i64 as u64
    jgt r2, r3, lbb_18098                           if r2 > r3 { pc += 1 }
    mov64 r5, 0                                     r5 = 0 as i32 as i64 as u64
lbb_18098:
    jne r5, 0, lbb_18100                            if r5 != (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r4, r2                                    r4 = r2
lbb_18100:
    lddw r2, 0x300007fe0                            r2 load str located at 12884934624
    jeq r3, 0, lbb_18104                            if r3 == (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r2, r4                                    r2 = r4
lbb_18104:
    lddw r3, 0x300000007                            r3 load str located at 12884901895
    jgt r2, r3, lbb_18108                           if r2 > r3 { pc += 1 }
    ja lbb_17905                                    if true { pc += -203 }
lbb_18108:
    lddw r3, 0x300000000                            r3 load str located at 12884901888
    stxdw [r3+0x0], r2                      
    ldxdw r4, [r0+0x18]                     
    stxdw [r2+0x18], r4                     
    ldxdw r4, [r0+0x10]                     
    stxdw [r2+0x10], r4                     
    ldxdw r4, [r0+0x8]                      
    stxdw [r2+0x8], r4                      
    ldxdw r4, [r0+0x0]                      
    stxdw [r2+0x0], r4                      
    ldxdw r5, [r10-0x140]                   
    ldxdw r4, [r5+0x18]                     
    stxdw [r10-0x110], r4                   
    ldxdw r4, [r5+0x10]                     
    stxdw [r10-0x118], r4                   
    ldxdw r4, [r5+0x8]                      
    stxdw [r10-0x120], r4                   
    ldxdw r4, [r5+0x0]                      
    stxdw [r10-0x128], r4                   
    ldxdw r4, [r3+0x0]                      
    mov64 r5, 0                                     r5 = 0 as i32 as i64 as u64
    mov64 r0, 1                                     r0 = 1 as i32 as i64 as u64
    mov64 r3, r4                                    r3 = r4
    add64 r3, -32                                   r3 += -32   ///  r3 = r3.wrapping_add(-32 as i32 as i64 as u64)
    jgt r3, r4, lbb_18135                           if r3 > r4 { pc += 1 }
    mov64 r0, 0                                     r0 = 0 as i32 as i64 as u64
lbb_18135:
    jne r0, 0, lbb_18137                            if r0 != (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r5, r3                                    r5 = r3
lbb_18137:
    lddw r3, 0x300007fe0                            r3 load str located at 12884934624
    jeq r4, 0, lbb_18141                            if r4 == (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r3, r5                                    r3 = r5
lbb_18141:
    lddw r4, 0x300000007                            r4 load str located at 12884901895
    mov64 r0, r8                                    r0 = r8
    jgt r3, r4, lbb_18146                           if r3 > r4 { pc += 1 }
    ja lbb_17905                                    if true { pc += -241 }
lbb_18146:
    lddw r4, 0x300000000                            r4 load str located at 12884901888
    stxdw [r4+0x0], r3                      
    ldxdw r4, [r10-0x110]                   
    stxdw [r3+0x18], r4                     
    ldxdw r4, [r10-0x118]                   
    stxdw [r3+0x10], r4                     
    ldxdw r4, [r10-0x120]                   
    stxdw [r3+0x8], r4                      
    ldxdw r4, [r10-0x128]                   
    stxdw [r3+0x0], r4                      
    stxdw [r6+0x18], r3                     
    stxdw [r6+0x10], r2                     
    stxdw [r6+0x8], r1                      
    mov64 r1, 22                                    r1 = 22 as i32 as i64 as u64
    ja lbb_18383                                    if true { pc += 221 }
lbb_18162:
    mov64 r9, r8                                    r9 = r8
    add64 r9, 88                                    r9 += 88   ///  r9 = r9.wrapping_add(88 as i32 as i64 as u64)
    ldxdw r2, [r10-0x130]                   
    ldxdw r1, [r2+0x28]                     
    add64 r2, 40                                    r2 += 40   ///  r2 = r2.wrapping_add(40 as i32 as i64 as u64)
    stxdw [r10-0x130], r2                   
    ldxdw r2, [r8+0x58]                     
    jeq r2, r1, lbb_18172                           if r2 == r1 { pc += 2 }
lbb_18170:
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    ja lbb_18185                                    if true { pc += 13 }
lbb_18172:
    ldxdw r1, [r10-0x130]                   
    ldxdw r1, [r1+0x8]                      
    ldxdw r2, [r9+0x8]                      
    jne r2, r1, lbb_18170                           if r2 != r1 { pc += -6 }
    ldxdw r1, [r10-0x130]                   
    ldxdw r1, [r1+0x10]                     
    ldxdw r2, [r9+0x10]                     
    jne r2, r1, lbb_18170                           if r2 != r1 { pc += -10 }
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    ldxdw r2, [r10-0x130]                   
    ldxdw r2, [r2+0x18]                     
    ldxdw r3, [r9+0x18]                     
    jne r3, r2, lbb_18170                           if r3 != r2 { pc += -15 }
lbb_18185:
    mov64 r2, 43                                    r2 = 43 as i32 as i64 as u64
    stxdw [r10-0x78], r2                    
    lddw r2, 0x100060d02 --> b"Quote account is for incorrect market maker\x09\xe2`;\xf3BB"        r2 load str located at 4295363842
    stxdw [r10-0x80], r2                    
    jeq r1, 0, lbb_18335                            if r1 == (0 as i32 as i64 as u64) { pc += 144 }
    mov64 r8, r0                                    r8 = r0
    lddw r1, 0x100065580 --> b"\x00\x00\x00\x00\xc1\x0c\x06\x00\x1f\x00\x00\x00\x00\x00\x00\x004\x00\x00…        r1 load str located at 4295382400
    stxdw [r10-0x70], r1                    
    lddw r1, 0x100064c98 --> b"\x00\x00\x00\x00p\xfa\x05\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00…        r1 load str located at 4295380120
    stxdw [r10-0x128], r1                   
    mov64 r1, 2                                     r1 = 2 as i32 as i64 as u64
    stxdw [r10-0x120], r1                   
    stxdw [r10-0x110], r1                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -80                                   r1 += -80   ///  r1 = r1.wrapping_add(-80 as i32 as i64 as u64)
    stxdw [r10-0x118], r1                   
    lddw r1, 0x100000888 --> b"y\x11\x00\x00\x00\x00\x00\x00\x85\x10\x00\x00]\xab\x00\x00\x95\x00\x00\x0…        r1 load str located at 4294969480
    stxdw [r10-0x38], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -112                                  r1 += -112   ///  r1 = r1.wrapping_add(-112 as i32 as i64 as u64)
    stxdw [r10-0x40], r1                    
    lddw r1, 0x100000860 --> b"\xbf#\x00\x00\x00\x00\x00\x00y\x12\x08\x00\x00\x00\x00\x00y\x11\x00\x00\x…        r1 load str located at 4294969440
    stxdw [r10-0x48], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -128                                  r1 += -128   ///  r1 = r1.wrapping_add(-128 as i32 as i64 as u64)
    stxdw [r10-0x50], r1                    
    mov64 r7, 0                                     r7 = 0 as i32 as i64 as u64
    stxdw [r10-0x108], r7                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -104                                  r1 += -104   ///  r1 = r1.wrapping_add(-104 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -296                                  r2 += -296   ///  r2 = r2.wrapping_add(-296 as i32 as i64 as u64)
    call function_43415                     
    ldxdw r1, [r10-0x68]                    
    ldxdw r2, [r10-0x58]                    
    syscall [invalid]                       
    ldxdw r1, [r9+0x18]                     
    stxdw [r10-0x110], r1                   
    ldxdw r1, [r9+0x10]                     
    stxdw [r10-0x118], r1                   
    ldxdw r1, [r9+0x8]                      
    stxdw [r10-0x120], r1                   
    ldxdw r1, [r9+0x0]                      
    stxdw [r10-0x128], r1                   
    lddw r1, 0x300000000                            r1 load str located at 12884901888
    ldxdw r2, [r1+0x0]                      
    mov64 r3, 1                                     r3 = 1 as i32 as i64 as u64
    mov64 r1, r2                                    r1 = r2
    add64 r1, -32                                   r1 += -32   ///  r1 = r1.wrapping_add(-32 as i32 as i64 as u64)
    jgt r1, r2, lbb_18242                           if r1 > r2 { pc += 1 }
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
lbb_18242:
    jne r3, 0, lbb_18244                            if r3 != (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r7, r1                                    r7 = r1
lbb_18244:
    lddw r1, 0x300007fe0                            r1 load str located at 12884934624
    jeq r2, 0, lbb_18248                            if r2 == (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r1, r7                                    r1 = r7
lbb_18248:
    lddw r2, 0x300000007                            r2 load str located at 12884901895
    jgt r1, r2, lbb_18252                           if r1 > r2 { pc += 1 }
    ja lbb_17905                                    if true { pc += -347 }
lbb_18252:
    lddw r2, 0x300000000                            r2 load str located at 12884901888
    stxdw [r2+0x0], r1                      
    ldxdw r3, [r10-0x110]                   
    stxdw [r1+0x18], r3                     
    ldxdw r3, [r10-0x118]                   
    stxdw [r1+0x10], r3                     
    ldxdw r3, [r10-0x120]                   
    stxdw [r1+0x8], r3                      
    ldxdw r3, [r10-0x128]                   
    stxdw [r1+0x0], r3                      
    ldxdw r3, [r2+0x0]                      
    mov64 r2, r3                                    r2 = r3
    add64 r2, -32                                   r2 += -32   ///  r2 = r2.wrapping_add(-32 as i32 as i64 as u64)
    mov64 r4, 0                                     r4 = 0 as i32 as i64 as u64
    mov64 r5, 1                                     r5 = 1 as i32 as i64 as u64
    jgt r2, r3, lbb_18270                           if r2 > r3 { pc += 1 }
    mov64 r5, 0                                     r5 = 0 as i32 as i64 as u64
lbb_18270:
    jne r5, 0, lbb_18272                            if r5 != (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r4, r2                                    r4 = r2
lbb_18272:
    lddw r2, 0x300007fe0                            r2 load str located at 12884934624
    jeq r3, 0, lbb_18276                            if r3 == (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r2, r4                                    r2 = r4
lbb_18276:
    lddw r3, 0x300000007                            r3 load str located at 12884901895
    jgt r2, r3, lbb_18280                           if r2 > r3 { pc += 1 }
    ja lbb_17905                                    if true { pc += -375 }
lbb_18280:
    lddw r3, 0x300000000                            r3 load str located at 12884901888
    stxdw [r3+0x0], r2                      
    ldxdw r5, [r10-0x130]                   
    ldxdw r4, [r5+0x18]                     
    stxdw [r2+0x18], r4                     
    ldxdw r4, [r5+0x10]                     
    stxdw [r2+0x10], r4                     
    ldxdw r4, [r5+0x8]                      
    stxdw [r2+0x8], r4                      
    ldxdw r4, [r5+0x0]                      
    stxdw [r2+0x0], r4                      
    ldxdw r5, [r10-0x140]                   
    ldxdw r4, [r5+0x18]                     
    stxdw [r10-0x110], r4                   
    ldxdw r4, [r5+0x10]                     
    stxdw [r10-0x118], r4                   
    ldxdw r4, [r5+0x8]                      
    stxdw [r10-0x120], r4                   
    ldxdw r4, [r5+0x0]                      
    stxdw [r10-0x128], r4                   
    ldxdw r4, [r3+0x0]                      
    mov64 r5, 0                                     r5 = 0 as i32 as i64 as u64
    mov64 r0, 1                                     r0 = 1 as i32 as i64 as u64
    mov64 r3, r4                                    r3 = r4
    add64 r3, -32                                   r3 += -32   ///  r3 = r3.wrapping_add(-32 as i32 as i64 as u64)
    jgt r3, r4, lbb_18308                           if r3 > r4 { pc += 1 }
    mov64 r0, 0                                     r0 = 0 as i32 as i64 as u64
lbb_18308:
    jne r0, 0, lbb_18310                            if r0 != (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r5, r3                                    r5 = r3
lbb_18310:
    lddw r3, 0x300007fe0                            r3 load str located at 12884934624
    jeq r4, 0, lbb_18314                            if r4 == (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r3, r5                                    r3 = r5
lbb_18314:
    lddw r4, 0x300000007                            r4 load str located at 12884901895
    mov64 r0, r8                                    r0 = r8
    jgt r3, r4, lbb_18319                           if r3 > r4 { pc += 1 }
    ja lbb_17905                                    if true { pc += -414 }
lbb_18319:
    lddw r4, 0x300000000                            r4 load str located at 12884901888
    stxdw [r4+0x0], r3                      
    ldxdw r4, [r10-0x110]                   
    stxdw [r3+0x18], r4                     
    ldxdw r4, [r10-0x118]                   
    stxdw [r3+0x10], r4                     
    ldxdw r4, [r10-0x120]                   
    stxdw [r3+0x8], r4                      
    ldxdw r4, [r10-0x128]                   
    stxdw [r3+0x0], r4                      
    stxdw [r6+0x18], r3                     
    stxdw [r6+0x10], r2                     
    stxdw [r6+0x8], r1                      
    mov64 r1, 24                                    r1 = 24 as i32 as i64 as u64
    ja lbb_18383                                    if true { pc += 48 }
lbb_18335:
    ldxdw r1, [r7+0x18]                     
    ldxdw r2, [r1+0x0]                      
    lddw r3, 0x974242f33b60e209                     r3 load str located at -7547396413078838775
    jeq r2, r3, lbb_18388                           if r2 == r3 { pc += 48 }
lbb_18340:
    mov64 r2, 1                                     r2 = 1 as i32 as i64 as u64
    jeq r2, 0, lbb_18403                            if r2 == (0 as i32 as i64 as u64) { pc += 61 }
lbb_18342:
    lddw r1, 0x300000000                            r1 load str located at 12884901888
    ldxdw r2, [r1+0x0]                      
    mov64 r1, r2                                    r1 = r2
    add64 r1, -29                                   r1 += -29   ///  r1 = r1.wrapping_add(-29 as i32 as i64 as u64)
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
    mov64 r4, 1                                     r4 = 1 as i32 as i64 as u64
    jgt r1, r2, lbb_18351                           if r1 > r2 { pc += 1 }
    mov64 r4, 0                                     r4 = 0 as i32 as i64 as u64
lbb_18351:
    jne r4, 0, lbb_18353                            if r4 != (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r3, r1                                    r3 = r1
lbb_18353:
    lddw r1, 0x300007fe3                            r1 load str located at 12884934627
    jeq r2, 0, lbb_18357                            if r2 == (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r1, r3                                    r1 = r3
lbb_18357:
    lddw r2, 0x300000007                            r2 load str located at 12884901895
    jgt r1, r2, lbb_18364                           if r1 > r2 { pc += 4 }
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    mov64 r2, 29                                    r2 = 29 as i32 as i64 as u64
    call function_43400                     
    syscall [invalid]                       
lbb_18364:
    lddw r2, 0x300000000                            r2 load str located at 12884901888
    stxdw [r2+0x0], r1                      
    lddw r2, 0x746e756f63636120                     r2 load str located at 8389772277107089696
    stxdw [r1+0x15], r2                     
    lddw r2, 0x63612065746f7571                     r2 load str located at 7161040502613046641
    stxdw [r1+0x10], r2                     
    lddw r2, 0x20726f662072656e                     r2 load str located at 2338053640980424046
    stxdw [r1+0x8], r2                      
    lddw r2, 0x776f20676e6f7257                     r2 load str located at 8606133041534825047
    stxdw [r1+0x0], r2                      
    stxdw [r6+0x8], r1                      
    mov64 r1, 29                                    r1 = 29 as i32 as i64 as u64
    stxdw [r6+0x18], r1                     
    stxdw [r6+0x10], r1                     
lbb_18383:
    stxb [r6+0x0], r1                       
lbb_18384:
    ldxdw r1, [r0+0x0]                      
    add64 r1, -1                                    r1 += -1   ///  r1 = r1.wrapping_add(-1 as i32 as i64 as u64)
    stxdw [r0+0x0], r1                      
lbb_18387:
    exit                                    
lbb_18388:
    ldxdw r2, [r1+0x8]                      
    lddw r3, 0xc3132e93ed47a24d                     r3 load str located at -4390113998880136627
    jne r2, r3, lbb_18340                           if r2 != r3 { pc += -52 }
    ldxdw r2, [r1+0x10]                     
    lddw r3, 0x1569326529647267                     r3 load str located at 1542819757418639975
    jne r2, r3, lbb_18340                           if r2 != r3 { pc += -56 }
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
    ldxdw r1, [r1+0x18]                     
    lddw r3, 0x90f88222f5a7a8bc                     r3 load str located at -8000501651361781572
    jne r1, r3, lbb_18340                           if r1 != r3 { pc += -61 }
    jeq r2, 0, lbb_18403                            if r2 == (0 as i32 as i64 as u64) { pc += 1 }
    ja lbb_18342                                    if true { pc += -61 }
lbb_18403:
    stxdw [r10-0x130], r0                   
    ldxb r1, [r8+0x78]                      
    stxdw [r10-0x1000], r1                  
    lddw r1, 0x100060d2d --> b"\x09\xe2`;\xf3BB\x97M\xa2G\xed\x93.\x13\xc3grd)e2i\x15\xbc\xa8\xa7\xf5"\x…        r1 load str located at 4295363885
    stxdw [r10-0xff8], r1                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -296                                  r1 += -296   ///  r1 = r1.wrapping_add(-296 as i32 as i64 as u64)
    mov64 r5, r10                                   r5 = r10
    ldxdw r9, [r10-0x140]                   
    mov64 r2, r9                                    r2 = r9
    ldxdw r3, [r10-0x148]                   
    ldxdw r4, [r10-0x138]                   
    call function_28862                     
    ldxb r7, [r10-0x128]                    
    jeq r7, 56, lbb_18420                           if r7 == (56 as i32 as i64 as u64) { pc += 1 }
    ja lbb_18427                                    if true { pc += 7 }
lbb_18420:
    stxdw [r6+0x18], r9                     
    ldxdw r1, [r10-0x130]                   
    stxdw [r6+0x10], r1                     
    stxdw [r6+0x8], r8                      
    mov64 r1, 56                                    r1 = 56 as i32 as i64 as u64
    stxb [r6+0x0], r1                       
    ja lbb_18387                                    if true { pc += -40 }
lbb_18427:
    mov64 r1, r6                                    r1 = r6
    add64 r1, 1                                     r1 += 1   ///  r1 = r1.wrapping_add(1 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -295                                  r2 += -295   ///  r2 = r2.wrapping_add(-295 as i32 as i64 as u64)
    mov64 r3, 71                                    r3 = 71 as i32 as i64 as u64
    call function_48190                     
    stxb [r6+0x0], r7                       
    ldxdw r0, [r10-0x130]                   
    ja lbb_18384                                    if true { pc += -52 }

function_18436:
    mov64 r8, r4                                    r8 = r4
    mov64 r7, r3                                    r7 = r3
    mov64 r6, r1                                    r6 = r1
    jne r8, 0, lbb_18481                            if r8 != (0 as i32 as i64 as u64) { pc += 41 }
    mov64 r1, 2                                     r1 = 2 as i32 as i64 as u64
    stxdw [r10-0x70], r1                    
    lddw r1, 0x100065598 --> b"\x00\x00\x00\x00m\x0d\x06\x00+\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x0…        r1 load str located at 4295382424
    stxdw [r10-0x78], r1                    
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    stxdw [r10-0x60], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -152                                  r1 += -152   ///  r1 = r1.wrapping_add(-152 as i32 as i64 as u64)
    stxdw [r10-0x68], r1                    
    lddw r1, 0x10005df58 --> b"\xbf#\x00\x00\x00\x00\x00\x00y\x11\x00\x00\x00\x00\x00\x00\xb7\x02\x00\x0…        r1 load str located at 4295352152
    stxdw [r10-0x90], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -160                                  r1 += -160   ///  r1 = r1.wrapping_add(-160 as i32 as i64 as u64)
    stxdw [r10-0x98], r1                    
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    stxdw [r10-0x58], r1                    
    stxdw [r10-0xa0], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -184                                  r1 += -184   ///  r1 = r1.wrapping_add(-184 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -120                                  r2 += -120   ///  r2 = r2.wrapping_add(-120 as i32 as i64 as u64)
    call function_43415                     
    ldxdw r1, [r10-0xb8]                    
    stxdw [r10-0xd0], r1                    
    ldxdw r1, [r10-0xb0]                    
    stxdw [r10-0xc8], r1                    
    ldxdw r1, [r10-0xa8]                    
    stxdw [r10-0xc0], r1                    
    mov64 r1, 29                                    r1 = 29 as i32 as i64 as u64
    stxb [r6+0x0], r1                       
    ldxdw r1, [r10-0xd7]                    
    stxdw [r6+0x1], r1                      
    ldxdw r1, [r10-0xcf]                    
    stxdw [r6+0x9], r1                      
    ldxdw r1, [r10-0xc7]                    
    stxdw [r6+0x11], r1                     
    ldxdw r1, [r10-0xc0]                    
    stxdw [r6+0x18], r1                     
    ja lbb_18533                                    if true { pc += 52 }
lbb_18481:
    ldxdw r1, [r5-0xff0]                    
    ldxdw r2, [r5-0xff8]                    
    ldxdw r4, [r5-0x1000]                   
    stxdw [r10-0x1000], r2                  
    stxdw [r10-0xff8], r1                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -120                                  r1 += -120   ///  r1 = r1.wrapping_add(-120 as i32 as i64 as u64)
    mov64 r5, r10                                   r5 = r10
    mov64 r3, r7                                    r3 = r7
    call function_17733                     
    ldxb r9, [r10-0x78]                     
    jeq r9, 56, lbb_18494                           if r9 == (56 as i32 as i64 as u64) { pc += 1 }
    ja lbb_18510                                    if true { pc += 16 }
lbb_18494:
    ldxdw r1, [r10-0x60]                    
    stxdw [r10-0x81], r1                    
    ldxdw r2, [r10-0x68]                    
    stxdw [r10-0x89], r2                    
    ldxdw r3, [r10-0x70]                    
    stxdw [r10-0x91], r3                    
    stxdw [r6+0x18], r1                     
    stxdw [r6+0x10], r2                     
    stxdw [r6+0x8], r3                      
    add64 r8, -1                                    r8 += -1   ///  r8 = r8.wrapping_add(-1 as i32 as i64 as u64)
    stxdw [r6+0x28], r8                     
    add64 r7, 48                                    r7 += 48   ///  r7 = r7.wrapping_add(48 as i32 as i64 as u64)
    stxdw [r6+0x20], r7                     
    mov64 r1, 56                                    r1 = 56 as i32 as i64 as u64
    stxb [r6+0x0], r1                       
    ja lbb_18533                                    if true { pc += 23 }
lbb_18510:
    ldxdw r1, [r10-0x60]                    
    stxdw [r10-0x81], r1                    
    ldxdw r1, [r10-0x67]                    
    stxdw [r10-0x88], r1                    
    ldxdw r1, [r10-0x6f]                    
    stxdw [r10-0x90], r1                    
    ldxdw r1, [r10-0x77]                    
    stxdw [r10-0x98], r1                    
    mov64 r1, r6                                    r1 = r6
    add64 r1, 32                                    r1 += 32   ///  r1 = r1.wrapping_add(32 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -88                                   r2 += -88   ///  r2 = r2.wrapping_add(-88 as i32 as i64 as u64)
    mov64 r3, 40                                    r3 = 40 as i32 as i64 as u64
    call function_48190                     
    ldxdw r1, [r10-0x81]                    
    stxdw [r6+0x18], r1                     
    ldxdw r1, [r10-0x88]                    
    stxdw [r6+0x11], r1                     
    ldxdw r1, [r10-0x90]                    
    stxdw [r6+0x9], r1                      
    ldxdw r1, [r10-0x98]                    
    stxdw [r6+0x1], r1                      
    stxb [r6+0x0], r9                       
lbb_18533:
    exit                                    

function_18534:
    mov64 r9, r2                                    r9 = r2
    mov64 r7, r1                                    r7 = r1
    jgt r3, 6, lbb_18579                            if r3 > (6 as i32 as i64 as u64) { pc += 42 }
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    stxdw [r10-0xf0], r1                    
    lddw r1, 0x1000655b8 --> b"\x00\x00\x00\x00\xae\x0d\x06\x000\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00…        r1 load str located at 4295382456
    stxdw [r10-0x110], r1                   
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    stxdw [r10-0xf8], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -1448                                 r1 += -1448   ///  r1 = r1.wrapping_add(-1448 as i32 as i64 as u64)
    stxdw [r10-0x100], r1                   
    lddw r1, 0x10005df58 --> b"\xbf#\x00\x00\x00\x00\x00\x00y\x11\x00\x00\x00\x00\x00\x00\xb7\x02\x00\x0…        r1 load str located at 4295352152
    stxdw [r10-0x5a0], r1                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -1624                                 r1 += -1624   ///  r1 = r1.wrapping_add(-1624 as i32 as i64 as u64)
    stxdw [r10-0x5a8], r1                   
    stxdw [r10-0x658], r3                   
    mov64 r6, 2                                     r6 = 2 as i32 as i64 as u64
    stxdw [r10-0x108], r6                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -1648                                 r1 += -1648   ///  r1 = r1.wrapping_add(-1648 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -272                                  r2 += -272   ///  r2 = r2.wrapping_add(-272 as i32 as i64 as u64)
    call function_43415                     
    ldxdw r1, [r10-0x670]                   
    stxdw [r10-0x688], r1                   
    ldxdw r1, [r10-0x668]                   
    stxdw [r10-0x680], r1                   
    ldxdw r1, [r10-0x660]                   
    stxdw [r10-0x678], r1                   
    mov64 r1, 29                                    r1 = 29 as i32 as i64 as u64
    stxb [r7+0x8], r1                       
    ldxdw r1, [r10-0x68f]                   
    stxdw [r7+0x9], r1                      
    ldxdw r1, [r10-0x687]                   
    stxdw [r7+0x11], r1                     
    ldxdw r1, [r10-0x67f]                   
    stxdw [r7+0x19], r1                     
    ldxdw r1, [r10-0x678]                   
lbb_18576:
    stxdw [r7+0x20], r1                     
lbb_18577:
    stxw [r7+0x0], r6                       
    ja lbb_18628                                    if true { pc += 49 }
lbb_18579:
    stxdw [r10-0x698], r3                   
    ldxdw r8, [r9+0x70]                     
    ldxdw r1, [r8+0x10]                     
    lddw r2, 0x7fffffffffffffff                     r2 load str located at 9223372036854775807
    jgt r2, r1, lbb_18586                           if r2 > r1 { pc += 1 }
    ja lbb_18774                                    if true { pc += 188 }
lbb_18586:
    add64 r1, 1                                     r1 += 1   ///  r1 = r1.wrapping_add(1 as i32 as i64 as u64)
    stxdw [r8+0x10], r1                     
    mov64 r6, 3                                     r6 = 3 as i32 as i64 as u64
    ldxdw r1, [r8+0x20]                     
    jne r1, 165, lbb_18599                          if r1 != (165 as i32 as i64 as u64) { pc += 8 }
    ldxdw r2, [r8+0x18]                     
    mov64 r1, r10                                   r1 = r10
    add64 r1, -272                                  r1 += -272   ///  r1 = r1.wrapping_add(-272 as i32 as i64 as u64)
    mov64 r3, 165                                   r3 = 165 as i32 as i64 as u64
    call function_32610                     
    ldxw r6, [r10-0x110]                    
    ldxw r1, [r10-0x88]                     
    jne r1, 2, lbb_18629                            if r1 != (2 as i32 as i64 as u64) { pc += 30 }
lbb_18599:
    ldxdw r1, [r10-0x10c]                   
    stxdw [r10-0x1e0], r1                   
    ldxdw r1, [r10-0x104]                   
    stxdw [r10-0x1d8], r1                   
    ldxdw r1, [r10-0xfc]                    
    stxdw [r10-0x1d0], r1                   
    ldxw r1, [r10-0xf4]                     
    stxw [r10-0x590], r1                    
    stxw [r10-0x1c8], r1                    
lbb_18608:
    ldxw r1, [r10-0x1c8]                    
    stxw [r10-0x478], r1                    
    ldxdw r2, [r10-0x1d0]                   
    stxdw [r10-0x480], r2                   
    ldxdw r3, [r10-0x1d8]                   
    stxdw [r10-0x488], r3                   
    ldxdw r4, [r10-0x1e0]                   
    stxdw [r10-0x490], r4                   
lbb_18616:
    stxw [r7+0x2c], r1                      
    stxdw [r7+0x24], r2                     
    stxdw [r7+0x1c], r3                     
    stxdw [r7+0x14], r4                     
    stxw [r7+0x10], r6                      
    mov64 r1, 55                                    r1 = 55 as i32 as i64 as u64
    stxb [r7+0x8], r1                       
    mov64 r1, 2                                     r1 = 2 as i32 as i64 as u64
    stxw [r7+0x0], r1                       
    ldxdw r1, [r8+0x10]                     
    add64 r1, -1                                    r1 += -1   ///  r1 = r1.wrapping_add(-1 as i32 as i64 as u64)
    stxdw [r8+0x10], r1                     
lbb_18628:
    exit                                    
lbb_18629:
    stxdw [r10-0x6b0], r1                   
    stxdw [r10-0x6a8], r9                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -1448                                 r1 += -1448   ///  r1 = r1.wrapping_add(-1448 as i32 as i64 as u64)
    stxdw [r10-0x6a0], r1                   
    mov64 r2, r10                                   r2 = r10
    add64 r2, -268                                  r2 += -268   ///  r2 = r2.wrapping_add(-268 as i32 as i64 as u64)
    mov64 r3, 104                                   r3 = 104 as i32 as i64 as u64
    call function_48190                     
    ldxdw r1, [r10-0xa3]                    
    stxdw [r10-0x228], r1                   
    ldxdw r1, [r10-0x9b]                    
    stxdw [r10-0x220], r1                   
    ldxdw r1, [r10-0x93]                    
    stxdw [r10-0x218], r1                   
    ldxw r1, [r10-0x8c]                     
    stxw [r10-0x211], r1                    
    ldxb r9, [r10-0xa4]                     
    mov64 r1, r10                                   r1 = r10
    add64 r1, -1272                                 r1 += -1272   ///  r1 = r1.wrapping_add(-1272 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -132                                  r2 += -132   ///  r2 = r2.wrapping_add(-132 as i32 as i64 as u64)
    mov64 r3, 36                                    r3 = 36 as i32 as i64 as u64
    call function_48190                     
    mov64 r1, r10                                   r1 = r10
    add64 r1, -376                                  r1 += -376   ///  r1 = r1.wrapping_add(-376 as i32 as i64 as u64)
    ldxdw r2, [r10-0x6a0]                   
    mov64 r3, 104                                   r3 = 104 as i32 as i64 as u64
    call function_48190                     
    stxdw [r10-0x6a0], r9                   
    jne r9, 0, lbb_18662                            if r9 != (0 as i32 as i64 as u64) { pc += 2 }
    mov64 r6, 9                                     r6 = 9 as i32 as i64 as u64
    ja lbb_18608                                    if true { pc += -54 }
lbb_18662:
    stxdw [r10-0x6b8], r7                   
    mov64 r9, r10                                   r9 = r10
    add64 r9, -480                                  r9 += -480   ///  r9 = r9.wrapping_add(-480 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -376                                  r2 += -376   ///  r2 = r2.wrapping_add(-376 as i32 as i64 as u64)
    mov64 r1, r9                                    r1 = r9
    mov64 r3, 104                                   r3 = 104 as i32 as i64 as u64
    call function_48190                     
    ldxdw r1, [r10-0x228]                   
    stxdw [r10-0x5eb], r1                   
    ldxdw r1, [r10-0x220]                   
    stxdw [r10-0x5e3], r1                   
    ldxdw r1, [r10-0x218]                   
    stxdw [r10-0x5db], r1                   
    ldxw r1, [r10-0x211]                    
    stxw [r10-0x5d4], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -1484                                 r1 += -1484   ///  r1 = r1.wrapping_add(-1484 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -1272                                 r2 += -1272   ///  r2 = r2.wrapping_add(-1272 as i32 as i64 as u64)
    mov64 r3, 36                                    r3 = 36 as i32 as i64 as u64
    call function_48190                     
    mov64 r7, r10                                   r7 = r10
    add64 r7, -1168                                 r7 += -1168   ///  r7 = r7.wrapping_add(-1168 as i32 as i64 as u64)
    mov64 r1, r7                                    r1 = r7
    mov64 r2, r9                                    r2 = r9
    mov64 r3, 104                                   r3 = 104 as i32 as i64 as u64
    call function_48190                     
    mov64 r1, r10                                   r1 = r10
    add64 r1, -1620                                 r1 += -1620   ///  r1 = r1.wrapping_add(-1620 as i32 as i64 as u64)
    mov64 r2, r7                                    r2 = r7
    mov64 r3, 104                                   r3 = 104 as i32 as i64 as u64
    call function_48190                     
    ldxdw r1, [r10-0x6b0]                   
    stxw [r10-0x5d0], r1                    
    ldxdw r1, [r10-0x6a0]                   
    stxb [r10-0x5ec], r1                    
    stxw [r10-0x658], r6                    
    ldxdw r1, [r8+0x10]                     
    add64 r1, -1                                    r1 += -1   ///  r1 = r1.wrapping_add(-1 as i32 as i64 as u64)
    stxdw [r8+0x10], r1                     
    ldxdw r1, [r10-0x6a8]                   
    ldxdw r8, [r1+0x100]                    
    ldxdw r1, [r8+0x10]                     
    lddw r2, 0x7fffffffffffffff                     r2 load str located at 9223372036854775807
    jgt r2, r1, lbb_18710                           if r2 > r1 { pc += 1 }
    ja lbb_18778                                    if true { pc += 68 }
lbb_18710:
    add64 r1, 1                                     r1 += 1   ///  r1 = r1.wrapping_add(1 as i32 as i64 as u64)
    stxdw [r8+0x10], r1                     
    mov64 r6, 3                                     r6 = 3 as i32 as i64 as u64
    ldxdw r1, [r8+0x20]                     
    ldxdw r7, [r10-0x6b8]                   
    jne r1, 165, lbb_18724                          if r1 != (165 as i32 as i64 as u64) { pc += 8 }
    ldxdw r2, [r8+0x18]                     
    mov64 r1, r10                                   r1 = r10
    add64 r1, -272                                  r1 += -272   ///  r1 = r1.wrapping_add(-272 as i32 as i64 as u64)
    mov64 r3, 165                                   r3 = 165 as i32 as i64 as u64
    call function_32610                     
    ldxw r6, [r10-0x110]                    
    ldxw r1, [r10-0x88]                     
    jne r1, 2, lbb_18742                            if r1 != (2 as i32 as i64 as u64) { pc += 18 }
lbb_18724:
    ldxdw r1, [r10-0x10c]                   
    stxdw [r10-0x490], r1                   
    ldxdw r1, [r10-0x104]                   
    stxdw [r10-0x488], r1                   
    ldxdw r1, [r10-0xfc]                    
    stxdw [r10-0x480], r1                   
    ldxw r1, [r10-0xf4]                     
    stxw [r10-0x160], r1                    
    stxw [r10-0x478], r1                    
lbb_18733:
    ldxw r1, [r10-0x478]                    
    stxw [r10-0x4e0], r1                    
    ldxdw r2, [r10-0x480]                   
    stxdw [r10-0x4e8], r2                   
    ldxdw r3, [r10-0x488]                   
    stxdw [r10-0x4f0], r3                   
    ldxdw r4, [r10-0x490]                   
    stxdw [r10-0x4f8], r4                   
    ja lbb_18616                                    if true { pc += -126 }
lbb_18742:
    stxdw [r10-0x6b0], r1                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -376                                  r1 += -376   ///  r1 = r1.wrapping_add(-376 as i32 as i64 as u64)
    stxdw [r10-0x6a0], r1                   
    mov64 r2, r10                                   r2 = r10
    add64 r2, -268                                  r2 += -268   ///  r2 = r2.wrapping_add(-268 as i32 as i64 as u64)
    mov64 r3, 104                                   r3 = 104 as i32 as i64 as u64
    call function_48190                     
    ldxdw r1, [r10-0xa3]                    
    stxdw [r10-0x200], r1                   
    ldxdw r1, [r10-0x9b]                    
    stxdw [r10-0x1f8], r1                   
    ldxdw r1, [r10-0x93]                    
    stxdw [r10-0x1f0], r1                   
    ldxw r1, [r10-0x8c]                     
    stxw [r10-0x1e9], r1                    
    ldxb r9, [r10-0xa4]                     
    mov64 r1, r10                                   r1 = r10
    add64 r1, -552                                  r1 += -552   ///  r1 = r1.wrapping_add(-552 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -132                                  r2 += -132   ///  r2 = r2.wrapping_add(-132 as i32 as i64 as u64)
    mov64 r3, 36                                    r3 = 36 as i32 as i64 as u64
    call function_48190                     
    mov64 r1, r10                                   r1 = r10
    add64 r1, -480                                  r1 += -480   ///  r1 = r1.wrapping_add(-480 as i32 as i64 as u64)
    ldxdw r2, [r10-0x6a0]                   
    mov64 r3, 104                                   r3 = 104 as i32 as i64 as u64
    call function_48190                     
    stxdw [r10-0x6a0], r9                   
    jne r9, 0, lbb_18782                            if r9 != (0 as i32 as i64 as u64) { pc += 10 }
    mov64 r6, 9                                     r6 = 9 as i32 as i64 as u64
    ja lbb_18733                                    if true { pc += -41 }
lbb_18774:
    lddw r1, 0x1000656c0 --> b"\x00\x00\x00\x00P\xff\x05\x00 \x00\x00\x00\x00\x00\x00\x00\x1f\x00\x00\x0…        r1 load str located at 4295382720
    call function_43759                     
    syscall [invalid]                       
lbb_18778:
    lddw r1, 0x1000656a8 --> b"\x00\x00\x00\x00P\xff\x05\x00 \x00\x00\x00\x00\x00\x00\x00 \x00\x00\x00S\…        r1 load str located at 4295382696
    call function_43759                     
    syscall [invalid]                       
lbb_18782:
    mov64 r9, r10                                   r9 = r10
    add64 r9, -1168                                 r9 += -1168   ///  r9 = r9.wrapping_add(-1168 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -480                                  r2 += -480   ///  r2 = r2.wrapping_add(-480 as i32 as i64 as u64)
    mov64 r1, r9                                    r1 = r9
    mov64 r3, 104                                   r3 = 104 as i32 as i64 as u64
    call function_48190                     
    ldxdw r1, [r10-0x200]                   
    stxdw [r10-0x53b], r1                   
    ldxdw r1, [r10-0x1f8]                   
    stxdw [r10-0x533], r1                   
    ldxdw r1, [r10-0x1f0]                   
    stxdw [r10-0x52b], r1                   
    ldxw r1, [r10-0x1e9]                    
    stxw [r10-0x524], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -1308                                 r1 += -1308   ///  r1 = r1.wrapping_add(-1308 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -552                                  r2 += -552   ///  r2 = r2.wrapping_add(-552 as i32 as i64 as u64)
    mov64 r3, 36                                    r3 = 36 as i32 as i64 as u64
    call function_48190                     
    mov64 r7, r10                                   r7 = r10
    add64 r7, -1272                                 r7 += -1272   ///  r7 = r7.wrapping_add(-1272 as i32 as i64 as u64)
    mov64 r1, r7                                    r1 = r7
    mov64 r2, r9                                    r2 = r9
    mov64 r3, 104                                   r3 = 104 as i32 as i64 as u64
    call function_48190                     
    mov64 r1, r10                                   r1 = r10
    add64 r1, -1444                                 r1 += -1444   ///  r1 = r1.wrapping_add(-1444 as i32 as i64 as u64)
    mov64 r2, r7                                    r2 = r7
    mov64 r3, 104                                   r3 = 104 as i32 as i64 as u64
    call function_48190                     
    ldxdw r1, [r10-0x6b0]                   
    stxw [r10-0x520], r1                    
    ldxdw r1, [r10-0x6a0]                   
    stxb [r10-0x53c], r1                    
    stxw [r10-0x5a8], r6                    
    ldxdw r1, [r8+0x10]                     
    add64 r1, -1                                    r1 += -1   ///  r1 = r1.wrapping_add(-1 as i32 as i64 as u64)
    stxdw [r8+0x10], r1                     
    ldxdw r5, [r10-0x6a8]                   
    ldxdw r1, [r5+0x0]                      
    ldxdw r2, [r1+0x0]                      
    ldxdw r3, [r10-0x638]                   
    jeq r3, r2, lbb_18829                           if r3 == r2 { pc += 2 }
lbb_18827:
    mov64 r2, 1                                     r2 = 1 as i32 as i64 as u64
    ja lbb_18839                                    if true { pc += 10 }
lbb_18829:
    ldxdw r2, [r1+0x8]                      
    ldxdw r3, [r10-0x630]                   
    jne r3, r2, lbb_18827                           if r3 != r2 { pc += -5 }
    ldxdw r2, [r1+0x10]                     
    ldxdw r3, [r10-0x628]                   
    jne r3, r2, lbb_18827                           if r3 != r2 { pc += -8 }
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
    ldxdw r3, [r1+0x18]                     
    ldxdw r4, [r10-0x620]                   
    jne r4, r3, lbb_18827                           if r4 != r3 { pc += -12 }
lbb_18839:
    ldxdw r7, [r10-0x6b8]                   
    jeq r2, 0, lbb_18883                            if r2 == (0 as i32 as i64 as u64) { pc += 42 }
    mov64 r1, r10                                   r1 = r10
    add64 r1, -1592                                 r1 += -1592   ///  r1 = r1.wrapping_add(-1592 as i32 as i64 as u64)
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
    stxdw [r10-0xf0], r2                    
    lddw r2, 0x1000655d8 --> b"\x00\x00\x00\x00\xde\x0d\x06\x00\x12\x00\x00\x00\x00\x00\x00\x00\x00\x00\…        r2 load str located at 4295382488
    stxdw [r10-0x110], r2                   
    mov64 r2, r10                                   r2 = r10
    add64 r2, -376                                  r2 += -376   ///  r2 = r2.wrapping_add(-376 as i32 as i64 as u64)
    stxdw [r10-0x100], r2                   
    lddw r2, 0x1000008a0 --> b"y\x11\x00\x00\x00\x00\x00\x00\x85\x10\x00\x00*\x99\x00\x00\x95\x00\x00\x0…        r2 load str located at 4294969504
    stxdw [r10-0x160], r2                   
    stxdw [r10-0x168], r5                   
    lddw r2, 0x10004d200 --> b"\xbf&\x00\x00\x00\x00\x00\x00y\x12\x00\x00\x00\x00\x00\x00y\x13\x08\x00\x…        r2 load str located at 4295283200
    stxdw [r10-0x170], r2                   
    stxdw [r10-0x178], r1                   
    mov64 r6, 2                                     r6 = 2 as i32 as i64 as u64
    stxdw [r10-0x108], r6                   
    stxdw [r10-0xf8], r6                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -1032                                 r1 += -1032   ///  r1 = r1.wrapping_add(-1032 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -272                                  r2 += -272   ///  r2 = r2.wrapping_add(-272 as i32 as i64 as u64)
    call function_43415                     
    ldxdw r1, [r10-0x408]                   
    stxdw [r10-0x420], r1                   
    ldxdw r1, [r10-0x400]                   
    stxdw [r10-0x418], r1                   
    ldxdw r1, [r10-0x3f8]                   
    stxdw [r10-0x410], r1                   
    mov64 r1, 29                                    r1 = 29 as i32 as i64 as u64
    stxb [r7+0x8], r1                       
    ldxdw r1, [r10-0x427]                   
    stxdw [r7+0x9], r1                      
    ldxdw r1, [r10-0x41f]                   
    stxdw [r7+0x11], r1                     
    ldxdw r1, [r10-0x417]                   
    stxdw [r7+0x19], r1                     
    ldxdw r1, [r10-0x410]                   
    ja lbb_18576                                    if true { pc += -307 }
lbb_18883:
    ldxdw r2, [r1+0x0]                      
    ldxdw r3, [r10-0x588]                   
    jeq r3, r2, lbb_18888                           if r3 == r2 { pc += 2 }
lbb_18886:
    mov64 r2, 1                                     r2 = 1 as i32 as i64 as u64
    ja lbb_18898                                    if true { pc += 10 }
lbb_18888:
    ldxdw r2, [r1+0x8]                      
    ldxdw r3, [r10-0x580]                   
    jne r3, r2, lbb_18886                           if r3 != r2 { pc += -5 }
    ldxdw r2, [r1+0x10]                     
    ldxdw r3, [r10-0x578]                   
    jne r3, r2, lbb_18886                           if r3 != r2 { pc += -8 }
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
    ldxdw r1, [r1+0x18]                     
    ldxdw r3, [r10-0x570]                   
    jne r3, r1, lbb_18886                           if r3 != r1 { pc += -12 }
lbb_18898:
    jeq r2, 0, lbb_18941                            if r2 == (0 as i32 as i64 as u64) { pc += 42 }
    mov64 r1, r10                                   r1 = r10
    add64 r1, -1416                                 r1 += -1416   ///  r1 = r1.wrapping_add(-1416 as i32 as i64 as u64)
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
    stxdw [r10-0xf0], r2                    
    lddw r2, 0x1000655f8 --> b"\x00\x00\x00\x00\x0e\x0e\x06\x00\x13\x00\x00\x00\x00\x00\x00\x00\x00\x00\…        r2 load str located at 4295382520
    stxdw [r10-0x110], r2                   
    mov64 r2, r10                                   r2 = r10
    add64 r2, -376                                  r2 += -376   ///  r2 = r2.wrapping_add(-376 as i32 as i64 as u64)
    stxdw [r10-0x100], r2                   
    lddw r2, 0x1000008a0 --> b"y\x11\x00\x00\x00\x00\x00\x00\x85\x10\x00\x00*\x99\x00\x00\x95\x00\x00\x0…        r2 load str located at 4294969504
    stxdw [r10-0x160], r2                   
    stxdw [r10-0x168], r5                   
    lddw r2, 0x10004d200 --> b"\xbf&\x00\x00\x00\x00\x00\x00y\x12\x00\x00\x00\x00\x00\x00y\x13\x08\x00\x…        r2 load str located at 4295283200
    stxdw [r10-0x170], r2                   
    stxdw [r10-0x178], r1                   
    mov64 r6, 2                                     r6 = 2 as i32 as i64 as u64
    stxdw [r10-0x108], r6                   
    stxdw [r10-0xf8], r6                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -976                                  r1 += -976   ///  r1 = r1.wrapping_add(-976 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -272                                  r2 += -272   ///  r2 = r2.wrapping_add(-272 as i32 as i64 as u64)
    call function_43415                     
    ldxdw r1, [r10-0x3d0]                   
    stxdw [r10-0x3e8], r1                   
    ldxdw r1, [r10-0x3c8]                   
    stxdw [r10-0x3e0], r1                   
    ldxdw r1, [r10-0x3c0]                   
    stxdw [r10-0x3d8], r1                   
    mov64 r1, 29                                    r1 = 29 as i32 as i64 as u64
    stxb [r7+0x8], r1                       
    ldxdw r1, [r10-0x3ef]                   
    stxdw [r7+0x9], r1                      
    ldxdw r1, [r10-0x3e7]                   
    stxdw [r7+0x11], r1                     
    ldxdw r1, [r10-0x3df]                   
    stxdw [r7+0x19], r1                     
    ldxdw r1, [r10-0x3d8]                   
    ja lbb_18576                                    if true { pc += -365 }
lbb_18941:
    mov64 r4, r5                                    r4 = r5
    add64 r4, 96                                    r4 += 96   ///  r4 = r4.wrapping_add(96 as i32 as i64 as u64)
    add64 r5, 240                                   r5 += 240   ///  r5 = r5.wrapping_add(240 as i32 as i64 as u64)
    ldxdw r7, [r5+0x0]                      
    ldxdw r1, [r7+0x0]                      
    ldxdw r9, [r4+0x0]                      
    ldxdw r2, [r9+0x0]                      
    jeq r2, r1, lbb_18951                           if r2 == r1 { pc += 2 }
lbb_18949:
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    ja lbb_18961                                    if true { pc += 10 }
lbb_18951:
    ldxdw r1, [r7+0x8]                      
    ldxdw r2, [r9+0x8]                      
    jne r2, r1, lbb_18949                           if r2 != r1 { pc += -5 }
    ldxdw r1, [r7+0x10]                     
    ldxdw r2, [r9+0x10]                     
    jne r2, r1, lbb_18949                           if r2 != r1 { pc += -8 }
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    ldxdw r2, [r7+0x18]                     
    ldxdw r3, [r9+0x18]                     
    jne r3, r2, lbb_18949                           if r3 != r2 { pc += -12 }
lbb_18961:
    mov64 r2, 51                                    r2 = 51 as i32 as i64 as u64
    stxdw [r10-0x488], r2                   
    lddw r2, 0x100060e21 --> b"User passed identical base and quote token account"        r2 load str located at 4295364129
    stxdw [r10-0x490], r2                   
    jne r1, 0, lbb_19019                            if r1 != (0 as i32 as i64 as u64) { pc += 52 }
    lddw r1, 0x100065618 --> b"\x00\x00\x00\x00P\xff\x05\x00 \x00\x00\x00\x00\x00\x00\x000\x00\x00\x00\x…        r1 load str located at 4295382552
    stxdw [r10-0x4f8], r1                   
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    stxdw [r10-0xf0], r1                    
    lddw r1, 0x100064c98 --> b"\x00\x00\x00\x00p\xfa\x05\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00…        r1 load str located at 4295380120
    stxdw [r10-0x110], r1                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -376                                  r1 += -376   ///  r1 = r1.wrapping_add(-376 as i32 as i64 as u64)
    stxdw [r10-0x100], r1                   
    lddw r1, 0x100000888 --> b"y\x11\x00\x00\x00\x00\x00\x00\x85\x10\x00\x00]\xab\x00\x00\x95\x00\x00\x0…        r1 load str located at 4294969480
    stxdw [r10-0x160], r1                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -1272                                 r1 += -1272   ///  r1 = r1.wrapping_add(-1272 as i32 as i64 as u64)
    stxdw [r10-0x168], r1                   
    lddw r1, 0x100000860 --> b"\xbf#\x00\x00\x00\x00\x00\x00y\x12\x08\x00\x00\x00\x00\x00y\x11\x00\x00\x…        r1 load str located at 4294969440
    stxdw [r10-0x170], r1                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -1168                                 r1 += -1168   ///  r1 = r1.wrapping_add(-1168 as i32 as i64 as u64)
    stxdw [r10-0x178], r1                   
    mov64 r6, 2                                     r6 = 2 as i32 as i64 as u64
    stxdw [r10-0x108], r6                   
    stxdw [r10-0xf8], r6                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -480                                  r1 += -480   ///  r1 = r1.wrapping_add(-480 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -272                                  r2 += -272   ///  r2 = r2.wrapping_add(-272 as i32 as i64 as u64)
    call function_43415                     
    ldxdw r1, [r10-0x1e0]                   
    ldxdw r2, [r10-0x1d0]                   
    syscall [invalid]                       
    ldxdw r1, [r9+0x18]                     
    stxdw [r10-0x348], r1                   
    ldxdw r1, [r9+0x10]                     
    stxdw [r10-0x350], r1                   
    ldxdw r1, [r9+0x8]                      
    stxdw [r10-0x358], r1                   
    ldxdw r1, [r9+0x0]                      
    stxdw [r10-0x360], r1                   
    mov64 r1, 6                                     r1 = 6 as i32 as i64 as u64
    ldxdw r7, [r10-0x6b8]                   
    stxb [r7+0x8], r1                       
    mov64 r1, r7                                    r1 = r7
    add64 r1, 9                                     r1 += 9   ///  r1 = r1.wrapping_add(9 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -864                                  r2 += -864   ///  r2 = r2.wrapping_add(-864 as i32 as i64 as u64)
    mov64 r3, 71                                    r3 = 71 as i32 as i64 as u64
    call function_48190                     
    ja lbb_18577                                    if true { pc += -442 }
lbb_19019:
    ldxdw r1, [r10-0x5a8]                   
    ldxdw r2, [r10-0x658]                   
    jeq r2, r1, lbb_19024                           if r2 == r1 { pc += 2 }
lbb_19022:
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    ja lbb_19034                                    if true { pc += 10 }
lbb_19024:
    ldxdw r1, [r10-0x5a0]                   
    ldxdw r2, [r10-0x650]                   
    jne r2, r1, lbb_19022                           if r2 != r1 { pc += -5 }
    ldxdw r1, [r10-0x598]                   
    ldxdw r2, [r10-0x648]                   
    jne r2, r1, lbb_19022                           if r2 != r1 { pc += -8 }
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    ldxdw r2, [r10-0x590]                   
    ldxdw r3, [r10-0x640]                   
    jne r3, r2, lbb_19022                           if r3 != r2 { pc += -12 }
lbb_19034:
    mov64 r2, 48                                    r2 = 48 as i32 as i64 as u64
    stxdw [r10-0x488], r2                   
    lddw r2, 0x100060e54 --> b"User passed two token accounts for the same mint i"        r2 load str located at 4295364180
    stxdw [r10-0x490], r2                   
    jne r1, 0, lbb_19087                            if r1 != (0 as i32 as i64 as u64) { pc += 47 }
    lddw r1, 0x100065630 --> b"\x00\x00\x00\x00P\xff\x05\x00 \x00\x00\x00\x00\x00\x00\x008\x00\x00\x00\x…        r1 load str located at 4295382576
    stxdw [r10-0x4f8], r1                   
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    stxdw [r10-0xf0], r1                    
    lddw r1, 0x100064c98 --> b"\x00\x00\x00\x00p\xfa\x05\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00…        r1 load str located at 4295380120
    stxdw [r10-0x110], r1                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -376                                  r1 += -376   ///  r1 = r1.wrapping_add(-376 as i32 as i64 as u64)
    stxdw [r10-0x100], r1                   
    lddw r1, 0x100000888 --> b"y\x11\x00\x00\x00\x00\x00\x00\x85\x10\x00\x00]\xab\x00\x00\x95\x00\x00\x0…        r1 load str located at 4294969480
    stxdw [r10-0x160], r1                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -1272                                 r1 += -1272   ///  r1 = r1.wrapping_add(-1272 as i32 as i64 as u64)
    stxdw [r10-0x168], r1                   
    lddw r1, 0x100000860 --> b"\xbf#\x00\x00\x00\x00\x00\x00y\x12\x08\x00\x00\x00\x00\x00y\x11\x00\x00\x…        r1 load str located at 4294969440
    stxdw [r10-0x170], r1                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -1168                                 r1 += -1168   ///  r1 = r1.wrapping_add(-1168 as i32 as i64 as u64)
    stxdw [r10-0x178], r1                   
    mov64 r6, 2                                     r6 = 2 as i32 as i64 as u64
    stxdw [r10-0x108], r6                   
    stxdw [r10-0xf8], r6                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -480                                  r1 += -480   ///  r1 = r1.wrapping_add(-480 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -272                                  r2 += -272   ///  r2 = r2.wrapping_add(-272 as i32 as i64 as u64)
    call function_43415                     
    ldxdw r1, [r10-0x1e0]                   
    ldxdw r2, [r10-0x1d0]                   
    syscall [invalid]                       
    ldxdw r1, [r10-0x640]                   
    ldxdw r2, [r10-0x6b8]                   
    stxdw [r2+0x21], r1                     
    ldxdw r1, [r10-0x648]                   
    stxdw [r2+0x19], r1                     
    ldxdw r1, [r10-0x650]                   
    stxdw [r2+0x11], r1                     
    ldxdw r1, [r10-0x658]                   
    stxdw [r2+0x9], r1                      
    stxw [r2+0x0], r6                       
    mov64 r1, 6                                     r1 = 6 as i32 as i64 as u64
    stxb [r2+0x8], r1                       
    ja lbb_18628                                    if true { pc += -459 }
lbb_19087:
    ldxdw r1, [r10-0x6a8]                   
    ldxdw r8, [r1+0x90]                     
    ldxdw r1, [r8+0x0]                      
    ldxdw r2, [r10-0x658]                   
    jeq r2, r1, lbb_19094                           if r2 == r1 { pc += 2 }
lbb_19092:
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    ja lbb_19104                                    if true { pc += 10 }
lbb_19094:
    ldxdw r1, [r8+0x8]                      
    ldxdw r2, [r10-0x650]                   
    jne r2, r1, lbb_19092                           if r2 != r1 { pc += -5 }
    ldxdw r1, [r8+0x10]                     
    ldxdw r2, [r10-0x648]                   
    jne r2, r1, lbb_19092                           if r2 != r1 { pc += -8 }
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    ldxdw r2, [r8+0x18]                     
    ldxdw r3, [r10-0x640]                   
    jne r3, r2, lbb_19092                           if r3 != r2 { pc += -12 }
lbb_19104:
    mov64 r2, 24                                    r2 = 24 as i32 as i64 as u64
    stxdw [r10-0x488], r2                   
    lddw r2, 0x1000606ca --> b"Base token mint mismatchQuote token mint mismatchS"        r2 load str located at 4295362250
    stxdw [r10-0x490], r2                   
    jeq r1, 0, lbb_19238                            if r1 == (0 as i32 as i64 as u64) { pc += 128 }
    lddw r1, 0x100065648 --> b"\x00\x00\x00\x00P\xff\x05\x00 \x00\x00\x00\x00\x00\x00\x00@\x00\x00\x00\x…        r1 load str located at 4295382600
    stxdw [r10-0x4f8], r1                   
    lddw r1, 0x100064c98 --> b"\x00\x00\x00\x00p\xfa\x05\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00…        r1 load str located at 4295380120
    stxdw [r10-0x110], r1                   
    mov64 r1, 2                                     r1 = 2 as i32 as i64 as u64
    stxdw [r10-0x108], r1                   
    stxdw [r10-0xf8], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -376                                  r1 += -376   ///  r1 = r1.wrapping_add(-376 as i32 as i64 as u64)
    stxdw [r10-0x100], r1                   
    lddw r1, 0x100000888 --> b"y\x11\x00\x00\x00\x00\x00\x00\x85\x10\x00\x00]\xab\x00\x00\x95\x00\x00\x0…        r1 load str located at 4294969480
    stxdw [r10-0x160], r1                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -1272                                 r1 += -1272   ///  r1 = r1.wrapping_add(-1272 as i32 as i64 as u64)
    stxdw [r10-0x168], r1                   
    lddw r1, 0x100000860 --> b"\xbf#\x00\x00\x00\x00\x00\x00y\x12\x08\x00\x00\x00\x00\x00y\x11\x00\x00\x…        r1 load str located at 4294969440
    stxdw [r10-0x170], r1                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -1168                                 r1 += -1168   ///  r1 = r1.wrapping_add(-1168 as i32 as i64 as u64)
    stxdw [r10-0x178], r1                   
    mov64 r6, 0                                     r6 = 0 as i32 as i64 as u64
    stxdw [r10-0xf0], r6                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -480                                  r1 += -480   ///  r1 = r1.wrapping_add(-480 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -272                                  r2 += -272   ///  r2 = r2.wrapping_add(-272 as i32 as i64 as u64)
    call function_43415                     
    ldxdw r1, [r10-0x1e0]                   
    ldxdw r2, [r10-0x1d0]                   
    syscall [invalid]                       
    ldxdw r1, [r9+0x18]                     
    stxdw [r10-0xf8], r1                    
    ldxdw r1, [r9+0x10]                     
    stxdw [r10-0x100], r1                   
    ldxdw r1, [r9+0x8]                      
    stxdw [r10-0x108], r1                   
    ldxdw r1, [r9+0x0]                      
    stxdw [r10-0x110], r1                   
    lddw r1, 0x300000000                            r1 load str located at 12884901888
    ldxdw r2, [r1+0x0]                      
    mov64 r3, 1                                     r3 = 1 as i32 as i64 as u64
    mov64 r1, r2                                    r1 = r2
    add64 r1, -32                                   r1 += -32   ///  r1 = r1.wrapping_add(-32 as i32 as i64 as u64)
    jgt r1, r2, lbb_19160                           if r1 > r2 { pc += 1 }
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
lbb_19160:
    ldxdw r7, [r10-0x6b8]                   
    jne r3, 0, lbb_19163                            if r3 != (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r6, r1                                    r6 = r1
lbb_19163:
    lddw r1, 0x300007fe0                            r1 load str located at 12884934624
    jeq r2, 0, lbb_19167                            if r2 == (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r1, r6                                    r1 = r6
lbb_19167:
    lddw r2, 0x300000007                            r2 load str located at 12884901895
    jgt r1, r2, lbb_19174                           if r1 > r2 { pc += 4 }
lbb_19170:
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    mov64 r2, 32                                    r2 = 32 as i32 as i64 as u64
    call function_43400                     
    syscall [invalid]                       
lbb_19174:
    lddw r2, 0x300000000                            r2 load str located at 12884901888
    stxdw [r2+0x0], r1                      
    ldxdw r3, [r10-0xf8]                    
    stxdw [r1+0x18], r3                     
    ldxdw r3, [r10-0x100]                   
    stxdw [r1+0x10], r3                     
    ldxdw r3, [r10-0x108]                   
    stxdw [r1+0x8], r3                      
    ldxdw r3, [r10-0x110]                   
    stxdw [r1+0x0], r3                      
    ldxdw r3, [r2+0x0]                      
    mov64 r2, r3                                    r2 = r3
    add64 r2, -32                                   r2 += -32   ///  r2 = r2.wrapping_add(-32 as i32 as i64 as u64)
    mov64 r4, 0                                     r4 = 0 as i32 as i64 as u64
    mov64 r5, 1                                     r5 = 1 as i32 as i64 as u64
    jgt r2, r3, lbb_19192                           if r2 > r3 { pc += 1 }
    mov64 r5, 0                                     r5 = 0 as i32 as i64 as u64
lbb_19192:
    jne r5, 0, lbb_19194                            if r5 != (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r4, r2                                    r4 = r2
lbb_19194:
    lddw r2, 0x300007fe0                            r2 load str located at 12884934624
    jeq r3, 0, lbb_19198                            if r3 == (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r2, r4                                    r2 = r4
lbb_19198:
    lddw r3, 0x300000007                            r3 load str located at 12884901895
    jgt r2, r3, lbb_19202                           if r2 > r3 { pc += 1 }
    ja lbb_19170                                    if true { pc += -32 }
lbb_19202:
    lddw r3, 0x300000000                            r3 load str located at 12884901888
    stxdw [r3+0x0], r2                      
    ldxdw r4, [r10-0x658]                   
    ldxdw r5, [r10-0x650]                   
    ldxdw r0, [r10-0x648]                   
    ldxdw r6, [r10-0x640]                   
    stxdw [r2+0x18], r6                     
    stxdw [r2+0x10], r0                     
    stxdw [r2+0x8], r5                      
    stxdw [r2+0x0], r4                      
    ldxdw r4, [r8+0x18]                     
    stxdw [r10-0xf8], r4                    
    ldxdw r4, [r8+0x10]                     
    stxdw [r10-0x100], r4                   
    ldxdw r4, [r8+0x8]                      
    stxdw [r10-0x108], r4                   
    ldxdw r4, [r8+0x0]                      
    stxdw [r10-0x110], r4                   
    ldxdw r4, [r3+0x0]                      
    mov64 r5, 0                                     r5 = 0 as i32 as i64 as u64
    mov64 r0, 1                                     r0 = 1 as i32 as i64 as u64
    mov64 r3, r4                                    r3 = r4
    add64 r3, -32                                   r3 += -32   ///  r3 = r3.wrapping_add(-32 as i32 as i64 as u64)
    jgt r3, r4, lbb_19228                           if r3 > r4 { pc += 1 }
    mov64 r0, 0                                     r0 = 0 as i32 as i64 as u64
lbb_19228:
    jne r0, 0, lbb_19230                            if r0 != (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r5, r3                                    r5 = r3
lbb_19230:
    lddw r3, 0x300007fe0                            r3 load str located at 12884934624
    jeq r4, 0, lbb_19234                            if r4 == (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r3, r5                                    r3 = r5
lbb_19234:
    lddw r4, 0x300000007                            r4 load str located at 12884901895
    jgt r3, r4, lbb_19386                           if r3 > r4 { pc += 149 }
    ja lbb_19170                                    if true { pc += -68 }
lbb_19238:
    ldxdw r1, [r10-0x6a8]                   
    ldxdw r9, [r1+0x120]                    
    ldxdw r1, [r9+0x0]                      
    ldxdw r2, [r10-0x5a8]                   
    jeq r2, r1, lbb_19245                           if r2 == r1 { pc += 2 }
lbb_19243:
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    ja lbb_19255                                    if true { pc += 10 }
lbb_19245:
    ldxdw r1, [r9+0x8]                      
    ldxdw r2, [r10-0x5a0]                   
    jne r2, r1, lbb_19243                           if r2 != r1 { pc += -5 }
    ldxdw r1, [r9+0x10]                     
    ldxdw r2, [r10-0x598]                   
    jne r2, r1, lbb_19243                           if r2 != r1 { pc += -8 }
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    ldxdw r2, [r9+0x18]                     
    ldxdw r3, [r10-0x590]                   
    jne r3, r2, lbb_19243                           if r3 != r2 { pc += -12 }
lbb_19255:
    mov64 r2, 25                                    r2 = 25 as i32 as i64 as u64
    stxdw [r10-0x488], r2                   
    lddw r2, 0x1000606e2 --> b"Quote token mint mismatchSigner account is not a s"        r2 load str located at 4295362274
    stxdw [r10-0x490], r2                   
    jeq r1, 0, lbb_19405                            if r1 == (0 as i32 as i64 as u64) { pc += 144 }
    lddw r1, 0x100065660 --> b"\x00\x00\x00\x00P\xff\x05\x00 \x00\x00\x00\x00\x00\x00\x00J\x00\x00\x00\x…        r1 load str located at 4295382624
    stxdw [r10-0x4f8], r1                   
    lddw r1, 0x100064c98 --> b"\x00\x00\x00\x00p\xfa\x05\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00…        r1 load str located at 4295380120
    stxdw [r10-0x110], r1                   
    mov64 r1, 2                                     r1 = 2 as i32 as i64 as u64
    stxdw [r10-0x108], r1                   
    stxdw [r10-0xf8], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -376                                  r1 += -376   ///  r1 = r1.wrapping_add(-376 as i32 as i64 as u64)
    stxdw [r10-0x100], r1                   
    lddw r1, 0x100000888 --> b"y\x11\x00\x00\x00\x00\x00\x00\x85\x10\x00\x00]\xab\x00\x00\x95\x00\x00\x0…        r1 load str located at 4294969480
    stxdw [r10-0x160], r1                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -1272                                 r1 += -1272   ///  r1 = r1.wrapping_add(-1272 as i32 as i64 as u64)
    stxdw [r10-0x168], r1                   
    lddw r1, 0x100000860 --> b"\xbf#\x00\x00\x00\x00\x00\x00y\x12\x08\x00\x00\x00\x00\x00y\x11\x00\x00\x…        r1 load str located at 4294969440
    stxdw [r10-0x170], r1                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -1168                                 r1 += -1168   ///  r1 = r1.wrapping_add(-1168 as i32 as i64 as u64)
    stxdw [r10-0x178], r1                   
    mov64 r6, 0                                     r6 = 0 as i32 as i64 as u64
    stxdw [r10-0xf0], r6                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -480                                  r1 += -480   ///  r1 = r1.wrapping_add(-480 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -272                                  r2 += -272   ///  r2 = r2.wrapping_add(-272 as i32 as i64 as u64)
    call function_43415                     
    ldxdw r1, [r10-0x1e0]                   
    ldxdw r2, [r10-0x1d0]                   
    syscall [invalid]                       
    ldxdw r1, [r7+0x18]                     
    stxdw [r10-0xf8], r1                    
    ldxdw r1, [r7+0x10]                     
    stxdw [r10-0x100], r1                   
    ldxdw r1, [r7+0x8]                      
    stxdw [r10-0x108], r1                   
    ldxdw r1, [r7+0x0]                      
    stxdw [r10-0x110], r1                   
    lddw r1, 0x300000000                            r1 load str located at 12884901888
    ldxdw r2, [r1+0x0]                      
    mov64 r3, 1                                     r3 = 1 as i32 as i64 as u64
    mov64 r1, r2                                    r1 = r2
    add64 r1, -32                                   r1 += -32   ///  r1 = r1.wrapping_add(-32 as i32 as i64 as u64)
    jgt r1, r2, lbb_19311                           if r1 > r2 { pc += 1 }
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
lbb_19311:
    ldxdw r7, [r10-0x6b8]                   
    jne r3, 0, lbb_19314                            if r3 != (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r6, r1                                    r6 = r1
lbb_19314:
    lddw r1, 0x300007fe0                            r1 load str located at 12884934624
    jeq r2, 0, lbb_19318                            if r2 == (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r1, r6                                    r1 = r6
lbb_19318:
    lddw r2, 0x300000007                            r2 load str located at 12884901895
    jgt r1, r2, lbb_19322                           if r1 > r2 { pc += 1 }
    ja lbb_19170                                    if true { pc += -152 }
lbb_19322:
    lddw r2, 0x300000000                            r2 load str located at 12884901888
    stxdw [r2+0x0], r1                      
    ldxdw r3, [r10-0xf8]                    
    stxdw [r1+0x18], r3                     
    ldxdw r3, [r10-0x100]                   
    stxdw [r1+0x10], r3                     
    ldxdw r3, [r10-0x108]                   
    stxdw [r1+0x8], r3                      
    ldxdw r3, [r10-0x110]                   
    stxdw [r1+0x0], r3                      
    ldxdw r3, [r2+0x0]                      
    mov64 r2, r3                                    r2 = r3
    add64 r2, -32                                   r2 += -32   ///  r2 = r2.wrapping_add(-32 as i32 as i64 as u64)
    mov64 r4, 0                                     r4 = 0 as i32 as i64 as u64
    mov64 r5, 1                                     r5 = 1 as i32 as i64 as u64
    jgt r2, r3, lbb_19340                           if r2 > r3 { pc += 1 }
    mov64 r5, 0                                     r5 = 0 as i32 as i64 as u64
lbb_19340:
    jne r5, 0, lbb_19342                            if r5 != (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r4, r2                                    r4 = r2
lbb_19342:
    lddw r2, 0x300007fe0                            r2 load str located at 12884934624
    jeq r3, 0, lbb_19346                            if r3 == (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r2, r4                                    r2 = r4
lbb_19346:
    lddw r3, 0x300000007                            r3 load str located at 12884901895
    jgt r2, r3, lbb_19350                           if r2 > r3 { pc += 1 }
    ja lbb_19170                                    if true { pc += -180 }
lbb_19350:
    lddw r3, 0x300000000                            r3 load str located at 12884901888
    stxdw [r3+0x0], r2                      
    ldxdw r4, [r10-0x5a8]                   
    ldxdw r5, [r10-0x5a0]                   
    ldxdw r0, [r10-0x598]                   
    ldxdw r6, [r10-0x590]                   
    stxdw [r2+0x18], r6                     
    stxdw [r2+0x10], r0                     
    stxdw [r2+0x8], r5                      
    stxdw [r2+0x0], r4                      
    ldxdw r4, [r9+0x18]                     
    stxdw [r10-0xf8], r4                    
    ldxdw r4, [r9+0x10]                     
    stxdw [r10-0x100], r4                   
    ldxdw r4, [r9+0x8]                      
    stxdw [r10-0x108], r4                   
    ldxdw r4, [r9+0x0]                      
    stxdw [r10-0x110], r4                   
    ldxdw r4, [r3+0x0]                      
    mov64 r5, 0                                     r5 = 0 as i32 as i64 as u64
    mov64 r0, 1                                     r0 = 1 as i32 as i64 as u64
    mov64 r3, r4                                    r3 = r4
    add64 r3, -32                                   r3 += -32   ///  r3 = r3.wrapping_add(-32 as i32 as i64 as u64)
    jgt r3, r4, lbb_19376                           if r3 > r4 { pc += 1 }
    mov64 r0, 0                                     r0 = 0 as i32 as i64 as u64
lbb_19376:
    jne r0, 0, lbb_19378                            if r0 != (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r5, r3                                    r5 = r3
lbb_19378:
    lddw r3, 0x300007fe0                            r3 load str located at 12884934624
    jeq r4, 0, lbb_19382                            if r4 == (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r3, r5                                    r3 = r5
lbb_19382:
    lddw r4, 0x300000007                            r4 load str located at 12884901895
    jgt r3, r4, lbb_19386                           if r3 > r4 { pc += 1 }
    ja lbb_19170                                    if true { pc += -216 }
lbb_19386:
    lddw r4, 0x300000000                            r4 load str located at 12884901888
    stxdw [r4+0x0], r3                      
    ldxdw r4, [r10-0xf8]                    
    stxdw [r3+0x18], r4                     
    ldxdw r4, [r10-0x100]                   
    stxdw [r3+0x10], r4                     
    ldxdw r4, [r10-0x108]                   
    stxdw [r3+0x8], r4                      
    ldxdw r4, [r10-0x110]                   
    stxdw [r3+0x0], r4                      
    stxdw [r7+0x20], r3                     
    stxdw [r7+0x18], r2                     
    stxdw [r7+0x10], r1                     
    mov64 r1, 7                                     r1 = 7 as i32 as i64 as u64
    stxb [r7+0x8], r1                       
    mov64 r1, 2                                     r1 = 2 as i32 as i64 as u64
    stxw [r7+0x0], r1                       
    ja lbb_18628                                    if true { pc += -777 }
lbb_19405:
    stxdw [r10-0x6b0], r5                   
    stxdw [r10-0x6a0], r4                   
    ldxdw r1, [r10-0x6a8]                   
    ldxdw r6, [r1+0xa0]                     
    ldxdw r1, [r6+0x10]                     
    lddw r2, 0x7fffffffffffffff                     r2 load str located at 9223372036854775807
    jgt r2, r1, lbb_19414                           if r2 > r1 { pc += 1 }
    ja lbb_19577                                    if true { pc += 163 }
lbb_19414:
    add64 r1, 1                                     r1 += 1   ///  r1 = r1.wrapping_add(1 as i32 as i64 as u64)
    stxdw [r6+0x10], r1                     
    ldxdw r2, [r6+0x18]                     
    ldxdw r3, [r6+0x20]                     
    mov64 r1, r10                                   r1 = r10
    add64 r1, -272                                  r1 += -272   ///  r1 = r1.wrapping_add(-272 as i32 as i64 as u64)
    call function_0                         
    ldxw r7, [r10-0x110]                    
    jeq r7, 2, lbb_19424                            if r7 == (2 as i32 as i64 as u64) { pc += 1 }
    ja lbb_19433                                    if true { pc += 9 }
lbb_19424:
    ldxdw r1, [r10-0xf0]                    
    stxdw [r10-0x15c], r1                   
    ldxdw r2, [r10-0xf8]                    
    stxdw [r10-0x164], r2                   
    ldxdw r3, [r10-0x100]                   
    stxdw [r10-0x16c], r3                   
    ldxdw r4, [r10-0x108]                   
    stxdw [r10-0x174], r4                   
    ja lbb_19479                                    if true { pc += 46 }
lbb_19433:
    mov64 r8, r10                                   r8 = r10
    add64 r8, -376                                  r8 += -376   ///  r8 = r8.wrapping_add(-376 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -268                                  r2 += -268   ///  r2 = r2.wrapping_add(-268 as i32 as i64 as u64)
    mov64 r1, r8                                    r1 = r8
    mov64 r3, 36                                    r3 = 36 as i32 as i64 as u64
    call function_48190                     
    mov64 r1, r10                                   r1 = r10
    add64 r1, -952                                  r1 += -952   ///  r1 = r1.wrapping_add(-952 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -232                                  r2 += -232   ///  r2 = r2.wrapping_add(-232 as i32 as i64 as u64)
    mov64 r3, 48                                    r3 = 48 as i32 as i64 as u64
    call function_48190                     
    mov64 r1, r10                                   r1 = r10
    add64 r1, -900                                  r1 += -900   ///  r1 = r1.wrapping_add(-900 as i32 as i64 as u64)
    mov64 r2, r8                                    r2 = r8
    mov64 r3, 36                                    r3 = 36 as i32 as i64 as u64
    call function_48190                     
    ldxdw r1, [r6+0x10]                     
    add64 r1, -1                                    r1 += -1   ///  r1 = r1.wrapping_add(-1 as i32 as i64 as u64)
    stxdw [r6+0x10], r1                     
    ldxdw r1, [r10-0x6a8]                   
    ldxdw r6, [r1+0x130]                    
    ldxdw r1, [r6+0x10]                     
    lddw r2, 0x7fffffffffffffff                     r2 load str located at 9223372036854775807
    jgt r2, r1, lbb_19461                           if r2 > r1 { pc += 1 }
    ja lbb_19581                                    if true { pc += 120 }
lbb_19461:
    add64 r1, 1                                     r1 += 1   ///  r1 = r1.wrapping_add(1 as i32 as i64 as u64)
    stxdw [r6+0x10], r1                     
    ldxdw r2, [r6+0x18]                     
    ldxdw r3, [r6+0x20]                     
    mov64 r1, r10                                   r1 = r10
    add64 r1, -272                                  r1 += -272   ///  r1 = r1.wrapping_add(-272 as i32 as i64 as u64)
    call function_0                         
    ldxw r8, [r10-0x110]                    
    jeq r8, 2, lbb_19471                            if r8 == (2 as i32 as i64 as u64) { pc += 1 }
    ja lbb_19498                                    if true { pc += 27 }
lbb_19471:
    ldxdw r1, [r10-0xf0]                    
    stxdw [r10-0x1c4], r1                   
    ldxdw r2, [r10-0xf8]                    
    stxdw [r10-0x1cc], r2                   
    ldxdw r3, [r10-0x100]                   
    stxdw [r10-0x1d4], r3                   
    ldxdw r4, [r10-0x108]                   
    stxdw [r10-0x1dc], r4                   
lbb_19479:
    stxdw [r10-0xf1], r1                    
    stxdw [r10-0xf9], r2                    
    stxdw [r10-0x101], r3                   
    stxdw [r10-0x109], r4                   
    mov64 r1, 55                                    r1 = 55 as i32 as i64 as u64
    ldxdw r7, [r10-0x6b8]                   
    stxb [r7+0x8], r1                       
    mov64 r1, r7                                    r1 = r7
    add64 r1, 9                                     r1 += 9   ///  r1 = r1.wrapping_add(9 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -272                                  r2 += -272   ///  r2 = r2.wrapping_add(-272 as i32 as i64 as u64)
    mov64 r3, 39                                    r3 = 39 as i32 as i64 as u64
    call function_48190                     
    mov64 r1, 2                                     r1 = 2 as i32 as i64 as u64
    stxw [r7+0x0], r1                       
    ldxdw r1, [r6+0x10]                     
    add64 r1, -1                                    r1 += -1   ///  r1 = r1.wrapping_add(-1 as i32 as i64 as u64)
    stxdw [r6+0x10], r1                     
    ja lbb_18628                                    if true { pc += -870 }
lbb_19498:
    mov64 r9, r10                                   r9 = r10
    add64 r9, -480                                  r9 += -480   ///  r9 = r9.wrapping_add(-480 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -268                                  r2 += -268   ///  r2 = r2.wrapping_add(-268 as i32 as i64 as u64)
    mov64 r1, r9                                    r1 = r9
    mov64 r3, 36                                    r3 = 36 as i32 as i64 as u64
    call function_48190                     
    mov64 r1, r10                                   r1 = r10
    add64 r1, -376                                  r1 += -376   ///  r1 = r1.wrapping_add(-376 as i32 as i64 as u64)
    stxdw [r10-0x6c0], r1                   
    mov64 r2, r10                                   r2 = r10
    add64 r2, -232                                  r2 += -232   ///  r2 = r2.wrapping_add(-232 as i32 as i64 as u64)
    mov64 r3, 48                                    r3 = 48 as i32 as i64 as u64
    call function_48190                     
    mov64 r1, r10                                   r1 = r10
    add64 r1, -272                                  r1 += -272   ///  r1 = r1.wrapping_add(-272 as i32 as i64 as u64)
    stxdw [r10-0x6c8], r1                   
    mov64 r2, r9                                    r2 = r9
    mov64 r3, 36                                    r3 = 36 as i32 as i64 as u64
    call function_48190                     
    ldxdw r1, [r6+0x10]                     
    add64 r1, -1                                    r1 += -1   ///  r1 = r1.wrapping_add(-1 as i32 as i64 as u64)
    stxdw [r6+0x10], r1                     
    ldxdw r6, [r10-0x6b8]                   
    mov64 r1, r6                                    r1 = r6
    add64 r1, 176                                   r1 += 176   ///  r1 = r1.wrapping_add(176 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -1624                                 r2 += -1624   ///  r2 = r2.wrapping_add(-1624 as i32 as i64 as u64)
    mov64 r3, 176                                   r3 = 176 as i32 as i64 as u64
    call function_48190                     
    mov64 r1, r6                                    r1 = r6
    add64 r1, 352                                   r1 += 352   ///  r1 = r1.wrapping_add(352 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -1448                                 r2 += -1448   ///  r2 = r2.wrapping_add(-1448 as i32 as i64 as u64)
    mov64 r3, 176                                   r3 = 176 as i32 as i64 as u64
    call function_48190                     
    mov64 r1, r6                                    r1 = r6
    add64 r1, 4                                     r1 += 4   ///  r1 = r1.wrapping_add(4 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -900                                  r2 += -900   ///  r2 = r2.wrapping_add(-900 as i32 as i64 as u64)
    mov64 r3, 36                                    r3 = 36 as i32 as i64 as u64
    call function_48190                     
    mov64 r1, r6                                    r1 = r6
    add64 r1, 40                                    r1 += 40   ///  r1 = r1.wrapping_add(40 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -952                                  r2 += -952   ///  r2 = r2.wrapping_add(-952 as i32 as i64 as u64)
    mov64 r3, 48                                    r3 = 48 as i32 as i64 as u64
    call function_48190                     
    stxw [r6+0x58], r8                      
    stxw [r6+0x0], r7                       
    mov64 r1, r6                                    r1 = r6
    add64 r1, 92                                    r1 += 92   ///  r1 = r1.wrapping_add(92 as i32 as i64 as u64)
    ldxdw r2, [r10-0x6c8]                   
    mov64 r3, 36                                    r3 = 36 as i32 as i64 as u64
    call function_48190                     
    mov64 r1, r6                                    r1 = r6
    add64 r1, 128                                   r1 += 128   ///  r1 = r1.wrapping_add(128 as i32 as i64 as u64)
    ldxdw r2, [r10-0x6c0]                   
    mov64 r3, 48                                    r3 = 48 as i32 as i64 as u64
    call function_48190                     
    ldxdw r1, [r10-0x698]                   
    add64 r1, -7                                    r1 += -7   ///  r1 = r1.wrapping_add(-7 as i32 as i64 as u64)
    stxdw [r6+0x240], r1                    
    ldxdw r2, [r10-0x6a8]                   
    mov64 r1, r2                                    r1 = r2
    add64 r1, 336                                   r1 += 336   ///  r1 = r1.wrapping_add(336 as i32 as i64 as u64)
    stxdw [r6+0x238], r1                    
    mov64 r1, r2                                    r1 = r2
    add64 r1, 192                                   r1 += 192   ///  r1 = r1.wrapping_add(192 as i32 as i64 as u64)
    stxdw [r6+0x230], r1                    
    mov64 r1, r2                                    r1 = r2
    add64 r1, 48                                    r1 += 48   ///  r1 = r1.wrapping_add(48 as i32 as i64 as u64)
    stxdw [r6+0x228], r1                    
    ldxdw r1, [r10-0x6b0]                   
    stxdw [r6+0x220], r1                    
    ldxdw r1, [r10-0x6a0]                   
    stxdw [r6+0x218], r1                    
    stxdw [r6+0x210], r2                    
    ja lbb_18628                                    if true { pc += -949 }
lbb_19577:
    lddw r1, 0x100065690 --> b"\x00\x00\x00\x00P\xff\x05\x00 \x00\x00\x00\x00\x00\x00\x00T\x00\x00\x00P\…        r1 load str located at 4295382672
    call function_43759                     
    syscall [invalid]                       
lbb_19581:
    lddw r1, 0x100065678 --> b"\x00\x00\x00\x00P\xff\x05\x00 \x00\x00\x00\x00\x00\x00\x00U\x00\x00\x00R\…        r1 load str located at 4295382648
    call function_43759                     
    syscall [invalid]                       

function_19585:
    mov64 r7, r5                                    r7 = r5
    mov64 r8, r4                                    r8 = r4
    stxdw [r10-0x808], r3                   
    mov64 r3, r2                                    r3 = r2
    mov64 r9, r1                                    r9 = r1
    mov64 r1, r10                                   r1 = r10
    add64 r1, -760                                  r1 += -760   ///  r1 = r1.wrapping_add(-760 as i32 as i64 as u64)
    lddw r2, 0x1000607bb --> b"\x8b\xbc\x13%\x8a\x81u\xd1\xc8\xf9\x18\xd1\x1du\xbb\x9d\xf3\xa2&\x0b\x8c\…        r2 load str located at 4295362491
    stxdw [r10-0x810], r3                   
    lddw r4, 0x100060ebb --> b"Invalid program ID for dex"        r4 load str located at 4295364283
    mov64 r5, 26                                    r5 = 26 as i32 as i64 as u64
    call function_30095                     
    ldxb r6, [r10-0x2f8]                    
    jeq r6, 56, lbb_19602                           if r6 == (56 as i32 as i64 as u64) { pc += 1 }
    ja lbb_19923                                    if true { pc += 321 }
lbb_19602:
    ldxdw r2, [r7-0xff8]                    
    jeq r2, 0, lbb_20616                            if r2 == (0 as i32 as i64 as u64) { pc += 1012 }
    ldxdw r3, [r7-0x1000]                   
    mov64 r6, r2                                    r6 = r2
    add64 r6, -1                                    r6 += -1   ///  r6 = r6.wrapping_add(-1 as i32 as i64 as u64)
    ldxb r5, [r3+0x0]                       
    stxdw [r10-0x770], r6                   
    mov64 r4, r3                                    r4 = r3
    add64 r4, 1                                     r4 += 1   ///  r4 = r4.wrapping_add(1 as i32 as i64 as u64)
    stxdw [r10-0x778], r4                   
    stxb [r10-0x761], r5                    
    stxdw [r10-0x800], r5                   
    jsgt r5, 6, lbb_19844                           if (r5 as i64) > (6 as i32 as i64) { pc += 229 }
    jsgt r5, 2, lbb_19863                           if (r5 as i64) > (2 as i32 as i64) { pc += 247 }
    mov64 r6, r5                                    r6 = r5
    jeq r6, 0, lbb_21070                            if r6 == (0 as i32 as i64 as u64) { pc += 1452 }
    ldxdw r1, [r10-0x800]                   
    jeq r1, 1, lbb_20170                            if r1 == (1 as i32 as i64 as u64) { pc += 550 }
    jeq r1, 2, lbb_19622                            if r1 == (2 as i32 as i64 as u64) { pc += 1 }
    ja lbb_20254                                    if true { pc += 632 }
lbb_19622:
    mov64 r1, 33                                    r1 = 33 as i32 as i64 as u64
    jgt r1, r2, lbb_20616                           if r1 > r2 { pc += 992 }
    stxdw [r10-0x848], r8                   
    stxdw [r10-0x830], r9                   
    ldxb r5, [r4+0x1c]                      
    lsh64 r5, 16                                    r5 <<= 16   ///  r5 = r5.wrapping_shl(16)
    ldxb r1, [r4+0x1d]                      
    lsh64 r1, 24                                    r1 <<= 24   ///  r1 = r1.wrapping_shl(24)
    or64 r1, r5                                     r1 |= r5   ///  r1 = r1.or(r5)
    ldxb r5, [r4+0x1b]                      
    lsh64 r5, 8                                     r5 <<= 8   ///  r5 = r5.wrapping_shl(8)
    ldxb r7, [r4+0x1a]                      
    or64 r7, r5                                     r7 |= r5   ///  r7 = r7.or(r5)
    ldxb r5, [r4+0x18]                      
    lsh64 r5, 16                                    r5 <<= 16   ///  r5 = r5.wrapping_shl(16)
    ldxb r0, [r4+0x19]                      
    lsh64 r0, 24                                    r0 <<= 24   ///  r0 = r0.wrapping_shl(24)
    or64 r0, r5                                     r0 |= r5   ///  r0 = r0.or(r5)
    ldxb r6, [r4+0x17]                      
    lsh64 r6, 8                                     r6 <<= 8   ///  r6 = r6.wrapping_shl(8)
    ldxb r5, [r4+0x16]                      
    or64 r5, r6                                     r5 |= r6   ///  r5 = r5.or(r6)
    and64 r5, 65535                                 r5 &= 65535   ///  r5 = r5.and(65535)
    or64 r5, r0                                     r5 |= r0   ///  r5 = r5.or(r0)
    and64 r7, 65535                                 r7 &= 65535   ///  r7 = r7.and(65535)
    or64 r7, r1                                     r7 |= r1   ///  r7 = r7.or(r1)
    ldxb r1, [r4+0x14]                      
    lsh64 r1, 16                                    r1 <<= 16   ///  r1 = r1.wrapping_shl(16)
    ldxb r0, [r4+0x15]                      
    lsh64 r0, 24                                    r0 <<= 24   ///  r0 = r0.wrapping_shl(24)
    or64 r0, r1                                     r0 |= r1   ///  r0 = r0.or(r1)
    stxdw [r10-0x820], r0                   
    ldxb r1, [r4+0x13]                      
    lsh64 r1, 8                                     r1 <<= 8   ///  r1 = r1.wrapping_shl(8)
    ldxb r0, [r4+0x12]                      
    or64 r0, r1                                     r0 |= r1   ///  r0 = r0.or(r1)
    stxdw [r10-0x818], r0                   
    ldxb r1, [r4+0x10]                      
    lsh64 r1, 16                                    r1 <<= 16   ///  r1 = r1.wrapping_shl(16)
    ldxb r9, [r4+0x11]                      
    lsh64 r9, 24                                    r9 <<= 24   ///  r9 = r9.wrapping_shl(24)
    or64 r9, r1                                     r9 |= r1   ///  r9 = r9.or(r1)
    ldxb r1, [r4+0xf]                       
    lsh64 r1, 8                                     r1 <<= 8   ///  r1 = r1.wrapping_shl(8)
    ldxb r6, [r4+0xe]                       
    or64 r6, r1                                     r6 |= r1   ///  r6 = r6.or(r1)
    ldxb r0, [r4+0xa]                       
    lsh64 r0, 16                                    r0 <<= 16   ///  r0 = r0.wrapping_shl(16)
    ldxb r1, [r4+0xb]                       
    lsh64 r1, 24                                    r1 <<= 24   ///  r1 = r1.wrapping_shl(24)
    or64 r1, r0                                     r1 |= r0   ///  r1 = r1.or(r0)
    ldxb r8, [r4+0x9]                       
    lsh64 r8, 8                                     r8 <<= 8   ///  r8 = r8.wrapping_shl(8)
    ldxb r0, [r4+0x8]                       
    or64 r0, r8                                     r0 |= r8   ///  r0 = r0.or(r8)
    lsh64 r7, 32                                    r7 <<= 32   ///  r7 = r7.wrapping_shl(32)
    lsh64 r5, 32                                    r5 <<= 32   ///  r5 = r5.wrapping_shl(32)
    rsh64 r5, 32                                    r5 >>= 32   ///  r5 = r5.wrapping_shr(32)
    or64 r5, r7                                     r5 |= r7   ///  r5 = r5.or(r7)
    and64 r0, 65535                                 r0 &= 65535   ///  r0 = r0.and(65535)
    or64 r0, r1                                     r0 |= r1   ///  r0 = r0.or(r1)
    and64 r6, 65535                                 r6 &= 65535   ///  r6 = r6.and(65535)
    or64 r6, r9                                     r6 |= r9   ///  r6 = r6.or(r9)
    ldxdw r1, [r10-0x818]                   
    and64 r1, 65535                                 r1 &= 65535   ///  r1 = r1.and(65535)
    ldxdw r7, [r10-0x820]                   
    or64 r1, r7                                     r1 |= r7   ///  r1 = r1.or(r7)
    stxdw [r10-0x818], r1                   
    ldxb r1, [r4+0x1f]                      
    lsh64 r1, 8                                     r1 <<= 8   ///  r1 = r1.wrapping_shl(8)
    ldxb r7, [r4+0x1e]                      
    or64 r7, r1                                     r7 |= r1   ///  r7 = r7.or(r1)
    stxdw [r10-0x850], r7                   
    ldxb r7, [r4+0xc]                       
    lsh64 r7, 32                                    r7 <<= 32   ///  r7 = r7.wrapping_shl(32)
    ldxb r1, [r4+0xd]                       
    lsh64 r1, 40                                    r1 <<= 40   ///  r1 = r1.wrapping_shl(40)
    or64 r1, r7                                     r1 |= r7   ///  r1 = r1.or(r7)
    ldxb r7, [r4+0x0]                       
    ldxb r9, [r4+0x1]                       
    stxdw [r10-0x820], r9                   
    ldxb r9, [r4+0x3]                       
    stxdw [r10-0x828], r9                   
    ldxb r9, [r4+0x2]                       
    stxdw [r10-0x838], r9                   
    ldxb r9, [r4+0x7]                       
    ldxb r8, [r4+0x6]                       
    stxdw [r10-0x840], r8                   
    ldxb r8, [r4+0x4]                       
    stxdw [r10-0x858], r8                   
    ldxb r4, [r4+0x5]                       
    ldxdw r8, [r10-0x850]                   
    stxh [r10-0x1a2], r8                    
    stxdw [r10-0x1aa], r5                   
    ldxdw r5, [r10-0x818]                   
    lsh64 r5, 32                                    r5 <<= 32   ///  r5 = r5.wrapping_shl(32)
    lsh64 r6, 32                                    r6 <<= 32   ///  r6 = r6.wrapping_shl(32)
    rsh64 r6, 32                                    r6 >>= 32   ///  r6 = r6.wrapping_shr(32)
    or64 r6, r5                                     r6 |= r5   ///  r6 = r6.or(r5)
    lsh64 r0, 32                                    r0 <<= 32   ///  r0 = r0.wrapping_shl(32)
    rsh64 r0, 32                                    r0 >>= 32   ///  r0 = r0.wrapping_shr(32)
    or64 r0, r1                                     r0 |= r1   ///  r0 = r0.or(r1)
    lsh64 r4, 8                                     r4 <<= 8   ///  r4 = r4.wrapping_shl(8)
    ldxdw r1, [r10-0x858]                   
    or64 r1, r4                                     r1 |= r4   ///  r1 = r1.or(r4)
    ldxdw r4, [r10-0x840]                   
    lsh64 r4, 48                                    r4 <<= 48   ///  r4 = r4.wrapping_shl(48)
    lsh64 r9, 56                                    r9 <<= 56   ///  r9 = r9.wrapping_shl(56)
    or64 r9, r4                                     r9 |= r4   ///  r9 = r9.or(r4)
    ldxdw r5, [r10-0x838]                   
    lsh64 r5, 16                                    r5 <<= 16   ///  r5 = r5.wrapping_shl(16)
    ldxdw r4, [r10-0x828]                   
    lsh64 r4, 24                                    r4 <<= 24   ///  r4 = r4.wrapping_shl(24)
    or64 r4, r5                                     r4 |= r5   ///  r4 = r4.or(r5)
    ldxdw r5, [r10-0x820]                   
    lsh64 r5, 8                                     r5 <<= 8   ///  r5 = r5.wrapping_shl(8)
    or64 r7, r5                                     r7 |= r5   ///  r7 = r7.or(r5)
    and64 r7, 65535                                 r7 &= 65535   ///  r7 = r7.and(65535)
    or64 r7, r4                                     r7 |= r4   ///  r7 = r7.or(r4)
    lsh64 r0, 16                                    r0 <<= 16   ///  r0 = r0.wrapping_shl(16)
    rsh64 r9, 48                                    r9 >>= 48   ///  r9 = r9.wrapping_shr(48)
    or64 r9, r0                                     r9 |= r0   ///  r9 = r9.or(r0)
    stxdw [r10-0x1b2], r6                   
    stxh [r10-0x1bc], r1                    
    stxdw [r10-0x1ba], r9                   
    ldxb r1, [r10-0x1a2]                    
    ldxb r6, [r10-0x1a3]                    
    stxw [r10-0x1c0], r7                    
    jeq r2, 33, lbb_20958                           if r2 == (33 as i32 as i64 as u64) { pc += 1207 }
    stxdw [r10-0x8a8], r1                   
    ldxb r1, [r10-0x1b6]                    
    stxdw [r10-0x910], r1                   
    ldxb r1, [r10-0x1b5]                    
    stxdw [r10-0x8c8], r1                   
    ldxb r1, [r10-0x1a7]                    
    stxdw [r10-0x908], r1                   
    ldxb r1, [r10-0x1a6]                    
    stxdw [r10-0x8d8], r1                   
    ldxb r1, [r10-0x1ab]                    
    stxdw [r10-0x900], r1                   
    ldxb r1, [r10-0x1aa]                    
    stxdw [r10-0x8f0], r1                   
    ldxb r1, [r10-0x1ac]                    
    stxdw [r10-0x8f8], r1                   
    ldxb r1, [r10-0x1ad]                    
    ldxb r4, [r10-0x1a8]                    
    stxdw [r10-0x8e8], r4                   
    ldxb r7, [r10-0x1a9]                    
    ldxb r4, [r10-0x1b7]                    
    stxdw [r10-0x8e0], r4                   
    ldxb r4, [r10-0x1b8]                    
    ldxb r5, [r10-0x1a4]                    
    stxdw [r10-0x8d0], r5                   
    ldxb r5, [r10-0x1a5]                    
    stxdw [r10-0x818], r5                   
    ldxb r5, [r10-0x1af]                    
    stxdw [r10-0x8c0], r5                   
    ldxb r5, [r10-0x1ae]                    
    stxdw [r10-0x898], r5                   
    ldxb r5, [r10-0x1b3]                    
    stxdw [r10-0x8b8], r5                   
    ldxb r5, [r10-0x1b4]                    
    stxdw [r10-0x8b0], r5                   
    ldxb r5, [r10-0x1b2]                    
    stxdw [r10-0x860], r5                   
    ldxb r5, [r10-0x1b0]                    
    stxdw [r10-0x8a0], r5                   
    ldxb r5, [r10-0x1b1]                    
    stxdw [r10-0x870], r5                   
    ldxb r5, [r10-0x1a1]                    
    stxdw [r10-0x890], r5                   
    ldxb r5, [r10-0x1bb]                    
    stxdw [r10-0x858], r5                   
    ldxb r5, [r10-0x1bc]                    
    stxdw [r10-0x868], r5                   
    ldxb r5, [r10-0x1bd]                    
    stxdw [r10-0x878], r5                   
    ldxb r5, [r10-0x1be]                    
    stxdw [r10-0x850], r5                   
    ldxb r5, [r10-0x1bf]                    
    stxdw [r10-0x828], r5                   
    ldxb r5, [r10-0x1c0]                    
    stxdw [r10-0x820], r5                   
    ldxb r5, [r10-0x1b9]                    
    stxdw [r10-0x888], r5                   
    ldxb r5, [r10-0x1ba]                    
    stxdw [r10-0x880], r5                   
    mov64 r5, 0                                     r5 = 0 as i32 as i64 as u64
    ldxb r0, [r3+0x21]                      
    mov64 r9, r2                                    r9 = r2
    add64 r9, -34                                   r9 += -34   ///  r9 = r9.wrapping_add(-34 as i32 as i64 as u64)
    stxdw [r10-0x770], r9                   
    stxb [r10-0x6e8], r0                    
    ldxdw r8, [r10-0x848]                   
    jeq r0, 0, lbb_20979                            if r0 == (0 as i32 as i64 as u64) { pc += 1162 }
    jne r0, 1, lbb_20620                            if r0 != (1 as i32 as i64 as u64) { pc += 802 }
    jeq r9, 0, lbb_20958                            if r9 == (0 as i32 as i64 as u64) { pc += 1139 }
    stxdw [r10-0x840], r0                   
    ldxb r5, [r3+0x22]                      
    stxb [r10-0x6d9], r5                    
    mov64 r8, 2                                     r8 = 2 as i32 as i64 as u64
    jgt r8, r5, lbb_20963                           if r8 > r5 { pc += 1139 }
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    stxdw [r10-0x1a0], r1                   
    lddw r1, 0x100064af0 --> b"\x00\x00\x00\x00?\xfb\x05\x00\x1d\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00…        r1 load str located at 4295379696
    stxdw [r10-0x1c0], r1                   
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    stxdw [r10-0x1b8], r1                   
    stxdw [r10-0x1a8], r1                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -1384                                 r1 += -1384   ///  r1 = r1.wrapping_add(-1384 as i32 as i64 as u64)
    stxdw [r10-0x1b0], r1                   
    lddw r1, 0x10005de98 --> b"\xbf#\x00\x00\x00\x00\x00\x00q\x11\x00\x00\x00\x00\x00\x00\xb7\x02\x00\x0…        r1 load str located at 4295351960
    stxdw [r10-0x560], r1                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -1753                                 r1 += -1753   ///  r1 = r1.wrapping_add(-1753 as i32 as i64 as u64)
    stxdw [r10-0x568], r1                   
    mov64 r7, r10                                   r7 = r10
    add64 r7, -760                                  r7 += -760   ///  r7 = r7.wrapping_add(-760 as i32 as i64 as u64)
    ja lbb_20639                                    if true { pc += 795 }
lbb_19844:
    jsgt r5, 9, lbb_19875                           if (r5 as i64) > (9 as i32 as i64) { pc += 30 }
    mov64 r4, r5                                    r4 = r5
    jeq r4, 7, lbb_21070                            if r4 == (7 as i32 as i64 as u64) { pc += 1223 }
    ldxdw r1, [r10-0x800]                   
    jeq r1, 8, lbb_20178                            if r1 == (8 as i32 as i64 as u64) { pc += 329 }
    jeq r1, 9, lbb_19851                            if r1 == (9 as i32 as i64 as u64) { pc += 1 }
    ja lbb_20254                                    if true { pc += 403 }
lbb_19851:
    mov64 r1, r10                                   r1 = r10
    add64 r1, -448                                  r1 += -448   ///  r1 = r1.wrapping_add(-448 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -1912                                 r2 += -1912   ///  r2 = r2.wrapping_add(-1912 as i32 as i64 as u64)
    call function_697                       
    ldxdw r0, [r10-0x1b8]                   
    ldxdw r7, [r10-0x1c0]                   
    jeq r7, 0, lbb_21079                            if r7 == (0 as i32 as i64 as u64) { pc += 1220 }
    ldxdw r1, [r10-0x1b0]                   
    ldxdw r2, [r10-0x770]                   
    jeq r2, 0, lbb_20195                            if r2 == (0 as i32 as i64 as u64) { pc += 333 }
    ja lbb_21072                                    if true { pc += 1209 }
lbb_19863:
    jsgt r5, 4, lbb_19894                           if (r5 as i64) > (4 as i32 as i64) { pc += 30 }
    jeq r5, 3, lbb_19935                            if r5 == (3 as i32 as i64 as u64) { pc += 70 }
    jeq r5, 4, lbb_19867                            if r5 == (4 as i32 as i64 as u64) { pc += 1 }
    ja lbb_20254                                    if true { pc += 387 }
lbb_19867:
    jeq r6, 0, lbb_20616                            if r6 == (0 as i32 as i64 as u64) { pc += 748 }
    ldxb r1, [r4+0x0]                       
    stxdw [r10-0x840], r1                   
    add64 r2, -2                                    r2 += -2   ///  r2 = r2.wrapping_add(-2 as i32 as i64 as u64)
    stxdw [r10-0x770], r2                   
    ldxdw r2, [r10-0x770]                   
    jeq r2, 0, lbb_20195                            if r2 == (0 as i32 as i64 as u64) { pc += 321 }
    ja lbb_21072                                    if true { pc += 1197 }
lbb_19875:
    mov64 r2, r5                                    r2 = r5
    add64 r2, -11                                   r2 += -11   ///  r2 = r2.wrapping_add(-11 as i32 as i64 as u64)
    mov64 r3, 2                                     r3 = 2 as i32 as i64 as u64
    jgt r3, r2, lbb_21070                           if r3 > r2 { pc += 1191 }
    ldxdw r1, [r10-0x800]                   
    jeq r1, 10, lbb_19882                           if r1 == (10 as i32 as i64 as u64) { pc += 1 }
    ja lbb_20254                                    if true { pc += 372 }
lbb_19882:
    mov64 r1, r10                                   r1 = r10
    add64 r1, -448                                  r1 += -448   ///  r1 = r1.wrapping_add(-448 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -1912                                 r2 += -1912   ///  r2 = r2.wrapping_add(-1912 as i32 as i64 as u64)
    call function_697                       
    ldxdw r0, [r10-0x1b8]                   
    ldxdw r7, [r10-0x1c0]                   
    jeq r7, 0, lbb_21079                            if r7 == (0 as i32 as i64 as u64) { pc += 1189 }
    ldxdw r1, [r10-0x1b0]                   
    ldxdw r2, [r10-0x770]                   
    jeq r2, 0, lbb_20195                            if r2 == (0 as i32 as i64 as u64) { pc += 302 }
    ja lbb_21072                                    if true { pc += 1178 }
lbb_19894:
    mov64 r2, r5                                    r2 = r5
    jeq r2, 5, lbb_21070                            if r2 == (5 as i32 as i64 as u64) { pc += 1174 }
    ldxdw r1, [r10-0x800]                   
    jeq r1, 6, lbb_19899                            if r1 == (6 as i32 as i64 as u64) { pc += 1 }
    ja lbb_20254                                    if true { pc += 355 }
lbb_19899:
    mov64 r1, r10                                   r1 = r10
    add64 r1, -448                                  r1 += -448   ///  r1 = r1.wrapping_add(-448 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -1912                                 r2 += -1912   ///  r2 = r2.wrapping_add(-1912 as i32 as i64 as u64)
    call function_1398                      
    ldxw r1, [r10-0x1c0]                    
    jne r1, 0, lbb_19921                            if r1 != (0 as i32 as i64 as u64) { pc += 15 }
    ldxdw r6, [r10-0x1b8]                   
    ldxw r7, [r10-0x1bc]                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -1072                                 r1 += -1072   ///  r1 = r1.wrapping_add(-1072 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -432                                  r2 += -432   ///  r2 = r2.wrapping_add(-432 as i32 as i64 as u64)
    mov64 r3, 308                                   r3 = 308 as i32 as i64 as u64
    call function_48190                     
    mov64 r1, r10                                   r1 = r10
    add64 r1, -448                                  r1 += -448   ///  r1 = r1.wrapping_add(-448 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -1912                                 r2 += -1912   ///  r2 = r2.wrapping_add(-1912 as i32 as i64 as u64)
    call function_1398                      
    ldxw r1, [r10-0x1c0]                    
    jeq r1, 0, lbb_20473                            if r1 == (0 as i32 as i64 as u64) { pc += 552 }
lbb_19921:
    ldxdw r0, [r10-0x1b8]                   
    ja lbb_21079                                    if true { pc += 1156 }
lbb_19923:
    mov64 r1, r10                                   r1 = r10
    add64 r1, -447                                  r1 += -447   ///  r1 = r1.wrapping_add(-447 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -759                                  r2 += -759   ///  r2 = r2.wrapping_add(-759 as i32 as i64 as u64)
    mov64 r3, 71                                    r3 = 71 as i32 as i64 as u64
    call function_48190                     
    stxb [r10-0x1c0], r6                    
    mov64 r2, r10                                   r2 = r10
    add64 r2, -448                                  r2 += -448   ///  r2 = r2.wrapping_add(-448 as i32 as i64 as u64)
    mov64 r1, r9                                    r1 = r9
    call function_26067                     
    ja lbb_21091                                    if true { pc += 1156 }
lbb_19935:
    mov64 r1, 33                                    r1 = 33 as i32 as i64 as u64
    jgt r1, r2, lbb_20616                           if r1 > r2 { pc += 679 }
    ldxb r3, [r4+0x14]                      
    lsh64 r3, 16                                    r3 <<= 16   ///  r3 = r3.wrapping_shl(16)
    ldxb r1, [r4+0x15]                      
    lsh64 r1, 24                                    r1 <<= 24   ///  r1 = r1.wrapping_shl(24)
    or64 r1, r3                                     r1 |= r3   ///  r1 = r1.or(r3)
    ldxb r3, [r4+0x13]                      
    lsh64 r3, 8                                     r3 <<= 8   ///  r3 = r3.wrapping_shl(8)
    stxdw [r10-0x848], r8                   
    stxdw [r10-0x830], r9                   
    ldxb r9, [r4+0x12]                      
    or64 r9, r3                                     r9 |= r3   ///  r9 = r9.or(r3)
    ldxb r3, [r4+0x10]                      
    lsh64 r3, 16                                    r3 <<= 16   ///  r3 = r3.wrapping_shl(16)
    ldxb r5, [r4+0x11]                      
    lsh64 r5, 24                                    r5 <<= 24   ///  r5 = r5.wrapping_shl(24)
    or64 r5, r3                                     r5 |= r3   ///  r5 = r5.or(r3)
    ldxb r0, [r4+0xf]                       
    lsh64 r0, 8                                     r0 <<= 8   ///  r0 = r0.wrapping_shl(8)
    ldxb r3, [r4+0xe]                       
    or64 r3, r0                                     r3 |= r0   ///  r3 = r3.or(r0)
    and64 r3, 65535                                 r3 &= 65535   ///  r3 = r3.and(65535)
    or64 r3, r5                                     r3 |= r5   ///  r3 = r3.or(r5)
    and64 r9, 65535                                 r9 &= 65535   ///  r9 = r9.and(65535)
    or64 r9, r1                                     r9 |= r1   ///  r9 = r9.or(r1)
    ldxb r1, [r4+0x18]                      
    lsh64 r1, 16                                    r1 <<= 16   ///  r1 = r1.wrapping_shl(16)
    ldxb r5, [r4+0x19]                      
    lsh64 r5, 24                                    r5 <<= 24   ///  r5 = r5.wrapping_shl(24)
    or64 r5, r1                                     r5 |= r1   ///  r5 = r5.or(r1)
    stxdw [r10-0x870], r5                   
    ldxb r1, [r4+0x17]                      
    lsh64 r1, 8                                     r1 <<= 8   ///  r1 = r1.wrapping_shl(8)
    ldxb r0, [r4+0x16]                      
    or64 r0, r1                                     r0 |= r1   ///  r0 = r0.or(r1)
    ldxb r1, [r4+0xa]                       
    lsh64 r1, 16                                    r1 <<= 16   ///  r1 = r1.wrapping_shl(16)
    ldxb r6, [r4+0xb]                       
    lsh64 r6, 24                                    r6 <<= 24   ///  r6 = r6.wrapping_shl(24)
    or64 r6, r1                                     r6 |= r1   ///  r6 = r6.or(r1)
    ldxb r1, [r4+0x9]                       
    lsh64 r1, 8                                     r1 <<= 8   ///  r1 = r1.wrapping_shl(8)
    ldxb r7, [r4+0x8]                       
    or64 r7, r1                                     r7 |= r1   ///  r7 = r7.or(r1)
    ldxb r1, [r4+0x7]                       
    stxdw [r10-0x818], r1                   
    ldxb r1, [r4+0x6]                       
    stxdw [r10-0x820], r1                   
    ldxb r1, [r4+0x0]                       
    stxdw [r10-0x888], r1                   
    ldxb r1, [r4+0x1]                       
    stxdw [r10-0x828], r1                   
    ldxb r1, [r4+0x3]                       
    stxdw [r10-0x838], r1                   
    ldxb r1, [r4+0x2]                       
    stxdw [r10-0x840], r1                   
    ldxb r1, [r4+0x4]                       
    stxdw [r10-0x850], r1                   
    ldxb r1, [r4+0x5]                       
    stxdw [r10-0x858], r1                   
    ldxb r1, [r4+0x1e]                      
    stxdw [r10-0x860], r1                   
    ldxb r1, [r4+0x1f]                      
    stxdw [r10-0x868], r1                   
    ldxb r1, [r4+0xd]                       
    stxdw [r10-0x878], r1                   
    ldxb r1, [r4+0xc]                       
    stxdw [r10-0x880], r1                   
    ldxb r1, [r4+0x1a]                      
    ldxb r8, [r4+0x1b]                      
    ldxb r5, [r4+0x1d]                      
    ldxb r4, [r4+0x1c]                      
    add64 r2, -33                                   r2 += -33   ///  r2 = r2.wrapping_add(-33 as i32 as i64 as u64)
    stxdw [r10-0x770], r2                   
    lsh64 r9, 32                                    r9 <<= 32   ///  r9 = r9.wrapping_shl(32)
    lsh64 r3, 32                                    r3 <<= 32   ///  r3 = r3.wrapping_shl(32)
    rsh64 r3, 32                                    r3 >>= 32   ///  r3 = r3.wrapping_shr(32)
    or64 r3, r9                                     r3 |= r9   ///  r3 = r3.or(r9)
    ldxdw r9, [r10-0x830]                   
    and64 r7, 65535                                 r7 &= 65535   ///  r7 = r7.and(65535)
    or64 r7, r6                                     r7 |= r6   ///  r7 = r7.or(r6)
    and64 r0, 65535                                 r0 &= 65535   ///  r0 = r0.and(65535)
    ldxdw r2, [r10-0x870]                   
    or64 r0, r2                                     r0 |= r2   ///  r0 = r0.or(r2)
    lsh64 r4, 16                                    r4 <<= 16   ///  r4 = r4.wrapping_shl(16)
    lsh64 r5, 24                                    r5 <<= 24   ///  r5 = r5.wrapping_shl(24)
    or64 r5, r4                                     r5 |= r4   ///  r5 = r5.or(r4)
    lsh64 r8, 8                                     r8 <<= 8   ///  r8 = r8.wrapping_shl(8)
    or64 r1, r8                                     r1 |= r8   ///  r1 = r1.or(r8)
    and64 r1, 65535                                 r1 &= 65535   ///  r1 = r1.and(65535)
    or64 r1, r5                                     r1 |= r5   ///  r1 = r1.or(r5)
    ldxdw r4, [r10-0x880]                   
    lsh64 r4, 32                                    r4 <<= 32   ///  r4 = r4.wrapping_shl(32)
    ldxdw r2, [r10-0x878]                   
    lsh64 r2, 40                                    r2 <<= 40   ///  r2 = r2.wrapping_shl(40)
    or64 r2, r4                                     r2 |= r4   ///  r2 = r2.or(r4)
    lsh64 r1, 32                                    r1 <<= 32   ///  r1 = r1.wrapping_shl(32)
    lsh64 r0, 32                                    r0 <<= 32   ///  r0 = r0.wrapping_shl(32)
    rsh64 r0, 32                                    r0 >>= 32   ///  r0 = r0.wrapping_shr(32)
    or64 r0, r1                                     r0 |= r1   ///  r0 = r0.or(r1)
    lsh64 r7, 32                                    r7 <<= 32   ///  r7 = r7.wrapping_shl(32)
    rsh64 r7, 32                                    r7 >>= 32   ///  r7 = r7.wrapping_shr(32)
    or64 r7, r2                                     r7 |= r2   ///  r7 = r7.or(r2)
    ldxdw r1, [r10-0x868]                   
    lsh64 r1, 8                                     r1 <<= 8   ///  r1 = r1.wrapping_shl(8)
    ldxdw r4, [r10-0x860]                   
    or64 r4, r1                                     r4 |= r1   ///  r4 = r4.or(r1)
    stxdw [r10-0x1b2], r3                   
    ldxdw r1, [r10-0x858]                   
    lsh64 r1, 8                                     r1 <<= 8   ///  r1 = r1.wrapping_shl(8)
    ldxdw r2, [r10-0x850]                   
    or64 r2, r1                                     r2 |= r1   ///  r2 = r2.or(r1)
    ldxdw r3, [r10-0x840]                   
    lsh64 r3, 16                                    r3 <<= 16   ///  r3 = r3.wrapping_shl(16)
    ldxdw r1, [r10-0x838]                   
    lsh64 r1, 24                                    r1 <<= 24   ///  r1 = r1.wrapping_shl(24)
    or64 r1, r3                                     r1 |= r3   ///  r1 = r1.or(r3)
    mov64 r3, r1                                    r3 = r1
    ldxdw r1, [r10-0x828]                   
    lsh64 r1, 8                                     r1 <<= 8   ///  r1 = r1.wrapping_shl(8)
    ldxdw r8, [r10-0x888]                   
    or64 r8, r1                                     r8 |= r1   ///  r8 = r8.or(r1)
    ldxdw r5, [r10-0x820]                   
    lsh64 r5, 48                                    r5 <<= 48   ///  r5 = r5.wrapping_shl(48)
    ldxdw r1, [r10-0x818]                   
    lsh64 r1, 56                                    r1 <<= 56   ///  r1 = r1.wrapping_shl(56)
    or64 r1, r5                                     r1 |= r5   ///  r1 = r1.or(r5)
    lsh64 r7, 16                                    r7 <<= 16   ///  r7 = r7.wrapping_shl(16)
    rsh64 r1, 48                                    r1 >>= 48   ///  r1 = r1.wrapping_shr(48)
    or64 r1, r7                                     r1 |= r7   ///  r1 = r1.or(r7)
    and64 r8, 65535                                 r8 &= 65535   ///  r8 = r8.and(65535)
    or64 r8, r3                                     r8 |= r3   ///  r8 = r8.or(r3)
    stxdw [r10-0x1aa], r0                   
    stxw [r10-0x1c0], r8                    
    stxh [r10-0x1a2], r4                    
    stxh [r10-0x1bc], r2                    
    stxdw [r10-0x1ba], r1                   
    ldxb r1, [r10-0x1b7]                    
    lsh64 r1, 8                                     r1 <<= 8   ///  r1 = r1.wrapping_shl(8)
    ldxb r3, [r10-0x1b8]                    
    or64 r3, r1                                     r3 |= r1   ///  r3 = r3.or(r1)
    ldxb r1, [r10-0x1ac]                    
    lsh64 r1, 8                                     r1 <<= 8   ///  r1 = r1.wrapping_shl(8)
    ldxb r2, [r10-0x1ad]                    
    or64 r2, r1                                     r2 |= r1   ///  r2 = r2.or(r1)
    ldxb r1, [r10-0x1b6]                    
    lsh64 r1, 16                                    r1 <<= 16   ///  r1 = r1.wrapping_shl(16)
    ldxb r6, [r10-0x1b5]                    
    lsh64 r6, 24                                    r6 <<= 24   ///  r6 = r6.wrapping_shl(24)
    or64 r6, r1                                     r6 |= r1   ///  r6 = r6.or(r1)
    ldxb r1, [r10-0x1ab]                    
    lsh64 r1, 16                                    r1 <<= 16   ///  r1 = r1.wrapping_shl(16)
    ldxb r5, [r10-0x1aa]                    
    lsh64 r5, 24                                    r5 <<= 24   ///  r5 = r5.wrapping_shl(24)
    or64 r5, r1                                     r5 |= r1   ///  r5 = r5.or(r1)
    ldxb r1, [r10-0x1a7]                    
    lsh64 r1, 16                                    r1 <<= 16   ///  r1 = r1.wrapping_shl(16)
    ldxb r4, [r10-0x1a6]                    
    lsh64 r4, 24                                    r4 <<= 24   ///  r4 = r4.wrapping_shl(24)
    or64 r4, r1                                     r4 |= r1   ///  r4 = r4.or(r1)
    ldxb r0, [r10-0x1a8]                    
    lsh64 r0, 8                                     r0 <<= 8   ///  r0 = r0.wrapping_shl(8)
    ldxb r1, [r10-0x1a9]                    
    or64 r1, r0                                     r1 |= r0   ///  r1 = r1.or(r0)
    ldxb r0, [r10-0x1af]                    
    lsh64 r0, 16                                    r0 <<= 16   ///  r0 = r0.wrapping_shl(16)
    ldxb r7, [r10-0x1ae]                    
    lsh64 r7, 24                                    r7 <<= 24   ///  r7 = r7.wrapping_shl(24)
    or64 r7, r0                                     r7 |= r0   ///  r7 = r7.or(r0)
    ldxb r8, [r10-0x1b0]                    
    lsh64 r8, 8                                     r8 <<= 8   ///  r8 = r8.wrapping_shl(8)
    ldxb r0, [r10-0x1b1]                    
    or64 r0, r8                                     r0 |= r8   ///  r0 = r0.or(r8)
    and64 r2, 65535                                 r2 &= 65535   ///  r2 = r2.and(65535)
    or64 r2, r5                                     r2 |= r5   ///  r2 = r2.or(r5)
    ldxb r8, [r10-0x1bd]                    
    lsh64 r8, 16                                    r8 <<= 16   ///  r8 = r8.wrapping_shl(16)
    ldxh r5, [r10-0x1bf]                    
    or64 r5, r8                                     r5 |= r8   ///  r5 = r5.or(r8)
    stxdw [r10-0x838], r5                   
    and64 r3, 65535                                 r3 &= 65535   ///  r3 = r3.and(65535)
    or64 r3, r6                                     r3 |= r6   ///  r3 = r3.or(r6)
    ldxb r6, [r10-0x1b3]                    
    lsh64 r6, 8                                     r6 <<= 8   ///  r6 = r6.wrapping_shl(8)
    ldxb r8, [r10-0x1b4]                    
    or64 r8, r6                                     r8 |= r6   ///  r8 = r8.or(r6)
    and64 r8, 65535                                 r8 &= 65535   ///  r8 = r8.and(65535)
    lsh64 r8, 40                                    r8 <<= 40   ///  r8 = r8.wrapping_shl(40)
    ldxb r6, [r10-0x1b2]                    
    lsh64 r6, 56                                    r6 <<= 56   ///  r6 = r6.wrapping_shl(56)
    or64 r6, r8                                     r6 |= r8   ///  r6 = r6.or(r8)
    ldxdw r8, [r10-0x848]                   
    lsh64 r3, 32                                    r3 <<= 32   ///  r3 = r3.wrapping_shl(32)
    rsh64 r3, 32                                    r3 >>= 32   ///  r3 = r3.wrapping_shr(32)
    lsh64 r3, 8                                     r3 <<= 8   ///  r3 = r3.wrapping_shl(8)
    or64 r6, r3                                     r6 |= r3   ///  r6 = r6.or(r3)
    and64 r0, 65535                                 r0 &= 65535   ///  r0 = r0.and(65535)
    or64 r0, r7                                     r0 |= r7   ///  r0 = r0.or(r7)
    and64 r1, 65535                                 r1 &= 65535   ///  r1 = r1.and(65535)
    or64 r1, r4                                     r1 |= r4   ///  r1 = r1.or(r4)
    ldxb r3, [r10-0x1a2]                    
    lsh64 r3, 24                                    r3 <<= 24   ///  r3 = r3.wrapping_shl(24)
    ldxb r4, [r10-0x1a3]                    
    lsh64 r4, 16                                    r4 <<= 16   ///  r4 = r4.wrapping_shl(16)
    or64 r3, r4                                     r3 |= r4   ///  r3 = r3.or(r4)
    ldxb r4, [r10-0x1a4]                    
    lsh64 r4, 8                                     r4 <<= 8   ///  r4 = r4.wrapping_shl(8)
    ldxb r7, [r10-0x1a5]                    
    or64 r7, r4                                     r7 |= r4   ///  r7 = r7.or(r4)
    and64 r7, 65535                                 r7 &= 65535   ///  r7 = r7.and(65535)
    or64 r7, r3                                     r7 |= r3   ///  r7 = r7.or(r3)
    lsh64 r7, 32                                    r7 <<= 32   ///  r7 = r7.wrapping_shl(32)
    lsh64 r1, 32                                    r1 <<= 32   ///  r1 = r1.wrapping_shl(32)
    rsh64 r1, 32                                    r1 >>= 32   ///  r1 = r1.wrapping_shr(32)
    or64 r1, r7                                     r1 |= r7   ///  r1 = r1.or(r7)
    lsh64 r2, 32                                    r2 <<= 32   ///  r2 = r2.wrapping_shl(32)
    lsh64 r0, 32                                    r0 <<= 32   ///  r0 = r0.wrapping_shl(32)
    rsh64 r0, 32                                    r0 >>= 32   ///  r0 = r0.wrapping_shr(32)
    or64 r0, r2                                     r0 |= r2   ///  r0 = r0.or(r2)
    ldxb r7, [r10-0x1b9]                    
    or64 r7, r6                                     r7 |= r6   ///  r7 = r7.or(r6)
    ldxb r2, [r10-0x1bb]                    
    stxdw [r10-0x828], r2                   
    ldxb r2, [r10-0x1bc]                    
    stxdw [r10-0x820], r2                   
    ldxb r2, [r10-0x1a1]                    
    stxdw [r10-0x818], r2                   
    ldxb r2, [r10-0x1c0]                    
    stxdw [r10-0x840], r2                   
    ldxb r2, [r10-0x1ba]                    
    stxdw [r10-0x850], r2                   
    ldxdw r2, [r10-0x770]                   
    jeq r2, 0, lbb_20195                            if r2 == (0 as i32 as i64 as u64) { pc += 26 }
    ja lbb_21072                                    if true { pc += 902 }
lbb_20170:
    mov64 r1, 9                                     r1 = 9 as i32 as i64 as u64
    jgt r1, r2, lbb_20616                           if r1 > r2 { pc += 444 }
    ldxdw r7, [r4+0x0]                      
    add64 r2, -9                                    r2 += -9   ///  r2 = r2.wrapping_add(-9 as i32 as i64 as u64)
    stxdw [r10-0x770], r2                   
    ldxdw r2, [r10-0x770]                   
    jeq r2, 0, lbb_20195                            if r2 == (0 as i32 as i64 as u64) { pc += 18 }
    ja lbb_21072                                    if true { pc += 894 }
lbb_20178:
    jeq r6, 0, lbb_20616                            if r6 == (0 as i32 as i64 as u64) { pc += 437 }
    ldxb r7, [r3+0x1]                       
    mov64 r1, r2                                    r1 = r2
    add64 r1, -2                                    r1 += -2   ///  r1 = r1.wrapping_add(-2 as i32 as i64 as u64)
    stxdw [r10-0x770], r1                   
    stxb [r10-0x568], r7                    
    jeq r7, 0, lbb_20192                            if r7 == (0 as i32 as i64 as u64) { pc += 7 }
    jne r7, 1, lbb_20452                            if r7 != (1 as i32 as i64 as u64) { pc += 266 }
    mov64 r1, 10                                    r1 = 10 as i32 as i64 as u64
    jgt r1, r2, lbb_20616                           if r1 > r2 { pc += 428 }
    ldxdw r0, [r3+0x2]                      
    add64 r2, -10                                   r2 += -10   ///  r2 = r2.wrapping_add(-10 as i32 as i64 as u64)
    stxdw [r10-0x770], r2                   
    mov64 r7, 1                                     r7 = 1 as i32 as i64 as u64
lbb_20192:
    ldxdw r2, [r10-0x770]                   
    jeq r2, 0, lbb_20195                            if r2 == (0 as i32 as i64 as u64) { pc += 1 }
    ja lbb_21072                                    if true { pc += 877 }
lbb_20195:
    ldxdw r2, [r10-0x800]                   
    jsgt r2, 5, lbb_20239                           if (r2 as i64) > (5 as i32 as i64) { pc += 42 }
    jsgt r2, 2, lbb_20296                           if (r2 as i64) > (2 as i32 as i64) { pc += 98 }
    ldxdw r3, [r10-0x818]                   
    ldxdw r4, [r10-0x820]                   
    ldxdw r6, [r10-0x828]                   
    ldxdw r5, [r10-0x838]                   
    jeq r2, 0, lbb_20324                            if r2 == (0 as i32 as i64 as u64) { pc += 121 }
    jeq r2, 1, lbb_20333                            if r2 == (1 as i32 as i64 as u64) { pc += 129 }
    stxdw [r10-0x7a5], r1                   
    stxdw [r10-0x7ad], r0                   
    stxdw [r10-0x7b5], r7                   
    ldxdw r1, [r10-0x840]                   
    stxb [r10-0x7bc], r1                    
    stxw [r10-0x79d], r3                    
    rsh64 r3, 32                                    r3 >>= 32   ///  r3 = r3.wrapping_shr(32)
    stxb [r10-0x799], r3                    
    stxh [r10-0x7bb], r5                    
    rsh64 r5, 16                                    r5 >>= 16   ///  r5 = r5.wrapping_shr(16)
    stxb [r10-0x7b9], r5                    
    ldxdw r1, [r10-0x850]                   
    stxb [r10-0x7b6], r1                    
    and64 r4, 255                                   r4 &= 255   ///  r4 = r4.and(255)
    lsh64 r6, 8                                     r6 <<= 8   ///  r6 = r6.wrapping_shl(8)
    or64 r4, r6                                     r4 |= r6   ///  r4 = r4.or(r6)
    stxh [r10-0x7b8], r4                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -1980                                 r1 += -1980   ///  r1 = r1.wrapping_add(-1980 as i32 as i64 as u64)
    stxdw [r10-0x2f0], r1                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -1976                                 r1 += -1976   ///  r1 = r1.wrapping_add(-1976 as i32 as i64 as u64)
    stxdw [r10-0x2f8], r1                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -448                                  r1 += -448   ///  r1 = r1.wrapping_add(-448 as i32 as i64 as u64)
    mov64 r4, r10                                   r4 = r10
    add64 r4, -760                                  r4 += -760   ///  r4 = r4.wrapping_add(-760 as i32 as i64 as u64)
    ldxdw r2, [r10-0x808]                   
    mov64 r3, r8                                    r3 = r8
    lddw r5, 0x100014600 --> b"\xbf4\x00\x00\x00\x00\x00\x00\xbf\x16\x00\x00\x00\x00\x00\x00\xb7\x03\x00…        r5 load str located at 4295050752
    call function_10224                     
    ldxw r1, [r10-0x1c0]                    
    jeq r1, 24, lbb_20432                           if r1 == (24 as i32 as i64 as u64) { pc += 194 }
    ja lbb_20442                                    if true { pc += 203 }
lbb_20239:
    jsgt r2, 8, lbb_20280                           if (r2 as i64) > (8 as i32 as i64) { pc += 40 }
    jeq r2, 6, lbb_20356                            if r2 == (6 as i32 as i64 as u64) { pc += 115 }
    jeq r2, 7, lbb_20434                            if r2 == (7 as i32 as i64 as u64) { pc += 192 }
    stxdw [r10-0x1000], r7                  
    stxdw [r10-0xff8], r0                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -448                                  r1 += -448   ///  r1 = r1.wrapping_add(-448 as i32 as i64 as u64)
    mov64 r5, r10                                   r5 = r10
    ldxdw r2, [r10-0x810]                   
    ldxdw r3, [r10-0x808]                   
    mov64 r4, r8                                    r4 = r8
    call function_13727                     
    ldxw r1, [r10-0x1c0]                    
    jeq r1, 24, lbb_20432                           if r1 == (24 as i32 as i64 as u64) { pc += 179 }
    ja lbb_20442                                    if true { pc += 188 }
lbb_20254:
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    stxdw [r10-0x1a0], r1                   
    lddw r1, 0x100064b40 --> b"\x00\x00\x00\x00\xef\xfb\x05\x00\x18\x00\x00\x00\x00\x00\x00\x00\x00\x00\…        r1 load str located at 4295379776
    stxdw [r10-0x1c0], r1                   
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    stxdw [r10-0x1b8], r1                   
    stxdw [r10-0x1a8], r1                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -760                                  r1 += -760   ///  r1 = r1.wrapping_add(-760 as i32 as i64 as u64)
    stxdw [r10-0x1b0], r1                   
    lddw r1, 0x1000008d0 --> b"a#4\x00\x00\x00\x00\x00\xbf4\x00\x00\x00\x00\x00\x00W\x04\x00\x00\x10\x00…        r1 load str located at 4294969552
    stxdw [r10-0x2f0], r1                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -1889                                 r1 += -1889   ///  r1 = r1.wrapping_add(-1889 as i32 as i64 as u64)
    stxdw [r10-0x2f8], r1                   
    mov64 r7, r10                                   r7 = r10
    add64 r7, -1888                                 r7 += -1888   ///  r7 = r7.wrapping_add(-1888 as i32 as i64 as u64)
lbb_20273:
    mov64 r2, r10                                   r2 = r10
    add64 r2, -448                                  r2 += -448   ///  r2 = r2.wrapping_add(-448 as i32 as i64 as u64)
    mov64 r1, r7                                    r1 = r7
    call function_43415                     
    mov64 r1, r7                                    r1 = r7
    call function_77                        
    ja lbb_21079                                    if true { pc += 799 }
lbb_20280:
    jsgt r2, 10, lbb_20311                          if (r2 as i64) > (10 as i32 as i64) { pc += 30 }
    jeq r2, 9, lbb_20366                            if r2 == (9 as i32 as i64 as u64) { pc += 84 }
    stxdw [r10-0x7c8], r1                   
    stxdw [r10-0x7d0], r0                   
    stxdw [r10-0x7d8], r7                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -448                                  r1 += -448   ///  r1 = r1.wrapping_add(-448 as i32 as i64 as u64)
    mov64 r5, r10                                   r5 = r10
    add64 r5, -2008                                 r5 += -2008   ///  r5 = r5.wrapping_add(-2008 as i32 as i64 as u64)
    ldxdw r2, [r10-0x810]                   
    ldxdw r3, [r10-0x808]                   
    mov64 r4, r8                                    r4 = r8
    call function_10942                     
    ldxw r1, [r10-0x1c0]                    
    jeq r1, 24, lbb_20432                           if r1 == (24 as i32 as i64 as u64) { pc += 137 }
    ja lbb_20442                                    if true { pc += 146 }
lbb_20296:
    ldxdw r3, [r10-0x818]                   
    ldxdw r4, [r10-0x820]                   
    ldxdw r6, [r10-0x828]                   
    ldxdw r5, [r10-0x838]                   
    jeq r2, 3, lbb_20380                            if r2 == (3 as i32 as i64 as u64) { pc += 79 }
    jeq r2, 4, lbb_20410                            if r2 == (4 as i32 as i64 as u64) { pc += 108 }
    mov64 r1, r10                                   r1 = r10
    add64 r1, -448                                  r1 += -448   ///  r1 = r1.wrapping_add(-448 as i32 as i64 as u64)
    ldxdw r2, [r10-0x810]                   
    ldxdw r3, [r10-0x808]                   
    mov64 r4, r8                                    r4 = r8
    call function_3890                      
    ldxw r1, [r10-0x1c0]                    
    jeq r1, 24, lbb_20432                           if r1 == (24 as i32 as i64 as u64) { pc += 122 }
    ja lbb_20442                                    if true { pc += 131 }
lbb_20311:
    jeq r2, 11, lbb_20420                           if r2 == (11 as i32 as i64 as u64) { pc += 108 }
    mov64 r1, r10                                   r1 = r10
    add64 r1, -448                                  r1 += -448   ///  r1 = r1.wrapping_add(-448 as i32 as i64 as u64)
    mov64 r4, r10                                   r4 = r10
    add64 r4, -760                                  r4 += -760   ///  r4 = r4.wrapping_add(-760 as i32 as i64 as u64)
    ldxdw r2, [r10-0x808]                   
    mov64 r3, r8                                    r3 = r8
    lddw r5, 0x100014cb0 --> b"{\x1aX\xff\x00\x00\x00\x00{:`\xff\x00\x00\x00\x00a9H!\x00\x00\x00\x00\xb7…        r5 load str located at 4295052464
    call function_10224                     
    ldxw r1, [r10-0x1c0]                    
    jeq r1, 24, lbb_20432                           if r1 == (24 as i32 as i64 as u64) { pc += 109 }
    ja lbb_20442                                    if true { pc += 118 }
lbb_20324:
    mov64 r1, r10                                   r1 = r10
    add64 r1, -448                                  r1 += -448   ///  r1 = r1.wrapping_add(-448 as i32 as i64 as u64)
    ldxdw r2, [r10-0x810]                   
    ldxdw r3, [r10-0x808]                   
    mov64 r4, r8                                    r4 = r8
    call function_7793                      
    ldxw r1, [r10-0x1c0]                    
    jeq r1, 24, lbb_20432                           if r1 == (24 as i32 as i64 as u64) { pc += 100 }
    ja lbb_20442                                    if true { pc += 109 }
lbb_20333:
    stxdw [r10-0x1c0], r7                   
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    stxdw [r10-0x1b8], r1                   
    stxdw [r10-0x1b0], r1                   
    stxb [r10-0x1a8], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -760                                  r1 += -760   ///  r1 = r1.wrapping_add(-760 as i32 as i64 as u64)
    mov64 r5, r10                                   r5 = r10
    add64 r5, -448                                  r5 += -448   ///  r5 = r5.wrapping_add(-448 as i32 as i64 as u64)
    ldxdw r2, [r10-0x810]                   
    ldxdw r3, [r10-0x808]                   
    mov64 r4, r8                                    r4 = r8
    call function_11116                     
    ldxw r1, [r10-0x2f8]                    
    jeq r1, 24, lbb_20432                           if r1 == (24 as i32 as i64 as u64) { pc += 84 }
    ldxw r2, [r10-0x2dc]                    
    stxw [r9+0x1c], r2                      
    ldxdw r2, [r10-0x2e4]                   
    stxdw [r9+0x14], r2                     
    ldxdw r2, [r10-0x2ec]                   
    stxdw [r9+0xc], r2                      
    ldxdw r2, [r10-0x2f4]                   
    ja lbb_20449                                    if true { pc += 93 }
lbb_20356:
    mov64 r1, r10                                   r1 = r10
    add64 r1, -448                                  r1 += -448   ///  r1 = r1.wrapping_add(-448 as i32 as i64 as u64)
    ldxdw r2, [r10-0x810]                   
    ldxdw r3, [r10-0x808]                   
    mov64 r4, r8                                    r4 = r8
    mov64 r5, r7                                    r5 = r7
    call function_13214                     
    ldxw r1, [r10-0x1c0]                    
    jeq r1, 24, lbb_20432                           if r1 == (24 as i32 as i64 as u64) { pc += 67 }
    ja lbb_20442                                    if true { pc += 76 }
lbb_20366:
    stxdw [r10-0x7e0], r1                   
    stxdw [r10-0x7e8], r0                   
    stxdw [r10-0x7f0], r7                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -448                                  r1 += -448   ///  r1 = r1.wrapping_add(-448 as i32 as i64 as u64)
    mov64 r5, r10                                   r5 = r10
    add64 r5, -2032                                 r5 += -2032   ///  r5 = r5.wrapping_add(-2032 as i32 as i64 as u64)
    ldxdw r2, [r10-0x810]                   
    ldxdw r3, [r10-0x808]                   
    mov64 r4, r8                                    r4 = r8
    call function_10692                     
    ldxw r1, [r10-0x1c0]                    
    jeq r1, 24, lbb_20432                           if r1 == (24 as i32 as i64 as u64) { pc += 53 }
    ja lbb_20442                                    if true { pc += 62 }
lbb_20380:
    stxb [r10-0x779], r3                    
    stxdw [r10-0x781], r1                   
    stxdw [r10-0x789], r0                   
    stxdw [r10-0x791], r7                   
    ldxdw r1, [r10-0x840]                   
    stxb [r10-0x798], r1                    
    stxh [r10-0x797], r5                    
    rsh64 r5, 16                                    r5 >>= 16   ///  r5 = r5.wrapping_shr(16)
    stxb [r10-0x795], r5                    
    ldxdw r1, [r10-0x850]                   
    stxb [r10-0x792], r1                    
    and64 r4, 255                                   r4 &= 255   ///  r4 = r4.and(255)
    lsh64 r6, 8                                     r6 <<= 8   ///  r6 = r6.wrapping_shl(8)
    or64 r4, r6                                     r4 |= r6   ///  r4 = r4.or(r6)
    stxh [r10-0x794], r4                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -1944                                 r1 += -1944   ///  r1 = r1.wrapping_add(-1944 as i32 as i64 as u64)
    stxdw [r10-0x2f8], r1                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -448                                  r1 += -448   ///  r1 = r1.wrapping_add(-448 as i32 as i64 as u64)
    mov64 r4, r10                                   r4 = r10
    add64 r4, -760                                  r4 += -760   ///  r4 = r4.wrapping_add(-760 as i32 as i64 as u64)
    ldxdw r2, [r10-0x808]                   
    mov64 r3, r8                                    r3 = r8
    lddw r5, 0x1000148f0 --> b"\xbf\x16\x00\x00\x00\x00\x00\x00y'\x00\x00\x00\x00\x00\x00\x07\x03\x00\x0…        r5 load str located at 4295051504
    call function_10224                     
    ldxw r1, [r10-0x1c0]                    
    jeq r1, 24, lbb_20432                           if r1 == (24 as i32 as i64 as u64) { pc += 23 }
    ja lbb_20442                                    if true { pc += 32 }
lbb_20410:
    mov64 r1, r10                                   r1 = r10
    add64 r1, -448                                  r1 += -448   ///  r1 = r1.wrapping_add(-448 as i32 as i64 as u64)
    ldxdw r2, [r10-0x810]                   
    ldxdw r3, [r10-0x808]                   
    mov64 r4, r8                                    r4 = r8
    ldxdw r5, [r10-0x840]                   
    call function_8805                      
    ldxw r1, [r10-0x1c0]                    
    jeq r1, 24, lbb_20432                           if r1 == (24 as i32 as i64 as u64) { pc += 13 }
    ja lbb_20442                                    if true { pc += 22 }
lbb_20420:
    mov64 r1, r10                                   r1 = r10
    add64 r1, -448                                  r1 += -448   ///  r1 = r1.wrapping_add(-448 as i32 as i64 as u64)
    mov64 r4, r10                                   r4 = r10
    add64 r4, -760                                  r4 += -760   ///  r4 = r4.wrapping_add(-760 as i32 as i64 as u64)
    ldxdw r2, [r10-0x808]                   
    mov64 r3, r8                                    r3 = r8
    lddw r5, 0x100014b80 --> b"\xbf\x16\x00\x00\x00\x00\x00\x00\xb7\x01\x00\x00\x00\x00\x00\x00c\x13H!\x…        r5 load str located at 4295052160
    call function_10224                     
    ldxw r1, [r10-0x1c0]                    
    jeq r1, 24, lbb_20432                           if r1 == (24 as i32 as i64 as u64) { pc += 1 }
    ja lbb_20442                                    if true { pc += 10 }
lbb_20432:
    mov64 r1, 24                                    r1 = 24 as i32 as i64 as u64
    ja lbb_20450                                    if true { pc += 16 }
lbb_20434:
    mov64 r1, r10                                   r1 = r10
    add64 r1, -448                                  r1 += -448   ///  r1 = r1.wrapping_add(-448 as i32 as i64 as u64)
    ldxdw r2, [r10-0x810]                   
    ldxdw r3, [r10-0x808]                   
    mov64 r4, r8                                    r4 = r8
    call function_6378                      
    ldxw r1, [r10-0x1c0]                    
    jeq r1, 24, lbb_20432                           if r1 == (24 as i32 as i64 as u64) { pc += -10 }
lbb_20442:
    ldxw r2, [r10-0x1a4]                    
    stxw [r9+0x1c], r2                      
    ldxdw r2, [r10-0x1ac]                   
    stxdw [r9+0x14], r2                     
    ldxdw r2, [r10-0x1b4]                   
    stxdw [r9+0xc], r2                      
    ldxdw r2, [r10-0x1bc]                   
lbb_20449:
    stxdw [r9+0x4], r2                      
lbb_20450:
    stxw [r9+0x0], r1                       
    ja lbb_21091                                    if true { pc += 639 }
lbb_20452:
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    stxdw [r10-0x1a0], r1                   
    mov64 r1, 2                                     r1 = 2 as i32 as i64 as u64
    stxdw [r10-0x1b8], r1                   
    lddw r1, 0x100064b00 --> b"\x00\x00\x00\x00n\xfb\x05\x00\x1f\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00…        r1 load str located at 4295379712
    stxdw [r10-0x1c0], r1                   
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    stxdw [r10-0x1a8], r1                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -1072                                 r1 += -1072   ///  r1 = r1.wrapping_add(-1072 as i32 as i64 as u64)
    stxdw [r10-0x1b0], r1                   
    lddw r1, 0x10005de98 --> b"\xbf#\x00\x00\x00\x00\x00\x00q\x11\x00\x00\x00\x00\x00\x00\xb7\x02\x00\x0…        r1 load str located at 4295351960
    stxdw [r10-0x428], r1                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -1384                                 r1 += -1384   ///  r1 = r1.wrapping_add(-1384 as i32 as i64 as u64)
    stxdw [r10-0x430], r1                   
    mov64 r7, r10                                   r7 = r10
    add64 r7, -760                                  r7 += -760   ///  r7 = r7.wrapping_add(-760 as i32 as i64 as u64)
    ja lbb_20273                                    if true { pc += -200 }
lbb_20473:
    stxdw [r10-0x840], r7                   
    stxdw [r10-0x838], r6                   
    stxdw [r10-0x848], r8                   
    ldxdw r1, [r10-0x1b8]                   
    stxdw [r10-0x858], r1                   
    ldxw r1, [r10-0x1bc]                    
    stxdw [r10-0x850], r1                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -760                                  r1 += -760   ///  r1 = r1.wrapping_add(-760 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -432                                  r2 += -432   ///  r2 = r2.wrapping_add(-432 as i32 as i64 as u64)
    mov64 r3, 308                                   r3 = 308 as i32 as i64 as u64
    call function_48190                     
    ldxdw r4, [r10-0x770]                   
    mov64 r1, 32                                    r1 = 32 as i32 as i64 as u64
    jgt r1, r4, lbb_20616                           if r1 > r4 { pc += 127 }
    ldxdw r2, [r10-0x778]                   
    ldxb r3, [r2+0xa]                       
    lsh64 r3, 16                                    r3 <<= 16   ///  r3 = r3.wrapping_shl(16)
    ldxb r1, [r2+0xb]                       
    lsh64 r1, 24                                    r1 <<= 24   ///  r1 = r1.wrapping_shl(24)
    or64 r1, r3                                     r1 |= r3   ///  r1 = r1.or(r3)
    ldxb r3, [r2+0x9]                       
    lsh64 r3, 8                                     r3 <<= 8   ///  r3 = r3.wrapping_shl(8)
    stxdw [r10-0x828], r4                   
    ldxb r4, [r2+0x8]                       
    or64 r4, r3                                     r4 |= r3   ///  r4 = r4.or(r3)
    ldxb r3, [r2+0xf]                       
    lsh64 r3, 8                                     r3 <<= 8   ///  r3 = r3.wrapping_shl(8)
    ldxb r5, [r2+0xe]                       
    or64 r5, r3                                     r5 |= r3   ///  r5 = r5.or(r3)
    stxdw [r10-0x818], r5                   
    ldxb r3, [r2+0x1b]                      
    lsh64 r3, 8                                     r3 <<= 8   ///  r3 = r3.wrapping_shl(8)
    ldxb r5, [r2+0x1a]                      
    or64 r5, r3                                     r5 |= r3   ///  r5 = r5.or(r3)
    stxdw [r10-0x820], r5                   
    ldxb r3, [r2+0x17]                      
    lsh64 r3, 8                                     r3 <<= 8   ///  r3 = r3.wrapping_shl(8)
    ldxb r5, [r2+0x16]                      
    or64 r5, r3                                     r5 |= r3   ///  r5 = r5.or(r3)
    and64 r4, 65535                                 r4 &= 65535   ///  r4 = r4.and(65535)
    or64 r4, r1                                     r4 |= r1   ///  r4 = r4.or(r1)
    ldxb r3, [r2+0x14]                      
    lsh64 r3, 16                                    r3 <<= 16   ///  r3 = r3.wrapping_shl(16)
    ldxb r1, [r2+0x15]                      
    lsh64 r1, 24                                    r1 <<= 24   ///  r1 = r1.wrapping_shl(24)
    or64 r1, r3                                     r1 |= r3   ///  r1 = r1.or(r3)
    ldxb r3, [r2+0x13]                      
    lsh64 r3, 8                                     r3 <<= 8   ///  r3 = r3.wrapping_shl(8)
    ldxb r6, [r2+0x12]                      
    or64 r6, r3                                     r6 |= r3   ///  r6 = r6.or(r3)
    ldxb r3, [r2+0x10]                      
    lsh64 r3, 16                                    r3 <<= 16   ///  r3 = r3.wrapping_shl(16)
    ldxb r7, [r2+0x11]                      
    lsh64 r7, 24                                    r7 <<= 24   ///  r7 = r7.wrapping_shl(24)
    or64 r7, r3                                     r7 |= r3   ///  r7 = r7.or(r3)
    ldxb r3, [r2+0x1c]                      
    lsh64 r3, 16                                    r3 <<= 16   ///  r3 = r3.wrapping_shl(16)
    ldxb r0, [r2+0x1d]                      
    lsh64 r0, 24                                    r0 <<= 24   ///  r0 = r0.wrapping_shl(24)
    or64 r0, r3                                     r0 |= r3   ///  r0 = r0.or(r3)
    ldxb r3, [r2+0x18]                      
    lsh64 r3, 16                                    r3 <<= 16   ///  r3 = r3.wrapping_shl(16)
    ldxb r8, [r2+0x19]                      
    lsh64 r8, 24                                    r8 <<= 24   ///  r8 = r8.wrapping_shl(24)
    or64 r8, r3                                     r8 |= r3   ///  r8 = r8.or(r3)
    ldxb r3, [r2+0xc]                       
    lsh64 r3, 32                                    r3 <<= 32   ///  r3 = r3.wrapping_shl(32)
    stxdw [r10-0x830], r9                   
    ldxb r9, [r2+0xd]                       
    lsh64 r9, 40                                    r9 <<= 40   ///  r9 = r9.wrapping_shl(40)
    or64 r9, r3                                     r9 |= r3   ///  r9 = r9.or(r3)
    and64 r5, 65535                                 r5 &= 65535   ///  r5 = r5.and(65535)
    or64 r5, r8                                     r5 |= r8   ///  r5 = r5.or(r8)
    ldxdw r3, [r10-0x820]                   
    and64 r3, 65535                                 r3 &= 65535   ///  r3 = r3.and(65535)
    or64 r3, r0                                     r3 |= r0   ///  r3 = r3.or(r0)
    stxdw [r10-0x820], r3                   
    ldxdw r3, [r10-0x818]                   
    and64 r3, 65535                                 r3 &= 65535   ///  r3 = r3.and(65535)
    or64 r3, r7                                     r3 |= r7   ///  r3 = r3.or(r7)
    stxdw [r10-0x818], r3                   
    and64 r6, 65535                                 r6 &= 65535   ///  r6 = r6.and(65535)
    or64 r6, r1                                     r6 |= r1   ///  r6 = r6.or(r1)
    ldxb r1, [r2+0x1f]                      
    lsh64 r1, 8                                     r1 <<= 8   ///  r1 = r1.wrapping_shl(8)
    ldxb r8, [r2+0x1e]                      
    or64 r8, r1                                     r8 |= r1   ///  r8 = r8.or(r1)
    lsh64 r4, 32                                    r4 <<= 32   ///  r4 = r4.wrapping_shl(32)
    rsh64 r4, 32                                    r4 >>= 32   ///  r4 = r4.wrapping_shr(32)
    or64 r4, r9                                     r4 |= r9   ///  r4 = r4.or(r9)
    ldxb r1, [r2+0x4]                       
    stxdw [r10-0x860], r1                   
    ldxb r1, [r2+0x5]                       
    stxdw [r10-0x868], r1                   
    ldxb r1, [r2+0x7]                       
    ldxb r3, [r2+0x6]                       
    stxdw [r10-0x870], r3                   
    ldxb r7, [r2+0x0]                       
    ldxb r0, [r2+0x1]                       
    ldxb r9, [r2+0x3]                       
    ldxb r3, [r2+0x2]                       
    stxh [r10-0x1a2], r8                    
    lsh64 r6, 32                                    r6 <<= 32   ///  r6 = r6.wrapping_shl(32)
    ldxdw r8, [r10-0x818]                   
    lsh64 r8, 32                                    r8 <<= 32   ///  r8 = r8.wrapping_shl(32)
    rsh64 r8, 32                                    r8 >>= 32   ///  r8 = r8.wrapping_shr(32)
    or64 r8, r6                                     r8 |= r6   ///  r8 = r8.or(r6)
    mov64 r6, r8                                    r6 = r8
    ldxdw r8, [r10-0x820]                   
    lsh64 r8, 32                                    r8 <<= 32   ///  r8 = r8.wrapping_shl(32)
    lsh64 r5, 32                                    r5 <<= 32   ///  r5 = r5.wrapping_shl(32)
    rsh64 r5, 32                                    r5 >>= 32   ///  r5 = r5.wrapping_shr(32)
    or64 r5, r8                                     r5 |= r8   ///  r5 = r5.or(r8)
    lsh64 r3, 16                                    r3 <<= 16   ///  r3 = r3.wrapping_shl(16)
    lsh64 r9, 24                                    r9 <<= 24   ///  r9 = r9.wrapping_shl(24)
    or64 r9, r3                                     r9 |= r3   ///  r9 = r9.or(r3)
    lsh64 r0, 8                                     r0 <<= 8   ///  r0 = r0.wrapping_shl(8)
    or64 r7, r0                                     r7 |= r0   ///  r7 = r7.or(r0)
    ldxdw r3, [r10-0x870]                   
    lsh64 r3, 48                                    r3 <<= 48   ///  r3 = r3.wrapping_shl(48)
    lsh64 r1, 56                                    r1 <<= 56   ///  r1 = r1.wrapping_shl(56)
    or64 r1, r3                                     r1 |= r3   ///  r1 = r1.or(r3)
    ldxdw r0, [r10-0x868]                   
    lsh64 r0, 8                                     r0 <<= 8   ///  r0 = r0.wrapping_shl(8)
    ldxdw r3, [r10-0x860]                   
    or64 r3, r0                                     r3 |= r0   ///  r3 = r3.or(r0)
    stxh [r10-0x1bc], r3                    
    lsh64 r4, 16                                    r4 <<= 16   ///  r4 = r4.wrapping_shl(16)
    rsh64 r1, 48                                    r1 >>= 48   ///  r1 = r1.wrapping_shr(48)
    or64 r1, r4                                     r1 |= r4   ///  r1 = r1.or(r4)
    and64 r7, 65535                                 r7 &= 65535   ///  r7 = r7.and(65535)
    or64 r7, r9                                     r7 |= r9   ///  r7 = r7.or(r9)
    ldxdw r9, [r10-0x830]                   
    stxw [r10-0x1c0], r7                    
    stxdw [r10-0x1aa], r5                   
    stxdw [r10-0x1b2], r6                   
    stxdw [r10-0x1ba], r1                   
    ldxdw r1, [r10-0x828]                   
    and64 r1, -32                                   r1 &= -32   ///  r1 = r1.and(-32)
    jeq r1, 32, lbb_20616                           if r1 == (32 as i32 as i64 as u64) { pc += 1 }
    ja lbb_20647                                    if true { pc += 31 }
lbb_20616:
    lddw r1, 0x100064a98 --> b"\x00\x00\x00\x00\xaa\xfa\x05\x00\x1b\x00\x00\x00\x00\x00\x00\x00%\x00\x00…        r1 load str located at 4295379608
    call function_42270                     
    ja lbb_21079                                    if true { pc += 459 }
lbb_20620:
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    stxdw [r10-0x1a0], r1                   
    lddw r1, 0x100064b40 --> b"\x00\x00\x00\x00\xef\xfb\x05\x00\x18\x00\x00\x00\x00\x00\x00\x00\x00\x00\…        r1 load str located at 4295379776
    stxdw [r10-0x1c0], r1                   
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    stxdw [r10-0x1b8], r1                   
    stxdw [r10-0x1a8], r1                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -760                                  r1 += -760   ///  r1 = r1.wrapping_add(-760 as i32 as i64 as u64)
    stxdw [r10-0x1b0], r1                   
    lddw r1, 0x1000008d0 --> b"a#4\x00\x00\x00\x00\x00\xbf4\x00\x00\x00\x00\x00\x00W\x04\x00\x00\x10\x00…        r1 load str located at 4294969552
    stxdw [r10-0x2f0], r1                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -1768                                 r1 += -1768   ///  r1 = r1.wrapping_add(-1768 as i32 as i64 as u64)
    stxdw [r10-0x2f8], r1                   
    mov64 r7, r10                                   r7 = r10
    add64 r7, -1072                                 r7 += -1072   ///  r7 = r7.wrapping_add(-1072 as i32 as i64 as u64)
lbb_20639:
    mov64 r2, r10                                   r2 = r10
    add64 r2, -448                                  r2 += -448   ///  r2 = r2.wrapping_add(-448 as i32 as i64 as u64)
    mov64 r1, r7                                    r1 = r7
    call function_43415                     
    mov64 r1, r7                                    r1 = r7
    call function_77                        
    ldxdw r9, [r10-0x830]                   
    ja lbb_21079                                    if true { pc += 432 }
lbb_20647:
    ldxb r1, [r10-0x1a1]                    
    stxdw [r10-0x870], r1                   
    ldxb r1, [r10-0x1a2]                    
    stxdw [r10-0x888], r1                   
    ldxb r1, [r10-0x1bb]                    
    stxdw [r10-0x8c0], r1                   
    ldxb r1, [r10-0x1bc]                    
    stxdw [r10-0x8c8], r1                   
    ldxb r1, [r10-0x1bd]                    
    stxdw [r10-0x8d0], r1                   
    ldxb r1, [r10-0x1be]                    
    stxdw [r10-0x8e8], r1                   
    ldxb r1, [r10-0x1bf]                    
    stxdw [r10-0x8d8], r1                   
    ldxb r1, [r10-0x1c0]                    
    stxdw [r10-0x8e0], r1                   
    ldxb r1, [r10-0x1a3]                    
    stxdw [r10-0x8b8], r1                   
    ldxb r1, [r10-0x1a4]                    
    stxdw [r10-0x8a8], r1                   
    ldxb r1, [r10-0x1a5]                    
    stxdw [r10-0x8b0], r1                   
    ldxb r1, [r10-0x1a6]                    
    stxdw [r10-0x878], r1                   
    ldxb r1, [r10-0x1a7]                    
    stxdw [r10-0x8a0], r1                   
    ldxb r1, [r10-0x1a8]                    
    stxdw [r10-0x880], r1                   
    ldxb r1, [r10-0x1a9]                    
    stxdw [r10-0x898], r1                   
    ldxb r1, [r10-0x1aa]                    
    stxdw [r10-0x8f8], r1                   
    ldxb r1, [r10-0x1ab]                    
    stxdw [r10-0x910], r1                   
    ldxb r1, [r10-0x1ac]                    
    stxdw [r10-0x900], r1                   
    ldxb r1, [r10-0x1ad]                    
    stxdw [r10-0x908], r1                   
    ldxb r1, [r10-0x1ae]                    
    stxdw [r10-0x8f0], r1                   
    ldxb r1, [r10-0x1af]                    
    stxdw [r10-0x928], r1                   
    ldxb r1, [r10-0x1b0]                    
    stxdw [r10-0x918], r1                   
    ldxb r1, [r10-0x1b1]                    
    stxdw [r10-0x920], r1                   
    ldxb r1, [r10-0x1b2]                    
    stxdw [r10-0x930], r1                   
    ldxb r1, [r10-0x1b3]                    
    stxdw [r10-0x940], r1                   
    ldxb r1, [r10-0x1b4]                    
    stxdw [r10-0x950], r1                   
    ldxb r1, [r10-0x1b5]                    
    stxdw [r10-0x948], r1                   
    ldxb r1, [r10-0x1b6]                    
    stxdw [r10-0x960], r1                   
    ldxb r1, [r10-0x1b7]                    
    stxdw [r10-0x958], r1                   
    ldxb r1, [r10-0x1b8]                    
    stxdw [r10-0x968], r1                   
    ldxb r1, [r10-0x1b9]                    
    stxdw [r10-0x938], r1                   
    ldxb r1, [r10-0x1ba]                    
    stxdw [r10-0x890], r1                   
    ldxb r1, [r2+0x2a]                      
    lsh64 r1, 16                                    r1 <<= 16   ///  r1 = r1.wrapping_shl(16)
    ldxb r3, [r2+0x2b]                      
    lsh64 r3, 24                                    r3 <<= 24   ///  r3 = r3.wrapping_shl(24)
    or64 r3, r1                                     r3 |= r1   ///  r3 = r3.or(r1)
    ldxb r1, [r2+0x29]                      
    lsh64 r1, 8                                     r1 <<= 8   ///  r1 = r1.wrapping_shl(8)
    ldxb r5, [r2+0x28]                      
    or64 r5, r1                                     r5 |= r1   ///  r5 = r5.or(r1)
    and64 r5, 65535                                 r5 &= 65535   ///  r5 = r5.and(65535)
    or64 r5, r3                                     r5 |= r3   ///  r5 = r5.or(r3)
    ldxb r1, [r2+0x33]                      
    lsh64 r1, 8                                     r1 <<= 8   ///  r1 = r1.wrapping_shl(8)
    ldxb r3, [r2+0x32]                      
    or64 r3, r1                                     r3 |= r1   ///  r3 = r3.or(r1)
    stxdw [r10-0x820], r3                   
    ldxb r1, [r2+0x2f]                      
    lsh64 r1, 8                                     r1 <<= 8   ///  r1 = r1.wrapping_shl(8)
    ldxb r6, [r2+0x2e]                      
    or64 r6, r1                                     r6 |= r1   ///  r6 = r6.or(r1)
    ldxb r1, [r2+0x3b]                      
    lsh64 r1, 8                                     r1 <<= 8   ///  r1 = r1.wrapping_shl(8)
    ldxb r3, [r2+0x3a]                      
    or64 r3, r1                                     r3 |= r1   ///  r3 = r3.or(r1)
    stxdw [r10-0x818], r3                   
    ldxb r1, [r2+0x22]                      
    lsh64 r1, 16                                    r1 <<= 16   ///  r1 = r1.wrapping_shl(16)
    ldxb r3, [r2+0x23]                      
    lsh64 r3, 24                                    r3 <<= 24   ///  r3 = r3.wrapping_shl(24)
    or64 r3, r1                                     r3 |= r1   ///  r3 = r3.or(r1)
    stxdw [r10-0x860], r3                   
    ldxb r1, [r2+0x21]                      
    lsh64 r1, 8                                     r1 <<= 8   ///  r1 = r1.wrapping_shl(8)
    ldxb r3, [r2+0x20]                      
    or64 r3, r1                                     r3 |= r1   ///  r3 = r3.or(r1)
    stxdw [r10-0x868], r3                   
    ldxb r1, [r2+0x2c]                      
    lsh64 r1, 32                                    r1 <<= 32   ///  r1 = r1.wrapping_shl(32)
    ldxb r7, [r2+0x2d]                      
    lsh64 r7, 40                                    r7 <<= 40   ///  r7 = r7.wrapping_shl(40)
    or64 r7, r1                                     r7 |= r1   ///  r7 = r7.or(r1)
    ldxb r1, [r2+0x34]                      
    lsh64 r1, 16                                    r1 <<= 16   ///  r1 = r1.wrapping_shl(16)
    ldxb r0, [r2+0x35]                      
    lsh64 r0, 24                                    r0 <<= 24   ///  r0 = r0.wrapping_shl(24)
    or64 r0, r1                                     r0 |= r1   ///  r0 = r0.or(r1)
    ldxb r1, [r2+0x30]                      
    lsh64 r1, 16                                    r1 <<= 16   ///  r1 = r1.wrapping_shl(16)
    ldxb r4, [r2+0x31]                      
    lsh64 r4, 24                                    r4 <<= 24   ///  r4 = r4.wrapping_shl(24)
    or64 r4, r1                                     r4 |= r1   ///  r4 = r4.or(r1)
    ldxb r8, [r2+0x3c]                      
    lsh64 r8, 16                                    r8 <<= 16   ///  r8 = r8.wrapping_shl(16)
    ldxb r3, [r2+0x3d]                      
    lsh64 r3, 24                                    r3 <<= 24   ///  r3 = r3.wrapping_shl(24)
    or64 r3, r8                                     r3 |= r8   ///  r3 = r3.or(r8)
    ldxb r8, [r2+0x38]                      
    lsh64 r8, 16                                    r8 <<= 16   ///  r8 = r8.wrapping_shl(16)
    ldxb r1, [r2+0x39]                      
    lsh64 r1, 24                                    r1 <<= 24   ///  r1 = r1.wrapping_shl(24)
    or64 r1, r8                                     r1 |= r8   ///  r1 = r1.or(r8)
    ldxb r8, [r2+0x37]                      
    lsh64 r8, 8                                     r8 <<= 8   ///  r8 = r8.wrapping_shl(8)
    ldxb r9, [r2+0x36]                      
    or64 r9, r8                                     r9 |= r8   ///  r9 = r9.or(r8)
    and64 r9, 65535                                 r9 &= 65535   ///  r9 = r9.and(65535)
    or64 r9, r1                                     r9 |= r1   ///  r9 = r9.or(r1)
    ldxdw r1, [r10-0x818]                   
    and64 r1, 65535                                 r1 &= 65535   ///  r1 = r1.and(65535)
    or64 r1, r3                                     r1 |= r3   ///  r1 = r1.or(r3)
    stxdw [r10-0x818], r1                   
    and64 r6, 65535                                 r6 &= 65535   ///  r6 = r6.and(65535)
    or64 r6, r4                                     r6 |= r4   ///  r6 = r6.or(r4)
    ldxdw r8, [r10-0x820]                   
    and64 r8, 65535                                 r8 &= 65535   ///  r8 = r8.and(65535)
    or64 r8, r0                                     r8 |= r0   ///  r8 = r8.or(r0)
    lsh64 r5, 32                                    r5 <<= 32   ///  r5 = r5.wrapping_shl(32)
    rsh64 r5, 32                                    r5 >>= 32   ///  r5 = r5.wrapping_shr(32)
    or64 r5, r7                                     r5 |= r7   ///  r5 = r5.or(r7)
    ldxdw r7, [r10-0x868]                   
    and64 r7, 65535                                 r7 &= 65535   ///  r7 = r7.and(65535)
    ldxdw r1, [r10-0x860]                   
    or64 r7, r1                                     r7 |= r1   ///  r7 = r7.or(r1)
    ldxb r3, [r2+0x25]                      
    lsh64 r3, 8                                     r3 <<= 8   ///  r3 = r3.wrapping_shl(8)
    ldxb r1, [r2+0x24]                      
    or64 r1, r3                                     r1 |= r3   ///  r1 = r1.or(r3)
    ldxb r4, [r2+0x3f]                      
    lsh64 r4, 8                                     r4 <<= 8   ///  r4 = r4.wrapping_shl(8)
    ldxb r3, [r2+0x3e]                      
    or64 r3, r4                                     r3 |= r4   ///  r3 = r3.or(r4)
    ldxb r4, [r2+0x26]                      
    lsh64 r4, 48                                    r4 <<= 48   ///  r4 = r4.wrapping_shl(48)
    ldxb r0, [r2+0x27]                      
    lsh64 r0, 56                                    r0 <<= 56   ///  r0 = r0.wrapping_shl(56)
    or64 r0, r4                                     r0 |= r4   ///  r0 = r0.or(r4)
    ldxdw r4, [r10-0x828]                   
    lsh64 r8, 32                                    r8 <<= 32   ///  r8 = r8.wrapping_shl(32)
    lsh64 r6, 32                                    r6 <<= 32   ///  r6 = r6.wrapping_shl(32)
    rsh64 r6, 32                                    r6 >>= 32   ///  r6 = r6.wrapping_shr(32)
    or64 r6, r8                                     r6 |= r8   ///  r6 = r6.or(r8)
    ldxdw r8, [r10-0x818]                   
    lsh64 r8, 32                                    r8 <<= 32   ///  r8 = r8.wrapping_shl(32)
    lsh64 r9, 32                                    r9 <<= 32   ///  r9 = r9.wrapping_shl(32)
    rsh64 r9, 32                                    r9 >>= 32   ///  r9 = r9.wrapping_shr(32)
    or64 r9, r8                                     r9 |= r8   ///  r9 = r9.or(r8)
    lsh64 r5, 16                                    r5 <<= 16   ///  r5 = r5.wrapping_shl(16)
    rsh64 r0, 48                                    r0 >>= 48   ///  r0 = r0.wrapping_shr(48)
    or64 r0, r5                                     r0 |= r5   ///  r0 = r0.or(r5)
    stxh [r10-0x1a2], r3                    
    stxh [r10-0x1bc], r1                    
    stxw [r10-0x1c0], r7                    
    stxdw [r10-0x1aa], r9                   
    stxdw [r10-0x1b2], r6                   
    stxdw [r10-0x1ba], r0                   
    mov64 r1, r4                                    r1 = r4
    and64 r1, -8                                    r1 &= -8   ///  r1 = r1.and(-8)
    jeq r1, 64, lbb_20958                           if r1 == (64 as i32 as i64 as u64) { pc += 129 }
    mov64 r1, r4                                    r1 = r4
    add64 r1, -72                                   r1 += -72   ///  r1 = r1.wrapping_add(-72 as i32 as i64 as u64)
    mov64 r3, 64                                    r3 = 64 as i32 as i64 as u64
    ldxdw r9, [r10-0x830]                   
    jgt r3, r1, lbb_20616                           if r3 > r1 { pc += -218 }
    ldxb r1, [r10-0x1a1]                    
    stxdw [r10-0x818], r1                   
    ldxb r1, [r10-0x1a2]                    
    stxdw [r10-0x820], r1                   
    ldxb r1, [r10-0x1bb]                    
    stxdw [r10-0xa18], r1                   
    ldxb r1, [r10-0x1bc]                    
    stxdw [r10-0xa10], r1                   
    ldxb r1, [r10-0x1bd]                    
    stxdw [r10-0xa08], r1                   
    ldxb r1, [r10-0x1be]                    
    stxdw [r10-0xa00], r1                   
    ldxb r1, [r10-0x1bf]                    
    stxdw [r10-0x9f8], r1                   
    ldxb r1, [r10-0x1c0]                    
    stxdw [r10-0xa58], r1                   
    ldxb r1, [r10-0x1a3]                    
    stxdw [r10-0x860], r1                   
    ldxb r1, [r10-0x1a4]                    
    stxdw [r10-0x868], r1                   
    ldxb r1, [r10-0x1a5]                    
    stxdw [r10-0x970], r1                   
    ldxb r1, [r10-0x1a6]                    
    stxdw [r10-0x978], r1                   
    ldxb r1, [r10-0x1a7]                    
    stxdw [r10-0x980], r1                   
    ldxb r1, [r10-0x1a8]                    
    stxdw [r10-0x988], r1                   
    ldxb r1, [r10-0x1a9]                    
    stxdw [r10-0x990], r1                   
    ldxb r1, [r10-0x1aa]                    
    stxdw [r10-0x998], r1                   
    ldxb r1, [r10-0x1ab]                    
    stxdw [r10-0x9a0], r1                   
    ldxb r1, [r10-0x1ac]                    
    stxdw [r10-0x9a8], r1                   
    ldxb r1, [r10-0x1ad]                    
    stxdw [r10-0x9b0], r1                   
    ldxb r1, [r10-0x1ae]                    
    stxdw [r10-0x9b8], r1                   
    ldxb r1, [r10-0x1af]                    
    stxdw [r10-0x9c0], r1                   
    ldxb r1, [r10-0x1b0]                    
    stxdw [r10-0x9c8], r1                   
    ldxb r1, [r10-0x1b1]                    
    stxdw [r10-0x9d0], r1                   
    ldxb r1, [r10-0x1b2]                    
    stxdw [r10-0x9e0], r1                   
    ldxb r1, [r10-0x1b3]                    
    stxdw [r10-0x9e8], r1                   
    ldxb r1, [r10-0x1b4]                    
    stxdw [r10-0xa20], r1                   
    ldxb r1, [r10-0x1b5]                    
    stxdw [r10-0xa28], r1                   
    ldxb r1, [r10-0x1b6]                    
    stxdw [r10-0xa30], r1                   
    ldxb r1, [r10-0x1b7]                    
    stxdw [r10-0xa38], r1                   
    ldxb r1, [r10-0x1b8]                    
    stxdw [r10-0xa40], r1                   
    ldxb r1, [r10-0x1b9]                    
    stxdw [r10-0xa50], r1                   
    ldxb r1, [r10-0x1ba]                    
    stxdw [r10-0xa48], r1                   
    ldxdw r1, [r2+0x40]                     
    stxdw [r10-0x9f0], r1                   
    add64 r4, -136                                  r4 += -136   ///  r4 = r4.wrapping_add(-136 as i32 as i64 as u64)
    stxdw [r10-0x770], r4                   
    ldxdw r3, [r2+0x4e]                     
    ldxb r1, [r2+0x56]                      
    stxb [r10-0x1b8], r1                    
    ldxw r1, [r2+0x48]                      
    stxw [r10-0x6a8], r1                    
    ldxh r1, [r2+0x4c]                      
    stxh [r10-0x6a4], r1                    
    stxdw [r10-0x828], r3                   
    stxdw [r10-0x1c0], r3                   
    add64 r2, 87                                    r2 += 87   ///  r2 = r2.wrapping_add(87 as i32 as i64 as u64)
    ldxdw r1, [r10-0x1bf]                   
    stxdw [r10-0x9d8], r1                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -1753                                 r1 += -1753   ///  r1 = r1.wrapping_add(-1753 as i32 as i64 as u64)
    mov64 r3, 49                                    r3 = 49 as i32 as i64 as u64
    call function_48190                     
    mov64 r1, r10                                   r1 = r10
    add64 r1, -1384                                 r1 += -1384   ///  r1 = r1.wrapping_add(-1384 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -1072                                 r2 += -1072   ///  r2 = r2.wrapping_add(-1072 as i32 as i64 as u64)
    mov64 r3, 308                                   r3 = 308 as i32 as i64 as u64
    call function_48190                     
    mov64 r1, r10                                   r1 = r10
    add64 r1, -1696                                 r1 += -1696   ///  r1 = r1.wrapping_add(-1696 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -760                                  r2 += -760   ///  r2 = r2.wrapping_add(-760 as i32 as i64 as u64)
    mov64 r3, 308                                   r3 = 308 as i32 as i64 as u64
    call function_48190                     
    ldxdw r5, [r10-0x838]                   
    stxdw [r10-0x6e4], r5                   
    ldxdw r1, [r10-0x840]                   
    stxw [r10-0x6e8], r1                    
    lddw r1, 0x300000000                            r1 load str located at 12884901888
    ldxdw r2, [r1+0x0]                      
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    mov64 r4, 1                                     r4 = 1 as i32 as i64 as u64
    mov64 r3, r2                                    r3 = r2
    add64 r3, -776                                  r3 += -776   ///  r3 = r3.wrapping_add(-776 as i32 as i64 as u64)
    jgt r3, r2, lbb_20943                           if r3 > r2 { pc += 1 }
    mov64 r4, 0                                     r4 = 0 as i32 as i64 as u64
lbb_20943:
    ldxdw r8, [r10-0x848]                   
    jne r4, 0, lbb_20946                            if r4 != (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r1, r3                                    r1 = r3
lbb_20946:
    lddw r7, 0x300007cf8                            r7 load str located at 12884933880
    jeq r2, 0, lbb_20951                            if r2 == (0 as i32 as i64 as u64) { pc += 2 }
    and64 r1, -8                                    r1 &= -8   ///  r1 = r1.and(-8)
    mov64 r7, r1                                    r7 = r1
lbb_20951:
    lddw r1, 0x300000007                            r1 load str located at 12884901895
    jgt r7, r1, lbb_21092                           if r7 > r1 { pc += 138 }
    mov64 r1, 8                                     r1 = 8 as i32 as i64 as u64
    mov64 r2, 776                                   r2 = 776 as i32 as i64 as u64
    call function_43400                     
    syscall [invalid]                       
lbb_20958:
    lddw r1, 0x100064a98 --> b"\x00\x00\x00\x00\xaa\xfa\x05\x00\x1b\x00\x00\x00\x00\x00\x00\x00%\x00\x00…        r1 load str located at 4295379608
    call function_42270                     
    ldxdw r9, [r10-0x830]                   
    ja lbb_21079                                    if true { pc += 116 }
lbb_20963:
    ldxdw r9, [r10-0x830]                   
    jeq r2, 35, lbb_20616                           if r2 == (35 as i32 as i64 as u64) { pc += -349 }
    jeq r2, 36, lbb_20616                           if r2 == (36 as i32 as i64 as u64) { pc += -350 }
    ldxb r9, [r3+0x23]                      
    mov64 r0, 1                                     r0 = 1 as i32 as i64 as u64
    jne r5, 0, lbb_20970                            if r5 != (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r0, 0                                     r0 = 0 as i32 as i64 as u64
lbb_20970:
    ldxb r5, [r3+0x24]                      
    add64 r2, -37                                   r2 += -37   ///  r2 = r2.wrapping_add(-37 as i32 as i64 as u64)
    stxdw [r10-0x770], r2                   
    lsh64 r9, 8                                     r9 <<= 8   ///  r9 = r9.wrapping_shl(8)
    or64 r9, r0                                     r9 |= r0   ///  r9 = r9.or(r0)
    lsh64 r5, 16                                    r5 <<= 16   ///  r5 = r5.wrapping_shl(16)
    or64 r5, r9                                     r5 |= r9   ///  r5 = r5.or(r9)
    ldxdw r8, [r10-0x848]                   
    ldxdw r0, [r10-0x840]                   
lbb_20979:
    stxdw [r10-0x838], r5                   
    stxdw [r10-0x840], r0                   
    ldxdw r3, [r10-0x8a8]                   
    lsh64 r3, 24                                    r3 <<= 24   ///  r3 = r3.wrapping_shl(24)
    lsh64 r6, 16                                    r6 <<= 16   ///  r6 = r6.wrapping_shl(16)
    or64 r3, r6                                     r3 |= r6   ///  r3 = r3.or(r6)
    ldxdw r5, [r10-0x910]                   
    lsh64 r5, 16                                    r5 <<= 16   ///  r5 = r5.wrapping_shl(16)
    ldxdw r2, [r10-0x8c8]                   
    lsh64 r2, 24                                    r2 <<= 24   ///  r2 = r2.wrapping_shl(24)
    or64 r2, r5                                     r2 |= r5   ///  r2 = r2.or(r5)
    ldxdw r0, [r10-0x908]                   
    lsh64 r0, 16                                    r0 <<= 16   ///  r0 = r0.wrapping_shl(16)
    ldxdw r5, [r10-0x8d8]                   
    lsh64 r5, 24                                    r5 <<= 24   ///  r5 = r5.wrapping_shl(24)
    or64 r5, r0                                     r5 |= r0   ///  r5 = r5.or(r0)
    ldxdw r6, [r10-0x900]                   
    lsh64 r6, 16                                    r6 <<= 16   ///  r6 = r6.wrapping_shl(16)
    ldxdw r0, [r10-0x8f0]                   
    lsh64 r0, 24                                    r0 <<= 24   ///  r0 = r0.wrapping_shl(24)
    or64 r0, r6                                     r0 |= r6   ///  r0 = r0.or(r6)
    ldxdw r6, [r10-0x8f8]                   
    lsh64 r6, 8                                     r6 <<= 8   ///  r6 = r6.wrapping_shl(8)
    or64 r1, r6                                     r1 |= r6   ///  r1 = r1.or(r6)
    and64 r1, 65535                                 r1 &= 65535   ///  r1 = r1.and(65535)
    or64 r1, r0                                     r1 |= r0   ///  r1 = r1.or(r0)
    ldxdw r0, [r10-0x8e8]                   
    lsh64 r0, 8                                     r0 <<= 8   ///  r0 = r0.wrapping_shl(8)
    or64 r7, r0                                     r7 |= r0   ///  r7 = r7.or(r0)
    and64 r7, 65535                                 r7 &= 65535   ///  r7 = r7.and(65535)
    or64 r7, r5                                     r7 |= r5   ///  r7 = r7.or(r5)
    ldxdw r5, [r10-0x8e0]                   
    lsh64 r5, 8                                     r5 <<= 8   ///  r5 = r5.wrapping_shl(8)
    or64 r4, r5                                     r4 |= r5   ///  r4 = r4.or(r5)
    and64 r4, 65535                                 r4 &= 65535   ///  r4 = r4.and(65535)
    or64 r4, r2                                     r4 |= r2   ///  r4 = r4.or(r2)
    ldxdw r5, [r10-0x8d0]                   
    lsh64 r5, 8                                     r5 <<= 8   ///  r5 = r5.wrapping_shl(8)
    ldxdw r2, [r10-0x818]                   
    or64 r2, r5                                     r2 |= r5   ///  r2 = r2.or(r5)
    and64 r2, 65535                                 r2 &= 65535   ///  r2 = r2.and(65535)
    or64 r2, r3                                     r2 |= r3   ///  r2 = r2.or(r3)
    ldxdw r3, [r10-0x8c0]                   
    lsh64 r3, 16                                    r3 <<= 16   ///  r3 = r3.wrapping_shl(16)
    ldxdw r0, [r10-0x898]                   
    lsh64 r0, 24                                    r0 <<= 24   ///  r0 = r0.wrapping_shl(24)
    or64 r0, r3                                     r0 |= r3   ///  r0 = r0.or(r3)
    ldxdw r3, [r10-0x8b8]                   
    lsh64 r3, 8                                     r3 <<= 8   ///  r3 = r3.wrapping_shl(8)
    ldxdw r5, [r10-0x8b0]                   
    or64 r5, r3                                     r5 |= r3   ///  r5 = r5.or(r3)
    and64 r5, 65535                                 r5 &= 65535   ///  r5 = r5.and(65535)
    lsh64 r5, 40                                    r5 <<= 40   ///  r5 = r5.wrapping_shl(40)
    ldxdw r3, [r10-0x860]                   
    lsh64 r3, 56                                    r3 <<= 56   ///  r3 = r3.wrapping_shl(56)
    or64 r3, r5                                     r3 |= r5   ///  r3 = r3.or(r5)
    lsh64 r7, 32                                    r7 <<= 32   ///  r7 = r7.wrapping_shl(32)
    lsh64 r1, 32                                    r1 <<= 32   ///  r1 = r1.wrapping_shl(32)
    rsh64 r1, 32                                    r1 >>= 32   ///  r1 = r1.wrapping_shr(32)
    or64 r1, r7                                     r1 |= r7   ///  r1 = r1.or(r7)
    ldxdw r6, [r10-0x8a0]                   
    lsh64 r6, 8                                     r6 <<= 8   ///  r6 = r6.wrapping_shl(8)
    ldxdw r5, [r10-0x870]                   
    or64 r5, r6                                     r5 |= r6   ///  r5 = r5.or(r6)
    and64 r5, 65535                                 r5 &= 65535   ///  r5 = r5.and(65535)
    or64 r5, r0                                     r5 |= r0   ///  r5 = r5.or(r0)
    lsh64 r2, 32                                    r2 <<= 32   ///  r2 = r2.wrapping_shl(32)
    rsh64 r2, 32                                    r2 >>= 32   ///  r2 = r2.wrapping_shr(32)
    ldxdw r0, [r10-0x890]                   
    lsh64 r0, 32                                    r0 <<= 32   ///  r0 = r0.wrapping_shl(32)
    or64 r2, r0                                     r2 |= r0   ///  r2 = r2.or(r0)
    stxdw [r10-0x818], r2                   
    lsh64 r4, 32                                    r4 <<= 32   ///  r4 = r4.wrapping_shl(32)
    rsh64 r4, 32                                    r4 >>= 32   ///  r4 = r4.wrapping_shr(32)
    lsh64 r4, 8                                     r4 <<= 8   ///  r4 = r4.wrapping_shl(8)
    or64 r3, r4                                     r3 |= r4   ///  r3 = r3.or(r4)
    ldxdw r2, [r10-0x888]                   
    or64 r2, r3                                     r2 |= r3   ///  r2 = r2.or(r3)
    stxw [r10-0x694], r5                    
    stxdw [r10-0x69c], r2                   
    ldxdw r2, [r10-0x878]                   
    stxb [r10-0x6a0], r2                    
    ldxdw r2, [r10-0x868]                   
    stxb [r10-0x69f], r2                    
    ldxdw r2, [r10-0x858]                   
    stxb [r10-0x69e], r2                    
    ldxdw r2, [r10-0x880]                   
    stxb [r10-0x69d], r2                    
    ldxdw r0, [r10-0x698]                   
    ldxdw r7, [r10-0x6a0]                   
    ldxdw r9, [r10-0x830]                   
lbb_21070:
    ldxdw r2, [r10-0x770]                   
    jeq r2, 0, lbb_20195                            if r2 == (0 as i32 as i64 as u64) { pc += -877 }
lbb_21072:
    lddw r1, 0x10005fb5c --> b"Not all bytes read"        r1 load str located at 4295359324
    mov64 r2, 18                                    r2 = 18 as i32 as i64 as u64
    call function_114                       
    ldxdw r1, [r10-0x800]                   
    jeq r1, 10, lbb_21079                           if r1 == (10 as i32 as i64 as u64) { pc += 1 }
    jne r1, 9, lbb_21079                            if r1 != (9 as i32 as i64 as u64) { pc += 0 }
lbb_21079:
    mov64 r1, r0                                    r1 = r0
    and64 r1, 3                                     r1 &= 3   ///  r1 = r1.and(3)
    mov64 r2, r1                                    r2 = r1
    add64 r2, -2                                    r2 += -2   ///  r2 = r2.wrapping_add(-2 as i32 as i64 as u64)
    mov64 r6, 2                                     r6 = 2 as i32 as i64 as u64
    jgt r6, r2, lbb_21090                           if r6 > r2 { pc += 5 }
    jeq r1, 0, lbb_21090                            if r1 == (0 as i32 as i64 as u64) { pc += 4 }
    ldxdw r1, [r0-0x1]                      
    ldxdw r2, [r0+0x7]                      
    ldxdw r2, [r2+0x0]                      
    callx r2                                
lbb_21090:
    stxdw [r9+0x0], r6                      
lbb_21091:
    exit                                    
lbb_21092:
    ldxdw r1, [r10-0x960]                   
    mov64 r2, r1                                    r2 = r1
    ldxdw r1, [r10-0x968]                   
    ldxdw r3, [r10-0x958]                   
    lsh64 r3, 8                                     r3 <<= 8   ///  r3 = r3.wrapping_shl(8)
    lsh64 r2, 16                                    r2 <<= 16   ///  r2 = r2.wrapping_shl(16)
    ldxdw r4, [r10-0x948]                   
    lsh64 r4, 24                                    r4 <<= 24   ///  r4 = r4.wrapping_shl(24)
    or64 r1, r3                                     r1 |= r3   ///  r1 = r1.or(r3)
    or64 r4, r2                                     r4 |= r2   ///  r4 = r4.or(r2)
    and64 r1, 65535                                 r1 &= 65535   ///  r1 = r1.and(65535)
    ldxdw r2, [r10-0x950]                   
    ldxdw r3, [r10-0x940]                   
    lsh64 r3, 8                                     r3 <<= 8   ///  r3 = r3.wrapping_shl(8)
    or64 r1, r4                                     r1 |= r4   ///  r1 = r1.or(r4)
    or64 r2, r3                                     r2 |= r3   ///  r2 = r2.or(r3)
    and64 r2, 65535                                 r2 &= 65535   ///  r2 = r2.and(65535)
    lsh64 r1, 32                                    r1 <<= 32   ///  r1 = r1.wrapping_shl(32)
    lsh64 r2, 40                                    r2 <<= 40   ///  r2 = r2.wrapping_shl(40)
    ldxdw r3, [r10-0x930]                   
    lsh64 r3, 56                                    r3 <<= 56   ///  r3 = r3.wrapping_shl(56)
    rsh64 r1, 32                                    r1 >>= 32   ///  r1 = r1.wrapping_shr(32)
    or64 r3, r2                                     r3 |= r2   ///  r3 = r3.or(r2)
    lsh64 r1, 8                                     r1 <<= 8   ///  r1 = r1.wrapping_shl(8)
    or64 r3, r1                                     r3 |= r1   ///  r3 = r3.or(r1)
    ldxdw r1, [r10-0x938]                   
    mov64 r6, r1                                    r6 = r1
    or64 r6, r3                                     r6 |= r3   ///  r6 = r6.or(r3)
    ldxdw r1, [r10-0x6e8]                   
    lddw r2, 0x300000000                            r2 load str located at 12884901888
    stxdw [r2+0x0], r7                      
    rsh64 r5, 32                                    r5 >>= 32   ///  r5 = r5.wrapping_shr(32)
    stxw [r7+0x8], r5                       
    stxdw [r7+0x0], r1                      
    mov64 r1, r7                                    r1 = r7
    add64 r1, 12                                    r1 += 12   ///  r1 = r1.wrapping_add(12 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -1384                                 r2 += -1384   ///  r2 = r2.wrapping_add(-1384 as i32 as i64 as u64)
    mov64 r3, 308                                   r3 = 308 as i32 as i64 as u64
    call function_48190                     
    ldxdw r1, [r10-0x858]                   
    stxdw [r7+0x144], r1                    
    ldxdw r1, [r10-0x850]                   
    stxw [r7+0x140], r1                     
    mov64 r1, r7                                    r1 = r7
    add64 r1, 332                                   r1 += 332   ///  r1 = r1.wrapping_add(332 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -1696                                 r2 += -1696   ///  r2 = r2.wrapping_add(-1696 as i32 as i64 as u64)
    mov64 r3, 308                                   r3 = 308 as i32 as i64 as u64
    call function_48190                     
    ldxdw r1, [r10-0x928]                   
    lsh64 r1, 16                                    r1 <<= 16   ///  r1 = r1.wrapping_shl(16)
    ldxdw r3, [r10-0x8f0]                   
    lsh64 r3, 24                                    r3 <<= 24   ///  r3 = r3.wrapping_shl(24)
    or64 r3, r1                                     r3 |= r1   ///  r3 = r3.or(r1)
    ldxdw r1, [r10-0x920]                   
    ldxdw r2, [r10-0x918]                   
    lsh64 r2, 8                                     r2 <<= 8   ///  r2 = r2.wrapping_shl(8)
    or64 r1, r2                                     r1 |= r2   ///  r1 = r1.or(r2)
    ldxdw r2, [r10-0x910]                   
    lsh64 r2, 16                                    r2 <<= 16   ///  r2 = r2.wrapping_shl(16)
    ldxdw r5, [r10-0x8f8]                   
    lsh64 r5, 24                                    r5 <<= 24   ///  r5 = r5.wrapping_shl(24)
    or64 r5, r2                                     r5 |= r2   ///  r5 = r5.or(r2)
    ldxdw r2, [r10-0x908]                   
    mov64 r4, r2                                    r4 = r2
    ldxdw r2, [r10-0x900]                   
    lsh64 r2, 8                                     r2 <<= 8   ///  r2 = r2.wrapping_shl(8)
    or64 r4, r2                                     r4 |= r2   ///  r4 = r4.or(r2)
    and64 r4, 65535                                 r4 &= 65535   ///  r4 = r4.and(65535)
    or64 r4, r5                                     r4 |= r5   ///  r4 = r4.or(r5)
    and64 r1, 65535                                 r1 &= 65535   ///  r1 = r1.and(65535)
    or64 r1, r3                                     r1 |= r3   ///  r1 = r1.or(r3)
    ldxdw r2, [r10-0x8e8]                   
    lsh64 r2, 16                                    r2 <<= 16   ///  r2 = r2.wrapping_shl(16)
    ldxdw r3, [r10-0x8d0]                   
    lsh64 r3, 24                                    r3 <<= 24   ///  r3 = r3.wrapping_shl(24)
    or64 r3, r2                                     r3 |= r2   ///  r3 = r3.or(r2)
    ldxdw r2, [r10-0x8e0]                   
    ldxdw r5, [r10-0x8d8]                   
    lsh64 r5, 8                                     r5 <<= 8   ///  r5 = r5.wrapping_shl(8)
    or64 r2, r5                                     r2 |= r5   ///  r2 = r2.or(r5)
    and64 r2, 65535                                 r2 &= 65535   ///  r2 = r2.and(65535)
    or64 r2, r3                                     r2 |= r3   ///  r2 = r2.or(r3)
    ldxdw r3, [r10-0x8c8]                   
    ldxdw r5, [r10-0x8c0]                   
    lsh64 r5, 8                                     r5 <<= 8   ///  r5 = r5.wrapping_shl(8)
    or64 r3, r5                                     r3 |= r5   ///  r3 = r3.or(r5)
    lsh64 r1, 32                                    r1 <<= 32   ///  r1 = r1.wrapping_shl(32)
    rsh64 r1, 32                                    r1 >>= 32   ///  r1 = r1.wrapping_shr(32)
    lsh64 r4, 32                                    r4 <<= 32   ///  r4 = r4.wrapping_shl(32)
    or64 r1, r4                                     r1 |= r4   ///  r1 = r1.or(r4)
    ldxdw r4, [r10-0xa50]                   
    stxb [r7+0x2a7], r4                     
    ldxdw r4, [r10-0xa48]                   
    stxb [r7+0x2a6], r4                     
    ldxdw r4, [r10-0xa18]                   
    stxb [r7+0x2a5], r4                     
    ldxdw r4, [r10-0xa10]                   
    stxb [r7+0x2a4], r4                     
    ldxdw r4, [r10-0xa08]                   
    stxb [r7+0x2a3], r4                     
    ldxdw r4, [r10-0xa00]                   
    stxb [r7+0x2a2], r4                     
    ldxdw r4, [r10-0x9f8]                   
    stxb [r7+0x2a1], r4                     
    ldxdw r4, [r10-0xa58]                   
    stxb [r7+0x2a0], r4                     
    ldxdw r4, [r10-0xa40]                   
    stxb [r7+0x2a8], r4                     
    ldxdw r4, [r10-0xa38]                   
    stxb [r7+0x2a9], r4                     
    ldxdw r4, [r10-0xa30]                   
    stxb [r7+0x2aa], r4                     
    ldxdw r4, [r10-0xa28]                   
    stxb [r7+0x2ab], r4                     
    ldxdw r4, [r10-0xa20]                   
    stxb [r7+0x2ac], r4                     
    stxdw [r7+0x287], r6                    
    ldxdw r4, [r10-0x8b8]                   
    lsh64 r4, 16                                    r4 <<= 16   ///  r4 = r4.wrapping_shl(16)
    ldxdw r0, [r10-0x888]                   
    lsh64 r0, 24                                    r0 <<= 24   ///  r0 = r0.wrapping_shl(24)
    or64 r0, r4                                     r0 |= r4   ///  r0 = r0.or(r4)
    ldxdw r4, [r10-0x8b0]                   
    mov64 r5, r4                                    r5 = r4
    ldxdw r4, [r10-0x8a8]                   
    lsh64 r4, 8                                     r4 <<= 8   ///  r4 = r4.wrapping_shl(8)
    or64 r5, r4                                     r5 |= r4   ///  r5 = r5.or(r4)
    and64 r5, 65535                                 r5 &= 65535   ///  r5 = r5.and(65535)
    or64 r5, r0                                     r5 |= r0   ///  r5 = r5.or(r0)
    ldxdw r4, [r10-0x8a0]                   
    lsh64 r4, 16                                    r4 <<= 16   ///  r4 = r4.wrapping_shl(16)
    ldxdw r0, [r10-0x878]                   
    lsh64 r0, 24                                    r0 <<= 24   ///  r0 = r0.wrapping_shl(24)
    or64 r0, r4                                     r0 |= r4   ///  r0 = r0.or(r4)
    ldxdw r4, [r10-0x898]                   
    ldxdw r6, [r10-0x880]                   
    lsh64 r6, 8                                     r6 <<= 8   ///  r6 = r6.wrapping_shl(8)
    or64 r4, r6                                     r4 |= r6   ///  r4 = r4.or(r6)
    and64 r4, 65535                                 r4 &= 65535   ///  r4 = r4.and(65535)
    or64 r4, r0                                     r4 |= r0   ///  r4 = r4.or(r0)
    lsh64 r4, 32                                    r4 <<= 32   ///  r4 = r4.wrapping_shl(32)
    rsh64 r4, 32                                    r4 >>= 32   ///  r4 = r4.wrapping_shr(32)
    lsh64 r5, 32                                    r5 <<= 32   ///  r5 = r5.wrapping_shl(32)
    or64 r4, r5                                     r4 |= r5   ///  r4 = r4.or(r5)
    ldxdw r5, [r10-0x9e8]                   
    stxb [r7+0x2ad], r5                     
    ldxdw r5, [r10-0x890]                   
    stxb [r7+0x286], r5                     
    stxh [r7+0x284], r3                     
    stxw [r7+0x280], r2                     
    ldxdw r2, [r10-0x9f0]                   
    stxdw [r7+0x2c0], r2                    
    ldxdw r2, [r10-0x9e0]                   
    stxb [r7+0x2ae], r2                     
    ldxdw r2, [r10-0x9d0]                   
    stxb [r7+0x2af], r2                     
    ldxdw r2, [r10-0x9c8]                   
    stxb [r7+0x2b0], r2                     
    ldxdw r2, [r10-0x9c0]                   
    stxb [r7+0x2b1], r2                     
    ldxdw r2, [r10-0x9b8]                   
    stxb [r7+0x2b2], r2                     
    stxdw [r7+0x28f], r1                    
    ldxdw r1, [r10-0x9b0]                   
    stxb [r7+0x2b3], r1                     
    ldxdw r1, [r10-0x9a8]                   
    stxb [r7+0x2b4], r1                     
    ldxdw r1, [r10-0x9a0]                   
    stxb [r7+0x2b5], r1                     
    ldxdw r1, [r10-0x998]                   
    stxb [r7+0x2b6], r1                     
    ldxdw r1, [r10-0x870]                   
    stxb [r7+0x29f], r1                     
    ldxdw r1, [r10-0x990]                   
    stxb [r7+0x2b7], r1                     
    ldxdw r1, [r10-0x988]                   
    stxb [r7+0x2b8], r1                     
    ldxdw r1, [r10-0x980]                   
    stxb [r7+0x2b9], r1                     
    ldxdw r1, [r10-0x978]                   
    stxb [r7+0x2ba], r1                     
    stxdw [r7+0x297], r4                    
    ldxdw r1, [r10-0x970]                   
    stxb [r7+0x2bb], r1                     
    ldxdw r1, [r10-0x868]                   
    stxb [r7+0x2bc], r1                     
    ldxdw r1, [r10-0x860]                   
    stxb [r7+0x2bd], r1                     
    ldxdw r1, [r10-0x820]                   
    stxb [r7+0x2be], r1                     
    ldxdw r1, [r10-0x818]                   
    stxb [r7+0x2bf], r1                     
    ldxh r1, [r10-0x6a4]                    
    ldxw r2, [r10-0x6a8]                    
    ldxdw r3, [r10-0x828]                   
    stxb [r7+0x2ce], r3                     
    ldxdw r3, [r10-0x9d8]                   
    stxdw [r7+0x2cf], r3                    
    stxw [r7+0x2c8], r2                     
    stxh [r7+0x2cc], r1                     
    mov64 r1, r7                                    r1 = r7
    add64 r1, 727                                   r1 += 727   ///  r1 = r1.wrapping_add(727 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -1753                                 r2 += -1753   ///  r2 = r2.wrapping_add(-1753 as i32 as i64 as u64)
    mov64 r3, 49                                    r3 = 49 as i32 as i64 as u64
    call function_48190                     
    ldxdw r2, [r10-0x770]                   
    jeq r2, 0, lbb_20195                            if r2 == (0 as i32 as i64 as u64) { pc += -1108 }
    ja lbb_21072                                    if true { pc += -232 }

entrypoint:
    mov64 r2, r1                                    r2 = r1
    mov64 r1, r10                                   r1 = r10
    add64 r1, -80                                   r1 += -80   ///  r1 = r1.wrapping_add(-80 as i32 as i64 as u64)
    call function_39206                     
    ldxdw r6, [r10-0x38]                    
    ldxdw r7, [r10-0x48]                    
    ldxdw r2, [r10-0x50]                    
    ldxdw r1, [r10-0x28]                    
    ldxdw r3, [r10-0x30]                    
    stxdw [r10-0x1000], r3                  
    stxdw [r10-0xff8], r1                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -80                                   r1 += -80   ///  r1 = r1.wrapping_add(-80 as i32 as i64 as u64)
    mov64 r5, r10                                   r5 = r10
    mov64 r3, r7                                    r3 = r7
    mov64 r4, r6                                    r4 = r6
    call function_19585                     
    mov64 r0, 0                                     r0 = 0 as i32 as i64 as u64
    ldxw r1, [r10-0x50]                     
    jeq r1, 24, lbb_21335                           if r1 == (24 as i32 as i64 as u64) { pc += 11 }
    ldxdw r1, [r10-0x38]                    
    stxdw [r10-0x8], r1                     
    ldxdw r1, [r10-0x40]                    
    stxdw [r10-0x10], r1                    
    ldxdw r1, [r10-0x48]                    
    stxdw [r10-0x18], r1                    
    ldxdw r1, [r10-0x50]                    
    stxdw [r10-0x20], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -32                                   r1 += -32   ///  r1 = r1.wrapping_add(-32 as i32 as i64 as u64)
    call function_40623                     
lbb_21335:
    jeq r6, 0, lbb_21341                            if r6 == (0 as i32 as i64 as u64) { pc += 5 }
    add64 r7, 16                                    r7 += 16   ///  r7 = r7.wrapping_add(16 as i32 as i64 as u64)
    ja lbb_21342                                    if true { pc += 4 }
lbb_21338:
    add64 r7, 48                                    r7 += 48   ///  r7 = r7.wrapping_add(48 as i32 as i64 as u64)
    add64 r6, -1                                    r6 += -1   ///  r6 = r6.wrapping_add(-1 as i32 as i64 as u64)
    jne r6, 0, lbb_21342                            if r6 != (0 as i32 as i64 as u64) { pc += 1 }
lbb_21341:
    exit                                    
lbb_21342:
    ldxdw r1, [r7+0x0]                      
    ldxdw r2, [r7-0x8]                      
    ldxdw r3, [r2+0x0]                      
    add64 r3, -1                                    r3 += -1   ///  r3 = r3.wrapping_add(-1 as i32 as i64 as u64)
    stxdw [r2+0x0], r3                      
    jne r3, 0, lbb_21351                            if r3 != (0 as i32 as i64 as u64) { pc += 3 }
    ldxdw r3, [r2+0x8]                      
    add64 r3, -1                                    r3 += -1   ///  r3 = r3.wrapping_add(-1 as i32 as i64 as u64)
    stxdw [r2+0x8], r3                      
lbb_21351:
    ldxdw r2, [r1+0x0]                      
    add64 r2, -1                                    r2 += -1   ///  r2 = r2.wrapping_add(-1 as i32 as i64 as u64)
    stxdw [r1+0x0], r2                      
    jne r2, 0, lbb_21338                            if r2 != (0 as i32 as i64 as u64) { pc += -17 }
    ldxdw r2, [r1+0x8]                      
    add64 r2, -1                                    r2 += -1   ///  r2 = r2.wrapping_add(-1 as i32 as i64 as u64)
    stxdw [r1+0x8], r2                      
    ja lbb_21338                                    if true { pc += -21 }

function_21359:
    lddw r3, 0x300000000                            r3 load str located at 12884901888
    ldxdw r3, [r3+0x0]                      
    lddw r4, 0x300008000                            r4 load str located at 12884934656
    jeq r3, 0, lbb_21366                            if r3 == (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r4, r3                                    r4 = r3
lbb_21366:
    mov64 r3, r4                                    r3 = r4
    sub64 r3, r1                                    r3 -= r1   ///  r3 = r3.wrapping_sub(r1)
    mov64 r0, 0                                     r0 = 0 as i32 as i64 as u64
    mov64 r5, 1                                     r5 = 1 as i32 as i64 as u64
    jgt r3, r4, lbb_21372                           if r3 > r4 { pc += 1 }
    mov64 r5, 0                                     r5 = 0 as i32 as i64 as u64
lbb_21372:
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    jne r5, 0, lbb_21375                            if r5 != (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r1, r3                                    r1 = r3
lbb_21375:
    neg64 r2                                        r2 = -r2   ///  r2 = (r2 as i64).wrapping_neg() as u64
    and64 r1, r2                                    r1 &= r2   ///  r1 = r1.and(r2)
    lddw r2, 0x300000008                            r2 load str located at 12884901896
    jgt r2, r1, lbb_21384                           if r2 > r1 { pc += 4 }
    lddw r2, 0x300000000                            r2 load str located at 12884901888
    stxdw [r2+0x0], r1                      
    mov64 r0, r1                                    r0 = r1
lbb_21384:
    exit                                    

function_21385:
    exit                                    

function_21386:
    mov64 r5, r2                                    r5 = r2
    mov64 r2, r1                                    r2 = r1
    lddw r1, 0x300000000                            r1 load str located at 12884901888
    ldxdw r1, [r1+0x0]                      
    lddw r6, 0x300008000                            r6 load str located at 12884934656
    jeq r1, 0, lbb_21395                            if r1 == (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r6, r1                                    r6 = r1
lbb_21395:
    mov64 r1, r6                                    r1 = r6
    sub64 r1, r4                                    r1 -= r4   ///  r1 = r1.wrapping_sub(r4)
    mov64 r0, 0                                     r0 = 0 as i32 as i64 as u64
    mov64 r7, 1                                     r7 = 1 as i32 as i64 as u64
    jgt r1, r6, lbb_21401                           if r1 > r6 { pc += 1 }
    mov64 r7, 0                                     r7 = 0 as i32 as i64 as u64
lbb_21401:
    mov64 r6, 0                                     r6 = 0 as i32 as i64 as u64
    jne r7, 0, lbb_21404                            if r7 != (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r6, r1                                    r6 = r1
lbb_21404:
    neg64 r3                                        r3 = -r3   ///  r3 = (r3 as i64).wrapping_neg() as u64
    and64 r6, r3                                    r6 &= r3   ///  r6 = r6.and(r3)
    lddw r1, 0x300000008                            r1 load str located at 12884901896
    jgt r1, r6, lbb_21418                           if r1 > r6 { pc += 9 }
    lddw r1, 0x300000000                            r1 load str located at 12884901888
    stxdw [r1+0x0], r6                      
    jgt r4, r5, lbb_21414                           if r4 > r5 { pc += 1 }
    mov64 r5, r4                                    r5 = r4
lbb_21414:
    mov64 r1, r6                                    r1 = r6
    mov64 r3, r5                                    r3 = r5
    call function_48190                     
    mov64 r0, r6                                    r0 = r6
lbb_21418:
    exit                                    

custom_panic:
    stxdw [r10-0x90], r1                    
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    stxdw [r10-0x50], r1                    
    lddw r1, 0x100065708 --> b"\x00\x00\x00\x00p\xfa\x05\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00…        r1 load str located at 4295382792
    stxdw [r10-0x70], r1                    
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    stxdw [r10-0x68], r1                    
    stxdw [r10-0x58], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -64                                   r1 += -64   ///  r1 = r1.wrapping_add(-64 as i32 as i64 as u64)
    stxdw [r10-0x60], r1                    
    lddw r1, 0x1000008b8 --> b"y\x11\x00\x00\x00\x00\x00\x00\x85\x10\x00\x00w\xab\x00\x00\x95\x00\x00\x0…        r1 load str located at 4294969528
    stxdw [r10-0x38], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -144                                  r1 += -144   ///  r1 = r1.wrapping_add(-144 as i32 as i64 as u64)
    stxdw [r10-0x40], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -136                                  r1 += -136   ///  r1 = r1.wrapping_add(-136 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -112                                  r2 += -112   ///  r2 = r2.wrapping_add(-112 as i32 as i64 as u64)
    call function_43415                     
    ldxdw r1, [r10-0x88]                    
    ldxdw r2, [r10-0x78]                    
    syscall [invalid]                       
    exit                                    

function_21446:
    call function_43223                     
    exit                                    

function_21448:
    mov64 r6, r1                                    r6 = r1
    mov64 r1, r10                                   r1 = r10
    add64 r1, -68                                   r1 += -68   ///  r1 = r1.wrapping_add(-68 as i32 as i64 as u64)
    call function_34122                     
    ldxw r1, [r10-0x44]                     
    jne r1, 0, lbb_21459                            if r1 != (0 as i32 as i64 as u64) { pc += 5 }
    ldxdw r1, [r10-0x38]                    
    stxdw [r6+0x8], r1                      
    ldxdw r1, [r10-0x40]                    
    stxdw [r6+0x0], r1                      
    exit                                    
lbb_21459:
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    stxdw [r10-0x28], r1                    
    lddw r1, 0x1000657b8 --> b"\x00\x00\x00\x00+\x0f\x06\x00\x16\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00…        r1 load str located at 4295382968
    stxdw [r10-0x30], r1                    
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    stxdw [r10-0x10], r1                    
    stxdw [r10-0x18], r1                    
    lddw r1, 0x100060ee8 --> b"src/arithmetic_impls.rsAddition overflowedMultipli"        r1 load str located at 4295364328
    stxdw [r10-0x20], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -48                                   r1 += -48   ///  r1 = r1.wrapping_add(-48 as i32 as i64 as u64)
    lddw r2, 0x1000657c8 --> b"\x00\x00\x00\x00\xe8\x0e\x06\x00\x17\x00\x00\x00\x00\x00\x00\x00\x03\x01\…        r2 load str located at 4295382984
    call function_44240                     
    syscall [invalid]                       
    ldxdw r1, [r1+0x0]                      
    ldxw r3, [r2+0x34]                      
    mov64 r4, r3                                    r4 = r3
    and64 r4, 16                                    r4 &= 16   ///  r4 = r4.and(16)
    jne r4, 0, lbb_21486                            if r4 != (0 as i32 as i64 as u64) { pc += 5 }
    and64 r3, 32                                    r3 &= 32   ///  r3 = r3.and(32)
    jeq r3, 0, lbb_21484                            if r3 == (0 as i32 as i64 as u64) { pc += 1 }
    ja lbb_21488                                    if true { pc += 4 }
lbb_21484:
    call function_48052                     
    ja lbb_21489                                    if true { pc += 3 }
lbb_21486:
    call function_47567                     
    ja lbb_21489                                    if true { pc += 1 }
lbb_21488:
    call function_47614                     
lbb_21489:
    exit                                    

function_21490:
    ldxdw r1, [r1+0x0]                      
    ldxw r3, [r2+0x34]                      
    mov64 r4, r3                                    r4 = r3
    and64 r4, 16                                    r4 &= 16   ///  r4 = r4.and(16)
    jne r4, 0, lbb_21500                            if r4 != (0 as i32 as i64 as u64) { pc += 5 }
    and64 r3, 32                                    r3 &= 32   ///  r3 = r3.and(32)
    jeq r3, 0, lbb_21498                            if r3 == (0 as i32 as i64 as u64) { pc += 1 }
    ja lbb_21502                                    if true { pc += 4 }
lbb_21498:
    call function_48033                     
    ja lbb_21503                                    if true { pc += 3 }
lbb_21500:
    call function_47475                     
    ja lbb_21503                                    if true { pc += 1 }
lbb_21502:
    call function_47521                     
lbb_21503:
    exit                                    

function_21504:
    ldxdw r1, [r1+0x0]                      
    ldxw r3, [r2+0x34]                      
    mov64 r4, r3                                    r4 = r3
    and64 r4, 16                                    r4 &= 16   ///  r4 = r4.and(16)
    jne r4, 0, lbb_21514                            if r4 != (0 as i32 as i64 as u64) { pc += 5 }
    and64 r3, 32                                    r3 &= 32   ///  r3 = r3.and(32)
    jeq r3, 0, lbb_21512                            if r3 == (0 as i32 as i64 as u64) { pc += 1 }
    ja lbb_21516                                    if true { pc += 4 }
lbb_21512:
    call function_45154                     
    ja lbb_21517                                    if true { pc += 3 }
lbb_21514:
    call function_47751                     
    ja lbb_21517                                    if true { pc += 1 }
lbb_21516:
    call function_47807                     
lbb_21517:
    exit                                    

function_21518:
    ldxdw r1, [r1+0x0]                      
    ldxw r3, [r2+0x34]                      
    mov64 r4, r3                                    r4 = r3
    and64 r4, 16                                    r4 &= 16   ///  r4 = r4.and(16)
    jne r4, 0, lbb_21528                            if r4 != (0 as i32 as i64 as u64) { pc += 5 }
    and64 r3, 32                                    r3 &= 32   ///  r3 = r3.and(32)
    jeq r3, 0, lbb_21526                            if r3 == (0 as i32 as i64 as u64) { pc += 1 }
    ja lbb_21530                                    if true { pc += 4 }
lbb_21526:
    call function_48047                     
    ja lbb_21531                                    if true { pc += 3 }
lbb_21528:
    call function_47475                     
    ja lbb_21531                                    if true { pc += 1 }
lbb_21530:
    call function_47521                     
lbb_21531:
    exit                                    

function_21532:
    ldxdw r1, [r1+0x0]                      
    call function_33919                     
    exit                                    

function_21535:
    ldxdw r1, [r1+0x0]                      
    call function_39452                     
    exit                                    

function_21538:
    ldxdw r1, [r1+0x0]                      
    call function_48052                     
    exit                                    

function_21541:
    ldxdw r1, [r1+0x0]                      
    call function_44108                     
    exit                                    

function_21544:
    ldxdw r1, [r1+0x0]                      
    call function_41743                     
    exit                                    

function_21547:
    ldxdw r1, [r1+0x0]                      
    ldxdw r1, [r1+0x0]                      
    call function_39452                     
    exit                                    

function_21551:
    ldxdw r1, [r1+0x0]                      
    call function_33790                     
    exit                                    

function_21554:
    ldxdw r1, [r1+0x0]                      
    call function_48047                     
    exit                                    

function_21557:
    ldxdw r1, [r1+0x0]                      
    call function_48071                     
    exit                                    

function_21560:
    mov64 r3, r2                                    r3 = r2
    ldxdw r1, [r1+0x0]                      
    ldxdw r2, [r1+0x8]                      
    ldxdw r1, [r1+0x0]                      
    call function_46428                     
    exit                                    

function_21566:
    ldxdw r1, [r1+0x0]                      
    call function_48071                     
    exit                                    

function_21569:
    mov64 r3, r2                                    r3 = r2
    ldxdw r1, [r1+0x0]                      
    ldxdw r2, [r1+0x10]                     
    ldxdw r1, [r1+0x0]                      
    call function_46428                     
    exit                                    

function_21575:
    ldxdw r1, [r1+0x0]                      
    call function_45154                     
    exit                                    

function_21578:
    ldxdw r1, [r1+0x0]                      
    call function_48033                     
    exit                                    

function_21581:
    mov64 r3, r2                                    r3 = r2
    ldxdw r2, [r1+0x8]                      
    ldxdw r1, [r1+0x0]                      
    call function_46428                     
    exit                                    

function_21586:
    ldxw r3, [r2+0x34]                      
    mov64 r4, r3                                    r4 = r3
    and64 r4, 16                                    r4 &= 16   ///  r4 = r4.and(16)
    jne r4, 0, lbb_21595                            if r4 != (0 as i32 as i64 as u64) { pc += 5 }
    and64 r3, 32                                    r3 &= 32   ///  r3 = r3.and(32)
    jeq r3, 0, lbb_21593                            if r3 == (0 as i32 as i64 as u64) { pc += 1 }
    ja lbb_21597                                    if true { pc += 4 }
lbb_21593:
    call function_48033                     
    ja lbb_21598                                    if true { pc += 3 }
lbb_21595:
    call function_47475                     
    ja lbb_21598                                    if true { pc += 1 }
lbb_21597:
    call function_47521                     
lbb_21598:
    exit                                    

function_21599:
    ldxw r3, [r2+0x34]                      
    mov64 r4, r3                                    r4 = r3
    and64 r4, 16                                    r4 &= 16   ///  r4 = r4.and(16)
    jne r4, 0, lbb_21608                            if r4 != (0 as i32 as i64 as u64) { pc += 5 }
    and64 r3, 32                                    r3 &= 32   ///  r3 = r3.and(32)
    jeq r3, 0, lbb_21606                            if r3 == (0 as i32 as i64 as u64) { pc += 1 }
    ja lbb_21610                                    if true { pc += 4 }
lbb_21606:
    call function_48047                     
    ja lbb_21611                                    if true { pc += 3 }
lbb_21608:
    call function_47475                     
    ja lbb_21611                                    if true { pc += 1 }
lbb_21610:
    call function_47521                     
lbb_21611:
    exit                                    

function_21612:
    ldxw r3, [r2+0x34]                      
    mov64 r4, r3                                    r4 = r3
    and64 r4, 16                                    r4 &= 16   ///  r4 = r4.and(16)
    jne r4, 0, lbb_21621                            if r4 != (0 as i32 as i64 as u64) { pc += 5 }
    and64 r3, 32                                    r3 &= 32   ///  r3 = r3.and(32)
    jeq r3, 0, lbb_21619                            if r3 == (0 as i32 as i64 as u64) { pc += 1 }
    ja lbb_21623                                    if true { pc += 4 }
lbb_21619:
    call function_45154                     
    ja lbb_21624                                    if true { pc += 3 }
lbb_21621:
    call function_47751                     
    ja lbb_21624                                    if true { pc += 1 }
lbb_21623:
    call function_47807                     
lbb_21624:
    exit                                    

function_21625:
    mov64 r0, r5                                    r0 = r5
    add64 r0, 1                                     r0 += 1   ///  r0 = r0.wrapping_add(1 as i32 as i64 as u64)
    jgt r3, r0, lbb_21636                           if r3 > r0 { pc += 8 }
    jgt r5, r3, lbb_21636                           if r5 > r3 { pc += 7 }
    mov64 r0, 0                                     r0 = 0 as i32 as i64 as u64
    stxdw [r1+0x20], r0                     
    stxdw [r1+0x8], r3                      
    stxdw [r1+0x0], r2                      
    stxdw [r1+0x18], r5                     
    stxdw [r1+0x10], r4                     
    exit                                    
lbb_21636:
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    stxdw [r10-0x28], r1                    
    lddw r1, 0x1000657f8 --> b"\x00\x00\x00\x00\xad\x0f\x06\x00\x0c\x00\x00\x00\x00\x00\x00\x00\x00\x00\…        r1 load str located at 4295383032
    stxdw [r10-0x30], r1                    
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    stxdw [r10-0x10], r1                    
    stxdw [r10-0x18], r1                    
    lddw r1, 0x100060ee8 --> b"src/arithmetic_impls.rsAddition overflowedMultipli"        r1 load str located at 4295364328
    stxdw [r10-0x20], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -48                                   r1 += -48   ///  r1 = r1.wrapping_add(-48 as i32 as i64 as u64)
    lddw r2, 0x100065808 --> b"\x00\x00\x00\x00\xb9\x0f\x06\x00T\x00\x00\x00\x00\x00\x00\x00M\x01\x00\x0…        r2 load str located at 4295383048
    call function_44240                     
    syscall [invalid]                       
    exit                                    

function_21654:
    exit                                    

function_21655:
    exit                                    

function_21656:
    mov64 r6, r1                                    r6 = r1
    ldxb r1, [r6+0x0]                       
    jsgt r1, 26, lbb_21666                          if (r1 as i64) > (26 as i32 as i64) { pc += 7 }
    jsgt r1, 11, lbb_21689                          if (r1 as i64) > (11 as i32 as i64) { pc += 29 }
    jsgt r1, 6, lbb_21696                           if (r1 as i64) > (6 as i32 as i64) { pc += 35 }
    jsgt r1, 2, lbb_21700                           if (r1 as i64) > (2 as i32 as i64) { pc += 38 }
    jeq r1, 0, lbb_21784                            if r1 == (0 as i32 as i64 as u64) { pc += 121 }
    jeq r1, 1, lbb_21714                            if r1 == (1 as i32 as i64 as u64) { pc += 50 }
    jeq r1, 2, lbb_21714                            if r1 == (2 as i32 as i64 as u64) { pc += 49 }
    ja lbb_21775                                    if true { pc += 109 }
lbb_21666:
    jsgt r1, 35, lbb_21675                          if (r1 as i64) > (35 as i32 as i64) { pc += 8 }
    jsgt r1, 29, lbb_21784                          if (r1 as i64) > (29 as i32 as i64) { pc += 116 }
    jeq r1, 27, lbb_21784                           if r1 == (27 as i32 as i64 as u64) { pc += 115 }
    jeq r1, 28, lbb_21724                           if r1 == (28 as i32 as i64 as u64) { pc += 54 }
    jeq r1, 29, lbb_21672                           if r1 == (29 as i32 as i64 as u64) { pc += 1 }
    ja lbb_21775                                    if true { pc += 103 }
lbb_21672:
    ldxdw r7, [r6+0x10]                     
    jeq r7, 0, lbb_21784                            if r7 == (0 as i32 as i64 as u64) { pc += 110 }
    ja lbb_21708                                    if true { pc += 33 }
lbb_21675:
    jgt r1, 54, lbb_21750                           if r1 > (54 as i32 as i64 as u64) { pc += 74 }
    mov64 r2, 1                                     r2 = 1 as i32 as i64 as u64
    lsh64 r2, r1                                    r2 <<= r1   ///  r2 = r2.wrapping_shl(r1 as u32)
    lddw r3, 0x7cffe000000000                       r3 load str located at 35184234649878528
    and64 r2, r3                                    r2 &= r3   ///  r2 = r2.and(r3)
    jne r2, 0, lbb_21784                            if r2 != (0 as i32 as i64 as u64) { pc += 102 }
    jeq r1, 48, lbb_21771                           if r1 == (48 as i32 as i64 as u64) { pc += 88 }
    jeq r1, 49, lbb_21685                           if r1 == (49 as i32 as i64 as u64) { pc += 1 }
    ja lbb_21750                                    if true { pc += 65 }
lbb_21685:
    ldxdw r7, [r6+0x30]                     
    jeq r7, 0, lbb_21784                            if r7 == (0 as i32 as i64 as u64) { pc += 97 }
    add64 r6, 40                                    r6 += 40   ///  r6 = r6.wrapping_add(40 as i32 as i64 as u64)
    ja lbb_21780                                    if true { pc += 91 }
lbb_21689:
    mov64 r2, 21                                    r2 = 21 as i32 as i64 as u64
    jsgt r2, r1, lbb_21784                          if (r2 as i64) > (r1 as i64) { pc += 93 }
    jsgt r1, 23, lbb_21710                          if (r1 as i64) > (23 as i32 as i64) { pc += 18 }
    jeq r1, 21, lbb_21724                           if r1 == (21 as i32 as i64 as u64) { pc += 31 }
    jeq r1, 22, lbb_21724                           if r1 == (22 as i32 as i64 as u64) { pc += 30 }
    jeq r1, 23, lbb_21784                           if r1 == (23 as i32 as i64 as u64) { pc += 89 }
    ja lbb_21775                                    if true { pc += 79 }
lbb_21696:
    jsgt r1, 8, lbb_21720                           if (r1 as i64) > (8 as i32 as i64) { pc += 23 }
    jeq r1, 7, lbb_21724                            if r1 == (7 as i32 as i64 as u64) { pc += 26 }
    jeq r1, 8, lbb_21714                            if r1 == (8 as i32 as i64 as u64) { pc += 15 }
    ja lbb_21775                                    if true { pc += 75 }
lbb_21700:
    mov64 r2, r1                                    r2 = r1
    add64 r2, -4                                    r2 += -4   ///  r2 = r2.wrapping_add(-4 as i32 as i64 as u64)
    mov64 r3, 3                                     r3 = 3 as i32 as i64 as u64
    jgt r3, r2, lbb_21784                           if r3 > r2 { pc += 80 }
    jeq r1, 3, lbb_21706                            if r1 == (3 as i32 as i64 as u64) { pc += 1 }
    ja lbb_21775                                    if true { pc += 69 }
lbb_21706:
    ldxdw r7, [r6+0x10]                     
    jeq r7, 0, lbb_21784                            if r7 == (0 as i32 as i64 as u64) { pc += 76 }
lbb_21708:
    add64 r6, 8                                     r6 += 8   ///  r6 = r6.wrapping_add(8 as i32 as i64 as u64)
    ja lbb_21780                                    if true { pc += 70 }
lbb_21710:
    jeq r1, 24, lbb_21724                           if r1 == (24 as i32 as i64 as u64) { pc += 13 }
    jeq r1, 25, lbb_21784                           if r1 == (25 as i32 as i64 as u64) { pc += 72 }
    jeq r1, 26, lbb_21714                           if r1 == (26 as i32 as i64 as u64) { pc += 1 }
    ja lbb_21775                                    if true { pc += 61 }
lbb_21714:
    ldxdw r1, [r6+0x8]                      
    mov64 r7, 32                                    r7 = 32 as i32 as i64 as u64
    mov64 r2, 32                                    r2 = 32 as i32 as i64 as u64
    mov64 r3, 1                                     r3 = 1 as i32 as i64 as u64
    call function_21385                     
    ja lbb_21779                                    if true { pc += 59 }
lbb_21720:
    jeq r1, 9, lbb_21735                            if r1 == (9 as i32 as i64 as u64) { pc += 14 }
    jeq r1, 10, lbb_21735                           if r1 == (10 as i32 as i64 as u64) { pc += 13 }
    jeq r1, 11, lbb_21724                           if r1 == (11 as i32 as i64 as u64) { pc += 1 }
    ja lbb_21775                                    if true { pc += 51 }
lbb_21724:
    ldxdw r1, [r6+0x8]                      
    mov64 r7, 32                                    r7 = 32 as i32 as i64 as u64
    mov64 r2, 32                                    r2 = 32 as i32 as i64 as u64
    mov64 r3, 1                                     r3 = 1 as i32 as i64 as u64
    call function_21385                     
    ldxdw r1, [r6+0x10]                     
    mov64 r2, 32                                    r2 = 32 as i32 as i64 as u64
    mov64 r3, 1                                     r3 = 1 as i32 as i64 as u64
    call function_21385                     
    add64 r6, 24                                    r6 += 24   ///  r6 = r6.wrapping_add(24 as i32 as i64 as u64)
    ja lbb_21780                                    if true { pc += 45 }
lbb_21735:
    ldxdw r1, [r6+0x8]                      
    mov64 r7, 32                                    r7 = 32 as i32 as i64 as u64
    mov64 r2, 32                                    r2 = 32 as i32 as i64 as u64
    mov64 r3, 1                                     r3 = 1 as i32 as i64 as u64
    call function_21385                     
    ldxdw r1, [r6+0x10]                     
    mov64 r2, 32                                    r2 = 32 as i32 as i64 as u64
    mov64 r3, 1                                     r3 = 1 as i32 as i64 as u64
    call function_21385                     
    ldxdw r1, [r6+0x18]                     
    mov64 r2, 32                                    r2 = 32 as i32 as i64 as u64
    mov64 r3, 1                                     r3 = 1 as i32 as i64 as u64
    call function_21385                     
    add64 r6, 32                                    r6 += 32   ///  r6 = r6.wrapping_add(32 as i32 as i64 as u64)
    ja lbb_21780                                    if true { pc += 30 }
lbb_21750:
    jeq r1, 36, lbb_21752                           if r1 == (36 as i32 as i64 as u64) { pc += 1 }
    ja lbb_21775                                    if true { pc += 23 }
lbb_21752:
    ldxdw r1, [r6+0x8]                      
    mov64 r7, 32                                    r7 = 32 as i32 as i64 as u64
    mov64 r2, 32                                    r2 = 32 as i32 as i64 as u64
    mov64 r3, 1                                     r3 = 1 as i32 as i64 as u64
    call function_21385                     
    ldxdw r1, [r6+0x10]                     
    mov64 r2, 32                                    r2 = 32 as i32 as i64 as u64
    mov64 r3, 1                                     r3 = 1 as i32 as i64 as u64
    call function_21385                     
    ldxdw r1, [r6+0x18]                     
    mov64 r2, 32                                    r2 = 32 as i32 as i64 as u64
    mov64 r3, 1                                     r3 = 1 as i32 as i64 as u64
    call function_21385                     
    ldxdw r1, [r6+0x20]                     
    mov64 r2, 32                                    r2 = 32 as i32 as i64 as u64
    mov64 r3, 1                                     r3 = 1 as i32 as i64 as u64
    call function_21385                     
    add64 r6, 40                                    r6 += 40   ///  r6 = r6.wrapping_add(40 as i32 as i64 as u64)
    ja lbb_21780                                    if true { pc += 9 }
lbb_21771:
    ldxdw r7, [r6+0x20]                     
    jeq r7, 0, lbb_21784                            if r7 == (0 as i32 as i64 as u64) { pc += 11 }
    add64 r6, 24                                    r6 += 24   ///  r6 = r6.wrapping_add(24 as i32 as i64 as u64)
    ja lbb_21780                                    if true { pc += 5 }
lbb_21775:
    ldxw r1, [r6+0x8]                       
    jne r1, 14, lbb_21784                           if r1 != (14 as i32 as i64 as u64) { pc += 7 }
    ldxdw r7, [r6+0x18]                     
    jeq r7, 0, lbb_21784                            if r7 == (0 as i32 as i64 as u64) { pc += 5 }
lbb_21779:
    add64 r6, 16                                    r6 += 16   ///  r6 = r6.wrapping_add(16 as i32 as i64 as u64)
lbb_21780:
    ldxdw r1, [r6+0x0]                      
    mov64 r2, r7                                    r2 = r7
    mov64 r3, 1                                     r3 = 1 as i32 as i64 as u64
    call function_21385                     
lbb_21784:
    exit                                    

function_21785:
    mov64 r6, r2                                    r6 = r2
    mov64 r7, r1                                    r7 = r1
    add64 r6, 1                                     r6 += 1   ///  r6 = r6.wrapping_add(1 as i32 as i64 as u64)
lbb_21788:
    mov64 r0, 0                                     r0 = 0 as i32 as i64 as u64
    jeq r6, 1, lbb_21798                            if r6 == (1 as i32 as i64 as u64) { pc += 8 }
    mov64 r1, r10                                   r1 = r10
    add64 r1, -48                                   r1 += -48   ///  r1 = r1.wrapping_add(-48 as i32 as i64 as u64)
    mov64 r2, r7                                    r2 = r7
    call function_26345                     
    add64 r6, -1                                    r6 += -1   ///  r6 = r6.wrapping_add(-1 as i32 as i64 as u64)
    ldxdw r1, [r10-0x30]                    
    mov64 r0, r6                                    r0 = r6
    jne r1, 0, lbb_21788                            if r1 != (0 as i32 as i64 as u64) { pc += -10 }
lbb_21798:
    exit                                    

function_21799:
    mov64 r8, r3                                    r8 = r3
    mov64 r7, r2                                    r7 = r2
    mov64 r6, r1                                    r6 = r1
    add64 r8, 1                                     r8 += 1   ///  r8 = r8.wrapping_add(1 as i32 as i64 as u64)
lbb_21803:
    add64 r8, -1                                    r8 += -1   ///  r8 = r8.wrapping_add(-1 as i32 as i64 as u64)
    jeq r8, 0, lbb_21815                            if r8 == (0 as i32 as i64 as u64) { pc += 10 }
    mov64 r1, r10                                   r1 = r10
    add64 r1, -48                                   r1 += -48   ///  r1 = r1.wrapping_add(-48 as i32 as i64 as u64)
    mov64 r2, r7                                    r2 = r7
    call function_26345                     
    ldxdw r1, [r10-0x30]                    
    jeq r1, 0, lbb_21812                            if r1 == (0 as i32 as i64 as u64) { pc += 1 }
    ja lbb_21803                                    if true { pc += -9 }
lbb_21812:
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    stxdw [r6+0x0], r1                      
    ja lbb_21818                                    if true { pc += 3 }
lbb_21815:
    mov64 r1, r6                                    r1 = r6
    mov64 r2, r7                                    r2 = r7
    call function_26345                     
lbb_21818:
    exit                                    

function_21819:
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
    stxdw [r1+0x8], r2                      
    stxdw [r1+0x0], r2                      
    exit                                    

function_21823:
    mov64 r6, r1                                    r6 = r1
    ldxdw r1, [r2+0x18]                     
    ldxdw r3, [r2+0x8]                      
    jeq r3, 1, lbb_21836                            if r3 == (1 as i32 as i64 as u64) { pc += 9 }
    jne r3, 0, lbb_21833                            if r3 != (0 as i32 as i64 as u64) { pc += 5 }
    mov64 r8, 1                                     r8 = 1 as i32 as i64 as u64
    mov64 r9, 0                                     r9 = 0 as i32 as i64 as u64
    lddw r7, 0x100060ee8 --> b"src/arithmetic_impls.rsAddition overflowedMultipli"        r7 load str located at 4295364328
    jeq r1, 0, lbb_21857                            if r1 == (0 as i32 as i64 as u64) { pc += 24 }
lbb_21833:
    mov64 r1, r6                                    r1 = r6
    call function_43415                     
    ja lbb_21864                                    if true { pc += 28 }
lbb_21836:
    jeq r1, 0, lbb_21838                            if r1 == (0 as i32 as i64 as u64) { pc += 1 }
    ja lbb_21833                                    if true { pc += -5 }
lbb_21838:
    ldxdw r1, [r2+0x0]                      
    mov64 r8, 1                                     r8 = 1 as i32 as i64 as u64
    mov64 r9, 0                                     r9 = 0 as i32 as i64 as u64
    ldxdw r7, [r1+0x0]                      
    ldxdw r1, [r1+0x8]                      
    jeq r1, 0, lbb_21857                            if r1 == (0 as i32 as i64 as u64) { pc += 13 }
    jsgt r1, -1, lbb_21847                          if (r1 as i64) > (-1 as i32 as i64) { pc += 2 }
    call function_43383                     
    syscall [invalid]                       
lbb_21847:
    mov64 r8, r1                                    r8 = r1
    mov64 r2, 1                                     r2 = 1 as i32 as i64 as u64
    call function_21359                     
    mov64 r2, r8                                    r2 = r8
    mov64 r8, r0                                    r8 = r0
    mov64 r9, r2                                    r9 = r2
    jne r8, 0, lbb_21857                            if r8 != (0 as i32 as i64 as u64) { pc += 3 }
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    call function_43400                     
    syscall [invalid]                       
lbb_21857:
    mov64 r1, r8                                    r1 = r8
    mov64 r2, r7                                    r2 = r7
    mov64 r3, r9                                    r3 = r9
    call function_48190                     
    stxdw [r6+0x10], r9                     
    stxdw [r6+0x8], r9                      
    stxdw [r6+0x0], r8                      
lbb_21864:
    exit                                    

function_21865:
    mov64 r7, r3                                    r7 = r3
    mov64 r8, r2                                    r8 = r2
    mov64 r6, r1                                    r6 = r1
    jeq r8, 0, lbb_21879                            if r8 == (0 as i32 as i64 as u64) { pc += 10 }
    ldxdw r1, [r4+0x8]                      
    jeq r1, 0, lbb_21889                            if r1 == (0 as i32 as i64 as u64) { pc += 18 }
    ldxdw r2, [r4+0x10]                     
    jne r2, 0, lbb_21883                            if r2 != (0 as i32 as i64 as u64) { pc += 10 }
    jeq r7, 0, lbb_21899                            if r7 == (0 as i32 as i64 as u64) { pc += 25 }
    mov64 r1, r7                                    r1 = r7
    mov64 r2, r8                                    r2 = r8
    call function_21359                     
    jeq r0, 0, lbb_21895                            if r0 == (0 as i32 as i64 as u64) { pc += 17 }
    ja lbb_21901                                    if true { pc += 22 }
lbb_21879:
    stxdw [r6+0x10], r7                     
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    stxdw [r6+0x8], r1                      
    ja lbb_21897                                    if true { pc += 14 }
lbb_21883:
    ldxdw r1, [r4+0x0]                      
    mov64 r3, r8                                    r3 = r8
    mov64 r4, r7                                    r4 = r7
    call function_21386                     
    jeq r0, 0, lbb_21895                            if r0 == (0 as i32 as i64 as u64) { pc += 7 }
    ja lbb_21901                                    if true { pc += 12 }
lbb_21889:
    jeq r7, 0, lbb_21899                            if r7 == (0 as i32 as i64 as u64) { pc += 9 }
    mov64 r1, r7                                    r1 = r7
    mov64 r2, r8                                    r2 = r8
    call function_21359                     
    jeq r0, 0, lbb_21895                            if r0 == (0 as i32 as i64 as u64) { pc += 1 }
    ja lbb_21901                                    if true { pc += 6 }
lbb_21895:
    stxdw [r6+0x10], r7                     
    stxdw [r6+0x8], r8                      
lbb_21897:
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    ja lbb_21904                                    if true { pc += 5 }
lbb_21899:
    mov64 r7, 0                                     r7 = 0 as i32 as i64 as u64
    mov64 r0, r8                                    r0 = r8
lbb_21901:
    stxdw [r6+0x10], r7                     
    stxdw [r6+0x8], r0                      
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
lbb_21904:
    stxdw [r6+0x0], r1                      
    exit                                    

function_21906:
    mov64 r6, r1                                    r6 = r1
    add64 r2, 1                                     r2 += 1   ///  r2 = r2.wrapping_add(1 as i32 as i64 as u64)
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    jeq r2, 0, lbb_21911                            if r2 == (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
lbb_21911:
    and64 r1, 1                                     r1 &= 1   ///  r1 = r1.and(1)
    jne r1, 0, lbb_21953                            if r1 != (0 as i32 as i64 as u64) { pc += 40 }
    ldxdw r1, [r6+0x8]                      
    mov64 r7, r1                                    r7 = r1
    lsh64 r7, 1                                     r7 <<= 1   ///  r7 = r7.wrapping_shl(1)
    jgt r7, r2, lbb_21918                           if r7 > r2 { pc += 1 }
    mov64 r7, r2                                    r7 = r2
lbb_21918:
    jgt r7, 4, lbb_21920                            if r7 > (4 as i32 as i64 as u64) { pc += 1 }
    mov64 r7, 4                                     r7 = 4 as i32 as i64 as u64
lbb_21920:
    mov64 r2, 1                                     r2 = 1 as i32 as i64 as u64
    lddw r3, 0x333333333333334                      r3 load str located at 230584300921369396
    jgt r3, r7, lbb_21925                           if r3 > r7 { pc += 1 }
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
lbb_21925:
    mov64 r3, r7                                    r3 = r7
    mul64 r3, 40                                    r3 *= 40   ///  r3 = r3.wrapping_mul(40 as u64)
    lsh64 r2, 2                                     r2 <<= 2   ///  r2 = r2.wrapping_shl(2)
    jne r1, 0, lbb_21932                            if r1 != (0 as i32 as i64 as u64) { pc += 3 }
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    stxdw [r10-0x10], r1                    
    ja lbb_21938                                    if true { pc += 6 }
lbb_21932:
    ldxdw r4, [r6+0x0]                      
    mul64 r1, 40                                    r1 *= 40   ///  r1 = r1.wrapping_mul(40 as u64)
    stxdw [r10-0x8], r1                     
    mov64 r1, 4                                     r1 = 4 as i32 as i64 as u64
    stxdw [r10-0x10], r1                    
    stxdw [r10-0x18], r4                    
lbb_21938:
    mov64 r1, r10                                   r1 = r10
    add64 r1, -48                                   r1 += -48   ///  r1 = r1.wrapping_add(-48 as i32 as i64 as u64)
    mov64 r4, r10                                   r4 = r10
    add64 r4, -24                                   r4 += -24   ///  r4 = r4.wrapping_add(-24 as i32 as i64 as u64)
    call function_21865                     
    ldxdw r1, [r10-0x28]                    
    ldxdw r2, [r10-0x30]                    
    jne r2, 0, lbb_21949                            if r2 != (0 as i32 as i64 as u64) { pc += 3 }
    stxdw [r6+0x8], r7                      
    stxdw [r6+0x0], r1                      
lbb_21948:
    exit                                    
lbb_21949:
    lddw r2, 0x8000000000000001                     r2 load str located at -9223372036854775807
    jeq r1, r2, lbb_21948                           if r1 == r2 { pc += -4 }
    jne r1, 0, lbb_21955                            if r1 != (0 as i32 as i64 as u64) { pc += 2 }
lbb_21953:
    call function_43383                     
    syscall [invalid]                       
lbb_21955:
    ldxdw r2, [r10-0x20]                    
    call function_43400                     
    syscall [invalid]                       
    mov64 r3, r2                                    r3 = r2
    ldxdw r2, [r1+0x10]                     
    ldxdw r1, [r1+0x0]                      
    call function_46428                     
    exit                                    

function_21963:
    mov64 r7, r3                                    r7 = r3
    mov64 r8, r2                                    r8 = r2
    mov64 r6, r1                                    r6 = r1
    mov64 r1, r10                                   r1 = r10
    add64 r1, -72                                   r1 += -72   ///  r1 = r1.wrapping_add(-72 as i32 as i64 as u64)
    lddw r2, 0x100061022 --> b"\x8b\xbc\x13%\x8a\x81u\xd1\xc8\xf9\x18\xd1\x1du\xbb\x9d\xf3\xa2&\x0b\x8c\…        r2 load str located at 4295364642
    lddw r4, 0x100061062 --> b"Invalid dex program ID for coin managed token account derivation"        r4 load str located at 4295364706
    mov64 r5, 64                                    r5 = 64 as i32 as i64 as u64
    call function_30095                     
    ldxb r9, [r10-0x48]                     
    jne r9, 56, lbb_21992                           if r9 != (56 as i32 as i64 as u64) { pc += 16 }
    mov64 r1, 32                                    r1 = 32 as i32 as i64 as u64
    stxdw [r10-0x30], r1                    
    stxdw [r10-0x38], r8                    
    mov64 r1, 15                                    r1 = 15 as i32 as i64 as u64
    stxdw [r10-0x40], r1                    
    lddw r1, 0x1000610a2 --> b"coin_managed_taInvalid dex program ID for coin man"        r1 load str located at 4295364770
    stxdw [r10-0x48], r1                    
    mov64 r1, r6                                    r1 = r6
    add64 r1, 1                                     r1 += 1   ///  r1 = r1.wrapping_add(1 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -72                                   r2 += -72   ///  r2 = r2.wrapping_add(-72 as i32 as i64 as u64)
    mov64 r3, 2                                     r3 = 2 as i32 as i64 as u64
    mov64 r4, r7                                    r4 = r7
    call function_40843                     
    ja lbb_21998                                    if true { pc += 6 }
lbb_21992:
    mov64 r1, r6                                    r1 = r6
    add64 r1, 1                                     r1 += 1   ///  r1 = r1.wrapping_add(1 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -71                                   r2 += -71   ///  r2 = r2.wrapping_add(-71 as i32 as i64 as u64)
    mov64 r3, 71                                    r3 = 71 as i32 as i64 as u64
    call function_48190                     
lbb_21998:
    stxb [r6+0x0], r9                       
    exit                                    

function_22000:
    mov64 r8, r5                                    r8 = r5
    mov64 r7, r4                                    r7 = r4
    stxdw [r10-0x120], r3                   
    stxdw [r10-0x128], r2                   
    mov64 r9, r1                                    r9 = r1
    mov64 r1, r10                                   r1 = r10
    add64 r1, -216                                  r1 += -216   ///  r1 = r1.wrapping_add(-216 as i32 as i64 as u64)
    lddw r2, 0x100061022 --> b"\x8b\xbc\x13%\x8a\x81u\xd1\xc8\xf9\x18\xd1\x1du\xbb\x9d\xf3\xa2&\x0b\x8c\…        r2 load str located at 4295364642
    mov64 r3, r8                                    r3 = r8
    lddw r4, 0x1000610b1 --> b"Invalid dex program ID for coin managed token account verification"        r4 load str located at 4295364785
    mov64 r5, 66                                    r5 = 66 as i32 as i64 as u64
    call function_30095                     
    ldxb r6, [r10-0xd8]                     
    jne r6, 56, lbb_22071                           if r6 != (56 as i32 as i64 as u64) { pc += 55 }
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    stxdw [r10-0x40], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -56                                   r1 += -56   ///  r1 = r1.wrapping_add(-56 as i32 as i64 as u64)
    stxdw [r10-0x48], r1                    
    mov64 r1, 32                                    r1 = 32 as i32 as i64 as u64
    stxdw [r10-0x50], r1                    
    stxdw [r10-0x58], r7                    
    mov64 r1, 15                                    r1 = 15 as i32 as i64 as u64
    stxdw [r10-0x60], r1                    
    lddw r1, 0x1000610a2 --> b"coin_managed_taInvalid dex program ID for coin man"        r1 load str located at 4295364770
    stxdw [r10-0x68], r1                    
    ldxdw r1, [r10-0x120]                   
    stxb [r10-0x38], r1                     
    mov64 r7, r10                                   r7 = r10
    add64 r7, -144                                  r7 += -144   ///  r7 = r7.wrapping_add(-144 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -104                                  r2 += -104   ///  r2 = r2.wrapping_add(-104 as i32 as i64 as u64)
    mov64 r1, r7                                    r1 = r7
    mov64 r3, 3                                     r3 = 3 as i32 as i64 as u64
    mov64 r4, r8                                    r4 = r8
    call function_40888                     
    lddw r1, 0x1000610f3 --> b"Could not derive Coin Managed Token Account PDA fr"        r1 load str located at 4295364851
    stxdw [r10-0x1000], r1                  
    mov64 r1, 67                                    r1 = 67 as i32 as i64 as u64
    stxdw [r10-0xff8], r1                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -216                                  r1 += -216   ///  r1 = r1.wrapping_add(-216 as i32 as i64 as u64)
    mov64 r5, r10                                   r5 = r10
    mov64 r2, r7                                    r2 = r7
    lddw r3, 0x1000610f3 --> b"Could not derive Coin Managed Token Account PDA from seeds and bump"        r3 load str located at 4295364851
    mov64 r4, 67                                    r4 = 67 as i32 as i64 as u64
    call function_25690                     
    ldxb r7, [r10-0xd8]                     
    jeq r7, 56, lbb_22055                           if r7 == (56 as i32 as i64 as u64) { pc += 1 }
    ja lbb_22079                                    if true { pc += 24 }
lbb_22055:
    ldxdw r1, [r10-0xcf]                    
    stxdw [r10-0xf0], r1                    
    stxdw [r10-0x110], r1                   
    ldxdw r1, [r10-0xc7]                    
    stxdw [r10-0xe8], r1                    
    stxdw [r10-0x108], r1                   
    ldxdw r1, [r10-0xbf]                    
    stxdw [r10-0xe0], r1                    
    stxdw [r10-0x100], r1                   
    ldxdw r1, [r10-0xd7]                    
    stxdw [r10-0x118], r1                   
    ldxdw r6, [r10-0x128]                   
    ldxdw r2, [r6+0x0]                      
    jeq r2, r1, lbb_22103                           if r2 == r1 { pc += 34 }
lbb_22069:
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    ja lbb_22113                                    if true { pc += 42 }
lbb_22071:
    mov64 r1, r9                                    r1 = r9
    add64 r1, 1                                     r1 += 1   ///  r1 = r1.wrapping_add(1 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -215                                  r2 += -215   ///  r2 = r2.wrapping_add(-215 as i32 as i64 as u64)
    mov64 r3, 71                                    r3 = 71 as i32 as i64 as u64
    call function_48190                     
    stxb [r9+0x0], r6                       
    ja lbb_22196                                    if true { pc += 117 }
lbb_22079:
    ldxdw r1, [r10-0xbf]                    
    stxdw [r10-0xe0], r1                    
    ldxdw r1, [r10-0xc7]                    
    stxdw [r10-0xe8], r1                    
    ldxdw r1, [r10-0xcf]                    
    stxdw [r10-0xf0], r1                    
    ldxdw r1, [r10-0xd7]                    
    stxdw [r10-0xf8], r1                    
    mov64 r1, r9                                    r1 = r9
    add64 r1, 33                                    r1 += 33   ///  r1 = r1.wrapping_add(33 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -183                                  r2 += -183   ///  r2 = r2.wrapping_add(-183 as i32 as i64 as u64)
    mov64 r3, 39                                    r3 = 39 as i32 as i64 as u64
    call function_48190                     
    ldxdw r1, [r10-0xe0]                    
    stxdw [r9+0x19], r1                     
    ldxdw r1, [r10-0xe8]                    
    stxdw [r9+0x11], r1                     
    ldxdw r1, [r10-0xf0]                    
    stxdw [r9+0x9], r1                      
    ldxdw r1, [r10-0xf8]                    
    stxdw [r9+0x1], r1                      
    stxb [r9+0x0], r7                       
    ja lbb_22196                                    if true { pc += 93 }
lbb_22103:
    ldxdw r1, [r6+0x8]                      
    ldxdw r2, [r10-0x110]                   
    jne r1, r2, lbb_22069                           if r1 != r2 { pc += -37 }
    ldxdw r1, [r6+0x10]                     
    ldxdw r2, [r10-0x108]                   
    jne r1, r2, lbb_22069                           if r1 != r2 { pc += -40 }
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    ldxdw r2, [r6+0x18]                     
    ldxdw r3, [r10-0x100]                   
    jne r2, r3, lbb_22069                           if r2 != r3 { pc += -44 }
lbb_22113:
    mov64 r2, 40                                    r2 = 40 as i32 as i64 as u64
    stxdw [r10-0xf0], r2                    
    lddw r2, 0x100061136 --> b"Coin Managed Token Account PDA mismatch.sdk/src/co"        r2 load str located at 4295364918
    stxdw [r10-0xf8], r2                    
    jeq r1, 0, lbb_22194                            if r1 == (0 as i32 as i64 as u64) { pc += 75 }
    lddw r1, 0x100065830 --> b"\x00\x00\x00\x00^\x11\x06\x00\x1b\x00\x00\x00\x00\x00\x00\x00C\x00\x00\x0…        r1 load str located at 4295383088
    stxdw [r10-0x38], r1                    
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    stxdw [r10-0xb8], r1                    
    lddw r1, 0x100065a98 --> b"\x00\x00\x00\x00\xe8\x0e\x06\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\…        r1 load str located at 4295383704
    stxdw [r10-0xd8], r1                    
    mov64 r1, 2                                     r1 = 2 as i32 as i64 as u64
    stxdw [r10-0xd0], r1                    
    stxdw [r10-0xc0], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -104                                  r1 += -104   ///  r1 = r1.wrapping_add(-104 as i32 as i64 as u64)
    stxdw [r10-0xc8], r1                    
    lddw r1, 0x10002a248 --> b"y\x11\x00\x00\x00\x00\x00\x00\x85\x10\x00\x00%X\x00\x00\x95\x00\x00\x00\x…        r1 load str located at 4295139912
    stxdw [r10-0x50], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -56                                   r1 += -56   ///  r1 = r1.wrapping_add(-56 as i32 as i64 as u64)
    stxdw [r10-0x58], r1                    
    lddw r1, 0x10002a388 --> b"\xbf#\x00\x00\x00\x00\x00\x00y\x12\x08\x00\x00\x00\x00\x00y\x11\x00\x00\x…        r1 load str located at 4295140232
    stxdw [r10-0x60], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -248                                  r1 += -248   ///  r1 = r1.wrapping_add(-248 as i32 as i64 as u64)
    stxdw [r10-0x68], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -144                                  r1 += -144   ///  r1 = r1.wrapping_add(-144 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -216                                  r2 += -216   ///  r2 = r2.wrapping_add(-216 as i32 as i64 as u64)
    call function_43415                     
    ldxdw r7, [r10-0x88]                    
    ldxdw r8, [r10-0x90]                    
    ldxdw r2, [r10-0x80]                    
    mov64 r1, r8                                    r1 = r8
    syscall [invalid]                       
    jeq r7, 0, lbb_22160                            if r7 == (0 as i32 as i64 as u64) { pc += 4 }
    mov64 r1, r8                                    r1 = r8
    mov64 r2, r7                                    r2 = r7
    mov64 r3, 1                                     r3 = 1 as i32 as i64 as u64
    call function_21385                     
lbb_22160:
    mov64 r1, 32                                    r1 = 32 as i32 as i64 as u64
    mov64 r2, 1                                     r2 = 1 as i32 as i64 as u64
    call function_21359                     
    mov64 r8, r0                                    r8 = r0
    jne r8, 0, lbb_22169                            if r8 != (0 as i32 as i64 as u64) { pc += 4 }
lbb_22165:
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    mov64 r2, 32                                    r2 = 32 as i32 as i64 as u64
    call function_43400                     
    syscall [invalid]                       
lbb_22169:
    ldxdw r1, [r6+0x18]                     
    stxdw [r8+0x18], r1                     
    ldxdw r1, [r6+0x10]                     
    stxdw [r8+0x10], r1                     
    ldxdw r1, [r6+0x8]                      
    stxdw [r8+0x8], r1                      
    ldxdw r1, [r6+0x0]                      
    stxdw [r8+0x0], r1                      
    mov64 r1, 32                                    r1 = 32 as i32 as i64 as u64
    mov64 r2, 1                                     r2 = 1 as i32 as i64 as u64
    call function_21359                     
    jne r0, 0, lbb_22182                            if r0 != (0 as i32 as i64 as u64) { pc += 1 }
    ja lbb_22165                                    if true { pc += -17 }
lbb_22182:
    ldxdw r1, [r10-0x100]                   
    stxdw [r0+0x18], r1                     
    ldxdw r1, [r10-0x108]                   
    stxdw [r0+0x10], r1                     
    ldxdw r1, [r10-0x110]                   
    stxdw [r0+0x8], r1                      
    ldxdw r1, [r10-0x118]                   
    stxdw [r0+0x0], r1                      
    stxdw [r9+0x10], r0                     
    stxdw [r9+0x8], r8                      
    mov64 r1, 8                                     r1 = 8 as i32 as i64 as u64
    ja lbb_22195                                    if true { pc += 1 }
lbb_22194:
    mov64 r1, 56                                    r1 = 56 as i32 as i64 as u64
lbb_22195:
    stxb [r9+0x0], r1                       
lbb_22196:
    exit                                    

function_22197:
    mov64 r7, r4                                    r7 = r4
    mov64 r9, r3                                    r9 = r3
    stxdw [r10-0x50], r2                    
    mov64 r6, r1                                    r6 = r1
    mov64 r1, r10                                   r1 = r10
    add64 r1, -72                                   r1 += -72   ///  r1 = r1.wrapping_add(-72 as i32 as i64 as u64)
    lddw r2, 0x100061022 --> b"\x8b\xbc\x13%\x8a\x81u\xd1\xc8\xf9\x18\xd1\x1du\xbb\x9d\xf3\xa2&\x0b\x8c\…        r2 load str located at 4295364642
    mov64 r3, r7                                    r3 = r7
    lddw r4, 0x100061179 --> b"Invalid dex program ID for coin derivation"        r4 load str located at 4295364985
    mov64 r5, 42                                    r5 = 42 as i32 as i64 as u64
    call function_30095                     
    ldxb r8, [r10-0x48]                     
    jne r8, 56, lbb_22231                           if r8 != (56 as i32 as i64 as u64) { pc += 19 }
    stxdw [r10-0x28], r9                    
    mov64 r1, 32                                    r1 = 32 as i32 as i64 as u64
    stxdw [r10-0x20], r1                    
    stxdw [r10-0x30], r1                    
    ldxdw r1, [r10-0x50]                    
    stxdw [r10-0x38], r1                    
    mov64 r1, 4                                     r1 = 4 as i32 as i64 as u64
    stxdw [r10-0x40], r1                    
    lddw r1, 0x10005fbb0 --> b"coin\x1c\x00\x00\x00GoodKindkindbids != Some <= x1e-true to No"        r1 load str located at 4295359408
    stxdw [r10-0x48], r1                    
    mov64 r1, r6                                    r1 = r6
    add64 r1, 1                                     r1 += 1   ///  r1 = r1.wrapping_add(1 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -72                                   r2 += -72   ///  r2 = r2.wrapping_add(-72 as i32 as i64 as u64)
    mov64 r3, 3                                     r3 = 3 as i32 as i64 as u64
    mov64 r4, r7                                    r4 = r7
    call function_40843                     
    ja lbb_22237                                    if true { pc += 6 }
lbb_22231:
    mov64 r1, r6                                    r1 = r6
    add64 r1, 1                                     r1 += 1   ///  r1 = r1.wrapping_add(1 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -71                                   r2 += -71   ///  r2 = r2.wrapping_add(-71 as i32 as i64 as u64)
    mov64 r3, 71                                    r3 = 71 as i32 as i64 as u64
    call function_48190                     
lbb_22237:
    stxb [r6+0x0], r8                       
    exit                                    

function_22239:
    mov64 r8, r5                                    r8 = r5
    stxdw [r10-0x130], r4                   
    stxdw [r10-0x138], r3                   
    stxdw [r10-0x140], r2                   
    mov64 r9, r1                                    r9 = r1
    ldxdw r7, [r8-0xff8]                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -232                                  r1 += -232   ///  r1 = r1.wrapping_add(-232 as i32 as i64 as u64)
    lddw r2, 0x100061022 --> b"\x8b\xbc\x13%\x8a\x81u\xd1\xc8\xf9\x18\xd1\x1du\xbb\x9d\xf3\xa2&\x0b\x8c\…        r2 load str located at 4295364642
    mov64 r3, r7                                    r3 = r7
    lddw r4, 0x1000611a3 --> b"Invalid dex program ID for coin verification"        r4 load str located at 4295365027
    mov64 r5, 44                                    r5 = 44 as i32 as i64 as u64
    call function_30095                     
    ldxb r6, [r10-0xe8]                     
    jne r6, 56, lbb_22318                           if r6 != (56 as i32 as i64 as u64) { pc += 62 }
    stxdw [r10-0x148], r9                   
    ldxdw r9, [r8-0x1000]                   
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    stxdw [r10-0x40], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -56                                   r1 += -56   ///  r1 = r1.wrapping_add(-56 as i32 as i64 as u64)
    stxdw [r10-0x48], r1                    
    stxdw [r10-0x58], r9                    
    mov64 r1, 32                                    r1 = 32 as i32 as i64 as u64
    stxdw [r10-0x50], r1                    
    stxdw [r10-0x60], r1                    
    ldxdw r6, [r10-0x130]                   
    stxdw [r10-0x68], r6                    
    lddw r1, 0x10005fbb0 --> b"coin\x1c\x00\x00\x00GoodKindkindbids != Some <= x1e-true to No"        r1 load str located at 4295359408
    stxdw [r10-0x78], r1                    
    ldxdw r1, [r10-0x138]                   
    stxb [r10-0x38], r1                     
    mov64 r1, 4                                     r1 = 4 as i32 as i64 as u64
    stxdw [r10-0x70], r1                    
    mov64 r8, r10                                   r8 = r10
    add64 r8, -160                                  r8 += -160   ///  r8 = r8.wrapping_add(-160 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -120                                  r2 += -120   ///  r2 = r2.wrapping_add(-120 as i32 as i64 as u64)
    mov64 r1, r8                                    r1 = r8
    mov64 r3, 4                                     r3 = 4 as i32 as i64 as u64
    mov64 r4, r7                                    r4 = r7
    call function_40888                     
    lddw r1, 0x1000611cf --> b"Could not derive Coin PDA from seeds and bumpCoin "        r1 load str located at 4295365071
    stxdw [r10-0x1000], r1                  
    mov64 r1, 45                                    r1 = 45 as i32 as i64 as u64
    stxdw [r10-0xff8], r1                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -232                                  r1 += -232   ///  r1 = r1.wrapping_add(-232 as i32 as i64 as u64)
    mov64 r5, r10                                   r5 = r10
    mov64 r2, r8                                    r2 = r8
    lddw r3, 0x1000611cf --> b"Could not derive Coin PDA from seeds and bump"        r3 load str located at 4295365071
    mov64 r4, 45                                    r4 = 45 as i32 as i64 as u64
    call function_25690                     
    ldxb r7, [r10-0xe8]                     
    jeq r7, 56, lbb_22300                           if r7 == (56 as i32 as i64 as u64) { pc += 1 }
    ja lbb_22326                                    if true { pc += 26 }
lbb_22300:
    stxdw [r10-0x138], r9                   
    ldxdw r1, [r10-0xdf]                    
    stxdw [r10-0x100], r1                   
    stxdw [r10-0x120], r1                   
    ldxdw r1, [r10-0xd7]                    
    stxdw [r10-0xf8], r1                    
    stxdw [r10-0x118], r1                   
    ldxdw r1, [r10-0xcf]                    
    stxdw [r10-0xf0], r1                    
    stxdw [r10-0x110], r1                   
    ldxdw r1, [r10-0xe7]                    
    stxdw [r10-0x128], r1                   
    ldxdw r3, [r10-0x140]                   
    ldxdw r2, [r3+0x0]                      
    ldxdw r6, [r10-0x148]                   
    jeq r2, r1, lbb_22351                           if r2 == r1 { pc += 35 }
lbb_22316:
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    ja lbb_22361                                    if true { pc += 43 }
lbb_22318:
    mov64 r1, r9                                    r1 = r9
    add64 r1, 1                                     r1 += 1   ///  r1 = r1.wrapping_add(1 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -231                                  r2 += -231   ///  r2 = r2.wrapping_add(-231 as i32 as i64 as u64)
    mov64 r3, 71                                    r3 = 71 as i32 as i64 as u64
    call function_48190                     
    stxb [r9+0x0], r6                       
    ja lbb_22477                                    if true { pc += 151 }
lbb_22326:
    ldxdw r1, [r10-0xcf]                    
    stxdw [r10-0xf0], r1                    
    ldxdw r1, [r10-0xd7]                    
    stxdw [r10-0xf8], r1                    
    ldxdw r1, [r10-0xdf]                    
    stxdw [r10-0x100], r1                   
    ldxdw r1, [r10-0xe7]                    
    stxdw [r10-0x108], r1                   
    ldxdw r6, [r10-0x148]                   
    mov64 r1, r6                                    r1 = r6
    add64 r1, 33                                    r1 += 33   ///  r1 = r1.wrapping_add(33 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -199                                  r2 += -199   ///  r2 = r2.wrapping_add(-199 as i32 as i64 as u64)
    mov64 r3, 39                                    r3 = 39 as i32 as i64 as u64
    call function_48190                     
    ldxdw r1, [r10-0xf0]                    
    stxdw [r6+0x19], r1                     
    ldxdw r1, [r10-0xf8]                    
    stxdw [r6+0x11], r1                     
    ldxdw r1, [r10-0x100]                   
    stxdw [r6+0x9], r1                      
    ldxdw r1, [r10-0x108]                   
    stxdw [r6+0x1], r1                      
    stxb [r6+0x0], r7                       
    ja lbb_22477                                    if true { pc += 126 }
lbb_22351:
    ldxdw r1, [r3+0x8]                      
    ldxdw r2, [r10-0x120]                   
    jne r1, r2, lbb_22316                           if r1 != r2 { pc += -38 }
    ldxdw r1, [r3+0x10]                     
    ldxdw r2, [r10-0x118]                   
    jne r1, r2, lbb_22316                           if r1 != r2 { pc += -41 }
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    ldxdw r2, [r3+0x18]                     
    ldxdw r3, [r10-0x110]                   
    jne r2, r3, lbb_22316                           if r2 != r3 { pc += -45 }
lbb_22361:
    mov64 r2, 85                                    r2 = 85 as i32 as i64 as u64
    stxdw [r10-0x100], r2                   
    lddw r2, 0x1000611fc --> b"Coin PDA mismatch: The provided Coin PDA does not "        r2 load str located at 4295365116
    stxdw [r10-0x108], r2                   
    jeq r1, 0, lbb_22475                            if r1 == (0 as i32 as i64 as u64) { pc += 108 }
    lddw r1, 0x100065848 --> b"\x00\x00\x00\x00^\x11\x06\x00\x1b\x00\x00\x00\x00\x00\x00\x00m\x00\x00\x0…        r1 load str located at 4295383112
    stxdw [r10-0x38], r1                    
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    stxdw [r10-0xc8], r1                    
    lddw r1, 0x100065a98 --> b"\x00\x00\x00\x00\xe8\x0e\x06\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\…        r1 load str located at 4295383704
    stxdw [r10-0xe8], r1                    
    mov64 r1, 2                                     r1 = 2 as i32 as i64 as u64
    stxdw [r10-0xe0], r1                    
    stxdw [r10-0xd0], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -120                                  r1 += -120   ///  r1 = r1.wrapping_add(-120 as i32 as i64 as u64)
    stxdw [r10-0xd8], r1                    
    lddw r1, 0x10002a248 --> b"y\x11\x00\x00\x00\x00\x00\x00\x85\x10\x00\x00%X\x00\x00\x95\x00\x00\x00\x…        r1 load str located at 4295139912
    stxdw [r10-0x60], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -56                                   r1 += -56   ///  r1 = r1.wrapping_add(-56 as i32 as i64 as u64)
    stxdw [r10-0x68], r1                    
    lddw r1, 0x10002a388 --> b"\xbf#\x00\x00\x00\x00\x00\x00y\x12\x08\x00\x00\x00\x00\x00y\x11\x00\x00\x…        r1 load str located at 4295140232
    stxdw [r10-0x70], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -264                                  r1 += -264   ///  r1 = r1.wrapping_add(-264 as i32 as i64 as u64)
    stxdw [r10-0x78], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -160                                  r1 += -160   ///  r1 = r1.wrapping_add(-160 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -232                                  r2 += -232   ///  r2 = r2.wrapping_add(-232 as i32 as i64 as u64)
    call function_43415                     
    ldxdw r7, [r10-0x98]                    
    ldxdw r8, [r10-0xa0]                    
    ldxdw r2, [r10-0x90]                    
    mov64 r1, r8                                    r1 = r8
    syscall [invalid]                       
    jeq r7, 0, lbb_22408                            if r7 == (0 as i32 as i64 as u64) { pc += 4 }
    mov64 r1, r8                                    r1 = r8
    mov64 r2, r7                                    r2 = r7
    mov64 r3, 1                                     r3 = 1 as i32 as i64 as u64
    call function_21385                     
lbb_22408:
    mov64 r1, 32                                    r1 = 32 as i32 as i64 as u64
    mov64 r2, 1                                     r2 = 1 as i32 as i64 as u64
    call function_21359                     
    mov64 r9, r0                                    r9 = r0
    jne r9, 0, lbb_22417                            if r9 != (0 as i32 as i64 as u64) { pc += 4 }
lbb_22413:
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    mov64 r2, 32                                    r2 = 32 as i32 as i64 as u64
    call function_43400                     
    syscall [invalid]                       
lbb_22417:
    ldxdw r2, [r10-0x138]                   
    ldxdw r1, [r2+0x18]                     
    stxdw [r9+0x18], r1                     
    ldxdw r1, [r2+0x10]                     
    stxdw [r9+0x10], r1                     
    ldxdw r1, [r2+0x8]                      
    stxdw [r9+0x8], r1                      
    ldxdw r1, [r2+0x0]                      
    stxdw [r9+0x0], r1                      
    mov64 r1, 32                                    r1 = 32 as i32 as i64 as u64
    mov64 r2, 1                                     r2 = 1 as i32 as i64 as u64
    call function_21359                     
    mov64 r7, r0                                    r7 = r0
    jne r7, 0, lbb_22432                            if r7 != (0 as i32 as i64 as u64) { pc += 1 }
    ja lbb_22413                                    if true { pc += -19 }
lbb_22432:
    ldxdw r2, [r10-0x130]                   
    ldxdw r1, [r2+0x18]                     
    stxdw [r7+0x18], r1                     
    ldxdw r1, [r2+0x10]                     
    stxdw [r7+0x10], r1                     
    ldxdw r1, [r2+0x8]                      
    stxdw [r7+0x8], r1                      
    ldxdw r1, [r2+0x0]                      
    stxdw [r7+0x0], r1                      
    mov64 r1, 32                                    r1 = 32 as i32 as i64 as u64
    mov64 r2, 1                                     r2 = 1 as i32 as i64 as u64
    call function_21359                     
    mov64 r8, r0                                    r8 = r0
    jne r8, 0, lbb_22447                            if r8 != (0 as i32 as i64 as u64) { pc += 1 }
    ja lbb_22413                                    if true { pc += -34 }
lbb_22447:
    ldxdw r2, [r10-0x140]                   
    ldxdw r1, [r2+0x18]                     
    stxdw [r8+0x18], r1                     
    ldxdw r1, [r2+0x10]                     
    stxdw [r8+0x10], r1                     
    ldxdw r1, [r2+0x8]                      
    stxdw [r8+0x8], r1                      
    ldxdw r1, [r2+0x0]                      
    stxdw [r8+0x0], r1                      
    mov64 r1, 32                                    r1 = 32 as i32 as i64 as u64
    mov64 r2, 1                                     r2 = 1 as i32 as i64 as u64
    call function_21359                     
    jne r0, 0, lbb_22461                            if r0 != (0 as i32 as i64 as u64) { pc += 1 }
    ja lbb_22413                                    if true { pc += -48 }
lbb_22461:
    ldxdw r1, [r10-0x110]                   
    stxdw [r0+0x18], r1                     
    ldxdw r1, [r10-0x118]                   
    stxdw [r0+0x10], r1                     
    ldxdw r1, [r10-0x120]                   
    stxdw [r0+0x8], r1                      
    ldxdw r1, [r10-0x128]                   
    stxdw [r0+0x0], r1                      
    stxdw [r6+0x20], r0                     
    stxdw [r6+0x18], r8                     
    stxdw [r6+0x10], r9                     
    stxdw [r6+0x8], r7                      
    mov64 r1, 9                                     r1 = 9 as i32 as i64 as u64
    ja lbb_22476                                    if true { pc += 1 }
lbb_22475:
    mov64 r1, 56                                    r1 = 56 as i32 as i64 as u64
lbb_22476:
    stxb [r6+0x0], r1                       
lbb_22477:
    exit                                    

function_22478:
    mov64 r9, r3                                    r9 = r3
    mov64 r7, r2                                    r7 = r2
    mov64 r6, r1                                    r6 = r1
    mov64 r8, r7                                    r8 = r7
    add64 r8, 952                                   r8 += 952   ///  r8 = r8.wrapping_add(952 as i32 as i64 as u64)
    ldxdw r1, [r9+0x0]                      
    ldxdw r2, [r8+0x0]                      
    jne r2, r1, lbb_22515                           if r2 != r1 { pc += 29 }
    ldxdw r1, [r9+0x8]                      
    ldxdw r2, [r8+0x8]                      
    jne r2, r1, lbb_22515                           if r2 != r1 { pc += 26 }
    ldxdw r1, [r9+0x10]                     
    ldxdw r2, [r8+0x10]                     
    jne r2, r1, lbb_22515                           if r2 != r1 { pc += 23 }
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    ldxdw r2, [r9+0x18]                     
    ldxdw r3, [r8+0x18]                     
    jne r3, r2, lbb_22515                           if r3 != r2 { pc += 19 }
lbb_22496:
    jne r1, 0, lbb_22551                            if r1 != (0 as i32 as i64 as u64) { pc += 54 }
    add64 r7, 984                                   r7 += 984   ///  r7 = r7.wrapping_add(984 as i32 as i64 as u64)
    ldxdw r1, [r4+0x0]                      
    ldxdw r2, [r7+0x0]                      
    jne r2, r1, lbb_22517                           if r2 != r1 { pc += 16 }
    ldxdw r1, [r4+0x8]                      
    ldxdw r2, [r7+0x8]                      
    jne r2, r1, lbb_22517                           if r2 != r1 { pc += 13 }
    ldxdw r1, [r4+0x10]                     
    ldxdw r2, [r7+0x10]                     
    jne r2, r1, lbb_22517                           if r2 != r1 { pc += 10 }
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    ldxdw r2, [r4+0x18]                     
    ldxdw r3, [r7+0x18]                     
    jne r3, r2, lbb_22517                           if r3 != r2 { pc += 6 }
    jeq r1, 0, lbb_22513                            if r1 == (0 as i32 as i64 as u64) { pc += 1 }
    ja lbb_22519                                    if true { pc += 6 }
lbb_22513:
    mov64 r1, 56                                    r1 = 56 as i32 as i64 as u64
    ja lbb_22584                                    if true { pc += 69 }
lbb_22515:
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    ja lbb_22496                                    if true { pc += -21 }
lbb_22517:
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    jeq r1, 0, lbb_22513                            if r1 == (0 as i32 as i64 as u64) { pc += -6 }
lbb_22519:
    mov64 r8, r4                                    r8 = r4
    mov64 r1, 32                                    r1 = 32 as i32 as i64 as u64
    mov64 r2, 1                                     r2 = 1 as i32 as i64 as u64
    call function_21359                     
    mov64 r9, r0                                    r9 = r0
    jne r9, 0, lbb_22526                            if r9 != (0 as i32 as i64 as u64) { pc += 1 }
    ja lbb_22556                                    if true { pc += 30 }
lbb_22526:
    ldxdw r1, [r7+0x18]                     
    stxdw [r9+0x18], r1                     
    ldxdw r1, [r7+0x10]                     
    stxdw [r9+0x10], r1                     
    ldxdw r1, [r7+0x8]                      
    stxdw [r9+0x8], r1                      
    ldxdw r1, [r7+0x0]                      
    stxdw [r9+0x0], r1                      
    mov64 r1, 32                                    r1 = 32 as i32 as i64 as u64
    mov64 r2, 1                                     r2 = 1 as i32 as i64 as u64
    call function_21359                     
    jne r0, 0, lbb_22539                            if r0 != (0 as i32 as i64 as u64) { pc += 1 }
    ja lbb_22556                                    if true { pc += 17 }
lbb_22539:
    ldxdw r1, [r8+0x18]                     
    stxdw [r0+0x18], r1                     
    ldxdw r1, [r8+0x10]                     
    stxdw [r0+0x10], r1                     
    ldxdw r1, [r8+0x8]                      
    stxdw [r0+0x8], r1                      
    ldxdw r1, [r8+0x0]                      
    stxdw [r0+0x0], r1                      
    stxdw [r6+0x10], r9                     
    stxdw [r6+0x8], r0                      
    mov64 r1, 8                                     r1 = 8 as i32 as i64 as u64
    ja lbb_22584                                    if true { pc += 33 }
lbb_22551:
    mov64 r1, 32                                    r1 = 32 as i32 as i64 as u64
    mov64 r2, 1                                     r2 = 1 as i32 as i64 as u64
    call function_21359                     
    mov64 r7, r0                                    r7 = r0
    jne r7, 0, lbb_22560                            if r7 != (0 as i32 as i64 as u64) { pc += 4 }
lbb_22556:
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    mov64 r2, 32                                    r2 = 32 as i32 as i64 as u64
    call function_43400                     
    syscall [invalid]                       
lbb_22560:
    ldxdw r1, [r8+0x18]                     
    stxdw [r7+0x18], r1                     
    ldxdw r1, [r8+0x10]                     
    stxdw [r7+0x10], r1                     
    ldxdw r1, [r8+0x8]                      
    stxdw [r7+0x8], r1                      
    ldxdw r1, [r8+0x0]                      
    stxdw [r7+0x0], r1                      
    mov64 r1, 32                                    r1 = 32 as i32 as i64 as u64
    mov64 r2, 1                                     r2 = 1 as i32 as i64 as u64
    call function_21359                     
    jne r0, 0, lbb_22573                            if r0 != (0 as i32 as i64 as u64) { pc += 1 }
    ja lbb_22556                                    if true { pc += -17 }
lbb_22573:
    ldxdw r1, [r9+0x18]                     
    stxdw [r0+0x18], r1                     
    ldxdw r1, [r9+0x10]                     
    stxdw [r0+0x10], r1                     
    ldxdw r1, [r9+0x8]                      
    stxdw [r0+0x8], r1                      
    ldxdw r1, [r9+0x0]                      
    stxdw [r0+0x0], r1                      
    stxdw [r6+0x10], r0                     
    stxdw [r6+0x8], r7                      
    mov64 r1, 2                                     r1 = 2 as i32 as i64 as u64
lbb_22584:
    stxb [r6+0x0], r1                       
    exit                                    

function_22586:
    mov64 r6, r1                                    r6 = r1
    ldxw r3, [r2+0x0]                       
    lsh64 r3, 32                                    r3 <<= 32   ///  r3 = r3.wrapping_shl(32)
    arsh64 r3, 32                                   r3 >>= 32 (signed)   ///  r3 = (r3 as i64).wrapping_shr(32)
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    jsgt r1, r3, lbb_22610                          if (r1 as i64) > (r3 as i64) { pc += 18 }
    ldxw r1, [r2+0x10]                      
    lsh64 r1, 32                                    r1 <<= 32   ///  r1 = r1.wrapping_shl(32)
    arsh64 r1, 32                                   r1 >>= 32 (signed)   ///  r1 = (r1 as i64).wrapping_shr(32)
    jsgt r1, -1, lbb_22597                          if (r1 as i64) > (-1 as i32 as i64) { pc += 1 }
    ja lbb_22645                                    if true { pc += 48 }
lbb_22597:
    ldxw r1, [r2+0x20]                      
    lsh64 r1, 32                                    r1 <<= 32   ///  r1 = r1.wrapping_shl(32)
    arsh64 r1, 32                                   r1 >>= 32 (signed)   ///  r1 = (r1 as i64).wrapping_shr(32)
    jsgt r1, -1, lbb_22602                          if (r1 as i64) > (-1 as i32 as i64) { pc += 1 }
    ja lbb_22682                                    if true { pc += 80 }
lbb_22602:
    ldxw r1, [r2+0x30]                      
    lsh64 r1, 32                                    r1 <<= 32   ///  r1 = r1.wrapping_shl(32)
    arsh64 r1, 32                                   r1 >>= 32 (signed)   ///  r1 = (r1 as i64).wrapping_shr(32)
    jsgt r1, -1, lbb_22607                          if (r1 as i64) > (-1 as i32 as i64) { pc += 1 }
    ja lbb_22719                                    if true { pc += 112 }
lbb_22607:
    mov64 r1, 56                                    r1 = 56 as i32 as i64 as u64
    stxb [r6+0x0], r1                       
    ja lbb_22756                                    if true { pc += 146 }
lbb_22610:
    stxdw [r10-0xe0], r1                    
    lddw r1, 0x100065890 --> b"\x00\x00\x00\x00\xa7\x12\x06\x00\x1a\x00\x00\x00\x00\x00\x00\x00\x00\x00\…        r1 load str located at 4295383184
    stxdw [r10-0x100], r1                   
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    stxdw [r10-0xf8], r1                    
    stxdw [r10-0xe8], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -208                                  r1 += -208   ///  r1 = r1.wrapping_add(-208 as i32 as i64 as u64)
    stxdw [r10-0xf0], r1                    
    lddw r1, 0x10003acf0 --> b"\xbf#\x00\x00\x00\x00\x00\x00\xb7\x02\x00\x00\x00\x00\x00\x00{*\xb0\xff\x…        r1 load str located at 4295208176
    stxdw [r10-0xc8], r1                    
    stxdw [r10-0xd0], r2                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -448                                  r1 += -448   ///  r1 = r1.wrapping_add(-448 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -256                                  r2 += -256   ///  r2 = r2.wrapping_add(-256 as i32 as i64 as u64)
    call function_43415                     
    ldxdw r1, [r10-0x1c0]                   
    stxdw [r10-0x1d8], r1                   
    ldxdw r1, [r10-0x1b8]                   
    stxdw [r10-0x1d0], r1                   
    ldxdw r1, [r10-0x1b0]                   
    stxdw [r10-0x1c8], r1                   
    mov64 r1, 29                                    r1 = 29 as i32 as i64 as u64
    stxb [r6+0x0], r1                       
    ldxdw r1, [r10-0x1df]                   
    stxdw [r6+0x1], r1                      
    ldxdw r1, [r10-0x1d7]                   
    stxdw [r6+0x9], r1                      
    ldxdw r1, [r10-0x1cf]                   
    stxdw [r6+0x11], r1                     
    ldxdw r1, [r10-0x1c8]                   
    ja lbb_22755                                    if true { pc += 110 }
lbb_22645:
    add64 r2, 16                                    r2 += 16   ///  r2 = r2.wrapping_add(16 as i32 as i64 as u64)
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    stxdw [r10-0xe0], r1                    
    lddw r1, 0x100065880 --> b"\x00\x00\x00\x00\x8d\x12\x06\x00\x1a\x00\x00\x00\x00\x00\x00\x00\x00\x00\…        r1 load str located at 4295383168
    stxdw [r10-0x100], r1                   
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    stxdw [r10-0xf8], r1                    
    stxdw [r10-0xe8], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -208                                  r1 += -208   ///  r1 = r1.wrapping_add(-208 as i32 as i64 as u64)
    stxdw [r10-0xf0], r1                    
    lddw r1, 0x10003acf0 --> b"\xbf#\x00\x00\x00\x00\x00\x00\xb7\x02\x00\x00\x00\x00\x00\x00{*\xb0\xff\x…        r1 load str located at 4295208176
    stxdw [r10-0xc8], r1                    
    stxdw [r10-0xd0], r2                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -392                                  r1 += -392   ///  r1 = r1.wrapping_add(-392 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -256                                  r2 += -256   ///  r2 = r2.wrapping_add(-256 as i32 as i64 as u64)
    call function_43415                     
    ldxdw r1, [r10-0x188]                   
    stxdw [r10-0x1a0], r1                   
    ldxdw r1, [r10-0x180]                   
    stxdw [r10-0x198], r1                   
    ldxdw r1, [r10-0x178]                   
    stxdw [r10-0x190], r1                   
    mov64 r1, 29                                    r1 = 29 as i32 as i64 as u64
    stxb [r6+0x0], r1                       
    ldxdw r1, [r10-0x1a7]                   
    stxdw [r6+0x1], r1                      
    ldxdw r1, [r10-0x19f]                   
    stxdw [r6+0x9], r1                      
    ldxdw r1, [r10-0x197]                   
    stxdw [r6+0x11], r1                     
    ldxdw r1, [r10-0x190]                   
    ja lbb_22755                                    if true { pc += 73 }
lbb_22682:
    add64 r2, 32                                    r2 += 32   ///  r2 = r2.wrapping_add(32 as i32 as i64 as u64)
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    stxdw [r10-0xe0], r1                    
    lddw r1, 0x100065870 --> b"\x00\x00\x00\x00o\x12\x06\x00\x1e\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00…        r1 load str located at 4295383152
    stxdw [r10-0x100], r1                   
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    stxdw [r10-0xf8], r1                    
    stxdw [r10-0xe8], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -208                                  r1 += -208   ///  r1 = r1.wrapping_add(-208 as i32 as i64 as u64)
    stxdw [r10-0xf0], r1                    
    lddw r1, 0x10003acf0 --> b"\xbf#\x00\x00\x00\x00\x00\x00\xb7\x02\x00\x00\x00\x00\x00\x00{*\xb0\xff\x…        r1 load str located at 4295208176
    stxdw [r10-0xc8], r1                    
    stxdw [r10-0xd0], r2                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -336                                  r1 += -336   ///  r1 = r1.wrapping_add(-336 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -256                                  r2 += -256   ///  r2 = r2.wrapping_add(-256 as i32 as i64 as u64)
    call function_43415                     
    ldxdw r1, [r10-0x150]                   
    stxdw [r10-0x168], r1                   
    ldxdw r1, [r10-0x148]                   
    stxdw [r10-0x160], r1                   
    ldxdw r1, [r10-0x140]                   
    stxdw [r10-0x158], r1                   
    mov64 r1, 29                                    r1 = 29 as i32 as i64 as u64
    stxb [r6+0x0], r1                       
    ldxdw r1, [r10-0x16f]                   
    stxdw [r6+0x1], r1                      
    ldxdw r1, [r10-0x167]                   
    stxdw [r6+0x9], r1                      
    ldxdw r1, [r10-0x15f]                   
    stxdw [r6+0x11], r1                     
    ldxdw r1, [r10-0x158]                   
    ja lbb_22755                                    if true { pc += 36 }
lbb_22719:
    add64 r2, 48                                    r2 += 48   ///  r2 = r2.wrapping_add(48 as i32 as i64 as u64)
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    stxdw [r10-0xe0], r1                    
    lddw r1, 0x100065860 --> b"\x00\x00\x00\x00Q\x12\x06\x00\x1e\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00…        r1 load str located at 4295383136
    stxdw [r10-0x100], r1                   
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    stxdw [r10-0xf8], r1                    
    stxdw [r10-0xe8], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -208                                  r1 += -208   ///  r1 = r1.wrapping_add(-208 as i32 as i64 as u64)
    stxdw [r10-0xf0], r1                    
    lddw r1, 0x10003acf0 --> b"\xbf#\x00\x00\x00\x00\x00\x00\xb7\x02\x00\x00\x00\x00\x00\x00{*\xb0\xff\x…        r1 load str located at 4295208176
    stxdw [r10-0xc8], r1                    
    stxdw [r10-0xd0], r2                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -280                                  r1 += -280   ///  r1 = r1.wrapping_add(-280 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -256                                  r2 += -256   ///  r2 = r2.wrapping_add(-256 as i32 as i64 as u64)
    call function_43415                     
    ldxdw r1, [r10-0x118]                   
    stxdw [r10-0x130], r1                   
    ldxdw r1, [r10-0x110]                   
    stxdw [r10-0x128], r1                   
    ldxdw r1, [r10-0x108]                   
    stxdw [r10-0x120], r1                   
    mov64 r1, 29                                    r1 = 29 as i32 as i64 as u64
    stxb [r6+0x0], r1                       
    ldxdw r1, [r10-0x137]                   
    stxdw [r6+0x1], r1                      
    ldxdw r1, [r10-0x12f]                   
    stxdw [r6+0x9], r1                      
    ldxdw r1, [r10-0x127]                   
    stxdw [r6+0x11], r1                     
    ldxdw r1, [r10-0x120]                   
lbb_22755:
    stxdw [r6+0x18], r1                     
lbb_22756:
    exit                                    

function_22757:
    mov64 r6, r3                                    r6 = r3
    mov64 r8, r2                                    r8 = r2
    mov64 r9, r1                                    r9 = r1
    ldxdw r1, [r8+0x40]                     
    jge r1, r6, lbb_23089                           if r1 >= r6 { pc += 327 }
    mov64 r7, r6                                    r7 = r6
    sub64 r7, r1                                    r7 -= r1   ///  r7 = r7.wrapping_sub(r1)
    ldxb r1, [r8+0x48]                      
    stxdw [r10-0xf8], r6                    
    stxdw [r10-0xf0], r1                    
    jeq r7, 0, lbb_22783                            if r7 == (0 as i32 as i64 as u64) { pc += 15 }
    mov64 r0, r1                                    r0 = r1
    jeq r7, 1, lbb_22775                            if r7 == (1 as i32 as i64 as u64) { pc += 5 }
    stxdw [r10-0x100], r8                   
    mov64 r8, r9                                    r8 = r9
    mov64 r2, r7                                    r2 = r7
    call function_30043                     
    ldxdw r8, [r10-0x100]                   
lbb_22775:
    mov64 r2, r0                                    r2 = r0
    and64 r2, 255                                   r2 &= 255   ///  r2 = r2.and(255)
    jeq r2, 255, lbb_22783                          if r2 == (255 as i32 as i64 as u64) { pc += 5 }
    jne r2, 0, lbb_22788                            if r2 != (0 as i32 as i64 as u64) { pc += 9 }
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    stxdw [r10-0xc8], r1                    
    stxdw [r10-0xd0], r1                    
    ja lbb_22820                                    if true { pc += 37 }
lbb_22783:
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    stxdw [r10-0xc8], r1                    
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    stxdw [r10-0xd0], r1                    
    ja lbb_22820                                    if true { pc += 32 }
lbb_22788:
    stxdw [r10-0x100], r9                   
    and64 r0, 255                                   r0 &= 255   ///  r0 = r0.and(255)
    stxw [r10-0x8], r0                      
    mov64 r9, 0                                     r9 = 0 as i32 as i64 as u64
    stxw [r10-0x4], r9                      
    stxdw [r10-0x10], r9                    
    stxdw [r10-0x1000], r9                  
    stxdw [r10-0xff8], r9                   
    mov64 r6, r10                                   r6 = r10
    add64 r6, -112                                  r6 += -112   ///  r6 = r6.wrapping_add(-112 as i32 as i64 as u64)
    mov64 r5, r10                                   r5 = r10
    mov64 r1, r6                                    r1 = r6
    mov64 r2, 255                                   r2 = 255 as i32 as i64 as u64
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
    mov64 r4, 0                                     r4 = 0 as i32 as i64 as u64
    call function_33183                     
    mov64 r1, r10                                   r1 = r10
    add64 r1, -88                                   r1 += -88   ///  r1 = r1.wrapping_add(-88 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -16                                   r2 += -16   ///  r2 = r2.wrapping_add(-16 as i32 as i64 as u64)
    mov64 r3, r6                                    r3 = r6
    call function_35767                     
    ldxw r1, [r10-0x58]                     
    jeq r1, 0, lbb_22815                            if r1 == (0 as i32 as i64 as u64) { pc += 3 }
    stxdw [r10-0xd0], r9                    
    stxdw [r10-0xc8], r9                    
    ja lbb_22819                                    if true { pc += 4 }
lbb_22815:
    ldxdw r1, [r10-0x4c]                    
    stxdw [r10-0xc8], r1                    
    ldxdw r1, [r10-0x54]                    
    stxdw [r10-0xd0], r1                    
lbb_22819:
    ldxdw r9, [r10-0x100]                   
lbb_22820:
    ldxdw r1, [r8+0x8]                      
    stxdw [r10-0x88], r1                    
    ldxdw r1, [r8+0x0]                      
    stxdw [r10-0x90], r1                    
    ldxdw r1, [r10-0xc8]                    
    stxdw [r10-0x8], r1                     
    ldxdw r1, [r10-0xd0]                    
    stxdw [r10-0x10], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -88                                   r1 += -88   ///  r1 = r1.wrapping_add(-88 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -144                                  r2 += -144   ///  r2 = r2.wrapping_add(-144 as i32 as i64 as u64)
    mov64 r3, r10                                   r3 = r10
    add64 r3, -16                                   r3 += -16   ///  r3 = r3.wrapping_add(-16 as i32 as i64 as u64)
    lddw r4, 0x1000612c1 --> b"Decaying bid quantity"        r4 load str located at 4295365313
    mov64 r5, 21                                    r5 = 21 as i32 as i64 as u64
    call function_25589                     
    ldxb r6, [r10-0x58]                     
    jeq r6, 56, lbb_22841                           if r6 == (56 as i32 as i64 as u64) { pc += 1 }
    ja lbb_23025                                    if true { pc += 184 }
lbb_22841:
    ldxdw r1, [r10-0x4c]                    
    stxdw [r10-0x65], r1                    
    ldxdw r2, [r10-0x54]                    
    stxdw [r10-0x6d], r2                    
    stxdw [r8+0x8], r1                      
    stxdw [r8+0x0], r2                      
    ldxdw r1, [r8+0x18]                     
    stxdw [r10-0x88], r1                    
    ldxdw r1, [r8+0x10]                     
    stxdw [r10-0x90], r1                    
    ldxdw r1, [r10-0xc8]                    
    stxdw [r10-0x8], r1                     
    ldxdw r1, [r10-0xd0]                    
    stxdw [r10-0x10], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -88                                   r1 += -88   ///  r1 = r1.wrapping_add(-88 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -144                                  r2 += -144   ///  r2 = r2.wrapping_add(-144 as i32 as i64 as u64)
    mov64 r3, r10                                   r3 = r10
    add64 r3, -16                                   r3 += -16   ///  r3 = r3.wrapping_add(-16 as i32 as i64 as u64)
    lddw r4, 0x1000612d6 --> b"Decaying ask quantity"        r4 load str located at 4295365334
    mov64 r5, 21                                    r5 = 21 as i32 as i64 as u64
    call function_25589                     
    ldxb r6, [r10-0x58]                     
    jeq r6, 56, lbb_22868                           if r6 == (56 as i32 as i64 as u64) { pc += 1 }
    ja lbb_23025                                    if true { pc += 157 }
lbb_22868:
    mov64 r6, r8                                    r6 = r8
    add64 r6, 16                                    r6 += 16   ///  r6 = r6.wrapping_add(16 as i32 as i64 as u64)
    ldxdw r1, [r10-0x4c]                    
    stxdw [r10-0x65], r1                    
    ldxdw r2, [r10-0x54]                    
    stxdw [r10-0x6d], r2                    
    stxdw [r6+0x8], r1                      
    stxdw [r6+0x0], r2                      
    ldxdw r1, [r8+0x28]                     
    stxdw [r10-0xb8], r1                    
    ldxdw r1, [r8+0x20]                     
    stxdw [r10-0xc0], r1                    
    ldxdw r1, [r8+0x38]                     
    stxdw [r10-0xa8], r1                    
    ldxdw r1, [r8+0x30]                     
    stxdw [r10-0xb0], r1                    
    jgt r7, 1, lbb_23092                            if r7 > (1 as i32 as i64 as u64) { pc += 207 }
lbb_22885:
    ldxdw r1, [r10-0xb8]                    
    stxdw [r10-0x88], r1                    
    ldxdw r1, [r10-0xc0]                    
    stxdw [r10-0x90], r1                    
    ldxdw r1, [r8+0x8]                      
    stxdw [r10-0x8], r1                     
    ldxdw r1, [r8+0x0]                      
    stxdw [r10-0x10], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -88                                   r1 += -88   ///  r1 = r1.wrapping_add(-88 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -144                                  r2 += -144   ///  r2 = r2.wrapping_add(-144 as i32 as i64 as u64)
    mov64 r3, r10                                   r3 = r10
    add64 r3, -16                                   r3 += -16   ///  r3 = r3.wrapping_add(-16 as i32 as i64 as u64)
    lddw r4, 0x100061325 --> b"Adding pending bid risk to bid quantity"        r4 load str located at 4295365413
    mov64 r5, 39                                    r5 = 39 as i32 as i64 as u64
    call function_25190                     
    ldxb r7, [r10-0x58]                     
    jeq r7, 56, lbb_22906                           if r7 == (56 as i32 as i64 as u64) { pc += 1 }
    ja lbb_23193                                    if true { pc += 287 }
lbb_22906:
    ldxdw r1, [r10-0x4c]                    
    stxdw [r10-0x65], r1                    
    ldxdw r2, [r10-0x54]                    
    stxdw [r10-0x6d], r2                    
    stxdw [r8+0x8], r1                      
    stxdw [r8+0x0], r2                      
    ldxdw r1, [r10-0xa8]                    
    stxdw [r10-0x88], r1                    
    ldxdw r1, [r10-0xb0]                    
    stxdw [r10-0x90], r1                    
    ldxdw r1, [r6+0x8]                      
    stxdw [r10-0x8], r1                     
    ldxdw r1, [r6+0x0]                      
    stxdw [r10-0x10], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -88                                   r1 += -88   ///  r1 = r1.wrapping_add(-88 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -144                                  r2 += -144   ///  r2 = r2.wrapping_add(-144 as i32 as i64 as u64)
    mov64 r3, r10                                   r3 = r10
    add64 r3, -16                                   r3 += -16   ///  r3 = r3.wrapping_add(-16 as i32 as i64 as u64)
    lddw r4, 0x10006134c --> b"Adding pending ask risk to ask quantity"        r4 load str located at 4295365452
    mov64 r5, 39                                    r5 = 39 as i32 as i64 as u64
    call function_25190                     
    ldxb r7, [r10-0x58]                     
    jeq r7, 56, lbb_22933                           if r7 == (56 as i32 as i64 as u64) { pc += 1 }
    ja lbb_23193                                    if true { pc += 260 }
lbb_22933:
    stxdw [r10-0x100], r9                   
    ldxdw r1, [r10-0x4c]                    
    stxdw [r10-0x65], r1                    
    ldxdw r2, [r10-0x54]                    
    stxdw [r10-0x6d], r2                    
    stxdw [r6+0x8], r1                      
    stxdw [r6+0x0], r2                      
    ldxb r9, [r8+0x4b]                      
    lsh64 r9, 56                                    r9 <<= 56   ///  r9 = r9.wrapping_shl(56)
    arsh64 r9, 56                                   r9 >>= 56 (signed)   ///  r9 = (r9 as i64).wrapping_shr(56)
    jeq r9, 0, lbb_23079                            if r9 == (0 as i32 as i64 as u64) { pc += 135 }
    mov64 r7, 0                                     r7 = 0 as i32 as i64 as u64
    stxw [r10-0x74], r7                     
    stxw [r10-0x7c], r7                     
    mov64 r1, r9                                    r1 = r9
    and64 r1, 128                                   r1 &= 128   ///  r1 = r1.and(128)
    lsh64 r1, 24                                    r1 <<= 24   ///  r1 = r1.wrapping_shl(24)
    stxw [r10-0x80], r1                     
    mov64 r1, r9                                    r1 = r9
    arsh64 r1, 63                                   r1 >>= 63 (signed)   ///  r1 = (r1 as i64).wrapping_shr(63)
    mov64 r2, r9                                    r2 = r9
    xor64 r2, r1                                    r2 ^= r1   ///  r2 = r2.xor(r1)
    sub64 r2, r1                                    r2 -= r1   ///  r2 = r2.wrapping_sub(r1)
    stxw [r10-0x78], r2                     
    mov64 r1, r10                                   r1 = r10
    add64 r1, -88                                   r1 += -88   ///  r1 = r1.wrapping_add(-88 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -128                                  r2 += -128   ///  r2 = r2.wrapping_add(-128 as i32 as i64 as u64)
    mov64 r3, r10                                   r3 = r10
    add64 r3, -208                                  r3 += -208   ///  r3 = r3.wrapping_add(-208 as i32 as i64 as u64)
    lddw r4, 0x100061373 --> b"Decaying trades in a way"        r4 load str located at 4295365491
    mov64 r5, 24                                    r5 = 24 as i32 as i64 as u64
    call function_25589                     
    ldxb r6, [r10-0x58]                     
    jeq r6, 56, lbb_22970                           if r6 == (56 as i32 as i64 as u64) { pc += 1 }
    ja lbb_23045                                    if true { pc += 75 }
lbb_22970:
    ldxdw r1, [r10-0x54]                    
    stxdw [r10-0x10], r1                    
    ldxdw r1, [r10-0x4c]                    
    stxdw [r10-0x8], r1                     
    mov64 r6, r10                                   r6 = r10
    add64 r6, -88                                   r6 += -88   ///  r6 = r6.wrapping_add(-88 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -16                                   r2 += -16   ///  r2 = r2.wrapping_add(-16 as i32 as i64 as u64)
    mov64 r1, r6                                    r1 = r6
    call function_33225                     
    mov64 r1, r10                                   r1 = r10
    add64 r1, -232                                  r1 += -232   ///  r1 = r1.wrapping_add(-232 as i32 as i64 as u64)
    mov64 r2, r6                                    r2 = r6
    call function_33630                     
    mov64 r2, 1                                     r2 = 1 as i32 as i64 as u64
    mov64 r3, 128                                   r3 = 128 as i32 as i64 as u64
    ldxdw r1, [r10-0xe0]                    
    mov64 r4, 1                                     r4 = 1 as i32 as i64 as u64
    jgt r3, r1, lbb_22990                           if r3 > r1 { pc += 1 }
    mov64 r4, 0                                     r4 = 0 as i32 as i64 as u64
lbb_22990:
    ldxdw r3, [r10-0xd8]                    
    mov64 r5, 1                                     r5 = 1 as i32 as i64 as u64
    jsgt r7, r3, lbb_22994                          if (r7 as i64) > (r3 as i64) { pc += 1 }
    mov64 r5, 0                                     r5 = 0 as i32 as i64 as u64
lbb_22994:
    jeq r3, 0, lbb_22996                            if r3 == (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r4, r5                                    r4 = r5
lbb_22996:
    jne r4, 0, lbb_22998                            if r4 != (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r1, 128                                   r1 = 128 as i32 as i64 as u64
lbb_22998:
    jne r4, 0, lbb_23000                            if r4 != (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
lbb_23000:
    mov64 r4, 1                                     r4 = 1 as i32 as i64 as u64
    jsgt r3, -1, lbb_23003                          if (r3 as i64) > (-1 as i32 as i64) { pc += 1 }
    mov64 r4, 0                                     r4 = 0 as i32 as i64 as u64
lbb_23003:
    jgt r1, -127, lbb_23005                         if r1 > (-127 as i32 as i64 as u64) { pc += 1 }
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
lbb_23005:
    jeq r3, -1, lbb_23007                           if r3 == (-1 as i32 as i64 as u64) { pc += 1 }
    mov64 r2, r4                                    r2 = r4
lbb_23007:
    jne r2, 0, lbb_23009                            if r2 != (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r1, -127                                  r1 = -127 as i32 as i64 as u64
lbb_23009:
    ldxdw r2, [r10-0xe8]                    
    jeq r2, 0, lbb_23012                            if r2 == (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r7, r1                                    r7 = r1
lbb_23012:
    jsgt r9, 0, lbb_23014                           if (r9 as i64) > (0 as i32 as i64) { pc += 1 }
    ja lbb_23066                                    if true { pc += 52 }
lbb_23014:
    lsh64 r9, 56                                    r9 <<= 56   ///  r9 = r9.wrapping_shl(56)
    lddw r1, 0xff00000000000000                     r1 load str located at -72057594037927936
    add64 r9, r1                                    r9 += r1   ///  r9 = r9.wrapping_add(r1)
    arsh64 r9, 56                                   r9 >>= 56 (signed)   ///  r9 = (r9 as i64).wrapping_shr(56)
    lsh64 r7, 56                                    r7 <<= 56   ///  r7 = r7.wrapping_shl(56)
    arsh64 r7, 56                                   r7 >>= 56 (signed)   ///  r7 = (r7 as i64).wrapping_shr(56)
    jsgt r9, r7, lbb_23023                          if (r9 as i64) > (r7 as i64) { pc += 1 }
    mov64 r7, r9                                    r7 = r9
lbb_23023:
    jsgt r7, 0, lbb_23078                           if (r7 as i64) > (0 as i32 as i64) { pc += 54 }
    ja lbb_23077                                    if true { pc += 52 }
lbb_23025:
    ldxw r1, [r10-0x48]                     
    stxw [r10-0x61], r1                     
    ldxdw r1, [r10-0x4f]                    
    stxdw [r10-0x68], r1                    
    ldxdw r1, [r10-0x57]                    
    stxdw [r10-0x70], r1                    
    mov64 r1, r9                                    r1 = r9
    add64 r1, 20                                    r1 += 20   ///  r1 = r1.wrapping_add(20 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -68                                   r2 += -68   ///  r2 = r2.wrapping_add(-68 as i32 as i64 as u64)
    mov64 r3, 52                                    r3 = 52 as i32 as i64 as u64
    call function_48190                     
    ldxw r1, [r10-0x61]                     
    stxw [r9+0x10], r1                      
    ldxdw r1, [r10-0x68]                    
    stxdw [r9+0x9], r1                      
    ldxdw r1, [r10-0x70]                    
    stxdw [r9+0x1], r1                      
    stxb [r9+0x0], r6                       
    ja lbb_23091                                    if true { pc += 46 }
lbb_23045:
    ldxw r1, [r10-0x48]                     
    stxw [r10-0x61], r1                     
    ldxdw r1, [r10-0x4f]                    
    stxdw [r10-0x68], r1                    
    ldxdw r1, [r10-0x57]                    
    stxdw [r10-0x70], r1                    
    ldxdw r7, [r10-0x100]                   
    mov64 r1, r7                                    r1 = r7
    add64 r1, 20                                    r1 += 20   ///  r1 = r1.wrapping_add(20 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -68                                   r2 += -68   ///  r2 = r2.wrapping_add(-68 as i32 as i64 as u64)
    mov64 r3, 52                                    r3 = 52 as i32 as i64 as u64
    call function_48190                     
    ldxw r1, [r10-0x61]                     
    stxw [r7+0x10], r1                      
    ldxdw r1, [r10-0x68]                    
    stxdw [r7+0x9], r1                      
    ldxdw r1, [r10-0x70]                    
    stxdw [r7+0x1], r1                      
    stxb [r7+0x0], r6                       
    ja lbb_23091                                    if true { pc += 25 }
lbb_23066:
    lsh64 r9, 56                                    r9 <<= 56   ///  r9 = r9.wrapping_shl(56)
    lddw r1, 0x100000000000000                      r1 load str located at 72057594037927936
    add64 r9, r1                                    r9 += r1   ///  r9 = r9.wrapping_add(r1)
    arsh64 r9, 56                                   r9 >>= 56 (signed)   ///  r9 = (r9 as i64).wrapping_shr(56)
    lsh64 r7, 56                                    r7 <<= 56   ///  r7 = r7.wrapping_shl(56)
    arsh64 r7, 56                                   r7 >>= 56 (signed)   ///  r7 = (r7 as i64).wrapping_shr(56)
    jsgt r7, r9, lbb_23075                          if (r7 as i64) > (r9 as i64) { pc += 1 }
    mov64 r7, r9                                    r7 = r9
lbb_23075:
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    jsgt r1, r7, lbb_23078                          if (r1 as i64) > (r7 as i64) { pc += 1 }
lbb_23077:
    mov64 r7, 0                                     r7 = 0 as i32 as i64 as u64
lbb_23078:
    stxb [r8+0x4b], r7                      
lbb_23079:
    mov64 r1, r8                                    r1 = r8
    add64 r1, 32                                    r1 += 32   ///  r1 = r1.wrapping_add(32 as i32 as i64 as u64)
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
    stxdw [r1+0x18], r2                     
    stxdw [r1+0x10], r2                     
    stxdw [r1+0x8], r2                      
    stxdw [r1+0x0], r2                      
    ldxdw r1, [r10-0xf8]                    
    stxdw [r8+0x40], r1                     
    ldxdw r9, [r10-0x100]                   
lbb_23089:
    mov64 r1, 56                                    r1 = 56 as i32 as i64 as u64
    stxb [r9+0x0], r1                       
lbb_23091:
    exit                                    
lbb_23092:
    add64 r7, -1                                    r7 += -1   ///  r7 = r7.wrapping_add(-1 as i32 as i64 as u64)
    ldxdw r0, [r10-0xf0]                    
    jne r7, 1, lbb_23103                            if r7 != (1 as i32 as i64 as u64) { pc += 8 }
lbb_23095:
    mov64 r1, r0                                    r1 = r0
    and64 r1, 255                                   r1 &= 255   ///  r1 = r1.and(255)
    jeq r1, 255, lbb_23107                          if r1 == (255 as i32 as i64 as u64) { pc += 9 }
    jne r1, 0, lbb_23112                            if r1 != (0 as i32 as i64 as u64) { pc += 13 }
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    stxdw [r10-0x98], r1                    
    stxdw [r10-0xa0], r1                    
    ja lbb_23144                                    if true { pc += 41 }
lbb_23103:
    mov64 r1, r0                                    r1 = r0
    mov64 r2, r7                                    r2 = r7
    call function_30043                     
    ja lbb_23095                                    if true { pc += -12 }
lbb_23107:
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    stxdw [r10-0x98], r1                    
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    stxdw [r10-0xa0], r1                    
    ja lbb_23144                                    if true { pc += 32 }
lbb_23112:
    stxdw [r10-0x100], r9                   
    and64 r0, 255                                   r0 &= 255   ///  r0 = r0.and(255)
    stxw [r10-0x8], r0                      
    mov64 r9, 0                                     r9 = 0 as i32 as i64 as u64
    stxw [r10-0x4], r9                      
    stxdw [r10-0x10], r9                    
    stxdw [r10-0x1000], r9                  
    stxdw [r10-0xff8], r9                   
    mov64 r7, r10                                   r7 = r10
    add64 r7, -112                                  r7 += -112   ///  r7 = r7.wrapping_add(-112 as i32 as i64 as u64)
    mov64 r5, r10                                   r5 = r10
    mov64 r1, r7                                    r1 = r7
    mov64 r2, 255                                   r2 = 255 as i32 as i64 as u64
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
    mov64 r4, 0                                     r4 = 0 as i32 as i64 as u64
    call function_33183                     
    mov64 r1, r10                                   r1 = r10
    add64 r1, -88                                   r1 += -88   ///  r1 = r1.wrapping_add(-88 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -16                                   r2 += -16   ///  r2 = r2.wrapping_add(-16 as i32 as i64 as u64)
    mov64 r3, r7                                    r3 = r7
    call function_35767                     
    ldxw r1, [r10-0x58]                     
    jeq r1, 0, lbb_23139                            if r1 == (0 as i32 as i64 as u64) { pc += 3 }
    stxdw [r10-0xa0], r9                    
    stxdw [r10-0x98], r9                    
    ja lbb_23143                                    if true { pc += 4 }
lbb_23139:
    ldxdw r1, [r10-0x4c]                    
    stxdw [r10-0x98], r1                    
    ldxdw r1, [r10-0x54]                    
    stxdw [r10-0xa0], r1                    
lbb_23143:
    ldxdw r9, [r10-0x100]                   
lbb_23144:
    ldxdw r1, [r10-0xb8]                    
    stxdw [r10-0x88], r1                    
    ldxdw r1, [r10-0xc0]                    
    stxdw [r10-0x90], r1                    
    ldxdw r1, [r10-0x98]                    
    stxdw [r10-0x8], r1                     
    ldxdw r1, [r10-0xa0]                    
    stxdw [r10-0x10], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -88                                   r1 += -88   ///  r1 = r1.wrapping_add(-88 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -144                                  r2 += -144   ///  r2 = r2.wrapping_add(-144 as i32 as i64 as u64)
    mov64 r3, r10                                   r3 = r10
    add64 r3, -16                                   r3 += -16   ///  r3 = r3.wrapping_add(-16 as i32 as i64 as u64)
    lddw r4, 0x1000612eb --> b"Decaying bid pending quantity"        r4 load str located at 4295365355
    mov64 r5, 29                                    r5 = 29 as i32 as i64 as u64
    call function_25589                     
    ldxb r7, [r10-0x58]                     
    jeq r7, 56, lbb_23165                           if r7 == (56 as i32 as i64 as u64) { pc += 1 }
    ja lbb_23193                                    if true { pc += 28 }
lbb_23165:
    mov64 r1, r8                                    r1 = r8
    add64 r1, 48                                    r1 += 48   ///  r1 = r1.wrapping_add(48 as i32 as i64 as u64)
    ldxdw r2, [r10-0x54]                    
    stxdw [r10-0xc0], r2                    
    ldxdw r2, [r10-0x4c]                    
    stxdw [r10-0xb8], r2                    
    ldxdw r2, [r1+0x8]                      
    stxdw [r10-0x8], r2                     
    ldxdw r1, [r1+0x0]                      
    stxdw [r10-0x10], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -88                                   r1 += -88   ///  r1 = r1.wrapping_add(-88 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -16                                   r2 += -16   ///  r2 = r2.wrapping_add(-16 as i32 as i64 as u64)
    mov64 r3, r10                                   r3 = r10
    add64 r3, -160                                  r3 += -160   ///  r3 = r3.wrapping_add(-160 as i32 as i64 as u64)
    lddw r4, 0x100061308 --> b"Decaying ask pending quantity"        r4 load str located at 4295365384
    mov64 r5, 29                                    r5 = 29 as i32 as i64 as u64
    call function_25589                     
    ldxb r7, [r10-0x58]                     
    jeq r7, 56, lbb_23188                           if r7 == (56 as i32 as i64 as u64) { pc += 1 }
    ja lbb_23193                                    if true { pc += 5 }
lbb_23188:
    ldxdw r1, [r10-0x54]                    
    stxdw [r10-0xb0], r1                    
    ldxdw r1, [r10-0x4c]                    
    stxdw [r10-0xa8], r1                    
    ja lbb_22885                                    if true { pc += -308 }
lbb_23193:
    ldxw r1, [r10-0x48]                     
    stxw [r10-0x61], r1                     
    ldxdw r1, [r10-0x4f]                    
    stxdw [r10-0x68], r1                    
    ldxdw r1, [r10-0x57]                    
    stxdw [r10-0x70], r1                    
    mov64 r1, r9                                    r1 = r9
    add64 r1, 20                                    r1 += 20   ///  r1 = r1.wrapping_add(20 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -68                                   r2 += -68   ///  r2 = r2.wrapping_add(-68 as i32 as i64 as u64)
    mov64 r3, 52                                    r3 = 52 as i32 as i64 as u64
    call function_48190                     
    ldxw r1, [r10-0x61]                     
    stxw [r9+0x10], r1                      
    ldxdw r1, [r10-0x68]                    
    stxdw [r9+0x9], r1                      
    ldxdw r1, [r10-0x70]                    
    stxdw [r9+0x1], r1                      
    stxb [r9+0x0], r7                       
    ja lbb_23091                                    if true { pc += -122 }

function_23213:
    mov64 r7, r3                                    r7 = r3
    mov64 r8, r2                                    r8 = r2
    mov64 r6, r1                                    r6 = r1
    ldxw r2, [r7+0x0]                       
    lsh64 r2, 32                                    r2 <<= 32   ///  r2 = r2.wrapping_shl(32)
    arsh64 r2, 32                                   r2 >>= 32 (signed)   ///  r2 = (r2 as i64).wrapping_shr(32)
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    jsgt r1, r2, lbb_23256                          if (r1 as i64) > (r2 as i64) { pc += 35 }
    ldxw r2, [r7+0x8]                       
    ldxw r3, [r7+0xc]                       
    or64 r3, r2                                     r3 |= r2   ///  r3 = r3.or(r2)
    ldxw r2, [r7+0x4]                       
    or64 r3, r2                                     r3 |= r2   ///  r3 = r3.or(r2)
    lsh64 r3, 32                                    r3 <<= 32   ///  r3 = r3.wrapping_shl(32)
    rsh64 r3, 32                                    r3 >>= 32   ///  r3 = r3.wrapping_shr(32)
    jeq r3, 0, lbb_23256                            if r3 == (0 as i32 as i64 as u64) { pc += 27 }
    mov64 r3, r8                                    r3 = r8
    add64 r3, 48                                    r3 += 48   ///  r3 = r3.wrapping_add(48 as i32 as i64 as u64)
    mov64 r1, r8                                    r1 = r8
    add64 r1, 32                                    r1 += 32   ///  r1 = r1.wrapping_add(32 as i32 as i64 as u64)
    mov64 r2, r1                                    r2 = r1
    jne r4, 0, lbb_23236                            if r4 != (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r2, r3                                    r2 = r3
lbb_23236:
    stxdw [r10-0x168], r2                   
    jne r4, 0, lbb_23239                            if r4 != (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r3, r1                                    r3 = r1
lbb_23239:
    mov64 r2, r8                                    r2 = r8
    add64 r2, 16                                    r2 += 16   ///  r2 = r2.wrapping_add(16 as i32 as i64 as u64)
    mov64 r1, r8                                    r1 = r8
    jne r4, 0, lbb_23244                            if r4 != (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r1, r2                                    r1 = r2
lbb_23244:
    stxdw [r10-0x160], r1                   
    jne r4, 0, lbb_23247                            if r4 != (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r2, r8                                    r2 = r8
lbb_23247:
    stxdw [r10-0x150], r2                   
    ldxb r1, [r8+0x49]                      
    stxdw [r10-0x170], r4                   
    stxdw [r10-0x158], r3                   
    jeq r1, 255, lbb_23292                          if r1 == (255 as i32 as i64 as u64) { pc += 40 }
    jne r1, 0, lbb_23296                            if r1 != (0 as i32 as i64 as u64) { pc += 43 }
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    stxdw [r10-0x108], r1                   
    ja lbb_23325                                    if true { pc += 69 }
lbb_23256:
    stxdw [r10-0x78], r1                    
    lddw r1, 0x1000658a0 --> b"\x00\x00\x00\x00C\x14\x06\x00*\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x0…        r1 load str located at 4295383200
    stxdw [r10-0x98], r1                    
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    stxdw [r10-0x90], r1                    
    stxdw [r10-0x80], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -176                                  r1 += -176   ///  r1 = r1.wrapping_add(-176 as i32 as i64 as u64)
    stxdw [r10-0x88], r1                    
    lddw r1, 0x100042110 --> b"\xbf'\x00\x00\x00\x00\x00\x00\xbf\x18\x00\x00\x00\x00\x00\x00yu\x18\x00\x…        r1 load str located at 4295237904
    stxdw [r10-0xa8], r1                    
    stxdw [r10-0xb0], r7                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -296                                  r1 += -296   ///  r1 = r1.wrapping_add(-296 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -152                                  r2 += -152   ///  r2 = r2.wrapping_add(-152 as i32 as i64 as u64)
    call function_43415                     
    ldxdw r1, [r10-0x128]                   
    stxdw [r10-0x140], r1                   
    ldxdw r1, [r10-0x120]                   
    stxdw [r10-0x138], r1                   
    ldxdw r1, [r10-0x118]                   
    stxdw [r10-0x130], r1                   
    mov64 r1, 29                                    r1 = 29 as i32 as i64 as u64
    stxb [r6+0x0], r1                       
    ldxdw r1, [r10-0x147]                   
    stxdw [r6+0x1], r1                      
    ldxdw r1, [r10-0x13f]                   
    stxdw [r6+0x9], r1                      
    ldxdw r1, [r10-0x137]                   
    stxdw [r6+0x11], r1                     
    ldxdw r1, [r10-0x130]                   
    stxdw [r6+0x18], r1                     
    ja lbb_23655                                    if true { pc += 363 }
lbb_23292:
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    stxdw [r10-0x108], r1                   
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    ja lbb_23325                                    if true { pc += 29 }
lbb_23296:
    stxw [r10-0x38], r1                     
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    stxw [r10-0x34], r1                     
    stxdw [r10-0x40], r1                    
    stxdw [r10-0x1000], r1                  
    stxdw [r10-0xff8], r1                   
    mov64 r9, r10                                   r9 = r10
    add64 r9, -176                                  r9 += -176   ///  r9 = r9.wrapping_add(-176 as i32 as i64 as u64)
    mov64 r5, r10                                   r5 = r10
    mov64 r1, r9                                    r1 = r9
    mov64 r2, 255                                   r2 = 255 as i32 as i64 as u64
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
    mov64 r4, 0                                     r4 = 0 as i32 as i64 as u64
    call function_33183                     
    mov64 r1, r10                                   r1 = r10
    add64 r1, -152                                  r1 += -152   ///  r1 = r1.wrapping_add(-152 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -64                                   r2 += -64   ///  r2 = r2.wrapping_add(-64 as i32 as i64 as u64)
    mov64 r3, r9                                    r3 = r9
    call function_35767                     
    ldxw r1, [r10-0x98]                     
    jeq r1, 0, lbb_23322                            if r1 == (0 as i32 as i64 as u64) { pc += 4 }
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    stxdw [r10-0x110], r1                   
    stxdw [r10-0x108], r1                   
    ja lbb_23326                                    if true { pc += 4 }
lbb_23322:
    ldxdw r1, [r10-0x8c]                    
    stxdw [r10-0x108], r1                   
    ldxdw r1, [r10-0x94]                    
lbb_23325:
    stxdw [r10-0x110], r1                   
lbb_23326:
    ldxb r1, [r8+0x4a]                      
    jeq r1, 255, lbb_23332                          if r1 == (255 as i32 as i64 as u64) { pc += 4 }
    jne r1, 0, lbb_23336                            if r1 != (0 as i32 as i64 as u64) { pc += 7 }
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    stxdw [r10-0xf8], r1                    
    ja lbb_23365                                    if true { pc += 33 }
lbb_23332:
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    stxdw [r10-0xf8], r1                    
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    ja lbb_23365                                    if true { pc += 29 }
lbb_23336:
    stxw [r10-0x38], r1                     
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    stxw [r10-0x34], r1                     
    stxdw [r10-0x40], r1                    
    stxdw [r10-0x1000], r1                  
    stxdw [r10-0xff8], r1                   
    mov64 r9, r10                                   r9 = r10
    add64 r9, -176                                  r9 += -176   ///  r9 = r9.wrapping_add(-176 as i32 as i64 as u64)
    mov64 r5, r10                                   r5 = r10
    mov64 r1, r9                                    r1 = r9
    mov64 r2, 255                                   r2 = 255 as i32 as i64 as u64
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
    mov64 r4, 0                                     r4 = 0 as i32 as i64 as u64
    call function_33183                     
    mov64 r1, r10                                   r1 = r10
    add64 r1, -152                                  r1 += -152   ///  r1 = r1.wrapping_add(-152 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -64                                   r2 += -64   ///  r2 = r2.wrapping_add(-64 as i32 as i64 as u64)
    mov64 r3, r9                                    r3 = r9
    call function_35767                     
    ldxw r1, [r10-0x98]                     
    jeq r1, 0, lbb_23362                            if r1 == (0 as i32 as i64 as u64) { pc += 4 }
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    stxdw [r10-0x100], r1                   
    stxdw [r10-0xf8], r1                    
    ja lbb_23366                                    if true { pc += 4 }
lbb_23362:
    ldxdw r1, [r10-0x8c]                    
    stxdw [r10-0xf8], r1                    
    ldxdw r1, [r10-0x94]                    
lbb_23365:
    stxdw [r10-0x100], r1                   
lbb_23366:
    ldxdw r1, [r7+0x8]                      
    stxdw [r10-0x38], r1                    
    ldxdw r1, [r7+0x0]                      
    stxdw [r10-0x40], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -152                                  r1 += -152   ///  r1 = r1.wrapping_add(-152 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -64                                   r2 += -64   ///  r2 = r2.wrapping_add(-64 as i32 as i64 as u64)
    mov64 r3, r10                                   r3 = r10
    add64 r3, -272                                  r3 += -272   ///  r3 = r3.wrapping_add(-272 as i32 as i64 as u64)
    lddw r4, 0x10006138b --> b"Calculating for opposing side"        r4 load str located at 4295365515
    mov64 r5, 29                                    r5 = 29 as i32 as i64 as u64
    call function_25589                     
    ldxb r9, [r10-0x98]                     
    jeq r9, 56, lbb_23383                           if r9 == (56 as i32 as i64 as u64) { pc += 1 }
    ja lbb_23490                                    if true { pc += 107 }
lbb_23383:
    ldxdw r1, [r10-0x94]                    
    stxdw [r10-0xf0], r1                    
    ldxdw r1, [r10-0x8c]                    
    stxdw [r10-0xe8], r1                    
    ldxdw r1, [r7+0x8]                      
    stxdw [r10-0x38], r1                    
    ldxdw r1, [r7+0x0]                      
    stxdw [r10-0x40], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -152                                  r1 += -152   ///  r1 = r1.wrapping_add(-152 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -64                                   r2 += -64   ///  r2 = r2.wrapping_add(-64 as i32 as i64 as u64)
    mov64 r3, r10                                   r3 = r10
    add64 r3, -256                                  r3 += -256   ///  r3 = r3.wrapping_add(-256 as i32 as i64 as u64)
    lddw r4, 0x1000613a8 --> b"Calculating for pending"        r4 load str located at 4295365544
    mov64 r5, 23                                    r5 = 23 as i32 as i64 as u64
    call function_25589                     
    ldxb r9, [r10-0x98]                     
    jeq r9, 56, lbb_23404                           if r9 == (56 as i32 as i64 as u64) { pc += 1 }
    ja lbb_23490                                    if true { pc += 86 }
lbb_23404:
    ldxdw r1, [r10-0x94]                    
    stxdw [r10-0xe0], r1                    
    ldxdw r1, [r10-0x8c]                    
    stxdw [r10-0xd8], r1                    
    ldxdw r9, [r10-0x150]                   
    ldxdw r1, [r9+0x8]                      
    stxdw [r10-0x48], r1                    
    ldxdw r1, [r9+0x0]                      
    stxdw [r10-0x50], r1                    
    ldxdw r1, [r7+0x8]                      
    stxdw [r10-0x38], r1                    
    ldxdw r1, [r7+0x0]                      
    stxdw [r10-0x40], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -152                                  r1 += -152   ///  r1 = r1.wrapping_add(-152 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -80                                   r2 += -80   ///  r2 = r2.wrapping_add(-80 as i32 as i64 as u64)
    mov64 r3, r10                                   r3 = r10
    add64 r3, -64                                   r3 += -64   ///  r3 = r3.wrapping_add(-64 as i32 as i64 as u64)
    call function_25088                     
    ldxb r7, [r10-0x98]                     
    jeq r7, 56, lbb_23427                           if r7 == (56 as i32 as i64 as u64) { pc += 1 }
    ja lbb_23636                                    if true { pc += 209 }
lbb_23427:
    ldxdw r1, [r10-0x8c]                    
    stxdw [r10-0xa5], r1                    
    ldxdw r2, [r10-0x94]                    
    stxdw [r10-0xad], r2                    
    stxdw [r9+0x8], r1                      
    stxdw [r9+0x0], r2                      
    ldxdw r9, [r10-0x158]                   
    ldxdw r1, [r9+0x8]                      
    stxdw [r10-0x48], r1                    
    ldxdw r1, [r9+0x0]                      
    stxdw [r10-0x50], r1                    
    ldxdw r1, [r10-0xd8]                    
    stxdw [r10-0x38], r1                    
    ldxdw r1, [r10-0xe0]                    
    stxdw [r10-0x40], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -152                                  r1 += -152   ///  r1 = r1.wrapping_add(-152 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -80                                   r2 += -80   ///  r2 = r2.wrapping_add(-80 as i32 as i64 as u64)
    mov64 r3, r10                                   r3 = r10
    add64 r3, -64                                   r3 += -64   ///  r3 = r3.wrapping_add(-64 as i32 as i64 as u64)
    call function_25088                     
    ldxb r7, [r10-0x98]                     
    jeq r7, 56, lbb_23452                           if r7 == (56 as i32 as i64 as u64) { pc += 1 }
    ja lbb_23636                                    if true { pc += 184 }
lbb_23452:
    ldxdw r1, [r10-0x8c]                    
    stxdw [r10-0xa5], r1                    
    ldxdw r2, [r10-0x94]                    
    stxdw [r10-0xad], r2                    
    stxdw [r9+0x8], r1                      
    stxdw [r9+0x0], r2                      
    mov64 r1, r10                                   r1 = r10
    add64 r1, -240                                  r1 += -240   ///  r1 = r1.wrapping_add(-240 as i32 as i64 as u64)
    ldxdw r9, [r10-0x160]                   
    mov64 r2, r9                                    r2 = r9
    call function_33952                     
    and64 r0, 255                                   r0 &= 255   ///  r0 = r0.and(255)
    jeq r0, 1, lbb_23510                            if r0 == (1 as i32 as i64 as u64) { pc += 45 }
    ldxdw r1, [r9+0x8]                      
    stxdw [r10-0x48], r1                    
    ldxdw r1, [r9+0x0]                      
    stxdw [r10-0x50], r1                    
    ldxdw r1, [r10-0xe8]                    
    stxdw [r10-0x38], r1                    
    ldxdw r1, [r10-0xf0]                    
    stxdw [r10-0x40], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -152                                  r1 += -152   ///  r1 = r1.wrapping_add(-152 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -80                                   r2 += -80   ///  r2 = r2.wrapping_add(-80 as i32 as i64 as u64)
    mov64 r3, r10                                   r3 = r10
    add64 r3, -64                                   r3 += -64   ///  r3 = r3.wrapping_add(-64 as i32 as i64 as u64)
    call function_25392                     
    ldxb r7, [r10-0x98]                     
    jeq r7, 56, lbb_23483                           if r7 == (56 as i32 as i64 as u64) { pc += 1 }
    ja lbb_23636                                    if true { pc += 153 }
lbb_23483:
    ldxdw r1, [r10-0x8c]                    
    stxdw [r10-0xa5], r1                    
    ldxdw r2, [r10-0x94]                    
    stxdw [r10-0xad], r2                    
    stxdw [r9+0x8], r1                      
    stxdw [r9+0x0], r2                      
    ja lbb_23564                                    if true { pc += 74 }
lbb_23490:
    ldxw r1, [r10-0x88]                     
    stxw [r10-0xa1], r1                     
    ldxdw r1, [r10-0x8f]                    
    stxdw [r10-0xa8], r1                    
    ldxdw r1, [r10-0x97]                    
    stxdw [r10-0xb0], r1                    
    mov64 r1, r6                                    r1 = r6
    add64 r1, 20                                    r1 += 20   ///  r1 = r1.wrapping_add(20 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -132                                  r2 += -132   ///  r2 = r2.wrapping_add(-132 as i32 as i64 as u64)
    mov64 r3, 52                                    r3 = 52 as i32 as i64 as u64
    call function_48190                     
    ldxw r1, [r10-0xa1]                     
    stxw [r6+0x10], r1                      
    ldxdw r1, [r10-0xa8]                    
    stxdw [r6+0x9], r1                      
    ldxdw r1, [r10-0xb0]                    
    stxdw [r6+0x1], r1                      
    stxb [r6+0x0], r9                       
    ja lbb_23655                                    if true { pc += 145 }
lbb_23510:
    ldxdw r1, [r10-0xe8]                    
    stxdw [r10-0xa8], r1                    
    ldxdw r1, [r10-0xf0]                    
    stxdw [r10-0xb0], r1                    
    ldxdw r1, [r9+0x8]                      
    stxdw [r10-0x90], r1                    
    ldxdw r1, [r9+0x0]                      
    stxdw [r10-0x98], r1                    
    mov64 r7, r10                                   r7 = r10
    add64 r7, -208                                  r7 += -208   ///  r7 = r7.wrapping_add(-208 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -176                                  r2 += -176   ///  r2 = r2.wrapping_add(-176 as i32 as i64 as u64)
    mov64 r3, r10                                   r3 = r10
    add64 r3, -152                                  r3 += -152   ///  r3 = r3.wrapping_add(-152 as i32 as i64 as u64)
    mov64 r1, r7                                    r1 = r7
    call function_21448                     
    ldxdw r2, [r10-0x168]                   
    ldxdw r1, [r2+0x8]                      
    stxdw [r10-0x38], r1                    
    ldxdw r1, [r2+0x0]                      
    stxdw [r10-0x40], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -152                                  r1 += -152   ///  r1 = r1.wrapping_add(-152 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -64                                   r2 += -64   ///  r2 = r2.wrapping_add(-64 as i32 as i64 as u64)
    mov64 r3, r7                                    r3 = r7
    lddw r4, 0x1000613e3 --> b"Subtracting excess from other side pending"        r4 load str located at 4295365603
    mov64 r5, 42                                    r5 = 42 as i32 as i64 as u64
    call function_25291                     
    ldxb r7, [r10-0x98]                     
    jeq r7, 56, lbb_23543                           if r7 == (56 as i32 as i64 as u64) { pc += 1 }
    ja lbb_23636                                    if true { pc += 93 }
lbb_23543:
    ldxdw r1, [r10-0x94]                    
    stxdw [r10-0xad], r1                    
    stxdw [r10-0xc0], r1                    
    ldxdw r1, [r10-0x8c]                    
    stxdw [r10-0xa5], r1                    
    stxdw [r10-0xb8], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -80                                   r1 += -80   ///  r1 = r1.wrapping_add(-80 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -192                                  r2 += -192   ///  r2 = r2.wrapping_add(-192 as i32 as i64 as u64)
    lddw r3, 0x10005fda8 --> b"\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00AddrNotAv…        r3 load str located at 4295359912
    call function_33537                     
    ldxdw r1, [r10-0x48]                    
    ldxdw r2, [r10-0x168]                   
    stxdw [r2+0x8], r1                      
    ldxdw r1, [r10-0x50]                    
    stxdw [r2+0x0], r1                      
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    stxdw [r9+0x8], r1                      
    stxdw [r9+0x0], r1                      
lbb_23564:
    ldxdw r9, [r10-0x150]                   
    ldxdw r2, [r10-0x170]                   
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    mov64 r3, -1                                    r3 = -1 as i32 as i64 as u64
    jne r2, 0, lbb_23570                            if r2 != (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r3, 1                                     r3 = 1 as i32 as i64 as u64
lbb_23570:
    ldxb r2, [r8+0x4b]                      
    lsh64 r2, 56                                    r2 <<= 56   ///  r2 = r2.wrapping_shl(56)
    arsh64 r2, 56                                   r2 >>= 56 (signed)   ///  r2 = (r2 as i64).wrapping_shr(56)
    add64 r2, r3                                    r2 += r3   ///  r2 = r2.wrapping_add(r3)
    mov64 r3, 127                                   r3 = 127 as i32 as i64 as u64
    jsgt r3, r2, lbb_23577                          if (r3 as i64) > (r2 as i64) { pc += 1 }
    mov64 r2, 127                                   r2 = 127 as i32 as i64 as u64
lbb_23577:
    jsgt r2, -128, lbb_23579                        if (r2 as i64) > (-128 as i32 as i64) { pc += 1 }
    mov64 r2, -128                                  r2 = -128 as i32 as i64 as u64
lbb_23579:
    stxb [r8+0x4b], r2                      
    ldxdw r2, [r9+0x8]                      
    stxdw [r10-0x48], r2                    
    ldxdw r2, [r9+0x0]                      
    stxdw [r10-0x50], r2                    
    stxdw [r10-0x38], r1                    
    mov64 r7, 0                                     r7 = 0 as i32 as i64 as u64
    stxdw [r10-0x40], r7                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -152                                  r1 += -152   ///  r1 = r1.wrapping_add(-152 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -80                                   r2 += -80   ///  r2 = r2.wrapping_add(-80 as i32 as i64 as u64)
    mov64 r3, r10                                   r3 = r10
    add64 r3, -64                                   r3 += -64   ///  r3 = r3.wrapping_add(-64 as i32 as i64 as u64)
    lddw r4, 0x10006140d --> b"Sanity check mul by one bid"        r4 load str located at 4295365645
    mov64 r5, 27                                    r5 = 27 as i32 as i64 as u64
    call function_25589                     
    ldxb r8, [r10-0x98]                     
    jeq r8, 56, lbb_23600                           if r8 == (56 as i32 as i64 as u64) { pc += 1 }
    ja lbb_23656                                    if true { pc += 56 }
lbb_23600:
    ldxdw r1, [r10-0x8c]                    
    stxdw [r10-0xa5], r1                    
    ldxdw r2, [r10-0x94]                    
    stxdw [r10-0xad], r2                    
    stxdw [r9+0x8], r1                      
    stxdw [r9+0x0], r2                      
    ldxdw r8, [r10-0x160]                   
    ldxdw r1, [r8+0x8]                      
    stxdw [r10-0x48], r1                    
    ldxdw r1, [r8+0x0]                      
    stxdw [r10-0x50], r1                    
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    stxdw [r10-0x38], r1                    
    stxdw [r10-0x40], r7                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -152                                  r1 += -152   ///  r1 = r1.wrapping_add(-152 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -80                                   r2 += -80   ///  r2 = r2.wrapping_add(-80 as i32 as i64 as u64)
    mov64 r3, r10                                   r3 = r10
    add64 r3, -64                                   r3 += -64   ///  r3 = r3.wrapping_add(-64 as i32 as i64 as u64)
    lddw r4, 0x100061428 --> b"Sanity check mul by one ask"        r4 load str located at 4295365672
    mov64 r5, 27                                    r5 = 27 as i32 as i64 as u64
    call function_25589                     
    ldxb r7, [r10-0x98]                     
    jeq r7, 56, lbb_23627                           if r7 == (56 as i32 as i64 as u64) { pc += 1 }
    ja lbb_23636                                    if true { pc += 9 }
lbb_23627:
    ldxdw r1, [r10-0x8c]                    
    stxdw [r10-0xa5], r1                    
    ldxdw r2, [r10-0x94]                    
    stxdw [r10-0xad], r2                    
    stxdw [r8+0x8], r1                      
    stxdw [r8+0x0], r2                      
    mov64 r1, 56                                    r1 = 56 as i32 as i64 as u64
    stxb [r6+0x0], r1                       
    ja lbb_23655                                    if true { pc += 19 }
lbb_23636:
    ldxw r1, [r10-0x88]                     
    stxw [r10-0xa1], r1                     
    ldxdw r1, [r10-0x8f]                    
    stxdw [r10-0xa8], r1                    
    ldxdw r1, [r10-0x97]                    
    stxdw [r10-0xb0], r1                    
    mov64 r1, r6                                    r1 = r6
    add64 r1, 20                                    r1 += 20   ///  r1 = r1.wrapping_add(20 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -132                                  r2 += -132   ///  r2 = r2.wrapping_add(-132 as i32 as i64 as u64)
    mov64 r3, 52                                    r3 = 52 as i32 as i64 as u64
    call function_48190                     
    ldxw r1, [r10-0xa1]                     
    stxw [r6+0x10], r1                      
    ldxdw r1, [r10-0xa8]                    
    stxdw [r6+0x9], r1                      
    ldxdw r1, [r10-0xb0]                    
    stxdw [r6+0x1], r1                      
    stxb [r6+0x0], r7                       
lbb_23655:
    exit                                    
lbb_23656:
    ldxw r1, [r10-0x88]                     
    stxw [r10-0xa1], r1                     
    ldxdw r1, [r10-0x8f]                    
    stxdw [r10-0xa8], r1                    
    ldxdw r1, [r10-0x97]                    
    stxdw [r10-0xb0], r1                    
    mov64 r1, r6                                    r1 = r6
    add64 r1, 20                                    r1 += 20   ///  r1 = r1.wrapping_add(20 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -132                                  r2 += -132   ///  r2 = r2.wrapping_add(-132 as i32 as i64 as u64)
    mov64 r3, 52                                    r3 = 52 as i32 as i64 as u64
    call function_48190                     
    ldxw r1, [r10-0xa1]                     
    stxw [r6+0x10], r1                      
    ldxdw r1, [r10-0xa8]                    
    stxdw [r6+0x9], r1                      
    ldxdw r1, [r10-0xb0]                    
    stxdw [r6+0x1], r1                      
    stxb [r6+0x0], r8                       
    ja lbb_23655                                    if true { pc += -21 }

function_23676:
    mov64 r7, r2                                    r7 = r2
    mov64 r6, r1                                    r6 = r1
    ldxb r2, [r7+0x4c]                      
    jgt r2, 20, lbb_23681                           if r2 > (20 as i32 as i64 as u64) { pc += 1 }
    mov64 r2, 20                                    r2 = 20 as i32 as i64 as u64
lbb_23681:
    mov64 r1, r2                                    r1 = r2
    lsh64 r1, 56                                    r1 <<= 56   ///  r1 = r1.wrapping_shl(56)
    arsh64 r1, 56                                   r1 >>= 56 (signed)   ///  r1 = (r1 as i64).wrapping_shr(56)
    neg64 r2                                        r2 = -r2   ///  r2 = (r2 as i64).wrapping_neg() as u64
    lsh64 r2, 56                                    r2 <<= 56   ///  r2 = r2.wrapping_shl(56)
    arsh64 r2, 56                                   r2 >>= 56 (signed)   ///  r2 = (r2 as i64).wrapping_shr(56)
    jsge r1, r2, lbb_23695                          if (r1 as i64) >= (r2 as i64) { pc += 7 }
    lddw r1, 0x100060f41 --> b"assertion failed: min <= max"        r1 load str located at 4295364417
    mov64 r2, 28                                    r2 = 28 as i32 as i64 as u64
    lddw r3, 0x1000657e0 --> b"\x00\x00\x00\x00]\x0f\x06\x00P\x00\x00\x00\x00\x00\x00\x00l\x03\x00\x00\x…        r3 load str located at 4295383008
    call function_44254                     
    syscall [invalid]                       
lbb_23695:
    ldxb r4, [r7+0x4b]                      
    lsh64 r4, 56                                    r4 <<= 56   ///  r4 = r4.wrapping_shl(56)
    arsh64 r4, 56                                   r4 >>= 56 (signed)   ///  r4 = (r4 as i64).wrapping_shr(56)
    mov64 r5, r4                                    r5 = r4
    jsgt r1, r4, lbb_23701                          if (r1 as i64) > (r4 as i64) { pc += 1 }
    mov64 r5, r1                                    r5 = r1
lbb_23701:
    jsgt r2, r4, lbb_23703                          if (r2 as i64) > (r4 as i64) { pc += 1 }
    mov64 r2, r5                                    r2 = r5
lbb_23703:
    jeq r3, 0, lbb_23758                            if r3 == (0 as i32 as i64 as u64) { pc += 54 }
    mov64 r3, r2                                    r3 = r2
    lsh64 r3, 56                                    r3 <<= 56   ///  r3 = r3.wrapping_shl(56)
    arsh64 r3, 56                                   r3 >>= 56 (signed)   ///  r3 = (r3 as i64).wrapping_shr(56)
    jsgt r3, -1, lbb_23764                          if (r3 as i64) > (-1 as i32 as i64) { pc += 56 }
    neg64 r2                                        r2 = -r2   ///  r2 = (r2 as i64).wrapping_neg() as u64
    mov64 r3, r2                                    r3 = r2
lbb_23710:
    and64 r3, 255                                   r3 &= 255   ///  r3 = r3.and(255)
    stxw [r10-0x60], r3                     
    mov64 r8, 0                                     r8 = 0 as i32 as i64 as u64
    stxw [r10-0x5c], r8                     
    stxdw [r10-0x68], r8                    
    and64 r1, 255                                   r1 &= 255   ///  r1 = r1.and(255)
    stxw [r10-0x4c], r1                     
    stxw [r10-0x48], r8                     
    stxdw [r10-0x54], r8                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -68                                   r1 += -68   ///  r1 = r1.wrapping_add(-68 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -104                                  r2 += -104   ///  r2 = r2.wrapping_add(-104 as i32 as i64 as u64)
    mov64 r3, r10                                   r3 = r10
    add64 r3, -84                                   r3 += -84   ///  r3 = r3.wrapping_add(-84 as i32 as i64 as u64)
    call function_35767                     
    ldxw r1, [r10-0x44]                     
    jeq r1, 0, lbb_23729                            if r1 == (0 as i32 as i64 as u64) { pc += 1 }
    ja lbb_23811                                    if true { pc += 82 }
lbb_23729:
    ldxdw r1, [r10-0x38]                    
    stxdw [r10-0x70], r1                    
    ldxdw r1, [r10-0x40]                    
    stxdw [r10-0x78], r1                    
    ldxb r1, [r7+0x4d]                      
    stxw [r10-0x48], r8                     
    stxdw [r10-0x54], r8                    
    mov64 r2, 15                                    r2 = 15 as i32 as i64 as u64
    jgt r2, r1, lbb_23739                           if r2 > r1 { pc += 1 }
    mov64 r1, 15                                    r1 = 15 as i32 as i64 as u64
lbb_23739:
    stxw [r10-0x4c], r1                     
    mov64 r1, r10                                   r1 = r10
    add64 r1, -68                                   r1 += -68   ///  r1 = r1.wrapping_add(-68 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -84                                   r2 += -84   ///  r2 = r2.wrapping_add(-84 as i32 as i64 as u64)
    mov64 r3, r10                                   r3 = r10
    add64 r3, -120                                  r3 += -120   ///  r3 = r3.wrapping_add(-120 as i32 as i64 as u64)
    call function_37362                     
    ldxw r1, [r10-0x44]                     
    jeq r1, 0, lbb_23767                            if r1 == (0 as i32 as i64 as u64) { pc += 18 }
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    stxdw [r10-0x28], r1                    
    lddw r1, 0x100065790 --> b"\x00\x00\x00\x00\x12\x0f\x06\x00\x19\x00\x00\x00\x00\x00\x00\x00\x00\x00\…        r1 load str located at 4295382928
    stxdw [r10-0x30], r1                    
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    stxdw [r10-0x10], r1                    
    stxdw [r10-0x18], r1                    
    ja lbb_23797                                    if true { pc += 39 }
lbb_23758:
    lsh64 r2, 56                                    r2 <<= 56   ///  r2 = r2.wrapping_shl(56)
    arsh64 r2, 56                                   r2 >>= 56 (signed)   ///  r2 = (r2 as i64).wrapping_shr(56)
    mov64 r3, r2                                    r3 = r2
    jsgt r2, 0, lbb_23763                           if (r2 as i64) > (0 as i32 as i64) { pc += 1 }
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
lbb_23763:
    jsgt r2, 0, lbb_23710                           if (r2 as i64) > (0 as i32 as i64) { pc += -54 }
lbb_23764:
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    stxdw [r6+0x8], r1                      
    ja lbb_23809                                    if true { pc += 42 }
lbb_23767:
    ldxdw r1, [r10-0x38]                    
    stxdw [r10-0x60], r1                    
    ldxdw r1, [r10-0x40]                    
    stxdw [r10-0x68], r1                    
    mov64 r1, 5                                     r1 = 5 as i32 as i64 as u64
    stxdw [r10-0xff8], r1                   
    stxdw [r10-0x1000], r8                  
    mov64 r7, r10                                   r7 = r10
    add64 r7, -84                                   r7 += -84   ///  r7 = r7.wrapping_add(-84 as i32 as i64 as u64)
    mov64 r9, 1                                     r9 = 1 as i32 as i64 as u64
    mov64 r5, r10                                   r5 = r10
    mov64 r1, r7                                    r1 = r7
    mov64 r2, 1                                     r2 = 1 as i32 as i64 as u64
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
    mov64 r4, 0                                     r4 = 0 as i32 as i64 as u64
    call function_33183                     
    mov64 r1, r10                                   r1 = r10
    add64 r1, -68                                   r1 += -68   ///  r1 = r1.wrapping_add(-68 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -104                                  r2 += -104   ///  r2 = r2.wrapping_add(-104 as i32 as i64 as u64)
    mov64 r3, r7                                    r3 = r7
    call function_37362                     
    ldxw r1, [r10-0x44]                     
    jeq r1, 0, lbb_23806                            if r1 == (0 as i32 as i64 as u64) { pc += 15 }
    stxdw [r10-0x28], r9                    
    lddw r1, 0x100065790 --> b"\x00\x00\x00\x00\x12\x0f\x06\x00\x19\x00\x00\x00\x00\x00\x00\x00\x00\x00\…        r1 load str located at 4295382928
    stxdw [r10-0x30], r1                    
    stxdw [r10-0x10], r8                    
    stxdw [r10-0x18], r8                    
lbb_23797:
    lddw r1, 0x100060ee8 --> b"src/arithmetic_impls.rsAddition overflowedMultipli"        r1 load str located at 4295364328
    stxdw [r10-0x20], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -48                                   r1 += -48   ///  r1 = r1.wrapping_add(-48 as i32 as i64 as u64)
    lddw r2, 0x1000657a0 --> b"\x00\x00\x00\x00\xe8\x0e\x06\x00\x17\x00\x00\x00\x00\x00\x00\x00\xe8\x00\…        r2 load str located at 4295382944
    call function_44240                     
    syscall [invalid]                       
lbb_23806:
    ldxdw r1, [r10-0x38]                    
    stxdw [r6+0x8], r1                      
    ldxdw r1, [r10-0x40]                    
lbb_23809:
    stxdw [r6+0x0], r1                      
    exit                                    
lbb_23811:
    jeq r1, 1, lbb_23829                            if r1 == (1 as i32 as i64 as u64) { pc += 17 }
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    stxdw [r10-0x28], r1                    
    lddw r1, 0x100065740 --> b"\x00\x00\x00\x00\x88\xfc\x05\x00\x10\x00\x00\x00\x00\x00\x00\x00\x00\x00\…        r1 load str located at 4295382848
    stxdw [r10-0x30], r1                    
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    stxdw [r10-0x10], r1                    
    stxdw [r10-0x18], r1                    
    lddw r1, 0x100060ee8 --> b"src/arithmetic_impls.rsAddition overflowedMultipli"        r1 load str located at 4295364328
    stxdw [r10-0x20], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -48                                   r1 += -48   ///  r1 = r1.wrapping_add(-48 as i32 as i64 as u64)
    lddw r2, 0x100065750 --> b"\x00\x00\x00\x00\xe8\x0e\x06\x00\x17\x00\x00\x00\x00\x00\x00\x00\xdb\x00\…        r2 load str located at 4295382864
    call function_44240                     
    syscall [invalid]                       
lbb_23829:
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    stxdw [r10-0x28], r1                    
    lddw r1, 0x100065718 --> b"\x00\x00\x00\x00\xd5\x0e\x06\x00\x13\x00\x00\x00\x00\x00\x00\x00\x00\x00\…        r1 load str located at 4295382808
    stxdw [r10-0x30], r1                    
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    stxdw [r10-0x10], r1                    
    stxdw [r10-0x18], r1                    
    lddw r1, 0x100060ee8 --> b"src/arithmetic_impls.rsAddition overflowedMultipli"        r1 load str located at 4295364328
    stxdw [r10-0x20], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -48                                   r1 += -48   ///  r1 = r1.wrapping_add(-48 as i32 as i64 as u64)
    lddw r2, 0x100065728 --> b"\x00\x00\x00\x00\xe8\x0e\x06\x00\x17\x00\x00\x00\x00\x00\x00\x00\xda\x00\…        r2 load str located at 4295382824
    call function_44240                     
    syscall [invalid]                       

function_23846:
    stxdw [r10-0x8], r1                     
    ldxw r1, [r1+0x2100]                    
    mov64 r3, 257                                   r3 = 257 as i32 as i64 as u64
    jgt r3, r1, lbb_23855                           if r3 > r1 { pc += 5 }
    mov64 r2, 256                                   r2 = 256 as i32 as i64 as u64
    lddw r3, 0x1000658e0 --> b"\x00\x00\x00\x00m\x14\x06\x00\x17\x00\x00\x00\x00\x00\x00\x007\x00\x00\x0…        r3 load str located at 4295383264
    call function_46535                     
    syscall [invalid]                       
lbb_23855:
    mov64 r0, 0                                     r0 = 0 as i32 as i64 as u64
    mov64 r3, r1                                    r3 = r1
    jeq r1, 0, lbb_23927                            if r1 == (0 as i32 as i64 as u64) { pc += 69 }
    mov64 r6, 0                                     r6 = 0 as i32 as i64 as u64
    mov64 r7, r3                                    r7 = r3
    mov64 r5, r7                                    r5 = r7
    ja lbb_23873                                    if true { pc += 11 }
lbb_23862:
    jeq r0, 1, lbb_23868                            if r0 == (1 as i32 as i64 as u64) { pc += 5 }
    and64 r0, 255                                   r0 &= 255   ///  r0 = r0.and(255)
    jne r0, 255, lbb_23916                          if r0 != (255 as i32 as i64 as u64) { pc += 51 }
    mov64 r6, r5                                    r6 = r5
    add64 r6, 1                                     r6 += 1   ///  r6 = r6.wrapping_add(1 as i32 as i64 as u64)
    mov64 r5, r7                                    r5 = r7
lbb_23868:
    mov64 r7, r5                                    r7 = r5
    mov64 r0, 0                                     r0 = 0 as i32 as i64 as u64
    sub64 r5, r6                                    r5 -= r6   ///  r5 = r5.wrapping_sub(r6)
    jgt r7, r6, lbb_23873                           if r7 > r6 { pc += 1 }
    ja lbb_23927                                    if true { pc += 54 }
lbb_23873:
    rsh64 r5, 1                                     r5 >>= 1   ///  r5 = r5.wrapping_shr(1)
    add64 r5, r6                                    r5 += r6   ///  r5 = r5.wrapping_add(r6)
    mov64 r4, r5                                    r4 = r5
    mul64 r4, 33                                    r4 *= 33   ///  r4 = r4.wrapping_mul(33 as u64)
    ldxdw r1, [r10-0x8]                     
    add64 r1, r4                                    r1 += r4   ///  r1 = r1.wrapping_add(r4)
    ldxdw r9, [r1+0x0]                      
    be64 r9                                         r9 = match 64 { 16 => (r9 as u16).swap_bytes() as u64, 32 => (r9 as u32).swap_bytes() as u64, 64 => r9.swap_bytes(), _ => r9 }
    ldxdw r0, [r2+0x0]                      
    be64 r0                                         r0 = match 64 { 16 => (r0 as u16).swap_bytes() as u64, 32 => (r0 as u32).swap_bytes() as u64, 64 => r0.swap_bytes(), _ => r0 }
    jeq r9, r0, lbb_23888                           if r9 == r0 { pc += 4 }
lbb_23884:
    mov64 r8, -1                                    r8 = -1 as i32 as i64 as u64
    jgt r0, r9, lbb_23904                           if r0 > r9 { pc += 18 }
    mov64 r8, 1                                     r8 = 1 as i32 as i64 as u64
    ja lbb_23904                                    if true { pc += 16 }
lbb_23888:
    ldxdw r0, [r2+0x8]                      
    be64 r0                                         r0 = match 64 { 16 => (r0 as u16).swap_bytes() as u64, 32 => (r0 as u32).swap_bytes() as u64, 64 => r0.swap_bytes(), _ => r0 }
    ldxdw r9, [r1+0x8]                      
    be64 r9                                         r9 = match 64 { 16 => (r9 as u16).swap_bytes() as u64, 32 => (r9 as u32).swap_bytes() as u64, 64 => r9.swap_bytes(), _ => r9 }
    jne r9, r0, lbb_23884                           if r9 != r0 { pc += -9 }
    ldxdw r0, [r2+0x10]                     
    be64 r0                                         r0 = match 64 { 16 => (r0 as u16).swap_bytes() as u64, 32 => (r0 as u32).swap_bytes() as u64, 64 => r0.swap_bytes(), _ => r0 }
    ldxdw r9, [r1+0x10]                     
    be64 r9                                         r9 = match 64 { 16 => (r9 as u16).swap_bytes() as u64, 32 => (r9 as u32).swap_bytes() as u64, 64 => r9.swap_bytes(), _ => r9 }
    jne r9, r0, lbb_23884                           if r9 != r0 { pc += -14 }
    mov64 r8, 0                                     r8 = 0 as i32 as i64 as u64
    ldxdw r0, [r2+0x18]                     
    be64 r0                                         r0 = match 64 { 16 => (r0 as u16).swap_bytes() as u64, 32 => (r0 as u32).swap_bytes() as u64, 64 => r0.swap_bytes(), _ => r0 }
    ldxdw r9, [r1+0x18]                     
    be64 r9                                         r9 = match 64 { 16 => (r9 as u16).swap_bytes() as u64, 32 => (r9 as u32).swap_bytes() as u64, 64 => r9.swap_bytes(), _ => r9 }
    jne r9, r0, lbb_23884                           if r9 != r0 { pc += -20 }
lbb_23904:
    lsh64 r8, 32                                    r8 <<= 32   ///  r8 = r8.wrapping_shl(32)
    mov64 r0, r8                                    r0 = r8
    rsh64 r0, 32                                    r0 >>= 32   ///  r0 = r0.wrapping_shr(32)
    mov64 r9, 0                                     r9 = 0 as i32 as i64 as u64
    mov64 r4, 1                                     r4 = 1 as i32 as i64 as u64
    jne r0, 0, lbb_23911                            if r0 != (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r4, 0                                     r4 = 0 as i32 as i64 as u64
lbb_23911:
    arsh64 r8, 32                                   r8 >>= 32 (signed)   ///  r8 = (r8 as i64).wrapping_shr(32)
    mov64 r0, -1                                    r0 = -1 as i32 as i64 as u64
    jsgt r9, r8, lbb_23862                          if (r9 as i64) > (r8 as i64) { pc += -52 }
    mov64 r0, r4                                    r0 = r4
    ja lbb_23862                                    if true { pc += -54 }
lbb_23916:
    mov64 r4, r3                                    r4 = r3
    add64 r4, -1                                    r4 += -1   ///  r4 = r4.wrapping_add(-1 as i32 as i64 as u64)
    ldxdw r2, [r10-0x8]                     
    stxw [r2+0x2100], r4                    
    add64 r5, 1                                     r5 += 1   ///  r5 = r5.wrapping_add(1 as i32 as i64 as u64)
    sub64 r3, r5                                    r3 -= r5   ///  r3 = r3.wrapping_sub(r5)
    mul64 r5, 33                                    r5 *= 33   ///  r5 = r5.wrapping_mul(33 as u64)
    add64 r2, r5                                    r2 += r5   ///  r2 = r2.wrapping_add(r5)
    mul64 r3, 33                                    r3 *= 33   ///  r3 = r3.wrapping_mul(33 as u64)
    call function_48224                     
    mov64 r0, 1                                     r0 = 1 as i32 as i64 as u64
lbb_23927:
    exit                                    

function_23928:
    stxdw [r10-0x40], r3                    
    stxdw [r10-0x38], r2                    
    mov64 r6, r1                                    r6 = r1
    ldxw r3, [r6+0x2100]                    
    mov64 r1, 257                                   r1 = 257 as i32 as i64 as u64
    jgt r1, r3, lbb_23940                           if r1 > r3 { pc += 6 }
    mov64 r1, r3                                    r1 = r3
    mov64 r2, 256                                   r2 = 256 as i32 as i64 as u64
    lddw r3, 0x1000658f8 --> b"\x00\x00\x00\x00m\x14\x06\x00\x17\x00\x00\x00\x00\x00\x00\x00I\x00\x00\x0…        r3 load str located at 4295383288
    call function_46535                     
    syscall [invalid]                       
lbb_23940:
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    jeq r3, 0, lbb_24007                            if r3 == (0 as i32 as i64 as u64) { pc += 65 }
    mov64 r2, r3                                    r2 = r3
    mov64 r4, r3                                    r4 = r3
    ja lbb_23959                                    if true { pc += 14 }
lbb_23945:
    mov64 r6, r8                                    r6 = r8
    jeq r0, 1, lbb_23952                            if r0 == (1 as i32 as i64 as u64) { pc += 5 }
    and64 r0, 255                                   r0 &= 255   ///  r0 = r0.and(255)
    jne r0, 255, lbb_24048                          if r0 != (255 as i32 as i64 as u64) { pc += 99 }
    mov64 r1, r2                                    r1 = r2
    add64 r1, 1                                     r1 += 1   ///  r1 = r1.wrapping_add(1 as i32 as i64 as u64)
    mov64 r2, r4                                    r2 = r4
lbb_23952:
    mov64 r4, r2                                    r4 = r2
    sub64 r2, r1                                    r2 -= r1   ///  r2 = r2.wrapping_sub(r1)
    jgt r4, r1, lbb_23959                           if r4 > r1 { pc += 4 }
    mov64 r0, 0                                     r0 = 0 as i32 as i64 as u64
    mov64 r2, 256                                   r2 = 256 as i32 as i64 as u64
    jgt r2, r3, lbb_24007                           if r2 > r3 { pc += 49 }
    ja lbb_24053                                    if true { pc += 94 }
lbb_23959:
    rsh64 r2, 1                                     r2 >>= 1   ///  r2 = r2.wrapping_shr(1)
    add64 r2, r1                                    r2 += r1   ///  r2 = r2.wrapping_add(r1)
    mov64 r5, r2                                    r5 = r2
    mul64 r5, 33                                    r5 *= 33   ///  r5 = r5.wrapping_mul(33 as u64)
    mov64 r8, r6                                    r8 = r6
    mov64 r9, r6                                    r9 = r6
    add64 r9, r5                                    r9 += r5   ///  r9 = r9.wrapping_add(r5)
    ldxdw r7, [r9+0x0]                      
    be64 r7                                         r7 = match 64 { 16 => (r7 as u16).swap_bytes() as u64, 32 => (r7 as u32).swap_bytes() as u64, 64 => r7.swap_bytes(), _ => r7 }
    ldxdw r0, [r10-0x38]                    
    ldxdw r0, [r0+0x0]                      
    be64 r0                                         r0 = match 64 { 16 => (r0 as u16).swap_bytes() as u64, 32 => (r0 as u32).swap_bytes() as u64, 64 => r0.swap_bytes(), _ => r0 }
    jeq r7, r0, lbb_23976                           if r7 == r0 { pc += 4 }
lbb_23972:
    mov64 r6, -1                                    r6 = -1 as i32 as i64 as u64
    jgt r0, r7, lbb_23995                           if r0 > r7 { pc += 21 }
    mov64 r6, 1                                     r6 = 1 as i32 as i64 as u64
    ja lbb_23995                                    if true { pc += 19 }
lbb_23976:
    ldxdw r0, [r10-0x38]                    
    ldxdw r0, [r0+0x8]                      
    be64 r0                                         r0 = match 64 { 16 => (r0 as u16).swap_bytes() as u64, 32 => (r0 as u32).swap_bytes() as u64, 64 => r0.swap_bytes(), _ => r0 }
    ldxdw r7, [r9+0x8]                      
    be64 r7                                         r7 = match 64 { 16 => (r7 as u16).swap_bytes() as u64, 32 => (r7 as u32).swap_bytes() as u64, 64 => r7.swap_bytes(), _ => r7 }
    jne r7, r0, lbb_23972                           if r7 != r0 { pc += -10 }
    ldxdw r0, [r10-0x38]                    
    ldxdw r0, [r0+0x10]                     
    be64 r0                                         r0 = match 64 { 16 => (r0 as u16).swap_bytes() as u64, 32 => (r0 as u32).swap_bytes() as u64, 64 => r0.swap_bytes(), _ => r0 }
    ldxdw r7, [r9+0x10]                     
    be64 r7                                         r7 = match 64 { 16 => (r7 as u16).swap_bytes() as u64, 32 => (r7 as u32).swap_bytes() as u64, 64 => r7.swap_bytes(), _ => r7 }
    jne r7, r0, lbb_23972                           if r7 != r0 { pc += -16 }
    mov64 r6, 0                                     r6 = 0 as i32 as i64 as u64
    ldxdw r0, [r10-0x38]                    
    ldxdw r0, [r0+0x18]                     
    be64 r0                                         r0 = match 64 { 16 => (r0 as u16).swap_bytes() as u64, 32 => (r0 as u32).swap_bytes() as u64, 64 => r0.swap_bytes(), _ => r0 }
    ldxdw r7, [r9+0x18]                     
    be64 r7                                         r7 = match 64 { 16 => (r7 as u16).swap_bytes() as u64, 32 => (r7 as u32).swap_bytes() as u64, 64 => r7.swap_bytes(), _ => r7 }
    jne r7, r0, lbb_23972                           if r7 != r0 { pc += -23 }
lbb_23995:
    lsh64 r6, 32                                    r6 <<= 32   ///  r6 = r6.wrapping_shl(32)
    mov64 r0, r6                                    r0 = r6
    rsh64 r0, 32                                    r0 >>= 32   ///  r0 = r0.wrapping_shr(32)
    mov64 r7, 0                                     r7 = 0 as i32 as i64 as u64
    mov64 r9, 1                                     r9 = 1 as i32 as i64 as u64
    jne r0, 0, lbb_24002                            if r0 != (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r9, 0                                     r9 = 0 as i32 as i64 as u64
lbb_24002:
    arsh64 r6, 32                                   r6 >>= 32 (signed)   ///  r6 = (r6 as i64).wrapping_shr(32)
    mov64 r0, -1                                    r0 = -1 as i32 as i64 as u64
    jsgt r7, r6, lbb_23945                          if (r7 as i64) > (r6 as i64) { pc += -60 }
    mov64 r0, r9                                    r0 = r9
    ja lbb_23945                                    if true { pc += -62 }
lbb_24007:
    mov64 r2, r3                                    r2 = r3
    add64 r2, 1                                     r2 += 1   ///  r2 = r2.wrapping_add(1 as i32 as i64 as u64)
    stxw [r6+0x2100], r2                    
    mov64 r2, r1                                    r2 = r1
    add64 r2, 1                                     r2 += 1   ///  r2 = r2.wrapping_add(1 as i32 as i64 as u64)
    jgt r2, r1, lbb_24030                           if r2 > r1 { pc += 17 }
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    stxdw [r10-0x28], r1                    
    lddw r1, 0x100065820 --> b"\x00\x00\x00\x00\x0d\x10\x06\x00\x15\x00\x00\x00\x00\x00\x00\x00\x00\x00\…        r1 load str located at 4295383072
    stxdw [r10-0x30], r1                    
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    stxdw [r10-0x10], r1                    
    stxdw [r10-0x18], r1                    
    lddw r1, 0x100060ee8 --> b"src/arithmetic_impls.rsAddition overflowedMultipli"        r1 load str located at 4295364328
    stxdw [r10-0x20], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -48                                   r1 += -48   ///  r1 = r1.wrapping_add(-48 as i32 as i64 as u64)
    lddw r2, 0x100065910 --> b"\x00\x00\x00\x00m\x14\x06\x00\x17\x00\x00\x00\x00\x00\x00\x00U\x00\x00\x0…        r2 load str located at 4295383312
    call function_44240                     
    syscall [invalid]                       
lbb_24030:
    sub64 r3, r1                                    r3 -= r1   ///  r3 = r3.wrapping_sub(r1)
    mul64 r1, 33                                    r1 *= 33   ///  r1 = r1.wrapping_mul(33 as u64)
    add64 r6, r1                                    r6 += r1   ///  r6 = r6.wrapping_add(r1)
    mul64 r3, 33                                    r3 *= 33   ///  r3 = r3.wrapping_mul(33 as u64)
    mov64 r1, r6                                    r1 = r6
    add64 r1, 33                                    r1 += 33   ///  r1 = r1.wrapping_add(33 as i32 as i64 as u64)
    mov64 r2, r6                                    r2 = r6
    call function_48224                     
    ldxdw r2, [r10-0x38]                    
    ldxdw r1, [r2+0x0]                      
    stxdw [r6+0x0], r1                      
    ldxdw r1, [r2+0x8]                      
    stxdw [r6+0x8], r1                      
    ldxdw r1, [r2+0x10]                     
    stxdw [r6+0x10], r1                     
    ldxdw r1, [r2+0x18]                     
    stxdw [r6+0x18], r1                     
    ja lbb_24049                                    if true { pc += 1 }
lbb_24048:
    add64 r6, r5                                    r6 += r5   ///  r6 = r6.wrapping_add(r5)
lbb_24049:
    add64 r6, 32                                    r6 += 32   ///  r6 = r6.wrapping_add(32 as i32 as i64 as u64)
    ldxdw r1, [r10-0x40]                    
    stxb [r6+0x0], r1                       
    mov64 r0, 1                                     r0 = 1 as i32 as i64 as u64
lbb_24053:
    exit                                    

function_24054:
    mov64 r7, r3                                    r7 = r3
    mov64 r8, r2                                    r8 = r2
    mov64 r6, r1                                    r6 = r1
    mov64 r1, r10                                   r1 = r10
    add64 r1, -72                                   r1 += -72   ///  r1 = r1.wrapping_add(-72 as i32 as i64 as u64)
    lddw r2, 0x100061022 --> b"\x8b\xbc\x13%\x8a\x81u\xd1\xc8\xf9\x18\xd1\x1du\xbb\x9d\xf3\xa2&\x0b\x8c\…        r2 load str located at 4295364642
    lddw r4, 0x100061484 --> b"Invalid dex program ID for dex PDA derivation"        r4 load str located at 4295365764
    mov64 r5, 45                                    r5 = 45 as i32 as i64 as u64
    call function_30095                     
    ldxb r9, [r10-0x48]                     
    jne r9, 56, lbb_24083                           if r9 != (56 as i32 as i64 as u64) { pc += 16 }
    mov64 r1, 32                                    r1 = 32 as i32 as i64 as u64
    stxdw [r10-0x30], r1                    
    stxdw [r10-0x38], r8                    
    mov64 r1, 3                                     r1 = 3 as i32 as i64 as u64
    stxdw [r10-0x40], r1                    
    lddw r1, 0x1000614b1 --> b"dexInvalid dex program ID for dex PDA verification"        r1 load str located at 4295365809
    stxdw [r10-0x48], r1                    
    mov64 r1, r6                                    r1 = r6
    add64 r1, 1                                     r1 += 1   ///  r1 = r1.wrapping_add(1 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -72                                   r2 += -72   ///  r2 = r2.wrapping_add(-72 as i32 as i64 as u64)
    mov64 r3, 2                                     r3 = 2 as i32 as i64 as u64
    mov64 r4, r7                                    r4 = r7
    call function_40843                     
    ja lbb_24089                                    if true { pc += 6 }
lbb_24083:
    mov64 r1, r6                                    r1 = r6
    add64 r1, 1                                     r1 += 1   ///  r1 = r1.wrapping_add(1 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -71                                   r2 += -71   ///  r2 = r2.wrapping_add(-71 as i32 as i64 as u64)
    mov64 r3, 71                                    r3 = 71 as i32 as i64 as u64
    call function_48190                     
lbb_24089:
    stxb [r6+0x0], r9                       
    exit                                    

function_24091:
    mov64 r8, r5                                    r8 = r5
    stxdw [r10-0x128], r4                   
    stxdw [r10-0x120], r3                   
    mov64 r7, r2                                    r7 = r2
    mov64 r9, r1                                    r9 = r1
    mov64 r1, r10                                   r1 = r10
    add64 r1, -216                                  r1 += -216   ///  r1 = r1.wrapping_add(-216 as i32 as i64 as u64)
    lddw r2, 0x100061022 --> b"\x8b\xbc\x13%\x8a\x81u\xd1\xc8\xf9\x18\xd1\x1du\xbb\x9d\xf3\xa2&\x0b\x8c\…        r2 load str located at 4295364642
    mov64 r3, r8                                    r3 = r8
    lddw r4, 0x1000614b4 --> b"Invalid dex program ID for dex PDA verification"        r4 load str located at 4295365812
    mov64 r5, 47                                    r5 = 47 as i32 as i64 as u64
    call function_30095                     
    ldxb r6, [r10-0xd8]                     
    jne r6, 56, lbb_24163                           if r6 != (56 as i32 as i64 as u64) { pc += 56 }
    mov64 r6, r7                                    r6 = r7
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    stxdw [r10-0x40], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -56                                   r1 += -56   ///  r1 = r1.wrapping_add(-56 as i32 as i64 as u64)
    stxdw [r10-0x48], r1                    
    mov64 r1, 32                                    r1 = 32 as i32 as i64 as u64
    stxdw [r10-0x50], r1                    
    ldxdw r1, [r10-0x128]                   
    stxdw [r10-0x58], r1                    
    lddw r1, 0x1000614b1 --> b"dexInvalid dex program ID for dex PDA verification"        r1 load str located at 4295365809
    stxdw [r10-0x68], r1                    
    ldxdw r1, [r10-0x120]                   
    stxb [r10-0x38], r1                     
    mov64 r1, 3                                     r1 = 3 as i32 as i64 as u64
    stxdw [r10-0x60], r1                    
    mov64 r7, r10                                   r7 = r10
    add64 r7, -144                                  r7 += -144   ///  r7 = r7.wrapping_add(-144 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -104                                  r2 += -104   ///  r2 = r2.wrapping_add(-104 as i32 as i64 as u64)
    mov64 r1, r7                                    r1 = r7
    mov64 r3, 3                                     r3 = 3 as i32 as i64 as u64
    mov64 r4, r8                                    r4 = r8
    call function_40888                     
    lddw r1, 0x1000614e3 --> b"Could not derive dex pda from owner and bumpsdk/sr"        r1 load str located at 4295365859
    stxdw [r10-0x1000], r1                  
    mov64 r1, 44                                    r1 = 44 as i32 as i64 as u64
    stxdw [r10-0xff8], r1                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -216                                  r1 += -216   ///  r1 = r1.wrapping_add(-216 as i32 as i64 as u64)
    mov64 r5, r10                                   r5 = r10
    mov64 r2, r7                                    r2 = r7
    lddw r3, 0x1000614e3 --> b"Could not derive dex pda from owner and bump"        r3 load str located at 4295365859
    mov64 r4, 44                                    r4 = 44 as i32 as i64 as u64
    call function_25690                     
    ldxb r7, [r10-0xd8]                     
    jeq r7, 56, lbb_24148                           if r7 == (56 as i32 as i64 as u64) { pc += 1 }
    ja lbb_24171                                    if true { pc += 23 }
lbb_24148:
    ldxdw r1, [r10-0xcf]                    
    stxdw [r10-0xf0], r1                    
    stxdw [r10-0x110], r1                   
    ldxdw r1, [r10-0xc7]                    
    stxdw [r10-0xe8], r1                    
    stxdw [r10-0x108], r1                   
    ldxdw r1, [r10-0xbf]                    
    stxdw [r10-0xe0], r1                    
    stxdw [r10-0x100], r1                   
    ldxdw r1, [r10-0xd7]                    
    stxdw [r10-0x118], r1                   
    ldxdw r2, [r6+0x0]                      
    jeq r2, r1, lbb_24195                           if r2 == r1 { pc += 34 }
lbb_24161:
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    ja lbb_24205                                    if true { pc += 42 }
lbb_24163:
    mov64 r1, r9                                    r1 = r9
    add64 r1, 1                                     r1 += 1   ///  r1 = r1.wrapping_add(1 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -215                                  r2 += -215   ///  r2 = r2.wrapping_add(-215 as i32 as i64 as u64)
    mov64 r3, 71                                    r3 = 71 as i32 as i64 as u64
    call function_48190                     
    stxb [r9+0x0], r6                       
    ja lbb_24273                                    if true { pc += 102 }
lbb_24171:
    ldxdw r1, [r10-0xbf]                    
    stxdw [r10-0xe0], r1                    
    ldxdw r1, [r10-0xc7]                    
    stxdw [r10-0xe8], r1                    
    ldxdw r1, [r10-0xcf]                    
    stxdw [r10-0xf0], r1                    
    ldxdw r1, [r10-0xd7]                    
    stxdw [r10-0xf8], r1                    
    mov64 r1, r9                                    r1 = r9
    add64 r1, 33                                    r1 += 33   ///  r1 = r1.wrapping_add(33 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -183                                  r2 += -183   ///  r2 = r2.wrapping_add(-183 as i32 as i64 as u64)
    mov64 r3, 39                                    r3 = 39 as i32 as i64 as u64
    call function_48190                     
    ldxdw r1, [r10-0xe0]                    
    stxdw [r9+0x19], r1                     
    ldxdw r1, [r10-0xe8]                    
    stxdw [r9+0x11], r1                     
    ldxdw r1, [r10-0xf0]                    
    stxdw [r9+0x9], r1                      
    ldxdw r1, [r10-0xf8]                    
    stxdw [r9+0x1], r1                      
    stxb [r9+0x0], r7                       
    ja lbb_24273                                    if true { pc += 78 }
lbb_24195:
    ldxdw r1, [r6+0x8]                      
    ldxdw r2, [r10-0x110]                   
    jne r1, r2, lbb_24161                           if r1 != r2 { pc += -37 }
    ldxdw r1, [r6+0x10]                     
    ldxdw r2, [r10-0x108]                   
    jne r1, r2, lbb_24161                           if r1 != r2 { pc += -40 }
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    ldxdw r2, [r6+0x18]                     
    ldxdw r3, [r10-0x100]                   
    jne r2, r3, lbb_24161                           if r2 != r3 { pc += -44 }
lbb_24205:
    mov64 r2, 16                                    r2 = 16 as i32 as i64 as u64
    stxdw [r10-0xf0], r2                    
    lddw r2, 0x10005fd78 --> b"Dex pda mismatchPermissionDeniedno storage space\x00\x00"        r2 load str located at 4295359864
    stxdw [r10-0xf8], r2                    
    jeq r1, 0, lbb_24271                            if r1 == (0 as i32 as i64 as u64) { pc += 60 }
    lddw r1, 0x100065928 --> b"\x00\x00\x00\x00\x0f\x15\x06\x00\x19\x00\x00\x00\x00\x00\x00\x00$\x00\x00…        r1 load str located at 4295383336
    stxdw [r10-0x38], r1                    
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    stxdw [r10-0xb8], r1                    
    lddw r1, 0x100065a98 --> b"\x00\x00\x00\x00\xe8\x0e\x06\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\…        r1 load str located at 4295383704
    stxdw [r10-0xd8], r1                    
    mov64 r1, 2                                     r1 = 2 as i32 as i64 as u64
    stxdw [r10-0xd0], r1                    
    stxdw [r10-0xc0], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -104                                  r1 += -104   ///  r1 = r1.wrapping_add(-104 as i32 as i64 as u64)
    stxdw [r10-0xc8], r1                    
    lddw r1, 0x10002a248 --> b"y\x11\x00\x00\x00\x00\x00\x00\x85\x10\x00\x00%X\x00\x00\x95\x00\x00\x00\x…        r1 load str located at 4295139912
    stxdw [r10-0x50], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -56                                   r1 += -56   ///  r1 = r1.wrapping_add(-56 as i32 as i64 as u64)
    stxdw [r10-0x58], r1                    
    lddw r1, 0x10002a388 --> b"\xbf#\x00\x00\x00\x00\x00\x00y\x12\x08\x00\x00\x00\x00\x00y\x11\x00\x00\x…        r1 load str located at 4295140232
    stxdw [r10-0x60], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -248                                  r1 += -248   ///  r1 = r1.wrapping_add(-248 as i32 as i64 as u64)
    stxdw [r10-0x68], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -144                                  r1 += -144   ///  r1 = r1.wrapping_add(-144 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -216                                  r2 += -216   ///  r2 = r2.wrapping_add(-216 as i32 as i64 as u64)
    call function_43415                     
    ldxdw r7, [r10-0x88]                    
    ldxdw r8, [r10-0x90]                    
    ldxdw r2, [r10-0x80]                    
    mov64 r1, r8                                    r1 = r8
    syscall [invalid]                       
    jeq r7, 0, lbb_24252                            if r7 == (0 as i32 as i64 as u64) { pc += 4 }
    mov64 r1, r8                                    r1 = r8
    mov64 r2, r7                                    r2 = r7
    mov64 r3, 1                                     r3 = 1 as i32 as i64 as u64
    call function_21385                     
lbb_24252:
    mov64 r1, 18                                    r1 = 18 as i32 as i64 as u64
    stxb [r9+0x0], r1                       
    ldxdw r1, [r10-0x118]                   
    stxdw [r9+0x1], r1                      
    ldxdw r1, [r10-0x110]                   
    stxdw [r9+0x9], r1                      
    ldxdw r1, [r10-0x108]                   
    stxdw [r9+0x11], r1                     
    ldxdw r1, [r10-0x100]                   
    stxdw [r9+0x19], r1                     
    ldxdw r1, [r6+0x0]                      
    stxdw [r9+0x21], r1                     
    ldxdw r1, [r6+0x8]                      
    stxdw [r9+0x29], r1                     
    ldxdw r1, [r6+0x10]                     
    stxdw [r9+0x31], r1                     
    ldxdw r1, [r6+0x18]                     
    stxdw [r9+0x39], r1                     
    ja lbb_24273                                    if true { pc += 2 }
lbb_24271:
    mov64 r1, 56                                    r1 = 56 as i32 as i64 as u64
    stxb [r9+0x0], r1                       
lbb_24273:
    exit                                    

function_24274:
    mov64 r7, r4                                    r7 = r4
    stxdw [r10-0x58], r3                    
    mov64 r9, r2                                    r9 = r2
    mov64 r6, r1                                    r6 = r1
    mov64 r1, r10                                   r1 = r10
    add64 r1, -80                                   r1 += -80   ///  r1 = r1.wrapping_add(-80 as i32 as i64 as u64)
    lddw r2, 0x100061022 --> b"\x8b\xbc\x13%\x8a\x81u\xd1\xc8\xf9\x18\xd1\x1du\xbb\x9d\xf3\xa2&\x0b\x8c\…        r2 load str located at 4295364642
    mov64 r3, r7                                    r3 = r7
    lddw r4, 0x100061528 --> b"Invalid dex program ID for dex instance PDA derivation"        r4 load str located at 4295365928
    mov64 r5, 54                                    r5 = 54 as i32 as i64 as u64
    call function_30095                     
    ldxb r8, [r10-0x50]                     
    jne r8, 56, lbb_24312                           if r8 != (56 as i32 as i64 as u64) { pc += 23 }
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    stxdw [r10-0x28], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -1                                    r1 += -1   ///  r1 = r1.wrapping_add(-1 as i32 as i64 as u64)
    stxdw [r10-0x30], r1                    
    mov64 r1, 32                                    r1 = 32 as i32 as i64 as u64
    stxdw [r10-0x38], r1                    
    stxdw [r10-0x40], r9                    
    mov64 r1, 12                                    r1 = 12 as i32 as i64 as u64
    stxdw [r10-0x48], r1                    
    lddw r1, 0x10006155e --> b"dex_instanceInvalid dex program ID for dex instanc"        r1 load str located at 4295365982
    stxdw [r10-0x50], r1                    
    ldxdw r1, [r10-0x58]                    
    stxb [r10-0x1], r1                      
    mov64 r1, r6                                    r1 = r6
    add64 r1, 1                                     r1 += 1   ///  r1 = r1.wrapping_add(1 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -80                                   r2 += -80   ///  r2 = r2.wrapping_add(-80 as i32 as i64 as u64)
    mov64 r3, 3                                     r3 = 3 as i32 as i64 as u64
    mov64 r4, r7                                    r4 = r7
    call function_40843                     
    ja lbb_24318                                    if true { pc += 6 }
lbb_24312:
    mov64 r1, r6                                    r1 = r6
    add64 r1, 1                                     r1 += 1   ///  r1 = r1.wrapping_add(1 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -79                                   r2 += -79   ///  r2 = r2.wrapping_add(-79 as i32 as i64 as u64)
    mov64 r3, 71                                    r3 = 71 as i32 as i64 as u64
    call function_48190                     
lbb_24318:
    stxb [r6+0x0], r8                       
    exit                                    

function_24320:
    mov64 r6, r5                                    r6 = r5
    stxdw [r10-0x140], r4                   
    stxdw [r10-0x138], r3                   
    stxdw [r10-0x148], r2                   
    mov64 r7, r1                                    r7 = r1
    ldxdw r8, [r6-0xff8]                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -240                                  r1 += -240   ///  r1 = r1.wrapping_add(-240 as i32 as i64 as u64)
    lddw r2, 0x100061022 --> b"\x8b\xbc\x13%\x8a\x81u\xd1\xc8\xf9\x18\xd1\x1du\xbb\x9d\xf3\xa2&\x0b\x8c\…        r2 load str located at 4295364642
    mov64 r3, r8                                    r3 = r8
    lddw r4, 0x10006156a --> b"Invalid dex program ID for dex instance PDA verification"        r4 load str located at 4295365994
    mov64 r5, 56                                    r5 = 56 as i32 as i64 as u64
    call function_30095                     
    ldxb r9, [r10-0xf0]                     
    jne r9, 56, lbb_24399                           if r9 != (56 as i32 as i64 as u64) { pc += 62 }
    ldxdw r9, [r10-0x148]                   
    ldxdw r1, [r6-0x1000]                   
    stxb [r10-0x39], r1                     
    mov64 r1, r10                                   r1 = r10
    add64 r1, -56                                   r1 += -56   ///  r1 = r1.wrapping_add(-56 as i32 as i64 as u64)
    stxdw [r10-0x50], r1                    
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    stxdw [r10-0x48], r1                    
    stxdw [r10-0x58], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -57                                   r1 += -57   ///  r1 = r1.wrapping_add(-57 as i32 as i64 as u64)
    stxdw [r10-0x60], r1                    
    mov64 r1, 32                                    r1 = 32 as i32 as i64 as u64
    stxdw [r10-0x68], r1                    
    ldxdw r1, [r10-0x140]                   
    stxdw [r10-0x70], r1                    
    mov64 r1, 12                                    r1 = 12 as i32 as i64 as u64
    stxdw [r10-0x78], r1                    
    lddw r1, 0x10006155e --> b"dex_instanceInvalid dex program ID for dex instanc"        r1 load str located at 4295365982
    stxdw [r10-0x80], r1                    
    ldxdw r1, [r10-0x138]                   
    stxb [r10-0x38], r1                     
    mov64 r6, r10                                   r6 = r10
    add64 r6, -168                                  r6 += -168   ///  r6 = r6.wrapping_add(-168 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -128                                  r2 += -128   ///  r2 = r2.wrapping_add(-128 as i32 as i64 as u64)
    mov64 r1, r6                                    r1 = r6
    mov64 r3, 4                                     r3 = 4 as i32 as i64 as u64
    mov64 r4, r8                                    r4 = r8
    call function_40888                     
    lddw r1, 0x1000615a2 --> b"Could not derive dex instance pda from dex_pda, in"        r1 load str located at 4295366050
    stxdw [r10-0x1000], r1                  
    mov64 r1, 68                                    r1 = 68 as i32 as i64 as u64
    stxdw [r10-0xff8], r1                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -240                                  r1 += -240   ///  r1 = r1.wrapping_add(-240 as i32 as i64 as u64)
    mov64 r5, r10                                   r5 = r10
    mov64 r2, r6                                    r2 = r6
    lddw r3, 0x1000615a2 --> b"Could not derive dex instance pda from dex_pda, instance_id and bump"        r3 load str located at 4295366050
    mov64 r4, 68                                    r4 = 68 as i32 as i64 as u64
    call function_25690                     
    ldxb r6, [r10-0xf0]                     
    jeq r6, 56, lbb_24384                           if r6 == (56 as i32 as i64 as u64) { pc += 1 }
    ja lbb_24407                                    if true { pc += 23 }
lbb_24384:
    ldxdw r1, [r10-0xe7]                    
    stxdw [r10-0x108], r1                   
    stxdw [r10-0x128], r1                   
    ldxdw r1, [r10-0xdf]                    
    stxdw [r10-0x100], r1                   
    stxdw [r10-0x120], r1                   
    ldxdw r1, [r10-0xd7]                    
    stxdw [r10-0xf8], r1                    
    stxdw [r10-0x118], r1                   
    ldxdw r1, [r10-0xef]                    
    stxdw [r10-0x130], r1                   
    ldxdw r2, [r9+0x0]                      
    jeq r2, r1, lbb_24431                           if r2 == r1 { pc += 34 }
lbb_24397:
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    ja lbb_24441                                    if true { pc += 42 }
lbb_24399:
    mov64 r1, r7                                    r1 = r7
    add64 r1, 1                                     r1 += 1   ///  r1 = r1.wrapping_add(1 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -239                                  r2 += -239   ///  r2 = r2.wrapping_add(-239 as i32 as i64 as u64)
    mov64 r3, 71                                    r3 = 71 as i32 as i64 as u64
    call function_48190                     
    stxb [r7+0x0], r9                       
    ja lbb_24510                                    if true { pc += 103 }
lbb_24407:
    ldxdw r1, [r10-0xd7]                    
    stxdw [r10-0xf8], r1                    
    ldxdw r1, [r10-0xdf]                    
    stxdw [r10-0x100], r1                   
    ldxdw r1, [r10-0xe7]                    
    stxdw [r10-0x108], r1                   
    ldxdw r1, [r10-0xef]                    
    stxdw [r10-0x110], r1                   
    mov64 r1, r7                                    r1 = r7
    add64 r1, 33                                    r1 += 33   ///  r1 = r1.wrapping_add(33 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -207                                  r2 += -207   ///  r2 = r2.wrapping_add(-207 as i32 as i64 as u64)
    mov64 r3, 39                                    r3 = 39 as i32 as i64 as u64
    call function_48190                     
    ldxdw r1, [r10-0xf8]                    
    stxdw [r7+0x19], r1                     
    ldxdw r1, [r10-0x100]                   
    stxdw [r7+0x11], r1                     
    ldxdw r1, [r10-0x108]                   
    stxdw [r7+0x9], r1                      
    ldxdw r1, [r10-0x110]                   
    stxdw [r7+0x1], r1                      
    stxb [r7+0x0], r6                       
    ja lbb_24510                                    if true { pc += 79 }
lbb_24431:
    ldxdw r1, [r9+0x8]                      
    ldxdw r2, [r10-0x128]                   
    jne r1, r2, lbb_24397                           if r1 != r2 { pc += -37 }
    ldxdw r1, [r9+0x10]                     
    ldxdw r2, [r10-0x120]                   
    jne r1, r2, lbb_24397                           if r1 != r2 { pc += -40 }
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    ldxdw r2, [r9+0x18]                     
    ldxdw r3, [r10-0x118]                   
    jne r2, r3, lbb_24397                           if r2 != r3 { pc += -44 }
lbb_24441:
    mov64 r2, 25                                    r2 = 25 as i32 as i64 as u64
    stxdw [r10-0x108], r2                   
    lddw r2, 0x1000615e6 --> b"Dex instance pda mismatchInstance id of  is out of"        r2 load str located at 4295366118
    stxdw [r10-0x110], r2                   
    mov64 r8, r7                                    r8 = r7
    jeq r1, 0, lbb_24508                            if r1 == (0 as i32 as i64 as u64) { pc += 60 }
    lddw r1, 0x100065940 --> b"\x00\x00\x00\x00\x0f\x15\x06\x00\x19\x00\x00\x00\x00\x00\x00\x00[\x00\x00…        r1 load str located at 4295383360
    stxdw [r10-0x38], r1                    
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    stxdw [r10-0xd0], r1                    
    lddw r1, 0x100065a98 --> b"\x00\x00\x00\x00\xe8\x0e\x06\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\…        r1 load str located at 4295383704
    stxdw [r10-0xf0], r1                    
    mov64 r1, 2                                     r1 = 2 as i32 as i64 as u64
    stxdw [r10-0xe8], r1                    
    stxdw [r10-0xd8], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -128                                  r1 += -128   ///  r1 = r1.wrapping_add(-128 as i32 as i64 as u64)
    stxdw [r10-0xe0], r1                    
    lddw r1, 0x10002a248 --> b"y\x11\x00\x00\x00\x00\x00\x00\x85\x10\x00\x00%X\x00\x00\x95\x00\x00\x00\x…        r1 load str located at 4295139912
    stxdw [r10-0x68], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -56                                   r1 += -56   ///  r1 = r1.wrapping_add(-56 as i32 as i64 as u64)
    stxdw [r10-0x70], r1                    
    lddw r1, 0x10002a388 --> b"\xbf#\x00\x00\x00\x00\x00\x00y\x12\x08\x00\x00\x00\x00\x00y\x11\x00\x00\x…        r1 load str located at 4295140232
    stxdw [r10-0x78], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -272                                  r1 += -272   ///  r1 = r1.wrapping_add(-272 as i32 as i64 as u64)
    stxdw [r10-0x80], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -168                                  r1 += -168   ///  r1 = r1.wrapping_add(-168 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -240                                  r2 += -240   ///  r2 = r2.wrapping_add(-240 as i32 as i64 as u64)
    call function_43415                     
    ldxdw r6, [r10-0xa0]                    
    ldxdw r7, [r10-0xa8]                    
    ldxdw r2, [r10-0x98]                    
    mov64 r1, r7                                    r1 = r7
    syscall [invalid]                       
    jeq r6, 0, lbb_24489                            if r6 == (0 as i32 as i64 as u64) { pc += 4 }
    mov64 r1, r7                                    r1 = r7
    mov64 r2, r6                                    r2 = r6
    mov64 r3, 1                                     r3 = 1 as i32 as i64 as u64
    call function_21385                     
lbb_24489:
    mov64 r1, 25                                    r1 = 25 as i32 as i64 as u64
    stxb [r8+0x0], r1                       
    ldxdw r1, [r10-0x130]                   
    stxdw [r8+0x1], r1                      
    ldxdw r1, [r10-0x128]                   
    stxdw [r8+0x9], r1                      
    ldxdw r1, [r10-0x120]                   
    stxdw [r8+0x11], r1                     
    ldxdw r1, [r10-0x118]                   
    stxdw [r8+0x19], r1                     
    ldxdw r1, [r9+0x0]                      
    stxdw [r8+0x21], r1                     
    ldxdw r1, [r9+0x8]                      
    stxdw [r8+0x29], r1                     
    ldxdw r1, [r9+0x10]                     
    stxdw [r8+0x31], r1                     
    ldxdw r1, [r9+0x18]                     
    stxdw [r8+0x39], r1                     
    ja lbb_24510                                    if true { pc += 2 }
lbb_24508:
    mov64 r1, 56                                    r1 = 56 as i32 as i64 as u64
    stxb [r8+0x0], r1                       
lbb_24510:
    exit                                    

function_24511:
    mov64 r4, r2                                    r4 = r2
    and64 r4, 1                                     r4 &= 1   ///  r4 = r4.and(1)
    lddw r5, 0xffffff00                             r5 load str located at 4294967040
    mov64 r3, r2                                    r3 = r2
    and64 r3, r5                                    r3 &= r5   ///  r3 = r3.and(r5)
    rsh64 r3, 8                                     r3 >>= 8   ///  r3 = r3.wrapping_shr(8)
    mov64 r0, r1                                    r0 = r1
    and64 r0, 1                                     r0 &= 1   ///  r0 = r0.and(1)
    jne r0, 0, lbb_24527                            if r0 != (0 as i32 as i64 as u64) { pc += 6 }
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    mov64 r0, 0                                     r0 = 0 as i32 as i64 as u64
    jeq r4, 0, lbb_24553                            if r4 == (0 as i32 as i64 as u64) { pc += 29 }
    mov64 r1, r2                                    r1 = r2
    mov64 r0, r3                                    r0 = r3
    ja lbb_24553                                    if true { pc += 26 }
lbb_24527:
    mov64 r0, r1                                    r0 = r1
    and64 r0, r5                                    r0 &= r5   ///  r0 = r0.and(r5)
    rsh64 r0, 8                                     r0 >>= 8   ///  r0 = r0.wrapping_shr(8)
    jeq r4, 0, lbb_24553                            if r4 == (0 as i32 as i64 as u64) { pc += 22 }
    mov64 r5, r2                                    r5 = r2
    rsh64 r5, 24                                    r5 >>= 24   ///  r5 = r5.wrapping_shr(24)
    and64 r5, 255                                   r5 &= 255   ///  r5 = r5.and(255)
    mov64 r4, r1                                    r4 = r1
    rsh64 r4, 24                                    r4 >>= 24   ///  r4 = r4.wrapping_shr(24)
    and64 r4, 255                                   r4 &= 255   ///  r4 = r4.and(255)
    jgt r4, r5, lbb_24539                           if r4 > r5 { pc += 1 }
    mov64 r4, r5                                    r4 = r5
lbb_24539:
    rsh64 r2, 16                                    r2 >>= 16   ///  r2 = r2.wrapping_shr(16)
    and64 r2, 255                                   r2 &= 255   ///  r2 = r2.and(255)
    rsh64 r1, 16                                    r1 >>= 16   ///  r1 = r1.wrapping_shr(16)
    and64 r1, 255                                   r1 &= 255   ///  r1 = r1.and(255)
    jgt r1, r2, lbb_24545                           if r1 > r2 { pc += 1 }
    mov64 r1, r2                                    r1 = r2
lbb_24545:
    lsh64 r1, 8                                     r1 <<= 8   ///  r1 = r1.wrapping_shl(8)
    lsh64 r4, 16                                    r4 <<= 16   ///  r4 = r4.wrapping_shl(16)
    or64 r4, r1                                     r4 |= r1   ///  r4 = r4.or(r1)
    or64 r3, r0                                     r3 |= r0   ///  r3 = r3.or(r0)
    and64 r3, 1                                     r3 &= 1   ///  r3 = r3.and(1)
    or64 r4, r3                                     r4 |= r3   ///  r4 = r4.or(r3)
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    mov64 r0, r4                                    r0 = r4
lbb_24553:
    and64 r1, 255                                   r1 &= 255   ///  r1 = r1.and(255)
    lsh64 r0, 8                                     r0 <<= 8   ///  r0 = r0.wrapping_shl(8)
    or64 r0, r1                                     r0 |= r1   ///  r0 = r0.or(r1)
    exit                                    

function_24557:
    mov64 r0, 0                                     r0 = 0 as i32 as i64 as u64
    mov64 r2, r1                                    r2 = r1
    and64 r2, 1                                     r2 &= 1   ///  r2 = r2.and(1)
    jne r2, 0, lbb_24575                            if r2 != (0 as i32 as i64 as u64) { pc += 14 }
    lddw r2, 0xffffffffe0                           r2 load str located at 1099511627744
    mov64 r3, r1                                    r3 = r1
    and64 r3, r2                                    r3 &= r2   ///  r3 = r3.and(r2)
    lsh64 r3, 16                                    r3 <<= 16   ///  r3 = r3.wrapping_shl(16)
    mov64 r0, r1                                    r0 = r1
    lsh64 r0, 6                                     r0 <<= 6   ///  r0 = r0.wrapping_shl(6)
    and64 r0, 1792                                  r0 &= 1792   ///  r0 = r0.and(1792)
    or64 r0, r3                                     r0 |= r3   ///  r0 = r0.or(r3)
    rsh64 r1, 1                                     r1 >>= 1   ///  r1 = r1.wrapping_shr(1)
    and64 r1, 1                                     r1 &= 1   ///  r1 = r1.and(1)
    or64 r0, r1                                     r0 |= r1   ///  r0 = r0.or(r1)
    lsh64 r0, 8                                     r0 <<= 8   ///  r0 = r0.wrapping_shl(8)
    or64 r0, 1                                      r0 |= 1   ///  r0 = r0.or(1)
lbb_24575:
    exit                                    

function_24576:
    mov64 r0, r1                                    r0 = r1
    ldxw r1, [r2+0x2100]                    
    mov64 r3, 257                                   r3 = 257 as i32 as i64 as u64
    jgt r3, r1, lbb_24585                           if r3 > r1 { pc += 5 }
    mov64 r2, 256                                   r2 = 256 as i32 as i64 as u64
    lddw r3, 0x1000658c8 --> b"\x00\x00\x00\x00m\x14\x06\x00\x17\x00\x00\x00\x00\x00\x00\x00,\x00\x00\x0…        r3 load str located at 4295383240
    call function_46535                     
    syscall [invalid]                       
lbb_24585:
    mov64 r3, 2                                     r3 = 2 as i32 as i64 as u64
    stxdw [r10-0x8], r3                     
    jeq r1, 0, lbb_24664                            if r1 == (0 as i32 as i64 as u64) { pc += 76 }
    mov64 r4, 0                                     r4 = 0 as i32 as i64 as u64
    mov64 r5, r1                                    r5 = r1
    ja lbb_24601                                    if true { pc += 10 }
lbb_24591:
    jeq r3, 1, lbb_24597                            if r3 == (1 as i32 as i64 as u64) { pc += 5 }
    and64 r3, 255                                   r3 &= 255   ///  r3 = r3.and(255)
    jne r3, 255, lbb_24644                          if r3 != (255 as i32 as i64 as u64) { pc += 50 }
    mov64 r4, r1                                    r4 = r1
    add64 r4, 1                                     r4 += 1   ///  r4 = r4.wrapping_add(1 as i32 as i64 as u64)
    mov64 r1, r5                                    r1 = r5
lbb_24597:
    mov64 r5, r1                                    r5 = r1
    sub64 r1, r4                                    r1 -= r4   ///  r1 = r1.wrapping_sub(r4)
    jgt r5, r4, lbb_24601                           if r5 > r4 { pc += 1 }
    ja lbb_24664                                    if true { pc += 63 }
lbb_24601:
    rsh64 r1, 1                                     r1 >>= 1   ///  r1 = r1.wrapping_shr(1)
    add64 r1, r4                                    r1 += r4   ///  r1 = r1.wrapping_add(r4)
    mov64 r6, r1                                    r6 = r1
    mul64 r6, 33                                    r6 *= 33   ///  r6 = r6.wrapping_mul(33 as u64)
    mov64 r8, r2                                    r8 = r2
    add64 r8, r6                                    r8 += r6   ///  r8 = r8.wrapping_add(r6)
    ldxdw r3, [r8+0x0]                      
    be64 r3                                         r3 = match 64 { 16 => (r3 as u16).swap_bytes() as u64, 32 => (r3 as u32).swap_bytes() as u64, 64 => r3.swap_bytes(), _ => r3 }
    ldxdw r7, [r0+0x0]                      
    be64 r7                                         r7 = match 64 { 16 => (r7 as u16).swap_bytes() as u64, 32 => (r7 as u32).swap_bytes() as u64, 64 => r7.swap_bytes(), _ => r7 }
    jeq r3, r7, lbb_24616                           if r3 == r7 { pc += 4 }
lbb_24612:
    mov64 r9, -1                                    r9 = -1 as i32 as i64 as u64
    jgt r7, r3, lbb_24632                           if r7 > r3 { pc += 18 }
    mov64 r9, 1                                     r9 = 1 as i32 as i64 as u64
    ja lbb_24632                                    if true { pc += 16 }
lbb_24616:
    ldxdw r7, [r0+0x8]                      
    be64 r7                                         r7 = match 64 { 16 => (r7 as u16).swap_bytes() as u64, 32 => (r7 as u32).swap_bytes() as u64, 64 => r7.swap_bytes(), _ => r7 }
    ldxdw r3, [r8+0x8]                      
    be64 r3                                         r3 = match 64 { 16 => (r3 as u16).swap_bytes() as u64, 32 => (r3 as u32).swap_bytes() as u64, 64 => r3.swap_bytes(), _ => r3 }
    jne r3, r7, lbb_24612                           if r3 != r7 { pc += -9 }
    ldxdw r7, [r0+0x10]                     
    be64 r7                                         r7 = match 64 { 16 => (r7 as u16).swap_bytes() as u64, 32 => (r7 as u32).swap_bytes() as u64, 64 => r7.swap_bytes(), _ => r7 }
    ldxdw r3, [r8+0x10]                     
    be64 r3                                         r3 = match 64 { 16 => (r3 as u16).swap_bytes() as u64, 32 => (r3 as u32).swap_bytes() as u64, 64 => r3.swap_bytes(), _ => r3 }
    jne r3, r7, lbb_24612                           if r3 != r7 { pc += -14 }
    mov64 r9, 0                                     r9 = 0 as i32 as i64 as u64
    ldxdw r7, [r0+0x18]                     
    be64 r7                                         r7 = match 64 { 16 => (r7 as u16).swap_bytes() as u64, 32 => (r7 as u32).swap_bytes() as u64, 64 => r7.swap_bytes(), _ => r7 }
    ldxdw r3, [r8+0x18]                     
    be64 r3                                         r3 = match 64 { 16 => (r3 as u16).swap_bytes() as u64, 32 => (r3 as u32).swap_bytes() as u64, 64 => r3.swap_bytes(), _ => r3 }
    jne r3, r7, lbb_24612                           if r3 != r7 { pc += -20 }
lbb_24632:
    lsh64 r9, 32                                    r9 <<= 32   ///  r9 = r9.wrapping_shl(32)
    mov64 r3, r9                                    r3 = r9
    rsh64 r3, 32                                    r3 >>= 32   ///  r3 = r3.wrapping_shr(32)
    mov64 r7, 0                                     r7 = 0 as i32 as i64 as u64
    mov64 r8, 1                                     r8 = 1 as i32 as i64 as u64
    jne r3, 0, lbb_24639                            if r3 != (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r8, 0                                     r8 = 0 as i32 as i64 as u64
lbb_24639:
    arsh64 r9, 32                                   r9 >>= 32 (signed)   ///  r9 = (r9 as i64).wrapping_shr(32)
    mov64 r3, -1                                    r3 = -1 as i32 as i64 as u64
    jsgt r7, r9, lbb_24591                          if (r7 as i64) > (r9 as i64) { pc += -51 }
    mov64 r3, r8                                    r3 = r8
    ja lbb_24591                                    if true { pc += -53 }
lbb_24644:
    add64 r2, r6                                    r2 += r6   ///  r2 = r2.wrapping_add(r6)
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    stxdw [r10-0x8], r1                     
    ldxb r1, [r2+0x20]                      
    mov64 r2, r1                                    r2 = r1
    and64 r2, 1                                     r2 &= 1   ///  r2 = r2.and(1)
    jne r2, 0, lbb_24664                            if r2 != (0 as i32 as i64 as u64) { pc += 13 }
    mov64 r2, r1                                    r2 = r1
    and64 r2, 224                                   r2 &= 224   ///  r2 = r2.and(224)
    lsh64 r2, 16                                    r2 <<= 16   ///  r2 = r2.wrapping_shl(16)
    mov64 r3, r1                                    r3 = r1
    lsh64 r3, 6                                     r3 <<= 6   ///  r3 = r3.wrapping_shl(6)
    and64 r3, 1792                                  r3 &= 1792   ///  r3 = r3.and(1792)
    or64 r3, r2                                     r3 |= r2   ///  r3 = r3.or(r2)
    rsh64 r1, 1                                     r1 >>= 1   ///  r1 = r1.wrapping_shr(1)
    and64 r1, 1                                     r1 &= 1   ///  r1 = r1.and(1)
    or64 r3, r1                                     r3 |= r1   ///  r3 = r3.or(r1)
    lsh64 r3, 8                                     r3 <<= 8   ///  r3 = r3.wrapping_shl(8)
    or64 r3, 1                                      r3 |= 1   ///  r3 = r3.or(1)
    stxdw [r10-0x8], r3                     
lbb_24664:
    ldxdw r0, [r10-0x8]                     
    exit                                    

function_24666:
    mov64 r7, r3                                    r7 = r3
    mov64 r6, r1                                    r6 = r1
    stxb [r10-0xe0], r7                     
    mov64 r1, r7                                    r1 = r7
    and64 r1, 255                                   r1 &= 255   ///  r1 = r1.and(255)
    mov64 r3, 64                                    r3 = 64 as i32 as i64 as u64
    jgt r3, r1, lbb_24711                           if r3 > r1 { pc += 38 }
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    stxdw [r10-0x50], r1                    
    mov64 r1, 2                                     r1 = 2 as i32 as i64 as u64
    stxdw [r10-0x68], r1                    
    lddw r1, 0x100065958 --> b"\x00\x00\x00\x00\xff\x15\x06\x00\x0f\x00\x00\x00\x00\x00\x00\x00\x00\x00\…        r1 load str located at 4295383384
    stxdw [r10-0x70], r1                    
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    stxdw [r10-0x58], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -64                                   r1 += -64   ///  r1 = r1.wrapping_add(-64 as i32 as i64 as u64)
    stxdw [r10-0x60], r1                    
    lddw r1, 0x10005de98 --> b"\xbf#\x00\x00\x00\x00\x00\x00q\x11\x00\x00\x00\x00\x00\x00\xb7\x02\x00\x0…        r1 load str located at 4295351960
    stxdw [r10-0x38], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -224                                  r1 += -224   ///  r1 = r1.wrapping_add(-224 as i32 as i64 as u64)
    stxdw [r10-0x40], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -136                                  r1 += -136   ///  r1 = r1.wrapping_add(-136 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -112                                  r2 += -112   ///  r2 = r2.wrapping_add(-112 as i32 as i64 as u64)
    call function_43415                     
    ldxdw r1, [r10-0x88]                    
    stxdw [r10-0xd2], r1                    
    ldxdw r1, [r10-0x80]                    
    stxdw [r10-0xca], r1                    
    ldxdw r1, [r10-0x78]                    
    stxdw [r10-0xc2], r1                    
    stxdw [r6+0x18], r1                     
    ldxdw r1, [r10-0xd0]                    
    stxdw [r6+0xa], r1                      
    ldxdw r1, [r10-0xc8]                    
    stxdw [r6+0x12], r1                     
    ldxdw r1, [r10-0xd8]                    
    stxdw [r6+0x2], r1                      
    mov64 r1, 29                                    r1 = 29 as i32 as i64 as u64
    ja lbb_24765                                    if true { pc += 54 }
lbb_24711:
    ldxdw r2, [r2+0x0]                      
    mov64 r3, 25                                    r3 = 25 as i32 as i64 as u64
    stxdw [r10-0x38], r3                    
    lddw r3, 0x10006161f --> b"Instance id is not activesdk/src/dex.rsInstance id"        r3 load str located at 4295366175
    stxdw [r10-0x40], r3                    
    rsh64 r2, r1                                    r2 >>= r1   ///  r2 = r2.wrapping_shr(r1 as u32)
    and64 r2, 1                                     r2 &= 1   ///  r2 = r2.and(1)
    jne r2, 0, lbb_24764                            if r2 != (0 as i32 as i64 as u64) { pc += 44 }
    lddw r1, 0x100065978 --> b"\x00\x00\x00\x008\x16\x06\x00\x0e\x00\x00\x00\x00\x00\x00\x007\x00\x00\x0…        r1 load str located at 4295383416
    stxdw [r10-0xe0], r1                    
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    stxdw [r10-0x50], r1                    
    lddw r1, 0x100065a98 --> b"\x00\x00\x00\x00\xe8\x0e\x06\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\…        r1 load str located at 4295383704
    stxdw [r10-0x70], r1                    
    mov64 r1, 2                                     r1 = 2 as i32 as i64 as u64
    stxdw [r10-0x68], r1                    
    stxdw [r10-0x58], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -216                                  r1 += -216   ///  r1 = r1.wrapping_add(-216 as i32 as i64 as u64)
    stxdw [r10-0x60], r1                    
    lddw r1, 0x10002a248 --> b"y\x11\x00\x00\x00\x00\x00\x00\x85\x10\x00\x00%X\x00\x00\x95\x00\x00\x00\x…        r1 load str located at 4295139912
    stxdw [r10-0xc0], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -224                                  r1 += -224   ///  r1 = r1.wrapping_add(-224 as i32 as i64 as u64)
    stxdw [r10-0xc8], r1                    
    lddw r1, 0x10002a388 --> b"\xbf#\x00\x00\x00\x00\x00\x00y\x12\x08\x00\x00\x00\x00\x00y\x11\x00\x00\x…        r1 load str located at 4295140232
    stxdw [r10-0xd0], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -64                                   r1 += -64   ///  r1 = r1.wrapping_add(-64 as i32 as i64 as u64)
    stxdw [r10-0xd8], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -136                                  r1 += -136   ///  r1 = r1.wrapping_add(-136 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -112                                  r2 += -112   ///  r2 = r2.wrapping_add(-112 as i32 as i64 as u64)
    call function_43415                     
    ldxdw r8, [r10-0x80]                    
    ldxdw r9, [r10-0x88]                    
    ldxdw r2, [r10-0x78]                    
    mov64 r1, r9                                    r1 = r9
    syscall [invalid]                       
    jeq r8, 0, lbb_24761                            if r8 == (0 as i32 as i64 as u64) { pc += 4 }
    mov64 r1, r9                                    r1 = r9
    mov64 r2, r8                                    r2 = r8
    mov64 r3, 1                                     r3 = 1 as i32 as i64 as u64
    call function_21385                     
lbb_24761:
    stxb [r6+0x1], r7                       
    mov64 r1, 27                                    r1 = 27 as i32 as i64 as u64
    ja lbb_24765                                    if true { pc += 1 }
lbb_24764:
    mov64 r1, 56                                    r1 = 56 as i32 as i64 as u64
lbb_24765:
    stxb [r6+0x0], r1                       
    exit                                    

function_24767:
    mov64 r7, r3                                    r7 = r3
    mov64 r6, r1                                    r6 = r1
    stxb [r10-0xe0], r7                     
    mov64 r1, r7                                    r1 = r7
    and64 r1, 255                                   r1 &= 255   ///  r1 = r1.and(255)
    mov64 r3, 64                                    r3 = 64 as i32 as i64 as u64
    jgt r3, r1, lbb_24812                           if r3 > r1 { pc += 38 }
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    stxdw [r10-0x50], r1                    
    mov64 r1, 2                                     r1 = 2 as i32 as i64 as u64
    stxdw [r10-0x68], r1                    
    lddw r1, 0x100065958 --> b"\x00\x00\x00\x00\xff\x15\x06\x00\x0f\x00\x00\x00\x00\x00\x00\x00\x00\x00\…        r1 load str located at 4295383384
    stxdw [r10-0x70], r1                    
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    stxdw [r10-0x58], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -64                                   r1 += -64   ///  r1 = r1.wrapping_add(-64 as i32 as i64 as u64)
    stxdw [r10-0x60], r1                    
    lddw r1, 0x10005de98 --> b"\xbf#\x00\x00\x00\x00\x00\x00q\x11\x00\x00\x00\x00\x00\x00\xb7\x02\x00\x0…        r1 load str located at 4295351960
    stxdw [r10-0x38], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -224                                  r1 += -224   ///  r1 = r1.wrapping_add(-224 as i32 as i64 as u64)
    stxdw [r10-0x40], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -136                                  r1 += -136   ///  r1 = r1.wrapping_add(-136 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -112                                  r2 += -112   ///  r2 = r2.wrapping_add(-112 as i32 as i64 as u64)
    call function_43415                     
    ldxdw r1, [r10-0x88]                    
    stxdw [r10-0xd2], r1                    
    ldxdw r1, [r10-0x80]                    
    stxdw [r10-0xca], r1                    
    ldxdw r1, [r10-0x78]                    
    stxdw [r10-0xc2], r1                    
    stxdw [r6+0x18], r1                     
    ldxdw r1, [r10-0xd0]                    
    stxdw [r6+0xa], r1                      
    ldxdw r1, [r10-0xc8]                    
    stxdw [r6+0x12], r1                     
    ldxdw r1, [r10-0xd8]                    
    stxdw [r6+0x2], r1                      
    mov64 r1, 29                                    r1 = 29 as i32 as i64 as u64
    ja lbb_24866                                    if true { pc += 54 }
lbb_24812:
    ldxdw r2, [r2+0x0]                      
    mov64 r3, 29                                    r3 = 29 as i32 as i64 as u64
    stxdw [r10-0x38], r3                    
    lddw r3, 0x100061646 --> b"Instance id is already activeCoin {} is already in"        r3 load str located at 4295366214
    stxdw [r10-0x40], r3                    
    rsh64 r2, r1                                    r2 >>= r1   ///  r2 = r2.wrapping_shr(r1 as u32)
    and64 r2, 1                                     r2 &= 1   ///  r2 = r2.and(1)
    jeq r2, 0, lbb_24865                            if r2 == (0 as i32 as i64 as u64) { pc += 44 }
    lddw r1, 0x100065990 --> b"\x00\x00\x00\x008\x16\x06\x00\x0e\x00\x00\x00\x00\x00\x00\x00?\x00\x00\x0…        r1 load str located at 4295383440
    stxdw [r10-0xe0], r1                    
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    stxdw [r10-0x50], r1                    
    lddw r1, 0x100065a98 --> b"\x00\x00\x00\x00\xe8\x0e\x06\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\…        r1 load str located at 4295383704
    stxdw [r10-0x70], r1                    
    mov64 r1, 2                                     r1 = 2 as i32 as i64 as u64
    stxdw [r10-0x68], r1                    
    stxdw [r10-0x58], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -216                                  r1 += -216   ///  r1 = r1.wrapping_add(-216 as i32 as i64 as u64)
    stxdw [r10-0x60], r1                    
    lddw r1, 0x10002a248 --> b"y\x11\x00\x00\x00\x00\x00\x00\x85\x10\x00\x00%X\x00\x00\x95\x00\x00\x00\x…        r1 load str located at 4295139912
    stxdw [r10-0xc0], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -224                                  r1 += -224   ///  r1 = r1.wrapping_add(-224 as i32 as i64 as u64)
    stxdw [r10-0xc8], r1                    
    lddw r1, 0x10002a388 --> b"\xbf#\x00\x00\x00\x00\x00\x00y\x12\x08\x00\x00\x00\x00\x00y\x11\x00\x00\x…        r1 load str located at 4295140232
    stxdw [r10-0xd0], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -64                                   r1 += -64   ///  r1 = r1.wrapping_add(-64 as i32 as i64 as u64)
    stxdw [r10-0xd8], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -136                                  r1 += -136   ///  r1 = r1.wrapping_add(-136 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -112                                  r2 += -112   ///  r2 = r2.wrapping_add(-112 as i32 as i64 as u64)
    call function_43415                     
    ldxdw r8, [r10-0x80]                    
    ldxdw r9, [r10-0x88]                    
    ldxdw r2, [r10-0x78]                    
    mov64 r1, r9                                    r1 = r9
    syscall [invalid]                       
    jeq r8, 0, lbb_24862                            if r8 == (0 as i32 as i64 as u64) { pc += 4 }
    mov64 r1, r9                                    r1 = r9
    mov64 r2, r8                                    r2 = r8
    mov64 r3, 1                                     r3 = 1 as i32 as i64 as u64
    call function_21385                     
lbb_24862:
    stxb [r6+0x1], r7                       
    mov64 r1, 38                                    r1 = 38 as i32 as i64 as u64
    ja lbb_24866                                    if true { pc += 1 }
lbb_24865:
    mov64 r1, 56                                    r1 = 56 as i32 as i64 as u64
lbb_24866:
    stxb [r6+0x0], r1                       
    exit                                    

function_24868:
    mov64 r7, r2                                    r7 = r2
    mov64 r6, r1                                    r6 = r1
    ldxb r8, [r3+0x2125]                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -72                                   r1 += -72   ///  r1 = r1.wrapping_add(-72 as i32 as i64 as u64)
    mov64 r3, r8                                    r3 = r8
    call function_24767                     
    ldxb r9, [r10-0x48]                     
    jne r9, 56, lbb_24884                           if r9 != (56 as i32 as i64 as u64) { pc += 7 }
    and64 r8, 63                                    r8 &= 63   ///  r8 = r8.and(63)
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    lsh64 r1, r8                                    r1 <<= r8   ///  r1 = r1.wrapping_shl(r8 as u32)
    ldxdw r2, [r7+0x0]                      
    or64 r2, r1                                     r2 |= r1   ///  r2 = r2.or(r1)
    stxdw [r7+0x0], r2                      
    ja lbb_24890                                    if true { pc += 6 }
lbb_24884:
    mov64 r1, r6                                    r1 = r6
    add64 r1, 1                                     r1 += 1   ///  r1 = r1.wrapping_add(1 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -71                                   r2 += -71   ///  r2 = r2.wrapping_add(-71 as i32 as i64 as u64)
    mov64 r3, 71                                    r3 = 71 as i32 as i64 as u64
    call function_48190                     
lbb_24890:
    stxb [r6+0x0], r9                       
    exit                                    

function_24892:
    mov64 r7, r3                                    r7 = r3
    mov64 r6, r1                                    r6 = r1
    add64 r2, 32                                    r2 += 32   ///  r2 = r2.wrapping_add(32 as i32 as i64 as u64)
    mov64 r8, 0                                     r8 = 0 as i32 as i64 as u64
    mov64 r1, r2                                    r1 = r2
    mov64 r2, r7                                    r2 = r7
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
    call function_23928                     
    mov64 r1, 30                                    r1 = 30 as i32 as i64 as u64
    stxdw [r10-0xa8], r1                    
    lddw r1, 0x100061663 --> b"Coin {} is already in the listCoin {} is not in th"        r1 load str located at 4295366243
    stxdw [r10-0xb0], r1                    
    jne r0, 0, lbb_24957                            if r0 != (0 as i32 as i64 as u64) { pc += 51 }
    lddw r1, 0x1000659a8 --> b"\x00\x00\x00\x008\x16\x06\x00\x0e\x00\x00\x00\x00\x00\x00\x00\\x00\x00\x0…        r1 load str located at 4295383464
    stxdw [r10-0xa0], r1                    
    stxdw [r10-0x60], r8                    
    lddw r1, 0x100065a98 --> b"\x00\x00\x00\x00\xe8\x0e\x06\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\…        r1 load str located at 4295383704
    stxdw [r10-0x80], r1                    
    mov64 r1, 2                                     r1 = 2 as i32 as i64 as u64
    stxdw [r10-0x78], r1                    
    stxdw [r10-0x68], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -80                                   r1 += -80   ///  r1 = r1.wrapping_add(-80 as i32 as i64 as u64)
    stxdw [r10-0x70], r1                    
    lddw r1, 0x10002a248 --> b"y\x11\x00\x00\x00\x00\x00\x00\x85\x10\x00\x00%X\x00\x00\x95\x00\x00\x00\x…        r1 load str located at 4295139912
    stxdw [r10-0x38], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -160                                  r1 += -160   ///  r1 = r1.wrapping_add(-160 as i32 as i64 as u64)
    stxdw [r10-0x40], r1                    
    lddw r1, 0x10002a388 --> b"\xbf#\x00\x00\x00\x00\x00\x00y\x12\x08\x00\x00\x00\x00\x00y\x11\x00\x00\x…        r1 load str located at 4295140232
    stxdw [r10-0x48], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -176                                  r1 += -176   ///  r1 = r1.wrapping_add(-176 as i32 as i64 as u64)
    stxdw [r10-0x50], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -152                                  r1 += -152   ///  r1 = r1.wrapping_add(-152 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -128                                  r2 += -128   ///  r2 = r2.wrapping_add(-128 as i32 as i64 as u64)
    call function_43415                     
    ldxdw r8, [r10-0x90]                    
    ldxdw r9, [r10-0x98]                    
    ldxdw r2, [r10-0x88]                    
    mov64 r1, r9                                    r1 = r9
    syscall [invalid]                       
    jeq r8, 0, lbb_24946                            if r8 == (0 as i32 as i64 as u64) { pc += 4 }
    mov64 r1, r9                                    r1 = r9
    mov64 r2, r8                                    r2 = r8
    mov64 r3, 1                                     r3 = 1 as i32 as i64 as u64
    call function_21385                     
lbb_24946:
    mov64 r1, 41                                    r1 = 41 as i32 as i64 as u64
    stxb [r6+0x0], r1                       
    ldxdw r1, [r7+0x0]                      
    stxdw [r6+0x1], r1                      
    ldxdw r1, [r7+0x8]                      
    stxdw [r6+0x9], r1                      
    ldxdw r1, [r7+0x10]                     
    stxdw [r6+0x11], r1                     
    ldxdw r1, [r7+0x18]                     
    stxdw [r6+0x19], r1                     
    ja lbb_24959                                    if true { pc += 2 }
lbb_24957:
    mov64 r1, 56                                    r1 = 56 as i32 as i64 as u64
    stxb [r6+0x0], r1                       
lbb_24959:
    exit                                    

function_24960:
    mov64 r7, r3                                    r7 = r3
    mov64 r6, r1                                    r6 = r1
    ldxw r1, [r2+0x2120]                    
    mov64 r3, 257                                   r3 = 257 as i32 as i64 as u64
    jgt r3, r1, lbb_24970                           if r3 > r1 { pc += 5 }
    mov64 r2, 256                                   r2 = 256 as i32 as i64 as u64
    lddw r3, 0x1000658b0 --> b"\x00\x00\x00\x00m\x14\x06\x00\x17\x00\x00\x00\x00\x00\x00\x00#\x00\x00\x0…        r3 load str located at 4295383216
    call function_46535                     
    syscall [invalid]                       
lbb_24970:
    jeq r1, 0, lbb_24984                            if r1 == (0 as i32 as i64 as u64) { pc += 13 }
    add64 r2, 32                                    r2 += 32   ///  r2 = r2.wrapping_add(32 as i32 as i64 as u64)
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
    mov64 r4, r1                                    r4 = r1
    ja lbb_25031                                    if true { pc += 56 }
lbb_24975:
    jeq r5, 1, lbb_24981                            if r5 == (1 as i32 as i64 as u64) { pc += 5 }
    and64 r5, 255                                   r5 &= 255   ///  r5 = r5.and(255)
    jne r5, 255, lbb_25085                          if r5 != (255 as i32 as i64 as u64) { pc += 107 }
    mov64 r3, r1                                    r3 = r1
    add64 r3, 1                                     r3 += 1   ///  r3 = r3.wrapping_add(1 as i32 as i64 as u64)
    mov64 r1, r4                                    r1 = r4
lbb_24981:
    mov64 r4, r1                                    r4 = r1
    sub64 r1, r3                                    r1 -= r3   ///  r1 = r1.wrapping_sub(r3)
    jgt r4, r3, lbb_25031                           if r4 > r3 { pc += 47 }
lbb_24984:
    mov64 r1, 26                                    r1 = 26 as i32 as i64 as u64
    stxdw [r10-0xa8], r1                    
    lddw r1, 0x100061681 --> b"Coin {} is not in the list +  -> !:  -  /  * . \x0asd"        r1 load str located at 4295366273
    stxdw [r10-0xb0], r1                    
    lddw r1, 0x1000659c0 --> b"\x00\x00\x00\x008\x16\x06\x00\x0e\x00\x00\x00\x00\x00\x00\x00d\x00\x00\x0…        r1 load str located at 4295383488
    stxdw [r10-0xa0], r1                    
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    stxdw [r10-0x60], r1                    
    lddw r1, 0x100065a98 --> b"\x00\x00\x00\x00\xe8\x0e\x06\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\…        r1 load str located at 4295383704
    stxdw [r10-0x80], r1                    
    mov64 r1, 2                                     r1 = 2 as i32 as i64 as u64
    stxdw [r10-0x78], r1                    
    stxdw [r10-0x68], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -80                                   r1 += -80   ///  r1 = r1.wrapping_add(-80 as i32 as i64 as u64)
    stxdw [r10-0x70], r1                    
    lddw r1, 0x10002a248 --> b"y\x11\x00\x00\x00\x00\x00\x00\x85\x10\x00\x00%X\x00\x00\x95\x00\x00\x00\x…        r1 load str located at 4295139912
    stxdw [r10-0x38], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -160                                  r1 += -160   ///  r1 = r1.wrapping_add(-160 as i32 as i64 as u64)
    stxdw [r10-0x40], r1                    
    lddw r1, 0x10002a388 --> b"\xbf#\x00\x00\x00\x00\x00\x00y\x12\x08\x00\x00\x00\x00\x00y\x11\x00\x00\x…        r1 load str located at 4295140232
    stxdw [r10-0x48], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -176                                  r1 += -176   ///  r1 = r1.wrapping_add(-176 as i32 as i64 as u64)
    stxdw [r10-0x50], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -152                                  r1 += -152   ///  r1 = r1.wrapping_add(-152 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -128                                  r2 += -128   ///  r2 = r2.wrapping_add(-128 as i32 as i64 as u64)
    call function_43415                     
    ldxdw r8, [r10-0x90]                    
    ldxdw r9, [r10-0x98]                    
    ldxdw r2, [r10-0x88]                    
    mov64 r1, r9                                    r1 = r9
    syscall [invalid]                       
    jeq r8, 0, lbb_25074                            if r8 == (0 as i32 as i64 as u64) { pc += 48 }
    mov64 r1, r9                                    r1 = r9
    mov64 r2, r8                                    r2 = r8
    mov64 r3, 1                                     r3 = 1 as i32 as i64 as u64
    call function_21385                     
    ja lbb_25074                                    if true { pc += 43 }
lbb_25031:
    rsh64 r1, 1                                     r1 >>= 1   ///  r1 = r1.wrapping_shr(1)
    add64 r1, r3                                    r1 += r3   ///  r1 = r1.wrapping_add(r3)
    mov64 r5, r1                                    r5 = r1
    mul64 r5, 33                                    r5 *= 33   ///  r5 = r5.wrapping_mul(33 as u64)
    mov64 r0, r2                                    r0 = r2
    add64 r0, r5                                    r0 += r5   ///  r0 = r0.wrapping_add(r5)
    ldxdw r9, [r0+0x0]                      
    be64 r9                                         r9 = match 64 { 16 => (r9 as u16).swap_bytes() as u64, 32 => (r9 as u32).swap_bytes() as u64, 64 => r9.swap_bytes(), _ => r9 }
    ldxdw r5, [r7+0x0]                      
    be64 r5                                         r5 = match 64 { 16 => (r5 as u16).swap_bytes() as u64, 32 => (r5 as u32).swap_bytes() as u64, 64 => r5.swap_bytes(), _ => r5 }
    jeq r9, r5, lbb_25046                           if r9 == r5 { pc += 4 }
lbb_25042:
    mov64 r8, -1                                    r8 = -1 as i32 as i64 as u64
    jgt r5, r9, lbb_25062                           if r5 > r9 { pc += 18 }
    mov64 r8, 1                                     r8 = 1 as i32 as i64 as u64
    ja lbb_25062                                    if true { pc += 16 }
lbb_25046:
    ldxdw r5, [r7+0x8]                      
    be64 r5                                         r5 = match 64 { 16 => (r5 as u16).swap_bytes() as u64, 32 => (r5 as u32).swap_bytes() as u64, 64 => r5.swap_bytes(), _ => r5 }
    ldxdw r9, [r0+0x8]                      
    be64 r9                                         r9 = match 64 { 16 => (r9 as u16).swap_bytes() as u64, 32 => (r9 as u32).swap_bytes() as u64, 64 => r9.swap_bytes(), _ => r9 }
    jne r9, r5, lbb_25042                           if r9 != r5 { pc += -9 }
    ldxdw r5, [r7+0x10]                     
    be64 r5                                         r5 = match 64 { 16 => (r5 as u16).swap_bytes() as u64, 32 => (r5 as u32).swap_bytes() as u64, 64 => r5.swap_bytes(), _ => r5 }
    ldxdw r9, [r0+0x10]                     
    be64 r9                                         r9 = match 64 { 16 => (r9 as u16).swap_bytes() as u64, 32 => (r9 as u32).swap_bytes() as u64, 64 => r9.swap_bytes(), _ => r9 }
    jne r9, r5, lbb_25042                           if r9 != r5 { pc += -14 }
    mov64 r8, 0                                     r8 = 0 as i32 as i64 as u64
    ldxdw r5, [r7+0x18]                     
    be64 r5                                         r5 = match 64 { 16 => (r5 as u16).swap_bytes() as u64, 32 => (r5 as u32).swap_bytes() as u64, 64 => r5.swap_bytes(), _ => r5 }
    ldxdw r9, [r0+0x18]                     
    be64 r9                                         r9 = match 64 { 16 => (r9 as u16).swap_bytes() as u64, 32 => (r9 as u32).swap_bytes() as u64, 64 => r9.swap_bytes(), _ => r9 }
    jne r9, r5, lbb_25042                           if r9 != r5 { pc += -20 }
lbb_25062:
    lsh64 r8, 32                                    r8 <<= 32   ///  r8 = r8.wrapping_shl(32)
    mov64 r5, r8                                    r5 = r8
    rsh64 r5, 32                                    r5 >>= 32   ///  r5 = r5.wrapping_shr(32)
    mov64 r0, 0                                     r0 = 0 as i32 as i64 as u64
    mov64 r9, 1                                     r9 = 1 as i32 as i64 as u64
    jne r5, 0, lbb_25069                            if r5 != (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r9, 0                                     r9 = 0 as i32 as i64 as u64
lbb_25069:
    arsh64 r8, 32                                   r8 >>= 32 (signed)   ///  r8 = (r8 as i64).wrapping_shr(32)
    mov64 r5, -1                                    r5 = -1 as i32 as i64 as u64
    jsgt r0, r8, lbb_24975                          if (r0 as i64) > (r8 as i64) { pc += -97 }
    mov64 r5, r9                                    r5 = r9
    ja lbb_24975                                    if true { pc += -99 }
lbb_25074:
    mov64 r1, 42                                    r1 = 42 as i32 as i64 as u64
    stxb [r6+0x0], r1                       
    ldxdw r1, [r7+0x0]                      
    stxdw [r6+0x1], r1                      
    ldxdw r1, [r7+0x8]                      
    stxdw [r6+0x9], r1                      
    ldxdw r1, [r7+0x10]                     
    stxdw [r6+0x11], r1                     
    ldxdw r1, [r7+0x18]                     
    stxdw [r6+0x19], r1                     
    ja lbb_25087                                    if true { pc += 2 }
lbb_25085:
    mov64 r1, 56                                    r1 = 56 as i32 as i64 as u64
    stxb [r6+0x0], r1                       
lbb_25087:
    exit                                    

function_25088:
    mov64 r8, r3                                    r8 = r3
    mov64 r7, r2                                    r7 = r2
    mov64 r6, r1                                    r6 = r1
    ldxdw r1, [r7+0x8]                      
    stxdw [r10-0xc8], r1                    
    ldxdw r1, [r7+0x0]                      
    stxdw [r10-0xd0], r1                    
    ldxdw r1, [r8+0x8]                      
    stxdw [r10-0x98], r1                    
    ldxdw r1, [r8+0x0]                      
    stxdw [r10-0xa0], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -112                                  r1 += -112   ///  r1 = r1.wrapping_add(-112 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -208                                  r2 += -208   ///  r2 = r2.wrapping_add(-208 as i32 as i64 as u64)
    mov64 r3, r10                                   r3 = r10
    add64 r3, -160                                  r3 += -160   ///  r3 = r3.wrapping_add(-160 as i32 as i64 as u64)
    call function_34119                     
    ldxw r1, [r10-0x70]                     
    jne r1, 0, lbb_25117                            if r1 != (0 as i32 as i64 as u64) { pc += 9 }
    ldxdw r1, [r10-0x64]                    
    stxdw [r10-0x38], r1                    
    ldxdw r2, [r10-0x6c]                    
    stxdw [r10-0x40], r2                    
    stxdw [r6+0xc], r1                      
    stxdw [r6+0x4], r2                      
    mov64 r1, 56                                    r1 = 56 as i32 as i64 as u64
    stxb [r6+0x0], r1                       
    ja lbb_25189                                    if true { pc += 72 }
lbb_25117:
    mov64 r9, 29                                    r9 = 29 as i32 as i64 as u64
    mov64 r1, 29                                    r1 = 29 as i32 as i64 as u64
    mov64 r2, 1                                     r2 = 1 as i32 as i64 as u64
    call function_21359                     
    jne r0, 0, lbb_25126                            if r0 != (0 as i32 as i64 as u64) { pc += 4 }
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    mov64 r2, 29                                    r2 = 29 as i32 as i64 as u64
    call function_43400                     
    syscall [invalid]                       
lbb_25126:
    lddw r1, 0x66666f6b63616220                     r1 load str located at 7378707546512646688
    stxdw [r0+0x15], r1                     
    lddw r1, 0x6162206d6d206f74                     r1 load str located at 7017206823751020404
    stxdw [r0+0x10], r1                     
    lddw r1, 0x20797469746e6175                     r1 load str located at 2340029477669462389
    stxdw [r0+0x8], r1                      
    lddw r1, 0x7120676e69646441                     r1 load str located at 8151629049452848193
    stxdw [r0+0x0], r1                      
    stxdw [r10-0xc0], r9                    
    stxdw [r10-0xc8], r9                    
    stxdw [r10-0xd0], r0                    
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    stxdw [r10-0x80], r1                    
    lddw r1, 0x1000659d8 --> b"\x00\x00\x00\x00\xe8\x0e\x06\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\…        r1 load str located at 4295383512
    stxdw [r10-0xa0], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -112                                  r1 += -112   ///  r1 = r1.wrapping_add(-112 as i32 as i64 as u64)
    stxdw [r10-0x90], r1                    
    lddw r1, 0x10002af50 --> b"\xbf#\x00\x00\x00\x00\x00\x00y\x12\x10\x00\x00\x00\x00\x00y\x11\x00\x00\x…        r1 load str located at 4295143248
    stxdw [r10-0x48], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -208                                  r1 += -208   ///  r1 = r1.wrapping_add(-208 as i32 as i64 as u64)
    stxdw [r10-0x50], r1                    
    stxdw [r10-0x60], r8                    
    lddw r1, 0x10003acf0 --> b"\xbf#\x00\x00\x00\x00\x00\x00\xb7\x02\x00\x00\x00\x00\x00\x00{*\xb0\xff\x…        r1 load str located at 4295208176
    stxdw [r10-0x58], r1                    
    stxdw [r10-0x68], r1                    
    stxdw [r10-0x70], r7                    
    mov64 r7, 3                                     r7 = 3 as i32 as i64 as u64
    stxdw [r10-0x98], r7                    
    stxdw [r10-0x88], r7                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -184                                  r1 += -184   ///  r1 = r1.wrapping_add(-184 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -160                                  r2 += -160   ///  r2 = r2.wrapping_add(-160 as i32 as i64 as u64)
    call function_43415                     
    ldxdw r1, [r10-0xa8]                    
    stxdw [r10-0x59], r1                    
    ldxdw r1, [r10-0xb0]                    
    stxdw [r10-0x61], r1                    
    ldxdw r1, [r10-0xb8]                    
    stxdw [r10-0x69], r1                    
    stxb [r6+0x0], r7                       
    ldxdw r1, [r10-0x59]                    
    stxdw [r6+0x18], r1                     
    ldxdw r1, [r10-0x60]                    
    stxdw [r6+0x11], r1                     
    ldxdw r1, [r10-0x68]                    
    stxdw [r6+0x9], r1                      
    ldxdw r1, [r10-0x70]                    
    stxdw [r6+0x1], r1                      
    ldxdw r2, [r10-0xc8]                    
    jeq r2, 0, lbb_25189                            if r2 == (0 as i32 as i64 as u64) { pc += 3 }
    ldxdw r1, [r10-0xd0]                    
    mov64 r3, 1                                     r3 = 1 as i32 as i64 as u64
    call function_21385                     
lbb_25189:
    exit                                    

function_25190:
    mov64 r9, r5                                    r9 = r5
    stxdw [r10-0xc8], r4                    
    mov64 r8, r3                                    r8 = r3
    mov64 r7, r2                                    r7 = r2
    mov64 r6, r1                                    r6 = r1
    ldxdw r1, [r7+0x8]                      
    stxdw [r10-0xb8], r1                    
    ldxdw r1, [r7+0x0]                      
    stxdw [r10-0xc0], r1                    
    ldxdw r1, [r8+0x8]                      
    stxdw [r10-0x88], r1                    
    ldxdw r1, [r8+0x0]                      
    stxdw [r10-0x90], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -96                                   r1 += -96   ///  r1 = r1.wrapping_add(-96 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -192                                  r2 += -192   ///  r2 = r2.wrapping_add(-192 as i32 as i64 as u64)
    mov64 r3, r10                                   r3 = r10
    add64 r3, -144                                  r3 += -144   ///  r3 = r3.wrapping_add(-144 as i32 as i64 as u64)
    call function_34119                     
    ldxw r1, [r10-0x60]                     
    jne r1, 0, lbb_25219                            if r1 != (0 as i32 as i64 as u64) { pc += 7 }
    ldxdw r1, [r10-0x54]                    
    stxdw [r6+0xc], r1                      
    ldxdw r1, [r10-0x5c]                    
    stxdw [r6+0x4], r1                      
    mov64 r1, 56                                    r1 = 56 as i32 as i64 as u64
    stxb [r6+0x0], r1                       
    ja lbb_25290                                    if true { pc += 71 }
lbb_25219:
    stxdw [r10-0xd0], r7                    
    mov64 r7, 1                                     r7 = 1 as i32 as i64 as u64
    jeq r9, 0, lbb_25234                            if r9 == (0 as i32 as i64 as u64) { pc += 12 }
    jsgt r9, -1, lbb_25225                          if (r9 as i64) > (-1 as i32 as i64) { pc += 2 }
    call function_43383                     
    syscall [invalid]                       
lbb_25225:
    mov64 r1, r9                                    r1 = r9
    mov64 r2, 1                                     r2 = 1 as i32 as i64 as u64
    call function_21359                     
    mov64 r7, r0                                    r7 = r0
    jne r7, 0, lbb_25234                            if r7 != (0 as i32 as i64 as u64) { pc += 4 }
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    mov64 r2, r9                                    r2 = r9
    call function_43400                     
    syscall [invalid]                       
lbb_25234:
    mov64 r1, r7                                    r1 = r7
    ldxdw r2, [r10-0xc8]                    
    mov64 r3, r9                                    r3 = r9
    call function_48190                     
    stxdw [r10-0xb0], r9                    
    stxdw [r10-0xb8], r9                    
    stxdw [r10-0xc0], r7                    
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    stxdw [r10-0x70], r1                    
    lddw r1, 0x1000659d8 --> b"\x00\x00\x00\x00\xe8\x0e\x06\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\…        r1 load str located at 4295383512
    stxdw [r10-0x90], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -96                                   r1 += -96   ///  r1 = r1.wrapping_add(-96 as i32 as i64 as u64)
    stxdw [r10-0x80], r1                    
    lddw r1, 0x10002af50 --> b"\xbf#\x00\x00\x00\x00\x00\x00y\x12\x10\x00\x00\x00\x00\x00y\x11\x00\x00\x…        r1 load str located at 4295143248
    stxdw [r10-0x38], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -192                                  r1 += -192   ///  r1 = r1.wrapping_add(-192 as i32 as i64 as u64)
    stxdw [r10-0x40], r1                    
    stxdw [r10-0x50], r8                    
    lddw r1, 0x100042110 --> b"\xbf'\x00\x00\x00\x00\x00\x00\xbf\x18\x00\x00\x00\x00\x00\x00yu\x18\x00\x…        r1 load str located at 4295237904
    stxdw [r10-0x48], r1                    
    stxdw [r10-0x58], r1                    
    ldxdw r1, [r10-0xd0]                    
    stxdw [r10-0x60], r1                    
    mov64 r7, 3                                     r7 = 3 as i32 as i64 as u64
    stxdw [r10-0x88], r7                    
    stxdw [r10-0x78], r7                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -168                                  r1 += -168   ///  r1 = r1.wrapping_add(-168 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -144                                  r2 += -144   ///  r2 = r2.wrapping_add(-144 as i32 as i64 as u64)
    call function_43415                     
    ldxdw r1, [r10-0x98]                    
    stxdw [r10-0x49], r1                    
    ldxdw r1, [r10-0xa0]                    
    stxdw [r10-0x51], r1                    
    ldxdw r1, [r10-0xa8]                    
    stxdw [r10-0x59], r1                    
    stxb [r6+0x0], r7                       
    ldxdw r1, [r10-0x49]                    
    stxdw [r6+0x18], r1                     
    ldxdw r1, [r10-0x50]                    
    stxdw [r6+0x11], r1                     
    ldxdw r1, [r10-0x58]                    
    stxdw [r6+0x9], r1                      
    ldxdw r1, [r10-0x60]                    
    stxdw [r6+0x1], r1                      
    ldxdw r2, [r10-0xb8]                    
    jeq r2, 0, lbb_25290                            if r2 == (0 as i32 as i64 as u64) { pc += 3 }
    ldxdw r1, [r10-0xc0]                    
    mov64 r3, 1                                     r3 = 1 as i32 as i64 as u64
    call function_21385                     
lbb_25290:
    exit                                    

function_25291:
    mov64 r9, r5                                    r9 = r5
    stxdw [r10-0xc8], r4                    
    mov64 r8, r3                                    r8 = r3
    mov64 r7, r2                                    r7 = r2
    mov64 r6, r1                                    r6 = r1
    ldxdw r1, [r7+0x8]                      
    stxdw [r10-0xb8], r1                    
    ldxdw r1, [r7+0x0]                      
    stxdw [r10-0xc0], r1                    
    ldxdw r1, [r8+0x8]                      
    stxdw [r10-0x88], r1                    
    ldxdw r1, [r8+0x0]                      
    stxdw [r10-0x90], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -96                                   r1 += -96   ///  r1 = r1.wrapping_add(-96 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -192                                  r2 += -192   ///  r2 = r2.wrapping_add(-192 as i32 as i64 as u64)
    mov64 r3, r10                                   r3 = r10
    add64 r3, -144                                  r3 += -144   ///  r3 = r3.wrapping_add(-144 as i32 as i64 as u64)
    call function_34122                     
    ldxw r1, [r10-0x60]                     
    jne r1, 0, lbb_25320                            if r1 != (0 as i32 as i64 as u64) { pc += 7 }
    ldxdw r1, [r10-0x54]                    
    stxdw [r6+0xc], r1                      
    ldxdw r1, [r10-0x5c]                    
    stxdw [r6+0x4], r1                      
    mov64 r1, 56                                    r1 = 56 as i32 as i64 as u64
    stxb [r6+0x0], r1                       
    ja lbb_25391                                    if true { pc += 71 }
lbb_25320:
    stxdw [r10-0xd0], r7                    
    mov64 r7, 1                                     r7 = 1 as i32 as i64 as u64
    jeq r9, 0, lbb_25335                            if r9 == (0 as i32 as i64 as u64) { pc += 12 }
    jsgt r9, -1, lbb_25326                          if (r9 as i64) > (-1 as i32 as i64) { pc += 2 }
    call function_43383                     
    syscall [invalid]                       
lbb_25326:
    mov64 r1, r9                                    r1 = r9
    mov64 r2, 1                                     r2 = 1 as i32 as i64 as u64
    call function_21359                     
    mov64 r7, r0                                    r7 = r0
    jne r7, 0, lbb_25335                            if r7 != (0 as i32 as i64 as u64) { pc += 4 }
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    mov64 r2, r9                                    r2 = r9
    call function_43400                     
    syscall [invalid]                       
lbb_25335:
    mov64 r1, r7                                    r1 = r7
    ldxdw r2, [r10-0xc8]                    
    mov64 r3, r9                                    r3 = r9
    call function_48190                     
    stxdw [r10-0xb0], r9                    
    stxdw [r10-0xb8], r9                    
    stxdw [r10-0xc0], r7                    
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    stxdw [r10-0x70], r1                    
    lddw r1, 0x100065a08 --> b"\x00\x00\x00\x00\xe8\x0e\x06\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\…        r1 load str located at 4295383560
    stxdw [r10-0x90], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -96                                   r1 += -96   ///  r1 = r1.wrapping_add(-96 as i32 as i64 as u64)
    stxdw [r10-0x80], r1                    
    lddw r1, 0x10002af50 --> b"\xbf#\x00\x00\x00\x00\x00\x00y\x12\x10\x00\x00\x00\x00\x00y\x11\x00\x00\x…        r1 load str located at 4295143248
    stxdw [r10-0x38], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -192                                  r1 += -192   ///  r1 = r1.wrapping_add(-192 as i32 as i64 as u64)
    stxdw [r10-0x40], r1                    
    stxdw [r10-0x50], r8                    
    lddw r1, 0x100042110 --> b"\xbf'\x00\x00\x00\x00\x00\x00\xbf\x18\x00\x00\x00\x00\x00\x00yu\x18\x00\x…        r1 load str located at 4295237904
    stxdw [r10-0x48], r1                    
    stxdw [r10-0x58], r1                    
    ldxdw r1, [r10-0xd0]                    
    stxdw [r10-0x60], r1                    
    mov64 r7, 3                                     r7 = 3 as i32 as i64 as u64
    stxdw [r10-0x88], r7                    
    stxdw [r10-0x78], r7                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -168                                  r1 += -168   ///  r1 = r1.wrapping_add(-168 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -144                                  r2 += -144   ///  r2 = r2.wrapping_add(-144 as i32 as i64 as u64)
    call function_43415                     
    ldxdw r1, [r10-0x98]                    
    stxdw [r10-0x49], r1                    
    ldxdw r1, [r10-0xa0]                    
    stxdw [r10-0x51], r1                    
    ldxdw r1, [r10-0xa8]                    
    stxdw [r10-0x59], r1                    
    stxb [r6+0x0], r7                       
    ldxdw r1, [r10-0x49]                    
    stxdw [r6+0x18], r1                     
    ldxdw r1, [r10-0x50]                    
    stxdw [r6+0x11], r1                     
    ldxdw r1, [r10-0x58]                    
    stxdw [r6+0x9], r1                      
    ldxdw r1, [r10-0x60]                    
    stxdw [r6+0x1], r1                      
    ldxdw r2, [r10-0xb8]                    
    jeq r2, 0, lbb_25391                            if r2 == (0 as i32 as i64 as u64) { pc += 3 }
    ldxdw r1, [r10-0xc0]                    
    mov64 r3, 1                                     r3 = 1 as i32 as i64 as u64
    call function_21385                     
lbb_25391:
    exit                                    

function_25392:
    mov64 r8, r3                                    r8 = r3
    mov64 r7, r2                                    r7 = r2
    mov64 r6, r1                                    r6 = r1
    ldxdw r1, [r7+0x8]                      
    stxdw [r10-0xc8], r1                    
    ldxdw r1, [r7+0x0]                      
    stxdw [r10-0xd0], r1                    
    ldxdw r1, [r8+0x8]                      
    stxdw [r10-0x98], r1                    
    ldxdw r1, [r8+0x0]                      
    stxdw [r10-0xa0], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -112                                  r1 += -112   ///  r1 = r1.wrapping_add(-112 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -208                                  r2 += -208   ///  r2 = r2.wrapping_add(-208 as i32 as i64 as u64)
    mov64 r3, r10                                   r3 = r10
    add64 r3, -160                                  r3 += -160   ///  r3 = r3.wrapping_add(-160 as i32 as i64 as u64)
    call function_34122                     
    ldxw r1, [r10-0x70]                     
    jne r1, 0, lbb_25421                            if r1 != (0 as i32 as i64 as u64) { pc += 9 }
    ldxdw r1, [r10-0x64]                    
    stxdw [r10-0x38], r1                    
    ldxdw r2, [r10-0x6c]                    
    stxdw [r10-0x40], r2                    
    stxdw [r6+0xc], r1                      
    stxdw [r6+0x4], r2                      
    mov64 r1, 56                                    r1 = 56 as i32 as i64 as u64
    stxb [r6+0x0], r1                       
    ja lbb_25487                                    if true { pc += 66 }
lbb_25421:
    mov64 r1, 36                                    r1 = 36 as i32 as i64 as u64
    mov64 r2, 1                                     r2 = 1 as i32 as i64 as u64
    call function_21359                     
    mov64 r9, r0                                    r9 = r0
    jne r9, 0, lbb_25430                            if r9 != (0 as i32 as i64 as u64) { pc += 4 }
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    mov64 r2, 36                                    r2 = 36 as i32 as i64 as u64
    call function_43400                     
    syscall [invalid]                       
lbb_25430:
    mov64 r1, r9                                    r1 = r9
    lddw r2, 0x1000613bf --> b"Subtracting quantity from mm backoff"        r2 load str located at 4295365567
    mov64 r3, 36                                    r3 = 36 as i32 as i64 as u64
    call function_48190                     
    mov64 r1, 36                                    r1 = 36 as i32 as i64 as u64
    stxdw [r10-0xc0], r1                    
    stxdw [r10-0xc8], r1                    
    stxdw [r10-0xd0], r9                    
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    stxdw [r10-0x80], r1                    
    lddw r1, 0x100065a08 --> b"\x00\x00\x00\x00\xe8\x0e\x06\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\…        r1 load str located at 4295383560
    stxdw [r10-0xa0], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -112                                  r1 += -112   ///  r1 = r1.wrapping_add(-112 as i32 as i64 as u64)
    stxdw [r10-0x90], r1                    
    lddw r1, 0x10002af50 --> b"\xbf#\x00\x00\x00\x00\x00\x00y\x12\x10\x00\x00\x00\x00\x00y\x11\x00\x00\x…        r1 load str located at 4295143248
    stxdw [r10-0x48], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -208                                  r1 += -208   ///  r1 = r1.wrapping_add(-208 as i32 as i64 as u64)
    stxdw [r10-0x50], r1                    
    stxdw [r10-0x60], r8                    
    lddw r1, 0x10003acf0 --> b"\xbf#\x00\x00\x00\x00\x00\x00\xb7\x02\x00\x00\x00\x00\x00\x00{*\xb0\xff\x…        r1 load str located at 4295208176
    stxdw [r10-0x58], r1                    
    stxdw [r10-0x68], r1                    
    stxdw [r10-0x70], r7                    
    mov64 r7, 3                                     r7 = 3 as i32 as i64 as u64
    stxdw [r10-0x98], r7                    
    stxdw [r10-0x88], r7                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -184                                  r1 += -184   ///  r1 = r1.wrapping_add(-184 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -160                                  r2 += -160   ///  r2 = r2.wrapping_add(-160 as i32 as i64 as u64)
    call function_43415                     
    ldxdw r1, [r10-0xa8]                    
    stxdw [r10-0x59], r1                    
    ldxdw r1, [r10-0xb0]                    
    stxdw [r10-0x61], r1                    
    ldxdw r1, [r10-0xb8]                    
    stxdw [r10-0x69], r1                    
    stxb [r6+0x0], r7                       
    ldxdw r1, [r10-0x59]                    
    stxdw [r6+0x18], r1                     
    ldxdw r1, [r10-0x60]                    
    stxdw [r6+0x11], r1                     
    ldxdw r1, [r10-0x68]                    
    stxdw [r6+0x9], r1                      
    ldxdw r1, [r10-0x70]                    
    stxdw [r6+0x1], r1                      
    ldxdw r2, [r10-0xc8]                    
    jeq r2, 0, lbb_25487                            if r2 == (0 as i32 as i64 as u64) { pc += 3 }
    ldxdw r1, [r10-0xd0]                    
    mov64 r3, 1                                     r3 = 1 as i32 as i64 as u64
    call function_21385                     
lbb_25487:
    exit                                    

function_25488:
    mov64 r9, r5                                    r9 = r5
    stxdw [r10-0xc8], r4                    
    mov64 r8, r3                                    r8 = r3
    mov64 r7, r2                                    r7 = r2
    mov64 r6, r1                                    r6 = r1
    ldxdw r1, [r7+0x8]                      
    stxdw [r10-0xb8], r1                    
    ldxdw r1, [r7+0x0]                      
    stxdw [r10-0xc0], r1                    
    ldxdw r1, [r8+0x8]                      
    stxdw [r10-0x88], r1                    
    ldxdw r1, [r8+0x0]                      
    stxdw [r10-0x90], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -96                                   r1 += -96   ///  r1 = r1.wrapping_add(-96 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -192                                  r2 += -192   ///  r2 = r2.wrapping_add(-192 as i32 as i64 as u64)
    mov64 r3, r10                                   r3 = r10
    add64 r3, -144                                  r3 += -144   ///  r3 = r3.wrapping_add(-144 as i32 as i64 as u64)
    call function_35767                     
    ldxw r1, [r10-0x60]                     
    jne r1, 0, lbb_25517                            if r1 != (0 as i32 as i64 as u64) { pc += 7 }
    ldxdw r1, [r10-0x54]                    
    stxdw [r6+0xc], r1                      
    ldxdw r1, [r10-0x5c]                    
    stxdw [r6+0x4], r1                      
    mov64 r1, 56                                    r1 = 56 as i32 as i64 as u64
    stxb [r6+0x0], r1                       
    ja lbb_25588                                    if true { pc += 71 }
lbb_25517:
    stxdw [r10-0xd0], r7                    
    mov64 r7, 1                                     r7 = 1 as i32 as i64 as u64
    jeq r9, 0, lbb_25532                            if r9 == (0 as i32 as i64 as u64) { pc += 12 }
    jsgt r9, -1, lbb_25523                          if (r9 as i64) > (-1 as i32 as i64) { pc += 2 }
    call function_43383                     
    syscall [invalid]                       
lbb_25523:
    mov64 r1, r9                                    r1 = r9
    mov64 r2, 1                                     r2 = 1 as i32 as i64 as u64
    call function_21359                     
    mov64 r7, r0                                    r7 = r0
    jne r7, 0, lbb_25532                            if r7 != (0 as i32 as i64 as u64) { pc += 4 }
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    mov64 r2, r9                                    r2 = r9
    call function_43400                     
    syscall [invalid]                       
lbb_25532:
    mov64 r1, r7                                    r1 = r7
    ldxdw r2, [r10-0xc8]                    
    mov64 r3, r9                                    r3 = r9
    call function_48190                     
    stxdw [r10-0xb0], r9                    
    stxdw [r10-0xb8], r9                    
    stxdw [r10-0xc0], r7                    
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    stxdw [r10-0x70], r1                    
    lddw r1, 0x100065a38 --> b"\x00\x00\x00\x00\xe8\x0e\x06\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\…        r1 load str located at 4295383608
    stxdw [r10-0x90], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -96                                   r1 += -96   ///  r1 = r1.wrapping_add(-96 as i32 as i64 as u64)
    stxdw [r10-0x80], r1                    
    lddw r1, 0x10002af50 --> b"\xbf#\x00\x00\x00\x00\x00\x00y\x12\x10\x00\x00\x00\x00\x00y\x11\x00\x00\x…        r1 load str located at 4295143248
    stxdw [r10-0x38], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -192                                  r1 += -192   ///  r1 = r1.wrapping_add(-192 as i32 as i64 as u64)
    stxdw [r10-0x40], r1                    
    stxdw [r10-0x50], r8                    
    lddw r1, 0x100042110 --> b"\xbf'\x00\x00\x00\x00\x00\x00\xbf\x18\x00\x00\x00\x00\x00\x00yu\x18\x00\x…        r1 load str located at 4295237904
    stxdw [r10-0x48], r1                    
    stxdw [r10-0x58], r1                    
    ldxdw r1, [r10-0xd0]                    
    stxdw [r10-0x60], r1                    
    mov64 r7, 3                                     r7 = 3 as i32 as i64 as u64
    stxdw [r10-0x88], r7                    
    stxdw [r10-0x78], r7                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -168                                  r1 += -168   ///  r1 = r1.wrapping_add(-168 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -144                                  r2 += -144   ///  r2 = r2.wrapping_add(-144 as i32 as i64 as u64)
    call function_43415                     
    ldxdw r1, [r10-0x98]                    
    stxdw [r10-0x49], r1                    
    ldxdw r1, [r10-0xa0]                    
    stxdw [r10-0x51], r1                    
    ldxdw r1, [r10-0xa8]                    
    stxdw [r10-0x59], r1                    
    stxb [r6+0x0], r7                       
    ldxdw r1, [r10-0x49]                    
    stxdw [r6+0x18], r1                     
    ldxdw r1, [r10-0x50]                    
    stxdw [r6+0x11], r1                     
    ldxdw r1, [r10-0x58]                    
    stxdw [r6+0x9], r1                      
    ldxdw r1, [r10-0x60]                    
    stxdw [r6+0x1], r1                      
    ldxdw r2, [r10-0xb8]                    
    jeq r2, 0, lbb_25588                            if r2 == (0 as i32 as i64 as u64) { pc += 3 }
    ldxdw r1, [r10-0xc0]                    
    mov64 r3, 1                                     r3 = 1 as i32 as i64 as u64
    call function_21385                     
lbb_25588:
    exit                                    

function_25589:
    mov64 r9, r5                                    r9 = r5
    stxdw [r10-0xc8], r4                    
    mov64 r8, r3                                    r8 = r3
    mov64 r7, r2                                    r7 = r2
    mov64 r6, r1                                    r6 = r1
    ldxdw r1, [r7+0x8]                      
    stxdw [r10-0xb8], r1                    
    ldxdw r1, [r7+0x0]                      
    stxdw [r10-0xc0], r1                    
    ldxdw r1, [r8+0x8]                      
    stxdw [r10-0x88], r1                    
    ldxdw r1, [r8+0x0]                      
    stxdw [r10-0x90], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -96                                   r1 += -96   ///  r1 = r1.wrapping_add(-96 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -192                                  r2 += -192   ///  r2 = r2.wrapping_add(-192 as i32 as i64 as u64)
    mov64 r3, r10                                   r3 = r10
    add64 r3, -144                                  r3 += -144   ///  r3 = r3.wrapping_add(-144 as i32 as i64 as u64)
    call function_37362                     
    ldxw r1, [r10-0x60]                     
    jne r1, 0, lbb_25618                            if r1 != (0 as i32 as i64 as u64) { pc += 7 }
    ldxdw r1, [r10-0x54]                    
    stxdw [r6+0xc], r1                      
    ldxdw r1, [r10-0x5c]                    
    stxdw [r6+0x4], r1                      
    mov64 r1, 56                                    r1 = 56 as i32 as i64 as u64
    stxb [r6+0x0], r1                       
    ja lbb_25689                                    if true { pc += 71 }
lbb_25618:
    stxdw [r10-0xd0], r7                    
    mov64 r7, 1                                     r7 = 1 as i32 as i64 as u64
    jeq r9, 0, lbb_25633                            if r9 == (0 as i32 as i64 as u64) { pc += 12 }
    jsgt r9, -1, lbb_25624                          if (r9 as i64) > (-1 as i32 as i64) { pc += 2 }
    call function_43383                     
    syscall [invalid]                       
lbb_25624:
    mov64 r1, r9                                    r1 = r9
    mov64 r2, 1                                     r2 = 1 as i32 as i64 as u64
    call function_21359                     
    mov64 r7, r0                                    r7 = r0
    jne r7, 0, lbb_25633                            if r7 != (0 as i32 as i64 as u64) { pc += 4 }
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    mov64 r2, r9                                    r2 = r9
    call function_43400                     
    syscall [invalid]                       
lbb_25633:
    mov64 r1, r7                                    r1 = r7
    ldxdw r2, [r10-0xc8]                    
    mov64 r3, r9                                    r3 = r9
    call function_48190                     
    stxdw [r10-0xb0], r9                    
    stxdw [r10-0xb8], r9                    
    stxdw [r10-0xc0], r7                    
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    stxdw [r10-0x70], r1                    
    lddw r1, 0x100065a68 --> b"\x00\x00\x00\x00\xe8\x0e\x06\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\…        r1 load str located at 4295383656
    stxdw [r10-0x90], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -96                                   r1 += -96   ///  r1 = r1.wrapping_add(-96 as i32 as i64 as u64)
    stxdw [r10-0x80], r1                    
    lddw r1, 0x10002af50 --> b"\xbf#\x00\x00\x00\x00\x00\x00y\x12\x10\x00\x00\x00\x00\x00y\x11\x00\x00\x…        r1 load str located at 4295143248
    stxdw [r10-0x38], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -192                                  r1 += -192   ///  r1 = r1.wrapping_add(-192 as i32 as i64 as u64)
    stxdw [r10-0x40], r1                    
    stxdw [r10-0x50], r8                    
    lddw r1, 0x100042110 --> b"\xbf'\x00\x00\x00\x00\x00\x00\xbf\x18\x00\x00\x00\x00\x00\x00yu\x18\x00\x…        r1 load str located at 4295237904
    stxdw [r10-0x48], r1                    
    stxdw [r10-0x58], r1                    
    ldxdw r1, [r10-0xd0]                    
    stxdw [r10-0x60], r1                    
    mov64 r7, 3                                     r7 = 3 as i32 as i64 as u64
    stxdw [r10-0x88], r7                    
    stxdw [r10-0x78], r7                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -168                                  r1 += -168   ///  r1 = r1.wrapping_add(-168 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -144                                  r2 += -144   ///  r2 = r2.wrapping_add(-144 as i32 as i64 as u64)
    call function_43415                     
    ldxdw r1, [r10-0x98]                    
    stxdw [r10-0x49], r1                    
    ldxdw r1, [r10-0xa0]                    
    stxdw [r10-0x51], r1                    
    ldxdw r1, [r10-0xa8]                    
    stxdw [r10-0x59], r1                    
    stxb [r6+0x0], r7                       
    ldxdw r1, [r10-0x49]                    
    stxdw [r6+0x18], r1                     
    ldxdw r1, [r10-0x50]                    
    stxdw [r6+0x11], r1                     
    ldxdw r1, [r10-0x58]                    
    stxdw [r6+0x9], r1                      
    ldxdw r1, [r10-0x60]                    
    stxdw [r6+0x1], r1                      
    ldxdw r2, [r10-0xb8]                    
    jeq r2, 0, lbb_25689                            if r2 == (0 as i32 as i64 as u64) { pc += 3 }
    ldxdw r1, [r10-0xc0]                    
    mov64 r3, 1                                     r3 = 1 as i32 as i64 as u64
    call function_21385                     
lbb_25689:
    exit                                    

function_25690:
    mov64 r7, r4                                    r7 = r4
    mov64 r6, r1                                    r6 = r1
    ldxdw r1, [r5-0xff8]                    
    stxdw [r10-0xc0], r1                    
    ldxdw r1, [r5-0x1000]                   
    stxdw [r10-0xc8], r1                    
    ldxb r1, [r2+0x0]                       
    jne r1, 0, lbb_25708                            if r1 != (0 as i32 as i64 as u64) { pc += 10 }
    ldxdw r1, [r2+0x19]                     
    stxdw [r6+0x19], r1                     
    ldxdw r1, [r2+0x11]                     
    stxdw [r6+0x11], r1                     
    ldxdw r1, [r2+0x9]                      
    stxdw [r6+0x9], r1                      
    ldxdw r1, [r2+0x1]                      
    stxdw [r6+0x1], r1                      
    mov64 r1, 56                                    r1 = 56 as i32 as i64 as u64
    ja lbb_25780                                    if true { pc += 72 }
lbb_25708:
    stxdw [r10-0xd0], r3                    
    ldxb r1, [r2+0x1]                       
    stxb [r10-0xb1], r1                     
    lddw r1, 0x100065ab8 --> b"\x00\x00\x00\x00\xb1\x16\x06\x00\x1b\x00\x00\x00\x00\x00\x00\x00k\x00\x00…        r1 load str located at 4295383736
    stxdw [r10-0xb0], r1                    
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    stxdw [r10-0x70], r1                    
    lddw r1, 0x100065ad0 --> b"\x00\x00\x00\x00\xe8\x0e\x06\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\…        r1 load str located at 4295383760
    stxdw [r10-0x90], r1                    
    mov64 r1, 3                                     r1 = 3 as i32 as i64 as u64
    stxdw [r10-0x88], r1                    
    stxdw [r10-0x78], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -96                                   r1 += -96   ///  r1 = r1.wrapping_add(-96 as i32 as i64 as u64)
    stxdw [r10-0x80], r1                    
    lddw r1, 0x10002a248 --> b"y\x11\x00\x00\x00\x00\x00\x00\x85\x10\x00\x00%X\x00\x00\x95\x00\x00\x00\x…        r1 load str located at 4295139912
    stxdw [r10-0x38], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -176                                  r1 += -176   ///  r1 = r1.wrapping_add(-176 as i32 as i64 as u64)
    stxdw [r10-0x40], r1                    
    lddw r1, 0x100051fa8 --> b"q\x11\x00\x00\x00\x00\x00\x00\x15\x01\x06\x00\x00\x00\x00\x00\x15\x01\x0a…        r1 load str located at 4295303080
    stxdw [r10-0x48], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -177                                  r1 += -177   ///  r1 = r1.wrapping_add(-177 as i32 as i64 as u64)
    stxdw [r10-0x50], r1                    
    lddw r1, 0x10002a388 --> b"\xbf#\x00\x00\x00\x00\x00\x00y\x12\x08\x00\x00\x00\x00\x00y\x11\x00\x00\x…        r1 load str located at 4295140232
    stxdw [r10-0x58], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -200                                  r1 += -200   ///  r1 = r1.wrapping_add(-200 as i32 as i64 as u64)
    stxdw [r10-0x60], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -168                                  r1 += -168   ///  r1 = r1.wrapping_add(-168 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -144                                  r2 += -144   ///  r2 = r2.wrapping_add(-144 as i32 as i64 as u64)
    call function_43415                     
    ldxdw r9, [r10-0xa0]                    
    ldxdw r8, [r10-0xa8]                    
    ldxdw r2, [r10-0x98]                    
    mov64 r1, r8                                    r1 = r8
    syscall [invalid]                       
    jeq r9, 0, lbb_25758                            if r9 == (0 as i32 as i64 as u64) { pc += 4 }
    mov64 r1, r8                                    r1 = r8
    mov64 r2, r9                                    r2 = r9
    mov64 r3, 1                                     r3 = 1 as i32 as i64 as u64
    call function_21385                     
lbb_25758:
    mov64 r9, 1                                     r9 = 1 as i32 as i64 as u64
    jeq r7, 0, lbb_25772                            if r7 == (0 as i32 as i64 as u64) { pc += 12 }
    jsgt r7, -1, lbb_25763                          if (r7 as i64) > (-1 as i32 as i64) { pc += 2 }
    call function_43383                     
    syscall [invalid]                       
lbb_25763:
    mov64 r1, r7                                    r1 = r7
    mov64 r2, 1                                     r2 = 1 as i32 as i64 as u64
    call function_21359                     
    mov64 r9, r0                                    r9 = r0
    jne r9, 0, lbb_25772                            if r9 != (0 as i32 as i64 as u64) { pc += 4 }
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    mov64 r2, r7                                    r2 = r7
    call function_43400                     
    syscall [invalid]                       
lbb_25772:
    mov64 r1, r9                                    r1 = r9
    ldxdw r2, [r10-0xd0]                    
    mov64 r3, r7                                    r3 = r7
    call function_48190                     
    stxdw [r6+0x18], r7                     
    stxdw [r6+0x10], r7                     
    stxdw [r6+0x8], r9                      
    mov64 r1, 29                                    r1 = 29 as i32 as i64 as u64
lbb_25780:
    stxb [r6+0x0], r1                       
    exit                                    

function_25782:
    mov64 r7, r4                                    r7 = r4
    mov64 r6, r1                                    r6 = r1
    ldxdw r1, [r5-0xff8]                    
    stxdw [r10-0xf0], r1                    
    ldxdw r1, [r5-0x1000]                   
    stxdw [r10-0xf8], r1                    
    ldxb r1, [r2+0x0]                       
    jne r1, 11, lbb_25796                           if r1 != (11 as i32 as i64 as u64) { pc += 6 }
    ldxdw r1, [r2+0xc]                      
    stxdw [r6+0xc], r1                      
    ldxdw r1, [r2+0x4]                      
    stxdw [r6+0x4], r1                      
    mov64 r1, 56                                    r1 = 56 as i32 as i64 as u64
    ja lbb_25869                                    if true { pc += 73 }
lbb_25796:
    stxdw [r10-0x100], r3                   
    mov64 r9, r10                                   r9 = r10
    add64 r9, -232                                  r9 += -232   ///  r9 = r9.wrapping_add(-232 as i32 as i64 as u64)
    mov64 r1, r9                                    r1 = r9
    mov64 r3, 56                                    r3 = 56 as i32 as i64 as u64
    call function_48190                     
    lddw r1, 0x100065ab8 --> b"\x00\x00\x00\x00\xb1\x16\x06\x00\x1b\x00\x00\x00\x00\x00\x00\x00k\x00\x00…        r1 load str located at 4295383736
    stxdw [r10-0xb0], r1                    
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    stxdw [r10-0x70], r1                    
    lddw r1, 0x100065ad0 --> b"\x00\x00\x00\x00\xe8\x0e\x06\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\…        r1 load str located at 4295383760
    stxdw [r10-0x90], r1                    
    mov64 r1, 3                                     r1 = 3 as i32 as i64 as u64
    stxdw [r10-0x88], r1                    
    stxdw [r10-0x78], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -96                                   r1 += -96   ///  r1 = r1.wrapping_add(-96 as i32 as i64 as u64)
    stxdw [r10-0x80], r1                    
    lddw r1, 0x10002a248 --> b"y\x11\x00\x00\x00\x00\x00\x00\x85\x10\x00\x00%X\x00\x00\x95\x00\x00\x00\x…        r1 load str located at 4295139912
    stxdw [r10-0x38], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -176                                  r1 += -176   ///  r1 = r1.wrapping_add(-176 as i32 as i64 as u64)
    stxdw [r10-0x40], r1                    
    lddw r1, 0x10003cb40 --> b"\xbf#\x00\x00\x00\x00\x00\x00q\x12\x00\x00\x00\x00\x00\x00e\x02\x1b\x00\x…        r1 load str located at 4295215936
    stxdw [r10-0x48], r1                    
    stxdw [r10-0x50], r9                    
    lddw r1, 0x10002a388 --> b"\xbf#\x00\x00\x00\x00\x00\x00y\x12\x08\x00\x00\x00\x00\x00y\x11\x00\x00\x…        r1 load str located at 4295140232
    stxdw [r10-0x58], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -248                                  r1 += -248   ///  r1 = r1.wrapping_add(-248 as i32 as i64 as u64)
    stxdw [r10-0x60], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -168                                  r1 += -168   ///  r1 = r1.wrapping_add(-168 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -144                                  r2 += -144   ///  r2 = r2.wrapping_add(-144 as i32 as i64 as u64)
    call function_43415                     
    ldxdw r9, [r10-0xa0]                    
    ldxdw r8, [r10-0xa8]                    
    ldxdw r2, [r10-0x98]                    
    mov64 r1, r8                                    r1 = r8
    syscall [invalid]                       
    jeq r9, 0, lbb_25847                            if r9 == (0 as i32 as i64 as u64) { pc += 4 }
    mov64 r1, r8                                    r1 = r8
    mov64 r2, r9                                    r2 = r9
    mov64 r3, 1                                     r3 = 1 as i32 as i64 as u64
    call function_21385                     
lbb_25847:
    mov64 r9, 1                                     r9 = 1 as i32 as i64 as u64
    jeq r7, 0, lbb_25861                            if r7 == (0 as i32 as i64 as u64) { pc += 12 }
    jsgt r7, -1, lbb_25852                          if (r7 as i64) > (-1 as i32 as i64) { pc += 2 }
    call function_43383                     
    syscall [invalid]                       
lbb_25852:
    mov64 r1, r7                                    r1 = r7
    mov64 r2, 1                                     r2 = 1 as i32 as i64 as u64
    call function_21359                     
    mov64 r9, r0                                    r9 = r0
    jne r9, 0, lbb_25861                            if r9 != (0 as i32 as i64 as u64) { pc += 4 }
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    mov64 r2, r7                                    r2 = r7
    call function_43400                     
    syscall [invalid]                       
lbb_25861:
    mov64 r1, r9                                    r1 = r9
    ldxdw r2, [r10-0x100]                   
    mov64 r3, r7                                    r3 = r7
    call function_48190                     
    stxdw [r6+0x18], r7                     
    stxdw [r6+0x10], r7                     
    stxdw [r6+0x8], r9                      
    mov64 r1, 29                                    r1 = 29 as i32 as i64 as u64
lbb_25869:
    stxb [r6+0x0], r1                       
    exit                                    

function_25871:
    ldxb r2, [r1+0x0]                       
    jsgt r2, 24, lbb_25881                          if (r2 as i64) > (24 as i32 as i64) { pc += 8 }
    jsgt r2, 11, lbb_25894                          if (r2 as i64) > (11 as i32 as i64) { pc += 20 }
    jsgt r2, 5, lbb_25910                           if (r2 as i64) > (5 as i32 as i64) { pc += 35 }
    jsgt r2, 2, lbb_25937                           if (r2 as i64) > (2 as i32 as i64) { pc += 61 }
    mov64 r6, 0                                     r6 = 0 as i32 as i64 as u64
    jeq r2, 0, lbb_26064                            if r2 == (0 as i32 as i64 as u64) { pc += 186 }
    jeq r2, 1, lbb_26005                            if r2 == (1 as i32 as i64 as u64) { pc += 126 }
    mov64 r6, 2                                     r6 = 2 as i32 as i64 as u64
    ja lbb_26064                                    if true { pc += 183 }
lbb_25881:
    jsgt r2, 41, lbb_25888                          if (r2 as i64) > (41 as i32 as i64) { pc += 6 }
    jsgt r2, 35, lbb_25915                          if (r2 as i64) > (35 as i32 as i64) { pc += 32 }
    jsgt r2, 27, lbb_25928                          if (r2 as i64) > (27 as i32 as i64) { pc += 44 }
    jeq r2, 25, lbb_26007                           if r2 == (25 as i32 as i64 as u64) { pc += 122 }
    jeq r2, 26, lbb_26009                           if r2 == (26 as i32 as i64 as u64) { pc += 123 }
    mov64 r6, 31                                    r6 = 31 as i32 as i64 as u64
    ja lbb_26064                                    if true { pc += 176 }
lbb_25888:
    jsgt r2, 48, lbb_25905                          if (r2 as i64) > (48 as i32 as i64) { pc += 16 }
    jsgt r2, 44, lbb_25920                          if (r2 as i64) > (44 as i32 as i64) { pc += 30 }
    jeq r2, 42, lbb_26011                           if r2 == (42 as i32 as i64 as u64) { pc += 120 }
    jeq r2, 43, lbb_26013                           if r2 == (43 as i32 as i64 as u64) { pc += 121 }
    mov64 r6, 42                                    r6 = 42 as i32 as i64 as u64
    ja lbb_26064                                    if true { pc += 170 }
lbb_25894:
    jsgt r2, 17, lbb_25900                          if (r2 as i64) > (17 as i32 as i64) { pc += 5 }
    jsgt r2, 14, lbb_25941                          if (r2 as i64) > (14 as i32 as i64) { pc += 45 }
    jeq r2, 12, lbb_26015                           if r2 == (12 as i32 as i64 as u64) { pc += 118 }
    jeq r2, 13, lbb_26017                           if r2 == (13 as i32 as i64 as u64) { pc += 119 }
    mov64 r6, 13                                    r6 = 13 as i32 as i64 as u64
    ja lbb_26064                                    if true { pc += 164 }
lbb_25900:
    jsgt r2, 20, lbb_25924                          if (r2 as i64) > (20 as i32 as i64) { pc += 23 }
    jeq r2, 18, lbb_26003                           if r2 == (18 as i32 as i64 as u64) { pc += 101 }
    jeq r2, 19, lbb_26019                           if r2 == (19 as i32 as i64 as u64) { pc += 116 }
    mov64 r6, 21                                    r6 = 21 as i32 as i64 as u64
    ja lbb_26064                                    if true { pc += 159 }
lbb_25905:
    jsgt r2, 51, lbb_25933                          if (r2 as i64) > (51 as i32 as i64) { pc += 27 }
    jeq r2, 49, lbb_26021                           if r2 == (49 as i32 as i64 as u64) { pc += 114 }
    jeq r2, 50, lbb_26023                           if r2 == (50 as i32 as i64 as u64) { pc += 115 }
    mov64 r6, 49                                    r6 = 49 as i32 as i64 as u64
    ja lbb_26064                                    if true { pc += 154 }
lbb_25910:
    jsgt r2, 8, lbb_25945                           if (r2 as i64) > (8 as i32 as i64) { pc += 34 }
    jeq r2, 6, lbb_26025                            if r2 == (6 as i32 as i64 as u64) { pc += 113 }
    jeq r2, 7, lbb_26027                            if r2 == (7 as i32 as i64 as u64) { pc += 114 }
    mov64 r6, 8                                     r6 = 8 as i32 as i64 as u64
    ja lbb_26064                                    if true { pc += 149 }
lbb_25915:
    jsgt r2, 38, lbb_25949                          if (r2 as i64) > (38 as i32 as i64) { pc += 33 }
    jeq r2, 36, lbb_26029                           if r2 == (36 as i32 as i64 as u64) { pc += 112 }
    jeq r2, 37, lbb_26031                           if r2 == (37 as i32 as i64 as u64) { pc += 113 }
    mov64 r6, 36                                    r6 = 36 as i32 as i64 as u64
    ja lbb_26064                                    if true { pc += 144 }
lbb_25920:
    jsgt r2, 46, lbb_25953                          if (r2 as i64) > (46 as i32 as i64) { pc += 32 }
    jeq r2, 45, lbb_26033                           if r2 == (45 as i32 as i64 as u64) { pc += 111 }
    mov64 r6, 44                                    r6 = 44 as i32 as i64 as u64
    ja lbb_26064                                    if true { pc += 140 }
lbb_25924:
    jsgt r2, 22, lbb_25956                          if (r2 as i64) > (22 as i32 as i64) { pc += 31 }
    jeq r2, 21, lbb_26035                           if r2 == (21 as i32 as i64 as u64) { pc += 109 }
    mov64 r6, 26                                    r6 = 26 as i32 as i64 as u64
    ja lbb_26064                                    if true { pc += 136 }
lbb_25928:
    jsgt r2, 29, lbb_25959                          if (r2 as i64) > (29 as i32 as i64) { pc += 30 }
    jeq r2, 28, lbb_26037                           if r2 == (28 as i32 as i64 as u64) { pc += 107 }
    lddw r6, 0xffffffff                             r6 load str located at 4294967295
    ja lbb_26064                                    if true { pc += 131 }
lbb_25933:
    jsgt r2, 53, lbb_25979                          if (r2 as i64) > (53 as i32 as i64) { pc += 45 }
    jeq r2, 52, lbb_26039                           if r2 == (52 as i32 as i64 as u64) { pc += 104 }
    mov64 r6, 51                                    r6 = 51 as i32 as i64 as u64
    ja lbb_26064                                    if true { pc += 127 }
lbb_25937:
    jeq r2, 3, lbb_26041                            if r2 == (3 as i32 as i64 as u64) { pc += 103 }
    jeq r2, 4, lbb_26043                            if r2 == (4 as i32 as i64 as u64) { pc += 104 }
    mov64 r6, 5                                     r6 = 5 as i32 as i64 as u64
    ja lbb_26064                                    if true { pc += 123 }
lbb_25941:
    jeq r2, 15, lbb_26045                           if r2 == (15 as i32 as i64 as u64) { pc += 103 }
    jeq r2, 16, lbb_26047                           if r2 == (16 as i32 as i64 as u64) { pc += 104 }
    mov64 r6, 18                                    r6 = 18 as i32 as i64 as u64
    ja lbb_26064                                    if true { pc += 119 }
lbb_25945:
    jeq r2, 9, lbb_26049                            if r2 == (9 as i32 as i64 as u64) { pc += 103 }
    jeq r2, 10, lbb_26051                           if r2 == (10 as i32 as i64 as u64) { pc += 104 }
    mov64 r6, 24                                    r6 = 24 as i32 as i64 as u64
    ja lbb_26064                                    if true { pc += 115 }
lbb_25949:
    jeq r2, 39, lbb_26053                           if r2 == (39 as i32 as i64 as u64) { pc += 103 }
    jeq r2, 40, lbb_26055                           if r2 == (40 as i32 as i64 as u64) { pc += 104 }
    mov64 r6, 39                                    r6 = 39 as i32 as i64 as u64
    ja lbb_26064                                    if true { pc += 111 }
lbb_25953:
    jeq r2, 47, lbb_26057                           if r2 == (47 as i32 as i64 as u64) { pc += 103 }
    mov64 r6, 46                                    r6 = 46 as i32 as i64 as u64
    ja lbb_26064                                    if true { pc += 108 }
lbb_25956:
    jeq r2, 23, lbb_26059                           if r2 == (23 as i32 as i64 as u64) { pc += 102 }
    mov64 r6, 28                                    r6 = 28 as i32 as i64 as u64
    ja lbb_26064                                    if true { pc += 105 }
lbb_25959:
    jeq r2, 35, lbb_26061                           if r2 == (35 as i32 as i64 as u64) { pc += 101 }
    lddw r2, 0x10003b088 --> b"q\x13\x00\x00\x00\x00\x00\x00e\x03\x0d\x00\x1b\x00\x00\x00e\x03\x19\x00\x…        r2 load str located at 4295209096
    stxdw [r10-0x8], r2                     
    stxdw [r10-0x10], r1                    
    mov64 r6, r10                                   r6 = r10
    add64 r6, -64                                   r6 += -64   ///  r6 = r6.wrapping_add(-64 as i32 as i64 as u64)
    mov64 r4, r10                                   r4 = r10
    add64 r4, -16                                   r4 += -16   ///  r4 = r4.wrapping_add(-16 as i32 as i64 as u64)
    mov64 r1, r6                                    r1 = r6
    lddw r2, 0x100065b00 --> b"\x00\x00"            r2 load str located at 4295383808
    mov64 r3, 2                                     r3 = 2 as i32 as i64 as u64
    mov64 r5, 1                                     r5 = 1 as i32 as i64 as u64
    call function_21625                     
    mov64 r1, r6                                    r1 = r6
    lddw r2, 0x100065b20 --> b"\x00\x00\x00\x00\xb8\xfc\x05\x00\x10\x00\x00\x00\x00\x00\x00\x00\x8e\x01\…        r2 load str located at 4295383840
    call function_44240                     
    syscall [invalid]                       
lbb_25979:
    jeq r2, 54, lbb_26063                           if r2 == (54 as i32 as i64 as u64) { pc += 83 }
    add64 r1, 8                                     r1 += 8   ///  r1 = r1.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x48], r1                    
    lddw r1, 0x10002a260 --> b"y\x11\x00\x00\x00\x00\x00\x00\x85\x10\x00\x00\xe5N\x00\x00\x95\x00\x00\x0…        r1 load str located at 4295139936
    stxdw [r10-0x8], r1                     
    mov64 r1, r10                                   r1 = r10
    add64 r1, -72                                   r1 += -72   ///  r1 = r1.wrapping_add(-72 as i32 as i64 as u64)
    stxdw [r10-0x10], r1                    
    mov64 r6, r10                                   r6 = r10
    add64 r6, -64                                   r6 += -64   ///  r6 = r6.wrapping_add(-64 as i32 as i64 as u64)
    mov64 r4, r10                                   r4 = r10
    add64 r4, -16                                   r4 += -16   ///  r4 = r4.wrapping_add(-16 as i32 as i64 as u64)
    mov64 r1, r6                                    r1 = r6
    lddw r2, 0x100065b38 --> b"\x00"                r2 load str located at 4295383864
    mov64 r3, 1                                     r3 = 1 as i32 as i64 as u64
    mov64 r5, 1                                     r5 = 1 as i32 as i64 as u64
    call function_21625                     
    mov64 r1, r6                                    r1 = r6
    lddw r2, 0x100065b48 --> b"\x00\x00\x00\x00\xb8\xfc\x05\x00\x10\x00\x00\x00\x00\x00\x00\x00\x91\x01\…        r2 load str located at 4295383880
    call function_44240                     
    syscall [invalid]                       
lbb_26003:
    mov64 r6, 19                                    r6 = 19 as i32 as i64 as u64
    ja lbb_26064                                    if true { pc += 59 }
lbb_26005:
    mov64 r6, 1                                     r6 = 1 as i32 as i64 as u64
    ja lbb_26064                                    if true { pc += 57 }
lbb_26007:
    mov64 r6, 29                                    r6 = 29 as i32 as i64 as u64
    ja lbb_26064                                    if true { pc += 55 }
lbb_26009:
    mov64 r6, 30                                    r6 = 30 as i32 as i64 as u64
    ja lbb_26064                                    if true { pc += 53 }
lbb_26011:
    mov64 r6, 40                                    r6 = 40 as i32 as i64 as u64
    ja lbb_26064                                    if true { pc += 51 }
lbb_26013:
    mov64 r6, 41                                    r6 = 41 as i32 as i64 as u64
    ja lbb_26064                                    if true { pc += 49 }
lbb_26015:
    mov64 r6, 10                                    r6 = 10 as i32 as i64 as u64
    ja lbb_26064                                    if true { pc += 47 }
lbb_26017:
    mov64 r6, 12                                    r6 = 12 as i32 as i64 as u64
    ja lbb_26064                                    if true { pc += 45 }
lbb_26019:
    mov64 r6, 20                                    r6 = 20 as i32 as i64 as u64
    ja lbb_26064                                    if true { pc += 43 }
lbb_26021:
    mov64 r6, 47                                    r6 = 47 as i32 as i64 as u64
    ja lbb_26064                                    if true { pc += 41 }
lbb_26023:
    mov64 r6, 48                                    r6 = 48 as i32 as i64 as u64
    ja lbb_26064                                    if true { pc += 39 }
lbb_26025:
    mov64 r6, 6                                     r6 = 6 as i32 as i64 as u64
    ja lbb_26064                                    if true { pc += 37 }
lbb_26027:
    mov64 r6, 7                                     r6 = 7 as i32 as i64 as u64
    ja lbb_26064                                    if true { pc += 35 }
lbb_26029:
    mov64 r6, 34                                    r6 = 34 as i32 as i64 as u64
    ja lbb_26064                                    if true { pc += 33 }
lbb_26031:
    mov64 r6, 35                                    r6 = 35 as i32 as i64 as u64
    ja lbb_26064                                    if true { pc += 31 }
lbb_26033:
    mov64 r6, 43                                    r6 = 43 as i32 as i64 as u64
    ja lbb_26064                                    if true { pc += 29 }
lbb_26035:
    mov64 r6, 25                                    r6 = 25 as i32 as i64 as u64
    ja lbb_26064                                    if true { pc += 27 }
lbb_26037:
    mov64 r6, 32                                    r6 = 32 as i32 as i64 as u64
    ja lbb_26064                                    if true { pc += 25 }
lbb_26039:
    mov64 r6, 50                                    r6 = 50 as i32 as i64 as u64
    ja lbb_26064                                    if true { pc += 23 }
lbb_26041:
    mov64 r6, 3                                     r6 = 3 as i32 as i64 as u64
    ja lbb_26064                                    if true { pc += 21 }
lbb_26043:
    mov64 r6, 4                                     r6 = 4 as i32 as i64 as u64
    ja lbb_26064                                    if true { pc += 19 }
lbb_26045:
    mov64 r6, 16                                    r6 = 16 as i32 as i64 as u64
    ja lbb_26064                                    if true { pc += 17 }
lbb_26047:
    mov64 r6, 17                                    r6 = 17 as i32 as i64 as u64
    ja lbb_26064                                    if true { pc += 15 }
lbb_26049:
    mov64 r6, 23                                    r6 = 23 as i32 as i64 as u64
    ja lbb_26064                                    if true { pc += 13 }
lbb_26051:
    mov64 r6, 22                                    r6 = 22 as i32 as i64 as u64
    ja lbb_26064                                    if true { pc += 11 }
lbb_26053:
    mov64 r6, 37                                    r6 = 37 as i32 as i64 as u64
    ja lbb_26064                                    if true { pc += 9 }
lbb_26055:
    mov64 r6, 38                                    r6 = 38 as i32 as i64 as u64
    ja lbb_26064                                    if true { pc += 7 }
lbb_26057:
    mov64 r6, 45                                    r6 = 45 as i32 as i64 as u64
    ja lbb_26064                                    if true { pc += 5 }
lbb_26059:
    mov64 r6, 27                                    r6 = 27 as i32 as i64 as u64
    ja lbb_26064                                    if true { pc += 3 }
lbb_26061:
    mov64 r6, 33                                    r6 = 33 as i32 as i64 as u64
    ja lbb_26064                                    if true { pc += 1 }
lbb_26063:
    mov64 r6, 52                                    r6 = 52 as i32 as i64 as u64
lbb_26064:
    call function_21656                     
    mov64 r0, r6                                    r0 = r6
    exit                                    

function_26067:
    mov64 r7, r2                                    r7 = r2
    mov64 r6, r1                                    r6 = r1
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    stxdw [r10-0x58], r1                    
    lddw r1, 0x100065b60 --> b"\x00\x00\x00\x00<\x17\x06\x00\x0d\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00…        r1 load str located at 4295383904
    stxdw [r10-0x78], r1                    
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    stxdw [r10-0x70], r1                    
    stxdw [r10-0x60], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -136                                  r1 += -136   ///  r1 = r1.wrapping_add(-136 as i32 as i64 as u64)
    stxdw [r10-0x68], r1                    
    lddw r1, 0x10003b088 --> b"q\x13\x00\x00\x00\x00\x00\x00e\x03\x0d\x00\x1b\x00\x00\x00e\x03\x19\x00\x…        r1 load str located at 4295209096
    stxdw [r10-0x80], r1                    
    stxdw [r10-0x88], r7                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -160                                  r1 += -160   ///  r1 = r1.wrapping_add(-160 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -120                                  r2 += -120   ///  r2 = r2.wrapping_add(-120 as i32 as i64 as u64)
    call function_43415                     
    ldxdw r8, [r10-0x98]                    
    ldxdw r9, [r10-0xa0]                    
    ldxdw r2, [r10-0x90]                    
    mov64 r1, r9                                    r1 = r9
    syscall [invalid]                       
    jeq r8, 0, lbb_26099                            if r8 == (0 as i32 as i64 as u64) { pc += 4 }
    mov64 r1, r9                                    r1 = r9
    mov64 r2, r8                                    r2 = r8
    mov64 r3, 1                                     r3 = 1 as i32 as i64 as u64
    call function_21385                     
lbb_26099:
    ldxb r1, [r7+0x0]                       
    jeq r1, 55, lbb_26113                           if r1 == (55 as i32 as i64 as u64) { pc += 12 }
    mov64 r8, r10                                   r8 = r10
    add64 r8, -120                                  r8 += -120   ///  r8 = r8.wrapping_add(-120 as i32 as i64 as u64)
    mov64 r1, r8                                    r1 = r8
    mov64 r2, r7                                    r2 = r7
    mov64 r3, 72                                    r3 = 72 as i32 as i64 as u64
    call function_48190                     
    mov64 r1, r8                                    r1 = r8
    call function_25871                     
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    stxw [r6+0x0], r1                       
    stxw [r6+0x4], r0                       
    ja lbb_26121                                    if true { pc += 8 }
lbb_26113:
    ldxdw r1, [r7+0x20]                     
    stxdw [r6+0x18], r1                     
    ldxdw r1, [r7+0x18]                     
    stxdw [r6+0x10], r1                     
    ldxdw r1, [r7+0x10]                     
    stxdw [r6+0x8], r1                      
    ldxdw r1, [r7+0x8]                      
    stxdw [r6+0x0], r1                      
lbb_26121:
    exit                                    

function_26122:
    mov64 r8, r1                                    r8 = r1
    mov64 r1, r2                                    r1 = r2
    and64 r1, 1                                     r1 &= 1   ///  r1 = r1.and(1)
    mov64 r9, r2                                    r9 = r2
    rsh64 r9, 1                                     r9 >>= 1   ///  r9 = r9.wrapping_shr(1)
    add64 r9, r1                                    r9 += r1   ///  r9 = r9.wrapping_add(r1)
    jeq r9, 0, lbb_26152                            if r9 == (0 as i32 as i64 as u64) { pc += 23 }
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    mov64 r7, r2                                    r7 = r2
    add64 r7, -1                                    r7 += -1   ///  r7 = r7.wrapping_add(-1 as i32 as i64 as u64)
    mov64 r3, r9                                    r3 = r9
lbb_26133:
    jgt r7, r1, lbb_26139                           if r7 > r1 { pc += 5 }
lbb_26134:
    add64 r3, -1                                    r3 += -1   ///  r3 = r3.wrapping_add(-1 as i32 as i64 as u64)
    add64 r7, -2                                    r7 += -2   ///  r7 = r7.wrapping_add(-2 as i32 as i64 as u64)
    add64 r1, 2                                     r1 += 2   ///  r1 = r1.wrapping_add(2 as i32 as i64 as u64)
    jeq r3, 0, lbb_26152                            if r3 == (0 as i32 as i64 as u64) { pc += 14 }
    ja lbb_26133                                    if true { pc += -6 }
lbb_26139:
    jge r1, r2, lbb_26229                           if r1 >= r2 { pc += 89 }
    jgt r2, r7, lbb_26143                           if r2 > r7 { pc += 2 }
    mov64 r1, r7                                    r1 = r7
    ja lbb_26229                                    if true { pc += 86 }
lbb_26143:
    mov64 r4, r8                                    r4 = r8
    add64 r4, r7                                    r4 += r7   ///  r4 = r4.wrapping_add(r7)
    mov64 r5, r8                                    r5 = r8
    add64 r5, r1                                    r5 += r1   ///  r5 = r5.wrapping_add(r1)
    ldxb r0, [r5+0x0]                       
    ldxb r6, [r4+0x0]                       
    stxb [r5+0x0], r6                       
    stxb [r4+0x0], r0                       
    ja lbb_26134                                    if true { pc += -18 }
lbb_26152:
    stxdw [r10-0x30], r9                    
    stxdw [r10-0x28], r8                    
    stxdw [r10-0x20], r2                    
    jeq r2, 0, lbb_26174                            if r2 == (0 as i32 as i64 as u64) { pc += 18 }
    lddw r7, 0x1234567890abcdef                     r7 load str located at 1311768467294899695
    lddw r2, 0xfd74c63348a7c25f                     r2 load str located at -183303761250762145
    lddw r4, 0x14057b7ef767814f                     r4 load str located at 1442695040888963407
    ldxdw r9, [r10-0x20]                    
    ldxdw r8, [r10-0x28]                    
    ja lbb_26182                                    if true { pc += 17 }
lbb_26165:
    ldxdw r1, [r8+0x0]                      
    xor64 r1, r7                                    r1 ^= r7   ///  r1 = r1.xor(r7)
    stxdw [r8+0x0], r1                      
    mov64 r7, r1                                    r7 = r1
lbb_26169:
    add64 r8, r3                                    r8 += r3   ///  r8 = r8.wrapping_add(r3)
    sub64 r9, r3                                    r9 -= r3   ///  r9 = r9.wrapping_sub(r3)
    mul64 r7, r2                                    r7 *= r2   ///  r7 = r7.wrapping_mul(r2)
    add64 r7, r4                                    r7 += r4   ///  r7 = r7.wrapping_add(r4)
    jne r9, 0, lbb_26182                            if r9 != (0 as i32 as i64 as u64) { pc += 8 }
lbb_26174:
    ldxdw r2, [r10-0x20]                    
    ldxdw r7, [r10-0x28]                    
    ldxdw r8, [r10-0x30]                    
    jeq r8, 0, lbb_26228                            if r8 == (0 as i32 as i64 as u64) { pc += 50 }
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    mov64 r6, r2                                    r6 = r2
    add64 r6, -1                                    r6 += -1   ///  r6 = r6.wrapping_add(-1 as i32 as i64 as u64)
    ja lbb_26209                                    if true { pc += 27 }
lbb_26182:
    mov64 r1, 8                                     r1 = 8 as i32 as i64 as u64
    mov64 r3, r9                                    r3 = r9
    jgt r1, r9, lbb_26186                           if r1 > r9 { pc += 1 }
    mov64 r3, 8                                     r3 = 8 as i32 as i64 as u64
lbb_26186:
    jgt r9, 7, lbb_26165                            if r9 > (7 as i32 as i64 as u64) { pc += -22 }
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    stxdw [r10-0x8], r1                     
    mov64 r1, r10                                   r1 = r10
    add64 r1, -8                                    r1 += -8   ///  r1 = r1.wrapping_add(-8 as i32 as i64 as u64)
    stxdw [r10-0x18], r1                    
    mov64 r2, r8                                    r2 = r8
    stxdw [r10-0x10], r3                    
    call function_48190                     
    ldxdw r6, [r10-0x8]                     
    xor64 r6, r7                                    r6 ^= r7   ///  r6 = r6.xor(r7)
    stxdw [r10-0x8], r6                     
    mov64 r1, r8                                    r1 = r8
    ldxdw r2, [r10-0x18]                    
    ldxdw r3, [r10-0x10]                    
    call function_48190                     
    ldxdw r3, [r10-0x10]                    
    lddw r4, 0x14057b7ef767814f                     r4 load str located at 1442695040888963407
    lddw r2, 0xfd74c63348a7c25f                     r2 load str located at -183303761250762145
    mov64 r7, r6                                    r7 = r6
    ja lbb_26169                                    if true { pc += -40 }
lbb_26209:
    jgt r6, r1, lbb_26215                           if r6 > r1 { pc += 5 }
lbb_26210:
    add64 r8, -1                                    r8 += -1   ///  r8 = r8.wrapping_add(-1 as i32 as i64 as u64)
    add64 r6, -2                                    r6 += -2   ///  r6 = r6.wrapping_add(-2 as i32 as i64 as u64)
    add64 r1, 2                                     r1 += 2   ///  r1 = r1.wrapping_add(2 as i32 as i64 as u64)
    jeq r8, 0, lbb_26228                            if r8 == (0 as i32 as i64 as u64) { pc += 14 }
    ja lbb_26209                                    if true { pc += -6 }
lbb_26215:
    jge r1, r2, lbb_26229                           if r1 >= r2 { pc += 13 }
    jgt r2, r6, lbb_26219                           if r2 > r6 { pc += 2 }
    mov64 r1, r6                                    r1 = r6
    ja lbb_26229                                    if true { pc += 10 }
lbb_26219:
    mov64 r3, r7                                    r3 = r7
    add64 r3, r6                                    r3 += r6   ///  r3 = r3.wrapping_add(r6)
    mov64 r4, r7                                    r4 = r7
    add64 r4, r1                                    r4 += r1   ///  r4 = r4.wrapping_add(r1)
    ldxb r5, [r4+0x0]                       
    ldxb r0, [r3+0x0]                       
    stxb [r4+0x0], r0                       
    stxb [r3+0x0], r5                       
    ja lbb_26210                                    if true { pc += -18 }
lbb_26228:
    exit                                    
lbb_26229:
    lddw r3, 0x100065b70 --> b"\x00\x00\x00\x00I\x17\x06\x00\x1c\x00\x00\x00\x00\x00\x00\x00M\x00\x00\x0…        r3 load str located at 4295383920
    call function_44272                     
    syscall [invalid]                       

function_26233:
    mov64 r8, r1                                    r8 = r1
    mov64 r1, r2                                    r1 = r2
    and64 r1, 1                                     r1 &= 1   ///  r1 = r1.and(1)
    mov64 r9, r2                                    r9 = r2
    rsh64 r9, 1                                     r9 >>= 1   ///  r9 = r9.wrapping_shr(1)
    add64 r9, r1                                    r9 += r1   ///  r9 = r9.wrapping_add(r1)
    jeq r9, 0, lbb_26263                            if r9 == (0 as i32 as i64 as u64) { pc += 23 }
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    mov64 r7, r2                                    r7 = r2
    add64 r7, -1                                    r7 += -1   ///  r7 = r7.wrapping_add(-1 as i32 as i64 as u64)
    mov64 r3, r9                                    r3 = r9
lbb_26244:
    jgt r7, r1, lbb_26250                           if r7 > r1 { pc += 5 }
lbb_26245:
    add64 r3, -1                                    r3 += -1   ///  r3 = r3.wrapping_add(-1 as i32 as i64 as u64)
    add64 r7, -2                                    r7 += -2   ///  r7 = r7.wrapping_add(-2 as i32 as i64 as u64)
    add64 r1, 2                                     r1 += 2   ///  r1 = r1.wrapping_add(2 as i32 as i64 as u64)
    jeq r3, 0, lbb_26263                            if r3 == (0 as i32 as i64 as u64) { pc += 14 }
    ja lbb_26244                                    if true { pc += -6 }
lbb_26250:
    jge r1, r2, lbb_26341                           if r1 >= r2 { pc += 90 }
    jgt r2, r7, lbb_26254                           if r2 > r7 { pc += 2 }
    mov64 r1, r7                                    r1 = r7
    ja lbb_26341                                    if true { pc += 87 }
lbb_26254:
    mov64 r4, r8                                    r4 = r8
    add64 r4, r7                                    r4 += r7   ///  r4 = r4.wrapping_add(r7)
    mov64 r5, r8                                    r5 = r8
    add64 r5, r1                                    r5 += r1   ///  r5 = r5.wrapping_add(r1)
    ldxb r0, [r5+0x0]                       
    ldxb r6, [r4+0x0]                       
    stxb [r5+0x0], r6                       
    stxb [r4+0x0], r0                       
    ja lbb_26245                                    if true { pc += -18 }
lbb_26263:
    stxdw [r10-0x30], r9                    
    stxdw [r10-0x28], r8                    
    stxdw [r10-0x20], r2                    
    jeq r2, 0, lbb_26286                            if r2 == (0 as i32 as i64 as u64) { pc += 19 }
    lddw r7, 0x1234567890abcdef                     r7 load str located at 1311768467294899695
    lddw r3, 0xfd74c63348a7c25f                     r3 load str located at -183303761250762145
    lddw r4, 0x14057b7ef767814f                     r4 load str located at 1442695040888963407
    ldxdw r9, [r10-0x20]                    
    ldxdw r8, [r10-0x28]                    
    ja lbb_26294                                    if true { pc += 18 }
lbb_26276:
    ldxdw r1, [r8+0x0]                      
    mov64 r2, r1                                    r2 = r1
    xor64 r2, r7                                    r2 ^= r7   ///  r2 = r2.xor(r7)
    stxdw [r8+0x0], r2                      
    mov64 r7, r1                                    r7 = r1
lbb_26281:
    add64 r8, r6                                    r8 += r6   ///  r8 = r8.wrapping_add(r6)
    sub64 r9, r6                                    r9 -= r6   ///  r9 = r9.wrapping_sub(r6)
    mul64 r7, r3                                    r7 *= r3   ///  r7 = r7.wrapping_mul(r3)
    add64 r7, r4                                    r7 += r4   ///  r7 = r7.wrapping_add(r4)
    jne r9, 0, lbb_26294                            if r9 != (0 as i32 as i64 as u64) { pc += 8 }
lbb_26286:
    ldxdw r2, [r10-0x20]                    
    ldxdw r7, [r10-0x28]                    
    ldxdw r8, [r10-0x30]                    
    jeq r8, 0, lbb_26340                            if r8 == (0 as i32 as i64 as u64) { pc += 50 }
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    mov64 r6, r2                                    r6 = r2
    add64 r6, -1                                    r6 += -1   ///  r6 = r6.wrapping_add(-1 as i32 as i64 as u64)
    ja lbb_26321                                    if true { pc += 27 }
lbb_26294:
    mov64 r1, 8                                     r1 = 8 as i32 as i64 as u64
    mov64 r6, r9                                    r6 = r9
    jgt r1, r9, lbb_26298                           if r1 > r9 { pc += 1 }
    mov64 r6, 8                                     r6 = 8 as i32 as i64 as u64
lbb_26298:
    jgt r9, 7, lbb_26276                            if r9 > (7 as i32 as i64 as u64) { pc += -23 }
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    stxdw [r10-0x8], r1                     
    mov64 r1, r10                                   r1 = r10
    add64 r1, -8                                    r1 += -8   ///  r1 = r1.wrapping_add(-8 as i32 as i64 as u64)
    stxdw [r10-0x10], r1                    
    mov64 r2, r8                                    r2 = r8
    mov64 r3, r6                                    r3 = r6
    call function_48190                     
    ldxdw r1, [r10-0x8]                     
    stxdw [r10-0x18], r1                    
    xor64 r1, r7                                    r1 ^= r7   ///  r1 = r1.xor(r7)
    stxdw [r10-0x8], r1                     
    mov64 r1, r8                                    r1 = r8
    ldxdw r2, [r10-0x10]                    
    mov64 r3, r6                                    r3 = r6
    call function_48190                     
    lddw r4, 0x14057b7ef767814f                     r4 load str located at 1442695040888963407
    lddw r3, 0xfd74c63348a7c25f                     r3 load str located at -183303761250762145
    ldxdw r7, [r10-0x18]                    
    ja lbb_26281                                    if true { pc += -40 }
lbb_26321:
    jgt r6, r1, lbb_26327                           if r6 > r1 { pc += 5 }
lbb_26322:
    add64 r8, -1                                    r8 += -1   ///  r8 = r8.wrapping_add(-1 as i32 as i64 as u64)
    add64 r6, -2                                    r6 += -2   ///  r6 = r6.wrapping_add(-2 as i32 as i64 as u64)
    add64 r1, 2                                     r1 += 2   ///  r1 = r1.wrapping_add(2 as i32 as i64 as u64)
    jeq r8, 0, lbb_26340                            if r8 == (0 as i32 as i64 as u64) { pc += 14 }
    ja lbb_26321                                    if true { pc += -6 }
lbb_26327:
    jge r1, r2, lbb_26341                           if r1 >= r2 { pc += 13 }
    jgt r2, r6, lbb_26331                           if r2 > r6 { pc += 2 }
    mov64 r1, r6                                    r1 = r6
    ja lbb_26341                                    if true { pc += 10 }
lbb_26331:
    mov64 r3, r7                                    r3 = r7
    add64 r3, r6                                    r3 += r6   ///  r3 = r3.wrapping_add(r6)
    mov64 r4, r7                                    r4 = r7
    add64 r4, r1                                    r4 += r1   ///  r4 = r4.wrapping_add(r1)
    ldxb r5, [r4+0x0]                       
    ldxb r0, [r3+0x0]                       
    stxb [r4+0x0], r0                       
    stxb [r3+0x0], r5                       
    ja lbb_26322                                    if true { pc += -18 }
lbb_26340:
    exit                                    
lbb_26341:
    lddw r3, 0x100065b70 --> b"\x00\x00\x00\x00I\x17\x06\x00\x1c\x00\x00\x00\x00\x00\x00\x00M\x00\x00\x0…        r3 load str located at 4295383920
    call function_44272                     
    syscall [invalid]                       

function_26345:
    mov64 r7, r2                                    r7 = r2
    stxdw [r10-0xd8], r1                    
    ldxw r1, [r7+0x28]                      
    ldxw r2, [r7+0x2c]                      
    or64 r2, r1                                     r2 |= r1   ///  r2 = r2.or(r1)
    ldxw r1, [r7+0x24]                      
    or64 r2, r1                                     r2 |= r1   ///  r2 = r2.or(r1)
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    lsh64 r2, 32                                    r2 <<= 32   ///  r2 = r2.wrapping_shl(32)
    rsh64 r2, 32                                    r2 >>= 32   ///  r2 = r2.wrapping_shr(32)
    jeq r2, 0, lbb_26511                            if r2 == (0 as i32 as i64 as u64) { pc += 155 }
    ldxdw r9, [r7+0x40]                     
    jgt r9, 31, lbb_26511                           if r9 > (31 as i32 as i64 as u64) { pc += 153 }
    mov64 r1, r10                                   r1 = r10
    add64 r1, -184                                  r1 += -184   ///  r1 = r1.wrapping_add(-184 as i32 as i64 as u64)
    stxdw [r10-0xd0], r1                    
    mov64 r1, r7                                    r1 = r7
    add64 r1, 16                                    r1 += 16   ///  r1 = r1.wrapping_add(16 as i32 as i64 as u64)
    stxdw [r10-0xc8], r1                    
    mov64 r6, 32                                    r6 = 32 as i32 as i64 as u64
lbb_26365:
    ldxb r4, [r7+0x50]                      
    ldxdw r3, [r7+0x8]                      
    ldxdw r2, [r7+0x0]                      
    ldxdw r1, [r7+0x48]                     
    stxdw [r10-0x1000], r9                  
    stxdw [r10-0xff8], r1                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -188                                  r1 += -188   ///  r1 = r1.wrapping_add(-188 as i32 as i64 as u64)
    mov64 r5, r10                                   r5 = r10
    call function_29645                     
    ldxw r1, [r10-0xbc]                     
    jeq r1, 0, lbb_26382                            if r1 == (0 as i32 as i64 as u64) { pc += 5 }
    jeq r1, 2, lbb_26506                            if r1 == (2 as i32 as i64 as u64) { pc += 128 }
lbb_26378:
    mov64 r1, 32                                    r1 = 32 as i32 as i64 as u64
    stxdw [r7+0x40], r1                     
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    ja lbb_26511                                    if true { pc += 129 }
lbb_26382:
    ldxdw r2, [r10-0xd0]                    
    ldxdw r1, [r2+0x18]                     
    stxdw [r10-0x80], r1                    
    ldxdw r1, [r2+0x10]                     
    stxdw [r10-0x88], r1                    
    ldxdw r1, [r2+0x8]                      
    stxdw [r10-0x90], r1                    
    ldxdw r1, [r2+0x0]                      
    stxdw [r10-0x98], r1                    
    ldxdw r1, [r10-0xc8]                    
    ldxw r1, [r1+0x0]                       
    lsh64 r1, 32                                    r1 <<= 32   ///  r1 = r1.wrapping_shl(32)
    arsh64 r1, 32                                   r1 >>= 32 (signed)   ///  r1 = (r1 as i64).wrapping_shr(32)
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
    jsgt r2, r1, lbb_26438                          if (r2 as i64) > (r1 as i64) { pc += 41 }
    ldxw r1, [r7+0x18]                      
    ldxw r2, [r7+0x1c]                      
    or64 r2, r1                                     r2 |= r1   ///  r2 = r2.or(r1)
    ldxw r1, [r7+0x14]                      
    or64 r2, r1                                     r2 |= r1   ///  r2 = r2.or(r1)
    lsh64 r2, 32                                    r2 <<= 32   ///  r2 = r2.wrapping_shl(32)
    rsh64 r2, 32                                    r2 >>= 32   ///  r2 = r2.wrapping_shr(32)
    jeq r2, 0, lbb_26438                            if r2 == (0 as i32 as i64 as u64) { pc += 33 }
    ldxdw r8, [r10-0xc8]                    
    ldxdw r1, [r8+0x8]                      
    stxdw [r10-0x28], r1                    
    ldxdw r1, [r8+0x0]                      
    stxdw [r10-0x30], r1                    
    mov64 r6, r10                                   r6 = r10
    add64 r6, -120                                  r6 += -120   ///  r6 = r6.wrapping_add(-120 as i32 as i64 as u64)
    mov64 r3, r10                                   r3 = r10
    add64 r3, -48                                   r3 += -48   ///  r3 = r3.wrapping_add(-48 as i32 as i64 as u64)
    mov64 r1, r6                                    r1 = r6
    ldxdw r2, [r10-0xd0]                    
    call function_33551                     
    ldxdw r1, [r10-0x70]                    
    stxdw [r10-0x28], r1                    
    ldxdw r1, [r10-0x78]                    
    stxdw [r10-0x30], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -152                                  r1 += -152   ///  r1 = r1.wrapping_add(-152 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -48                                   r2 += -48   ///  r2 = r2.wrapping_add(-48 as i32 as i64 as u64)
    call function_33921                     
    mov64 r1, r8                                    r1 = r8
    mov64 r2, r6                                    r2 = r6
    mov64 r6, 32                                    r6 = 32 as i32 as i64 as u64
    call function_33921                     
    ldxw r1, [r10-0x90]                     
    ldxw r2, [r10-0x8c]                     
    or64 r2, r1                                     r2 |= r1   ///  r2 = r2.or(r1)
    ldxw r1, [r10-0x94]                     
    or64 r2, r1                                     r2 |= r1   ///  r2 = r2.or(r1)
    lsh64 r2, 32                                    r2 <<= 32   ///  r2 = r2.wrapping_shl(32)
    rsh64 r2, 32                                    r2 >>= 32   ///  r2 = r2.wrapping_shr(32)
    jeq r2, 0, lbb_26506                            if r2 == (0 as i32 as i64 as u64) { pc += 68 }
lbb_26438:
    ldxdw r1, [r10-0x90]                    
    stxdw [r10-0x40], r1                    
    ldxdw r1, [r10-0x98]                    
    stxdw [r10-0x48], r1                    
    ldxdw r1, [r7+0x28]                     
    stxdw [r10-0x28], r1                    
    ldxdw r1, [r7+0x20]                     
    stxdw [r10-0x30], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -88                                   r1 += -88   ///  r1 = r1.wrapping_add(-88 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -72                                   r2 += -72   ///  r2 = r2.wrapping_add(-72 as i32 as i64 as u64)
    mov64 r3, r10                                   r3 = r10
    add64 r3, -48                                   r3 += -48   ///  r3 = r3.wrapping_add(-48 as i32 as i64 as u64)
    call function_33551                     
    ldxdw r1, [r10-0x58]                    
    stxdw [r10-0x98], r1                    
    ldxdw r1, [r10-0x50]                    
    stxdw [r10-0x90], r1                    
    ldxw r1, [r10-0x98]                     
    lsh64 r1, 32                                    r1 <<= 32   ///  r1 = r1.wrapping_shl(32)
    arsh64 r1, 32                                   r1 >>= 32 (signed)   ///  r1 = (r1 as i64).wrapping_shr(32)
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
    jsgt r2, r1, lbb_26378                          if (r2 as i64) > (r1 as i64) { pc += -84 }
    ldxw r1, [r10-0x90]                     
    ldxw r2, [r10-0x8c]                     
    or64 r2, r1                                     r2 |= r1   ///  r2 = r2.or(r1)
    ldxw r1, [r10-0x94]                     
    or64 r2, r1                                     r2 |= r1   ///  r2 = r2.or(r1)
    lsh64 r2, 32                                    r2 <<= 32   ///  r2 = r2.wrapping_shl(32)
    rsh64 r2, 32                                    r2 >>= 32   ///  r2 = r2.wrapping_shr(32)
    jeq r2, 0, lbb_26378                            if r2 == (0 as i32 as i64 as u64) { pc += -92 }
    ldxb r1, [r7+0x50]                      
    ldxdw r2, [r7+0x38]                     
    stxdw [r10-0x60], r2                    
    ldxdw r2, [r7+0x30]                     
    stxdw [r10-0x68], r2                    
    ldxdw r2, [r10-0x80]                    
    stxdw [r10-0x50], r2                    
    ldxdw r2, [r10-0x88]                    
    stxdw [r10-0x58], r2                    
    jne r1, 0, lbb_26514                            if r1 != (0 as i32 as i64 as u64) { pc += 34 }
    mov64 r1, r10                                   r1 = r10
    add64 r1, -72                                   r1 += -72   ///  r1 = r1.wrapping_add(-72 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -104                                  r2 += -104   ///  r2 = r2.wrapping_add(-104 as i32 as i64 as u64)
    mov64 r3, r10                                   r3 = r10
    add64 r3, -88                                   r3 += -88   ///  r3 = r3.wrapping_add(-88 as i32 as i64 as u64)
    call function_34122                     
    ldxw r1, [r10-0x48]                     
    jeq r1, 0, lbb_26540                            if r1 == (0 as i32 as i64 as u64) { pc += 51 }
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    stxdw [r10-0x28], r1                    
    lddw r1, 0x1000657b8 --> b"\x00\x00\x00\x00+\x0f\x06\x00\x16\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00…        r1 load str located at 4295382968
    stxdw [r10-0x30], r1                    
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    stxdw [r10-0x10], r1                    
    stxdw [r10-0x18], r1                    
    lddw r1, 0x100060ee8 --> b"src/arithmetic_impls.rsAddition overflowedMultipli"        r1 load str located at 4295364328
    stxdw [r10-0x20], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -48                                   r1 += -48   ///  r1 = r1.wrapping_add(-48 as i32 as i64 as u64)
    lddw r2, 0x1000657c8 --> b"\x00\x00\x00\x00\xe8\x0e\x06\x00\x17\x00\x00\x00\x00\x00\x00\x00\x03\x01\…        r2 load str located at 4295382984
    call function_44240                     
    syscall [invalid]                       
lbb_26506:
    ldxdw r9, [r7+0x40]                     
    add64 r9, 1                                     r9 += 1   ///  r9 = r9.wrapping_add(1 as i32 as i64 as u64)
    stxdw [r7+0x40], r9                     
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    jgt r6, r9, lbb_26365                           if r6 > r9 { pc += -146 }
lbb_26511:
    ldxdw r2, [r10-0xd8]                    
    stxdw [r2+0x0], r1                      
    exit                                    
lbb_26514:
    mov64 r1, r10                                   r1 = r10
    add64 r1, -72                                   r1 += -72   ///  r1 = r1.wrapping_add(-72 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -104                                  r2 += -104   ///  r2 = r2.wrapping_add(-104 as i32 as i64 as u64)
    mov64 r3, r10                                   r3 = r10
    add64 r3, -88                                   r3 += -88   ///  r3 = r3.wrapping_add(-88 as i32 as i64 as u64)
    call function_34119                     
    ldxw r1, [r10-0x48]                     
    jeq r1, 0, lbb_26540                            if r1 == (0 as i32 as i64 as u64) { pc += 17 }
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    stxdw [r10-0x28], r1                    
    lddw r1, 0x100065768 --> b"\x00\x00\x00\x00\xff\x0e\x06\x00\x13\x00\x00\x00\x00\x00\x00\x00\x00\x00\…        r1 load str located at 4295382888
    stxdw [r10-0x30], r1                    
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    stxdw [r10-0x10], r1                    
    stxdw [r10-0x18], r1                    
    lddw r1, 0x100060ee8 --> b"src/arithmetic_impls.rsAddition overflowedMultipli"        r1 load str located at 4295364328
    stxdw [r10-0x20], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -48                                   r1 += -48   ///  r1 = r1.wrapping_add(-48 as i32 as i64 as u64)
    lddw r2, 0x100065778 --> b"\x00\x00\x00\x00\xe8\x0e\x06\x00\x17\x00\x00\x00\x00\x00\x00\x00\xa1\x00\…        r2 load str located at 4295382904
    call function_44240                     
    syscall [invalid]                       
lbb_26540:
    ldxw r3, [r10-0x38]                     
    ldxw r4, [r10-0x3c]                     
    ldxw r6, [r10-0x40]                     
    ldxw r8, [r10-0x44]                     
    mov64 r1, r8                                    r1 = r8
    lsh64 r1, 32                                    r1 <<= 32   ///  r1 = r1.wrapping_shl(32)
    arsh64 r1, 32                                   r1 >>= 32 (signed)   ///  r1 = (r1 as i64).wrapping_shr(32)
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
    jsgt r2, r1, lbb_26378                          if (r2 as i64) > (r1 as i64) { pc += -171 }
    mov64 r1, r4                                    r1 = r4
    or64 r1, r3                                     r1 |= r3   ///  r1 = r1.or(r3)
    or64 r1, r6                                     r1 |= r6   ///  r1 = r1.or(r6)
    lsh64 r1, 32                                    r1 <<= 32   ///  r1 = r1.wrapping_shl(32)
    rsh64 r1, 32                                    r1 >>= 32   ///  r1 = r1.wrapping_shr(32)
    jeq r1, 0, lbb_26378                            if r1 == (0 as i32 as i64 as u64) { pc += -177 }
    mov64 r1, r7                                    r1 = r7
    add64 r1, 32                                    r1 += 32   ///  r1 = r1.wrapping_add(32 as i32 as i64 as u64)
    ldxdw r2, [r10-0x90]                    
    stxdw [r10-0x28], r2                    
    ldxdw r2, [r10-0x98]                    
    stxdw [r10-0x30], r2                    
    mov64 r2, r10                                   r2 = r10
    add64 r2, -48                                   r2 += -48   ///  r2 = r2.wrapping_add(-48 as i32 as i64 as u64)
    stxdw [r10-0xd0], r3                    
    stxdw [r10-0xc8], r4                    
    call function_33921                     
    ldxdw r1, [r10-0x90]                    
    ldxdw r2, [r10-0xd8]                    
    stxdw [r2+0x10], r1                     
    ldxdw r1, [r10-0x98]                    
    stxdw [r2+0x8], r1                      
    ldxdw r1, [r7+0x40]                     
    add64 r1, 1                                     r1 += 1   ///  r1 = r1.wrapping_add(1 as i32 as i64 as u64)
    stxdw [r7+0x40], r1                     
    stxdw [r2+0x28], r9                     
    ldxdw r1, [r10-0xd0]                    
    stxw [r2+0x24], r1                      
    ldxdw r1, [r10-0xc8]                    
    stxw [r2+0x20], r1                      
    stxw [r2+0x1c], r6                      
    stxw [r2+0x18], r8                      
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    ja lbb_26511                                    if true { pc += -72 }

function_26583:
    mov64 r6, r5                                    r6 = r5
    mov64 r8, r4                                    r8 = r4
    mov64 r9, r3                                    r9 = r3
    mov64 r7, r2                                    r7 = r2
    stxdw [r10-0x1d0], r1                   
    mov64 r1, 4                                     r1 = 4 as i32 as i64 as u64
    stxdw [r10-0x1b8], r1                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -432                                  r1 += -432   ///  r1 = r1.wrapping_add(-432 as i32 as i64 as u64)
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
    mov64 r3, 48                                    r3 = 48 as i32 as i64 as u64
    call function_48291                     
    ldxdw r3, [r9+0x18]                     
    mov64 r1, r10                                   r1 = r10
    add64 r1, -88                                   r1 += -88   ///  r1 = r1.wrapping_add(-88 as i32 as i64 as u64)
    stxdw [r10-0x1e0], r7                   
    mov64 r2, r7                                    r2 = r7
    stxdw [r10-0x1c8], r3                   
    callx r3                                
    ldxdw r1, [r10-0x58]                    
    jne r1, 0, lbb_26614                            if r1 != (0 as i32 as i64 as u64) { pc += 10 }
    mov64 r7, 33                                    r7 = 33 as i32 as i64 as u64
    mov64 r1, 33                                    r1 = 33 as i32 as i64 as u64
    mov64 r2, 1                                     r2 = 1 as i32 as i64 as u64
    call function_21359                     
    mov64 r6, r0                                    r6 = r0
    jne r6, 0, lbb_27162                            if r6 != (0 as i32 as i64 as u64) { pc += 552 }
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    mov64 r2, 33                                    r2 = 33 as i32 as i64 as u64
    call function_43400                     
    syscall [invalid]                       
lbb_26614:
    ldxdw r9, [r6-0xff0]                    
    ldxdw r7, [r6-0xff8]                    
    ldxdw r1, [r6-0x1000]                   
    ldxdw r2, [r10-0x38]                    
    stxdw [r10-0x118], r2                   
    ldxdw r2, [r10-0x30]                    
    stxdw [r10-0x110], r2                   
    ldxdw r2, [r10-0x40]                    
    stxdw [r10-0x120], r2                   
    ldxdw r2, [r10-0x48]                    
    stxdw [r10-0x128], r2                   
    ldxdw r2, [r10-0x50]                    
    stxdw [r10-0x130], r2                   
    ldxdw r6, [r1+0x18]                     
    mov64 r1, r10                                   r1 = r10
    add64 r1, -88                                   r1 += -88   ///  r1 = r1.wrapping_add(-88 as i32 as i64 as u64)
    mov64 r2, r8                                    r2 = r8
    callx r6                                
    ldxdw r1, [r10-0x58]                    
    stxdw [r10-0x1e8], r8                   
    jeq r1, 0, lbb_27167                            if r1 == (0 as i32 as i64 as u64) { pc += 532 }
    mov64 r2, r9                                    r2 = r9
    ldxdw r1, [r10-0x1d0]                   
    ldxdw r1, [r10-0x38]                    
    stxdw [r10-0xf0], r1                    
    ldxdw r1, [r10-0x30]                    
    stxdw [r10-0xe8], r1                    
    ldxdw r1, [r10-0x40]                    
    stxdw [r10-0xf8], r1                    
    ldxdw r1, [r10-0x48]                    
    stxdw [r10-0x100], r1                   
    ldxdw r1, [r10-0x50]                    
    stxdw [r10-0x108], r1                   
    mov64 r8, 0                                     r8 = 0 as i32 as i64 as u64
    stxb [r10-0x180], r8                    
    ldxw r1, [r7+0x0]                       
    lsh64 r1, 32                                    r1 <<= 32   ///  r1 = r1.wrapping_shl(32)
    arsh64 r1, 32                                   r1 >>= 32 (signed)   ///  r1 = (r1 as i64).wrapping_shr(32)
    jsgt r8, r1, lbb_27199                          if (r8 as i64) > (r1 as i64) { pc += 546 }
    mov64 r4, r10                                   r4 = r10
    add64 r4, -400                                  r4 += -400   ///  r4 = r4.wrapping_add(-400 as i32 as i64 as u64)
    mov64 r1, r10                                   r1 = r10
    add64 r1, -416                                  r1 += -416   ///  r1 = r1.wrapping_add(-416 as i32 as i64 as u64)
    stxdw [r10-0x238], r1                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -288                                  r1 += -288   ///  r1 = r1.wrapping_add(-288 as i32 as i64 as u64)
    stxdw [r10-0x220], r1                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -248                                  r1 += -248   ///  r1 = r1.wrapping_add(-248 as i32 as i64 as u64)
    stxdw [r10-0x228], r1                   
    mov64 r9, 0                                     r9 = 0 as i32 as i64 as u64
    mov64 r1, 4                                     r1 = 4 as i32 as i64 as u64
    stxdw [r10-0x218], r1                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -109                                  r1 += -109   ///  r1 = r1.wrapping_add(-109 as i32 as i64 as u64)
    stxdw [r10-0x200], r1                   
    mov64 r5, r10                                   r5 = r10
    add64 r5, -84                                   r5 += -84   ///  r5 = r5.wrapping_add(-84 as i32 as i64 as u64)
    mov64 r1, r10                                   r1 = r10
    add64 r1, -80                                   r1 += -80   ///  r1 = r1.wrapping_add(-80 as i32 as i64 as u64)
    stxdw [r10-0x1d8], r1                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -80                                   r1 += -80   ///  r1 = r1.wrapping_add(-80 as i32 as i64 as u64)
    stxdw [r10-0x1c0], r1                   
    ldxw r1, [r2+0x0]                       
    add64 r2, 4                                     r2 += 4   ///  r2 = r2.wrapping_add(4 as i32 as i64 as u64)
    stxdw [r10-0x240], r2                   
    stxdw [r10-0x230], r1                   
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    stxdw [r10-0x210], r1                   
    stxdw [r10-0x208], r7                   
    stxdw [r10-0x1f8], r4                   
    stxdw [r10-0x1f0], r5                   
lbb_26687:
    ldxw r1, [r7+0x8]                       
    ldxw r2, [r7+0xc]                       
    or64 r2, r1                                     r2 |= r1   ///  r2 = r2.or(r1)
    ldxw r1, [r7+0x4]                       
    or64 r2, r1                                     r2 |= r1   ///  r2 = r2.or(r1)
    lsh64 r2, 32                                    r2 <<= 32   ///  r2 = r2.wrapping_shl(32)
    rsh64 r2, 32                                    r2 >>= 32   ///  r2 = r2.wrapping_shr(32)
    mov64 r8, 0                                     r8 = 0 as i32 as i64 as u64
    jeq r2, 0, lbb_27199                            if r2 == (0 as i32 as i64 as u64) { pc += 503 }
    ldxdw r8, [r10-0x1e0]                   
    ldxdw r7, [r10-0x1e8]                   
lbb_26698:
    ldxw r1, [r10-0x108]                    
    lsh64 r1, 32                                    r1 <<= 32   ///  r1 = r1.wrapping_shl(32)
    arsh64 r1, 32                                   r1 >>= 32 (signed)   ///  r1 = (r1 as i64).wrapping_shr(32)
    jsgt r9, r1, lbb_26718                          if (r9 as i64) > (r1 as i64) { pc += 16 }
    ldxw r1, [r10-0x100]                    
    ldxw r2, [r10-0xfc]                     
    or64 r2, r1                                     r2 |= r1   ///  r2 = r2.or(r1)
    ldxw r1, [r10-0x104]                    
    or64 r2, r1                                     r2 |= r1   ///  r2 = r2.or(r1)
    lsh64 r2, 32                                    r2 <<= 32   ///  r2 = r2.wrapping_shl(32)
    rsh64 r2, 32                                    r2 >>= 32   ///  r2 = r2.wrapping_shr(32)
    jeq r2, 0, lbb_26718                            if r2 == (0 as i32 as i64 as u64) { pc += 8 }
    mov64 r1, r10                                   r1 = r10
    add64 r1, -264                                  r1 += -264   ///  r1 = r1.wrapping_add(-264 as i32 as i64 as u64)
    lddw r2, 0x10005fdd8 --> b"\x00\x00\x06\x00\x00\x00\x00\x00\x01\x00\x00\x00\x00\x00\x00\x00, coin_de…        r2 load str located at 4295359960
    call function_33952                     
    and64 r0, 255                                   r0 &= 255   ///  r0 = r0.and(255)
    mov64 r1, 2                                     r1 = 2 as i32 as i64 as u64
    jgt r1, r0, lbb_26730                           if r1 > r0 { pc += 12 }
lbb_26718:
    mov64 r1, r10                                   r1 = r10
    add64 r1, -88                                   r1 += -88   ///  r1 = r1.wrapping_add(-88 as i32 as i64 as u64)
    mov64 r2, r7                                    r2 = r7
    callx r6                                
    ldxdw r1, [r10-0x58]                    
    jeq r1, 0, lbb_27198                            if r1 == (0 as i32 as i64 as u64) { pc += 474 }
    mov64 r1, r10                                   r1 = r10
    add64 r1, -264                                  r1 += -264   ///  r1 = r1.wrapping_add(-264 as i32 as i64 as u64)
    ldxdw r2, [r10-0x1c0]                   
    mov64 r3, 40                                    r3 = 40 as i32 as i64 as u64
    call function_48190                     
    ja lbb_26698                                    if true { pc += -32 }
lbb_26730:
    ldxdw r1, [r10-0x1f8]                   
    ldxdw r7, [r10-0x1f0]                   
lbb_26732:
    ldxw r1, [r10-0x130]                    
    lsh64 r1, 32                                    r1 <<= 32   ///  r1 = r1.wrapping_shl(32)
    arsh64 r1, 32                                   r1 >>= 32 (signed)   ///  r1 = (r1 as i64).wrapping_shr(32)
    jsgt r9, r1, lbb_26752                          if (r9 as i64) > (r1 as i64) { pc += 16 }
    ldxw r1, [r10-0x128]                    
    ldxw r2, [r10-0x124]                    
    or64 r2, r1                                     r2 |= r1   ///  r2 = r2.or(r1)
    ldxw r1, [r10-0x12c]                    
    or64 r2, r1                                     r2 |= r1   ///  r2 = r2.or(r1)
    lsh64 r2, 32                                    r2 <<= 32   ///  r2 = r2.wrapping_shl(32)
    rsh64 r2, 32                                    r2 >>= 32   ///  r2 = r2.wrapping_shr(32)
    jeq r2, 0, lbb_26752                            if r2 == (0 as i32 as i64 as u64) { pc += 8 }
    mov64 r1, r10                                   r1 = r10
    add64 r1, -304                                  r1 += -304   ///  r1 = r1.wrapping_add(-304 as i32 as i64 as u64)
    lddw r2, 0x10005fdd8 --> b"\x00\x00\x06\x00\x00\x00\x00\x00\x01\x00\x00\x00\x00\x00\x00\x00, coin_de…        r2 load str located at 4295359960
    call function_33952                     
    and64 r0, 255                                   r0 &= 255   ///  r0 = r0.and(255)
    mov64 r1, 2                                     r1 = 2 as i32 as i64 as u64
    jgt r1, r0, lbb_26765                           if r1 > r0 { pc += 13 }
lbb_26752:
    mov64 r1, r10                                   r1 = r10
    add64 r1, -88                                   r1 += -88   ///  r1 = r1.wrapping_add(-88 as i32 as i64 as u64)
    mov64 r2, r8                                    r2 = r8
    ldxdw r3, [r10-0x1c8]                   
    callx r3                                
    ldxdw r1, [r10-0x58]                    
    jeq r1, 0, lbb_27198                            if r1 == (0 as i32 as i64 as u64) { pc += 439 }
    mov64 r1, r10                                   r1 = r10
    add64 r1, -304                                  r1 += -304   ///  r1 = r1.wrapping_add(-304 as i32 as i64 as u64)
    ldxdw r2, [r10-0x1d8]                   
    mov64 r3, 40                                    r3 = 40 as i32 as i64 as u64
    call function_48190                     
    ja lbb_26732                                    if true { pc += -33 }
lbb_26765:
    mov64 r8, 1                                     r8 = 1 as i32 as i64 as u64
    ldxw r1, [r10-0x130]                    
    lsh64 r1, 32                                    r1 <<= 32   ///  r1 = r1.wrapping_shl(32)
    arsh64 r1, 32                                   r1 >>= 32 (signed)   ///  r1 = (r1 as i64).wrapping_shr(32)
    jsgt r9, r1, lbb_27199                          if (r9 as i64) > (r1 as i64) { pc += 429 }
    ldxw r1, [r10-0x128]                    
    ldxw r2, [r10-0x124]                    
    or64 r2, r1                                     r2 |= r1   ///  r2 = r2.or(r1)
    ldxw r1, [r10-0x12c]                    
    or64 r2, r1                                     r2 |= r1   ///  r2 = r2.or(r1)
    lsh64 r2, 32                                    r2 <<= 32   ///  r2 = r2.wrapping_shl(32)
    rsh64 r2, 32                                    r2 >>= 32   ///  r2 = r2.wrapping_shr(32)
    jeq r2, 0, lbb_27199                            if r2 == (0 as i32 as i64 as u64) { pc += 421 }
    ldxw r1, [r10-0x120]                    
    lsh64 r1, 32                                    r1 <<= 32   ///  r1 = r1.wrapping_shl(32)
    arsh64 r1, 32                                   r1 >>= 32 (signed)   ///  r1 = (r1 as i64).wrapping_shr(32)
    jsgt r9, r1, lbb_27199                          if (r9 as i64) > (r1 as i64) { pc += 417 }
    ldxw r1, [r10-0x118]                    
    ldxw r2, [r10-0x114]                    
    or64 r2, r1                                     r2 |= r1   ///  r2 = r2.or(r1)
    ldxw r1, [r10-0x11c]                    
    or64 r2, r1                                     r2 |= r1   ///  r2 = r2.or(r1)
    lsh64 r2, 32                                    r2 <<= 32   ///  r2 = r2.wrapping_shl(32)
    rsh64 r2, 32                                    r2 >>= 32   ///  r2 = r2.wrapping_shr(32)
    jeq r2, 0, lbb_27199                            if r2 == (0 as i32 as i64 as u64) { pc += 409 }
    ldxw r1, [r10-0x108]                    
    lsh64 r1, 32                                    r1 <<= 32   ///  r1 = r1.wrapping_shl(32)
    arsh64 r1, 32                                   r1 >>= 32 (signed)   ///  r1 = (r1 as i64).wrapping_shr(32)
    jsgt r9, r1, lbb_27199                          if (r9 as i64) > (r1 as i64) { pc += 405 }
    ldxw r1, [r10-0x100]                    
    ldxw r2, [r10-0xfc]                     
    or64 r2, r1                                     r2 |= r1   ///  r2 = r2.or(r1)
    ldxw r1, [r10-0x104]                    
    or64 r2, r1                                     r2 |= r1   ///  r2 = r2.or(r1)
    lsh64 r2, 32                                    r2 <<= 32   ///  r2 = r2.wrapping_shl(32)
    rsh64 r2, 32                                    r2 >>= 32   ///  r2 = r2.wrapping_shr(32)
    jeq r2, 0, lbb_27199                            if r2 == (0 as i32 as i64 as u64) { pc += 397 }
    ldxw r1, [r10-0xf8]                     
    lsh64 r1, 32                                    r1 <<= 32   ///  r1 = r1.wrapping_shl(32)
    arsh64 r1, 32                                   r1 >>= 32 (signed)   ///  r1 = (r1 as i64).wrapping_shr(32)
    jsgt r9, r1, lbb_27199                          if (r9 as i64) > (r1 as i64) { pc += 393 }
    ldxw r1, [r10-0xf0]                     
    ldxw r2, [r10-0xec]                     
    or64 r2, r1                                     r2 |= r1   ///  r2 = r2.or(r1)
    ldxw r1, [r10-0xf4]                     
    or64 r2, r1                                     r2 |= r1   ///  r2 = r2.or(r1)
    lsh64 r2, 32                                    r2 <<= 32   ///  r2 = r2.wrapping_shl(32)
    rsh64 r2, 32                                    r2 >>= 32   ///  r2 = r2.wrapping_shr(32)
    jeq r2, 0, lbb_27199                            if r2 == (0 as i32 as i64 as u64) { pc += 385 }
    ldxdw r2, [r10-0x220]                   
    ldxdw r1, [r2+0x8]                      
    stxdw [r10-0x8], r1                     
    ldxdw r1, [r2+0x0]                      
    stxdw [r10-0x10], r1                    
    ldxdw r2, [r10-0x228]                   
    ldxdw r1, [r2+0x8]                      
    stxdw [r10-0x170], r1                   
    ldxdw r1, [r2+0x0]                      
    stxdw [r10-0x178], r1                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -88                                   r1 += -88   ///  r1 = r1.wrapping_add(-88 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -16                                   r2 += -16   ///  r2 = r2.wrapping_add(-16 as i32 as i64 as u64)
    mov64 r3, r10                                   r3 = r10
    add64 r3, -376                                  r3 += -376   ///  r3 = r3.wrapping_add(-376 as i32 as i64 as u64)
    lddw r4, 0x1000617a8 --> b"Calculating implied price in cross"        r4 load str located at 4295366568
    mov64 r5, 34                                    r5 = 34 as i32 as i64 as u64
    call function_25488                     
    ldxb r9, [r10-0x58]                     
    jne r9, 56, lbb_27235                           if r9 != (56 as i32 as i64 as u64) { pc += 399 }
    ldxdw r1, [r7+0x8]                      
    ldxdw r9, [r10-0x200]                   
    stxdw [r9+0x8], r1                      
    ldxdw r1, [r7+0x0]                      
    stxdw [r9+0x0], r1                      
    ldxdw r1, [r9+0x8]                      
    stxdw [r10-0xd8], r1                    
    ldxdw r1, [r9+0x0]                      
    stxdw [r10-0xe0], r1                    
    lsh64 r1, 32                                    r1 <<= 32   ///  r1 = r1.wrapping_shl(32)
    arsh64 r1, 32                                   r1 >>= 32 (signed)   ///  r1 = (r1 as i64).wrapping_shr(32)
    jsgt r1, -1, lbb_26849                          if (r1 as i64) > (-1 as i32 as i64) { pc += 1 }
    ja lbb_27199                                    if true { pc += 350 }
lbb_26849:
    ldxw r1, [r10-0xd8]                     
    ldxw r2, [r10-0xd4]                     
    or64 r2, r1                                     r2 |= r1   ///  r2 = r2.or(r1)
    ldxw r1, [r10-0xdc]                     
    or64 r2, r1                                     r2 |= r1   ///  r2 = r2.or(r1)
    lsh64 r2, 32                                    r2 <<= 32   ///  r2 = r2.wrapping_shl(32)
    rsh64 r2, 32                                    r2 >>= 32   ///  r2 = r2.wrapping_shr(32)
    jeq r2, 0, lbb_27199                            if r2 == (0 as i32 as i64 as u64) { pc += 342 }
    ldxdw r1, [r10-0x230]                   
    jeq r1, 0, lbb_26871                            if r1 == (0 as i32 as i64 as u64) { pc += 12 }
    ldxdw r2, [r10-0x240]                   
    ldxdw r1, [r2+0x8]                      
    stxdw [r10-0x50], r1                    
    ldxdw r1, [r2+0x0]                      
    stxdw [r10-0x58], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -224                                  r1 += -224   ///  r1 = r1.wrapping_add(-224 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -88                                   r2 += -88   ///  r2 = r2.wrapping_add(-88 as i32 as i64 as u64)
    call function_33952                     
    and64 r0, 255                                   r0 &= 255   ///  r0 = r0.and(255)
    jeq r0, 1, lbb_27199                            if r0 == (1 as i32 as i64 as u64) { pc += 328 }
lbb_26871:
    ldxdw r1, [r10-0x128]                   
    stxdw [r10-0xc8], r1                    
    ldxdw r1, [r10-0x130]                   
    stxdw [r10-0xd0], r1                    
    ldxdw r1, [r10-0x100]                   
    stxdw [r10-0x50], r1                    
    ldxdw r1, [r10-0x108]                   
    stxdw [r10-0x58], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -192                                  r1 += -192   ///  r1 = r1.wrapping_add(-192 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -88                                   r2 += -88   ///  r2 = r2.wrapping_add(-88 as i32 as i64 as u64)
    ldxdw r3, [r10-0x208]                   
    call function_33551                     
    ldxdw r1, [r10-0xd8]                    
    stxdw [r10-0x8], r1                     
    ldxdw r1, [r10-0xe0]                    
    stxdw [r10-0x10], r1                    
    ldxdw r1, [r10-0xc8]                    
    stxdw [r10-0x170], r1                   
    ldxdw r1, [r10-0xd0]                    
    stxdw [r10-0x178], r1                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -88                                   r1 += -88   ///  r1 = r1.wrapping_add(-88 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -376                                  r2 += -376   ///  r2 = r2.wrapping_add(-376 as i32 as i64 as u64)
    mov64 r3, r10                                   r3 = r10
    add64 r3, -16                                   r3 += -16   ///  r3 = r3.wrapping_add(-16 as i32 as i64 as u64)
    lddw r4, 0x1000617ca --> b"Calculating implied quote available"        r4 load str located at 4295366602
    mov64 r5, 35                                    r5 = 35 as i32 as i64 as u64
    call function_25589                     
    ldxb r8, [r10-0x58]                     
    jne r8, 56, lbb_27206                           if r8 != (56 as i32 as i64 as u64) { pc += 301 }
    ldxdw r1, [r7+0x8]                      
    stxdw [r9+0x8], r1                      
    ldxdw r1, [r7+0x0]                      
    stxdw [r9+0x0], r1                      
    ldxdw r1, [r9+0x0]                      
    stxdw [r10-0xb0], r1                    
    ldxdw r1, [r9+0x8]                      
    stxdw [r10-0xa8], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -176                                  r1 += -176   ///  r1 = r1.wrapping_add(-176 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -192                                  r2 += -192   ///  r2 = r2.wrapping_add(-192 as i32 as i64 as u64)
    call function_33952                     
    and64 r0, 255                                   r0 &= 255   ///  r0 = r0.and(255)
    mov64 r1, 2                                     r1 = 2 as i32 as i64 as u64
    jgt r1, r0, lbb_26922                           if r1 > r0 { pc += 1 }
    ja lbb_26995                                    if true { pc += 73 }
lbb_26922:
    ldxdw r1, [r10-0xb8]                    
    stxdw [r10-0x88], r1                    
    ldxdw r2, [r10-0xc0]                    
    stxdw [r10-0x90], r2                    
    stxdw [r10-0x8], r1                     
    stxdw [r10-0x10], r2                    
    ldxdw r1, [r10-0xd8]                    
    stxdw [r10-0x170], r1                   
    ldxdw r1, [r10-0xe0]                    
    stxdw [r10-0x178], r1                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -88                                   r1 += -88   ///  r1 = r1.wrapping_add(-88 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -16                                   r2 += -16   ///  r2 = r2.wrapping_add(-16 as i32 as i64 as u64)
    mov64 r3, r10                                   r3 = r10
    add64 r3, -376                                  r3 += -376   ///  r3 = r3.wrapping_add(-376 as i32 as i64 as u64)
    lddw r4, 0x10006181f --> b"Calculating base for available quote"        r4 load str located at 4295366687
    mov64 r5, 36                                    r5 = 36 as i32 as i64 as u64
    call function_25488                     
    ldxb r8, [r10-0x58]                     
    jeq r8, 56, lbb_26945                           if r8 == (56 as i32 as i64 as u64) { pc += 1 }
    ja lbb_27206                                    if true { pc += 261 }
lbb_26945:
    ldxdw r1, [r7+0x8]                      
    stxdw [r9+0x8], r1                      
    ldxdw r1, [r7+0x0]                      
    stxdw [r9+0x0], r1                      
    ldxdw r1, [r9+0x0]                      
    stxdw [r10-0x80], r1                    
    ldxdw r1, [r9+0x8]                      
    stxdw [r10-0x78], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -160                                  r1 += -160   ///  r1 = r1.wrapping_add(-160 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -128                                  r2 += -128   ///  r2 = r2.wrapping_add(-128 as i32 as i64 as u64)
    mov64 r3, r10                                   r3 = r10
    add64 r3, -208                                  r3 += -208   ///  r3 = r3.wrapping_add(-208 as i32 as i64 as u64)
    call function_33551                     
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    stxdw [r10-0x100], r1                   
    mov64 r8, r7                                    r8 = r7
    mov64 r7, r9                                    r7 = r9
    mov64 r9, 0                                     r9 = 0 as i32 as i64 as u64
    stxdw [r10-0x108], r1                   
    ldxdw r1, [r10-0x128]                   
    stxdw [r10-0x8], r1                     
    ldxdw r1, [r10-0x130]                   
    stxdw [r10-0x10], r1                    
    ldxdw r1, [r10-0x98]                    
    stxdw [r10-0x170], r1                   
    ldxdw r1, [r10-0xa0]                    
    stxdw [r10-0x178], r1                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -88                                   r1 += -88   ///  r1 = r1.wrapping_add(-88 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -16                                   r2 += -16   ///  r2 = r2.wrapping_add(-16 as i32 as i64 as u64)
    mov64 r3, r10                                   r3 = r10
    add64 r3, -376                                  r3 += -376   ///  r3 = r3.wrapping_add(-376 as i32 as i64 as u64)
    lddw r4, 0x100061843 --> b"Subtracting matched base from current base order"        r4 load str located at 4295366723
    mov64 r5, 48                                    r5 = 48 as i32 as i64 as u64
    call function_25291                     
    ldxb r1, [r10-0x58]                     
    jeq r1, 56, lbb_26987                           if r1 == (56 as i32 as i64 as u64) { pc += 1 }
    ja lbb_27220                                    if true { pc += 233 }
lbb_26987:
    ldxdw r1, [r8+0x8]                      
    stxdw [r7+0x8], r1                      
    ldxdw r1, [r8+0x0]                      
    stxdw [r7+0x0], r1                      
    ldxdw r1, [r7+0x0]                      
    stxdw [r10-0x130], r1                   
    ldxdw r1, [r7+0x8]                      
    ja lbb_27032                                    if true { pc += 37 }
lbb_26995:
    ldxdw r1, [r10-0xd0]                    
    stxdw [r10-0xa0], r1                    
    ldxdw r1, [r10-0xc8]                    
    stxdw [r10-0x98], r1                    
    ldxdw r1, [r10-0xa8]                    
    stxdw [r10-0x88], r1                    
    ldxdw r2, [r10-0xb0]                    
    stxdw [r10-0x90], r2                    
    ldxdw r3, [r10-0x100]                   
    stxdw [r10-0x8], r3                     
    ldxdw r3, [r10-0x108]                   
    stxdw [r10-0x10], r3                    
    stxdw [r10-0x170], r1                   
    stxdw [r10-0x178], r2                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -88                                   r1 += -88   ///  r1 = r1.wrapping_add(-88 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -16                                   r2 += -16   ///  r2 = r2.wrapping_add(-16 as i32 as i64 as u64)
    mov64 r3, r10                                   r3 = r10
    add64 r3, -376                                  r3 += -376   ///  r3 = r3.wrapping_add(-376 as i32 as i64 as u64)
    lddw r4, 0x1000617ed --> b"Subtracting matched quote from current quote order"        r4 load str located at 4295366637
    mov64 r5, 50                                    r5 = 50 as i32 as i64 as u64
    call function_25291                     
    ldxb r8, [r10-0x58]                     
    jne r8, 56, lbb_27206                           if r8 != (56 as i32 as i64 as u64) { pc += 185 }
    ldxdw r1, [r7+0x8]                      
    stxdw [r9+0x8], r1                      
    ldxdw r1, [r7+0x0]                      
    stxdw [r9+0x0], r1                      
    ldxdw r1, [r9+0x0]                      
    stxdw [r10-0x108], r1                   
    ldxdw r1, [r9+0x8]                      
    stxdw [r10-0x100], r1                   
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    stxdw [r10-0x130], r1                   
    mov64 r9, 0                                     r9 = 0 as i32 as i64 as u64
lbb_27032:
    stxdw [r10-0x128], r1                   
    ldxdw r7, [r10-0xe8]                    
    ldxdw r8, [r10-0x110]                   
    ldxdw r1, [r10-0x1b0]                   
    ldxdw r2, [r10-0x210]                   
    jne r2, r1, lbb_27044                           if r2 != r1 { pc += 6 }
    mov64 r1, r10                                   r1 = r10
    add64 r1, -440                                  r1 += -440   ///  r1 = r1.wrapping_add(-440 as i32 as i64 as u64)
    call function_21906                     
    ldxdw r1, [r10-0x1b8]                   
    stxdw [r10-0x218], r1                   
    ldxdw r2, [r10-0x1a8]                   
lbb_27044:
    mov64 r1, r2                                    r1 = r2
    mul64 r1, 40                                    r1 *= 40   ///  r1 = r1.wrapping_mul(40 as u64)
    ldxdw r3, [r10-0x218]                   
    add64 r3, r1                                    r3 += r1   ///  r3 = r3.wrapping_add(r1)
    ldxdw r1, [r10-0x98]                    
    stxdw [r3+0x8], r1                      
    ldxdw r1, [r10-0xa0]                    
    stxdw [r3+0x0], r1                      
    stxb [r3+0x10], r8                      
    ldxdw r1, [r10-0x90]                    
    stxdw [r3+0x14], r1                     
    ldxdw r1, [r10-0x88]                    
    stxdw [r3+0x1c], r1                     
    stxb [r3+0x24], r7                      
    add64 r2, 1                                     r2 += 1   ///  r2 = r2.wrapping_add(1 as i32 as i64 as u64)
    stxdw [r10-0x210], r2                   
    stxdw [r10-0x1a8], r2                   
    ldxdw r7, [r10-0x1f8]                   
    ldxdw r1, [r7+0x8]                      
    stxdw [r10-0x8], r1                     
    ldxdw r1, [r7+0x0]                      
    stxdw [r10-0x10], r1                    
    ldxdw r1, [r10-0x98]                    
    stxdw [r10-0x170], r1                   
    ldxdw r1, [r10-0xa0]                    
    stxdw [r10-0x178], r1                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -88                                   r1 += -88   ///  r1 = r1.wrapping_add(-88 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -16                                   r2 += -16   ///  r2 = r2.wrapping_add(-16 as i32 as i64 as u64)
    mov64 r3, r10                                   r3 = r10
    add64 r3, -376                                  r3 += -376   ///  r3 = r3.wrapping_add(-376 as i32 as i64 as u64)
    lddw r4, 0x100061873 --> b"Adding matched base to summary"        r4 load str located at 4295366771
    mov64 r5, 30                                    r5 = 30 as i32 as i64 as u64
    call function_25190                     
    ldxb r8, [r10-0x58]                     
    jeq r8, 56, lbb_27083                           if r8 == (56 as i32 as i64 as u64) { pc += 1 }
    ja lbb_27206                                    if true { pc += 123 }
lbb_27083:
    ldxdw r2, [r10-0x1f0]                   
    ldxdw r1, [r2+0x8]                      
    ldxdw r8, [r10-0x200]                   
    stxdw [r8+0x8], r1                      
    ldxdw r1, [r2+0x0]                      
    stxdw [r8+0x0], r1                      
    ldxdw r1, [r8+0x8]                      
    stxdw [r7+0x8], r1                      
    ldxdw r1, [r8+0x0]                      
    stxdw [r7+0x0], r1                      
    ldxdw r7, [r10-0x238]                   
    ldxdw r1, [r7+0x8]                      
    stxdw [r10-0x8], r1                     
    ldxdw r1, [r7+0x0]                      
    stxdw [r10-0x10], r1                    
    ldxdw r1, [r10-0x88]                    
    stxdw [r10-0x170], r1                   
    ldxdw r1, [r10-0x90]                    
    stxdw [r10-0x178], r1                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -88                                   r1 += -88   ///  r1 = r1.wrapping_add(-88 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -16                                   r2 += -16   ///  r2 = r2.wrapping_add(-16 as i32 as i64 as u64)
    mov64 r3, r10                                   r3 = r10
    add64 r3, -376                                  r3 += -376   ///  r3 = r3.wrapping_add(-376 as i32 as i64 as u64)
    lddw r4, 0x100061891 --> b"Adding matched quote to summary"        r4 load str located at 4295366801
    mov64 r5, 31                                    r5 = 31 as i32 as i64 as u64
    call function_25190                     
    ldxb r1, [r10-0x58]                     
    jeq r1, 56, lbb_27115                           if r1 == (56 as i32 as i64 as u64) { pc += 1 }
    ja lbb_27220                                    if true { pc += 105 }
lbb_27115:
    ldxdw r2, [r10-0x1f0]                   
    ldxdw r1, [r2+0x8]                      
    stxdw [r8+0x8], r1                      
    ldxdw r1, [r2+0x0]                      
    stxdw [r8+0x0], r1                      
    ldxdw r1, [r8+0x8]                      
    stxdw [r7+0x8], r1                      
    ldxdw r1, [r8+0x0]                      
    stxdw [r7+0x0], r1                      
    ldxdw r7, [r10-0x208]                   
    ldxdw r1, [r7+0x8]                      
    stxdw [r10-0x8], r1                     
    ldxdw r1, [r7+0x0]                      
    stxdw [r10-0x10], r1                    
    ldxdw r1, [r10-0x88]                    
    stxdw [r10-0x170], r1                   
    ldxdw r1, [r10-0x90]                    
    stxdw [r10-0x178], r1                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -88                                   r1 += -88   ///  r1 = r1.wrapping_add(-88 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -16                                   r2 += -16   ///  r2 = r2.wrapping_add(-16 as i32 as i64 as u64)
    mov64 r3, r10                                   r3 = r10
    add64 r3, -376                                  r3 += -376   ///  r3 = r3.wrapping_add(-376 as i32 as i64 as u64)
    lddw r4, 0x1000618b0 --> b"Subtracting matched quote from crossable size"        r4 load str located at 4295366832
    mov64 r5, 45                                    r5 = 45 as i32 as i64 as u64
    call function_25291                     
    ldxb r1, [r10-0x58]                     
    jeq r1, 56, lbb_27146                           if r1 == (56 as i32 as i64 as u64) { pc += 1 }
    ja lbb_27220                                    if true { pc += 74 }
lbb_27146:
    ldxdw r5, [r10-0x1f0]                   
    ldxdw r1, [r5+0x8]                      
    stxdw [r8+0x8], r1                      
    ldxdw r1, [r5+0x0]                      
    stxdw [r8+0x0], r1                      
    ldxdw r1, [r8+0x8]                      
    stxdw [r7+0x8], r1                      
    ldxdw r1, [r8+0x0]                      
    stxdw [r7+0x0], r1                      
    ldxw r1, [r7+0x0]                       
    lsh64 r1, 32                                    r1 <<= 32   ///  r1 = r1.wrapping_shl(32)
    arsh64 r1, 32                                   r1 >>= 32 (signed)   ///  r1 = (r1 as i64).wrapping_shr(32)
    mov64 r8, 0                                     r8 = 0 as i32 as i64 as u64
    ldxdw r4, [r10-0x1f8]                   
    jsgt r1, -1, lbb_26687                          if (r1 as i64) > (-1 as i32 as i64) { pc += -474 }
    ja lbb_27199                                    if true { pc += 37 }
lbb_27162:
    mov64 r1, r6                                    r1 = r6
    lddw r2, 0x100061765 --> b"Initial base order iterator empty"        r2 load str located at 4295366501
    mov64 r3, 33                                    r3 = 33 as i32 as i64 as u64
    ja lbb_27181                                    if true { pc += 14 }
lbb_27167:
    mov64 r7, 34                                    r7 = 34 as i32 as i64 as u64
    mov64 r1, 34                                    r1 = 34 as i32 as i64 as u64
    mov64 r2, 1                                     r2 = 1 as i32 as i64 as u64
    call function_21359                     
    mov64 r6, r0                                    r6 = r0
    jne r6, 0, lbb_27177                            if r6 != (0 as i32 as i64 as u64) { pc += 4 }
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    mov64 r2, 34                                    r2 = 34 as i32 as i64 as u64
    call function_43400                     
    syscall [invalid]                       
lbb_27177:
    mov64 r1, r6                                    r1 = r6
    lddw r2, 0x100061786 --> b"Initial quote order iterator empty"        r2 load str located at 4295366534
    mov64 r3, 34                                    r3 = 34 as i32 as i64 as u64
lbb_27181:
    call function_48190                     
    stxdw [r10-0x160], r7                   
    stxdw [r10-0x168], r7                   
    stxdw [r10-0x170], r6                   
    mov64 r1, 29                                    r1 = 29 as i32 as i64 as u64
    stxb [r10-0x178], r1                    
lbb_27187:
    ldxdw r1, [r10-0x1d0]                   
    mov64 r2, 1                                     r2 = 1 as i32 as i64 as u64
    stxb [r10-0x180], r2                    
    mov64 r2, r10                                   r2 = r10
    add64 r2, -440                                  r2 += -440   ///  r2 = r2.wrapping_add(-440 as i32 as i64 as u64)
    mov64 r3, 64                                    r3 = 64 as i32 as i64 as u64
    call function_48190                     
    mov64 r1, r10                                   r1 = r10
    add64 r1, -376                                  r1 += -376   ///  r1 = r1.wrapping_add(-376 as i32 as i64 as u64)
    call function_21656                     
    ja lbb_27205                                    if true { pc += 7 }
lbb_27198:
    mov64 r8, 1                                     r8 = 1 as i32 as i64 as u64
lbb_27199:
    stxb [r10-0x180], r8                    
    mov64 r2, r10                                   r2 = r10
    add64 r2, -440                                  r2 += -440   ///  r2 = r2.wrapping_add(-440 as i32 as i64 as u64)
    ldxdw r1, [r10-0x1d0]                   
    mov64 r3, 64                                    r3 = 64 as i32 as i64 as u64
    call function_48190                     
lbb_27205:
    exit                                    
lbb_27206:
    ldxw r1, [r10-0x48]                     
    stxw [r10-0x61], r1                     
    ldxdw r1, [r10-0x4f]                    
    stxdw [r10-0x68], r1                    
    ldxdw r1, [r10-0x57]                    
    stxdw [r10-0x70], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -356                                  r1 += -356   ///  r1 = r1.wrapping_add(-356 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -68                                   r2 += -68   ///  r2 = r2.wrapping_add(-68 as i32 as i64 as u64)
    mov64 r3, 52                                    r3 = 52 as i32 as i64 as u64
    call function_48190                     
    stxb [r10-0x178], r8                    
    ja lbb_27248                                    if true { pc += 28 }
lbb_27220:
    mov64 r6, r1                                    r6 = r1
    ldxw r1, [r10-0x48]                     
    stxw [r10-0x61], r1                     
    ldxdw r1, [r10-0x4f]                    
    stxdw [r10-0x68], r1                    
    ldxdw r1, [r10-0x57]                    
    stxdw [r10-0x70], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -356                                  r1 += -356   ///  r1 = r1.wrapping_add(-356 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -68                                   r2 += -68   ///  r2 = r2.wrapping_add(-68 as i32 as i64 as u64)
    mov64 r3, 52                                    r3 = 52 as i32 as i64 as u64
    call function_48190                     
    stxb [r10-0x178], r6                    
    ja lbb_27248                                    if true { pc += 13 }
lbb_27235:
    ldxw r1, [r10-0x48]                     
    stxw [r10-0x61], r1                     
    ldxdw r1, [r10-0x4f]                    
    stxdw [r10-0x68], r1                    
    ldxdw r1, [r10-0x57]                    
    stxdw [r10-0x70], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -356                                  r1 += -356   ///  r1 = r1.wrapping_add(-356 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -68                                   r2 += -68   ///  r2 = r2.wrapping_add(-68 as i32 as i64 as u64)
    mov64 r3, 52                                    r3 = 52 as i32 as i64 as u64
    call function_48190                     
    stxb [r10-0x178], r9                    
lbb_27248:
    ldxdw r1, [r10-0x70]                    
    stxdw [r10-0x177], r1                   
    ldxdw r1, [r10-0x68]                    
    stxdw [r10-0x16f], r1                   
    ldxw r1, [r10-0x61]                     
    stxw [r10-0x168], r1                    
    ja lbb_27187                                    if true { pc += -68 }

function_27255:
    mov64 r7, r2                                    r7 = r2
    mov64 r6, r1                                    r6 = r1
    ldxw r1, [r7+0x8]                       
    ldxw r2, [r7+0xc]                       
    or64 r2, r1                                     r2 |= r1   ///  r2 = r2.or(r1)
    ldxw r1, [r7+0x4]                       
    or64 r2, r1                                     r2 |= r1   ///  r2 = r2.or(r1)
    lsh64 r2, 32                                    r2 <<= 32   ///  r2 = r2.wrapping_shl(32)
    rsh64 r2, 32                                    r2 >>= 32   ///  r2 = r2.wrapping_shr(32)
    jne r2, 0, lbb_27271                            if r2 != (0 as i32 as i64 as u64) { pc += 6 }
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    stxdw [r6+0x18], r1                     
    stxdw [r6+0x10], r1                     
    stxdw [r6+0x8], r1                      
    mov64 r1, 56                                    r1 = 56 as i32 as i64 as u64
    ja lbb_27421                                    if true { pc += 150 }
lbb_27271:
    ldxw r1, [r7+0x0]                       
    lsh64 r1, 32                                    r1 <<= 32   ///  r1 = r1.wrapping_shl(32)
    arsh64 r1, 32                                   r1 >>= 32 (signed)   ///  r1 = (r1 as i64).wrapping_shr(32)
    jsgt r1, -1, lbb_27276                          if (r1 as i64) > (-1 as i32 as i64) { pc += 1 }
    ja lbb_27352                                    if true { pc += 76 }
lbb_27276:
    mov64 r1, 10                                    r1 = 10 as i32 as i64 as u64
    stxdw [r10-0x98], r1                    
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    stxdw [r10-0xa0], r1                    
    and64 r3, 255                                   r3 &= 255   ///  r3 = r3.and(255)
    mov64 r1, r10                                   r1 = r10
    add64 r1, -208                                  r1 += -208   ///  r1 = r1.wrapping_add(-208 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -160                                  r2 += -160   ///  r2 = r2.wrapping_add(-160 as i32 as i64 as u64)
    call function_38094                     
    ldxdw r1, [r7+0x8]                      
    stxdw [r10-0xa8], r1                    
    ldxdw r1, [r7+0x0]                      
    stxdw [r10-0xb0], r1                    
    ldxdw r1, [r10-0xc8]                    
    stxdw [r10-0x38], r1                    
    ldxdw r1, [r10-0xd0]                    
    stxdw [r10-0x40], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -160                                  r1 += -160   ///  r1 = r1.wrapping_add(-160 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -176                                  r2 += -176   ///  r2 = r2.wrapping_add(-176 as i32 as i64 as u64)
    mov64 r3, r10                                   r3 = r10
    add64 r3, -64                                   r3 += -64   ///  r3 = r3.wrapping_add(-64 as i32 as i64 as u64)
    lddw r4, 0x1000618dd --> b"Scaling decimal for token bits"        r4 load str located at 4295366877
    mov64 r5, 30                                    r5 = 30 as i32 as i64 as u64
    call function_25589                     
    ldxb r7, [r10-0xa0]                     
    jeq r7, 56, lbb_27307                           if r7 == (56 as i32 as i64 as u64) { pc += 1 }
    ja lbb_27371                                    if true { pc += 64 }
lbb_27307:
    ldxdw r1, [r10-0x9c]                    
    stxdw [r10-0xc0], r1                    
    ldxdw r1, [r10-0x94]                    
    stxdw [r10-0xb8], r1                    
    mov64 r7, r10                                   r7 = r10
    add64 r7, -176                                  r7 += -176   ///  r7 = r7.wrapping_add(-176 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -192                                  r2 += -192   ///  r2 = r2.wrapping_add(-192 as i32 as i64 as u64)
    mov64 r1, r7                                    r1 = r7
    call function_33400                     
    mov64 r1, r10                                   r1 = r10
    add64 r1, -224                                  r1 += -224   ///  r1 = r1.wrapping_add(-224 as i32 as i64 as u64)
    mov64 r2, r7                                    r2 = r7
    call function_33720                     
    ldxdw r1, [r10-0xe0]                    
    jeq r1, 0, lbb_27391                            if r1 == (0 as i32 as i64 as u64) { pc += 68 }
    ldxdw r7, [r10-0xd8]                    
    mov64 r1, r7                                    r1 = r7
    rsh64 r1, 32                                    r1 >>= 32   ///  r1 = r1.wrapping_shr(32)
    stxw [r10-0x34], r1                     
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    stxdw [r10-0x40], r1                    
    stxw [r10-0x38], r7                     
    mov64 r1, r10                                   r1 = r10
    add64 r1, -160                                  r1 += -160   ///  r1 = r1.wrapping_add(-160 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -64                                   r2 += -64   ///  r2 = r2.wrapping_add(-64 as i32 as i64 as u64)
    mov64 r3, r10                                   r3 = r10
    add64 r3, -208                                  r3 += -208   ///  r3 = r3.wrapping_add(-208 as i32 as i64 as u64)
    lddw r4, 0x100061924 --> b"Converting token bits back to decimal"        r4 load str located at 4295366948
    mov64 r5, 37                                    r5 = 37 as i32 as i64 as u64
    call function_25488                     
    ldxb r8, [r10-0xa0]                     
    jne r8, 56, lbb_27423                           if r8 != (56 as i32 as i64 as u64) { pc += 81 }
    ldxdw r1, [r10-0x94]                    
    stxdw [r10-0x4d], r1                    
    ldxdw r2, [r10-0x9c]                    
    stxdw [r10-0x55], r2                    
    stxdw [r6+0x18], r1                     
    stxdw [r6+0x10], r2                     
    mov64 r1, 56                                    r1 = 56 as i32 as i64 as u64
    stxb [r6+0x0], r1                       
    stxdw [r6+0x8], r7                      
    ja lbb_27422                                    if true { pc += 70 }
lbb_27352:
    mov64 r8, 57                                    r8 = 57 as i32 as i64 as u64
    mov64 r1, 57                                    r1 = 57 as i32 as i64 as u64
    mov64 r2, 1                                     r2 = 1 as i32 as i64 as u64
    call function_21359                     
    mov64 r7, r0                                    r7 = r0
    jne r7, 0, lbb_27362                            if r7 != (0 as i32 as i64 as u64) { pc += 4 }
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    mov64 r2, 57                                    r2 = 57 as i32 as i64 as u64
    call function_43400                     
    syscall [invalid]                       
lbb_27362:
    mov64 r1, r7                                    r1 = r7
    lddw r2, 0x100061949 --> b"Input decimal must be positive for rounding to token bits"        r2 load str located at 4295366985
    mov64 r3, 57                                    r3 = 57 as i32 as i64 as u64
    call function_48190                     
    stxdw [r6+0x18], r8                     
    stxdw [r6+0x10], r8                     
    stxdw [r6+0x8], r7                      
    ja lbb_27420                                    if true { pc += 49 }
lbb_27371:
    ldxw r1, [r10-0x90]                     
    stxw [r10-0x49], r1                     
    ldxdw r1, [r10-0x97]                    
    stxdw [r10-0x50], r1                    
    ldxdw r1, [r10-0x9f]                    
    stxdw [r10-0x58], r1                    
    mov64 r1, r6                                    r1 = r6
    add64 r1, 20                                    r1 += 20   ///  r1 = r1.wrapping_add(20 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -140                                  r2 += -140   ///  r2 = r2.wrapping_add(-140 as i32 as i64 as u64)
    mov64 r3, 52                                    r3 = 52 as i32 as i64 as u64
    call function_48190                     
    ldxw r1, [r10-0x49]                     
    stxw [r6+0x10], r1                      
    ldxdw r1, [r10-0x50]                    
    stxdw [r6+0x9], r1                      
    ldxdw r1, [r10-0x58]                    
    stxdw [r6+0x1], r1                      
    stxb [r6+0x0], r7                       
    ja lbb_27422                                    if true { pc += 31 }
lbb_27391:
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    stxdw [r10-0x80], r1                    
    mov64 r1, 2                                     r1 = 2 as i32 as i64 as u64
    stxdw [r10-0x98], r1                    
    lddw r1, 0x100065b88 --> b"\x00\x00\x00\x00\xfb\x18\x06\x00"\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00…        r1 load str located at 4295383944
    stxdw [r10-0xa0], r1                    
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    stxdw [r10-0x88], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -64                                   r1 += -64   ///  r1 = r1.wrapping_add(-64 as i32 as i64 as u64)
    stxdw [r10-0x90], r1                    
    lddw r1, 0x100042110 --> b"\xbf'\x00\x00\x00\x00\x00\x00\xbf\x18\x00\x00\x00\x00\x00\x00yu\x18\x00\x…        r1 load str located at 4295237904
    stxdw [r10-0x38], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -176                                  r1 += -176   ///  r1 = r1.wrapping_add(-176 as i32 as i64 as u64)
    stxdw [r10-0x40], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -88                                   r1 += -88   ///  r1 = r1.wrapping_add(-88 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -160                                  r2 += -160   ///  r2 = r2.wrapping_add(-160 as i32 as i64 as u64)
    call function_43415                     
    ldxdw r1, [r10-0x58]                    
    ldxdw r2, [r10-0x48]                    
    stxdw [r6+0x18], r2                     
    ldxdw r2, [r10-0x50]                    
    stxdw [r6+0x10], r2                     
    stxdw [r6+0x8], r1                      
lbb_27420:
    mov64 r1, 29                                    r1 = 29 as i32 as i64 as u64
lbb_27421:
    stxb [r6+0x0], r1                       
lbb_27422:
    exit                                    
lbb_27423:
    ldxw r1, [r10-0x90]                     
    stxw [r10-0x49], r1                     
    ldxdw r1, [r10-0x97]                    
    stxdw [r10-0x50], r1                    
    ldxdw r1, [r10-0x9f]                    
    stxdw [r10-0x58], r1                    
    mov64 r1, r6                                    r1 = r6
    add64 r1, 20                                    r1 += 20   ///  r1 = r1.wrapping_add(20 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -140                                  r2 += -140   ///  r2 = r2.wrapping_add(-140 as i32 as i64 as u64)
    mov64 r3, 52                                    r3 = 52 as i32 as i64 as u64
    call function_48190                     
    ldxw r1, [r10-0x49]                     
    stxw [r6+0x10], r1                      
    ldxdw r1, [r10-0x50]                    
    stxdw [r6+0x9], r1                      
    ldxdw r1, [r10-0x58]                    
    stxdw [r6+0x1], r1                      
    stxb [r6+0x0], r8                       
    ja lbb_27422                                    if true { pc += -21 }

function_27443:
    stxdw [r10-0x1b8], r2                   
    mov64 r6, r1                                    r6 = r1
    stxdw [r10-0x1b0], r3                   
    stxw [r10-0x190], r3                    
    rsh64 r3, 32                                    r3 >>= 32   ///  r3 = r3.wrapping_shr(32)
    stxw [r10-0x18c], r3                    
    stxdw [r10-0x1a8], r4                   
    stxw [r10-0x180], r4                    
    rsh64 r4, 32                                    r4 >>= 32   ///  r4 = r4.wrapping_shr(32)
    stxw [r10-0x17c], r4                    
    mov64 r7, 0                                     r7 = 0 as i32 as i64 as u64
    stxdw [r10-0x198], r7                   
    stxdw [r10-0x188], r7                   
    ldxdw r3, [r5-0x1000]                   
    stxb [r10-0x19a], r3                    
    ldxdw r9, [r5-0xff8]                    
    stxb [r10-0x199], r9                    
    mov64 r1, 10                                    r1 = 10 as i32 as i64 as u64
    stxdw [r10-0xa8], r1                    
    stxdw [r10-0xb0], r7                    
    and64 r3, 255                                   r3 &= 255   ///  r3 = r3.and(255)
    mov64 r8, r10                                   r8 = r10
    add64 r8, -376                                  r8 += -376   ///  r8 = r8.wrapping_add(-376 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -176                                  r2 += -176   ///  r2 = r2.wrapping_add(-176 as i32 as i64 as u64)
    mov64 r1, r8                                    r1 = r8
    call function_38094                     
    mov64 r1, 10                                    r1 = 10 as i32 as i64 as u64
    stxdw [r10-0xa8], r1                    
    stxdw [r10-0xb0], r7                    
    and64 r9, 255                                   r9 &= 255   ///  r9 = r9.and(255)
    mov64 r1, r10                                   r1 = r10
    add64 r1, -360                                  r1 += -360   ///  r1 = r1.wrapping_add(-360 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -176                                  r2 += -176   ///  r2 = r2.wrapping_add(-176 as i32 as i64 as u64)
    mov64 r3, r9                                    r3 = r9
    call function_38094                     
    mov64 r1, r10                                   r1 = r10
    add64 r1, -176                                  r1 += -176   ///  r1 = r1.wrapping_add(-176 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -408                                  r2 += -408   ///  r2 = r2.wrapping_add(-408 as i32 as i64 as u64)
    mov64 r3, r8                                    r3 = r8
    lddw r4, 0x100061982 --> b"Base decimal conversion"        r4 load str located at 4295367042
    mov64 r5, 23                                    r5 = 23 as i32 as i64 as u64
    call function_25488                     
    ldxb r7, [r10-0xb0]                     
    jne r7, 56, lbb_27580                           if r7 != (56 as i32 as i64 as u64) { pc += 89 }
    stxdw [r10-0x1c0], r6                   
    ldxw r6, [r10-0xa0]                     
    ldxw r7, [r10-0xa4]                     
    ldxw r9, [r10-0xa8]                     
    ldxw r1, [r10-0xac]                     
    stxdw [r10-0x1c8], r1                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -176                                  r1 += -176   ///  r1 = r1.wrapping_add(-176 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -392                                  r2 += -392   ///  r2 = r2.wrapping_add(-392 as i32 as i64 as u64)
    mov64 r3, r10                                   r3 = r10
    add64 r3, -360                                  r3 += -360   ///  r3 = r3.wrapping_add(-360 as i32 as i64 as u64)
    lddw r4, 0x100061999 --> b"Quote decimal conversion"        r4 load str located at 4295367065
    mov64 r5, 24                                    r5 = 24 as i32 as i64 as u64
    call function_25488                     
    ldxb r8, [r10-0xb0]                     
    jeq r8, 56, lbb_27510                           if r8 == (56 as i32 as i64 as u64) { pc += 1 }
    ja lbb_27596                                    if true { pc += 86 }
lbb_27510:
    ldxdw r1, [r10-0xac]                    
    stxdw [r10-0x158], r1                   
    ldxdw r1, [r10-0xa4]                    
    stxdw [r10-0x150], r1                   
    mov64 r1, r7                                    r1 = r7
    or64 r1, r9                                     r1 |= r9   ///  r1 = r1.or(r9)
    or64 r1, r6                                     r1 |= r6   ///  r1 = r1.or(r6)
    lsh64 r1, 32                                    r1 <<= 32   ///  r1 = r1.wrapping_shl(32)
    rsh64 r1, 32                                    r1 >>= 32   ///  r1 = r1.wrapping_shr(32)
    jeq r1, 0, lbb_27617                            if r1 == (0 as i32 as i64 as u64) { pc += 97 }
    stxw [r10-0x34], r6                     
    stxw [r10-0x38], r7                     
    stxw [r10-0x3c], r9                     
    ldxdw r1, [r10-0x1c8]                   
    stxw [r10-0x40], r1                     
    mov64 r1, r10                                   r1 = r10
    add64 r1, -176                                  r1 += -176   ///  r1 = r1.wrapping_add(-176 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -344                                  r2 += -344   ///  r2 = r2.wrapping_add(-344 as i32 as i64 as u64)
    mov64 r3, r10                                   r3 = r10
    add64 r3, -64                                   r3 += -64   ///  r3 = r3.wrapping_add(-64 as i32 as i64 as u64)
    lddw r4, 0x1000619b1 --> b"Calculating discretized implied price"        r4 load str located at 4295367089
    mov64 r5, 37                                    r5 = 37 as i32 as i64 as u64
    call function_25488                     
    ldxb r7, [r10-0xb0]                     
    jne r7, 56, lbb_27645                           if r7 != (56 as i32 as i64 as u64) { pc += 108 }
    ldxdw r1, [r10-0xac]                    
    stxdw [r10-0x148], r1                   
    ldxdw r1, [r10-0xa4]                    
    stxdw [r10-0x140], r1                   
    ldxdw r8, [r10-0x1b8]                   
    ldxdw r1, [r8+0x8]                      
    stxdw [r10-0x120], r1                   
    ldxdw r1, [r8+0x0]                      
    stxdw [r10-0x128], r1                   
    mov64 r1, 999995                                r1 = 999995 as i32 as i64 as u64
    stxdw [r10-0x38], r1                    
    mov64 r1, 393216                                r1 = 393216 as i32 as i64 as u64
    stxdw [r10-0x40], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -176                                  r1 += -176   ///  r1 = r1.wrapping_add(-176 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -296                                  r2 += -296   ///  r2 = r2.wrapping_add(-296 as i32 as i64 as u64)
    mov64 r3, r10                                   r3 = r10
    add64 r3, -64                                   r3 += -64   ///  r3 = r3.wrapping_add(-64 as i32 as i64 as u64)
    lddw r4, 0x1000619d6 --> b"Calculating min allowed price variance"        r4 load str located at 4295367126
    mov64 r5, 38                                    r5 = 38 as i32 as i64 as u64
    call function_25589                     
    ldxb r7, [r10-0xb0]                     
    ldxdw r6, [r10-0x1c0]                   
    jeq r7, 56, lbb_27564                           if r7 == (56 as i32 as i64 as u64) { pc += 1 }
    ja lbb_27653                                    if true { pc += 89 }
lbb_27564:
    ldxdw r1, [r10-0xac]                    
    stxdw [r10-0x138], r1                   
    ldxdw r1, [r10-0xa4]                    
    stxdw [r10-0x130], r1                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -328                                  r1 += -328   ///  r1 = r1.wrapping_add(-328 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -312                                  r2 += -312   ///  r2 = r2.wrapping_add(-312 as i32 as i64 as u64)
    call function_33952                     
    and64 r0, 255                                   r0 &= 255   ///  r0 = r0.and(255)
    mov64 r1, 2                                     r1 = 2 as i32 as i64 as u64
    jgt r1, r0, lbb_27577                           if r1 > r0 { pc += 1 }
    ja lbb_27672                                    if true { pc += 95 }
lbb_27577:
    mov64 r1, 56                                    r1 = 56 as i32 as i64 as u64
    stxb [r6+0x0], r1                       
    ja lbb_27644                                    if true { pc += 64 }
lbb_27580:
    ldxb r1, [r10-0xad]                     
    stxb [r6+0x3], r1                       
    ldxh r1, [r10-0xaf]                     
    stxh [r6+0x1], r1                       
    ldxdw r9, [r10-0xac]                    
    ldxdw r8, [r10-0xa4]                    
    mov64 r1, r6                                    r1 = r6
    add64 r1, 20                                    r1 += 20   ///  r1 = r1.wrapping_add(20 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -156                                  r2 += -156   ///  r2 = r2.wrapping_add(-156 as i32 as i64 as u64)
    mov64 r3, 52                                    r3 = 52 as i32 as i64 as u64
    call function_48190                     
    stxdw [r6+0xc], r8                      
    stxdw [r6+0x4], r9                      
lbb_27594:
    stxb [r6+0x0], r7                       
    ja lbb_27644                                    if true { pc += 48 }
lbb_27596:
    ldxw r1, [r10-0xa0]                     
    stxw [r10-0xd1], r1                     
    ldxdw r1, [r10-0xa7]                    
    stxdw [r10-0xd8], r1                    
    ldxdw r1, [r10-0xaf]                    
    stxdw [r10-0xe0], r1                    
    ldxdw r6, [r10-0x1c0]                   
    mov64 r1, r6                                    r1 = r6
    add64 r1, 20                                    r1 += 20   ///  r1 = r1.wrapping_add(20 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -156                                  r2 += -156   ///  r2 = r2.wrapping_add(-156 as i32 as i64 as u64)
    mov64 r3, 52                                    r3 = 52 as i32 as i64 as u64
    call function_48190                     
    ldxw r1, [r10-0xd1]                     
    stxw [r6+0x10], r1                      
    ldxdw r1, [r10-0xd8]                    
    stxdw [r6+0x9], r1                      
    ldxdw r1, [r10-0xe0]                    
    stxdw [r6+0x1], r1                      
    stxb [r6+0x0], r8                       
    ja lbb_27644                                    if true { pc += 27 }
lbb_27617:
    mov64 r7, 32                                    r7 = 32 as i32 as i64 as u64
    mov64 r1, 32                                    r1 = 32 as i32 as i64 as u64
    mov64 r2, 1                                     r2 = 1 as i32 as i64 as u64
    call function_21359                     
    jne r0, 0, lbb_27626                            if r0 != (0 as i32 as i64 as u64) { pc += 4 }
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    mov64 r2, 32                                    r2 = 32 as i32 as i64 as u64
    call function_43400                     
    syscall [invalid]                       
lbb_27626:
    lddw r1, 0x6f72657a20736920                     r1 load str located at 8030592660759865632
    stxdw [r0+0x18], r1                     
    lddw r1, 0x2973746962206d6f                     r1 load str located at 2986858973843451247
    stxdw [r0+0x10], r1                     
    lddw r1, 0x726628206c616d69                     r1 load str located at 8243320287670660457
    stxdw [r0+0x8], r1                      
    lddw r1, 0x6365642065736142                     r1 load str located at 7162240872706433346
    stxdw [r0+0x0], r1                      
    ldxdw r6, [r10-0x1c0]                   
    stxdw [r6+0x18], r7                     
    stxdw [r6+0x10], r7                     
    stxdw [r6+0x8], r0                      
    mov64 r1, 29                                    r1 = 29 as i32 as i64 as u64
    stxb [r6+0x0], r1                       
lbb_27644:
    exit                                    
lbb_27645:
    ldxw r1, [r10-0xa0]                     
    stxw [r10-0xd1], r1                     
    ldxdw r1, [r10-0xa7]                    
    stxdw [r10-0xd8], r1                    
    ldxdw r1, [r10-0xaf]                    
    stxdw [r10-0xe0], r1                    
    ldxdw r6, [r10-0x1c0]                   
    ja lbb_27659                                    if true { pc += 6 }
lbb_27653:
    ldxw r1, [r10-0xa0]                     
    stxw [r10-0xd1], r1                     
    ldxdw r1, [r10-0xa7]                    
    stxdw [r10-0xd8], r1                    
    ldxdw r1, [r10-0xaf]                    
    stxdw [r10-0xe0], r1                    
lbb_27659:
    mov64 r1, r6                                    r1 = r6
    add64 r1, 20                                    r1 += 20   ///  r1 = r1.wrapping_add(20 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -156                                  r2 += -156   ///  r2 = r2.wrapping_add(-156 as i32 as i64 as u64)
    mov64 r3, 52                                    r3 = 52 as i32 as i64 as u64
    call function_48190                     
    ldxw r1, [r10-0xd1]                     
    stxw [r6+0x10], r1                      
    ldxdw r1, [r10-0xd8]                    
    stxdw [r6+0x9], r1                      
    ldxdw r1, [r10-0xe0]                    
    stxdw [r6+0x1], r1                      
    ja lbb_27594                                    if true { pc += -78 }
lbb_27672:
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    stxdw [r10-0xc0], r1                    
    mov64 r1, 8                                     r1 = 8 as i32 as i64 as u64
    stxdw [r10-0xd8], r1                    
    lddw r1, 0x100065ba8 --> b"\x00\x00\x00\x00\xfc\x19\x06\x00/\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00…        r1 load str located at 4295383976
    stxdw [r10-0xe0], r1                    
    mov64 r1, 7                                     r1 = 7 as i32 as i64 as u64
    stxdw [r10-0xc8], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -176                                  r1 += -176   ///  r1 = r1.wrapping_add(-176 as i32 as i64 as u64)
    stxdw [r10-0xd0], r1                    
    stxdw [r10-0x50], r8                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -312                                  r1 += -312   ///  r1 = r1.wrapping_add(-312 as i32 as i64 as u64)
    stxdw [r10-0x60], r1                    
    lddw r1, 0x100042110 --> b"\xbf'\x00\x00\x00\x00\x00\x00\xbf\x18\x00\x00\x00\x00\x00\x00yu\x18\x00\x…        r1 load str located at 4295237904
    stxdw [r10-0x48], r1                    
    stxdw [r10-0x58], r1                    
    stxdw [r10-0x68], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -328                                  r1 += -328   ///  r1 = r1.wrapping_add(-328 as i32 as i64 as u64)
    stxdw [r10-0x70], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -410                                  r1 += -410   ///  r1 = r1.wrapping_add(-410 as i32 as i64 as u64)
    stxdw [r10-0x80], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -432                                  r1 += -432   ///  r1 = r1.wrapping_add(-432 as i32 as i64 as u64)
    stxdw [r10-0x90], r1                    
    lddw r1, 0x10005de98 --> b"\xbf#\x00\x00\x00\x00\x00\x00q\x11\x00\x00\x00\x00\x00\x00\xb7\x02\x00\x0…        r1 load str located at 4295351960
    stxdw [r10-0x78], r1                    
    stxdw [r10-0x98], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -409                                  r1 += -409   ///  r1 = r1.wrapping_add(-409 as i32 as i64 as u64)
    stxdw [r10-0xa0], r1                    
    lddw r1, 0x10005df58 --> b"\xbf#\x00\x00\x00\x00\x00\x00y\x11\x00\x00\x00\x00\x00\x00\xb7\x02\x00\x0…        r1 load str located at 4295352152
    stxdw [r10-0x88], r1                    
    stxdw [r10-0xa8], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -424                                  r1 += -424   ///  r1 = r1.wrapping_add(-424 as i32 as i64 as u64)
    stxdw [r10-0xb0], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -248                                  r1 += -248   ///  r1 = r1.wrapping_add(-248 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -224                                  r2 += -224   ///  r2 = r2.wrapping_add(-224 as i32 as i64 as u64)
    call function_43415                     
    ldxdw r1, [r10-0xf8]                    
    stxdw [r10-0x110], r1                   
    ldxdw r1, [r10-0xf0]                    
    stxdw [r10-0x108], r1                   
    ldxdw r1, [r10-0xe8]                    
    stxdw [r10-0x100], r1                   
    mov64 r1, 29                                    r1 = 29 as i32 as i64 as u64
    stxb [r6+0x0], r1                       
    ldxdw r1, [r10-0x117]                   
    stxdw [r6+0x1], r1                      
    ldxdw r1, [r10-0x10f]                   
    stxdw [r6+0x9], r1                      
    ldxdw r1, [r10-0x107]                   
    stxdw [r6+0x11], r1                     
    ldxdw r1, [r10-0x100]                   
    stxdw [r6+0x18], r1                     
    ja lbb_27644                                    if true { pc += -94 }

function_27738:
    mov64 r8, r5                                    r8 = r5
    stxdw [r10-0x140], r4                   
    mov64 r9, r3                                    r9 = r3
    stxdw [r10-0x148], r2                   
    mov64 r6, r1                                    r6 = r1
    ldxdw r1, [r9+0x8]                      
    stxdw [r10-0x120], r1                   
    ldxdw r1, [r9+0x0]                      
    stxdw [r10-0x128], r1                   
    mov64 r1, 999995                                r1 = 999995 as i32 as i64 as u64
    stxdw [r10-0x38], r1                    
    mov64 r1, 393216                                r1 = 393216 as i32 as i64 as u64
    stxdw [r10-0x40], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -176                                  r1 += -176   ///  r1 = r1.wrapping_add(-176 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -296                                  r2 += -296   ///  r2 = r2.wrapping_add(-296 as i32 as i64 as u64)
    mov64 r3, r10                                   r3 = r10
    add64 r3, -64                                   r3 += -64   ///  r3 = r3.wrapping_add(-64 as i32 as i64 as u64)
    lddw r4, 0x100061a49 --> b"Calculating min allowed price for swap implied"        r4 load str located at 4295367241
    mov64 r5, 46                                    r5 = 46 as i32 as i64 as u64
    call function_25589                     
    ldxb r7, [r10-0xb0]                     
    jne r7, 56, lbb_27785                           if r7 != (56 as i32 as i64 as u64) { pc += 22 }
    ldxdw r1, [r10-0x140]                   
    ldxdw r1, [r8-0xff0]                    
    stxdw [r10-0x158], r1                   
    ldxdw r1, [r8-0xff8]                    
    stxdw [r10-0x150], r1                   
    ldxdw r8, [r8-0x1000]                   
    ldxdw r1, [r10-0xac]                    
    stxdw [r10-0x138], r1                   
    ldxdw r1, [r10-0xa4]                    
    stxdw [r10-0x130], r1                   
    mov64 r2, r10                                   r2 = r10
    add64 r2, -312                                  r2 += -312   ///  r2 = r2.wrapping_add(-312 as i32 as i64 as u64)
    ldxdw r7, [r10-0x148]                   
    mov64 r1, r7                                    r1 = r7
    call function_33952                     
    and64 r0, 255                                   r0 &= 255   ///  r0 = r0.and(255)
    mov64 r1, 2                                     r1 = 2 as i32 as i64 as u64
    jgt r1, r0, lbb_27782                           if r1 > r0 { pc += 1 }
    ja lbb_27805                                    if true { pc += 23 }
lbb_27782:
    mov64 r1, 56                                    r1 = 56 as i32 as i64 as u64
    stxb [r6+0x0], r1                       
    ja lbb_27858                                    if true { pc += 73 }
lbb_27785:
    ldxw r1, [r10-0xa0]                     
    stxw [r10-0xd1], r1                     
    ldxdw r1, [r10-0xa7]                    
    stxdw [r10-0xd8], r1                    
    ldxdw r1, [r10-0xaf]                    
    stxdw [r10-0xe0], r1                    
    mov64 r1, r6                                    r1 = r6
    add64 r1, 20                                    r1 += 20   ///  r1 = r1.wrapping_add(20 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -156                                  r2 += -156   ///  r2 = r2.wrapping_add(-156 as i32 as i64 as u64)
    mov64 r3, 52                                    r3 = 52 as i32 as i64 as u64
    call function_48190                     
    ldxw r1, [r10-0xd1]                     
    stxw [r6+0x10], r1                      
    ldxdw r1, [r10-0xd8]                    
    stxdw [r6+0x9], r1                      
    ldxdw r1, [r10-0xe0]                    
    stxdw [r6+0x1], r1                      
    stxb [r6+0x0], r7                       
    ja lbb_27858                                    if true { pc += 53 }
lbb_27805:
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    stxdw [r10-0xc0], r1                    
    lddw r1, 0x100065c28 --> b"\x00\x00\x00\x00w\x1a\x06\x00\x1a\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00…        r1 load str located at 4295384104
    stxdw [r10-0xe0], r1                    
    mov64 r1, 7                                     r1 = 7 as i32 as i64 as u64
    stxdw [r10-0xd8], r1                    
    stxdw [r10-0xc8], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -176                                  r1 += -176   ///  r1 = r1.wrapping_add(-176 as i32 as i64 as u64)
    stxdw [r10-0xd0], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -312                                  r1 += -312   ///  r1 = r1.wrapping_add(-312 as i32 as i64 as u64)
    stxdw [r10-0x50], r1                    
    ldxdw r1, [r10-0x158]                   
    stxdw [r10-0x60], r1                    
    ldxdw r1, [r10-0x150]                   
    stxdw [r10-0x70], r1                    
    stxdw [r10-0x80], r9                    
    stxdw [r10-0x90], r8                    
    ldxdw r1, [r10-0x140]                   
    stxdw [r10-0xa0], r1                    
    lddw r1, 0x100042110 --> b"\xbf'\x00\x00\x00\x00\x00\x00\xbf\x18\x00\x00\x00\x00\x00\x00yu\x18\x00\x…        r1 load str located at 4295237904
    stxdw [r10-0x48], r1                    
    stxdw [r10-0x58], r1                    
    stxdw [r10-0x68], r1                    
    stxdw [r10-0x78], r1                    
    stxdw [r10-0x88], r1                    
    stxdw [r10-0x98], r1                    
    stxdw [r10-0xa8], r1                    
    stxdw [r10-0xb0], r7                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -248                                  r1 += -248   ///  r1 = r1.wrapping_add(-248 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -224                                  r2 += -224   ///  r2 = r2.wrapping_add(-224 as i32 as i64 as u64)
    call function_43415                     
    ldxdw r1, [r10-0xf8]                    
    stxdw [r10-0x110], r1                   
    ldxdw r1, [r10-0xf0]                    
    stxdw [r10-0x108], r1                   
    ldxdw r1, [r10-0xe8]                    
    stxdw [r10-0x100], r1                   
    mov64 r1, 29                                    r1 = 29 as i32 as i64 as u64
    stxb [r6+0x0], r1                       
    ldxdw r1, [r10-0x117]                   
    stxdw [r6+0x1], r1                      
    ldxdw r1, [r10-0x10f]                   
    stxdw [r6+0x9], r1                      
    ldxdw r1, [r10-0x107]                   
    stxdw [r6+0x11], r1                     
    ldxdw r1, [r10-0x100]                   
    stxdw [r6+0x18], r1                     
lbb_27858:
    exit                                    

function_27859:
    mov64 r8, r5                                    r8 = r5
    stxdw [r10-0x140], r4                   
    mov64 r9, r3                                    r9 = r3
    stxdw [r10-0x148], r2                   
    mov64 r6, r1                                    r6 = r1
    ldxdw r1, [r9+0x8]                      
    stxdw [r10-0x120], r1                   
    ldxdw r1, [r9+0x0]                      
    stxdw [r10-0x128], r1                   
    mov64 r1, 999995                                r1 = 999995 as i32 as i64 as u64
    stxdw [r10-0x38], r1                    
    mov64 r1, 393216                                r1 = 393216 as i32 as i64 as u64
    stxdw [r10-0x40], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -176                                  r1 += -176   ///  r1 = r1.wrapping_add(-176 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -296                                  r2 += -296   ///  r2 = r2.wrapping_add(-296 as i32 as i64 as u64)
    mov64 r3, r10                                   r3 = r10
    add64 r3, -64                                   r3 += -64   ///  r3 = r3.wrapping_add(-64 as i32 as i64 as u64)
    lddw r4, 0x100061ab7 --> b"Calculating min allowed price for oracle implied"        r4 load str located at 4295367351
    mov64 r5, 48                                    r5 = 48 as i32 as i64 as u64
    call function_25589                     
    ldxb r7, [r10-0xb0]                     
    jne r7, 56, lbb_27906                           if r7 != (56 as i32 as i64 as u64) { pc += 22 }
    ldxdw r1, [r10-0x140]                   
    ldxdw r1, [r8-0xff0]                    
    stxdw [r10-0x158], r1                   
    ldxdw r1, [r8-0xff8]                    
    stxdw [r10-0x150], r1                   
    ldxdw r8, [r8-0x1000]                   
    ldxdw r1, [r10-0xac]                    
    stxdw [r10-0x138], r1                   
    ldxdw r1, [r10-0xa4]                    
    stxdw [r10-0x130], r1                   
    mov64 r2, r10                                   r2 = r10
    add64 r2, -312                                  r2 += -312   ///  r2 = r2.wrapping_add(-312 as i32 as i64 as u64)
    ldxdw r7, [r10-0x148]                   
    mov64 r1, r7                                    r1 = r7
    call function_33952                     
    and64 r0, 255                                   r0 &= 255   ///  r0 = r0.and(255)
    mov64 r1, 2                                     r1 = 2 as i32 as i64 as u64
    jgt r1, r0, lbb_27903                           if r1 > r0 { pc += 1 }
    ja lbb_27926                                    if true { pc += 23 }
lbb_27903:
    mov64 r1, 56                                    r1 = 56 as i32 as i64 as u64
    stxb [r6+0x0], r1                       
    ja lbb_27979                                    if true { pc += 73 }
lbb_27906:
    ldxw r1, [r10-0xa0]                     
    stxw [r10-0xd1], r1                     
    ldxdw r1, [r10-0xa7]                    
    stxdw [r10-0xd8], r1                    
    ldxdw r1, [r10-0xaf]                    
    stxdw [r10-0xe0], r1                    
    mov64 r1, r6                                    r1 = r6
    add64 r1, 20                                    r1 += 20   ///  r1 = r1.wrapping_add(20 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -156                                  r2 += -156   ///  r2 = r2.wrapping_add(-156 as i32 as i64 as u64)
    mov64 r3, 52                                    r3 = 52 as i32 as i64 as u64
    call function_48190                     
    ldxw r1, [r10-0xd1]                     
    stxw [r6+0x10], r1                      
    ldxdw r1, [r10-0xd8]                    
    stxdw [r6+0x9], r1                      
    ldxdw r1, [r10-0xe0]                    
    stxdw [r6+0x1], r1                      
    stxb [r6+0x0], r7                       
    ja lbb_27979                                    if true { pc += 53 }
lbb_27926:
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    stxdw [r10-0xc0], r1                    
    lddw r1, 0x100065c98 --> b"\x00\x00\x00\x00w\x1a\x06\x00\x1a\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00…        r1 load str located at 4295384216
    stxdw [r10-0xe0], r1                    
    mov64 r1, 7                                     r1 = 7 as i32 as i64 as u64
    stxdw [r10-0xd8], r1                    
    stxdw [r10-0xc8], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -176                                  r1 += -176   ///  r1 = r1.wrapping_add(-176 as i32 as i64 as u64)
    stxdw [r10-0xd0], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -312                                  r1 += -312   ///  r1 = r1.wrapping_add(-312 as i32 as i64 as u64)
    stxdw [r10-0x50], r1                    
    ldxdw r1, [r10-0x158]                   
    stxdw [r10-0x60], r1                    
    ldxdw r1, [r10-0x150]                   
    stxdw [r10-0x70], r1                    
    stxdw [r10-0x80], r9                    
    stxdw [r10-0x90], r8                    
    ldxdw r1, [r10-0x140]                   
    stxdw [r10-0xa0], r1                    
    lddw r1, 0x100042110 --> b"\xbf'\x00\x00\x00\x00\x00\x00\xbf\x18\x00\x00\x00\x00\x00\x00yu\x18\x00\x…        r1 load str located at 4295237904
    stxdw [r10-0x48], r1                    
    stxdw [r10-0x58], r1                    
    stxdw [r10-0x68], r1                    
    stxdw [r10-0x78], r1                    
    stxdw [r10-0x88], r1                    
    stxdw [r10-0x98], r1                    
    stxdw [r10-0xa8], r1                    
    stxdw [r10-0xb0], r7                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -248                                  r1 += -248   ///  r1 = r1.wrapping_add(-248 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -224                                  r2 += -224   ///  r2 = r2.wrapping_add(-224 as i32 as i64 as u64)
    call function_43415                     
    ldxdw r1, [r10-0xf8]                    
    stxdw [r10-0x110], r1                   
    ldxdw r1, [r10-0xf0]                    
    stxdw [r10-0x108], r1                   
    ldxdw r1, [r10-0xe8]                    
    stxdw [r10-0x100], r1                   
    mov64 r1, 29                                    r1 = 29 as i32 as i64 as u64
    stxb [r6+0x0], r1                       
    ldxdw r1, [r10-0x117]                   
    stxdw [r6+0x1], r1                      
    ldxdw r1, [r10-0x10f]                   
    stxdw [r6+0x9], r1                      
    ldxdw r1, [r10-0x107]                   
    stxdw [r6+0x11], r1                     
    ldxdw r1, [r10-0x100]                   
    stxdw [r6+0x18], r1                     
lbb_27979:
    exit                                    

function_27980:
    mov64 r8, r3                                    r8 = r3
    mov64 r9, r2                                    r9 = r2
    mov64 r6, r1                                    r6 = r1
    ldxdw r0, [r5-0xff8]                    
    ldxw r2, [r0+0x0]                       
    lsh64 r2, 32                                    r2 <<= 32   ///  r2 = r2.wrapping_shl(32)
    arsh64 r2, 32                                   r2 >>= 32 (signed)   ///  r2 = (r2 as i64).wrapping_shr(32)
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    jsgt r1, r2, lbb_28490                          if (r1 as i64) > (r2 as i64) { pc += 501 }
    ldxw r2, [r0+0x8]                       
    ldxw r3, [r0+0xc]                       
    or64 r3, r2                                     r3 |= r2   ///  r3 = r3.or(r2)
    ldxw r2, [r0+0x4]                       
    or64 r3, r2                                     r3 |= r2   ///  r3 = r3.or(r2)
    lsh64 r3, 32                                    r3 <<= 32   ///  r3 = r3.wrapping_shl(32)
    rsh64 r3, 32                                    r3 >>= 32   ///  r3 = r3.wrapping_shr(32)
    jeq r3, 0, lbb_28490                            if r3 == (0 as i32 as i64 as u64) { pc += 493 }
    stxdw [r10-0x450], r0                   
    stxdw [r10-0x430], r6                   
    ldxdw r1, [r5-0xfe0]                    
    stxdw [r10-0x458], r1                   
    ldxdw r1, [r5-0xfe8]                    
    stxdw [r10-0x438], r1                   
    ldxdw r6, [r5-0xff0]                    
    ldxdw r1, [r5-0x1000]                   
    stxdw [r10-0x440], r1                   
    ldxw r1, [r9+0x10]                      
    stxdw [r10-0x448], r1                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -920                                  r1 += -920   ///  r1 = r1.wrapping_add(-920 as i32 as i64 as u64)
    mov64 r2, r4                                    r2 = r4
    mov64 r3, 1                                     r3 = 1 as i32 as i64 as u64
    mov64 r7, r4                                    r7 = r4
    call function_29099                     
    ldxb r0, [r10-0x398]                    
    jeq r0, 56, lbb_28017                           if r0 == (56 as i32 as i64 as u64) { pc += 1 }
    ja lbb_28526                                    if true { pc += 509 }
lbb_28017:
    ldxw r1, [r10-0x394]                    
    ldxdw r2, [r10-0x390]                   
    ldxw r3, [r10-0x388]                    
    ldxw r4, [r9+0x1c]                      
    stxw [r10-0x100], r4                    
    ldxdw r4, [r9+0x14]                     
    stxdw [r10-0x108], r4                   
    ldxdw r5, [r6+0x8]                      
    stxdw [r10-0xf4], r5                    
    stxdw [r10-0x460], r6                   
    ldxdw r5, [r6+0x0]                      
    stxdw [r10-0xfc], r5                    
    stxdw [r10-0x320], r4                   
    ldxw r4, [r10-0xf0]                     
    stxw [r10-0x308], r4                    
    ldxdw r4, [r10-0xf8]                    
    stxdw [r10-0x310], r4                   
    ldxdw r4, [r10-0x100]                   
    stxdw [r10-0x318], r4                   
    ldxdw r4, [r10-0x320]                   
    stxdw [r10-0x3dc], r4                   
    ldxdw r4, [r10-0x318]                   
    stxdw [r10-0x3d4], r4                   
    ldxdw r4, [r10-0x310]                   
    stxdw [r10-0x3cc], r4                   
    ldxw r4, [r10-0x308]                    
    stxw [r10-0x3c4], r4                    
    mov64 r4, 1                                     r4 = 1 as i32 as i64 as u64
    stxb [r10-0x3a0], r4                    
    ldxdw r4, [r10-0x438]                   
    stxdw [r10-0x3a8], r4                   
    stxw [r10-0x3b4], r3                    
    stxdw [r10-0x3bc], r2                   
    stxw [r10-0x3c0], r1                    
    ldxdw r1, [r10-0x448]                   
    stxw [r10-0x3e0], r1                    
    stxdw [r10-0x448], r7                   
    stxdw [r10-0x3e8], r7                   
    add64 r9, 144                                   r9 += 144   ///  r9 = r9.wrapping_add(144 as i32 as i64 as u64)
    stxdw [r10-0x3f0], r9                   
    mov64 r9, 0                                     r9 = 0 as i32 as i64 as u64
    stxdw [r10-0x3b0], r9                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -264                                  r1 += -264   ///  r1 = r1.wrapping_add(-264 as i32 as i64 as u64)
    ldxdw r6, [r10-0x440]                   
    mov64 r2, r6                                    r2 = r6
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
    call function_29099                     
    ldxb r0, [r10-0x108]                    
    jeq r0, 56, lbb_28068                           if r0 == (56 as i32 as i64 as u64) { pc += 1 }
    ja lbb_28555                                    if true { pc += 487 }
lbb_28068:
    ldxw r1, [r10-0x104]                    
    ldxdw r2, [r10-0x100]                   
    ldxw r4, [r10-0xf8]                     
    ldxw r3, [r8+0x0]                       
    ldxw r5, [r8+0xc]                       
    stxw [r10-0x318], r5                    
    ldxdw r5, [r8+0x4]                      
    stxdw [r10-0x320], r5                   
    ldxdw r7, [r10-0x450]                   
    ldxdw r0, [r7+0x8]                      
    stxdw [r10-0x30c], r0                   
    ldxdw r0, [r7+0x0]                      
    stxdw [r10-0x314], r0                   
    stxdw [r10-0x340], r5                   
    ldxdw r5, [r10-0x310]                   
    stxdw [r10-0x330], r5                   
    ldxw r5, [r10-0x308]                    
    stxw [r10-0x328], r5                    
    ldxdw r5, [r10-0x318]                   
    stxdw [r10-0x338], r5                   
    ldxw r5, [r10-0x328]                    
    stxw [r10-0x36c], r5                    
    ldxdw r5, [r10-0x330]                   
    stxdw [r10-0x374], r5                   
    ldxdw r5, [r10-0x338]                   
    stxdw [r10-0x37c], r5                   
    ldxdw r5, [r10-0x340]                   
    stxdw [r10-0x384], r5                   
    ldxdw r5, [r10-0x438]                   
    stxdw [r10-0x350], r5                   
    stxw [r10-0x35c], r4                    
    stxdw [r10-0x364], r2                   
    stxw [r10-0x368], r1                    
    stxw [r10-0x388], r3                    
    stxdw [r10-0x390], r6                   
    add64 r8, 144                                   r8 += 144   ///  r8 = r8.wrapping_add(144 as i32 as i64 as u64)
    stxdw [r10-0x398], r8                   
    stxb [r10-0x348], r9                    
    stxdw [r10-0x358], r9                   
    ldxdw r1, [r7+0x8]                      
    stxdw [r10-0x338], r1                   
    ldxdw r1, [r7+0x0]                      
    stxdw [r10-0x340], r1                   
    stxw [r10-0x108], r9                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -832                                  r1 += -832   ///  r1 = r1.wrapping_add(-832 as i32 as i64 as u64)
    stxdw [r10-0xff8], r1                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -264                                  r1 += -264   ///  r1 = r1.wrapping_add(-264 as i32 as i64 as u64)
    stxdw [r10-0xff0], r1                   
    lddw r1, 0x100065d08 --> b"\x00\x00\x00\x00\xd8\xa5\x02\x00X\x00\x00\x00\x00\x00\x00\x00\x08\x00\x00…        r1 load str located at 4295384328
    stxdw [r10-0x1000], r1                  
    mov64 r1, r10                                   r1 = r10
    add64 r1, -800                                  r1 += -800   ///  r1 = r1.wrapping_add(-800 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -1008                                 r2 += -1008   ///  r2 = r2.wrapping_add(-1008 as i32 as i64 as u64)
    mov64 r4, r10                                   r4 = r10
    add64 r4, -920                                  r4 += -920   ///  r4 = r4.wrapping_add(-920 as i32 as i64 as u64)
    mov64 r5, r10                                   r5 = r10
    lddw r3, 0x100065d08 --> b"\x00\x00\x00\x00\xd8\xa5\x02\x00X\x00\x00\x00\x00\x00\x00\x00\x08\x00\x00…        r3 load str located at 4295384328
    call function_26583                     
    ldxdw r2, [r10-0x458]                   
    ldxw r1, [r2+0x0]                       
    mov64 r3, r10                                   r3 = r10
    add64 r3, -760                                  r3 += -760   ///  r3 = r3.wrapping_add(-760 as i32 as i64 as u64)
    jeq r1, 0, lbb_28175                            if r1 == (0 as i32 as i64 as u64) { pc += 39 }
    stxdw [r10-0x438], r3                   
    add64 r2, 4                                     r2 += 4   ///  r2 = r2.wrapping_add(4 as i32 as i64 as u64)
    mov64 r8, r10                                   r8 = r10
    add64 r8, -264                                  r8 += -264   ///  r8 = r8.wrapping_add(-264 as i32 as i64 as u64)
    mov64 r1, r8                                    r1 = r8
    lddw r3, 0x10005fca8 --> b"\x00\x00\x00\x00\x00\x00\x00\x00\x01\x00\x00\x00\x00\x00\x00\x00sdk/src/e…        r3 load str located at 4295359656
    call function_33551                     
    mov64 r9, r10                                   r9 = r10
    add64 r9, -736                                  r9 += -736   ///  r9 = r9.wrapping_add(-736 as i32 as i64 as u64)
    mov64 r1, r9                                    r1 = r9
    mov64 r2, r8                                    r2 = r8
    lddw r3, 0x10005fda8 --> b"\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00AddrNotAv…        r3 load str located at 4295359912
    call function_33537                     
    ldxdw r1, [r10-0x2f0]                   
    stxdw [r10-0x140], r1                   
    ldxdw r1, [r10-0x2f8]                   
    stxdw [r10-0x148], r1                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -264                                  r1 += -264   ///  r1 = r1.wrapping_add(-264 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -328                                  r2 += -328   ///  r2 = r2.wrapping_add(-328 as i32 as i64 as u64)
    mov64 r3, r9                                    r3 = r9
    lddw r4, 0x100061b06 --> b"Applying toxicity fee to base quantity out"        r4 load str located at 4295367430
    mov64 r5, 42                                    r5 = 42 as i32 as i64 as u64
    call function_25589                     
    ldxb r6, [r10-0x108]                    
    jeq r6, 56, lbb_28167                           if r6 == (56 as i32 as i64 as u64) { pc += 1 }
    ja lbb_28638                                    if true { pc += 471 }
lbb_28167:
    ldxdw r1, [r10-0xfc]                    
    stxdw [r10-0x335], r1                   
    ldxdw r2, [r10-0x104]                   
    stxdw [r10-0x33d], r2                   
    ldxdw r3, [r10-0x438]                   
    stxdw [r3+0x8], r1                      
    stxdw [r3+0x0], r2                      
    ldxdw r6, [r10-0x440]                   
lbb_28175:
    ldxw r1, [r10-0x2f8]                    
    lsh64 r1, 32                                    r1 <<= 32   ///  r1 = r1.wrapping_shl(32)
    arsh64 r1, 32                                   r1 >>= 32 (signed)   ///  r1 = (r1 as i64).wrapping_shr(32)
    jsgt r1, -1, lbb_28180                          if (r1 as i64) > (-1 as i32 as i64) { pc += 1 }
    ja lbb_28600                                    if true { pc += 420 }
lbb_28180:
    ldxw r1, [r10-0x2f0]                    
    ldxw r2, [r10-0x2ec]                    
    or64 r2, r1                                     r2 |= r1   ///  r2 = r2.or(r1)
    ldxw r1, [r10-0x2f4]                    
    or64 r2, r1                                     r2 |= r1   ///  r2 = r2.or(r1)
    lsh64 r2, 32                                    r2 <<= 32   ///  r2 = r2.wrapping_shl(32)
    rsh64 r2, 32                                    r2 >>= 32   ///  r2 = r2.wrapping_shr(32)
    jeq r2, 0, lbb_28600                            if r2 == (0 as i32 as i64 as u64) { pc += 412 }
    mov64 r9, r6                                    r9 = r6
    mov64 r8, r10                                   r8 = r10
    add64 r8, -776                                  r8 += -776   ///  r8 = r8.wrapping_add(-776 as i32 as i64 as u64)
    ldxw r1, [r10-0x308]                    
    lsh64 r1, 32                                    r1 <<= 32   ///  r1 = r1.wrapping_shl(32)
    arsh64 r1, 32                                   r1 >>= 32 (signed)   ///  r1 = (r1 as i64).wrapping_shr(32)
    ldxdw r6, [r10-0x430]                   
    jsgt r1, -1, lbb_28197                          if (r1 as i64) > (-1 as i32 as i64) { pc += 1 }
    ja lbb_28659                                    if true { pc += 462 }
lbb_28197:
    ldxw r1, [r10-0x300]                    
    ldxw r2, [r10-0x2fc]                    
    or64 r2, r1                                     r2 |= r1   ///  r2 = r2.or(r1)
    ldxw r1, [r10-0x304]                    
    or64 r2, r1                                     r2 |= r1   ///  r2 = r2.or(r1)
    lsh64 r2, 32                                    r2 <<= 32   ///  r2 = r2.wrapping_shl(32)
    rsh64 r2, 32                                    r2 >>= 32   ///  r2 = r2.wrapping_shr(32)
    jeq r2, 0, lbb_28659                            if r2 == (0 as i32 as i64 as u64) { pc += 454 }
    ldxdw r1, [r8+0x8]                      
    stxdw [r10-0x150], r1                   
    ldxdw r1, [r8+0x0]                      
    stxdw [r10-0x158], r1                   
    ldxdw r1, [r3+0x8]                      
    stxdw [r10-0x140], r1                   
    stxdw [r10-0x438], r3                   
    ldxdw r1, [r3+0x0]                      
    stxdw [r10-0x148], r1                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -264                                  r1 += -264   ///  r1 = r1.wrapping_add(-264 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -344                                  r2 += -344   ///  r2 = r2.wrapping_add(-344 as i32 as i64 as u64)
    mov64 r3, r10                                   r3 = r10
    add64 r3, -328                                  r3 += -328   ///  r3 = r3.wrapping_add(-328 as i32 as i64 as u64)
    lddw r4, 0x100061b30 --> b"Calculating implied price by swap"        r4 load str located at 4295367472
    mov64 r5, 33                                    r5 = 33 as i32 as i64 as u64
    call function_25488                     
    ldxb r6, [r10-0x108]                    
    jeq r6, 56, lbb_28227                           if r6 == (56 as i32 as i64 as u64) { pc += 1 }
    ja lbb_28638                                    if true { pc += 411 }
lbb_28227:
    ldxdw r1, [r10-0xfc]                    
    stxdw [r10-0x258], r1                   
    ldxdw r1, [r10-0x104]                   
    stxdw [r10-0x260], r1                   
    lsh64 r1, 32                                    r1 <<= 32   ///  r1 = r1.wrapping_shl(32)
    arsh64 r1, 32                                   r1 >>= 32 (signed)   ///  r1 = (r1 as i64).wrapping_shr(32)
    jsgt r1, -1, lbb_28235                          if (r1 as i64) > (-1 as i32 as i64) { pc += 1 }
    ja lbb_28702                                    if true { pc += 467 }
lbb_28235:
    ldxw r1, [r10-0x258]                    
    ldxw r2, [r10-0x254]                    
    or64 r2, r1                                     r2 |= r1   ///  r2 = r2.or(r1)
    ldxw r1, [r10-0x25c]                    
    or64 r2, r1                                     r2 |= r1   ///  r2 = r2.or(r1)
    lsh64 r2, 32                                    r2 <<= 32   ///  r2 = r2.wrapping_shl(32)
    rsh64 r2, 32                                    r2 >>= 32   ///  r2 = r2.wrapping_shr(32)
    jeq r2, 0, lbb_28702                            if r2 == (0 as i32 as i64 as u64) { pc += 459 }
    ldxdw r2, [r10-0x438]                   
    ldxdw r1, [r2+0x8]                      
    stxdw [r10-0x338], r1                   
    ldxdw r1, [r2+0x0]                      
    stxdw [r10-0x340], r1                   
    ldxdw r6, [r10-0x460]                   
    ldxb r3, [r6+0x18]                      
    mov64 r1, r10                                   r1 = r10
    add64 r1, -264                                  r1 += -264   ///  r1 = r1.wrapping_add(-264 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -832                                  r2 += -832   ///  r2 = r2.wrapping_add(-832 as i32 as i64 as u64)
    stxdw [r10-0x458], r3                   
    call function_27255                     
    ldxb r1, [r10-0x108]                    
    jeq r1, 56, lbb_28259                           if r1 == (56 as i32 as i64 as u64) { pc += 1 }
    ja lbb_28742                                    if true { pc += 483 }
lbb_28259:
    ldxdw r2, [r10-0x100]                   
    ldxdw r1, [r6+0x10]                     
    jgt r1, r2, lbb_28263                           if r1 > r2 { pc += 1 }
    mov64 r2, r1                                    r2 = r1
lbb_28263:
    mov64 r1, r2                                    r1 = r2
    rsh64 r1, 32                                    r1 >>= 32   ///  r1 = r1.wrapping_shr(32)
    stxw [r10-0x15c], r1                    
    stxdw [r10-0x460], r2                   
    stxw [r10-0x160], r2                    
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    stxdw [r10-0x168], r1                   
    mov64 r2, 10                                    r2 = 10 as i32 as i64 as u64
    stxdw [r10-0x140], r2                   
    stxdw [r10-0x148], r1                   
    mov64 r6, r10                                   r6 = r10
    add64 r6, -344                                  r6 += -344   ///  r6 = r6.wrapping_add(-344 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -328                                  r2 += -328   ///  r2 = r2.wrapping_add(-328 as i32 as i64 as u64)
    mov64 r1, r6                                    r1 = r6
    ldxdw r3, [r10-0x458]                   
    call function_38094                     
    mov64 r1, r10                                   r1 = r10
    add64 r1, -264                                  r1 += -264   ///  r1 = r1.wrapping_add(-264 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -360                                  r2 += -360   ///  r2 = r2.wrapping_add(-360 as i32 as i64 as u64)
    mov64 r3, r6                                    r3 = r6
    lddw r4, 0x100061b51 --> b"Final discretized out decimal for price validation"        r4 load str located at 4295367505
    mov64 r5, 50                                    r5 = 50 as i32 as i64 as u64
    call function_25488                     
    ldxb r6, [r10-0x108]                    
    jeq r6, 56, lbb_28292                           if r6 == (56 as i32 as i64 as u64) { pc += 1 }
    ja lbb_28638                                    if true { pc += 346 }
lbb_28292:
    ldxdw r1, [r10-0x104]                   
    stxdw [r10-0x218], r1                   
    ldxdw r1, [r10-0xfc]                    
    stxdw [r10-0x210], r1                   
    ldxw r2, [r10-0x20c]                    
    or64 r2, r1                                     r2 |= r1   ///  r2 = r2.or(r1)
    ldxw r1, [r10-0x214]                    
    or64 r2, r1                                     r2 |= r1   ///  r2 = r2.or(r1)
    lsh64 r2, 32                                    r2 <<= 32   ///  r2 = r2.wrapping_shl(32)
    rsh64 r2, 32                                    r2 >>= 32   ///  r2 = r2.wrapping_shr(32)
    jeq r2, 0, lbb_28763                            if r2 == (0 as i32 as i64 as u64) { pc += 460 }
    ldxdw r1, [r7+0x8]                      
    stxdw [r10-0x150], r1                   
    ldxdw r1, [r7+0x0]                      
    stxdw [r10-0x158], r1                   
    ldxdw r1, [r10-0x210]                   
    stxdw [r10-0x140], r1                   
    ldxdw r1, [r10-0x218]                   
    stxdw [r10-0x148], r1                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -264                                  r1 += -264   ///  r1 = r1.wrapping_add(-264 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -344                                  r2 += -344   ///  r2 = r2.wrapping_add(-344 as i32 as i64 as u64)
    mov64 r3, r10                                   r3 = r10
    add64 r3, -328                                  r3 += -328   ///  r3 = r3.wrapping_add(-328 as i32 as i64 as u64)
    lddw r4, 0x100061bd4 --> b"Calculating price post discretization"        r4 load str located at 4295367636
    mov64 r5, 37                                    r5 = 37 as i32 as i64 as u64
    call function_25488                     
    ldxb r6, [r10-0x108]                    
    jeq r6, 56, lbb_28324                           if r6 == (56 as i32 as i64 as u64) { pc += 1 }
    ja lbb_28638                                    if true { pc += 314 }
lbb_28324:
    ldxdw r1, [r10-0x104]                   
    stxdw [r10-0x1d0], r1                   
    ldxdw r1, [r10-0xfc]                    
    stxdw [r10-0x1c8], r1                   
    ldxdw r1, [r10-0x258]                   
    stxdw [r10-0x338], r1                   
    ldxdw r1, [r10-0x260]                   
    stxdw [r10-0x340], r1                   
    ldxdw r4, [r7+0x10]                     
    ldxb r1, [r7+0x18]                      
    ldxdw r2, [r10-0x458]                   
    stxdw [r10-0x1000], r2                  
    stxdw [r10-0xff8], r1                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -264                                  r1 += -264   ///  r1 = r1.wrapping_add(-264 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -832                                  r2 += -832   ///  r2 = r2.wrapping_add(-832 as i32 as i64 as u64)
    mov64 r5, r10                                   r5 = r10
    ldxdw r3, [r10-0x460]                   
    call function_27443                     
    ldxb r6, [r10-0x108]                    
    jeq r6, 56, lbb_28347                           if r6 == (56 as i32 as i64 as u64) { pc += 1 }
    ja lbb_28803                                    if true { pc += 456 }
lbb_28347:
    mov64 r1, r10                                   r1 = r10
    add64 r1, -264                                  r1 += -264   ///  r1 = r1.wrapping_add(-264 as i32 as i64 as u64)
    ldxdw r2, [r10-0x448]                   
    mov64 r3, 1                                     r3 = 1 as i32 as i64 as u64
    call function_29099                     
    ldxb r6, [r10-0x108]                    
    jeq r6, 56, lbb_28355                           if r6 == (56 as i32 as i64 as u64) { pc += 1 }
    ja lbb_28638                                    if true { pc += 283 }
lbb_28355:
    ldxdw r1, [r10-0x104]                   
    stxdw [r10-0x1c0], r1                   
    ldxdw r1, [r10-0xfc]                    
    stxdw [r10-0x1b8], r1                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -264                                  r1 += -264   ///  r1 = r1.wrapping_add(-264 as i32 as i64 as u64)
    mov64 r2, r9                                    r2 = r9
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
    call function_29099                     
    ldxb r6, [r10-0x108]                    
    jeq r6, 56, lbb_28367                           if r6 == (56 as i32 as i64 as u64) { pc += 1 }
    ja lbb_28811                                    if true { pc += 444 }
lbb_28367:
    ldxw r7, [r10-0x100]                    
    ldxw r1, [r10-0xfc]                     
    stxdw [r10-0x440], r1                   
    or64 r1, r7                                     r1 |= r7   ///  r1 = r1.or(r7)
    ldxw r9, [r10-0xf8]                     
    or64 r1, r9                                     r1 |= r9   ///  r1 = r1.or(r9)
    lsh64 r1, 32                                    r1 <<= 32   ///  r1 = r1.wrapping_shl(32)
    rsh64 r1, 32                                    r1 >>= 32   ///  r1 = r1.wrapping_shr(32)
    jeq r1, 0, lbb_28828                            if r1 == (0 as i32 as i64 as u64) { pc += 452 }
    ldxw r2, [r10-0x104]                    
    stxw [r10-0x14c], r9                    
    ldxdw r1, [r10-0x440]                   
    stxw [r10-0x150], r1                    
    stxw [r10-0x154], r7                    
    stxdw [r10-0x448], r2                   
    stxw [r10-0x158], r2                    
    ldxdw r1, [r10-0x1b8]                   
    stxdw [r10-0x140], r1                   
    ldxdw r1, [r10-0x1c0]                   
    stxdw [r10-0x148], r1                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -264                                  r1 += -264   ///  r1 = r1.wrapping_add(-264 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -328                                  r2 += -328   ///  r2 = r2.wrapping_add(-328 as i32 as i64 as u64)
    mov64 r3, r10                                   r3 = r10
    add64 r3, -344                                  r3 += -344   ///  r3 = r3.wrapping_add(-344 as i32 as i64 as u64)
    lddw r4, 0x10005feb0 --> b"Calculating implied oracle price"        r4 load str located at 4295360176
    mov64 r5, 32                                    r5 = 32 as i32 as i64 as u64
    call function_25488                     
    ldxb r6, [r10-0x108]                    
    jne r6, 56, lbb_28638                           if r6 != (56 as i32 as i64 as u64) { pc += 239 }
    ldxdw r1, [r10-0x104]                   
    stxdw [r10-0x178], r1                   
    ldxdw r1, [r10-0xfc]                    
    stxdw [r10-0x170], r1                   
    ldxdw r1, [r10-0x258]                   
    stxdw [r10-0x160], r1                   
    ldxdw r1, [r10-0x260]                   
    stxdw [r10-0x168], r1                   
    ldxdw r1, [r10-0x210]                   
    stxdw [r10-0x150], r1                   
    ldxdw r1, [r10-0x218]                   
    stxdw [r10-0x158], r1                   
    ldxdw r1, [r8+0x8]                      
    stxdw [r10-0x140], r1                   
    ldxdw r1, [r8+0x0]                      
    stxdw [r10-0x148], r1                   
    ldxdw r2, [r10-0x438]                   
    ldxdw r1, [r2+0x8]                      
    stxdw [r10-0x338], r1                   
    ldxdw r1, [r2+0x0]                      
    stxdw [r10-0x340], r1                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -328                                  r1 += -328   ///  r1 = r1.wrapping_add(-328 as i32 as i64 as u64)
    stxdw [r10-0xff8], r1                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -832                                  r1 += -832   ///  r1 = r1.wrapping_add(-832 as i32 as i64 as u64)
    stxdw [r10-0xff0], r1                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -344                                  r1 += -344   ///  r1 = r1.wrapping_add(-344 as i32 as i64 as u64)
    stxdw [r10-0x1000], r1                  
    mov64 r1, r10                                   r1 = r10
    add64 r1, -264                                  r1 += -264   ///  r1 = r1.wrapping_add(-264 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -464                                  r2 += -464   ///  r2 = r2.wrapping_add(-464 as i32 as i64 as u64)
    mov64 r3, r10                                   r3 = r10
    add64 r3, -360                                  r3 += -360   ///  r3 = r3.wrapping_add(-360 as i32 as i64 as u64)
    mov64 r5, r10                                   r5 = r10
    ldxdw r4, [r10-0x450]                   
    call function_27738                     
    ldxb r6, [r10-0x108]                    
    jeq r6, 56, lbb_28441                           if r6 == (56 as i32 as i64 as u64) { pc += 1 }
    ja lbb_28803                                    if true { pc += 362 }
lbb_28441:
    ldxdw r1, [r10-0x210]                   
    stxdw [r10-0x140], r1                   
    ldxdw r1, [r10-0x218]                   
    stxdw [r10-0x148], r1                   
    stxw [r10-0x334], r9                    
    ldxdw r1, [r10-0x440]                   
    stxw [r10-0x338], r1                    
    stxw [r10-0x33c], r7                    
    ldxdw r1, [r10-0x448]                   
    stxw [r10-0x340], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -832                                  r1 += -832   ///  r1 = r1.wrapping_add(-832 as i32 as i64 as u64)
    stxdw [r10-0xff8], r1                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -448                                  r1 += -448   ///  r1 = r1.wrapping_add(-448 as i32 as i64 as u64)
    stxdw [r10-0xff0], r1                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -328                                  r1 += -328   ///  r1 = r1.wrapping_add(-328 as i32 as i64 as u64)
    stxdw [r10-0x1000], r1                  
    mov64 r1, r10                                   r1 = r10
    add64 r1, -264                                  r1 += -264   ///  r1 = r1.wrapping_add(-264 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -464                                  r2 += -464   ///  r2 = r2.wrapping_add(-464 as i32 as i64 as u64)
    mov64 r3, r10                                   r3 = r10
    add64 r3, -376                                  r3 += -376   ///  r3 = r3.wrapping_add(-376 as i32 as i64 as u64)
    mov64 r5, r10                                   r5 = r10
    ldxdw r4, [r10-0x450]                   
    call function_27859                     
    ldxb r6, [r10-0x108]                    
    jeq r6, 56, lbb_28472                           if r6 == (56 as i32 as i64 as u64) { pc += 1 }
    ja lbb_28803                                    if true { pc += 331 }
lbb_28472:
    ldxdw r1, [r10-0x210]                   
    ldxdw r5, [r10-0x430]                   
    stxdw [r5+0x30], r1                     
    ldxdw r1, [r10-0x218]                   
    stxdw [r5+0x28], r1                     
    ldxdw r1, [r10-0x310]                   
    ldxb r2, [r10-0x2e8]                    
    ldxdw r3, [r10-0x320]                   
    ldxdw r4, [r10-0x318]                   
    ldxdw r0, [r10-0x460]                   
    stxdw [r5+0x20], r0                     
    stxdw [r5+0x10], r4                     
    stxdw [r5+0x8], r3                      
    mov64 r3, 56                                    r3 = 56 as i32 as i64 as u64
    stxb [r5+0x0], r3                       
    stxb [r5+0x38], r2                      
    stxdw [r5+0x18], r1                     
    ja lbb_28599                                    if true { pc += 109 }
lbb_28490:
    stxdw [r10-0x378], r1                   
    lddw r1, 0x100065d90 --> b"\x00\x00\x00\x00\x02\x1d\x06\x00@\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00…        r1 load str located at 4295384464
    stxdw [r10-0x398], r1                   
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    stxdw [r10-0x390], r1                   
    stxdw [r10-0x380], r1                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -1008                                 r1 += -1008   ///  r1 = r1.wrapping_add(-1008 as i32 as i64 as u64)
    stxdw [r10-0x388], r1                   
    lddw r1, 0x100042518 --> b"\x85\x10\x00\x00~\xff\xff\xff\x95\x00\x00\x00\x00\x00\x00\x00\xbf#\x00\x0…        r1 load str located at 4295238936
    stxdw [r10-0x3e8], r1                   
    stxdw [r10-0x3f0], r0                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -1032                                 r1 += -1032   ///  r1 = r1.wrapping_add(-1032 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -920                                  r2 += -920   ///  r2 = r2.wrapping_add(-920 as i32 as i64 as u64)
    call function_43415                     
    ldxdw r1, [r10-0x408]                   
    stxdw [r10-0x420], r1                   
    ldxdw r1, [r10-0x400]                   
    stxdw [r10-0x418], r1                   
    ldxdw r1, [r10-0x3f8]                   
    stxdw [r10-0x410], r1                   
    mov64 r1, 29                                    r1 = 29 as i32 as i64 as u64
    stxb [r6+0x0], r1                       
    ldxdw r1, [r10-0x427]                   
    stxdw [r6+0x1], r1                      
    ldxdw r1, [r10-0x41f]                   
    stxdw [r6+0x9], r1                      
    ldxdw r1, [r10-0x417]                   
    stxdw [r6+0x11], r1                     
    ldxdw r1, [r10-0x410]                   
    stxdw [r6+0x18], r1                     
    ja lbb_28599                                    if true { pc += 73 }
lbb_28526:
    ldxdw r2, [r10-0x384]                   
    stxdw [r10-0x108], r2                   
    stxdw [r10-0x320], r2                   
    ldxdw r2, [r10-0x37c]                   
    stxdw [r10-0x318], r2                   
    ldxdw r2, [r10-0x374]                   
    stxdw [r10-0x310], r2                   
    ldxw r2, [r10-0x36c]                    
    stxw [r10-0x308], r2                    
    ldxw r2, [r10-0x397]                    
    ldxb r3, [r10-0x391]                    
    ldxh r4, [r10-0x393]                    
    ldxdw r1, [r10-0x390]                   
    stxdw [r10-0x438], r1                   
    ldxw r1, [r10-0x388]                    
    stxdw [r10-0x440], r1                   
    ldxw r6, [r10-0x368]                    
    ldxdw r7, [r10-0x364]                   
    ldxw r8, [r10-0x35c]                    
    ldxdw r9, [r10-0x358]                   
    ldxw r5, [r10-0x308]                    
    ldxdw r1, [r10-0x430]                   
    stxw [r1+0x2c], r5                      
    ldxdw r5, [r10-0x310]                   
    stxdw [r1+0x24], r5                     
    ldxdw r5, [r10-0x318]                   
    stxdw [r1+0x1c], r5                     
    ldxdw r5, [r10-0x320]                   
    ja lbb_28583                                    if true { pc += 28 }
lbb_28555:
    ldxdw r2, [r10-0xf4]                    
    stxdw [r10-0x320], r2                   
    stxdw [r10-0x340], r2                   
    ldxdw r2, [r10-0xec]                    
    stxdw [r10-0x338], r2                   
    ldxdw r2, [r10-0xe4]                    
    stxdw [r10-0x330], r2                   
    ldxw r2, [r10-0xdc]                     
    stxw [r10-0x328], r2                    
    ldxw r2, [r10-0x107]                    
    ldxb r3, [r10-0x101]                    
    ldxh r4, [r10-0x103]                    
    ldxdw r1, [r10-0x100]                   
    stxdw [r10-0x438], r1                   
    ldxw r1, [r10-0xf8]                     
    stxdw [r10-0x440], r1                   
    ldxw r6, [r10-0xd8]                     
    ldxdw r7, [r10-0xd4]                    
    ldxw r8, [r10-0xcc]                     
    ldxdw r9, [r10-0xc8]                    
    ldxw r5, [r10-0x328]                    
    ldxdw r1, [r10-0x430]                   
    stxw [r1+0x2c], r5                      
    ldxdw r5, [r10-0x330]                   
    stxdw [r1+0x24], r5                     
    ldxdw r5, [r10-0x338]                   
    stxdw [r1+0x1c], r5                     
    ldxdw r5, [r10-0x340]                   
lbb_28583:
    stxdw [r1+0x14], r5                     
    stxdw [r1+0x40], r9                     
    stxw [r1+0x3c], r8                      
    stxdw [r1+0x34], r7                     
    stxw [r1+0x30], r6                      
    ldxdw r5, [r10-0x440]                   
    stxw [r1+0x10], r5                      
    ldxdw r5, [r10-0x438]                   
    stxdw [r1+0x8], r5                      
    lsh64 r4, 32                                    r4 <<= 32   ///  r4 = r4.wrapping_shl(32)
    lsh64 r3, 48                                    r3 <<= 48   ///  r3 = r3.wrapping_shl(48)
    or64 r3, r4                                     r3 |= r4   ///  r3 = r3.or(r4)
    or64 r2, r3                                     r2 |= r3   ///  r2 = r2.or(r3)
    lsh64 r2, 8                                     r2 <<= 8   ///  r2 = r2.wrapping_shl(8)
    or64 r2, r0                                     r2 |= r0   ///  r2 = r2.or(r0)
    stxdw [r1+0x0], r2                      
lbb_28599:
    exit                                    
lbb_28600:
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    stxdw [r10-0xe8], r1                    
    lddw r1, 0x100065d80 --> b"\x00\x00\x00\x00\xc1\x1c\x06\x00A\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00…        r1 load str located at 4295384448
    stxdw [r10-0x108], r1                   
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    stxdw [r10-0x100], r1                   
    stxdw [r10-0xf0], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -832                                  r1 += -832   ///  r1 = r1.wrapping_add(-832 as i32 as i64 as u64)
    stxdw [r10-0xf8], r1                    
    lddw r1, 0x100042518 --> b"\x85\x10\x00\x00~\xff\xff\xff\x95\x00\x00\x00\x00\x00\x00\x00\xbf#\x00\x0…        r1 load str located at 4295238936
    stxdw [r10-0x338], r1                   
    stxdw [r10-0x340], r3                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -688                                  r1 += -688   ///  r1 = r1.wrapping_add(-688 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -264                                  r2 += -264   ///  r2 = r2.wrapping_add(-264 as i32 as i64 as u64)
    call function_43415                     
    ldxdw r1, [r10-0x2b0]                   
    stxdw [r10-0x2c8], r1                   
    ldxdw r1, [r10-0x2a8]                   
    stxdw [r10-0x2c0], r1                   
    ldxdw r1, [r10-0x2a0]                   
    stxdw [r10-0x2b8], r1                   
    mov64 r1, 29                                    r1 = 29 as i32 as i64 as u64
    ldxdw r2, [r10-0x430]                   
    stxb [r2+0x0], r1                       
    ldxdw r1, [r10-0x2cf]                   
    stxdw [r2+0x1], r1                      
    ldxdw r1, [r10-0x2c7]                   
    stxdw [r2+0x9], r1                      
    ldxdw r1, [r10-0x2bf]                   
    stxdw [r2+0x11], r1                     
    ldxdw r1, [r10-0x2b8]                   
    stxdw [r2+0x18], r1                     
    ja lbb_28695                                    if true { pc += 57 }
lbb_28638:
    ldxw r1, [r10-0xf8]                     
    stxw [r10-0x331], r1                    
    ldxdw r1, [r10-0xff]                    
    stxdw [r10-0x338], r1                   
    ldxdw r1, [r10-0x107]                   
    stxdw [r10-0x340], r1                   
    ldxdw r7, [r10-0x430]                   
    mov64 r1, r7                                    r1 = r7
    add64 r1, 20                                    r1 += 20   ///  r1 = r1.wrapping_add(20 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -244                                  r2 += -244   ///  r2 = r2.wrapping_add(-244 as i32 as i64 as u64)
    mov64 r3, 52                                    r3 = 52 as i32 as i64 as u64
    call function_48190                     
    ldxw r1, [r10-0x331]                    
    stxw [r7+0x10], r1                      
    ldxdw r1, [r10-0x338]                   
    stxdw [r7+0x9], r1                      
    ldxdw r1, [r10-0x340]                   
    stxdw [r7+0x1], r1                      
lbb_28657:
    stxb [r7+0x0], r6                       
    ja lbb_28695                                    if true { pc += 36 }
lbb_28659:
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    stxdw [r10-0xe8], r1                    
    lddw r1, 0x100065d70 --> b"\x00\x00\x00\x00\x80\x1c\x06\x00A\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00…        r1 load str located at 4295384432
    stxdw [r10-0x108], r1                   
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    stxdw [r10-0x100], r1                   
    stxdw [r10-0xf0], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -832                                  r1 += -832   ///  r1 = r1.wrapping_add(-832 as i32 as i64 as u64)
    stxdw [r10-0xf8], r1                    
    lddw r1, 0x100042518 --> b"\x85\x10\x00\x00~\xff\xff\xff\x95\x00\x00\x00\x00\x00\x00\x00\xbf#\x00\x0…        r1 load str located at 4295238936
    stxdw [r10-0x338], r1                   
    stxdw [r10-0x340], r8                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -632                                  r1 += -632   ///  r1 = r1.wrapping_add(-632 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -264                                  r2 += -264   ///  r2 = r2.wrapping_add(-264 as i32 as i64 as u64)
    call function_21823                     
    ldxdw r1, [r10-0x278]                   
    stxdw [r10-0x290], r1                   
    ldxdw r1, [r10-0x270]                   
    stxdw [r10-0x288], r1                   
    ldxdw r1, [r10-0x268]                   
    stxdw [r10-0x280], r1                   
    mov64 r1, 29                                    r1 = 29 as i32 as i64 as u64
    stxb [r6+0x0], r1                       
    ldxdw r1, [r10-0x297]                   
    stxdw [r6+0x1], r1                      
    ldxdw r1, [r10-0x28f]                   
    stxdw [r6+0x9], r1                      
    ldxdw r1, [r10-0x287]                   
    stxdw [r6+0x11], r1                     
    ldxdw r1, [r10-0x280]                   
    stxdw [r6+0x18], r1                     
lbb_28695:
    ldxdw r2, [r10-0x318]                   
    jeq r2, 0, lbb_28599                            if r2 == (0 as i32 as i64 as u64) { pc += -98 }
    mul64 r2, 40                                    r2 *= 40   ///  r2 = r2.wrapping_mul(40 as u64)
    ldxdw r1, [r10-0x320]                   
    mov64 r3, 4                                     r3 = 4 as i32 as i64 as u64
    call function_21385                     
    ja lbb_28599                                    if true { pc += -103 }
lbb_28702:
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    stxdw [r10-0xe8], r1                    
    lddw r1, 0x100065d60 --> b"\x00\x00\x00\x00?\x1c\x06\x00A\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x0…        r1 load str located at 4295384416
    stxdw [r10-0x108], r1                   
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    stxdw [r10-0x100], r1                   
    stxdw [r10-0xf0], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -832                                  r1 += -832   ///  r1 = r1.wrapping_add(-832 as i32 as i64 as u64)
    stxdw [r10-0xf8], r1                    
    lddw r1, 0x100042518 --> b"\x85\x10\x00\x00~\xff\xff\xff\x95\x00\x00\x00\x00\x00\x00\x00\xbf#\x00\x0…        r1 load str located at 4295238936
    stxdw [r10-0x338], r1                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -608                                  r1 += -608   ///  r1 = r1.wrapping_add(-608 as i32 as i64 as u64)
    stxdw [r10-0x340], r1                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -560                                  r1 += -560   ///  r1 = r1.wrapping_add(-560 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -264                                  r2 += -264   ///  r2 = r2.wrapping_add(-264 as i32 as i64 as u64)
    call function_21823                     
    ldxdw r1, [r10-0x230]                   
    stxdw [r10-0x248], r1                   
    ldxdw r1, [r10-0x228]                   
    stxdw [r10-0x240], r1                   
    ldxdw r1, [r10-0x220]                   
    stxdw [r10-0x238], r1                   
    mov64 r1, 29                                    r1 = 29 as i32 as i64 as u64
    ldxdw r2, [r10-0x430]                   
    stxb [r2+0x0], r1                       
    ldxdw r1, [r10-0x24f]                   
    stxdw [r2+0x1], r1                      
    ldxdw r1, [r10-0x247]                   
    stxdw [r2+0x9], r1                      
    ldxdw r1, [r10-0x23f]                   
    stxdw [r2+0x11], r1                     
    ldxdw r1, [r10-0x238]                   
    stxdw [r2+0x18], r1                     
    ja lbb_28695                                    if true { pc += -47 }
lbb_28742:
    mov64 r6, r1                                    r6 = r1
    ldxw r1, [r10-0x104]                    
    ldxdw r7, [r10-0x430]                   
    stxw [r7+0x4], r1                       
    ldxw r1, [r10-0x107]                    
    stxw [r7+0x1], r1                       
    ldxdw r1, [r10-0x100]                   
    stxdw [r10-0x438], r1                   
    ldxdw r8, [r10-0xf8]                    
    ldxdw r9, [r10-0xf0]                    
    mov64 r1, r7                                    r1 = r7
    add64 r1, 32                                    r1 += 32   ///  r1 = r1.wrapping_add(32 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -232                                  r2 += -232   ///  r2 = r2.wrapping_add(-232 as i32 as i64 as u64)
    mov64 r3, 40                                    r3 = 40 as i32 as i64 as u64
    call function_48190                     
    stxdw [r7+0x18], r9                     
    stxdw [r7+0x10], r8                     
    ldxdw r1, [r10-0x438]                   
    stxdw [r7+0x8], r1                      
    ja lbb_28657                                    if true { pc += -106 }
lbb_28763:
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    stxdw [r10-0xe8], r1                    
    lddw r1, 0x100065d40 --> b"\x00\x00\x00\x00\x83\x1b\x06\x00Q\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00…        r1 load str located at 4295384384
    stxdw [r10-0x108], r1                   
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    stxdw [r10-0x100], r1                   
    stxdw [r10-0xf0], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -832                                  r1 += -832   ///  r1 = r1.wrapping_add(-832 as i32 as i64 as u64)
    stxdw [r10-0xf8], r1                    
    lddw r1, 0x100042518 --> b"\x85\x10\x00\x00~\xff\xff\xff\x95\x00\x00\x00\x00\x00\x00\x00\xbf#\x00\x0…        r1 load str located at 4295238936
    stxdw [r10-0x338], r1                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -536                                  r1 += -536   ///  r1 = r1.wrapping_add(-536 as i32 as i64 as u64)
    stxdw [r10-0x340], r1                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -488                                  r1 += -488   ///  r1 = r1.wrapping_add(-488 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -264                                  r2 += -264   ///  r2 = r2.wrapping_add(-264 as i32 as i64 as u64)
    call function_21823                     
    ldxdw r1, [r10-0x1e8]                   
    stxdw [r10-0x200], r1                   
    ldxdw r1, [r10-0x1e0]                   
    stxdw [r10-0x1f8], r1                   
    ldxdw r1, [r10-0x1d8]                   
    stxdw [r10-0x1f0], r1                   
    mov64 r1, 29                                    r1 = 29 as i32 as i64 as u64
    ldxdw r2, [r10-0x430]                   
    stxb [r2+0x0], r1                       
    ldxdw r1, [r10-0x207]                   
    stxdw [r2+0x1], r1                      
    ldxdw r1, [r10-0x1ff]                   
    stxdw [r2+0x9], r1                      
    ldxdw r1, [r10-0x1f7]                   
    stxdw [r2+0x11], r1                     
    ldxdw r1, [r10-0x1f0]                   
    stxdw [r2+0x18], r1                     
    ja lbb_28695                                    if true { pc += -108 }
lbb_28803:
    ldxdw r7, [r10-0x430]                   
    mov64 r1, r7                                    r1 = r7
    add64 r1, 1                                     r1 += 1   ///  r1 = r1.wrapping_add(1 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -263                                  r2 += -263   ///  r2 = r2.wrapping_add(-263 as i32 as i64 as u64)
    mov64 r3, 71                                    r3 = 71 as i32 as i64 as u64
    call function_48190                     
    ja lbb_28657                                    if true { pc += -154 }
lbb_28811:
    ldxb r1, [r10-0x105]                    
    ldxdw r9, [r10-0x430]                   
    stxb [r9+0x3], r1                       
    ldxh r1, [r10-0x107]                    
    stxh [r9+0x1], r1                       
    ldxdw r7, [r10-0x104]                   
    ldxdw r8, [r10-0xfc]                    
    mov64 r1, r9                                    r1 = r9
    add64 r1, 20                                    r1 += 20   ///  r1 = r1.wrapping_add(20 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -244                                  r2 += -244   ///  r2 = r2.wrapping_add(-244 as i32 as i64 as u64)
    mov64 r3, 52                                    r3 = 52 as i32 as i64 as u64
    call function_48190                     
    stxdw [r9+0xc], r8                      
    stxdw [r9+0x4], r7                      
    stxb [r9+0x0], r6                       
    ja lbb_28695                                    if true { pc += -133 }
lbb_28828:
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    stxdw [r10-0x100], r1                   
    lddw r1, 0x100065d50 --> b"\x00\x00\x00\x00\xf9\x1b\x06\x00F\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00…        r1 load str located at 4295384400
    stxdw [r10-0x108], r1                   
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    stxdw [r10-0xe8], r1                    
    stxdw [r10-0xf0], r1                    
    lddw r1, 0x100060ee8 --> b"src/arithmetic_impls.rsAddition overflowedMultipli"        r1 load str located at 4295364328
    stxdw [r10-0xf8], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -400                                  r1 += -400   ///  r1 = r1.wrapping_add(-400 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -264                                  r2 += -264   ///  r2 = r2.wrapping_add(-264 as i32 as i64 as u64)
    call function_21823                     
    ldxdw r1, [r10-0x190]                   
    stxdw [r10-0x1a8], r1                   
    ldxdw r1, [r10-0x188]                   
    stxdw [r10-0x1a0], r1                   
    ldxdw r1, [r10-0x180]                   
    stxdw [r10-0x198], r1                   
    mov64 r1, 29                                    r1 = 29 as i32 as i64 as u64
    ldxdw r2, [r10-0x430]                   
    stxb [r2+0x0], r1                       
    ldxdw r1, [r10-0x1af]                   
    stxdw [r2+0x1], r1                      
    ldxdw r1, [r10-0x1a7]                   
    stxdw [r2+0x9], r1                      
    ldxdw r1, [r10-0x19f]                   
    stxdw [r2+0x11], r1                     
    ldxdw r1, [r10-0x198]                   
    stxdw [r2+0x18], r1                     
    ja lbb_28695                                    if true { pc += -167 }

function_28862:
    mov64 r8, r5                                    r8 = r5
    stxdw [r10-0x130], r4                   
    stxdw [r10-0x138], r3                   
    stxdw [r10-0x140], r2                   
    mov64 r6, r1                                    r6 = r1
    ldxdw r7, [r8-0xff8]                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -232                                  r1 += -232   ///  r1 = r1.wrapping_add(-232 as i32 as i64 as u64)
    lddw r2, 0x100061d42 --> b"\x09\xe2`;\xf3BB\x97M\xa2G\xed\x93.\x13\xc3grd)e2i\x15\xbc\xa8\xa7\xf5"\x…        r2 load str located at 4295368002
    mov64 r3, r7                                    r3 = r7
    lddw r4, 0x100061d82 --> b"Invalid quote program ID"        r4 load str located at 4295368066
    mov64 r5, 24                                    r5 = 24 as i32 as i64 as u64
    call function_30095                     
    ldxb r9, [r10-0xe8]                     
    jne r9, 56, lbb_28939                           if r9 != (56 as i32 as i64 as u64) { pc += 60 }
    stxdw [r10-0x148], r6                   
    ldxdw r1, [r8-0x1000]                   
    mov64 r2, 1                                     r2 = 1 as i32 as i64 as u64
    stxdw [r10-0x40], r2                    
    mov64 r2, r10                                   r2 = r10
    add64 r2, -56                                   r2 += -56   ///  r2 = r2.wrapping_add(-56 as i32 as i64 as u64)
    stxdw [r10-0x48], r2                    
    ldxdw r9, [r10-0x130]                   
    stxdw [r10-0x58], r9                    
    mov64 r2, 32                                    r2 = 32 as i32 as i64 as u64
    stxdw [r10-0x50], r2                    
    stxdw [r10-0x60], r2                    
    ldxdw r6, [r10-0x138]                   
    stxdw [r10-0x68], r6                    
    mov64 r2, 5                                     r2 = 5 as i32 as i64 as u64
    stxdw [r10-0x70], r2                    
    lddw r2, 0x100061d9a --> b"quoteCould not derive Quote PDA from seeds and bum"        r2 load str located at 4295368090
    stxdw [r10-0x78], r2                    
    stxb [r10-0x38], r1                     
    mov64 r8, r10                                   r8 = r10
    add64 r8, -160                                  r8 += -160   ///  r8 = r8.wrapping_add(-160 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -120                                  r2 += -120   ///  r2 = r2.wrapping_add(-120 as i32 as i64 as u64)
    mov64 r1, r8                                    r1 = r8
    mov64 r3, 4                                     r3 = 4 as i32 as i64 as u64
    mov64 r4, r7                                    r4 = r7
    call function_40888                     
    lddw r1, 0x100061d9f --> b"Could not derive Quote PDA from seeds and bumpQuot"        r1 load str located at 4295368095
    stxdw [r10-0x1000], r1                  
    mov64 r1, 46                                    r1 = 46 as i32 as i64 as u64
    stxdw [r10-0xff8], r1                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -232                                  r1 += -232   ///  r1 = r1.wrapping_add(-232 as i32 as i64 as u64)
    mov64 r5, r10                                   r5 = r10
    mov64 r2, r8                                    r2 = r8
    lddw r3, 0x100061d9f --> b"Could not derive Quote PDA from seeds and bump"        r3 load str located at 4295368095
    mov64 r4, 46                                    r4 = 46 as i32 as i64 as u64
    call function_25690                     
    ldxb r7, [r10-0xe8]                     
    jeq r7, 56, lbb_28923                           if r7 == (56 as i32 as i64 as u64) { pc += 1 }
    ja lbb_28947                                    if true { pc += 24 }
lbb_28923:
    ldxdw r1, [r10-0xdf]                    
    stxdw [r10-0x100], r1                   
    stxdw [r10-0x120], r1                   
    ldxdw r1, [r10-0xd7]                    
    stxdw [r10-0xf8], r1                    
    stxdw [r10-0x118], r1                   
    ldxdw r1, [r10-0xcf]                    
    stxdw [r10-0xf0], r1                    
    stxdw [r10-0x110], r1                   
    ldxdw r1, [r10-0xe7]                    
    stxdw [r10-0x128], r1                   
    ldxdw r3, [r10-0x140]                   
    ldxdw r2, [r3+0x0]                      
    jeq r2, r1, lbb_28972                           if r2 == r1 { pc += 35 }
lbb_28937:
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    ja lbb_28982                                    if true { pc += 43 }
lbb_28939:
    mov64 r1, r6                                    r1 = r6
    add64 r1, 1                                     r1 += 1   ///  r1 = r1.wrapping_add(1 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -231                                  r2 += -231   ///  r2 = r2.wrapping_add(-231 as i32 as i64 as u64)
    mov64 r3, 71                                    r3 = 71 as i32 as i64 as u64
    call function_48190                     
    stxb [r6+0x0], r9                       
    ja lbb_29098                                    if true { pc += 151 }
lbb_28947:
    ldxdw r1, [r10-0xcf]                    
    stxdw [r10-0xf0], r1                    
    ldxdw r1, [r10-0xd7]                    
    stxdw [r10-0xf8], r1                    
    ldxdw r1, [r10-0xdf]                    
    stxdw [r10-0x100], r1                   
    ldxdw r1, [r10-0xe7]                    
    stxdw [r10-0x108], r1                   
    ldxdw r6, [r10-0x148]                   
    mov64 r1, r6                                    r1 = r6
    add64 r1, 33                                    r1 += 33   ///  r1 = r1.wrapping_add(33 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -199                                  r2 += -199   ///  r2 = r2.wrapping_add(-199 as i32 as i64 as u64)
    mov64 r3, 39                                    r3 = 39 as i32 as i64 as u64
    call function_48190                     
    ldxdw r1, [r10-0xf0]                    
    stxdw [r6+0x19], r1                     
    ldxdw r1, [r10-0xf8]                    
    stxdw [r6+0x11], r1                     
    ldxdw r1, [r10-0x100]                   
    stxdw [r6+0x9], r1                      
    ldxdw r1, [r10-0x108]                   
    stxdw [r6+0x1], r1                      
    stxb [r6+0x0], r7                       
    ja lbb_29098                                    if true { pc += 126 }
lbb_28972:
    ldxdw r1, [r3+0x8]                      
    ldxdw r2, [r10-0x120]                   
    jne r1, r2, lbb_28937                           if r1 != r2 { pc += -38 }
    ldxdw r1, [r3+0x10]                     
    ldxdw r2, [r10-0x118]                   
    jne r1, r2, lbb_28937                           if r1 != r2 { pc += -41 }
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    ldxdw r2, [r3+0x18]                     
    ldxdw r3, [r10-0x110]                   
    jne r2, r3, lbb_28937                           if r2 != r3 { pc += -45 }
lbb_28982:
    mov64 r2, 87                                    r2 = 87 as i32 as i64 as u64
    stxdw [r10-0x100], r2                   
    lddw r2, 0x100061dcd --> b"Quote PDA mismatch: The provided Quote PDA does no"        r2 load str located at 4295368141
    stxdw [r10-0x108], r2                   
    jeq r1, 0, lbb_29095                            if r1 == (0 as i32 as i64 as u64) { pc += 107 }
    lddw r1, 0x100065da0 --> b"\x00\x00\x00\x00$\x1e\x06\x00\x1d\x00\x00\x00\x00\x00\x00\x003\x00\x00\x0…        r1 load str located at 4295384480
    stxdw [r10-0x38], r1                    
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    stxdw [r10-0xc8], r1                    
    lddw r1, 0x100065a98 --> b"\x00\x00\x00\x00\xe8\x0e\x06\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\…        r1 load str located at 4295383704
    stxdw [r10-0xe8], r1                    
    mov64 r1, 2                                     r1 = 2 as i32 as i64 as u64
    stxdw [r10-0xe0], r1                    
    stxdw [r10-0xd0], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -120                                  r1 += -120   ///  r1 = r1.wrapping_add(-120 as i32 as i64 as u64)
    stxdw [r10-0xd8], r1                    
    lddw r1, 0x10002a248 --> b"y\x11\x00\x00\x00\x00\x00\x00\x85\x10\x00\x00%X\x00\x00\x95\x00\x00\x00\x…        r1 load str located at 4295139912
    stxdw [r10-0x60], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -56                                   r1 += -56   ///  r1 = r1.wrapping_add(-56 as i32 as i64 as u64)
    stxdw [r10-0x68], r1                    
    lddw r1, 0x10002a388 --> b"\xbf#\x00\x00\x00\x00\x00\x00y\x12\x08\x00\x00\x00\x00\x00y\x11\x00\x00\x…        r1 load str located at 4295140232
    stxdw [r10-0x70], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -264                                  r1 += -264   ///  r1 = r1.wrapping_add(-264 as i32 as i64 as u64)
    stxdw [r10-0x78], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -160                                  r1 += -160   ///  r1 = r1.wrapping_add(-160 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -232                                  r2 += -232   ///  r2 = r2.wrapping_add(-232 as i32 as i64 as u64)
    call function_43415                     
    ldxdw r7, [r10-0x98]                    
    ldxdw r8, [r10-0xa0]                    
    ldxdw r2, [r10-0x90]                    
    mov64 r1, r8                                    r1 = r8
    syscall [invalid]                       
    jeq r7, 0, lbb_29029                            if r7 == (0 as i32 as i64 as u64) { pc += 4 }
    mov64 r1, r8                                    r1 = r8
    mov64 r2, r7                                    r2 = r7
    mov64 r3, 1                                     r3 = 1 as i32 as i64 as u64
    call function_21385                     
lbb_29029:
    mov64 r1, 32                                    r1 = 32 as i32 as i64 as u64
    mov64 r2, 1                                     r2 = 1 as i32 as i64 as u64
    call function_21359                     
    mov64 r7, r0                                    r7 = r0
    jne r7, 0, lbb_29038                            if r7 != (0 as i32 as i64 as u64) { pc += 4 }
lbb_29034:
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    mov64 r2, 32                                    r2 = 32 as i32 as i64 as u64
    call function_43400                     
    syscall [invalid]                       
lbb_29038:
    ldxdw r1, [r9+0x18]                     
    stxdw [r7+0x18], r1                     
    ldxdw r1, [r9+0x10]                     
    stxdw [r7+0x10], r1                     
    ldxdw r1, [r9+0x8]                      
    stxdw [r7+0x8], r1                      
    ldxdw r1, [r9+0x0]                      
    stxdw [r7+0x0], r1                      
    mov64 r1, 32                                    r1 = 32 as i32 as i64 as u64
    mov64 r2, 1                                     r2 = 1 as i32 as i64 as u64
    call function_21359                     
    mov64 r9, r0                                    r9 = r0
    jne r9, 0, lbb_29052                            if r9 != (0 as i32 as i64 as u64) { pc += 1 }
    ja lbb_29034                                    if true { pc += -18 }
lbb_29052:
    ldxdw r1, [r6+0x18]                     
    stxdw [r9+0x18], r1                     
    ldxdw r1, [r6+0x10]                     
    stxdw [r9+0x10], r1                     
    ldxdw r1, [r6+0x8]                      
    stxdw [r9+0x8], r1                      
    ldxdw r1, [r6+0x0]                      
    stxdw [r9+0x0], r1                      
    mov64 r1, 32                                    r1 = 32 as i32 as i64 as u64
    mov64 r2, 1                                     r2 = 1 as i32 as i64 as u64
    call function_21359                     
    mov64 r8, r0                                    r8 = r0
    jne r8, 0, lbb_29066                            if r8 != (0 as i32 as i64 as u64) { pc += 1 }
    ja lbb_29034                                    if true { pc += -32 }
lbb_29066:
    ldxdw r2, [r10-0x140]                   
    ldxdw r1, [r2+0x18]                     
    stxdw [r8+0x18], r1                     
    ldxdw r1, [r2+0x10]                     
    stxdw [r8+0x10], r1                     
    ldxdw r1, [r2+0x8]                      
    stxdw [r8+0x8], r1                      
    ldxdw r1, [r2+0x0]                      
    stxdw [r8+0x0], r1                      
    mov64 r1, 32                                    r1 = 32 as i32 as i64 as u64
    mov64 r2, 1                                     r2 = 1 as i32 as i64 as u64
    call function_21359                     
    ldxdw r2, [r10-0x148]                   
    jne r0, 0, lbb_29081                            if r0 != (0 as i32 as i64 as u64) { pc += 1 }
    ja lbb_29034                                    if true { pc += -47 }
lbb_29081:
    ldxdw r1, [r10-0x110]                   
    stxdw [r0+0x18], r1                     
    ldxdw r1, [r10-0x118]                   
    stxdw [r0+0x10], r1                     
    ldxdw r1, [r10-0x120]                   
    stxdw [r0+0x8], r1                      
    ldxdw r1, [r10-0x128]                   
    stxdw [r0+0x0], r1                      
    stxdw [r2+0x20], r0                     
    stxdw [r2+0x18], r8                     
    stxdw [r2+0x10], r9                     
    stxdw [r2+0x8], r7                      
    mov64 r1, 10                                    r1 = 10 as i32 as i64 as u64
    ja lbb_29097                                    if true { pc += 2 }
lbb_29095:
    mov64 r1, 56                                    r1 = 56 as i32 as i64 as u64
    ldxdw r2, [r10-0x148]                   
lbb_29097:
    stxb [r2+0x0], r1                       
lbb_29098:
    exit                                    

function_29099:
    ldxdw r7, [r2+0x0]                      
    mov64 r9, r7                                    r9 = r7
    rsh64 r9, 28                                    r9 >>= 28   ///  r9 = r9.wrapping_shr(28)
    jne r3, 0, lbb_29104                            if r3 != (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r9, r7                                    r9 = r7
lbb_29104:
    and64 r9, 268435455                             r9 &= 268435455   ///  r9 = r9.and(268435455)
    jne r9, 0, lbb_29119                            if r9 != (0 as i32 as i64 as u64) { pc += 13 }
    lddw r4, 0x100061e44 --> b"offerInsane error converting price to decimalsdk/s"        r4 load str located at 4295368260
    jne r3, 0, lbb_29111                            if r3 != (0 as i32 as i64 as u64) { pc += 2 }
    lddw r4, 0x100061e41 --> b"bidof"               r4 load str located at 4295368257
lbb_29111:
    mov64 r2, 5                                     r2 = 5 as i32 as i64 as u64
    jne r3, 0, lbb_29114                            if r3 != (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r2, 3                                     r2 = 3 as i32 as i64 as u64
lbb_29114:
    mov64 r3, 52                                    r3 = 52 as i32 as i64 as u64
    stxb [r1+0x0], r3                       
    stxdw [r1+0x10], r2                     
    stxdw [r1+0x8], r4                      
    ja lbb_29220                                    if true { pc += 101 }
lbb_29119:
    stxdw [r10-0x60], r1                    
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
    mov64 r1, r7                                    r1 = r7
    rsh64 r1, 56                                    r1 >>= 56   ///  r1 = r1.wrapping_shr(56)
    stxdw [r10-0x58], r1                    
    arsh64 r7, 56                                   r7 >>= 56 (signed)   ///  r7 = (r7 as i64).wrapping_shr(56)
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    mov64 r2, r9                                    r2 = r9
    jsgt r1, r7, lbb_29152                          if (r1 as i64) > (r7 as i64) { pc += 24 }
    mov64 r6, 0                                     r6 = 0 as i32 as i64 as u64
    lddw r8, 0xff00000000000000                     r8 load str located at -72057594037927936
    mov64 r2, r9                                    r2 = r9
    ldxdw r7, [r10-0x58]                    
lbb_29133:
    stxdw [r10-0x40], r6                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -64                                   r1 += -64   ///  r1 = r1.wrapping_add(-64 as i32 as i64 as u64)
    stxdw [r10-0xff8], r1                   
    stxdw [r10-0x1000], r6                  
    mov64 r1, r10                                   r1 = r10
    add64 r1, -80                                   r1 += -80   ///  r1 = r1.wrapping_add(-80 as i32 as i64 as u64)
    mov64 r5, r10                                   r5 = r10
    mov64 r4, 10                                    r4 = 10 as i32 as i64 as u64
    call function_48428                     
    ldxdw r1, [r10-0x40]                    
    jne r1, 0, lbb_29145                            if r1 != (0 as i32 as i64 as u64) { pc += 0 }
lbb_29145:
    jne r1, 0, lbb_29195                            if r1 != (0 as i32 as i64 as u64) { pc += 49 }
    ldxdw r3, [r10-0x48]                    
    ldxdw r2, [r10-0x50]                    
    lsh64 r7, 56                                    r7 <<= 56   ///  r7 = r7.wrapping_shl(56)
    add64 r7, r8                                    r7 += r8   ///  r7 = r7.wrapping_add(r8)
    arsh64 r7, 56                                   r7 >>= 56 (signed)   ///  r7 = (r7 as i64).wrapping_shr(56)
    jsgt r7, 0, lbb_29133                           if (r7 as i64) > (0 as i32 as i64) { pc += -19 }
lbb_29152:
    mov64 r1, r7                                    r1 = r7
    arsh64 r1, 7                                    r1 >>= 7 (signed)   ///  r1 = (r1 as i64).wrapping_shr(7)
    xor64 r7, r1                                    r7 ^= r1   ///  r7 = r7.xor(r1)
    sub64 r7, r1                                    r7 -= r1   ///  r7 = r7.wrapping_sub(r1)
    mov64 r4, r7                                    r4 = r7
    and64 r4, 255                                   r4 &= 255   ///  r4 = r4.and(255)
    ldxdw r8, [r10-0x60]                    
    jgt r4, 28, lbb_29161                           if r4 > (28 as i32 as i64 as u64) { pc += 1 }
    ja lbb_29168                                    if true { pc += 7 }
lbb_29161:
    mov64 r1, 28                                    r1 = 28 as i32 as i64 as u64
    stxb [r10-0x35], r1                     
    stxb [r10-0x36], r7                     
    ldxdw r1, [r10-0x58]                    
    stxb [r10-0x37], r1                     
    mov64 r1, 6                                     r1 = 6 as i32 as i64 as u64
    ja lbb_29206                                    if true { pc += 38 }
lbb_29168:
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    mov64 r0, 0                                     r0 = 0 as i32 as i64 as u64
    mov64 r5, 1                                     r5 = 1 as i32 as i64 as u64
    jsgt r0, r2, lbb_29173                          if (r0 as i64) > (r2 as i64) { pc += 1 }
    mov64 r5, 0                                     r5 = 0 as i32 as i64 as u64
lbb_29173:
    jsgt r3, 0, lbb_29175                           if (r3 as i64) > (0 as i32 as i64) { pc += 1 }
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
lbb_29175:
    jeq r3, 0, lbb_29177                            if r3 == (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r5, r1                                    r5 = r1
lbb_29177:
    mov64 r1, r10                                   r1 = r10
    add64 r1, -52                                   r1 += -52   ///  r1 = r1.wrapping_add(-52 as i32 as i64 as u64)
    and64 r5, 1                                     r5 &= 1   ///  r5 = r5.and(1)
    jne r5, 0, lbb_29204                            if r5 != (0 as i32 as i64 as u64) { pc += 23 }
    mov64 r5, 1                                     r5 = 1 as i32 as i64 as u64
    mov64 r6, -1                                    r6 = -1 as i32 as i64 as u64
    mov64 r0, 1                                     r0 = 1 as i32 as i64 as u64
    jsgt r6, r3, lbb_29186                          if (r6 as i64) > (r3 as i64) { pc += 1 }
    mov64 r0, 0                                     r0 = 0 as i32 as i64 as u64
lbb_29186:
    jsgt r2, -1, lbb_29188                          if (r2 as i64) > (-1 as i32 as i64) { pc += 1 }
    mov64 r5, 0                                     r5 = 0 as i32 as i64 as u64
lbb_29188:
    jeq r3, -1, lbb_29190                           if r3 == (-1 as i32 as i64 as u64) { pc += 1 }
    mov64 r5, r0                                    r5 = r0
lbb_29190:
    and64 r5, 1                                     r5 &= 1   ///  r5 = r5.and(1)
    jne r5, 0, lbb_29204                            if r5 != (0 as i32 as i64 as u64) { pc += 12 }
    mov64 r3, r4                                    r3 = r4
    call function_33100                     
    ja lbb_29205                                    if true { pc += 10 }
lbb_29195:
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    stxdw [r10-0x28], r1                    
    stxdw [r10-0x30], r9                    
    ldxdw r1, [r10-0x58]                    
    stxb [r10-0x37], r1                     
    mov64 r1, 5                                     r1 = 5 as i32 as i64 as u64
    stxb [r10-0x38], r1                     
    ldxdw r8, [r10-0x60]                    
    ja lbb_29207                                    if true { pc += 3 }
lbb_29204:
    call function_33131                     
lbb_29205:
    mov64 r1, 11                                    r1 = 11 as i32 as i64 as u64
lbb_29206:
    stxb [r10-0x38], r1                     
lbb_29207:
    lddw r1, 0x100061e49 --> b"Insane error converting price to decimalsdk/src/ty"        r1 load str located at 4295368265
    stxdw [r10-0x1000], r1                  
    mov64 r1, 40                                    r1 = 40 as i32 as i64 as u64
    stxdw [r10-0xff8], r1                   
    mov64 r2, r10                                   r2 = r10
    add64 r2, -56                                   r2 += -56   ///  r2 = r2.wrapping_add(-56 as i32 as i64 as u64)
    mov64 r5, r10                                   r5 = r10
    mov64 r1, r8                                    r1 = r8
    lddw r3, 0x100061e49 --> b"Insane error converting price to decimal"        r3 load str located at 4295368265
    mov64 r4, 40                                    r4 = 40 as i32 as i64 as u64
    call function_25782                     
lbb_29220:
    exit                                    

function_29221:
    stxdw [r10-0x1a0], r3                   
    stxdw [r10-0x198], r1                   
    mov64 r9, 0                                     r9 = 0 as i32 as i64 as u64
    mov64 r1, r10                                   r1 = r10
    add64 r1, -69                                   r1 += -69   ///  r1 = r1.wrapping_add(-69 as i32 as i64 as u64)
    stxdw [r10-0x178], r1                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -284                                  r1 += -284   ///  r1 = r1.wrapping_add(-284 as i32 as i64 as u64)
    stxdw [r10-0x180], r1                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -212                                  r1 += -212   ///  r1 = r1.wrapping_add(-212 as i32 as i64 as u64)
    stxdw [r10-0x190], r1                   
    mov64 r5, r2                                    r5 = r2
    mov64 r0, 0                                     r0 = 0 as i32 as i64 as u64
    mov64 r4, 0                                     r4 = 0 as i32 as i64 as u64
    stxdw [r10-0x188], r2                   
    ja lbb_29249                                    if true { pc += 11 }
lbb_29238:
    ldxdw r1, [r10-0x128]                   
    stxdw [r10-0x138], r1                   
    ldxdw r1, [r10-0x130]                   
    stxdw [r10-0x140], r1                   
    mov64 r0, 1                                     r0 = 1 as i32 as i64 as u64
    ldxdw r5, [r10-0x170]                   
    add64 r5, 4                                     r5 += 4   ///  r5 = r5.wrapping_add(4 as i32 as i64 as u64)
    ldxdw r4, [r10-0x168]                   
    add64 r4, 1                                     r4 += 1   ///  r4 = r4.wrapping_add(1 as i32 as i64 as u64)
    ldxdw r2, [r10-0x188]                   
    jeq r4, 32, lbb_29465                           if r4 == (32 as i32 as i64 as u64) { pc += 216 }
lbb_29249:
    mov64 r3, r4                                    r3 = r4
    lsh64 r3, 2                                     r3 <<= 2   ///  r3 = r3.wrapping_shl(2)
    mov64 r1, r2                                    r1 = r2
    add64 r1, r3                                    r1 += r3   ///  r1 = r1.wrapping_add(r3)
    ldxw r3, [r1+0x0]                       
    jeq r3, 0, lbb_29450                            if r3 == (0 as i32 as i64 as u64) { pc += 195 }
    stxdw [r10-0x160], r0                   
    stxdw [r10-0x170], r5                   
    stxdw [r10-0x168], r4                   
    add64 r2, r4                                    r2 += r4   ///  r2 = r2.wrapping_add(r4)
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
    ldxw r7, [r1+0xa0]                      
    ldxb r8, [r2+0x120]                     
    lsh64 r8, 56                                    r8 <<= 56   ///  r8 = r8.wrapping_shl(56)
    arsh64 r8, 56                                   r8 >>= 56 (signed)   ///  r8 = (r8 as i64).wrapping_shr(56)
    mov64 r6, r8                                    r6 = r8
    mov64 r2, r7                                    r2 = r7
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    jsgt r1, r8, lbb_29291                          if (r1 as i64) > (r8 as i64) { pc += 23 }
    mov64 r2, r7                                    r2 = r7
    mov64 r6, r8                                    r6 = r8
lbb_29270:
    stxdw [r10-0x148], r9                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -328                                  r1 += -328   ///  r1 = r1.wrapping_add(-328 as i32 as i64 as u64)
    stxdw [r10-0xff8], r1                   
    stxdw [r10-0x1000], r9                  
    mov64 r1, r10                                   r1 = r10
    add64 r1, -344                                  r1 += -344   ///  r1 = r1.wrapping_add(-344 as i32 as i64 as u64)
    mov64 r5, r10                                   r5 = r10
    mov64 r4, 10                                    r4 = 10 as i32 as i64 as u64
    call function_48428                     
    ldxdw r1, [r10-0x148]                   
    jne r1, 0, lbb_29282                            if r1 != (0 as i32 as i64 as u64) { pc += 0 }
lbb_29282:
    jne r1, 0, lbb_29331                            if r1 != (0 as i32 as i64 as u64) { pc += 48 }
    ldxdw r3, [r10-0x150]                   
    ldxdw r2, [r10-0x158]                   
    lsh64 r6, 56                                    r6 <<= 56   ///  r6 = r6.wrapping_shl(56)
    lddw r1, 0xff00000000000000                     r1 load str located at -72057594037927936
    add64 r6, r1                                    r6 += r1   ///  r6 = r6.wrapping_add(r1)
    arsh64 r6, 56                                   r6 >>= 56 (signed)   ///  r6 = (r6 as i64).wrapping_shr(56)
    jsgt r6, 0, lbb_29270                           if (r6 as i64) > (0 as i32 as i64) { pc += -21 }
lbb_29291:
    mov64 r1, r6                                    r1 = r6
    arsh64 r1, 7                                    r1 >>= 7 (signed)   ///  r1 = (r1 as i64).wrapping_shr(7)
    xor64 r6, r1                                    r6 ^= r1   ///  r6 = r6.xor(r1)
    sub64 r6, r1                                    r6 -= r1   ///  r6 = r6.wrapping_sub(r1)
    mov64 r4, r6                                    r4 = r6
    and64 r4, 255                                   r4 &= 255   ///  r4 = r4.and(255)
    jgt r4, 28, lbb_29299                           if r4 > (28 as i32 as i64 as u64) { pc += 1 }
    ja lbb_29305                                    if true { pc += 6 }
lbb_29299:
    mov64 r1, 28                                    r1 = 28 as i32 as i64 as u64
    stxb [r10-0xd5], r1                     
    stxb [r10-0xd6], r6                     
    stxb [r10-0xd7], r8                     
    mov64 r1, 6                                     r1 = 6 as i32 as i64 as u64
    ja lbb_29339                                    if true { pc += 34 }
lbb_29305:
    mov64 r5, 1                                     r5 = 1 as i32 as i64 as u64
    mov64 r0, 0                                     r0 = 0 as i32 as i64 as u64
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    jsgt r0, r2, lbb_29310                          if (r0 as i64) > (r2 as i64) { pc += 1 }
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
lbb_29310:
    jsgt r3, 0, lbb_29312                           if (r3 as i64) > (0 as i32 as i64) { pc += 1 }
    mov64 r5, 0                                     r5 = 0 as i32 as i64 as u64
lbb_29312:
    jeq r3, 0, lbb_29314                            if r3 == (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r1, r5                                    r1 = r5
lbb_29314:
    and64 r1, 1                                     r1 &= 1   ///  r1 = r1.and(1)
    jne r1, 0, lbb_29336                            if r1 != (0 as i32 as i64 as u64) { pc += 20 }
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    mov64 r5, 1                                     r5 = 1 as i32 as i64 as u64
    mov64 r0, -1                                    r0 = -1 as i32 as i64 as u64
    jsgt r0, r3, lbb_29321                          if (r0 as i64) > (r3 as i64) { pc += 1 }
    mov64 r5, 0                                     r5 = 0 as i32 as i64 as u64
lbb_29321:
    jsgt r2, -1, lbb_29323                          if (r2 as i64) > (-1 as i32 as i64) { pc += 1 }
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
lbb_29323:
    jeq r3, -1, lbb_29325                           if r3 == (-1 as i32 as i64 as u64) { pc += 1 }
    mov64 r1, r5                                    r1 = r5
lbb_29325:
    and64 r1, 1                                     r1 &= 1   ///  r1 = r1.and(1)
    jne r1, 0, lbb_29336                            if r1 != (0 as i32 as i64 as u64) { pc += 9 }
    ldxdw r1, [r10-0x190]                   
    mov64 r3, r4                                    r3 = r4
    call function_33100                     
    ja lbb_29338                                    if true { pc += 7 }
lbb_29331:
    stxdw [r10-0xc8], r9                    
    stxdw [r10-0xd0], r7                    
    stxb [r10-0xd7], r8                     
    mov64 r1, 5                                     r1 = 5 as i32 as i64 as u64
    ja lbb_29339                                    if true { pc += 3 }
lbb_29336:
    ldxdw r1, [r10-0x190]                   
    call function_33131                     
lbb_29338:
    mov64 r1, 11                                    r1 = 11 as i32 as i64 as u64
lbb_29339:
    stxb [r10-0xd8], r1                     
    lddw r1, 0x100061eba --> b"Insane error converting price offset to decimalPri"        r1 load str located at 4295368378
    stxdw [r10-0x1000], r1                  
    mov64 r1, 47                                    r1 = 47 as i32 as i64 as u64
    stxdw [r10-0xff8], r1                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -288                                  r1 += -288   ///  r1 = r1.wrapping_add(-288 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -216                                  r2 += -216   ///  r2 = r2.wrapping_add(-216 as i32 as i64 as u64)
    mov64 r5, r10                                   r5 = r10
    lddw r3, 0x100061eba --> b"Insane error converting price offset to decimal"        r3 load str located at 4295368378
    mov64 r4, 47                                    r4 = 47 as i32 as i64 as u64
    call function_25782                     
    ldxb r6, [r10-0x120]                    
    jne r6, 56, lbb_29469                           if r6 != (56 as i32 as i64 as u64) { pc += 113 }
    ldxdw r3, [r10-0x180]                   
    ldxdw r1, [r3+0x8]                      
    ldxdw r2, [r10-0x178]                   
    stxdw [r2+0x8], r1                      
    ldxdw r1, [r3+0x0]                      
    stxdw [r2+0x0], r1                      
    ldxdw r1, [r2+0x0]                      
    stxdw [r10-0x130], r1                   
    ldxdw r1, [r2+0x8]                      
    stxdw [r10-0x128], r1                   
    ldxdw r1, [r10-0x160]                   
    and64 r1, 1                                     r1 &= 1   ///  r1 = r1.and(1)
    jne r1, 0, lbb_29370                            if r1 != (0 as i32 as i64 as u64) { pc += 1 }
    ja lbb_29238                                    if true { pc += -132 }
lbb_29370:
    ldxdw r1, [r10-0x138]                   
    stxdw [r10-0x98], r1                    
    ldxdw r1, [r10-0x140]                   
    stxdw [r10-0xa0], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -160                                  r1 += -160   ///  r1 = r1.wrapping_add(-160 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -304                                  r2 += -304   ///  r2 = r2.wrapping_add(-304 as i32 as i64 as u64)
    call function_33952                     
    mov64 r1, 35                                    r1 = 35 as i32 as i64 as u64
    stxdw [r10-0x58], r1                    
    lddw r1, 0x100061ee9 --> b"Price offset nonincreasing in depthInvalid bid slo"        r1 load str located at 4295368425
    stxdw [r10-0x60], r1                    
    and64 r0, 255                                   r0 &= 255   ///  r0 = r0.and(255)
    jeq r0, 255, lbb_29238                          if r0 == (255 as i32 as i64 as u64) { pc += -148 }
    lddw r1, 0x100065dd0 --> b"\x00\x00\x00\x00q\x1e\x06\x00\x1e\x00\x00\x00\x00\x00\x00\x00\xac\x00\x00…        r1 load str located at 4295384528
    stxdw [r10-0x50], r1                    
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    stxdw [r10-0x100], r1                   
    lddw r1, 0x100065a98 --> b"\x00\x00\x00\x00\xe8\x0e\x06\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\…        r1 load str located at 4295383704
    stxdw [r10-0x120], r1                   
    mov64 r1, 2                                     r1 = 2 as i32 as i64 as u64
    stxdw [r10-0x118], r1                   
    stxdw [r10-0x108], r1                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -216                                  r1 += -216   ///  r1 = r1.wrapping_add(-216 as i32 as i64 as u64)
    stxdw [r10-0x110], r1                   
    lddw r1, 0x10002a248 --> b"y\x11\x00\x00\x00\x00\x00\x00\x85\x10\x00\x00%X\x00\x00\x95\x00\x00\x00\x…        r1 load str located at 4295139912
    stxdw [r10-0xc0], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -80                                   r1 += -80   ///  r1 = r1.wrapping_add(-80 as i32 as i64 as u64)
    stxdw [r10-0xc8], r1                    
    lddw r1, 0x10002a388 --> b"\xbf#\x00\x00\x00\x00\x00\x00y\x12\x08\x00\x00\x00\x00\x00y\x11\x00\x00\x…        r1 load str located at 4295140232
    stxdw [r10-0xd0], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -96                                   r1 += -96   ///  r1 = r1.wrapping_add(-96 as i32 as i64 as u64)
    stxdw [r10-0xd8], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -72                                   r1 += -72   ///  r1 = r1.wrapping_add(-72 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -288                                  r2 += -288   ///  r2 = r2.wrapping_add(-288 as i32 as i64 as u64)
    call function_43415                     
    ldxdw r8, [r10-0x40]                    
    ldxdw r9, [r10-0x48]                    
    ldxdw r2, [r10-0x38]                    
    mov64 r1, r9                                    r1 = r9
    syscall [invalid]                       
    jeq r8, 0, lbb_29427                            if r8 == (0 as i32 as i64 as u64) { pc += 4 }
    mov64 r1, r9                                    r1 = r9
    mov64 r2, r8                                    r2 = r8
    mov64 r3, 1                                     r3 = 1 as i32 as i64 as u64
    call function_21385                     
lbb_29427:
    ldxdw r1, [r10-0x98]                    
    stxdw [r10-0x116], r1                   
    ldxdw r1, [r10-0xa0]                    
    stxdw [r10-0x11e], r1                   
    ldxdw r1, [r10-0x128]                   
    ldxdw r2, [r10-0x198]                   
    stxdw [r2+0x1c], r1                     
    ldxdw r1, [r10-0x130]                   
    stxdw [r2+0x14], r1                     
    ldxh r1, [r10-0x110]                    
    stxh [r2+0x12], r1                      
    ldxdw r1, [r10-0x118]                   
    stxdw [r2+0xa], r1                      
    ldxdw r1, [r10-0x120]                   
    stxdw [r2+0x2], r1                      
    mov64 r1, 4                                     r1 = 4 as i32 as i64 as u64
    stxdw [r2+0x30], r1                     
    ldxdw r1, [r10-0x1a0]                   
    stxdw [r2+0x28], r1                     
    ldxdw r1, [r10-0x168]                   
    stxb [r2+0x1], r1                       
    mov64 r1, 46                                    r1 = 46 as i32 as i64 as u64
    ja lbb_29467                                    if true { pc += 17 }
lbb_29450:
    jgt r4, 31, lbb_29465                           if r4 > (31 as i32 as i64 as u64) { pc += 14 }
    mov64 r1, 43                                    r1 = 43 as i32 as i64 as u64
    lddw r2, 0x100061e8f --> b"Nonzero order seen after zero q"        r2 load str located at 4295368335
    mov64 r3, 31                                    r3 = 31 as i32 as i64 as u64
lbb_29455:
    mov64 r6, r4                                    r6 = r4
    ldxw r4, [r5+0x0]                       
    stxdw [r10-0x58], r1                    
    stxdw [r10-0x60], r2                    
    jeq r4, 0, lbb_29461                            if r4 == (0 as i32 as i64 as u64) { pc += 1 }
    ja lbb_29490                                    if true { pc += 29 }
lbb_29461:
    add64 r5, 4                                     r5 += 4   ///  r5 = r5.wrapping_add(4 as i32 as i64 as u64)
    mov64 r4, r6                                    r4 = r6
    add64 r4, 1                                     r4 += 1   ///  r4 = r4.wrapping_add(1 as i32 as i64 as u64)
    jgt r3, r6, lbb_29455                           if r3 > r6 { pc += -10 }
lbb_29465:
    mov64 r1, 56                                    r1 = 56 as i32 as i64 as u64
    ldxdw r2, [r10-0x198]                   
lbb_29467:
    stxb [r2+0x0], r1                       
    ja lbb_29489                                    if true { pc += 20 }
lbb_29469:
    ldxw r1, [r10-0x110]                    
    stxw [r10-0x39], r1                     
    ldxdw r1, [r10-0x117]                   
    stxdw [r10-0x40], r1                    
    ldxdw r1, [r10-0x11f]                   
    stxdw [r10-0x48], r1                    
    ldxdw r7, [r10-0x198]                   
    mov64 r1, r7                                    r1 = r7
    add64 r1, 20                                    r1 += 20   ///  r1 = r1.wrapping_add(20 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -268                                  r2 += -268   ///  r2 = r2.wrapping_add(-268 as i32 as i64 as u64)
    mov64 r3, 52                                    r3 = 52 as i32 as i64 as u64
    call function_48190                     
    ldxw r1, [r10-0x39]                     
    stxw [r7+0x10], r1                      
    ldxdw r1, [r10-0x40]                    
    stxdw [r7+0x9], r1                      
    ldxdw r1, [r10-0x48]                    
    stxdw [r7+0x1], r1                      
    stxb [r7+0x0], r6                       
lbb_29489:
    exit                                    
lbb_29490:
    lddw r1, 0x100065db8 --> b"\x00\x00\x00\x00q\x1e\x06\x00\x1e\x00\x00\x00\x00\x00\x00\x00\xbe\x00\x00…        r1 load str located at 4295384504
    stxdw [r10-0xa0], r1                    
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    stxdw [r10-0x100], r1                   
    lddw r1, 0x100065a98 --> b"\x00\x00\x00\x00\xe8\x0e\x06\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\…        r1 load str located at 4295383704
    stxdw [r10-0x120], r1                   
    mov64 r1, 2                                     r1 = 2 as i32 as i64 as u64
    stxdw [r10-0x118], r1                   
    stxdw [r10-0x108], r1                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -216                                  r1 += -216   ///  r1 = r1.wrapping_add(-216 as i32 as i64 as u64)
    stxdw [r10-0x110], r1                   
    lddw r1, 0x10002a248 --> b"y\x11\x00\x00\x00\x00\x00\x00\x85\x10\x00\x00%X\x00\x00\x95\x00\x00\x00\x…        r1 load str located at 4295139912
    stxdw [r10-0xc0], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -160                                  r1 += -160   ///  r1 = r1.wrapping_add(-160 as i32 as i64 as u64)
    stxdw [r10-0xc8], r1                    
    lddw r1, 0x10002a388 --> b"\xbf#\x00\x00\x00\x00\x00\x00y\x12\x08\x00\x00\x00\x00\x00y\x11\x00\x00\x…        r1 load str located at 4295140232
    stxdw [r10-0xd0], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -96                                   r1 += -96   ///  r1 = r1.wrapping_add(-96 as i32 as i64 as u64)
    stxdw [r10-0xd8], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -72                                   r1 += -72   ///  r1 = r1.wrapping_add(-72 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -288                                  r2 += -288   ///  r2 = r2.wrapping_add(-288 as i32 as i64 as u64)
    call function_43415                     
    ldxdw r8, [r10-0x40]                    
    ldxdw r9, [r10-0x48]                    
    ldxdw r2, [r10-0x38]                    
    mov64 r1, r9                                    r1 = r9
    syscall [invalid]                       
    jeq r8, 0, lbb_29531                            if r8 == (0 as i32 as i64 as u64) { pc += 4 }
    mov64 r1, r9                                    r1 = r9
    mov64 r2, r8                                    r2 = r8
    mov64 r3, 1                                     r3 = 1 as i32 as i64 as u64
    call function_21385                     
lbb_29531:
    mov64 r1, 4                                     r1 = 4 as i32 as i64 as u64
    ldxdw r2, [r10-0x198]                   
    stxdw [r2+0x10], r1                     
    ldxdw r1, [r10-0x1a0]                   
    stxdw [r2+0x8], r1                      
    stxb [r2+0x1], r6                       
    mov64 r1, 45                                    r1 = 45 as i32 as i64 as u64
    ja lbb_29467                                    if true { pc += -72 }

function_29539:
    mov64 r6, r1                                    r6 = r1
    mov64 r9, 0                                     r9 = 0 as i32 as i64 as u64
    mov64 r1, 26                                    r1 = 26 as i32 as i64 as u64
    lddw r3, 0x100061f0c --> b"Invalid bid slot stalenessInvalid ask slot stalene"        r3 load str located at 4295368460
    lddw r4, 0x100061f26 --> b"Invalid ask slot stalenessIn practice impossible d"        r4 load str located at 4295368486
    ja lbb_29549                                    if true { pc += 2 }
lbb_29547:
    add64 r9, 1                                     r9 += 1   ///  r9 = r9.wrapping_add(1 as i32 as i64 as u64)
    jeq r9, 32, lbb_29642                           if r9 == (32 as i32 as i64 as u64) { pc += 93 }
lbb_29549:
    mov64 r5, r2                                    r5 = r2
    add64 r5, r9                                    r5 += r9   ///  r5 = r5.wrapping_add(r9)
    ldxb r0, [r5+0x0]                       
    stxdw [r10-0xa8], r1                    
    stxdw [r10-0xb0], r3                    
    jne r0, 0, lbb_29556                            if r0 != (0 as i32 as i64 as u64) { pc += 1 }
    ja lbb_29598                                    if true { pc += 42 }
lbb_29556:
    ldxb r5, [r5+0x20]                      
    stxdw [r10-0xa8], r1                    
    stxdw [r10-0xb0], r4                    
    jne r5, 0, lbb_29547                            if r5 != (0 as i32 as i64 as u64) { pc += -13 }
    lddw r1, 0x100065e00 --> b"\x00\x00\x00\x00q\x1e\x06\x00\x1e\x00\x00\x00\x00\x00\x00\x00\xe5\x00\x00…        r1 load str located at 4295384576
    stxdw [r10-0xa0], r1                    
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    stxdw [r10-0x60], r1                    
    lddw r1, 0x100065a98 --> b"\x00\x00\x00\x00\xe8\x0e\x06\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\…        r1 load str located at 4295383704
    stxdw [r10-0x80], r1                    
    mov64 r1, 2                                     r1 = 2 as i32 as i64 as u64
    stxdw [r10-0x78], r1                    
    stxdw [r10-0x68], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -80                                   r1 += -80   ///  r1 = r1.wrapping_add(-80 as i32 as i64 as u64)
    stxdw [r10-0x70], r1                    
    lddw r1, 0x10002a248 --> b"y\x11\x00\x00\x00\x00\x00\x00\x85\x10\x00\x00%X\x00\x00\x95\x00\x00\x00\x…        r1 load str located at 4295139912
    stxdw [r10-0x38], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -160                                  r1 += -160   ///  r1 = r1.wrapping_add(-160 as i32 as i64 as u64)
    stxdw [r10-0x40], r1                    
    lddw r1, 0x10002a388 --> b"\xbf#\x00\x00\x00\x00\x00\x00y\x12\x08\x00\x00\x00\x00\x00y\x11\x00\x00\x…        r1 load str located at 4295140232
    stxdw [r10-0x48], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -176                                  r1 += -176   ///  r1 = r1.wrapping_add(-176 as i32 as i64 as u64)
    stxdw [r10-0x50], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -152                                  r1 += -152   ///  r1 = r1.wrapping_add(-152 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -128                                  r2 += -128   ///  r2 = r2.wrapping_add(-128 as i32 as i64 as u64)
    call function_43415                     
    ldxdw r7, [r10-0x90]                    
    ldxdw r8, [r10-0x98]                    
    ldxdw r2, [r10-0x88]                    
    mov64 r1, r8                                    r1 = r8
    syscall [invalid]                       
    jeq r7, 0, lbb_29639                            if r7 == (0 as i32 as i64 as u64) { pc += 42 }
    ja lbb_29635                                    if true { pc += 37 }
lbb_29598:
    lddw r1, 0x100065de8 --> b"\x00\x00\x00\x00q\x1e\x06\x00\x1e\x00\x00\x00\x00\x00\x00\x00\xe0\x00\x00…        r1 load str located at 4295384552
    stxdw [r10-0xa0], r1                    
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    stxdw [r10-0x60], r1                    
    lddw r1, 0x100065a98 --> b"\x00\x00\x00\x00\xe8\x0e\x06\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\…        r1 load str located at 4295383704
    stxdw [r10-0x80], r1                    
    mov64 r1, 2                                     r1 = 2 as i32 as i64 as u64
    stxdw [r10-0x78], r1                    
    stxdw [r10-0x68], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -80                                   r1 += -80   ///  r1 = r1.wrapping_add(-80 as i32 as i64 as u64)
    stxdw [r10-0x70], r1                    
    lddw r1, 0x10002a248 --> b"y\x11\x00\x00\x00\x00\x00\x00\x85\x10\x00\x00%X\x00\x00\x95\x00\x00\x00\x…        r1 load str located at 4295139912
    stxdw [r10-0x38], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -160                                  r1 += -160   ///  r1 = r1.wrapping_add(-160 as i32 as i64 as u64)
    stxdw [r10-0x40], r1                    
    lddw r1, 0x10002a388 --> b"\xbf#\x00\x00\x00\x00\x00\x00y\x12\x08\x00\x00\x00\x00\x00y\x11\x00\x00\x…        r1 load str located at 4295140232
    stxdw [r10-0x48], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -176                                  r1 += -176   ///  r1 = r1.wrapping_add(-176 as i32 as i64 as u64)
    stxdw [r10-0x50], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -152                                  r1 += -152   ///  r1 = r1.wrapping_add(-152 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -128                                  r2 += -128   ///  r2 = r2.wrapping_add(-128 as i32 as i64 as u64)
    call function_43415                     
    ldxdw r7, [r10-0x90]                    
    ldxdw r8, [r10-0x98]                    
    ldxdw r2, [r10-0x88]                    
    mov64 r1, r8                                    r1 = r8
    syscall [invalid]                       
    jeq r7, 0, lbb_29639                            if r7 == (0 as i32 as i64 as u64) { pc += 4 }
lbb_29635:
    mov64 r1, r8                                    r1 = r8
    mov64 r2, r7                                    r2 = r7
    mov64 r3, 1                                     r3 = 1 as i32 as i64 as u64
    call function_21385                     
lbb_29639:
    stxb [r6+0x1], r9                       
    mov64 r1, 47                                    r1 = 47 as i32 as i64 as u64
    ja lbb_29643                                    if true { pc += 1 }
lbb_29642:
    mov64 r1, 56                                    r1 = 56 as i32 as i64 as u64
lbb_29643:
    stxb [r6+0x0], r1                       
    exit                                    

function_29645:
    mov64 r7, r1                                    r7 = r1
    ldxdw r1, [r5-0x1000]                   
    jgt r1, 31, lbb_29843                           if r1 > (31 as i32 as i64 as u64) { pc += 195 }
    mov64 r8, r2                                    r8 = r2
    add64 r8, 320                                   r8 += 320   ///  r8 = r8.wrapping_add(320 as i32 as i64 as u64)
    jne r4, 0, lbb_29652                            if r4 != (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r8, r2                                    r8 = r2
lbb_29652:
    mov64 r0, 1                                     r0 = 1 as i32 as i64 as u64
    mov64 r9, r1                                    r9 = r1
    lsh64 r9, 2                                     r9 <<= 2   ///  r9 = r9.wrapping_shl(2)
    mov64 r6, r8                                    r6 = r8
    add64 r6, r9                                    r6 += r9   ///  r6 = r6.wrapping_add(r9)
    ldxw r9, [r6+0x0]                       
    jeq r9, 0, lbb_29841                            if r9 == (0 as i32 as i64 as u64) { pc += 182 }
    ldxdw r0, [r5-0xff8]                    
    ldxdw r5, [r3+0x8]                      
    mov64 r3, r0                                    r3 = r0
    sub64 r3, r5                                    r3 -= r5   ///  r3 = r3.wrapping_sub(r5)
    mov64 r6, 0                                     r6 = 0 as i32 as i64 as u64
    mov64 r5, 1                                     r5 = 1 as i32 as i64 as u64
    jgt r3, r0, lbb_29667                           if r3 > r0 { pc += 1 }
    mov64 r5, 0                                     r5 = 0 as i32 as i64 as u64
lbb_29667:
    jne r5, 0, lbb_29669                            if r5 != (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r6, r3                                    r6 = r3
lbb_29669:
    mov64 r3, 672                                   r3 = 672 as i32 as i64 as u64
    jne r4, 0, lbb_29672                            if r4 != (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r3, 640                                   r3 = 640 as i32 as i64 as u64
lbb_29672:
    add64 r2, r3                                    r2 += r3   ///  r2 = r2.wrapping_add(r3)
    add64 r2, r1                                    r2 += r1   ///  r2 = r2.wrapping_add(r1)
    mov64 r0, 2                                     r0 = 2 as i32 as i64 as u64
    ldxb r2, [r2+0x0]                       
    jgt r6, r2, lbb_29841                           if r6 > r2 { pc += 164 }
    stxdw [r10-0xe0], r7                    
    mov64 r2, r8                                    r2 = r8
    stxdw [r10-0xd8], r1                    
    add64 r2, r1                                    r2 += r1   ///  r2 = r2.wrapping_add(r1)
    ldxb r4, [r2+0x80]                      
    lsh64 r4, 56                                    r4 <<= 56   ///  r4 = r4.wrapping_shl(56)
    arsh64 r4, 56                                   r4 >>= 56 (signed)   ///  r4 = (r4 as i64).wrapping_shr(56)
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    mov64 r6, r4                                    r6 = r4
    stxdw [r10-0xf0], r9                    
    mov64 r2, r9                                    r2 = r9
    stxdw [r10-0xe8], r4                    
    jsgt r1, r4, lbb_29715                          if (r1 as i64) > (r4 as i64) { pc += 24 }
    mov64 r7, 0                                     r7 = 0 as i32 as i64 as u64
    lddw r9, 0xff00000000000000                     r9 load str located at -72057594037927936
    ldxdw r2, [r10-0xf0]                    
    ldxdw r6, [r10-0xe8]                    
lbb_29696:
    stxdw [r10-0xa8], r7                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -168                                  r1 += -168   ///  r1 = r1.wrapping_add(-168 as i32 as i64 as u64)
    stxdw [r10-0xff8], r1                   
    stxdw [r10-0x1000], r7                  
    mov64 r1, r10                                   r1 = r10
    add64 r1, -184                                  r1 += -184   ///  r1 = r1.wrapping_add(-184 as i32 as i64 as u64)
    mov64 r5, r10                                   r5 = r10
    mov64 r4, 10                                    r4 = 10 as i32 as i64 as u64
    call function_48428                     
    ldxdw r1, [r10-0xa8]                    
    jne r1, 0, lbb_29708                            if r1 != (0 as i32 as i64 as u64) { pc += 0 }
lbb_29708:
    jne r1, 0, lbb_29848                            if r1 != (0 as i32 as i64 as u64) { pc += 139 }
    ldxdw r3, [r10-0xb0]                    
    ldxdw r2, [r10-0xb8]                    
    lsh64 r6, 56                                    r6 <<= 56   ///  r6 = r6.wrapping_shl(56)
    add64 r6, r9                                    r6 += r9   ///  r6 = r6.wrapping_add(r9)
    arsh64 r6, 56                                   r6 >>= 56 (signed)   ///  r6 = (r6 as i64).wrapping_shr(56)
    jsgt r6, 0, lbb_29696                           if (r6 as i64) > (0 as i32 as i64) { pc += -19 }
lbb_29715:
    mov64 r1, r6                                    r1 = r6
    arsh64 r1, 7                                    r1 >>= 7 (signed)   ///  r1 = (r1 as i64).wrapping_shr(7)
    xor64 r6, r1                                    r6 ^= r1   ///  r6 = r6.xor(r1)
    sub64 r6, r1                                    r6 -= r1   ///  r6 = r6.wrapping_sub(r1)
    mov64 r4, r6                                    r4 = r6
    and64 r4, 255                                   r4 &= 255   ///  r4 = r4.and(255)
    jgt r4, 28, lbb_29897                           if r4 > (28 as i32 as i64 as u64) { pc += 175 }
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    mov64 r0, 0                                     r0 = 0 as i32 as i64 as u64
    mov64 r5, 1                                     r5 = 1 as i32 as i64 as u64
    jsgt r0, r2, lbb_29727                          if (r0 as i64) > (r2 as i64) { pc += 1 }
    mov64 r5, 0                                     r5 = 0 as i32 as i64 as u64
lbb_29727:
    jsgt r3, 0, lbb_29729                           if (r3 as i64) > (0 as i32 as i64) { pc += 1 }
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
lbb_29729:
    ldxdw r7, [r10-0xd8]                    
    jeq r3, 0, lbb_29732                            if r3 == (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r5, r1                                    r5 = r1
lbb_29732:
    mov64 r1, r10                                   r1 = r10
    add64 r1, -108                                  r1 += -108   ///  r1 = r1.wrapping_add(-108 as i32 as i64 as u64)
    and64 r5, 1                                     r5 &= 1   ///  r5 = r5.and(1)
    jne r5, 0, lbb_29750                            if r5 != (0 as i32 as i64 as u64) { pc += 14 }
    mov64 r5, 1                                     r5 = 1 as i32 as i64 as u64
    mov64 r6, -1                                    r6 = -1 as i32 as i64 as u64
    mov64 r0, 1                                     r0 = 1 as i32 as i64 as u64
    jsgt r6, r3, lbb_29741                          if (r6 as i64) > (r3 as i64) { pc += 1 }
    mov64 r0, 0                                     r0 = 0 as i32 as i64 as u64
lbb_29741:
    jsgt r2, -1, lbb_29743                          if (r2 as i64) > (-1 as i32 as i64) { pc += 1 }
    mov64 r5, 0                                     r5 = 0 as i32 as i64 as u64
lbb_29743:
    jeq r3, -1, lbb_29745                           if r3 == (-1 as i32 as i64 as u64) { pc += 1 }
    mov64 r5, r0                                    r5 = r0
lbb_29745:
    and64 r5, 1                                     r5 &= 1   ///  r5 = r5.and(1)
    jne r5, 0, lbb_29750                            if r5 != (0 as i32 as i64 as u64) { pc += 3 }
    mov64 r3, r4                                    r3 = r4
    call function_33100                     
    ja lbb_29751                                    if true { pc += 1 }
lbb_29750:
    call function_33131                     
lbb_29751:
    ldxdw r1, [r10-0x64]                    
    stxdw [r10-0x78], r1                    
    ldxdw r1, [r10-0x6c]                    
    stxdw [r10-0x80], r1                    
    mov64 r1, r8                                    r1 = r8
    add64 r1, r7                                    r1 += r7   ///  r1 = r1.wrapping_add(r7)
    lsh64 r7, 2                                     r7 <<= 2   ///  r7 = r7.wrapping_shl(2)
    add64 r8, r7                                    r8 += r7   ///  r8 = r8.wrapping_add(r7)
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
    ldxw r2, [r8+0xa0]                      
    ldxb r6, [r1+0x120]                     
    lsh64 r6, 56                                    r6 <<= 56   ///  r6 = r6.wrapping_shl(56)
    arsh64 r6, 56                                   r6 >>= 56 (signed)   ///  r6 = (r6 as i64).wrapping_shr(56)
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    mov64 r8, r6                                    r8 = r6
    stxdw [r10-0xd8], r2                    
    jsgt r1, r6, lbb_29792                          if (r1 as i64) > (r6 as i64) { pc += 24 }
    mov64 r9, 0                                     r9 = 0 as i32 as i64 as u64
    lddw r7, 0xff00000000000000                     r7 load str located at -72057594037927936
    ldxdw r2, [r10-0xd8]                    
    mov64 r8, r6                                    r8 = r6
lbb_29773:
    stxdw [r10-0xc0], r9                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -192                                  r1 += -192   ///  r1 = r1.wrapping_add(-192 as i32 as i64 as u64)
    stxdw [r10-0xff8], r1                   
    stxdw [r10-0x1000], r9                  
    mov64 r1, r10                                   r1 = r10
    add64 r1, -208                                  r1 += -208   ///  r1 = r1.wrapping_add(-208 as i32 as i64 as u64)
    mov64 r5, r10                                   r5 = r10
    mov64 r4, 10                                    r4 = 10 as i32 as i64 as u64
    call function_48428                     
    ldxdw r1, [r10-0xc0]                    
    jne r1, 0, lbb_29785                            if r1 != (0 as i32 as i64 as u64) { pc += 0 }
lbb_29785:
    jne r1, 0, lbb_29873                            if r1 != (0 as i32 as i64 as u64) { pc += 87 }
    ldxdw r3, [r10-0xc8]                    
    ldxdw r2, [r10-0xd0]                    
    lsh64 r8, 56                                    r8 <<= 56   ///  r8 = r8.wrapping_shl(56)
    add64 r8, r7                                    r8 += r7   ///  r8 = r8.wrapping_add(r7)
    arsh64 r8, 56                                   r8 >>= 56 (signed)   ///  r8 = (r8 as i64).wrapping_shr(56)
    jsgt r8, 0, lbb_29773                           if (r8 as i64) > (0 as i32 as i64) { pc += -19 }
lbb_29792:
    mov64 r1, r8                                    r1 = r8
    arsh64 r1, 7                                    r1 >>= 7 (signed)   ///  r1 = (r1 as i64).wrapping_shr(7)
    xor64 r8, r1                                    r8 ^= r1   ///  r8 = r8.xor(r1)
    sub64 r8, r1                                    r8 -= r1   ///  r8 = r8.wrapping_sub(r1)
    mov64 r4, r8                                    r4 = r8
    and64 r4, 255                                   r4 &= 255   ///  r4 = r4.and(255)
    jgt r4, 28, lbb_29904                           if r4 > (28 as i32 as i64 as u64) { pc += 105 }
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    mov64 r0, 0                                     r0 = 0 as i32 as i64 as u64
    mov64 r5, 1                                     r5 = 1 as i32 as i64 as u64
    ldxdw r7, [r10-0xe0]                    
    jsgt r0, r2, lbb_29805                          if (r0 as i64) > (r2 as i64) { pc += 1 }
    mov64 r5, 0                                     r5 = 0 as i32 as i64 as u64
lbb_29805:
    jsgt r3, 0, lbb_29807                           if (r3 as i64) > (0 as i32 as i64) { pc += 1 }
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
lbb_29807:
    jeq r3, 0, lbb_29809                            if r3 == (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r5, r1                                    r5 = r1
lbb_29809:
    mov64 r1, r10                                   r1 = r10
    add64 r1, -108                                  r1 += -108   ///  r1 = r1.wrapping_add(-108 as i32 as i64 as u64)
    and64 r5, 1                                     r5 &= 1   ///  r5 = r5.and(1)
    jne r5, 0, lbb_29827                            if r5 != (0 as i32 as i64 as u64) { pc += 14 }
    mov64 r5, 1                                     r5 = 1 as i32 as i64 as u64
    mov64 r6, -1                                    r6 = -1 as i32 as i64 as u64
    mov64 r0, 1                                     r0 = 1 as i32 as i64 as u64
    jsgt r6, r3, lbb_29818                          if (r6 as i64) > (r3 as i64) { pc += 1 }
    mov64 r0, 0                                     r0 = 0 as i32 as i64 as u64
lbb_29818:
    jsgt r2, -1, lbb_29820                          if (r2 as i64) > (-1 as i32 as i64) { pc += 1 }
    mov64 r5, 0                                     r5 = 0 as i32 as i64 as u64
lbb_29820:
    jeq r3, -1, lbb_29822                           if r3 == (-1 as i32 as i64 as u64) { pc += 1 }
    mov64 r5, r0                                    r5 = r0
lbb_29822:
    and64 r5, 1                                     r5 &= 1   ///  r5 = r5.and(1)
    jne r5, 0, lbb_29827                            if r5 != (0 as i32 as i64 as u64) { pc += 3 }
    mov64 r3, r4                                    r3 = r4
    call function_33100                     
    ja lbb_29828                                    if true { pc += 1 }
lbb_29827:
    call function_33131                     
lbb_29828:
    ldxdw r1, [r10-0x64]                    
    stxdw [r10-0x88], r1                    
    ldxdw r2, [r10-0x6c]                    
    stxdw [r10-0x90], r2                    
    ldxdw r3, [r10-0x80]                    
    stxdw [r10-0xa0], r3                    
    ldxdw r4, [r10-0x78]                    
    stxdw [r10-0x98], r4                    
    stxdw [r7+0x1c], r1                     
    stxdw [r7+0x14], r2                     
    stxdw [r7+0xc], r4                      
    stxdw [r7+0x4], r3                      
    mov64 r0, 0                                     r0 = 0 as i32 as i64 as u64
lbb_29841:
    stxw [r7+0x0], r0                       
    exit                                    
lbb_29843:
    mov64 r2, 32                                    r2 = 32 as i32 as i64 as u64
    lddw r3, 0x100065e18 --> b"\x00\x00\x00\x00q\x1e\x06\x00\x1e\x00\x00\x00\x00\x00\x00\x00\x1a\x01\x00…        r3 load str located at 4295384600
    call function_44272                     
    syscall [invalid]                       
lbb_29848:
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    stxdw [r10-0x60], r1                    
    ldxdw r1, [r10-0xf0]                    
    stxdw [r10-0x68], r1                    
    ldxdw r1, [r10-0xe8]                    
    stxb [r10-0x6f], r1                     
    mov64 r1, 5                                     r1 = 5 as i32 as i64 as u64
lbb_29855:
    stxb [r10-0x70], r1                     
    mov64 r6, r10                                   r6 = r10
    add64 r6, -56                                   r6 += -56   ///  r6 = r6.wrapping_add(-56 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -112                                  r2 += -112   ///  r2 = r2.wrapping_add(-112 as i32 as i64 as u64)
    mov64 r1, r6                                    r1 = r6
    mov64 r3, 56                                    r3 = 56 as i32 as i64 as u64
    call function_48190                     
    lddw r1, 0x100061f40 --> b"In practice impossible decimal overflow"        r1 load str located at 4295368512
    mov64 r2, 39                                    r2 = 39 as i32 as i64 as u64
    mov64 r3, r6                                    r3 = r6
    lddw r4, 0x100065e30 --> b"\x00\x00\x00\x00\xd8\xa5\x02\x008\x00\x00\x00\x00\x00\x00\x00\x08\x00\x00…        r4 load str located at 4295384624
    lddw r5, 0x100065e68 --> b"\x00\x00\x00\x00q\x1e\x06\x00\x1e\x00\x00\x00\x00\x00\x00\x000\x01\x00\x0…        r5 load str located at 4295384680
    call function_44299                     
    syscall [invalid]                       
lbb_29873:
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    stxdw [r10-0x60], r1                    
    ldxdw r1, [r10-0xd8]                    
    stxdw [r10-0x68], r1                    
    stxb [r10-0x6f], r6                     
    mov64 r1, 5                                     r1 = 5 as i32 as i64 as u64
lbb_29879:
    stxb [r10-0x70], r1                     
    mov64 r6, r10                                   r6 = r10
    add64 r6, -56                                   r6 += -56   ///  r6 = r6.wrapping_add(-56 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -112                                  r2 += -112   ///  r2 = r2.wrapping_add(-112 as i32 as i64 as u64)
    mov64 r1, r6                                    r1 = r6
    mov64 r3, 56                                    r3 = 56 as i32 as i64 as u64
    call function_48190                     
    lddw r1, 0x100061f40 --> b"In practice impossible decimal overflow"        r1 load str located at 4295368512
    mov64 r2, 39                                    r2 = 39 as i32 as i64 as u64
    mov64 r3, r6                                    r3 = r6
    lddw r4, 0x100065e30 --> b"\x00\x00\x00\x00\xd8\xa5\x02\x008\x00\x00\x00\x00\x00\x00\x00\x08\x00\x00…        r4 load str located at 4295384624
    lddw r5, 0x100065e50 --> b"\x00\x00\x00\x00q\x1e\x06\x00\x1e\x00\x00\x00\x00\x00\x00\x005\x01\x00\x0…        r5 load str located at 4295384656
    call function_44299                     
    syscall [invalid]                       
lbb_29897:
    mov64 r1, 28                                    r1 = 28 as i32 as i64 as u64
    stxb [r10-0x6d], r1                     
    stxb [r10-0x6e], r6                     
    ldxdw r1, [r10-0xe8]                    
    stxb [r10-0x6f], r1                     
    mov64 r1, 6                                     r1 = 6 as i32 as i64 as u64
    ja lbb_29855                                    if true { pc += -49 }
lbb_29904:
    mov64 r1, 28                                    r1 = 28 as i32 as i64 as u64
    stxb [r10-0x6d], r1                     
    stxb [r10-0x6e], r8                     
    stxb [r10-0x6f], r6                     
    mov64 r1, 6                                     r1 = 6 as i32 as i64 as u64
    ja lbb_29879                                    if true { pc += -31 }

function_29910:
    mov64 r7, r2                                    r7 = r2
    mov64 r6, r1                                    r6 = r1
    mov64 r1, r10                                   r1 = r10
    add64 r1, -72                                   r1 += -72   ///  r1 = r1.wrapping_add(-72 as i32 as i64 as u64)
    lddw r3, 0x10005fbc4 --> b"bids != Some <= x1e-true to None    asksBadUnexpec"        r3 load str located at 4295359428
    call function_29221                     
    ldxb r8, [r10-0x48]                     
    jne r8, 56, lbb_29939                           if r8 != (56 as i32 as i64 as u64) { pc += 20 }
    mov64 r2, r7                                    r2 = r7
    add64 r2, 320                                   r2 += 320   ///  r2 = r2.wrapping_add(320 as i32 as i64 as u64)
    mov64 r1, r10                                   r1 = r10
    add64 r1, -72                                   r1 += -72   ///  r1 = r1.wrapping_add(-72 as i32 as i64 as u64)
    lddw r3, 0x10005fbe8 --> b"asksBadUnexpected variant tag: \x00BidPrecisionLoss n"        r3 load str located at 4295359464
    call function_29221                     
    ldxb r8, [r10-0x48]                     
    jeq r8, 56, lbb_29929                           if r8 == (56 as i32 as i64 as u64) { pc += 1 }
    ja lbb_29939                                    if true { pc += 10 }
lbb_29929:
    add64 r7, 640                                   r7 += 640   ///  r7 = r7.wrapping_add(640 as i32 as i64 as u64)
    mov64 r1, r10                                   r1 = r10
    add64 r1, -72                                   r1 += -72   ///  r1 = r1.wrapping_add(-72 as i32 as i64 as u64)
    mov64 r2, r7                                    r2 = r7
    call function_29539                     
    ldxb r8, [r10-0x48]                     
    jeq r8, 56, lbb_29937                           if r8 == (56 as i32 as i64 as u64) { pc += 1 }
    ja lbb_29939                                    if true { pc += 2 }
lbb_29937:
    mov64 r8, 56                                    r8 = 56 as i32 as i64 as u64
    ja lbb_29945                                    if true { pc += 6 }
lbb_29939:
    mov64 r1, r6                                    r1 = r6
    add64 r1, 1                                     r1 += 1   ///  r1 = r1.wrapping_add(1 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -71                                   r2 += -71   ///  r2 = r2.wrapping_add(-71 as i32 as i64 as u64)
    mov64 r3, 71                                    r3 = 71 as i32 as i64 as u64
    call function_48190                     
lbb_29945:
    stxb [r6+0x0], r8                       
    exit                                    

function_29947:
    mov64 r7, r2                                    r7 = r2
    mov64 r6, r1                                    r6 = r1
    ldxb r1, [r6+0x0]                       
    jeq r1, 0, lbb_29956                            if r1 == (0 as i32 as i64 as u64) { pc += 5 }
    jne r1, 255, lbb_29959                          if r1 != (255 as i32 as i64 as u64) { pc += 7 }
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    stxdw [r10-0x70], r1                    
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    ja lbb_30003                                    if true { pc += 47 }
lbb_29956:
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    stxdw [r10-0x70], r1                    
    ja lbb_30003                                    if true { pc += 44 }
lbb_29959:
    stxw [r10-0x5c], r1                     
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    stxw [r10-0x58], r1                     
    stxdw [r10-0x64], r1                    
    mov64 r2, 1                                     r2 = 1 as i32 as i64 as u64
    stxdw [r10-0xff8], r2                   
    stxdw [r10-0x1000], r1                  
    mov64 r8, r10                                   r8 = r10
    add64 r8, -84                                   r8 += -84   ///  r8 = r8.wrapping_add(-84 as i32 as i64 as u64)
    mov64 r5, r10                                   r5 = r10
    mov64 r1, r8                                    r1 = r8
    mov64 r2, 2550                                  r2 = 2550 as i32 as i64 as u64
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
    mov64 r4, 0                                     r4 = 0 as i32 as i64 as u64
    call function_33183                     
    mov64 r1, r10                                   r1 = r10
    add64 r1, -68                                   r1 += -68   ///  r1 = r1.wrapping_add(-68 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -100                                  r2 += -100   ///  r2 = r2.wrapping_add(-100 as i32 as i64 as u64)
    mov64 r3, r8                                    r3 = r8
    call function_35767                     
    ldxw r1, [r10-0x44]                     
    jeq r1, 0, lbb_30000                            if r1 == (0 as i32 as i64 as u64) { pc += 18 }
    jeq r1, 1, lbb_30026                            if r1 == (1 as i32 as i64 as u64) { pc += 43 }
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    stxdw [r10-0x28], r1                    
    lddw r1, 0x100065740 --> b"\x00\x00\x00\x00\x88\xfc\x05\x00\x10\x00\x00\x00\x00\x00\x00\x00\x00\x00\…        r1 load str located at 4295382848
    stxdw [r10-0x30], r1                    
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    stxdw [r10-0x10], r1                    
    stxdw [r10-0x18], r1                    
    lddw r1, 0x100060ee8 --> b"src/arithmetic_impls.rsAddition overflowedMultipli"        r1 load str located at 4295364328
    stxdw [r10-0x20], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -48                                   r1 += -48   ///  r1 = r1.wrapping_add(-48 as i32 as i64 as u64)
    lddw r2, 0x100065750 --> b"\x00\x00\x00\x00\xe8\x0e\x06\x00\x17\x00\x00\x00\x00\x00\x00\x00\xdb\x00\…        r2 load str located at 4295382864
    call function_44240                     
    syscall [invalid]                       
lbb_30000:
    ldxdw r1, [r10-0x38]                    
    stxdw [r10-0x70], r1                    
    ldxdw r1, [r10-0x40]                    
lbb_30003:
    stxdw [r10-0x78], r1                    
    mov64 r8, r10                                   r8 = r10
    add64 r8, -48                                   r8 += -48   ///  r8 = r8.wrapping_add(-48 as i32 as i64 as u64)
    mov64 r1, r8                                    r1 = r8
    mov64 r2, r7                                    r2 = r7
    lddw r3, 0x100061f67 --> b"TinyRatio"           r3 load str located at 4295368551
    mov64 r4, 9                                     r4 = 9 as i32 as i64 as u64
    call function_46086                     
    mov64 r1, r8                                    r1 = r8
    mov64 r2, r6                                    r2 = r6
    lddw r3, 0x100065e90 --> b"\x00\x00\x00\x00\xc8\xa5\x02\x00\x01\x00\x00\x00\x00\x00\x00\x00\x01\x00\…        r3 load str located at 4295384720
    call function_44672                     
    mov64 r2, r10                                   r2 = r10
    add64 r2, -120                                  r2 += -120   ///  r2 = r2.wrapping_add(-120 as i32 as i64 as u64)
    mov64 r1, r0                                    r1 = r0
    lddw r3, 0x100065eb0 --> b"\x00\x00\x00\x00\xd0\xa5\x02\x00\x10\x00\x00\x00\x00\x00\x00\x00\x04\x00\…        r3 load str located at 4295384752
    call function_44672                     
    mov64 r1, r0                                    r1 = r0
    call function_44762                     
    exit                                    
lbb_30026:
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    stxdw [r10-0x28], r1                    
    lddw r1, 0x100065718 --> b"\x00\x00\x00\x00\xd5\x0e\x06\x00\x13\x00\x00\x00\x00\x00\x00\x00\x00\x00\…        r1 load str located at 4295382808
    stxdw [r10-0x30], r1                    
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    stxdw [r10-0x10], r1                    
    stxdw [r10-0x18], r1                    
    lddw r1, 0x100060ee8 --> b"src/arithmetic_impls.rsAddition overflowedMultipli"        r1 load str located at 4295364328
    stxdw [r10-0x20], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -48                                   r1 += -48   ///  r1 = r1.wrapping_add(-48 as i32 as i64 as u64)
    lddw r2, 0x100065728 --> b"\x00\x00\x00\x00\xe8\x0e\x06\x00\x17\x00\x00\x00\x00\x00\x00\x00\xda\x00\…        r2 load str located at 4295382824
    call function_44240                     
    syscall [invalid]                       

function_30043:
    mov64 r0, r1                                    r0 = r1
    mov64 r1, r2                                    r1 = r2
    and64 r1, 1                                     r1 &= 1   ///  r1 = r1.and(1)
    jne r1, 0, lbb_30056                            if r1 != (0 as i32 as i64 as u64) { pc += 9 }
    mov64 r1, r2                                    r1 = r2
lbb_30048:
    rsh64 r2, 1                                     r2 >>= 1   ///  r2 = r2.wrapping_shr(1)
    and64 r0, 255                                   r0 &= 255   ///  r0 = r0.and(255)
    mul64 r0, r0                                    r0 *= r0   ///  r0 = r0.wrapping_mul(r0)
    rsh64 r0, 8                                     r0 >>= 8   ///  r0 = r0.wrapping_shr(8)
    mov64 r3, r1                                    r3 = r1
    and64 r3, 2                                     r3 &= 2   ///  r3 = r3.and(2)
    mov64 r1, r2                                    r1 = r2
    jeq r3, 0, lbb_30048                            if r3 == (0 as i32 as i64 as u64) { pc += -8 }
lbb_30056:
    mov64 r1, r0                                    r1 = r0
    ja lbb_30062                                    if true { pc += 4 }
lbb_30058:
    mov64 r2, r3                                    r2 = r3
    rsh64 r2, 1                                     r2 >>= 1   ///  r2 = r2.wrapping_shr(1)
    jgt r3, 3, lbb_30062                            if r3 > (3 as i32 as i64 as u64) { pc += 1 }
    exit                                    
lbb_30062:
    mov64 r3, r2                                    r3 = r2
    and64 r1, 255                                   r1 &= 255   ///  r1 = r1.and(255)
    mul64 r1, r1                                    r1 *= r1   ///  r1 = r1.wrapping_mul(r1)
    rsh64 r1, 8                                     r1 >>= 8   ///  r1 = r1.wrapping_shr(8)
    and64 r2, 2                                     r2 &= 2   ///  r2 = r2.and(2)
    jeq r2, 0, lbb_30058                            if r2 == (0 as i32 as i64 as u64) { pc += -10 }
    and64 r0, 255                                   r0 &= 255   ///  r0 = r0.and(255)
    mov64 r2, r1                                    r2 = r1
    mul64 r2, r0                                    r2 *= r0   ///  r2 = r2.wrapping_mul(r0)
    rsh64 r2, 8                                     r2 >>= 8   ///  r2 = r2.wrapping_shr(8)
    mov64 r0, r2                                    r0 = r2
    ja lbb_30058                                    if true { pc += -16 }

function_30074:
    mov64 r3, r2                                    r3 = r2
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
    stxdw [r10-0x50], r2                    
    lddw r2, 0x100065e80 --> b"\x00\x00\x00\x00\xe8\x0e\x06\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\…        r2 load str located at 4295384704
    stxdw [r10-0x70], r2                    
    mov64 r2, 1                                     r2 = 1 as i32 as i64 as u64
    stxdw [r10-0x68], r2                    
    stxdw [r10-0x58], r2                    
    mov64 r2, r10                                   r2 = r10
    add64 r2, -64                                   r2 += -64   ///  r2 = r2.wrapping_add(-64 as i32 as i64 as u64)
    stxdw [r10-0x60], r2                    
    lddw r2, 0x100042110 --> b"\xbf'\x00\x00\x00\x00\x00\x00\xbf\x18\x00\x00\x00\x00\x00\x00yu\x18\x00\x…        r2 load str located at 4295237904
    stxdw [r10-0x38], r2                    
    stxdw [r10-0x40], r1                    
    mov64 r2, r10                                   r2 = r10
    add64 r2, -112                                  r2 += -112   ///  r2 = r2.wrapping_add(-112 as i32 as i64 as u64)
    mov64 r1, r3                                    r1 = r3
    call function_45907                     
    exit                                    

function_30095:
    mov64 r7, r3                                    r7 = r3
    mov64 r6, r1                                    r6 = r1
    ldxdw r1, [r7+0x0]                      
    ldxdw r3, [r2+0x0]                      
    jeq r3, r1, lbb_30102                           if r3 == r1 { pc += 2 }
lbb_30100:
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    ja lbb_30112                                    if true { pc += 10 }
lbb_30102:
    ldxdw r1, [r7+0x8]                      
    ldxdw r3, [r2+0x8]                      
    jne r3, r1, lbb_30100                           if r3 != r1 { pc += -5 }
    ldxdw r1, [r7+0x10]                     
    ldxdw r3, [r2+0x10]                     
    jne r3, r1, lbb_30100                           if r3 != r1 { pc += -8 }
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    ldxdw r3, [r7+0x18]                     
    ldxdw r2, [r2+0x18]                     
    jne r2, r3, lbb_30100                           if r2 != r3 { pc += -12 }
lbb_30112:
    stxdw [r10-0xa8], r5                    
    stxdw [r10-0xb0], r4                    
    jeq r1, 0, lbb_30167                            if r1 == (0 as i32 as i64 as u64) { pc += 52 }
    lddw r1, 0x100065ed0 --> b"\x00\x00\x00\x00p\x1f\x06\x00\x0f\x00\x00\x00\x00\x00\x00\x00^\x00\x00\x0…        r1 load str located at 4295384784
    stxdw [r10-0xa0], r1                    
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    stxdw [r10-0x60], r1                    
    lddw r1, 0x100065a98 --> b"\x00\x00\x00\x00\xe8\x0e\x06\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\…        r1 load str located at 4295383704
    stxdw [r10-0x80], r1                    
    mov64 r1, 2                                     r1 = 2 as i32 as i64 as u64
    stxdw [r10-0x78], r1                    
    stxdw [r10-0x68], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -80                                   r1 += -80   ///  r1 = r1.wrapping_add(-80 as i32 as i64 as u64)
    stxdw [r10-0x70], r1                    
    lddw r1, 0x10002a248 --> b"y\x11\x00\x00\x00\x00\x00\x00\x85\x10\x00\x00%X\x00\x00\x95\x00\x00\x00\x…        r1 load str located at 4295139912
    stxdw [r10-0x38], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -160                                  r1 += -160   ///  r1 = r1.wrapping_add(-160 as i32 as i64 as u64)
    stxdw [r10-0x40], r1                    
    lddw r1, 0x10002a388 --> b"\xbf#\x00\x00\x00\x00\x00\x00y\x12\x08\x00\x00\x00\x00\x00y\x11\x00\x00\x…        r1 load str located at 4295140232
    stxdw [r10-0x48], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -176                                  r1 += -176   ///  r1 = r1.wrapping_add(-176 as i32 as i64 as u64)
    stxdw [r10-0x50], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -152                                  r1 += -152   ///  r1 = r1.wrapping_add(-152 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -128                                  r2 += -128   ///  r2 = r2.wrapping_add(-128 as i32 as i64 as u64)
    call function_43415                     
    ldxdw r8, [r10-0x90]                    
    ldxdw r9, [r10-0x98]                    
    ldxdw r2, [r10-0x88]                    
    mov64 r1, r9                                    r1 = r9
    syscall [invalid]                       
    jeq r8, 0, lbb_30156                            if r8 == (0 as i32 as i64 as u64) { pc += 4 }
    mov64 r1, r9                                    r1 = r9
    mov64 r2, r8                                    r2 = r8
    mov64 r3, 1                                     r3 = 1 as i32 as i64 as u64
    call function_21385                     
lbb_30156:
    mov64 r1, 34                                    r1 = 34 as i32 as i64 as u64
    stxb [r6+0x0], r1                       
    ldxdw r1, [r7+0x0]                      
    stxdw [r6+0x1], r1                      
    ldxdw r1, [r7+0x8]                      
    stxdw [r6+0x9], r1                      
    ldxdw r1, [r7+0x10]                     
    stxdw [r6+0x11], r1                     
    ldxdw r1, [r7+0x18]                     
    stxdw [r6+0x19], r1                     
    ja lbb_30169                                    if true { pc += 2 }
lbb_30167:
    mov64 r1, 56                                    r1 = 56 as i32 as i64 as u64
    stxb [r6+0x0], r1                       
lbb_30169:
    exit                                    

function_30170:
    ldxdw r3, [r2+0x0]                      
    ldxdw r4, [r1+0x20]                     
    jeq r4, r3, lbb_30175                           if r4 == r3 { pc += 2 }
lbb_30173:
    mov64 r3, 1                                     r3 = 1 as i32 as i64 as u64
    ja lbb_30185                                    if true { pc += 10 }
lbb_30175:
    ldxdw r3, [r2+0x8]                      
    ldxdw r4, [r1+0x28]                     
    jne r4, r3, lbb_30173                           if r4 != r3 { pc += -5 }
    ldxdw r3, [r2+0x10]                     
    ldxdw r4, [r1+0x30]                     
    jne r4, r3, lbb_30173                           if r4 != r3 { pc += -8 }
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
    ldxdw r2, [r2+0x18]                     
    ldxdw r1, [r1+0x38]                     
    jne r1, r2, lbb_30173                           if r1 != r2 { pc += -12 }
lbb_30185:
    mov64 r0, 1                                     r0 = 1 as i32 as i64 as u64
    jeq r3, 0, lbb_30188                            if r3 == (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r0, 0                                     r0 = 0 as i32 as i64 as u64
lbb_30188:
    exit                                    

function_30189:
    ldxb r3, [r1+0x0]                       
    jsgt r3, 27, lbb_30204                          if (r3 as i64) > (27 as i32 as i64) { pc += 13 }
    jsgt r3, 13, lbb_30217                          if (r3 as i64) > (13 as i32 as i64) { pc += 25 }
    jsgt r3, 6, lbb_30238                           if (r3 as i64) > (6 as i32 as i64) { pc += 45 }
    jsgt r3, 2, lbb_30296                           if (r3 as i64) > (2 as i32 as i64) { pc += 102 }
    jeq r3, 0, lbb_30510                            if r3 == (0 as i32 as i64 as u64) { pc += 315 }
    jeq r3, 1, lbb_30525                            if r3 == (1 as i32 as i64 as u64) { pc += 329 }
    mov64 r3, r1                                    r3 = r1
    add64 r3, 8                                     r3 += 8   ///  r3 = r3.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x9d0], r3                   
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
    stxdw [r10-0xa48], r3                   
    lddw r3, 0x100065f28 --> b"\x00\x00\x00\x00\xcf\x1f\x06\x00!\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00…        r3 load str located at 4295384872
    ja lbb_31000                                    if true { pc += 796 }
lbb_30204:
    jsgt r3, 41, lbb_30226                          if (r3 as i64) > (41 as i32 as i64) { pc += 21 }
    jsgt r3, 34, lbb_30255                          if (r3 as i64) > (34 as i32 as i64) { pc += 49 }
    jsgt r3, 30, lbb_30305                          if (r3 as i64) > (30 as i32 as i64) { pc += 98 }
    jeq r3, 28, lbb_30533                           if r3 == (28 as i32 as i64 as u64) { pc += 325 }
    jeq r3, 29, lbb_30544                           if r3 == (29 as i32 as i64 as u64) { pc += 335 }
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
    stxdw [r10-0xa48], r3                   
    lddw r3, 0x100066298 --> b"\x00\x00\x00\x00\xf1#\x06\x00'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x0…        r3 load str located at 4295385752
    stxdw [r10-0xa68], r3                   
    mov64 r3, 1                                     r3 = 1 as i32 as i64 as u64
    stxdw [r10-0xa60], r3                   
    ja lbb_30518                                    if true { pc += 301 }
lbb_30217:
    jsgt r3, 20, lbb_30265                          if (r3 as i64) > (20 as i32 as i64) { pc += 47 }
    jsgt r3, 16, lbb_30315                          if (r3 as i64) > (16 as i32 as i64) { pc += 96 }
    jeq r3, 14, lbb_30549                           if r3 == (14 as i32 as i64 as u64) { pc += 329 }
    jeq r3, 15, lbb_30557                           if r3 == (15 as i32 as i64 as u64) { pc += 336 }
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
    stxdw [r10-0xa48], r3                   
    lddw r3, 0x1000660f8 --> b"\x00\x00\x00\x00\xa7!\x06\x00"\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x0…        r3 load str located at 4295385336
    ja lbb_30438                                    if true { pc += 212 }
lbb_30226:
    jsgt r3, 48, lbb_30288                          if (r3 as i64) > (48 as i32 as i64) { pc += 61 }
    jsgt r3, 44, lbb_30325                          if (r3 as i64) > (44 as i32 as i64) { pc += 97 }
    jeq r3, 42, lbb_30564                           if r3 == (42 as i32 as i64 as u64) { pc += 335 }
    jeq r3, 43, lbb_30571                           if r3 == (43 as i32 as i64 as u64) { pc += 341 }
    mov64 r3, r1                                    r3 = r1
    add64 r3, 8                                     r3 += 8   ///  r3 = r3.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x9d0], r3                   
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
    stxdw [r10-0xa48], r3                   
    lddw r3, 0x100066428 --> b"\x00\x00\x00\x00\xb0%\x06\x00%\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x0…        r3 load str located at 4295386152
    ja lbb_30275                                    if true { pc += 37 }
lbb_30238:
    jsgt r3, 9, lbb_30365                           if (r3 as i64) > (9 as i32 as i64) { pc += 126 }
    jeq r3, 7, lbb_30578                            if r3 == (7 as i32 as i64 as u64) { pc += 338 }
    jeq r3, 8, lbb_30589                            if r3 == (8 as i32 as i64 as u64) { pc += 348 }
    mov64 r3, r1                                    r3 = r1
    add64 r3, 8                                     r3 += 8   ///  r3 = r3.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0xa10], r3                   
    mov64 r3, r1                                    r3 = r1
    add64 r3, 16                                    r3 += 16   ///  r3 = r3.wrapping_add(16 as i32 as i64 as u64)
    stxdw [r10-0x9d8], r3                   
    mov64 r3, r1                                    r3 = r1
    add64 r3, 24                                    r3 += 24   ///  r3 = r3.wrapping_add(24 as i32 as i64 as u64)
    stxdw [r10-0x9d0], r3                   
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
    stxdw [r10-0x9e8], r3                   
    lddw r3, 0x100065ff8 --> b"\x00\x00\x00\x00\xc8 \x06\x00"\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x0…        r3 load str located at 4295385080
    ja lbb_30832                                    if true { pc += 577 }
lbb_30255:
    jsgt r3, 37, lbb_30393                          if (r3 as i64) > (37 as i32 as i64) { pc += 137 }
    jeq r3, 35, lbb_30597                           if r3 == (35 as i32 as i64 as u64) { pc += 340 }
    jeq r3, 36, lbb_30632                           if r3 == (36 as i32 as i64 as u64) { pc += 374 }
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
    stxdw [r10-0xa48], r3                   
    mov64 r3, 2                                     r3 = 2 as i32 as i64 as u64
    stxdw [r10-0xa60], r3                   
    lddw r3, 0x100066358 --> b"\x00\x00\x00\x00\x80\x09\x06\x00\x08\x00\x00\x00\x00\x00\x00\x00\x00\x00\…        r3 load str located at 4295385944
    ja lbb_30979                                    if true { pc += 714 }
lbb_30265:
    jsgt r3, 23, lbb_30404                          if (r3 as i64) > (23 as i32 as i64) { pc += 138 }
    jeq r3, 21, lbb_30675                           if r3 == (21 as i32 as i64 as u64) { pc += 408 }
    jeq r3, 22, lbb_30686                           if r3 == (22 as i32 as i64 as u64) { pc += 418 }
    mov64 r3, r1                                    r3 = r1
    add64 r3, 8                                     r3 += 8   ///  r3 = r3.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x9d0], r3                   
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
    stxdw [r10-0xa48], r3                   
    lddw r3, 0x1000661b8 --> b"\x00\x00\x00\x00\xd2"\x06\x00\x0c\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00…        r3 load str located at 4295385528
lbb_30275:
    stxdw [r10-0xa68], r3                   
    mov64 r3, 2                                     r3 = 2 as i32 as i64 as u64
    stxdw [r10-0xa60], r3                   
    stxdw [r10-0xa50], r3                   
    mov64 r3, r10                                   r3 = r10
    add64 r3, -2568                                 r3 += -2568   ///  r3 = r3.wrapping_add(-2568 as i32 as i64 as u64)
    stxdw [r10-0xa58], r3                   
    mov64 r3, r10                                   r3 = r10
    add64 r3, -2504                                 r3 += -2504   ///  r3 = r3.wrapping_add(-2504 as i32 as i64 as u64)
    stxdw [r10-0x9f8], r3                   
    lddw r3, 0x10002a310 --> b"y\x11\x00\x00\x00\x00\x00\x00\x85\x10\x00\x00\x87g\x00\x00\x95\x00\x00\x0…        r3 load str located at 4295140112
    ja lbb_31012                                    if true { pc += 724 }
lbb_30288:
    jsgt r3, 51, lbb_30414                          if (r3 as i64) > (51 as i32 as i64) { pc += 125 }
    jeq r3, 49, lbb_30697                           if r3 == (49 as i32 as i64 as u64) { pc += 407 }
    jeq r3, 50, lbb_30733                           if r3 == (50 as i32 as i64 as u64) { pc += 442 }
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
    stxdw [r10-0xa48], r3                   
    lddw r3, 0x100066568 --> b"\x00\x00\x00\x00\xf9&\x06\x00.\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x0…        r3 load str located at 4295386472
    ja lbb_30438                                    if true { pc += 142 }
lbb_30296:
    jsgt r3, 4, lbb_30421                           if (r3 as i64) > (4 as i32 as i64) { pc += 124 }
    jeq r3, 3, lbb_30766                            if r3 == (3 as i32 as i64 as u64) { pc += 468 }
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
    stxdw [r10-0xa48], r3                   
    mov64 r3, 2                                     r3 = 2 as i32 as i64 as u64
    stxdw [r10-0xa60], r3                   
    lddw r3, 0x100065f58 --> b"\x00\x00\x00\x00% \x06\x00\x0f\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x0…        r3 load str located at 4295384920
    ja lbb_30979                                    if true { pc += 674 }
lbb_30305:
    jsgt r3, 32, lbb_30427                          if (r3 as i64) > (32 as i32 as i64) { pc += 121 }
    jeq r3, 31, lbb_30780                           if r3 == (31 as i32 as i64 as u64) { pc += 473 }
    mov64 r3, r1                                    r3 = r1
    add64 r3, 1                                     r3 += 1   ///  r3 = r3.wrapping_add(1 as i32 as i64 as u64)
    stxdw [r10-0x9d0], r3                   
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
    stxdw [r10-0xa48], r3                   
    lddw r3, 0x1000662a8 --> b"\x00\x00\x00\x00A$\x06\x00\x19\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x0…        r3 load str located at 4295385768
    ja lbb_30922                                    if true { pc += 607 }
lbb_30315:
    jsgt r3, 18, lbb_30433                          if (r3 as i64) > (18 as i32 as i64) { pc += 117 }
    jeq r3, 17, lbb_30784                           if r3 == (17 as i32 as i64 as u64) { pc += 467 }
    mov64 r3, r1                                    r3 = r1
    add64 r3, 1                                     r3 += 1   ///  r3 = r3.wrapping_add(1 as i32 as i64 as u64)
    stxdw [r10-0x9d0], r3                   
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
    stxdw [r10-0xa48], r3                   
    lddw r3, 0x100066128 --> b"\x00\x00\x00\x00\xff!\x06\x00\x1a\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00…        r3 load str located at 4295385384
    ja lbb_30922                                    if true { pc += 597 }
lbb_30325:
    jsgt r3, 46, lbb_30442                          if (r3 as i64) > (46 as i32 as i64) { pc += 116 }
    jeq r3, 45, lbb_30792                           if r3 == (45 as i32 as i64 as u64) { pc += 465 }
    mov64 r3, r1                                    r3 = r1
    add64 r3, 4                                     r3 += 4   ///  r3 = r3.wrapping_add(4 as i32 as i64 as u64)
    stxdw [r10-0xa10], r3                   
    mov64 r3, r1                                    r3 = r1
    add64 r3, 20                                    r3 += 20   ///  r3 = r3.wrapping_add(20 as i32 as i64 as u64)
    stxdw [r10-0x9d8], r3                   
    mov64 r3, r1                                    r3 = r1
    add64 r3, 1                                     r3 += 1   ///  r3 = r3.wrapping_add(1 as i32 as i64 as u64)
    stxdw [r10-0x9d0], r3                   
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
    stxdw [r10-0x9e8], r3                   
    lddw r3, 0x100066478 --> b"\x00\x00\x00\x00\xb0\xff\x05\x00 \x00\x00\x00\x00\x00\x00\x00\x00\x00\x00…        r3 load str located at 4295386232
    stxdw [r10-0xa08], r3                   
    lddw r3, 0x10002a2e0 --> b"\xbf#\x00\x00\x00\x00\x00\x00y\x11\x00\x00\x00\x00\x00\x00y\x12\x08\x00\x…        r3 load str located at 4295140064
    stxdw [r10-0xa30], r3                   
    mov64 r3, r10                                   r3 = r10
    add64 r3, -2504                                 r3 += -2504   ///  r3 = r3.wrapping_add(-2504 as i32 as i64 as u64)
    stxdw [r10-0xa38], r3                   
    lddw r3, 0x10002a2b0 --> b"y\x11\x00\x00\x00\x00\x00\x00\x85\x10\x00\x00{g\x00\x00\x95\x00\x00\x00\x…        r3 load str located at 4295140016
    stxdw [r10-0xa40], r3                   
    mov64 r3, r10                                   r3 = r10
    add64 r3, -2512                                 r3 += -2512   ///  r3 = r3.wrapping_add(-2512 as i32 as i64 as u64)
    stxdw [r10-0xa48], r3                   
    mov64 r3, r10                                   r3 = r10
    add64 r3, -2520                                 r3 += -2520   ///  r3 = r3.wrapping_add(-2520 as i32 as i64 as u64)
    stxdw [r10-0xa58], r3                   
    lddw r3, 0x10002a298 --> b"y\x11\x00\x00\x00\x00\x00\x00\x85\x10\x00\x00\xcd/\x00\x00\x95\x00\x00\x0…        r3 load str located at 4295139992
    stxdw [r10-0xa50], r3                   
    stxdw [r10-0xa60], r3                   
    mov64 r3, r10                                   r3 = r10
    add64 r3, -2576                                 r3 += -2576   ///  r3 = r3.wrapping_add(-2576 as i32 as i64 as u64)
    stxdw [r10-0xa68], r3                   
    add64 r1, 40                                    r1 += 40   ///  r1 = r1.wrapping_add(40 as i32 as i64 as u64)
    ja lbb_30852                                    if true { pc += 487 }
lbb_30365:
    jsgt r3, 11, lbb_30472                          if (r3 as i64) > (11 as i32 as i64) { pc += 106 }
    jeq r3, 10, lbb_30819                           if r3 == (10 as i32 as i64 as u64) { pc += 452 }
    mov64 r3, r1                                    r3 = r1
    add64 r3, 16                                    r3 += 16   ///  r3 = r3.wrapping_add(16 as i32 as i64 as u64)
    stxdw [r10-0x9d0], r3                   
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
    stxdw [r10-0xa48], r3                   
    lddw r3, 0x100066078 --> b"\x00\x00\x00\x00\x14!\x06\x00"\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x0…        r3 load str located at 4295385208
    stxdw [r10-0xa68], r3                   
    mov64 r3, 2                                     r3 = 2 as i32 as i64 as u64
    stxdw [r10-0xa60], r3                   
    stxdw [r10-0xa50], r3                   
    mov64 r3, r10                                   r3 = r10
    add64 r3, -2568                                 r3 += -2568   ///  r3 = r3.wrapping_add(-2568 as i32 as i64 as u64)
    stxdw [r10-0xa58], r3                   
    mov64 r3, r10                                   r3 = r10
    add64 r3, -2504                                 r3 += -2504   ///  r3 = r3.wrapping_add(-2504 as i32 as i64 as u64)
    stxdw [r10-0x9f8], r3                   
    lddw r3, 0x10002a278 --> b"y\x11\x00\x00\x00\x00\x00\x00y\x11\x00\x00\x00\x00\x00\x00\x85\x10\x00\x0…        r3 load str located at 4295139960
    stxdw [r10-0x9f0], r3                   
    stxdw [r10-0xa00], r3                   
    mov64 r3, r10                                   r3 = r10
    add64 r3, -2512                                 r3 += -2512   ///  r3 = r3.wrapping_add(-2512 as i32 as i64 as u64)
    stxdw [r10-0xa08], r3                   
    add64 r1, 24                                    r1 += 24   ///  r1 = r1.wrapping_add(24 as i32 as i64 as u64)
    ja lbb_31037                                    if true { pc += 644 }
lbb_30393:
    jsgt r3, 39, lbb_30481                          if (r3 as i64) > (39 as i32 as i64) { pc += 87 }
    jeq r3, 38, lbb_30860                           if r3 == (38 as i32 as i64 as u64) { pc += 465 }
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
    stxdw [r10-0xa48], r3                   
    mov64 r3, 2                                     r3 = 2 as i32 as i64 as u64
    stxdw [r10-0xa60], r3                   
    lddw r3, 0x100066388 --> b"\x00\x00\x00\x00'%\x06\x00\x0c\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x0…        r3 load str located at 4295385992
    stxdw [r10-0xa68], r3                   
    mov64 r3, 1                                     r3 = 1 as i32 as i64 as u64
    ja lbb_30960                                    if true { pc += 556 }
lbb_30404:
    jsgt r3, 25, lbb_30489                          if (r3 as i64) > (25 as i32 as i64) { pc += 84 }
    jeq r3, 24, lbb_30865                           if r3 == (24 as i32 as i64 as u64) { pc += 459 }
    mov64 r3, r1                                    r3 = r1
    add64 r3, 1                                     r3 += 1   ///  r3 = r3.wrapping_add(1 as i32 as i64 as u64)
    stxdw [r10-0x9d0], r3                   
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
    stxdw [r10-0xa48], r3                   
    lddw r3, 0x100066208 --> b"\x00\x00\x00\x00G#\x06\x00#\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x…        r3 load str located at 4295385608
    ja lbb_30922                                    if true { pc += 508 }
lbb_30414:
    jsgt r3, 53, lbb_30495                          if (r3 as i64) > (53 as i32 as i64) { pc += 80 }
    jeq r3, 52, lbb_30901                           if r3 == (52 as i32 as i64 as u64) { pc += 485 }
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
    stxdw [r10-0xa48], r3                   
    lddw r3, 0x100066588 --> b"\x00\x00\x00\x009'\x06\x00\x09\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x0…        r3 load str located at 4295386504
    ja lbb_30438                                    if true { pc += 17 }
lbb_30421:
    jeq r3, 5, lbb_30915                            if r3 == (5 as i32 as i64 as u64) { pc += 493 }
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
    stxdw [r10-0xa48], r3                   
    lddw r3, 0x100065f98 --> b"\x00\x00\x00\x00o \x06\x00-\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x…        r3 load str located at 4295384984
    ja lbb_30438                                    if true { pc += 11 }
lbb_30427:
    jeq r3, 33, lbb_30941                           if r3 == (33 as i32 as i64 as u64) { pc += 513 }
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
    stxdw [r10-0xa48], r3                   
    lddw r3, 0x1000662c8 --> b"\x00\x00\x00\x00\x8a$\x06\x00%\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x0…        r3 load str located at 4295385800
    ja lbb_30438                                    if true { pc += 5 }
lbb_30433:
    jeq r3, 19, lbb_30947                           if r3 == (19 as i32 as i64 as u64) { pc += 513 }
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
    stxdw [r10-0xa48], r3                   
    lddw r3, 0x100066148 --> b"\x00\x00\x00\x00B"\x06\x00\x1e\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x0…        r3 load str located at 4295385416
lbb_30438:
    stxdw [r10-0xa68], r3                   
    mov64 r3, 1                                     r3 = 1 as i32 as i64 as u64
    stxdw [r10-0xa60], r3                   
    ja lbb_30981                                    if true { pc += 539 }
lbb_30442:
    jeq r3, 47, lbb_30953                           if r3 == (47 as i32 as i64 as u64) { pc += 510 }
    mov64 r3, r1                                    r3 = r1
    add64 r3, 24                                    r3 += 24   ///  r3 = r3.wrapping_add(24 as i32 as i64 as u64)
    stxdw [r10-0x9d0], r3                   
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
    stxdw [r10-0xa48], r3                   
    mov64 r3, 3                                     r3 = 3 as i32 as i64 as u64
    stxdw [r10-0xa60], r3                   
    lddw r3, 0x1000664c8 --> b"\x00\x00\x00\x00?&\x06\x00\x0f\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x0…        r3 load str located at 4295386312
    stxdw [r10-0xa68], r3                   
    mov64 r3, 2                                     r3 = 2 as i32 as i64 as u64
    stxdw [r10-0xa50], r3                   
    mov64 r3, r10                                   r3 = r10
    add64 r3, -2568                                 r3 += -2568   ///  r3 = r3.wrapping_add(-2568 as i32 as i64 as u64)
    stxdw [r10-0xa58], r3                   
    lddw r3, 0x10002a298 --> b"y\x11\x00\x00\x00\x00\x00\x00\x85\x10\x00\x00\xcd/\x00\x00\x95\x00\x00\x0…        r3 load str located at 4295139992
    stxdw [r10-0x9f0], r3                   
    mov64 r3, r10                                   r3 = r10
    add64 r3, -2504                                 r3 += -2504   ///  r3 = r3.wrapping_add(-2504 as i32 as i64 as u64)
    stxdw [r10-0x9f8], r3                   
    lddw r3, 0x10002a328 --> b"\xbf#\x00\x00\x00\x00\x00\x00y\x11\x00\x00\x00\x00\x00\x00y\x12\x10\x00\x…        r3 load str located at 4295140136
    stxdw [r10-0xa00], r3                   
    mov64 r3, r10                                   r3 = r10
    add64 r3, -2512                                 r3 += -2512   ///  r3 = r3.wrapping_add(-2512 as i32 as i64 as u64)
    stxdw [r10-0xa08], r3                   
    add64 r1, 4                                     r1 += 4   ///  r1 = r1.wrapping_add(4 as i32 as i64 as u64)
    ja lbb_31037                                    if true { pc += 565 }
lbb_30472:
    jeq r3, 12, lbb_30967                           if r3 == (12 as i32 as i64 as u64) { pc += 494 }
    mov64 r3, r1                                    r3 = r1
    add64 r3, 1                                     r3 += 1   ///  r3 = r3.wrapping_add(1 as i32 as i64 as u64)
    stxdw [r10-0x9d0], r3                   
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
    stxdw [r10-0xa48], r3                   
    lddw r3, 0x100066098 --> b"\x00\x00\x00\x00W!\x06\x00\x18\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x0…        r3 load str located at 4295385240
    ja lbb_30922                                    if true { pc += 441 }
lbb_30481:
    jeq r3, 40, lbb_30973                           if r3 == (40 as i32 as i64 as u64) { pc += 491 }
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
    stxdw [r10-0xa48], r3                   
    mov64 r3, 2                                     r3 = 2 as i32 as i64 as u64
    stxdw [r10-0xa60], r3                   
    lddw r3, 0x1000663c8 --> b"\x00\x00\x00\x00t%\x06\x00\x05\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x0…        r3 load str located at 4295386056
    ja lbb_30979                                    if true { pc += 490 }
lbb_30489:
    jeq r3, 26, lbb_30993                           if r3 == (26 as i32 as i64 as u64) { pc += 503 }
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
    stxdw [r10-0xa48], r3                   
    lddw r3, 0x100066248 --> b"\x00\x00\x00\x00\x94#\x06\x00\x17\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00…        r3 load str located at 4295385672
    ja lbb_30957                                    if true { pc += 462 }
lbb_30495:
    jeq r3, 54, lbb_31019                           if r3 == (54 as i32 as i64 as u64) { pc += 523 }
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
    stxdw [r10-0xa48], r3                   
    lddw r3, 0x1000665a8 --> b"\x00\x00\x00\x00['\x06\x00\x0f\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x0…        r3 load str located at 4295386536
    stxdw [r10-0xa68], r3                   
    mov64 r3, 1                                     r3 = 1 as i32 as i64 as u64
    stxdw [r10-0xa60], r3                   
    stxdw [r10-0xa50], r3                   
    mov64 r3, r10                                   r3 = r10
    add64 r3, -2568                                 r3 += -2568   ///  r3 = r3.wrapping_add(-2568 as i32 as i64 as u64)
    stxdw [r10-0xa58], r3                   
    lddw r3, 0x10002a260 --> b"y\x11\x00\x00\x00\x00\x00\x00\x85\x10\x00\x00\xe5N\x00\x00\x95\x00\x00\x0…        r3 load str located at 4295139936
    ja lbb_31032                                    if true { pc += 522 }
lbb_30510:
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
    stxdw [r10-0xa48], r3                   
    mov64 r3, 2                                     r3 = 2 as i32 as i64 as u64
    stxdw [r10-0xa60], r3                   
    lddw r3, 0x100065ee8 --> b"\x00\x00\x00\x00\x7f\x1f\x06\x00\x06\x00\x00\x00\x00\x00\x00\x00\x00\x00\…        r3 load str located at 4295384808
    stxdw [r10-0xa68], r3                   
    mov64 r3, 1                                     r3 = 1 as i32 as i64 as u64
lbb_30518:
    stxdw [r10-0xa50], r3                   
    mov64 r3, r10                                   r3 = r10
    add64 r3, -2568                                 r3 += -2568   ///  r3 = r3.wrapping_add(-2568 as i32 as i64 as u64)
    stxdw [r10-0xa58], r3                   
    lddw r3, 0x10002a2c8 --> b"y\x11\x00\x00\x00\x00\x00\x00\x85\x10\x00\x00\x90g\x00\x00\x95\x00\x00\x0…        r3 load str located at 4295140040
    ja lbb_31032                                    if true { pc += 507 }
lbb_30525:
    mov64 r3, r1                                    r3 = r1
    add64 r3, 8                                     r3 += 8   ///  r3 = r3.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x9d0], r3                   
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
    stxdw [r10-0xa48], r3                   
    lddw r3, 0x100065f08 --> b"\x00\x00\x00\x00\x9c\x1f\x06\x00$\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00…        r3 load str located at 4295384840
    ja lbb_31000                                    if true { pc += 467 }
lbb_30533:
    mov64 r3, r1                                    r3 = r1
    add64 r3, 8                                     r3 += 8   ///  r3 = r3.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x9d8], r3                   
    mov64 r3, r1                                    r3 = r1
    add64 r3, 16                                    r3 += 16   ///  r3 = r3.wrapping_add(16 as i32 as i64 as u64)
    stxdw [r10-0x9d0], r3                   
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
    stxdw [r10-0x9e8], r3                   
    lddw r3, 0x100066258 --> b"\x00\x00\x00\x00\xab#\x06\x00\x18\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00…        r3 load str located at 4295385688
    ja lbb_30875                                    if true { pc += 331 }
lbb_30544:
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
    stxdw [r10-0xa48], r3                   
    lddw r3, 0x100066288 --> b"\x00\x00\x00\x00\xe2#\x06\x00\x0f\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00…        r3 load str located at 4295385736
    ja lbb_30770                                    if true { pc += 221 }
lbb_30549:
    mov64 r3, r1                                    r3 = r1
    add64 r3, 1                                     r3 += 1   ///  r3 = r3.wrapping_add(1 as i32 as i64 as u64)
    stxdw [r10-0x9d0], r3                   
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
    stxdw [r10-0xa48], r3                   
    lddw r3, 0x1000660b8 --> b"\x00\x00\x00\x00o!\x06\x00\x18\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x0…        r3 load str located at 4295385272
    ja lbb_30922                                    if true { pc += 365 }
lbb_30557:
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
    stxdw [r10-0xa48], r3                   
    mov64 r3, 2                                     r3 = 2 as i32 as i64 as u64
    stxdw [r10-0xa60], r3                   
    lddw r3, 0x1000660d8 --> b"\x00\x00\x00\x00\x80\x09\x06\x00\x08\x00\x00\x00\x00\x00\x00\x00\x00\x00\…        r3 load str located at 4295385304
    ja lbb_30979                                    if true { pc += 415 }
lbb_30564:
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
    stxdw [r10-0xa48], r3                   
    mov64 r3, 2                                     r3 = 2 as i32 as i64 as u64
    stxdw [r10-0xa60], r3                   
    lddw r3, 0x1000663e8 --> b"\x00\x00\x00\x00t%\x06\x00\x05\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x0…        r3 load str located at 4295386088
    ja lbb_30979                                    if true { pc += 408 }
lbb_30571:
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
    stxdw [r10-0xa48], r3                   
    mov64 r3, 2                                     r3 = 2 as i32 as i64 as u64
    stxdw [r10-0xa60], r3                   
    lddw r3, 0x100066408 --> b"\x00\x00\x00\x00\xa3%\x06\x00\x0d\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00…        r3 load str located at 4295386120
    ja lbb_30979                                    if true { pc += 401 }
lbb_30578:
    mov64 r3, r1                                    r3 = r1
    add64 r3, 8                                     r3 += 8   ///  r3 = r3.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x9d8], r3                   
    mov64 r3, r1                                    r3 = r1
    add64 r3, 16                                    r3 += 16   ///  r3 = r3.wrapping_add(16 as i32 as i64 as u64)
    stxdw [r10-0x9d0], r3                   
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
    stxdw [r10-0x9e8], r3                   
    lddw r3, 0x100065fa8 --> b"\x00\x00\x00\x00\x9c \x06\x00\x1f\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00…        r3 load str located at 4295385000
    ja lbb_30875                                    if true { pc += 286 }
lbb_30589:
    mov64 r3, r1                                    r3 = r1
    add64 r3, 8                                     r3 += 8   ///  r3 = r3.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x9d0], r3                   
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
    stxdw [r10-0xa48], r3                   
    lddw r3, 0x100065fd8 --> b"\x00\x00\x00\x00\xd0\xfe\x05\x00 \x00\x00\x00\x00\x00\x00\x00\x00\x00\x00…        r3 load str located at 4295385048
    ja lbb_31000                                    if true { pc += 403 }
lbb_30597:
    mov64 r3, r1                                    r3 = r1
    add64 r3, 24                                    r3 += 24   ///  r3 = r3.wrapping_add(24 as i32 as i64 as u64)
    stxdw [r10-0x9d8], r3                   
    mov64 r3, r1                                    r3 = r1
    add64 r3, 8                                     r3 += 8   ///  r3 = r3.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x9d0], r3                   
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
    stxdw [r10-0x9e8], r3                   
    lddw r3, 0x1000662d8 --> b"\x00\x00\x00\x00\x80\x09\x06\x00\x08\x00\x00\x00\x00\x00\x00\x00\x00\x00\…        r3 load str located at 4295385816
    stxdw [r10-0xa08], r3                   
    mov64 r3, 3                                     r3 = 3 as i32 as i64 as u64
    stxdw [r10-0xa00], r3                   
    stxdw [r10-0x9f0], r3                   
    mov64 r3, r10                                   r3 = r10
    add64 r3, -2664                                 r3 += -2664   ///  r3 = r3.wrapping_add(-2664 as i32 as i64 as u64)
    stxdw [r10-0x9f8], r3                   
    mov64 r3, r10                                   r3 = r10
    add64 r3, -2504                                 r3 += -2504   ///  r3 = r3.wrapping_add(-2504 as i32 as i64 as u64)
    stxdw [r10-0xa48], r3                   
    lddw r3, 0x10002a2c8 --> b"y\x11\x00\x00\x00\x00\x00\x00\x85\x10\x00\x00\x90g\x00\x00\x95\x00\x00\x0…        r3 load str located at 4295140040
    stxdw [r10-0xa40], r3                   
    stxdw [r10-0xa50], r3                   
    mov64 r3, r10                                   r3 = r10
    add64 r3, -2512                                 r3 += -2512   ///  r3 = r3.wrapping_add(-2512 as i32 as i64 as u64)
    stxdw [r10-0xa58], r3                   
    lddw r3, 0x10002a218 --> b"y\x11\x00\x00\x00\x00\x00\x00\x85\x10\x00\x00\xfbE\x00\x00\x95\x00\x00\x0…        r3 load str located at 4295139864
    stxdw [r10-0xa60], r3                   
    mov64 r3, r10                                   r3 = r10
    add64 r3, -2520                                 r3 += -2520   ///  r3 = r3.wrapping_add(-2520 as i32 as i64 as u64)
    stxdw [r10-0xa68], r3                   
    add64 r1, 16                                    r1 += 16   ///  r1 = r1.wrapping_add(16 as i32 as i64 as u64)
    ja lbb_30897                                    if true { pc += 265 }
lbb_30632:
    mov64 r3, r1                                    r3 = r1
    add64 r3, 8                                     r3 += 8   ///  r3 = r3.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0xa18], r3                   
    mov64 r3, r1                                    r3 = r1
    add64 r3, 16                                    r3 += 16   ///  r3 = r3.wrapping_add(16 as i32 as i64 as u64)
    stxdw [r10-0xa10], r3                   
    mov64 r3, r1                                    r3 = r1
    add64 r3, 24                                    r3 += 24   ///  r3 = r3.wrapping_add(24 as i32 as i64 as u64)
    stxdw [r10-0x9d8], r3                   
    mov64 r3, r10                                   r3 = r10
    add64 r3, -2504                                 r3 += -2504   ///  r3 = r3.wrapping_add(-2504 as i32 as i64 as u64)
    stxdw [r10-0xa28], r3                   
    mov64 r3, r10                                   r3 = r10
    add64 r3, -2512                                 r3 += -2512   ///  r3 = r3.wrapping_add(-2512 as i32 as i64 as u64)
    stxdw [r10-0xa38], r3                   
    mov64 r3, r10                                   r3 = r10
    add64 r3, -2520                                 r3 += -2520   ///  r3 = r3.wrapping_add(-2520 as i32 as i64 as u64)
    stxdw [r10-0xa48], r3                   
    mov64 r3, r10                                   r3 = r10
    add64 r3, -2576                                 r3 += -2576   ///  r3 = r3.wrapping_add(-2576 as i32 as i64 as u64)
    stxdw [r10-0xa58], r3                   
    lddw r3, 0x10002a278 --> b"y\x11\x00\x00\x00\x00\x00\x00y\x11\x00\x00\x00\x00\x00\x00\x85\x10\x00\x0…        r3 load str located at 4295139960
    stxdw [r10-0xa20], r3                   
    stxdw [r10-0xa30], r3                   
    stxdw [r10-0xa40], r3                   
    stxdw [r10-0xa50], r3                   
    stxdw [r10-0xa60], r3                   
    mov64 r3, r10                                   r3 = r10
    add64 r3, -2584                                 r3 += -2584   ///  r3 = r3.wrapping_add(-2584 as i32 as i64 as u64)
    stxdw [r10-0xa68], r3                   
    mov64 r3, r1                                    r3 = r1
    add64 r3, 32                                    r3 += 32   ///  r3 = r3.wrapping_add(32 as i32 as i64 as u64)
    stxdw [r10-0x9d0], r3                   
    add64 r1, 40                                    r1 += 40   ///  r1 = r1.wrapping_add(40 as i32 as i64 as u64)
    stxdw [r10-0x9c8], r1                   
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    stxdw [r10-0x9e8], r1                   
    lddw r1, 0x100066308 --> b"\x00\x00\x00\x00\xde$\x06\x00\x1d\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00…        r1 load str located at 4295385864
    stxdw [r10-0xa08], r1                   
    mov64 r1, 5                                     r1 = 5 as i32 as i64 as u64
    ja lbb_30854                                    if true { pc += 179 }
lbb_30675:
    mov64 r3, r1                                    r3 = r1
    add64 r3, 8                                     r3 += 8   ///  r3 = r3.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x9d8], r3                   
    mov64 r3, r1                                    r3 = r1
    add64 r3, 16                                    r3 += 16   ///  r3 = r3.wrapping_add(16 as i32 as i64 as u64)
    stxdw [r10-0x9d0], r3                   
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
    stxdw [r10-0x9e8], r3                   
    lddw r3, 0x100066158 --> b"\x00\x00\x00\x00`"\x06\x00.\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x…        r3 load str located at 4295385432
    ja lbb_30875                                    if true { pc += 189 }
lbb_30686:
    mov64 r3, r1                                    r3 = r1
    add64 r3, 8                                     r3 += 8   ///  r3 = r3.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x9d8], r3                   
    mov64 r3, r1                                    r3 = r1
    add64 r3, 16                                    r3 += 16   ///  r3 = r3.wrapping_add(16 as i32 as i64 as u64)
    stxdw [r10-0x9d0], r3                   
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
    stxdw [r10-0x9e8], r3                   
    lddw r3, 0x100066188 --> b"\x00\x00\x00\x00\x98"\x06\x00/\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x0…        r3 load str located at 4295385480
    ja lbb_30875                                    if true { pc += 178 }
lbb_30697:
    mov64 r3, r1                                    r3 = r1
    add64 r3, 40                                    r3 += 40   ///  r3 = r3.wrapping_add(40 as i32 as i64 as u64)
    stxdw [r10-0x9d8], r3                   
    mov64 r3, r1                                    r3 = r1
    add64 r3, 4                                     r3 += 4   ///  r3 = r3.wrapping_add(4 as i32 as i64 as u64)
    stxdw [r10-0x9d0], r3                   
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
    stxdw [r10-0x9e8], r3                   
    mov64 r3, 4                                     r3 = 4 as i32 as i64 as u64
    stxdw [r10-0xa00], r3                   
    lddw r3, 0x1000664f8 --> b"\x00\x00\x00\x00d&\x06\x00\x13\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x0…        r3 load str located at 4295386360
    stxdw [r10-0xa08], r3                   
    mov64 r3, 3                                     r3 = 3 as i32 as i64 as u64
    stxdw [r10-0x9f0], r3                   
    mov64 r3, r10                                   r3 = r10
    add64 r3, -2664                                 r3 += -2664   ///  r3 = r3.wrapping_add(-2664 as i32 as i64 as u64)
    stxdw [r10-0x9f8], r3                   
    mov64 r3, r10                                   r3 = r10
    add64 r3, -2504                                 r3 += -2504   ///  r3 = r3.wrapping_add(-2504 as i32 as i64 as u64)
    stxdw [r10-0xa48], r3                   
    lddw r3, 0x10002a298 --> b"y\x11\x00\x00\x00\x00\x00\x00\x85\x10\x00\x00\xcd/\x00\x00\x95\x00\x00\x0…        r3 load str located at 4295139992
    stxdw [r10-0xa40], r3                   
    stxdw [r10-0xa50], r3                   
    mov64 r3, r10                                   r3 = r10
    add64 r3, -2512                                 r3 += -2512   ///  r3 = r3.wrapping_add(-2512 as i32 as i64 as u64)
    stxdw [r10-0xa58], r3                   
    lddw r3, 0x10002a328 --> b"\xbf#\x00\x00\x00\x00\x00\x00y\x11\x00\x00\x00\x00\x00\x00y\x12\x10\x00\x…        r3 load str located at 4295140136
    stxdw [r10-0xa60], r3                   
    mov64 r3, r10                                   r3 = r10
    add64 r3, -2520                                 r3 += -2520   ///  r3 = r3.wrapping_add(-2520 as i32 as i64 as u64)
    stxdw [r10-0xa68], r3                   
    add64 r1, 20                                    r1 += 20   ///  r1 = r1.wrapping_add(20 as i32 as i64 as u64)
    ja lbb_30897                                    if true { pc += 164 }
lbb_30733:
    mov64 r3, r1                                    r3 = r1
    add64 r3, 4                                     r3 += 4   ///  r3 = r3.wrapping_add(4 as i32 as i64 as u64)
    stxdw [r10-0x9d8], r3                   
    mov64 r3, r1                                    r3 = r1
    add64 r3, 20                                    r3 += 20   ///  r3 = r3.wrapping_add(20 as i32 as i64 as u64)
    stxdw [r10-0x9d0], r3                   
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
    stxdw [r10-0x9e8], r3                   
    lddw r3, 0x100066538 --> b"\x00\x00\x00\x00\x8f&\x06\x00*\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x0…        r3 load str located at 4295386424
    stxdw [r10-0xa08], r3                   
    mov64 r3, 3                                     r3 = 3 as i32 as i64 as u64
    stxdw [r10-0xa00], r3                   
    stxdw [r10-0x9f0], r3                   
    mov64 r3, r10                                   r3 = r10
    add64 r3, -2664                                 r3 += -2664   ///  r3 = r3.wrapping_add(-2664 as i32 as i64 as u64)
    stxdw [r10-0x9f8], r3                   
    mov64 r3, r10                                   r3 = r10
    add64 r3, -2504                                 r3 += -2504   ///  r3 = r3.wrapping_add(-2504 as i32 as i64 as u64)
    stxdw [r10-0xa48], r3                   
    mov64 r3, r10                                   r3 = r10
    add64 r3, -2512                                 r3 += -2512   ///  r3 = r3.wrapping_add(-2512 as i32 as i64 as u64)
    stxdw [r10-0xa58], r3                   
    lddw r3, 0x10002a298 --> b"y\x11\x00\x00\x00\x00\x00\x00\x85\x10\x00\x00\xcd/\x00\x00\x95\x00\x00\x0…        r3 load str located at 4295139992
    stxdw [r10-0xa40], r3                   
    stxdw [r10-0xa50], r3                   
    stxdw [r10-0xa60], r3                   
    mov64 r3, r10                                   r3 = r10
    add64 r3, -2520                                 r3 += -2520   ///  r3 = r3.wrapping_add(-2520 as i32 as i64 as u64)
    stxdw [r10-0xa68], r3                   
    add64 r1, 36                                    r1 += 36   ///  r1 = r1.wrapping_add(36 as i32 as i64 as u64)
    ja lbb_30897                                    if true { pc += 131 }
lbb_30766:
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
    stxdw [r10-0xa48], r3                   
    lddw r3, 0x100065f48 --> b"\x00\x00\x00\x00\x04 \x06\x00!\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x0…        r3 load str located at 4295384904
lbb_30770:
    stxdw [r10-0xa68], r3                   
    mov64 r3, 1                                     r3 = 1 as i32 as i64 as u64
    stxdw [r10-0xa60], r3                   
    stxdw [r10-0xa50], r3                   
    mov64 r3, r10                                   r3 = r10
    add64 r3, -2568                                 r3 += -2568   ///  r3 = r3.wrapping_add(-2568 as i32 as i64 as u64)
    stxdw [r10-0xa58], r3                   
    lddw r3, 0x10002a328 --> b"\xbf#\x00\x00\x00\x00\x00\x00y\x11\x00\x00\x00\x00\x00\x00y\x12\x10\x00\x…        r3 load str located at 4295140136
    ja lbb_31032                                    if true { pc += 252 }
lbb_30780:
    mov64 r1, r2                                    r1 = r2
    lddw r2, 0x100062418 --> b"Last slot passed in oracle update is zeroDuplicate"        r2 load str located at 4295369752
    ja lbb_30950                                    if true { pc += 166 }
lbb_30784:
    mov64 r3, r1                                    r3 = r1
    add64 r3, 1                                     r3 += 1   ///  r3 = r3.wrapping_add(1 as i32 as i64 as u64)
    stxdw [r10-0x9d0], r3                   
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
    stxdw [r10-0xa48], r3                   
    lddw r3, 0x100066108 --> b"\x00\x00\x00\x00\xc9!\x06\x000\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x0…        r3 load str located at 4295385352
    ja lbb_30922                                    if true { pc += 130 }
lbb_30792:
    mov64 r3, r1                                    r3 = r1
    add64 r3, 8                                     r3 += 8   ///  r3 = r3.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x9d0], r3                   
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
    stxdw [r10-0xa48], r3                   
    mov64 r3, 3                                     r3 = 3 as i32 as i64 as u64
    stxdw [r10-0xa60], r3                   
    lddw r3, 0x100066448 --> b"\x00\x00\x00\x00\xdf%\x06\x00\x1b\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00…        r3 load str located at 4295386184
    stxdw [r10-0xa68], r3                   
    mov64 r3, 2                                     r3 = 2 as i32 as i64 as u64
    stxdw [r10-0xa50], r3                   
    mov64 r3, r10                                   r3 = r10
    add64 r3, -2568                                 r3 += -2568   ///  r3 = r3.wrapping_add(-2568 as i32 as i64 as u64)
    stxdw [r10-0xa58], r3                   
    lddw r3, 0x10002a2b0 --> b"y\x11\x00\x00\x00\x00\x00\x00\x85\x10\x00\x00{g\x00\x00\x95\x00\x00\x00\x…        r3 load str located at 4295140016
    stxdw [r10-0x9f0], r3                   
    mov64 r3, r10                                   r3 = r10
    add64 r3, -2504                                 r3 += -2504   ///  r3 = r3.wrapping_add(-2504 as i32 as i64 as u64)
    stxdw [r10-0x9f8], r3                   
    lddw r3, 0x10002a2e0 --> b"\xbf#\x00\x00\x00\x00\x00\x00y\x11\x00\x00\x00\x00\x00\x00y\x12\x08\x00\x…        r3 load str located at 4295140064
    stxdw [r10-0xa00], r3                   
    mov64 r3, r10                                   r3 = r10
    add64 r3, -2512                                 r3 += -2512   ///  r3 = r3.wrapping_add(-2512 as i32 as i64 as u64)
    ja lbb_30990                                    if true { pc += 171 }
lbb_30819:
    mov64 r3, r1                                    r3 = r1
    add64 r3, 8                                     r3 += 8   ///  r3 = r3.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0xa10], r3                   
    mov64 r3, r1                                    r3 = r1
    add64 r3, 16                                    r3 += 16   ///  r3 = r3.wrapping_add(16 as i32 as i64 as u64)
    stxdw [r10-0x9d8], r3                   
    mov64 r3, r1                                    r3 = r1
    add64 r3, 24                                    r3 += 24   ///  r3 = r3.wrapping_add(24 as i32 as i64 as u64)
    stxdw [r10-0x9d0], r3                   
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
    stxdw [r10-0x9e8], r3                   
    lddw r3, 0x100066038 --> b"\x00\x00\x00\x00\xf0 \x06\x00\x1f\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00…        r3 load str located at 4295385144
lbb_30832:
    stxdw [r10-0xa08], r3                   
    mov64 r3, r10                                   r3 = r10
    add64 r3, -2504                                 r3 += -2504   ///  r3 = r3.wrapping_add(-2504 as i32 as i64 as u64)
    stxdw [r10-0xa38], r3                   
    mov64 r3, r10                                   r3 = r10
    add64 r3, -2512                                 r3 += -2512   ///  r3 = r3.wrapping_add(-2512 as i32 as i64 as u64)
    stxdw [r10-0xa48], r3                   
    mov64 r3, r10                                   r3 = r10
    add64 r3, -2520                                 r3 += -2520   ///  r3 = r3.wrapping_add(-2520 as i32 as i64 as u64)
    stxdw [r10-0xa58], r3                   
    lddw r3, 0x10002a278 --> b"y\x11\x00\x00\x00\x00\x00\x00y\x11\x00\x00\x00\x00\x00\x00\x85\x10\x00\x0…        r3 load str located at 4295139960
    stxdw [r10-0xa30], r3                   
    stxdw [r10-0xa40], r3                   
    stxdw [r10-0xa50], r3                   
    stxdw [r10-0xa60], r3                   
    mov64 r3, r10                                   r3 = r10
    add64 r3, -2576                                 r3 += -2576   ///  r3 = r3.wrapping_add(-2576 as i32 as i64 as u64)
    stxdw [r10-0xa68], r3                   
    add64 r1, 32                                    r1 += 32   ///  r1 = r1.wrapping_add(32 as i32 as i64 as u64)
lbb_30852:
    stxdw [r10-0x9c8], r1                   
    mov64 r1, 4                                     r1 = 4 as i32 as i64 as u64
lbb_30854:
    stxdw [r10-0xa00], r1                   
    stxdw [r10-0x9f0], r1                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -2664                                 r1 += -2664   ///  r1 = r1.wrapping_add(-2664 as i32 as i64 as u64)
    stxdw [r10-0x9f8], r1                   
    ja lbb_30898                                    if true { pc += 38 }
lbb_30860:
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
    stxdw [r10-0xa48], r3                   
    lddw r3, 0x100066378 --> b"\x00\x00\x00\x00\x12%\x06\x00\x15\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00…        r3 load str located at 4295385976
    ja lbb_30957                                    if true { pc += 92 }
lbb_30865:
    mov64 r3, r1                                    r3 = r1
    add64 r3, 8                                     r3 += 8   ///  r3 = r3.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x9d8], r3                   
    mov64 r3, r1                                    r3 = r1
    add64 r3, 16                                    r3 += 16   ///  r3 = r3.wrapping_add(16 as i32 as i64 as u64)
    stxdw [r10-0x9d0], r3                   
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
    stxdw [r10-0x9e8], r3                   
    lddw r3, 0x1000661d8 --> b"\x00\x00\x00\x00\x03#\x06\x00D\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x0…        r3 load str located at 4295385560
lbb_30875:
    stxdw [r10-0xa08], r3                   
    mov64 r3, 3                                     r3 = 3 as i32 as i64 as u64
    stxdw [r10-0xa00], r3                   
    stxdw [r10-0x9f0], r3                   
    mov64 r3, r10                                   r3 = r10
    add64 r3, -2664                                 r3 += -2664   ///  r3 = r3.wrapping_add(-2664 as i32 as i64 as u64)
    stxdw [r10-0x9f8], r3                   
    mov64 r3, r10                                   r3 = r10
    add64 r3, -2504                                 r3 += -2504   ///  r3 = r3.wrapping_add(-2504 as i32 as i64 as u64)
    stxdw [r10-0xa48], r3                   
    mov64 r3, r10                                   r3 = r10
    add64 r3, -2512                                 r3 += -2512   ///  r3 = r3.wrapping_add(-2512 as i32 as i64 as u64)
    stxdw [r10-0xa58], r3                   
    lddw r3, 0x10002a278 --> b"y\x11\x00\x00\x00\x00\x00\x00y\x11\x00\x00\x00\x00\x00\x00\x85\x10\x00\x0…        r3 load str located at 4295139960
    stxdw [r10-0xa40], r3                   
    stxdw [r10-0xa50], r3                   
    stxdw [r10-0xa60], r3                   
    mov64 r3, r10                                   r3 = r10
    add64 r3, -2520                                 r3 += -2520   ///  r3 = r3.wrapping_add(-2520 as i32 as i64 as u64)
    stxdw [r10-0xa68], r3                   
    add64 r1, 24                                    r1 += 24   ///  r1 = r1.wrapping_add(24 as i32 as i64 as u64)
lbb_30897:
    stxdw [r10-0x9c8], r1                   
lbb_30898:
    mov64 r3, r10                                   r3 = r10
    add64 r3, -2568                                 r3 += -2568   ///  r3 = r3.wrapping_add(-2568 as i32 as i64 as u64)
    ja lbb_31040                                    if true { pc += 139 }
lbb_30901:
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
    stxdw [r10-0xa48], r3                   
    lddw r3, 0x100066578 --> b"\x00\x00\x00\x00''\x06\x00\x12\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x0…        r3 load str located at 4295386488
    stxdw [r10-0xa68], r3                   
    mov64 r3, 1                                     r3 = 1 as i32 as i64 as u64
    stxdw [r10-0xa60], r3                   
    stxdw [r10-0xa50], r3                   
    mov64 r3, r10                                   r3 = r10
    add64 r3, -2568                                 r3 += -2568   ///  r3 = r3.wrapping_add(-2568 as i32 as i64 as u64)
    stxdw [r10-0xa58], r3                   
    lddw r3, 0x10002a2e0 --> b"\xbf#\x00\x00\x00\x00\x00\x00y\x11\x00\x00\x00\x00\x00\x00y\x12\x08\x00\x…        r3 load str located at 4295140064
    ja lbb_31032                                    if true { pc += 117 }
lbb_30915:
    mov64 r3, r1                                    r3 = r1
    add64 r3, 1                                     r3 += 1   ///  r3 = r3.wrapping_add(1 as i32 as i64 as u64)
    stxdw [r10-0x9d0], r3                   
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
    stxdw [r10-0xa48], r3                   
    lddw r3, 0x100065f78 --> b"\x00\x00\x00\x00% \x06\x00\x0f\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x0…        r3 load str located at 4295384952
lbb_30922:
    stxdw [r10-0xa68], r3                   
    mov64 r3, 2                                     r3 = 2 as i32 as i64 as u64
    stxdw [r10-0xa60], r3                   
    stxdw [r10-0xa50], r3                   
    mov64 r3, r10                                   r3 = r10
    add64 r3, -2568                                 r3 += -2568   ///  r3 = r3.wrapping_add(-2568 as i32 as i64 as u64)
    stxdw [r10-0xa58], r3                   
    mov64 r3, r10                                   r3 = r10
    add64 r3, -2504                                 r3 += -2504   ///  r3 = r3.wrapping_add(-2504 as i32 as i64 as u64)
    stxdw [r10-0x9f8], r3                   
    lddw r3, 0x10002a218 --> b"y\x11\x00\x00\x00\x00\x00\x00\x85\x10\x00\x00\xfbE\x00\x00\x95\x00\x00\x0…        r3 load str located at 4295139864
    stxdw [r10-0x9f0], r3                   
    stxdw [r10-0xa00], r3                   
    mov64 r3, r10                                   r3 = r10
    add64 r3, -2512                                 r3 += -2512   ///  r3 = r3.wrapping_add(-2512 as i32 as i64 as u64)
    stxdw [r10-0xa08], r3                   
    add64 r1, 33                                    r1 += 33   ///  r1 = r1.wrapping_add(33 as i32 as i64 as u64)
    ja lbb_31037                                    if true { pc += 96 }
lbb_30941:
    mov64 r1, r2                                    r1 = r2
    lddw r2, 0x10006245b --> b"No updated provider to quote update instruction"        r2 load str located at 4295369819
    mov64 r3, 47                                    r3 = 47 as i32 as i64 as u64
    call function_45901                     
    ja lbb_31043                                    if true { pc += 96 }
lbb_30947:
    mov64 r1, r2                                    r1 = r2
    lddw r2, 0x100062219 --> b"Shitlist is full, cannot add more pubkeys"        r2 load str located at 4295369241
lbb_30950:
    mov64 r3, 41                                    r3 = 41 as i32 as i64 as u64
    call function_45901                     
    ja lbb_31043                                    if true { pc += 90 }
lbb_30953:
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
    stxdw [r10-0xa48], r3                   
    lddw r3, 0x1000664b8 --> b"\x00\x00\x00\x00!&\x06\x00\x1e\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x0…        r3 load str located at 4295386296
lbb_30957:
    stxdw [r10-0xa68], r3                   
    mov64 r3, 1                                     r3 = 1 as i32 as i64 as u64
    stxdw [r10-0xa60], r3                   
lbb_30960:
    stxdw [r10-0xa50], r3                   
    mov64 r3, r10                                   r3 = r10
    add64 r3, -2568                                 r3 += -2568   ///  r3 = r3.wrapping_add(-2568 as i32 as i64 as u64)
    stxdw [r10-0xa58], r3                   
    lddw r3, 0x10002a2b0 --> b"y\x11\x00\x00\x00\x00\x00\x00\x85\x10\x00\x00{g\x00\x00\x95\x00\x00\x00\x…        r3 load str located at 4295140016
    ja lbb_30987                                    if true { pc += 20 }
lbb_30967:
    mov64 r1, r2                                    r1 = r2
    lddw r2, 0x100062136 --> b"Authority account is not a signer"        r2 load str located at 4295369014
    mov64 r3, 33                                    r3 = 33 as i32 as i64 as u64
    call function_45901                     
    ja lbb_31043                                    if true { pc += 70 }
lbb_30973:
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
    stxdw [r10-0xa48], r3                   
    mov64 r3, 2                                     r3 = 2 as i32 as i64 as u64
    stxdw [r10-0xa60], r3                   
    lddw r3, 0x1000663a8 --> b"\x00\x00\x00\x00M%\x06\x00\x15\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x0…        r3 load str located at 4295386024
lbb_30979:
    stxdw [r10-0xa68], r3                   
    mov64 r3, 1                                     r3 = 1 as i32 as i64 as u64
lbb_30981:
    stxdw [r10-0xa50], r3                   
    mov64 r3, r10                                   r3 = r10
    add64 r3, -2568                                 r3 += -2568   ///  r3 = r3.wrapping_add(-2568 as i32 as i64 as u64)
    stxdw [r10-0xa58], r3                   
    lddw r3, 0x10002a218 --> b"y\x11\x00\x00\x00\x00\x00\x00\x85\x10\x00\x00\xfbE\x00\x00\x95\x00\x00\x0…        r3 load str located at 4295139864
lbb_30987:
    stxdw [r10-0xa00], r3                   
    mov64 r3, r10                                   r3 = r10
    add64 r3, -2504                                 r3 += -2504   ///  r3 = r3.wrapping_add(-2504 as i32 as i64 as u64)
lbb_30990:
    stxdw [r10-0xa08], r3                   
    add64 r1, 1                                     r1 += 1   ///  r1 = r1.wrapping_add(1 as i32 as i64 as u64)
    ja lbb_31037                                    if true { pc += 44 }
lbb_30993:
    mov64 r3, r1                                    r3 = r1
    add64 r3, 8                                     r3 += 8   ///  r3 = r3.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x9d0], r3                   
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
    stxdw [r10-0xa48], r3                   
    lddw r3, 0x100066228 --> b"\x00\x00\x00\x00j#\x06\x00*\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x…        r3 load str located at 4295385640
lbb_31000:
    stxdw [r10-0xa68], r3                   
    mov64 r3, 2                                     r3 = 2 as i32 as i64 as u64
    stxdw [r10-0xa60], r3                   
    stxdw [r10-0xa50], r3                   
    mov64 r3, r10                                   r3 = r10
    add64 r3, -2568                                 r3 += -2568   ///  r3 = r3.wrapping_add(-2568 as i32 as i64 as u64)
    stxdw [r10-0xa58], r3                   
    mov64 r3, r10                                   r3 = r10
    add64 r3, -2504                                 r3 += -2504   ///  r3 = r3.wrapping_add(-2504 as i32 as i64 as u64)
    stxdw [r10-0x9f8], r3                   
    lddw r3, 0x10002a278 --> b"y\x11\x00\x00\x00\x00\x00\x00y\x11\x00\x00\x00\x00\x00\x00\x85\x10\x00\x0…        r3 load str located at 4295139960
lbb_31012:
    stxdw [r10-0x9f0], r3                   
    stxdw [r10-0xa00], r3                   
    mov64 r3, r10                                   r3 = r10
    add64 r3, -2512                                 r3 += -2512   ///  r3 = r3.wrapping_add(-2512 as i32 as i64 as u64)
    stxdw [r10-0xa08], r3                   
    add64 r1, 16                                    r1 += 16   ///  r1 = r1.wrapping_add(16 as i32 as i64 as u64)
    ja lbb_31037                                    if true { pc += 18 }
lbb_31019:
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
    stxdw [r10-0xa48], r3                   
    lddw r3, 0x100066598 --> b"\x00\x00\x00\x00B'\x06\x00\x19\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x0…        r3 load str located at 4295386520
    stxdw [r10-0xa68], r3                   
    mov64 r3, 1                                     r3 = 1 as i32 as i64 as u64
    stxdw [r10-0xa60], r3                   
    stxdw [r10-0xa50], r3                   
    mov64 r3, r10                                   r3 = r10
    add64 r3, -2568                                 r3 += -2568   ///  r3 = r3.wrapping_add(-2568 as i32 as i64 as u64)
    stxdw [r10-0xa58], r3                   
    lddw r3, 0x10002a310 --> b"y\x11\x00\x00\x00\x00\x00\x00\x85\x10\x00\x00\x87g\x00\x00\x95\x00\x00\x0…        r3 load str located at 4295140112
lbb_31032:
    stxdw [r10-0xa00], r3                   
    mov64 r3, r10                                   r3 = r10
    add64 r3, -2504                                 r3 += -2504   ///  r3 = r3.wrapping_add(-2504 as i32 as i64 as u64)
    stxdw [r10-0xa08], r3                   
    add64 r1, 8                                     r1 += 8   ///  r1 = r1.wrapping_add(8 as i32 as i64 as u64)
lbb_31037:
    stxdw [r10-0x9c8], r1                   
    mov64 r3, r10                                   r3 = r10
    add64 r3, -2664                                 r3 += -2664   ///  r3 = r3.wrapping_add(-2664 as i32 as i64 as u64)
lbb_31040:
    mov64 r1, r2                                    r1 = r2
    mov64 r2, r3                                    r2 = r3
    call function_45907                     
lbb_31043:
    exit                                    

function_31044:
    mov64 r3, r2                                    r3 = r2
    ldxb r2, [r1+0x0]                       
    jsgt r2, 4, lbb_31074                           if (r2 as i64) > (4 as i32 as i64) { pc += 27 }
    jsgt r2, 1, lbb_31088                           if (r2 as i64) > (1 as i32 as i64) { pc += 40 }
    jeq r2, 0, lbb_31114                            if r2 == (0 as i32 as i64 as u64) { pc += 65 }
    mov64 r2, r1                                    r2 = r1
    add64 r2, 20                                    r2 += 20   ///  r2 = r2.wrapping_add(20 as i32 as i64 as u64)
    stxdw [r10-0x250], r2                   
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
    stxdw [r10-0x228], r2                   
    mov64 r2, 3                                     r2 = 3 as i32 as i64 as u64
    stxdw [r10-0x240], r2                   
    lddw r2, 0x1000665c8 --> b"\x00\x00\x00\x00\x92'\x06\x00\x0a\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00…        r2 load str located at 4295386568
    stxdw [r10-0x248], r2                   
    mov64 r2, 2                                     r2 = 2 as i32 as i64 as u64
    stxdw [r10-0x230], r2                   
    mov64 r2, r10                                   r2 = r10
    add64 r2, -648                                  r2 += -648   ///  r2 = r2.wrapping_add(-648 as i32 as i64 as u64)
    stxdw [r10-0x238], r2                   
    mov64 r2, r10                                   r2 = r10
    add64 r2, -536                                  r2 += -536   ///  r2 = r2.wrapping_add(-536 as i32 as i64 as u64)
    stxdw [r10-0x278], r2                   
    lddw r2, 0x10002a298 --> b"y\x11\x00\x00\x00\x00\x00\x00\x85\x10\x00\x00\xcd/\x00\x00\x95\x00\x00\x0…        r2 load str located at 4295139992
    stxdw [r10-0x270], r2                   
    stxdw [r10-0x280], r2                   
    mov64 r2, r10                                   r2 = r10
    add64 r2, -592                                  r2 += -592   ///  r2 = r2.wrapping_add(-592 as i32 as i64 as u64)
    ja lbb_31227                                    if true { pc += 153 }
lbb_31074:
    jsgt r2, 7, lbb_31105                           if (r2 as i64) > (7 as i32 as i64) { pc += 30 }
    jeq r2, 5, lbb_31122                            if r2 == (5 as i32 as i64 as u64) { pc += 46 }
    jeq r2, 6, lbb_31146                            if r2 == (6 as i32 as i64 as u64) { pc += 69 }
    mov64 r2, r1                                    r2 = r1
    add64 r2, 4                                     r2 += 4   ///  r2 = r2.wrapping_add(4 as i32 as i64 as u64)
    stxdw [r10-0x258], r2                   
    mov64 r2, r1                                    r2 = r1
    add64 r2, 20                                    r2 += 20   ///  r2 = r2.wrapping_add(20 as i32 as i64 as u64)
    stxdw [r10-0x250], r2                   
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
    stxdw [r10-0x268], r2                   
    lddw r2, 0x1000666c8 --> b"\x00\x00\x00\x00\x0f)\x06\x000\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x0…        r2 load str located at 4295386824
    ja lbb_31243                                    if true { pc += 155 }
lbb_31088:
    jeq r2, 2, lbb_31182                            if r2 == (2 as i32 as i64 as u64) { pc += 93 }
    jeq r2, 3, lbb_31210                            if r2 == (3 as i32 as i64 as u64) { pc += 120 }
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
    stxdw [r10-0x228], r2                   
    mov64 r2, 2                                     r2 = 2 as i32 as i64 as u64
    stxdw [r10-0x240], r2                   
    lddw r2, 0x100066638 --> b"\x00\x00\x00\x00D(\x06\x00\x17\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x0…        r2 load str located at 4295386680
    stxdw [r10-0x248], r2                   
    mov64 r2, 1                                     r2 = 1 as i32 as i64 as u64
    stxdw [r10-0x230], r2                   
    mov64 r2, r10                                   r2 = r10
    add64 r2, -648                                  r2 += -648   ///  r2 = r2.wrapping_add(-648 as i32 as i64 as u64)
    stxdw [r10-0x238], r2                   
    lddw r2, 0x10002a230 --> b"y\x11\x00\x00\x00\x00\x00\x00\x85\x10\x00\x00\x90g\x00\x00\x95\x00\x00\x0…        r2 load str located at 4295139888
    ja lbb_31224                                    if true { pc += 119 }
lbb_31105:
    jeq r2, 8, lbb_31233                            if r2 == (8 as i32 as i64 as u64) { pc += 127 }
    jeq r2, 9, lbb_31271                            if r2 == (9 as i32 as i64 as u64) { pc += 164 }
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
    stxdw [r10-0x228], r2                   
    mov64 r2, 2                                     r2 = 2 as i32 as i64 as u64
    stxdw [r10-0x240], r2                   
    lddw r2, 0x100066758 --> b"\x00\x00\x00\x00\xcc)\x06\x00B\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x0…        r2 load str located at 4295386968
    ja lbb_31216                                    if true { pc += 102 }
lbb_31114:
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
    stxdw [r10-0x228], r2                   
    lddw r2, 0x1000665b8 --> b"\x00\x00\x00\x00j'\x06\x00(\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x…        r2 load str located at 4295386552
    stxdw [r10-0x248], r2                   
    mov64 r2, 1                                     r2 = 1 as i32 as i64 as u64
    stxdw [r10-0x240], r2                   
    ja lbb_31218                                    if true { pc += 96 }
lbb_31122:
    mov64 r2, r1                                    r2 = r1
    add64 r2, 8                                     r2 += 8   ///  r2 = r2.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x250], r2                   
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
    stxdw [r10-0x228], r2                   
    mov64 r2, 3                                     r2 = 3 as i32 as i64 as u64
    stxdw [r10-0x240], r2                   
    lddw r2, 0x100066658 --> b"\x00\x00\x00\x00z(\x06\x00\x19\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x0…        r2 load str located at 4295386712
    stxdw [r10-0x248], r2                   
    mov64 r2, 2                                     r2 = 2 as i32 as i64 as u64
    stxdw [r10-0x230], r2                   
    mov64 r2, r10                                   r2 = r10
    add64 r2, -648                                  r2 += -648   ///  r2 = r2.wrapping_add(-648 as i32 as i64 as u64)
    stxdw [r10-0x238], r2                   
    lddw r2, 0x10002a370 --> b"y\x11\x00\x00\x00\x00\x00\x00\x85\x10\x00\x00Ug\x00\x00\x95\x00\x00\x00\x…        r2 load str located at 4295140208
    stxdw [r10-0x270], r2                   
    mov64 r2, r10                                   r2 = r10
    add64 r2, -536                                  r2 += -536   ///  r2 = r2.wrapping_add(-536 as i32 as i64 as u64)
    stxdw [r10-0x278], r2                   
    lddw r2, 0x10002a358 --> b"y\x11\x00\x00\x00\x00\x00\x00\x85\x10\x00\x00\x19\\x00\x00\x95\x00\x00\x0…        r2 load str located at 4295140184
    ja lbb_31204                                    if true { pc += 58 }
lbb_31146:
    mov64 r2, r1                                    r2 = r1
    add64 r2, 2                                     r2 += 2   ///  r2 = r2.wrapping_add(2 as i32 as i64 as u64)
    stxdw [r10-0x258], r2                   
    mov64 r2, r1                                    r2 = r1
    add64 r2, 1                                     r2 += 1   ///  r2 = r2.wrapping_add(1 as i32 as i64 as u64)
    stxdw [r10-0x250], r2                   
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
    stxdw [r10-0x268], r2                   
    mov64 r2, 4                                     r2 = 4 as i32 as i64 as u64
    stxdw [r10-0x280], r2                   
    lddw r2, 0x100066688 --> b"\x00\x00\x00\x00\xc3(\x06\x00&\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x0…        r2 load str located at 4295386760
    stxdw [r10-0x288], r2                   
    mov64 r2, 3                                     r2 = 3 as i32 as i64 as u64
    stxdw [r10-0x270], r2                   
    mov64 r2, r10                                   r2 = r10
    add64 r2, -584                                  r2 += -584   ///  r2 = r2.wrapping_add(-584 as i32 as i64 as u64)
    stxdw [r10-0x278], r2                   
    mov64 r2, r10                                   r2 = r10
    add64 r2, -536                                  r2 += -536   ///  r2 = r2.wrapping_add(-536 as i32 as i64 as u64)
    stxdw [r10-0x228], r2                   
    lddw r2, 0x10002a370 --> b"y\x11\x00\x00\x00\x00\x00\x00\x85\x10\x00\x00Ug\x00\x00\x95\x00\x00\x00\x…        r2 load str located at 4295140208
    stxdw [r10-0x230], r2                   
    mov64 r2, r10                                   r2 = r10
    add64 r2, -592                                  r2 += -592   ///  r2 = r2.wrapping_add(-592 as i32 as i64 as u64)
    stxdw [r10-0x238], r2                   
    lddw r2, 0x10002a2b0 --> b"y\x11\x00\x00\x00\x00\x00\x00\x85\x10\x00\x00{g\x00\x00\x95\x00\x00\x00\x…        r2 load str located at 4295140016
    stxdw [r10-0x220], r2                   
    stxdw [r10-0x240], r2                   
    mov64 r2, r10                                   r2 = r10
    add64 r2, -600                                  r2 += -600   ///  r2 = r2.wrapping_add(-600 as i32 as i64 as u64)
    stxdw [r10-0x248], r2                   
    add64 r1, 3                                     r1 += 3   ///  r1 = r1.wrapping_add(3 as i32 as i64 as u64)
    ja lbb_31265                                    if true { pc += 83 }
lbb_31182:
    mov64 r2, r1                                    r2 = r1
    add64 r2, 4                                     r2 += 4   ///  r2 = r2.wrapping_add(4 as i32 as i64 as u64)
    stxdw [r10-0x250], r2                   
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
    stxdw [r10-0x228], r2                   
    lddw r2, 0x1000665f8 --> b"\x00\x00\x00\x00\xda'\x06\x003\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x0…        r2 load str located at 4295386616
    stxdw [r10-0x248], r2                   
    mov64 r2, 2                                     r2 = 2 as i32 as i64 as u64
    stxdw [r10-0x240], r2                   
    stxdw [r10-0x230], r2                   
    mov64 r2, r10                                   r2 = r10
    add64 r2, -648                                  r2 += -648   ///  r2 = r2.wrapping_add(-648 as i32 as i64 as u64)
    stxdw [r10-0x238], r2                   
    lddw r2, 0x10002a2b0 --> b"y\x11\x00\x00\x00\x00\x00\x00\x85\x10\x00\x00{g\x00\x00\x95\x00\x00\x00\x…        r2 load str located at 4295140016
    stxdw [r10-0x270], r2                   
    mov64 r2, r10                                   r2 = r10
    add64 r2, -536                                  r2 += -536   ///  r2 = r2.wrapping_add(-536 as i32 as i64 as u64)
    stxdw [r10-0x278], r2                   
    lddw r2, 0x10002a298 --> b"y\x11\x00\x00\x00\x00\x00\x00\x85\x10\x00\x00\xcd/\x00\x00\x95\x00\x00\x0…        r2 load str located at 4295139992
lbb_31204:
    stxdw [r10-0x280], r2                   
    mov64 r2, r10                                   r2 = r10
    add64 r2, -592                                  r2 += -592   ///  r2 = r2.wrapping_add(-592 as i32 as i64 as u64)
    stxdw [r10-0x288], r2                   
    add64 r1, 1                                     r1 += 1   ///  r1 = r1.wrapping_add(1 as i32 as i64 as u64)
    ja lbb_31229                                    if true { pc += 19 }
lbb_31210:
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
    stxdw [r10-0x228], r2                   
    mov64 r2, 2                                     r2 = 2 as i32 as i64 as u64
    stxdw [r10-0x240], r2                   
    lddw r2, 0x100066618 --> b"\x00\x00\x00\x00\x0d(\x06\x00\x1c\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00…        r2 load str located at 4295386648
lbb_31216:
    stxdw [r10-0x248], r2                   
    mov64 r2, 1                                     r2 = 1 as i32 as i64 as u64
lbb_31218:
    stxdw [r10-0x230], r2                   
    mov64 r2, r10                                   r2 = r10
    add64 r2, -648                                  r2 += -648   ///  r2 = r2.wrapping_add(-648 as i32 as i64 as u64)
    stxdw [r10-0x238], r2                   
    lddw r2, 0x10002a298 --> b"y\x11\x00\x00\x00\x00\x00\x00\x85\x10\x00\x00\xcd/\x00\x00\x95\x00\x00\x0…        r2 load str located at 4295139992
lbb_31224:
    stxdw [r10-0x280], r2                   
    mov64 r2, r10                                   r2 = r10
    add64 r2, -536                                  r2 += -536   ///  r2 = r2.wrapping_add(-536 as i32 as i64 as u64)
lbb_31227:
    stxdw [r10-0x288], r2                   
    add64 r1, 4                                     r1 += 4   ///  r1 = r1.wrapping_add(4 as i32 as i64 as u64)
lbb_31229:
    stxdw [r10-0x218], r1                   
    mov64 r2, r10                                   r2 = r10
    add64 r2, -584                                  r2 += -584   ///  r2 = r2.wrapping_add(-584 as i32 as i64 as u64)
    ja lbb_31268                                    if true { pc += 35 }
lbb_31233:
    mov64 r2, r1                                    r2 = r1
    add64 r2, 4                                     r2 += 4   ///  r2 = r2.wrapping_add(4 as i32 as i64 as u64)
    stxdw [r10-0x258], r2                   
    mov64 r2, r1                                    r2 = r1
    add64 r2, 20                                    r2 += 20   ///  r2 = r2.wrapping_add(20 as i32 as i64 as u64)
    stxdw [r10-0x250], r2                   
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
    stxdw [r10-0x268], r2                   
    lddw r2, 0x1000666f8 --> b"\x00\x00\x00\x00?)\x06\x000\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x008\…        r2 load str located at 4295386872
lbb_31243:
    stxdw [r10-0x288], r2                   
    mov64 r2, 3                                     r2 = 3 as i32 as i64 as u64
    stxdw [r10-0x280], r2                   
    stxdw [r10-0x270], r2                   
    mov64 r2, r10                                   r2 = r10
    add64 r2, -584                                  r2 += -584   ///  r2 = r2.wrapping_add(-584 as i32 as i64 as u64)
    stxdw [r10-0x278], r2                   
    mov64 r2, r10                                   r2 = r10
    add64 r2, -536                                  r2 += -536   ///  r2 = r2.wrapping_add(-536 as i32 as i64 as u64)
    stxdw [r10-0x228], r2                   
    mov64 r2, r10                                   r2 = r10
    add64 r2, -592                                  r2 += -592   ///  r2 = r2.wrapping_add(-592 as i32 as i64 as u64)
    stxdw [r10-0x238], r2                   
    lddw r2, 0x10002a298 --> b"y\x11\x00\x00\x00\x00\x00\x00\x85\x10\x00\x00\xcd/\x00\x00\x95\x00\x00\x0…        r2 load str located at 4295139992
    stxdw [r10-0x220], r2                   
    stxdw [r10-0x230], r2                   
    stxdw [r10-0x240], r2                   
    mov64 r2, r10                                   r2 = r10
    add64 r2, -600                                  r2 += -600   ///  r2 = r2.wrapping_add(-600 as i32 as i64 as u64)
    stxdw [r10-0x248], r2                   
    add64 r1, 36                                    r1 += 36   ///  r1 = r1.wrapping_add(36 as i32 as i64 as u64)
lbb_31265:
    stxdw [r10-0x218], r1                   
    mov64 r2, r10                                   r2 = r10
    add64 r2, -648                                  r2 += -648   ///  r2 = r2.wrapping_add(-648 as i32 as i64 as u64)
lbb_31268:
    mov64 r1, r3                                    r1 = r3
    call function_45907                     
    exit                                    
lbb_31271:
    mov64 r2, r1                                    r2 = r1
    add64 r2, 8                                     r2 += 8   ///  r2 = r2.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x250], r2                   
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
    stxdw [r10-0x228], r2                   
    mov64 r2, 3                                     r2 = 3 as i32 as i64 as u64
    stxdw [r10-0x240], r2                   
    lddw r2, 0x100066728 --> b"\x00\x00\x00\x00o)\x06\x00\x18\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x0…        r2 load str located at 4295386920
    stxdw [r10-0x248], r2                   
    mov64 r2, 2                                     r2 = 2 as i32 as i64 as u64
    stxdw [r10-0x230], r2                   
    mov64 r2, r10                                   r2 = r10
    add64 r2, -648                                  r2 += -648   ///  r2 = r2.wrapping_add(-648 as i32 as i64 as u64)
    stxdw [r10-0x238], r2                   
    mov64 r2, r10                                   r2 = r10
    add64 r2, -536                                  r2 += -536   ///  r2 = r2.wrapping_add(-536 as i32 as i64 as u64)
    stxdw [r10-0x278], r2                   
    lddw r2, 0x10002a358 --> b"y\x11\x00\x00\x00\x00\x00\x00\x85\x10\x00\x00\x19\\x00\x00\x95\x00\x00\x0…        r2 load str located at 4295140184
    stxdw [r10-0x270], r2                   
    stxdw [r10-0x280], r2                   
    mov64 r2, r10                                   r2 = r10
    add64 r2, -592                                  r2 += -592   ///  r2 = r2.wrapping_add(-592 as i32 as i64 as u64)
    stxdw [r10-0x288], r2                   
    add64 r1, 24                                    r1 += 24   ///  r1 = r1.wrapping_add(24 as i32 as i64 as u64)
    ja lbb_31229                                    if true { pc += -69 }

function_31298:
    ldxb r3, [r1+0x0]                       
    jsgt r3, 4, lbb_31330                           if (r3 as i64) > (4 as i32 as i64) { pc += 30 }
    jsgt r3, 1, lbb_31372                           if (r3 as i64) > (1 as i32 as i64) { pc += 71 }
    jeq r3, 0, lbb_31407                            if r3 == (0 as i32 as i64 as u64) { pc += 105 }
    mov64 r3, r1                                    r3 = r1
    add64 r3, 20                                    r3 += 20   ///  r3 = r3.wrapping_add(20 as i32 as i64 as u64)
    stxdw [r10-0x8], r3                     
    mov64 r3, r10                                   r3 = r10
    add64 r3, -8                                    r3 += -8   ///  r3 = r3.wrapping_add(-8 as i32 as i64 as u64)
    stxdw [r10-0xfd8], r3                   
    lddw r3, 0x100066778 --> b"\x00\x00\x00\x00\xd8\xa5\x02\x00\x08\x00\x00\x00\x00\x00\x00\x00\x08\x00\…        r3 load str located at 4295387000
    stxdw [r10-0xfd0], r3                   
    lddw r3, 0x100062a59 --> b"ask_priceInitialScalingOverflowpricescale_expZeroM"        r3 load str located at 4295371353
    stxdw [r10-0xfe8], r3                   
    lddw r3, 0x100065eb0 --> b"\x00\x00\x00\x00\xd0\xa5\x02\x00\x10\x00\x00\x00\x00\x00\x00\x00\x04\x00\…        r3 load str located at 4295384752
    stxdw [r10-0xff0], r3                   
    add64 r1, 4                                     r1 += 4   ///  r1 = r1.wrapping_add(4 as i32 as i64 as u64)
    stxdw [r10-0xff8], r1                   
    mov64 r1, 9                                     r1 = 9 as i32 as i64 as u64
    stxdw [r10-0xfe0], r1                   
    stxdw [r10-0x1000], r1                  
    mov64 r5, r10                                   r5 = r10
    mov64 r1, r2                                    r1 = r2
    lddw r2, 0x100062a42 --> b"AskLessThanBid"        r2 load str located at 4295371330
    mov64 r3, 14                                    r3 = 14 as i32 as i64 as u64
    lddw r4, 0x100062a50 --> b"bid_priceask_priceInitialScalingOverflowpricescale"        r4 load str located at 4295371344
    ja lbb_31603                                    if true { pc += 273 }
lbb_31330:
    jsgt r3, 7, lbb_31386                           if (r3 as i64) > (7 as i32 as i64) { pc += 55 }
    jeq r3, 5, lbb_31419                            if r3 == (5 as i32 as i64 as u64) { pc += 87 }
    jeq r3, 6, lbb_31447                            if r3 == (6 as i32 as i64 as u64) { pc += 114 }
    mov64 r3, r1                                    r3 = r1
    add64 r3, 36                                    r3 += 36   ///  r3 = r3.wrapping_add(36 as i32 as i64 as u64)
    stxdw [r10-0x8], r3                     
    mov64 r3, r10                                   r3 = r10
    add64 r3, -8                                    r3 += -8   ///  r3 = r3.wrapping_add(-8 as i32 as i64 as u64)
    stxdw [r10-0xfb8], r3                   
    lddw r3, 0x100066778 --> b"\x00\x00\x00\x00\xd8\xa5\x02\x00\x08\x00\x00\x00\x00\x00\x00\x00\x08\x00\…        r3 load str located at 4295387000
    stxdw [r10-0xfb0], r3                   
    mov64 r3, 13                                    r3 = 13 as i32 as i64 as u64
    stxdw [r10-0xfc0], r3                   
    lddw r3, 0x100062b30 --> b"relative_difforiginal_askreconstructed_askFinalMan"        r3 load str located at 4295371568
    stxdw [r10-0xfc8], r3                   
    mov64 r3, r1                                    r3 = r1
    add64 r3, 20                                    r3 += 20   ///  r3 = r3.wrapping_add(20 as i32 as i64 as u64)
    stxdw [r10-0xfd8], r3                   
    mov64 r3, 17                                    r3 = 17 as i32 as i64 as u64
    stxdw [r10-0xfe0], r3                   
    lddw r3, 0x100062b1f --> b"reconstructed_bidrelative_difforiginal_askreconstr"        r3 load str located at 4295371551
    stxdw [r10-0xfe8], r3                   
    lddw r3, 0x100065eb0 --> b"\x00\x00\x00\x00\xd0\xa5\x02\x00\x10\x00\x00\x00\x00\x00\x00\x00\x04\x00\…        r3 load str located at 4295384752
    stxdw [r10-0xfd0], r3                   
    stxdw [r10-0xff0], r3                   
    add64 r1, 4                                     r1 += 4   ///  r1 = r1.wrapping_add(4 as i32 as i64 as u64)
    stxdw [r10-0xff8], r1                   
    mov64 r1, 12                                    r1 = 12 as i32 as i64 as u64
    stxdw [r10-0x1000], r1                  
    mov64 r5, r10                                   r5 = r10
    mov64 r1, r2                                    r1 = r2
    lddw r2, 0x10005fc08 --> b"BidPrecisionLoss"        r2 load str located at 4295359496
    mov64 r3, 16                                    r3 = 16 as i32 as i64 as u64
    lddw r4, 0x100062b13 --> b"original_bidreconstructed_bidrelative_difforiginal"        r4 load str located at 4295371539
    call function_46026                     
    ja lbb_31604                                    if true { pc += 232 }
lbb_31372:
    jeq r3, 2, lbb_31488                            if r3 == (2 as i32 as i64 as u64) { pc += 115 }
    jeq r3, 3, lbb_31517                            if r3 == (3 as i32 as i64 as u64) { pc += 143 }
    add64 r1, 4                                     r1 += 4   ///  r1 = r1.wrapping_add(4 as i32 as i64 as u64)
    stxdw [r10-0x8], r1                     
    mov64 r4, r10                                   r4 = r10
    add64 r4, -8                                    r4 += -8   ///  r4 = r4.wrapping_add(-8 as i32 as i64 as u64)
    mov64 r1, r2                                    r1 = r2
    lddw r2, 0x100062aa0 --> b"ExponentOutOfRange"        r2 load str located at 4295371424
    mov64 r3, 18                                    r3 = 18 as i32 as i64 as u64
    lddw r5, 0x1000667b8 --> b"\x00\x00\x00\x00\xd8\xa5\x02\x00\x08\x00\x00\x00\x00\x00\x00\x00\x08\x00\…        r5 load str located at 4295387064
    call function_46104                     
    ja lbb_31604                                    if true { pc += 218 }
lbb_31386:
    jeq r3, 8, lbb_31536                            if r3 == (8 as i32 as i64 as u64) { pc += 149 }
    jeq r3, 9, lbb_31575                            if r3 == (9 as i32 as i64 as u64) { pc += 187 }
    add64 r1, 4                                     r1 += 4   ///  r1 = r1.wrapping_add(4 as i32 as i64 as u64)
    stxdw [r10-0x8], r1                     
    mov64 r1, r10                                   r1 = r10
    add64 r1, -8                                    r1 += -8   ///  r1 = r1.wrapping_add(-8 as i32 as i64 as u64)
    stxdw [r10-0xff8], r1                   
    lddw r1, 0x100066778 --> b"\x00\x00\x00\x00\xd8\xa5\x02\x00\x08\x00\x00\x00\x00\x00\x00\x00\x08\x00\…        r1 load str located at 4295387000
    stxdw [r10-0xff0], r1                   
    mov64 r1, 5                                     r1 = 5 as i32 as i64 as u64
    stxdw [r10-0x1000], r1                  
    mov64 r5, r10                                   r5 = r10
    mov64 r1, r2                                    r1 = r2
    lddw r2, 0x100062b84 --> b"RelativeErrorReconstructionMismatch"        r2 load str located at 4295371652
    mov64 r3, 35                                    r3 = 35 as i32 as i64 as u64
    lddw r4, 0x100062a78 --> b"pricescale_expZeroMantissaoriginal_priceExponentOu"        r4 load str located at 4295371384
    call function_45925                     
    ja lbb_31604                                    if true { pc += 197 }
lbb_31407:
    add64 r1, 4                                     r1 += 4   ///  r1 = r1.wrapping_add(4 as i32 as i64 as u64)
    stxdw [r10-0x8], r1                     
    mov64 r4, r10                                   r4 = r10
    add64 r4, -8                                    r4 += -8   ///  r4 = r4.wrapping_add(-8 as i32 as i64 as u64)
    mov64 r1, r2                                    r1 = r2
    lddw r2, 0x100062a31 --> b"InvalidInputPrice"        r2 load str located at 4295371313
    mov64 r3, 17                                    r3 = 17 as i32 as i64 as u64
    lddw r5, 0x100066778 --> b"\x00\x00\x00\x00\xd8\xa5\x02\x00\x08\x00\x00\x00\x00\x00\x00\x00\x08\x00\…        r5 load str located at 4295387000
    call function_46104                     
    ja lbb_31604                                    if true { pc += 185 }
lbb_31419:
    mov64 r3, r1                                    r3 = r1
    add64 r3, 1                                     r3 += 1   ///  r3 = r3.wrapping_add(1 as i32 as i64 as u64)
    stxdw [r10-0x8], r3                     
    mov64 r3, r10                                   r3 = r10
    add64 r3, -8                                    r3 += -8   ///  r3 = r3.wrapping_add(-8 as i32 as i64 as u64)
    stxdw [r10-0xfd8], r3                   
    lddw r3, 0x1000667f8 --> b"\x00\x00\x00\x00\xd8\xa5\x02\x00\x08\x00\x00\x00\x00\x00\x00\x00\x08\x00\…        r3 load str located at 4295387128
    stxdw [r10-0xfd0], r3                   
    lddw r3, 0x100060960 --> b"exponentmantissaDeadlockdeadlockAccount Expected 1"        r3 load str located at 4295362912
    stxdw [r10-0xfe8], r3                   
    lddw r3, 0x1000667d8 --> b"\x00\x00\x00\x00\xd8\xa5\x02\x00\x10\x00\x00\x00\x00\x00\x00\x00\x08\x00\…        r3 load str located at 4295387096
    stxdw [r10-0xff0], r3                   
    add64 r1, 8                                     r1 += 8   ///  r1 = r1.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0xff8], r1                   
    mov64 r1, 8                                     r1 = 8 as i32 as i64 as u64
    stxdw [r10-0xfe0], r1                   
    stxdw [r10-0x1000], r1                  
    mov64 r5, r10                                   r5 = r10
    mov64 r1, r2                                    r1 = r2
    lddw r2, 0x100062ab2 --> b"ReconstructionOverflowMantissa"        r2 load str located at 4295371442
    mov64 r3, 30                                    r3 = 30 as i32 as i64 as u64
    lddw r4, 0x100060968 --> b"mantissaDeadlockdeadlockAccount Expected 1 token m"        r4 load str located at 4295362920
    ja lbb_31603                                    if true { pc += 156 }
lbb_31447:
    mov64 r3, r1                                    r3 = r1
    add64 r3, 3                                     r3 += 3   ///  r3 = r3.wrapping_add(3 as i32 as i64 as u64)
    stxdw [r10-0x8], r3                     
    mov64 r3, r10                                   r3 = r10
    add64 r3, -8                                    r3 += -8   ///  r3 = r3.wrapping_add(-8 as i32 as i64 as u64)
    stxdw [r10-0xfb8], r3                   
    lddw r3, 0x100066798 --> b"\x00\x00\x00\x00\xd8\xa5\x02\x00\x08\x00\x00\x00\x00\x00\x00\x00\x08\x00\…        r3 load str located at 4295387032
    stxdw [r10-0xfb0], r3                   
    mov64 r3, 18                                    r3 = 18 as i32 as i64 as u64
    stxdw [r10-0xfc0], r3                   
    lddw r3, 0x100062b01 --> b"max_fpdec_exponentoriginal_bidreconstructed_bidrel"        r3 load str located at 4295371521
    stxdw [r10-0xfc8], r3                   
    lddw r3, 0x100065e90 --> b"\x00\x00\x00\x00\xc8\xa5\x02\x00\x01\x00\x00\x00\x00\x00\x00\x00\x01\x00\…        r3 load str located at 4295384720
    stxdw [r10-0xfd0], r3                   
    mov64 r3, r1                                    r3 = r1
    add64 r3, 2                                     r3 += 2   ///  r3 = r3.wrapping_add(2 as i32 as i64 as u64)
    stxdw [r10-0xfd8], r3                   
    mov64 r3, 14                                    r3 = 14 as i32 as i64 as u64
    stxdw [r10-0xfe0], r3                   
    lddw r3, 0x100062af3 --> b"fpdec_exponentmax_fpdec_exponentoriginal_bidrecons"        r3 load str located at 4295371507
    stxdw [r10-0xfe8], r3                   
    lddw r3, 0x100066818 --> b"\x00\x00\x00\x00\xc8\xa5\x02\x00\x01\x00\x00\x00\x00\x00\x00\x00\x01\x00\…        r3 load str located at 4295387160
    stxdw [r10-0xff0], r3                   
    add64 r1, 1                                     r1 += 1   ///  r1 = r1.wrapping_add(1 as i32 as i64 as u64)
    stxdw [r10-0xff8], r1                   
    mov64 r1, 8                                     r1 = 8 as i32 as i64 as u64
    stxdw [r10-0x1000], r1                  
    mov64 r5, r10                                   r5 = r10
    mov64 r1, r2                                    r1 = r2
    lddw r2, 0x100062ad0 --> b"ReconstructionOverflowFpdecExponent"        r2 load str located at 4295371472
    mov64 r3, 35                                    r3 = 35 as i32 as i64 as u64
    lddw r4, 0x100060960 --> b"exponentmantissaDeadlockdeadlockAccount Expected 1"        r4 load str located at 4295362912
    call function_46026                     
    ja lbb_31604                                    if true { pc += 116 }
lbb_31488:
    mov64 r3, r1                                    r3 = r1
    add64 r3, 1                                     r3 += 1   ///  r3 = r3.wrapping_add(1 as i32 as i64 as u64)
    stxdw [r10-0x8], r3                     
    mov64 r3, r10                                   r3 = r10
    add64 r3, -8                                    r3 += -8   ///  r3 = r3.wrapping_add(-8 as i32 as i64 as u64)
    stxdw [r10-0xfd8], r3                   
    lddw r3, 0x100066798 --> b"\x00\x00\x00\x00\xd8\xa5\x02\x00\x08\x00\x00\x00\x00\x00\x00\x00\x08\x00\…        r3 load str located at 4295387032
    stxdw [r10-0xfd0], r3                   
    mov64 r3, 9                                     r3 = 9 as i32 as i64 as u64
    stxdw [r10-0xfe0], r3                   
    lddw r3, 0x100062a7d --> b"scale_expZeroMantissaoriginal_priceExponentOutOfRa"        r3 load str located at 4295371389
    stxdw [r10-0xfe8], r3                   
    lddw r3, 0x100065eb0 --> b"\x00\x00\x00\x00\xd0\xa5\x02\x00\x10\x00\x00\x00\x00\x00\x00\x00\x04\x00\…        r3 load str located at 4295384752
    stxdw [r10-0xff0], r3                   
    add64 r1, 4                                     r1 += 4   ///  r1 = r1.wrapping_add(4 as i32 as i64 as u64)
    stxdw [r10-0xff8], r1                   
    mov64 r1, 5                                     r1 = 5 as i32 as i64 as u64
    stxdw [r10-0x1000], r1                  
    mov64 r5, r10                                   r5 = r10
    mov64 r1, r2                                    r1 = r2
    lddw r2, 0x100062a62 --> b"InitialScalingOverflow"        r2 load str located at 4295371362
    mov64 r3, 22                                    r3 = 22 as i32 as i64 as u64
    lddw r4, 0x100062a78 --> b"pricescale_expZeroMantissaoriginal_priceExponentOu"        r4 load str located at 4295371384
    ja lbb_31603                                    if true { pc += 86 }
lbb_31517:
    add64 r1, 4                                     r1 += 4   ///  r1 = r1.wrapping_add(4 as i32 as i64 as u64)
    stxdw [r10-0x8], r1                     
    mov64 r1, r10                                   r1 = r10
    add64 r1, -8                                    r1 += -8   ///  r1 = r1.wrapping_add(-8 as i32 as i64 as u64)
    stxdw [r10-0xff8], r1                   
    lddw r1, 0x100066778 --> b"\x00\x00\x00\x00\xd8\xa5\x02\x00\x08\x00\x00\x00\x00\x00\x00\x00\x08\x00\…        r1 load str located at 4295387000
    stxdw [r10-0xff0], r1                   
    mov64 r1, 14                                    r1 = 14 as i32 as i64 as u64
    stxdw [r10-0x1000], r1                  
    mov64 r5, r10                                   r5 = r10
    mov64 r1, r2                                    r1 = r2
    lddw r2, 0x100062a86 --> b"ZeroMantissa"        r2 load str located at 4295371398
    mov64 r3, 12                                    r3 = 12 as i32 as i64 as u64
    lddw r4, 0x100062a92 --> b"original_priceExponentOutOfRangeReconstructionOver"        r4 load str located at 4295371410
    call function_45925                     
    ja lbb_31604                                    if true { pc += 68 }
lbb_31536:
    mov64 r3, r1                                    r3 = r1
    add64 r3, 36                                    r3 += 36   ///  r3 = r3.wrapping_add(36 as i32 as i64 as u64)
    stxdw [r10-0x8], r3                     
    mov64 r3, r10                                   r3 = r10
    add64 r3, -8                                    r3 += -8   ///  r3 = r3.wrapping_add(-8 as i32 as i64 as u64)
    stxdw [r10-0xfb8], r3                   
    lddw r3, 0x100066778 --> b"\x00\x00\x00\x00\xd8\xa5\x02\x00\x08\x00\x00\x00\x00\x00\x00\x00\x08\x00\…        r3 load str located at 4295387000
    stxdw [r10-0xfb0], r3                   
    mov64 r3, 13                                    r3 = 13 as i32 as i64 as u64
    stxdw [r10-0xfc0], r3                   
    lddw r3, 0x100062b30 --> b"relative_difforiginal_askreconstructed_askFinalMan"        r3 load str located at 4295371568
    stxdw [r10-0xfc8], r3                   
    mov64 r3, r1                                    r3 = r1
    add64 r3, 20                                    r3 += 20   ///  r3 = r3.wrapping_add(20 as i32 as i64 as u64)
    stxdw [r10-0xfd8], r3                   
    mov64 r3, 17                                    r3 = 17 as i32 as i64 as u64
    stxdw [r10-0xfe0], r3                   
    lddw r3, 0x100062b49 --> b"reconstructed_askFinalMantissaConversionErrorvalue"        r3 load str located at 4295371593
    stxdw [r10-0xfe8], r3                   
    lddw r3, 0x100065eb0 --> b"\x00\x00\x00\x00\xd0\xa5\x02\x00\x10\x00\x00\x00\x00\x00\x00\x00\x04\x00\…        r3 load str located at 4295384752
    stxdw [r10-0xfd0], r3                   
    stxdw [r10-0xff0], r3                   
    add64 r1, 4                                     r1 += 4   ///  r1 = r1.wrapping_add(4 as i32 as i64 as u64)
    stxdw [r10-0xff8], r1                   
    mov64 r1, 12                                    r1 = 12 as i32 as i64 as u64
    stxdw [r10-0x1000], r1                  
    mov64 r5, r10                                   r5 = r10
    mov64 r1, r2                                    r1 = r2
    lddw r2, 0x10005fc28 --> b"AskPrecisionLoss"        r2 load str located at 4295359528
    mov64 r3, 16                                    r3 = 16 as i32 as i64 as u64
    lddw r4, 0x100062b3d --> b"original_askreconstructed_askFinalMantissaConversi"        r4 load str located at 4295371581
    call function_46026                     
    ja lbb_31604                                    if true { pc += 29 }
lbb_31575:
    mov64 r3, r1                                    r3 = r1
    add64 r3, 24                                    r3 += 24   ///  r3 = r3.wrapping_add(24 as i32 as i64 as u64)
    stxdw [r10-0x8], r3                     
    mov64 r3, r10                                   r3 = r10
    add64 r3, -8                                    r3 += -8   ///  r3 = r3.wrapping_add(-8 as i32 as i64 as u64)
    stxdw [r10-0xfd8], r3                   
    lddw r3, 0x100066838 --> b"\x00\x00\x00\x00\xd8\xa5\x02\x00\x08\x00\x00\x00\x00\x00\x00\x00\x08\x00\…        r3 load str located at 4295387192
    stxdw [r10-0xfd0], r3                   
    mov64 r3, 9                                     r3 = 9 as i32 as i64 as u64
    stxdw [r10-0xfe0], r3                   
    lddw r3, 0x100062b7b --> b"value_askRelativeErrorReconstructionMismatch\x00\x09\x00\x00\x00\x00"        r3 load str located at 4295371643
    stxdw [r10-0xfe8], r3                   
    lddw r3, 0x1000667d8 --> b"\x00\x00\x00\x00\xd8\xa5\x02\x00\x10\x00\x00\x00\x00\x00\x00\x00\x08\x00\…        r3 load str located at 4295387096
    stxdw [r10-0xff0], r3                   
    add64 r1, 8                                     r1 += 8   ///  r1 = r1.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0xff8], r1                   
    mov64 r1, 5                                     r1 = 5 as i32 as i64 as u64
    stxdw [r10-0x1000], r1                  
    mov64 r5, r10                                   r5 = r10
    mov64 r1, r2                                    r1 = r2
    lddw r2, 0x100062b5a --> b"FinalMantissaConversionError"        r2 load str located at 4295371610
    mov64 r3, 28                                    r3 = 28 as i32 as i64 as u64
    lddw r4, 0x100062b76 --> b"valuevalue_askRelativeErrorReconstructionMismatch\x00"        r4 load str located at 4295371638
lbb_31603:
    call function_45972                     
lbb_31604:
    exit                                    

function_31605:
    mov64 r7, r3                                    r7 = r3
    mov64 r6, r1                                    r6 = r1
    jeq r2, 0, lbb_31621                            if r2 == (0 as i32 as i64 as u64) { pc += 13 }
    ldxdw r1, [r4+0x8]                      
    jeq r1, 0, lbb_31637                            if r1 == (0 as i32 as i64 as u64) { pc += 27 }
    ldxdw r2, [r4+0x10]                     
    jne r2, 0, lbb_31626                            if r2 != (0 as i32 as i64 as u64) { pc += 14 }
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    mov64 r0, 1                                     r0 = 1 as i32 as i64 as u64
    jeq r7, 0, lbb_31645                            if r7 == (0 as i32 as i64 as u64) { pc += 30 }
    mov64 r1, r7                                    r1 = r7
    mov64 r2, 1                                     r2 = 1 as i32 as i64 as u64
    call function_21359                     
    mov64 r1, r7                                    r1 = r7
    jeq r0, 0, lbb_31633                            if r0 == (0 as i32 as i64 as u64) { pc += 13 }
    ja lbb_31645                                    if true { pc += 24 }
lbb_31621:
    stxdw [r6+0x10], r7                     
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    stxdw [r6+0x8], r1                      
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    ja lbb_31648                                    if true { pc += 22 }
lbb_31626:
    ldxdw r1, [r4+0x0]                      
    mov64 r3, 1                                     r3 = 1 as i32 as i64 as u64
    mov64 r4, r7                                    r4 = r7
    call function_21386                     
    mov64 r1, r7                                    r1 = r7
    jeq r0, 0, lbb_31633                            if r0 == (0 as i32 as i64 as u64) { pc += 1 }
    ja lbb_31645                                    if true { pc += 12 }
lbb_31633:
    stxdw [r6+0x10], r7                     
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    stxdw [r6+0x8], r1                      
    ja lbb_31648                                    if true { pc += 11 }
lbb_31637:
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    mov64 r0, 1                                     r0 = 1 as i32 as i64 as u64
    jeq r7, 0, lbb_31645                            if r7 == (0 as i32 as i64 as u64) { pc += 5 }
    mov64 r1, r7                                    r1 = r7
    mov64 r2, 1                                     r2 = 1 as i32 as i64 as u64
    call function_21359                     
    mov64 r1, r7                                    r1 = r7
    jeq r0, 0, lbb_31633                            if r0 == (0 as i32 as i64 as u64) { pc += -12 }
lbb_31645:
    stxdw [r6+0x10], r1                     
    stxdw [r6+0x8], r0                      
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
lbb_31648:
    stxdw [r6+0x0], r1                      
    exit                                    

function_31650:
    mov64 r6, r1                                    r6 = r1
    add64 r2, 1                                     r2 += 1   ///  r2 = r2.wrapping_add(1 as i32 as i64 as u64)
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    jeq r2, 0, lbb_31655                            if r2 == (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
lbb_31655:
    and64 r1, 1                                     r1 &= 1   ///  r1 = r1.and(1)
    jne r1, 0, lbb_31696                            if r1 != (0 as i32 as i64 as u64) { pc += 39 }
    ldxdw r1, [r6+0x8]                      
    mov64 r7, r1                                    r7 = r1
    lsh64 r7, 1                                     r7 <<= 1   ///  r7 = r7.wrapping_shl(1)
    jgt r7, r2, lbb_31662                           if r7 > r2 { pc += 1 }
    mov64 r7, r2                                    r7 = r2
lbb_31662:
    jgt r7, 4, lbb_31664                            if r7 > (4 as i32 as i64 as u64) { pc += 1 }
    mov64 r7, 4                                     r7 = 4 as i32 as i64 as u64
lbb_31664:
    mov64 r2, 1                                     r2 = 1 as i32 as i64 as u64
    lddw r3, 0x3c3c3c3c3c3c3c4                      r3 load str located at 271275648142787524
    jgt r3, r7, lbb_31669                           if r3 > r7 { pc += 1 }
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
lbb_31669:
    mov64 r3, r7                                    r3 = r7
    mul64 r3, 34                                    r3 *= 34   ///  r3 = r3.wrapping_mul(34 as u64)
    jne r1, 0, lbb_31675                            if r1 != (0 as i32 as i64 as u64) { pc += 3 }
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    stxdw [r10-0x10], r1                    
    ja lbb_31681                                    if true { pc += 6 }
lbb_31675:
    ldxdw r4, [r6+0x0]                      
    mul64 r1, 34                                    r1 *= 34   ///  r1 = r1.wrapping_mul(34 as u64)
    stxdw [r10-0x8], r1                     
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    stxdw [r10-0x10], r1                    
    stxdw [r10-0x18], r4                    
lbb_31681:
    mov64 r1, r10                                   r1 = r10
    add64 r1, -48                                   r1 += -48   ///  r1 = r1.wrapping_add(-48 as i32 as i64 as u64)
    mov64 r4, r10                                   r4 = r10
    add64 r4, -24                                   r4 += -24   ///  r4 = r4.wrapping_add(-24 as i32 as i64 as u64)
    call function_31605                     
    ldxdw r1, [r10-0x28]                    
    ldxdw r2, [r10-0x30]                    
    jne r2, 0, lbb_31692                            if r2 != (0 as i32 as i64 as u64) { pc += 3 }
    stxdw [r6+0x8], r7                      
    stxdw [r6+0x0], r1                      
lbb_31691:
    exit                                    
lbb_31692:
    lddw r2, 0x8000000000000001                     r2 load str located at -9223372036854775807
    jeq r1, r2, lbb_31691                           if r1 == r2 { pc += -4 }
    jne r1, 0, lbb_31698                            if r1 != (0 as i32 as i64 as u64) { pc += 2 }
lbb_31696:
    call function_43383                     
    syscall [invalid]                       
lbb_31698:
    ldxdw r2, [r10-0x20]                    
    call function_43400                     
    syscall [invalid]                       

function_31701:
    mov64 r6, r1                                    r6 = r1
    mov64 r4, r2                                    r4 = r2
    add64 r4, r3                                    r4 += r3   ///  r4 = r4.wrapping_add(r3)
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    jgt r2, r4, lbb_31707                           if r2 > r4 { pc += 1 }
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
lbb_31707:
    and64 r1, 1                                     r1 &= 1   ///  r1 = r1.and(1)
    jne r1, 0, lbb_31744                            if r1 != (0 as i32 as i64 as u64) { pc += 35 }
    ldxdw r1, [r6+0x8]                      
    mov64 r7, r1                                    r7 = r1
    lsh64 r7, 1                                     r7 <<= 1   ///  r7 = r7.wrapping_shl(1)
    jgt r7, r4, lbb_31714                           if r7 > r4 { pc += 1 }
    mov64 r7, r4                                    r7 = r4
lbb_31714:
    jgt r7, 8, lbb_31716                            if r7 > (8 as i32 as i64 as u64) { pc += 1 }
    mov64 r7, 8                                     r7 = 8 as i32 as i64 as u64
lbb_31716:
    mov64 r2, r7                                    r2 = r7
    xor64 r2, -1                                    r2 ^= -1   ///  r2 = r2.xor(-1)
    rsh64 r2, 63                                    r2 >>= 63   ///  r2 = r2.wrapping_shr(63)
    jne r1, 0, lbb_31723                            if r1 != (0 as i32 as i64 as u64) { pc += 3 }
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    stxdw [r10-0x10], r1                    
    ja lbb_31728                                    if true { pc += 5 }
lbb_31723:
    ldxdw r3, [r6+0x0]                      
    stxdw [r10-0x8], r1                     
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    stxdw [r10-0x10], r1                    
    stxdw [r10-0x18], r3                    
lbb_31728:
    mov64 r1, r10                                   r1 = r10
    add64 r1, -48                                   r1 += -48   ///  r1 = r1.wrapping_add(-48 as i32 as i64 as u64)
    mov64 r4, r10                                   r4 = r10
    add64 r4, -24                                   r4 += -24   ///  r4 = r4.wrapping_add(-24 as i32 as i64 as u64)
    mov64 r3, r7                                    r3 = r7
    call function_31605                     
    ldxdw r1, [r10-0x28]                    
    ldxdw r2, [r10-0x30]                    
    jne r2, 0, lbb_31740                            if r2 != (0 as i32 as i64 as u64) { pc += 3 }
    stxdw [r6+0x8], r7                      
    stxdw [r6+0x0], r1                      
lbb_31739:
    exit                                    
lbb_31740:
    lddw r2, 0x8000000000000001                     r2 load str located at -9223372036854775807
    jeq r1, r2, lbb_31739                           if r1 == r2 { pc += -4 }
    jne r1, 0, lbb_31746                            if r1 != (0 as i32 as i64 as u64) { pc += 2 }
lbb_31744:
    call function_43383                     
    syscall [invalid]                       
lbb_31746:
    ldxdw r2, [r10-0x20]                    
    call function_43400                     
    syscall [invalid]                       

function_31749:
    mov64 r7, r2                                    r7 = r2
    mov64 r6, r1                                    r6 = r1
    mov64 r8, 80                                    r8 = 80 as i32 as i64 as u64
    mov64 r1, 80                                    r1 = 80 as i32 as i64 as u64
    mov64 r2, 1                                     r2 = 1 as i32 as i64 as u64
    call function_21359                     
    jne r0, 0, lbb_31760                            if r0 != (0 as i32 as i64 as u64) { pc += 4 }
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    mov64 r2, 80                                    r2 = 80 as i32 as i64 as u64
    call function_43400                     
    syscall [invalid]                       
lbb_31760:
    stxdw [r10-0x10], r8                    
    stxdw [r10-0x18], r0                    
    ldxw r1, [r7+0x0]                       
    jsgt r1, 11, lbb_31773                          if (r1 as i64) > (11 as i32 as i64) { pc += 9 }
    jsgt r1, 5, lbb_31813                           if (r1 as i64) > (5 as i32 as i64) { pc += 48 }
    jsgt r1, 2, lbb_31824                           if (r1 as i64) > (2 as i32 as i64) { pc += 58 }
    jeq r1, 0, lbb_31952                            if r1 == (0 as i32 as i64 as u64) { pc += 185 }
    jeq r1, 1, lbb_31889                            if r1 == (1 as i32 as i64 as u64) { pc += 121 }
    ldxb r1, [r7+0x8]                       
    stxb [r0+0x1], r1                       
    mov64 r9, 2                                     r9 = 2 as i32 as i64 as u64
    stxb [r0+0x0], r9                       
    ja lbb_31931                                    if true { pc += 158 }
lbb_31773:
    jsgt r1, 17, lbb_31783                          if (r1 as i64) > (17 as i32 as i64) { pc += 9 }
    jsgt r1, 14, lbb_31828                          if (r1 as i64) > (14 as i32 as i64) { pc += 53 }
    jeq r1, 12, lbb_31853                           if r1 == (12 as i32 as i64 as u64) { pc += 77 }
    jeq r1, 13, lbb_31892                           if r1 == (13 as i32 as i64 as u64) { pc += 115 }
    ldxdw r1, [r7+0x8]                      
    ldxb r2, [r7+0x10]                      
    stxb [r0+0x9], r2                       
    stxdw [r0+0x1], r1                      
    mov64 r1, 14                                    r1 = 14 as i32 as i64 as u64
    ja lbb_31897                                    if true { pc += 114 }
lbb_31783:
    jsgt r1, 20, lbb_31820                          if (r1 as i64) > (20 as i32 as i64) { pc += 36 }
    jeq r1, 18, lbb_31859                           if r1 == (18 as i32 as i64 as u64) { pc += 74 }
    jeq r1, 19, lbb_31861                           if r1 == (19 as i32 as i64 as u64) { pc += 75 }
    ldxb r1, [r7+0x8]                       
    stxb [r0+0x1], r1                       
    mov64 r1, 20                                    r1 = 20 as i32 as i64 as u64
    stxb [r0+0x0], r1                       
    ldxdw r1, [r7+0x21]                     
    stxdw [r0+0x1a], r1                     
    ldxdw r1, [r7+0x19]                     
    stxdw [r0+0x12], r1                     
    ldxdw r1, [r7+0x11]                     
    stxdw [r0+0xa], r1                      
    ldxdw r1, [r7+0x9]                      
    stxdw [r0+0x2], r1                      
    ldxw r1, [r7+0x2c]                      
    jne r1, 0, lbb_31801                            if r1 != (0 as i32 as i64 as u64) { pc += 1 }
    ja lbb_31950                                    if true { pc += 149 }
lbb_31801:
    ldxdw r1, [r7+0x30]                     
    ldxdw r2, [r7+0x38]                     
    ldxdw r3, [r7+0x40]                     
    ldxdw r4, [r7+0x48]                     
    stxdw [r0+0x3b], r4                     
    stxdw [r0+0x33], r3                     
    stxdw [r0+0x2b], r2                     
    stxdw [r0+0x23], r1                     
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    stxb [r0+0x22], r1                      
    mov64 r9, 67                                    r9 = 67 as i32 as i64 as u64
    ja lbb_31931                                    if true { pc += 118 }
lbb_31813:
    jsgt r1, 8, lbb_31832                           if (r1 as i64) > (8 as i32 as i64) { pc += 18 }
    jeq r1, 6, lbb_31867                            if r1 == (6 as i32 as i64 as u64) { pc += 52 }
    jeq r1, 7, lbb_31900                            if r1 == (7 as i32 as i64 as u64) { pc += 84 }
    ldxdw r1, [r7+0x8]                      
    stxdw [r0+0x1], r1                      
    mov64 r1, 8                                     r1 = 8 as i32 as i64 as u64
    ja lbb_31929                                    if true { pc += 109 }
lbb_31820:
    jsgt r1, 22, lbb_31836                          if (r1 as i64) > (22 as i32 as i64) { pc += 15 }
    jeq r1, 21, lbb_31904                           if r1 == (21 as i32 as i64 as u64) { pc += 82 }
    mov64 r1, 22                                    r1 = 22 as i32 as i64 as u64
    ja lbb_31923                                    if true { pc += 99 }
lbb_31824:
    jeq r1, 3, lbb_31877                            if r1 == (3 as i32 as i64 as u64) { pc += 52 }
    jeq r1, 4, lbb_31906                            if r1 == (4 as i32 as i64 as u64) { pc += 80 }
    mov64 r1, 5                                     r1 = 5 as i32 as i64 as u64
    ja lbb_31923                                    if true { pc += 95 }
lbb_31828:
    jeq r1, 15, lbb_31881                           if r1 == (15 as i32 as i64 as u64) { pc += 52 }
    jeq r1, 16, lbb_31910                           if r1 == (16 as i32 as i64 as u64) { pc += 80 }
    mov64 r1, 17                                    r1 = 17 as i32 as i64 as u64
    ja lbb_31923                                    if true { pc += 91 }
lbb_31832:
    jeq r1, 9, lbb_31887                            if r1 == (9 as i32 as i64 as u64) { pc += 54 }
    jeq r1, 10, lbb_31922                           if r1 == (10 as i32 as i64 as u64) { pc += 88 }
    mov64 r1, 11                                    r1 = 11 as i32 as i64 as u64
    ja lbb_31923                                    if true { pc += 87 }
lbb_31836:
    jeq r1, 23, lbb_31926                           if r1 == (23 as i32 as i64 as u64) { pc += 89 }
    mov64 r1, 24                                    r1 = 24 as i32 as i64 as u64
    stxb [r0+0x0], r1                       
    mov64 r9, 1                                     r9 = 1 as i32 as i64 as u64
    stxdw [r10-0x8], r9                     
    ldxdw r8, [r7+0x8]                      
    ldxdw r7, [r7+0x10]                     
    mov64 r1, 80                                    r1 = 80 as i32 as i64 as u64
    jgt r1, r7, lbb_31846                           if r1 > r7 { pc += 1 }
    ja lbb_31969                                    if true { pc += 123 }
lbb_31846:
    add64 r0, r9                                    r0 += r9   ///  r0 = r0.wrapping_add(r9)
    mov64 r1, r0                                    r1 = r0
    mov64 r2, r8                                    r2 = r8
    mov64 r3, r7                                    r3 = r7
    call function_48190                     
    add64 r9, r7                                    r9 += r7   ///  r9 = r9.wrapping_add(r7)
    ja lbb_31931                                    if true { pc += 78 }
lbb_31853:
    ldxdw r1, [r7+0x8]                      
    ldxb r2, [r7+0x10]                      
    stxb [r0+0x9], r2                       
    stxdw [r0+0x1], r1                      
    mov64 r1, 12                                    r1 = 12 as i32 as i64 as u64
    ja lbb_31897                                    if true { pc += 38 }
lbb_31859:
    mov64 r1, 18                                    r1 = 18 as i32 as i64 as u64
    ja lbb_31911                                    if true { pc += 50 }
lbb_31861:
    ldxb r1, [r7+0x8]                       
    stxb [r0+0x1], r1                       
    mov64 r1, 19                                    r1 = 19 as i32 as i64 as u64
    stxb [r0+0x0], r1                       
    mov64 r9, 2                                     r9 = 2 as i32 as i64 as u64
    ja lbb_31931                                    if true { pc += 64 }
lbb_31867:
    mov64 r1, 6                                     r1 = 6 as i32 as i64 as u64
    stxb [r0+0x0], r1                       
    ldxb r1, [r7+0x8]                       
    stxb [r0+0x1], r1                       
    ldxw r1, [r7+0xc]                       
    jne r1, 0, lbb_31938                            if r1 != (0 as i32 as i64 as u64) { pc += 65 }
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    stxb [r0+0x2], r1                       
    mov64 r9, 3                                     r9 = 3 as i32 as i64 as u64
    ja lbb_31931                                    if true { pc += 54 }
lbb_31877:
    ldxdw r1, [r7+0x8]                      
    stxdw [r0+0x1], r1                      
    mov64 r1, 3                                     r1 = 3 as i32 as i64 as u64
    ja lbb_31929                                    if true { pc += 48 }
lbb_31881:
    ldxdw r1, [r7+0x8]                      
    ldxb r2, [r7+0x10]                      
    stxb [r0+0x9], r2                       
    stxdw [r0+0x1], r1                      
    mov64 r1, 15                                    r1 = 15 as i32 as i64 as u64
    ja lbb_31897                                    if true { pc += 10 }
lbb_31887:
    mov64 r1, 9                                     r1 = 9 as i32 as i64 as u64
    ja lbb_31923                                    if true { pc += 34 }
lbb_31889:
    mov64 r9, 1                                     r9 = 1 as i32 as i64 as u64
    stxb [r0+0x0], r9                       
    ja lbb_31931                                    if true { pc += 39 }
lbb_31892:
    ldxdw r1, [r7+0x8]                      
    ldxb r2, [r7+0x10]                      
    stxb [r0+0x9], r2                       
    stxdw [r0+0x1], r1                      
    mov64 r1, 13                                    r1 = 13 as i32 as i64 as u64
lbb_31897:
    stxb [r0+0x0], r1                       
    mov64 r9, 10                                    r9 = 10 as i32 as i64 as u64
    ja lbb_31931                                    if true { pc += 31 }
lbb_31900:
    ldxdw r1, [r7+0x8]                      
    stxdw [r0+0x1], r1                      
    mov64 r1, 7                                     r1 = 7 as i32 as i64 as u64
    ja lbb_31929                                    if true { pc += 25 }
lbb_31904:
    mov64 r1, 21                                    r1 = 21 as i32 as i64 as u64
    ja lbb_31923                                    if true { pc += 17 }
lbb_31906:
    ldxdw r1, [r7+0x8]                      
    stxdw [r0+0x1], r1                      
    mov64 r1, 4                                     r1 = 4 as i32 as i64 as u64
    ja lbb_31929                                    if true { pc += 19 }
lbb_31910:
    mov64 r1, 16                                    r1 = 16 as i32 as i64 as u64
lbb_31911:
    stxb [r0+0x0], r1                       
    ldxdw r1, [r7+0x8]                      
    stxdw [r0+0x1], r1                      
    ldxdw r1, [r7+0x10]                     
    stxdw [r0+0x9], r1                      
    ldxdw r1, [r7+0x18]                     
    stxdw [r0+0x11], r1                     
    ldxdw r1, [r7+0x20]                     
    stxdw [r0+0x19], r1                     
    mov64 r9, 33                                    r9 = 33 as i32 as i64 as u64
    ja lbb_31931                                    if true { pc += 9 }
lbb_31922:
    mov64 r1, 10                                    r1 = 10 as i32 as i64 as u64
lbb_31923:
    stxb [r0+0x0], r1                       
    mov64 r9, 1                                     r9 = 1 as i32 as i64 as u64
    ja lbb_31931                                    if true { pc += 5 }
lbb_31926:
    ldxdw r1, [r7+0x8]                      
    stxdw [r0+0x1], r1                      
    mov64 r1, 23                                    r1 = 23 as i32 as i64 as u64
lbb_31929:
    stxb [r0+0x0], r1                       
    mov64 r9, 9                                     r9 = 9 as i32 as i64 as u64
lbb_31931:
    stxdw [r10-0x8], r9                     
    stxdw [r6+0x10], r9                     
    ldxdw r1, [r10-0x10]                    
    stxdw [r6+0x8], r1                      
    ldxdw r1, [r10-0x18]                    
    stxdw [r6+0x0], r1                      
    exit                                    
lbb_31938:
    ldxdw r1, [r7+0x10]                     
    ldxdw r2, [r7+0x18]                     
    ldxdw r3, [r7+0x20]                     
    ldxdw r4, [r7+0x28]                     
    stxdw [r0+0x1b], r4                     
    stxdw [r0+0x13], r3                     
    stxdw [r0+0xb], r2                      
    stxdw [r0+0x3], r1                      
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    stxb [r0+0x2], r1                       
    mov64 r9, 35                                    r9 = 35 as i32 as i64 as u64
    ja lbb_31931                                    if true { pc += -19 }
lbb_31950:
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    ja lbb_31966                                    if true { pc += 14 }
lbb_31952:
    ldxb r1, [r7+0x8]                       
    stxb [r0+0x1], r1                       
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    stxb [r0+0x0], r1                       
    ldxdw r2, [r7+0x21]                     
    stxdw [r0+0x1a], r2                     
    ldxdw r2, [r7+0x19]                     
    stxdw [r0+0x12], r2                     
    ldxdw r2, [r7+0x11]                     
    stxdw [r0+0xa], r2                      
    ldxdw r2, [r7+0x9]                      
    stxdw [r0+0x2], r2                      
    ldxw r2, [r7+0x2c]                      
    jne r2, 0, lbb_31801                            if r2 != (0 as i32 as i64 as u64) { pc += -165 }
lbb_31966:
    stxb [r0+0x22], r1                      
    mov64 r9, 35                                    r9 = 35 as i32 as i64 as u64
    ja lbb_31931                                    if true { pc += -38 }
lbb_31969:
    mov64 r1, r10                                   r1 = r10
    add64 r1, -24                                   r1 += -24   ///  r1 = r1.wrapping_add(-24 as i32 as i64 as u64)
    mov64 r2, 1                                     r2 = 1 as i32 as i64 as u64
    mov64 r3, r7                                    r3 = r7
    call function_31701                     
    ldxdw r0, [r10-0x18]                    
    ldxdw r9, [r10-0x8]                     
    ja lbb_31846                                    if true { pc += -131 }

function_31977:
    mov64 r8, r4                                    r8 = r4
    mov64 r9, r3                                    r9 = r3
    mov64 r7, r2                                    r7 = r2
    mov64 r6, r1                                    r6 = r1
    ldxdw r1, [r7+0x0]                      
    lddw r2, 0x93a165d7e1f6dd06                     r2 load str located at -7808848301000303354
    jne r1, r2, lbb_32057                           if r1 != r2 { pc += 72 }
    ldxdw r1, [r7+0x8]                      
    lddw r2, 0xac79ebce46e1cbd9                     r2 load str located at -6018520155818964007
    jne r1, r2, lbb_32057                           if r1 != r2 { pc += 68 }
    ldxdw r1, [r7+0x10]                     
    lddw r2, 0x91375b5fed85b41c                     r2 load str located at -7982811346925931492
    jne r1, r2, lbb_32057                           if r1 != r2 { pc += 64 }
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    ldxdw r2, [r7+0x18]                     
    lddw r3, 0xa900ff7e85f58c3a                     r3 load str located at -6268729762421306310
    jne r2, r3, lbb_32057                           if r2 != r3 { pc += 59 }
lbb_31998:
    jne r1, 0, lbb_32059                            if r1 != (0 as i32 as i64 as u64) { pc += 60 }
    ldxdw r1, [r5+0x18]                     
    stxdw [r10-0x30], r1                    
    ldxdw r1, [r5+0x10]                     
    stxdw [r10-0x38], r1                    
    ldxdw r1, [r5+0x8]                      
    stxdw [r10-0x40], r1                    
    ldxdw r1, [r5+0x0]                      
    stxdw [r10-0x48], r1                    
    mov64 r1, 18                                    r1 = 18 as i32 as i64 as u64
    stxw [r10-0x50], r1                     
    mov64 r1, r10                                   r1 = r10
    add64 r1, -104                                  r1 += -104   ///  r1 = r1.wrapping_add(-104 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -80                                   r2 += -80   ///  r2 = r2.wrapping_add(-80 as i32 as i64 as u64)
    call function_31749                     
    mov64 r1, 68                                    r1 = 68 as i32 as i64 as u64
    mov64 r2, 1                                     r2 = 1 as i32 as i64 as u64
    call function_21359                     
    jeq r0, 0, lbb_32064                            if r0 == (0 as i32 as i64 as u64) { pc += 46 }
    ldxdw r1, [r9+0x18]                     
    stxdw [r0+0x18], r1                     
    ldxdw r1, [r9+0x10]                     
    stxdw [r0+0x10], r1                     
    ldxdw r1, [r9+0x8]                      
    stxdw [r0+0x8], r1                      
    ldxdw r1, [r9+0x0]                      
    stxdw [r0+0x0], r1                      
    mov64 r1, 256                                   r1 = 256 as i32 as i64 as u64
    stxh [r0+0x20], r1                      
    ldxdw r1, [r8+0x0]                      
    stxdw [r0+0x22], r1                     
    ldxdw r1, [r8+0x8]                      
    stxdw [r0+0x2a], r1                     
    ldxdw r1, [r8+0x10]                     
    stxdw [r0+0x32], r1                     
    ldxdw r1, [r8+0x18]                     
    stxdw [r0+0x3a], r1                     
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    stxh [r0+0x42], r1                      
    ldxdw r1, [r7+0x18]                     
    stxdw [r6+0x48], r1                     
    ldxdw r1, [r7+0x10]                     
    stxdw [r6+0x40], r1                     
    ldxdw r1, [r7+0x8]                      
    stxdw [r6+0x38], r1                     
    ldxdw r1, [r7+0x0]                      
    stxdw [r6+0x30], r1                     
    ldxdw r1, [r10-0x68]                    
    stxdw [r6+0x18], r1                     
    ldxdw r1, [r10-0x60]                    
    stxdw [r6+0x20], r1                     
    ldxdw r1, [r10-0x58]                    
    stxdw [r6+0x28], r1                     
    mov64 r1, 2                                     r1 = 2 as i32 as i64 as u64
    stxdw [r6+0x10], r1                     
    stxdw [r6+0x8], r1                      
    stxdw [r6+0x0], r0                      
    ja lbb_32063                                    if true { pc += 6 }
lbb_32057:
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    ja lbb_31998                                    if true { pc += -61 }
lbb_32059:
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    stxdw [r6+0x0], r1                      
    mov64 r1, 6                                     r1 = 6 as i32 as i64 as u64
    stxw [r6+0x8], r1                       
lbb_32063:
    exit                                    
lbb_32064:
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    mov64 r2, 68                                    r2 = 68 as i32 as i64 as u64
    call function_43400                     
    syscall [invalid]                       

function_32068:
    mov64 r9, r1                                    r9 = r1
    ldxdw r1, [r2+0x0]                      
    lddw r0, 0x93a165d7e1f6dd06                     r0 load str located at -7808848301000303354
    jeq r1, r0, lbb_32075                           if r1 == r0 { pc += 2 }
lbb_32073:
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    ja lbb_32088                                    if true { pc += 13 }
lbb_32075:
    ldxdw r1, [r2+0x8]                      
    lddw r0, 0xac79ebce46e1cbd9                     r0 load str located at -6018520155818964007
    jne r1, r0, lbb_32073                           if r1 != r0 { pc += -6 }
    ldxdw r1, [r2+0x10]                     
    lddw r0, 0x91375b5fed85b41c                     r0 load str located at -7982811346925931492
    jne r1, r0, lbb_32073                           if r1 != r0 { pc += -10 }
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    ldxdw r0, [r2+0x18]                     
    lddw r6, 0xa900ff7e85f58c3a                     r6 load str located at -6268729762421306310
    jne r0, r6, lbb_32073                           if r0 != r6 { pc += -15 }
lbb_32088:
    jne r1, 0, lbb_32114                            if r1 != (0 as i32 as i64 as u64) { pc += 25 }
    stxdw [r10-0xa0], r3                    
    stxdw [r10-0x98], r4                    
    stxdw [r10-0x88], r2                    
    ldxdw r1, [r5-0xfe8]                    
    ldxdw r8, [r5-0xff0]                    
    ldxdw r7, [r5-0xff8]                    
    ldxdw r2, [r5-0x1000]                   
    stxdw [r10-0x90], r2                    
    mov64 r2, 3                                     r2 = 3 as i32 as i64 as u64
    stxw [r10-0x50], r2                     
    stxdw [r10-0x48], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -128                                  r1 += -128   ///  r1 = r1.wrapping_add(-128 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -80                                   r2 += -80   ///  r2 = r2.wrapping_add(-80 as i32 as i64 as u64)
    call function_31749                     
    mov64 r6, r8                                    r6 = r8
    add64 r6, 3                                     r6 += 3   ///  r6 = r6.wrapping_add(3 as i32 as i64 as u64)
    jeq r6, 0, lbb_32136                            if r6 == (0 as i32 as i64 as u64) { pc += 28 }
    stxdw [r10-0xa8], r9                    
    lddw r1, 0x3c3c3c3c3c3c3c4                      r1 load str located at 271275648142787524
    jgt r1, r6, lbb_32119                           if r1 > r6 { pc += 7 }
    call function_43383                     
    syscall [invalid]                       
lbb_32114:
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    stxdw [r9+0x0], r1                      
    mov64 r1, 6                                     r1 = 6 as i32 as i64 as u64
    stxw [r9+0x8], r1                       
    ja lbb_32280                                    if true { pc += 161 }
lbb_32119:
    mov64 r9, r6                                    r9 = r6
    mul64 r9, 34                                    r9 *= 34   ///  r9 = r9.wrapping_mul(34 as u64)
    mov64 r0, 1                                     r0 = 1 as i32 as i64 as u64
    jeq r9, 0, lbb_32131                            if r9 == (0 as i32 as i64 as u64) { pc += 8 }
    mov64 r1, r9                                    r1 = r9
    mov64 r2, 1                                     r2 = 1 as i32 as i64 as u64
    call function_21359                     
    jne r0, 0, lbb_32131                            if r0 != (0 as i32 as i64 as u64) { pc += 4 }
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    mov64 r2, r9                                    r2 = r9
    call function_43400                     
    syscall [invalid]                       
lbb_32131:
    stxdw [r10-0x60], r6                    
    stxdw [r10-0x68], r0                    
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
    ldxdw r9, [r10-0xa8]                    
    ja lbb_32147                                    if true { pc += 11 }
lbb_32136:
    stxdw [r10-0x60], r6                    
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    stxdw [r10-0x68], r1                    
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    stxdw [r10-0x58], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -104                                  r1 += -104   ///  r1 = r1.wrapping_add(-104 as i32 as i64 as u64)
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
    call function_31650                     
    ldxdw r0, [r10-0x68]                    
    ldxdw r2, [r10-0x58]                    
lbb_32147:
    mov64 r1, r2                                    r1 = r2
    mul64 r1, 34                                    r1 *= 34   ///  r1 = r1.wrapping_mul(34 as u64)
    add64 r0, r1                                    r0 += r1   ///  r0 = r0.wrapping_add(r1)
    ldxdw r3, [r10-0xa0]                    
    ldxdw r1, [r3+0x18]                     
    stxdw [r0+0x18], r1                     
    ldxdw r1, [r3+0x10]                     
    stxdw [r0+0x10], r1                     
    ldxdw r1, [r3+0x8]                      
    stxdw [r0+0x8], r1                      
    ldxdw r1, [r3+0x0]                      
    stxdw [r0+0x0], r1                      
    mov64 r6, 256                                   r6 = 256 as i32 as i64 as u64
    stxh [r0+0x20], r6                      
    add64 r2, 1                                     r2 += 1   ///  r2 = r2.wrapping_add(1 as i32 as i64 as u64)
    stxdw [r10-0x58], r2                    
    ldxdw r3, [r10-0x60]                    
    jne r2, r3, lbb_32170                           if r2 != r3 { pc += 5 }
    mov64 r1, r10                                   r1 = r10
    add64 r1, -104                                  r1 += -104   ///  r1 = r1.wrapping_add(-104 as i32 as i64 as u64)
    call function_31650                     
    ldxdw r3, [r10-0x60]                    
    ldxdw r2, [r10-0x58]                    
lbb_32170:
    mov64 r4, r2                                    r4 = r2
    mul64 r4, 34                                    r4 *= 34   ///  r4 = r4.wrapping_mul(34 as u64)
    ldxdw r1, [r10-0x68]                    
    mov64 r5, r1                                    r5 = r1
    add64 r5, r4                                    r5 += r4   ///  r5 = r5.wrapping_add(r4)
    ldxdw r0, [r10-0x98]                    
    ldxdw r4, [r0+0x18]                     
    stxdw [r5+0x18], r4                     
    ldxdw r4, [r0+0x10]                     
    stxdw [r5+0x10], r4                     
    ldxdw r4, [r0+0x8]                      
    stxdw [r5+0x8], r4                      
    ldxdw r4, [r0+0x0]                      
    stxdw [r5+0x0], r4                      
    stxh [r5+0x20], r6                      
    mov64 r6, 1                                     r6 = 1 as i32 as i64 as u64
    jeq r8, 0, lbb_32188                            if r8 == (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r6, 0                                     r6 = 0 as i32 as i64 as u64
lbb_32188:
    add64 r2, 1                                     r2 += 1   ///  r2 = r2.wrapping_add(1 as i32 as i64 as u64)
    stxdw [r10-0x58], r2                    
    jne r2, r3, lbb_32197                           if r2 != r3 { pc += 6 }
    mov64 r1, r10                                   r1 = r10
    add64 r1, -104                                  r1 += -104   ///  r1 = r1.wrapping_add(-104 as i32 as i64 as u64)
    mov64 r2, r3                                    r2 = r3
    call function_31650                     
    ldxdw r1, [r10-0x68]                    
    ldxdw r2, [r10-0x58]                    
lbb_32197:
    mov64 r3, r2                                    r3 = r2
    mul64 r3, 34                                    r3 *= 34   ///  r3 = r3.wrapping_mul(34 as u64)
    mov64 r4, r1                                    r4 = r1
    add64 r4, r3                                    r4 += r3   ///  r4 = r4.wrapping_add(r3)
    ldxdw r5, [r10-0x90]                    
    ldxdw r3, [r5+0x18]                     
    stxdw [r4+0x18], r3                     
    ldxdw r3, [r5+0x10]                     
    stxdw [r4+0x10], r3                     
    ldxdw r3, [r5+0x8]                      
    stxdw [r4+0x8], r3                      
    ldxdw r3, [r5+0x0]                      
    stxdw [r4+0x0], r3                      
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
    stxb [r4+0x21], r3                      
    stxb [r4+0x20], r6                      
    add64 r2, 1                                     r2 += 1   ///  r2 = r2.wrapping_add(1 as i32 as i64 as u64)
    stxdw [r10-0x58], r2                    
    jeq r8, 0, lbb_32254                            if r8 == (0 as i32 as i64 as u64) { pc += 38 }
    lsh64 r8, 3                                     r8 <<= 3   ///  r8 = r8.wrapping_shl(3)
    mov64 r6, 1                                     r6 = 1 as i32 as i64 as u64
    ja lbb_32237                                    if true { pc += 18 }
lbb_32219:
    add64 r7, 8                                     r7 += 8   ///  r7 = r7.wrapping_add(8 as i32 as i64 as u64)
    mov64 r3, r2                                    r3 = r2
    mul64 r3, 34                                    r3 *= 34   ///  r3 = r3.wrapping_mul(34 as u64)
    mov64 r4, r1                                    r4 = r1
    add64 r4, r3                                    r4 += r3   ///  r4 = r4.wrapping_add(r3)
    ldxdw r3, [r10-0x38]                    
    stxdw [r4+0x18], r3                     
    ldxdw r3, [r10-0x40]                    
    stxdw [r4+0x10], r3                     
    ldxdw r3, [r10-0x48]                    
    stxdw [r4+0x8], r3                      
    ldxdw r3, [r10-0x50]                    
    stxdw [r4+0x0], r3                      
    stxh [r4+0x20], r6                      
    add64 r2, 1                                     r2 += 1   ///  r2 = r2.wrapping_add(1 as i32 as i64 as u64)
    stxdw [r10-0x58], r2                    
    add64 r8, -8                                    r8 += -8   ///  r8 = r8.wrapping_add(-8 as i32 as i64 as u64)
    jeq r8, 0, lbb_32254                            if r8 == (0 as i32 as i64 as u64) { pc += 17 }
lbb_32237:
    ldxdw r3, [r7+0x0]                      
    ldxdw r4, [r3+0x18]                     
    stxdw [r10-0x38], r4                    
    ldxdw r4, [r3+0x10]                     
    stxdw [r10-0x40], r4                    
    ldxdw r4, [r3+0x8]                      
    stxdw [r10-0x48], r4                    
    ldxdw r3, [r3+0x0]                      
    stxdw [r10-0x50], r3                    
    ldxdw r3, [r10-0x60]                    
    jne r2, r3, lbb_32219                           if r2 != r3 { pc += -29 }
    mov64 r1, r10                                   r1 = r10
    add64 r1, -104                                  r1 += -104   ///  r1 = r1.wrapping_add(-104 as i32 as i64 as u64)
    call function_31650                     
    ldxdw r1, [r10-0x68]                    
    ldxdw r2, [r10-0x58]                    
    ja lbb_32219                                    if true { pc += -35 }
lbb_32254:
    ldxdw r1, [r10-0x58]                    
    stxdw [r10-0x40], r1                    
    ldxdw r1, [r10-0x60]                    
    stxdw [r10-0x48], r1                    
    ldxdw r1, [r10-0x68]                    
    stxdw [r10-0x50], r1                    
    ldxdw r4, [r10-0x88]                    
    ldxdw r1, [r4+0x18]                     
    ldxdw r2, [r4+0x10]                     
    ldxdw r3, [r4+0x8]                      
    ldxdw r4, [r4+0x0]                      
    ldxdw r5, [r10-0x80]                    
    stxdw [r10-0x38], r5                    
    ldxdw r5, [r10-0x78]                    
    stxdw [r10-0x30], r5                    
    ldxdw r5, [r10-0x70]                    
    stxdw [r10-0x28], r5                    
    stxdw [r10-0x20], r4                    
    stxdw [r10-0x18], r3                    
    stxdw [r10-0x10], r2                    
    stxdw [r10-0x8], r1                     
    mov64 r2, r10                                   r2 = r10
    add64 r2, -80                                   r2 += -80   ///  r2 = r2.wrapping_add(-80 as i32 as i64 as u64)
    mov64 r1, r9                                    r1 = r9
    mov64 r3, 80                                    r3 = 80 as i32 as i64 as u64
    call function_48190                     
lbb_32280:
    exit                                    

function_32281:
    mov64 r9, r1                                    r9 = r1
    ldxdw r1, [r2+0x0]                      
    lddw r0, 0x93a165d7e1f6dd06                     r0 load str located at -7808848301000303354
    jeq r1, r0, lbb_32288                           if r1 == r0 { pc += 2 }
lbb_32286:
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    ja lbb_32301                                    if true { pc += 13 }
lbb_32288:
    ldxdw r1, [r2+0x8]                      
    lddw r0, 0xac79ebce46e1cbd9                     r0 load str located at -6018520155818964007
    jne r1, r0, lbb_32286                           if r1 != r0 { pc += -6 }
    ldxdw r1, [r2+0x10]                     
    lddw r0, 0x91375b5fed85b41c                     r0 load str located at -7982811346925931492
    jne r1, r0, lbb_32286                           if r1 != r0 { pc += -10 }
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    ldxdw r0, [r2+0x18]                     
    lddw r6, 0xa900ff7e85f58c3a                     r6 load str located at -6268729762421306310
    jne r0, r6, lbb_32286                           if r0 != r6 { pc += -15 }
lbb_32301:
    jne r1, 0, lbb_32323                            if r1 != (0 as i32 as i64 as u64) { pc += 21 }
    stxdw [r10-0xa0], r3                    
    stxdw [r10-0x98], r4                    
    stxdw [r10-0x88], r2                    
    ldxdw r7, [r5-0xff0]                    
    ldxdw r8, [r5-0xff8]                    
    ldxdw r1, [r5-0x1000]                   
    stxdw [r10-0x90], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -128                                  r1 += -128   ///  r1 = r1.wrapping_add(-128 as i32 as i64 as u64)
    lddw r2, 0x100062ba8 --> b"\x09\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\…        r2 load str located at 4295371688
    call function_31749                     
    mov64 r6, r7                                    r6 = r7
    add64 r6, 3                                     r6 += 3   ///  r6 = r6.wrapping_add(3 as i32 as i64 as u64)
    jeq r6, 0, lbb_32345                            if r6 == (0 as i32 as i64 as u64) { pc += 28 }
    stxdw [r10-0xa8], r9                    
    lddw r1, 0x3c3c3c3c3c3c3c4                      r1 load str located at 271275648142787524
    jgt r1, r6, lbb_32328                           if r1 > r6 { pc += 7 }
    call function_43383                     
    syscall [invalid]                       
lbb_32323:
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    stxdw [r9+0x0], r1                      
    mov64 r1, 6                                     r1 = 6 as i32 as i64 as u64
    stxw [r9+0x8], r1                       
    ja lbb_32489                                    if true { pc += 161 }
lbb_32328:
    mov64 r9, r6                                    r9 = r6
    mul64 r9, 34                                    r9 *= 34   ///  r9 = r9.wrapping_mul(34 as u64)
    mov64 r0, 1                                     r0 = 1 as i32 as i64 as u64
    jeq r9, 0, lbb_32340                            if r9 == (0 as i32 as i64 as u64) { pc += 8 }
    mov64 r1, r9                                    r1 = r9
    mov64 r2, 1                                     r2 = 1 as i32 as i64 as u64
    call function_21359                     
    jne r0, 0, lbb_32340                            if r0 != (0 as i32 as i64 as u64) { pc += 4 }
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    mov64 r2, r9                                    r2 = r9
    call function_43400                     
    syscall [invalid]                       
lbb_32340:
    stxdw [r10-0x60], r6                    
    stxdw [r10-0x68], r0                    
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
    ldxdw r9, [r10-0xa8]                    
    ja lbb_32356                                    if true { pc += 11 }
lbb_32345:
    stxdw [r10-0x60], r6                    
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    stxdw [r10-0x68], r1                    
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    stxdw [r10-0x58], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -104                                  r1 += -104   ///  r1 = r1.wrapping_add(-104 as i32 as i64 as u64)
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
    call function_31650                     
    ldxdw r0, [r10-0x68]                    
    ldxdw r2, [r10-0x58]                    
lbb_32356:
    mov64 r1, r2                                    r1 = r2
    mul64 r1, 34                                    r1 *= 34   ///  r1 = r1.wrapping_mul(34 as u64)
    add64 r0, r1                                    r0 += r1   ///  r0 = r0.wrapping_add(r1)
    ldxdw r3, [r10-0xa0]                    
    ldxdw r1, [r3+0x18]                     
    stxdw [r0+0x18], r1                     
    ldxdw r1, [r3+0x10]                     
    stxdw [r0+0x10], r1                     
    ldxdw r1, [r3+0x8]                      
    stxdw [r0+0x8], r1                      
    ldxdw r1, [r3+0x0]                      
    stxdw [r0+0x0], r1                      
    mov64 r6, 256                                   r6 = 256 as i32 as i64 as u64
    stxh [r0+0x20], r6                      
    add64 r2, 1                                     r2 += 1   ///  r2 = r2.wrapping_add(1 as i32 as i64 as u64)
    stxdw [r10-0x58], r2                    
    ldxdw r3, [r10-0x60]                    
    jne r2, r3, lbb_32379                           if r2 != r3 { pc += 5 }
    mov64 r1, r10                                   r1 = r10
    add64 r1, -104                                  r1 += -104   ///  r1 = r1.wrapping_add(-104 as i32 as i64 as u64)
    call function_31650                     
    ldxdw r3, [r10-0x60]                    
    ldxdw r2, [r10-0x58]                    
lbb_32379:
    mov64 r4, r2                                    r4 = r2
    mul64 r4, 34                                    r4 *= 34   ///  r4 = r4.wrapping_mul(34 as u64)
    ldxdw r1, [r10-0x68]                    
    mov64 r5, r1                                    r5 = r1
    add64 r5, r4                                    r5 += r4   ///  r5 = r5.wrapping_add(r4)
    ldxdw r0, [r10-0x98]                    
    ldxdw r4, [r0+0x18]                     
    stxdw [r5+0x18], r4                     
    ldxdw r4, [r0+0x10]                     
    stxdw [r5+0x10], r4                     
    ldxdw r4, [r0+0x8]                      
    stxdw [r5+0x8], r4                      
    ldxdw r4, [r0+0x0]                      
    stxdw [r5+0x0], r4                      
    stxh [r5+0x20], r6                      
    mov64 r6, 1                                     r6 = 1 as i32 as i64 as u64
    jeq r7, 0, lbb_32397                            if r7 == (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r6, 0                                     r6 = 0 as i32 as i64 as u64
lbb_32397:
    add64 r2, 1                                     r2 += 1   ///  r2 = r2.wrapping_add(1 as i32 as i64 as u64)
    stxdw [r10-0x58], r2                    
    jne r2, r3, lbb_32406                           if r2 != r3 { pc += 6 }
    mov64 r1, r10                                   r1 = r10
    add64 r1, -104                                  r1 += -104   ///  r1 = r1.wrapping_add(-104 as i32 as i64 as u64)
    mov64 r2, r3                                    r2 = r3
    call function_31650                     
    ldxdw r1, [r10-0x68]                    
    ldxdw r2, [r10-0x58]                    
lbb_32406:
    mov64 r3, r2                                    r3 = r2
    mul64 r3, 34                                    r3 *= 34   ///  r3 = r3.wrapping_mul(34 as u64)
    mov64 r4, r1                                    r4 = r1
    add64 r4, r3                                    r4 += r3   ///  r4 = r4.wrapping_add(r3)
    ldxdw r5, [r10-0x90]                    
    ldxdw r3, [r5+0x18]                     
    stxdw [r4+0x18], r3                     
    ldxdw r3, [r5+0x10]                     
    stxdw [r4+0x10], r3                     
    ldxdw r3, [r5+0x8]                      
    stxdw [r4+0x8], r3                      
    ldxdw r3, [r5+0x0]                      
    stxdw [r4+0x0], r3                      
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
    stxb [r4+0x21], r3                      
    stxb [r4+0x20], r6                      
    add64 r2, 1                                     r2 += 1   ///  r2 = r2.wrapping_add(1 as i32 as i64 as u64)
    stxdw [r10-0x58], r2                    
    jeq r7, 0, lbb_32463                            if r7 == (0 as i32 as i64 as u64) { pc += 38 }
    lsh64 r7, 3                                     r7 <<= 3   ///  r7 = r7.wrapping_shl(3)
    mov64 r6, 1                                     r6 = 1 as i32 as i64 as u64
    ja lbb_32446                                    if true { pc += 18 }
lbb_32428:
    add64 r8, 8                                     r8 += 8   ///  r8 = r8.wrapping_add(8 as i32 as i64 as u64)
    mov64 r3, r2                                    r3 = r2
    mul64 r3, 34                                    r3 *= 34   ///  r3 = r3.wrapping_mul(34 as u64)
    mov64 r4, r1                                    r4 = r1
    add64 r4, r3                                    r4 += r3   ///  r4 = r4.wrapping_add(r3)
    ldxdw r3, [r10-0x38]                    
    stxdw [r4+0x18], r3                     
    ldxdw r3, [r10-0x40]                    
    stxdw [r4+0x10], r3                     
    ldxdw r3, [r10-0x48]                    
    stxdw [r4+0x8], r3                      
    ldxdw r3, [r10-0x50]                    
    stxdw [r4+0x0], r3                      
    stxh [r4+0x20], r6                      
    add64 r2, 1                                     r2 += 1   ///  r2 = r2.wrapping_add(1 as i32 as i64 as u64)
    stxdw [r10-0x58], r2                    
    add64 r7, -8                                    r7 += -8   ///  r7 = r7.wrapping_add(-8 as i32 as i64 as u64)
    jeq r7, 0, lbb_32463                            if r7 == (0 as i32 as i64 as u64) { pc += 17 }
lbb_32446:
    ldxdw r3, [r8+0x0]                      
    ldxdw r4, [r3+0x18]                     
    stxdw [r10-0x38], r4                    
    ldxdw r4, [r3+0x10]                     
    stxdw [r10-0x40], r4                    
    ldxdw r4, [r3+0x8]                      
    stxdw [r10-0x48], r4                    
    ldxdw r3, [r3+0x0]                      
    stxdw [r10-0x50], r3                    
    ldxdw r3, [r10-0x60]                    
    jne r2, r3, lbb_32428                           if r2 != r3 { pc += -29 }
    mov64 r1, r10                                   r1 = r10
    add64 r1, -104                                  r1 += -104   ///  r1 = r1.wrapping_add(-104 as i32 as i64 as u64)
    call function_31650                     
    ldxdw r1, [r10-0x68]                    
    ldxdw r2, [r10-0x58]                    
    ja lbb_32428                                    if true { pc += -35 }
lbb_32463:
    ldxdw r1, [r10-0x58]                    
    stxdw [r10-0x40], r1                    
    ldxdw r1, [r10-0x60]                    
    stxdw [r10-0x48], r1                    
    ldxdw r1, [r10-0x68]                    
    stxdw [r10-0x50], r1                    
    ldxdw r4, [r10-0x88]                    
    ldxdw r1, [r4+0x18]                     
    ldxdw r2, [r4+0x10]                     
    ldxdw r3, [r4+0x8]                      
    ldxdw r4, [r4+0x0]                      
    ldxdw r5, [r10-0x80]                    
    stxdw [r10-0x38], r5                    
    ldxdw r5, [r10-0x78]                    
    stxdw [r10-0x30], r5                    
    ldxdw r5, [r10-0x70]                    
    stxdw [r10-0x28], r5                    
    stxdw [r10-0x20], r4                    
    stxdw [r10-0x18], r3                    
    stxdw [r10-0x10], r2                    
    stxdw [r10-0x8], r1                     
    mov64 r2, r10                                   r2 = r10
    add64 r2, -80                                   r2 += -80   ///  r2 = r2.wrapping_add(-80 as i32 as i64 as u64)
    mov64 r1, r9                                    r1 = r9
    mov64 r3, 80                                    r3 = 80 as i32 as i64 as u64
    call function_48190                     
lbb_32489:
    exit                                    

function_32490:
    jgt r3, 81, lbb_32497                           if r3 > (81 as i32 as i64 as u64) { pc += 6 }
    mov64 r1, 82                                    r1 = 82 as i32 as i64 as u64
    mov64 r2, r3                                    r2 = r3
    lddw r3, 0x100066858 --> b"\x00\x00\x00\x00\xf8+\x06\x00\x0c\x00\x00\x00\x00\x00\x00\x00'\x00\x00\x0…        r3 load str located at 4295387224
    call function_46535                     
    syscall [invalid]                       
lbb_32497:
    ldxb r3, [r2+0x0]                       
    jeq r3, 1, lbb_32508                            if r3 == (1 as i32 as i64 as u64) { pc += 9 }
    jne r3, 0, lbb_32537                            if r3 != (0 as i32 as i64 as u64) { pc += 37 }
    ldxb r3, [r2+0x1]                       
    jne r3, 0, lbb_32537                            if r3 != (0 as i32 as i64 as u64) { pc += 35 }
    ldxb r3, [r2+0x2]                       
    jne r3, 0, lbb_32537                            if r3 != (0 as i32 as i64 as u64) { pc += 33 }
    mov64 r5, 0                                     r5 = 0 as i32 as i64 as u64
    ldxb r3, [r2+0x3]                       
    jeq r3, 0, lbb_32531                            if r3 == (0 as i32 as i64 as u64) { pc += 24 }
    ja lbb_32537                                    if true { pc += 29 }
lbb_32508:
    ldxb r3, [r2+0x1]                       
    jne r3, 0, lbb_32537                            if r3 != (0 as i32 as i64 as u64) { pc += 27 }
    ldxb r3, [r2+0x2]                       
    jne r3, 0, lbb_32537                            if r3 != (0 as i32 as i64 as u64) { pc += 25 }
    ldxb r3, [r2+0x3]                       
    jne r3, 0, lbb_32537                            if r3 != (0 as i32 as i64 as u64) { pc += 23 }
    mov64 r5, 1                                     r5 = 1 as i32 as i64 as u64
    ldxw r3, [r2+0x20]                      
    stxdw [r10-0x8], r3                     
    ldxw r3, [r2+0x1c]                      
    stxdw [r10-0x10], r3                    
    ldxw r3, [r2+0x18]                      
    stxdw [r10-0x18], r3                    
    ldxw r3, [r2+0x14]                      
    stxdw [r10-0x20], r3                    
    ldxw r3, [r2+0x10]                      
    stxdw [r10-0x28], r3                    
    ldxw r3, [r2+0xc]                       
    stxdw [r10-0x30], r3                    
    ldxw r3, [r2+0x8]                       
    stxdw [r10-0x38], r3                    
    ldxw r3, [r2+0x4]                       
    stxdw [r10-0x40], r3                    
lbb_32531:
    mov64 r6, 0                                     r6 = 0 as i32 as i64 as u64
    ldxb r0, [r2+0x2c]                      
    ldxdw r4, [r2+0x24]                     
    ldxb r3, [r2+0x2d]                      
    jeq r3, 0, lbb_32543                            if r3 == (0 as i32 as i64 as u64) { pc += 7 }
    jeq r3, 1, lbb_32542                            if r3 == (1 as i32 as i64 as u64) { pc += 5 }
lbb_32537:
    mov64 r2, 2                                     r2 = 2 as i32 as i64 as u64
    stxw [r1+0x0], r2                       
    mov64 r2, 3                                     r2 = 3 as i32 as i64 as u64
    stxw [r1+0x8], r2                       
lbb_32541:
    exit                                    
lbb_32542:
    mov64 r6, 1                                     r6 = 1 as i32 as i64 as u64
lbb_32543:
    ldxb r3, [r2+0x2e]                      
    jeq r3, 1, lbb_32555                            if r3 == (1 as i32 as i64 as u64) { pc += 10 }
    jne r3, 0, lbb_32537                            if r3 != (0 as i32 as i64 as u64) { pc += -9 }
    ldxb r3, [r2+0x2f]                      
    jne r3, 0, lbb_32537                            if r3 != (0 as i32 as i64 as u64) { pc += -11 }
    ldxb r3, [r2+0x30]                      
    jne r3, 0, lbb_32537                            if r3 != (0 as i32 as i64 as u64) { pc += -13 }
    mov64 r8, 0                                     r8 = 0 as i32 as i64 as u64
    ldxb r2, [r2+0x31]                      
    mov64 r7, r2                                    r7 = r2
    jeq r7, 0, lbb_32575                            if r7 == (0 as i32 as i64 as u64) { pc += 21 }
    ja lbb_32537                                    if true { pc += -18 }
lbb_32555:
    ldxb r3, [r2+0x2f]                      
    jne r3, 0, lbb_32537                            if r3 != (0 as i32 as i64 as u64) { pc += -20 }
    ldxb r3, [r2+0x30]                      
    jne r3, 0, lbb_32537                            if r3 != (0 as i32 as i64 as u64) { pc += -22 }
    ldxb r3, [r2+0x31]                      
    jne r3, 0, lbb_32537                            if r3 != (0 as i32 as i64 as u64) { pc += -24 }
    mov64 r8, 1                                     r8 = 1 as i32 as i64 as u64
    ldxw r3, [r2+0x4e]                      
    stxdw [r10-0x48], r3                    
    ldxw r9, [r2+0x4a]                      
    ldxw r3, [r2+0x46]                      
    stxdw [r10-0x50], r3                    
    ldxw r3, [r2+0x42]                      
    stxdw [r10-0x58], r3                    
    ldxw r3, [r2+0x3e]                      
    stxdw [r10-0x60], r3                    
    ldxw r3, [r2+0x3a]                      
    stxdw [r10-0x68], r3                    
    ldxw r3, [r2+0x36]                      
    ldxw r2, [r2+0x32]                      
lbb_32575:
    stxw [r1+0x38], r2                      
    ldxdw r2, [r10-0x40]                    
    stxw [r1+0x4], r2                       
    stxw [r1+0x34], r8                      
    stxb [r1+0x31], r6                      
    stxb [r1+0x30], r0                      
    stxdw [r1+0x28], r4                     
    stxw [r1+0x0], r5                       
    stxw [r1+0x3c], r3                      
    ldxdw r2, [r10-0x38]                    
    stxw [r1+0x8], r2                       
    ldxdw r2, [r10-0x68]                    
    stxw [r1+0x40], r2                      
    ldxdw r2, [r10-0x30]                    
    stxw [r1+0xc], r2                       
    ldxdw r2, [r10-0x60]                    
    stxw [r1+0x44], r2                      
    ldxdw r2, [r10-0x28]                    
    stxw [r1+0x10], r2                      
    ldxdw r2, [r10-0x58]                    
    stxw [r1+0x48], r2                      
    ldxdw r2, [r10-0x20]                    
    stxw [r1+0x14], r2                      
    ldxdw r2, [r10-0x50]                    
    stxw [r1+0x4c], r2                      
    ldxdw r2, [r10-0x18]                    
    stxw [r1+0x18], r2                      
    stxw [r1+0x50], r9                      
    ldxdw r2, [r10-0x10]                    
    stxw [r1+0x1c], r2                      
    ldxdw r2, [r10-0x48]                    
    stxw [r1+0x54], r2                      
    ldxdw r2, [r10-0x8]                     
    stxw [r1+0x20], r2                      
    ja lbb_32541                                    if true { pc += -69 }

function_32610:
    jgt r3, 164, lbb_32617                          if r3 > (164 as i32 as i64 as u64) { pc += 6 }
    mov64 r1, 165                                   r1 = 165 as i32 as i64 as u64
    mov64 r2, r3                                    r2 = r3
    lddw r3, 0x100066870 --> b"\x00\x00\x00\x00\xf8+\x06\x00\x0c\x00\x00\x00\x00\x00\x00\x00\x83\x00\x00…        r3 load str located at 4295387248
    call function_46535                     
    syscall [invalid]                       
lbb_32617:
    ldxb r5, [r2+0x3f]                      
    ldxb r3, [r2+0x3e]                      
    stxdw [r10-0x8], r3                     
    ldxb r3, [r2+0x3d]                      
    stxdw [r10-0x10], r3                    
    ldxb r3, [r2+0x3c]                      
    stxdw [r10-0x18], r3                    
    ldxb r3, [r2+0x3b]                      
    stxdw [r10-0x20], r3                    
    ldxb r3, [r2+0x3a]                      
    stxdw [r10-0x28], r3                    
    ldxb r3, [r2+0x39]                      
    stxdw [r10-0x30], r3                    
    ldxb r3, [r2+0x38]                      
    stxdw [r10-0x38], r3                    
    ldxb r3, [r2+0x37]                      
    stxdw [r10-0x40], r3                    
    ldxb r3, [r2+0x36]                      
    stxdw [r10-0x48], r3                    
    ldxb r3, [r2+0x35]                      
    stxdw [r10-0x50], r3                    
    ldxb r3, [r2+0x34]                      
    stxdw [r10-0x60], r3                    
    ldxb r3, [r2+0x33]                      
    stxdw [r10-0x70], r3                    
    ldxb r3, [r2+0x32]                      
    stxdw [r10-0x80], r3                    
    ldxb r3, [r2+0x31]                      
    stxdw [r10-0x90], r3                    
    ldxb r3, [r2+0x30]                      
    stxdw [r10-0xa0], r3                    
    ldxb r3, [r2+0x2f]                      
    stxdw [r10-0xb0], r3                    
    ldxb r3, [r2+0x2e]                      
    stxdw [r10-0xc0], r3                    
    ldxb r3, [r2+0x2d]                      
    stxdw [r10-0xd0], r3                    
    ldxb r3, [r2+0x2c]                      
    stxdw [r10-0xe0], r3                    
    ldxb r3, [r2+0x2b]                      
    stxdw [r10-0xf0], r3                    
    ldxb r3, [r2+0x2a]                      
    stxdw [r10-0x100], r3                   
    ldxb r3, [r2+0x29]                      
    stxdw [r10-0x110], r3                   
    ldxb r3, [r2+0x28]                      
    stxdw [r10-0x120], r3                   
    ldxb r3, [r2+0x27]                      
    stxdw [r10-0x130], r3                   
    ldxb r3, [r2+0x26]                      
    stxdw [r10-0x148], r3                   
    ldxb r3, [r2+0x25]                      
    stxdw [r10-0x160], r3                   
    ldxb r3, [r2+0x24]                      
    stxdw [r10-0x170], r3                   
    ldxb r3, [r2+0x23]                      
    stxdw [r10-0x188], r3                   
    ldxb r3, [r2+0x22]                      
    stxdw [r10-0x1a0], r3                   
    ldxb r3, [r2+0x21]                      
    stxdw [r10-0x1b0], r3                   
    ldxb r3, [r2+0x20]                      
    stxdw [r10-0x1d0], r3                   
    ldxb r3, [r2+0x1f]                      
    stxdw [r10-0x58], r3                    
    ldxb r3, [r2+0x1e]                      
    stxdw [r10-0x68], r3                    
    ldxb r3, [r2+0x1d]                      
    stxdw [r10-0x78], r3                    
    ldxb r3, [r2+0x1c]                      
    stxdw [r10-0x88], r3                    
    ldxb r3, [r2+0x1b]                      
    stxdw [r10-0x98], r3                    
    ldxb r3, [r2+0x1a]                      
    stxdw [r10-0xa8], r3                    
    ldxb r3, [r2+0x19]                      
    stxdw [r10-0xb8], r3                    
    ldxb r3, [r2+0x18]                      
    stxdw [r10-0xc8], r3                    
    ldxb r3, [r2+0x17]                      
    stxdw [r10-0xd8], r3                    
    ldxb r3, [r2+0x16]                      
    stxdw [r10-0xe8], r3                    
    ldxb r3, [r2+0x15]                      
    stxdw [r10-0xf8], r3                    
    ldxb r3, [r2+0x14]                      
    stxdw [r10-0x108], r3                   
    ldxb r3, [r2+0x13]                      
    stxdw [r10-0x118], r3                   
    ldxb r3, [r2+0x12]                      
    stxdw [r10-0x128], r3                   
    ldxb r3, [r2+0x11]                      
    stxdw [r10-0x138], r3                   
    ldxb r3, [r2+0x10]                      
    stxdw [r10-0x140], r3                   
    ldxb r3, [r2+0xf]                       
    stxdw [r10-0x150], r3                   
    ldxb r3, [r2+0xe]                       
    stxdw [r10-0x158], r3                   
    ldxb r3, [r2+0xd]                       
    stxdw [r10-0x168], r3                   
    ldxb r3, [r2+0xc]                       
    stxdw [r10-0x178], r3                   
    ldxb r3, [r2+0xb]                       
    stxdw [r10-0x180], r3                   
    ldxb r3, [r2+0xa]                       
    stxdw [r10-0x190], r3                   
    ldxb r3, [r2+0x9]                       
    stxdw [r10-0x198], r3                   
    ldxb r3, [r2+0x8]                       
    stxdw [r10-0x1a8], r3                   
    ldxb r3, [r2+0x7]                       
    stxdw [r10-0x1b8], r3                   
    ldxb r3, [r2+0x6]                       
    stxdw [r10-0x1c0], r3                   
    ldxb r3, [r2+0x5]                       
    stxdw [r10-0x1c8], r3                   
    ldxb r0, [r2+0x4]                       
    ldxb r6, [r2+0x3]                       
    ldxb r7, [r2+0x2]                       
    ldxb r8, [r2+0x1]                       
    ldxb r3, [r2+0x0]                       
    ldxdw r9, [r2+0x40]                     
    ldxb r4, [r2+0x48]                      
    jeq r4, 1, lbb_32772                            if r4 == (1 as i32 as i64 as u64) { pc += 30 }
    jne r4, 0, lbb_32767                            if r4 != (0 as i32 as i64 as u64) { pc += 24 }
    ldxb r4, [r2+0x49]                      
    jne r4, 0, lbb_32767                            if r4 != (0 as i32 as i64 as u64) { pc += 22 }
    ldxb r4, [r2+0x4a]                      
    jne r4, 0, lbb_32767                            if r4 != (0 as i32 as i64 as u64) { pc += 20 }
    mov64 r4, 0                                     r4 = 0 as i32 as i64 as u64
    stxdw [r10-0x1e0], r4                   
    ldxb r4, [r2+0x4b]                      
    stxdw [r10-0x1d8], r1                   
    mov64 r1, r5                                    r1 = r5
    mov64 r5, r3                                    r5 = r3
    mov64 r3, r9                                    r3 = r9
    mov64 r9, r8                                    r9 = r8
    mov64 r8, r7                                    r8 = r7
    mov64 r7, r6                                    r7 = r6
    mov64 r6, r0                                    r6 = r0
    mov64 r0, r6                                    r0 = r6
    mov64 r6, r7                                    r6 = r7
    mov64 r7, r8                                    r7 = r8
    mov64 r8, r9                                    r8 = r9
    mov64 r9, r3                                    r9 = r3
    mov64 r3, r5                                    r3 = r5
    mov64 r5, r1                                    r5 = r1
    ldxdw r1, [r10-0x1d8]                   
    jeq r4, 0, lbb_32796                            if r4 == (0 as i32 as i64 as u64) { pc += 29 }
lbb_32767:
    mov64 r2, 2                                     r2 = 2 as i32 as i64 as u64
    stxw [r1+0x88], r2                      
    mov64 r2, 3                                     r2 = 3 as i32 as i64 as u64
    stxw [r1+0x0], r2                       
lbb_32771:
    exit                                    
lbb_32772:
    ldxb r4, [r2+0x49]                      
    jne r4, 0, lbb_32767                            if r4 != (0 as i32 as i64 as u64) { pc += -7 }
    ldxb r4, [r2+0x4a]                      
    jne r4, 0, lbb_32767                            if r4 != (0 as i32 as i64 as u64) { pc += -9 }
    ldxb r4, [r2+0x4b]                      
    jne r4, 0, lbb_32767                            if r4 != (0 as i32 as i64 as u64) { pc += -11 }
    mov64 r4, 1                                     r4 = 1 as i32 as i64 as u64
    stxdw [r10-0x1e0], r4                   
    ldxw r4, [r2+0x68]                      
    stxdw [r10-0x1e8], r4                   
    ldxw r4, [r2+0x64]                      
    stxdw [r10-0x1f0], r4                   
    ldxw r4, [r2+0x60]                      
    stxdw [r10-0x1f8], r4                   
    ldxw r4, [r2+0x5c]                      
    stxdw [r10-0x200], r4                   
    ldxw r4, [r2+0x58]                      
    stxdw [r10-0x208], r4                   
    ldxw r4, [r2+0x54]                      
    stxdw [r10-0x210], r4                   
    ldxw r4, [r2+0x50]                      
    stxdw [r10-0x218], r4                   
    ldxw r4, [r2+0x4c]                      
    stxdw [r10-0x220], r4                   
lbb_32796:
    stxdw [r10-0x1d8], r5                   
    ldxb r4, [r2+0x6c]                      
    mov64 r5, 3                                     r5 = 3 as i32 as i64 as u64
    jgt r5, r4, lbb_32801                           if r5 > r4 { pc += 1 }
    ja lbb_32815                                    if true { pc += 14 }
lbb_32801:
    ldxb r5, [r2+0x6d]                      
    jeq r5, 1, lbb_32820                            if r5 == (1 as i32 as i64 as u64) { pc += 17 }
    jne r5, 0, lbb_32767                            if r5 != (0 as i32 as i64 as u64) { pc += -37 }
    ldxb r5, [r2+0x6e]                      
    jne r5, 0, lbb_32767                            if r5 != (0 as i32 as i64 as u64) { pc += -39 }
    ldxb r5, [r2+0x6f]                      
    jne r5, 0, lbb_32767                            if r5 != (0 as i32 as i64 as u64) { pc += -41 }
    mov64 r5, 0                                     r5 = 0 as i32 as i64 as u64
    stxdw [r10-0x228], r5                   
    ldxb r5, [r2+0x70]                      
    stxdw [r10-0x230], r5                   
    ldxdw r5, [r10-0x230]                   
    jeq r5, 0, lbb_32830                            if r5 == (0 as i32 as i64 as u64) { pc += 16 }
    ja lbb_32767                                    if true { pc += -48 }
lbb_32815:
    mov64 r2, 2                                     r2 = 2 as i32 as i64 as u64
    stxw [r1+0x88], r2                      
    stxb [r1+0x4], r4                       
    stxw [r1+0x0], r5                       
    ja lbb_32771                                    if true { pc += -49 }
lbb_32820:
    ldxb r5, [r2+0x6e]                      
    jne r5, 0, lbb_32767                            if r5 != (0 as i32 as i64 as u64) { pc += -55 }
    ldxb r5, [r2+0x6f]                      
    jne r5, 0, lbb_32767                            if r5 != (0 as i32 as i64 as u64) { pc += -57 }
    ldxb r5, [r2+0x70]                      
    jne r5, 0, lbb_32767                            if r5 != (0 as i32 as i64 as u64) { pc += -59 }
    mov64 r5, 1                                     r5 = 1 as i32 as i64 as u64
    stxdw [r10-0x228], r5                   
    ldxdw r5, [r2+0x71]                     
    stxdw [r10-0x238], r5                   
lbb_32830:
    ldxdw r5, [r2+0x79]                     
    stxdw [r10-0x230], r5                   
    ldxb r5, [r2+0x81]                      
    jeq r5, 1, lbb_32845                            if r5 == (1 as i32 as i64 as u64) { pc += 11 }
    jne r5, 0, lbb_32767                            if r5 != (0 as i32 as i64 as u64) { pc += -68 }
    ldxb r5, [r2+0x82]                      
    jne r5, 0, lbb_32767                            if r5 != (0 as i32 as i64 as u64) { pc += -70 }
    ldxb r5, [r2+0x83]                      
    jne r5, 0, lbb_32767                            if r5 != (0 as i32 as i64 as u64) { pc += -72 }
    mov64 r5, 0                                     r5 = 0 as i32 as i64 as u64
    stxdw [r10-0x240], r5                   
    ldxb r2, [r2+0x84]                      
    mov64 r5, r2                                    r5 = r2
    jeq r5, 0, lbb_32868                            if r5 == (0 as i32 as i64 as u64) { pc += 24 }
    ja lbb_32767                                    if true { pc += -78 }
lbb_32845:
    ldxb r5, [r2+0x82]                      
    jne r5, 0, lbb_32767                            if r5 != (0 as i32 as i64 as u64) { pc += -80 }
    ldxb r5, [r2+0x83]                      
    jne r5, 0, lbb_32767                            if r5 != (0 as i32 as i64 as u64) { pc += -82 }
    ldxb r5, [r2+0x84]                      
    jne r5, 0, lbb_32767                            if r5 != (0 as i32 as i64 as u64) { pc += -84 }
    mov64 r5, 1                                     r5 = 1 as i32 as i64 as u64
    stxdw [r10-0x240], r5                   
    ldxw r5, [r2+0xa1]                      
    stxdw [r10-0x248], r5                   
    ldxw r5, [r2+0x9d]                      
    stxdw [r10-0x250], r5                   
    ldxw r5, [r2+0x99]                      
    stxdw [r10-0x258], r5                   
    ldxw r5, [r2+0x95]                      
    stxdw [r10-0x260], r5                   
    ldxw r5, [r2+0x91]                      
    stxdw [r10-0x268], r5                   
    ldxw r5, [r2+0x8d]                      
    stxdw [r10-0x270], r5                   
    ldxw r5, [r2+0x89]                      
    stxdw [r10-0x278], r5                   
    ldxw r2, [r2+0x85]                      
lbb_32868:
    stxw [r1+0x8c], r2                      
    ldxdw r2, [r10-0x220]                   
    stxw [r1+0x4c], r2                      
    ldxdw r2, [r10-0x1d0]                   
    stxb [r1+0x20], r2                      
    stxb [r1+0x0], r3                       
    ldxdw r2, [r10-0x240]                   
    stxw [r1+0x88], r2                      
    ldxdw r2, [r10-0x230]                   
    stxdw [r1+0x80], r2                     
    ldxdw r2, [r10-0x238]                   
    stxdw [r1+0x78], r2                     
    ldxdw r2, [r10-0x228]                   
    stxw [r1+0x70], r2                      
    stxb [r1+0x6c], r4                      
    ldxdw r2, [r10-0x1e0]                   
    stxw [r1+0x48], r2                      
    stxdw [r1+0x40], r9                     
    ldxdw r2, [r10-0x278]                   
    stxw [r1+0x90], r2                      
    ldxdw r2, [r10-0x218]                   
    stxw [r1+0x50], r2                      
    ldxdw r2, [r10-0x1b0]                   
    stxb [r1+0x21], r2                      
    stxb [r1+0x1], r8                       
    ldxdw r2, [r10-0x270]                   
    stxw [r1+0x94], r2                      
    ldxdw r2, [r10-0x210]                   
    stxw [r1+0x54], r2                      
    ldxdw r2, [r10-0x1a0]                   
    stxb [r1+0x22], r2                      
    stxb [r1+0x2], r7                       
    ldxdw r2, [r10-0x268]                   
    stxw [r1+0x98], r2                      
    ldxdw r2, [r10-0x208]                   
    stxw [r1+0x58], r2                      
    ldxdw r2, [r10-0x188]                   
    stxb [r1+0x23], r2                      
    stxb [r1+0x3], r6                       
    ldxdw r2, [r10-0x260]                   
    stxw [r1+0x9c], r2                      
    ldxdw r2, [r10-0x200]                   
    stxw [r1+0x5c], r2                      
    ldxdw r2, [r10-0x170]                   
    stxb [r1+0x24], r2                      
    stxb [r1+0x4], r0                       
    ldxdw r2, [r10-0x258]                   
    stxw [r1+0xa0], r2                      
    ldxdw r2, [r10-0x1f8]                   
    stxw [r1+0x60], r2                      
    ldxdw r2, [r10-0x160]                   
    stxb [r1+0x25], r2                      
    ldxdw r2, [r10-0x1c8]                   
    stxb [r1+0x5], r2                       
    ldxdw r2, [r10-0x250]                   
    stxw [r1+0xa4], r2                      
    ldxdw r2, [r10-0x1f0]                   
    stxw [r1+0x64], r2                      
    ldxdw r2, [r10-0x148]                   
    stxb [r1+0x26], r2                      
    ldxdw r2, [r10-0x1c0]                   
    stxb [r1+0x6], r2                       
    ldxdw r2, [r10-0x248]                   
    stxw [r1+0xa8], r2                      
    ldxdw r2, [r10-0x1e8]                   
    stxw [r1+0x68], r2                      
    ldxdw r2, [r10-0x130]                   
    stxb [r1+0x27], r2                      
    ldxdw r2, [r10-0x1b8]                   
    stxb [r1+0x7], r2                       
    ldxdw r2, [r10-0x120]                   
    stxb [r1+0x28], r2                      
    ldxdw r2, [r10-0x1a8]                   
    stxb [r1+0x8], r2                       
    ldxdw r2, [r10-0x110]                   
    stxb [r1+0x29], r2                      
    ldxdw r2, [r10-0x198]                   
    stxb [r1+0x9], r2                       
    ldxdw r2, [r10-0x100]                   
    stxb [r1+0x2a], r2                      
    ldxdw r2, [r10-0x190]                   
    stxb [r1+0xa], r2                       
    ldxdw r2, [r10-0xf0]                    
    stxb [r1+0x2b], r2                      
    ldxdw r2, [r10-0x180]                   
    stxb [r1+0xb], r2                       
    ldxdw r2, [r10-0xe0]                    
    stxb [r1+0x2c], r2                      
    ldxdw r2, [r10-0x178]                   
    stxb [r1+0xc], r2                       
    ldxdw r2, [r10-0xd0]                    
    stxb [r1+0x2d], r2                      
    ldxdw r2, [r10-0x168]                   
    stxb [r1+0xd], r2                       
    ldxdw r2, [r10-0xc0]                    
    stxb [r1+0x2e], r2                      
    ldxdw r2, [r10-0x158]                   
    stxb [r1+0xe], r2                       
    ldxdw r2, [r10-0xb0]                    
    stxb [r1+0x2f], r2                      
    ldxdw r2, [r10-0x150]                   
    stxb [r1+0xf], r2                       
    ldxdw r2, [r10-0xa0]                    
    stxb [r1+0x30], r2                      
    ldxdw r2, [r10-0x140]                   
    stxb [r1+0x10], r2                      
    ldxdw r2, [r10-0x90]                    
    stxb [r1+0x31], r2                      
    ldxdw r2, [r10-0x138]                   
    stxb [r1+0x11], r2                      
    ldxdw r2, [r10-0x80]                    
    stxb [r1+0x32], r2                      
    ldxdw r2, [r10-0x128]                   
    stxb [r1+0x12], r2                      
    ldxdw r2, [r10-0x70]                    
    stxb [r1+0x33], r2                      
    ldxdw r2, [r10-0x118]                   
    stxb [r1+0x13], r2                      
    ldxdw r2, [r10-0x60]                    
    stxb [r1+0x34], r2                      
    ldxdw r2, [r10-0x108]                   
    stxb [r1+0x14], r2                      
    ldxdw r2, [r10-0x50]                    
    stxb [r1+0x35], r2                      
    ldxdw r2, [r10-0xf8]                    
    stxb [r1+0x15], r2                      
    ldxdw r2, [r10-0x48]                    
    stxb [r1+0x36], r2                      
    ldxdw r2, [r10-0xe8]                    
    stxb [r1+0x16], r2                      
    ldxdw r2, [r10-0x40]                    
    stxb [r1+0x37], r2                      
    ldxdw r2, [r10-0xd8]                    
    stxb [r1+0x17], r2                      
    ldxdw r2, [r10-0x38]                    
    stxb [r1+0x38], r2                      
    ldxdw r2, [r10-0xc8]                    
    stxb [r1+0x18], r2                      
    ldxdw r2, [r10-0x30]                    
    stxb [r1+0x39], r2                      
    ldxdw r2, [r10-0xb8]                    
    stxb [r1+0x19], r2                      
    ldxdw r2, [r10-0x28]                    
    stxb [r1+0x3a], r2                      
    ldxdw r2, [r10-0xa8]                    
    stxb [r1+0x1a], r2                      
    ldxdw r2, [r10-0x20]                    
    stxb [r1+0x3b], r2                      
    ldxdw r2, [r10-0x98]                    
    stxb [r1+0x1b], r2                      
    ldxdw r2, [r10-0x18]                    
    stxb [r1+0x3c], r2                      
    ldxdw r2, [r10-0x88]                    
    stxb [r1+0x1c], r2                      
    ldxdw r2, [r10-0x10]                    
    stxb [r1+0x3d], r2                      
    ldxdw r2, [r10-0x78]                    
    stxb [r1+0x1d], r2                      
    ldxdw r2, [r10-0x8]                     
    stxb [r1+0x3e], r2                      
    ldxdw r2, [r10-0x68]                    
    stxb [r1+0x1e], r2                      
    ldxdw r2, [r10-0x1d8]                   
    stxb [r1+0x3f], r2                      
    ldxdw r2, [r10-0x58]                    
    stxb [r1+0x1f], r2                      
    ja lbb_32771                                    if true { pc += -264 }

function_33035:
    ldxdw r1, [r1+0x0]                      
    call function_48066                     
    exit                                    

function_33038:
    mov64 r3, r2                                    r3 = r2
    ldxdw r1, [r1+0x0]                      
    ldxdw r2, [r1+0x10]                     
    ldxdw r1, [r1+0x0]                      
    call function_46428                     
    exit                                    

function_33044:
    mov64 r3, r2                                    r3 = r2
    ldxdw r2, [r1+0x8]                      
    ldxdw r1, [r1+0x0]                      
    call function_46428                     
    exit                                    

function_33049:
    mov64 r0, r5                                    r0 = r5
    add64 r0, 1                                     r0 += 1   ///  r0 = r0.wrapping_add(1 as i32 as i64 as u64)
    jgt r3, r0, lbb_33060                           if r3 > r0 { pc += 8 }
    jgt r5, r3, lbb_33060                           if r5 > r3 { pc += 7 }
    mov64 r0, 0                                     r0 = 0 as i32 as i64 as u64
    stxdw [r1+0x20], r0                     
    stxdw [r1+0x8], r3                      
    stxdw [r1+0x0], r2                      
    stxdw [r1+0x18], r5                     
    stxdw [r1+0x10], r4                     
    exit                                    
lbb_33060:
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    stxdw [r10-0x28], r1                    
    lddw r1, 0x100066888 --> b"\x00\x00\x00\x00\x08,\x06\x00\x0c\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00…        r1 load str located at 4295387272
    stxdw [r10-0x30], r1                    
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    stxdw [r10-0x10], r1                    
    stxdw [r10-0x18], r1                    
    lddw r1, 0x100062c08 --> b"invalid args/home/runner/work/platform-tools/platf"        r1 load str located at 4295371784
    stxdw [r10-0x20], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -48                                   r1 += -48   ///  r1 = r1.wrapping_add(-48 as i32 as i64 as u64)
    lddw r2, 0x100066898 --> b"\x00\x00\x00\x00\x14,\x06\x00T\x00\x00\x00\x00\x00\x00\x00M\x01\x00\x00\x…        r2 load str located at 4295387288
    call function_44240                     
    syscall [invalid]                       
    exit                                    

function_33078:
    mov64 r1, r2                                    r1 = r2
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
    stxdw [r10-0x50], r2                    
    lddw r2, 0x1000668e0 --> b"\x00\x00\x00\x002-\x06\x00\x0f\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x0…        r2 load str located at 4295387360
    stxdw [r10-0x70], r2                    
    mov64 r2, 1                                     r2 = 1 as i32 as i64 as u64
    stxdw [r10-0x68], r2                    
    stxdw [r10-0x58], r2                    
    mov64 r2, r10                                   r2 = r10
    add64 r2, -64                                   r2 += -64   ///  r2 = r2.wrapping_add(-64 as i32 as i64 as u64)
    stxdw [r10-0x60], r2                    
    lddw r2, 0x1000409c0 --> b"\xbf#\x00\x00\x00\x00\x00\x00y\x12\x08\x00\x00\x00\x00\x00y\x11\x00\x00\x…        r2 load str located at 4295231936
    stxdw [r10-0x38], r2                    
    lddw r2, 0x1000668f0 --> b"\x00\x00\x00\x00A-\x06\x00\x15\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x0…        r2 load str located at 4295387376
    stxdw [r10-0x40], r2                    
    mov64 r2, r10                                   r2 = r10
    add64 r2, -112                                  r2 += -112   ///  r2 = r2.wrapping_add(-112 as i32 as i64 as u64)
    call function_45907                     
    exit                                    

function_33100:
    mov64 r4, r3                                    r4 = r3
    lsh64 r4, 32                                    r4 <<= 32   ///  r4 = r4.wrapping_shl(32)
    rsh64 r4, 32                                    r4 >>= 32   ///  r4 = r4.wrapping_shr(32)
    jgt r4, 28, lbb_33122                           if r4 > (28 as i32 as i64 as u64) { pc += 18 }
    lsh64 r3, 16                                    r3 <<= 16   ///  r3 = r3.wrapping_shl(16)
    lddw r5, 0x80000000                             r5 load str located at 2147483648
    mov64 r4, r3                                    r4 = r3
    or64 r4, r5                                     r4 |= r5   ///  r4 = r4.or(r5)
    mov64 r5, 0                                     r5 = 0 as i32 as i64 as u64
    jsgt r5, r2, lbb_33112                          if (r5 as i64) > (r2 as i64) { pc += 1 }
    mov64 r4, r3                                    r4 = r3
lbb_33112:
    stxw [r1+0x4], r5                       
    stxw [r1+0x0], r4                       
    mov64 r3, r2                                    r3 = r2
    arsh64 r3, 63                                   r3 >>= 63 (signed)   ///  r3 = (r3 as i64).wrapping_shr(63)
    xor64 r2, r3                                    r2 ^= r3   ///  r2 = r2.xor(r3)
    sub64 r2, r3                                    r2 -= r3   ///  r2 = r2.wrapping_sub(r3)
    stxw [r1+0x8], r2                       
    rsh64 r2, 32                                    r2 >>= 32   ///  r2 = r2.wrapping_shr(32)
    stxw [r1+0xc], r2                       
    exit                                    
lbb_33122:
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    stxw [r10-0x18], r1                     
    stxw [r10-0x1c], r3                     
    mov64 r1, 4                                     r1 = 4 as i32 as i64 as u64
    stxw [r10-0x20], r1                     
    mov64 r1, r10                                   r1 = r10
    add64 r1, -32                                   r1 += -32   ///  r1 = r1.wrapping_add(-32 as i32 as i64 as u64)
    call function_38372                     
    syscall [invalid]                       

function_33131:
    mov64 r5, 4                                     r5 = 4 as i32 as i64 as u64
    mov64 r0, r4                                    r0 = r4
    lsh64 r0, 32                                    r0 <<= 32   ///  r0 = r0.wrapping_shl(32)
    rsh64 r0, 32                                    r0 >>= 32   ///  r0 = r0.wrapping_shr(32)
    jgt r0, 28, lbb_33177                           if r0 > (28 as i32 as i64 as u64) { pc += 41 }
    mov64 r5, 1                                     r5 = 1 as i32 as i64 as u64
    lddw r0, 0xffffffff                             r0 load str located at 4294967295
    jsgt r3, r0, lbb_33177                          if (r3 as i64) > (r0 as i64) { pc += 37 }
    mov64 r0, 1                                     r0 = 1 as i32 as i64 as u64
    jeq r2, 0, lbb_33143                            if r2 == (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r0, 0                                     r0 = 0 as i32 as i64 as u64
lbb_33143:
    lddw r6, 0xffffffff00000000                     r6 load str located at -4294967296
    jsgt r6, r3, lbb_33147                          if (r6 as i64) > (r3 as i64) { pc += 1 }
    mov64 r5, 0                                     r5 = 0 as i32 as i64 as u64
lbb_33147:
    jeq r3, r6, lbb_33149                           if r3 == r6 { pc += 1 }
    mov64 r0, r5                                    r0 = r5
lbb_33149:
    mov64 r5, 2                                     r5 = 2 as i32 as i64 as u64
    and64 r0, 1                                     r0 &= 1   ///  r0 = r0.and(1)
    jne r0, 0, lbb_33177                            if r0 != (0 as i32 as i64 as u64) { pc += 25 }
    mov64 r5, r2                                    r5 = r2
    neg64 r5                                        r5 = -r5   ///  r5 = (r5 as i64).wrapping_neg() as u64
    mov64 r0, 0                                     r0 = 0 as i32 as i64 as u64
    jsgt r0, r3, lbb_33157                          if (r0 as i64) > (r3 as i64) { pc += 1 }
    mov64 r5, r2                                    r5 = r2
lbb_33157:
    mov64 r6, 1                                     r6 = 1 as i32 as i64 as u64
    jne r2, 0, lbb_33160                            if r2 != (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r6, 0                                     r6 = 0 as i32 as i64 as u64
lbb_33160:
    mov64 r2, r3                                    r2 = r3
    add64 r2, r6                                    r2 += r6   ///  r2 = r2.wrapping_add(r6)
    neg64 r2                                        r2 = -r2   ///  r2 = (r2 as i64).wrapping_neg() as u64
    jsgt r0, r3, lbb_33165                          if (r0 as i64) > (r3 as i64) { pc += 1 }
    mov64 r2, r3                                    r2 = r3
lbb_33165:
    stxw [r1+0x8], r5                       
    rsh64 r5, 32                                    r5 >>= 32   ///  r5 = r5.wrapping_shr(32)
    stxw [r1+0xc], r5                       
    stxw [r1+0x4], r2                       
    rsh64 r3, 32                                    r3 >>= 32   ///  r3 = r3.wrapping_shr(32)
    lddw r2, 0x80000000                             r2 load str located at 2147483648
    and64 r3, r2                                    r3 &= r2   ///  r3 = r3.and(r2)
    lsh64 r4, 16                                    r4 <<= 16   ///  r4 = r4.wrapping_shl(16)
    or64 r3, r4                                     r3 |= r4   ///  r3 = r3.or(r4)
    stxw [r1+0x0], r3                       
    exit                                    
lbb_33177:
    stxw [r10-0x1c], r4                     
    stxw [r10-0x20], r5                     
    mov64 r1, r10                                   r1 = r10
    add64 r1, -32                                   r1 += -32   ///  r1 = r1.wrapping_add(-32 as i32 as i64 as u64)
    call function_38391                     
    syscall [invalid]                       

function_33183:
    ldxdw r0, [r5-0xff8]                    
    mov64 r6, r0                                    r6 = r0
    lsh64 r6, 32                                    r6 <<= 32   ///  r6 = r6.wrapping_shl(32)
    rsh64 r6, 32                                    r6 >>= 32   ///  r6 = r6.wrapping_shr(32)
    mov64 r7, 29                                    r7 = 29 as i32 as i64 as u64
    jgt r7, r6, lbb_33206                           if r7 > r6 { pc += 17 }
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    stxdw [r10-0x28], r1                    
    lddw r1, 0x100066950 --> b"\x00\x00\x00\x00\x8f-\x06\x00%\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x0…        r1 load str located at 4295387472
    stxdw [r10-0x30], r1                    
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    stxdw [r10-0x10], r1                    
    stxdw [r10-0x18], r1                    
    lddw r1, 0x100062c08 --> b"invalid args/home/runner/work/platform-tools/platf"        r1 load str located at 4295371784
    stxdw [r10-0x20], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -48                                   r1 += -48   ///  r1 = r1.wrapping_add(-48 as i32 as i64 as u64)
    lddw r2, 0x100066960 --> b"\x00\x00\x00\x00\x81-\x06\x00\x0e\x00\x00\x00\x00\x00\x00\x00\x11\x02\x00…        r2 load str located at 4295387488
    call function_44240                     
    syscall [invalid]                       
lbb_33206:
    ldxdw r7, [r5-0x1000]                   
    mov64 r5, 0                                     r5 = 0 as i32 as i64 as u64
    mov64 r6, -2147483648                           r6 = -2147483648 as i32 as i64 as u64
    jne r7, 0, lbb_33211                            if r7 != (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r6, 0                                     r6 = 0 as i32 as i64 as u64
lbb_33211:
    mov64 r7, r3                                    r7 = r3
    or64 r7, r2                                     r7 |= r2   ///  r7 = r7.or(r2)
    or64 r7, r4                                     r7 |= r4   ///  r7 = r7.or(r4)
    lsh64 r7, 32                                    r7 <<= 32   ///  r7 = r7.wrapping_shl(32)
    rsh64 r7, 32                                    r7 >>= 32   ///  r7 = r7.wrapping_shr(32)
    jeq r7, 0, lbb_33218                            if r7 == (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r5, r6                                    r5 = r6
lbb_33218:
    stxw [r1+0xc], r3                       
    stxw [r1+0x8], r2                       
    stxw [r1+0x4], r4                       
    lsh64 r0, 16                                    r0 <<= 16   ///  r0 = r0.wrapping_shl(16)
    or64 r0, r5                                     r0 |= r5   ///  r0 = r0.or(r5)
    stxw [r1+0x0], r0                       
    exit                                    

function_33225:
    ldxw r7, [r2+0x4]                       
    ldxw r0, [r2+0xc]                       
    ldxw r3, [r2+0x8]                       
    ldxw r2, [r2+0x0]                       
    mov64 r4, r2                                    r4 = r2
    rsh64 r4, 16                                    r4 >>= 16   ///  r4 = r4.wrapping_shr(16)
    and64 r4, 255                                   r4 &= 255   ///  r4 = r4.and(255)
    mov64 r5, r7                                    r5 = r7
    mov64 r6, r0                                    r6 = r0
    mov64 r8, r3                                    r8 = r3
    jeq r4, 0, lbb_33289                            if r4 == (0 as i32 as i64 as u64) { pc += 53 }
    mov64 r9, r0                                    r9 = r0
    or64 r9, r3                                     r9 |= r3   ///  r9 = r9.or(r3)
    or64 r9, r7                                     r9 |= r7   ///  r9 = r9.or(r7)
    mov64 r5, 0                                     r5 = 0 as i32 as i64 as u64
    lsh64 r9, 32                                    r9 <<= 32   ///  r9 = r9.wrapping_shl(32)
    rsh64 r9, 32                                    r9 >>= 32   ///  r9 = r9.wrapping_shr(32)
    mov64 r6, 0                                     r6 = 0 as i32 as i64 as u64
    mov64 r8, 0                                     r8 = 0 as i32 as i64 as u64
    jeq r9, 0, lbb_33289                            if r9 == (0 as i32 as i64 as u64) { pc += 44 }
    mov64 r5, r7                                    r5 = r7
    mov64 r6, r0                                    r6 = r0
lbb_33247:
    mov64 r0, r3                                    r0 = r3
    mov64 r7, r6                                    r7 = r6
    mov64 r3, r5                                    r3 = r5
    lsh64 r0, 32                                    r0 <<= 32   ///  r0 = r0.wrapping_shl(32)
    rsh64 r0, 32                                    r0 >>= 32   ///  r0 = r0.wrapping_shr(32)
    jne r0, 0, lbb_33264                            if r0 != (0 as i32 as i64 as u64) { pc += 11 }
    mov64 r5, r7                                    r5 = r7
    lsh64 r5, 32                                    r5 <<= 32   ///  r5 = r5.wrapping_shl(32)
    rsh64 r5, 32                                    r5 >>= 32   ///  r5 = r5.wrapping_shr(32)
    jne r5, 0, lbb_33264                            if r5 != (0 as i32 as i64 as u64) { pc += 7 }
    mov64 r9, r3                                    r9 = r3
    lsh64 r9, 32                                    r9 <<= 32   ///  r9 = r9.wrapping_shl(32)
    rsh64 r9, 32                                    r9 >>= 32   ///  r9 = r9.wrapping_shr(32)
    mov64 r5, 0                                     r5 = 0 as i32 as i64 as u64
    mov64 r6, 0                                     r6 = 0 as i32 as i64 as u64
    mov64 r8, 0                                     r8 = 0 as i32 as i64 as u64
    jeq r9, 0, lbb_33289                            if r9 == (0 as i32 as i64 as u64) { pc += 25 }
lbb_33264:
    mov64 r5, r3                                    r5 = r3
    lsh64 r5, 32                                    r5 <<= 32   ///  r5 = r5.wrapping_shl(32)
    rsh64 r5, 32                                    r5 >>= 32   ///  r5 = r5.wrapping_shr(32)
    div64 r5, 10                                    r5 /= 10   ///  r5 = r5 / (10 as u64)
    mov64 r6, r5                                    r6 = r5
    mul64 r6, 10                                    r6 *= 10   ///  r6 = r6.wrapping_mul(10 as u64)
    sub64 r3, r6                                    r3 -= r6   ///  r3 = r3.wrapping_sub(r6)
    lsh64 r3, 32                                    r3 <<= 32   ///  r3 = r3.wrapping_shl(32)
    lsh64 r7, 32                                    r7 <<= 32   ///  r7 = r7.wrapping_shl(32)
    rsh64 r7, 32                                    r7 >>= 32   ///  r7 = r7.wrapping_shr(32)
    or64 r3, r7                                     r3 |= r7   ///  r3 = r3.or(r7)
    mov64 r6, r3                                    r6 = r3
    div64 r6, 10                                    r6 /= 10   ///  r6 = r6 / (10 as u64)
    mov64 r7, r6                                    r7 = r6
    mul64 r7, 10                                    r7 *= 10   ///  r7 = r7.wrapping_mul(10 as u64)
    sub64 r3, r7                                    r3 -= r7   ///  r3 = r3.wrapping_sub(r7)
    lsh64 r3, 32                                    r3 <<= 32   ///  r3 = r3.wrapping_shl(32)
    or64 r3, r0                                     r3 |= r0   ///  r3 = r3.or(r0)
    div64 r3, 10                                    r3 /= 10   ///  r3 = r3 / (10 as u64)
    add64 r4, -1                                    r4 += -1   ///  r4 = r4.wrapping_add(-1 as i32 as i64 as u64)
    mov64 r0, r4                                    r0 = r4
    lsh64 r0, 32                                    r0 <<= 32   ///  r0 = r0.wrapping_shl(32)
    rsh64 r0, 32                                    r0 >>= 32   ///  r0 = r0.wrapping_shr(32)
    mov64 r8, r3                                    r8 = r3
    jne r0, 0, lbb_33247                            if r0 != (0 as i32 as i64 as u64) { pc += -42 }
lbb_33289:
    stxw [r1+0xc], r6                       
    stxw [r1+0x8], r8                       
    stxw [r1+0x4], r5                       
    lddw r3, 0x80000000                             r3 load str located at 2147483648
    and64 r2, r3                                    r2 &= r3   ///  r2 = r2.and(r3)
    stxw [r1+0x0], r2                       
    exit                                    

function_33297:
    stxdw [r10-0x60], r1                    
    ldxw r8, [r2+0x4]                       
    ldxw r6, [r2+0xc]                       
    ldxw r3, [r2+0x8]                       
    ldxw r1, [r2+0x0]                       
    mov64 r4, r1                                    r4 = r1
    rsh64 r4, 16                                    r4 >>= 16   ///  r4 = r4.wrapping_shr(16)
    and64 r4, 255                                   r4 &= 255   ///  r4 = r4.and(255)
    mov64 r5, r8                                    r5 = r8
    mov64 r7, r6                                    r7 = r6
    mov64 r9, r3                                    r9 = r3
    jeq r4, 0, lbb_33362                            if r4 == (0 as i32 as i64 as u64) { pc += 53 }
    mov64 r0, r6                                    r0 = r6
    or64 r0, r3                                     r0 |= r3   ///  r0 = r0.or(r3)
    or64 r0, r8                                     r0 |= r8   ///  r0 = r0.or(r8)
    mov64 r5, 0                                     r5 = 0 as i32 as i64 as u64
    lsh64 r0, 32                                    r0 <<= 32   ///  r0 = r0.wrapping_shl(32)
    rsh64 r0, 32                                    r0 >>= 32   ///  r0 = r0.wrapping_shr(32)
    mov64 r7, 0                                     r7 = 0 as i32 as i64 as u64
    mov64 r9, 0                                     r9 = 0 as i32 as i64 as u64
    jeq r0, 0, lbb_33362                            if r0 == (0 as i32 as i64 as u64) { pc += 44 }
    mov64 r5, r8                                    r5 = r8
    mov64 r7, r6                                    r7 = r6
lbb_33320:
    mov64 r0, r3                                    r0 = r3
    mov64 r8, r7                                    r8 = r7
    mov64 r3, r5                                    r3 = r5
    lsh64 r0, 32                                    r0 <<= 32   ///  r0 = r0.wrapping_shl(32)
    rsh64 r0, 32                                    r0 >>= 32   ///  r0 = r0.wrapping_shr(32)
    jne r0, 0, lbb_33337                            if r0 != (0 as i32 as i64 as u64) { pc += 11 }
    mov64 r5, r8                                    r5 = r8
    lsh64 r5, 32                                    r5 <<= 32   ///  r5 = r5.wrapping_shl(32)
    rsh64 r5, 32                                    r5 >>= 32   ///  r5 = r5.wrapping_shr(32)
    jne r5, 0, lbb_33337                            if r5 != (0 as i32 as i64 as u64) { pc += 7 }
    mov64 r6, r3                                    r6 = r3
    lsh64 r6, 32                                    r6 <<= 32   ///  r6 = r6.wrapping_shl(32)
    rsh64 r6, 32                                    r6 >>= 32   ///  r6 = r6.wrapping_shr(32)
    mov64 r5, 0                                     r5 = 0 as i32 as i64 as u64
    mov64 r7, 0                                     r7 = 0 as i32 as i64 as u64
    mov64 r9, 0                                     r9 = 0 as i32 as i64 as u64
    jeq r6, 0, lbb_33362                            if r6 == (0 as i32 as i64 as u64) { pc += 25 }
lbb_33337:
    mov64 r5, r3                                    r5 = r3
    lsh64 r5, 32                                    r5 <<= 32   ///  r5 = r5.wrapping_shl(32)
    rsh64 r5, 32                                    r5 >>= 32   ///  r5 = r5.wrapping_shr(32)
    div64 r5, 10                                    r5 /= 10   ///  r5 = r5 / (10 as u64)
    mov64 r6, r5                                    r6 = r5
    mul64 r6, 10                                    r6 *= 10   ///  r6 = r6.wrapping_mul(10 as u64)
    sub64 r3, r6                                    r3 -= r6   ///  r3 = r3.wrapping_sub(r6)
    lsh64 r3, 32                                    r3 <<= 32   ///  r3 = r3.wrapping_shl(32)
    lsh64 r8, 32                                    r8 <<= 32   ///  r8 = r8.wrapping_shl(32)
    rsh64 r8, 32                                    r8 >>= 32   ///  r8 = r8.wrapping_shr(32)
    or64 r3, r8                                     r3 |= r8   ///  r3 = r3.or(r8)
    mov64 r7, r3                                    r7 = r3
    div64 r7, 10                                    r7 /= 10   ///  r7 = r7 / (10 as u64)
    mov64 r6, r7                                    r6 = r7
    mul64 r6, 10                                    r6 *= 10   ///  r6 = r6.wrapping_mul(10 as u64)
    sub64 r3, r6                                    r3 -= r6   ///  r3 = r3.wrapping_sub(r6)
    lsh64 r3, 32                                    r3 <<= 32   ///  r3 = r3.wrapping_shl(32)
    or64 r3, r0                                     r3 |= r0   ///  r3 = r3.or(r0)
    div64 r3, 10                                    r3 /= 10   ///  r3 = r3 / (10 as u64)
    add64 r4, -1                                    r4 += -1   ///  r4 = r4.wrapping_add(-1 as i32 as i64 as u64)
    mov64 r0, r4                                    r0 = r4
    lsh64 r0, 32                                    r0 <<= 32   ///  r0 = r0.wrapping_shl(32)
    rsh64 r0, 32                                    r0 >>= 32   ///  r0 = r0.wrapping_shr(32)
    mov64 r9, r3                                    r9 = r3
    jne r0, 0, lbb_33320                            if r0 != (0 as i32 as i64 as u64) { pc += -42 }
lbb_33362:
    stxw [r10-0x48], r7                     
    stxw [r10-0x4c], r9                     
    stxw [r10-0x50], r5                     
    lddw r3, 0x80000000                             r3 load str located at 2147483648
    and64 r1, r3                                    r1 &= r3   ///  r1 = r1.and(r3)
    stxw [r10-0x54], r1                     
    mov64 r1, r10                                   r1 = r10
    add64 r1, -68                                   r1 += -68   ///  r1 = r1.wrapping_add(-68 as i32 as i64 as u64)
    mov64 r3, r10                                   r3 = r10
    add64 r3, -84                                   r3 += -84   ///  r3 = r3.wrapping_add(-84 as i32 as i64 as u64)
    mov64 r7, 1                                     r7 = 1 as i32 as i64 as u64
    mov64 r4, 1                                     r4 = 1 as i32 as i64 as u64
    call function_34125                     
    ldxw r1, [r10-0x44]                     
    jeq r1, 0, lbb_33394                            if r1 == (0 as i32 as i64 as u64) { pc += 16 }
    stxdw [r10-0x28], r7                    
    lddw r1, 0x100066978 --> b"\x00\x00\x00\x00x.\x06\x00\x16\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x0…        r1 load str located at 4295387512
    stxdw [r10-0x30], r1                    
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    stxdw [r10-0x10], r1                    
    stxdw [r10-0x18], r1                    
    lddw r1, 0x100062c08 --> b"invalid args/home/runner/work/platform-tools/platf"        r1 load str located at 4295371784
    stxdw [r10-0x20], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -48                                   r1 += -48   ///  r1 = r1.wrapping_add(-48 as i32 as i64 as u64)
    lddw r2, 0x100066988 --> b"\x00\x00\x00\x00\x8e.\x06\x00\x17\x00\x00\x00\x00\x00\x00\x00\x03\x01\x00…        r2 load str located at 4295387528
    call function_44240                     
    syscall [invalid]                       
lbb_33394:
    ldxdw r1, [r10-0x38]                    
    ldxdw r2, [r10-0x60]                    
    stxdw [r2+0x8], r1                      
    ldxdw r1, [r10-0x40]                    
    stxdw [r2+0x0], r1                      
    exit                                    

function_33400:
    ldxw r5, [r2+0x0]                       
    lsh64 r5, 32                                    r5 <<= 32   ///  r5 = r5.wrapping_shl(32)
    arsh64 r5, 32                                   r5 >>= 32 (signed)   ///  r5 = (r5 as i64).wrapping_shr(32)
    mov64 r3, r5                                    r3 = r5
    and64 r3, 16711680                              r3 &= 16711680   ///  r3 = r3.and(16711680)
    jne r3, 0, lbb_33411                            if r3 != (0 as i32 as i64 as u64) { pc += 5 }
    ldxdw r3, [r2+0x8]                      
    stxdw [r1+0x8], r3                      
    ldxdw r2, [r2+0x0]                      
    stxdw [r1+0x0], r2                      
    ja lbb_33536                                    if true { pc += 125 }
lbb_33411:
    stxdw [r10-0x60], r1                    
    ldxw r8, [r2+0x4]                       
    ldxw r6, [r2+0xc]                       
    stxdw [r10-0x68], r2                    
    ldxw r4, [r2+0x8]                       
    mov64 r1, r5                                    r1 = r5
    mov64 r3, r5                                    r3 = r5
    rsh64 r3, 16                                    r3 >>= 16   ///  r3 = r3.wrapping_shr(16)
    and64 r3, 255                                   r3 &= 255   ///  r3 = r3.and(255)
    mov64 r5, r8                                    r5 = r8
    mov64 r7, r6                                    r7 = r6
    mov64 r9, r4                                    r9 = r4
    jeq r3, 0, lbb_33477                            if r3 == (0 as i32 as i64 as u64) { pc += 53 }
    mov64 r0, r6                                    r0 = r6
    or64 r0, r4                                     r0 |= r4   ///  r0 = r0.or(r4)
    or64 r0, r8                                     r0 |= r8   ///  r0 = r0.or(r8)
    mov64 r5, 0                                     r5 = 0 as i32 as i64 as u64
    lsh64 r0, 32                                    r0 <<= 32   ///  r0 = r0.wrapping_shl(32)
    rsh64 r0, 32                                    r0 >>= 32   ///  r0 = r0.wrapping_shr(32)
    mov64 r7, 0                                     r7 = 0 as i32 as i64 as u64
    mov64 r9, 0                                     r9 = 0 as i32 as i64 as u64
    jeq r0, 0, lbb_33477                            if r0 == (0 as i32 as i64 as u64) { pc += 44 }
    mov64 r5, r8                                    r5 = r8
    mov64 r7, r6                                    r7 = r6
lbb_33435:
    mov64 r0, r4                                    r0 = r4
    mov64 r8, r7                                    r8 = r7
    mov64 r4, r5                                    r4 = r5
    lsh64 r0, 32                                    r0 <<= 32   ///  r0 = r0.wrapping_shl(32)
    rsh64 r0, 32                                    r0 >>= 32   ///  r0 = r0.wrapping_shr(32)
    jne r0, 0, lbb_33452                            if r0 != (0 as i32 as i64 as u64) { pc += 11 }
    mov64 r5, r8                                    r5 = r8
    lsh64 r5, 32                                    r5 <<= 32   ///  r5 = r5.wrapping_shl(32)
    rsh64 r5, 32                                    r5 >>= 32   ///  r5 = r5.wrapping_shr(32)
    jne r5, 0, lbb_33452                            if r5 != (0 as i32 as i64 as u64) { pc += 7 }
    mov64 r6, r4                                    r6 = r4
    lsh64 r6, 32                                    r6 <<= 32   ///  r6 = r6.wrapping_shl(32)
    rsh64 r6, 32                                    r6 >>= 32   ///  r6 = r6.wrapping_shr(32)
    mov64 r5, 0                                     r5 = 0 as i32 as i64 as u64
    mov64 r7, 0                                     r7 = 0 as i32 as i64 as u64
    mov64 r9, 0                                     r9 = 0 as i32 as i64 as u64
    jeq r6, 0, lbb_33477                            if r6 == (0 as i32 as i64 as u64) { pc += 25 }
lbb_33452:
    mov64 r5, r4                                    r5 = r4
    lsh64 r5, 32                                    r5 <<= 32   ///  r5 = r5.wrapping_shl(32)
    rsh64 r5, 32                                    r5 >>= 32   ///  r5 = r5.wrapping_shr(32)
    div64 r5, 10                                    r5 /= 10   ///  r5 = r5 / (10 as u64)
    mov64 r6, r5                                    r6 = r5
    mul64 r6, 10                                    r6 *= 10   ///  r6 = r6.wrapping_mul(10 as u64)
    sub64 r4, r6                                    r4 -= r6   ///  r4 = r4.wrapping_sub(r6)
    lsh64 r4, 32                                    r4 <<= 32   ///  r4 = r4.wrapping_shl(32)
    lsh64 r8, 32                                    r8 <<= 32   ///  r8 = r8.wrapping_shl(32)
    rsh64 r8, 32                                    r8 >>= 32   ///  r8 = r8.wrapping_shr(32)
    or64 r4, r8                                     r4 |= r8   ///  r4 = r4.or(r8)
    mov64 r7, r4                                    r7 = r4
    div64 r7, 10                                    r7 /= 10   ///  r7 = r7 / (10 as u64)
    mov64 r6, r7                                    r6 = r7
    mul64 r6, 10                                    r6 *= 10   ///  r6 = r6.wrapping_mul(10 as u64)
    sub64 r4, r6                                    r4 -= r6   ///  r4 = r4.wrapping_sub(r6)
    lsh64 r4, 32                                    r4 <<= 32   ///  r4 = r4.wrapping_shl(32)
    or64 r4, r0                                     r4 |= r0   ///  r4 = r4.or(r0)
    div64 r4, 10                                    r4 /= 10   ///  r4 = r4 / (10 as u64)
    add64 r3, -1                                    r3 += -1   ///  r3 = r3.wrapping_add(-1 as i32 as i64 as u64)
    mov64 r0, r3                                    r0 = r3
    lsh64 r0, 32                                    r0 <<= 32   ///  r0 = r0.wrapping_shl(32)
    rsh64 r0, 32                                    r0 >>= 32   ///  r0 = r0.wrapping_shr(32)
    mov64 r9, r4                                    r9 = r4
    jne r0, 0, lbb_33435                            if r0 != (0 as i32 as i64 as u64) { pc += -42 }
lbb_33477:
    stxw [r10-0x48], r7                     
    stxw [r10-0x4c], r9                     
    stxw [r10-0x50], r5                     
    lddw r3, 0x80000000                             r3 load str located at 2147483648
    mov64 r4, r1                                    r4 = r1
    and64 r4, r3                                    r4 &= r3   ///  r4 = r4.and(r3)
    stxw [r10-0x54], r4                     
    jsgt r1, -1, lbb_33487                          if (r1 as i64) > (-1 as i32 as i64) { pc += 1 }
    ja lbb_33492                                    if true { pc += 5 }
lbb_33487:
    ldxdw r1, [r10-0x4c]                    
    ldxdw r2, [r10-0x60]                    
    stxdw [r2+0x8], r1                      
    ldxdw r1, [r10-0x54]                    
    ja lbb_33535                                    if true { pc += 43 }
lbb_33492:
    mov64 r1, r10                                   r1 = r10
    add64 r1, -48                                   r1 += -48   ///  r1 = r1.wrapping_add(-48 as i32 as i64 as u64)
    ldxdw r2, [r10-0x68]                    
    call function_33297                     
    ldxw r1, [r10-0x28]                     
    ldxw r2, [r10-0x24]                     
    or64 r2, r1                                     r2 |= r1   ///  r2 = r2.or(r1)
    ldxw r1, [r10-0x2c]                     
    or64 r2, r1                                     r2 |= r1   ///  r2 = r2.or(r1)
    lsh64 r2, 32                                    r2 <<= 32   ///  r2 = r2.wrapping_shl(32)
    rsh64 r2, 32                                    r2 >>= 32   ///  r2 = r2.wrapping_shr(32)
    jeq r2, 0, lbb_33487                            if r2 == (0 as i32 as i64 as u64) { pc += -17 }
    mov64 r1, r10                                   r1 = r10
    add64 r1, -68                                   r1 += -68   ///  r1 = r1.wrapping_add(-68 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -84                                   r2 += -84   ///  r2 = r2.wrapping_add(-84 as i32 as i64 as u64)
    mov64 r7, 1                                     r7 = 1 as i32 as i64 as u64
    lddw r3, 0x10005fca8 --> b"\x00"                r3 load str located at 4295359656
    mov64 r4, 1                                     r4 = 1 as i32 as i64 as u64
    call function_34125                     
    ldxw r1, [r10-0x44]                     
    jeq r1, 0, lbb_33531                            if r1 == (0 as i32 as i64 as u64) { pc += 16 }
    stxdw [r10-0x28], r7                    
    lddw r1, 0x100066978 --> b"\x00\x00\x00\x00x.\x06\x00\x16\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x0…        r1 load str located at 4295387512
    stxdw [r10-0x30], r1                    
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    stxdw [r10-0x10], r1                    
    stxdw [r10-0x18], r1                    
    lddw r1, 0x100062c08 --> b"invalid args/home/runner/work/platform-tools/platf"        r1 load str located at 4295371784
    stxdw [r10-0x20], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -48                                   r1 += -48   ///  r1 = r1.wrapping_add(-48 as i32 as i64 as u64)
    lddw r2, 0x100066988 --> b"\x00\x00\x00\x00\x8e.\x06\x00\x17\x00\x00\x00\x00\x00\x00\x00\x03\x01\x00…        r2 load str located at 4295387528
    call function_44240                     
    syscall [invalid]                       
lbb_33531:
    ldxdw r1, [r10-0x38]                    
    ldxdw r2, [r10-0x60]                    
    stxdw [r2+0x8], r1                      
    ldxdw r1, [r10-0x40]                    
lbb_33535:
    stxdw [r2+0x0], r1                      
lbb_33536:
    exit                                    

function_33537:
    mov64 r7, r3                                    r7 = r3
    mov64 r8, r2                                    r8 = r2
    mov64 r6, r1                                    r6 = r1
    mov64 r1, r8                                    r1 = r8
    mov64 r2, r7                                    r2 = r7
    call function_33952                     
    and64 r0, 255                                   r0 &= 255   ///  r0 = r0.and(255)
    jeq r0, 255, lbb_33546                          if r0 == (255 as i32 as i64 as u64) { pc += 1 }
    mov64 r7, r8                                    r7 = r8
lbb_33546:
    ldxdw r1, [r7+0x0]                      
    stxdw [r6+0x0], r1                      
    ldxdw r1, [r7+0x8]                      
    stxdw [r6+0x8], r1                      
    exit                                    

function_33551:
    mov64 r7, r3                                    r7 = r3
    mov64 r8, r2                                    r8 = r2
    mov64 r6, r1                                    r6 = r1
    mov64 r1, r8                                    r1 = r8
    mov64 r2, r7                                    r2 = r7
    call function_33952                     
    and64 r0, 255                                   r0 &= 255   ///  r0 = r0.and(255)
    jeq r0, 1, lbb_33560                            if r0 == (1 as i32 as i64 as u64) { pc += 1 }
    mov64 r7, r8                                    r7 = r8
lbb_33560:
    ldxdw r1, [r7+0x0]                      
    stxdw [r6+0x0], r1                      
    ldxdw r1, [r7+0x8]                      
    stxdw [r6+0x8], r1                      
    exit                                    

function_33565:
    mov64 r8, 0                                     r8 = 0 as i32 as i64 as u64
    ldxw r4, [r2+0x4]                       
    ldxw r3, [r2+0x8]                       
    mov64 r5, r3                                    r5 = r3
    or64 r5, r4                                     r5 |= r4   ///  r5 = r5.or(r4)
    ldxw r0, [r2+0xc]                       
    or64 r5, r0                                     r5 |= r0   ///  r5 = r5.or(r0)
    lsh64 r5, 32                                    r5 <<= 32   ///  r5 = r5.wrapping_shl(32)
    rsh64 r5, 32                                    r5 >>= 32   ///  r5 = r5.wrapping_shr(32)
    jeq r5, 0, lbb_33625                            if r5 == (0 as i32 as i64 as u64) { pc += 50 }
    ldxw r8, [r2+0x0]                       
    mov64 r2, r8                                    r2 = r8
    rsh64 r2, 16                                    r2 >>= 16   ///  r2 = r2.wrapping_shr(16)
    and64 r2, 255                                   r2 &= 255   ///  r2 = r2.and(255)
    jeq r2, 0, lbb_33625                            if r2 == (0 as i32 as i64 as u64) { pc += 45 }
    stxdw [r10-0x8], r8                     
    mov64 r6, r4                                    r6 = r4
    ja lbb_33592                                    if true { pc += 9 }
lbb_33583:
    mov64 r8, 0                                     r8 = 0 as i32 as i64 as u64
    add64 r2, -1                                    r2 += -1   ///  r2 = r2.wrapping_add(-1 as i32 as i64 as u64)
    mov64 r9, r2                                    r9 = r2
    lsh64 r9, 32                                    r9 <<= 32   ///  r9 = r9.wrapping_shl(32)
    rsh64 r9, 32                                    r9 >>= 32   ///  r9 = r9.wrapping_shr(32)
    mov64 r3, r5                                    r3 = r5
    mov64 r0, r7                                    r0 = r7
    mov64 r4, r6                                    r4 = r6
    jeq r9, 0, lbb_33621                            if r9 == (0 as i32 as i64 as u64) { pc += 29 }
lbb_33592:
    lsh64 r6, 32                                    r6 <<= 32   ///  r6 = r6.wrapping_shl(32)
    rsh64 r6, 32                                    r6 >>= 32   ///  r6 = r6.wrapping_shr(32)
    div64 r6, 10                                    r6 /= 10   ///  r6 = r6 / (10 as u64)
    mov64 r5, r6                                    r5 = r6
    mul64 r5, 10                                    r5 *= 10   ///  r5 = r5.wrapping_mul(10 as u64)
    mov64 r9, r4                                    r9 = r4
    sub64 r9, r5                                    r9 -= r5   ///  r9 = r9.wrapping_sub(r5)
    lsh64 r9, 32                                    r9 <<= 32   ///  r9 = r9.wrapping_shl(32)
    mov64 r5, r0                                    r5 = r0
    lsh64 r5, 32                                    r5 <<= 32   ///  r5 = r5.wrapping_shl(32)
    rsh64 r5, 32                                    r5 >>= 32   ///  r5 = r5.wrapping_shr(32)
    or64 r9, r5                                     r9 |= r5   ///  r9 = r9.or(r5)
    mov64 r7, r9                                    r7 = r9
    div64 r7, 10                                    r7 /= 10   ///  r7 = r7 / (10 as u64)
    mov64 r5, r7                                    r5 = r7
    mul64 r5, 10                                    r5 *= 10   ///  r5 = r5.wrapping_mul(10 as u64)
    sub64 r9, r5                                    r9 -= r5   ///  r9 = r9.wrapping_sub(r5)
    mov64 r5, r3                                    r5 = r3
    lsh64 r5, 32                                    r5 <<= 32   ///  r5 = r5.wrapping_shl(32)
    rsh64 r5, 32                                    r5 >>= 32   ///  r5 = r5.wrapping_shr(32)
    lsh64 r9, 32                                    r9 <<= 32   ///  r9 = r9.wrapping_shl(32)
    or64 r9, r5                                     r9 |= r5   ///  r9 = r9.or(r5)
    mov64 r5, r9                                    r5 = r9
    div64 r5, 10                                    r5 /= 10   ///  r5 = r5 / (10 as u64)
    mov64 r8, r5                                    r8 = r5
    mul64 r8, 10                                    r8 *= 10   ///  r8 = r8.wrapping_mul(10 as u64)
    sub64 r9, r8                                    r9 -= r8   ///  r9 = r9.wrapping_sub(r8)
    mov64 r8, r2                                    r8 = r2
    jeq r9, 0, lbb_33583                            if r9 == (0 as i32 as i64 as u64) { pc += -38 }
lbb_33621:
    ldxdw r2, [r10-0x8]                     
    and64 r2, -2147483648                           r2 &= -2147483648   ///  r2 = r2.and(-2147483648)
    lsh64 r8, 16                                    r8 <<= 16   ///  r8 = r8.wrapping_shl(16)
    or64 r8, r2                                     r8 |= r2   ///  r8 = r8.or(r2)
lbb_33625:
    stxw [r1+0xc], r0                       
    stxw [r1+0x8], r3                       
    stxw [r1+0x4], r4                       
    stxw [r1+0x0], r8                       
    exit                                    

function_33630:
    ldxw r7, [r2+0x4]                       
    ldxw r6, [r2+0xc]                       
    ldxw r4, [r2+0x8]                       
    ldxw r2, [r2+0x0]                       
    lsh64 r2, 32                                    r2 <<= 32   ///  r2 = r2.wrapping_shl(32)
    arsh64 r2, 32                                   r2 >>= 32 (signed)   ///  r2 = (r2 as i64).wrapping_shr(32)
    mov64 r5, r2                                    r5 = r2
    rsh64 r5, 16                                    r5 >>= 16   ///  r5 = r5.wrapping_shr(16)
    and64 r5, 255                                   r5 &= 255   ///  r5 = r5.and(255)
    mov64 r3, r7                                    r3 = r7
    mov64 r0, r6                                    r0 = r6
    mov64 r8, r4                                    r8 = r4
    jeq r5, 0, lbb_33696                            if r5 == (0 as i32 as i64 as u64) { pc += 53 }
    mov64 r9, r6                                    r9 = r6
    or64 r9, r4                                     r9 |= r4   ///  r9 = r9.or(r4)
    or64 r9, r7                                     r9 |= r7   ///  r9 = r9.or(r7)
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
    lsh64 r9, 32                                    r9 <<= 32   ///  r9 = r9.wrapping_shl(32)
    rsh64 r9, 32                                    r9 >>= 32   ///  r9 = r9.wrapping_shr(32)
    mov64 r0, 0                                     r0 = 0 as i32 as i64 as u64
    mov64 r8, 0                                     r8 = 0 as i32 as i64 as u64
    jeq r9, 0, lbb_33696                            if r9 == (0 as i32 as i64 as u64) { pc += 44 }
    mov64 r3, r7                                    r3 = r7
    mov64 r0, r6                                    r0 = r6
lbb_33654:
    mov64 r6, r4                                    r6 = r4
    mov64 r7, r0                                    r7 = r0
    mov64 r4, r3                                    r4 = r3
    lsh64 r6, 32                                    r6 <<= 32   ///  r6 = r6.wrapping_shl(32)
    rsh64 r6, 32                                    r6 >>= 32   ///  r6 = r6.wrapping_shr(32)
    jne r6, 0, lbb_33671                            if r6 != (0 as i32 as i64 as u64) { pc += 11 }
    mov64 r3, r7                                    r3 = r7
    lsh64 r3, 32                                    r3 <<= 32   ///  r3 = r3.wrapping_shl(32)
    rsh64 r3, 32                                    r3 >>= 32   ///  r3 = r3.wrapping_shr(32)
    jne r3, 0, lbb_33671                            if r3 != (0 as i32 as i64 as u64) { pc += 7 }
    mov64 r9, r4                                    r9 = r4
    lsh64 r9, 32                                    r9 <<= 32   ///  r9 = r9.wrapping_shl(32)
    rsh64 r9, 32                                    r9 >>= 32   ///  r9 = r9.wrapping_shr(32)
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
    mov64 r0, 0                                     r0 = 0 as i32 as i64 as u64
    mov64 r8, 0                                     r8 = 0 as i32 as i64 as u64
    jeq r9, 0, lbb_33696                            if r9 == (0 as i32 as i64 as u64) { pc += 25 }
lbb_33671:
    mov64 r3, r4                                    r3 = r4
    lsh64 r3, 32                                    r3 <<= 32   ///  r3 = r3.wrapping_shl(32)
    rsh64 r3, 32                                    r3 >>= 32   ///  r3 = r3.wrapping_shr(32)
    div64 r3, 10                                    r3 /= 10   ///  r3 = r3 / (10 as u64)
    mov64 r0, r3                                    r0 = r3
    mul64 r0, 10                                    r0 *= 10   ///  r0 = r0.wrapping_mul(10 as u64)
    sub64 r4, r0                                    r4 -= r0   ///  r4 = r4.wrapping_sub(r0)
    lsh64 r4, 32                                    r4 <<= 32   ///  r4 = r4.wrapping_shl(32)
    lsh64 r7, 32                                    r7 <<= 32   ///  r7 = r7.wrapping_shl(32)
    rsh64 r7, 32                                    r7 >>= 32   ///  r7 = r7.wrapping_shr(32)
    or64 r4, r7                                     r4 |= r7   ///  r4 = r4.or(r7)
    mov64 r0, r4                                    r0 = r4
    div64 r0, 10                                    r0 /= 10   ///  r0 = r0 / (10 as u64)
    mov64 r7, r0                                    r7 = r0
    mul64 r7, 10                                    r7 *= 10   ///  r7 = r7.wrapping_mul(10 as u64)
    sub64 r4, r7                                    r4 -= r7   ///  r4 = r4.wrapping_sub(r7)
    lsh64 r4, 32                                    r4 <<= 32   ///  r4 = r4.wrapping_shl(32)
    or64 r4, r6                                     r4 |= r6   ///  r4 = r4.or(r6)
    div64 r4, 10                                    r4 /= 10   ///  r4 = r4 / (10 as u64)
    add64 r5, -1                                    r5 += -1   ///  r5 = r5.wrapping_add(-1 as i32 as i64 as u64)
    mov64 r6, r5                                    r6 = r5
    lsh64 r6, 32                                    r6 <<= 32   ///  r6 = r6.wrapping_shl(32)
    rsh64 r6, 32                                    r6 >>= 32   ///  r6 = r6.wrapping_shr(32)
    mov64 r8, r4                                    r8 = r4
    jne r6, 0, lbb_33654                            if r6 != (0 as i32 as i64 as u64) { pc += -42 }
lbb_33696:
    lsh64 r0, 32                                    r0 <<= 32   ///  r0 = r0.wrapping_shl(32)
    lsh64 r8, 32                                    r8 <<= 32   ///  r8 = r8.wrapping_shl(32)
    rsh64 r8, 32                                    r8 >>= 32   ///  r8 = r8.wrapping_shr(32)
    or64 r0, r8                                     r0 |= r8   ///  r0 = r0.or(r8)
    mov64 r4, r0                                    r4 = r0
    neg64 r4                                        r4 = -r4   ///  r4 = (r4 as i64).wrapping_neg() as u64
    mov64 r5, 0                                     r5 = 0 as i32 as i64 as u64
    jsgt r5, r2, lbb_33705                          if (r5 as i64) > (r2 as i64) { pc += 1 }
    mov64 r4, r0                                    r4 = r0
lbb_33705:
    mov64 r6, 1                                     r6 = 1 as i32 as i64 as u64
    mov64 r7, 1                                     r7 = 1 as i32 as i64 as u64
    jne r0, 0, lbb_33709                            if r0 != (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r7, 0                                     r7 = 0 as i32 as i64 as u64
lbb_33709:
    lsh64 r3, 32                                    r3 <<= 32   ///  r3 = r3.wrapping_shl(32)
    rsh64 r3, 32                                    r3 >>= 32   ///  r3 = r3.wrapping_shr(32)
    mov64 r0, r3                                    r0 = r3
    add64 r0, r7                                    r0 += r7   ///  r0 = r0.wrapping_add(r7)
    neg64 r0                                        r0 = -r0   ///  r0 = (r0 as i64).wrapping_neg() as u64
    jsgt r5, r2, lbb_33716                          if (r5 as i64) > (r2 as i64) { pc += 1 }
    mov64 r0, r3                                    r0 = r3
lbb_33716:
    stxdw [r1+0x0], r6                      
    stxdw [r1+0x8], r4                      
    stxdw [r1+0x10], r0                     
    exit                                    

function_33720:
    ldxw r4, [r2+0x0]                       
    lsh64 r4, 32                                    r4 <<= 32   ///  r4 = r4.wrapping_shl(32)
    arsh64 r4, 32                                   r4 >>= 32 (signed)   ///  r4 = (r4 as i64).wrapping_shr(32)
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
    jsgt r3, r4, lbb_33787                          if (r3 as i64) > (r4 as i64) { pc += 62 }
    ldxw r6, [r2+0x4]                       
    ldxw r5, [r2+0xc]                       
    ldxw r2, [r2+0x8]                       
    rsh64 r4, 16                                    r4 >>= 16   ///  r4 = r4.wrapping_shr(16)
    and64 r4, 255                                   r4 &= 255   ///  r4 = r4.and(255)
    jeq r4, 0, lbb_33777                            if r4 == (0 as i32 as i64 as u64) { pc += 46 }
    mov64 r7, r5                                    r7 = r5
    or64 r7, r2                                     r7 |= r2   ///  r7 = r7.or(r2)
    or64 r7, r6                                     r7 |= r6   ///  r7 = r7.or(r6)
    mov64 r0, 0                                     r0 = 0 as i32 as i64 as u64
    lsh64 r7, 32                                    r7 <<= 32   ///  r7 = r7.wrapping_shl(32)
    rsh64 r7, 32                                    r7 >>= 32   ///  r7 = r7.wrapping_shr(32)
    mov64 r8, 0                                     r8 = 0 as i32 as i64 as u64
    jeq r7, 0, lbb_33782                            if r7 == (0 as i32 as i64 as u64) { pc += 43 }
lbb_33739:
    mov64 r7, r2                                    r7 = r2
    mov64 r2, r6                                    r2 = r6
    lsh64 r7, 32                                    r7 <<= 32   ///  r7 = r7.wrapping_shl(32)
    rsh64 r7, 32                                    r7 >>= 32   ///  r7 = r7.wrapping_shr(32)
    jne r7, 0, lbb_33753                            if r7 != (0 as i32 as i64 as u64) { pc += 9 }
    mov64 r6, r5                                    r6 = r5
    lsh64 r6, 32                                    r6 <<= 32   ///  r6 = r6.wrapping_shl(32)
    rsh64 r6, 32                                    r6 >>= 32   ///  r6 = r6.wrapping_shr(32)
    jne r6, 0, lbb_33753                            if r6 != (0 as i32 as i64 as u64) { pc += 5 }
    mov64 r6, r2                                    r6 = r2
    lsh64 r6, 32                                    r6 <<= 32   ///  r6 = r6.wrapping_shl(32)
    rsh64 r6, 32                                    r6 >>= 32   ///  r6 = r6.wrapping_shr(32)
    mov64 r8, 0                                     r8 = 0 as i32 as i64 as u64
    jeq r6, 0, lbb_33782                            if r6 == (0 as i32 as i64 as u64) { pc += 29 }
lbb_33753:
    mov64 r6, r2                                    r6 = r2
    lsh64 r6, 32                                    r6 <<= 32   ///  r6 = r6.wrapping_shl(32)
    rsh64 r6, 32                                    r6 >>= 32   ///  r6 = r6.wrapping_shr(32)
    div64 r6, 10                                    r6 /= 10   ///  r6 = r6 / (10 as u64)
    mov64 r8, r6                                    r8 = r6
    mul64 r8, 10                                    r8 *= 10   ///  r8 = r8.wrapping_mul(10 as u64)
    sub64 r2, r8                                    r2 -= r8   ///  r2 = r2.wrapping_sub(r8)
    lsh64 r2, 32                                    r2 <<= 32   ///  r2 = r2.wrapping_shl(32)
    lsh64 r5, 32                                    r5 <<= 32   ///  r5 = r5.wrapping_shl(32)
    rsh64 r5, 32                                    r5 >>= 32   ///  r5 = r5.wrapping_shr(32)
    or64 r2, r5                                     r2 |= r5   ///  r2 = r2.or(r5)
    mov64 r5, r2                                    r5 = r2
    div64 r5, 10                                    r5 /= 10   ///  r5 = r5 / (10 as u64)
    mov64 r8, r5                                    r8 = r5
    mul64 r8, 10                                    r8 *= 10   ///  r8 = r8.wrapping_mul(10 as u64)
    sub64 r2, r8                                    r2 -= r8   ///  r2 = r2.wrapping_sub(r8)
    lsh64 r2, 32                                    r2 <<= 32   ///  r2 = r2.wrapping_shl(32)
    or64 r2, r7                                     r2 |= r7   ///  r2 = r2.or(r7)
    div64 r2, 10                                    r2 /= 10   ///  r2 = r2 / (10 as u64)
    add64 r4, -1                                    r4 += -1   ///  r4 = r4.wrapping_add(-1 as i32 as i64 as u64)
    mov64 r7, r4                                    r7 = r4
    lsh64 r7, 32                                    r7 <<= 32   ///  r7 = r7.wrapping_shl(32)
    rsh64 r7, 32                                    r7 >>= 32   ///  r7 = r7.wrapping_shr(32)
    jne r7, 0, lbb_33739                            if r7 != (0 as i32 as i64 as u64) { pc += -38 }
lbb_33777:
    lsh64 r6, 32                                    r6 <<= 32   ///  r6 = r6.wrapping_shl(32)
    rsh64 r6, 32                                    r6 >>= 32   ///  r6 = r6.wrapping_shr(32)
    mov64 r0, r2                                    r0 = r2
    mov64 r8, r5                                    r8 = r5
    jne r6, 0, lbb_33787                            if r6 != (0 as i32 as i64 as u64) { pc += 5 }
lbb_33782:
    lsh64 r8, 32                                    r8 <<= 32   ///  r8 = r8.wrapping_shl(32)
    lsh64 r0, 32                                    r0 <<= 32   ///  r0 = r0.wrapping_shl(32)
    rsh64 r0, 32                                    r0 >>= 32   ///  r0 = r0.wrapping_shr(32)
    or64 r8, r0                                     r8 |= r0   ///  r8 = r8.or(r0)
    mov64 r3, 1                                     r3 = 1 as i32 as i64 as u64
lbb_33787:
    stxdw [r1+0x8], r8                      
    stxdw [r1+0x0], r3                      
    exit                                    

function_33790:
    mov64 r7, r2                                    r7 = r2
    mov64 r8, r1                                    r8 = r1
    ldxdw r5, [r7+0x18]                     
    ldxdw r4, [r7+0x10]                     
    mov64 r6, r10                                   r6 = r10
    add64 r6, -56                                   r6 += -56   ///  r6 = r6.wrapping_add(-56 as i32 as i64 as u64)
    mov64 r1, r6                                    r1 = r6
    mov64 r2, r8                                    r2 = r8
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
    call function_37685                     
    mov64 r1, r10                                   r1 = r10
    add64 r1, -92                                   r1 += -92   ///  r1 = r1.wrapping_add(-92 as i32 as i64 as u64)
    mov64 r2, r6                                    r2 = r6
    mov64 r3, 36                                    r3 = 36 as i32 as i64 as u64
    call function_48190                     
    mov64 r3, r10                                   r3 = r10
    add64 r3, -88                                   r3 += -88   ///  r3 = r3.wrapping_add(-88 as i32 as i64 as u64)
    ldxdw r1, [r10-0x10]                    
    jeq r1, 0, lbb_33901                            if r1 == (0 as i32 as i64 as u64) { pc += 92 }
    stxdw [r10-0x70], r3                    
    stxdw [r10-0x80], r8                    
    stxdw [r10-0x78], r7                    
    ldxdw r4, [r10-0x8]                     
    ldxw r6, [r10-0x5c]                     
    mov64 r1, r10                                   r1 = r10
    add64 r1, -56                                   r1 += -56   ///  r1 = r1.wrapping_add(-56 as i32 as i64 as u64)
    mov64 r8, 1                                     r8 = 1 as i32 as i64 as u64
    lddw r2, 0x100062ea5 --> b"0"                   r2 load str located at 4295372453
    mov64 r3, 1                                     r3 = 1 as i32 as i64 as u64
    call function_43495                     
    ldxdw r7, [r10-0x28]                    
    mov64 r9, r6                                    r9 = r6
    add64 r9, r7                                    r9 += r7   ///  r9 = r9.wrapping_add(r7)
    jgt r6, r9, lbb_33826                           if r6 > r9 { pc += 1 }
    mov64 r8, 0                                     r8 = 0 as i32 as i64 as u64
lbb_33826:
    jne r8, 1, lbb_33834                            if r8 != (1 as i32 as i64 as u64) { pc += 7 }
    lddw r1, 0x100062cac --> b"attempt to join into collection with len > usize::MAX"        r1 load str located at 4295371948
    mov64 r2, 53                                    r2 = 53 as i32 as i64 as u64
    lddw r3, 0x1000668b0 --> b"\x00\x00\x00\x00\xe1,\x06\x00Q\x00\x00\x00\x00\x00\x00\x00\x99\x00\x00\x0…        r3 load str located at 4295387312
    call function_44085                     
    syscall [invalid]                       
lbb_33834:
    ldxdw r1, [r10-0x38]                    
    stxdw [r10-0x68], r1                    
    mov64 r8, 1                                     r8 = 1 as i32 as i64 as u64
    jeq r9, 0, lbb_33850                            if r9 == (0 as i32 as i64 as u64) { pc += 12 }
    jsgt r9, -1, lbb_33841                          if (r9 as i64) > (-1 as i32 as i64) { pc += 2 }
    call function_43383                     
    syscall [invalid]                       
lbb_33841:
    mov64 r1, r9                                    r1 = r9
    mov64 r2, 1                                     r2 = 1 as i32 as i64 as u64
    call function_21359                     
    mov64 r8, r0                                    r8 = r0
    jne r8, 0, lbb_33850                            if r8 != (0 as i32 as i64 as u64) { pc += 4 }
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    mov64 r2, r9                                    r2 = r9
    call function_43400                     
    syscall [invalid]                       
lbb_33850:
    mov64 r1, r8                                    r1 = r8
    ldxdw r2, [r10-0x70]                    
    mov64 r3, r6                                    r3 = r6
    call function_48190                     
    mov64 r1, r8                                    r1 = r8
    mov64 r8, r9                                    r8 = r9
    sub64 r8, r6                                    r8 -= r6   ///  r8 = r8.wrapping_sub(r6)
    jge r8, r7, lbb_33865                           if r8 >= r7 { pc += 7 }
    lddw r1, 0x100062c89 --> b"assertion failed: mid <= self.len()"        r1 load str located at 4295371913
    mov64 r2, 35                                    r2 = 35 as i32 as i64 as u64
    lddw r3, 0x1000668c8 --> b"\x00\x00\x00\x00\xe1,\x06\x00Q\x00\x00\x00\x00\x00\x00\x00\xb0\x00\x00\x0…        r3 load str located at 4295387336
    call function_44254                     
    syscall [invalid]                       
lbb_33865:
    stxdw [r10-0x70], r1                    
    add64 r1, r6                                    r1 += r6   ///  r1 = r1.wrapping_add(r6)
    ldxdw r2, [r10-0x68]                    
    mov64 r3, r7                                    r3 = r7
    call function_48190                     
    mov64 r6, r9                                    r6 = r9
    add64 r6, r7                                    r6 += r7   ///  r6 = r6.wrapping_add(r7)
    sub64 r6, r8                                    r6 -= r8   ///  r6 = r6.wrapping_sub(r8)
    ldxdw r2, [r10-0x30]                    
    jeq r2, 0, lbb_33878                            if r2 == (0 as i32 as i64 as u64) { pc += 3 }
    ldxdw r1, [r10-0x68]                    
    mov64 r3, 1                                     r3 = 1 as i32 as i64 as u64
    call function_21385                     
lbb_33878:
    ldxdw r1, [r10-0x80]                    
    ldxw r3, [r1+0x0]                       
    ldxdw r7, [r10-0x70]                    
    stxdw [r10-0x1000], r7                  
    stxdw [r10-0xff8], r6                   
    lsh64 r3, 32                                    r3 <<= 32   ///  r3 = r3.wrapping_shl(32)
    arsh64 r3, 32                                   r3 >>= 32 (signed)   ///  r3 = (r3 as i64).wrapping_shr(32)
    mov64 r2, 1                                     r2 = 1 as i32 as i64 as u64
    ldxdw r1, [r10-0x78]                    
    jsgt r3, -1, lbb_33889                          if (r3 as i64) > (-1 as i32 as i64) { pc += 1 }
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
lbb_33889:
    mov64 r5, r10                                   r5 = r10
    lddw r3, 0x100062c08 --> b"invalid args/home/runner/work/platform-tools/platf"        r3 load str located at 4295371784
    mov64 r4, 0                                     r4 = 0 as i32 as i64 as u64
    call function_45507                     
    mov64 r6, r0                                    r6 = r0
    jeq r9, 0, lbb_33917                            if r9 == (0 as i32 as i64 as u64) { pc += 21 }
    mov64 r1, r7                                    r1 = r7
    mov64 r2, r9                                    r2 = r9
    mov64 r3, 1                                     r3 = 1 as i32 as i64 as u64
    call function_21385                     
    ja lbb_33917                                    if true { pc += 16 }
lbb_33901:
    ldxw r1, [r8+0x0]                       
    ldxw r2, [r10-0x5c]                     
    stxdw [r10-0x1000], r3                  
    stxdw [r10-0xff8], r2                   
    lsh64 r1, 32                                    r1 <<= 32   ///  r1 = r1.wrapping_shl(32)
    arsh64 r1, 32                                   r1 >>= 32 (signed)   ///  r1 = (r1 as i64).wrapping_shr(32)
    mov64 r2, 1                                     r2 = 1 as i32 as i64 as u64
    jsgt r1, -1, lbb_33910                          if (r1 as i64) > (-1 as i32 as i64) { pc += 1 }
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
lbb_33910:
    mov64 r5, r10                                   r5 = r10
    mov64 r1, r7                                    r1 = r7
    lddw r3, 0x100062c08 --> b"invalid args/home/runner/work/platform-tools/platf"        r3 load str located at 4295371784
    mov64 r4, 0                                     r4 = 0 as i32 as i64 as u64
    call function_45507                     
    mov64 r6, r0                                    r6 = r0
lbb_33917:
    mov64 r0, r6                                    r0 = r6
    exit                                    

function_33919:
    call function_33790                     
    exit                                    

function_33921:
    mov64 r3, r2                                    r3 = r2
    mov64 r6, r1                                    r6 = r1
    mov64 r1, r10                                   r1 = r10
    add64 r1, -68                                   r1 += -68   ///  r1 = r1.wrapping_add(-68 as i32 as i64 as u64)
    mov64 r7, 1                                     r7 = 1 as i32 as i64 as u64
    mov64 r2, r6                                    r2 = r6
    mov64 r4, 1                                     r4 = 1 as i32 as i64 as u64
    call function_34125                     
    ldxw r1, [r10-0x44]                     
    jeq r1, 0, lbb_33947                            if r1 == (0 as i32 as i64 as u64) { pc += 16 }
    stxdw [r10-0x28], r7                    
    lddw r1, 0x100066978 --> b"\x00\x00\x00\x00x.\x06\x00\x16\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x0…        r1 load str located at 4295387512
    stxdw [r10-0x30], r1                    
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    stxdw [r10-0x10], r1                    
    stxdw [r10-0x18], r1                    
    lddw r1, 0x100062c08 --> b"invalid args/home/runner/work/platform-tools/platf"        r1 load str located at 4295371784
    stxdw [r10-0x20], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -48                                   r1 += -48   ///  r1 = r1.wrapping_add(-48 as i32 as i64 as u64)
    lddw r2, 0x100066988 --> b"\x00\x00\x00\x00\x8e.\x06\x00\x17\x00\x00\x00\x00\x00\x00\x00\x03\x01\x00…        r2 load str located at 4295387528
    call function_44240                     
    syscall [invalid]                       
lbb_33947:
    ldxdw r1, [r10-0x40]                    
    ldxdw r2, [r10-0x38]                    
    stxdw [r6+0x8], r2                      
    stxdw [r6+0x0], r1                      
    exit                                    

function_33952:
    ldxw r7, [r1+0x4]                       
    ldxw r5, [r1+0x8]                       
    ldxw r0, [r1+0xc]                       
    mov64 r8, r0                                    r8 = r0
    or64 r8, r5                                     r8 |= r5   ///  r8 = r8.or(r5)
    or64 r8, r7                                     r8 |= r7   ///  r8 = r8.or(r7)
    ldxw r6, [r2+0x4]                       
    ldxw r3, [r2+0x8]                       
    ldxw r4, [r2+0xc]                       
    mov64 r9, r4                                    r9 = r4
    or64 r9, r3                                     r9 |= r3   ///  r9 = r9.or(r3)
    or64 r9, r6                                     r9 |= r6   ///  r9 = r9.or(r6)
    lsh64 r9, 32                                    r9 <<= 32   ///  r9 = r9.wrapping_shl(32)
    rsh64 r9, 32                                    r9 >>= 32   ///  r9 = r9.wrapping_shr(32)
    jne r9, 0, lbb_33978                            if r9 != (0 as i32 as i64 as u64) { pc += 11 }
    mov64 r0, 0                                     r0 = 0 as i32 as i64 as u64
    lsh64 r8, 32                                    r8 <<= 32   ///  r8 = r8.wrapping_shl(32)
    rsh64 r8, 32                                    r8 >>= 32   ///  r8 = r8.wrapping_shr(32)
    jeq r8, 0, lbb_34038                            if r8 == (0 as i32 as i64 as u64) { pc += 67 }
    ldxw r1, [r1+0x0]                       
    lsh64 r1, 32                                    r1 <<= 32   ///  r1 = r1.wrapping_shl(32)
    arsh64 r1, 32                                   r1 >>= 32 (signed)   ///  r1 = (r1 as i64).wrapping_shr(32)
    mov64 r0, 1                                     r0 = 1 as i32 as i64 as u64
    jsgt r1, -1, lbb_34038                          if (r1 as i64) > (-1 as i32 as i64) { pc += 62 }
    mov64 r0, -1                                    r0 = -1 as i32 as i64 as u64
    ja lbb_34038                                    if true { pc += 60 }
lbb_33978:
    lsh64 r8, 32                                    r8 <<= 32   ///  r8 = r8.wrapping_shl(32)
    rsh64 r8, 32                                    r8 >>= 32   ///  r8 = r8.wrapping_shr(32)
    jeq r8, 0, lbb_34026                            if r8 == (0 as i32 as i64 as u64) { pc += 45 }
    ldxw r2, [r2+0x0]                       
    ldxw r1, [r1+0x0]                       
    lsh64 r1, 32                                    r1 <<= 32   ///  r1 = r1.wrapping_shl(32)
    arsh64 r1, 32                                   r1 >>= 32 (signed)   ///  r1 = (r1 as i64).wrapping_shr(32)
    mov64 r9, r2                                    r9 = r2
    xor64 r9, r1                                    r9 ^= r1   ///  r9 = r9.xor(r1)
    lsh64 r9, 32                                    r9 <<= 32   ///  r9 = r9.wrapping_shl(32)
    arsh64 r9, 32                                   r9 >>= 32 (signed)   ///  r9 = (r9 as i64).wrapping_shr(32)
    mov64 r8, 0                                     r8 = 0 as i32 as i64 as u64
    jsgt r8, r9, lbb_34023                          if (r8 as i64) > (r9 as i64) { pc += 32 }
    stxw [r10-0x24], r7                     
    mov64 r7, r1                                    r7 = r1
    rsh64 r7, 16                                    r7 >>= 16   ///  r7 = r7.wrapping_shr(16)
    and64 r7, 255                                   r7 &= 255   ///  r7 = r7.and(255)
    stxw [r10-0x28], r7                     
    lddw r7, 0x80000000                             r7 load str located at 2147483648
    mov64 r8, r1                                    r8 = r1
    and64 r8, r7                                    r8 &= r7   ///  r8 = r8.and(r7)
    rsh64 r8, 31                                    r8 >>= 31   ///  r8 = r8.wrapping_shr(31)
    stxb [r10-0x20], r8                     
    lsh64 r0, 32                                    r0 <<= 32   ///  r0 = r0.wrapping_shl(32)
    or64 r0, r5                                     r0 |= r5   ///  r0 = r0.or(r5)
    stxdw [r10-0x30], r0                    
    stxw [r10-0xc], r6                      
    mov64 r5, r2                                    r5 = r2
    and64 r5, r7                                    r5 &= r7   ///  r5 = r5.and(r7)
    rsh64 r2, 16                                    r2 >>= 16   ///  r2 = r2.wrapping_shr(16)
    and64 r2, 255                                   r2 &= 255   ///  r2 = r2.and(255)
    stxw [r10-0x10], r2                     
    rsh64 r5, 31                                    r5 >>= 31   ///  r5 = r5.wrapping_shr(31)
    stxb [r10-0x8], r5                      
    lsh64 r4, 32                                    r4 <<= 32   ///  r4 = r4.wrapping_shl(32)
    or64 r4, r3                                     r4 |= r3   ///  r4 = r4.or(r3)
    stxdw [r10-0x18], r4                    
    jsgt r1, -1, lbb_34018                          if (r1 as i64) > (-1 as i32 as i64) { pc += 1 }
    ja lbb_34033                                    if true { pc += 15 }
lbb_34018:
    mov64 r1, r10                                   r1 = r10
    add64 r1, -48                                   r1 += -48   ///  r1 = r1.wrapping_add(-48 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -24                                   r2 += -24   ///  r2 = r2.wrapping_add(-24 as i32 as i64 as u64)
    ja lbb_34037                                    if true { pc += 14 }
lbb_34023:
    mov64 r0, -1                                    r0 = -1 as i32 as i64 as u64
    jsgt r8, r1, lbb_34038                          if (r8 as i64) > (r1 as i64) { pc += 13 }
    ja lbb_34031                                    if true { pc += 5 }
lbb_34026:
    ldxw r1, [r2+0x0]                       
    lsh64 r1, 32                                    r1 <<= 32   ///  r1 = r1.wrapping_shl(32)
    arsh64 r1, 32                                   r1 >>= 32 (signed)   ///  r1 = (r1 as i64).wrapping_shr(32)
    mov64 r0, -1                                    r0 = -1 as i32 as i64 as u64
    jsgt r1, -1, lbb_34038                          if (r1 as i64) > (-1 as i32 as i64) { pc += 7 }
lbb_34031:
    mov64 r0, 1                                     r0 = 1 as i32 as i64 as u64
    ja lbb_34038                                    if true { pc += 5 }
lbb_34033:
    mov64 r1, r10                                   r1 = r10
    add64 r1, -24                                   r1 += -24   ///  r1 = r1.wrapping_add(-24 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -48                                   r2 += -48   ///  r2 = r2.wrapping_add(-48 as i32 as i64 as u64)
lbb_34037:
    call function_35260                     
lbb_34038:
    exit                                    

function_34039:
    mov64 r4, r2                                    r4 = r2
    ldxw r2, [r1+0x0]                       
    jsgt r2, 2, lbb_34049                           if (r2 as i64) > (2 as i32 as i64) { pc += 7 }
    jeq r2, 0, lbb_34067                            if r2 == (0 as i32 as i64 as u64) { pc += 24 }
    jeq r2, 1, lbb_34072                            if r2 == (1 as i32 as i64 as u64) { pc += 28 }
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    stxdw [r10-0x88], r1                    
    lddw r1, 0x1000669b0 --> b"\x00\x00\x00\x00\xdb.\x06\x007\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x0…        r1 load str located at 4295387568
    ja lbb_34081                                    if true { pc += 32 }
lbb_34049:
    jeq r2, 3, lbb_34077                            if r2 == (3 as i32 as i64 as u64) { pc += 27 }
    jeq r2, 4, lbb_34089                            if r2 == (4 as i32 as i64 as u64) { pc += 38 }
    add64 r1, 8                                     r1 += 8   ///  r1 = r1.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x98], r1                    
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    stxdw [r10-0x70], r1                    
    lddw r1, 0x1000669f0 --> b"\x00\x00\x00\x00z/\x06\x00\x1a\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x0…        r1 load str located at 4295387632
    stxdw [r10-0x90], r1                    
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    stxdw [r10-0x88], r1                    
    stxdw [r10-0x78], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -184                                  r1 += -184   ///  r1 = r1.wrapping_add(-184 as i32 as i64 as u64)
    stxdw [r10-0x80], r1                    
    lddw r1, 0x100040990 --> b"\xbf#\x00\x00\x00\x00\x00\x00y\x11\x00\x00\x00\x00\x00\x00y\x12\x10\x00\x…        r1 load str located at 4295231888
    ja lbb_34110                                    if true { pc += 43 }
lbb_34067:
    ldxdw r3, [r1+0x18]                     
    ldxdw r2, [r1+0x8]                      
    mov64 r1, r4                                    r1 = r4
    call function_45728                     
    ja lbb_34118                                    if true { pc += 46 }
lbb_34072:
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    stxdw [r10-0x88], r1                    
    lddw r1, 0x1000669a0 --> b"\x00\x00\x00\x00\xa6.\x06\x005\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x0…        r1 load str located at 4295387552
    ja lbb_34081                                    if true { pc += 4 }
lbb_34077:
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    stxdw [r10-0x88], r1                    
    lddw r1, 0x1000669c0 --> b"\x00\x00\x00\x00\x12/\x06\x008\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x0…        r1 load str located at 4295387584
lbb_34081:
    stxdw [r10-0x90], r1                    
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    stxdw [r10-0x70], r1                    
    stxdw [r10-0x78], r1                    
    lddw r1, 0x100062c08 --> b"invalid args/home/runner/work/platform-tools/platf"        r1 load str located at 4295371784
    stxdw [r10-0x80], r1                    
    ja lbb_34114                                    if true { pc += 25 }
lbb_34089:
    add64 r1, 4                                     r1 += 4   ///  r1 = r1.wrapping_add(4 as i32 as i64 as u64)
    stxdw [r10-0x98], r1                    
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    stxdw [r10-0x70], r1                    
    lddw r1, 0x1000669d0 --> b"\x00\x00\x00\x00J/\x06\x00-\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00w/…        r1 load str located at 4295387600
    stxdw [r10-0x90], r1                    
    mov64 r1, 2                                     r1 = 2 as i32 as i64 as u64
    stxdw [r10-0x88], r1                    
    stxdw [r10-0x78], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -184                                  r1 += -184   ///  r1 = r1.wrapping_add(-184 as i32 as i64 as u64)
    stxdw [r10-0x80], r1                    
    lddw r1, 0x10005df30 --> b"\xbf#\x00\x00\x00\x00\x00\x00a\x11\x00\x00\x00\x00\x00\x00\xb7\x02\x00\x0…        r1 load str located at 4295352112
    stxdw [r10-0xa0], r1                    
    lddw r1, 0x10005fbb4 --> b"\x1c\x00\x00\x00GoodKindkindbids != Some <= x1e-true to None  "        r1 load str located at 4295359412
    stxdw [r10-0xa8], r1                    
    lddw r1, 0x100040978 --> b"y\x11\x00\x00\x00\x00\x00\x00\x85\x10\x00\x00\xb5:\x00\x00\x95\x00\x00\x0…        r1 load str located at 4295231864
lbb_34110:
    stxdw [r10-0xb0], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -152                                  r1 += -152   ///  r1 = r1.wrapping_add(-152 as i32 as i64 as u64)
    stxdw [r10-0xb8], r1                    
lbb_34114:
    mov64 r2, r10                                   r2 = r10
    add64 r2, -144                                  r2 += -144   ///  r2 = r2.wrapping_add(-144 as i32 as i64 as u64)
    mov64 r1, r4                                    r1 = r4
    call function_45907                     
lbb_34118:
    exit                                    

function_34119:
    mov64 r4, 0                                     r4 = 0 as i32 as i64 as u64
    call function_34125                     
    exit                                    

function_34122:
    mov64 r4, 1                                     r4 = 1 as i32 as i64 as u64
    call function_34125                     
    exit                                    

function_34125:
    mov64 r5, r4                                    r5 = r4
    mov64 r4, r3                                    r4 = r3
    mov64 r6, r2                                    r6 = r2
    ldxw r7, [r6+0x4]                       
    ldxw r2, [r6+0xc]                       
    mov64 r3, r7                                    r3 = r7
    or64 r3, r2                                     r3 |= r2   ///  r3 = r3.or(r2)
    ldxw r9, [r6+0x8]                       
    mov64 r0, r3                                    r0 = r3
    or64 r0, r9                                     r0 |= r9   ///  r0 = r0.or(r9)
    lsh64 r0, 32                                    r0 <<= 32   ///  r0 = r0.wrapping_shl(32)
    rsh64 r0, 32                                    r0 >>= 32   ///  r0 = r0.wrapping_shr(32)
    jne r0, 0, lbb_34157                            if r0 != (0 as i32 as i64 as u64) { pc += 19 }
    mov64 r0, r4                                    r0 = r4
    add64 r0, 4                                     r0 += 4   ///  r0 = r0.wrapping_add(4 as i32 as i64 as u64)
    ldxw r2, [r4+0x0]                       
    lsh64 r2, 32                                    r2 <<= 32   ///  r2 = r2.wrapping_shl(32)
    arsh64 r2, 32                                   r2 >>= 32 (signed)   ///  r2 = (r2 as i64).wrapping_shr(32)
    jne r5, 0, lbb_34145                            if r5 != (0 as i32 as i64 as u64) { pc += 1 }
    ja lbb_34269                                    if true { pc += 124 }
lbb_34145:
    ldxw r3, [r4+0x8]                       
    ldxw r5, [r4+0xc]                       
    or64 r5, r3                                     r5 |= r3   ///  r5 = r5.or(r3)
    ldxw r3, [r4+0x4]                       
    or64 r5, r3                                     r5 |= r3   ///  r5 = r5.or(r3)
    lsh64 r5, 32                                    r5 <<= 32   ///  r5 = r5.wrapping_shl(32)
    rsh64 r5, 32                                    r5 >>= 32   ///  r5 = r5.wrapping_shr(32)
    jeq r5, 0, lbb_34269                            if r5 == (0 as i32 as i64 as u64) { pc += 116 }
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
    jsgt r3, r2, lbb_34268                          if (r3 as i64) > (r2 as i64) { pc += 113 }
    or64 r2, -2147483648                            r2 |= -2147483648   ///  r2 = r2.or(-2147483648)
    ja lbb_34269                                    if true { pc += 112 }
lbb_34157:
    stxdw [r10-0x48], r7                    
    ldxw r7, [r4+0x4]                       
    ldxw r0, [r4+0xc]                       
    stxdw [r10-0x40], r7                    
    or64 r7, r0                                     r7 |= r0   ///  r7 = r7.or(r0)
    ldxw r8, [r4+0x8]                       
    or64 r7, r8                                     r7 |= r8   ///  r7 = r7.or(r8)
    lsh64 r7, 32                                    r7 <<= 32   ///  r7 = r7.wrapping_shl(32)
    rsh64 r7, 32                                    r7 >>= 32   ///  r7 = r7.wrapping_shr(32)
    jeq r7, 0, lbb_34214                            if r7 == (0 as i32 as i64 as u64) { pc += 47 }
    stxdw [r10-0x50], r9                    
    stxdw [r10-0x38], r8                    
    stxdw [r10-0x60], r1                    
    ldxw r9, [r4+0x0]                       
    ldxw r4, [r6+0x0]                       
    lsh64 r4, 32                                    r4 <<= 32   ///  r4 = r4.wrapping_shl(32)
    arsh64 r4, 32                                   r4 >>= 32 (signed)   ///  r4 = (r4 as i64).wrapping_shr(32)
    mov64 r1, r9                                    r1 = r9
    xor64 r1, r4                                    r1 ^= r4   ///  r1 = r1.xor(r4)
    mov64 r7, r1                                    r7 = r1
    lsh64 r7, 32                                    r7 <<= 32   ///  r7 = r7.wrapping_shl(32)
    arsh64 r7, 32                                   r7 >>= 32 (signed)   ///  r7 = (r7 as i64).wrapping_shr(32)
    mov64 r6, 1                                     r6 = 1 as i32 as i64 as u64
    mov64 r8, 0                                     r8 = 0 as i32 as i64 as u64
    jsgt r8, r7, lbb_34183                          if (r8 as i64) > (r7 as i64) { pc += 1 }
    mov64 r6, 0                                     r6 = 0 as i32 as i64 as u64
lbb_34183:
    or64 r3, r0                                     r3 |= r0   ///  r3 = r3.or(r0)
    xor64 r6, r5                                    r6 ^= r5   ///  r6 = r6.xor(r5)
    stxdw [r10-0x58], r6                    
    ldxdw r6, [r10-0x40]                    
    or64 r3, r6                                     r3 |= r6   ///  r3 = r3.or(r6)
    and64 r1, 16711680                              r1 &= 16711680   ///  r1 = r1.and(16711680)
    lsh64 r3, 32                                    r3 <<= 32   ///  r3 = r3.wrapping_shl(32)
    rsh64 r3, 32                                    r3 >>= 32   ///  r3 = r3.wrapping_shr(32)
    ldxdw r5, [r10-0x38]                    
    jne r3, 0, lbb_34294                            if r3 != (0 as i32 as i64 as u64) { pc += 101 }
    jne r1, 0, lbb_34219                            if r1 != (0 as i32 as i64 as u64) { pc += 25 }
    ldxdw r1, [r10-0x58]                    
    and64 r1, 1                                     r1 &= 1   ///  r1 = r1.and(1)
    jne r1, 0, lbb_34375                            if r1 != (0 as i32 as i64 as u64) { pc += 178 }
    ldxdw r0, [r10-0x50]                    
    ldxdw r3, [r10-0x38]                    
    add64 r3, r0                                    r3 += r0   ///  r3 = r3.wrapping_add(r0)
    stxdw [r10-0x38], r3                    
    lsh64 r3, 32                                    r3 <<= 32   ///  r3 = r3.wrapping_shl(32)
    rsh64 r3, 32                                    r3 >>= 32   ///  r3 = r3.wrapping_shr(32)
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    jgt r0, r3, lbb_34206                           if r0 > r3 { pc += 1 }
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
lbb_34206:
    mov64 r2, r4                                    r2 = r4
    and64 r2, 16711680                              r2 &= 16711680   ///  r2 = r2.and(16711680)
    ldxdw r5, [r10-0x60]                    
    jge r3, r0, lbb_34211                           if r3 >= r0 { pc += 1 }
    mov64 r2, r4                                    r2 = r4
lbb_34211:
    jeq r3, 0, lbb_34396                            if r3 == (0 as i32 as i64 as u64) { pc += 184 }
    mov64 r2, r4                                    r2 = r4
    ja lbb_34396                                    if true { pc += 182 }
lbb_34214:
    ldxdw r2, [r6+0x8]                      
    stxdw [r1+0xc], r2                      
    ldxdw r2, [r6+0x0]                      
    stxdw [r1+0x4], r2                      
    ja lbb_34274                                    if true { pc += 55 }
lbb_34219:
    mov64 r8, r4                                    r8 = r4
    and64 r8, 16711680                              r8 &= 16711680   ///  r8 = r8.and(16711680)
    mov64 r6, r9                                    r6 = r9
    and64 r6, 16711680                              r6 &= 16711680   ///  r6 = r6.and(16711680)
    mov64 r5, r6                                    r5 = r6
    sub64 r5, r8                                    r5 -= r8   ///  r5 = r5.wrapping_sub(r8)
    mov64 r3, r5                                    r3 = r5
    arsh64 r3, 16                                   r3 >>= 16 (signed)   ///  r3 = (r3 as i64).wrapping_shr(16)
    mov64 r7, 0                                     r7 = 0 as i32 as i64 as u64
    jsgt r7, r5, lbb_34277                          if (r7 as i64) > (r5 as i64) { pc += 48 }
    mov64 r7, r6                                    r7 = r6
    ldxdw r6, [r10-0x40]                    
    jgt r5, 589824, lbb_34294                       if r5 > (589824 as i32 as i64 as u64) { pc += 62 }
    lsh64 r3, 32                                    r3 <<= 32   ///  r3 = r3.wrapping_shl(32)
    rsh64 r3, 32                                    r3 >>= 32   ///  r3 = r3.wrapping_shr(32)
    lsh64 r3, 2                                     r3 <<= 2   ///  r3 = r3.wrapping_shl(2)
    lddw r5, 0x100062e50 --> b"\x01\x00\x00\x00\x0a\x00\x00\x00d\x00\x00\x00\xe8\x03\x00\x00\x10'\x00\x0…        r5 load str located at 4295372368
    add64 r5, r3                                    r5 += r3   ///  r5 = r5.wrapping_add(r3)
    ldxw r5, [r5+0x0]                       
    ldxdw r3, [r10-0x50]                    
    mul64 r3, r5                                    r3 *= r5   ///  r3 = r3.wrapping_mul(r5)
    mov64 r5, r3                                    r5 = r3
    rsh64 r5, 32                                    r5 >>= 32   ///  r5 = r5.wrapping_shr(32)
    jne r5, 0, lbb_34294                            if r5 != (0 as i32 as i64 as u64) { pc += 50 }
    and64 r4, -2147483648                           r4 &= -2147483648   ///  r4 = r4.and(-2147483648)
    mov64 r6, r7                                    r6 = r7
    mov64 r1, r6                                    r1 = r6
    or64 r1, r4                                     r1 |= r4   ///  r1 = r1.or(r4)
    ldxdw r2, [r10-0x58]                    
    and64 r2, 1                                     r2 &= 1   ///  r2 = r2.and(1)
    jne r2, 0, lbb_34418                            if r2 != (0 as i32 as i64 as u64) { pc += 167 }
    mov64 r2, r3                                    r2 = r3
    ldxdw r4, [r10-0x38]                    
    add64 r2, r4                                    r2 += r4   ///  r2 = r2.wrapping_add(r4)
    mov64 r0, r2                                    r0 = r2
    lsh64 r0, 32                                    r0 <<= 32   ///  r0 = r0.wrapping_shl(32)
    rsh64 r0, 32                                    r0 >>= 32   ///  r0 = r0.wrapping_shr(32)
    lsh64 r3, 32                                    r3 <<= 32   ///  r3 = r3.wrapping_shl(32)
    rsh64 r3, 32                                    r3 >>= 32   ///  r3 = r3.wrapping_shr(32)
    mov64 r4, 1                                     r4 = 1 as i32 as i64 as u64
    jgt r3, r0, lbb_34262                           if r3 > r0 { pc += 1 }
    mov64 r4, 0                                     r4 = 0 as i32 as i64 as u64
lbb_34262:
    ldxdw r5, [r10-0x60]                    
    jge r0, r3, lbb_34265                           if r0 >= r3 { pc += 1 }
    mov64 r6, r1                                    r6 = r1
lbb_34265:
    jeq r0, 0, lbb_34448                            if r0 == (0 as i32 as i64 as u64) { pc += 182 }
    mov64 r6, r1                                    r6 = r1
    ja lbb_34448                                    if true { pc += 180 }
lbb_34268:
    and64 r2, 1342177279                            r2 &= 1342177279   ///  r2 = r2.and(1342177279)
lbb_34269:
    stxw [r1+0x4], r2                       
    ldxdw r2, [r0+0x0]                      
    stxdw [r1+0x8], r2                      
    ldxw r2, [r0+0x8]                       
    stxw [r1+0x10], r2                      
lbb_34274:
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
    stxw [r1+0x0], r2                       
lbb_34276:
    exit                                    
lbb_34277:
    mov64 r7, -589824                               r7 = -589824 as i32 as i64 as u64
    ldxdw r6, [r10-0x40]                    
    jgt r7, r5, lbb_34294                           if r7 > r5 { pc += 14 }
    neg64 r3                                        r3 = -r3   ///  r3 = (r3 as i64).wrapping_neg() as u64
    lsh64 r3, 32                                    r3 <<= 32   ///  r3 = r3.wrapping_shl(32)
    rsh64 r3, 32                                    r3 >>= 32   ///  r3 = r3.wrapping_shr(32)
    lsh64 r3, 2                                     r3 <<= 2   ///  r3 = r3.wrapping_shl(2)
    lddw r5, 0x100062e50 --> b"\x01\x00\x00\x00\x0a\x00\x00\x00d\x00\x00\x00\xe8\x03\x00\x00\x10'\x00\x0…        r5 load str located at 4295372368
    add64 r5, r3                                    r5 += r3   ///  r5 = r5.wrapping_add(r3)
    ldxw r3, [r5+0x0]                       
    ldxdw r5, [r10-0x38]                    
    mul64 r5, r3                                    r5 *= r3   ///  r5 = r5.wrapping_mul(r3)
    mov64 r3, r5                                    r3 = r5
    rsh64 r3, 32                                    r3 >>= 32   ///  r3 = r3.wrapping_shr(32)
    jne r3, 0, lbb_34294                            if r3 != (0 as i32 as i64 as u64) { pc += 1 }
    ja lbb_34401                                    if true { pc += 107 }
lbb_34294:
    ldxdw r3, [r10-0x48]                    
    stxw [r10-0x24], r3                     
    lddw r5, 0x80000000                             r5 load str located at 2147483648
    mov64 r8, r4                                    r8 = r4
    and64 r8, r5                                    r8 &= r5   ///  r8 = r8.and(r5)
    rsh64 r8, 31                                    r8 >>= 31   ///  r8 = r8.wrapping_shr(31)
    stxb [r10-0x20], r8                     
    mov64 r7, r9                                    r7 = r9
    and64 r7, r5                                    r7 &= r5   ///  r7 = r7.and(r5)
    rsh64 r7, 31                                    r7 >>= 31   ///  r7 = r7.wrapping_shr(31)
    stxb [r10-0x8], r7                      
    lsh64 r2, 32                                    r2 <<= 32   ///  r2 = r2.wrapping_shl(32)
    ldxdw r5, [r10-0x50]                    
    or64 r2, r5                                     r2 |= r5   ///  r2 = r2.or(r5)
    lsh64 r0, 32                                    r0 <<= 32   ///  r0 = r0.wrapping_shl(32)
    ldxdw r5, [r10-0x38]                    
    or64 r0, r5                                     r0 |= r5   ///  r0 = r0.or(r5)
    stxw [r10-0xc], r6                      
    rsh64 r9, 16                                    r9 >>= 16   ///  r9 = r9.wrapping_shr(16)
    and64 r9, 255                                   r9 &= 255   ///  r9 = r9.and(255)
    stxw [r10-0x10], r9                     
    stxdw [r10-0x18], r0                    
    mov64 r5, r4                                    r5 = r4
    rsh64 r5, 16                                    r5 >>= 16   ///  r5 = r5.wrapping_shr(16)
    and64 r5, 255                                   r5 &= 255   ///  r5 = r5.and(255)
    stxw [r10-0x28], r5                     
    stxdw [r10-0x30], r2                    
    jne r1, 0, lbb_34334                            if r1 != (0 as i32 as i64 as u64) { pc += 11 }
    stxdw [r10-0xff0], r5                   
    ldxdw r1, [r10-0x58]                    
    and64 r1, 1                                     r1 &= 1   ///  r1 = r1.and(1)
    stxdw [r10-0xfe8], r1                   
    stxdw [r10-0x1000], r6                  
    stxdw [r10-0xff8], r8                   
    mov64 r5, r10                                   r5 = r10
    ldxdw r1, [r10-0x60]                    
    mov64 r4, r0                                    r4 = r0
    call function_34467                     
    ja lbb_34276                                    if true { pc += -58 }
lbb_34334:
    mov64 r2, r9                                    r2 = r9
    sub64 r2, r5                                    r2 -= r5   ///  r2 = r2.wrapping_sub(r5)
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
    jsgt r3, r2, lbb_34355                          if (r3 as i64) > (r2 as i64) { pc += 17 }
    stxdw [r10-0xff8], r2                   
    ldxdw r1, [r10-0x58]                    
    and64 r1, 1                                     r1 &= 1   ///  r1 = r1.and(1)
    stxdw [r10-0xff0], r1                   
    stxdw [r10-0x1000], r9                  
    lddw r1, 0x80000000                             r1 load str located at 2147483648
    and64 r4, r1                                    r4 &= r1   ///  r4 = r4.and(r1)
    rsh64 r4, 31                                    r4 >>= 31   ///  r4 = r4.wrapping_shr(31)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -48                                   r2 += -48   ///  r2 = r2.wrapping_add(-48 as i32 as i64 as u64)
    mov64 r3, r10                                   r3 = r10
    add64 r3, -24                                   r3 += -24   ///  r3 = r3.wrapping_add(-24 as i32 as i64 as u64)
    mov64 r5, r10                                   r5 = r10
    ldxdw r1, [r10-0x60]                    
    call function_34713                     
    ja lbb_34276                                    if true { pc += -79 }
lbb_34355:
    mov64 r0, 1                                     r0 = 1 as i32 as i64 as u64
    ldxdw r1, [r10-0x60]                    
    ldxdw r6, [r10-0x58]                    
    jsgt r3, r4, lbb_34360                          if (r3 as i64) > (r4 as i64) { pc += 1 }
    mov64 r0, 0                                     r0 = 0 as i32 as i64 as u64
lbb_34360:
    neg64 r2                                        r2 = -r2   ///  r2 = (r2 as i64).wrapping_neg() as u64
    stxdw [r10-0xff8], r2                   
    xor64 r0, r6                                    r0 ^= r6   ///  r0 = r0.xor(r6)
    and64 r6, 1                                     r6 &= 1   ///  r6 = r6.and(1)
    stxdw [r10-0xff0], r6                   
    stxdw [r10-0x1000], r5                  
    and64 r0, 1                                     r0 &= 1   ///  r0 = r0.and(1)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -24                                   r2 += -24   ///  r2 = r2.wrapping_add(-24 as i32 as i64 as u64)
    mov64 r3, r10                                   r3 = r10
    add64 r3, -48                                   r3 += -48   ///  r3 = r3.wrapping_add(-48 as i32 as i64 as u64)
    mov64 r5, r10                                   r5 = r10
    mov64 r4, r0                                    r4 = r0
    call function_34713                     
    ja lbb_34276                                    if true { pc += -99 }
lbb_34375:
    ldxdw r3, [r10-0x50]                    
    ldxdw r1, [r10-0x38]                    
    jgt r1, r3, lbb_34389                           if r1 > r3 { pc += 11 }
    mov64 r2, r4                                    r2 = r4
    and64 r2, 16711680                              r2 &= 16711680   ///  r2 = r2.and(16711680)
    ldxdw r5, [r10-0x60]                    
    ldxdw r1, [r10-0x38]                    
    jeq r3, r1, lbb_34384                           if r3 == r1 { pc += 1 }
    mov64 r2, r4                                    r2 = r4
lbb_34384:
    ldxdw r1, [r10-0x38]                    
    sub64 r3, r1                                    r3 -= r1   ///  r3 = r3.wrapping_sub(r1)
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    stxdw [r10-0x38], r3                    
    ja lbb_34396                                    if true { pc += 7 }
lbb_34389:
    ldxdw r1, [r10-0x38]                    
    sub64 r1, r3                                    r1 -= r3   ///  r1 = r1.wrapping_sub(r3)
    stxdw [r10-0x38], r1                    
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    xor64 r4, -2147483648                           r4 ^= -2147483648   ///  r4 = r4.xor(-2147483648)
    mov64 r2, r4                                    r2 = r4
    ldxdw r5, [r10-0x60]                    
lbb_34396:
    stxw [r5+0x10], r1                      
    ldxdw r1, [r10-0x38]                    
    stxw [r5+0xc], r1                       
    stxw [r5+0x4], r2                       
    ja lbb_34451                                    if true { pc += 50 }
lbb_34401:
    ldxdw r1, [r10-0x58]                    
    and64 r1, 1                                     r1 &= 1   ///  r1 = r1.and(1)
    jne r1, 0, lbb_34431                            if r1 != (0 as i32 as i64 as u64) { pc += 27 }
    ldxdw r0, [r10-0x50]                    
    add64 r5, r0                                    r5 += r0   ///  r5 = r5.wrapping_add(r0)
    mov64 r2, r5                                    r2 = r5
    lsh64 r2, 32                                    r2 <<= 32   ///  r2 = r2.wrapping_shl(32)
    rsh64 r2, 32                                    r2 >>= 32   ///  r2 = r2.wrapping_shr(32)
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    jgt r0, r2, lbb_34412                           if r0 > r2 { pc += 1 }
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
lbb_34412:
    ldxdw r3, [r10-0x60]                    
    jge r2, r0, lbb_34415                           if r2 >= r0 { pc += 1 }
    mov64 r8, r4                                    r8 = r4
lbb_34415:
    jeq r2, 0, lbb_34460                            if r2 == (0 as i32 as i64 as u64) { pc += 44 }
    mov64 r8, r4                                    r8 = r4
    ja lbb_34460                                    if true { pc += 42 }
lbb_34418:
    mov64 r2, r3                                    r2 = r3
    lsh64 r2, 32                                    r2 <<= 32   ///  r2 = r2.wrapping_shl(32)
    rsh64 r2, 32                                    r2 >>= 32   ///  r2 = r2.wrapping_shr(32)
    ldxdw r4, [r10-0x38]                    
    jgt r4, r2, lbb_34442                           if r4 > r2 { pc += 19 }
    ldxdw r4, [r10-0x38]                    
    jeq r2, r4, lbb_34426                           if r2 == r4 { pc += 1 }
    mov64 r6, r1                                    r6 = r1
lbb_34426:
    ldxdw r1, [r10-0x38]                    
    sub64 r3, r1                                    r3 -= r1   ///  r3 = r3.wrapping_sub(r1)
    mov64 r4, 0                                     r4 = 0 as i32 as i64 as u64
    mov64 r2, r3                                    r2 = r3
    ja lbb_34447                                    if true { pc += 16 }
lbb_34431:
    mov64 r1, r5                                    r1 = r5
    lsh64 r1, 32                                    r1 <<= 32   ///  r1 = r1.wrapping_shl(32)
    rsh64 r1, 32                                    r1 >>= 32   ///  r1 = r1.wrapping_shr(32)
    ldxdw r2, [r10-0x50]                    
    jgt r1, r2, lbb_34455                           if r1 > r2 { pc += 19 }
    jeq r2, r1, lbb_34438                           if r2 == r1 { pc += 1 }
    mov64 r8, r4                                    r8 = r4
lbb_34438:
    sub64 r2, r5                                    r2 -= r5   ///  r2 = r2.wrapping_sub(r5)
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    mov64 r5, r2                                    r5 = r2
    ja lbb_34459                                    if true { pc += 17 }
lbb_34442:
    ldxdw r2, [r10-0x38]                    
    sub64 r2, r3                                    r2 -= r3   ///  r2 = r2.wrapping_sub(r3)
    mov64 r4, 0                                     r4 = 0 as i32 as i64 as u64
    xor64 r1, -2147483648                           r1 ^= -2147483648   ///  r1 = r1.xor(-2147483648)
    mov64 r6, r1                                    r6 = r1
lbb_34447:
    ldxdw r5, [r10-0x60]                    
lbb_34448:
    stxw [r5+0x10], r4                      
    stxw [r5+0xc], r2                       
    stxw [r5+0x4], r6                       
lbb_34451:
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    stxw [r5+0x8], r1                       
    stxw [r5+0x0], r1                       
    ja lbb_34276                                    if true { pc += -179 }
lbb_34455:
    sub64 r5, r2                                    r5 -= r2   ///  r5 = r5.wrapping_sub(r2)
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    xor64 r4, -2147483648                           r4 ^= -2147483648   ///  r4 = r4.xor(-2147483648)
    mov64 r8, r4                                    r8 = r4
lbb_34459:
    ldxdw r3, [r10-0x60]                    
lbb_34460:
    stxw [r3+0x10], r1                      
    stxw [r3+0xc], r5                       
    stxw [r3+0x4], r8                       
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    stxw [r3+0x8], r1                       
    stxw [r3+0x0], r1                       
    ja lbb_34276                                    if true { pc += -191 }

function_34467:
    ldxdw r0, [r5-0xff0]                    
    ldxdw r6, [r5-0xff8]                    
    ldxdw r7, [r5-0x1000]                   
    ldxdw r5, [r5-0xfe8]                    
    jne r5, 0, lbb_34547                            if r5 != (0 as i32 as i64 as u64) { pc += 75 }
    mov64 r8, r4                                    r8 = r4
    add64 r8, r2                                    r8 += r2   ///  r8 = r8.wrapping_add(r2)
    mov64 r2, 1                                     r2 = 1 as i32 as i64 as u64
    jgt r4, r8, lbb_34477                           if r4 > r8 { pc += 1 }
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
lbb_34477:
    add64 r7, r3                                    r7 += r3   ///  r7 = r7.wrapping_add(r3)
    and64 r2, 1                                     r2 &= 1   ///  r2 = r2.and(1)
    jne r2, 0, lbb_34481                            if r2 != (0 as i32 as i64 as u64) { pc += 1 }
    ja lbb_34566                                    if true { pc += 85 }
lbb_34481:
    lsh64 r3, 32                                    r3 <<= 32   ///  r3 = r3.wrapping_shl(32)
    rsh64 r3, 32                                    r3 >>= 32   ///  r3 = r3.wrapping_shr(32)
    add64 r7, 1                                     r7 += 1   ///  r7 = r7.wrapping_add(1 as i32 as i64 as u64)
    mov64 r2, r7                                    r2 = r7
    lsh64 r2, 32                                    r2 <<= 32   ///  r2 = r2.wrapping_shl(32)
    rsh64 r2, 32                                    r2 >>= 32   ///  r2 = r2.wrapping_shr(32)
    mov64 r5, r8                                    r5 = r8
    jgt r2, r3, lbb_34635                           if r2 > r3 { pc += 146 }
    mov64 r2, 1                                     r2 = 1 as i32 as i64 as u64
    mov64 r3, r0                                    r3 = r0
    lsh64 r3, 32                                    r3 <<= 32   ///  r3 = r3.wrapping_shl(32)
    rsh64 r3, 32                                    r3 >>= 32   ///  r3 = r3.wrapping_shr(32)
    jeq r3, 0, lbb_34711                            if r3 == (0 as i32 as i64 as u64) { pc += 217 }
    mov64 r2, r7                                    r2 = r7
    lsh64 r2, 32                                    r2 <<= 32   ///  r2 = r2.wrapping_shl(32)
    rsh64 r2, 32                                    r2 >>= 32   ///  r2 = r2.wrapping_shr(32)
    lddw r3, 0x100000000                            r3 load str located at 4294967296
    or64 r2, r3                                     r2 |= r3   ///  r2 = r2.or(r3)
    div64 r2, 10                                    r2 /= 10   ///  r2 = r2 / (10 as u64)
    lddw r5, 0xfffffff6                             r5 load str located at 4294967286
    mov64 r4, r2                                    r4 = r2
    mul64 r4, r5                                    r4 *= r5   ///  r4 = r4.wrapping_mul(r5)
    add64 r4, r7                                    r4 += r7   ///  r4 = r4.wrapping_add(r7)
    lsh64 r4, 32                                    r4 <<= 32   ///  r4 = r4.wrapping_shl(32)
    mov64 r7, r8                                    r7 = r8
    rsh64 r7, 32                                    r7 >>= 32   ///  r7 = r7.wrapping_shr(32)
    or64 r4, r7                                     r4 |= r7   ///  r4 = r4.or(r7)
    div64 r4, 10                                    r4 /= 10   ///  r4 = r4 / (10 as u64)
    mov64 r3, r4                                    r3 = r4
    mul64 r3, r5                                    r3 *= r5   ///  r3 = r3.wrapping_mul(r5)
    add64 r3, r7                                    r3 += r7   ///  r3 = r3.wrapping_add(r7)
    lddw r5, 0xfffffffe                             r5 load str located at 4294967294
    mov64 r7, r8                                    r7 = r8
    and64 r7, r5                                    r7 &= r5   ///  r7 = r7.and(r5)
    lsh64 r3, 32                                    r3 <<= 32   ///  r3 = r3.wrapping_shl(32)
    or64 r3, r7                                     r3 |= r7   ///  r3 = r3.or(r7)
    div64 r3, 10                                    r3 /= 10   ///  r3 = r3 / (10 as u64)
    mov64 r5, r3                                    r5 = r3
    lsh64 r5, 32                                    r5 <<= 32   ///  r5 = r5.wrapping_shl(32)
    rsh64 r5, 32                                    r5 >>= 32   ///  r5 = r5.wrapping_shr(32)
    lsh64 r4, 32                                    r4 <<= 32   ///  r4 = r4.wrapping_shl(32)
    or64 r5, r4                                     r5 |= r4   ///  r5 = r5.or(r4)
    mov64 r4, r3                                    r4 = r3
    mul64 r4, -10                                   r4 *= -10   ///  r4 = r4.wrapping_mul(-10 as u64)
    add64 r4, r8                                    r4 += r8   ///  r4 = r4.wrapping_add(r8)
    mov64 r8, r4                                    r8 = r4
    lsh64 r8, 32                                    r8 <<= 32   ///  r8 = r8.wrapping_shl(32)
    rsh64 r8, 32                                    r8 >>= 32   ///  r8 = r8.wrapping_shr(32)
    mov64 r9, 5                                     r9 = 5 as i32 as i64 as u64
    mov64 r7, r2                                    r7 = r2
    jgt r9, r8, lbb_34634                           if r9 > r8 { pc += 99 }
    mov64 r7, r2                                    r7 = r2
    and64 r3, 1                                     r3 &= 1   ///  r3 = r3.and(1)
    jne r3, 0, lbb_34541                            if r3 != (0 as i32 as i64 as u64) { pc += 3 }
    lsh64 r4, 32                                    r4 <<= 32   ///  r4 = r4.wrapping_shl(32)
    rsh64 r4, 32                                    r4 >>= 32   ///  r4 = r4.wrapping_shr(32)
    jeq r4, 5, lbb_34634                            if r4 == (5 as i32 as i64 as u64) { pc += 93 }
lbb_34541:
    add64 r5, 1                                     r5 += 1   ///  r5 = r5.wrapping_add(1 as i32 as i64 as u64)
    mov64 r3, 1                                     r3 = 1 as i32 as i64 as u64
    jeq r5, 0, lbb_34545                            if r5 == (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
lbb_34545:
    jne r3, 1, lbb_34634                            if r3 != (1 as i32 as i64 as u64) { pc += 88 }
    ja lbb_34631                                    if true { pc += 84 }
lbb_34547:
    mov64 r8, r3                                    r8 = r3
    sub64 r8, r7                                    r8 -= r7   ///  r8 = r8.wrapping_sub(r7)
    mov64 r5, r2                                    r5 = r2
    sub64 r5, r4                                    r5 -= r4   ///  r5 = r5.wrapping_sub(r4)
    jgt r4, r2, lbb_34553                           if r4 > r2 { pc += 1 }
    ja lbb_34670                                    if true { pc += 117 }
lbb_34553:
    lsh64 r3, 32                                    r3 <<= 32   ///  r3 = r3.wrapping_shl(32)
    rsh64 r3, 32                                    r3 >>= 32   ///  r3 = r3.wrapping_shr(32)
    mov64 r2, r8                                    r2 = r8
    add64 r2, -1                                    r2 += -1   ///  r2 = r2.wrapping_add(-1 as i32 as i64 as u64)
    mov64 r4, r2                                    r4 = r2
    lsh64 r4, 32                                    r4 <<= 32   ///  r4 = r4.wrapping_shl(32)
    rsh64 r4, 32                                    r4 >>= 32   ///  r4 = r4.wrapping_shr(32)
    jgt r3, r4, lbb_34684                           if r3 > r4 { pc += 123 }
    xor64 r6, 1                                     r6 ^= 1   ///  r6 = r6.xor(1)
    neg64 r5                                        r5 = -r5   ///  r5 = (r5 as i64).wrapping_neg() as u64
    neg64 r8                                        r8 = -r8   ///  r8 = (r8 as i64).wrapping_neg() as u64
    mov64 r2, r8                                    r2 = r8
    ja lbb_34684                                    if true { pc += 118 }
lbb_34566:
    mov64 r2, r7                                    r2 = r7
    lsh64 r2, 32                                    r2 <<= 32   ///  r2 = r2.wrapping_shl(32)
    rsh64 r2, 32                                    r2 >>= 32   ///  r2 = r2.wrapping_shr(32)
    lsh64 r3, 32                                    r3 <<= 32   ///  r3 = r3.wrapping_shl(32)
    rsh64 r3, 32                                    r3 >>= 32   ///  r3 = r3.wrapping_shr(32)
    mov64 r5, r8                                    r5 = r8
    jgt r3, r2, lbb_34574                           if r3 > r2 { pc += 1 }
    ja lbb_34635                                    if true { pc += 61 }
lbb_34574:
    mov64 r2, 1                                     r2 = 1 as i32 as i64 as u64
    mov64 r3, r0                                    r3 = r0
    lsh64 r3, 32                                    r3 <<= 32   ///  r3 = r3.wrapping_shl(32)
    rsh64 r3, 32                                    r3 >>= 32   ///  r3 = r3.wrapping_shr(32)
    jeq r3, 0, lbb_34711                            if r3 == (0 as i32 as i64 as u64) { pc += 132 }
    mov64 r2, r7                                    r2 = r7
    lsh64 r2, 32                                    r2 <<= 32   ///  r2 = r2.wrapping_shl(32)
    rsh64 r2, 32                                    r2 >>= 32   ///  r2 = r2.wrapping_shr(32)
    lddw r3, 0x100000000                            r3 load str located at 4294967296
    or64 r2, r3                                     r2 |= r3   ///  r2 = r2.or(r3)
    div64 r2, 10                                    r2 /= 10   ///  r2 = r2 / (10 as u64)
    lddw r5, 0xfffffff6                             r5 load str located at 4294967286
    mov64 r4, r2                                    r4 = r2
    mul64 r4, r5                                    r4 *= r5   ///  r4 = r4.wrapping_mul(r5)
    add64 r4, r7                                    r4 += r7   ///  r4 = r4.wrapping_add(r7)
    lsh64 r4, 32                                    r4 <<= 32   ///  r4 = r4.wrapping_shl(32)
    mov64 r7, r8                                    r7 = r8
    rsh64 r7, 32                                    r7 >>= 32   ///  r7 = r7.wrapping_shr(32)
    or64 r4, r7                                     r4 |= r7   ///  r4 = r4.or(r7)
    div64 r4, 10                                    r4 /= 10   ///  r4 = r4 / (10 as u64)
    mov64 r3, r4                                    r3 = r4
    mul64 r3, r5                                    r3 *= r5   ///  r3 = r3.wrapping_mul(r5)
    add64 r3, r7                                    r3 += r7   ///  r3 = r3.wrapping_add(r7)
    lddw r5, 0xfffffffe                             r5 load str located at 4294967294
    mov64 r7, r8                                    r7 = r8
    and64 r7, r5                                    r7 &= r5   ///  r7 = r7.and(r5)
    lsh64 r3, 32                                    r3 <<= 32   ///  r3 = r3.wrapping_shl(32)
    or64 r3, r7                                     r3 |= r7   ///  r3 = r3.or(r7)
    div64 r3, 10                                    r3 /= 10   ///  r3 = r3 / (10 as u64)
    mov64 r5, r3                                    r5 = r3
    lsh64 r5, 32                                    r5 <<= 32   ///  r5 = r5.wrapping_shl(32)
    rsh64 r5, 32                                    r5 >>= 32   ///  r5 = r5.wrapping_shr(32)
    lsh64 r4, 32                                    r4 <<= 32   ///  r4 = r4.wrapping_shl(32)
    or64 r5, r4                                     r5 |= r4   ///  r5 = r5.or(r4)
    mov64 r4, r3                                    r4 = r3
    mul64 r4, -10                                   r4 *= -10   ///  r4 = r4.wrapping_mul(-10 as u64)
    add64 r4, r8                                    r4 += r8   ///  r4 = r4.wrapping_add(r8)
    mov64 r8, r4                                    r8 = r4
    lsh64 r8, 32                                    r8 <<= 32   ///  r8 = r8.wrapping_shl(32)
    rsh64 r8, 32                                    r8 >>= 32   ///  r8 = r8.wrapping_shr(32)
    mov64 r9, 5                                     r9 = 5 as i32 as i64 as u64
    mov64 r7, r2                                    r7 = r2
    jgt r9, r8, lbb_34634                           if r9 > r8 { pc += 14 }
    mov64 r7, r2                                    r7 = r2
    and64 r3, 1                                     r3 &= 1   ///  r3 = r3.and(1)
    jne r3, 0, lbb_34626                            if r3 != (0 as i32 as i64 as u64) { pc += 3 }
    lsh64 r4, 32                                    r4 <<= 32   ///  r4 = r4.wrapping_shl(32)
    rsh64 r4, 32                                    r4 >>= 32   ///  r4 = r4.wrapping_shr(32)
    jeq r4, 5, lbb_34634                            if r4 == (5 as i32 as i64 as u64) { pc += 8 }
lbb_34626:
    add64 r5, 1                                     r5 += 1   ///  r5 = r5.wrapping_add(1 as i32 as i64 as u64)
    mov64 r3, 1                                     r3 = 1 as i32 as i64 as u64
    jeq r5, 0, lbb_34630                            if r5 == (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
lbb_34630:
    jne r3, 1, lbb_34634                            if r3 != (1 as i32 as i64 as u64) { pc += 3 }
lbb_34631:
    mov64 r5, 0                                     r5 = 0 as i32 as i64 as u64
    add64 r2, 1                                     r2 += 1   ///  r2 = r2.wrapping_add(1 as i32 as i64 as u64)
    mov64 r7, r2                                    r7 = r2
lbb_34634:
    add64 r0, -1                                    r0 += -1   ///  r0 = r0.wrapping_add(-1 as i32 as i64 as u64)
lbb_34635:
    mov64 r2, r0                                    r2 = r0
    lsh64 r2, 32                                    r2 <<= 32   ///  r2 = r2.wrapping_shl(32)
    rsh64 r2, 32                                    r2 >>= 32   ///  r2 = r2.wrapping_shr(32)
    mov64 r3, 29                                    r3 = 29 as i32 as i64 as u64
    jgt r3, r2, lbb_34657                           if r3 > r2 { pc += 17 }
lbb_34640:
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    stxdw [r10-0x28], r1                    
    lddw r1, 0x100066950 --> b"\x00\x00\x00\x00\x8f-\x06\x00%\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x0…        r1 load str located at 4295387472
    stxdw [r10-0x30], r1                    
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    stxdw [r10-0x10], r1                    
    stxdw [r10-0x18], r1                    
    lddw r1, 0x100062c08 --> b"invalid args/home/runner/work/platform-tools/platf"        r1 load str located at 4295371784
    stxdw [r10-0x20], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -48                                   r1 += -48   ///  r1 = r1.wrapping_add(-48 as i32 as i64 as u64)
    lddw r2, 0x100066960 --> b"\x00\x00\x00\x00\x81-\x06\x00\x0e\x00\x00\x00\x00\x00\x00\x00\x11\x02\x00…        r2 load str located at 4295387488
    call function_44240                     
    syscall [invalid]                       
lbb_34657:
    mov64 r3, -2147483648                           r3 = -2147483648 as i32 as i64 as u64
    jne r6, 0, lbb_34660                            if r6 != (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
lbb_34660:
    mov64 r2, r7                                    r2 = r7
    or64 r2, r5                                     r2 |= r5   ///  r2 = r2.or(r5)
    mov64 r4, r5                                    r4 = r5
    rsh64 r4, 32                                    r4 >>= 32   ///  r4 = r4.wrapping_shr(32)
    or64 r2, r4                                     r2 |= r4   ///  r2 = r2.or(r4)
    lsh64 r2, 32                                    r2 <<= 32   ///  r2 = r2.wrapping_shl(32)
    rsh64 r2, 32                                    r2 >>= 32   ///  r2 = r2.wrapping_shr(32)
    jne r2, 0, lbb_34704                            if r2 != (0 as i32 as i64 as u64) { pc += 36 }
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
    ja lbb_34704                                    if true { pc += 34 }
lbb_34670:
    lsh64 r3, 32                                    r3 <<= 32   ///  r3 = r3.wrapping_shl(32)
    rsh64 r3, 32                                    r3 >>= 32   ///  r3 = r3.wrapping_shr(32)
    lsh64 r7, 32                                    r7 <<= 32   ///  r7 = r7.wrapping_shl(32)
    rsh64 r7, 32                                    r7 >>= 32   ///  r7 = r7.wrapping_shr(32)
    mov64 r2, r8                                    r2 = r8
    jgt r7, r3, lbb_34677                           if r7 > r3 { pc += 1 }
    ja lbb_34684                                    if true { pc += 7 }
lbb_34677:
    mov64 r2, r8                                    r2 = r8
    neg64 r2                                        r2 = -r2   ///  r2 = (r2 as i64).wrapping_neg() as u64
    jeq r5, 0, lbb_34682                            if r5 == (0 as i32 as i64 as u64) { pc += 2 }
    xor64 r8, -1                                    r8 ^= -1   ///  r8 = r8.xor(-1)
    mov64 r2, r8                                    r2 = r8
lbb_34682:
    xor64 r6, 1                                     r6 ^= 1   ///  r6 = r6.xor(1)
    neg64 r5                                        r5 = -r5   ///  r5 = (r5 as i64).wrapping_neg() as u64
lbb_34684:
    mov64 r3, r0                                    r3 = r0
    lsh64 r3, 32                                    r3 <<= 32   ///  r3 = r3.wrapping_shl(32)
    rsh64 r3, 32                                    r3 >>= 32   ///  r3 = r3.wrapping_shr(32)
    mov64 r4, 29                                    r4 = 29 as i32 as i64 as u64
    jgt r4, r3, lbb_34690                           if r4 > r3 { pc += 1 }
    ja lbb_34640                                    if true { pc += -50 }
lbb_34690:
    mov64 r8, r2                                    r8 = r2
    or64 r8, r5                                     r8 |= r5   ///  r8 = r8.or(r5)
    mov64 r4, r5                                    r4 = r5
    rsh64 r4, 32                                    r4 >>= 32   ///  r4 = r4.wrapping_shr(32)
    or64 r8, r4                                     r8 |= r4   ///  r8 = r8.or(r4)
    lsh64 r8, 32                                    r8 <<= 32   ///  r8 = r8.wrapping_shl(32)
    rsh64 r8, 32                                    r8 >>= 32   ///  r8 = r8.wrapping_shr(32)
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
    mov64 r7, 0                                     r7 = 0 as i32 as i64 as u64
    jeq r8, 0, lbb_34701                            if r8 == (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r7, -2147483648                           r7 = -2147483648 as i32 as i64 as u64
lbb_34701:
    jeq r6, 0, lbb_34703                            if r6 == (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r3, r7                                    r3 = r7
lbb_34703:
    mov64 r7, r2                                    r7 = r2
lbb_34704:
    stxw [r1+0x10], r4                      
    stxw [r1+0xc], r5                       
    stxw [r1+0x8], r7                       
    lsh64 r0, 16                                    r0 <<= 16   ///  r0 = r0.wrapping_shl(16)
    or64 r3, r0                                     r3 |= r0   ///  r3 = r3.or(r0)
    stxw [r1+0x4], r3                       
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
lbb_34711:
    stxw [r1+0x0], r2                       
    exit                                    

function_34713:
    stxdw [r10-0x78], r4                    
    stxdw [r10-0x70], r3                    
    mov64 r0, r2                                    r0 = r2
    stxdw [r10-0x60], r1                    
    ldxdw r2, [r0+0x0]                      
    ldxdw r1, [r5-0xff0]                    
    stxdw [r10-0x68], r1                    
    ldxdw r8, [r5-0xff8]                    
    ldxdw r1, [r5-0x1000]                   
    stxdw [r10-0x58], r1                    
    ldxw r0, [r0+0xc]                       
    mov64 r1, r8                                    r1 = r8
    jne r0, 0, lbb_34792                            if r0 != (0 as i32 as i64 as u64) { pc += 66 }
    lddw r1, 0xffffffff                             r1 load str located at 4294967295
    jgt r2, r1, lbb_34749                           if r2 > r1 { pc += 20 }
    lsh64 r8, 32                                    r8 <<= 32   ///  r8 = r8.wrapping_shl(32)
    arsh64 r8, 32                                   r8 >>= 32 (signed)   ///  r8 = (r8 as i64).wrapping_shr(32)
    mov64 r3, r8                                    r3 = r8
    lsh64 r3, 2                                     r3 <<= 2   ///  r3 = r3.wrapping_shl(2)
    lddw r1, 0x100062e50 --> b"\x01\x00\x00\x00\x0a\x00\x00\x00d\x00\x00\x00\xe8\x03\x00\x00\x10'\x00\x0…        r1 load str located at 4295372368
    add64 r1, r3                                    r1 += r3   ///  r1 = r1.wrapping_add(r3)
    mov64 r3, 10                                    r3 = 10 as i32 as i64 as u64
    mov64 r5, 5                                     r5 = 5 as i32 as i64 as u64
lbb_34738:
    mov64 r0, r2                                    r0 = r2
    mov64 r2, r8                                    r2 = r8
    lsh64 r2, 32                                    r2 <<= 32   ///  r2 = r2.wrapping_shl(32)
    mov64 r6, r2                                    r6 = r2
    arsh64 r6, 32                                   r6 >>= 32 (signed)   ///  r6 = (r6 as i64).wrapping_shr(32)
    jsgt r3, r6, lbb_35130                          if (r3 as i64) > (r6 as i64) { pc += 386 }
    add64 r1, -36                                   r1 += -36   ///  r1 = r1.wrapping_add(-36 as i32 as i64 as u64)
    mov64 r2, r0                                    r2 = r0
    mul64 r2, 1000000000                            r2 *= 1000000000   ///  r2 = r2.wrapping_mul(1000000000 as u64)
    add64 r8, -9                                    r8 += -9   ///  r8 = r8.wrapping_add(-9 as i32 as i64 as u64)
    jgt r5, r0, lbb_34738                           if r5 > r0 { pc += -11 }
lbb_34749:
    lsh64 r8, 32                                    r8 <<= 32   ///  r8 = r8.wrapping_shl(32)
    arsh64 r8, 32                                   r8 >>= 32 (signed)   ///  r8 = (r8 as i64).wrapping_shr(32)
    mov64 r1, r8                                    r1 = r8
    lsh64 r1, 2                                     r1 <<= 2   ///  r1 = r1.wrapping_shl(2)
    lddw r3, 0x100062e50 --> b"\x01\x00\x00\x00\x0a\x00\x00\x00d\x00\x00\x00\xe8\x03\x00\x00\x10'\x00\x0…        r3 load str located at 4295372368
    add64 r3, r1                                    r3 += r1   ///  r3 = r3.wrapping_add(r1)
    mov64 r0, 0                                     r0 = 0 as i32 as i64 as u64
    mov64 r5, 10                                    r5 = 10 as i32 as i64 as u64
lbb_34758:
    mov64 r1, r8                                    r1 = r8
    mov64 r6, r0                                    r6 = r0
    lsh64 r6, 32                                    r6 <<= 32   ///  r6 = r6.wrapping_shl(32)
    rsh64 r6, 32                                    r6 >>= 32   ///  r6 = r6.wrapping_shr(32)
    jne r6, 0, lbb_34792                            if r6 != (0 as i32 as i64 as u64) { pc += 29 }
    mov64 r6, 1000000000                            r6 = 1000000000 as i32 as i64 as u64
    jsgt r1, 9, lbb_34771                           if (r1 as i64) > (9 as i32 as i64) { pc += 6 }
    mov64 r0, r1                                    r0 = r1
    lsh64 r0, 32                                    r0 <<= 32   ///  r0 = r0.wrapping_shl(32)
    rsh64 r0, 32                                    r0 >>= 32   ///  r0 = r0.wrapping_shr(32)
    jgt r5, r0, lbb_34770                           if r5 > r0 { pc += 1 }
    ja lbb_35249                                    if true { pc += 479 }
lbb_34770:
    ldxw r6, [r3+0x0]                       
lbb_34771:
    mov64 r0, r2                                    r0 = r2
    rsh64 r0, 32                                    r0 >>= 32   ///  r0 = r0.wrapping_shr(32)
    mov64 r7, r6                                    r7 = r6
    mul64 r7, r0                                    r7 *= r0   ///  r7 = r7.wrapping_mul(r0)
    lsh64 r2, 32                                    r2 <<= 32   ///  r2 = r2.wrapping_shl(32)
    rsh64 r2, 32                                    r2 >>= 32   ///  r2 = r2.wrapping_shr(32)
    mul64 r6, r2                                    r6 *= r2   ///  r6 = r6.wrapping_mul(r2)
    mov64 r0, r6                                    r0 = r6
    rsh64 r0, 32                                    r0 >>= 32   ///  r0 = r0.wrapping_shr(32)
    add64 r0, r7                                    r0 += r7   ///  r0 = r0.wrapping_add(r7)
    lsh64 r6, 32                                    r6 <<= 32   ///  r6 = r6.wrapping_shl(32)
    rsh64 r6, 32                                    r6 >>= 32   ///  r6 = r6.wrapping_shr(32)
    mov64 r2, r0                                    r2 = r0
    lsh64 r2, 32                                    r2 <<= 32   ///  r2 = r2.wrapping_shl(32)
    or64 r2, r6                                     r2 |= r6   ///  r2 = r2.or(r6)
    add64 r3, -36                                   r3 += -36   ///  r3 = r3.wrapping_add(-36 as i32 as i64 as u64)
    mov64 r8, r1                                    r8 = r1
    add64 r8, -9                                    r8 += -9   ///  r8 = r8.wrapping_add(-9 as i32 as i64 as u64)
    rsh64 r0, 32                                    r0 >>= 32   ///  r0 = r0.wrapping_shr(32)
    jsgt r5, r1, lbb_34843                          if (r5 as i64) > (r1 as i64) { pc += 52 }
    ja lbb_34758                                    if true { pc += -34 }
lbb_34792:
    ldxdw r3, [r10-0x58]                    
    lsh64 r3, 32                                    r3 <<= 32   ///  r3 = r3.wrapping_shl(32)
    rsh64 r3, 32                                    r3 >>= 32   ///  r3 = r3.wrapping_shr(32)
    jgt r3, 28, lbb_34857                           if r3 > (28 as i32 as i64 as u64) { pc += 61 }
    lsh64 r1, 32                                    r1 <<= 32   ///  r1 = r1.wrapping_shl(32)
    arsh64 r1, 32                                   r1 >>= 32 (signed)   ///  r1 = (r1 as i64).wrapping_shr(32)
    mov64 r5, r1                                    r5 = r1
    lsh64 r5, 2                                     r5 <<= 2   ///  r5 = r5.wrapping_shl(2)
    lddw r3, 0x100062e50 --> b"\x01\x00\x00\x00\x0a\x00\x00\x00d\x00\x00\x00\xe8\x03\x00\x00\x10'\x00\x0…        r3 load str located at 4295372368
    add64 r3, r5                                    r3 += r5   ///  r3 = r3.wrapping_add(r5)
    mov64 r9, 10                                    r9 = 10 as i32 as i64 as u64
    lddw r6, 0xffffffff                             r6 load str located at 4294967295
    mov64 r5, r1                                    r5 = r1
lbb_34807:
    mov64 r1, 1000000000                            r1 = 1000000000 as i32 as i64 as u64
    jsgt r5, 9, lbb_34815                           if (r5 as i64) > (9 as i32 as i64) { pc += 6 }
    mov64 r1, r5                                    r1 = r5
    lsh64 r1, 32                                    r1 <<= 32   ///  r1 = r1.wrapping_shl(32)
    rsh64 r1, 32                                    r1 >>= 32   ///  r1 = r1.wrapping_shr(32)
    jgt r9, r1, lbb_34814                           if r9 > r1 { pc += 1 }
    ja lbb_35243                                    if true { pc += 429 }
lbb_34814:
    ldxw r1, [r3+0x0]                       
lbb_34815:
    mov64 r7, r2                                    r7 = r2
    rsh64 r7, 32                                    r7 >>= 32   ///  r7 = r7.wrapping_shr(32)
    mov64 r4, r1                                    r4 = r1
    mul64 r4, r7                                    r4 *= r7   ///  r4 = r4.wrapping_mul(r7)
    lsh64 r2, 32                                    r2 <<= 32   ///  r2 = r2.wrapping_shl(32)
    rsh64 r2, 32                                    r2 >>= 32   ///  r2 = r2.wrapping_shr(32)
    mov64 r8, r1                                    r8 = r1
    mul64 r8, r2                                    r8 *= r2   ///  r8 = r8.wrapping_mul(r2)
    mov64 r2, r8                                    r2 = r8
    rsh64 r2, 32                                    r2 >>= 32   ///  r2 = r2.wrapping_shr(32)
    add64 r2, r4                                    r2 += r4   ///  r2 = r2.wrapping_add(r4)
    lsh64 r0, 32                                    r0 <<= 32   ///  r0 = r0.wrapping_shl(32)
    rsh64 r0, 32                                    r0 >>= 32   ///  r0 = r0.wrapping_shr(32)
    mul64 r1, r0                                    r1 *= r0   ///  r1 = r1.wrapping_mul(r0)
    mov64 r0, r2                                    r0 = r2
    rsh64 r0, 32                                    r0 >>= 32   ///  r0 = r0.wrapping_shr(32)
    add64 r0, r1                                    r0 += r1   ///  r0 = r0.wrapping_add(r1)
    jgt r0, r6, lbb_34889                           if r0 > r6 { pc += 56 }
    add64 r5, -9                                    r5 += -9   ///  r5 = r5.wrapping_add(-9 as i32 as i64 as u64)
    lsh64 r2, 32                                    r2 <<= 32   ///  r2 = r2.wrapping_shl(32)
    lsh64 r8, 32                                    r8 <<= 32   ///  r8 = r8.wrapping_shl(32)
    rsh64 r8, 32                                    r8 >>= 32   ///  r8 = r8.wrapping_shr(32)
    or64 r2, r8                                     r2 |= r8   ///  r2 = r2.or(r8)
    add64 r3, -36                                   r3 += -36   ///  r3 = r3.wrapping_add(-36 as i32 as i64 as u64)
    mov64 r1, r5                                    r1 = r5
    add64 r1, 9                                     r1 += 9   ///  r1 = r1.wrapping_add(9 as i32 as i64 as u64)
    jsgt r9, r1, lbb_34843                          if (r9 as i64) > (r1 as i64) { pc += 1 }
    ja lbb_34807                                    if true { pc += -36 }
lbb_34843:
    ldxdw r1, [r10-0x70]                    
    ldxdw r8, [r1+0x0]                      
    ldxw r1, [r1+0xc]                       
    ldxdw r3, [r10-0x58]                    
    stxdw [r10-0xff0], r3                   
    ldxdw r3, [r10-0x68]                    
    stxdw [r10-0xfe8], r3                   
    ldxdw r3, [r10-0x78]                    
    stxdw [r10-0xff8], r3                   
    stxdw [r10-0x1000], r1                  
    mov64 r5, r10                                   r5 = r10
    ldxdw r1, [r10-0x60]                    
    mov64 r3, r0                                    r3 = r0
    ja lbb_35148                                    if true { pc += 291 }
lbb_34857:
    mov64 r3, 1000000000                            r3 = 1000000000 as i32 as i64 as u64
    mov64 r6, r1                                    r6 = r1
    lsh64 r6, 32                                    r6 <<= 32   ///  r6 = r6.wrapping_shl(32)
    mov64 r5, r6                                    r5 = r6
    arsh64 r5, 32                                   r5 >>= 32 (signed)   ///  r5 = (r5 as i64).wrapping_shr(32)
    jsgt r5, 9, lbb_34870                           if (r5 as i64) > (9 as i32 as i64) { pc += 7 }
    rsh64 r6, 32                                    r6 >>= 32   ///  r6 = r6.wrapping_shr(32)
    jgt r6, 9, lbb_35243                            if r6 > (9 as i32 as i64 as u64) { pc += 378 }
    lsh64 r5, 2                                     r5 <<= 2   ///  r5 = r5.wrapping_shl(2)
    lddw r3, 0x100062e50 --> b"\x01\x00\x00\x00\x0a\x00\x00\x00d\x00\x00\x00\xe8\x03\x00\x00\x10'\x00\x0…        r3 load str located at 4295372368
    add64 r3, r5                                    r3 += r5   ///  r3 = r3.wrapping_add(r5)
    ldxw r3, [r3+0x0]                       
lbb_34870:
    mov64 r5, r2                                    r5 = r2
    rsh64 r5, 32                                    r5 >>= 32   ///  r5 = r5.wrapping_shr(32)
    mov64 r6, r3                                    r6 = r3
    mul64 r6, r5                                    r6 *= r5   ///  r6 = r6.wrapping_mul(r5)
    lsh64 r2, 32                                    r2 <<= 32   ///  r2 = r2.wrapping_shl(32)
    rsh64 r2, 32                                    r2 >>= 32   ///  r2 = r2.wrapping_shr(32)
    mov64 r8, r3                                    r8 = r3
    mul64 r8, r2                                    r8 *= r2   ///  r8 = r8.wrapping_mul(r2)
    mov64 r2, r8                                    r2 = r8
    rsh64 r2, 32                                    r2 >>= 32   ///  r2 = r2.wrapping_shr(32)
    add64 r2, r6                                    r2 += r6   ///  r2 = r2.wrapping_add(r6)
    lsh64 r0, 32                                    r0 <<= 32   ///  r0 = r0.wrapping_shl(32)
    rsh64 r0, 32                                    r0 >>= 32   ///  r0 = r0.wrapping_shr(32)
    mul64 r3, r0                                    r3 *= r0   ///  r3 = r3.wrapping_mul(r0)
    mov64 r0, r2                                    r0 = r2
    rsh64 r0, 32                                    r0 >>= 32   ///  r0 = r0.wrapping_shr(32)
    add64 r0, r3                                    r0 += r3   ///  r0 = r0.wrapping_add(r3)
    add64 r1, -9                                    r1 += -9   ///  r1 = r1.wrapping_add(-9 as i32 as i64 as u64)
    ja lbb_34891                                    if true { pc += 2 }
lbb_34889:
    add64 r5, -9                                    r5 += -9   ///  r5 = r5.wrapping_add(-9 as i32 as i64 as u64)
    mov64 r1, r5                                    r1 = r5
lbb_34891:
    stxw [r10-0x44], r2                     
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
    stxdw [r10-0x38], r3                    
    stxw [r10-0x48], r8                     
    mov64 r3, 3                                     r3 = 3 as i32 as i64 as u64
    stxw [r10-0x40], r0                     
    mov64 r4, r0                                    r4 = r0
    rsh64 r4, 32                                    r4 >>= 32   ///  r4 = r4.wrapping_shr(32)
    stxw [r10-0x3c], r4                     
    jne r4, 0, lbb_34912                            if r4 != (0 as i32 as i64 as u64) { pc += 11 }
    mov64 r3, 2                                     r3 = 2 as i32 as i64 as u64
    mov64 r4, r0                                    r4 = r0
    lsh64 r4, 32                                    r4 <<= 32   ///  r4 = r4.wrapping_shl(32)
    rsh64 r4, 32                                    r4 >>= 32   ///  r4 = r4.wrapping_shr(32)
    jne r4, 0, lbb_34912                            if r4 != (0 as i32 as i64 as u64) { pc += 6 }
    mov64 r4, r2                                    r4 = r2
    lsh64 r4, 32                                    r4 <<= 32   ///  r4 = r4.wrapping_shl(32)
    rsh64 r4, 32                                    r4 >>= 32   ///  r4 = r4.wrapping_shr(32)
    mov64 r3, 1                                     r3 = 1 as i32 as i64 as u64
    jne r4, 0, lbb_34912                            if r4 != (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
lbb_34912:
    lsh64 r1, 32                                    r1 <<= 32   ///  r1 = r1.wrapping_shl(32)
    arsh64 r1, 32                                   r1 >>= 32 (signed)   ///  r1 = (r1 as i64).wrapping_shr(32)
    mov64 r4, 1                                     r4 = 1 as i32 as i64 as u64
    jsgt r4, r1, lbb_35002                          if (r4 as i64) > (r1 as i64) { pc += 86 }
    mov64 r4, r1                                    r4 = r1
    lsh64 r4, 2                                     r4 <<= 2   ///  r4 = r4.wrapping_shl(2)
    lddw r2, 0x100062e50 --> b"\x01\x00\x00\x00\x0a\x00\x00\x00d\x00\x00\x00\xe8\x03\x00\x00\x10'\x00\x0…        r2 load str located at 4295372368
    add64 r2, r4                                    r2 += r4   ///  r2 = r2.wrapping_add(r4)
    mov64 r0, 10                                    r0 = 10 as i32 as i64 as u64
    mov64 r8, 5                                     r8 = 5 as i32 as i64 as u64
    ja lbb_34943                                    if true { pc += 19 }
lbb_34924:
    jeq r6, 0, lbb_34934                            if r6 == (0 as i32 as i64 as u64) { pc += 9 }
    jgt r8, r3, lbb_34927                           if r8 > r3 { pc += 1 }
    ja lbb_35232                                    if true { pc += 305 }
lbb_34927:
    mov64 r3, r5                                    r3 = r5
    lsh64 r3, 2                                     r3 <<= 2   ///  r3 = r3.wrapping_shl(2)
    mov64 r4, r10                                   r4 = r10
    add64 r4, -72                                   r4 += -72   ///  r4 = r4.wrapping_add(-72 as i32 as i64 as u64)
    add64 r4, r3                                    r4 += r3   ///  r4 = r4.wrapping_add(r3)
    stxw [r4+0x0], r6                       
    mov64 r3, r5                                    r3 = r5
lbb_34934:
    add64 r2, -36                                   r2 += -36   ///  r2 = r2.wrapping_add(-36 as i32 as i64 as u64)
    mov64 r4, r1                                    r4 = r1
    add64 r4, -9                                    r4 += -9   ///  r4 = r4.wrapping_add(-9 as i32 as i64 as u64)
    lsh64 r1, 32                                    r1 <<= 32   ///  r1 = r1.wrapping_shl(32)
    mov64 r5, r1                                    r5 = r1
    arsh64 r5, 32                                   r5 >>= 32 (signed)   ///  r5 = (r5 as i64).wrapping_shr(32)
    mov64 r1, r4                                    r1 = r4
    jsgt r5, 9, lbb_34943                           if (r5 as i64) > (9 as i32 as i64) { pc += 1 }
    ja lbb_34999                                    if true { pc += 56 }
lbb_34943:
    mov64 r7, 1000000000                            r7 = 1000000000 as i32 as i64 as u64
    mov64 r5, r1                                    r5 = r1
    lsh64 r5, 32                                    r5 <<= 32   ///  r5 = r5.wrapping_shl(32)
    mov64 r4, r5                                    r4 = r5
    arsh64 r4, 32                                   r4 >>= 32 (signed)   ///  r4 = (r4 as i64).wrapping_shr(32)
    jsgt r0, r4, lbb_34950                          if (r0 as i64) > (r4 as i64) { pc += 1 }
    ja lbb_34954                                    if true { pc += 4 }
lbb_34950:
    rsh64 r5, 32                                    r5 >>= 32   ///  r5 = r5.wrapping_shr(32)
    jgt r0, r5, lbb_34953                           if r0 > r5 { pc += 1 }
    ja lbb_35238                                    if true { pc += 285 }
lbb_34953:
    ldxw r7, [r2+0x0]                       
lbb_34954:
    ldxw r4, [r10-0x48]                     
    mov64 r6, r7                                    r6 = r7
    mul64 r6, r4                                    r6 *= r4   ///  r6 = r6.wrapping_mul(r4)
    mov64 r5, r3                                    r5 = r3
    add64 r5, 1                                     r5 += 1   ///  r5 = r5.wrapping_add(1 as i32 as i64 as u64)
    stxw [r10-0x48], r6                     
    rsh64 r6, 32                                    r6 >>= 32   ///  r6 = r6.wrapping_shr(32)
    jeq r3, 0, lbb_34924                            if r3 == (0 as i32 as i64 as u64) { pc += -38 }
    ldxw r4, [r10-0x44]                     
    mov64 r9, r7                                    r9 = r7
    mul64 r9, r4                                    r9 *= r4   ///  r9 = r9.wrapping_mul(r4)
    add64 r9, r6                                    r9 += r6   ///  r9 = r9.wrapping_add(r6)
    stxw [r10-0x44], r9                     
    rsh64 r9, 32                                    r9 >>= 32   ///  r9 = r9.wrapping_shr(32)
    mov64 r6, r9                                    r6 = r9
    jeq r5, 2, lbb_34924                            if r5 == (2 as i32 as i64 as u64) { pc += -46 }
    ldxw r4, [r10-0x40]                     
    mov64 r6, r7                                    r6 = r7
    mul64 r6, r4                                    r6 *= r4   ///  r6 = r6.wrapping_mul(r4)
    add64 r6, r9                                    r6 += r9   ///  r6 = r6.wrapping_add(r9)
    stxw [r10-0x40], r6                     
    rsh64 r6, 32                                    r6 >>= 32   ///  r6 = r6.wrapping_shr(32)
    jeq r5, 3, lbb_34924                            if r5 == (3 as i32 as i64 as u64) { pc += -53 }
    ldxw r4, [r10-0x3c]                     
    mov64 r9, r7                                    r9 = r7
    mul64 r9, r4                                    r9 *= r4   ///  r9 = r9.wrapping_mul(r4)
    add64 r9, r6                                    r9 += r6   ///  r9 = r9.wrapping_add(r6)
    stxw [r10-0x3c], r9                     
    rsh64 r9, 32                                    r9 >>= 32   ///  r9 = r9.wrapping_shr(32)
    mov64 r6, r9                                    r6 = r9
    jeq r5, 4, lbb_34924                            if r5 == (4 as i32 as i64 as u64) { pc += -61 }
    ldxw r4, [r10-0x38]                     
    mov64 r6, r7                                    r6 = r7
    mul64 r6, r4                                    r6 *= r4   ///  r6 = r6.wrapping_mul(r4)
    add64 r6, r9                                    r6 += r9   ///  r6 = r6.wrapping_add(r9)
    stxw [r10-0x38], r6                     
    rsh64 r6, 32                                    r6 >>= 32   ///  r6 = r6.wrapping_shr(32)
    jeq r5, 5, lbb_34924                            if r5 == (5 as i32 as i64 as u64) { pc += -68 }
    ldxw r4, [r10-0x34]                     
    mul64 r7, r4                                    r7 *= r4   ///  r7 = r7.wrapping_mul(r4)
    add64 r7, r6                                    r7 += r6   ///  r7 = r7.wrapping_add(r6)
    stxw [r10-0x34], r7                     
    rsh64 r7, 32                                    r7 >>= 32   ///  r7 = r7.wrapping_shr(32)
    mov64 r6, r7                                    r6 = r7
    ja lbb_34924                                    if true { pc += -75 }
lbb_34999:
    ldxw r0, [r10-0x40]                     
    ldxw r8, [r10-0x48]                     
    ldxw r2, [r10-0x44]                     
lbb_35002:
    lsh64 r2, 32                                    r2 <<= 32   ///  r2 = r2.wrapping_shl(32)
    lsh64 r8, 32                                    r8 <<= 32   ///  r8 = r8.wrapping_shl(32)
    rsh64 r8, 32                                    r8 >>= 32   ///  r8 = r8.wrapping_shr(32)
    or64 r2, r8                                     r2 |= r8   ///  r2 = r2.or(r8)
    ldxdw r4, [r10-0x70]                    
    ldxw r1, [r4+0xc]                       
    ldxdw r7, [r4+0x0]                      
    ldxdw r4, [r10-0x68]                    
    jne r4, 0, lbb_35070                            if r4 != (0 as i32 as i64 as u64) { pc += 59 }
    lsh64 r0, 32                                    r0 <<= 32   ///  r0 = r0.wrapping_shl(32)
    rsh64 r0, 32                                    r0 >>= 32   ///  r0 = r0.wrapping_shr(32)
    mov64 r6, r1                                    r6 = r1
    add64 r6, r0                                    r6 += r0   ///  r6 = r6.wrapping_add(r0)
    mov64 r1, r6                                    r1 = r6
    add64 r1, 1                                     r1 += 1   ///  r1 = r1.wrapping_add(1 as i32 as i64 as u64)
    mov64 r4, r1                                    r4 = r1
    lsh64 r4, 32                                    r4 <<= 32   ///  r4 = r4.wrapping_shl(32)
    rsh64 r4, 32                                    r4 >>= 32   ///  r4 = r4.wrapping_shr(32)
    mov64 r9, 1                                     r9 = 1 as i32 as i64 as u64
    mov64 r8, 1                                     r8 = 1 as i32 as i64 as u64
    jge r0, r4, lbb_35024                           if r0 >= r4 { pc += 1 }
    mov64 r8, 0                                     r8 = 0 as i32 as i64 as u64
lbb_35024:
    mov64 r4, r6                                    r4 = r6
    lsh64 r4, 32                                    r4 <<= 32   ///  r4 = r4.wrapping_shl(32)
    rsh64 r4, 32                                    r4 >>= 32   ///  r4 = r4.wrapping_shr(32)
    mov64 r0, 1                                     r0 = 1 as i32 as i64 as u64
    jne r4, r6, lbb_35030                           if r4 != r6 { pc += 1 }
    mov64 r0, 0                                     r0 = 0 as i32 as i64 as u64
lbb_35030:
    mov64 r5, r2                                    r5 = r2
    add64 r5, r7                                    r5 += r7   ///  r5 = r5.wrapping_add(r7)
    jgt r2, r5, lbb_35034                           if r2 > r5 { pc += 1 }
    mov64 r9, 0                                     r9 = 0 as i32 as i64 as u64
lbb_35034:
    jne r9, 0, lbb_35036                            if r9 != (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r1, r6                                    r1 = r6
lbb_35036:
    jne r9, 0, lbb_35038                            if r9 != (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r8, r0                                    r8 = r0
lbb_35038:
    jne r8, 1, lbb_35154                            if r8 != (1 as i32 as i64 as u64) { pc += 115 }
    mov64 r2, r10                                   r2 = r10
    add64 r2, -60                                   r2 += -60   ///  r2 = r2.wrapping_add(-60 as i32 as i64 as u64)
    mov64 r0, 3                                     r0 = 3 as i32 as i64 as u64
    jgt r0, r3, lbb_35151                           if r0 > r3 { pc += 108 }
    ldxw r2, [r10-0x3c]                     
    add64 r2, 1                                     r2 += 1   ///  r2 = r2.wrapping_add(1 as i32 as i64 as u64)
    stxw [r10-0x3c], r2                     
    mov64 r4, r2                                    r4 = r2
    lsh64 r4, 32                                    r4 <<= 32   ///  r4 = r4.wrapping_shl(32)
    rsh64 r4, 32                                    r4 >>= 32   ///  r4 = r4.wrapping_shr(32)
    jne r4, r2, lbb_35051                           if r4 != r2 { pc += 1 }
    ja lbb_35154                                    if true { pc += 103 }
lbb_35051:
    mov64 r2, r10                                   r2 = r10
    add64 r2, -56                                   r2 += -56   ///  r2 = r2.wrapping_add(-56 as i32 as i64 as u64)
    mov64 r0, 4                                     r0 = 4 as i32 as i64 as u64
    jgt r0, r3, lbb_35151                           if r0 > r3 { pc += 96 }
    ldxw r2, [r10-0x38]                     
    add64 r2, 1                                     r2 += 1   ///  r2 = r2.wrapping_add(1 as i32 as i64 as u64)
    stxw [r10-0x38], r2                     
    mov64 r4, r2                                    r4 = r2
    lsh64 r4, 32                                    r4 <<= 32   ///  r4 = r4.wrapping_shl(32)
    rsh64 r4, 32                                    r4 >>= 32   ///  r4 = r4.wrapping_shr(32)
    jeq r4, r2, lbb_35154                           if r4 == r2 { pc += 92 }
    mov64 r2, r10                                   r2 = r10
    add64 r2, -52                                   r2 += -52   ///  r2 = r2.wrapping_add(-52 as i32 as i64 as u64)
    mov64 r0, 5                                     r0 = 5 as i32 as i64 as u64
    jgt r0, r3, lbb_35151                           if r0 > r3 { pc += 85 }
    ldxw r2, [r10-0x34]                     
    add64 r2, 1                                     r2 += 1   ///  r2 = r2.wrapping_add(1 as i32 as i64 as u64)
    stxw [r10-0x34], r2                     
    ja lbb_35154                                    if true { pc += 84 }
lbb_35070:
    mov64 r5, r0                                    r5 = r0
    sub64 r5, r1                                    r5 -= r1   ///  r5 = r5.wrapping_sub(r1)
    lsh64 r0, 32                                    r0 <<= 32   ///  r0 = r0.wrapping_shl(32)
    rsh64 r0, 32                                    r0 >>= 32   ///  r0 = r0.wrapping_shr(32)
    mov64 r6, 1                                     r6 = 1 as i32 as i64 as u64
    mov64 r8, 1                                     r8 = 1 as i32 as i64 as u64
    jgt r1, r0, lbb_35078                           if r1 > r0 { pc += 1 }
    mov64 r8, 0                                     r8 = 0 as i32 as i64 as u64
lbb_35078:
    mov64 r1, r5                                    r1 = r5
    add64 r1, -1                                    r1 += -1   ///  r1 = r1.wrapping_add(-1 as i32 as i64 as u64)
    mov64 r4, r1                                    r4 = r1
    lsh64 r4, 32                                    r4 <<= 32   ///  r4 = r4.wrapping_shl(32)
    rsh64 r4, 32                                    r4 >>= 32   ///  r4 = r4.wrapping_shr(32)
    jge r4, r0, lbb_35085                           if r4 >= r0 { pc += 1 }
    mov64 r6, 0                                     r6 = 0 as i32 as i64 as u64
lbb_35085:
    jgt r7, r2, lbb_35087                           if r7 > r2 { pc += 1 }
    mov64 r6, r8                                    r6 = r8
lbb_35087:
    jgt r7, r2, lbb_35089                           if r7 > r2 { pc += 1 }
    mov64 r1, r5                                    r1 = r5
lbb_35089:
    mov64 r5, r2                                    r5 = r2
    sub64 r5, r7                                    r5 -= r7   ///  r5 = r5.wrapping_sub(r7)
    jne r6, 1, lbb_35154                            if r6 != (1 as i32 as i64 as u64) { pc += 62 }
    ldxw r2, [r10-0x3c]                     
    add64 r2, -1                                    r2 += -1   ///  r2 = r2.wrapping_add(-1 as i32 as i64 as u64)
    stxw [r10-0x3c], r2                     
    lsh64 r2, 32                                    r2 <<= 32   ///  r2 = r2.wrapping_shl(32)
    rsh64 r2, 32                                    r2 >>= 32   ///  r2 = r2.wrapping_shr(32)
    jeq r2, 0, lbb_35222                            if r2 == (0 as i32 as i64 as u64) { pc += 124 }
lbb_35098:
    mov64 r2, r3                                    r2 = r3
    lsh64 r2, 2                                     r2 <<= 2   ///  r2 = r2.wrapping_shl(2)
    mov64 r4, r10                                   r4 = r10
    add64 r4, -72                                   r4 += -72   ///  r4 = r4.wrapping_add(-72 as i32 as i64 as u64)
    add64 r4, r2                                    r4 += r2   ///  r4 = r4.wrapping_add(r2)
    ldxw r2, [r4+0x0]                       
    jne r2, 0, lbb_35154                            if r2 != (0 as i32 as i64 as u64) { pc += 49 }
    mov64 r2, 3                                     r2 = 3 as i32 as i64 as u64
    jgt r2, r3, lbb_35108                           if r2 > r3 { pc += 1 }
    ja lbb_35154                                    if true { pc += 46 }
lbb_35108:
    ldxdw r2, [r10-0x58]                    
    lsh64 r2, 32                                    r2 <<= 32   ///  r2 = r2.wrapping_shl(32)
    rsh64 r2, 32                                    r2 >>= 32   ///  r2 = r2.wrapping_shr(32)
    mov64 r3, 29                                    r3 = 29 as i32 as i64 as u64
    jgt r3, r2, lbb_35197                           if r3 > r2 { pc += 84 }
lbb_35113:
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    stxdw [r10-0x28], r1                    
    lddw r1, 0x100066950 --> b"\x00\x00\x00\x00\x8f-\x06\x00%\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x0…        r1 load str located at 4295387472
    stxdw [r10-0x30], r1                    
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    stxdw [r10-0x10], r1                    
    stxdw [r10-0x18], r1                    
    lddw r1, 0x100062c08 --> b"invalid args/home/runner/work/platform-tools/platf"        r1 load str located at 4295371784
    stxdw [r10-0x20], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -48                                   r1 += -48   ///  r1 = r1.wrapping_add(-48 as i32 as i64 as u64)
    lddw r2, 0x100066960 --> b"\x00\x00\x00\x00\x81-\x06\x00\x0e\x00\x00\x00\x00\x00\x00\x00\x11\x02\x00…        r2 load str located at 4295387488
    call function_44240                     
    syscall [invalid]                       
lbb_35130:
    rsh64 r2, 32                                    r2 >>= 32   ///  r2 = r2.wrapping_shr(32)
    jgt r2, 9, lbb_35254                            if r2 > (9 as i32 as i64 as u64) { pc += 122 }
    ldxdw r2, [r10-0x70]                    
    ldxdw r8, [r2+0x0]                      
    ldxw r2, [r2+0xc]                       
    ldxdw r3, [r10-0x58]                    
    stxdw [r10-0xff0], r3                   
    ldxdw r3, [r10-0x68]                    
    stxdw [r10-0xfe8], r3                   
    ldxdw r3, [r10-0x78]                    
    stxdw [r10-0xff8], r3                   
    stxdw [r10-0x1000], r2                  
    ldxw r1, [r1+0x0]                       
    mul64 r0, r1                                    r0 *= r1   ///  r0 = r0.wrapping_mul(r1)
    mov64 r5, r10                                   r5 = r10
    ldxdw r1, [r10-0x60]                    
    mov64 r2, r0                                    r2 = r0
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
lbb_35148:
    mov64 r4, r8                                    r4 = r8
    call function_34467                     
    ja lbb_35196                                    if true { pc += 45 }
lbb_35151:
    mov64 r3, 1                                     r3 = 1 as i32 as i64 as u64
    stxw [r2+0x0], r3                       
    mov64 r3, r0                                    r3 = r0
lbb_35154:
    stxw [r10-0x40], r1                     
    stxw [r10-0x48], r5                     
    rsh64 r5, 32                                    r5 >>= 32   ///  r5 = r5.wrapping_shr(32)
    stxw [r10-0x44], r5                     
    mov64 r1, r10                                   r1 = r10
    add64 r1, -80                                   r1 += -80   ///  r1 = r1.wrapping_add(-80 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -72                                   r2 += -72   ///  r2 = r2.wrapping_add(-72 as i32 as i64 as u64)
    ldxdw r4, [r10-0x58]                    
    call function_35478                     
    mov64 r2, 1                                     r2 = 1 as i32 as i64 as u64
    ldxw r1, [r10-0x50]                     
    ldxdw r0, [r10-0x60]                    
    jeq r1, 1, lbb_35169                            if r1 == (1 as i32 as i64 as u64) { pc += 1 }
    ja lbb_35195                                    if true { pc += 26 }
lbb_35169:
    ldxw r1, [r10-0x4c]                     
    mov64 r2, r1                                    r2 = r1
    mov64 r3, 29                                    r3 = 29 as i32 as i64 as u64
    jgt r3, r2, lbb_35174                           if r3 > r2 { pc += 1 }
    ja lbb_35113                                    if true { pc += -61 }
lbb_35174:
    ldxw r4, [r10-0x48]                     
    ldxw r2, [r10-0x40]                     
    ldxw r3, [r10-0x44]                     
    stxw [r0+0x10], r3                      
    or64 r3, r2                                     r3 |= r2   ///  r3 = r3.or(r2)
    stxw [r0+0x8], r2                       
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
    mov64 r5, -2147483648                           r5 = -2147483648 as i32 as i64 as u64
    ldxdw r6, [r10-0x78]                    
    jne r6, 0, lbb_35185                            if r6 != (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r5, 0                                     r5 = 0 as i32 as i64 as u64
lbb_35185:
    stxw [r0+0xc], r4                       
    or64 r3, r4                                     r3 |= r4   ///  r3 = r3.or(r4)
    lsh64 r3, 32                                    r3 <<= 32   ///  r3 = r3.wrapping_shl(32)
    rsh64 r3, 32                                    r3 >>= 32   ///  r3 = r3.wrapping_shr(32)
    mov64 r4, 0                                     r4 = 0 as i32 as i64 as u64
    jeq r3, 0, lbb_35192                            if r3 == (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r4, r5                                    r4 = r5
lbb_35192:
    lsh64 r1, 16                                    r1 <<= 16   ///  r1 = r1.wrapping_shl(16)
    or64 r4, r1                                     r4 |= r1   ///  r4 = r4.or(r1)
    stxw [r0+0x4], r4                       
lbb_35195:
    stxw [r0+0x0], r2                       
lbb_35196:
    exit                                    
lbb_35197:
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
    mov64 r3, -2147483648                           r3 = -2147483648 as i32 as i64 as u64
    ldxdw r6, [r10-0x60]                    
    ldxdw r4, [r10-0x78]                    
    jne r4, 0, lbb_35203                            if r4 != (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
lbb_35203:
    stxw [r6+0xc], r5                       
    mov64 r0, r5                                    r0 = r5
    rsh64 r0, 32                                    r0 >>= 32   ///  r0 = r0.wrapping_shr(32)
    mov64 r4, r0                                    r4 = r0
    or64 r4, r5                                     r4 |= r5   ///  r4 = r4.or(r5)
    or64 r4, r1                                     r4 |= r1   ///  r4 = r4.or(r1)
    stxw [r6+0x8], r1                       
    lsh64 r4, 32                                    r4 <<= 32   ///  r4 = r4.wrapping_shl(32)
    rsh64 r4, 32                                    r4 >>= 32   ///  r4 = r4.wrapping_shr(32)
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    jeq r4, 0, lbb_35215                            if r4 == (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r1, r3                                    r1 = r3
lbb_35215:
    stxw [r6+0x0], r2                       
    stxw [r6+0x10], r0                      
    ldxdw r2, [r10-0x58]                    
    lsh64 r2, 16                                    r2 <<= 16   ///  r2 = r2.wrapping_shl(16)
    or64 r1, r2                                     r1 |= r2   ///  r1 = r1.or(r2)
    stxw [r6+0x4], r1                       
    ja lbb_35196                                    if true { pc += -26 }
lbb_35222:
    ldxw r2, [r10-0x38]                     
    add64 r2, -1                                    r2 += -1   ///  r2 = r2.wrapping_add(-1 as i32 as i64 as u64)
    stxw [r10-0x38], r2                     
    lsh64 r2, 32                                    r2 <<= 32   ///  r2 = r2.wrapping_shl(32)
    rsh64 r2, 32                                    r2 >>= 32   ///  r2 = r2.wrapping_shr(32)
    jne r2, 0, lbb_35098                            if r2 != (0 as i32 as i64 as u64) { pc += -130 }
    ldxw r2, [r10-0x34]                     
    add64 r2, -1                                    r2 += -1   ///  r2 = r2.wrapping_add(-1 as i32 as i64 as u64)
    stxw [r10-0x34], r2                     
    ja lbb_35098                                    if true { pc += -134 }
lbb_35232:
    mov64 r1, 6                                     r1 = 6 as i32 as i64 as u64
    mov64 r2, 6                                     r2 = 6 as i32 as i64 as u64
    lddw r3, 0x100066a60 --> b"\x00\x00\x00\x00\x94/\x06\x00\x0e\x00\x00\x00\x00\x00\x00\x00,\x01\x00\x0…        r3 load str located at 4295387744
    call function_44272                     
    syscall [invalid]                       
lbb_35238:
    mov64 r2, 10                                    r2 = 10 as i32 as i64 as u64
    lddw r3, 0x100066a48 --> b"\x00\x00\x00\x00\x94/\x06\x00\x0e\x00\x00\x00\x00\x00\x00\x00\x1b\x01\x00…        r3 load str located at 4295387720
    call function_44272                     
    syscall [invalid]                       
lbb_35243:
    mov64 r1, r5                                    r1 = r5
    mov64 r2, 10                                    r2 = 10 as i32 as i64 as u64
    lddw r3, 0x100066a30 --> b"\x00\x00\x00\x00\x94/\x06\x00\x0e\x00\x00\x00\x00\x00\x00\x00\xfb\x00\x00…        r3 load str located at 4295387696
    call function_44272                     
    syscall [invalid]                       
lbb_35249:
    mov64 r2, 10                                    r2 = 10 as i32 as i64 as u64
    lddw r3, 0x100066a00 --> b"\x00\x00\x00\x00\x94/\x06\x00\x0e\x00\x00\x00\x00\x00\x00\x00\xe5\x00\x00…        r3 load str located at 4295387648
    call function_44272                     
    syscall [invalid]                       
lbb_35254:
    mov64 r1, r8                                    r1 = r8
    mov64 r2, 10                                    r2 = 10 as i32 as i64 as u64
    lddw r3, 0x100066a18 --> b"\x00\x00\x00\x00\x94/\x06\x00\x0e\x00\x00\x00\x00\x00\x00\x00\xd9\x00\x00…        r3 load str located at 4295387672
    call function_44272                     
    syscall [invalid]                       

function_35260:
    ldxw r3, [r2+0xc]                       
    ldxdw r6, [r2+0x0]                      
    ldxw r4, [r1+0xc]                       
    ldxdw r5, [r1+0x0]                      
    ldxw r0, [r2+0x8]                       
    ldxw r1, [r1+0x8]                       
    jeq r0, r1, lbb_35367                           if r0 == r1 { pc += 100 }
    sub64 r0, r1                                    r0 -= r1   ///  r0 = r0.wrapping_sub(r1)
    lsh64 r0, 32                                    r0 <<= 32   ///  r0 = r0.wrapping_shl(32)
    arsh64 r0, 32                                   r0 >>= 32 (signed)   ///  r0 = (r0 as i64).wrapping_shr(32)
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    jsgt r1, r0, lbb_35317                          if (r1 as i64) > (r0 as i64) { pc += 45 }
    lsh64 r0, 32                                    r0 <<= 32   ///  r0 = r0.wrapping_shl(32)
    rsh64 r0, 32                                    r0 >>= 32   ///  r0 = r0.wrapping_shr(32)
    mov64 r2, r0                                    r2 = r0
    lsh64 r2, 2                                     r2 <<= 2   ///  r2 = r2.wrapping_shl(2)
    lddw r1, 0x100062e50 --> b"\x01\x00\x00\x00\x0a\x00\x00\x00d\x00\x00\x00\xe8\x03\x00\x00\x10'\x00\x0…        r1 load str located at 4295372368
    add64 r1, r2                                    r1 += r2   ///  r1 = r1.wrapping_add(r2)
    lddw r2, 0xffffffff                             r2 load str located at 4294967295
    mov64 r9, r5                                    r9 = r5
    ja lbb_35312                                    if true { pc += 29 }
lbb_35283:
    lsh64 r0, 32                                    r0 <<= 32   ///  r0 = r0.wrapping_shl(32)
    rsh64 r0, 32                                    r0 >>= 32   ///  r0 = r0.wrapping_shr(32)
    mov64 r7, r9                                    r7 = r9
    rsh64 r7, 32                                    r7 >>= 32   ///  r7 = r7.wrapping_shr(32)
    mul64 r7, r0                                    r7 *= r0   ///  r7 = r7.wrapping_mul(r0)
    lsh64 r9, 32                                    r9 <<= 32   ///  r9 = r9.wrapping_shl(32)
    rsh64 r9, 32                                    r9 >>= 32   ///  r9 = r9.wrapping_shr(32)
    mul64 r9, r0                                    r9 *= r0   ///  r9 = r9.wrapping_mul(r0)
    mov64 r5, r9                                    r5 = r9
    rsh64 r5, 32                                    r5 >>= 32   ///  r5 = r5.wrapping_shr(32)
    add64 r5, r7                                    r5 += r7   ///  r5 = r5.wrapping_add(r7)
    lsh64 r4, 32                                    r4 <<= 32   ///  r4 = r4.wrapping_shl(32)
    rsh64 r4, 32                                    r4 >>= 32   ///  r4 = r4.wrapping_shr(32)
    mul64 r0, r4                                    r0 *= r4   ///  r0 = r0.wrapping_mul(r4)
    mov64 r4, r5                                    r4 = r5
    rsh64 r4, 32                                    r4 >>= 32   ///  r4 = r4.wrapping_shr(32)
    add64 r4, r0                                    r4 += r0   ///  r4 = r4.wrapping_add(r0)
    mov64 r0, 1                                     r0 = 1 as i32 as i64 as u64
    jgt r4, r2, lbb_35374                           if r4 > r2 { pc += 72 }
    lsh64 r5, 32                                    r5 <<= 32   ///  r5 = r5.wrapping_shl(32)
    lsh64 r9, 32                                    r9 <<= 32   ///  r9 = r9.wrapping_shl(32)
    rsh64 r9, 32                                    r9 >>= 32   ///  r9 = r9.wrapping_shr(32)
    or64 r5, r9                                     r5 |= r9   ///  r5 = r5.or(r9)
    add64 r1, -36                                   r1 += -36   ///  r1 = r1.wrapping_add(-36 as i32 as i64 as u64)
    mov64 r0, r8                                    r0 = r8
    add64 r0, -9                                    r0 += -9   ///  r0 = r0.wrapping_add(-9 as i32 as i64 as u64)
    mov64 r9, r5                                    r9 = r5
    mov64 r7, 10                                    r7 = 10 as i32 as i64 as u64
    jgt r7, r8, lbb_35367                           if r7 > r8 { pc += 55 }
lbb_35312:
    mov64 r8, r0                                    r8 = r0
    mov64 r0, 1000000000                            r0 = 1000000000 as i32 as i64 as u64
    jgt r8, 8, lbb_35283                            if r8 > (8 as i32 as i64 as u64) { pc += -32 }
    ldxw r0, [r1+0x0]                       
    ja lbb_35283                                    if true { pc += -34 }
lbb_35317:
    neg64 r0                                        r0 = -r0   ///  r0 = (r0 as i64).wrapping_neg() as u64
    lsh64 r0, 32                                    r0 <<= 32   ///  r0 = r0.wrapping_shl(32)
    arsh64 r0, 32                                   r0 >>= 32 (signed)   ///  r0 = (r0 as i64).wrapping_shr(32)
    mov64 r1, r0                                    r1 = r0
    lsh64 r1, 2                                     r1 <<= 2   ///  r1 = r1.wrapping_shl(2)
    lddw r2, 0x100062e50 --> b"\x01\x00\x00\x00\x0a\x00\x00\x00d\x00\x00\x00\xe8\x03\x00\x00\x10'\x00\x0…        r2 load str located at 4295372368
    add64 r2, r1                                    r2 += r1   ///  r2 = r2.wrapping_add(r1)
    lddw r7, 0xffffffff                             r7 load str located at 4294967295
    mov64 r9, r6                                    r9 = r6
    ja lbb_35358                                    if true { pc += 29 }
lbb_35329:
    lsh64 r0, 32                                    r0 <<= 32   ///  r0 = r0.wrapping_shl(32)
    rsh64 r0, 32                                    r0 >>= 32   ///  r0 = r0.wrapping_shr(32)
    mov64 r8, r9                                    r8 = r9
    rsh64 r8, 32                                    r8 >>= 32   ///  r8 = r8.wrapping_shr(32)
    mul64 r8, r0                                    r8 *= r0   ///  r8 = r8.wrapping_mul(r0)
    lsh64 r9, 32                                    r9 <<= 32   ///  r9 = r9.wrapping_shl(32)
    rsh64 r9, 32                                    r9 >>= 32   ///  r9 = r9.wrapping_shr(32)
    mul64 r9, r0                                    r9 *= r0   ///  r9 = r9.wrapping_mul(r0)
    mov64 r6, r9                                    r6 = r9
    rsh64 r6, 32                                    r6 >>= 32   ///  r6 = r6.wrapping_shr(32)
    add64 r6, r8                                    r6 += r8   ///  r6 = r6.wrapping_add(r8)
    lsh64 r3, 32                                    r3 <<= 32   ///  r3 = r3.wrapping_shl(32)
    rsh64 r3, 32                                    r3 >>= 32   ///  r3 = r3.wrapping_shr(32)
    mul64 r0, r3                                    r0 *= r3   ///  r0 = r0.wrapping_mul(r3)
    mov64 r3, r6                                    r3 = r6
    rsh64 r3, 32                                    r3 >>= 32   ///  r3 = r3.wrapping_shr(32)
    add64 r3, r0                                    r3 += r0   ///  r3 = r3.wrapping_add(r0)
    mov64 r0, 255                                   r0 = 255 as i32 as i64 as u64
    jgt r3, r7, lbb_35374                           if r3 > r7 { pc += 26 }
    lsh64 r6, 32                                    r6 <<= 32   ///  r6 = r6.wrapping_shl(32)
    lsh64 r9, 32                                    r9 <<= 32   ///  r9 = r9.wrapping_shl(32)
    rsh64 r9, 32                                    r9 >>= 32   ///  r9 = r9.wrapping_shr(32)
    or64 r6, r9                                     r6 |= r9   ///  r6 = r6.or(r9)
    add64 r2, -36                                   r2 += -36   ///  r2 = r2.wrapping_add(-36 as i32 as i64 as u64)
    mov64 r0, r1                                    r0 = r1
    add64 r0, -9                                    r0 += -9   ///  r0 = r0.wrapping_add(-9 as i32 as i64 as u64)
    mov64 r9, r6                                    r9 = r6
    mov64 r8, 10                                    r8 = 10 as i32 as i64 as u64
    jsgt r8, r1, lbb_35367                          if (r8 as i64) > (r1 as i64) { pc += 9 }
lbb_35358:
    mov64 r1, r0                                    r1 = r0
    mov64 r0, 1000000000                            r0 = 1000000000 as i32 as i64 as u64
    jsgt r1, 8, lbb_35329                           if (r1 as i64) > (8 as i32 as i64) { pc += -32 }
    mov64 r0, r1                                    r0 = r1
    lsh64 r0, 32                                    r0 <<= 32   ///  r0 = r0.wrapping_shl(32)
    rsh64 r0, 32                                    r0 >>= 32   ///  r0 = r0.wrapping_shr(32)
    jgt r0, 9, lbb_35383                            if r0 > (9 as i32 as i64 as u64) { pc += 18 }
    ldxw r0, [r2+0x0]                       
    ja lbb_35329                                    if true { pc += -38 }
lbb_35367:
    lsh64 r4, 32                                    r4 <<= 32   ///  r4 = r4.wrapping_shl(32)
    rsh64 r4, 32                                    r4 >>= 32   ///  r4 = r4.wrapping_shr(32)
    lsh64 r3, 32                                    r3 <<= 32   ///  r3 = r3.wrapping_shl(32)
    rsh64 r3, 32                                    r3 >>= 32   ///  r3 = r3.wrapping_shr(32)
    mov64 r0, 255                                   r0 = 255 as i32 as i64 as u64
    jgt r3, r4, lbb_35374                           if r3 > r4 { pc += 1 }
    ja lbb_35375                                    if true { pc += 1 }
lbb_35374:
    exit                                    
lbb_35375:
    mov64 r0, 1                                     r0 = 1 as i32 as i64 as u64
    jne r4, r3, lbb_35374                           if r4 != r3 { pc += -3 }
    mov64 r0, 255                                   r0 = 255 as i32 as i64 as u64
    jgt r6, r5, lbb_35374                           if r6 > r5 { pc += -5 }
    mov64 r0, 1                                     r0 = 1 as i32 as i64 as u64
    jne r5, r6, lbb_35374                           if r5 != r6 { pc += -7 }
    mov64 r0, 0                                     r0 = 0 as i32 as i64 as u64
    ja lbb_35374                                    if true { pc += -9 }
lbb_35383:
    mov64 r2, 10                                    r2 = 10 as i32 as i64 as u64
    lddw r3, 0x100066a78 --> b"\x00\x00\x00\x00\xa2/\x06\x00\x0e\x00\x00\x00\x00\x00\x00\x00P\x00\x00\x0…        r3 load str located at 4295387768
    call function_44272                     
    syscall [invalid]                       

function_35388:
    ldxw r0, [r2+0x8]                       
    jgt r0, 429496729, lbb_35462                    if r0 > (429496729 as i32 as i64 as u64) { pc += 72 }
    ldxdw r5, [r2+0x0]                      
    mov64 r2, r3                                    r2 = r3
    lsh64 r2, 32                                    r2 <<= 32   ///  r2 = r2.wrapping_shl(32)
    arsh64 r2, 32                                   r2 >>= 32 (signed)   ///  r2 = (r2 as i64).wrapping_shr(32)
    jsgt r2, 19, lbb_35396                          if (r2 as i64) > (19 as i32 as i64) { pc += 1 }
    ja lbb_35413                                    if true { pc += 17 }
lbb_35396:
    mov64 r4, 28                                    r4 = 28 as i32 as i64 as u64
    sub64 r4, r3                                    r4 -= r3   ///  r4 = r4.wrapping_sub(r3)
    lsh64 r4, 32                                    r4 <<= 32   ///  r4 = r4.wrapping_shl(32)
    arsh64 r4, 32                                   r4 >>= 32 (signed)   ///  r4 = (r4 as i64).wrapping_shr(32)
    mov64 r2, r4                                    r2 = r4
    add64 r2, -1                                    r2 += -1   ///  r2 = r2.wrapping_add(-1 as i32 as i64 as u64)
    mov64 r6, 8                                     r6 = 8 as i32 as i64 as u64
    jgt r6, r2, lbb_35405                           if r6 > r2 { pc += 1 }
    ja lbb_35472                                    if true { pc += 67 }
lbb_35405:
    mul64 r2, 12                                    r2 *= 12   ///  r2 = r2.wrapping_mul(12 as u64)
    lddw r6, 0x100062fc4 --> b"\x99\x99\x99\x99\x99\x99\x99\x99\x99\x99\x99\x19\x8f\xc2\xf5(\\x8f\xc2\xf…        r6 load str located at 4295372740
    add64 r6, r2                                    r6 += r2   ///  r6 = r6.wrapping_add(r2)
    mov64 r2, 1                                     r2 = 1 as i32 as i64 as u64
    ldxw r6, [r6+0x8]                       
    jgt r6, r0, lbb_35468                           if r6 > r0 { pc += 56 }
    ja lbb_35421                                    if true { pc += 8 }
lbb_35413:
    mov64 r2, 1                                     r2 = 1 as i32 as i64 as u64
    mov64 r4, 9                                     r4 = 9 as i32 as i64 as u64
    mov64 r6, 4                                     r6 = 4 as i32 as i64 as u64
    jgt r6, r0, lbb_35468                           if r6 > r0 { pc += 51 }
    jne r0, 4, lbb_35421                            if r0 != (4 as i32 as i64 as u64) { pc += 3 }
    lddw r6, 0x4b82fa09b5a52cba                     r6 load str located at 5441186219426131130
    jgt r6, r5, lbb_35468                           if r6 > r5 { pc += 47 }
lbb_35421:
    jgt r0, 42949, lbb_35423                        if r0 > (42949 as i32 as i64 as u64) { pc += 1 }
    ja lbb_35429                                    if true { pc += 6 }
lbb_35423:
    jgt r0, 4294967, lbb_35425                      if r0 > (4294967 as i32 as i64 as u64) { pc += 1 }
    ja lbb_35435                                    if true { pc += 10 }
lbb_35425:
    mov64 r4, 1                                     r4 = 1 as i32 as i64 as u64
    jgt r0, 42949672, lbb_35442                     if r0 > (42949672 as i32 as i64 as u64) { pc += 15 }
    mov64 r4, 2                                     r4 = 2 as i32 as i64 as u64
    ja lbb_35442                                    if true { pc += 13 }
lbb_35429:
    jgt r0, 429, lbb_35431                          if r0 > (429 as i32 as i64 as u64) { pc += 1 }
    ja lbb_35439                                    if true { pc += 8 }
lbb_35431:
    mov64 r4, 5                                     r4 = 5 as i32 as i64 as u64
    jgt r0, 4294, lbb_35442                         if r0 > (4294 as i32 as i64 as u64) { pc += 9 }
    mov64 r4, 6                                     r4 = 6 as i32 as i64 as u64
    ja lbb_35442                                    if true { pc += 7 }
lbb_35435:
    mov64 r4, 3                                     r4 = 3 as i32 as i64 as u64
    jgt r0, 429496, lbb_35442                       if r0 > (429496 as i32 as i64 as u64) { pc += 5 }
    mov64 r4, 4                                     r4 = 4 as i32 as i64 as u64
    ja lbb_35442                                    if true { pc += 3 }
lbb_35439:
    mov64 r4, 7                                     r4 = 7 as i32 as i64 as u64
    jgt r0, 42, lbb_35442                           if r0 > (42 as i32 as i64 as u64) { pc += 1 }
    mov64 r4, 8                                     r4 = 8 as i32 as i64 as u64
lbb_35442:
    mov64 r2, r4                                    r2 = r4
    add64 r2, -1                                    r2 += -1   ///  r2 = r2.wrapping_add(-1 as i32 as i64 as u64)
    mov64 r7, r2                                    r7 = r2
    mul64 r7, 12                                    r7 *= 12   ///  r7 = r7.wrapping_mul(12 as u64)
    lddw r6, 0x100062fc4 --> b"\x99\x99\x99\x99\x99\x99\x99\x99\x99\x99\x99\x19\x8f\xc2\xf5(\\x8f\xc2\xf…        r6 load str located at 4295372740
    add64 r6, r7                                    r6 += r7   ///  r6 = r6.wrapping_add(r7)
    ldxw r7, [r6+0x8]                       
    jeq r0, r7, lbb_35452                           if r0 == r7 { pc += 1 }
    ja lbb_35455                                    if true { pc += 3 }
lbb_35452:
    ldxdw r0, [r6+0x0]                      
    jge r0, r5, lbb_35455                           if r0 >= r5 { pc += 1 }
    mov64 r4, r2                                    r4 = r2
lbb_35455:
    mov64 r5, r4                                    r5 = r4
    add64 r5, r3                                    r5 += r3   ///  r5 = r5.wrapping_add(r3)
    lsh64 r5, 32                                    r5 <<= 32   ///  r5 = r5.wrapping_shl(32)
    arsh64 r5, 32                                   r5 >>= 32 (signed)   ///  r5 = (r5 as i64).wrapping_shr(32)
    mov64 r2, 1                                     r2 = 1 as i32 as i64 as u64
    jsgt r5, -1, lbb_35468                          if (r5 as i64) > (-1 as i32 as i64) { pc += 7 }
    ja lbb_35467                                    if true { pc += 5 }
lbb_35462:
    lsh64 r3, 32                                    r3 <<= 32   ///  r3 = r3.wrapping_shl(32)
    arsh64 r3, 32                                   r3 >>= 32 (signed)   ///  r3 = (r3 as i64).wrapping_shr(32)
    mov64 r4, 0                                     r4 = 0 as i32 as i64 as u64
    mov64 r2, 1                                     r2 = 1 as i32 as i64 as u64
    jsgt r3, -1, lbb_35468                          if (r3 as i64) > (-1 as i32 as i64) { pc += 1 }
lbb_35467:
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
lbb_35468:
    stxdw [r1+0x8], r4                      
    and64 r2, 1                                     r2 &= 1   ///  r2 = r2.and(1)
    stxdw [r1+0x0], r2                      
    exit                                    
lbb_35472:
    mov64 r1, r2                                    r1 = r2
    mov64 r2, 8                                     r2 = 8 as i32 as i64 as u64
    lddw r3, 0x100066a90 --> b"\x00\x00\x00\x00\xb0/\x06\x00\x11\x00\x00\x00\x00\x00\x00\x00i\x00\x00\x0…        r3 load str located at 4295387792
    call function_44272                     
    syscall [invalid]                       

function_35478:
    mov64 r8, r3                                    r8 = r3
    mov64 r0, r2                                    r0 = r2
    stxdw [r10-0x30], r1                    
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
    mov64 r1, 3                                     r1 = 3 as i32 as i64 as u64
    jgt r1, r8, lbb_35550                           if r1 > r8 { pc += 66 }
    mov64 r1, 6                                     r1 = 6 as i32 as i64 as u64
    jgt r1, r8, lbb_35487                           if r1 > r8 { pc += 1 }
    ja lbb_35761                                    if true { pc += 274 }
lbb_35487:
    mov64 r1, r8                                    r1 = r8
    lsh64 r1, 2                                     r1 <<= 2   ///  r1 = r1.wrapping_shl(2)
    mov64 r3, r0                                    r3 = r0
    add64 r3, r1                                    r3 += r1   ///  r3 = r3.wrapping_add(r1)
    mov64 r2, 32                                    r2 = 32 as i32 as i64 as u64
    mov64 r1, r8                                    r1 = r8
    lsh64 r1, 5                                     r1 <<= 5   ///  r1 = r1.wrapping_shl(5)
    add64 r1, -65                                   r1 += -65   ///  r1 = r1.wrapping_add(-65 as i32 as i64 as u64)
    ldxw r5, [r3+0x0]                       
    jeq r5, 0, lbb_35537                            if r5 == (0 as i32 as i64 as u64) { pc += 40 }
    mov64 r2, r5                                    r2 = r5
    rsh64 r2, 1                                     r2 >>= 1   ///  r2 = r2.wrapping_shr(1)
    or64 r5, r2                                     r5 |= r2   ///  r5 = r5.or(r2)
    mov64 r2, r5                                    r2 = r5
    rsh64 r2, 2                                     r2 >>= 2   ///  r2 = r2.wrapping_shr(2)
    or64 r5, r2                                     r5 |= r2   ///  r5 = r5.or(r2)
    mov64 r2, r5                                    r2 = r5
    rsh64 r2, 4                                     r2 >>= 4   ///  r2 = r2.wrapping_shr(4)
    or64 r5, r2                                     r5 |= r2   ///  r5 = r5.or(r2)
    lddw r2, 0xffffff00                             r2 load str located at 4294967040
    mov64 r3, r5                                    r3 = r5
    and64 r3, r2                                    r3 &= r2   ///  r3 = r3.and(r2)
    rsh64 r3, 8                                     r3 >>= 8   ///  r3 = r3.wrapping_shr(8)
    or64 r5, r3                                     r5 |= r3   ///  r5 = r5.or(r3)
    lddw r2, 0xffff0000                             r2 load str located at 4294901760
    mov64 r3, r5                                    r3 = r5
    and64 r3, r2                                    r3 &= r2   ///  r3 = r3.and(r2)
    rsh64 r3, 16                                    r3 >>= 16   ///  r3 = r3.wrapping_shr(16)
    or64 r5, r3                                     r5 |= r3   ///  r5 = r5.or(r3)
    xor64 r5, -1                                    r5 ^= -1   ///  r5 = r5.xor(-1)
    mov64 r2, r5                                    r2 = r5
    rsh64 r2, 1                                     r2 >>= 1   ///  r2 = r2.wrapping_shr(1)
    and64 r2, 1431655765                            r2 &= 1431655765   ///  r2 = r2.and(1431655765)
    sub64 r5, r2                                    r5 -= r2   ///  r5 = r5.wrapping_sub(r2)
    mov64 r2, r5                                    r2 = r5
    and64 r2, 858993459                             r2 &= 858993459   ///  r2 = r2.and(858993459)
    rsh64 r5, 2                                     r5 >>= 2   ///  r5 = r5.wrapping_shr(2)
    and64 r5, 858993459                             r5 &= 858993459   ///  r5 = r5.and(858993459)
    add64 r2, r5                                    r2 += r5   ///  r2 = r2.wrapping_add(r5)
    mov64 r3, r2                                    r3 = r2
    rsh64 r3, 4                                     r3 >>= 4   ///  r3 = r3.wrapping_shr(4)
    add64 r2, r3                                    r2 += r3   ///  r2 = r2.wrapping_add(r3)
    and64 r2, 252645135                             r2 &= 252645135   ///  r2 = r2.and(252645135)
    mul64 r2, 16843009                              r2 *= 16843009   ///  r2 = r2.wrapping_mul(16843009 as u64)
    lddw r3, 0xff000000                             r3 load str located at 4278190080
    and64 r2, r3                                    r2 &= r3   ///  r2 = r2.and(r3)
    rsh64 r2, 24                                    r2 >>= 24   ///  r2 = r2.wrapping_shr(24)
lbb_35537:
    sub64 r1, r2                                    r1 -= r2   ///  r1 = r1.wrapping_sub(r2)
    lddw r2, 0x4d00000000                           r2 load str located at 330712481792
    mul64 r1, r2                                    r1 *= r2   ///  r1 = r1.wrapping_mul(r2)
    mov64 r6, 0                                     r6 = 0 as i32 as i64 as u64
    arsh64 r1, 40                                   r1 >>= 40 (signed)   ///  r1 = (r1 as i64).wrapping_shr(40)
    mov64 r2, r1                                    r2 = r1
    add64 r2, 1                                     r2 += 1   ///  r2 = r2.wrapping_add(1 as i32 as i64 as u64)
    mov64 r3, r4                                    r3 = r4
    lsh64 r3, 32                                    r3 <<= 32   ///  r3 = r3.wrapping_shl(32)
    arsh64 r3, 32                                   r3 >>= 32 (signed)   ///  r3 = (r3 as i64).wrapping_shr(32)
    jsgt r3, r1, lbb_35550                          if (r3 as i64) > (r1 as i64) { pc += 1 }
    ja lbb_35739                                    if true { pc += 189 }
lbb_35550:
    mov64 r1, r4                                    r1 = r4
    lsh64 r1, 32                                    r1 <<= 32   ///  r1 = r1.wrapping_shl(32)
    lddw r3, 0xffffffe400000000                     r3 load str located at -120259084288
    add64 r1, r3                                    r1 += r3   ///  r1 = r1.wrapping_add(r3)
    arsh64 r1, 32                                   r1 >>= 32 (signed)   ///  r1 = (r1 as i64).wrapping_shr(32)
    jsgt r2, r1, lbb_35558                          if (r2 as i64) > (r1 as i64) { pc += 1 }
    mov64 r2, r1                                    r2 = r1
lbb_35558:
    mov64 r6, 1                                     r6 = 1 as i32 as i64 as u64
    jeq r2, 0, lbb_35739                            if r2 == (0 as i32 as i64 as u64) { pc += 179 }
    sub64 r4, r2                                    r4 -= r2   ///  r4 = r4.wrapping_sub(r2)
    mov64 r7, 0                                     r7 = 0 as i32 as i64 as u64
    mov64 r5, r0                                    r5 = r0
    add64 r5, -8                                    r5 += -8   ///  r5 = r5.wrapping_add(-8 as i32 as i64 as u64)
    mov64 r1, r0                                    r1 = r0
    add64 r1, -4                                    r1 += -4   ///  r1 = r1.wrapping_add(-4 as i32 as i64 as u64)
    stxdw [r10-0x28], r1                    
    mov64 r9, r4                                    r9 = r4
    mov64 r6, r2                                    r6 = r2
    stxdw [r10-0x20], r0                    
    ja lbb_35575                                    if true { pc += 4 }
lbb_35571:
    add64 r6, -9                                    r6 += -9   ///  r6 = r6.wrapping_add(-9 as i32 as i64 as u64)
lbb_35572:
    ldxdw r1, [r10-0x18]                    
    or64 r1, r7                                     r1 |= r7   ///  r1 = r1.or(r7)
    mov64 r7, r1                                    r7 = r1
lbb_35575:
    mov64 r1, r6                                    r1 = r6
    lsh64 r1, 32                                    r1 <<= 32   ///  r1 = r1.wrapping_shl(32)
    rsh64 r1, 32                                    r1 >>= 32   ///  r1 = r1.wrapping_shr(32)
    jgt r1, 8, lbb_35592                            if r1 > (8 as i32 as i64 as u64) { pc += 13 }
    mov64 r1, 6                                     r1 = 6 as i32 as i64 as u64
    jgt r1, r8, lbb_35582                           if r1 > r8 { pc += 1 }
    ja lbb_35755                                    if true { pc += 173 }
lbb_35582:
    mov64 r1, r6                                    r1 = r6
    lsh64 r1, 32                                    r1 <<= 32   ///  r1 = r1.wrapping_shl(32)
    rsh64 r1, 32                                    r1 >>= 32   ///  r1 = r1.wrapping_shr(32)
    lsh64 r1, 2                                     r1 <<= 2   ///  r1 = r1.wrapping_shl(2)
    lddw r3, 0x100062e50 --> b"\x01\x00\x00\x00\x0a\x00\x00\x00d\x00\x00\x00\xe8\x03\x00\x00\x10'\x00\x0…        r3 load str located at 4295372368
    add64 r3, r1                                    r3 += r1   ///  r3 = r3.wrapping_add(r1)
    ldxw r1, [r3+0x0]                       
    jeq r1, 0, lbb_35748                            if r1 == (0 as i32 as i64 as u64) { pc += 157 }
    ja lbb_35596                                    if true { pc += 4 }
lbb_35592:
    mov64 r1, 1000000000                            r1 = 1000000000 as i32 as i64 as u64
    mov64 r2, 6                                     r2 = 6 as i32 as i64 as u64
    jgt r2, r8, lbb_35596                           if r2 > r8 { pc += 1 }
    ja lbb_35755                                    if true { pc += 159 }
lbb_35596:
    stxdw [r10-0x18], r7                    
    stxdw [r10-0x10], r6                    
    stxdw [r10-0x8], r9                     
    mov64 r3, r8                                    r3 = r8
    lsh64 r3, 2                                     r3 <<= 2   ///  r3 = r3.wrapping_shl(2)
    mov64 r2, r8                                    r2 = r8
    mov64 r6, r0                                    r6 = r0
    add64 r6, r3                                    r6 += r3   ///  r6 = r6.wrapping_add(r3)
    ldxw r9, [r6+0x0]                       
    mov64 r4, r9                                    r4 = r9
    div64 r4, r1                                    r4 /= r1   ///  r4 = r4 / r1
    mov64 r0, r4                                    r0 = r4
    mul64 r0, r1                                    r0 *= r1   ///  r0 = r0.wrapping_mul(r1)
    mov64 r7, r9                                    r7 = r9
    sub64 r7, r0                                    r7 -= r0   ///  r7 = r7.wrapping_sub(r0)
    jeq r2, 0, lbb_35641                            if r2 == (0 as i32 as i64 as u64) { pc += 29 }
    ldxdw r2, [r10-0x28]                    
    add64 r2, r3                                    r2 += r3   ///  r2 = r2.wrapping_add(r3)
    lsh64 r7, 32                                    r7 <<= 32   ///  r7 = r7.wrapping_shl(32)
    ldxw r0, [r2+0x0]                       
    or64 r7, r0                                     r7 |= r0   ///  r7 = r7.or(r0)
    div64 r7, r1                                    r7 /= r1   ///  r7 = r7 / r1
    stxw [r2+0x0], r7                       
    mov64 r3, r1                                    r3 = r1
    mul64 r3, r7                                    r3 *= r7   ///  r3 = r3.wrapping_mul(r7)
    sub64 r0, r3                                    r0 -= r3   ///  r0 = r0.wrapping_sub(r3)
    mov64 r7, r0                                    r7 = r0
    ldxdw r3, [r10-0x20]                    
    jeq r2, r3, lbb_35641                           if r2 == r3 { pc += 16 }
    mov64 r3, r8                                    r3 = r8
    lsh64 r3, 2                                     r3 <<= 2   ///  r3 = r3.wrapping_shl(2)
lbb_35627:
    mov64 r2, r5                                    r2 = r5
    add64 r2, r3                                    r2 += r3   ///  r2 = r2.wrapping_add(r3)
    lsh64 r0, 32                                    r0 <<= 32   ///  r0 = r0.wrapping_shl(32)
    ldxw r7, [r2+0x0]                       
    or64 r0, r7                                     r0 |= r7   ///  r0 = r0.or(r7)
    div64 r0, r1                                    r0 /= r1   ///  r0 = r0 / r1
    stxw [r2+0x0], r0                       
    mov64 r2, r1                                    r2 = r1
    mul64 r2, r0                                    r2 *= r0   ///  r2 = r2.wrapping_mul(r0)
    sub64 r7, r2                                    r7 -= r2   ///  r7 = r7.wrapping_sub(r2)
    add64 r3, -4                                    r3 += -4   ///  r3 = r3.wrapping_add(-4 as i32 as i64 as u64)
    mov64 r0, r7                                    r0 = r7
    jeq r3, 4, lbb_35641                            if r3 == (4 as i32 as i64 as u64) { pc += 1 }
    ja lbb_35627                                    if true { pc += -14 }
lbb_35641:
    stxw [r6+0x0], r4                       
    mov64 r4, 1                                     r4 = 1 as i32 as i64 as u64
    mov64 r3, 1                                     r3 = 1 as i32 as i64 as u64
    jgt r1, r9, lbb_35646                           if r1 > r9 { pc += 1 }
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
lbb_35646:
    ldxdw r0, [r10-0x20]                    
    ldxdw r6, [r10-0x10]                    
    jne r8, 0, lbb_35650                            if r8 != (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r4, 0                                     r4 = 0 as i32 as i64 as u64
lbb_35650:
    and64 r3, r4                                    r3 &= r4   ///  r3 = r3.and(r4)
    sub64 r8, r3                                    r8 -= r3   ///  r8 = r8.wrapping_sub(r3)
    mov64 r2, r6                                    r2 = r6
    lsh64 r2, 32                                    r2 <<= 32   ///  r2 = r2.wrapping_shl(32)
    arsh64 r2, 32                                   r2 >>= 32 (signed)   ///  r2 = (r2 as i64).wrapping_shr(32)
    ldxdw r9, [r10-0x8]                     
    jsgt r2, 9, lbb_35571                           if (r2 as i64) > (9 as i32 as i64) { pc += -86 }
    jgt r8, 2, lbb_35659                            if r8 > (2 as i32 as i64 as u64) { pc += 1 }
    ja lbb_35668                                    if true { pc += 9 }
lbb_35659:
    mov64 r4, 0                                     r4 = 0 as i32 as i64 as u64
    mov64 r1, r9                                    r1 = r9
    lsh64 r1, 32                                    r1 <<= 32   ///  r1 = r1.wrapping_shl(32)
    rsh64 r1, 32                                    r1 >>= 32   ///  r1 = r1.wrapping_shr(32)
    mov64 r6, 0                                     r6 = 0 as i32 as i64 as u64
    jeq r1, 0, lbb_35739                            if r1 == (0 as i32 as i64 as u64) { pc += 74 }
    mov64 r6, 1                                     r6 = 1 as i32 as i64 as u64
    add64 r9, -1                                    r9 += -1   ///  r9 = r9.wrapping_add(-1 as i32 as i64 as u64)
    ja lbb_35572                                    if true { pc += -96 }
lbb_35668:
    mov64 r6, 1                                     r6 = 1 as i32 as i64 as u64
    rsh64 r1, 1                                     r1 >>= 1   ///  r1 = r1.wrapping_shr(1)
    lsh64 r7, 32                                    r7 <<= 32   ///  r7 = r7.wrapping_shl(32)
    rsh64 r7, 32                                    r7 >>= 32   ///  r7 = r7.wrapping_shr(32)
    mov64 r4, r9                                    r4 = r9
    jgt r1, r7, lbb_35739                           if r1 > r7 { pc += 65 }
    ldxw r2, [r0+0x0]                       
    jgt r7, r1, lbb_35684                           if r7 > r1 { pc += 8 }
    mov64 r1, r2                                    r1 = r2
    and64 r1, 1                                     r1 &= 1   ///  r1 = r1.and(1)
    ldxdw r3, [r10-0x18]                    
    or64 r1, r3                                     r1 |= r3   ///  r1 = r1.or(r3)
    lsh64 r1, 32                                    r1 <<= 32   ///  r1 = r1.wrapping_shl(32)
    rsh64 r1, 32                                    r1 >>= 32   ///  r1 = r1.wrapping_shr(32)
    mov64 r4, r9                                    r4 = r9
    jeq r1, 0, lbb_35739                            if r1 == (0 as i32 as i64 as u64) { pc += 55 }
lbb_35684:
    mov64 r1, r2                                    r1 = r2
    add64 r1, 1                                     r1 += 1   ///  r1 = r1.wrapping_add(1 as i32 as i64 as u64)
    stxw [r0+0x0], r1                       
    mov64 r2, r1                                    r2 = r1
    lsh64 r2, 32                                    r2 <<= 32   ///  r2 = r2.wrapping_shl(32)
    rsh64 r2, 32                                    r2 >>= 32   ///  r2 = r2.wrapping_shr(32)
    mov64 r4, r9                                    r4 = r9
    jeq r2, r1, lbb_35739                           if r2 == r1 { pc += 47 }
    ldxw r1, [r0+0x4]                       
    add64 r1, 1                                     r1 += 1   ///  r1 = r1.wrapping_add(1 as i32 as i64 as u64)
    stxw [r0+0x4], r1                       
    mov64 r2, r1                                    r2 = r1
    lsh64 r2, 32                                    r2 <<= 32   ///  r2 = r2.wrapping_shl(32)
    rsh64 r2, 32                                    r2 >>= 32   ///  r2 = r2.wrapping_shr(32)
    mov64 r4, r9                                    r4 = r9
    jne r2, r1, lbb_35701                           if r2 != r1 { pc += 1 }
    ja lbb_35739                                    if true { pc += 38 }
lbb_35701:
    ldxw r2, [r0+0x8]                       
    add64 r2, 1                                     r2 += 1   ///  r2 = r2.wrapping_add(1 as i32 as i64 as u64)
    stxw [r0+0x8], r2                       
    mov64 r8, 2                                     r8 = 2 as i32 as i64 as u64
    mov64 r1, r2                                    r1 = r2
    lsh64 r1, 32                                    r1 <<= 32   ///  r1 = r1.wrapping_shl(32)
    rsh64 r1, 32                                    r1 >>= 32   ///  r1 = r1.wrapping_shr(32)
    jne r1, r2, lbb_35710                           if r1 != r2 { pc += 1 }
    ja lbb_35730                                    if true { pc += 20 }
lbb_35710:
    ldxw r2, [r0+0xc]                       
    add64 r2, 1                                     r2 += 1   ///  r2 = r2.wrapping_add(1 as i32 as i64 as u64)
    stxw [r0+0xc], r2                       
    mov64 r8, 3                                     r8 = 3 as i32 as i64 as u64
    mov64 r3, r2                                    r3 = r2
    lsh64 r3, 32                                    r3 <<= 32   ///  r3 = r3.wrapping_shl(32)
    rsh64 r3, 32                                    r3 >>= 32   ///  r3 = r3.wrapping_shr(32)
    jeq r3, r2, lbb_35730                           if r3 == r2 { pc += 12 }
    ldxw r2, [r0+0x10]                      
    add64 r2, 1                                     r2 += 1   ///  r2 = r2.wrapping_add(1 as i32 as i64 as u64)
    stxw [r0+0x10], r2                      
    mov64 r8, 4                                     r8 = 4 as i32 as i64 as u64
    mov64 r3, r2                                    r3 = r2
    lsh64 r3, 32                                    r3 <<= 32   ///  r3 = r3.wrapping_shl(32)
    rsh64 r3, 32                                    r3 >>= 32   ///  r3 = r3.wrapping_shr(32)
    jeq r3, r2, lbb_35730                           if r3 == r2 { pc += 4 }
    ldxw r2, [r0+0x14]                      
    add64 r2, 1                                     r2 += 1   ///  r2 = r2.wrapping_add(1 as i32 as i64 as u64)
    stxw [r0+0x14], r2                      
    mov64 r8, 5                                     r8 = 5 as i32 as i64 as u64
lbb_35730:
    mov64 r4, r9                                    r4 = r9
    jeq r1, 0, lbb_35733                            if r1 == (0 as i32 as i64 as u64) { pc += 1 }
    ja lbb_35739                                    if true { pc += 6 }
lbb_35733:
    mov64 r4, 0                                     r4 = 0 as i32 as i64 as u64
    mov64 r1, r9                                    r1 = r9
    lsh64 r1, 32                                    r1 <<= 32   ///  r1 = r1.wrapping_shl(32)
    rsh64 r1, 32                                    r1 >>= 32   ///  r1 = r1.wrapping_shr(32)
    mov64 r6, 0                                     r6 = 0 as i32 as i64 as u64
    jne r1, 0, lbb_35743                            if r1 != (0 as i32 as i64 as u64) { pc += 4 }
lbb_35739:
    ldxdw r1, [r10-0x30]                    
    stxw [r1+0x4], r4                       
    stxw [r1+0x0], r6                       
    exit                                    
lbb_35743:
    mov64 r6, 1                                     r6 = 1 as i32 as i64 as u64
    add64 r9, -1                                    r9 += -1   ///  r9 = r9.wrapping_add(-1 as i32 as i64 as u64)
    mov64 r7, 0                                     r7 = 0 as i32 as i64 as u64
    or64 r7, r7                                     r7 |= r7   ///  r7 = r7.or(r7)
    ja lbb_35575                                    if true { pc += -173 }
lbb_35748:
    lddw r1, 0x100062c70 --> b"attempt to divide by zero"        r1 load str located at 4295371888
    mov64 r2, 25                                    r2 = 25 as i32 as i64 as u64
    lddw r3, 0x100066ad8 --> b"\x00\x00\x00\x00\xb0/\x06\x00\x11\x00\x00\x00\x00\x00\x00\x00t\x01\x00\x0…        r3 load str located at 4295387864
    call function_44254                     
    syscall [invalid]                       
lbb_35755:
    mov64 r1, r8                                    r1 = r8
    mov64 r2, 6                                     r2 = 6 as i32 as i64 as u64
    lddw r3, 0x100066ac0 --> b"\x00\x00\x00\x00\xb0/\x06\x00\x11\x00\x00\x00\x00\x00\x00\x00s\x01\x00\x0…        r3 load str located at 4295387840
    call function_44272                     
    syscall [invalid]                       
lbb_35761:
    mov64 r1, r8                                    r1 = r8
    mov64 r2, 6                                     r2 = 6 as i32 as i64 as u64
    lddw r3, 0x100066aa8 --> b"\x00\x00\x00\x00\xb0/\x06\x00\x11\x00\x00\x00\x00\x00\x00\x00Y\x01\x00\x0…        r3 load str located at 4295387816
    call function_44272                     
    syscall [invalid]                       

function_35767:
    ldxw r9, [r3+0x4]                       
    ldxw r5, [r3+0xc]                       
    mov64 r0, r9                                    r0 = r9
    or64 r0, r5                                     r0 |= r5   ///  r0 = r0.or(r5)
    ldxw r7, [r3+0x8]                       
    mov64 r4, r0                                    r4 = r0
    or64 r4, r7                                     r4 |= r7   ///  r4 = r4.or(r7)
    jne r4, 0, lbb_35778                            if r4 != (0 as i32 as i64 as u64) { pc += 3 }
    mov64 r2, 2                                     r2 = 2 as i32 as i64 as u64
    stxw [r1+0x0], r2                       
    ja lbb_37032                                    if true { pc += 1254 }
lbb_35778:
    stxdw [r10-0xc8], r1                    
    ldxw r8, [r2+0x4]                       
    ldxw r1, [r2+0x8]                       
    ldxw r4, [r2+0xc]                       
    mov64 r6, r4                                    r6 = r4
    or64 r6, r1                                     r6 |= r1   ///  r6 = r6.or(r1)
    or64 r6, r8                                     r6 |= r8   ///  r6 = r6.or(r8)
    jeq r6, 0, lbb_35823                            if r6 == (0 as i32 as i64 as u64) { pc += 37 }
    ldxw r3, [r3+0x0]                       
    ldxw r6, [r2+0x0]                       
    stxw [r10-0x38], r8                     
    stxw [r10-0x3c], r4                     
    stxw [r10-0x40], r1                     
    stxdw [r10-0xe8], r3                    
    mov64 r2, r3                                    r2 = r3
    rsh64 r2, 16                                    r2 >>= 16   ///  r2 = r2.wrapping_shr(16)
    and64 r2, 255                                   r2 &= 255   ///  r2 = r2.and(255)
    stxdw [r10-0xf0], r6                    
    rsh64 r6, 16                                    r6 >>= 16   ///  r6 = r6.wrapping_shr(16)
    and64 r6, 255                                   r6 &= 255   ///  r6 = r6.and(255)
    sub64 r6, r2                                    r6 -= r2   ///  r6 = r6.wrapping_sub(r2)
    stxdw [r10-0xb0], r6                    
    jne r0, 0, lbb_35815                            if r0 != (0 as i32 as i64 as u64) { pc += 14 }
    jne r8, 0, lbb_35829                            if r8 != (0 as i32 as i64 as u64) { pc += 27 }
    mov64 r2, r4                                    r2 = r4
    lsh64 r2, 32                                    r2 <<= 32   ///  r2 = r2.wrapping_shl(32)
    or64 r2, r1                                     r2 |= r1   ///  r2 = r2.or(r1)
    mov64 r9, 0                                     r9 = 0 as i32 as i64 as u64
    mov64 r6, 0                                     r6 = 0 as i32 as i64 as u64
    ldxdw r0, [r10-0xb0]                    
    jeq r2, 0, lbb_35853                            if r2 == (0 as i32 as i64 as u64) { pc += 44 }
    jeq r7, 0, lbb_37018                            if r7 == (0 as i32 as i64 as u64) { pc += 1208 }
    div64 r2, r7                                    r2 /= r7   ///  r2 = r2 / r7
    mov64 r4, r2                                    r4 = r2
    rsh64 r4, 32                                    r4 >>= 32   ///  r4 = r4.wrapping_shr(32)
    stxw [r10-0x3c], r4                     
    ja lbb_35848                                    if true { pc += 33 }
lbb_35815:
    mov64 r6, r5                                    r6 = r5
    lsh64 r6, 32                                    r6 <<= 32   ///  r6 = r6.wrapping_shl(32)
    or64 r6, r7                                     r6 |= r7   ///  r6 = r6.or(r7)
    jeq r9, 0, lbb_36024                            if r9 == (0 as i32 as i64 as u64) { pc += 205 }
    mov64 r2, r9                                    r2 = r9
    rsh64 r2, 1                                     r2 >>= 1   ///  r2 = r2.wrapping_shr(1)
    mov64 r3, r9                                    r3 = r9
    ja lbb_36029                                    if true { pc += 206 }
lbb_35823:
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    ldxdw r2, [r10-0xc8]                    
    stxw [r2+0x10], r1                      
    stxdw [r2+0x8], r1                      
    stxdw [r2+0x0], r1                      
    ja lbb_37032                                    if true { pc += 1203 }
lbb_35829:
    ldxdw r0, [r10-0xb0]                    
    jeq r7, 0, lbb_36978                            if r7 == (0 as i32 as i64 as u64) { pc += 1147 }
    lsh64 r8, 32                                    r8 <<= 32   ///  r8 = r8.wrapping_shl(32)
    or64 r8, r4                                     r8 |= r4   ///  r8 = r8.or(r4)
    div64 r8, r7                                    r8 /= r7   ///  r8 = r8 / r7
    mov64 r2, r8                                    r2 = r8
    mul64 r2, r7                                    r2 *= r7   ///  r2 = r2.wrapping_mul(r7)
    sub64 r4, r2                                    r4 -= r2   ///  r4 = r4.wrapping_sub(r2)
    lsh64 r4, 32                                    r4 <<= 32   ///  r4 = r4.wrapping_shl(32)
    mov64 r2, r4                                    r2 = r4
    or64 r2, r1                                     r2 |= r1   ///  r2 = r2.or(r1)
    mov64 r6, 0                                     r6 = 0 as i32 as i64 as u64
    stxdw [r10-0x3c], r8                    
    mov64 r9, r8                                    r9 = r8
    rsh64 r9, 32                                    r9 >>= 32   ///  r9 = r9.wrapping_shr(32)
    mov64 r4, r8                                    r4 = r8
    jeq r2, 0, lbb_35853                            if r2 == (0 as i32 as i64 as u64) { pc += 7 }
    div64 r2, r7                                    r2 /= r7   ///  r2 = r2 / r7
    mov64 r4, r8                                    r4 = r8
lbb_35848:
    stxw [r10-0x40], r2                     
    mov64 r3, r7                                    r3 = r7
    mul64 r3, r2                                    r3 *= r2   ///  r3 = r3.wrapping_mul(r2)
    sub64 r1, r3                                    r1 -= r3   ///  r1 = r1.wrapping_sub(r3)
    mov64 r6, r1                                    r6 = r1
lbb_35853:
    jeq r7, 0, lbb_36950                            if r7 == (0 as i32 as i64 as u64) { pc += 1096 }
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
    ldxw r8, [r10-0x38]                     
lbb_35856:
    mov64 r1, r6                                    r1 = r6
    lsh64 r1, 32                                    r1 <<= 32   ///  r1 = r1.wrapping_shl(32)
    rsh64 r1, 32                                    r1 >>= 32   ///  r1 = r1.wrapping_shr(32)
    jne r1, 0, lbb_35861                            if r1 != (0 as i32 as i64 as u64) { pc += 1 }
    ja lbb_35891                                    if true { pc += 30 }
lbb_35861:
    mov64 r3, 28                                    r3 = 28 as i32 as i64 as u64
    mov64 r1, r0                                    r1 = r0
    lsh64 r1, 32                                    r1 <<= 32   ///  r1 = r1.wrapping_shl(32)
    rsh64 r1, 32                                    r1 >>= 32   ///  r1 = r1.wrapping_shr(32)
    jeq r1, 28, lbb_35879                           if r1 == (28 as i32 as i64 as u64) { pc += 13 }
    mov64 r1, r10                                   r1 = r10
    add64 r1, -128                                  r1 += -128   ///  r1 = r1.wrapping_add(-128 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -64                                   r2 += -64   ///  r2 = r2.wrapping_add(-64 as i32 as i64 as u64)
    mov64 r3, r0                                    r3 = r0
    mov64 r9, r0                                    r9 = r0
    call function_35388                     
    mov64 r0, r9                                    r0 = r9
    ldxdw r1, [r10-0x80]                    
    jne r1, 1, lbb_37014                            if r1 != (1 as i32 as i64 as u64) { pc += 1138 }
    ldxdw r1, [r10-0x78]                    
    mov64 r3, r0                                    r3 = r0
    jne r1, 0, lbb_35885                            if r1 != (0 as i32 as i64 as u64) { pc += 6 }
lbb_35879:
    mov64 r1, r6                                    r1 = r6
    lsh64 r1, 32                                    r1 <<= 32   ///  r1 = r1.wrapping_shl(32)
    arsh64 r1, 32                                   r1 >>= 32 (signed)   ///  r1 = (r1 as i64).wrapping_shr(32)
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
    jsgt r2, r1, lbb_36521                          if (r2 as i64) > (r1 as i64) { pc += 637 }
    ja lbb_36511                                    if true { pc += 626 }
lbb_35885:
    jgt r1, 9, lbb_36973                            if r1 > (9 as i32 as i64 as u64) { pc += 1087 }
    mov64 r2, 1                                     r2 = 1 as i32 as i64 as u64
    ldxw r3, [r10-0x3c]                     
    mov64 r9, r8                                    r9 = r8
    mov64 r8, r3                                    r8 = r3
    ja lbb_35905                                    if true { pc += 14 }
lbb_35891:
    mov64 r1, r0                                    r1 = r0
    lsh64 r1, 32                                    r1 <<= 32   ///  r1 = r1.wrapping_shl(32)
    arsh64 r1, 32                                   r1 >>= 32 (signed)   ///  r1 = (r1 as i64).wrapping_shr(32)
    mov64 r8, r0                                    r8 = r0
    jsgt r1, -1, lbb_36020                          if (r1 as i64) > (-1 as i32 as i64) { pc += 124 }
    mov64 r1, r8                                    r1 = r8
    neg64 r1                                        r1 = -r1   ///  r1 = (r1 as i64).wrapping_neg() as u64
    lsh64 r1, 32                                    r1 <<= 32   ///  r1 = r1.wrapping_shl(32)
    rsh64 r1, 32                                    r1 >>= 32   ///  r1 = r1.wrapping_shr(32)
    mov64 r3, 9                                     r3 = 9 as i32 as i64 as u64
    mov64 r0, r8                                    r0 = r8
    jgt r3, r1, lbb_35904                           if r3 > r1 { pc += 1 }
    mov64 r1, 9                                     r1 = 9 as i32 as i64 as u64
lbb_35904:
    mov64 r8, r4                                    r8 = r4
lbb_35905:
    mov64 r3, r1                                    r3 = r1
    lsh64 r3, 2                                     r3 <<= 2   ///  r3 = r3.wrapping_shl(2)
    lddw r4, 0x100062e50 --> b"\x01\x00\x00\x00\x0a\x00\x00\x00d\x00\x00\x00\xe8\x03\x00\x00\x10'\x00\x0…        r4 load str located at 4295372368
    add64 r4, r3                                    r4 += r3   ///  r4 = r4.wrapping_add(r3)
    ldxw r3, [r4+0x0]                       
    lsh64 r8, 32                                    r8 <<= 32   ///  r8 = r8.wrapping_shl(32)
    rsh64 r8, 32                                    r8 >>= 32   ///  r8 = r8.wrapping_shr(32)
    mul64 r8, r3                                    r8 *= r3   ///  r8 = r8.wrapping_mul(r3)
    ldxw r4, [r10-0x40]                     
    mul64 r4, r3                                    r4 *= r3   ///  r4 = r4.wrapping_mul(r3)
    mov64 r5, r4                                    r5 = r4
    rsh64 r5, 32                                    r5 >>= 32   ///  r5 = r5.wrapping_shr(32)
    add64 r8, r5                                    r8 += r5   ///  r8 = r8.wrapping_add(r5)
    stxw [r10-0x40], r4                     
    stxw [r10-0x3c], r8                     
    rsh64 r8, 32                                    r8 >>= 32   ///  r8 = r8.wrapping_shr(32)
    lsh64 r9, 32                                    r9 <<= 32   ///  r9 = r9.wrapping_shl(32)
    rsh64 r9, 32                                    r9 >>= 32   ///  r9 = r9.wrapping_shr(32)
    mul64 r9, r3                                    r9 *= r3   ///  r9 = r9.wrapping_mul(r3)
    add64 r8, r9                                    r8 += r9   ///  r8 = r8.wrapping_add(r9)
    stxw [r10-0x38], r8                     
    mov64 r4, r8                                    r4 = r8
    rsh64 r4, 32                                    r4 >>= 32   ///  r4 = r4.wrapping_shr(32)
    jne r4, 0, lbb_37014                            if r4 != (0 as i32 as i64 as u64) { pc += 1084 }
    mov64 r9, r0                                    r9 = r0
    lsh64 r6, 32                                    r6 <<= 32   ///  r6 = r6.wrapping_shl(32)
    mov64 r4, r6                                    r4 = r6
    rsh64 r4, 32                                    r4 >>= 32   ///  r4 = r4.wrapping_shr(32)
    mov64 r6, r3                                    r6 = r3
    mul64 r6, r4                                    r6 *= r4   ///  r6 = r6.wrapping_mul(r4)
    mov64 r4, r6                                    r4 = r6
    div64 r4, r7                                    r4 /= r7   ///  r4 = r4 / r7
    mov64 r5, r4                                    r5 = r4
    lsh64 r5, 32                                    r5 <<= 32   ///  r5 = r5.wrapping_shl(32)
    rsh64 r5, 32                                    r5 >>= 32   ///  r5 = r5.wrapping_shr(32)
    ldxdw r0, [r10-0x40]                    
    mov64 r3, r0                                    r3 = r0
    add64 r3, r5                                    r3 += r5   ///  r3 = r3.wrapping_add(r5)
    mov64 r5, 1                                     r5 = 1 as i32 as i64 as u64
    jgt r0, r3, lbb_35947                           if r0 > r3 { pc += 1 }
    mov64 r5, 0                                     r5 = 0 as i32 as i64 as u64
lbb_35947:
    mov64 r0, r9                                    r0 = r9
    add64 r0, r1                                    r0 += r1   ///  r0 = r0.wrapping_add(r1)
    mul64 r4, r7                                    r4 *= r7   ///  r4 = r4.wrapping_mul(r7)
    sub64 r6, r4                                    r6 -= r4   ///  r6 = r6.wrapping_sub(r4)
    stxdw [r10-0x40], r3                    
    mov64 r4, r3                                    r4 = r3
    rsh64 r4, 32                                    r4 >>= 32   ///  r4 = r4.wrapping_shr(32)
    mov64 r9, r8                                    r9 = r8
    jne r5, 1, lbb_35856                            if r5 != (1 as i32 as i64 as u64) { pc += -100 }
    lsh64 r8, 32                                    r8 <<= 32   ///  r8 = r8.wrapping_shl(32)
    rsh64 r8, 32                                    r8 >>= 32   ///  r8 = r8.wrapping_shr(32)
    add64 r8, 1                                     r8 += 1   ///  r8 = r8.wrapping_add(1 as i32 as i64 as u64)
    stxw [r10-0x38], r8                     
    mov64 r1, r8                                    r1 = r8
    lsh64 r1, 32                                    r1 <<= 32   ///  r1 = r1.wrapping_shl(32)
    rsh64 r1, 32                                    r1 >>= 32   ///  r1 = r1.wrapping_shr(32)
    mov64 r9, r8                                    r9 = r8
    jne r1, r8, lbb_35966                           if r1 != r8 { pc += 1 }
    ja lbb_35856                                    if true { pc += -110 }
lbb_35966:
    lsh64 r0, 32                                    r0 <<= 32   ///  r0 = r0.wrapping_shl(32)
    lddw r1, 0xffffffff00000000                     r1 load str located at -4294967296
    add64 r0, r1                                    r0 += r1   ///  r0 = r0.wrapping_add(r1)
    arsh64 r0, 32                                   r0 >>= 32 (signed)   ///  r0 = (r0 as i64).wrapping_shr(32)
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    jsgt r1, r0, lbb_37014                          if (r1 as i64) > (r0 as i64) { pc += 1041 }
    lddw r5, 0x600000000                            r5 load str located at 25769803776
    mov64 r1, r4                                    r1 = r4
    or64 r1, r5                                     r1 |= r5   ///  r1 = r1.or(r5)
    div64 r1, 10                                    r1 /= 10   ///  r1 = r1 / (10 as u64)
    mov64 r8, r0                                    r8 = r0
    lddw r0, 0xfffffff6                             r0 load str located at 4294967286
    mov64 r5, r1                                    r5 = r1
    mul64 r5, r0                                    r5 *= r0   ///  r5 = r5.wrapping_mul(r0)
    add64 r5, r4                                    r5 += r4   ///  r5 = r5.wrapping_add(r4)
    lddw r4, 0xfffffffe                             r4 load str located at 4294967294
    mov64 r0, r3                                    r0 = r3
    and64 r0, r4                                    r0 &= r4   ///  r0 = r0.and(r4)
    lsh64 r5, 32                                    r5 <<= 32   ///  r5 = r5.wrapping_shl(32)
    or64 r5, r0                                     r5 |= r0   ///  r5 = r5.or(r0)
    mov64 r9, 429496729                             r9 = 429496729 as i32 as i64 as u64
    stxw [r10-0x38], r9                     
    div64 r5, 10                                    r5 /= 10   ///  r5 = r5 / (10 as u64)
    mov64 r0, r5                                    r0 = r5
    mul64 r0, -10                                   r0 *= -10   ///  r0 = r0.wrapping_mul(-10 as u64)
    add64 r0, r3                                    r0 += r3   ///  r0 = r0.wrapping_add(r3)
    stxw [r10-0x3c], r1                     
    stxw [r10-0x40], r5                     
    lsh64 r0, 32                                    r0 <<= 32   ///  r0 = r0.wrapping_shl(32)
    rsh64 r0, 32                                    r0 >>= 32   ///  r0 = r0.wrapping_shr(32)
    jgt r0, 5, lbb_36010                            if r0 > (5 as i32 as i64 as u64) { pc += 9 }
    mov64 r4, r1                                    r4 = r1
    jeq r0, 5, lbb_36004                            if r0 == (5 as i32 as i64 as u64) { pc += 1 }
    ja lbb_36020                                    if true { pc += 16 }
lbb_36004:
    and64 r5, 1                                     r5 &= 1   ///  r5 = r5.and(1)
    or64 r5, r6                                     r5 |= r6   ///  r5 = r5.or(r6)
    lsh64 r5, 32                                    r5 <<= 32   ///  r5 = r5.wrapping_shl(32)
    rsh64 r5, 32                                    r5 >>= 32   ///  r5 = r5.wrapping_shr(32)
    mov64 r4, r1                                    r4 = r1
    jeq r5, 0, lbb_36020                            if r5 == (0 as i32 as i64 as u64) { pc += 10 }
lbb_36010:
    ldxdw r4, [r10-0x40]                    
    add64 r4, 1                                     r4 += 1   ///  r4 = r4.wrapping_add(1 as i32 as i64 as u64)
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    jeq r4, 0, lbb_36015                            if r4 == (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
lbb_36015:
    stxdw [r10-0x40], r4                    
    rsh64 r4, 32                                    r4 >>= 32   ///  r4 = r4.wrapping_shr(32)
    jne r1, 1, lbb_36020                            if r1 != (1 as i32 as i64 as u64) { pc += 2 }
    mov64 r9, 429496730                             r9 = 429496730 as i32 as i64 as u64
    stxw [r10-0x38], r9                     
lbb_36020:
    and64 r2, 1                                     r2 &= 1   ///  r2 = r2.and(1)
    mov64 r0, r8                                    r0 = r8
    jeq r2, 0, lbb_37248                            if r2 == (0 as i32 as i64 as u64) { pc += 1225 }
    ja lbb_37054                                    if true { pc += 1030 }
lbb_36024:
    mov64 r2, 32                                    r2 = 32 as i32 as i64 as u64
    jeq r5, 0, lbb_36067                            if r5 == (0 as i32 as i64 as u64) { pc += 41 }
    mov64 r2, r5                                    r2 = r5
    rsh64 r2, 1                                     r2 >>= 1   ///  r2 = r2.wrapping_shr(1)
    mov64 r3, r5                                    r3 = r5
lbb_36029:
    or64 r3, r2                                     r3 |= r2   ///  r3 = r3.or(r2)
    mov64 r2, r3                                    r2 = r3
    rsh64 r2, 2                                     r2 >>= 2   ///  r2 = r2.wrapping_shr(2)
    or64 r3, r2                                     r3 |= r2   ///  r3 = r3.or(r2)
    mov64 r2, r3                                    r2 = r3
    rsh64 r2, 4                                     r2 >>= 4   ///  r2 = r2.wrapping_shr(4)
    or64 r3, r2                                     r3 |= r2   ///  r3 = r3.or(r2)
    lddw r2, 0xffffff00                             r2 load str located at 4294967040
    mov64 r0, r3                                    r0 = r3
    and64 r0, r2                                    r0 &= r2   ///  r0 = r0.and(r2)
    rsh64 r0, 8                                     r0 >>= 8   ///  r0 = r0.wrapping_shr(8)
    or64 r3, r0                                     r3 |= r0   ///  r3 = r3.or(r0)
    lddw r2, 0xffff0000                             r2 load str located at 4294901760
    mov64 r0, r3                                    r0 = r3
    and64 r0, r2                                    r0 &= r2   ///  r0 = r0.and(r2)
    rsh64 r0, 16                                    r0 >>= 16   ///  r0 = r0.wrapping_shr(16)
    or64 r3, r0                                     r3 |= r0   ///  r3 = r3.or(r0)
    xor64 r3, -1                                    r3 ^= -1   ///  r3 = r3.xor(-1)
    mov64 r2, r3                                    r2 = r3
    rsh64 r2, 1                                     r2 >>= 1   ///  r2 = r2.wrapping_shr(1)
    and64 r2, 1431655765                            r2 &= 1431655765   ///  r2 = r2.and(1431655765)
    sub64 r3, r2                                    r3 -= r2   ///  r3 = r3.wrapping_sub(r2)
    mov64 r2, r3                                    r2 = r3
    and64 r2, 858993459                             r2 &= 858993459   ///  r2 = r2.and(858993459)
    rsh64 r3, 2                                     r3 >>= 2   ///  r3 = r3.wrapping_shr(2)
    and64 r3, 858993459                             r3 &= 858993459   ///  r3 = r3.and(858993459)
    add64 r2, r3                                    r2 += r3   ///  r2 = r2.wrapping_add(r3)
    mov64 r3, r2                                    r3 = r2
    rsh64 r3, 4                                     r3 >>= 4   ///  r3 = r3.wrapping_shr(4)
    add64 r2, r3                                    r2 += r3   ///  r2 = r2.wrapping_add(r3)
    and64 r2, 252645135                             r2 &= 252645135   ///  r2 = r2.and(252645135)
    mul64 r2, 16843009                              r2 *= 16843009   ///  r2 = r2.wrapping_mul(16843009 as u64)
    lddw r3, 0xff000000                             r3 load str located at 4278190080
    and64 r2, r3                                    r2 &= r3   ///  r2 = r2.and(r3)
    rsh64 r2, 24                                    r2 >>= 24   ///  r2 = r2.wrapping_shr(24)
lbb_36067:
    lsh64 r8, 32                                    r8 <<= 32   ///  r8 = r8.wrapping_shl(32)
    or64 r8, r4                                     r8 |= r4   ///  r8 = r8.or(r4)
    lsh64 r4, 32                                    r4 <<= 32   ///  r4 = r4.wrapping_shl(32)
    or64 r4, r1                                     r4 |= r1   ///  r4 = r4.or(r1)
    lsh64 r6, r2                                    r6 <<= r2   ///  r6 = r6.wrapping_shl(r2 as u32)
    mov64 r1, 32                                    r1 = 32 as i32 as i64 as u64
    sub64 r1, r2                                    r1 -= r2   ///  r1 = r1.wrapping_sub(r2)
    lsh64 r4, r2                                    r4 <<= r2   ///  r4 = r4.wrapping_shl(r2 as u32)
    rsh64 r8, r1                                    r8 >>= r1   ///  r8 = r8.wrapping_shr(r1 as u32)
    mov64 r7, r4                                    r7 = r4
    rsh64 r7, 32                                    r7 >>= 32   ///  r7 = r7.wrapping_shr(32)
    ldxdw r0, [r10-0xb0]                    
    stxdw [r10-0xa0], r6                    
    jne r9, 0, lbb_36097                            if r9 != (0 as i32 as i64 as u64) { pc += 16 }
    mov64 r5, r8                                    r5 = r8
    rsh64 r5, 32                                    r5 >>= 32   ///  r5 = r5.wrapping_shr(32)
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
    stxw [r10-0x38], r3                     
    jne r5, 0, lbb_36152                            if r5 != (0 as i32 as i64 as u64) { pc += 66 }
    mov64 r1, r8                                    r1 = r8
    lsh64 r1, 32                                    r1 <<= 32   ///  r1 = r1.wrapping_shl(32)
    or64 r1, r7                                     r1 |= r7   ///  r1 = r1.or(r7)
    jgt r6, r1, lbb_36553                           if r6 > r1 { pc += 463 }
    jeq r6, 0, lbb_36943                            if r6 == (0 as i32 as i64 as u64) { pc += 852 }
    mov64 r3, r1                                    r3 = r1
    div64 r3, r6                                    r3 /= r6   ///  r3 = r3 / r6
    mov64 r2, r3                                    r2 = r3
    mul64 r2, r6                                    r2 *= r6   ///  r2 = r2.wrapping_mul(r6)
    sub64 r1, r2                                    r1 -= r2   ///  r1 = r1.wrapping_sub(r2)
    ja lbb_36540                                    if true { pc += 443 }
lbb_36097:
    lsh64 r9, 32                                    r9 <<= 32   ///  r9 = r9.wrapping_shl(32)
    or64 r9, r5                                     r9 |= r5   ///  r9 = r9.or(r5)
    rsh64 r9, r1                                    r9 >>= r1   ///  r9 = r9.wrapping_shr(r1 as u32)
    mov64 r1, r6                                    r1 = r6
    rsh64 r1, 32                                    r1 >>= 32   ///  r1 = r1.wrapping_shr(32)
    stxdw [r10-0xd0], r1                    
    mov64 r1, r9                                    r1 = r9
    lsh64 r1, 32                                    r1 <<= 32   ///  r1 = r1.wrapping_shl(32)
    rsh64 r1, 32                                    r1 >>= 32   ///  r1 = r1.wrapping_shr(32)
    stxdw [r10-0xc0], r1                    
    jge r8, r1, lbb_36114                           if r8 >= r1 { pc += 6 }
    stxdw [r10-0xa8], r7                    
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
    lsh64 r6, 32                                    r6 <<= 32   ///  r6 = r6.wrapping_shl(32)
    rsh64 r6, 32                                    r6 >>= 32   ///  r6 = r6.wrapping_shr(32)
    stxdw [r10-0xe0], r6                    
    ja lbb_36229                                    if true { pc += 115 }
lbb_36114:
    jeq r1, 0, lbb_36936                            if r1 == (0 as i32 as i64 as u64) { pc += 821 }
    mov64 r3, r8                                    r3 = r8
    div64 r3, r1                                    r3 /= r1   ///  r3 = r3 / r1
    mov64 r2, r3                                    r2 = r3
    lsh64 r2, 32                                    r2 <<= 32   ///  r2 = r2.wrapping_shl(32)
    rsh64 r2, 32                                    r2 >>= 32   ///  r2 = r2.wrapping_shr(32)
    mov64 r1, r2                                    r1 = r2
    ldxdw r5, [r10-0xd0]                    
    mul64 r1, r5                                    r1 *= r5   ///  r1 = r1.wrapping_mul(r5)
    mov64 r5, r6                                    r5 = r6
    lsh64 r5, 32                                    r5 <<= 32   ///  r5 = r5.wrapping_shl(32)
    rsh64 r5, 32                                    r5 >>= 32   ///  r5 = r5.wrapping_shr(32)
    stxdw [r10-0xe0], r5                    
    mul64 r2, r5                                    r2 *= r5   ///  r2 = r2.wrapping_mul(r5)
    mov64 r5, r2                                    r5 = r2
    rsh64 r5, 32                                    r5 >>= 32   ///  r5 = r5.wrapping_shr(32)
    add64 r5, r1                                    r5 += r1   ///  r5 = r5.wrapping_add(r1)
    mov64 r0, r3                                    r0 = r3
    mul64 r0, r9                                    r0 *= r9   ///  r0 = r0.wrapping_mul(r9)
    mov64 r1, r5                                    r1 = r5
    rsh64 r1, 32                                    r1 >>= 32   ///  r1 = r1.wrapping_shr(32)
    add64 r0, r1                                    r0 += r1   ///  r0 = r0.wrapping_add(r1)
    sub64 r8, r0                                    r8 -= r0   ///  r8 = r8.wrapping_sub(r0)
    lsh64 r5, 32                                    r5 <<= 32   ///  r5 = r5.wrapping_shl(32)
    lsh64 r2, 32                                    r2 <<= 32   ///  r2 = r2.wrapping_shl(32)
    rsh64 r2, 32                                    r2 >>= 32   ///  r2 = r2.wrapping_shr(32)
    or64 r5, r2                                     r5 |= r2   ///  r5 = r5.or(r2)
    sub64 r4, r5                                    r4 -= r5   ///  r4 = r4.wrapping_sub(r5)
    xor64 r5, -1                                    r5 ^= -1   ///  r5 = r5.xor(-1)
    jgt r4, r5, lbb_36182                           if r4 > r5 { pc += 38 }
    lddw r2, 0xffffffff                             r2 load str located at 4294967295
    xor64 r1, r2                                    r1 ^= r2   ///  r1 = r1.xor(r2)
    mov64 r2, r8                                    r2 = r8
    lsh64 r2, 32                                    r2 <<= 32   ///  r2 = r2.wrapping_shl(32)
    rsh64 r2, 32                                    r2 >>= 32   ///  r2 = r2.wrapping_shr(32)
    jgt r2, r1, lbb_36190                           if r2 > r1 { pc += 39 }
    ja lbb_36225                                    if true { pc += 73 }
lbb_36152:
    mov64 r1, r6                                    r1 = r6
    rsh64 r1, 32                                    r1 >>= 32   ///  r1 = r1.wrapping_shr(32)
    jgt r1, r5, lbb_36156                           if r1 > r5 { pc += 1 }
    ja lbb_36530                                    if true { pc += 374 }
lbb_36156:
    mov64 r3, r8                                    r3 = r8
    div64 r3, r1                                    r3 /= r1   ///  r3 = r3 / r1
    mov64 r2, r3                                    r2 = r3
    mul64 r2, r1                                    r2 *= r1   ///  r2 = r2.wrapping_mul(r1)
    sub64 r8, r2                                    r8 -= r2   ///  r8 = r8.wrapping_sub(r2)
    mov64 r1, r6                                    r1 = r6
    lsh64 r1, 32                                    r1 <<= 32   ///  r1 = r1.wrapping_shl(32)
    rsh64 r1, 32                                    r1 >>= 32   ///  r1 = r1.wrapping_shr(32)
    mov64 r2, r3                                    r2 = r3
    mul64 r2, r1                                    r2 *= r1   ///  r2 = r2.wrapping_mul(r1)
    sub64 r7, r2                                    r7 -= r2   ///  r7 = r7.wrapping_sub(r2)
    lsh64 r8, 32                                    r8 <<= 32   ///  r8 = r8.wrapping_shl(32)
    add64 r8, r7                                    r8 += r7   ///  r8 = r8.wrapping_add(r7)
    xor64 r2, -1                                    r2 ^= -1   ///  r2 = r2.xor(-1)
    jge r2, r8, lbb_36549                           if r2 >= r8 { pc += 378 }
    mov64 r2, r8                                    r2 = r8
    ja lbb_36177                                    if true { pc += 4 }
lbb_36173:
    add64 r3, -1                                    r3 += -1   ///  r3 = r3.wrapping_add(-1 as i32 as i64 as u64)
    and64 r1, 1                                     r1 &= 1   ///  r1 = r1.and(1)
    mov64 r2, r8                                    r2 = r8
    jne r1, 0, lbb_36549                            if r1 != (0 as i32 as i64 as u64) { pc += 372 }
lbb_36177:
    add64 r8, r6                                    r8 += r6   ///  r8 = r8.wrapping_add(r6)
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    jgt r2, r8, lbb_36173                           if r2 > r8 { pc += -7 }
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    ja lbb_36173                                    if true { pc += -9 }
lbb_36182:
    lddw r2, 0xffffffff                             r2 load str located at 4294967295
    xor64 r1, r2                                    r1 ^= r2   ///  r1 = r1.xor(r2)
    add64 r8, -1                                    r8 += -1   ///  r8 = r8.wrapping_add(-1 as i32 as i64 as u64)
    mov64 r2, r8                                    r2 = r8
    lsh64 r2, 32                                    r2 <<= 32   ///  r2 = r2.wrapping_shl(32)
    rsh64 r2, 32                                    r2 >>= 32   ///  r2 = r2.wrapping_shr(32)
    jgt r1, r2, lbb_36225                           if r1 > r2 { pc += 35 }
lbb_36190:
    mov64 r2, r4                                    r2 = r4
    mov64 r1, r8                                    r1 = r8
    ja lbb_36210                                    if true { pc += 17 }
lbb_36193:
    add64 r1, r9                                    r1 += r9   ///  r1 = r1.wrapping_add(r9)
    add64 r3, -1                                    r3 += -1   ///  r3 = r3.wrapping_add(-1 as i32 as i64 as u64)
    jne r5, 1, lbb_36216                            if r5 != (1 as i32 as i64 as u64) { pc += 20 }
    mov64 r8, r1                                    r8 = r1
    add64 r8, 1                                     r8 += 1   ///  r8 = r8.wrapping_add(1 as i32 as i64 as u64)
    lsh64 r1, 32                                    r1 <<= 32   ///  r1 = r1.wrapping_shl(32)
    rsh64 r1, 32                                    r1 >>= 32   ///  r1 = r1.wrapping_shr(32)
    mov64 r5, r9                                    r5 = r9
    lsh64 r5, 32                                    r5 <<= 32   ///  r5 = r5.wrapping_shl(32)
    rsh64 r5, 32                                    r5 >>= 32   ///  r5 = r5.wrapping_shr(32)
    jgt r5, r1, lbb_36225                           if r5 > r1 { pc += 21 }
    mov64 r0, r8                                    r0 = r8
    lsh64 r0, 32                                    r0 <<= 32   ///  r0 = r0.wrapping_shl(32)
    rsh64 r0, 32                                    r0 >>= 32   ///  r0 = r0.wrapping_shr(32)
    mov64 r2, r4                                    r2 = r4
    mov64 r1, r8                                    r1 = r8
    jgt r5, r0, lbb_36225                           if r5 > r0 { pc += 15 }
lbb_36210:
    mov64 r4, r2                                    r4 = r2
    add64 r4, r6                                    r4 += r6   ///  r4 = r4.wrapping_add(r6)
    mov64 r5, 1                                     r5 = 1 as i32 as i64 as u64
    jgt r2, r4, lbb_36193                           if r2 > r4 { pc += -21 }
    mov64 r5, 0                                     r5 = 0 as i32 as i64 as u64
    ja lbb_36193                                    if true { pc += -23 }
lbb_36216:
    mov64 r5, r9                                    r5 = r9
    lsh64 r5, 32                                    r5 <<= 32   ///  r5 = r5.wrapping_shl(32)
    rsh64 r5, 32                                    r5 >>= 32   ///  r5 = r5.wrapping_shr(32)
    mov64 r0, r1                                    r0 = r1
    lsh64 r0, 32                                    r0 <<= 32   ///  r0 = r0.wrapping_shl(32)
    rsh64 r0, 32                                    r0 >>= 32   ///  r0 = r0.wrapping_shr(32)
    mov64 r2, r4                                    r2 = r4
    mov64 r8, r1                                    r8 = r1
    jge r0, r5, lbb_36210                           if r0 >= r5 { pc += -15 }
lbb_36225:
    mov64 r1, r4                                    r1 = r4
    rsh64 r1, 32                                    r1 >>= 32   ///  r1 = r1.wrapping_shr(32)
    stxdw [r10-0xa8], r1                    
    ldxdw r0, [r10-0xb0]                    
lbb_36229:
    mov64 r7, r4                                    r7 = r4
    stxw [r10-0x40], r3                     
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    stxdw [r10-0xb8], r1                    
    stxdw [r10-0x3c], r2                    
    mov64 r4, 0                                     r4 = 0 as i32 as i64 as u64
    stxdw [r10-0xd8], r1                    
lbb_36237:
    lsh64 r7, 32                                    r7 <<= 32   ///  r7 = r7.wrapping_shl(32)
    rsh64 r7, 32                                    r7 >>= 32   ///  r7 = r7.wrapping_shr(32)
    ldxdw r1, [r10-0xa8]                    
    lsh64 r1, 32                                    r1 <<= 32   ///  r1 = r1.wrapping_shl(32)
    mov64 r6, r1                                    r6 = r1
    or64 r6, r7                                     r6 |= r7   ///  r6 = r6.or(r7)
    rsh64 r1, 32                                    r1 >>= 32   ///  r1 = r1.wrapping_shr(32)
    stxdw [r10-0xa8], r1                    
    lsh64 r8, 32                                    r8 <<= 32   ///  r8 = r8.wrapping_shl(32)
    arsh64 r8, 32                                   r8 >>= 32 (signed)   ///  r8 = (r8 as i64).wrapping_shr(32)
    stxdw [r10-0xb0], r0                    
    jne r6, 0, lbb_36263                            if r6 != (0 as i32 as i64 as u64) { pc += 14 }
    jne r8, 0, lbb_36263                            if r8 != (0 as i32 as i64 as u64) { pc += 13 }
    mov64 r1, r0                                    r1 = r0
    lsh64 r1, 32                                    r1 <<= 32   ///  r1 = r1.wrapping_shl(32)
    arsh64 r1, 32                                   r1 >>= 32 (signed)   ///  r1 = (r1 as i64).wrapping_shr(32)
    jsgt r1, -1, lbb_36506                          if (r1 as i64) > (-1 as i32 as i64) { pc += 252 }
    mov64 r1, r0                                    r1 = r0
    neg64 r1                                        r1 = -r1   ///  r1 = (r1 as i64).wrapping_neg() as u64
    lsh64 r1, 32                                    r1 <<= 32   ///  r1 = r1.wrapping_shl(32)
    rsh64 r1, 32                                    r1 >>= 32   ///  r1 = r1.wrapping_shr(32)
    mov64 r2, 9                                     r2 = 9 as i32 as i64 as u64
    jgt r2, r1, lbb_36261                           if r2 > r1 { pc += 1 }
    mov64 r1, 9                                     r1 = 9 as i32 as i64 as u64
lbb_36261:
    mov64 r5, r4                                    r5 = r4
    ja lbb_36286                                    if true { pc += 23 }
lbb_36263:
    mov64 r1, r0                                    r1 = r0
    lsh64 r1, 32                                    r1 <<= 32   ///  r1 = r1.wrapping_shl(32)
    rsh64 r1, 32                                    r1 >>= 32   ///  r1 = r1.wrapping_shr(32)
    jeq r1, 28, lbb_36278                           if r1 == (28 as i32 as i64 as u64) { pc += 11 }
    mov64 r1, r10                                   r1 = r10
    add64 r1, -80                                   r1 += -80   ///  r1 = r1.wrapping_add(-80 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -64                                   r2 += -64   ///  r2 = r2.wrapping_add(-64 as i32 as i64 as u64)
    mov64 r3, r0                                    r3 = r0
    call function_35388                     
    ldxdw r0, [r10-0xb0]                    
    ldxdw r1, [r10-0x50]                    
    jne r1, 1, lbb_37014                            if r1 != (1 as i32 as i64 as u64) { pc += 738 }
    ldxdw r1, [r10-0x48]                    
    jne r1, 0, lbb_36281                            if r1 != (0 as i32 as i64 as u64) { pc += 3 }
lbb_36278:
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    jsgt r1, r8, lbb_36879                          if (r1 as i64) > (r8 as i64) { pc += 599 }
    ja lbb_36861                                    if true { pc += 580 }
lbb_36281:
    jgt r1, 9, lbb_36926                            if r1 > (9 as i32 as i64 as u64) { pc += 644 }
    mov64 r2, 1                                     r2 = 1 as i32 as i64 as u64
    stxdw [r10-0xd8], r2                    
    ldxw r5, [r10-0x3c]                     
    ldxw r3, [r10-0x40]                     
lbb_36286:
    mov64 r2, r1                                    r2 = r1
    lsh64 r2, 2                                     r2 <<= 2   ///  r2 = r2.wrapping_shl(2)
    lddw r4, 0x100062e50 --> b"\x01\x00\x00\x00\x0a\x00\x00\x00d\x00\x00\x00\xe8\x03\x00\x00\x10'\x00\x0…        r4 load str located at 4295372368
    add64 r4, r2                                    r4 += r2   ///  r4 = r4.wrapping_add(r2)
    ldxw r4, [r4+0x0]                       
    lsh64 r5, 32                                    r5 <<= 32   ///  r5 = r5.wrapping_shl(32)
    rsh64 r5, 32                                    r5 >>= 32   ///  r5 = r5.wrapping_shr(32)
    mul64 r5, r4                                    r5 *= r4   ///  r5 = r5.wrapping_mul(r4)
    lsh64 r3, 32                                    r3 <<= 32   ///  r3 = r3.wrapping_shl(32)
    rsh64 r3, 32                                    r3 >>= 32   ///  r3 = r3.wrapping_shr(32)
    mul64 r3, r4                                    r3 *= r4   ///  r3 = r3.wrapping_mul(r4)
    mov64 r2, r3                                    r2 = r3
    rsh64 r2, 32                                    r2 >>= 32   ///  r2 = r2.wrapping_shr(32)
    add64 r5, r2                                    r5 += r2   ///  r5 = r5.wrapping_add(r2)
    stxw [r10-0x40], r3                     
    stxw [r10-0x3c], r5                     
    rsh64 r5, 32                                    r5 >>= 32   ///  r5 = r5.wrapping_shr(32)
    ldxdw r2, [r10-0xb8]                    
    lsh64 r2, 32                                    r2 <<= 32   ///  r2 = r2.wrapping_shl(32)
    rsh64 r2, 32                                    r2 >>= 32   ///  r2 = r2.wrapping_shr(32)
    mul64 r2, r4                                    r2 *= r4   ///  r2 = r2.wrapping_mul(r4)
    add64 r5, r2                                    r5 += r2   ///  r5 = r5.wrapping_add(r2)
    stxw [r10-0x38], r5                     
    mov64 r2, r5                                    r2 = r5
    rsh64 r2, 32                                    r2 >>= 32   ///  r2 = r2.wrapping_shr(32)
    jne r2, 0, lbb_37014                            if r2 != (0 as i32 as i64 as u64) { pc += 701 }
    mov64 r2, r4                                    r2 = r4
    ldxdw r3, [r10-0xa8]                    
    mul64 r2, r3                                    r2 *= r3   ///  r2 = r2.wrapping_mul(r3)
    mov64 r3, r4                                    r3 = r4
    mul64 r3, r7                                    r3 *= r7   ///  r3 = r3.wrapping_mul(r7)
    mov64 r0, r3                                    r0 = r3
    rsh64 r0, 32                                    r0 >>= 32   ///  r0 = r0.wrapping_shr(32)
    add64 r0, r2                                    r0 += r2   ///  r0 = r0.wrapping_add(r2)
    lsh64 r8, 32                                    r8 <<= 32   ///  r8 = r8.wrapping_shl(32)
    rsh64 r8, 32                                    r8 >>= 32   ///  r8 = r8.wrapping_shr(32)
    mul64 r4, r8                                    r4 *= r8   ///  r4 = r4.wrapping_mul(r8)
    stxdw [r10-0xa8], r0                    
    mov64 r6, r0                                    r6 = r0
    rsh64 r6, 32                                    r6 >>= 32   ///  r6 = r6.wrapping_shr(32)
    add64 r6, r4                                    r6 += r4   ///  r6 = r6.wrapping_add(r4)
    mov64 r7, r3                                    r7 = r3
    mov64 r8, r6                                    r8 = r6
    mov64 r4, 0                                     r4 = 0 as i32 as i64 as u64
    ldxdw r2, [r10-0xc0]                    
    jgt r2, r6, lbb_36429                           if r2 > r6 { pc += 96 }
    mov64 r2, r9                                    r2 = r9
    lsh64 r2, 32                                    r2 <<= 32   ///  r2 = r2.wrapping_shl(32)
    rsh64 r2, 32                                    r2 >>= 32   ///  r2 = r2.wrapping_shr(32)
    jeq r2, 0, lbb_36936                            if r2 == (0 as i32 as i64 as u64) { pc += 599 }
    mov64 r4, r6                                    r4 = r6
    ldxdw r2, [r10-0xc0]                    
    div64 r4, r2                                    r4 /= r2   ///  r4 = r4 / r2
    mov64 r7, r4                                    r7 = r4
    lsh64 r7, 32                                    r7 <<= 32   ///  r7 = r7.wrapping_shl(32)
    rsh64 r7, 32                                    r7 >>= 32   ///  r7 = r7.wrapping_shr(32)
    mov64 r2, r7                                    r2 = r7
    ldxdw r0, [r10-0xd0]                    
    mul64 r2, r0                                    r2 *= r0   ///  r2 = r2.wrapping_mul(r0)
    ldxdw r0, [r10-0xe0]                    
    mul64 r7, r0                                    r7 *= r0   ///  r7 = r7.wrapping_mul(r0)
    mov64 r8, r6                                    r8 = r6
    mov64 r6, r7                                    r6 = r7
    rsh64 r6, 32                                    r6 >>= 32   ///  r6 = r6.wrapping_shr(32)
    add64 r6, r2                                    r6 += r2   ///  r6 = r6.wrapping_add(r2)
    mov64 r0, r4                                    r0 = r4
    mul64 r0, r9                                    r0 *= r9   ///  r0 = r0.wrapping_mul(r9)
    mov64 r2, r6                                    r2 = r6
    rsh64 r2, 32                                    r2 >>= 32   ///  r2 = r2.wrapping_shr(32)
    add64 r0, r2                                    r0 += r2   ///  r0 = r0.wrapping_add(r2)
    stxdw [r10-0xb8], r8                    
    sub64 r8, r0                                    r8 -= r0   ///  r8 = r8.wrapping_sub(r0)
    lsh64 r6, 32                                    r6 <<= 32   ///  r6 = r6.wrapping_shl(32)
    lsh64 r7, 32                                    r7 <<= 32   ///  r7 = r7.wrapping_shl(32)
    rsh64 r7, 32                                    r7 >>= 32   ///  r7 = r7.wrapping_shr(32)
    or64 r6, r7                                     r6 |= r7   ///  r6 = r6.or(r7)
    ldxdw r0, [r10-0xa8]                    
    lsh64 r0, 32                                    r0 <<= 32   ///  r0 = r0.wrapping_shl(32)
    lsh64 r3, 32                                    r3 <<= 32   ///  r3 = r3.wrapping_shl(32)
    rsh64 r3, 32                                    r3 >>= 32   ///  r3 = r3.wrapping_shr(32)
    or64 r3, r0                                     r3 |= r0   ///  r3 = r3.or(r0)
    sub64 r3, r6                                    r3 -= r6   ///  r3 = r3.wrapping_sub(r6)
    xor64 r6, -1                                    r6 ^= -1   ///  r6 = r6.xor(-1)
    jgt r3, r6, lbb_36372                           if r3 > r6 { pc += 1 }
    ja lbb_36383                                    if true { pc += 11 }
lbb_36372:
    lddw r0, 0xffffffff                             r0 load str located at 4294967295
    xor64 r2, r0                                    r2 ^= r0   ///  r2 = r2.xor(r0)
    add64 r8, -1                                    r8 += -1   ///  r8 = r8.wrapping_add(-1 as i32 as i64 as u64)
    mov64 r0, r8                                    r0 = r8
    lsh64 r0, 32                                    r0 <<= 32   ///  r0 = r0.wrapping_shl(32)
    rsh64 r0, 32                                    r0 >>= 32   ///  r0 = r0.wrapping_shr(32)
    mov64 r7, r3                                    r7 = r3
    jgt r2, r0, lbb_36425                           if r2 > r0 { pc += 44 }
lbb_36381:
    mov64 r6, r8                                    r6 = r8
    ja lbb_36409                                    if true { pc += 26 }
lbb_36383:
    lddw r0, 0xffffffff                             r0 load str located at 4294967295
    xor64 r2, r0                                    r2 ^= r0   ///  r2 = r2.xor(r0)
    mov64 r0, r8                                    r0 = r8
    lsh64 r0, 32                                    r0 <<= 32   ///  r0 = r0.wrapping_shl(32)
    rsh64 r0, 32                                    r0 >>= 32   ///  r0 = r0.wrapping_shr(32)
    mov64 r7, r3                                    r7 = r3
    jgt r0, r2, lbb_36381                           if r0 > r2 { pc += -10 }
    ja lbb_36425                                    if true { pc += 33 }
lbb_36392:
    add64 r6, r9                                    r6 += r9   ///  r6 = r6.wrapping_add(r9)
    add64 r4, -1                                    r4 += -1   ///  r4 = r4.wrapping_add(-1 as i32 as i64 as u64)
    jne r2, 1, lbb_36416                            if r2 != (1 as i32 as i64 as u64) { pc += 21 }
    mov64 r8, r6                                    r8 = r6
    add64 r8, 1                                     r8 += 1   ///  r8 = r8.wrapping_add(1 as i32 as i64 as u64)
    lsh64 r6, 32                                    r6 <<= 32   ///  r6 = r6.wrapping_shl(32)
    rsh64 r6, 32                                    r6 >>= 32   ///  r6 = r6.wrapping_shr(32)
    mov64 r2, r9                                    r2 = r9
    lsh64 r2, 32                                    r2 <<= 32   ///  r2 = r2.wrapping_shl(32)
    rsh64 r2, 32                                    r2 >>= 32   ///  r2 = r2.wrapping_shr(32)
    jgt r2, r6, lbb_36425                           if r2 > r6 { pc += 22 }
    mov64 r0, r8                                    r0 = r8
    lsh64 r0, 32                                    r0 <<= 32   ///  r0 = r0.wrapping_shl(32)
    rsh64 r0, 32                                    r0 >>= 32   ///  r0 = r0.wrapping_shr(32)
    mov64 r3, r7                                    r3 = r7
    mov64 r6, r8                                    r6 = r8
    jgt r2, r0, lbb_36425                           if r2 > r0 { pc += 16 }
lbb_36409:
    mov64 r7, r3                                    r7 = r3
    ldxdw r2, [r10-0xa0]                    
    add64 r7, r2                                    r7 += r2   ///  r7 = r7.wrapping_add(r2)
    mov64 r2, 1                                     r2 = 1 as i32 as i64 as u64
    jgt r3, r7, lbb_36392                           if r3 > r7 { pc += -22 }
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
    ja lbb_36392                                    if true { pc += -24 }
lbb_36416:
    mov64 r2, r9                                    r2 = r9
    lsh64 r2, 32                                    r2 <<= 32   ///  r2 = r2.wrapping_shl(32)
    rsh64 r2, 32                                    r2 >>= 32   ///  r2 = r2.wrapping_shr(32)
    mov64 r0, r6                                    r0 = r6
    lsh64 r0, 32                                    r0 <<= 32   ///  r0 = r0.wrapping_shl(32)
    rsh64 r0, 32                                    r0 >>= 32   ///  r0 = r0.wrapping_shr(32)
    mov64 r3, r7                                    r3 = r7
    mov64 r8, r6                                    r8 = r6
    jge r0, r2, lbb_36409                           if r0 >= r2 { pc += -16 }
lbb_36425:
    mov64 r2, r7                                    r2 = r7
    rsh64 r2, 32                                    r2 >>= 32   ///  r2 = r2.wrapping_shr(32)
    stxdw [r10-0xa8], r2                    
    ldxdw r6, [r10-0xb8]                    
lbb_36429:
    lsh64 r4, 32                                    r4 <<= 32   ///  r4 = r4.wrapping_shl(32)
    rsh64 r4, 32                                    r4 >>= 32   ///  r4 = r4.wrapping_shr(32)
    ldxdw r0, [r10-0x40]                    
    mov64 r3, r0                                    r3 = r0
    add64 r3, r4                                    r3 += r4   ///  r3 = r3.wrapping_add(r4)
    mov64 r2, 1                                     r2 = 1 as i32 as i64 as u64
    jgt r0, r3, lbb_36437                           if r0 > r3 { pc += 1 }
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
lbb_36437:
    ldxdw r0, [r10-0xb0]                    
    add64 r0, r1                                    r0 += r1   ///  r0 = r0.wrapping_add(r1)
    stxdw [r10-0x40], r3                    
    mov64 r4, r3                                    r4 = r3
    rsh64 r4, 32                                    r4 >>= 32   ///  r4 = r4.wrapping_shr(32)
    stxdw [r10-0xb8], r5                    
    jne r2, 1, lbb_36237                            if r2 != (1 as i32 as i64 as u64) { pc += -207 }
    lsh64 r5, 32                                    r5 <<= 32   ///  r5 = r5.wrapping_shl(32)
    rsh64 r5, 32                                    r5 >>= 32   ///  r5 = r5.wrapping_shr(32)
    add64 r5, 1                                     r5 += 1   ///  r5 = r5.wrapping_add(1 as i32 as i64 as u64)
    stxw [r10-0x38], r5                     
    mov64 r1, r5                                    r1 = r5
    lsh64 r1, 32                                    r1 <<= 32   ///  r1 = r1.wrapping_shl(32)
    rsh64 r1, 32                                    r1 >>= 32   ///  r1 = r1.wrapping_shr(32)
    stxdw [r10-0xb8], r5                    
    jeq r1, r5, lbb_36237                           if r1 == r5 { pc += -216 }
    lsh64 r0, 32                                    r0 <<= 32   ///  r0 = r0.wrapping_shl(32)
    lddw r1, 0xffffffff00000000                     r1 load str located at -4294967296
    add64 r0, r1                                    r0 += r1   ///  r0 = r0.wrapping_add(r1)
    arsh64 r0, 32                                   r0 >>= 32 (signed)   ///  r0 = (r0 as i64).wrapping_shr(32)
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    jsgt r1, r0, lbb_37014                          if (r1 as i64) > (r0 as i64) { pc += 554 }
    lddw r2, 0x600000000                            r2 load str located at 25769803776
    mov64 r1, r4                                    r1 = r4
    or64 r1, r2                                     r1 |= r2   ///  r1 = r1.or(r2)
    div64 r1, 10                                    r1 /= 10   ///  r1 = r1 / (10 as u64)
    lddw r2, 0xfffffff6                             r2 load str located at 4294967286
    mov64 r5, r1                                    r5 = r1
    mul64 r5, r2                                    r5 *= r2   ///  r5 = r5.wrapping_mul(r2)
    add64 r5, r4                                    r5 += r4   ///  r5 = r5.wrapping_add(r4)
    lddw r2, 0xfffffffe                             r2 load str located at 4294967294
    mov64 r4, r3                                    r4 = r3
    and64 r4, r2                                    r4 &= r2   ///  r4 = r4.and(r2)
    lsh64 r5, 32                                    r5 <<= 32   ///  r5 = r5.wrapping_shl(32)
    or64 r5, r4                                     r5 |= r4   ///  r5 = r5.or(r4)
    mov64 r4, 429496729                             r4 = 429496729 as i32 as i64 as u64
    mov64 r2, 429496729                             r2 = 429496729 as i32 as i64 as u64
    stxdw [r10-0xb8], r2                    
    stxw [r10-0x38], r4                     
    div64 r5, 10                                    r5 /= 10   ///  r5 = r5 / (10 as u64)
    mov64 r2, r5                                    r2 = r5
    mul64 r2, -10                                   r2 *= -10   ///  r2 = r2.wrapping_mul(-10 as u64)
    add64 r2, r3                                    r2 += r3   ///  r2 = r2.wrapping_add(r3)
    stxw [r10-0x3c], r1                     
    stxw [r10-0x40], r5                     
    lsh64 r2, 32                                    r2 <<= 32   ///  r2 = r2.wrapping_shl(32)
    rsh64 r2, 32                                    r2 >>= 32   ///  r2 = r2.wrapping_shr(32)
    jgt r2, 5, lbb_36912                            if r2 > (5 as i32 as i64 as u64) { pc += 423 }
    mov64 r4, r1                                    r4 = r1
    jeq r2, 5, lbb_36492                            if r2 == (5 as i32 as i64 as u64) { pc += 1 }
    ja lbb_36506                                    if true { pc += 14 }
lbb_36492:
    rsh64 r6, 32                                    r6 >>= 32   ///  r6 = r6.wrapping_shr(32)
    ldxdw r2, [r10-0xa8]                    
    or64 r2, r6                                     r2 |= r6   ///  r2 = r2.or(r6)
    lsh64 r2, 32                                    r2 <<= 32   ///  r2 = r2.wrapping_shl(32)
    lsh64 r7, 32                                    r7 <<= 32   ///  r7 = r7.wrapping_shl(32)
    rsh64 r7, 32                                    r7 >>= 32   ///  r7 = r7.wrapping_shr(32)
    or64 r2, r7                                     r2 |= r7   ///  r2 = r2.or(r7)
    lsh64 r8, 32                                    r8 <<= 32   ///  r8 = r8.wrapping_shl(32)
    rsh64 r8, 32                                    r8 >>= 32   ///  r8 = r8.wrapping_shr(32)
    or64 r2, r8                                     r2 |= r8   ///  r2 = r2.or(r8)
    jne r2, 0, lbb_36912                            if r2 != (0 as i32 as i64 as u64) { pc += 409 }
    and64 r5, 1                                     r5 &= 1   ///  r5 = r5.and(1)
    mov64 r4, r1                                    r4 = r1
    jne r5, 0, lbb_36912                            if r5 != (0 as i32 as i64 as u64) { pc += 406 }
lbb_36506:
    ldxdw r1, [r10-0xd8]                    
    and64 r1, 1                                     r1 &= 1   ///  r1 = r1.and(1)
    ldxdw r9, [r10-0xb8]                    
    jne r1, 0, lbb_37054                            if r1 != (0 as i32 as i64 as u64) { pc += 544 }
    ja lbb_37248                                    if true { pc += 737 }
lbb_36511:
    lsh64 r6, 1                                     r6 <<= 1   ///  r6 = r6.wrapping_shl(1)
    lsh64 r6, 32                                    r6 <<= 32   ///  r6 = r6.wrapping_shl(32)
    rsh64 r6, 32                                    r6 >>= 32   ///  r6 = r6.wrapping_shr(32)
    mov64 r0, r3                                    r0 = r3
    jgt r7, r6, lbb_37054                           if r7 > r6 { pc += 538 }
    jgt r6, r7, lbb_36521                           if r6 > r7 { pc += 4 }
    ldxw r1, [r10-0x40]                     
    and64 r1, 1                                     r1 &= 1   ///  r1 = r1.and(1)
    mov64 r0, r3                                    r0 = r3
    jeq r1, 0, lbb_37054                            if r1 == (0 as i32 as i64 as u64) { pc += 533 }
lbb_36521:
    mov64 r1, r10                                   r1 = r10
    add64 r1, -152                                  r1 += -152   ///  r1 = r1.wrapping_add(-152 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -64                                   r2 += -64   ///  r2 = r2.wrapping_add(-64 as i32 as i64 as u64)
    call function_37310                     
    ldxw r1, [r10-0x98]                     
    jne r1, 0, lbb_37014                            if r1 != (0 as i32 as i64 as u64) { pc += 486 }
    ldxw r0, [r10-0x94]                     
    ja lbb_37054                                    if true { pc += 524 }
lbb_36530:
    lsh64 r8, 32                                    r8 <<= 32   ///  r8 = r8.wrapping_shl(32)
    or64 r7, r8                                     r7 |= r8   ///  r7 = r7.or(r8)
    mov64 r1, r6                                    r1 = r6
    lsh64 r1, 32                                    r1 <<= 32   ///  r1 = r1.wrapping_shl(32)
    sub64 r7, r1                                    r7 -= r1   ///  r7 = r7.wrapping_sub(r1)
    mov64 r1, r7                                    r1 = r7
    ja lbb_36544                                    if true { pc += 7 }
lbb_36537:
    add64 r3, -1                                    r3 += -1   ///  r3 = r3.wrapping_add(-1 as i32 as i64 as u64)
    mov64 r7, r1                                    r7 = r1
    jne r2, 1, lbb_36544                            if r2 != (1 as i32 as i64 as u64) { pc += 4 }
lbb_36540:
    mov64 r8, r1                                    r8 = r1
    rsh64 r8, 32                                    r8 >>= 32   ///  r8 = r8.wrapping_shr(32)
    mov64 r7, r1                                    r7 = r1
    ja lbb_36553                                    if true { pc += 9 }
lbb_36544:
    add64 r1, r6                                    r1 += r6   ///  r1 = r1.wrapping_add(r6)
    mov64 r2, 1                                     r2 = 1 as i32 as i64 as u64
    jgt r7, r1, lbb_36537                           if r7 > r1 { pc += -10 }
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
    ja lbb_36537                                    if true { pc += -12 }
lbb_36549:
    mov64 r1, r8                                    r1 = r8
    rsh64 r1, 32                                    r1 >>= 32   ///  r1 = r1.wrapping_shr(32)
    mov64 r7, r8                                    r7 = r8
    mov64 r8, r1                                    r8 = r1
lbb_36553:
    stxw [r10-0x3c], r3                     
    mov64 r2, r8                                    r2 = r8
    lsh64 r2, 32                                    r2 <<= 32   ///  r2 = r2.wrapping_shl(32)
    rsh64 r2, 32                                    r2 >>= 32   ///  r2 = r2.wrapping_shr(32)
    jne r2, 0, lbb_36803                            if r2 != (0 as i32 as i64 as u64) { pc += 245 }
    stxdw [r10-0xa8], r7                    
    mov64 r1, r7                                    r1 = r7
    lsh64 r1, 32                                    r1 <<= 32   ///  r1 = r1.wrapping_shl(32)
    mov64 r2, r4                                    r2 = r4
    lsh64 r2, 32                                    r2 <<= 32   ///  r2 = r2.wrapping_shl(32)
    rsh64 r2, 32                                    r2 >>= 32   ///  r2 = r2.wrapping_shr(32)
    or64 r1, r2                                     r1 |= r2   ///  r1 = r1.or(r2)
    mov64 r8, 0                                     r8 = 0 as i32 as i64 as u64
    mov64 r7, r4                                    r7 = r4
    jgt r6, r1, lbb_36578                           if r6 > r1 { pc += 10 }
    jeq r6, 0, lbb_36943                            if r6 == (0 as i32 as i64 as u64) { pc += 374 }
    mov64 r8, r1                                    r8 = r1
    div64 r8, r6                                    r8 /= r6   ///  r8 = r8 / r6
    mov64 r2, r8                                    r2 = r8
    mul64 r2, r6                                    r2 *= r6   ///  r2 = r2.wrapping_mul(r6)
    sub64 r1, r2                                    r1 -= r2   ///  r1 = r1.wrapping_sub(r2)
    mov64 r2, r1                                    r2 = r1
    rsh64 r2, 32                                    r2 >>= 32   ///  r2 = r2.wrapping_shr(32)
    stxdw [r10-0xa8], r2                    
    mov64 r7, r1                                    r7 = r1
lbb_36578:
    stxdw [r10-0xd8], r5                    
    stxw [r10-0x40], r8                     
    mov64 r5, 0                                     r5 = 0 as i32 as i64 as u64
    ldxw r9, [r10-0x38]                     
    mov64 r1, r6                                    r1 = r6
    rsh64 r1, 32                                    r1 >>= 32   ///  r1 = r1.wrapping_shr(32)
    stxdw [r10-0xb8], r1                    
    lsh64 r6, 32                                    r6 <<= 32   ///  r6 = r6.wrapping_shl(32)
    stxdw [r10-0xc0], r6                    
    rsh64 r6, 32                                    r6 >>= 32   ///  r6 = r6.wrapping_shr(32)
    stxdw [r10-0xd0], r6                    
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
lbb_36590:
    lsh64 r7, 32                                    r7 <<= 32   ///  r7 = r7.wrapping_shl(32)
    rsh64 r7, 32                                    r7 >>= 32   ///  r7 = r7.wrapping_shr(32)
    ldxdw r6, [r10-0xa8]                    
    lsh64 r6, 32                                    r6 <<= 32   ///  r6 = r6.wrapping_shl(32)
    stxdw [r10-0xa8], r6                    
    or64 r6, r7                                     r6 |= r7   ///  r6 = r6.or(r7)
    jne r6, 0, lbb_36598                            if r6 != (0 as i32 as i64 as u64) { pc += 1 }
    ja lbb_36623                                    if true { pc += 25 }
lbb_36598:
    mov64 r1, r0                                    r1 = r0
    lsh64 r1, 32                                    r1 <<= 32   ///  r1 = r1.wrapping_shl(32)
    rsh64 r1, 32                                    r1 >>= 32   ///  r1 = r1.wrapping_shr(32)
    jeq r1, 28, lbb_36614                           if r1 == (28 as i32 as i64 as u64) { pc += 12 }
    mov64 r1, r10                                   r1 = r10
    add64 r1, -104                                  r1 += -104   ///  r1 = r1.wrapping_add(-104 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -64                                   r2 += -64   ///  r2 = r2.wrapping_add(-64 as i32 as i64 as u64)
    mov64 r3, r0                                    r3 = r0
    mov64 r8, r0                                    r8 = r0
    call function_35388                     
    mov64 r0, r8                                    r0 = r8
    ldxdw r1, [r10-0x68]                    
    jne r1, 1, lbb_37014                            if r1 != (1 as i32 as i64 as u64) { pc += 402 }
    ldxdw r1, [r10-0x60]                    
    jne r1, 0, lbb_36617                            if r1 != (0 as i32 as i64 as u64) { pc += 3 }
lbb_36614:
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    jsgt r1, r6, lbb_36897                          if (r1 as i64) > (r6 as i64) { pc += 281 }
    ja lbb_36889                                    if true { pc += 272 }
lbb_36617:
    jgt r1, 9, lbb_36931                            if r1 > (9 as i32 as i64 as u64) { pc += 313 }
    mov64 r2, 1                                     r2 = 1 as i32 as i64 as u64
    ldxw r3, [r10-0x3c]                     
    ldxw r8, [r10-0x40]                     
    mov64 r5, r9                                    r5 = r9
    ja lbb_36634                                    if true { pc += 11 }
lbb_36623:
    mov64 r1, r0                                    r1 = r0
    lsh64 r1, 32                                    r1 <<= 32   ///  r1 = r1.wrapping_shl(32)
    arsh64 r1, 32                                   r1 >>= 32 (signed)   ///  r1 = (r1 as i64).wrapping_shr(32)
    jsgt r1, -1, lbb_36907                          if (r1 as i64) > (-1 as i32 as i64) { pc += 280 }
    mov64 r1, r0                                    r1 = r0
    neg64 r1                                        r1 = -r1   ///  r1 = (r1 as i64).wrapping_neg() as u64
    lsh64 r1, 32                                    r1 <<= 32   ///  r1 = r1.wrapping_shl(32)
    rsh64 r1, 32                                    r1 >>= 32   ///  r1 = r1.wrapping_shr(32)
    mov64 r4, 9                                     r4 = 9 as i32 as i64 as u64
    jgt r4, r1, lbb_36634                           if r4 > r1 { pc += 1 }
    mov64 r1, 9                                     r1 = 9 as i32 as i64 as u64
lbb_36634:
    mov64 r9, r3                                    r9 = r3
    mov64 r3, r1                                    r3 = r1
    lsh64 r3, 2                                     r3 <<= 2   ///  r3 = r3.wrapping_shl(2)
    lddw r4, 0x100062e50 --> b"\x01\x00\x00\x00\x0a\x00\x00\x00d\x00\x00\x00\xe8\x03\x00\x00\x10'\x00\x0…        r4 load str located at 4295372368
    add64 r4, r3                                    r4 += r3   ///  r4 = r4.wrapping_add(r3)
    ldxw r4, [r4+0x0]                       
    lsh64 r9, 32                                    r9 <<= 32   ///  r9 = r9.wrapping_shl(32)
    rsh64 r9, 32                                    r9 >>= 32   ///  r9 = r9.wrapping_shr(32)
    mul64 r9, r4                                    r9 *= r4   ///  r9 = r9.wrapping_mul(r4)
    lsh64 r8, 32                                    r8 <<= 32   ///  r8 = r8.wrapping_shl(32)
    rsh64 r8, 32                                    r8 >>= 32   ///  r8 = r8.wrapping_shr(32)
    mul64 r8, r4                                    r8 *= r4   ///  r8 = r8.wrapping_mul(r4)
    mov64 r3, r8                                    r3 = r8
    rsh64 r3, 32                                    r3 >>= 32   ///  r3 = r3.wrapping_shr(32)
    add64 r9, r3                                    r9 += r3   ///  r9 = r9.wrapping_add(r3)
    stxw [r10-0x40], r8                     
    stxw [r10-0x3c], r9                     
    rsh64 r9, 32                                    r9 >>= 32   ///  r9 = r9.wrapping_shr(32)
    lsh64 r5, 32                                    r5 <<= 32   ///  r5 = r5.wrapping_shl(32)
    rsh64 r5, 32                                    r5 >>= 32   ///  r5 = r5.wrapping_shr(32)
    mul64 r5, r4                                    r5 *= r4   ///  r5 = r5.wrapping_mul(r4)
    add64 r9, r5                                    r9 += r5   ///  r9 = r9.wrapping_add(r5)
    stxw [r10-0x38], r9                     
    mov64 r3, r9                                    r3 = r9
    rsh64 r3, 32                                    r3 >>= 32   ///  r3 = r3.wrapping_shr(32)
    jne r3, 0, lbb_37014                            if r3 != (0 as i32 as i64 as u64) { pc += 353 }
    ldxdw r5, [r10-0xa8]                    
    rsh64 r5, 32                                    r5 >>= 32   ///  r5 = r5.wrapping_shr(32)
    mov64 r3, r4                                    r3 = r4
    mul64 r3, r5                                    r3 *= r5   ///  r3 = r3.wrapping_mul(r5)
    mul64 r4, r7                                    r4 *= r7   ///  r4 = r4.wrapping_mul(r7)
    mov64 r7, r4                                    r7 = r4
    rsh64 r7, 32                                    r7 >>= 32   ///  r7 = r7.wrapping_shr(32)
    add64 r7, r3                                    r7 += r3   ///  r7 = r7.wrapping_add(r3)
    mov64 r3, r7                                    r3 = r7
    rsh64 r3, 32                                    r3 >>= 32   ///  r3 = r3.wrapping_shr(32)
    jne r3, 0, lbb_36752                            if r3 != (0 as i32 as i64 as u64) { pc += 80 }
    stxdw [r10-0xa8], r7                    
    mov64 r5, r7                                    r5 = r7
    lsh64 r5, 32                                    r5 <<= 32   ///  r5 = r5.wrapping_shl(32)
    mov64 r3, r4                                    r3 = r4
    lsh64 r3, 32                                    r3 <<= 32   ///  r3 = r3.wrapping_shl(32)
    rsh64 r3, 32                                    r3 >>= 32   ///  r3 = r3.wrapping_shr(32)
    or64 r5, r3                                     r5 |= r3   ///  r5 = r5.or(r3)
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
    mov64 r7, r4                                    r7 = r4
    ldxdw r6, [r10-0xa0]                    
    jgt r6, r5, lbb_36693                           if r6 > r5 { pc += 10 }
    jeq r6, 0, lbb_36943                            if r6 == (0 as i32 as i64 as u64) { pc += 259 }
    mov64 r3, r5                                    r3 = r5
    div64 r3, r6                                    r3 /= r6   ///  r3 = r3 / r6
    mov64 r4, r3                                    r4 = r3
    mul64 r4, r6                                    r4 *= r6   ///  r4 = r4.wrapping_mul(r6)
    sub64 r5, r4                                    r5 -= r4   ///  r5 = r5.wrapping_sub(r4)
    mov64 r4, r5                                    r4 = r5
    rsh64 r4, 32                                    r4 >>= 32   ///  r4 = r4.wrapping_shr(32)
    stxdw [r10-0xa8], r4                    
    mov64 r7, r5                                    r7 = r5
lbb_36693:
    lsh64 r3, 32                                    r3 <<= 32   ///  r3 = r3.wrapping_shl(32)
    rsh64 r3, 32                                    r3 >>= 32   ///  r3 = r3.wrapping_shr(32)
    ldxdw r5, [r10-0x40]                    
    mov64 r8, r5                                    r8 = r5
    add64 r8, r3                                    r8 += r3   ///  r8 = r8.wrapping_add(r3)
    mov64 r4, 1                                     r4 = 1 as i32 as i64 as u64
    jgt r5, r8, lbb_36701                           if r5 > r8 { pc += 1 }
    mov64 r4, 0                                     r4 = 0 as i32 as i64 as u64
lbb_36701:
    add64 r0, r1                                    r0 += r1   ///  r0 = r0.wrapping_add(r1)
    stxdw [r10-0x40], r8                    
    mov64 r3, r8                                    r3 = r8
    rsh64 r3, 32                                    r3 >>= 32   ///  r3 = r3.wrapping_shr(32)
    mov64 r5, r9                                    r5 = r9
    jne r4, 1, lbb_36590                            if r4 != (1 as i32 as i64 as u64) { pc += -117 }
    lsh64 r9, 32                                    r9 <<= 32   ///  r9 = r9.wrapping_shl(32)
    rsh64 r9, 32                                    r9 >>= 32   ///  r9 = r9.wrapping_shr(32)
    add64 r9, 1                                     r9 += 1   ///  r9 = r9.wrapping_add(1 as i32 as i64 as u64)
    stxw [r10-0x38], r9                     
    mov64 r1, r9                                    r1 = r9
    lsh64 r1, 32                                    r1 <<= 32   ///  r1 = r1.wrapping_shl(32)
    rsh64 r1, 32                                    r1 >>= 32   ///  r1 = r1.wrapping_shr(32)
    mov64 r5, r9                                    r5 = r9
    jeq r1, r9, lbb_36590                           if r1 == r9 { pc += -126 }
    lsh64 r0, 32                                    r0 <<= 32   ///  r0 = r0.wrapping_shl(32)
    lddw r1, 0xffffffff00000000                     r1 load str located at -4294967296
    add64 r0, r1                                    r0 += r1   ///  r0 = r0.wrapping_add(r1)
    arsh64 r0, 32                                   r0 >>= 32 (signed)   ///  r0 = (r0 as i64).wrapping_shr(32)
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    jsgt r1, r0, lbb_37014                          if (r1 as i64) > (r0 as i64) { pc += 291 }
    lddw r1, 0x600000000                            r1 load str located at 25769803776
    mov64 r4, r3                                    r4 = r3
    or64 r4, r1                                     r4 |= r1   ///  r4 = r4.or(r1)
    div64 r4, 10                                    r4 /= 10   ///  r4 = r4 / (10 as u64)
    lddw r5, 0xfffffff6                             r5 load str located at 4294967286
    mov64 r1, r4                                    r1 = r4
    mul64 r1, r5                                    r1 *= r5   ///  r1 = r1.wrapping_mul(r5)
    add64 r1, r3                                    r1 += r3   ///  r1 = r1.wrapping_add(r3)
    lddw r3, 0xfffffffe                             r3 load str located at 4294967294
    mov64 r5, r8                                    r5 = r8
    and64 r5, r3                                    r5 &= r3   ///  r5 = r5.and(r3)
    lsh64 r1, 32                                    r1 <<= 32   ///  r1 = r1.wrapping_shl(32)
    or64 r1, r5                                     r1 |= r5   ///  r1 = r1.or(r5)
    mov64 r9, 429496729                             r9 = 429496729 as i32 as i64 as u64
    stxw [r10-0x38], r9                     
    div64 r1, 10                                    r1 /= 10   ///  r1 = r1 / (10 as u64)
    mov64 r3, r1                                    r3 = r1
    mul64 r3, -10                                   r3 *= -10   ///  r3 = r3.wrapping_mul(-10 as u64)
    add64 r3, r8                                    r3 += r8   ///  r3 = r3.wrapping_add(r8)
    stxw [r10-0x3c], r4                     
    stxw [r10-0x40], r1                     
    lsh64 r3, 32                                    r3 <<= 32   ///  r3 = r3.wrapping_shl(32)
    rsh64 r3, 32                                    r3 >>= 32   ///  r3 = r3.wrapping_shr(32)
    jgt r3, 5, lbb_37033                            if r3 > (5 as i32 as i64 as u64) { pc += 283 }
    jeq r3, 5, lbb_37044                            if r3 == (5 as i32 as i64 as u64) { pc += 293 }
    ja lbb_37052                                    if true { pc += 300 }
lbb_36752:
    ldxdw r6, [r10-0xa0]                    
    ldxdw r8, [r10-0xb8]                    
    jgt r8, r3, lbb_36756                           if r8 > r3 { pc += 1 }
    ja lbb_36782                                    if true { pc += 26 }
lbb_36756:
    mov64 r3, r7                                    r3 = r7
    div64 r3, r8                                    r3 /= r8   ///  r3 = r3 / r8
    mov64 r5, r3                                    r5 = r3
    mul64 r5, r8                                    r5 *= r8   ///  r5 = r5.wrapping_mul(r8)
    sub64 r7, r5                                    r7 -= r5   ///  r7 = r7.wrapping_sub(r5)
    mov64 r5, r3                                    r5 = r3
    ldxdw r8, [r10-0xd0]                    
    mul64 r5, r8                                    r5 *= r8   ///  r5 = r5.wrapping_mul(r8)
    lsh64 r4, 32                                    r4 <<= 32   ///  r4 = r4.wrapping_shl(32)
    rsh64 r4, 32                                    r4 >>= 32   ///  r4 = r4.wrapping_shr(32)
    sub64 r4, r5                                    r4 -= r5   ///  r4 = r4.wrapping_sub(r5)
    lsh64 r7, 32                                    r7 <<= 32   ///  r7 = r7.wrapping_shl(32)
    add64 r7, r4                                    r7 += r4   ///  r7 = r7.wrapping_add(r4)
    xor64 r5, -1                                    r5 ^= -1   ///  r5 = r5.xor(-1)
    jge r5, r7, lbb_36794                           if r5 >= r7 { pc += 23 }
    mov64 r5, r7                                    r5 = r7
    ja lbb_36777                                    if true { pc += 4 }
lbb_36773:
    add64 r3, -1                                    r3 += -1   ///  r3 = r3.wrapping_add(-1 as i32 as i64 as u64)
    and64 r4, 1                                     r4 &= 1   ///  r4 = r4.and(1)
    mov64 r5, r7                                    r5 = r7
    jne r4, 0, lbb_36794                            if r4 != (0 as i32 as i64 as u64) { pc += 17 }
lbb_36777:
    add64 r7, r6                                    r7 += r6   ///  r7 = r7.wrapping_add(r6)
    mov64 r4, 1                                     r4 = 1 as i32 as i64 as u64
    jgt r5, r7, lbb_36773                           if r5 > r7 { pc += -7 }
    mov64 r4, 0                                     r4 = 0 as i32 as i64 as u64
    ja lbb_36773                                    if true { pc += -9 }
lbb_36782:
    lsh64 r7, 32                                    r7 <<= 32   ///  r7 = r7.wrapping_shl(32)
    lsh64 r4, 32                                    r4 <<= 32   ///  r4 = r4.wrapping_shl(32)
    rsh64 r4, 32                                    r4 >>= 32   ///  r4 = r4.wrapping_shr(32)
    or64 r4, r7                                     r4 |= r7   ///  r4 = r4.or(r7)
    ldxdw r3, [r10-0xc0]                    
    sub64 r4, r3                                    r4 -= r3   ///  r4 = r4.wrapping_sub(r3)
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
    mov64 r7, r4                                    r7 = r4
    ja lbb_36798                                    if true { pc += 7 }
lbb_36791:
    add64 r3, -1                                    r3 += -1   ///  r3 = r3.wrapping_add(-1 as i32 as i64 as u64)
    mov64 r4, r7                                    r4 = r7
    jne r5, 1, lbb_36798                            if r5 != (1 as i32 as i64 as u64) { pc += 4 }
lbb_36794:
    mov64 r4, r7                                    r4 = r7
    rsh64 r4, 32                                    r4 >>= 32   ///  r4 = r4.wrapping_shr(32)
    stxdw [r10-0xa8], r4                    
    ja lbb_36693                                    if true { pc += -105 }
lbb_36798:
    add64 r7, r6                                    r7 += r6   ///  r7 = r7.wrapping_add(r6)
    mov64 r5, 1                                     r5 = 1 as i32 as i64 as u64
    jgt r4, r7, lbb_36791                           if r4 > r7 { pc += -10 }
    mov64 r5, 0                                     r5 = 0 as i32 as i64 as u64
    ja lbb_36791                                    if true { pc += -12 }
lbb_36803:
    mov64 r1, r6                                    r1 = r6
    rsh64 r1, 32                                    r1 >>= 32   ///  r1 = r1.wrapping_shr(32)
    jgt r1, r2, lbb_36807                           if r1 > r2 { pc += 1 }
    ja lbb_36839                                    if true { pc += 32 }
lbb_36807:
    lsh64 r8, 32                                    r8 <<= 32   ///  r8 = r8.wrapping_shl(32)
    mov64 r2, r7                                    r2 = r7
    lsh64 r2, 32                                    r2 <<= 32   ///  r2 = r2.wrapping_shl(32)
    rsh64 r2, 32                                    r2 >>= 32   ///  r2 = r2.wrapping_shr(32)
    or64 r8, r2                                     r8 |= r2   ///  r8 = r8.or(r2)
    div64 r8, r1                                    r8 /= r1   ///  r8 = r8 / r1
    mov64 r2, r8                                    r2 = r8
    mul64 r2, r1                                    r2 *= r1   ///  r2 = r2.wrapping_mul(r1)
    sub64 r7, r2                                    r7 -= r2   ///  r7 = r7.wrapping_sub(r2)
    mov64 r1, r6                                    r1 = r6
    lsh64 r1, 32                                    r1 <<= 32   ///  r1 = r1.wrapping_shl(32)
    rsh64 r1, 32                                    r1 >>= 32   ///  r1 = r1.wrapping_shr(32)
    mov64 r2, r8                                    r2 = r8
    mul64 r2, r1                                    r2 *= r1   ///  r2 = r2.wrapping_mul(r1)
    lsh64 r4, 32                                    r4 <<= 32   ///  r4 = r4.wrapping_shl(32)
    rsh64 r4, 32                                    r4 >>= 32   ///  r4 = r4.wrapping_shr(32)
    sub64 r4, r2                                    r4 -= r2   ///  r4 = r4.wrapping_sub(r2)
    lsh64 r7, 32                                    r7 <<= 32   ///  r7 = r7.wrapping_shl(32)
    add64 r7, r4                                    r7 += r4   ///  r7 = r7.wrapping_add(r4)
    xor64 r2, -1                                    r2 ^= -1   ///  r2 = r2.xor(-1)
    jge r2, r7, lbb_36852                           if r2 >= r7 { pc += 24 }
    mov64 r2, r7                                    r2 = r7
    ja lbb_36834                                    if true { pc += 4 }
lbb_36830:
    add64 r8, -1                                    r8 += -1   ///  r8 = r8.wrapping_add(-1 as i32 as i64 as u64)
    and64 r1, 1                                     r1 &= 1   ///  r1 = r1.and(1)
    mov64 r2, r7                                    r2 = r7
    jne r1, 0, lbb_36852                            if r1 != (0 as i32 as i64 as u64) { pc += 18 }
lbb_36834:
    add64 r7, r6                                    r7 += r6   ///  r7 = r7.wrapping_add(r6)
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    jgt r2, r7, lbb_36830                           if r2 > r7 { pc += -7 }
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    ja lbb_36830                                    if true { pc += -9 }
lbb_36839:
    lsh64 r7, 32                                    r7 <<= 32   ///  r7 = r7.wrapping_shl(32)
    lsh64 r4, 32                                    r4 <<= 32   ///  r4 = r4.wrapping_shl(32)
    rsh64 r4, 32                                    r4 >>= 32   ///  r4 = r4.wrapping_shr(32)
    or64 r4, r7                                     r4 |= r7   ///  r4 = r4.or(r7)
    mov64 r1, r6                                    r1 = r6
    lsh64 r1, 32                                    r1 <<= 32   ///  r1 = r1.wrapping_shl(32)
    sub64 r4, r1                                    r4 -= r1   ///  r4 = r4.wrapping_sub(r1)
    mov64 r8, 0                                     r8 = 0 as i32 as i64 as u64
    mov64 r7, r4                                    r7 = r4
    ja lbb_36856                                    if true { pc += 7 }
lbb_36849:
    add64 r8, -1                                    r8 += -1   ///  r8 = r8.wrapping_add(-1 as i32 as i64 as u64)
    mov64 r4, r7                                    r4 = r7
    jne r1, 1, lbb_36856                            if r1 != (1 as i32 as i64 as u64) { pc += 4 }
lbb_36852:
    mov64 r1, r7                                    r1 = r7
    rsh64 r1, 32                                    r1 >>= 32   ///  r1 = r1.wrapping_shr(32)
    stxdw [r10-0xa8], r1                    
    ja lbb_36578                                    if true { pc += -278 }
lbb_36856:
    add64 r7, r6                                    r7 += r6   ///  r7 = r7.wrapping_add(r6)
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    jgt r4, r7, lbb_36849                           if r4 > r7 { pc += -10 }
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    ja lbb_36849                                    if true { pc += -12 }
lbb_36861:
    ldxdw r1, [r10-0xa8]                    
    rsh64 r1, 31                                    r1 >>= 31   ///  r1 = r1.wrapping_shr(31)
    lsh64 r8, 1                                     r8 <<= 1   ///  r8 = r8.wrapping_shl(1)
    or64 r8, r1                                     r8 |= r1   ///  r8 = r8.or(r1)
    lsh64 r8, 32                                    r8 <<= 32   ///  r8 = r8.wrapping_shl(32)
    rsh64 r8, 32                                    r8 >>= 32   ///  r8 = r8.wrapping_shr(32)
    lsh64 r9, 32                                    r9 <<= 32   ///  r9 = r9.wrapping_shl(32)
    rsh64 r9, 32                                    r9 >>= 32   ///  r9 = r9.wrapping_shr(32)
    jgt r9, r8, lbb_37054                           if r9 > r8 { pc += 184 }
    jne r8, r9, lbb_36879                           if r8 != r9 { pc += 8 }
    lsh64 r6, 1                                     r6 <<= 1   ///  r6 = r6.wrapping_shl(1)
    ldxdw r1, [r10-0xa0]                    
    jgt r6, r1, lbb_36879                           if r6 > r1 { pc += 5 }
    ldxdw r1, [r10-0xa0]                    
    jne r6, r1, lbb_37054                           if r6 != r1 { pc += 178 }
    ldxw r1, [r10-0x40]                     
    and64 r1, 1                                     r1 &= 1   ///  r1 = r1.and(1)
    jeq r1, 0, lbb_37054                            if r1 == (0 as i32 as i64 as u64) { pc += 175 }
lbb_36879:
    mov64 r1, r10                                   r1 = r10
    add64 r1, -88                                   r1 += -88   ///  r1 = r1.wrapping_add(-88 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -64                                   r2 += -64   ///  r2 = r2.wrapping_add(-64 as i32 as i64 as u64)
    mov64 r3, r0                                    r3 = r0
    call function_37310                     
    ldxw r1, [r10-0x58]                     
    jne r1, 0, lbb_37014                            if r1 != (0 as i32 as i64 as u64) { pc += 127 }
    ldxw r0, [r10-0x54]                     
    ja lbb_37054                                    if true { pc += 165 }
lbb_36889:
    lsh64 r6, 1                                     r6 <<= 1   ///  r6 = r6.wrapping_shl(1)
    ldxdw r1, [r10-0xa0]                    
    jgt r6, r1, lbb_36897                           if r6 > r1 { pc += 5 }
    ldxdw r1, [r10-0xa0]                    
    jne r6, r1, lbb_37054                           if r6 != r1 { pc += 160 }
    ldxw r1, [r10-0x40]                     
    and64 r1, 1                                     r1 &= 1   ///  r1 = r1.and(1)
    jeq r1, 0, lbb_37054                            if r1 == (0 as i32 as i64 as u64) { pc += 157 }
lbb_36897:
    mov64 r1, r10                                   r1 = r10
    add64 r1, -112                                  r1 += -112   ///  r1 = r1.wrapping_add(-112 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -64                                   r2 += -64   ///  r2 = r2.wrapping_add(-64 as i32 as i64 as u64)
    mov64 r3, r0                                    r3 = r0
    call function_37310                     
    ldxw r1, [r10-0x70]                     
    jne r1, 0, lbb_37014                            if r1 != (0 as i32 as i64 as u64) { pc += 109 }
    ldxw r0, [r10-0x6c]                     
    ja lbb_37054                                    if true { pc += 147 }
lbb_36907:
    and64 r2, 1                                     r2 &= 1   ///  r2 = r2.and(1)
    mov64 r4, r3                                    r4 = r3
    mov64 r9, r5                                    r9 = r5
    jeq r2, 0, lbb_37248                            if r2 == (0 as i32 as i64 as u64) { pc += 337 }
    ja lbb_37054                                    if true { pc += 142 }
lbb_36912:
    ldxdw r4, [r10-0x40]                    
    add64 r4, 1                                     r4 += 1   ///  r4 = r4.wrapping_add(1 as i32 as i64 as u64)
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    jeq r4, 0, lbb_36917                            if r4 == (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
lbb_36917:
    stxdw [r10-0x40], r4                    
    rsh64 r4, 32                                    r4 >>= 32   ///  r4 = r4.wrapping_shr(32)
    jne r1, 1, lbb_36506                            if r1 != (1 as i32 as i64 as u64) { pc += -414 }
    mov64 r9, 429496730                             r9 = 429496730 as i32 as i64 as u64
    stxw [r10-0x38], r9                     
    ldxdw r1, [r10-0xd8]                    
    and64 r1, 1                                     r1 &= 1   ///  r1 = r1.and(1)
    jne r1, 0, lbb_37054                            if r1 != (0 as i32 as i64 as u64) { pc += 129 }
    ja lbb_37248                                    if true { pc += 322 }
lbb_36926:
    mov64 r2, 10                                    r2 = 10 as i32 as i64 as u64
    lddw r3, 0x100066b98 --> b"\x00\x00\x00\x00$0\x06\x00\x0e\x00\x00\x00\x00\x00\x00\x00\x0a\x02\x00\x0…        r3 load str located at 4295388056
    call function_44272                     
    syscall [invalid]                       
lbb_36931:
    mov64 r2, 10                                    r2 = 10 as i32 as i64 as u64
    lddw r3, 0x100066b80 --> b"\x00\x00\x00\x00$0\x06\x00\x0e\x00\x00\x00\x00\x00\x00\x00\xa5\x01\x00\x0…        r3 load str located at 4295388032
    call function_44272                     
    syscall [invalid]                       
lbb_36936:
    lddw r1, 0x100062c70 --> b"attempt to divide by zero"        r1 load str located at 4295371888
    mov64 r2, 25                                    r2 = 25 as i32 as i64 as u64
    lddw r3, 0x100066b38 --> b"\x00\x00\x00\x00$0\x06\x00\x0e\x00\x00\x00\x00\x00\x00\x00\xa1\x00\x00\x0…        r3 load str located at 4295387960
    call function_44254                     
    syscall [invalid]                       
lbb_36943:
    lddw r1, 0x100062c70 --> b"attempt to divide by zero"        r1 load str located at 4295371888
    mov64 r2, 25                                    r2 = 25 as i32 as i64 as u64
    lddw r3, 0x100066b20 --> b"\x00\x00\x00\x00$0\x06\x00\x0e\x00\x00\x00\x00\x00\x00\x00_\x00\x00\x00\x…        r3 load str located at 4295387936
    call function_44254                     
    syscall [invalid]                       
lbb_36950:
    mov64 r3, r9                                    r3 = r9
    mov64 r1, r6                                    r1 = r6
    lsh64 r1, 32                                    r1 <<= 32   ///  r1 = r1.wrapping_shl(32)
    rsh64 r1, 32                                    r1 >>= 32   ///  r1 = r1.wrapping_shr(32)
    jeq r1, 0, lbb_36985                            if r1 == (0 as i32 as i64 as u64) { pc += 30 }
    mov64 r3, 28                                    r3 = 28 as i32 as i64 as u64
    jeq r0, 28, lbb_35879                           if r0 == (28 as i32 as i64 as u64) { pc += -1078 }
    mov64 r1, r10                                   r1 = r10
    add64 r1, -144                                  r1 += -144   ///  r1 = r1.wrapping_add(-144 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -64                                   r2 += -64   ///  r2 = r2.wrapping_add(-64 as i32 as i64 as u64)
    mov64 r3, r0                                    r3 = r0
    call function_35388                     
    ldxdw r3, [r10-0xb0]                    
    ldxdw r1, [r10-0x90]                    
    jne r1, 1, lbb_37014                            if r1 != (1 as i32 as i64 as u64) { pc += 48 }
    ldxdw r1, [r10-0x88]                    
    jeq r1, 0, lbb_35879                            if r1 == (0 as i32 as i64 as u64) { pc += -1089 }
    jgt r1, 9, lbb_36973                            if r1 > (9 as i32 as i64 as u64) { pc += 4 }
    ldxw r3, [r10-0x38]                     
    ldxw r4, [r10-0x3c]                     
    mov64 r2, r1                                    r2 = r1
    ja lbb_36994                                    if true { pc += 21 }
lbb_36973:
    mov64 r2, 10                                    r2 = 10 as i32 as i64 as u64
    lddw r3, 0x100066b50 --> b"\x00\x00\x00\x00$0\x06\x00\x0e\x00\x00\x00\x00\x00\x00\x000\x01\x00\x00\x…        r3 load str located at 4295387984
    call function_44272                     
    syscall [invalid]                       
lbb_36978:
    lddw r1, 0x100062c70 --> b"attempt to divide by zero"        r1 load str located at 4295371888
    mov64 r2, 25                                    r2 = 25 as i32 as i64 as u64
    lddw r3, 0x100066b08 --> b"\x00\x00\x00\x00$0\x06\x00\x0e\x00\x00\x00\x00\x00\x00\x00\x1f\x00\x00\x0…        r3 load str located at 4295387912
    call function_44254                     
    syscall [invalid]                       
lbb_36985:
    mov64 r9, r3                                    r9 = r3
    jsgt r0, -1, lbb_37248                          if (r0 as i64) > (-1 as i32 as i64) { pc += 261 }
    neg64 r0                                        r0 = -r0   ///  r0 = (r0 as i64).wrapping_neg() as u64
    lsh64 r0, 32                                    r0 <<= 32   ///  r0 = r0.wrapping_shl(32)
    rsh64 r0, 32                                    r0 >>= 32   ///  r0 = r0.wrapping_shr(32)
    mov64 r1, 9                                     r1 = 9 as i32 as i64 as u64
    mov64 r2, r0                                    r2 = r0
    jgt r1, r0, lbb_36994                           if r1 > r0 { pc += 1 }
    mov64 r2, 9                                     r2 = 9 as i32 as i64 as u64
lbb_36994:
    lsh64 r2, 2                                     r2 <<= 2   ///  r2 = r2.wrapping_shl(2)
    lddw r1, 0x100062e50 --> b"\x01\x00\x00\x00\x0a\x00\x00\x00d\x00\x00\x00\xe8\x03\x00\x00\x10'\x00\x0…        r1 load str located at 4295372368
    add64 r1, r2                                    r1 += r2   ///  r1 = r1.wrapping_add(r2)
    ldxw r1, [r1+0x0]                       
    lsh64 r4, 32                                    r4 <<= 32   ///  r4 = r4.wrapping_shl(32)
    rsh64 r4, 32                                    r4 >>= 32   ///  r4 = r4.wrapping_shr(32)
    mul64 r4, r1                                    r4 *= r1   ///  r4 = r4.wrapping_mul(r1)
    ldxw r2, [r10-0x40]                     
    mul64 r2, r1                                    r2 *= r1   ///  r2 = r2.wrapping_mul(r1)
    rsh64 r2, 32                                    r2 >>= 32   ///  r2 = r2.wrapping_shr(32)
    add64 r4, r2                                    r4 += r2   ///  r4 = r4.wrapping_add(r2)
    lsh64 r3, 32                                    r3 <<= 32   ///  r3 = r3.wrapping_shl(32)
    rsh64 r3, 32                                    r3 >>= 32   ///  r3 = r3.wrapping_shr(32)
    mul64 r3, r1                                    r3 *= r1   ///  r3 = r3.wrapping_mul(r1)
    rsh64 r4, 32                                    r4 >>= 32   ///  r4 = r4.wrapping_shr(32)
    add64 r4, r3                                    r4 += r3   ///  r4 = r4.wrapping_add(r3)
    rsh64 r4, 32                                    r4 >>= 32   ///  r4 = r4.wrapping_shr(32)
    jne r4, 0, lbb_37014                            if r4 != (0 as i32 as i64 as u64) { pc += 1 }
    ja lbb_37025                                    if true { pc += 11 }
lbb_37014:
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    ldxdw r2, [r10-0xc8]                    
    stxw [r2+0x0], r1                       
    ja lbb_37032                                    if true { pc += 14 }
lbb_37018:
    lddw r1, 0x100062c70 --> b"attempt to divide by zero"        r1 load str located at 4295371888
    mov64 r2, 25                                    r2 = 25 as i32 as i64 as u64
    lddw r3, 0x100066af0 --> b"\x00\x00\x00\x00$0\x06\x00\x0e\x00\x00\x00\x00\x00\x00\x002\x00\x00\x00\x…        r3 load str located at 4295387888
    call function_44254                     
    syscall [invalid]                       
lbb_37025:
    lddw r1, 0x100062c70 --> b"attempt to divide by zero"        r1 load str located at 4295371888
    mov64 r2, 25                                    r2 = 25 as i32 as i64 as u64
    lddw r3, 0x100066b68 --> b"\x00\x00\x00\x00$0\x06\x00\x0e\x00\x00\x00\x00\x00\x00\x009\x01\x00\x00&\…        r3 load str located at 4295388008
    call function_44254                     
    syscall [invalid]                       
lbb_37032:
    exit                                    
lbb_37033:
    ldxdw r4, [r10-0x40]                    
    add64 r4, 1                                     r4 += 1   ///  r4 = r4.wrapping_add(1 as i32 as i64 as u64)
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    jeq r4, 0, lbb_37038                            if r4 == (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
lbb_37038:
    stxdw [r10-0x40], r4                    
    rsh64 r4, 32                                    r4 >>= 32   ///  r4 = r4.wrapping_shr(32)
    jne r1, 1, lbb_37052                            if r1 != (1 as i32 as i64 as u64) { pc += 11 }
    mov64 r9, 429496730                             r9 = 429496730 as i32 as i64 as u64
    stxw [r10-0x38], r9                     
    ja lbb_37052                                    if true { pc += 8 }
lbb_37044:
    lsh64 r7, 32                                    r7 <<= 32   ///  r7 = r7.wrapping_shl(32)
    rsh64 r7, 32                                    r7 >>= 32   ///  r7 = r7.wrapping_shr(32)
    ldxdw r3, [r10-0xa8]                    
    lsh64 r3, 32                                    r3 <<= 32   ///  r3 = r3.wrapping_shl(32)
    or64 r3, r7                                     r3 |= r7   ///  r3 = r3.or(r7)
    jne r3, 0, lbb_37033                            if r3 != (0 as i32 as i64 as u64) { pc += -17 }
    and64 r1, 1                                     r1 &= 1   ///  r1 = r1.and(1)
    jne r1, 0, lbb_37033                            if r1 != (0 as i32 as i64 as u64) { pc += -19 }
lbb_37052:
    and64 r2, 1                                     r2 &= 1   ///  r2 = r2.and(1)
    jeq r2, 0, lbb_37248                            if r2 == (0 as i32 as i64 as u64) { pc += 194 }
lbb_37054:
    ldxw r4, [r10-0x3c]                     
    ldxw r9, [r10-0x38]                     
    ldxw r1, [r10-0x40]                     
    mov64 r7, r0                                    r7 = r0
    lsh64 r0, 32                                    r0 <<= 32   ///  r0 = r0.wrapping_shl(32)
    arsh64 r0, 32                                   r0 >>= 32 (signed)   ///  r0 = (r0 as i64).wrapping_shr(32)
    mov64 r3, 8                                     r3 = 8 as i32 as i64 as u64
    jsgt r3, r0, lbb_37149                          if (r3 as i64) > (r0 as i64) { pc += 87 }
    mov64 r2, r1                                    r2 = r1
    jne r2, 0, lbb_37149                            if r2 != (0 as i32 as i64 as u64) { pc += 85 }
    mov64 r0, r9                                    r0 = r9
    lsh64 r0, 32                                    r0 <<= 32   ///  r0 = r0.wrapping_shl(32)
    or64 r0, r4                                     r0 |= r4   ///  r0 = r0.or(r4)
    div64 r0, 100000000                             r0 /= 100000000   ///  r0 = r0 / (100000000 as u64)
    lddw r1, 0xfa0a1f00                             r1 load str located at 4194967296
    mov64 r3, r0                                    r3 = r0
    mul64 r3, r1                                    r3 *= r1   ///  r3 = r3.wrapping_mul(r1)
    add64 r3, r4                                    r3 += r4   ///  r3 = r3.wrapping_add(r4)
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    ldxw r5, [r10-0x40]                     
    lsh64 r3, 32                                    r3 <<= 32   ///  r3 = r3.wrapping_shl(32)
    div64 r3, 100000000                             r3 /= 100000000   ///  r3 = r3 / (100000000 as u64)
    mov64 r6, r3                                    r6 = r3
    mul64 r6, 100000000                             r6 *= 100000000   ///  r6 = r6.wrapping_mul(100000000 as u64)
    lsh64 r6, 32                                    r6 <<= 32   ///  r6 = r6.wrapping_shl(32)
    rsh64 r6, 32                                    r6 >>= 32   ///  r6 = r6.wrapping_shr(32)
    mov64 r2, r7                                    r2 = r7
    jne r6, 0, lbb_37145                            if r6 != (0 as i32 as i64 as u64) { pc += 62 }
    mov64 r2, r7                                    r2 = r7
    add64 r2, -8                                    r2 += -8   ///  r2 = r2.wrapping_add(-8 as i32 as i64 as u64)
    mov64 r9, r0                                    r9 = r0
    rsh64 r9, 32                                    r9 >>= 32   ///  r9 = r9.wrapping_shr(32)
    mov64 r6, r3                                    r6 = r3
    lsh64 r6, 32                                    r6 <<= 32   ///  r6 = r6.wrapping_shl(32)
    rsh64 r6, 32                                    r6 >>= 32   ///  r6 = r6.wrapping_shr(32)
    mov64 r5, r3                                    r5 = r3
    mov64 r4, r0                                    r4 = r0
    mov64 r1, r3                                    r1 = r3
    jne r6, 0, lbb_37145                            if r6 != (0 as i32 as i64 as u64) { pc += 51 }
    lsh64 r7, 32                                    r7 <<= 32   ///  r7 = r7.wrapping_shl(32)
    rsh64 r7, 32                                    r7 >>= 32   ///  r7 = r7.wrapping_shr(32)
    mov64 r6, 16                                    r6 = 16 as i32 as i64 as u64
    mov64 r5, r3                                    r5 = r3
    mov64 r4, r0                                    r4 = r0
    mov64 r1, r3                                    r1 = r3
    jgt r6, r7, lbb_37145                           if r6 > r7 { pc += 44 }
    lddw r3, 0xfa0a1f00                             r3 load str located at 4194967296
    mov64 r4, r0                                    r4 = r0
    mov64 r0, r2                                    r0 = r2
    ja lbb_37126                                    if true { pc += 20 }
lbb_37106:
    mov64 r2, r0                                    r2 = r0
    add64 r2, -8                                    r2 += -8   ///  r2 = r2.wrapping_add(-8 as i32 as i64 as u64)
    mov64 r9, r6                                    r9 = r6
    rsh64 r9, 32                                    r9 >>= 32   ///  r9 = r9.wrapping_shr(32)
    mov64 r8, r7                                    r8 = r7
    lsh64 r8, 32                                    r8 <<= 32   ///  r8 = r8.wrapping_shl(32)
    rsh64 r8, 32                                    r8 >>= 32   ///  r8 = r8.wrapping_shr(32)
    mov64 r5, r7                                    r5 = r7
    mov64 r4, r6                                    r4 = r6
    mov64 r1, r7                                    r1 = r7
    jne r8, 0, lbb_37145                            if r8 != (0 as i32 as i64 as u64) { pc += 28 }
    lsh64 r0, 32                                    r0 <<= 32   ///  r0 = r0.wrapping_shl(32)
    mov64 r8, r0                                    r8 = r0
    rsh64 r8, 32                                    r8 >>= 32   ///  r8 = r8.wrapping_shr(32)
    mov64 r4, r6                                    r4 = r6
    mov64 r0, r2                                    r0 = r2
    mov64 r5, r7                                    r5 = r7
    mov64 r1, r7                                    r1 = r7
    jgt r8, 15, lbb_37126                           if r8 > (15 as i32 as i64 as u64) { pc += 1 }
    ja lbb_37145                                    if true { pc += 19 }
lbb_37126:
    mov64 r6, r9                                    r6 = r9
    lsh64 r6, 32                                    r6 <<= 32   ///  r6 = r6.wrapping_shl(32)
    mov64 r1, r4                                    r1 = r4
    lsh64 r1, 32                                    r1 <<= 32   ///  r1 = r1.wrapping_shl(32)
    rsh64 r1, 32                                    r1 >>= 32   ///  r1 = r1.wrapping_shr(32)
    or64 r6, r1                                     r6 |= r1   ///  r6 = r6.or(r1)
    div64 r6, 100000000                             r6 /= 100000000   ///  r6 = r6 / (100000000 as u64)
    mov64 r7, r6                                    r7 = r6
    mul64 r7, r3                                    r7 *= r3   ///  r7 = r7.wrapping_mul(r3)
    add64 r7, r4                                    r7 += r4   ///  r7 = r7.wrapping_add(r4)
    mov64 r5, 0                                     r5 = 0 as i32 as i64 as u64
    lsh64 r7, 32                                    r7 <<= 32   ///  r7 = r7.wrapping_shl(32)
    div64 r7, 100000000                             r7 /= 100000000   ///  r7 = r7 / (100000000 as u64)
    mov64 r8, r7                                    r8 = r7
    mul64 r8, 100000000                             r8 *= 100000000   ///  r8 = r8.wrapping_mul(100000000 as u64)
    lsh64 r8, 32                                    r8 <<= 32   ///  r8 = r8.wrapping_shl(32)
    rsh64 r8, 32                                    r8 >>= 32   ///  r8 = r8.wrapping_shr(32)
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    jeq r8, 0, lbb_37106                            if r8 == (0 as i32 as i64 as u64) { pc += -39 }
lbb_37145:
    stxw [r10-0x3c], r4                     
    stxw [r10-0x38], r9                     
    stxw [r10-0x40], r5                     
    mov64 r7, r2                                    r7 = r2
lbb_37149:
    mov64 r2, r1                                    r2 = r1
    and64 r2, 15                                    r2 &= 15   ///  r2 = r2.and(15)
    jne r2, 0, lbb_37180                            if r2 != (0 as i32 as i64 as u64) { pc += 28 }
    mov64 r2, r7                                    r2 = r7
    lsh64 r2, 32                                    r2 <<= 32   ///  r2 = r2.wrapping_shl(32)
    arsh64 r2, 32                                   r2 >>= 32 (signed)   ///  r2 = (r2 as i64).wrapping_shr(32)
    jsgt r2, 3, lbb_37157                           if (r2 as i64) > (3 as i32 as i64) { pc += 1 }
    ja lbb_37180                                    if true { pc += 23 }
lbb_37157:
    mov64 r2, r9                                    r2 = r9
    lsh64 r2, 32                                    r2 <<= 32   ///  r2 = r2.wrapping_shl(32)
    mov64 r3, r4                                    r3 = r4
    lsh64 r3, 32                                    r3 <<= 32   ///  r3 = r3.wrapping_shl(32)
    rsh64 r3, 32                                    r3 >>= 32   ///  r3 = r3.wrapping_shr(32)
    or64 r2, r3                                     r2 |= r3   ///  r2 = r2.or(r3)
    div64 r2, 10000                                 r2 /= 10000   ///  r2 = r2 / (10000 as u64)
    lddw r5, 0xffffd8f0                             r5 load str located at 4294957296
    mov64 r3, r2                                    r3 = r2
    mul64 r3, r5                                    r3 *= r5   ///  r3 = r3.wrapping_mul(r5)
    add64 r3, r4                                    r3 += r4   ///  r3 = r3.wrapping_add(r4)
    lsh64 r3, 32                                    r3 <<= 32   ///  r3 = r3.wrapping_shl(32)
    mov64 r5, r1                                    r5 = r1
    lsh64 r5, 32                                    r5 <<= 32   ///  r5 = r5.wrapping_shl(32)
    rsh64 r5, 32                                    r5 >>= 32   ///  r5 = r5.wrapping_shr(32)
    or64 r3, r5                                     r3 |= r5   ///  r3 = r3.or(r5)
    div64 r3, 10000                                 r3 /= 10000   ///  r3 = r3 / (10000 as u64)
    mov64 r0, r3                                    r0 = r3
    mul64 r0, 10000                                 r0 *= 10000   ///  r0 = r0.wrapping_mul(10000 as u64)
    lsh64 r0, 32                                    r0 <<= 32   ///  r0 = r0.wrapping_shl(32)
    rsh64 r0, 32                                    r0 >>= 32   ///  r0 = r0.wrapping_shr(32)
    jeq r5, r0, lbb_37294                           if r5 == r0 { pc += 114 }
lbb_37180:
    mov64 r2, r1                                    r2 = r1
    and64 r2, 3                                     r2 &= 3   ///  r2 = r2.and(3)
    jne r2, 0, lbb_37211                            if r2 != (0 as i32 as i64 as u64) { pc += 28 }
    mov64 r2, r7                                    r2 = r7
    lsh64 r2, 32                                    r2 <<= 32   ///  r2 = r2.wrapping_shl(32)
    arsh64 r2, 32                                   r2 >>= 32 (signed)   ///  r2 = (r2 as i64).wrapping_shr(32)
    jsgt r2, 1, lbb_37188                           if (r2 as i64) > (1 as i32 as i64) { pc += 1 }
    ja lbb_37211                                    if true { pc += 23 }
lbb_37188:
    mov64 r2, r9                                    r2 = r9
    lsh64 r2, 32                                    r2 <<= 32   ///  r2 = r2.wrapping_shl(32)
    mov64 r3, r4                                    r3 = r4
    lsh64 r3, 32                                    r3 <<= 32   ///  r3 = r3.wrapping_shl(32)
    rsh64 r3, 32                                    r3 >>= 32   ///  r3 = r3.wrapping_shr(32)
    or64 r2, r3                                     r2 |= r3   ///  r2 = r2.or(r3)
    div64 r2, 100                                   r2 /= 100   ///  r2 = r2 / (100 as u64)
    lddw r5, 0xffffff9c                             r5 load str located at 4294967196
    mov64 r3, r2                                    r3 = r2
    mul64 r3, r5                                    r3 *= r5   ///  r3 = r3.wrapping_mul(r5)
    add64 r3, r4                                    r3 += r4   ///  r3 = r3.wrapping_add(r4)
    lsh64 r3, 32                                    r3 <<= 32   ///  r3 = r3.wrapping_shl(32)
    mov64 r5, r1                                    r5 = r1
    lsh64 r5, 32                                    r5 <<= 32   ///  r5 = r5.wrapping_shl(32)
    rsh64 r5, 32                                    r5 >>= 32   ///  r5 = r5.wrapping_shr(32)
    or64 r3, r5                                     r3 |= r5   ///  r3 = r3.or(r5)
    div64 r3, 100                                   r3 /= 100   ///  r3 = r3 / (100 as u64)
    mov64 r0, r3                                    r0 = r3
    mul64 r0, 100                                   r0 *= 100   ///  r0 = r0.wrapping_mul(100 as u64)
    lsh64 r0, 32                                    r0 <<= 32   ///  r0 = r0.wrapping_shl(32)
    rsh64 r0, 32                                    r0 >>= 32   ///  r0 = r0.wrapping_shr(32)
    jeq r5, r0, lbb_37302                           if r5 == r0 { pc += 91 }
lbb_37211:
    mov64 r2, r1                                    r2 = r1
    and64 r2, 1                                     r2 &= 1   ///  r2 = r2.and(1)
    mov64 r0, r7                                    r0 = r7
    jne r2, 0, lbb_37248                            if r2 != (0 as i32 as i64 as u64) { pc += 33 }
    mov64 r2, r0                                    r2 = r0
    lsh64 r2, 32                                    r2 <<= 32   ///  r2 = r2.wrapping_shl(32)
    arsh64 r2, 32                                   r2 >>= 32 (signed)   ///  r2 = (r2 as i64).wrapping_shr(32)
    jsgt r2, 0, lbb_37220                           if (r2 as i64) > (0 as i32 as i64) { pc += 1 }
    ja lbb_37248                                    if true { pc += 28 }
lbb_37220:
    mov64 r2, r9                                    r2 = r9
    lsh64 r2, 32                                    r2 <<= 32   ///  r2 = r2.wrapping_shl(32)
    mov64 r3, r4                                    r3 = r4
    lsh64 r3, 32                                    r3 <<= 32   ///  r3 = r3.wrapping_shl(32)
    rsh64 r3, 32                                    r3 >>= 32   ///  r3 = r3.wrapping_shr(32)
    or64 r2, r3                                     r2 |= r3   ///  r2 = r2.or(r3)
    div64 r2, 10                                    r2 /= 10   ///  r2 = r2 / (10 as u64)
    lddw r5, 0xfffffff6                             r5 load str located at 4294967286
    mov64 r3, r2                                    r3 = r2
    mul64 r3, r5                                    r3 *= r5   ///  r3 = r3.wrapping_mul(r5)
    add64 r3, r4                                    r3 += r4   ///  r3 = r3.wrapping_add(r4)
    lsh64 r3, 32                                    r3 <<= 32   ///  r3 = r3.wrapping_shl(32)
    lsh64 r1, 32                                    r1 <<= 32   ///  r1 = r1.wrapping_shl(32)
    rsh64 r1, 32                                    r1 >>= 32   ///  r1 = r1.wrapping_shr(32)
    or64 r3, r1                                     r3 |= r1   ///  r3 = r3.or(r1)
    div64 r3, 10                                    r3 /= 10   ///  r3 = r3 / (10 as u64)
    mov64 r5, r3                                    r5 = r3
    mul64 r5, 10                                    r5 *= 10   ///  r5 = r5.wrapping_mul(10 as u64)
    lsh64 r5, 32                                    r5 <<= 32   ///  r5 = r5.wrapping_shl(32)
    rsh64 r5, 32                                    r5 >>= 32   ///  r5 = r5.wrapping_shr(32)
    jne r1, r5, lbb_37248                           if r1 != r5 { pc += 6 }
    stxw [r10-0x40], r3                     
    add64 r0, -1                                    r0 += -1   ///  r0 = r0.wrapping_add(-1 as i32 as i64 as u64)
    stxdw [r10-0x3c], r2                    
    mov64 r9, r2                                    r9 = r2
    rsh64 r9, 32                                    r9 >>= 32   ///  r9 = r9.wrapping_shr(32)
    mov64 r4, r2                                    r4 = r2
lbb_37248:
    mov64 r1, r0                                    r1 = r0
    lsh64 r1, 32                                    r1 <<= 32   ///  r1 = r1.wrapping_shl(32)
    rsh64 r1, 32                                    r1 >>= 32   ///  r1 = r1.wrapping_shr(32)
    mov64 r2, 29                                    r2 = 29 as i32 as i64 as u64
    jgt r2, r1, lbb_37270                           if r2 > r1 { pc += 17 }
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    stxdw [r10-0x28], r1                    
    lddw r1, 0x100066950 --> b"\x00\x00\x00\x00\x8f-\x06\x00%\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x0…        r1 load str located at 4295387472
    stxdw [r10-0x30], r1                    
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    stxdw [r10-0x10], r1                    
    stxdw [r10-0x18], r1                    
    lddw r1, 0x100062c08 --> b"invalid args/home/runner/work/platform-tools/platf"        r1 load str located at 4295371784
    stxdw [r10-0x20], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -48                                   r1 += -48   ///  r1 = r1.wrapping_add(-48 as i32 as i64 as u64)
    lddw r2, 0x100066960 --> b"\x00\x00\x00\x00\x81-\x06\x00\x0e\x00\x00\x00\x00\x00\x00\x00\x11\x02\x00…        r2 load str located at 4295387488
    call function_44240                     
    syscall [invalid]                       
lbb_37270:
    ldxw r1, [r10-0x40]                     
    ldxdw r3, [r10-0xc8]                    
    stxw [r3+0x10], r4                      
    or64 r4, r9                                     r4 |= r9   ///  r4 = r4.or(r9)
    stxw [r3+0x8], r9                       
    stxw [r3+0xc], r1                       
    or64 r4, r1                                     r4 |= r1   ///  r4 = r4.or(r1)
    lsh64 r4, 32                                    r4 <<= 32   ///  r4 = r4.wrapping_shl(32)
    rsh64 r4, 32                                    r4 >>= 32   ///  r4 = r4.wrapping_shr(32)
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
    jeq r4, 0, lbb_37289                            if r4 == (0 as i32 as i64 as u64) { pc += 7 }
    ldxdw r4, [r10-0xe8]                    
    ldxdw r2, [r10-0xf0]                    
    xor64 r4, r2                                    r4 ^= r2   ///  r4 = r4.xor(r2)
    lddw r2, 0x80000000                             r2 load str located at 2147483648
    and64 r4, r2                                    r4 &= r2   ///  r4 = r4.and(r2)
    mov64 r2, r4                                    r2 = r4
lbb_37289:
    stxw [r3+0x0], r1                       
    lsh64 r0, 16                                    r0 <<= 16   ///  r0 = r0.wrapping_shl(16)
    or64 r2, r0                                     r2 |= r0   ///  r2 = r2.or(r0)
    stxw [r3+0x4], r2                       
    ja lbb_37032                                    if true { pc += -262 }
lbb_37294:
    stxw [r10-0x40], r3                     
    add64 r7, -4                                    r7 += -4   ///  r7 = r7.wrapping_add(-4 as i32 as i64 as u64)
    stxdw [r10-0x3c], r2                    
    mov64 r9, r2                                    r9 = r2
    rsh64 r9, 32                                    r9 >>= 32   ///  r9 = r9.wrapping_shr(32)
    mov64 r4, r2                                    r4 = r2
    mov64 r1, r3                                    r1 = r3
    ja lbb_37180                                    if true { pc += -122 }
lbb_37302:
    stxw [r10-0x40], r3                     
    add64 r7, -2                                    r7 += -2   ///  r7 = r7.wrapping_add(-2 as i32 as i64 as u64)
    stxdw [r10-0x3c], r2                    
    mov64 r9, r2                                    r9 = r2
    rsh64 r9, 32                                    r9 >>= 32   ///  r9 = r9.wrapping_shr(32)
    mov64 r4, r2                                    r4 = r2
    mov64 r1, r3                                    r1 = r3
    ja lbb_37211                                    if true { pc += -99 }

function_37310:
    ldxdw r4, [r2+0x0]                      
    add64 r4, 1                                     r4 += 1   ///  r4 = r4.wrapping_add(1 as i32 as i64 as u64)
    stxdw [r2+0x0], r4                      
    mov64 r5, 0                                     r5 = 0 as i32 as i64 as u64
    mov64 r0, 1                                     r0 = 1 as i32 as i64 as u64
    jeq r4, 0, lbb_37317                            if r4 == (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r0, 0                                     r0 = 0 as i32 as i64 as u64
lbb_37317:
    jne r0, 1, lbb_37359                            if r0 != (1 as i32 as i64 as u64) { pc += 41 }
    ldxw r0, [r2+0x8]                       
    add64 r0, 1                                     r0 += 1   ///  r0 = r0.wrapping_add(1 as i32 as i64 as u64)
    stxw [r2+0x8], r0                       
    mov64 r6, r0                                    r6 = r0
    lsh64 r6, 32                                    r6 <<= 32   ///  r6 = r6.wrapping_shl(32)
    rsh64 r6, 32                                    r6 >>= 32   ///  r6 = r6.wrapping_shr(32)
    jeq r6, r0, lbb_37359                           if r6 == r0 { pc += 34 }
    lsh64 r3, 32                                    r3 <<= 32   ///  r3 = r3.wrapping_shl(32)
    lddw r5, 0xffffffff00000000                     r5 load str located at -4294967296
    add64 r3, r5                                    r3 += r5   ///  r3 = r3.wrapping_add(r5)
    mov64 r5, 1                                     r5 = 1 as i32 as i64 as u64
    arsh64 r3, 32                                   r3 >>= 32 (signed)   ///  r3 = (r3 as i64).wrapping_shr(32)
    mov64 r0, 0                                     r0 = 0 as i32 as i64 as u64
    jsgt r0, r3, lbb_37359                          if (r0 as i64) > (r3 as i64) { pc += 26 }
    rsh64 r4, 32                                    r4 >>= 32   ///  r4 = r4.wrapping_shr(32)
    lddw r5, 0x600000000                            r5 load str located at 25769803776
    mov64 r0, r4                                    r0 = r4
    or64 r0, r5                                     r0 |= r5   ///  r0 = r0.or(r5)
    div64 r0, 10                                    r0 /= 10   ///  r0 = r0 / (10 as u64)
    stxw [r2+0x4], r0                       
    lddw r5, 0xfffffff6                             r5 load str located at 4294967286
    mul64 r0, r5                                    r0 *= r5   ///  r0 = r0.wrapping_mul(r5)
    add64 r0, r4                                    r0 += r4   ///  r0 = r0.wrapping_add(r4)
    lsh64 r0, 32                                    r0 <<= 32   ///  r0 = r0.wrapping_shl(32)
    div64 r0, 10                                    r0 /= 10   ///  r0 = r0 / (10 as u64)
    stxw [r2+0x0], r0                       
    mov64 r4, 429496729                             r4 = 429496729 as i32 as i64 as u64
    stxw [r2+0x8], r4                       
    ldxdw r5, [r2+0x0]                      
    add64 r5, 1                                     r5 += 1   ///  r5 = r5.wrapping_add(1 as i32 as i64 as u64)
    stxdw [r2+0x0], r5                      
    mov64 r4, 1                                     r4 = 1 as i32 as i64 as u64
    jeq r5, 0, lbb_37355                            if r5 == (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r4, 0                                     r4 = 0 as i32 as i64 as u64
lbb_37355:
    mov64 r5, 0                                     r5 = 0 as i32 as i64 as u64
    jne r4, 1, lbb_37359                            if r4 != (1 as i32 as i64 as u64) { pc += 2 }
    mov64 r4, 429496730                             r4 = 429496730 as i32 as i64 as u64
    stxw [r2+0x8], r4                       
lbb_37359:
    stxw [r1+0x4], r3                       
    stxw [r1+0x0], r5                       
    exit                                    

function_37362:
    stxdw [r10-0x58], r1                    
    ldxw r0, [r2+0x4]                       
    ldxw r1, [r2+0xc]                       
    mov64 r9, r0                                    r9 = r0
    or64 r9, r1                                     r9 |= r1   ///  r9 = r9.or(r1)
    ldxw r6, [r2+0x8]                       
    mov64 r4, r9                                    r4 = r9
    or64 r4, r6                                     r4 |= r6   ///  r4 = r4.or(r6)
    jeq r4, 0, lbb_37379                            if r4 == (0 as i32 as i64 as u64) { pc += 8 }
    ldxw r4, [r3+0x4]                       
    ldxw r7, [r3+0xc]                       
    stxdw [r10-0x60], r4                    
    or64 r4, r7                                     r4 |= r7   ///  r4 = r4.or(r7)
    ldxw r8, [r3+0x8]                       
    mov64 r5, r4                                    r5 = r4
    or64 r5, r8                                     r5 |= r8   ///  r5 = r5.or(r8)
    jne r5, 0, lbb_37385                            if r5 != (0 as i32 as i64 as u64) { pc += 6 }
lbb_37379:
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    ldxdw r2, [r10-0x58]                    
    stxw [r2+0x10], r1                      
    stxdw [r2+0x8], r1                      
    stxdw [r2+0x0], r1                      
    ja lbb_37660                                    if true { pc += 275 }
lbb_37385:
    ldxw r5, [r3+0x0]                       
    ldxw r2, [r2+0x0]                       
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
    stxdw [r10-0x38], r3                    
    stxdw [r10-0x40], r3                    
    stxdw [r10-0x48], r3                    
    mov64 r3, r5                                    r3 = r5
    xor64 r3, r2                                    r3 ^= r2   ///  r3 = r3.xor(r2)
    stxdw [r10-0x78], r3                    
    rsh64 r2, 16                                    r2 >>= 16   ///  r2 = r2.wrapping_shr(16)
    and64 r2, 255                                   r2 &= 255   ///  r2 = r2.and(255)
    rsh64 r5, 16                                    r5 >>= 16   ///  r5 = r5.wrapping_shr(16)
    and64 r5, 255                                   r5 &= 255   ///  r5 = r5.and(255)
    add64 r5, r2                                    r5 += r2   ///  r5 = r5.wrapping_add(r2)
    stxdw [r10-0x70], r5                    
    jeq r9, 0, lbb_37496                            if r9 == (0 as i32 as i64 as u64) { pc += 95 }
    jeq r4, 0, lbb_37520                            if r4 == (0 as i32 as i64 as u64) { pc += 118 }
    mov64 r4, r7                                    r4 = r7
    mul64 r4, r6                                    r4 *= r6   ///  r4 = r4.wrapping_mul(r6)
    mov64 r2, r8                                    r2 = r8
    mul64 r2, r6                                    r2 *= r6   ///  r2 = r2.wrapping_mul(r6)
    stxdw [r10-0x68], r2                    
    rsh64 r2, 32                                    r2 >>= 32   ///  r2 = r2.wrapping_shr(32)
    add64 r4, r2                                    r4 += r2   ///  r4 = r4.wrapping_add(r2)
    mov64 r3, r8                                    r3 = r8
    mul64 r3, r1                                    r3 *= r1   ///  r3 = r3.wrapping_mul(r1)
    mov64 r2, r4                                    r2 = r4
    add64 r2, r3                                    r2 += r3   ///  r2 = r2.wrapping_add(r3)
    mov64 r3, 1                                     r3 = 1 as i32 as i64 as u64
    jgt r4, r2, lbb_37416                           if r4 > r2 { pc += 1 }
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
lbb_37416:
    mov64 r5, r2                                    r5 = r2
    rsh64 r5, 32                                    r5 >>= 32   ///  r5 = r5.wrapping_shr(32)
    lddw r4, 0x100000000                            r4 load str located at 4294967296
    mov64 r9, r5                                    r9 = r5
    or64 r9, r4                                     r9 |= r4   ///  r9 = r9.or(r4)
    jne r3, 0, lbb_37424                            if r3 != (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r9, r5                                    r9 = r5
lbb_37424:
    ldxdw r5, [r10-0x60]                    
    mov64 r3, r5                                    r3 = r5
    or64 r3, r0                                     r3 |= r0   ///  r3 = r3.or(r0)
    mov64 r4, r7                                    r4 = r7
    mul64 r4, r1                                    r4 *= r1   ///  r4 = r4.wrapping_mul(r1)
    add64 r9, r4                                    r9 += r4   ///  r9 = r9.wrapping_add(r4)
    ldxdw r4, [r10-0x68]                    
    stxw [r10-0x48], r4                     
    stxw [r10-0x44], r2                     
    jeq r3, 0, lbb_37541                            if r3 == (0 as i32 as i64 as u64) { pc += 107 }
    mul64 r8, r0                                    r8 *= r0   ///  r8 = r8.wrapping_mul(r0)
    mov64 r4, r5                                    r4 = r5
    mul64 r4, r6                                    r4 *= r6   ///  r4 = r4.wrapping_mul(r6)
    mov64 r3, r9                                    r3 = r9
    add64 r3, r4                                    r3 += r4   ///  r3 = r3.wrapping_add(r4)
    mov64 r6, r3                                    r6 = r3
    add64 r6, r8                                    r6 += r8   ///  r6 = r6.wrapping_add(r8)
    mov64 r5, 1                                     r5 = 1 as i32 as i64 as u64
    jgt r9, r3, lbb_37444                           if r9 > r3 { pc += 1 }
    mov64 r5, 0                                     r5 = 0 as i32 as i64 as u64
lbb_37444:
    mov64 r9, 1                                     r9 = 1 as i32 as i64 as u64
    jgt r3, r6, lbb_37447                           if r3 > r6 { pc += 1 }
    mov64 r9, 0                                     r9 = 0 as i32 as i64 as u64
lbb_37447:
    mov64 r8, 2                                     r8 = 2 as i32 as i64 as u64
    mov64 r3, 2                                     r3 = 2 as i32 as i64 as u64
    jne r5, 0, lbb_37451                            if r5 != (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r3, 1                                     r3 = 1 as i32 as i64 as u64
lbb_37451:
    jne r9, 0, lbb_37453                            if r9 != (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r3, r5                                    r3 = r5
lbb_37453:
    lsh64 r3, 32                                    r3 <<= 32   ///  r3 = r3.wrapping_shl(32)
    mov64 r4, r6                                    r4 = r6
    rsh64 r4, 32                                    r4 >>= 32   ///  r4 = r4.wrapping_shr(32)
    or64 r3, r4                                     r3 |= r4   ///  r3 = r3.or(r4)
    mul64 r7, r0                                    r7 *= r0   ///  r7 = r7.wrapping_mul(r0)
    ldxdw r4, [r10-0x60]                    
    mul64 r4, r1                                    r4 *= r1   ///  r4 = r4.wrapping_mul(r1)
    mov64 r9, r3                                    r9 = r3
    add64 r9, r4                                    r9 += r4   ///  r9 = r9.wrapping_add(r4)
    mov64 r5, 1                                     r5 = 1 as i32 as i64 as u64
    jgt r3, r9, lbb_37465                           if r3 > r9 { pc += 1 }
    mov64 r5, 0                                     r5 = 0 as i32 as i64 as u64
lbb_37465:
    mov64 r1, r9                                    r1 = r9
    add64 r1, r7                                    r1 += r7   ///  r1 = r1.wrapping_add(r7)
    mov64 r3, 1                                     r3 = 1 as i32 as i64 as u64
    jgt r9, r1, lbb_37470                           if r9 > r1 { pc += 1 }
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
lbb_37470:
    jne r5, 0, lbb_37472                            if r5 != (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r8, 1                                     r8 = 1 as i32 as i64 as u64
lbb_37472:
    jne r3, 0, lbb_37474                            if r3 != (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r8, r5                                    r8 = r5
lbb_37474:
    ldxdw r4, [r10-0x60]                    
    mul64 r4, r0                                    r4 *= r0   ///  r4 = r4.wrapping_mul(r0)
    lsh64 r8, 32                                    r8 <<= 32   ///  r8 = r8.wrapping_shl(32)
    mov64 r3, r1                                    r3 = r1
    rsh64 r3, 32                                    r3 >>= 32   ///  r3 = r3.wrapping_shr(32)
    or64 r8, r3                                     r8 |= r3   ///  r8 = r8.or(r3)
    add64 r8, r4                                    r8 += r4   ///  r8 = r8.wrapping_add(r4)
    mov64 r3, 5                                     r3 = 5 as i32 as i64 as u64
    stxw [r10-0x40], r6                     
    stxw [r10-0x3c], r1                     
    stxw [r10-0x38], r8                     
    mov64 r5, r8                                    r5 = r8
    rsh64 r5, 32                                    r5 >>= 32   ///  r5 = r5.wrapping_shr(32)
    stxw [r10-0x34], r5                     
    ldxdw r4, [r10-0x70]                    
    jne r5, 0, lbb_37563                            if r5 != (0 as i32 as i64 as u64) { pc += 73 }
    mov64 r3, 4                                     r3 = 4 as i32 as i64 as u64
    lsh64 r8, 32                                    r8 <<= 32   ///  r8 = r8.wrapping_shl(32)
    rsh64 r8, 32                                    r8 >>= 32   ///  r8 = r8.wrapping_shr(32)
    mov64 r9, r6                                    r9 = r6
    jeq r8, 0, lbb_37546                            if r8 == (0 as i32 as i64 as u64) { pc += 51 }
    ja lbb_37563                                    if true { pc += 67 }
lbb_37496:
    mul64 r8, r6                                    r8 *= r6   ///  r8 = r8.wrapping_mul(r6)
    ldxdw r5, [r10-0x60]                    
    jeq r4, 0, lbb_37602                            if r4 == (0 as i32 as i64 as u64) { pc += 103 }
    mul64 r7, r6                                    r7 *= r6   ///  r7 = r7.wrapping_mul(r6)
    mov64 r1, r8                                    r1 = r8
    rsh64 r1, 32                                    r1 >>= 32   ///  r1 = r1.wrapping_shr(32)
    add64 r7, r1                                    r7 += r1   ///  r7 = r7.wrapping_add(r1)
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    stxw [r10-0x48], r8                     
    stxw [r10-0x44], r7                     
    mov64 r9, r7                                    r9 = r7
    rsh64 r9, 32                                    r9 >>= 32   ///  r9 = r9.wrapping_shr(32)
    stxdw [r10-0x68], r8                    
    mov64 r2, r7                                    r2 = r7
    jeq r5, 0, lbb_37544                            if r5 == (0 as i32 as i64 as u64) { pc += 33 }
    mul64 r5, r6                                    r5 *= r6   ///  r5 = r5.wrapping_mul(r6)
    add64 r5, r9                                    r5 += r9   ///  r5 = r5.wrapping_add(r9)
    lddw r3, 0xffffffff                             r3 load str located at 4294967295
    mov64 r9, r5                                    r9 = r5
    stxdw [r10-0x68], r8                    
    mov64 r2, r7                                    r2 = r7
    jgt r5, r3, lbb_37541                           if r5 > r3 { pc += 22 }
    ja lbb_37544                                    if true { pc += 24 }
lbb_37520:
    mov64 r3, r8                                    r3 = r8
    mul64 r3, r1                                    r3 *= r1   ///  r3 = r3.wrapping_mul(r1)
    mov64 r4, r8                                    r4 = r8
    mul64 r4, r6                                    r4 *= r6   ///  r4 = r4.wrapping_mul(r6)
    mov64 r2, r4                                    r2 = r4
    rsh64 r2, 32                                    r2 >>= 32   ///  r2 = r2.wrapping_shr(32)
    add64 r2, r3                                    r2 += r3   ///  r2 = r2.wrapping_add(r3)
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    stxdw [r10-0x68], r4                    
    stxw [r10-0x48], r4                     
    stxw [r10-0x44], r2                     
    mov64 r9, r2                                    r9 = r2
    rsh64 r9, 32                                    r9 >>= 32   ///  r9 = r9.wrapping_shr(32)
    jeq r0, 0, lbb_37544                            if r0 == (0 as i32 as i64 as u64) { pc += 10 }
    mul64 r0, r8                                    r0 *= r8   ///  r0 = r0.wrapping_mul(r8)
    add64 r0, r9                                    r0 += r9   ///  r0 = r0.wrapping_add(r9)
    lddw r3, 0xffffffff                             r3 load str located at 4294967295
    mov64 r9, r0                                    r9 = r0
    jgt r0, r3, lbb_37541                           if r0 > r3 { pc += 1 }
    ja lbb_37544                                    if true { pc += 3 }
lbb_37541:
    mov64 r1, r9                                    r1 = r9
    rsh64 r1, 32                                    r1 >>= 32   ///  r1 = r1.wrapping_shr(32)
    stxw [r10-0x3c], r1                     
lbb_37544:
    stxw [r10-0x40], r9                     
    ldxdw r4, [r10-0x70]                    
lbb_37546:
    mov64 r3, 3                                     r3 = 3 as i32 as i64 as u64
    lsh64 r1, 32                                    r1 <<= 32   ///  r1 = r1.wrapping_shl(32)
    rsh64 r1, 32                                    r1 >>= 32   ///  r1 = r1.wrapping_shr(32)
    jne r1, 0, lbb_37563                            if r1 != (0 as i32 as i64 as u64) { pc += 13 }
    mov64 r1, r2                                    r1 = r2
    lsh64 r1, 32                                    r1 <<= 32   ///  r1 = r1.wrapping_shl(32)
    rsh64 r1, 32                                    r1 >>= 32   ///  r1 = r1.wrapping_shr(32)
    mov64 r3, 1                                     r3 = 1 as i32 as i64 as u64
    jne r1, 0, lbb_37556                            if r1 != (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
lbb_37556:
    mov64 r1, r9                                    r1 = r9
    lsh64 r1, 32                                    r1 <<= 32   ///  r1 = r1.wrapping_shl(32)
    rsh64 r1, 32                                    r1 >>= 32   ///  r1 = r1.wrapping_shr(32)
    jeq r1, 0, lbb_37561                            if r1 == (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r3, 2                                     r3 = 2 as i32 as i64 as u64
lbb_37561:
    jgt r4, 28, lbb_37563                           if r4 > (28 as i32 as i64 as u64) { pc += 1 }
    ja lbb_37577                                    if true { pc += 14 }
lbb_37563:
    mov64 r1, r10                                   r1 = r10
    add64 r1, -80                                   r1 += -80   ///  r1 = r1.wrapping_add(-80 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -72                                   r2 += -72   ///  r2 = r2.wrapping_add(-72 as i32 as i64 as u64)
    call function_35478                     
    ldxw r1, [r10-0x50]                     
    jne r1, 1, lbb_37598                            if r1 != (1 as i32 as i64 as u64) { pc += 28 }
    ldxw r4, [r10-0x4c]                     
    mov64 r1, r4                                    r1 = r4
    jgt r1, 28, lbb_37668                           if r1 > (28 as i32 as i64 as u64) { pc += 95 }
    ldxw r1, [r10-0x48]                     
    stxdw [r10-0x68], r1                    
    ldxw r2, [r10-0x44]                     
    ldxw r9, [r10-0x40]                     
lbb_37577:
    ldxdw r5, [r10-0x58]                    
    stxw [r5+0x10], r2                      
    or64 r2, r9                                     r2 |= r9   ///  r2 = r2.or(r9)
    stxw [r5+0x8], r9                       
    ldxdw r1, [r10-0x68]                    
    stxw [r5+0xc], r1                       
    or64 r2, r1                                     r2 |= r1   ///  r2 = r2.or(r1)
    lsh64 r2, 32                                    r2 <<= 32   ///  r2 = r2.wrapping_shl(32)
    rsh64 r2, 32                                    r2 >>= 32   ///  r2 = r2.wrapping_shr(32)
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
    jeq r2, 0, lbb_37593                            if r2 == (0 as i32 as i64 as u64) { pc += 4 }
    lddw r2, 0x80000000                             r2 load str located at 2147483648
    ldxdw r3, [r10-0x78]                    
    and64 r3, r2                                    r3 &= r2   ///  r3 = r3.and(r2)
lbb_37593:
    stxw [r5+0x0], r1                       
    lsh64 r4, 16                                    r4 <<= 16   ///  r4 = r4.wrapping_shl(16)
    or64 r3, r4                                     r3 |= r4   ///  r3 = r3.or(r4)
    stxw [r5+0x4], r3                       
    ja lbb_37660                                    if true { pc += 62 }
lbb_37598:
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    ldxdw r2, [r10-0x58]                    
    stxw [r2+0x0], r1                       
    ja lbb_37660                                    if true { pc += 58 }
lbb_37602:
    ldxdw r5, [r10-0x58]                    
    ldxdw r0, [r10-0x70]                    
    jgt r0, 28, lbb_37606                           if r0 > (28 as i32 as i64 as u64) { pc += 1 }
    ja lbb_37639                                    if true { pc += 33 }
lbb_37606:
    jgt r0, 47, lbb_37608                           if r0 > (47 as i32 as i64 as u64) { pc += 1 }
    ja lbb_37613                                    if true { pc += 5 }
lbb_37608:
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    stxw [r5+0x10], r1                      
    stxdw [r5+0x8], r1                      
    stxdw [r5+0x0], r1                      
    ja lbb_37660                                    if true { pc += 47 }
lbb_37613:
    add64 r0, -29                                   r0 += -29   ///  r0 = r0.wrapping_add(-29 as i32 as i64 as u64)
    lsh64 r0, 32                                    r0 <<= 32   ///  r0 = r0.wrapping_shl(32)
    rsh64 r0, 32                                    r0 >>= 32   ///  r0 = r0.wrapping_shr(32)
    lsh64 r0, 3                                     r0 <<= 3   ///  r0 = r0.wrapping_shl(3)
    lddw r1, 0x100062db8 --> b"\x0a\x00\x00\x00\x00\x00\x00\x00d\x00\x00\x00\x00\x00\x00\x00\xe8\x03\x00…        r1 load str located at 4295372216
    add64 r1, r0                                    r1 += r0   ///  r1 = r1.wrapping_add(r0)
    ldxdw r2, [r1+0x0]                      
    jeq r2, 0, lbb_37661                            if r2 == (0 as i32 as i64 as u64) { pc += 39 }
    mov64 r1, r8                                    r1 = r8
    div64 r1, r2                                    r1 /= r2   ///  r1 = r1 / r2
    mov64 r4, r1                                    r4 = r1
    mul64 r4, r2                                    r4 *= r2   ///  r4 = r4.wrapping_mul(r2)
    mov64 r3, r8                                    r3 = r8
    sub64 r3, r4                                    r3 -= r4   ///  r3 = r3.wrapping_sub(r4)
    mov64 r0, 28                                    r0 = 28 as i32 as i64 as u64
    rsh64 r2, 1                                     r2 >>= 1   ///  r2 = r2.wrapping_shr(1)
    mov64 r8, r1                                    r8 = r1
    jgt r2, r3, lbb_37639                           if r2 > r3 { pc += 7 }
    mov64 r4, r1                                    r4 = r1
    and64 r4, 1                                     r4 &= 1   ///  r4 = r4.and(1)
    jne r4, 0, lbb_37637                            if r4 != (0 as i32 as i64 as u64) { pc += 2 }
    mov64 r8, r1                                    r8 = r1
    jge r2, r3, lbb_37639                           if r2 >= r3 { pc += 2 }
lbb_37637:
    add64 r1, 1                                     r1 += 1   ///  r1 = r1.wrapping_add(1 as i32 as i64 as u64)
    mov64 r8, r1                                    r8 = r1
lbb_37639:
    stxw [r5+0xc], r8                       
    mov64 r1, r8                                    r1 = r8
    rsh64 r1, 32                                    r1 >>= 32   ///  r1 = r1.wrapping_shr(32)
    mov64 r4, r1                                    r4 = r1
    or64 r4, r8                                     r4 |= r8   ///  r4 = r4.or(r8)
    lsh64 r4, 32                                    r4 <<= 32   ///  r4 = r4.wrapping_shl(32)
    rsh64 r4, 32                                    r4 >>= 32   ///  r4 = r4.wrapping_shr(32)
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
    jeq r4, 0, lbb_37654                            if r4 == (0 as i32 as i64 as u64) { pc += 5 }
    lddw r2, 0x80000000                             r2 load str located at 2147483648
    ldxdw r4, [r10-0x78]                    
    and64 r4, r2                                    r4 &= r2   ///  r4 = r4.and(r2)
    mov64 r2, r4                                    r2 = r4
lbb_37654:
    stxw [r5+0x8], r3                       
    stxw [r5+0x0], r3                       
    stxw [r5+0x10], r1                      
    lsh64 r0, 16                                    r0 <<= 16   ///  r0 = r0.wrapping_shl(16)
    or64 r2, r0                                     r2 |= r0   ///  r2 = r2.or(r0)
    stxw [r5+0x4], r2                       
lbb_37660:
    exit                                    
lbb_37661:
    lddw r1, 0x100062c70 --> b"attempt to divide by zero"        r1 load str located at 4295371888
    mov64 r2, 25                                    r2 = 25 as i32 as i64 as u64
    lddw r3, 0x100066bb0 --> b"\x00\x00\x00\x0020\x06\x00\x0e\x00\x00\x00\x00\x00\x00\x00 \x00\x00\x00\x…        r3 load str located at 4295388080
    call function_44254                     
    syscall [invalid]                       
lbb_37668:
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    stxdw [r10-0x28], r1                    
    lddw r1, 0x100066950 --> b"\x00\x00\x00\x00\x8f-\x06\x00%\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x0…        r1 load str located at 4295387472
    stxdw [r10-0x30], r1                    
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    stxdw [r10-0x10], r1                    
    stxdw [r10-0x18], r1                    
    lddw r1, 0x100062c08 --> b"invalid args/home/runner/work/platform-tools/platf"        r1 load str located at 4295371784
    stxdw [r10-0x20], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -48                                   r1 += -48   ///  r1 = r1.wrapping_add(-48 as i32 as i64 as u64)
    lddw r2, 0x100066960 --> b"\x00\x00\x00\x00\x81-\x06\x00\x0e\x00\x00\x00\x00\x00\x00\x00\x11\x02\x00…        r2 load str located at 4295387488
    call function_44240                     
    syscall [invalid]                       

function_37685:
    stxdw [r10-0xc0], r5                    
    stxdw [r10-0xc8], r4                    
    stxdw [r10-0xd0], r3                    
    stxdw [r10-0xe0], r1                    
    mov64 r9, 0                                     r9 = 0 as i32 as i64 as u64
    mov64 r1, r10                                   r1 = r10
    add64 r1, -168                                  r1 += -168   ///  r1 = r1.wrapping_add(-168 as i32 as i64 as u64)
    stxdw [r10-0xd8], r1                    
    ldxw r1, [r2+0x0]                       
    stxdw [r10-0xb8], r1                    
    ldxw r4, [r2+0x4]                       
    ldxw r0, [r2+0xc]                       
    ldxw r2, [r2+0x8]                       
    mov64 r3, r2                                    r3 = r2
    or64 r3, r0                                     r3 |= r0   ///  r3 = r3.or(r0)
    or64 r3, r4                                     r3 |= r4   ///  r3 = r3.or(r4)
    lsh64 r3, 32                                    r3 <<= 32   ///  r3 = r3.wrapping_shl(32)
    rsh64 r3, 32                                    r3 >>= 32   ///  r3 = r3.wrapping_shr(32)
    jeq r3, 0, lbb_37751                            if r3 == (0 as i32 as i64 as u64) { pc += 47 }
    mov64 r6, 32                                    r6 = 32 as i32 as i64 as u64
    mov64 r8, 10                                    r8 = 10 as i32 as i64 as u64
    ldxdw r5, [r10-0xd8]                    
lbb_37707:
    mov64 r3, r4                                    r3 = r4
    lsh64 r4, 32                                    r4 <<= 32   ///  r4 = r4.wrapping_shl(32)
    rsh64 r4, 32                                    r4 >>= 32   ///  r4 = r4.wrapping_shr(32)
    div64 r4, 10                                    r4 /= 10   ///  r4 = r4 / (10 as u64)
    mov64 r1, r4                                    r1 = r4
    mul64 r1, 10                                    r1 *= 10   ///  r1 = r1.wrapping_mul(10 as u64)
    mov64 r7, r3                                    r7 = r3
    sub64 r7, r1                                    r7 -= r1   ///  r7 = r7.wrapping_sub(r1)
    lsh64 r7, 32                                    r7 <<= 32   ///  r7 = r7.wrapping_shl(32)
    lsh64 r0, 32                                    r0 <<= 32   ///  r0 = r0.wrapping_shl(32)
    rsh64 r0, 32                                    r0 >>= 32   ///  r0 = r0.wrapping_shr(32)
    or64 r7, r0                                     r7 |= r0   ///  r7 = r7.or(r0)
    mov64 r0, r7                                    r0 = r7
    div64 r0, 10                                    r0 /= 10   ///  r0 = r0 / (10 as u64)
    mov64 r1, r0                                    r1 = r0
    mul64 r1, 10                                    r1 *= 10   ///  r1 = r1.wrapping_mul(10 as u64)
    sub64 r7, r1                                    r7 -= r1   ///  r7 = r7.wrapping_sub(r1)
    lsh64 r2, 32                                    r2 <<= 32   ///  r2 = r2.wrapping_shl(32)
    rsh64 r2, 32                                    r2 >>= 32   ///  r2 = r2.wrapping_shr(32)
    lsh64 r7, 32                                    r7 <<= 32   ///  r7 = r7.wrapping_shl(32)
    or64 r7, r2                                     r7 |= r2   ///  r7 = r7.or(r2)
    mov64 r2, r7                                    r2 = r7
    div64 r2, 10                                    r2 /= 10   ///  r2 = r2 / (10 as u64)
    mov64 r1, r2                                    r1 = r2
    mul64 r1, 10                                    r1 *= 10   ///  r1 = r1.wrapping_mul(10 as u64)
    sub64 r7, r1                                    r7 -= r1   ///  r7 = r7.wrapping_sub(r1)
    or64 r7, 48                                     r7 |= 48   ///  r7 = r7.or(48)
    jgt r6, r9, lbb_37736                           if r6 > r9 { pc += 1 }
    ja lbb_38031                                    if true { pc += 295 }
lbb_37736:
    stxw [r5+0x0], r7                       
    add64 r5, 4                                     r5 += 4   ///  r5 = r5.wrapping_add(4 as i32 as i64 as u64)
    add64 r9, 1                                     r9 += 1   ///  r9 = r9.wrapping_add(1 as i32 as i64 as u64)
    mov64 r1, r2                                    r1 = r2
    lsh64 r1, 32                                    r1 <<= 32   ///  r1 = r1.wrapping_shl(32)
    rsh64 r1, 32                                    r1 >>= 32   ///  r1 = r1.wrapping_shr(32)
    jne r1, 0, lbb_37707                            if r1 != (0 as i32 as i64 as u64) { pc += -36 }
    mov64 r1, r0                                    r1 = r0
    lsh64 r1, 32                                    r1 <<= 32   ///  r1 = r1.wrapping_shl(32)
    rsh64 r1, 32                                    r1 >>= 32   ///  r1 = r1.wrapping_shr(32)
    jne r1, 0, lbb_37707                            if r1 != (0 as i32 as i64 as u64) { pc += -40 }
    lsh64 r3, 32                                    r3 <<= 32   ///  r3 = r3.wrapping_shl(32)
    rsh64 r3, 32                                    r3 >>= 32   ///  r3 = r3.wrapping_shr(32)
    jgt r8, r3, lbb_37751                           if r8 > r3 { pc += 1 }
    ja lbb_37707                                    if true { pc += -44 }
lbb_37751:
    ldxdw r4, [r10-0xb8]                    
    mov64 r0, r4                                    r0 = r4
    rsh64 r0, 16                                    r0 >>= 16   ///  r0 = r0.wrapping_shr(16)
    and64 r0, 255                                   r0 &= 255   ///  r0 = r0.and(255)
    mov64 r1, r9                                    r1 = r9
    lsh64 r1, 32                                    r1 <<= 32   ///  r1 = r1.wrapping_shl(32)
    rsh64 r1, 32                                    r1 >>= 32   ///  r1 = r1.wrapping_shr(32)
    jge r1, r0, lbb_37773                           if r1 >= r0 { pc += 14 }
    mov64 r1, r9                                    r1 = r9
    lsh64 r1, 2                                     r1 <<= 2   ///  r1 = r1.wrapping_shl(2)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -172                                  r2 += -172   ///  r2 = r2.wrapping_add(-172 as i32 as i64 as u64)
    add64 r1, r2                                    r1 += r2   ///  r1 = r1.wrapping_add(r2)
    add64 r1, 4                                     r1 += 4   ///  r1 = r1.wrapping_add(4 as i32 as i64 as u64)
    mov64 r2, 32                                    r2 = 32 as i32 as i64 as u64
    mov64 r3, 48                                    r3 = 48 as i32 as i64 as u64
lbb_37767:
    jgt r2, r9, lbb_37769                           if r2 > r9 { pc += 1 }
    ja lbb_38043                                    if true { pc += 274 }
lbb_37769:
    stxw [r1+0x0], r3                       
    add64 r1, 4                                     r1 += 4   ///  r1 = r1.wrapping_add(4 as i32 as i64 as u64)
    add64 r9, 1                                     r9 += 1   ///  r9 = r9.wrapping_add(1 as i32 as i64 as u64)
    jgt r0, r9, lbb_37767                           if r0 > r9 { pc += -6 }
lbb_37773:
    lsh64 r4, 32                                    r4 <<= 32   ///  r4 = r4.wrapping_shl(32)
    arsh64 r4, 32                                   r4 >>= 32 (signed)   ///  r4 = (r4 as i64).wrapping_shr(32)
    stxw [r10-0xac], r9                     
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
    mov64 r6, r0                                    r6 = r0
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
    ldxdw r1, [r10-0xc8]                    
    jeq r1, 0, lbb_37784                            if r1 == (0 as i32 as i64 as u64) { pc += 3 }
    ldxdw r1, [r10-0xc0]                    
    mov64 r6, r1                                    r6 = r1
    jgt r1, 28, lbb_37853                           if r1 > (28 as i32 as i64 as u64) { pc += 69 }
lbb_37784:
    stxdw [r10-0xe8], r2                    
    mov64 r2, r9                                    r2 = r9
    lsh64 r2, 32                                    r2 <<= 32   ///  r2 = r2.wrapping_shl(32)
    rsh64 r2, 32                                    r2 >>= 32   ///  r2 = r2.wrapping_shr(32)
    mov64 r1, r2                                    r1 = r2
    sub64 r1, r0                                    r1 -= r0   ///  r1 = r1.wrapping_sub(r0)
    jsgt r4, -1, lbb_37797                          if (r4 as i64) > (-1 as i32 as i64) { pc += 6 }
    ldxdw r4, [r10-0xd0]                    
    jne r4, 0, lbb_37794                            if r4 != (0 as i32 as i64 as u64) { pc += 1 }
    ja lbb_37797                                    if true { pc += 3 }
lbb_37794:
    mov64 r3, 45                                    r3 = 45 as i32 as i64 as u64
    stxb [r10-0x24], r3                     
    mov64 r3, 1                                     r3 = 1 as i32 as i64 as u64
lbb_37797:
    add64 r6, r1                                    r6 += r1   ///  r6 = r6.wrapping_add(r1)
    stxdw [r10-0xd0], r3                    
    mov64 r1, r3                                    r1 = r3
    jeq r6, 0, lbb_37890                            if r6 == (0 as i32 as i64 as u64) { pc += 89 }
    mov64 r1, r10                                   r1 = r10
    add64 r1, -36                                   r1 += -36   ///  r1 = r1.wrapping_add(-36 as i32 as i64 as u64)
    stxdw [r10-0xb8], r1                    
    lsh64 r9, 32                                    r9 <<= 32   ///  r9 = r9.wrapping_shl(32)
    rsh64 r9, 32                                    r9 >>= 32   ///  r9 = r9.wrapping_shr(32)
    ldxdw r5, [r10-0xd0]                    
    mov64 r4, r5                                    r4 = r5
    jne r9, r0, lbb_37815                           if r9 != r0 { pc += 6 }
    ldxdw r1, [r10-0xb8]                    
    add64 r1, r5                                    r1 += r5   ///  r1 = r1.wrapping_add(r5)
    mov64 r3, 11824                                 r3 = 11824 as i32 as i64 as u64
    stxh [r1+0x0], r3                       
    mov64 r4, r5                                    r4 = r5
    or64 r4, 2                                      r4 |= 2   ///  r4 = r4.or(2)
lbb_37815:
    jne r9, 0, lbb_37821                            if r9 != (0 as i32 as i64 as u64) { pc += 5 }
    ldxdw r1, [r10-0xb8]                    
    add64 r1, r4                                    r1 += r4   ///  r1 = r1.wrapping_add(r4)
    mov64 r3, 48                                    r3 = 48 as i32 as i64 as u64
    stxb [r1+0x0], r3                       
    ja lbb_37860                                    if true { pc += 39 }
lbb_37821:
    ldxdw r1, [r10-0xb8]                    
    add64 r1, r4                                    r1 += r4   ///  r1 = r1.wrapping_add(r4)
    mov64 r3, r2                                    r3 = r2
    lsh64 r3, 2                                     r3 <<= 2   ///  r3 = r3.wrapping_shl(2)
    ldxdw r5, [r10-0xd8]                    
    add64 r3, r5                                    r3 += r5   ///  r3 = r3.wrapping_add(r5)
    ldxw r5, [r3-0x4]                       
    mov64 r3, 128                                   r3 = 128 as i32 as i64 as u64
    jgt r3, r5, lbb_37859                           if r3 > r5 { pc += 29 }
    mov64 r3, 2048                                  r3 = 2048 as i32 as i64 as u64
    jgt r3, r5, lbb_38004                           if r3 > r5 { pc += 172 }
    mov64 r3, 65536                                 r3 = 65536 as i32 as i64 as u64
    jgt r3, r5, lbb_38013                           if r3 > r5 { pc += 179 }
    mov64 r3, r5                                    r3 = r5
    and64 r3, 63                                    r3 &= 63   ///  r3 = r3.and(63)
    or64 r3, 128                                    r3 |= 128   ///  r3 = r3.or(128)
    stxb [r1+0x3], r3                       
    mov64 r3, r5                                    r3 = r5
    rsh64 r3, 18                                    r3 >>= 18   ///  r3 = r3.wrapping_shr(18)
    or64 r3, 240                                    r3 |= 240   ///  r3 = r3.or(240)
    stxb [r1+0x0], r3                       
    mov64 r3, r5                                    r3 = r5
    rsh64 r3, 6                                     r3 >>= 6   ///  r3 = r3.wrapping_shr(6)
    and64 r3, 63                                    r3 &= 63   ///  r3 = r3.and(63)
    or64 r3, 128                                    r3 |= 128   ///  r3 = r3.or(128)
    stxb [r1+0x2], r3                       
    rsh64 r5, 12                                    r5 >>= 12   ///  r5 = r5.wrapping_shr(12)
    and64 r5, 63                                    r5 &= 63   ///  r5 = r5.and(63)
    or64 r5, 128                                    r5 |= 128   ///  r5 = r5.or(128)
    stxb [r1+0x1], r5                       
    mov64 r1, 4                                     r1 = 4 as i32 as i64 as u64
    ja lbb_37861                                    if true { pc += 8 }
lbb_37853:
    mov64 r2, 1                                     r2 = 1 as i32 as i64 as u64
    mov64 r6, 28                                    r6 = 28 as i32 as i64 as u64
    ldxdw r1, [r10-0xc0]                    
    add64 r1, -28                                   r1 += -28   ///  r1 = r1.wrapping_add(-28 as i32 as i64 as u64)
    stxdw [r10-0xc0], r1                    
    ja lbb_37784                                    if true { pc += -75 }
lbb_37859:
    stxb [r1+0x0], r5                       
lbb_37860:
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
lbb_37861:
    add64 r1, r4                                    r1 += r4   ///  r1 = r1.wrapping_add(r4)
    mov64 r3, 2                                     r3 = 2 as i32 as i64 as u64
    jgt r3, r6, lbb_37890                           if r3 > r6 { pc += 26 }
    mov64 r4, r2                                    r4 = r2
    sub64 r4, r0                                    r4 -= r0   ///  r4 = r4.wrapping_sub(r0)
    mov64 r0, r2                                    r0 = r2
    lsh64 r0, 2                                     r0 <<= 2   ///  r0 = r0.wrapping_shl(2)
    mov64 r3, r10                                   r3 = r10
    add64 r3, -172                                  r3 += -172   ///  r3 = r3.wrapping_add(-172 as i32 as i64 as u64)
    add64 r0, r3                                    r0 += r3   ///  r0 = r0.wrapping_add(r3)
    mov64 r7, 1                                     r7 = 1 as i32 as i64 as u64
    mov64 r9, -2                                    r9 = -2 as i32 as i64 as u64
    add64 r0, -4                                    r0 += -4   ///  r0 = r0.wrapping_add(-4 as i32 as i64 as u64)
    stxdw [r10-0xc8], r6                    
    ja lbb_37897                                    if true { pc += 21 }
lbb_37876:
    mov64 r1, r3                                    r1 = r3
    lsh64 r1, 32                                    r1 <<= 32   ///  r1 = r1.wrapping_shl(32)
    rsh64 r1, 32                                    r1 >>= 32   ///  r1 = r1.wrapping_shr(32)
    jeq r1, 32, lbb_38056                           if r1 == (32 as i32 as i64 as u64) { pc += 176 }
    ldxdw r5, [r10-0xb8]                    
    add64 r5, r1                                    r5 += r1   ///  r5 = r5.wrapping_add(r1)
    mov64 r1, 48                                    r1 = 48 as i32 as i64 as u64
    stxb [r5+0x0], r1                       
lbb_37884:
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
lbb_37885:
    add64 r7, 1                                     r7 += 1   ///  r7 = r7.wrapping_add(1 as i32 as i64 as u64)
    add64 r1, r3                                    r1 += r3   ///  r1 = r1.wrapping_add(r3)
    add64 r0, -4                                    r0 += -4   ///  r0 = r0.wrapping_add(-4 as i32 as i64 as u64)
    add64 r9, -1                                    r9 += -1   ///  r9 = r9.wrapping_add(-1 as i32 as i64 as u64)
    jgt r6, r7, lbb_37897                           if r6 > r7 { pc += 7 }
lbb_37890:
    stxw [r10-0x28], r1                     
    mov64 r2, r1                                    r2 = r1
    lsh64 r2, 32                                    r2 <<= 32   ///  r2 = r2.wrapping_shl(32)
    rsh64 r2, 32                                    r2 >>= 32   ///  r2 = r2.wrapping_shr(32)
    ldxdw r4, [r10-0xd0]                    
    jeq r4, r2, lbb_37979                           if r4 == r2 { pc += 83 }
    ja lbb_37993                                    if true { pc += 96 }
lbb_37897:
    jeq r4, r7, lbb_37899                           if r4 == r7 { pc += 1 }
    ja lbb_37908                                    if true { pc += 9 }
lbb_37899:
    mov64 r3, r1                                    r3 = r1
    lsh64 r3, 32                                    r3 <<= 32   ///  r3 = r3.wrapping_shl(32)
    rsh64 r3, 32                                    r3 >>= 32   ///  r3 = r3.wrapping_shr(32)
    jeq r3, 32, lbb_38069                           if r3 == (32 as i32 as i64 as u64) { pc += 166 }
    ldxdw r5, [r10-0xb8]                    
    add64 r5, r3                                    r5 += r3   ///  r5 = r5.wrapping_add(r3)
    mov64 r3, 46                                    r3 = 46 as i32 as i64 as u64
    stxb [r5+0x0], r3                       
    add64 r1, 1                                     r1 += 1   ///  r1 = r1.wrapping_add(1 as i32 as i64 as u64)
lbb_37908:
    mov64 r3, r1                                    r3 = r1
    jgt r2, r7, lbb_37911                           if r2 > r7 { pc += 1 }
    ja lbb_37876                                    if true { pc += -35 }
lbb_37911:
    mov64 r1, r2                                    r1 = r2
    add64 r1, r9                                    r1 += r9   ///  r1 = r1.wrapping_add(r9)
    jgt r2, r1, lbb_37915                           if r2 > r1 { pc += 1 }
    ja lbb_38027                                    if true { pc += 112 }
lbb_37915:
    mov64 r8, r3                                    r8 = r3
    lsh64 r8, 32                                    r8 <<= 32   ///  r8 = r8.wrapping_shl(32)
    rsh64 r8, 32                                    r8 >>= 32   ///  r8 = r8.wrapping_shr(32)
    ldxdw r1, [r10-0xb8]                    
    add64 r1, r8                                    r1 += r8   ///  r1 = r1.wrapping_add(r8)
    ldxw r5, [r0+0x0]                       
    jgt r5, 127, lbb_37923                          if r5 > (127 as i32 as i64 as u64) { pc += 1 }
    jne r8, 32, lbb_37945                           if r8 != (32 as i32 as i64 as u64) { pc += 22 }
lbb_37923:
    mov64 r6, 32                                    r6 = 32 as i32 as i64 as u64
    sub64 r6, r8                                    r6 -= r8   ///  r6 = r6.wrapping_sub(r8)
    jgt r5, 2047, lbb_37927                         if r5 > (2047 as i32 as i64 as u64) { pc += 1 }
    jgt r6, 1, lbb_37947                            if r6 > (1 as i32 as i64 as u64) { pc += 20 }
lbb_37927:
    jgt r5, 65535, lbb_37957                        if r5 > (65535 as i32 as i64 as u64) { pc += 29 }
    jgt r6, 2, lbb_37930                            if r6 > (2 as i32 as i64 as u64) { pc += 1 }
    ja lbb_37957                                    if true { pc += 27 }
lbb_37930:
    mov64 r6, r5                                    r6 = r5
    and64 r6, 63                                    r6 &= 63   ///  r6 = r6.and(63)
    or64 r6, 128                                    r6 |= 128   ///  r6 = r6.or(128)
    stxb [r1+0x2], r6                       
    mov64 r6, r5                                    r6 = r5
    rsh64 r6, 12                                    r6 >>= 12   ///  r6 = r6.wrapping_shr(12)
    or64 r6, 224                                    r6 |= 224   ///  r6 = r6.or(224)
    stxb [r1+0x0], r6                       
    rsh64 r5, 6                                     r5 >>= 6   ///  r5 = r5.wrapping_shr(6)
    and64 r5, 63                                    r5 &= 63   ///  r5 = r5.and(63)
    or64 r5, 128                                    r5 |= 128   ///  r5 = r5.or(128)
    stxb [r1+0x1], r5                       
    mov64 r1, 3                                     r1 = 3 as i32 as i64 as u64
    ldxdw r6, [r10-0xc8]                    
    ja lbb_37885                                    if true { pc += -60 }
lbb_37945:
    stxb [r1+0x0], r5                       
    ja lbb_37884                                    if true { pc += -63 }
lbb_37947:
    mov64 r6, r5                                    r6 = r5
    and64 r6, 63                                    r6 &= 63   ///  r6 = r6.and(63)
    or64 r6, 128                                    r6 |= 128   ///  r6 = r6.or(128)
    stxb [r1+0x1], r6                       
    rsh64 r5, 6                                     r5 >>= 6   ///  r5 = r5.wrapping_shr(6)
    or64 r5, 192                                    r5 |= 192   ///  r5 = r5.or(192)
    stxb [r1+0x0], r5                       
    mov64 r1, 2                                     r1 = 2 as i32 as i64 as u64
    ldxdw r6, [r10-0xc8]                    
    ja lbb_37885                                    if true { pc += -72 }
lbb_37957:
    jgt r6, 3, lbb_37959                            if r6 > (3 as i32 as i64 as u64) { pc += 1 }
    ja lbb_38082                                    if true { pc += 123 }
lbb_37959:
    mov64 r6, r5                                    r6 = r5
    and64 r6, 63                                    r6 &= 63   ///  r6 = r6.and(63)
    or64 r6, 128                                    r6 |= 128   ///  r6 = r6.or(128)
    stxb [r1+0x3], r6                       
    mov64 r6, r5                                    r6 = r5
    rsh64 r6, 18                                    r6 >>= 18   ///  r6 = r6.wrapping_shr(18)
    or64 r6, 240                                    r6 |= 240   ///  r6 = r6.or(240)
    stxb [r1+0x0], r6                       
    mov64 r6, r5                                    r6 = r5
    rsh64 r6, 6                                     r6 >>= 6   ///  r6 = r6.wrapping_shr(6)
    and64 r6, 63                                    r6 &= 63   ///  r6 = r6.and(63)
    or64 r6, 128                                    r6 |= 128   ///  r6 = r6.or(128)
    stxb [r1+0x2], r6                       
    rsh64 r5, 12                                    r5 >>= 12   ///  r5 = r5.wrapping_shr(12)
    and64 r5, 63                                    r5 &= 63   ///  r5 = r5.and(63)
    or64 r5, 128                                    r5 |= 128   ///  r5 = r5.or(128)
    stxb [r1+0x1], r5                       
    mov64 r1, 4                                     r1 = 4 as i32 as i64 as u64
    ldxdw r6, [r10-0xc8]                    
    ja lbb_37885                                    if true { pc += -94 }
lbb_37979:
    mov64 r3, r10                                   r3 = r10
    add64 r3, -40                                   r3 += -40   ///  r3 = r3.wrapping_add(-40 as i32 as i64 as u64)
    or64 r3, r4                                     r3 |= r4   ///  r3 = r3.or(r4)
    add64 r3, 4                                     r3 += 4   ///  r3 = r3.wrapping_add(4 as i32 as i64 as u64)
    jeq r2, 32, lbb_37988                           if r2 == (32 as i32 as i64 as u64) { pc += 4 }
    mov64 r2, 48                                    r2 = 48 as i32 as i64 as u64
    stxb [r3+0x0], r2                       
    mov64 r2, 1                                     r2 = 1 as i32 as i64 as u64
    ja lbb_37991                                    if true { pc += 3 }
lbb_37988:
    mov64 r2, 45248                                 r2 = 45248 as i32 as i64 as u64
    stxh [r3+0x0], r2                       
    mov64 r2, 2                                     r2 = 2 as i32 as i64 as u64
lbb_37991:
    add64 r2, r1                                    r2 += r1   ///  r2 = r2.wrapping_add(r1)
    stxw [r10-0x28], r2                     
lbb_37993:
    mov64 r2, r10                                   r2 = r10
    add64 r2, -40                                   r2 += -40   ///  r2 = r2.wrapping_add(-40 as i32 as i64 as u64)
    ldxdw r6, [r10-0xe0]                    
    mov64 r1, r6                                    r1 = r6
    mov64 r3, 36                                    r3 = 36 as i32 as i64 as u64
    call function_48190                     
    ldxdw r1, [r10-0xc0]                    
    stxdw [r6+0x30], r1                     
    ldxdw r1, [r10-0xe8]                    
    stxdw [r6+0x28], r1                     
    exit                                    
lbb_38004:
    mov64 r3, r5                                    r3 = r5
    and64 r3, 63                                    r3 &= 63   ///  r3 = r3.and(63)
    or64 r3, 128                                    r3 |= 128   ///  r3 = r3.or(128)
    stxb [r1+0x1], r3                       
    rsh64 r5, 6                                     r5 >>= 6   ///  r5 = r5.wrapping_shr(6)
    or64 r5, 192                                    r5 |= 192   ///  r5 = r5.or(192)
    stxb [r1+0x0], r5                       
    mov64 r1, 2                                     r1 = 2 as i32 as i64 as u64
    ja lbb_37861                                    if true { pc += -152 }
lbb_38013:
    mov64 r3, r5                                    r3 = r5
    and64 r3, 63                                    r3 &= 63   ///  r3 = r3.and(63)
    or64 r3, 128                                    r3 |= 128   ///  r3 = r3.or(128)
    stxb [r1+0x2], r3                       
    mov64 r3, r5                                    r3 = r5
    rsh64 r3, 12                                    r3 >>= 12   ///  r3 = r3.wrapping_shr(12)
    or64 r3, 224                                    r3 |= 224   ///  r3 = r3.or(224)
    stxb [r1+0x0], r3                       
    rsh64 r5, 6                                     r5 >>= 6   ///  r5 = r5.wrapping_shr(6)
    and64 r5, 63                                    r5 &= 63   ///  r5 = r5.and(63)
    or64 r5, 128                                    r5 |= 128   ///  r5 = r5.or(128)
    stxb [r1+0x1], r5                       
    mov64 r1, 3                                     r1 = 3 as i32 as i64 as u64
    ja lbb_37861                                    if true { pc += -166 }
lbb_38027:
    lddw r3, 0x100066bf8 --> b"\x00\x00\x00\x00@0\x06\x00\x0a\x00\x00\x00\x00\x00\x00\x00B\x00\x00\x00\x…        r3 load str located at 4295388152
    call function_44272                     
    syscall [invalid]                       
lbb_38031:
    stxw [r10-0x28], r7                     
    mov64 r3, r10                                   r3 = r10
    add64 r3, -40                                   r3 += -40   ///  r3 = r3.wrapping_add(-40 as i32 as i64 as u64)
    lddw r1, 0x100062d56 --> b"called `Result::unwrap()` on an `Err` value"        r1 load str located at 4295372118
    mov64 r2, 43                                    r2 = 43 as i32 as i64 as u64
    lddw r4, 0x100066900 --> b"\x00\x00\x00\x00\xc8\x0a\x04\x00\x04\x00\x00\x00\x00\x00\x00\x00\x04\x00\…        r4 load str located at 4295387392
    lddw r5, 0x100066bc8 --> b"\x00\x00\x00\x00@0\x06\x00\x0a\x00\x00\x00\x00\x00\x00\x00\x1b\x00\x00\x0…        r5 load str located at 4295388104
    call function_44299                     
    syscall [invalid]                       
lbb_38043:
    mov64 r1, 48                                    r1 = 48 as i32 as i64 as u64
    stxw [r10-0x28], r1                     
    mov64 r3, r10                                   r3 = r10
    add64 r3, -40                                   r3 += -40   ///  r3 = r3.wrapping_add(-40 as i32 as i64 as u64)
    lddw r1, 0x100062d56 --> b"called `Result::unwrap()` on an `Err` value"        r1 load str located at 4295372118
    mov64 r2, 43                                    r2 = 43 as i32 as i64 as u64
    lddw r4, 0x100066900 --> b"\x00\x00\x00\x00\xc8\x0a\x04\x00\x04\x00\x00\x00\x00\x00\x00\x00\x04\x00\…        r4 load str located at 4295387392
    lddw r5, 0x100066c40 --> b"\x00\x00\x00\x00@0\x06\x00\x0a\x00\x00\x00\x00\x00\x00\x00\x1e\x00\x00\x0…        r5 load str located at 4295388224
    call function_44299                     
    syscall [invalid]                       
lbb_38056:
    mov64 r1, 48                                    r1 = 48 as i32 as i64 as u64
    stxw [r10-0x4], r1                      
    mov64 r3, r10                                   r3 = r10
    add64 r3, -4                                    r3 += -4   ///  r3 = r3.wrapping_add(-4 as i32 as i64 as u64)
    lddw r1, 0x100062d56 --> b"called `Result::unwrap()` on an `Err` value"        r1 load str located at 4295372118
    mov64 r2, 43                                    r2 = 43 as i32 as i64 as u64
    lddw r4, 0x100066900 --> b"\x00\x00\x00\x00\xc8\x0a\x04\x00\x04\x00\x00\x00\x00\x00\x00\x00\x04\x00\…        r4 load str located at 4295387392
    lddw r5, 0x100066c28 --> b"\x00\x00\x00\x00@0\x06\x00\x0a\x00\x00\x00\x00\x00\x00\x00@\x00\x00\x00\x…        r5 load str located at 4295388200
    call function_44299                     
    syscall [invalid]                       
lbb_38069:
    mov64 r1, 46                                    r1 = 46 as i32 as i64 as u64
    stxw [r10-0x4], r1                      
    mov64 r3, r10                                   r3 = r10
    add64 r3, -4                                    r3 += -4   ///  r3 = r3.wrapping_add(-4 as i32 as i64 as u64)
    lddw r1, 0x100062d56 --> b"called `Result::unwrap()` on an `Err` value"        r1 load str located at 4295372118
    mov64 r2, 43                                    r2 = 43 as i32 as i64 as u64
    lddw r4, 0x100066900 --> b"\x00\x00\x00\x00\xc8\x0a\x04\x00\x04\x00\x00\x00\x00\x00\x00\x00\x04\x00\…        r4 load str located at 4295387392
    lddw r5, 0x100066be0 --> b"\x00\x00\x00\x00@0\x06\x00\x0a\x00\x00\x00\x00\x00\x00\x00<\x00\x00\x00\x…        r5 load str located at 4295388128
    call function_44299                     
    syscall [invalid]                       
lbb_38082:
    stxw [r10-0x4], r5                      
    mov64 r3, r10                                   r3 = r10
    add64 r3, -4                                    r3 += -4   ///  r3 = r3.wrapping_add(-4 as i32 as i64 as u64)
    lddw r1, 0x100062d56 --> b"called `Result::unwrap()` on an `Err` value"        r1 load str located at 4295372118
    mov64 r2, 43                                    r2 = 43 as i32 as i64 as u64
    lddw r4, 0x100066900 --> b"\x00\x00\x00\x00\xc8\x0a\x04\x00\x04\x00\x00\x00\x00\x00\x00\x00\x04\x00\…        r4 load str located at 4295387392
    lddw r5, 0x100066c10 --> b"\x00\x00\x00\x00@0\x06\x00\x0a\x00\x00\x00\x00\x00\x00\x00C\x00\x00\x00\x…        r5 load str located at 4295388176
    call function_44299                     
    syscall [invalid]                       

function_38094:
    mov64 r6, r1                                    r6 = r1
    mov64 r1, r10                                   r1 = r10
    add64 r1, -68                                   r1 += -68   ///  r1 = r1.wrapping_add(-68 as i32 as i64 as u64)
    call function_38122                     
    ldxw r1, [r10-0x44]                     
    jne r1, 0, lbb_38117                            if r1 != (0 as i32 as i64 as u64) { pc += 17 }
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    stxdw [r10-0x28], r1                    
    lddw r1, 0x100066c58 --> b"\x00\x00\x00\x00V0\x06\x00\x0e\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x0…        r1 load str located at 4295388248
    stxdw [r10-0x30], r1                    
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    stxdw [r10-0x10], r1                    
    stxdw [r10-0x18], r1                    
    lddw r1, 0x100062c08 --> b"invalid args/home/runner/work/platform-tools/platf"        r1 load str located at 4295371784
    stxdw [r10-0x20], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -48                                   r1 += -48   ///  r1 = r1.wrapping_add(-48 as i32 as i64 as u64)
    lddw r2, 0x100066c68 --> b"\x00\x00\x00\x00J0\x06\x00\x0c\x00\x00\x00\x00\x00\x00\x00\xe2\x00\x00\x0…        r2 load str located at 4295388264
    call function_44240                     
    syscall [invalid]                       
lbb_38117:
    ldxdw r1, [r10-0x38]                    
    stxdw [r6+0x8], r1                      
    ldxdw r1, [r10-0x40]                    
    stxdw [r6+0x0], r1                      
    exit                                    

function_38122:
    mov64 r7, r3                                    r7 = r3
    mov64 r8, r2                                    r8 = r2
    mov64 r6, r1                                    r6 = r1
    jne r7, 0, lbb_38131                            if r7 != (0 as i32 as i64 as u64) { pc += 5 }
lbb_38126:
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    stxdw [r6+0x4], r1                      
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    stxdw [r6+0xc], r1                      
    ja lbb_38234                                    if true { pc += 103 }
lbb_38131:
    ldxw r1, [r8+0x8]                       
    ldxw r2, [r8+0xc]                       
    or64 r2, r1                                     r2 |= r1   ///  r2 = r2.or(r1)
    ldxw r1, [r8+0x4]                       
    or64 r2, r1                                     r2 |= r1   ///  r2 = r2.or(r1)
    lsh64 r2, 32                                    r2 <<= 32   ///  r2 = r2.wrapping_shl(32)
    rsh64 r2, 32                                    r2 >>= 32   ///  r2 = r2.wrapping_shr(32)
    jeq r2, 0, lbb_38214                            if r2 == (0 as i32 as i64 as u64) { pc += 75 }
    mov64 r1, r8                                    r1 = r8
    lddw r2, 0x10005fca8 --> b"\x00\x00\x00\x00\x00\x00\x00\x00\x01\x00\x00\x00\x00\x00\x00\x00sdk/src/e…        r2 load str located at 4295359656
    call function_33952                     
    and64 r0, 255                                   r0 &= 255   ///  r0 = r0.and(255)
    jeq r0, 0, lbb_38126                            if r0 == (0 as i32 as i64 as u64) { pc += -19 }
    jeq r7, 1, lbb_38217                            if r7 == (1 as i32 as i64 as u64) { pc += 71 }
    jeq r7, 2, lbb_38221                            if r7 == (2 as i32 as i64 as u64) { pc += 74 }
    stxdw [r10-0x60], r6                    
    ldxdw r1, [r8+0x8]                      
    stxdw [r10-0x30], r1                    
    ldxdw r1, [r8+0x0]                      
    stxdw [r10-0x38], r1                    
    mov64 r9, 1                                     r9 = 1 as i32 as i64 as u64
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
    mov64 r1, r7                                    r1 = r7
    and64 r1, 1                                     r1 &= 1   ///  r1 = r1.and(1)
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
    stxdw [r10-0x48], r3                    
    mov64 r3, 1                                     r3 = 1 as i32 as i64 as u64
    stxdw [r10-0x40], r3                    
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
    stxdw [r10-0x50], r3                    
    jne r1, 0, lbb_38236                            if r1 != (0 as i32 as i64 as u64) { pc += 73 }
lbb_38163:
    stxdw [r10-0x58], r2                    
    mov64 r2, r7                                    r2 = r7
    rsh64 r2, 1                                     r2 >>= 1   ///  r2 = r2.wrapping_shr(1)
    mov64 r1, r7                                    r1 = r7
    or64 r1, r2                                     r1 |= r2   ///  r1 = r1.or(r2)
    mov64 r2, r1                                    r2 = r1
    rsh64 r2, 2                                     r2 >>= 2   ///  r2 = r2.wrapping_shr(2)
    or64 r1, r2                                     r1 |= r2   ///  r1 = r1.or(r2)
    mov64 r2, r1                                    r2 = r1
    rsh64 r2, 4                                     r2 >>= 4   ///  r2 = r2.wrapping_shr(4)
    or64 r1, r2                                     r1 |= r2   ///  r1 = r1.or(r2)
    mov64 r2, r1                                    r2 = r1
    rsh64 r2, 8                                     r2 >>= 8   ///  r2 = r2.wrapping_shr(8)
    or64 r1, r2                                     r1 |= r2   ///  r1 = r1.or(r2)
    mov64 r2, r1                                    r2 = r1
    rsh64 r2, 16                                    r2 >>= 16   ///  r2 = r2.wrapping_shr(16)
    or64 r1, r2                                     r1 |= r2   ///  r1 = r1.or(r2)
    mov64 r2, r1                                    r2 = r1
    rsh64 r2, 32                                    r2 >>= 32   ///  r2 = r2.wrapping_shr(32)
    or64 r1, r2                                     r1 |= r2   ///  r1 = r1.or(r2)
    xor64 r1, -1                                    r1 ^= -1   ///  r1 = r1.xor(-1)
    lddw r2, 0x5555555555555555                     r2 load str located at 6148914691236517205
    mov64 r3, r1                                    r3 = r1
    rsh64 r3, 1                                     r3 >>= 1   ///  r3 = r3.wrapping_shr(1)
    and64 r3, r2                                    r3 &= r2   ///  r3 = r3.and(r2)
    sub64 r1, r3                                    r1 -= r3   ///  r1 = r1.wrapping_sub(r3)
    lddw r3, 0x3333333333333333                     r3 load str located at 3689348814741910323
    mov64 r2, r1                                    r2 = r1
    and64 r2, r3                                    r2 &= r3   ///  r2 = r2.and(r3)
    rsh64 r1, 2                                     r1 >>= 2   ///  r1 = r1.wrapping_shr(2)
    and64 r1, r3                                    r1 &= r3   ///  r1 = r1.and(r3)
    add64 r2, r1                                    r2 += r1   ///  r2 = r2.wrapping_add(r1)
    mov64 r1, r2                                    r1 = r2
    rsh64 r1, 4                                     r1 >>= 4   ///  r1 = r1.wrapping_shr(4)
    add64 r2, r1                                    r2 += r1   ///  r2 = r2.wrapping_add(r1)
    lddw r1, 0xf0f0f0f0f0f0f0f                      r1 load str located at 1085102592571150095
    and64 r2, r1                                    r2 &= r1   ///  r2 = r2.and(r1)
    lddw r1, 0x101010101010101                      r1 load str located at 72340172838076673
    mul64 r2, r1                                    r2 *= r1   ///  r2 = r2.wrapping_mul(r1)
    rsh64 r2, 56                                    r2 >>= 56   ///  r2 = r2.wrapping_shr(56)
    mov64 r8, 64                                    r8 = 64 as i32 as i64 as u64
    sub64 r8, r2                                    r8 -= r2   ///  r8 = r8.wrapping_sub(r2)
    mov64 r6, r10                                   r6 = r10
    add64 r6, -16                                   r6 += -16   ///  r6 = r6.wrapping_add(-16 as i32 as i64 as u64)
    lsh64 r8, 32                                    r8 <<= 32   ///  r8 = r8.wrapping_shl(32)
    rsh64 r8, 32                                    r8 >>= 32   ///  r8 = r8.wrapping_shr(32)
    ja lbb_38316                                    if true { pc += 102 }
lbb_38214:
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    stxdw [r6+0xc], r1                      
    ja lbb_38232                                    if true { pc += 15 }
lbb_38217:
    ldxdw r1, [r8+0x8]                      
    stxdw [r6+0xc], r1                      
    ldxdw r1, [r8+0x0]                      
    ja lbb_38232                                    if true { pc += 11 }
lbb_38221:
    mov64 r1, r10                                   r1 = r10
    add64 r1, -20                                   r1 += -20   ///  r1 = r1.wrapping_add(-20 as i32 as i64 as u64)
    mov64 r2, r8                                    r2 = r8
    mov64 r3, r8                                    r3 = r8
    call function_37362                     
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    ldxw r2, [r10-0x14]                     
    jne r2, 0, lbb_38234                            if r2 != (0 as i32 as i64 as u64) { pc += 5 }
    ldxdw r1, [r10-0x8]                     
    stxdw [r6+0xc], r1                      
    ldxdw r1, [r10-0x10]                    
lbb_38232:
    stxdw [r6+0x4], r1                      
lbb_38233:
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
lbb_38234:
    stxw [r6+0x0], r1                       
lbb_38235:
    exit                                    
lbb_38236:
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    stxdw [r10-0x1c], r1                    
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    stxdw [r10-0x24], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -20                                   r1 += -20   ///  r1 = r1.wrapping_add(-20 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -36                                   r2 += -36   ///  r2 = r2.wrapping_add(-36 as i32 as i64 as u64)
    mov64 r3, r8                                    r3 = r8
    call function_37362                     
    ldxw r1, [r10-0x14]                     
    jne r1, 0, lbb_38280                            if r1 != (0 as i32 as i64 as u64) { pc += 32 }
    ldxw r1, [r10-0x4]                      
    stxdw [r10-0x50], r1                    
    ldxw r1, [r10-0x8]                      
    stxdw [r10-0x40], r1                    
    ldxw r1, [r10-0xc]                      
    stxdw [r10-0x48], r1                    
    ldxw r2, [r10-0x10]                     
    ja lbb_38163                                    if true { pc += -93 }
lbb_38256:
    ldxdw r1, [r6+0x8]                      
    stxdw [r10-0x30], r1                    
    ldxdw r1, [r6+0x0]                      
    stxdw [r10-0x38], r1                    
    mov64 r1, r7                                    r1 = r7
    and64 r1, 2                                     r1 &= 2   ///  r1 = r1.and(2)
    jeq r1, 0, lbb_38292                            if r1 == (0 as i32 as i64 as u64) { pc += 29 }
    ldxdw r1, [r10-0x50]                    
    stxw [r10-0x18], r1                     
    ldxdw r1, [r10-0x40]                    
    stxw [r10-0x1c], r1                     
    ldxdw r1, [r10-0x48]                    
    stxw [r10-0x20], r1                     
    ldxdw r1, [r10-0x58]                    
    stxw [r10-0x24], r1                     
    mov64 r1, r10                                   r1 = r10
    add64 r1, -20                                   r1 += -20   ///  r1 = r1.wrapping_add(-20 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -36                                   r2 += -36   ///  r2 = r2.wrapping_add(-36 as i32 as i64 as u64)
    mov64 r3, r10                                   r3 = r10
    add64 r3, -56                                   r3 += -56   ///  r3 = r3.wrapping_add(-56 as i32 as i64 as u64)
    call function_37362                     
    ldxw r1, [r10-0x14]                     
    jeq r1, 0, lbb_38284                            if r1 == (0 as i32 as i64 as u64) { pc += 4 }
lbb_38280:
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    ldxdw r2, [r10-0x60]                    
    stxw [r2+0x0], r1                       
    ja lbb_38235                                    if true { pc += -49 }
lbb_38284:
    ldxw r1, [r10-0x4]                      
    stxdw [r10-0x50], r1                    
    ldxw r1, [r10-0x8]                      
    stxdw [r10-0x40], r1                    
    ldxw r1, [r10-0xc]                      
    stxdw [r10-0x48], r1                    
    ldxw r1, [r10-0x10]                     
    stxdw [r10-0x58], r1                    
lbb_38292:
    add64 r9, 1                                     r9 += 1   ///  r9 = r9.wrapping_add(1 as i32 as i64 as u64)
    rsh64 r7, 1                                     r7 >>= 1   ///  r7 = r7.wrapping_shr(1)
    mov64 r1, r9                                    r1 = r9
    lsh64 r1, 32                                    r1 <<= 32   ///  r1 = r1.wrapping_shl(32)
    rsh64 r1, 32                                    r1 >>= 32   ///  r1 = r1.wrapping_shr(32)
    jgt r8, r1, lbb_38316                           if r8 > r1 { pc += 18 }
    ldxdw r7, [r10-0x40]                    
    mov64 r1, r7                                    r1 = r7
    ldxdw r9, [r10-0x50]                    
    or64 r1, r9                                     r1 |= r9   ///  r1 = r1.or(r9)
    ldxdw r8, [r10-0x48]                    
    or64 r1, r8                                     r1 |= r8   ///  r1 = r1.or(r8)
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
    lsh64 r1, 32                                    r1 <<= 32   ///  r1 = r1.wrapping_shl(32)
    rsh64 r1, 32                                    r1 >>= 32   ///  r1 = r1.wrapping_shr(32)
    ldxdw r6, [r10-0x60]                    
    jeq r1, 0, lbb_38367                            if r1 == (0 as i32 as i64 as u64) { pc += 58 }
    ldxdw r3, [r10-0x58]                    
    mov64 r1, r3                                    r1 = r3
    rsh64 r1, 16                                    r1 >>= 16   ///  r1 = r1.wrapping_shr(16)
    and64 r1, 255                                   r1 &= 255   ///  r1 = r1.and(255)
    jeq r1, 0, lbb_38367                            if r1 == (0 as i32 as i64 as u64) { pc += 53 }
    mov64 r2, r8                                    r2 = r8
    ja lbb_38334                                    if true { pc += 18 }
lbb_38316:
    mov64 r1, r10                                   r1 = r10
    add64 r1, -20                                   r1 += -20   ///  r1 = r1.wrapping_add(-20 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -56                                   r2 += -56   ///  r2 = r2.wrapping_add(-56 as i32 as i64 as u64)
    mov64 r3, r2                                    r3 = r2
    call function_37362                     
    ldxw r1, [r10-0x14]                     
    jne r1, 0, lbb_38280                            if r1 != (0 as i32 as i64 as u64) { pc += -44 }
    ja lbb_38256                                    if true { pc += -69 }
lbb_38325:
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
    add64 r1, -1                                    r1 += -1   ///  r1 = r1.wrapping_add(-1 as i32 as i64 as u64)
    mov64 r5, r1                                    r5 = r1
    lsh64 r5, 32                                    r5 <<= 32   ///  r5 = r5.wrapping_shl(32)
    rsh64 r5, 32                                    r5 >>= 32   ///  r5 = r5.wrapping_shr(32)
    mov64 r7, r0                                    r7 = r0
    mov64 r9, r4                                    r9 = r4
    mov64 r8, r2                                    r8 = r2
    jeq r5, 0, lbb_38363                            if r5 == (0 as i32 as i64 as u64) { pc += 29 }
lbb_38334:
    lsh64 r2, 32                                    r2 <<= 32   ///  r2 = r2.wrapping_shl(32)
    rsh64 r2, 32                                    r2 >>= 32   ///  r2 = r2.wrapping_shr(32)
    div64 r2, 10                                    r2 /= 10   ///  r2 = r2 / (10 as u64)
    mov64 r3, r2                                    r3 = r2
    mul64 r3, 10                                    r3 *= 10   ///  r3 = r3.wrapping_mul(10 as u64)
    mov64 r5, r8                                    r5 = r8
    sub64 r5, r3                                    r5 -= r3   ///  r5 = r5.wrapping_sub(r3)
    lsh64 r5, 32                                    r5 <<= 32   ///  r5 = r5.wrapping_shl(32)
    mov64 r3, r9                                    r3 = r9
    lsh64 r3, 32                                    r3 <<= 32   ///  r3 = r3.wrapping_shl(32)
    rsh64 r3, 32                                    r3 >>= 32   ///  r3 = r3.wrapping_shr(32)
    or64 r5, r3                                     r5 |= r3   ///  r5 = r5.or(r3)
    mov64 r4, r5                                    r4 = r5
    div64 r4, 10                                    r4 /= 10   ///  r4 = r4 / (10 as u64)
    mov64 r3, r4                                    r3 = r4
    mul64 r3, 10                                    r3 *= 10   ///  r3 = r3.wrapping_mul(10 as u64)
    sub64 r5, r3                                    r5 -= r3   ///  r5 = r5.wrapping_sub(r3)
    mov64 r3, r7                                    r3 = r7
    lsh64 r3, 32                                    r3 <<= 32   ///  r3 = r3.wrapping_shl(32)
    rsh64 r3, 32                                    r3 >>= 32   ///  r3 = r3.wrapping_shr(32)
    lsh64 r5, 32                                    r5 <<= 32   ///  r5 = r5.wrapping_shl(32)
    or64 r5, r3                                     r5 |= r3   ///  r5 = r5.or(r3)
    mov64 r0, r5                                    r0 = r5
    div64 r0, 10                                    r0 /= 10   ///  r0 = r0 / (10 as u64)
    mov64 r3, r0                                    r3 = r0
    mul64 r3, 10                                    r3 *= 10   ///  r3 = r3.wrapping_mul(10 as u64)
    sub64 r5, r3                                    r5 -= r3   ///  r5 = r5.wrapping_sub(r3)
    mov64 r3, r1                                    r3 = r1
    jeq r5, 0, lbb_38325                            if r5 == (0 as i32 as i64 as u64) { pc += -38 }
lbb_38363:
    ldxdw r1, [r10-0x58]                    
    and64 r1, -2147483648                           r1 &= -2147483648   ///  r1 = r1.and(-2147483648)
    lsh64 r3, 16                                    r3 <<= 16   ///  r3 = r3.wrapping_shl(16)
    or64 r3, r1                                     r3 |= r1   ///  r3 = r3.or(r1)
lbb_38367:
    stxw [r6+0x10], r9                      
    stxw [r6+0xc], r7                       
    stxw [r6+0x8], r8                       
    stxw [r6+0x4], r3                       
    ja lbb_38233                                    if true { pc += -139 }

function_38372:
    lddw r2, 0x1000428d8 --> b"\xbf$\x00\x00\x00\x00\x00\x00a\x12\x00\x00\x00\x00\x00\x00e\x02\x07\x00\x…        r2 load str located at 4295239896
    stxdw [r10-0x8], r2                     
    stxdw [r10-0x10], r1                    
    mov64 r6, r10                                   r6 = r10
    add64 r6, -64                                   r6 += -64   ///  r6 = r6.wrapping_add(-64 as i32 as i64 as u64)
    mov64 r4, r10                                   r4 = r10
    add64 r4, -16                                   r4 += -16   ///  r4 = r4.wrapping_add(-16 as i32 as i64 as u64)
    mov64 r1, r6                                    r1 = r6
    lddw r2, 0x100066c80 --> b"\x00"                r2 load str located at 4295388288
    mov64 r3, 1                                     r3 = 1 as i32 as i64 as u64
    mov64 r5, 1                                     r5 = 1 as i32 as i64 as u64
    call function_33049                     
    mov64 r1, r6                                    r1 = r6
    lddw r2, 0x100066920 --> b"\x00\x00\x00\x00\x81-\x06\x00\x0e\x00\x00\x00\x00\x00\x00\x00\x99\x01\x00…        r2 load str located at 4295387424
    call function_44240                     
    syscall [invalid]                       

function_38391:
    lddw r2, 0x1000428d8 --> b"\xbf$\x00\x00\x00\x00\x00\x00a\x12\x00\x00\x00\x00\x00\x00e\x02\x07\x00\x…        r2 load str located at 4295239896
    stxdw [r10-0x8], r2                     
    stxdw [r10-0x10], r1                    
    mov64 r6, r10                                   r6 = r10
    add64 r6, -64                                   r6 += -64   ///  r6 = r6.wrapping_add(-64 as i32 as i64 as u64)
    mov64 r4, r10                                   r4 = r10
    add64 r4, -16                                   r4 += -16   ///  r4 = r4.wrapping_add(-16 as i32 as i64 as u64)
    mov64 r1, r6                                    r1 = r6
    lddw r2, 0x100066c80 --> b"\x00"                r2 load str located at 4295388288
    mov64 r3, 1                                     r3 = 1 as i32 as i64 as u64
    mov64 r5, 1                                     r5 = 1 as i32 as i64 as u64
    call function_33049                     
    mov64 r1, r6                                    r1 = r6
    lddw r2, 0x100066938 --> b"\x00\x00\x00\x00\x81-\x06\x00\x0e\x00\x00\x00\x00\x00\x00\x00\xd6\x01\x00…        r2 load str located at 4295387448
    call function_44240                     
    syscall [invalid]                       
    mov64 r3, r2                                    r3 = r2
    ldxdw r1, [r1+0x0]                      
    ldxdw r2, [r1+0x10]                     
    ldxdw r1, [r1+0x0]                      
    call function_46189                     
    exit                                    

function_38416:
    ldxdw r1, [r1+0x0]                      
    mov64 r3, r1                                    r3 = r1
    add64 r3, 8                                     r3 += 8   ///  r3 = r3.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x8], r3                     
    mov64 r3, r10                                   r3 = r10
    add64 r3, -8                                    r3 += -8   ///  r3 = r3.wrapping_add(-8 as i32 as i64 as u64)
    stxdw [r10-0xfd8], r3                   
    lddw r3, 0x100066e00 --> b"\x00\x00\x00\x00\xa0\xbb\x04\x00\x08\x00\x00\x00\x00\x00\x00\x00\x08\x00\…        r3 load str located at 4295388672
    stxdw [r10-0xfd0], r3                   
    lddw r3, 0x10006314a --> b"error_lenFromUtf8Errorbyteserrorsrc/account_info.r"        r3 load str located at 4295373130
    stxdw [r10-0xfe8], r3                   
    lddw r3, 0x100066de0 --> b"\x00\x00\x00\x00\xa0\xbb\x04\x00\x08\x00\x00\x00\x00\x00\x00\x00\x08\x00\…        r3 load str located at 4295388640
    stxdw [r10-0xff0], r3                   
    stxdw [r10-0xff8], r1                   
    mov64 r1, 11                                    r1 = 11 as i32 as i64 as u64
    stxdw [r10-0x1000], r1                  
    mov64 r1, 9                                     r1 = 9 as i32 as i64 as u64
    stxdw [r10-0xfe0], r1                   
    mov64 r5, r10                                   r5 = r10
    mov64 r1, r2                                    r1 = r2
    lddw r2, 0x100063136 --> b"Utf8Error"           r2 load str located at 4295373110
    mov64 r3, 9                                     r3 = 9 as i32 as i64 as u64
    lddw r4, 0x10006313f --> b"valid_up_toerror_lenFromUtf8Errorbyteserrorsrc/acc"        r4 load str located at 4295373119
    call function_45972                     
    exit                                    

function_38446:
    ldxdw r1, [r1+0x0]                      
    ldxw r3, [r2+0x34]                      
    mov64 r4, r3                                    r4 = r3
    and64 r4, 16                                    r4 &= 16   ///  r4 = r4.and(16)
    jne r4, 0, lbb_38456                            if r4 != (0 as i32 as i64 as u64) { pc += 5 }
    and64 r3, 32                                    r3 &= 32   ///  r3 = r3.and(32)
    jeq r3, 0, lbb_38454                            if r3 == (0 as i32 as i64 as u64) { pc += 1 }
    ja lbb_38458                                    if true { pc += 4 }
lbb_38454:
    call function_48047                     
    ja lbb_38459                                    if true { pc += 3 }
lbb_38456:
    call function_47475                     
    ja lbb_38459                                    if true { pc += 1 }
lbb_38458:
    call function_47521                     
lbb_38459:
    exit                                    

function_38460:
    ldxdw r1, [r1+0x0]                      
    ldxb r3, [r1+0x0]                       
    jne r3, 0, lbb_38469                            if r3 != (0 as i32 as i64 as u64) { pc += 6 }
    mov64 r1, r2                                    r1 = r2
    lddw r2, 0x10005fbe0 --> b"None"                r2 load str located at 4295359456
    mov64 r3, 4                                     r3 = 4 as i32 as i64 as u64
    call function_45901                     
    ja lbb_38480                                    if true { pc += 11 }
lbb_38469:
    add64 r1, 1                                     r1 += 1   ///  r1 = r1.wrapping_add(1 as i32 as i64 as u64)
    stxdw [r10-0x8], r1                     
    mov64 r4, r10                                   r4 = r10
    add64 r4, -8                                    r4 += -8   ///  r4 = r4.wrapping_add(-8 as i32 as i64 as u64)
    mov64 r1, r2                                    r1 = r2
    lddw r2, 0x10005fbcc --> b"Some"                r2 load str located at 4295359436
    mov64 r3, 4                                     r3 = 4 as i32 as i64 as u64
    lddw r5, 0x100066d60 --> b"\x00\x00\x00\x00\xa0\xbb\x04\x00\x08\x00\x00\x00\x00\x00\x00\x00\x08\x00\…        r5 load str located at 4295388512
    call function_46104                     
lbb_38480:
    exit                                    

function_38481:
    ldxdw r1, [r1+0x0]                      
    call function_42517                     
    exit                                    

function_38484:
    ldxdw r1, [r1+0x0]                      
    ldxw r3, [r2+0x34]                      
    mov64 r4, r3                                    r4 = r3
    and64 r4, 16                                    r4 &= 16   ///  r4 = r4.and(16)
    jne r4, 0, lbb_38494                            if r4 != (0 as i32 as i64 as u64) { pc += 5 }
    and64 r3, 32                                    r3 &= 32   ///  r3 = r3.and(32)
    jeq r3, 0, lbb_38492                            if r3 == (0 as i32 as i64 as u64) { pc += 1 }
    ja lbb_38496                                    if true { pc += 4 }
lbb_38492:
    call function_48071                     
    ja lbb_38497                                    if true { pc += 3 }
lbb_38494:
    call function_47661                     
    ja lbb_38497                                    if true { pc += 1 }
lbb_38496:
    call function_47706                     
lbb_38497:
    exit                                    

function_38498:
    mov64 r3, r2                                    r3 = r2
    ldxdw r1, [r1+0x0]                      
    ldxdw r2, [r1+0x10]                     
    ldxdw r1, [r1+0x0]                      
    call function_46428                     
    exit                                    

function_38504:
    ldxdw r1, [r1+0x0]                      
    call function_47567                     
    exit                                    

function_38507:
    mov64 r6, r2                                    r6 = r2
    stxdw [r10-0x70], r1                    
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    stxdw [r10-0x50], r1                    
    mov64 r8, 0                                     r8 = 0 as i32 as i64 as u64
    stxdw [r10-0x48], r8                    
    stxdw [r10-0x40], r8                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -80                                   r1 += -80   ///  r1 = r1.wrapping_add(-80 as i32 as i64 as u64)
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
    mov64 r3, 56                                    r3 = 56 as i32 as i64 as u64
    call function_38943                     
    ldxdw r7, [r10-0x50]                    
    ldxdw r9, [r10-0x40]                    
    stxdw [r10-0x58], r7                    
    add64 r7, r9                                    r7 += r9   ///  r7 = r7.wrapping_add(r9)
    mov64 r1, r7                                    r1 = r7
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
    mov64 r3, 55                                    r3 = 55 as i32 as i64 as u64
    call function_48291                     
    stxb [r7+0x37], r8                      
    stxdw [r10-0x60], r9                    
    mov64 r2, r9                                    r2 = r9
    add64 r2, 56                                    r2 += 56   ///  r2 = r2.wrapping_add(56 as i32 as i64 as u64)
    ldxdw r1, [r6+0x0]                      
    stxdw [r10-0x68], r1                    
    add64 r6, 8                                     r6 += 8   ///  r6 = r6.wrapping_add(8 as i32 as i64 as u64)
    mov64 r3, r6                                    r3 = r6
    mov64 r1, 58                                    r1 = 58 as i32 as i64 as u64
    mov64 r4, 0                                     r4 = 0 as i32 as i64 as u64
    ja lbb_38549                                    if true { pc += 11 }
lbb_38538:
    add64 r4, 1                                     r4 += 1   ///  r4 = r4.wrapping_add(1 as i32 as i64 as u64)
    jne r4, 32, lbb_38549                           if r4 != (32 as i32 as i64 as u64) { pc += 9 }
    ldxdw r1, [r10-0x58]                    
    add64 r1, r8                                    r1 += r8   ///  r1 = r1.wrapping_add(r8)
    mov64 r4, r8                                    r4 = r8
    ldxdw r5, [r10-0x60]                    
    sub64 r4, r5                                    r4 -= r5   ///  r4 = r4.wrapping_sub(r5)
    mov64 r0, 0                                     r0 = 0 as i32 as i64 as u64
    add64 r4, -56                                   r4 += -56   ///  r4 = r4.wrapping_add(-56 as i32 as i64 as u64)
    mov64 r5, 0                                     r5 = 0 as i32 as i64 as u64
    ja lbb_38592                                    if true { pc += 43 }
lbb_38549:
    jge r2, r8, lbb_38551                           if r2 >= r8 { pc += 1 }
    ja lbb_38718                                    if true { pc += 167 }
lbb_38551:
    mov64 r5, r3                                    r5 = r3
    add64 r5, r4                                    r5 += r4   ///  r5 = r5.wrapping_add(r4)
    ldxb r0, [r5+0x0]                       
    jeq r8, 0, lbb_38570                            if r8 == (0 as i32 as i64 as u64) { pc += 15 }
    mov64 r6, r8                                    r6 = r8
    ldxdw r7, [r10-0x58]                    
lbb_38557:
    ldxb r9, [r7+0x0]                       
    lsh64 r9, 8                                     r9 <<= 8   ///  r9 = r9.wrapping_shl(8)
    add64 r9, r0                                    r9 += r0   ///  r9 = r9.wrapping_add(r0)
    mov64 r0, r9                                    r0 = r9
    div64 r0, 58                                    r0 /= 58   ///  r0 = r0 / (58 as u64)
    mov64 r5, r0                                    r5 = r0
    mul64 r5, 58                                    r5 *= 58   ///  r5 = r5.wrapping_mul(58 as u64)
    sub64 r9, r5                                    r9 -= r5   ///  r9 = r9.wrapping_sub(r5)
    stxb [r7+0x0], r9                       
    add64 r7, 1                                     r7 += 1   ///  r7 = r7.wrapping_add(1 as i32 as i64 as u64)
    add64 r6, -1                                    r6 += -1   ///  r6 = r6.wrapping_add(-1 as i32 as i64 as u64)
    jeq r6, 0, lbb_38570                            if r6 == (0 as i32 as i64 as u64) { pc += 1 }
    ja lbb_38557                                    if true { pc += -13 }
lbb_38570:
    jeq r0, 0, lbb_38538                            if r0 == (0 as i32 as i64 as u64) { pc += -33 }
lbb_38571:
    mov64 r5, r0                                    r5 = r0
    jeq r2, r8, lbb_38603                           if r2 == r8 { pc += 30 }
    jge r8, r2, lbb_38702                           if r8 >= r2 { pc += 128 }
    mov64 r0, r5                                    r0 = r5
    div64 r0, 58                                    r0 /= 58   ///  r0 = r0 / (58 as u64)
    mov64 r6, r0                                    r6 = r0
    mul64 r6, 58                                    r6 *= 58   ///  r6 = r6.wrapping_mul(58 as u64)
    mov64 r7, r5                                    r7 = r5
    sub64 r7, r6                                    r7 -= r6   ///  r7 = r7.wrapping_sub(r6)
    ldxdw r6, [r10-0x58]                    
    add64 r6, r8                                    r6 += r8   ///  r6 = r6.wrapping_add(r8)
    stxb [r6+0x0], r7                       
    add64 r8, 1                                     r8 += 1   ///  r8 = r8.wrapping_add(1 as i32 as i64 as u64)
    jgt r1, r5, lbb_38538                           if r1 > r5 { pc += -47 }
    ja lbb_38571                                    if true { pc += -15 }
lbb_38586:
    jge r7, r2, lbb_38712                           if r7 >= r2 { pc += 125 }
    mov64 r7, r1                                    r7 = r1
    add64 r7, r5                                    r7 += r5   ///  r7 = r7.wrapping_add(r5)
    add64 r5, 1                                     r5 += 1   ///  r5 = r5.wrapping_add(1 as i32 as i64 as u64)
    stxb [r7+0x0], r0                       
    jeq r5, 32, lbb_38619                           if r5 == (32 as i32 as i64 as u64) { pc += 27 }
lbb_38592:
    mov64 r7, r8                                    r7 = r8
    add64 r7, r5                                    r7 += r5   ///  r7 = r7.wrapping_add(r5)
    mov64 r9, r3                                    r9 = r3
    add64 r9, r5                                    r9 += r5   ///  r9 = r9.wrapping_add(r5)
    ldxb r9, [r9+0x0]                       
    jeq r9, 0, lbb_38599                            if r9 == (0 as i32 as i64 as u64) { pc += 1 }
    ja lbb_38695                                    if true { pc += 96 }
lbb_38599:
    mov64 r9, r4                                    r9 = r4
    add64 r9, r5                                    r9 += r5   ///  r9 = r9.wrapping_add(r5)
    jeq r9, 0, lbb_38603                            if r9 == (0 as i32 as i64 as u64) { pc += 1 }
    ja lbb_38586                                    if true { pc += -17 }
lbb_38603:
    ldxdw r2, [r10-0x48]                    
    jeq r2, 0, lbb_38608                            if r2 == (0 as i32 as i64 as u64) { pc += 3 }
    ldxdw r1, [r10-0x58]                    
    mov64 r3, 1                                     r3 = 1 as i32 as i64 as u64
    call function_21385                     
lbb_38608:
    mov64 r3, r10                                   r3 = r10
    add64 r3, -1                                    r3 += -1   ///  r3 = r3.wrapping_add(-1 as i32 as i64 as u64)
    lddw r1, 0x100063071 --> b"called `Result::unwrap()` on an `Err` value"        r1 load str located at 4295372913
    mov64 r2, 43                                    r2 = 43 as i32 as i64 as u64
    lddw r4, 0x100066d08 --> b"\x00\x00\x00\x00\xa8\xbb\x04\x00\x00\x00\x00\x00\x00\x00\x00\x00\x01\x00\…        r4 load str located at 4295388424
    lddw r5, 0x100066d28 --> b"\x00\x00\x00\x00d0\x06\x00\x0d\x00\x00\x00\x00\x00\x00\x00\xe6\x00\x00\x0…        r5 load str located at 4295388456
    call function_44299                     
    syscall [invalid]                       
lbb_38619:
    add64 r8, r5                                    r8 += r5   ///  r8 = r8.wrapping_add(r5)
    jge r2, r8, lbb_38622                           if r2 >= r8 { pc += 1 }
    ja lbb_38697                                    if true { pc += 75 }
lbb_38622:
    ldxdw r3, [r10-0x68]                    
    jeq r8, 0, lbb_38653                            if r8 == (0 as i32 as i64 as u64) { pc += 29 }
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
lbb_38625:
    ldxdw r4, [r10-0x58]                    
    add64 r4, r2                                    r4 += r2   ///  r4 = r4.wrapping_add(r2)
    ldxb r1, [r4+0x0]                       
    jgt r1, 57, lbb_38707                           if r1 > (57 as i32 as i64 as u64) { pc += 78 }
    mov64 r5, r3                                    r5 = r3
    add64 r5, r1                                    r5 += r1   ///  r5 = r5.wrapping_add(r1)
    ldxb r1, [r5+0x80]                      
    stxb [r4+0x0], r1                       
    add64 r2, 1                                     r2 += 1   ///  r2 = r2.wrapping_add(1 as i32 as i64 as u64)
    jeq r8, r2, lbb_38636                           if r8 == r2 { pc += 1 }
    ja lbb_38625                                    if true { pc += -11 }
lbb_38636:
    mov64 r1, 2                                     r1 = 2 as i32 as i64 as u64
    jgt r1, r8, lbb_38653                           if r1 > r8 { pc += 15 }
    mov64 r1, r8                                    r1 = r8
    rsh64 r1, 1                                     r1 >>= 1   ///  r1 = r1.wrapping_shr(1)
    mov64 r2, r8                                    r2 = r8
    ldxdw r3, [r10-0x58]                    
    add64 r2, r3                                    r2 += r3   ///  r2 = r2.wrapping_add(r3)
    add64 r2, -1                                    r2 += -1   ///  r2 = r2.wrapping_add(-1 as i32 as i64 as u64)
lbb_38644:
    ldxb r4, [r3+0x0]                       
    ldxb r5, [r2+0x0]                       
    stxb [r3+0x0], r5                       
    stxb [r2+0x0], r4                       
    add64 r2, -1                                    r2 += -1   ///  r2 = r2.wrapping_add(-1 as i32 as i64 as u64)
    add64 r3, 1                                     r3 += 1   ///  r3 = r3.wrapping_add(1 as i32 as i64 as u64)
    add64 r1, -1                                    r1 += -1   ///  r1 = r1.wrapping_add(-1 as i32 as i64 as u64)
    jeq r1, 0, lbb_38653                            if r1 == (0 as i32 as i64 as u64) { pc += 1 }
    ja lbb_38644                                    if true { pc += -9 }
lbb_38653:
    ldxdw r7, [r10-0x48]                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -48                                   r1 += -48   ///  r1 = r1.wrapping_add(-48 as i32 as i64 as u64)
    ldxdw r2, [r10-0x58]                    
    mov64 r3, r8                                    r3 = r8
    call function_46589                     
    ldxdw r1, [r10-0x30]                    
    jne r1, 0, lbb_38667                            if r1 != (0 as i32 as i64 as u64) { pc += 6 }
lbb_38661:
    ldxdw r1, [r10-0x70]                    
    stxdw [r1+0x10], r8                     
    stxdw [r1+0x8], r7                      
    ldxdw r2, [r10-0x58]                    
    stxdw [r1+0x0], r2                      
    exit                                    
lbb_38667:
    ldxw r1, [r10-0x1f]                     
    stxw [r10-0x38], r1                     
    ldxw r1, [r10-0x1c]                     
    stxw [r10-0x35], r1                     
    ldxb r1, [r10-0x20]                     
    jeq r1, 2, lbb_38661                            if r1 == (2 as i32 as i64 as u64) { pc += -12 }
    ldxdw r2, [r10-0x28]                    
    stxb [r10-0x10], r1                     
    stxdw [r10-0x18], r2                    
    stxdw [r10-0x20], r8                    
    stxdw [r10-0x28], r7                    
    ldxdw r1, [r10-0x58]                    
    stxdw [r10-0x30], r1                    
    ldxw r1, [r10-0x38]                     
    stxw [r10-0xf], r1                      
    ldxw r1, [r10-0x35]                     
    stxw [r10-0xc], r1                      
    mov64 r3, r10                                   r3 = r10
    add64 r3, -48                                   r3 += -48   ///  r3 = r3.wrapping_add(-48 as i32 as i64 as u64)
    lddw r1, 0x100063071 --> b"called `Result::unwrap()` on an `Err` value"        r1 load str located at 4295372913
    mov64 r2, 43                                    r2 = 43 as i32 as i64 as u64
    lddw r4, 0x100066e40 --> b"\x00\x00\x00\x00\xf8\xbc\x04\x00(\x00\x00\x00\x00\x00\x00\x00\x08\x00\x00…        r4 load str located at 4295388736
    lddw r5, 0x100066e60 --> b"\x00\x00\x00\x00d0\x06\x00\x0d\x00\x00\x00\x00\x00\x00\x00Q\x00\x00\x00+\…        r5 load str located at 4295388768
    call function_44299                     
    syscall [invalid]                       
lbb_38695:
    mov64 r8, r7                                    r8 = r7
    jge r2, r7, lbb_38622                           if r2 >= r7 { pc += -75 }
lbb_38697:
    mov64 r1, r8                                    r1 = r8
    lddw r3, 0x100066c90 --> b"\x00\x00\x00\x00d0\x06\x00\x0d\x00\x00\x00\x00\x00\x00\x00l\x01\x00\x00\x…        r3 load str located at 4295388304
    call function_46535                     
    syscall [invalid]                       
lbb_38702:
    mov64 r1, r8                                    r1 = r8
    lddw r3, 0x100066cf0 --> b"\x00\x00\x00\x00d0\x06\x00\x0d\x00\x00\x00\x00\x00\x00\x00^\x01\x00\x00\x…        r3 load str located at 4295388400
    call function_44272                     
    syscall [invalid]                       
lbb_38707:
    mov64 r2, 58                                    r2 = 58 as i32 as i64 as u64
    lddw r3, 0x100066ca8 --> b"\x00\x00\x00\x00d0\x06\x00\x0d\x00\x00\x00\x00\x00\x00\x00m\x01\x00\x00\x…        r3 load str located at 4295388328
    call function_44272                     
    syscall [invalid]                       
lbb_38712:
    add64 r8, r5                                    r8 += r5   ///  r8 = r8.wrapping_add(r5)
    mov64 r1, r8                                    r1 = r8
    lddw r3, 0x100066cc0 --> b"\x00\x00\x00\x00d0\x06\x00\x0d\x00\x00\x00\x00\x00\x00\x00h\x01\x00\x00\x…        r3 load str located at 4295388352
    call function_44272                     
    syscall [invalid]                       
lbb_38718:
    mov64 r1, r8                                    r1 = r8
    lddw r3, 0x100066cd8 --> b"\x00\x00\x00\x00d0\x06\x00\x0d\x00\x00\x00\x00\x00\x00\x00U\x01\x00\x00 \…        r3 load str located at 4295388376
    call function_46535                     
    syscall [invalid]                       
    ldxw r3, [r2+0x34]                      
    mov64 r4, r3                                    r4 = r3
    and64 r4, 16                                    r4 &= 16   ///  r4 = r4.and(16)
    jne r4, 0, lbb_38732                            if r4 != (0 as i32 as i64 as u64) { pc += 5 }
    and64 r3, 32                                    r3 &= 32   ///  r3 = r3.and(32)
    jeq r3, 0, lbb_38730                            if r3 == (0 as i32 as i64 as u64) { pc += 1 }
    ja lbb_38734                                    if true { pc += 4 }
lbb_38730:
    call function_48071                     
    ja lbb_38735                                    if true { pc += 3 }
lbb_38732:
    call function_47661                     
    ja lbb_38735                                    if true { pc += 1 }
lbb_38734:
    call function_47706                     
lbb_38735:
    exit                                    

function_38736:
    exit                                    

function_38737:
    exit                                    

function_38738:
    ldxdw r2, [r1+0x8]                      
    jeq r2, 0, lbb_38743                            if r2 == (0 as i32 as i64 as u64) { pc += 3 }
    ldxdw r1, [r1+0x0]                      
    mov64 r3, 1                                     r3 = 1 as i32 as i64 as u64
    call function_21385                     
lbb_38743:
    exit                                    

function_38744:
    ldxb r2, [r1+0x0]                       
    mov64 r3, r2                                    r3 = r2
    add64 r3, -1                                    r3 += -1   ///  r3 = r3.wrapping_add(-1 as i32 as i64 as u64)
    mov64 r4, 7                                     r4 = 7 as i32 as i64 as u64
    jgt r4, r3, lbb_38778                           if r4 > r3 { pc += 29 }
    jeq r2, 0, lbb_38755                            if r2 == (0 as i32 as i64 as u64) { pc += 5 }
    ldxdw r2, [r1+0x10]                     
    jeq r2, 0, lbb_38778                            if r2 == (0 as i32 as i64 as u64) { pc += 26 }
    ldxdw r1, [r1+0x8]                      
    mov64 r3, 1                                     r3 = 1 as i32 as i64 as u64
    ja lbb_38777                                    if true { pc += 22 }
lbb_38755:
    ldxdw r6, [r1+0x8]                      
    mov64 r1, r6                                    r1 = r6
    and64 r1, 3                                     r1 &= 3   ///  r1 = r1.and(3)
    mov64 r2, r1                                    r2 = r1
    add64 r2, -2                                    r2 += -2   ///  r2 = r2.wrapping_add(-2 as i32 as i64 as u64)
    mov64 r3, 2                                     r3 = 2 as i32 as i64 as u64
    jgt r3, r2, lbb_38778                           if r3 > r2 { pc += 16 }
    jeq r1, 0, lbb_38778                            if r1 == (0 as i32 as i64 as u64) { pc += 15 }
    ldxdw r7, [r6-0x1]                      
    ldxdw r8, [r6+0x7]                      
    ldxdw r2, [r8+0x0]                      
    mov64 r1, r7                                    r1 = r7
    callx r2                                
    add64 r6, -1                                    r6 += -1   ///  r6 = r6.wrapping_add(-1 as i32 as i64 as u64)
    ldxdw r2, [r8+0x8]                      
    jeq r2, 0, lbb_38774                            if r2 == (0 as i32 as i64 as u64) { pc += 3 }
    ldxdw r3, [r8+0x10]                     
    mov64 r1, r7                                    r1 = r7
    call function_21385                     
lbb_38774:
    mov64 r1, r6                                    r1 = r6
    mov64 r2, 24                                    r2 = 24 as i32 as i64 as u64
    mov64 r3, 8                                     r3 = 8 as i32 as i64 as u64
lbb_38777:
    call function_21385                     
lbb_38778:
    exit                                    

function_38779:
    ldxdw r2, [r1+0x8]                      
    jeq r2, 0, lbb_38784                            if r2 == (0 as i32 as i64 as u64) { pc += 3 }
    ldxdw r1, [r1+0x0]                      
    mov64 r3, 1                                     r3 = 1 as i32 as i64 as u64
    call function_21385                     
lbb_38784:
    exit                                    

function_38785:
    ldxdw r6, [r1+0x0]                      
    mov64 r1, r6                                    r1 = r6
    call function_38744                     
    mov64 r1, r6                                    r1 = r6
    mov64 r2, 32                                    r2 = 32 as i32 as i64 as u64
    mov64 r3, 8                                     r3 = 8 as i32 as i64 as u64
    call function_21385                     
    exit                                    

function_38793:
    mov64 r1, r2                                    r1 = r2
    lddw r2, 0x10006309c --> b"BufferTooSmall"        r2 load str located at 4295372956
    mov64 r3, 14                                    r3 = 14 as i32 as i64 as u64
    call function_45901                     
    exit                                    

function_38799:
    mov64 r7, r3                                    r7 = r3
    mov64 r8, r2                                    r8 = r2
    mov64 r6, r1                                    r6 = r1
    jeq r8, 0, lbb_38813                            if r8 == (0 as i32 as i64 as u64) { pc += 10 }
    ldxdw r1, [r4+0x8]                      
    jeq r1, 0, lbb_38823                            if r1 == (0 as i32 as i64 as u64) { pc += 18 }
    ldxdw r2, [r4+0x10]                     
    jne r2, 0, lbb_38817                            if r2 != (0 as i32 as i64 as u64) { pc += 10 }
    jeq r7, 0, lbb_38833                            if r7 == (0 as i32 as i64 as u64) { pc += 25 }
    mov64 r1, r7                                    r1 = r7
    mov64 r2, r8                                    r2 = r8
    call function_21359                     
    jeq r0, 0, lbb_38829                            if r0 == (0 as i32 as i64 as u64) { pc += 17 }
    ja lbb_38835                                    if true { pc += 22 }
lbb_38813:
    stxdw [r6+0x10], r7                     
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    stxdw [r6+0x8], r1                      
    ja lbb_38831                                    if true { pc += 14 }
lbb_38817:
    ldxdw r1, [r4+0x0]                      
    mov64 r3, r8                                    r3 = r8
    mov64 r4, r7                                    r4 = r7
    call function_21386                     
    jeq r0, 0, lbb_38829                            if r0 == (0 as i32 as i64 as u64) { pc += 7 }
    ja lbb_38835                                    if true { pc += 12 }
lbb_38823:
    jeq r7, 0, lbb_38833                            if r7 == (0 as i32 as i64 as u64) { pc += 9 }
    mov64 r1, r7                                    r1 = r7
    mov64 r2, r8                                    r2 = r8
    call function_21359                     
    jeq r0, 0, lbb_38829                            if r0 == (0 as i32 as i64 as u64) { pc += 1 }
    ja lbb_38835                                    if true { pc += 6 }
lbb_38829:
    stxdw [r6+0x10], r7                     
    stxdw [r6+0x8], r8                      
lbb_38831:
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    ja lbb_38838                                    if true { pc += 5 }
lbb_38833:
    mov64 r7, 0                                     r7 = 0 as i32 as i64 as u64
    mov64 r0, r8                                    r0 = r8
lbb_38835:
    stxdw [r6+0x10], r7                     
    stxdw [r6+0x8], r0                      
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
lbb_38838:
    stxdw [r6+0x0], r1                      
    exit                                    

function_38840:
    mov64 r6, r1                                    r6 = r1
    add64 r2, 1                                     r2 += 1   ///  r2 = r2.wrapping_add(1 as i32 as i64 as u64)
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    jeq r2, 0, lbb_38845                            if r2 == (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
lbb_38845:
    and64 r1, 1                                     r1 &= 1   ///  r1 = r1.and(1)
    jne r1, 0, lbb_38886                            if r1 != (0 as i32 as i64 as u64) { pc += 39 }
    ldxdw r1, [r6+0x8]                      
    mov64 r7, r1                                    r7 = r1
    lsh64 r7, 1                                     r7 <<= 1   ///  r7 = r7.wrapping_shl(1)
    jgt r7, r2, lbb_38852                           if r7 > r2 { pc += 1 }
    mov64 r7, r2                                    r7 = r2
lbb_38852:
    jgt r7, 4, lbb_38854                            if r7 > (4 as i32 as i64 as u64) { pc += 1 }
    mov64 r7, 4                                     r7 = 4 as i32 as i64 as u64
lbb_38854:
    mov64 r2, 1                                     r2 = 1 as i32 as i64 as u64
    lddw r3, 0x3c3c3c3c3c3c3c4                      r3 load str located at 271275648142787524
    jgt r3, r7, lbb_38859                           if r3 > r7 { pc += 1 }
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
lbb_38859:
    mov64 r3, r7                                    r3 = r7
    mul64 r3, 34                                    r3 *= 34   ///  r3 = r3.wrapping_mul(34 as u64)
    jne r1, 0, lbb_38865                            if r1 != (0 as i32 as i64 as u64) { pc += 3 }
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    stxdw [r10-0x10], r1                    
    ja lbb_38871                                    if true { pc += 6 }
lbb_38865:
    ldxdw r4, [r6+0x0]                      
    mul64 r1, 34                                    r1 *= 34   ///  r1 = r1.wrapping_mul(34 as u64)
    stxdw [r10-0x8], r1                     
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    stxdw [r10-0x10], r1                    
    stxdw [r10-0x18], r4                    
lbb_38871:
    mov64 r1, r10                                   r1 = r10
    add64 r1, -48                                   r1 += -48   ///  r1 = r1.wrapping_add(-48 as i32 as i64 as u64)
    mov64 r4, r10                                   r4 = r10
    add64 r4, -24                                   r4 += -24   ///  r4 = r4.wrapping_add(-24 as i32 as i64 as u64)
    call function_38799                     
    ldxdw r1, [r10-0x28]                    
    ldxdw r2, [r10-0x30]                    
    jne r2, 0, lbb_38882                            if r2 != (0 as i32 as i64 as u64) { pc += 3 }
    stxdw [r6+0x8], r7                      
    stxdw [r6+0x0], r1                      
lbb_38881:
    exit                                    
lbb_38882:
    lddw r2, 0x8000000000000001                     r2 load str located at -9223372036854775807
    jeq r1, r2, lbb_38881                           if r1 == r2 { pc += -4 }
    jne r1, 0, lbb_38888                            if r1 != (0 as i32 as i64 as u64) { pc += 2 }
lbb_38886:
    call function_43383                     
    syscall [invalid]                       
lbb_38888:
    ldxdw r2, [r10-0x20]                    
    call function_43400                     
    syscall [invalid]                       

function_38891:
    mov64 r6, r1                                    r6 = r1
    add64 r2, 1                                     r2 += 1   ///  r2 = r2.wrapping_add(1 as i32 as i64 as u64)
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    jeq r2, 0, lbb_38896                            if r2 == (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
lbb_38896:
    and64 r1, 1                                     r1 &= 1   ///  r1 = r1.and(1)
    jne r1, 0, lbb_38938                            if r1 != (0 as i32 as i64 as u64) { pc += 40 }
    ldxdw r1, [r6+0x8]                      
    mov64 r7, r1                                    r7 = r1
    lsh64 r7, 1                                     r7 <<= 1   ///  r7 = r7.wrapping_shl(1)
    jgt r7, r2, lbb_38903                           if r7 > r2 { pc += 1 }
    mov64 r7, r2                                    r7 = r2
lbb_38903:
    jgt r7, 4, lbb_38905                            if r7 > (4 as i32 as i64 as u64) { pc += 1 }
    mov64 r7, 4                                     r7 = 4 as i32 as i64 as u64
lbb_38905:
    mov64 r2, 1                                     r2 = 1 as i32 as i64 as u64
    lddw r3, 0x2aaaaaaaaaaaaab                      r3 load str located at 192153584101141163
    jgt r3, r7, lbb_38910                           if r3 > r7 { pc += 1 }
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
lbb_38910:
    mov64 r3, r7                                    r3 = r7
    mul64 r3, 48                                    r3 *= 48   ///  r3 = r3.wrapping_mul(48 as u64)
    lsh64 r2, 3                                     r2 <<= 3   ///  r2 = r2.wrapping_shl(3)
    jne r1, 0, lbb_38917                            if r1 != (0 as i32 as i64 as u64) { pc += 3 }
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    stxdw [r10-0x10], r1                    
    ja lbb_38923                                    if true { pc += 6 }
lbb_38917:
    ldxdw r4, [r6+0x0]                      
    mul64 r1, 48                                    r1 *= 48   ///  r1 = r1.wrapping_mul(48 as u64)
    stxdw [r10-0x8], r1                     
    mov64 r1, 8                                     r1 = 8 as i32 as i64 as u64
    stxdw [r10-0x10], r1                    
    stxdw [r10-0x18], r4                    
lbb_38923:
    mov64 r1, r10                                   r1 = r10
    add64 r1, -48                                   r1 += -48   ///  r1 = r1.wrapping_add(-48 as i32 as i64 as u64)
    mov64 r4, r10                                   r4 = r10
    add64 r4, -24                                   r4 += -24   ///  r4 = r4.wrapping_add(-24 as i32 as i64 as u64)
    call function_38799                     
    ldxdw r1, [r10-0x28]                    
    ldxdw r2, [r10-0x30]                    
    jne r2, 0, lbb_38934                            if r2 != (0 as i32 as i64 as u64) { pc += 3 }
    stxdw [r6+0x8], r7                      
    stxdw [r6+0x0], r1                      
lbb_38933:
    exit                                    
lbb_38934:
    lddw r2, 0x8000000000000001                     r2 load str located at -9223372036854775807
    jeq r1, r2, lbb_38933                           if r1 == r2 { pc += -4 }
    jne r1, 0, lbb_38940                            if r1 != (0 as i32 as i64 as u64) { pc += 2 }
lbb_38938:
    call function_43383                     
    syscall [invalid]                       
lbb_38940:
    ldxdw r2, [r10-0x20]                    
    call function_43400                     
    syscall [invalid]                       

function_38943:
    mov64 r6, r1                                    r6 = r1
    mov64 r4, r2                                    r4 = r2
    add64 r4, r3                                    r4 += r3   ///  r4 = r4.wrapping_add(r3)
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    jgt r2, r4, lbb_38949                           if r2 > r4 { pc += 1 }
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
lbb_38949:
    and64 r1, 1                                     r1 &= 1   ///  r1 = r1.and(1)
    jne r1, 0, lbb_38986                            if r1 != (0 as i32 as i64 as u64) { pc += 35 }
    ldxdw r1, [r6+0x8]                      
    mov64 r7, r1                                    r7 = r1
    lsh64 r7, 1                                     r7 <<= 1   ///  r7 = r7.wrapping_shl(1)
    jgt r7, r4, lbb_38956                           if r7 > r4 { pc += 1 }
    mov64 r7, r4                                    r7 = r4
lbb_38956:
    jgt r7, 8, lbb_38958                            if r7 > (8 as i32 as i64 as u64) { pc += 1 }
    mov64 r7, 8                                     r7 = 8 as i32 as i64 as u64
lbb_38958:
    mov64 r2, r7                                    r2 = r7
    xor64 r2, -1                                    r2 ^= -1   ///  r2 = r2.xor(-1)
    rsh64 r2, 63                                    r2 >>= 63   ///  r2 = r2.wrapping_shr(63)
    jne r1, 0, lbb_38965                            if r1 != (0 as i32 as i64 as u64) { pc += 3 }
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    stxdw [r10-0x10], r1                    
    ja lbb_38970                                    if true { pc += 5 }
lbb_38965:
    ldxdw r3, [r6+0x0]                      
    stxdw [r10-0x8], r1                     
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    stxdw [r10-0x10], r1                    
    stxdw [r10-0x18], r3                    
lbb_38970:
    mov64 r1, r10                                   r1 = r10
    add64 r1, -48                                   r1 += -48   ///  r1 = r1.wrapping_add(-48 as i32 as i64 as u64)
    mov64 r4, r10                                   r4 = r10
    add64 r4, -24                                   r4 += -24   ///  r4 = r4.wrapping_add(-24 as i32 as i64 as u64)
    mov64 r3, r7                                    r3 = r7
    call function_38799                     
    ldxdw r1, [r10-0x28]                    
    ldxdw r2, [r10-0x30]                    
    jne r2, 0, lbb_38982                            if r2 != (0 as i32 as i64 as u64) { pc += 3 }
    stxdw [r6+0x8], r7                      
    stxdw [r6+0x0], r1                      
lbb_38981:
    exit                                    
lbb_38982:
    lddw r2, 0x8000000000000001                     r2 load str located at -9223372036854775807
    jeq r1, r2, lbb_38981                           if r1 == r2 { pc += -4 }
    jne r1, 0, lbb_38988                            if r1 != (0 as i32 as i64 as u64) { pc += 2 }
lbb_38986:
    call function_43383                     
    syscall [invalid]                       
lbb_38988:
    ldxdw r2, [r10-0x20]                    
    call function_43400                     
    syscall [invalid]                       
    mov64 r3, r2                                    r3 = r2
    ldxdw r2, [r1+0x10]                     
    ldxdw r1, [r1+0x0]                      
    call function_46428                     
    exit                                    

function_38996:
    mov64 r3, r1                                    r3 = r1
    add64 r3, 24                                    r3 += 24   ///  r3 = r3.wrapping_add(24 as i32 as i64 as u64)
    stxdw [r10-0x8], r3                     
    mov64 r3, r10                                   r3 = r10
    add64 r3, -8                                    r3 += -8   ///  r3 = r3.wrapping_add(-8 as i32 as i64 as u64)
    stxdw [r10-0xfd8], r3                   
    lddw r3, 0x100066dc0 --> b"\x00\x00\x00\x00\xa0\xbb\x04\x00\x08\x00\x00\x00\x00\x00\x00\x00\x08\x00\…        r3 load str located at 4295388608
    stxdw [r10-0xfd0], r3                   
    lddw r3, 0x100063165 --> b"errorsrc/account_info.rs\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\…        r3 load str located at 4295373157
    stxdw [r10-0xfe8], r3                   
    lddw r3, 0x100066e20 --> b"\x00\x00\x00\x00\xb0\xbb\x04\x00\x18\x00\x00\x00\x00\x00\x00\x00\x08\x00\…        r3 load str located at 4295388704
    stxdw [r10-0xff0], r3                   
    stxdw [r10-0xff8], r1                   
    mov64 r1, 5                                     r1 = 5 as i32 as i64 as u64
    stxdw [r10-0xfe0], r1                   
    stxdw [r10-0x1000], r1                  
    mov64 r5, r10                                   r5 = r10
    mov64 r1, r2                                    r1 = r2
    lddw r2, 0x100063153 --> b"FromUtf8Error"        r2 load str located at 4295373139
    mov64 r3, 13                                    r3 = 13 as i32 as i64 as u64
    lddw r4, 0x100063160 --> b"byteserrorsrc/account_info.rs\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff…        r4 load str located at 4295373152
    call function_45972                     
    exit                                    

function_39024:
    ldxdw r6, [r1+0x10]                     
    ldxdw r7, [r1+0x0]                      
    mov64 r1, r10                                   r1 = r10
    add64 r1, -24                                   r1 += -24   ///  r1 = r1.wrapping_add(-24 as i32 as i64 as u64)
    call function_46162                     
    jeq r6, 0, lbb_39041                            if r6 == (0 as i32 as i64 as u64) { pc += 11 }
lbb_39030:
    stxdw [r10-0x8], r7                     
    mov64 r1, r10                                   r1 = r10
    add64 r1, -24                                   r1 += -24   ///  r1 = r1.wrapping_add(-24 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -8                                    r2 += -8   ///  r2 = r2.wrapping_add(-8 as i32 as i64 as u64)
    lddw r3, 0x100066d60 --> b"\x00\x00\x00\x00\xa0\xbb\x04\x00\x08\x00\x00\x00\x00\x00\x00\x00\x08\x00\…        r3 load str located at 4295388512
    call function_44802                     
    add64 r7, 1                                     r7 += 1   ///  r7 = r7.wrapping_add(1 as i32 as i64 as u64)
    add64 r6, -1                                    r6 += -1   ///  r6 = r6.wrapping_add(-1 as i32 as i64 as u64)
    jne r6, 0, lbb_39030                            if r6 != (0 as i32 as i64 as u64) { pc += -11 }
lbb_39041:
    mov64 r1, r10                                   r1 = r10
    add64 r1, -24                                   r1 += -24   ///  r1 = r1.wrapping_add(-24 as i32 as i64 as u64)
    call function_44895                     
    exit                                    

function_39045:
    ldxdw r1, [r1+0x0]                      
    ldxb r3, [r1+0x0]                       
    jsgt r3, 3, lbb_39061                           if (r3 as i64) > (3 as i32 as i64) { pc += 13 }
    jsgt r3, 1, lbb_39081                           if (r3 as i64) > (1 as i32 as i64) { pc += 32 }
    jeq r3, 0, lbb_39087                            if r3 == (0 as i32 as i64 as u64) { pc += 37 }
    add64 r1, 8                                     r1 += 8   ///  r1 = r1.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x8], r1                     
    mov64 r4, r10                                   r4 = r10
    add64 r4, -8                                    r4 += -8   ///  r4 = r4.wrapping_add(-8 as i32 as i64 as u64)
    mov64 r1, r2                                    r1 = r2
    lddw r2, 0x1000630ac --> b"InvalidUtf8Encoding"        r2 load str located at 4295372972
    mov64 r3, 19                                    r3 = 19 as i32 as i64 as u64
    lddw r5, 0x100066dc0 --> b"\x00\x00\x00\x00\xa0\xbb\x04\x00\x08\x00\x00\x00\x00\x00\x00\x00\x08\x00\…        r5 load str located at 4295388608
    ja lbb_39130                                    if true { pc += 69 }
lbb_39061:
    jsgt r3, 5, lbb_39068                           if (r3 as i64) > (5 as i32 as i64) { pc += 6 }
    jeq r3, 4, lbb_39120                            if r3 == (4 as i32 as i64 as u64) { pc += 57 }
    mov64 r1, r2                                    r1 = r2
    lddw r2, 0x1000630f7 --> b"DeserializeAnyNotSupported"        r2 load str located at 4295373047
    mov64 r3, 26                                    r3 = 26 as i32 as i64 as u64
    ja lbb_39107                                    if true { pc += 39 }
lbb_39068:
    jeq r3, 6, lbb_39098                            if r3 == (6 as i32 as i64 as u64) { pc += 29 }
    jeq r3, 7, lbb_39103                            if r3 == (7 as i32 as i64 as u64) { pc += 33 }
    add64 r1, 8                                     r1 += 8   ///  r1 = r1.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x8], r1                     
    mov64 r4, r10                                   r4 = r10
    add64 r4, -8                                    r4 += -8   ///  r4 = r4.wrapping_add(-8 as i32 as i64 as u64)
    mov64 r1, r2                                    r1 = r2
    lddw r2, 0x100063130 --> b"Custom"              r2 load str located at 4295373104
    mov64 r3, 6                                     r3 = 6 as i32 as i64 as u64
    lddw r5, 0x100066d40 --> b"\x00\x00\x00\x00\xa0\xbb\x04\x00\x08\x00\x00\x00\x00\x00\x00\x00\x08\x00\…        r5 load str located at 4295388480
    ja lbb_39130                                    if true { pc += 49 }
lbb_39081:
    jeq r3, 2, lbb_39109                            if r3 == (2 as i32 as i64 as u64) { pc += 27 }
    mov64 r1, r2                                    r1 = r2
    lddw r2, 0x1000630d2 --> b"InvalidCharEncoding"        r2 load str located at 4295373010
    mov64 r3, 19                                    r3 = 19 as i32 as i64 as u64
    ja lbb_39107                                    if true { pc += 20 }
lbb_39087:
    add64 r1, 8                                     r1 += 8   ///  r1 = r1.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x8], r1                     
    mov64 r4, r10                                   r4 = r10
    add64 r4, -8                                    r4 += -8   ///  r4 = r4.wrapping_add(-8 as i32 as i64 as u64)
    mov64 r1, r2                                    r1 = r2
    lddw r2, 0x1000630aa --> b"Io"                  r2 load str located at 4295372970
    mov64 r3, 2                                     r3 = 2 as i32 as i64 as u64
    lddw r5, 0x100066da0 --> b"\x00\x00\x00\x00\xa0\xbb\x04\x00\x08\x00\x00\x00\x00\x00\x00\x00\x08\x00\…        r5 load str located at 4295388576
    ja lbb_39130                                    if true { pc += 32 }
lbb_39098:
    mov64 r1, r2                                    r1 = r2
    lddw r2, 0x100063111 --> b"SizeLimit"           r2 load str located at 4295373073
    mov64 r3, 9                                     r3 = 9 as i32 as i64 as u64
    ja lbb_39107                                    if true { pc += 4 }
lbb_39103:
    mov64 r1, r2                                    r1 = r2
    lddw r2, 0x10006311a --> b"SequenceMustHaveLength"        r2 load str located at 4295373082
    mov64 r3, 22                                    r3 = 22 as i32 as i64 as u64
lbb_39107:
    call function_45901                     
    ja lbb_39131                                    if true { pc += 22 }
lbb_39109:
    add64 r1, 1                                     r1 += 1   ///  r1 = r1.wrapping_add(1 as i32 as i64 as u64)
    stxdw [r10-0x8], r1                     
    mov64 r4, r10                                   r4 = r10
    add64 r4, -8                                    r4 += -8   ///  r4 = r4.wrapping_add(-8 as i32 as i64 as u64)
    mov64 r1, r2                                    r1 = r2
    lddw r2, 0x1000630bf --> b"InvalidBoolEncoding"        r2 load str located at 4295372991
    mov64 r3, 19                                    r3 = 19 as i32 as i64 as u64
    lddw r5, 0x100066d60 --> b"\x00\x00\x00\x00\xa0\xbb\x04\x00\x08\x00\x00\x00\x00\x00\x00\x00\x08\x00\…        r5 load str located at 4295388512
    ja lbb_39130                                    if true { pc += 10 }
lbb_39120:
    add64 r1, 8                                     r1 += 8   ///  r1 = r1.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x8], r1                     
    mov64 r4, r10                                   r4 = r10
    add64 r4, -8                                    r4 += -8   ///  r4 = r4.wrapping_add(-8 as i32 as i64 as u64)
    mov64 r1, r2                                    r1 = r2
    lddw r2, 0x1000630e5 --> b"InvalidTagEncoding"        r2 load str located at 4295373029
    mov64 r3, 18                                    r3 = 18 as i32 as i64 as u64
    lddw r5, 0x100066d80 --> b"\x00\x00\x00\x00\xa0\xbb\x04\x00\x08\x00\x00\x00\x00\x00\x00\x00\x08\x00\…        r5 load str located at 4295388544
lbb_39130:
    call function_46104                     
lbb_39131:
    exit                                    

function_39132:
    ldxdw r1, [r1+0x8]                      
    ldxdw r2, [r1+0x10]                     
    lddw r3, 0x7ffffffffffffffe                     r3 load str located at 9223372036854775806
    jgt r2, r3, lbb_39144                           if r2 > r3 { pc += 7 }
    mov64 r3, r2                                    r3 = r2
    add64 r3, 1                                     r3 += 1   ///  r3 = r3.wrapping_add(1 as i32 as i64 as u64)
    stxdw [r1+0x10], r3                     
    ldxdw r3, [r1+0x18]                     
    ldxdw r0, [r3+0x0]                      
    stxdw [r1+0x10], r2                     
    exit                                    
lbb_39144:
    lddw r1, 0x100066e78 --> b"\x00\x00\x00\x00j1\x06\x00\x13\x00\x00\x00\x00\x00\x00\x00F\x00\x00\x00\x…        r1 load str located at 4295388792
    call function_43759                     
    syscall [invalid]                       

function_39148:
    ldxdw r1, [r1+0x10]                     
    ldxdw r2, [r1+0x10]                     
    lddw r3, 0x7ffffffffffffffe                     r3 load str located at 9223372036854775806
    jgt r2, r3, lbb_39158                           if r2 > r3 { pc += 5 }
    ldxdw r1, [r1+0x20]                     
    mov64 r0, 1                                     r0 = 1 as i32 as i64 as u64
    jeq r1, 0, lbb_39157                            if r1 == (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r0, 0                                     r0 = 0 as i32 as i64 as u64
lbb_39157:
    exit                                    
lbb_39158:
    lddw r1, 0x100066e90 --> b"\x00\x00\x00\x00j1\x06\x00\x13\x00\x00\x00\x00\x00\x00\x00c\x00\x00\x00\x…        r1 load str located at 4295388816
    call function_43759                     
    syscall [invalid]                       

function_39162:
    mov64 r3, 11                                    r3 = 11 as i32 as i64 as u64
    ldxdw r2, [r2+0x8]                      
    ldxdw r4, [r2+0x10]                     
    jne r4, 0, lbb_39174                            if r4 != (0 as i32 as i64 as u64) { pc += 8 }
    mov64 r3, r2                                    r3 = r2
    add64 r3, 16                                    r3 += 16   ///  r3 = r3.wrapping_add(16 as i32 as i64 as u64)
    mov64 r4, -1                                    r4 = -1 as i32 as i64 as u64
    stxdw [r2+0x10], r4                     
    stxdw [r1+0x10], r3                     
    add64 r2, 24                                    r2 += 24   ///  r2 = r2.wrapping_add(24 as i32 as i64 as u64)
    stxdw [r1+0x8], r2                      
    mov64 r3, 24                                    r3 = 24 as i32 as i64 as u64
lbb_39174:
    stxw [r1+0x0], r3                       
    exit                                    

function_39176:
    mov64 r3, 11                                    r3 = 11 as i32 as i64 as u64
    ldxdw r2, [r2+0x10]                     
    ldxdw r4, [r2+0x10]                     
    lddw r5, 0x7ffffffffffffffe                     r5 load str located at 9223372036854775806
    jgt r4, r5, lbb_39190                           if r4 > r5 { pc += 8 }
    mov64 r3, r2                                    r3 = r2
    add64 r3, 16                                    r3 += 16   ///  r3 = r3.wrapping_add(16 as i32 as i64 as u64)
    add64 r4, 1                                     r4 += 1   ///  r4 = r4.wrapping_add(1 as i32 as i64 as u64)
    stxdw [r2+0x10], r4                     
    stxdw [r1+0x10], r3                     
    add64 r2, 24                                    r2 += 24   ///  r2 = r2.wrapping_add(24 as i32 as i64 as u64)
    stxdw [r1+0x8], r2                      
    mov64 r3, 24                                    r3 = 24 as i32 as i64 as u64
lbb_39190:
    stxw [r1+0x0], r3                       
    exit                                    

function_39192:
    mov64 r3, 11                                    r3 = 11 as i32 as i64 as u64
    ldxdw r2, [r2+0x10]                     
    ldxdw r4, [r2+0x10]                     
    jne r4, 0, lbb_39204                            if r4 != (0 as i32 as i64 as u64) { pc += 8 }
    mov64 r3, r2                                    r3 = r2
    add64 r3, 16                                    r3 += 16   ///  r3 = r3.wrapping_add(16 as i32 as i64 as u64)
    mov64 r4, -1                                    r4 = -1 as i32 as i64 as u64
    stxdw [r2+0x10], r4                     
    stxdw [r1+0x10], r3                     
    add64 r2, 24                                    r2 += 24   ///  r2 = r2.wrapping_add(24 as i32 as i64 as u64)
    stxdw [r1+0x8], r2                      
    mov64 r3, 24                                    r3 = 24 as i32 as i64 as u64
lbb_39204:
    stxw [r1+0x0], r3                       
    exit                                    

function_39206:
    mov64 r4, r2                                    r4 = r2
    stxdw [r10-0x68], r1                    
    ldxdw r6, [r4+0x0]                      
    jne r6, 0, lbb_39234                            if r6 != (0 as i32 as i64 as u64) { pc += 24 }
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    stxdw [r10-0x10], r1                    
    stxdw [r10-0x18], r6                    
    mov64 r8, 8                                     r8 = 8 as i32 as i64 as u64
    stxdw [r10-0x20], r8                    
lbb_39215:
    mov64 r1, r4                                    r1 = r4
    add64 r1, r8                                    r1 += r8   ///  r1 = r1.wrapping_add(r8)
    ldxdw r1, [r1+0x0]                      
    ldxdw r2, [r10-0x10]                    
    ldxdw r3, [r10-0x68]                    
    stxdw [r3+0x18], r2                     
    ldxdw r2, [r10-0x18]                    
    stxdw [r3+0x10], r2                     
    ldxdw r2, [r10-0x20]                    
    stxdw [r3+0x8], r2                      
    add64 r8, 8                                     r8 += 8   ///  r8 = r8.wrapping_add(8 as i32 as i64 as u64)
    mov64 r2, r4                                    r2 = r4
    add64 r2, r8                                    r2 += r8   ///  r2 = r2.wrapping_add(r8)
    stxdw [r3+0x20], r2                     
    stxdw [r3+0x28], r1                     
    add64 r1, r8                                    r1 += r8   ///  r1 = r1.wrapping_add(r8)
    add64 r4, r1                                    r4 += r1   ///  r4 = r4.wrapping_add(r1)
    stxdw [r3+0x0], r4                      
    exit                                    
lbb_39234:
    lddw r1, 0x2aaaaaaaaaaaaab                      r1 load str located at 192153584101141163
    jgt r1, r6, lbb_39239                           if r1 > r6 { pc += 2 }
    call function_43383                     
    syscall [invalid]                       
lbb_39239:
    mov64 r7, r6                                    r7 = r6
    mul64 r7, 48                                    r7 *= 48   ///  r7 = r7.wrapping_mul(48 as u64)
    mov64 r8, 8                                     r8 = 8 as i32 as i64 as u64
    mov64 r0, 8                                     r0 = 8 as i32 as i64 as u64
    stxdw [r10-0x30], r4                    
    jeq r7, 0, lbb_39254                            if r7 == (0 as i32 as i64 as u64) { pc += 9 }
    mov64 r1, r7                                    r1 = r7
    mov64 r2, 8                                     r2 = 8 as i32 as i64 as u64
    call function_21359                     
    ldxdw r4, [r10-0x30]                    
    jne r0, 0, lbb_39254                            if r0 != (0 as i32 as i64 as u64) { pc += 4 }
    mov64 r1, 8                                     r1 = 8 as i32 as i64 as u64
    mov64 r2, r7                                    r2 = r7
    call function_43400                     
    syscall [invalid]                       
lbb_39254:
    stxdw [r10-0x18], r6                    
    stxdw [r10-0x20], r0                    
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    stxdw [r10-0x10], r1                    
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
    stxdw [r10-0x60], r6                    
    ja lbb_39291                                    if true { pc += 29 }
lbb_39262:
    mov64 r1, r2                                    r1 = r2
    mul64 r1, 48                                    r1 *= 48   ///  r1 = r1.wrapping_mul(48 as u64)
    mov64 r3, r0                                    r3 = r0
    add64 r3, r1                                    r3 += r1   ///  r3 = r3.wrapping_add(r1)
    ldxdw r1, [r10-0x58]                    
    stxb [r3+0x2a], r1                      
    ldxdw r1, [r10-0x50]                    
    stxb [r3+0x29], r1                      
    ldxdw r1, [r10-0x48]                    
    stxb [r3+0x28], r1                      
    ldxdw r1, [r10-0x40]                    
    stxdw [r3+0x20], r1                     
    ldxdw r1, [r10-0x38]                    
    stxdw [r3+0x18], r1                     
    stxdw [r3+0x10], r9                     
    stxdw [r3+0x8], r6                      
    stxdw [r3+0x0], r7                      
    ldxw r1, [r10-0x5]                      
    stxw [r3+0x2b], r1                      
    ldxb r1, [r10-0x1]                      
    stxb [r3+0x2f], r1                      
lbb_39283:
    add64 r2, 1                                     r2 += 1   ///  r2 = r2.wrapping_add(1 as i32 as i64 as u64)
    stxdw [r10-0x10], r2                    
    ldxdw r3, [r10-0x28]                    
    add64 r3, 1                                     r3 += 1   ///  r3 = r3.wrapping_add(1 as i32 as i64 as u64)
    add64 r8, 8                                     r8 += 8   ///  r8 = r8.wrapping_add(8 as i32 as i64 as u64)
    ldxdw r1, [r10-0x60]                    
    jgt r1, r3, lbb_39291                           if r1 > r3 { pc += 1 }
    ja lbb_39215                                    if true { pc += -76 }
lbb_39291:
    mov64 r1, r4                                    r1 = r4
    add64 r1, r8                                    r1 += r8   ///  r1 = r1.wrapping_add(r8)
    ldxb r1, [r1+0x0]                       
    stxdw [r10-0x28], r3                    
    jeq r1, 255, lbb_39347                          if r1 == (255 as i32 as i64 as u64) { pc += 51 }
    jgt r2, r1, lbb_39298                           if r2 > r1 { pc += 1 }
    ja lbb_39448                                    if true { pc += 150 }
lbb_39298:
    mov64 r5, r2                                    r5 = r2
    mul64 r1, 48                                    r1 *= 48   ///  r1 = r1.wrapping_mul(48 as u64)
    mov64 r2, r0                                    r2 = r0
    add64 r2, r1                                    r2 += r1   ///  r2 = r2.wrapping_add(r1)
    ldxdw r6, [r2+0x8]                      
    ldxdw r3, [r6+0x0]                      
    add64 r3, 1                                     r3 += 1   ///  r3 = r3.wrapping_add(1 as i32 as i64 as u64)
    mov64 r4, 1                                     r4 = 1 as i32 as i64 as u64
    jeq r3, 0, lbb_39308                            if r3 == (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r4, 0                                     r4 = 0 as i32 as i64 as u64
lbb_39308:
    ldxdw r7, [r2+0x0]                      
    stxdw [r6+0x0], r3                      
    jne r4, 1, lbb_39313                            if r4 != (1 as i32 as i64 as u64) { pc += 2 }
lbb_39311:
    syscall [invalid]                       
    syscall [invalid]                       
lbb_39313:
    mov64 r2, r0                                    r2 = r0
    add64 r2, r1                                    r2 += r1   ///  r2 = r2.wrapping_add(r1)
    ldxdw r9, [r2+0x10]                     
    ldxdw r2, [r9+0x0]                      
    add64 r2, 1                                     r2 += 1   ///  r2 = r2.wrapping_add(1 as i32 as i64 as u64)
    mov64 r3, 1                                     r3 = 1 as i32 as i64 as u64
    jeq r2, 0, lbb_39321                            if r2 == (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
lbb_39321:
    stxdw [r9+0x0], r2                      
    jne r3, 1, lbb_39324                            if r3 != (1 as i32 as i64 as u64) { pc += 1 }
    ja lbb_39311                                    if true { pc += -13 }
lbb_39324:
    mov64 r2, r0                                    r2 = r0
    add64 r2, r1                                    r2 += r1   ///  r2 = r2.wrapping_add(r1)
    ldxb r1, [r2+0x2a]                      
    stxdw [r10-0x58], r1                    
    ldxb r1, [r2+0x29]                      
    stxdw [r10-0x50], r1                    
    ldxb r1, [r2+0x28]                      
    stxdw [r10-0x48], r1                    
    ldxdw r1, [r2+0x20]                     
    stxdw [r10-0x40], r1                    
    ldxdw r1, [r2+0x18]                     
    stxdw [r10-0x38], r1                    
    ldxdw r1, [r10-0x18]                    
    mov64 r2, r5                                    r2 = r5
    ldxdw r4, [r10-0x30]                    
    jne r2, r1, lbb_39262                           if r2 != r1 { pc += -78 }
    mov64 r1, r10                                   r1 = r10
    add64 r1, -32                                   r1 += -32   ///  r1 = r1.wrapping_add(-32 as i32 as i64 as u64)
    call function_38891                     
    ldxdw r4, [r10-0x30]                    
    ldxdw r0, [r10-0x20]                    
    ldxdw r2, [r10-0x10]                    
    ja lbb_39262                                    if true { pc += -85 }
lbb_39347:
    stxdw [r10-0x38], r2                    
    mov64 r6, r8                                    r6 = r8
    add64 r6, r4                                    r6 += r4   ///  r6 = r6.wrapping_add(r4)
    ldxb r1, [r6+0x3]                       
    stxdw [r10-0x50], r1                    
    ldxb r1, [r6+0x2]                       
    stxdw [r10-0x48], r1                    
    ldxb r1, [r6+0x1]                       
    stxdw [r10-0x40], r1                    
    mov64 r1, 32                                    r1 = 32 as i32 as i64 as u64
    mov64 r2, 8                                     r2 = 8 as i32 as i64 as u64
    call function_21359                     
    jne r0, 0, lbb_39364                            if r0 != (0 as i32 as i64 as u64) { pc += 4 }
    mov64 r1, 8                                     r1 = 8 as i32 as i64 as u64
    mov64 r2, 32                                    r2 = 32 as i32 as i64 as u64
    call function_43400                     
    syscall [invalid]                       
lbb_39364:
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    stxdw [r0+0x10], r1                     
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    stxdw [r0+0x8], r1                      
    stxdw [r0+0x0], r1                      
    mov64 r1, r6                                    r1 = r6
    add64 r1, 72                                    r1 += 72   ///  r1 = r1.wrapping_add(72 as i32 as i64 as u64)
    stxdw [r10-0x58], r0                    
    stxdw [r0+0x18], r1                     
    ldxdw r9, [r6+0x50]                     
    stxw [r6+0x4], r9                       
    mov64 r1, 40                                    r1 = 40 as i32 as i64 as u64
    mov64 r2, 8                                     r2 = 8 as i32 as i64 as u64
    call function_21359                     
    mov64 r7, r0                                    r7 = r0
    jne r7, 0, lbb_39384                            if r7 != (0 as i32 as i64 as u64) { pc += 4 }
    mov64 r1, 8                                     r1 = 8 as i32 as i64 as u64
    mov64 r2, 40                                    r2 = 40 as i32 as i64 as u64
    call function_43400                     
    syscall [invalid]                       
lbb_39384:
    ldxdw r1, [r10-0x50]                    
    mov64 r3, r1                                    r3 = r1
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    mov64 r5, 1                                     r5 = 1 as i32 as i64 as u64
    ldxdw r4, [r10-0x30]                    
    jne r3, 0, lbb_39392                            if r3 != (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r5, 0                                     r5 = 0 as i32 as i64 as u64
lbb_39392:
    ldxdw r3, [r10-0x48]                    
    stxdw [r7+0x10], r2                     
    mov64 r2, 1                                     r2 = 1 as i32 as i64 as u64
    jne r3, 0, lbb_39397                            if r3 != (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
lbb_39397:
    stxdw [r10-0x48], r2                    
    ldxdw r2, [r10-0x40]                    
    mov64 r3, 1                                     r3 = 1 as i32 as i64 as u64
    jne r2, 0, lbb_39402                            if r2 != (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
lbb_39402:
    stxdw [r10-0x40], r3                    
    mov64 r2, r6                                    r2 = r6
    add64 r2, 40                                    r2 += 40   ///  r2 = r2.wrapping_add(40 as i32 as i64 as u64)
    stxdw [r10-0x50], r2                    
    add64 r6, 8                                     r6 += 8   ///  r6 = r6.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r7+0x8], r1                      
    stxdw [r7+0x0], r1                      
    mov64 r1, r8                                    r1 = r8
    add64 r1, r4                                    r1 += r4   ///  r1 = r1.wrapping_add(r4)
    add64 r1, 88                                    r1 += 88   ///  r1 = r1.wrapping_add(88 as i32 as i64 as u64)
    stxdw [r7+0x18], r1                     
    stxdw [r7+0x20], r9                     
    add64 r8, r9                                    r8 += r9   ///  r8 = r8.wrapping_add(r9)
    add64 r8, 10335                                 r8 += 10335   ///  r8 = r8.wrapping_add(10335 as i32 as i64 as u64)
    and64 r8, -8                                    r8 &= -8   ///  r8 = r8.and(-8)
    mov64 r1, r4                                    r1 = r4
    add64 r1, r8                                    r1 += r8   ///  r1 = r1.wrapping_add(r8)
    ldxdw r9, [r1+0x0]                      
    ldxdw r1, [r10-0x18]                    
    ldxdw r2, [r10-0x38]                    
    jne r2, r1, lbb_39430                           if r2 != r1 { pc += 7 }
    mov64 r1, r10                                   r1 = r10
    add64 r1, -32                                   r1 += -32   ///  r1 = r1.wrapping_add(-32 as i32 as i64 as u64)
    stxdw [r10-0x38], r5                    
    call function_38891                     
    ldxdw r5, [r10-0x38]                    
    ldxdw r4, [r10-0x30]                    
    ldxdw r2, [r10-0x10]                    
lbb_39430:
    mov64 r1, r2                                    r1 = r2
    mul64 r1, 48                                    r1 *= 48   ///  r1 = r1.wrapping_mul(48 as u64)
    ldxdw r0, [r10-0x20]                    
    mov64 r3, r0                                    r3 = r0
    add64 r3, r1                                    r3 += r1   ///  r3 = r3.wrapping_add(r1)
    stxb [r3+0x2a], r5                      
    ldxdw r1, [r10-0x48]                    
    stxb [r3+0x29], r1                      
    ldxdw r1, [r10-0x40]                    
    stxb [r3+0x28], r1                      
    stxdw [r3+0x20], r9                     
    ldxdw r1, [r10-0x50]                    
    stxdw [r3+0x18], r1                     
    stxdw [r3+0x10], r7                     
    ldxdw r1, [r10-0x58]                    
    stxdw [r3+0x8], r1                      
    stxdw [r3+0x0], r6                      
    ja lbb_39283                                    if true { pc += -165 }
lbb_39448:
    lddw r3, 0x100066eb8 --> b"\x00\x00\x00\x0072\x06\x00\x11\x00\x00\x00\x00\x00\x00\x00a\x01\x00\x00#\…        r3 load str located at 4295388856
    call function_44272                     
    syscall [invalid]                       

function_39452:
    mov64 r6, r2                                    r6 = r2
    ldxdw r2, [r1+0x0]                      
    ldxdw r3, [r1+0x8]                      
    ldxdw r4, [r1+0x10]                     
    ldxdw r1, [r1+0x18]                     
    stxdw [r10-0x38], r1                    
    stxdw [r10-0x40], r4                    
    stxdw [r10-0x48], r3                    
    stxdw [r10-0x50], r2                    
    lddw r1, 0x10006317d --> b"\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\…        r1 load str located at 4295373181
    stxdw [r10-0x58], r1                    
    mov64 r7, r10                                   r7 = r10
    add64 r7, -112                                  r7 += -112   ///  r7 = r7.wrapping_add(-112 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -88                                   r2 += -88   ///  r2 = r2.wrapping_add(-88 as i32 as i64 as u64)
    mov64 r1, r7                                    r1 = r7
    call function_38507                     
    lddw r1, 0x10004c398 --> b"\xbf#\x00\x00\x00\x00\x00\x00y\x12\x10\x00\x00\x00\x00\x00y\x11\x00\x00\x…        r1 load str located at 4295279512
    stxdw [r10-0x78], r1                    
    stxdw [r10-0x80], r7                    
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    stxdw [r10-0x90], r1                    
    lddw r1, 0x100066ea8 --> b"\x00\x00\x00\x00P4\x06\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x0…        r1 load str located at 4295388840
    stxdw [r10-0xb0], r1                    
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    stxdw [r10-0xa8], r1                    
    stxdw [r10-0x98], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -128                                  r1 += -128   ///  r1 = r1.wrapping_add(-128 as i32 as i64 as u64)
    stxdw [r10-0xa0], r1                    
    mov64 r2, r10                                   r2 = r10
    add64 r2, -176                                  r2 += -176   ///  r2 = r2.wrapping_add(-176 as i32 as i64 as u64)
    mov64 r1, r6                                    r1 = r6
    call function_45907                     
    mov64 r6, r0                                    r6 = r0
    ldxdw r2, [r10-0x68]                    
    jeq r2, 0, lbb_39495                            if r2 == (0 as i32 as i64 as u64) { pc += 3 }
    ldxdw r1, [r10-0x70]                    
    mov64 r3, 1                                     r3 = 1 as i32 as i64 as u64
    call function_21385                     
lbb_39495:
    mov64 r0, r6                                    r0 = r6
    exit                                    

function_39497:
    mov64 r6, r4                                    r6 = r4
    mov64 r9, r1                                    r9 = r1
    ldxb r7, [r3+0x0]                       
    stxdw [r10-0x20], r3                    
    stxdw [r10-0x28], r2                    
    jsgt r7, 5, lbb_39509                           if (r7 as i64) > (5 as i32 as i64) { pc += 6 }
    jsgt r7, 2, lbb_39519                           if (r7 as i64) > (2 as i32 as i64) { pc += 15 }
    mov64 r8, 52                                    r8 = 52 as i32 as i64 as u64
    jeq r7, 0, lbb_39546                            if r7 == (0 as i32 as i64 as u64) { pc += 40 }
    jeq r7, 1, lbb_39522                            if r7 == (1 as i32 as i64 as u64) { pc += 15 }
lbb_39507:
    mov64 r8, 12                                    r8 = 12 as i32 as i64 as u64
    ja lbb_39546                                    if true { pc += 37 }
lbb_39509:
    jsgt r7, 8, lbb_39513                           if (r7 as i64) > (8 as i32 as i64) { pc += 3 }
    jeq r7, 6, lbb_39522                            if r7 == (6 as i32 as i64 as u64) { pc += 11 }
    jeq r7, 7, lbb_39522                            if r7 == (7 as i32 as i64 as u64) { pc += 10 }
    ja lbb_39507                                    if true { pc += -6 }
lbb_39513:
    jsgt r7, 10, lbb_39524                          if (r7 as i64) > (10 as i32 as i64) { pc += 10 }
    jeq r7, 9, lbb_39527                            if r7 == (9 as i32 as i64 as u64) { pc += 12 }
    mov64 r1, 76                                    r1 = 76 as i32 as i64 as u64
    mov64 r2, r3                                    r2 = r3
    add64 r2, 88                                    r2 += 88   ///  r2 = r2.wrapping_add(88 as i32 as i64 as u64)
    ja lbb_39538                                    if true { pc += 19 }
lbb_39519:
    jeq r7, 3, lbb_39531                            if r7 == (3 as i32 as i64 as u64) { pc += 11 }
    jeq r7, 4, lbb_39525                            if r7 == (4 as i32 as i64 as u64) { pc += 4 }
    ja lbb_39507                                    if true { pc += -15 }
lbb_39522:
    mov64 r8, 36                                    r8 = 36 as i32 as i64 as u64
    ja lbb_39546                                    if true { pc += 22 }
lbb_39524:
    jeq r7, 11, lbb_39535                           if r7 == (11 as i32 as i64 as u64) { pc += 10 }
lbb_39525:
    mov64 r8, 4                                     r8 = 4 as i32 as i64 as u64
    ja lbb_39546                                    if true { pc += 19 }
lbb_39527:
    mov64 r1, 84                                    r1 = 84 as i32 as i64 as u64
    mov64 r2, r3                                    r2 = r3
    add64 r2, 96                                    r2 += 96   ///  r2 = r2.wrapping_add(96 as i32 as i64 as u64)
    ja lbb_39538                                    if true { pc += 7 }
lbb_39531:
    mov64 r1, 92                                    r1 = 92 as i32 as i64 as u64
    mov64 r2, r3                                    r2 = r3
    add64 r2, 104                                   r2 += 104   ///  r2 = r2.wrapping_add(104 as i32 as i64 as u64)
    ja lbb_39538                                    if true { pc += 3 }
lbb_39535:
    mov64 r1, 52                                    r1 = 52 as i32 as i64 as u64
    mov64 r2, r3                                    r2 = r3
    add64 r2, 64                                    r2 += 64   ///  r2 = r2.wrapping_add(64 as i32 as i64 as u64)
lbb_39538:
    ldxdw r2, [r2+0x0]                      
    add64 r2, r1                                    r2 += r1   ///  r2 = r2.wrapping_add(r1)
    mov64 r0, 1                                     r0 = 1 as i32 as i64 as u64
    mov64 r8, 0                                     r8 = 0 as i32 as i64 as u64
    jeq r2, 0, lbb_39551                            if r2 == (0 as i32 as i64 as u64) { pc += 8 }
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    mov64 r8, r2                                    r8 = r2
    jsgt r1, r2, lbb_40365                          if (r1 as i64) > (r2 as i64) { pc += 819 }
lbb_39546:
    mov64 r1, r8                                    r1 = r8
    mov64 r2, 1                                     r2 = 1 as i32 as i64 as u64
    call function_21359                     
    ldxdw r3, [r10-0x20]                    
    jeq r0, 0, lbb_40361                            if r0 == (0 as i32 as i64 as u64) { pc += 810 }
lbb_39551:
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    stxdw [r10-0x8], r1                     
    stxdw [r10-0x10], r8                    
    stxdw [r10-0x18], r0                    
    stxdw [r10-0x30], r6                    
    jsgt r7, 5, lbb_39574                           if (r7 as i64) > (5 as i32 as i64) { pc += 17 }
    jsgt r7, 2, lbb_39648                           if (r7 as i64) > (2 as i32 as i64) { pc += 90 }
    jeq r7, 0, lbb_39682                            if r7 == (0 as i32 as i64 as u64) { pc += 123 }
    jeq r7, 1, lbb_39747                            if r7 == (1 as i32 as i64 as u64) { pc += 187 }
    mov64 r7, 0                                     r7 = 0 as i32 as i64 as u64
    jgt r8, 3, lbb_39563                            if r8 > (3 as i32 as i64 as u64) { pc += 1 }
    ja lbb_40276                                    if true { pc += 713 }
lbb_39563:
    add64 r0, r7                                    r0 += r7   ///  r0 = r0.wrapping_add(r7)
    mov64 r1, 2                                     r1 = 2 as i32 as i64 as u64
    stxw [r0+0x0], r1                       
    add64 r7, 4                                     r7 += 4   ///  r7 = r7.wrapping_add(4 as i32 as i64 as u64)
    stxdw [r10-0x8], r7                     
    ldxdw r1, [r10-0x10]                    
    sub64 r1, r7                                    r1 -= r7   ///  r1 = r1.wrapping_sub(r7)
    ldxdw r6, [r3+0x8]                      
    mov64 r2, 8                                     r2 = 8 as i32 as i64 as u64
    jgt r2, r1, lbb_39668                           if r2 > r1 { pc += 95 }
    ja lbb_39596                                    if true { pc += 22 }
lbb_39574:
    jsgt r7, 8, lbb_39601                           if (r7 as i64) > (8 as i32 as i64) { pc += 26 }
    jeq r7, 6, lbb_39786                            if r7 == (6 as i32 as i64 as u64) { pc += 210 }
    jeq r7, 7, lbb_39825                            if r7 == (7 as i32 as i64 as u64) { pc += 248 }
    mov64 r7, 0                                     r7 = 0 as i32 as i64 as u64
    jgt r8, 3, lbb_39587                            if r8 > (3 as i32 as i64 as u64) { pc += 8 }
    mov64 r1, r10                                   r1 = r10
    add64 r1, -24                                   r1 += -24   ///  r1 = r1.wrapping_add(-24 as i32 as i64 as u64)
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
    mov64 r3, 4                                     r3 = 4 as i32 as i64 as u64
    call function_38943                     
    ldxdw r3, [r10-0x20]                    
    ldxdw r0, [r10-0x18]                    
    ldxdw r7, [r10-0x8]                     
lbb_39587:
    add64 r0, r7                                    r0 += r7   ///  r0 = r0.wrapping_add(r7)
    mov64 r1, 8                                     r1 = 8 as i32 as i64 as u64
    stxw [r0+0x0], r1                       
    add64 r7, 4                                     r7 += 4   ///  r7 = r7.wrapping_add(4 as i32 as i64 as u64)
    stxdw [r10-0x8], r7                     
    ldxdw r2, [r10-0x10]                    
    sub64 r2, r7                                    r2 -= r7   ///  r2 = r2.wrapping_sub(r7)
    ldxdw r6, [r3+0x8]                      
    jgt r1, r2, lbb_39668                           if r1 > r2 { pc += 72 }
lbb_39596:
    ldxdw r1, [r10-0x18]                    
    add64 r1, r7                                    r1 += r7   ///  r1 = r1.wrapping_add(r7)
    stxdw [r1+0x0], r6                      
    add64 r7, 8                                     r7 += 8   ///  r7 = r7.wrapping_add(8 as i32 as i64 as u64)
    ja lbb_40239                                    if true { pc += 638 }
lbb_39601:
    jsgt r7, 10, lbb_39675                          if (r7 as i64) > (10 as i32 as i64) { pc += 73 }
    stxdw [r10-0x38], r9                    
    jeq r7, 9, lbb_39864                            if r7 == (9 as i32 as i64 as u64) { pc += 260 }
    mov64 r6, 0                                     r6 = 0 as i32 as i64 as u64
    mov64 r7, 0                                     r7 = 0 as i32 as i64 as u64
    jgt r8, 3, lbb_39608                            if r8 > (3 as i32 as i64 as u64) { pc += 1 }
    ja lbb_40285                                    if true { pc += 677 }
lbb_39608:
    add64 r0, r7                                    r0 += r7   ///  r0 = r0.wrapping_add(r7)
    mov64 r1, 10                                    r1 = 10 as i32 as i64 as u64
    stxw [r0+0x0], r1                       
    mov64 r8, r3                                    r8 = r3
    add64 r8, 1                                     r8 += 1   ///  r8 = r8.wrapping_add(1 as i32 as i64 as u64)
    add64 r7, 4                                     r7 += 4   ///  r7 = r7.wrapping_add(4 as i32 as i64 as u64)
    stxdw [r10-0x8], r7                     
    ja lbb_39635                                    if true { pc += 19 }
lbb_39616:
    add64 r6, 1                                     r6 += 1   ///  r6 = r6.wrapping_add(1 as i32 as i64 as u64)
    ldxdw r1, [r10-0x18]                    
    add64 r1, r7                                    r1 += r7   ///  r1 = r1.wrapping_add(r7)
    stxb [r1+0x0], r9                       
    add64 r7, 1                                     r7 += 1   ///  r7 = r7.wrapping_add(1 as i32 as i64 as u64)
    stxdw [r10-0x8], r7                     
    jne r6, 32, lbb_39635                           if r6 != (32 as i32 as i64 as u64) { pc += 12 }
    ldxdw r1, [r10-0x10]                    
    sub64 r1, r7                                    r1 -= r7   ///  r1 = r1.wrapping_sub(r7)
    ldxdw r8, [r3+0x58]                     
    ldxdw r6, [r3+0x48]                     
    jgt r1, 7, lbb_39919                            if r1 > (7 as i32 as i64 as u64) { pc += 291 }
    mov64 r1, r10                                   r1 = r10
    add64 r1, -24                                   r1 += -24   ///  r1 = r1.wrapping_add(-24 as i32 as i64 as u64)
    mov64 r2, r7                                    r2 = r7
    mov64 r3, 8                                     r3 = 8 as i32 as i64 as u64
    call function_38943                     
    ldxdw r7, [r10-0x8]                     
    ja lbb_39919                                    if true { pc += 284 }
lbb_39635:
    mov64 r1, r8                                    r1 = r8
    add64 r1, r6                                    r1 += r6   ///  r1 = r1.wrapping_add(r6)
    ldxb r9, [r1+0x0]                       
    ldxdw r1, [r10-0x10]                    
    jne r1, r7, lbb_39616                           if r1 != r7 { pc += -24 }
    mov64 r1, r10                                   r1 = r10
    add64 r1, -24                                   r1 += -24   ///  r1 = r1.wrapping_add(-24 as i32 as i64 as u64)
    mov64 r2, r7                                    r2 = r7
    mov64 r3, 1                                     r3 = 1 as i32 as i64 as u64
    call function_38943                     
    ldxdw r3, [r10-0x20]                    
    ldxdw r7, [r10-0x8]                     
    ja lbb_39616                                    if true { pc += -32 }
lbb_39648:
    jeq r7, 3, lbb_39961                            if r7 == (3 as i32 as i64 as u64) { pc += 312 }
    jeq r7, 4, lbb_40017                            if r7 == (4 as i32 as i64 as u64) { pc += 367 }
    mov64 r7, 0                                     r7 = 0 as i32 as i64 as u64
    ldxdw r6, [r3+0x8]                      
    jgt r8, 3, lbb_39660                            if r8 > (3 as i32 as i64 as u64) { pc += 7 }
    mov64 r1, r10                                   r1 = r10
    add64 r1, -24                                   r1 += -24   ///  r1 = r1.wrapping_add(-24 as i32 as i64 as u64)
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
    mov64 r3, 4                                     r3 = 4 as i32 as i64 as u64
    call function_38943                     
    ldxdw r0, [r10-0x18]                    
    ldxdw r7, [r10-0x8]                     
lbb_39660:
    add64 r0, r7                                    r0 += r7   ///  r0 = r0.wrapping_add(r7)
    mov64 r1, 5                                     r1 = 5 as i32 as i64 as u64
    stxw [r0+0x0], r1                       
    add64 r7, 4                                     r7 += 4   ///  r7 = r7.wrapping_add(4 as i32 as i64 as u64)
    stxdw [r10-0x8], r7                     
    ldxdw r1, [r10-0x10]                    
    sub64 r1, r7                                    r1 -= r7   ///  r1 = r1.wrapping_sub(r7)
    jgt r1, 7, lbb_39596                            if r1 > (7 as i32 as i64 as u64) { pc += -72 }
lbb_39668:
    mov64 r1, r10                                   r1 = r10
    add64 r1, -24                                   r1 += -24   ///  r1 = r1.wrapping_add(-24 as i32 as i64 as u64)
    mov64 r2, r7                                    r2 = r7
    mov64 r3, 8                                     r3 = 8 as i32 as i64 as u64
    call function_38943                     
    ldxdw r7, [r10-0x8]                     
    ja lbb_39596                                    if true { pc += -79 }
lbb_39675:
    jeq r7, 11, lbb_40031                           if r7 == (11 as i32 as i64 as u64) { pc += 355 }
    mov64 r7, 0                                     r7 = 0 as i32 as i64 as u64
    jgt r8, 3, lbb_39679                            if r8 > (3 as i32 as i64 as u64) { pc += 1 }
    ja lbb_40294                                    if true { pc += 615 }
lbb_39679:
    add64 r0, r7                                    r0 += r7   ///  r0 = r0.wrapping_add(r7)
    mov64 r1, 12                                    r1 = 12 as i32 as i64 as u64
    ja lbb_40028                                    if true { pc += 346 }
lbb_39682:
    mov64 r6, 0                                     r6 = 0 as i32 as i64 as u64
    mov64 r7, 0                                     r7 = 0 as i32 as i64 as u64
    jgt r8, 3, lbb_39693                            if r8 > (3 as i32 as i64 as u64) { pc += 8 }
    mov64 r1, r10                                   r1 = r10
    add64 r1, -24                                   r1 += -24   ///  r1 = r1.wrapping_add(-24 as i32 as i64 as u64)
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
    mov64 r3, 4                                     r3 = 4 as i32 as i64 as u64
    call function_38943                     
    ldxdw r3, [r10-0x20]                    
    ldxdw r0, [r10-0x18]                    
    ldxdw r7, [r10-0x8]                     
lbb_39693:
    add64 r0, r7                                    r0 += r7   ///  r0 = r0.wrapping_add(r7)
    stxw [r0+0x0], r6                       
    add64 r7, 4                                     r7 += 4   ///  r7 = r7.wrapping_add(4 as i32 as i64 as u64)
    stxdw [r10-0x8], r7                     
    ldxdw r1, [r10-0x10]                    
    sub64 r1, r7                                    r1 -= r7   ///  r1 = r1.wrapping_sub(r7)
    ldxdw r6, [r3+0x8]                      
    mov64 r2, 8                                     r2 = 8 as i32 as i64 as u64
    jgt r2, r1, lbb_40302                           if r2 > r1 { pc += 600 }
lbb_39702:
    ldxdw r1, [r10-0x18]                    
    add64 r1, r7                                    r1 += r7   ///  r1 = r1.wrapping_add(r7)
    stxdw [r1+0x0], r6                      
    add64 r7, 8                                     r7 += 8   ///  r7 = r7.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x8], r7                     
    ldxdw r1, [r10-0x10]                    
    sub64 r1, r7                                    r1 -= r7   ///  r1 = r1.wrapping_sub(r7)
    ldxdw r6, [r3+0x10]                     
    jgt r1, 7, lbb_39718                            if r1 > (7 as i32 as i64 as u64) { pc += 7 }
    mov64 r1, r10                                   r1 = r10
    add64 r1, -24                                   r1 += -24   ///  r1 = r1.wrapping_add(-24 as i32 as i64 as u64)
    mov64 r2, r7                                    r2 = r7
    mov64 r3, 8                                     r3 = 8 as i32 as i64 as u64
    call function_38943                     
    ldxdw r3, [r10-0x20]                    
    ldxdw r7, [r10-0x8]                     
lbb_39718:
    ldxdw r1, [r10-0x18]                    
    add64 r1, r7                                    r1 += r7   ///  r1 = r1.wrapping_add(r7)
    stxdw [r1+0x0], r6                      
    mov64 r6, 0                                     r6 = 0 as i32 as i64 as u64
    add64 r3, 24                                    r3 += 24   ///  r3 = r3.wrapping_add(24 as i32 as i64 as u64)
    add64 r7, 8                                     r7 += 8   ///  r7 = r7.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x8], r7                     
    ja lbb_39733                                    if true { pc += 7 }
lbb_39726:
    add64 r6, 1                                     r6 += 1   ///  r6 = r6.wrapping_add(1 as i32 as i64 as u64)
    ldxdw r1, [r10-0x18]                    
    add64 r1, r7                                    r1 += r7   ///  r1 = r1.wrapping_add(r7)
    stxb [r1+0x0], r8                       
    add64 r7, 1                                     r7 += 1   ///  r7 = r7.wrapping_add(1 as i32 as i64 as u64)
    stxdw [r10-0x8], r7                     
    jeq r6, 32, lbb_40239                           if r6 == (32 as i32 as i64 as u64) { pc += 506 }
lbb_39733:
    mov64 r1, r3                                    r1 = r3
    add64 r1, r6                                    r1 += r6   ///  r1 = r1.wrapping_add(r6)
    ldxb r8, [r1+0x0]                       
    ldxdw r1, [r10-0x10]                    
    jne r1, r7, lbb_39726                           if r1 != r7 { pc += -12 }
    mov64 r1, r10                                   r1 = r10
    add64 r1, -24                                   r1 += -24   ///  r1 = r1.wrapping_add(-24 as i32 as i64 as u64)
    mov64 r2, r7                                    r2 = r7
    mov64 r7, r3                                    r7 = r3
    mov64 r3, 1                                     r3 = 1 as i32 as i64 as u64
    call function_38943                     
    mov64 r3, r7                                    r3 = r7
    ldxdw r7, [r10-0x8]                     
    ja lbb_39726                                    if true { pc += -21 }
lbb_39747:
    mov64 r6, 0                                     r6 = 0 as i32 as i64 as u64
    mov64 r7, 0                                     r7 = 0 as i32 as i64 as u64
    jgt r8, 3, lbb_39758                            if r8 > (3 as i32 as i64 as u64) { pc += 8 }
    mov64 r1, r10                                   r1 = r10
    add64 r1, -24                                   r1 += -24   ///  r1 = r1.wrapping_add(-24 as i32 as i64 as u64)
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
    mov64 r3, 4                                     r3 = 4 as i32 as i64 as u64
    call function_38943                     
    ldxdw r3, [r10-0x20]                    
    ldxdw r0, [r10-0x18]                    
    ldxdw r7, [r10-0x8]                     
lbb_39758:
    add64 r0, r7                                    r0 += r7   ///  r0 = r0.wrapping_add(r7)
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    stxw [r0+0x0], r1                       
    add64 r3, 1                                     r3 += 1   ///  r3 = r3.wrapping_add(1 as i32 as i64 as u64)
    add64 r7, 4                                     r7 += 4   ///  r7 = r7.wrapping_add(4 as i32 as i64 as u64)
    stxdw [r10-0x8], r7                     
    ja lbb_39772                                    if true { pc += 7 }
lbb_39765:
    add64 r6, 1                                     r6 += 1   ///  r6 = r6.wrapping_add(1 as i32 as i64 as u64)
    ldxdw r1, [r10-0x18]                    
    add64 r1, r7                                    r1 += r7   ///  r1 = r1.wrapping_add(r7)
    stxb [r1+0x0], r8                       
    add64 r7, 1                                     r7 += 1   ///  r7 = r7.wrapping_add(1 as i32 as i64 as u64)
    stxdw [r10-0x8], r7                     
    jeq r6, 32, lbb_40239                           if r6 == (32 as i32 as i64 as u64) { pc += 467 }
lbb_39772:
    mov64 r1, r3                                    r1 = r3
    add64 r1, r6                                    r1 += r6   ///  r1 = r1.wrapping_add(r6)
    ldxb r8, [r1+0x0]                       
    ldxdw r1, [r10-0x10]                    
    jne r1, r7, lbb_39765                           if r1 != r7 { pc += -12 }
    mov64 r1, r10                                   r1 = r10
    add64 r1, -24                                   r1 += -24   ///  r1 = r1.wrapping_add(-24 as i32 as i64 as u64)
    mov64 r2, r7                                    r2 = r7
    mov64 r7, r3                                    r7 = r3
    mov64 r3, 1                                     r3 = 1 as i32 as i64 as u64
    call function_38943                     
    mov64 r3, r7                                    r3 = r7
    ldxdw r7, [r10-0x8]                     
    ja lbb_39765                                    if true { pc += -21 }
lbb_39786:
    mov64 r6, 0                                     r6 = 0 as i32 as i64 as u64
    mov64 r7, 0                                     r7 = 0 as i32 as i64 as u64
    jgt r8, 3, lbb_39797                            if r8 > (3 as i32 as i64 as u64) { pc += 8 }
    mov64 r1, r10                                   r1 = r10
    add64 r1, -24                                   r1 += -24   ///  r1 = r1.wrapping_add(-24 as i32 as i64 as u64)
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
    mov64 r3, 4                                     r3 = 4 as i32 as i64 as u64
    call function_38943                     
    ldxdw r3, [r10-0x20]                    
    ldxdw r0, [r10-0x18]                    
    ldxdw r7, [r10-0x8]                     
lbb_39797:
    add64 r3, 1                                     r3 += 1   ///  r3 = r3.wrapping_add(1 as i32 as i64 as u64)
    add64 r0, r7                                    r0 += r7   ///  r0 = r0.wrapping_add(r7)
    mov64 r1, 6                                     r1 = 6 as i32 as i64 as u64
    stxw [r0+0x0], r1                       
    add64 r7, 4                                     r7 += 4   ///  r7 = r7.wrapping_add(4 as i32 as i64 as u64)
    stxdw [r10-0x8], r7                     
    ja lbb_39811                                    if true { pc += 7 }
lbb_39804:
    add64 r6, 1                                     r6 += 1   ///  r6 = r6.wrapping_add(1 as i32 as i64 as u64)
    ldxdw r1, [r10-0x18]                    
    add64 r1, r7                                    r1 += r7   ///  r1 = r1.wrapping_add(r7)
    stxb [r1+0x0], r8                       
    add64 r7, 1                                     r7 += 1   ///  r7 = r7.wrapping_add(1 as i32 as i64 as u64)
    stxdw [r10-0x8], r7                     
    jeq r6, 32, lbb_40239                           if r6 == (32 as i32 as i64 as u64) { pc += 428 }
lbb_39811:
    mov64 r1, r3                                    r1 = r3
    add64 r1, r6                                    r1 += r6   ///  r1 = r1.wrapping_add(r6)
    ldxb r8, [r1+0x0]                       
    ldxdw r1, [r10-0x10]                    
    jne r1, r7, lbb_39804                           if r1 != r7 { pc += -12 }
    mov64 r1, r10                                   r1 = r10
    add64 r1, -24                                   r1 += -24   ///  r1 = r1.wrapping_add(-24 as i32 as i64 as u64)
    mov64 r2, r7                                    r2 = r7
    mov64 r7, r3                                    r7 = r3
    mov64 r3, 1                                     r3 = 1 as i32 as i64 as u64
    call function_38943                     
    mov64 r3, r7                                    r3 = r7
    ldxdw r7, [r10-0x8]                     
    ja lbb_39804                                    if true { pc += -21 }
lbb_39825:
    mov64 r6, 0                                     r6 = 0 as i32 as i64 as u64
    mov64 r7, 0                                     r7 = 0 as i32 as i64 as u64
    jgt r8, 3, lbb_39836                            if r8 > (3 as i32 as i64 as u64) { pc += 8 }
    mov64 r1, r10                                   r1 = r10
    add64 r1, -24                                   r1 += -24   ///  r1 = r1.wrapping_add(-24 as i32 as i64 as u64)
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
    mov64 r3, 4                                     r3 = 4 as i32 as i64 as u64
    call function_38943                     
    ldxdw r3, [r10-0x20]                    
    ldxdw r0, [r10-0x18]                    
    ldxdw r7, [r10-0x8]                     
lbb_39836:
    add64 r3, 1                                     r3 += 1   ///  r3 = r3.wrapping_add(1 as i32 as i64 as u64)
    add64 r0, r7                                    r0 += r7   ///  r0 = r0.wrapping_add(r7)
    mov64 r1, 7                                     r1 = 7 as i32 as i64 as u64
    stxw [r0+0x0], r1                       
    add64 r7, 4                                     r7 += 4   ///  r7 = r7.wrapping_add(4 as i32 as i64 as u64)
    stxdw [r10-0x8], r7                     
    ja lbb_39850                                    if true { pc += 7 }
lbb_39843:
    add64 r6, 1                                     r6 += 1   ///  r6 = r6.wrapping_add(1 as i32 as i64 as u64)
    ldxdw r1, [r10-0x18]                    
    add64 r1, r7                                    r1 += r7   ///  r1 = r1.wrapping_add(r7)
    stxb [r1+0x0], r8                       
    add64 r7, 1                                     r7 += 1   ///  r7 = r7.wrapping_add(1 as i32 as i64 as u64)
    stxdw [r10-0x8], r7                     
    jeq r6, 32, lbb_40239                           if r6 == (32 as i32 as i64 as u64) { pc += 389 }
lbb_39850:
    mov64 r1, r3                                    r1 = r3
    add64 r1, r6                                    r1 += r6   ///  r1 = r1.wrapping_add(r6)
    ldxb r8, [r1+0x0]                       
    ldxdw r1, [r10-0x10]                    
    jne r1, r7, lbb_39843                           if r1 != r7 { pc += -12 }
    mov64 r1, r10                                   r1 = r10
    add64 r1, -24                                   r1 += -24   ///  r1 = r1.wrapping_add(-24 as i32 as i64 as u64)
    mov64 r2, r7                                    r2 = r7
    mov64 r7, r3                                    r7 = r3
    mov64 r3, 1                                     r3 = 1 as i32 as i64 as u64
    call function_38943                     
    mov64 r3, r7                                    r3 = r7
    ldxdw r7, [r10-0x8]                     
    ja lbb_39843                                    if true { pc += -21 }
lbb_39864:
    mov64 r6, 0                                     r6 = 0 as i32 as i64 as u64
    mov64 r7, 0                                     r7 = 0 as i32 as i64 as u64
    jgt r8, 3, lbb_39875                            if r8 > (3 as i32 as i64 as u64) { pc += 8 }
    mov64 r1, r10                                   r1 = r10
    add64 r1, -24                                   r1 += -24   ///  r1 = r1.wrapping_add(-24 as i32 as i64 as u64)
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
    mov64 r3, 4                                     r3 = 4 as i32 as i64 as u64
    call function_38943                     
    ldxdw r3, [r10-0x20]                    
    ldxdw r0, [r10-0x18]                    
    ldxdw r7, [r10-0x8]                     
lbb_39875:
    add64 r0, r7                                    r0 += r7   ///  r0 = r0.wrapping_add(r7)
    mov64 r1, 9                                     r1 = 9 as i32 as i64 as u64
    stxw [r0+0x0], r1                       
    mov64 r8, r3                                    r8 = r3
    add64 r8, 1                                     r8 += 1   ///  r8 = r8.wrapping_add(1 as i32 as i64 as u64)
    add64 r7, 4                                     r7 += 4   ///  r7 = r7.wrapping_add(4 as i32 as i64 as u64)
    stxdw [r10-0x8], r7                     
    ja lbb_39906                                    if true { pc += 23 }
lbb_39883:
    add64 r6, 1                                     r6 += 1   ///  r6 = r6.wrapping_add(1 as i32 as i64 as u64)
    ldxdw r1, [r10-0x18]                    
    add64 r1, r7                                    r1 += r7   ///  r1 = r1.wrapping_add(r7)
    stxb [r1+0x0], r9                       
    add64 r7, 1                                     r7 += 1   ///  r7 = r7.wrapping_add(1 as i32 as i64 as u64)
    stxdw [r10-0x8], r7                     
    jne r6, 32, lbb_39906                           if r6 != (32 as i32 as i64 as u64) { pc += 16 }
    ldxdw r1, [r10-0x10]                    
    sub64 r1, r7                                    r1 -= r7   ///  r1 = r1.wrapping_sub(r7)
    ldxdw r4, [r3+0x60]                     
    ldxdw r2, [r3+0x50]                     
    jgt r1, 7, lbb_40092                            if r1 > (7 as i32 as i64 as u64) { pc += 197 }
    mov64 r1, r10                                   r1 = r10
    add64 r1, -24                                   r1 += -24   ///  r1 = r1.wrapping_add(-24 as i32 as i64 as u64)
    mov64 r8, r2                                    r8 = r2
    mov64 r2, r7                                    r2 = r7
    mov64 r3, 8                                     r3 = 8 as i32 as i64 as u64
    mov64 r6, r4                                    r6 = r4
    call function_38943                     
    mov64 r2, r8                                    r2 = r8
    mov64 r4, r6                                    r4 = r6
    ldxdw r7, [r10-0x8]                     
    ja lbb_40092                                    if true { pc += 186 }
lbb_39906:
    mov64 r1, r8                                    r1 = r8
    add64 r1, r6                                    r1 += r6   ///  r1 = r1.wrapping_add(r6)
    ldxb r9, [r1+0x0]                       
    ldxdw r1, [r10-0x10]                    
    jne r1, r7, lbb_39883                           if r1 != r7 { pc += -28 }
    mov64 r1, r10                                   r1 = r10
    add64 r1, -24                                   r1 += -24   ///  r1 = r1.wrapping_add(-24 as i32 as i64 as u64)
    mov64 r2, r7                                    r2 = r7
    mov64 r3, 1                                     r3 = 1 as i32 as i64 as u64
    call function_38943                     
    ldxdw r3, [r10-0x20]                    
    ldxdw r7, [r10-0x8]                     
    ja lbb_39883                                    if true { pc += -36 }
lbb_39919:
    ldxdw r1, [r10-0x18]                    
    add64 r1, r7                                    r1 += r7   ///  r1 = r1.wrapping_add(r7)
    stxdw [r1+0x0], r8                      
    add64 r7, 8                                     r7 += 8   ///  r7 = r7.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x8], r7                     
    ldxdw r1, [r10-0x10]                    
    sub64 r1, r7                                    r1 -= r7   ///  r1 = r1.wrapping_sub(r7)
    ldxdw r9, [r10-0x38]                    
    jge r1, r8, lbb_39929                           if r1 >= r8 { pc += 1 }
    ja lbb_40310                                    if true { pc += 381 }
lbb_39929:
    ldxdw r1, [r10-0x18]                    
    add64 r1, r7                                    r1 += r7   ///  r1 = r1.wrapping_add(r7)
    mov64 r2, r6                                    r2 = r6
    mov64 r3, r8                                    r3 = r8
    call function_48190                     
    add64 r7, r8                                    r7 += r8   ///  r7 = r7.wrapping_add(r8)
    mov64 r6, 0                                     r6 = 0 as i32 as i64 as u64
    ldxdw r3, [r10-0x20]                    
    add64 r3, 33                                    r3 += 33   ///  r3 = r3.wrapping_add(33 as i32 as i64 as u64)
    stxdw [r10-0x8], r7                     
    ja lbb_39947                                    if true { pc += 7 }
lbb_39940:
    add64 r6, 1                                     r6 += 1   ///  r6 = r6.wrapping_add(1 as i32 as i64 as u64)
    ldxdw r1, [r10-0x18]                    
    add64 r1, r7                                    r1 += r7   ///  r1 = r1.wrapping_add(r7)
    stxb [r1+0x0], r8                       
    add64 r7, 1                                     r7 += 1   ///  r7 = r7.wrapping_add(1 as i32 as i64 as u64)
    stxdw [r10-0x8], r7                     
    jeq r6, 32, lbb_40239                           if r6 == (32 as i32 as i64 as u64) { pc += 292 }
lbb_39947:
    mov64 r1, r3                                    r1 = r3
    add64 r1, r6                                    r1 += r6   ///  r1 = r1.wrapping_add(r6)
    ldxb r8, [r1+0x0]                       
    ldxdw r1, [r10-0x10]                    
    jne r1, r7, lbb_39940                           if r1 != r7 { pc += -12 }
    mov64 r1, r10                                   r1 = r10
    add64 r1, -24                                   r1 += -24   ///  r1 = r1.wrapping_add(-24 as i32 as i64 as u64)
    mov64 r2, r7                                    r2 = r7
    mov64 r7, r3                                    r7 = r3
    mov64 r3, 1                                     r3 = 1 as i32 as i64 as u64
    call function_38943                     
    mov64 r3, r7                                    r3 = r7
    ldxdw r7, [r10-0x8]                     
    ja lbb_39940                                    if true { pc += -21 }
lbb_39961:
    stxdw [r10-0x38], r9                    
    mov64 r6, 0                                     r6 = 0 as i32 as i64 as u64
    mov64 r7, 0                                     r7 = 0 as i32 as i64 as u64
    jgt r8, 3, lbb_39973                            if r8 > (3 as i32 as i64 as u64) { pc += 8 }
    mov64 r1, r10                                   r1 = r10
    add64 r1, -24                                   r1 += -24   ///  r1 = r1.wrapping_add(-24 as i32 as i64 as u64)
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
    mov64 r3, 4                                     r3 = 4 as i32 as i64 as u64
    call function_38943                     
    ldxdw r3, [r10-0x20]                    
    ldxdw r0, [r10-0x18]                    
    ldxdw r7, [r10-0x8]                     
lbb_39973:
    add64 r0, r7                                    r0 += r7   ///  r0 = r0.wrapping_add(r7)
    mov64 r1, 3                                     r1 = 3 as i32 as i64 as u64
    stxw [r0+0x0], r1                       
    mov64 r8, r3                                    r8 = r3
    add64 r8, 1                                     r8 += 1   ///  r8 = r8.wrapping_add(1 as i32 as i64 as u64)
    add64 r7, 4                                     r7 += 4   ///  r7 = r7.wrapping_add(4 as i32 as i64 as u64)
    stxdw [r10-0x8], r7                     
    ja lbb_40004                                    if true { pc += 23 }
lbb_39981:
    add64 r6, 1                                     r6 += 1   ///  r6 = r6.wrapping_add(1 as i32 as i64 as u64)
    ldxdw r1, [r10-0x18]                    
    add64 r1, r7                                    r1 += r7   ///  r1 = r1.wrapping_add(r7)
    stxb [r1+0x0], r9                       
    add64 r7, 1                                     r7 += 1   ///  r7 = r7.wrapping_add(1 as i32 as i64 as u64)
    stxdw [r10-0x8], r7                     
    jne r6, 32, lbb_40004                           if r6 != (32 as i32 as i64 as u64) { pc += 16 }
    ldxdw r1, [r10-0x10]                    
    sub64 r1, r7                                    r1 -= r7   ///  r1 = r1.wrapping_sub(r7)
    ldxdw r4, [r3+0x68]                     
    ldxdw r2, [r3+0x58]                     
    jgt r1, 7, lbb_40154                            if r1 > (7 as i32 as i64 as u64) { pc += 161 }
    mov64 r1, r10                                   r1 = r10
    add64 r1, -24                                   r1 += -24   ///  r1 = r1.wrapping_add(-24 as i32 as i64 as u64)
    mov64 r8, r2                                    r8 = r2
    mov64 r2, r7                                    r2 = r7
    mov64 r3, 8                                     r3 = 8 as i32 as i64 as u64
    mov64 r6, r4                                    r6 = r4
    call function_38943                     
    mov64 r2, r8                                    r2 = r8
    mov64 r4, r6                                    r4 = r6
    ldxdw r7, [r10-0x8]                     
    ja lbb_40154                                    if true { pc += 150 }
lbb_40004:
    mov64 r1, r8                                    r1 = r8
    add64 r1, r6                                    r1 += r6   ///  r1 = r1.wrapping_add(r6)
    ldxb r9, [r1+0x0]                       
    ldxdw r1, [r10-0x10]                    
    jne r1, r7, lbb_39981                           if r1 != r7 { pc += -28 }
    mov64 r1, r10                                   r1 = r10
    add64 r1, -24                                   r1 += -24   ///  r1 = r1.wrapping_add(-24 as i32 as i64 as u64)
    mov64 r2, r7                                    r2 = r7
    mov64 r3, 1                                     r3 = 1 as i32 as i64 as u64
    call function_38943                     
    ldxdw r3, [r10-0x20]                    
    ldxdw r7, [r10-0x8]                     
    ja lbb_39981                                    if true { pc += -36 }
lbb_40017:
    mov64 r7, 0                                     r7 = 0 as i32 as i64 as u64
    jgt r8, 3, lbb_40026                            if r8 > (3 as i32 as i64 as u64) { pc += 7 }
    mov64 r1, r10                                   r1 = r10
    add64 r1, -24                                   r1 += -24   ///  r1 = r1.wrapping_add(-24 as i32 as i64 as u64)
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
    mov64 r3, 4                                     r3 = 4 as i32 as i64 as u64
    call function_38943                     
    ldxdw r0, [r10-0x18]                    
    ldxdw r7, [r10-0x8]                     
lbb_40026:
    add64 r0, r7                                    r0 += r7   ///  r0 = r0.wrapping_add(r7)
    mov64 r1, 4                                     r1 = 4 as i32 as i64 as u64
lbb_40028:
    stxw [r0+0x0], r1                       
    add64 r7, 4                                     r7 += 4   ///  r7 = r7.wrapping_add(4 as i32 as i64 as u64)
    ja lbb_40239                                    if true { pc += 208 }
lbb_40031:
    mov64 r7, 0                                     r7 = 0 as i32 as i64 as u64
    jgt r8, 3, lbb_40041                            if r8 > (3 as i32 as i64 as u64) { pc += 8 }
    mov64 r1, r10                                   r1 = r10
    add64 r1, -24                                   r1 += -24   ///  r1 = r1.wrapping_add(-24 as i32 as i64 as u64)
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
    mov64 r3, 4                                     r3 = 4 as i32 as i64 as u64
    call function_38943                     
    ldxdw r3, [r10-0x20]                    
    ldxdw r0, [r10-0x18]                    
    ldxdw r7, [r10-0x8]                     
lbb_40041:
    add64 r0, r7                                    r0 += r7   ///  r0 = r0.wrapping_add(r7)
    mov64 r1, 11                                    r1 = 11 as i32 as i64 as u64
    stxw [r0+0x0], r1                       
    add64 r7, 4                                     r7 += 4   ///  r7 = r7.wrapping_add(4 as i32 as i64 as u64)
    stxdw [r10-0x8], r7                     
    ldxdw r1, [r10-0x10]                    
    sub64 r1, r7                                    r1 -= r7   ///  r1 = r1.wrapping_sub(r7)
    ldxdw r6, [r3+0x8]                      
    mov64 r2, 8                                     r2 = 8 as i32 as i64 as u64
    jgt r2, r1, lbb_40317                           if r2 > r1 { pc += 266 }
lbb_40051:
    ldxdw r1, [r10-0x18]                    
    add64 r1, r7                                    r1 += r7   ///  r1 = r1.wrapping_add(r7)
    stxdw [r1+0x0], r6                      
    add64 r7, 8                                     r7 += 8   ///  r7 = r7.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x8], r7                     
    ldxdw r1, [r10-0x10]                    
    sub64 r1, r7                                    r1 -= r7   ///  r1 = r1.wrapping_sub(r7)
    ldxdw r8, [r3+0x40]                     
    ldxdw r6, [r3+0x30]                     
    jgt r1, 7, lbb_40067                            if r1 > (7 as i32 as i64 as u64) { pc += 6 }
    mov64 r1, r10                                   r1 = r10
    add64 r1, -24                                   r1 += -24   ///  r1 = r1.wrapping_add(-24 as i32 as i64 as u64)
    mov64 r2, r7                                    r2 = r7
    mov64 r3, 8                                     r3 = 8 as i32 as i64 as u64
    call function_38943                     
    ldxdw r7, [r10-0x8]                     
lbb_40067:
    ldxdw r1, [r10-0x18]                    
    add64 r1, r7                                    r1 += r7   ///  r1 = r1.wrapping_add(r7)
    stxdw [r1+0x0], r8                      
    add64 r7, 8                                     r7 += 8   ///  r7 = r7.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x8], r7                     
    ldxdw r1, [r10-0x10]                    
    sub64 r1, r7                                    r1 -= r7   ///  r1 = r1.wrapping_sub(r7)
    jge r1, r8, lbb_40081                           if r1 >= r8 { pc += 6 }
    mov64 r1, r10                                   r1 = r10
    add64 r1, -24                                   r1 += -24   ///  r1 = r1.wrapping_add(-24 as i32 as i64 as u64)
    mov64 r2, r7                                    r2 = r7
    mov64 r3, r8                                    r3 = r8
    call function_38943                     
    ldxdw r7, [r10-0x8]                     
lbb_40081:
    ldxdw r1, [r10-0x18]                    
    add64 r1, r7                                    r1 += r7   ///  r1 = r1.wrapping_add(r7)
    mov64 r2, r6                                    r2 = r6
    mov64 r3, r8                                    r3 = r8
    call function_48190                     
    add64 r7, r8                                    r7 += r8   ///  r7 = r7.wrapping_add(r8)
    mov64 r6, 0                                     r6 = 0 as i32 as i64 as u64
    ldxdw r3, [r10-0x20]                    
    add64 r3, 16                                    r3 += 16   ///  r3 = r3.wrapping_add(16 as i32 as i64 as u64)
    stxdw [r10-0x8], r7                     
    ja lbb_40262                                    if true { pc += 170 }
lbb_40092:
    ldxdw r1, [r10-0x18]                    
    add64 r1, r7                                    r1 += r7   ///  r1 = r1.wrapping_add(r7)
    stxdw [r1+0x0], r4                      
    add64 r7, 8                                     r7 += 8   ///  r7 = r7.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x8], r7                     
    ldxdw r6, [r10-0x10]                    
    mov64 r1, r6                                    r1 = r6
    sub64 r1, r7                                    r1 -= r7   ///  r1 = r1.wrapping_sub(r7)
    ldxdw r9, [r10-0x38]                    
    jge r1, r4, lbb_40103                           if r1 >= r4 { pc += 1 }
    ja lbb_40325                                    if true { pc += 222 }
lbb_40103:
    stxdw [r10-0x40], r4                    
    ldxdw r8, [r10-0x18]                    
    mov64 r1, r8                                    r1 = r8
    add64 r1, r7                                    r1 += r7   ///  r1 = r1.wrapping_add(r7)
    mov64 r3, r4                                    r3 = r4
    call function_48190                     
    ldxdw r1, [r10-0x40]                    
    add64 r7, r1                                    r7 += r1   ///  r7 = r7.wrapping_add(r1)
    stxdw [r10-0x8], r7                     
    sub64 r6, r7                                    r6 -= r7   ///  r6 = r6.wrapping_sub(r7)
    ldxdw r3, [r10-0x20]                    
    ldxdw r1, [r3+0x28]                     
    jgt r6, 7, lbb_40126                            if r6 > (7 as i32 as i64 as u64) { pc += 10 }
    mov64 r6, r1                                    r6 = r1
    mov64 r1, r10                                   r1 = r10
    add64 r1, -24                                   r1 += -24   ///  r1 = r1.wrapping_add(-24 as i32 as i64 as u64)
    mov64 r2, r7                                    r2 = r7
    mov64 r3, 8                                     r3 = 8 as i32 as i64 as u64
    call function_38943                     
    mov64 r1, r6                                    r1 = r6
    ldxdw r3, [r10-0x20]                    
    ldxdw r8, [r10-0x18]                    
    ldxdw r7, [r10-0x8]                     
lbb_40126:
    add64 r8, r7                                    r8 += r7   ///  r8 = r8.wrapping_add(r7)
    stxdw [r8+0x0], r1                      
    mov64 r6, 0                                     r6 = 0 as i32 as i64 as u64
    add64 r3, 48                                    r3 += 48   ///  r3 = r3.wrapping_add(48 as i32 as i64 as u64)
    add64 r7, 8                                     r7 += 8   ///  r7 = r7.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x8], r7                     
    ja lbb_40140                                    if true { pc += 7 }
lbb_40133:
    add64 r6, 1                                     r6 += 1   ///  r6 = r6.wrapping_add(1 as i32 as i64 as u64)
    ldxdw r1, [r10-0x18]                    
    add64 r1, r7                                    r1 += r7   ///  r1 = r1.wrapping_add(r7)
    stxb [r1+0x0], r8                       
    add64 r7, 1                                     r7 += 1   ///  r7 = r7.wrapping_add(1 as i32 as i64 as u64)
    stxdw [r10-0x8], r7                     
    jeq r6, 32, lbb_40239                           if r6 == (32 as i32 as i64 as u64) { pc += 99 }
lbb_40140:
    mov64 r1, r3                                    r1 = r3
    add64 r1, r6                                    r1 += r6   ///  r1 = r1.wrapping_add(r6)
    ldxb r8, [r1+0x0]                       
    ldxdw r1, [r10-0x10]                    
    jne r1, r7, lbb_40133                           if r1 != r7 { pc += -12 }
    mov64 r1, r10                                   r1 = r10
    add64 r1, -24                                   r1 += -24   ///  r1 = r1.wrapping_add(-24 as i32 as i64 as u64)
    mov64 r2, r7                                    r2 = r7
    mov64 r7, r3                                    r7 = r3
    mov64 r3, 1                                     r3 = 1 as i32 as i64 as u64
    call function_38943                     
    mov64 r3, r7                                    r3 = r7
    ldxdw r7, [r10-0x8]                     
    ja lbb_40133                                    if true { pc += -21 }
lbb_40154:
    ldxdw r1, [r10-0x18]                    
    add64 r1, r7                                    r1 += r7   ///  r1 = r1.wrapping_add(r7)
    stxdw [r1+0x0], r4                      
    add64 r7, 8                                     r7 += 8   ///  r7 = r7.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x8], r7                     
    ldxdw r6, [r10-0x10]                    
    mov64 r1, r6                                    r1 = r6
    sub64 r1, r7                                    r1 -= r7   ///  r1 = r1.wrapping_sub(r7)
    ldxdw r9, [r10-0x38]                    
    jge r1, r4, lbb_40165                           if r1 >= r4 { pc += 1 }
    ja lbb_40337                                    if true { pc += 172 }
lbb_40165:
    stxdw [r10-0x40], r4                    
    ldxdw r8, [r10-0x18]                    
    mov64 r1, r8                                    r1 = r8
    add64 r1, r7                                    r1 += r7   ///  r1 = r1.wrapping_add(r7)
    mov64 r3, r4                                    r3 = r4
    call function_48190                     
    ldxdw r1, [r10-0x40]                    
    add64 r7, r1                                    r7 += r1   ///  r7 = r7.wrapping_add(r1)
    stxdw [r10-0x8], r7                     
    sub64 r6, r7                                    r6 -= r7   ///  r6 = r6.wrapping_sub(r7)
    ldxdw r3, [r10-0x20]                    
    ldxdw r1, [r3+0x28]                     
    jgt r6, 7, lbb_40188                            if r6 > (7 as i32 as i64 as u64) { pc += 10 }
    mov64 r6, r1                                    r6 = r1
    mov64 r1, r10                                   r1 = r10
    add64 r1, -24                                   r1 += -24   ///  r1 = r1.wrapping_add(-24 as i32 as i64 as u64)
    mov64 r2, r7                                    r2 = r7
    mov64 r3, 8                                     r3 = 8 as i32 as i64 as u64
    call function_38943                     
    mov64 r1, r6                                    r1 = r6
    ldxdw r3, [r10-0x20]                    
    ldxdw r8, [r10-0x18]                    
    ldxdw r7, [r10-0x8]                     
lbb_40188:
    add64 r8, r7                                    r8 += r7   ///  r8 = r8.wrapping_add(r7)
    stxdw [r8+0x0], r1                      
    add64 r7, 8                                     r7 += 8   ///  r7 = r7.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x8], r7                     
    ldxdw r1, [r10-0x10]                    
    sub64 r1, r7                                    r1 -= r7   ///  r1 = r1.wrapping_sub(r7)
    ldxdw r6, [r3+0x30]                     
    jgt r1, 7, lbb_40203                            if r1 > (7 as i32 as i64 as u64) { pc += 7 }
    mov64 r1, r10                                   r1 = r10
    add64 r1, -24                                   r1 += -24   ///  r1 = r1.wrapping_add(-24 as i32 as i64 as u64)
    mov64 r2, r7                                    r2 = r7
    mov64 r3, 8                                     r3 = 8 as i32 as i64 as u64
    call function_38943                     
    ldxdw r3, [r10-0x20]                    
    ldxdw r7, [r10-0x8]                     
lbb_40203:
    ldxdw r1, [r10-0x18]                    
    add64 r1, r7                                    r1 += r7   ///  r1 = r1.wrapping_add(r7)
    stxdw [r1+0x0], r6                      
    mov64 r6, 0                                     r6 = 0 as i32 as i64 as u64
    add64 r3, 56                                    r3 += 56   ///  r3 = r3.wrapping_add(56 as i32 as i64 as u64)
    add64 r7, 8                                     r7 += 8   ///  r7 = r7.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x8], r7                     
    ja lbb_40218                                    if true { pc += 7 }
lbb_40211:
    add64 r6, 1                                     r6 += 1   ///  r6 = r6.wrapping_add(1 as i32 as i64 as u64)
    ldxdw r1, [r10-0x18]                    
    add64 r1, r7                                    r1 += r7   ///  r1 = r1.wrapping_add(r7)
    stxb [r1+0x0], r8                       
    add64 r7, 1                                     r7 += 1   ///  r7 = r7.wrapping_add(1 as i32 as i64 as u64)
    stxdw [r10-0x8], r7                     
    jeq r6, 32, lbb_40239                           if r6 == (32 as i32 as i64 as u64) { pc += 21 }
lbb_40218:
    mov64 r1, r3                                    r1 = r3
    add64 r1, r6                                    r1 += r6   ///  r1 = r1.wrapping_add(r6)
    ldxb r8, [r1+0x0]                       
    ldxdw r1, [r10-0x10]                    
    jne r1, r7, lbb_40211                           if r1 != r7 { pc += -12 }
    mov64 r1, r10                                   r1 = r10
    add64 r1, -24                                   r1 += -24   ///  r1 = r1.wrapping_add(-24 as i32 as i64 as u64)
    mov64 r2, r7                                    r2 = r7
    mov64 r7, r3                                    r7 = r3
    mov64 r3, 1                                     r3 = 1 as i32 as i64 as u64
    call function_38943                     
    mov64 r3, r7                                    r3 = r7
    ldxdw r7, [r10-0x8]                     
    ja lbb_40211                                    if true { pc += -21 }
lbb_40232:
    add64 r6, 1                                     r6 += 1   ///  r6 = r6.wrapping_add(1 as i32 as i64 as u64)
    ldxdw r1, [r10-0x18]                    
    add64 r1, r7                                    r1 += r7   ///  r1 = r1.wrapping_add(r7)
    stxb [r1+0x0], r8                       
    add64 r7, 1                                     r7 += 1   ///  r7 = r7.wrapping_add(1 as i32 as i64 as u64)
    stxdw [r10-0x8], r7                     
    jne r6, 32, lbb_40262                           if r6 != (32 as i32 as i64 as u64) { pc += 23 }
lbb_40239:
    ldxdw r1, [r10-0x10]                    
    ldxdw r2, [r10-0x18]                    
    jeq r2, 0, lbb_40349                            if r2 == (0 as i32 as i64 as u64) { pc += 107 }
    ldxdw r4, [r10-0x28]                    
    ldxdw r3, [r4+0x18]                     
    stxdw [r9+0x48], r3                     
    ldxdw r3, [r4+0x10]                     
    stxdw [r9+0x40], r3                     
    ldxdw r3, [r4+0x8]                      
    stxdw [r9+0x38], r3                     
    ldxdw r3, [r4+0x0]                      
    stxdw [r9+0x30], r3                     
    ldxdw r4, [r10-0x30]                    
    ldxdw r3, [r4+0x0]                      
    stxdw [r9+0x0], r3                      
    ldxdw r3, [r4+0x8]                      
    stxdw [r9+0x8], r3                      
    ldxdw r3, [r4+0x10]                     
    stxdw [r9+0x10], r3                     
    stxdw [r9+0x28], r7                     
    stxdw [r9+0x20], r1                     
    stxdw [r9+0x18], r2                     
    exit                                    
lbb_40262:
    mov64 r1, r3                                    r1 = r3
    add64 r1, r6                                    r1 += r6   ///  r1 = r1.wrapping_add(r6)
    ldxb r8, [r1+0x0]                       
    ldxdw r1, [r10-0x10]                    
    jne r1, r7, lbb_40232                           if r1 != r7 { pc += -35 }
    mov64 r1, r10                                   r1 = r10
    add64 r1, -24                                   r1 += -24   ///  r1 = r1.wrapping_add(-24 as i32 as i64 as u64)
    mov64 r2, r7                                    r2 = r7
    mov64 r7, r3                                    r7 = r3
    mov64 r3, 1                                     r3 = 1 as i32 as i64 as u64
    call function_38943                     
    mov64 r3, r7                                    r3 = r7
    ldxdw r7, [r10-0x8]                     
    ja lbb_40232                                    if true { pc += -44 }
lbb_40276:
    mov64 r1, r10                                   r1 = r10
    add64 r1, -24                                   r1 += -24   ///  r1 = r1.wrapping_add(-24 as i32 as i64 as u64)
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
    mov64 r3, 4                                     r3 = 4 as i32 as i64 as u64
    call function_38943                     
    ldxdw r3, [r10-0x20]                    
    ldxdw r0, [r10-0x18]                    
    ldxdw r7, [r10-0x8]                     
    ja lbb_39563                                    if true { pc += -722 }
lbb_40285:
    mov64 r1, r10                                   r1 = r10
    add64 r1, -24                                   r1 += -24   ///  r1 = r1.wrapping_add(-24 as i32 as i64 as u64)
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
    mov64 r3, 4                                     r3 = 4 as i32 as i64 as u64
    call function_38943                     
    ldxdw r3, [r10-0x20]                    
    ldxdw r0, [r10-0x18]                    
    ldxdw r7, [r10-0x8]                     
    ja lbb_39608                                    if true { pc += -686 }
lbb_40294:
    mov64 r1, r10                                   r1 = r10
    add64 r1, -24                                   r1 += -24   ///  r1 = r1.wrapping_add(-24 as i32 as i64 as u64)
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
    mov64 r3, 4                                     r3 = 4 as i32 as i64 as u64
    call function_38943                     
    ldxdw r0, [r10-0x18]                    
    ldxdw r7, [r10-0x8]                     
    ja lbb_39679                                    if true { pc += -623 }
lbb_40302:
    mov64 r1, r10                                   r1 = r10
    add64 r1, -24                                   r1 += -24   ///  r1 = r1.wrapping_add(-24 as i32 as i64 as u64)
    mov64 r2, r7                                    r2 = r7
    mov64 r3, 8                                     r3 = 8 as i32 as i64 as u64
    call function_38943                     
    ldxdw r3, [r10-0x20]                    
    ldxdw r7, [r10-0x8]                     
    ja lbb_39702                                    if true { pc += -608 }
lbb_40310:
    mov64 r1, r10                                   r1 = r10
    add64 r1, -24                                   r1 += -24   ///  r1 = r1.wrapping_add(-24 as i32 as i64 as u64)
    mov64 r2, r7                                    r2 = r7
    mov64 r3, r8                                    r3 = r8
    call function_38943                     
    ldxdw r7, [r10-0x8]                     
    ja lbb_39929                                    if true { pc += -388 }
lbb_40317:
    mov64 r1, r10                                   r1 = r10
    add64 r1, -24                                   r1 += -24   ///  r1 = r1.wrapping_add(-24 as i32 as i64 as u64)
    mov64 r2, r7                                    r2 = r7
    mov64 r3, 8                                     r3 = 8 as i32 as i64 as u64
    call function_38943                     
    ldxdw r3, [r10-0x20]                    
    ldxdw r7, [r10-0x8]                     
    ja lbb_40051                                    if true { pc += -274 }
lbb_40325:
    mov64 r1, r10                                   r1 = r10
    add64 r1, -24                                   r1 += -24   ///  r1 = r1.wrapping_add(-24 as i32 as i64 as u64)
    mov64 r8, r2                                    r8 = r2
    mov64 r2, r7                                    r2 = r7
    mov64 r3, r4                                    r3 = r4
    mov64 r6, r4                                    r6 = r4
    call function_38943                     
    mov64 r2, r8                                    r2 = r8
    mov64 r4, r6                                    r4 = r6
    ldxdw r6, [r10-0x10]                    
    ldxdw r7, [r10-0x8]                     
    ja lbb_40103                                    if true { pc += -234 }
lbb_40337:
    mov64 r1, r10                                   r1 = r10
    add64 r1, -24                                   r1 += -24   ///  r1 = r1.wrapping_add(-24 as i32 as i64 as u64)
    mov64 r8, r2                                    r8 = r2
    mov64 r2, r7                                    r2 = r7
    mov64 r3, r4                                    r3 = r4
    mov64 r6, r4                                    r6 = r4
    call function_38943                     
    mov64 r2, r8                                    r2 = r8
    mov64 r4, r6                                    r4 = r6
    ldxdw r6, [r10-0x10]                    
    ldxdw r7, [r10-0x8]                     
    ja lbb_40165                                    if true { pc += -184 }
lbb_40349:
    stxdw [r10-0x18], r1                    
    mov64 r3, r10                                   r3 = r10
    add64 r3, -24                                   r3 += -24   ///  r3 = r3.wrapping_add(-24 as i32 as i64 as u64)
    lddw r1, 0x100063071 --> b"called `Result::unwrap()` on an `Err` value"        r1 load str located at 4295372913
    mov64 r2, 43                                    r2 = 43 as i32 as i64 as u64
    lddw r4, 0x100066ed0 --> b"\x00\x00\x00\x00(\xbd\x04\x00\x08\x00\x00\x00\x00\x00\x00\x00\x08\x00\x00…        r4 load str located at 4295388880
    lddw r5, 0x100066ef0 --> b"\x00\x00\x00\x00H2\x06\x00\x12\x00\x00\x00\x00\x00\x00\x00\xbe\x01\x00\x0…        r5 load str located at 4295388912
    call function_44299                     
    syscall [invalid]                       
lbb_40361:
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    mov64 r2, r8                                    r2 = r8
    call function_43400                     
    syscall [invalid]                       
lbb_40365:
    call function_43383                     
    syscall [invalid]                       

function_40367:
    syscall [invalid]                       
    exit                                    

function_40369:
    lddw r5, 0x100063450 --> b"Custom program error: The arguments provided to a "        r5 load str located at 4295373904
    stxdw [r10-0x1000], r5                  
    mov64 r5, 0                                     r5 = 0 as i32 as i64 as u64
    stxdw [r10-0xff8], r5                   
    mov64 r5, r10                                   r5 = r10
    call function_40377                     
    exit                                    

function_40377:
    stxdw [r10-0x28], r4                    
    stxdw [r10-0x30], r3                    
    stxdw [r10-0x40], r1                    
    stxdw [r10-0x38], r2                    
    ldxdw r1, [r2+0x10]                     
    ldxdw r2, [r5-0xff8]                    
    stxdw [r10-0x68], r2                    
    ldxdw r2, [r5-0x1000]                   
    stxdw [r10-0x70], r2                    
    jeq r1, 0, lbb_40472                            if r1 == (0 as i32 as i64 as u64) { pc += 85 }
    ldxdw r2, [r10-0x38]                    
    ldxdw r7, [r2+0x0]                      
    mul64 r1, 34                                    r1 *= 34   ///  r1 = r1.wrapping_mul(34 as u64)
    mov64 r2, r7                                    r2 = r7
    add64 r2, r1                                    r2 += r1   ///  r2 = r2.wrapping_add(r1)
    stxdw [r10-0x8], r2                     
    ldxdw r0, [r10-0x28]                    
    mul64 r0, 48                                    r0 *= 48   ///  r0 = r0.wrapping_mul(48 as u64)
    ldxdw r5, [r10-0x30]                    
    add64 r5, -40                                   r5 += -40   ///  r5 = r5.wrapping_add(-40 as i32 as i64 as u64)
    ja lbb_40408                                    if true { pc += 10 }
lbb_40398:
    mov64 r2, r3                                    r2 = r3
    add64 r2, 16                                    r2 += 16   ///  r2 = r2.wrapping_add(16 as i32 as i64 as u64)
    stxdw [r10-0x10], r2                    
    stxdw [r3+0x10], r4                     
    add64 r3, 24                                    r3 += 24   ///  r3 = r3.wrapping_add(24 as i32 as i64 as u64)
    add64 r6, 24                                    r6 += 24   ///  r6 = r6.wrapping_add(24 as i32 as i64 as u64)
    stxdw [r10-0x20], r6                    
    stxdw [r10-0x18], r3                    
lbb_40406:
    ldxdw r2, [r10-0x8]                     
    jeq r7, r2, lbb_40472                           if r7 == r2 { pc += 64 }
lbb_40408:
    mov64 r6, r7                                    r6 = r7
    add64 r7, 34                                    r7 += 34   ///  r7 = r7.wrapping_add(34 as i32 as i64 as u64)
    mov64 r8, r0                                    r8 = r0
    mov64 r9, r5                                    r9 = r5
lbb_40412:
    jne r8, 0, lbb_40414                            if r8 != (0 as i32 as i64 as u64) { pc += 1 }
    ja lbb_40406                                    if true { pc += -8 }
lbb_40414:
    ldxdw r3, [r6+0x0]                      
    ldxdw r4, [r9+0x28]                     
    ldxdw r2, [r4+0x0]                      
    jeq r3, r2, lbb_40420                           if r3 == r2 { pc += 2 }
lbb_40418:
    mov64 r3, 1                                     r3 = 1 as i32 as i64 as u64
    ja lbb_40430                                    if true { pc += 10 }
lbb_40420:
    ldxdw r2, [r4+0x8]                      
    ldxdw r3, [r6+0x8]                      
    jne r3, r2, lbb_40418                           if r3 != r2 { pc += -5 }
    ldxdw r2, [r4+0x10]                     
    ldxdw r3, [r6+0x10]                     
    jne r3, r2, lbb_40418                           if r3 != r2 { pc += -8 }
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
    ldxdw r2, [r4+0x18]                     
    ldxdw r4, [r6+0x18]                     
    jne r4, r2, lbb_40418                           if r4 != r2 { pc += -12 }
lbb_40430:
    add64 r8, -48                                   r8 += -48   ///  r8 = r8.wrapping_add(-48 as i32 as i64 as u64)
    add64 r9, 48                                    r9 += 48   ///  r9 = r9.wrapping_add(48 as i32 as i64 as u64)
    jne r3, 0, lbb_40412                            if r3 != (0 as i32 as i64 as u64) { pc += -21 }
    ldxb r2, [r6+0x21]                      
    jne r2, 0, lbb_40456                            if r2 != (0 as i32 as i64 as u64) { pc += 21 }
    ldxdw r6, [r9+0x0]                      
    ldxdw r2, [r6+0x10]                     
    lddw r3, 0x7fffffffffffffff                     r3 load str located at 9223372036854775807
    jgt r3, r2, lbb_40441                           if r3 > r2 { pc += 1 }
    ja lbb_40487                                    if true { pc += 46 }
lbb_40441:
    ldxdw r8, [r9+0x8]                      
    ldxdw r2, [r8+0x10]                     
    jgt r3, r2, lbb_40445                           if r3 > r2 { pc += 1 }
    ja lbb_40492                                    if true { pc += 47 }
lbb_40445:
    mov64 r2, r6                                    r2 = r6
    add64 r2, 16                                    r2 += 16   ///  r2 = r2.wrapping_add(16 as i32 as i64 as u64)
    stxdw [r10-0x48], r2                    
    mov64 r2, r8                                    r2 = r8
    add64 r2, 16                                    r2 += 16   ///  r2 = r2.wrapping_add(16 as i32 as i64 as u64)
    stxdw [r10-0x58], r2                    
    add64 r8, 24                                    r8 += 24   ///  r8 = r8.wrapping_add(24 as i32 as i64 as u64)
    add64 r6, 24                                    r6 += 24   ///  r6 = r6.wrapping_add(24 as i32 as i64 as u64)
    stxdw [r10-0x50], r6                    
    stxdw [r10-0x60], r8                    
    ja lbb_40406                                    if true { pc += -50 }
lbb_40456:
    ldxdw r6, [r9+0x0]                      
    ldxdw r2, [r6+0x10]                     
    mov64 r4, 0                                     r4 = 0 as i32 as i64 as u64
    jeq r2, 0, lbb_40461                            if r2 == (0 as i32 as i64 as u64) { pc += 1 }
    ja lbb_40483                                    if true { pc += 22 }
lbb_40461:
    mov64 r1, r6                                    r1 = r6
    add64 r1, 16                                    r1 += 16   ///  r1 = r1.wrapping_add(16 as i32 as i64 as u64)
    stxdw [r1+0x0], r4                      
    ldxdw r3, [r9+0x8]                      
    ldxdw r2, [r3+0x10]                     
    jeq r2, 0, lbb_40398                            if r2 == (0 as i32 as i64 as u64) { pc += -69 }
    ldxdw r2, [r10-0x40]                    
    ldxdw r1, [r10-0x10]                    
    stxdw [r2+0x10], r1                     
    ldxdw r1, [r10-0x18]                    
    ja lbb_40496                                    if true { pc += 24 }
lbb_40472:
    ldxdw r1, [r10-0x70]                    
    stxdw [r10-0x1000], r1                  
    ldxdw r1, [r10-0x68]                    
    stxdw [r10-0xff8], r1                   
    mov64 r5, r10                                   r5 = r10
    ldxdw r1, [r10-0x40]                    
    ldxdw r2, [r10-0x38]                    
    ldxdw r3, [r10-0x30]                    
    ldxdw r4, [r10-0x28]                    
    call function_40500                     
    ja lbb_40499                                    if true { pc += 16 }
lbb_40483:
    ldxdw r2, [r10-0x40]                    
    stxdw [r2+0x10], r1                     
    ldxdw r1, [r10-0x20]                    
    ja lbb_40496                                    if true { pc += 9 }
lbb_40487:
    ldxdw r2, [r10-0x40]                    
    ldxdw r1, [r10-0x48]                    
    stxdw [r2+0x10], r1                     
    ldxdw r1, [r10-0x50]                    
    ja lbb_40496                                    if true { pc += 4 }
lbb_40492:
    ldxdw r2, [r10-0x40]                    
    ldxdw r1, [r10-0x58]                    
    stxdw [r2+0x10], r1                     
    ldxdw r1, [r10-0x60]                    
lbb_40496:
    stxdw [r2+0x8], r1                      
    mov64 r1, 11                                    r1 = 11 as i32 as i64 as u64
    stxw [r2+0x0], r1                       
lbb_40499:
    exit                                    

function_40500:
    stxdw [r10-0x80], r4                    
    stxdw [r10-0x88], r3                    
    stxdw [r10-0x78], r1                    
    ldxdw r1, [r5-0xff8]                    
    stxdw [r10-0x90], r1                    
    ldxdw r1, [r5-0x1000]                   
    stxdw [r10-0x98], r1                    
    stxdw [r10-0x68], r2                    
    ldxdw r1, [r2+0x10]                     
    mov64 r2, 1                                     r2 = 1 as i32 as i64 as u64
    stxdw [r10-0x60], r2                    
    stxdw [r10-0x70], r1                    
    jeq r1, 0, lbb_40559                            if r1 == (0 as i32 as i64 as u64) { pc += 46 }
    lddw r1, 0x3c3c3c3c3c3c3c4                      r1 load str located at 271275648142787524
    ldxdw r6, [r10-0x70]                    
    jgt r1, r6, lbb_40519                           if r1 > r6 { pc += 2 }
lbb_40517:
    call function_43383                     
    syscall [invalid]                       
lbb_40519:
    ldxdw r1, [r10-0x68]                    
    ldxdw r8, [r1+0x0]                      
    mov64 r7, r6                                    r7 = r6
    mul64 r7, 34                                    r7 *= 34   ///  r7 = r7.wrapping_mul(34 as u64)
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    stxdw [r10-0x60], r1                    
    jeq r7, 0, lbb_40534                            if r7 == (0 as i32 as i64 as u64) { pc += 8 }
    mov64 r1, r7                                    r1 = r7
    call function_21359                     
    stxdw [r10-0x60], r0                    
    jne r0, 0, lbb_40534                            if r0 != (0 as i32 as i64 as u64) { pc += 4 }
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    mov64 r2, r7                                    r2 = r7
    call function_43400                     
    syscall [invalid]                       
lbb_40534:
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    mov64 r2, r6                                    r2 = r6
lbb_40536:
    jeq r7, r1, lbb_40559                           if r7 == r1 { pc += 22 }
    ldxdw r3, [r10-0x60]                    
    add64 r3, r1                                    r3 += r1   ///  r3 = r3.wrapping_add(r1)
    ldxdw r4, [r8+0x0]                      
    stxdw [r10-0x58], r4                    
    ldxdw r5, [r8+0x8]                      
    ldxdw r0, [r8+0x10]                     
    mov64 r4, r7                                    r4 = r7
    ldxdw r7, [r8+0x18]                     
    ldxb r9, [r8+0x21]                      
    ldxb r6, [r8+0x20]                      
    stxb [r3+0x20], r6                      
    stxb [r3+0x21], r9                      
    stxdw [r3+0x18], r7                     
    mov64 r7, r4                                    r7 = r4
    stxdw [r3+0x10], r0                     
    stxdw [r3+0x8], r5                      
    ldxdw r4, [r10-0x58]                    
    stxdw [r3+0x0], r4                      
    add64 r1, 34                                    r1 += 34   ///  r1 = r1.wrapping_add(34 as i32 as i64 as u64)
    add64 r8, 34                                    r8 += 34   ///  r8 = r8.wrapping_add(34 as i32 as i64 as u64)
    add64 r2, -1                                    r2 += -1   ///  r2 = r2.wrapping_add(-1 as i32 as i64 as u64)
    jne r2, 0, lbb_40536                            if r2 != (0 as i32 as i64 as u64) { pc += -23 }
lbb_40559:
    ldxdw r7, [r10-0x68]                    
    ldxdw r9, [r7+0x18]                     
    ldxdw r6, [r7+0x28]                     
    mov64 r8, 1                                     r8 = 1 as i32 as i64 as u64
    jeq r6, 0, lbb_40571                            if r6 == (0 as i32 as i64 as u64) { pc += 7 }
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    jsgt r1, r6, lbb_40517                          if (r1 as i64) > (r6 as i64) { pc += -49 }
    mov64 r1, r6                                    r1 = r6
    mov64 r2, 1                                     r2 = 1 as i32 as i64 as u64
    call function_21359                     
    mov64 r8, r0                                    r8 = r0
    jeq r8, 0, lbb_40619                            if r8 == (0 as i32 as i64 as u64) { pc += 48 }
lbb_40571:
    add64 r7, 48                                    r7 += 48   ///  r7 = r7.wrapping_add(48 as i32 as i64 as u64)
    mov64 r1, r8                                    r1 = r8
    mov64 r2, r9                                    r2 = r9
    mov64 r3, r6                                    r3 = r6
    call function_48190                     
    ldxdw r1, [r7+0x18]                     
    ldxdw r2, [r7+0x10]                     
    ldxdw r3, [r7+0x8]                      
    ldxdw r4, [r7+0x0]                      
    ldxdw r5, [r10-0x60]                    
    stxdw [r10-0x50], r5                    
    ldxdw r5, [r10-0x70]                    
    stxdw [r10-0x48], r5                    
    stxdw [r10-0x40], r5                    
    stxdw [r10-0x38], r8                    
    stxdw [r10-0x30], r6                    
    stxdw [r10-0x28], r6                    
    stxdw [r10-0x20], r4                    
    stxdw [r10-0x18], r3                    
    stxdw [r10-0x10], r2                    
    stxdw [r10-0x8], r1                     
    mov64 r1, r10                                   r1 = r10
    add64 r1, -80                                   r1 += -80   ///  r1 = r1.wrapping_add(-80 as i32 as i64 as u64)
    ldxdw r2, [r10-0x88]                    
    ldxdw r3, [r10-0x80]                    
    ldxdw r4, [r10-0x98]                    
    ldxdw r5, [r10-0x90]                    
    syscall [invalid]                       
    jne r0, 0, lbb_40604                            if r0 != (0 as i32 as i64 as u64) { pc += 4 }
    mov64 r1, 24                                    r1 = 24 as i32 as i64 as u64
    ldxdw r2, [r10-0x78]                    
    stxw [r2+0x0], r1                       
    ja lbb_40607                                    if true { pc += 3 }
lbb_40604:
    ldxdw r1, [r10-0x78]                    
    mov64 r2, r0                                    r2 = r0
    call function_40728                     
lbb_40607:
    ldxdw r2, [r10-0x48]                    
    jeq r2, 0, lbb_40613                            if r2 == (0 as i32 as i64 as u64) { pc += 4 }
    mul64 r2, 34                                    r2 *= 34   ///  r2 = r2.wrapping_mul(34 as u64)
    ldxdw r1, [r10-0x50]                    
    mov64 r3, 1                                     r3 = 1 as i32 as i64 as u64
    call function_21385                     
lbb_40613:
    ldxdw r2, [r10-0x30]                    
    jeq r2, 0, lbb_40618                            if r2 == (0 as i32 as i64 as u64) { pc += 3 }
    ldxdw r1, [r10-0x38]                    
    mov64 r3, 1                                     r3 = 1 as i32 as i64 as u64
    call function_21385                     
lbb_40618:
    exit                                    
lbb_40619:
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    mov64 r2, r6                                    r2 = r6
    call function_43400                     
    syscall [invalid]                       

function_40623:
    ldxw r2, [r1+0x0]                       
    jsgt r2, 11, lbb_40634                          if (r2 as i64) > (11 as i32 as i64) { pc += 9 }
    jsgt r2, 5, lbb_40641                           if (r2 as i64) > (5 as i32 as i64) { pc += 15 }
    jsgt r2, 2, lbb_40653                           if (r2 as i64) > (2 as i32 as i64) { pc += 26 }
    jeq r2, 0, lbb_40673                            if r2 == (0 as i32 as i64 as u64) { pc += 45 }
    lddw r6, 0x200000000                            r6 load str located at 8589934592
    jeq r2, 1, lbb_40720                            if r2 == (1 as i32 as i64 as u64) { pc += 89 }
    lddw r6, 0x300000000                            r6 load str located at 12884901888
    ja lbb_40720                                    if true { pc += 86 }
lbb_40634:
    jsgt r2, 17, lbb_40647                          if (r2 as i64) > (17 as i32 as i64) { pc += 12 }
    jsgt r2, 14, lbb_40658                          if (r2 as i64) > (14 as i32 as i64) { pc += 22 }
    jeq r2, 12, lbb_40679                           if r2 == (12 as i32 as i64 as u64) { pc += 42 }
    jeq r2, 13, lbb_40682                           if r2 == (13 as i32 as i64 as u64) { pc += 44 }
    lddw r6, 0xf00000000                            r6 load str located at 64424509440
    ja lbb_40720                                    if true { pc += 79 }
lbb_40641:
    jsgt r2, 8, lbb_40663                           if (r2 as i64) > (8 as i32 as i64) { pc += 21 }
    jeq r2, 6, lbb_40685                            if r2 == (6 as i32 as i64 as u64) { pc += 42 }
    jeq r2, 7, lbb_40688                            if r2 == (7 as i32 as i64 as u64) { pc += 44 }
    lddw r6, 0x900000000                            r6 load str located at 38654705664
    ja lbb_40720                                    if true { pc += 73 }
lbb_40647:
    jsgt r2, 20, lbb_40668                          if (r2 as i64) > (20 as i32 as i64) { pc += 20 }
    jeq r2, 18, lbb_40691                           if r2 == (18 as i32 as i64 as u64) { pc += 42 }
    jeq r2, 19, lbb_40694                           if r2 == (19 as i32 as i64 as u64) { pc += 44 }
    lddw r6, 0x1500000000                           r6 load str located at 90194313216
    ja lbb_40720                                    if true { pc += 67 }
lbb_40653:
    jeq r2, 3, lbb_40697                            if r2 == (3 as i32 as i64 as u64) { pc += 43 }
    jeq r2, 4, lbb_40700                            if r2 == (4 as i32 as i64 as u64) { pc += 45 }
    lddw r6, 0x600000000                            r6 load str located at 25769803776
    ja lbb_40720                                    if true { pc += 62 }
lbb_40658:
    jeq r2, 15, lbb_40703                           if r2 == (15 as i32 as i64 as u64) { pc += 44 }
    jeq r2, 16, lbb_40706                           if r2 == (16 as i32 as i64 as u64) { pc += 46 }
    lddw r6, 0x1200000000                           r6 load str located at 77309411328
    ja lbb_40720                                    if true { pc += 57 }
lbb_40663:
    jeq r2, 9, lbb_40709                            if r2 == (9 as i32 as i64 as u64) { pc += 45 }
    jeq r2, 10, lbb_40712                           if r2 == (10 as i32 as i64 as u64) { pc += 47 }
    lddw r6, 0xc00000000                            r6 load str located at 51539607552
    ja lbb_40720                                    if true { pc += 52 }
lbb_40668:
    jeq r2, 21, lbb_40715                           if r2 == (21 as i32 as i64 as u64) { pc += 46 }
    jeq r2, 22, lbb_40718                           if r2 == (22 as i32 as i64 as u64) { pc += 48 }
    lddw r6, 0x1800000000                           r6 load str located at 103079215104
    ja lbb_40720                                    if true { pc += 47 }
lbb_40673:
    lddw r6, 0x100000000                            r6 load str located at 4294967296
    ldxw r3, [r1+0x4]                       
    jeq r3, 0, lbb_40720                            if r3 == (0 as i32 as i64 as u64) { pc += 43 }
    mov64 r6, r3                                    r6 = r3
    ja lbb_40720                                    if true { pc += 41 }
lbb_40679:
    lddw r6, 0xd00000000                            r6 load str located at 55834574848
    ja lbb_40720                                    if true { pc += 38 }
lbb_40682:
    lddw r6, 0xe00000000                            r6 load str located at 60129542144
    ja lbb_40720                                    if true { pc += 35 }
lbb_40685:
    lddw r6, 0x700000000                            r6 load str located at 30064771072
    ja lbb_40720                                    if true { pc += 32 }
lbb_40688:
    lddw r6, 0x800000000                            r6 load str located at 34359738368
    ja lbb_40720                                    if true { pc += 29 }
lbb_40691:
    lddw r6, 0x1300000000                           r6 load str located at 81604378624
    ja lbb_40720                                    if true { pc += 26 }
lbb_40694:
    lddw r6, 0x1400000000                           r6 load str located at 85899345920
    ja lbb_40720                                    if true { pc += 23 }
lbb_40697:
    lddw r6, 0x400000000                            r6 load str located at 17179869184
    ja lbb_40720                                    if true { pc += 20 }
lbb_40700:
    lddw r6, 0x500000000                            r6 load str located at 21474836480
    ja lbb_40720                                    if true { pc += 17 }
lbb_40703:
    lddw r6, 0x1000000000                           r6 load str located at 68719476736
    ja lbb_40720                                    if true { pc += 14 }
lbb_40706:
    lddw r6, 0x1100000000                           r6 load str located at 73014444032
    ja lbb_40720                                    if true { pc += 11 }
lbb_40709:
    lddw r6, 0xa00000000                            r6 load str located at 42949672960
    ja lbb_40720                                    if true { pc += 8 }
lbb_40712:
    lddw r6, 0xb00000000                            r6 load str located at 47244640256
    ja lbb_40720                                    if true { pc += 5 }
lbb_40715:
    lddw r6, 0x1600000000                           r6 load str located at 94489280512
    ja lbb_40720                                    if true { pc += 2 }
lbb_40718:
    lddw r6, 0x1700000000                           r6 load str located at 98784247808
lbb_40720:
    jne r2, 14, lbb_40726                           if r2 != (14 as i32 as i64 as u64) { pc += 5 }
    ldxdw r2, [r1+0x10]                     
    jeq r2, 0, lbb_40726                            if r2 == (0 as i32 as i64 as u64) { pc += 3 }
    ldxdw r1, [r1+0x8]                      
    mov64 r3, 1                                     r3 = 1 as i32 as i64 as u64
    call function_21385                     
lbb_40726:
    mov64 r0, r6                                    r0 = r6
    exit                                    

function_40728:
    mov64 r6, r1                                    r6 = r1
    lddw r1, 0xffffffff00000000                     r1 load str located at -4294967296
    mov64 r3, r2                                    r3 = r2
    add64 r3, r1                                    r3 += r1   ///  r3 = r3.wrapping_add(r1)
    rsh64 r3, 32                                    r3 >>= 32   ///  r3 = r3.wrapping_shr(32)
    mov64 r1, r2                                    r1 = r2
    lsh64 r1, 32                                    r1 <<= 32   ///  r1 = r1.wrapping_shl(32)
    or64 r1, r3                                     r1 |= r3   ///  r1 = r1.or(r3)
    jsgt r1, 11, lbb_40747                          if (r1 as i64) > (11 as i32 as i64) { pc += 9 }
    jsgt r1, 5, lbb_40762                           if (r1 as i64) > (5 as i32 as i64) { pc += 23 }
    jsgt r1, 2, lbb_40776                           if (r1 as i64) > (2 as i32 as i64) { pc += 36 }
    jeq r1, 0, lbb_40800                            if r1 == (0 as i32 as i64 as u64) { pc += 59 }
    mov64 r3, 1                                     r3 = 1 as i32 as i64 as u64
    jeq r1, 1, lbb_40841                            if r1 == (1 as i32 as i64 as u64) { pc += 98 }
    jeq r1, 2, lbb_40745                            if r1 == (2 as i32 as i64 as u64) { pc += 1 }
    ja lbb_40797                                    if true { pc += 52 }
lbb_40745:
    mov64 r3, 2                                     r3 = 2 as i32 as i64 as u64
    ja lbb_40841                                    if true { pc += 94 }
lbb_40747:
    jsgt r1, 17, lbb_40769                          if (r1 as i64) > (17 as i32 as i64) { pc += 21 }
    jsgt r1, 14, lbb_40782                          if (r1 as i64) > (14 as i32 as i64) { pc += 33 }
    jeq r1, 12, lbb_40803                           if r1 == (12 as i32 as i64 as u64) { pc += 53 }
    jeq r1, 13, lbb_40805                           if r1 == (13 as i32 as i64 as u64) { pc += 54 }
    jeq r1, 14, lbb_40753                           if r1 == (14 as i32 as i64 as u64) { pc += 1 }
    ja lbb_40797                                    if true { pc += 44 }
lbb_40753:
    mov64 r7, 7                                     r7 = 7 as i32 as i64 as u64
    mov64 r1, 7                                     r1 = 7 as i32 as i64 as u64
    mov64 r2, 1                                     r2 = 1 as i32 as i64 as u64
    call function_21359                     
    jne r0, 0, lbb_40833                            if r0 != (0 as i32 as i64 as u64) { pc += 75 }
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    mov64 r2, 7                                     r2 = 7 as i32 as i64 as u64
    call function_43400                     
    syscall [invalid]                       
lbb_40762:
    jsgt r1, 8, lbb_40788                           if (r1 as i64) > (8 as i32 as i64) { pc += 25 }
    jeq r1, 6, lbb_40807                            if r1 == (6 as i32 as i64 as u64) { pc += 43 }
    jeq r1, 7, lbb_40809                            if r1 == (7 as i32 as i64 as u64) { pc += 44 }
    jeq r1, 8, lbb_40767                            if r1 == (8 as i32 as i64 as u64) { pc += 1 }
    ja lbb_40797                                    if true { pc += 30 }
lbb_40767:
    mov64 r3, 8                                     r3 = 8 as i32 as i64 as u64
    ja lbb_40841                                    if true { pc += 72 }
lbb_40769:
    jsgt r1, 20, lbb_40794                          if (r1 as i64) > (20 as i32 as i64) { pc += 24 }
    jeq r1, 18, lbb_40811                           if r1 == (18 as i32 as i64 as u64) { pc += 40 }
    jeq r1, 19, lbb_40813                           if r1 == (19 as i32 as i64 as u64) { pc += 41 }
    jeq r1, 20, lbb_40774                           if r1 == (20 as i32 as i64 as u64) { pc += 1 }
    ja lbb_40797                                    if true { pc += 23 }
lbb_40774:
    mov64 r3, 20                                    r3 = 20 as i32 as i64 as u64
    ja lbb_40841                                    if true { pc += 65 }
lbb_40776:
    jeq r1, 3, lbb_40815                            if r1 == (3 as i32 as i64 as u64) { pc += 38 }
    jeq r1, 4, lbb_40817                            if r1 == (4 as i32 as i64 as u64) { pc += 39 }
    jeq r1, 5, lbb_40780                            if r1 == (5 as i32 as i64 as u64) { pc += 1 }
    ja lbb_40797                                    if true { pc += 17 }
lbb_40780:
    mov64 r3, 5                                     r3 = 5 as i32 as i64 as u64
    ja lbb_40841                                    if true { pc += 59 }
lbb_40782:
    jeq r1, 15, lbb_40819                           if r1 == (15 as i32 as i64 as u64) { pc += 36 }
    jeq r1, 16, lbb_40821                           if r1 == (16 as i32 as i64 as u64) { pc += 37 }
    jeq r1, 17, lbb_40786                           if r1 == (17 as i32 as i64 as u64) { pc += 1 }
    ja lbb_40797                                    if true { pc += 11 }
lbb_40786:
    mov64 r3, 17                                    r3 = 17 as i32 as i64 as u64
    ja lbb_40841                                    if true { pc += 53 }
lbb_40788:
    jeq r1, 9, lbb_40823                            if r1 == (9 as i32 as i64 as u64) { pc += 34 }
    jeq r1, 10, lbb_40825                           if r1 == (10 as i32 as i64 as u64) { pc += 35 }
    jeq r1, 11, lbb_40792                           if r1 == (11 as i32 as i64 as u64) { pc += 1 }
    ja lbb_40797                                    if true { pc += 5 }
lbb_40792:
    mov64 r3, 11                                    r3 = 11 as i32 as i64 as u64
    ja lbb_40841                                    if true { pc += 47 }
lbb_40794:
    jeq r1, 21, lbb_40827                           if r1 == (21 as i32 as i64 as u64) { pc += 32 }
    jeq r1, 22, lbb_40829                           if r1 == (22 as i32 as i64 as u64) { pc += 33 }
    jeq r1, 23, lbb_40831                           if r1 == (23 as i32 as i64 as u64) { pc += 34 }
lbb_40797:
    stxw [r6+0x4], r2                       
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
    ja lbb_40841                                    if true { pc += 41 }
lbb_40800:
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
    stxw [r6+0x4], r3                       
    ja lbb_40841                                    if true { pc += 38 }
lbb_40803:
    mov64 r3, 12                                    r3 = 12 as i32 as i64 as u64
    ja lbb_40841                                    if true { pc += 36 }
lbb_40805:
    mov64 r3, 13                                    r3 = 13 as i32 as i64 as u64
    ja lbb_40841                                    if true { pc += 34 }
lbb_40807:
    mov64 r3, 6                                     r3 = 6 as i32 as i64 as u64
    ja lbb_40841                                    if true { pc += 32 }
lbb_40809:
    mov64 r3, 7                                     r3 = 7 as i32 as i64 as u64
    ja lbb_40841                                    if true { pc += 30 }
lbb_40811:
    mov64 r3, 18                                    r3 = 18 as i32 as i64 as u64
    ja lbb_40841                                    if true { pc += 28 }
lbb_40813:
    mov64 r3, 19                                    r3 = 19 as i32 as i64 as u64
    ja lbb_40841                                    if true { pc += 26 }
lbb_40815:
    mov64 r3, 3                                     r3 = 3 as i32 as i64 as u64
    ja lbb_40841                                    if true { pc += 24 }
lbb_40817:
    mov64 r3, 4                                     r3 = 4 as i32 as i64 as u64
    ja lbb_40841                                    if true { pc += 22 }
lbb_40819:
    mov64 r3, 15                                    r3 = 15 as i32 as i64 as u64
    ja lbb_40841                                    if true { pc += 20 }
lbb_40821:
    mov64 r3, 16                                    r3 = 16 as i32 as i64 as u64
    ja lbb_40841                                    if true { pc += 18 }
lbb_40823:
    mov64 r3, 9                                     r3 = 9 as i32 as i64 as u64
    ja lbb_40841                                    if true { pc += 16 }
lbb_40825:
    mov64 r3, 10                                    r3 = 10 as i32 as i64 as u64
    ja lbb_40841                                    if true { pc += 14 }
lbb_40827:
    mov64 r3, 21                                    r3 = 21 as i32 as i64 as u64
    ja lbb_40841                                    if true { pc += 12 }
lbb_40829:
    mov64 r3, 22                                    r3 = 22 as i32 as i64 as u64
    ja lbb_40841                                    if true { pc += 10 }
lbb_40831:
    mov64 r3, 23                                    r3 = 23 as i32 as i64 as u64
    ja lbb_40841                                    if true { pc += 8 }
lbb_40833:
    mov64 r1, 1853321070                            r1 = 1853321070 as i32 as i64 as u64
    stxw [r0+0x3], r1                       
    mov64 r1, 1852534357                            r1 = 1852534357 as i32 as i64 as u64
    stxw [r0+0x0], r1                       
    stxdw [r6+0x18], r7                     
    stxdw [r6+0x10], r7                     
    stxdw [r6+0x8], r0                      
    mov64 r3, 14                                    r3 = 14 as i32 as i64 as u64
lbb_40841:
    stxw [r6+0x0], r3                       
    exit                                    

function_40843:
    mov64 r0, r4                                    r0 = r4
    mov64 r6, r1                                    r6 = r1
    mov64 r7, 0                                     r7 = 0 as i32 as i64 as u64
    stxdw [r10-0x18], r7                    
    stxdw [r10-0x20], r7                    
    stxdw [r10-0x28], r7                    
    stxdw [r10-0x30], r7                    
    mov64 r1, 255                                   r1 = 255 as i32 as i64 as u64
    stxb [r10-0x31], r1                     
    mov64 r4, r10                                   r4 = r10
    add64 r4, -48                                   r4 += -48   ///  r4 = r4.wrapping_add(-48 as i32 as i64 as u64)
    mov64 r5, r10                                   r5 = r10
    add64 r5, -49                                   r5 += -49   ///  r5 = r5.wrapping_add(-49 as i32 as i64 as u64)
    mov64 r1, r2                                    r1 = r2
    mov64 r2, r3                                    r2 = r3
    mov64 r3, r0                                    r3 = r0
    syscall [invalid]                       
    jeq r0, 0, lbb_40877                            if r0 == (0 as i32 as i64 as u64) { pc += 16 }
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    stxdw [r10-0x28], r1                    
    lddw r1, 0x100066f30 --> b"\x00\x00\x00\x00~2\x06\x001\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00q2…        r1 load str located at 4295388976
    stxdw [r10-0x30], r1                    
    stxdw [r10-0x10], r7                    
    stxdw [r10-0x18], r7                    
    lddw r1, 0x100063450 --> b"Custom program error: The arguments provided to a "        r1 load str located at 4295373904
    stxdw [r10-0x20], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -48                                   r1 += -48   ///  r1 = r1.wrapping_add(-48 as i32 as i64 as u64)
    lddw r2, 0x100066f40 --> b"\x00\x00\x00\x00q2\x06\x00\x0d\x00\x00\x00\x00\x00\x00\x00\xe2\x01\x00\x0…        r2 load str located at 4295388992
    call function_44240                     
    syscall [invalid]                       
lbb_40877:
    ldxb r1, [r10-0x31]                     
    ldxdw r2, [r10-0x30]                    
    ldxdw r3, [r10-0x28]                    
    ldxdw r4, [r10-0x20]                    
    ldxdw r5, [r10-0x18]                    
    stxdw [r6+0x18], r5                     
    stxdw [r6+0x10], r4                     
    stxdw [r6+0x8], r3                      
    stxdw [r6+0x0], r2                      
    stxb [r6+0x20], r1                      
    exit                                    

function_40888:
    mov64 r6, r1                                    r6 = r1
    jgt r3, 16, lbb_40917                           if r3 > (16 as i32 as i64 as u64) { pc += 27 }
    mov64 r1, r3                                    r1 = r3
    lsh64 r1, 4                                     r1 <<= 4   ///  r1 = r1.wrapping_shl(4)
    mov64 r5, r2                                    r5 = r2
    ja lbb_40898                                    if true { pc += 4 }
lbb_40894:
    add64 r1, -16                                   r1 += -16   ///  r1 = r1.wrapping_add(-16 as i32 as i64 as u64)
    ldxdw r0, [r5+0x8]                      
    add64 r5, 16                                    r5 += 16   ///  r5 = r5.wrapping_add(16 as i32 as i64 as u64)
    jgt r0, 32, lbb_40917                           if r0 > (32 as i32 as i64 as u64) { pc += 19 }
lbb_40898:
    jne r1, 0, lbb_40894                            if r1 != (0 as i32 as i64 as u64) { pc += -5 }
    mov64 r7, 0                                     r7 = 0 as i32 as i64 as u64
    stxdw [r10-0x38], r7                    
    stxdw [r10-0x40], r7                    
    stxdw [r10-0x48], r7                    
    stxdw [r10-0x50], r7                    
    mov64 r5, r10                                   r5 = r10
    add64 r5, -80                                   r5 += -80   ///  r5 = r5.wrapping_add(-80 as i32 as i64 as u64)
    mov64 r1, r2                                    r1 = r2
    mov64 r2, r3                                    r2 = r3
    mov64 r3, r4                                    r3 = r4
    mov64 r4, r5                                    r4 = r5
    syscall [invalid]                       
    jeq r0, 0, lbb_40920                            if r0 == (0 as i32 as i64 as u64) { pc += 8 }
    jeq r0, 1, lbb_40914                            if r0 == (1 as i32 as i64 as u64) { pc += 1 }
    ja lbb_40930                                    if true { pc += 16 }
lbb_40914:
    mov64 r7, 1                                     r7 = 1 as i32 as i64 as u64
    stxb [r6+0x1], r7                       
    ja lbb_40928                                    if true { pc += 11 }
lbb_40917:
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    stxh [r6+0x0], r1                       
    ja lbb_40929                                    if true { pc += 9 }
lbb_40920:
    ldxdw r1, [r10-0x50]                    
    ldxdw r2, [r10-0x48]                    
    ldxdw r3, [r10-0x40]                    
    ldxdw r4, [r10-0x38]                    
    stxdw [r6+0x19], r4                     
    stxdw [r6+0x11], r3                     
    stxdw [r6+0x9], r2                      
    stxdw [r6+0x1], r1                      
lbb_40928:
    stxb [r6+0x0], r7                       
lbb_40929:
    exit                                    
lbb_40930:
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    stxdw [r10-0x28], r1                    
    lddw r1, 0x100066f08 --> b"\x00\x00\x00\x00Z2\x06\x00\x17\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x0…        r1 load str located at 4295388936
    stxdw [r10-0x30], r1                    
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    stxdw [r10-0x10], r1                    
    stxdw [r10-0x18], r1                    
    lddw r1, 0x100063450 --> b"Custom program error: The arguments provided to a "        r1 load str located at 4295373904
    stxdw [r10-0x20], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -48                                   r1 += -48   ///  r1 = r1.wrapping_add(-48 as i32 as i64 as u64)
    lddw r2, 0x100066f18 --> b"\x00\x00\x00\x00q2\x06\x00\x0d\x00\x00\x00\x00\x00\x00\x000\x00\x00\x00\x…        r2 load str located at 4295388952
    call function_44240                     
    syscall [invalid]                       

function_40947:
    mov64 r6, r5                                    r6 = r5
    mov64 r7, r1                                    r7 = r1
    ldxdw r9, [r2+0x0]                      
    mov64 r8, r9                                    r8 = r9
    add64 r8, r6                                    r8 += r6   ///  r8 = r8.wrapping_add(r6)
    jgt r8, r4, lbb_40960                           if r8 > r4 { pc += 7 }
    jge r8, r9, lbb_40964                           if r8 >= r9 { pc += 10 }
    mov64 r1, r9                                    r1 = r9
    mov64 r2, r8                                    r2 = r8
    lddw r3, 0x100066fa0 --> b"\x00\x00\x00\x00\xaf2\x06\x00\x16\x00\x00\x00\x00\x00\x00\x00A\x00\x00\x0…        r3 load str located at 4295389088
    call function_46562                     
    syscall [invalid]                       
lbb_40960:
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    stxdw [r7+0x0], r1                      
    stxb [r7+0x8], r1                       
    ja lbb_40986                                    if true { pc += 22 }
lbb_40964:
    stxdw [r10-0x8], r2                     
    mov64 r0, 1                                     r0 = 1 as i32 as i64 as u64
    jeq r6, 0, lbb_40975                            if r6 == (0 as i32 as i64 as u64) { pc += 8 }
    stxdw [r10-0x10], r3                    
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    jsgt r1, r6, lbb_40987                          if (r1 as i64) > (r6 as i64) { pc += 17 }
    mov64 r1, r6                                    r1 = r6
    mov64 r2, 1                                     r2 = 1 as i32 as i64 as u64
    call function_21359                     
    ldxdw r3, [r10-0x10]                    
    jeq r0, 0, lbb_40989                            if r0 == (0 as i32 as i64 as u64) { pc += 14 }
lbb_40975:
    add64 r3, r9                                    r3 += r9   ///  r3 = r3.wrapping_add(r9)
    mov64 r9, r0                                    r9 = r0
    mov64 r1, r9                                    r1 = r9
    mov64 r2, r3                                    r2 = r3
    mov64 r3, r6                                    r3 = r6
    call function_48190                     
    ldxdw r1, [r10-0x8]                     
    stxdw [r1+0x0], r8                      
    stxdw [r7+0x0], r9                      
    stxdw [r7+0x8], r6                      
    stxdw [r7+0x10], r6                     
lbb_40986:
    exit                                    
lbb_40987:
    call function_43383                     
    syscall [invalid]                       
lbb_40989:
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    mov64 r2, r6                                    r2 = r6
    call function_43400                     
    syscall [invalid]                       

function_40993:
    mov64 r6, r5                                    r6 = r5
    mov64 r7, r4                                    r7 = r4
    mov64 r8, r3                                    r8 = r3
    mov64 r9, r2                                    r9 = r2
    stxdw [r10-0x90], r1                    
    mov64 r1, 68                                    r1 = 68 as i32 as i64 as u64
    mov64 r2, 1                                     r2 = 1 as i32 as i64 as u64
    call function_21359                     
    jne r0, 0, lbb_41006                            if r0 != (0 as i32 as i64 as u64) { pc += 4 }
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    mov64 r2, 68                                    r2 = 68 as i32 as i64 as u64
    call function_43400                     
    syscall [invalid]                       
lbb_41006:
    ldxdw r1, [r6-0xff8]                    
    ldxdw r2, [r6-0x1000]                   
    ldxdw r3, [r9+0x18]                     
    stxdw [r0+0x18], r3                     
    ldxdw r3, [r9+0x10]                     
    stxdw [r0+0x10], r3                     
    ldxdw r3, [r9+0x8]                      
    stxdw [r0+0x8], r3                      
    ldxdw r3, [r9+0x0]                      
    stxdw [r0+0x0], r3                      
    mov64 r3, 257                                   r3 = 257 as i32 as i64 as u64
    stxh [r0+0x20], r3                      
    ldxdw r4, [r8+0x0]                      
    stxdw [r0+0x22], r4                     
    ldxdw r4, [r8+0x8]                      
    stxdw [r0+0x2a], r4                     
    ldxdw r4, [r8+0x10]                     
    stxdw [r0+0x32], r4                     
    ldxdw r4, [r8+0x18]                     
    stxdw [r0+0x3a], r4                     
    stxh [r0+0x42], r3                      
    mov64 r3, 2                                     r3 = 2 as i32 as i64 as u64
    stxdw [r10-0x78], r3                    
    stxdw [r10-0x80], r3                    
    stxdw [r10-0x88], r0                    
    stxdw [r10-0x60], r2                    
    stxdw [r10-0x68], r7                    
    ldxdw r2, [r1+0x0]                      
    stxdw [r10-0x58], r2                    
    ldxdw r2, [r1+0x8]                      
    stxdw [r10-0x50], r2                    
    ldxdw r2, [r1+0x10]                     
    stxdw [r10-0x48], r2                    
    ldxdw r1, [r1+0x18]                     
    stxdw [r10-0x40], r1                    
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    stxb [r10-0x70], r1                     
    mov64 r3, r10                                   r3 = r10
    add64 r3, -112                                  r3 += -112   ///  r3 = r3.wrapping_add(-112 as i32 as i64 as u64)
    mov64 r4, r10                                   r4 = r10
    add64 r4, -136                                  r4 += -136   ///  r4 = r4.wrapping_add(-136 as i32 as i64 as u64)
    ldxdw r1, [r10-0x90]                    
    lddw r2, 0x10005ff70 --> b"\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\…        r2 load str located at 4295360368
    call function_39497                     
    exit                                    

function_41052:
    mov64 r6, r4                                    r6 = r4
    mov64 r5, r1                                    r5 = r1
    mov64 r1, 2                                     r1 = 2 as i32 as i64 as u64
    jgt r1, r6, lbb_41088                           if r1 > r6 { pc += 32 }
    ldxh r1, [r3+0x0]                       
    jgt r1, r2, lbb_41059                           if r1 > r2 { pc += 1 }
    ja lbb_41088                                    if true { pc += 29 }
lbb_41059:
    lsh64 r2, 1                                     r2 <<= 1   ///  r2 = r2.wrapping_shl(1)
    mov64 r4, r2                                    r4 = r2
    add64 r4, 4                                     r4 += 4   ///  r4 = r4.wrapping_add(4 as i32 as i64 as u64)
    jgt r4, r6, lbb_41088                           if r4 > r6 { pc += 25 }
    add64 r2, 2                                     r2 += 2   ///  r2 = r2.wrapping_add(2 as i32 as i64 as u64)
    jne r2, -2, lbb_41071                           if r2 != (-2 as i32 as i64 as u64) { pc += 6 }
    mov64 r1, r2                                    r1 = r2
    mov64 r2, r4                                    r2 = r4
    lddw r3, 0x100066f88 --> b"\x00\x00\x00\x00\xaf2\x06\x00\x16\x00\x00\x00\x00\x00\x00\x003\x00\x00\x0…        r3 load str located at 4295389064
    call function_46562                     
    syscall [invalid]                       
lbb_41071:
    mov64 r1, r3                                    r1 = r3
    add64 r1, r2                                    r1 += r2   ///  r1 = r1.wrapping_add(r2)
    ldxh r7, [r1+0x0]                       
    mov64 r0, r7                                    r0 = r7
    add64 r0, 2                                     r0 += 2   ///  r0 = r0.wrapping_add(2 as i32 as i64 as u64)
    jgt r0, r6, lbb_41088                           if r0 > r6 { pc += 11 }
    mov64 r1, r3                                    r1 = r3
    add64 r1, r7                                    r1 += r7   ///  r1 = r1.wrapping_add(r7)
    ldxh r8, [r1+0x0]                       
    stxdw [r10-0x140], r6                   
    jne r8, 0, lbb_41092                            if r8 != (0 as i32 as i64 as u64) { pc += 10 }
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    stxdw [r10-0x20], r1                    
    stxdw [r10-0x28], r8                    
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    stxdw [r10-0x30], r1                    
    ja lbb_41352                                    if true { pc += 264 }
lbb_41088:
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    stxdw [r5+0x0], r1                      
    stxb [r5+0x8], r1                       
lbb_41091:
    exit                                    
lbb_41092:
    stxdw [r10-0x148], r3                   
    stxdw [r10-0x158], r5                   
    mov64 r9, r8                                    r9 = r8
    mul64 r9, 34                                    r9 *= 34   ///  r9 = r9.wrapping_mul(34 as u64)
    mov64 r1, r9                                    r1 = r9
    mov64 r2, 1                                     r2 = 1 as i32 as i64 as u64
    call function_21359                     
    jne r0, 0, lbb_41104                            if r0 != (0 as i32 as i64 as u64) { pc += 4 }
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    mov64 r2, r9                                    r2 = r9
    call function_43400                     
    syscall [invalid]                       
lbb_41104:
    stxdw [r10-0x28], r8                    
    stxdw [r10-0x48], r0                    
    stxdw [r10-0x30], r0                    
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
    stxdw [r10-0x20], r2                    
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    stxdw [r10-0x40], r1                    
    stxdw [r10-0x150], r8                   
    ja lbb_41232                                    if true { pc += 119 }
lbb_41113:
    ldxdw r0, [r10-0x40]                    
    add64 r0, 1                                     r0 += 1   ///  r0 = r0.wrapping_add(1 as i32 as i64 as u64)
    ldxdw r1, [r10-0x138]                   
    lsh64 r1, 16                                    r1 <<= 16   ///  r1 = r1.wrapping_shl(16)
    lsh64 r8, 24                                    r8 <<= 24   ///  r8 = r8.wrapping_shl(24)
    or64 r8, r1                                     r8 |= r1   ///  r8 = r8.or(r1)
    mov64 r3, r4                                    r3 = r4
    lsh64 r7, 8                                     r7 <<= 8   ///  r7 = r7.wrapping_shl(8)
    or64 r3, r7                                     r3 |= r7   ///  r3 = r3.or(r7)
    mov64 r4, r2                                    r4 = r2
    mul64 r4, 34                                    r4 *= 34   ///  r4 = r4.wrapping_mul(34 as u64)
    stxdw [r10-0x48], r5                    
    mov64 r1, r5                                    r1 = r5
    add64 r1, r4                                    r1 += r4   ///  r1 = r1.wrapping_add(r4)
    stxb [r1+0x21], r6                      
    ldxdw r4, [r10-0x110]                   
    stxb [r1+0x20], r4                      
    ldxdw r4, [r10-0x130]                   
    stxb [r1+0x0], r4                       
    and64 r3, 65535                                 r3 &= 65535   ///  r3 = r3.and(65535)
    or64 r3, r8                                     r3 |= r8   ///  r3 = r3.or(r8)
    ldxdw r4, [r10-0x128]                   
    lsh64 r4, 16                                    r4 <<= 16   ///  r4 = r4.wrapping_shl(16)
    lsh64 r9, 24                                    r9 <<= 24   ///  r9 = r9.wrapping_shl(24)
    or64 r9, r4                                     r9 |= r4   ///  r9 = r9.or(r4)
    ldxdw r4, [r10-0x120]                   
    ldxdw r5, [r10-0x118]                   
    lsh64 r5, 8                                     r5 <<= 8   ///  r5 = r5.wrapping_shl(8)
    or64 r4, r5                                     r4 |= r5   ///  r4 = r4.or(r5)
    and64 r4, 65535                                 r4 &= 65535   ///  r4 = r4.and(65535)
    or64 r4, r9                                     r4 |= r9   ///  r4 = r4.or(r9)
    lsh64 r4, 32                                    r4 <<= 32   ///  r4 = r4.wrapping_shl(32)
    rsh64 r4, 32                                    r4 >>= 32   ///  r4 = r4.wrapping_shr(32)
    lsh64 r3, 32                                    r3 <<= 32   ///  r3 = r3.wrapping_shl(32)
    or64 r4, r3                                     r4 |= r3   ///  r4 = r4.or(r3)
    ldxdw r3, [r10-0x108]                   
    lsh64 r3, 16                                    r3 <<= 16   ///  r3 = r3.wrapping_shl(16)
    ldxdw r6, [r10-0xd0]                    
    lsh64 r6, 24                                    r6 <<= 24   ///  r6 = r6.wrapping_shl(24)
    or64 r6, r3                                     r6 |= r3   ///  r6 = r6.or(r3)
    ldxdw r3, [r10-0x100]                   
    ldxdw r5, [r10-0xf8]                    
    lsh64 r5, 8                                     r5 <<= 8   ///  r5 = r5.wrapping_shl(8)
    or64 r3, r5                                     r3 |= r5   ///  r3 = r3.or(r5)
    ldxdw r5, [r10-0xf0]                    
    lsh64 r5, 16                                    r5 <<= 16   ///  r5 = r5.wrapping_shl(16)
    ldxdw r7, [r10-0xd8]                    
    lsh64 r7, 24                                    r7 <<= 24   ///  r7 = r7.wrapping_shl(24)
    or64 r7, r5                                     r7 |= r5   ///  r7 = r7.or(r5)
    ldxdw r5, [r10-0xe8]                    
    ldxdw r8, [r10-0xe0]                    
    lsh64 r8, 8                                     r8 <<= 8   ///  r8 = r8.wrapping_shl(8)
    or64 r5, r8                                     r5 |= r8   ///  r5 = r5.or(r8)
    and64 r5, 65535                                 r5 &= 65535   ///  r5 = r5.and(65535)
    or64 r5, r7                                     r5 |= r7   ///  r5 = r5.or(r7)
    and64 r3, 65535                                 r3 &= 65535   ///  r3 = r3.and(65535)
    or64 r3, r6                                     r3 |= r6   ///  r3 = r3.or(r6)
    stxdw [r1+0x1], r4                      
    ldxdw r4, [r10-0xc8]                    
    lsh64 r4, 16                                    r4 <<= 16   ///  r4 = r4.wrapping_shl(16)
    ldxdw r6, [r10-0xa8]                    
    lsh64 r6, 24                                    r6 <<= 24   ///  r6 = r6.wrapping_shl(24)
    or64 r6, r4                                     r6 |= r4   ///  r6 = r6.or(r4)
    ldxdw r4, [r10-0xc0]                    
    ldxdw r7, [r10-0xb8]                    
    lsh64 r7, 8                                     r7 <<= 8   ///  r7 = r7.wrapping_shl(8)
    or64 r4, r7                                     r4 |= r7   ///  r4 = r4.or(r7)
    lsh64 r3, 32                                    r3 <<= 32   ///  r3 = r3.wrapping_shl(32)
    rsh64 r3, 32                                    r3 >>= 32   ///  r3 = r3.wrapping_shr(32)
    lsh64 r5, 32                                    r5 <<= 32   ///  r5 = r5.wrapping_shl(32)
    or64 r3, r5                                     r3 |= r5   ///  r3 = r3.or(r5)
    and64 r4, 65535                                 r4 &= 65535   ///  r4 = r4.and(65535)
    or64 r4, r6                                     r4 |= r6   ///  r4 = r4.or(r6)
    ldxdw r5, [r10-0xb0]                    
    lsh64 r5, 16                                    r5 <<= 16   ///  r5 = r5.wrapping_shl(16)
    ldxdw r6, [r10-0x90]                    
    lsh64 r6, 24                                    r6 <<= 24   ///  r6 = r6.wrapping_shl(24)
    or64 r6, r5                                     r6 |= r5   ///  r6 = r6.or(r5)
    ldxdw r5, [r10-0xa0]                    
    ldxdw r7, [r10-0x98]                    
    lsh64 r7, 8                                     r7 <<= 8   ///  r7 = r7.wrapping_shl(8)
    or64 r5, r7                                     r5 |= r7   ///  r5 = r5.or(r7)
    and64 r5, 65535                                 r5 &= 65535   ///  r5 = r5.and(65535)
    or64 r5, r6                                     r5 |= r6   ///  r5 = r5.or(r6)
    stxdw [r1+0x9], r3                      
    lsh64 r5, 32                                    r5 <<= 32   ///  r5 = r5.wrapping_shl(32)
    rsh64 r5, 32                                    r5 >>= 32   ///  r5 = r5.wrapping_shr(32)
    lsh64 r4, 32                                    r4 <<= 32   ///  r4 = r4.wrapping_shl(32)
    or64 r5, r4                                     r5 |= r4   ///  r5 = r5.or(r4)
    ldxdw r3, [r10-0x88]                    
    lsh64 r3, 16                                    r3 <<= 16   ///  r3 = r3.wrapping_shl(16)
    ldxdw r4, [r10-0x70]                    
    lsh64 r4, 24                                    r4 <<= 24   ///  r4 = r4.wrapping_shl(24)
    or64 r4, r3                                     r4 |= r3   ///  r4 = r4.or(r3)
    ldxdw r3, [r10-0x80]                    
    ldxdw r6, [r10-0x78]                    
    lsh64 r6, 8                                     r6 <<= 8   ///  r6 = r6.wrapping_shl(8)
    or64 r3, r6                                     r3 |= r6   ///  r3 = r3.or(r6)
    and64 r3, 65535                                 r3 &= 65535   ///  r3 = r3.and(65535)
    or64 r3, r4                                     r3 |= r4   ///  r3 = r3.or(r4)
    stxdw [r1+0x11], r5                     
    ldxdw r4, [r10-0x68]                    
    stxb [r1+0x1f], r4                      
    stxw [r1+0x19], r3                      
    ldxdw r3, [r10-0x60]                    
    ldxdw r4, [r10-0x58]                    
    lsh64 r4, 8                                     r4 <<= 8   ///  r4 = r4.wrapping_shl(8)
    or64 r3, r4                                     r3 |= r4   ///  r3 = r3.or(r4)
    stxh [r1+0x1d], r3                      
    ldxdw r7, [r10-0x50]                    
    add64 r7, 33                                    r7 += 33   ///  r7 = r7.wrapping_add(33 as i32 as i64 as u64)
    add64 r2, 1                                     r2 += 1   ///  r2 = r2.wrapping_add(1 as i32 as i64 as u64)
    stxdw [r10-0x20], r2                    
    stxdw [r10-0x40], r0                    
    and64 r0, 65535                                 r0 &= 65535   ///  r0 = r0.and(65535)
    ldxdw r6, [r10-0x140]                   
    ldxdw r8, [r10-0x150]                   
    jgt r8, r0, lbb_41232                           if r8 > r0 { pc += 1 }
    ja lbb_41348                                    if true { pc += 116 }
lbb_41232:
    mov64 r3, r7                                    r3 = r7
    add64 r3, 2                                     r3 += 2   ///  r3 = r3.wrapping_add(2 as i32 as i64 as u64)
    mov64 r1, r7                                    r1 = r7
    add64 r1, 3                                     r1 += 3   ///  r1 = r1.wrapping_add(3 as i32 as i64 as u64)
    jgt r1, r6, lbb_41341                           if r1 > r6 { pc += 104 }
    jgt r6, r3, lbb_41245                           if r6 > r3 { pc += 7 }
    add64 r7, 2                                     r7 += 2   ///  r7 = r7.wrapping_add(2 as i32 as i64 as u64)
    mov64 r1, r7                                    r1 = r7
    mov64 r2, r6                                    r2 = r6
    lddw r3, 0x100066f58 --> b"\x00\x00\x00\x00\xaf2\x06\x00\x16\x00\x00\x00\x00\x00\x00\x00\x1e\x00\x00…        r3 load str located at 4295389016
    call function_44272                     
    syscall [invalid]                       
lbb_41245:
    mov64 r3, r7                                    r3 = r7
    add64 r3, 35                                    r3 += 35   ///  r3 = r3.wrapping_add(35 as i32 as i64 as u64)
    jgt r3, r6, lbb_41344                           if r3 > r6 { pc += 96 }
    mov64 r3, -32                                   r3 = -32 as i32 as i64 as u64
    jgt r3, r1, lbb_41258                           if r3 > r1 { pc += 8 }
    mov64 r1, r7                                    r1 = r7
    add64 r1, 3                                     r1 += 3   ///  r1 = r1.wrapping_add(3 as i32 as i64 as u64)
    add64 r7, 35                                    r7 += 35   ///  r7 = r7.wrapping_add(35 as i32 as i64 as u64)
    mov64 r2, r7                                    r2 = r7
    lddw r3, 0x100066f70 --> b"\x00\x00\x00\x00\xaf2\x06\x00\x16\x00\x00\x00\x00\x00\x00\x00(\x00\x00\x0…        r3 load str located at 4295389040
    call function_46562                     
    syscall [invalid]                       
lbb_41258:
    ldxdw r3, [r10-0x148]                   
    mov64 r1, r3                                    r1 = r3
    add64 r1, r7                                    r1 += r7   ///  r1 = r1.wrapping_add(r7)
    ldxb r6, [r1+0x2]                       
    mov64 r1, r6                                    r1 = r6
    and64 r1, 1                                     r1 &= 1   ///  r1 = r1.and(1)
    stxdw [r10-0x110], r1                   
    mov64 r1, r3                                    r1 = r3
    stxdw [r10-0x50], r7                    
    add64 r1, r7                                    r1 += r7   ///  r1 = r1.wrapping_add(r7)
    ldxb r3, [r1+0x22]                      
    stxdw [r10-0x68], r3                    
    ldxb r3, [r1+0x21]                      
    stxdw [r10-0x58], r3                    
    ldxb r3, [r1+0x20]                      
    stxdw [r10-0x60], r3                    
    ldxb r3, [r1+0x1f]                      
    stxdw [r10-0x70], r3                    
    ldxb r3, [r1+0x1e]                      
    stxdw [r10-0x88], r3                    
    ldxb r3, [r1+0x1d]                      
    stxdw [r10-0x78], r3                    
    ldxb r3, [r1+0x1c]                      
    stxdw [r10-0x80], r3                    
    ldxb r3, [r1+0x1b]                      
    stxdw [r10-0xa8], r3                    
    ldxb r3, [r1+0x1a]                      
    stxdw [r10-0xc8], r3                    
    ldxb r3, [r1+0x19]                      
    stxdw [r10-0xb8], r3                    
    ldxb r3, [r1+0x18]                      
    stxdw [r10-0xc0], r3                    
    ldxb r3, [r1+0x17]                      
    stxdw [r10-0x90], r3                    
    ldxb r3, [r1+0x16]                      
    stxdw [r10-0xb0], r3                    
    ldxb r3, [r1+0x15]                      
    stxdw [r10-0x98], r3                    
    ldxb r3, [r1+0x14]                      
    stxdw [r10-0xa0], r3                    
    ldxb r3, [r1+0x13]                      
    stxdw [r10-0xd8], r3                    
    ldxb r3, [r1+0x12]                      
    stxdw [r10-0xf0], r3                    
    ldxb r3, [r1+0x11]                      
    stxdw [r10-0xe0], r3                    
    ldxb r3, [r1+0x10]                      
    stxdw [r10-0xe8], r3                    
    ldxb r3, [r1+0xf]                       
    stxdw [r10-0xd0], r3                    
    ldxb r3, [r1+0xe]                       
    stxdw [r10-0x108], r3                   
    ldxb r3, [r1+0xd]                       
    stxdw [r10-0xf8], r3                    
    ldxb r3, [r1+0xc]                       
    stxdw [r10-0x100], r3                   
    ldxb r8, [r1+0xb]                       
    ldxb r3, [r1+0xa]                       
    stxdw [r10-0x138], r3                   
    ldxb r7, [r1+0x9]                       
    ldxb r4, [r1+0x8]                       
    ldxb r9, [r1+0x7]                       
    ldxb r3, [r1+0x6]                       
    stxdw [r10-0x128], r3                   
    ldxb r3, [r1+0x5]                       
    stxdw [r10-0x118], r3                   
    ldxb r3, [r1+0x4]                       
    stxdw [r10-0x120], r3                   
    rsh64 r6, 1                                     r6 >>= 1   ///  r6 = r6.wrapping_shr(1)
    and64 r6, 1                                     r6 &= 1   ///  r6 = r6.and(1)
    ldxb r1, [r1+0x3]                       
    stxdw [r10-0x130], r1                   
    ldxdw r1, [r10-0x28]                    
    ldxdw r5, [r10-0x48]                    
    jne r2, r1, lbb_41113                           if r2 != r1 { pc += -220 }
    mov64 r1, r10                                   r1 = r10
    add64 r1, -48                                   r1 += -48   ///  r1 = r1.wrapping_add(-48 as i32 as i64 as u64)
    stxdw [r10-0x48], r4                    
    call function_38840                     
    ldxdw r4, [r10-0x48]                    
    ldxdw r5, [r10-0x30]                    
    ldxdw r2, [r10-0x20]                    
    ja lbb_41113                                    if true { pc += -228 }
lbb_41341:
    stxdw [r10-0x38], r3                    
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    ja lbb_41566                                    if true { pc += 222 }
lbb_41344:
    add64 r7, 3                                     r7 += 3   ///  r7 = r7.wrapping_add(3 as i32 as i64 as u64)
    stxdw [r10-0x38], r7                    
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    ja lbb_41566                                    if true { pc += 218 }
lbb_41348:
    add64 r7, 2                                     r7 += 2   ///  r7 = r7.wrapping_add(2 as i32 as i64 as u64)
    mov64 r0, r7                                    r0 = r7
    ldxdw r5, [r10-0x158]                   
    ldxdw r3, [r10-0x148]                   
lbb_41352:
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    stxdw [r10-0x38], r0                    
    mov64 r2, r0                                    r2 = r0
    add64 r2, 32                                    r2 += 32   ///  r2 = r2.wrapping_add(32 as i32 as i64 as u64)
    jgt r2, r6, lbb_41567                           if r2 > r6 { pc += 210 }
    mov64 r4, -32                                   r4 = -32 as i32 as i64 as u64
    jgt r4, r0, lbb_41364                           if r4 > r0 { pc += 5 }
    mov64 r1, r0                                    r1 = r0
    lddw r3, 0x100066f70 --> b"\x00\x00\x00\x00\xaf2\x06\x00\x16\x00\x00\x00\x00\x00\x00\x00(\x00\x00\x0…        r3 load str located at 4295389040
    call function_46562                     
    syscall [invalid]                       
lbb_41364:
    mov64 r4, r3                                    r4 = r3
    add64 r4, r0                                    r4 += r0   ///  r4 = r4.wrapping_add(r0)
    ldxb r6, [r4+0x1f]                      
    stxdw [r10-0x68], r6                    
    ldxb r6, [r4+0x1e]                      
    stxdw [r10-0x40], r6                    
    ldxb r6, [r4+0x1d]                      
    stxdw [r10-0x48], r6                    
    ldxb r6, [r4+0x1c]                      
    stxdw [r10-0x50], r6                    
    ldxb r6, [r4+0x1b]                      
    stxdw [r10-0x70], r6                    
    ldxb r6, [r4+0x1a]                      
    stxdw [r10-0x58], r6                    
    ldxb r6, [r4+0x19]                      
    stxdw [r10-0x60], r6                    
    ldxb r6, [r4+0x18]                      
    stxdw [r10-0x78], r6                    
    ldxb r6, [r4+0x17]                      
    stxdw [r10-0xb8], r6                    
    ldxb r6, [r4+0x16]                      
    stxdw [r10-0xa8], r6                    
    ldxb r6, [r4+0x15]                      
    stxdw [r10-0xb0], r6                    
    ldxb r6, [r4+0x14]                      
    stxdw [r10-0x80], r6                    
    ldxb r6, [r4+0x13]                      
    stxdw [r10-0x98], r6                    
    ldxb r6, [r4+0x12]                      
    stxdw [r10-0x88], r6                    
    ldxb r6, [r4+0x11]                      
    stxdw [r10-0x90], r6                    
    ldxb r6, [r4+0x10]                      
    stxdw [r10-0xa0], r6                    
    ldxb r6, [r4+0xf]                       
    stxdw [r10-0xd8], r6                    
    ldxb r6, [r4+0xe]                       
    stxdw [r10-0xc8], r6                    
    ldxb r6, [r4+0xd]                       
    stxdw [r10-0xd0], r6                    
    ldxb r6, [r4+0xc]                       
    stxdw [r10-0xc0], r6                    
    ldxb r6, [r4+0xb]                       
    stxdw [r10-0xf0], r6                    
    ldxb r6, [r4+0xa]                       
    stxdw [r10-0xe0], r6                    
    ldxb r6, [r4+0x9]                       
    stxdw [r10-0xe8], r6                    
    ldxb r6, [r4+0x8]                       
    ldxb r7, [r4+0x7]                       
    stxdw [r10-0x118], r7                   
    ldxb r7, [r4+0x6]                       
    ldxb r8, [r4+0x5]                       
    stxdw [r10-0x110], r8                   
    ldxb r8, [r4+0x4]                       
    ldxb r9, [r4+0x3]                       
    stxdw [r10-0x100], r9                   
    ldxb r9, [r4+0x2]                       
    stxdw [r10-0xf8], r9                    
    ldxb r9, [r4+0x1]                       
    ldxb r4, [r4+0x0]                       
    stxdw [r10-0x108], r4                   
    stxdw [r10-0x38], r2                    
    add64 r0, 34                                    r0 += 34   ///  r0 = r0.wrapping_add(34 as i32 as i64 as u64)
    ldxdw r4, [r10-0x140]                   
    jgt r0, r4, lbb_41567                           if r0 > r4 { pc += 137 }
    stxdw [r10-0x158], r5                   
    mov64 r1, -2                                    r1 = -2 as i32 as i64 as u64
    jgt r1, r2, lbb_41439                           if r1 > r2 { pc += 6 }
    mov64 r1, r2                                    r1 = r2
    mov64 r2, r0                                    r2 = r0
    lddw r3, 0x100066f88 --> b"\x00\x00\x00\x00\xaf2\x06\x00\x16\x00\x00\x00\x00\x00\x00\x003\x00\x00\x0…        r3 load str located at 4295389064
    call function_46562                     
    syscall [invalid]                       
lbb_41439:
    mov64 r1, r3                                    r1 = r3
    add64 r1, r2                                    r1 += r2   ///  r1 = r1.wrapping_add(r2)
    ldxh r5, [r1+0x0]                       
    stxdw [r10-0x38], r0                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -24                                   r1 += -24   ///  r1 = r1.wrapping_add(-24 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -56                                   r2 += -56   ///  r2 = r2.wrapping_add(-56 as i32 as i64 as u64)
    ldxdw r4, [r10-0x140]                   
    call function_40947                     
    ldxdw r1, [r10-0x18]                    
    jeq r1, 0, lbb_41565                            if r1 == (0 as i32 as i64 as u64) { pc += 114 }
    ldxb r2, [r10-0x10]                     
    ldxdw r3, [r10-0x8]                     
    ldxdw r5, [r10-0x158]                   
    stxdw [r5+0x28], r3                     
    ldxdw r3, [r10-0xf]                     
    stxdw [r5+0x21], r3                     
    ldxdw r3, [r10-0x118]                   
    lsh64 r3, 48                                    r3 <<= 48   ///  r3 = r3.wrapping_shl(48)
    lsh64 r6, 56                                    r6 <<= 56   ///  r6 = r6.wrapping_shl(56)
    or64 r6, r3                                     r6 |= r3   ///  r6 = r6.or(r3)
    ldxdw r3, [r10-0x110]                   
    lsh64 r7, 8                                     r7 <<= 8   ///  r7 = r7.wrapping_shl(8)
    or64 r3, r7                                     r3 |= r7   ///  r3 = r3.or(r7)
    ldxdw r4, [r10-0x20]                    
    stxdw [r5+0x10], r4                     
    ldxdw r4, [r10-0x28]                    
    stxdw [r5+0x8], r4                      
    ldxdw r4, [r10-0x30]                    
    stxdw [r5+0x0], r4                      
    ldxdw r4, [r10-0x108]                   
    stxb [r5+0x30], r4                      
    stxb [r5+0x20], r2                      
    stxdw [r5+0x18], r1                     
    and64 r3, 65535                                 r3 &= 65535   ///  r3 = r3.and(65535)
    lsh64 r3, 32                                    r3 <<= 32   ///  r3 = r3.wrapping_shl(32)
    or64 r6, r3                                     r6 |= r3   ///  r6 = r6.or(r3)
    ldxdw r1, [r10-0x100]                   
    lsh64 r1, 16                                    r1 <<= 16   ///  r1 = r1.wrapping_shl(16)
    lsh64 r8, 24                                    r8 <<= 24   ///  r8 = r8.wrapping_shl(24)
    or64 r8, r1                                     r8 |= r1   ///  r8 = r8.or(r1)
    mov64 r2, r9                                    r2 = r9
    ldxdw r1, [r10-0xf8]                    
    lsh64 r1, 8                                     r1 <<= 8   ///  r1 = r1.wrapping_shl(8)
    or64 r2, r1                                     r2 |= r1   ///  r2 = r2.or(r1)
    and64 r2, 65535                                 r2 &= 65535   ///  r2 = r2.and(65535)
    or64 r2, r8                                     r2 |= r8   ///  r2 = r2.or(r8)
    lsh64 r2, 32                                    r2 <<= 32   ///  r2 = r2.wrapping_shl(32)
    rsh64 r2, 32                                    r2 >>= 32   ///  r2 = r2.wrapping_shr(32)
    or64 r2, r6                                     r2 |= r6   ///  r2 = r2.or(r6)
    ldxdw r1, [r10-0xf0]                    
    lsh64 r1, 16                                    r1 <<= 16   ///  r1 = r1.wrapping_shl(16)
    ldxdw r0, [r10-0xc0]                    
    lsh64 r0, 24                                    r0 <<= 24   ///  r0 = r0.wrapping_shl(24)
    or64 r0, r1                                     r0 |= r1   ///  r0 = r0.or(r1)
    ldxdw r1, [r10-0xe8]                    
    ldxdw r3, [r10-0xe0]                    
    lsh64 r3, 8                                     r3 <<= 8   ///  r3 = r3.wrapping_shl(8)
    or64 r1, r3                                     r1 |= r3   ///  r1 = r1.or(r3)
    ldxdw r3, [r10-0xd8]                    
    lsh64 r3, 48                                    r3 <<= 48   ///  r3 = r3.wrapping_shl(48)
    ldxdw r4, [r10-0xa0]                    
    lsh64 r4, 56                                    r4 <<= 56   ///  r4 = r4.wrapping_shl(56)
    or64 r4, r3                                     r4 |= r3   ///  r4 = r4.or(r3)
    ldxdw r3, [r10-0xd0]                    
    ldxdw r6, [r10-0xc8]                    
    lsh64 r6, 8                                     r6 <<= 8   ///  r6 = r6.wrapping_shl(8)
    or64 r3, r6                                     r3 |= r6   ///  r3 = r3.or(r6)
    and64 r3, 65535                                 r3 &= 65535   ///  r3 = r3.and(65535)
    lsh64 r3, 32                                    r3 <<= 32   ///  r3 = r3.wrapping_shl(32)
    or64 r4, r3                                     r4 |= r3   ///  r4 = r4.or(r3)
    and64 r1, 65535                                 r1 &= 65535   ///  r1 = r1.and(65535)
    or64 r1, r0                                     r1 |= r0   ///  r1 = r1.or(r0)
    stxdw [r5+0x31], r2                     
    ldxdw r2, [r10-0xb8]                    
    lsh64 r2, 48                                    r2 <<= 48   ///  r2 = r2.wrapping_shl(48)
    ldxdw r3, [r10-0x78]                    
    lsh64 r3, 56                                    r3 <<= 56   ///  r3 = r3.wrapping_shl(56)
    or64 r3, r2                                     r3 |= r2   ///  r3 = r3.or(r2)
    ldxdw r2, [r10-0xb0]                    
    ldxdw r0, [r10-0xa8]                    
    lsh64 r0, 8                                     r0 <<= 8   ///  r0 = r0.wrapping_shl(8)
    or64 r2, r0                                     r2 |= r0   ///  r2 = r2.or(r0)
    lsh64 r1, 32                                    r1 <<= 32   ///  r1 = r1.wrapping_shl(32)
    rsh64 r1, 32                                    r1 >>= 32   ///  r1 = r1.wrapping_shr(32)
    or64 r1, r4                                     r1 |= r4   ///  r1 = r1.or(r4)
    and64 r2, 65535                                 r2 &= 65535   ///  r2 = r2.and(65535)
    lsh64 r2, 32                                    r2 <<= 32   ///  r2 = r2.wrapping_shl(32)
    or64 r3, r2                                     r3 |= r2   ///  r3 = r3.or(r2)
    ldxdw r2, [r10-0x98]                    
    lsh64 r2, 16                                    r2 <<= 16   ///  r2 = r2.wrapping_shl(16)
    ldxdw r4, [r10-0x80]                    
    lsh64 r4, 24                                    r4 <<= 24   ///  r4 = r4.wrapping_shl(24)
    or64 r4, r2                                     r4 |= r2   ///  r4 = r4.or(r2)
    ldxdw r2, [r10-0x90]                    
    ldxdw r0, [r10-0x88]                    
    lsh64 r0, 8                                     r0 <<= 8   ///  r0 = r0.wrapping_shl(8)
    or64 r2, r0                                     r2 |= r0   ///  r2 = r2.or(r0)
    and64 r2, 65535                                 r2 &= 65535   ///  r2 = r2.and(65535)
    or64 r2, r4                                     r2 |= r4   ///  r2 = r2.or(r4)
    stxdw [r5+0x39], r1                     
    lsh64 r2, 32                                    r2 <<= 32   ///  r2 = r2.wrapping_shl(32)
    rsh64 r2, 32                                    r2 >>= 32   ///  r2 = r2.wrapping_shr(32)
    or64 r2, r3                                     r2 |= r3   ///  r2 = r2.or(r3)
    stxdw [r5+0x41], r2                     
    ldxdw r1, [r10-0x68]                    
    stxb [r5+0x4f], r1                      
    ldxdw r1, [r10-0x70]                    
    lsh64 r1, 16                                    r1 <<= 16   ///  r1 = r1.wrapping_shl(16)
    ldxdw r2, [r10-0x50]                    
    lsh64 r2, 24                                    r2 <<= 24   ///  r2 = r2.wrapping_shl(24)
    or64 r2, r1                                     r2 |= r1   ///  r2 = r2.or(r1)
    ldxdw r1, [r10-0x60]                    
    ldxdw r3, [r10-0x58]                    
    lsh64 r3, 8                                     r3 <<= 8   ///  r3 = r3.wrapping_shl(8)
    or64 r1, r3                                     r1 |= r3   ///  r1 = r1.or(r3)
    and64 r1, 65535                                 r1 &= 65535   ///  r1 = r1.and(65535)
    or64 r1, r2                                     r1 |= r2   ///  r1 = r1.or(r2)
    stxw [r5+0x49], r1                      
    ldxdw r1, [r10-0x48]                    
    ldxdw r2, [r10-0x40]                    
    lsh64 r2, 8                                     r2 <<= 8   ///  r2 = r2.wrapping_shl(8)
    or64 r1, r2                                     r1 |= r2   ///  r1 = r1.or(r2)
    stxh [r5+0x4d], r1                      
    ja lbb_41091                                    if true { pc += -474 }
lbb_41565:
    ldxb r1, [r10-0x10]                     
lbb_41566:
    ldxdw r5, [r10-0x158]                   
lbb_41567:
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
    stxdw [r5+0x0], r2                      
    stxb [r5+0x8], r1                       
    ldxdw r2, [r10-0x28]                    
    jeq r2, 0, lbb_41091                            if r2 == (0 as i32 as i64 as u64) { pc += -481 }
    mul64 r2, 34                                    r2 *= 34   ///  r2 = r2.wrapping_mul(34 as u64)
    ldxdw r1, [r10-0x30]                    
    mov64 r3, 1                                     r3 = 1 as i32 as i64 as u64
    call function_21385                     
    ja lbb_41091                                    if true { pc += -486 }

function_41577:
    mov64 r6, r1                                    r6 = r1
    ldxdw r1, [r3+0x0]                      
    ldxdw r4, [r1+0x0]                      
    lddw r5, 0x66d17b1817d5a706                     r5 load str located at 7408838205410486022
    jeq r4, r5, lbb_41585                           if r4 == r5 { pc += 2 }
lbb_41583:
    mov64 r4, 1                                     r4 = 1 as i32 as i64 as u64
    ja lbb_41598                                    if true { pc += 13 }
lbb_41585:
    ldxdw r4, [r1+0x8]                      
    lddw r5, 0xc0c2fd5504d4da35                     r5 load str located at -4556801331350414795
    jne r4, r5, lbb_41583                           if r4 != r5 { pc += -6 }
    ldxdw r4, [r1+0x10]                     
    lddw r5, 0xa57556218fc624c1                     r5 load str located at -6524213783030258495
    jne r4, r5, lbb_41583                           if r4 != r5 { pc += -10 }
    mov64 r4, 0                                     r4 = 0 as i32 as i64 as u64
    ldxdw r1, [r1+0x18]                     
    lddw r5, 0x85fcbbadb                            r5 load str located at 35966925531
    jne r1, r5, lbb_41583                           if r1 != r5 { pc += -15 }
lbb_41598:
    jeq r4, 0, lbb_41604                            if r4 == (0 as i32 as i64 as u64) { pc += 5 }
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    stxdw [r6+0x0], r1                      
    mov64 r1, 16                                    r1 = 16 as i32 as i64 as u64
    stxw [r6+0x8], r1                       
    ja lbb_41643                                    if true { pc += 39 }
lbb_41604:
    ldxdw r1, [r3+0x10]                     
    mov64 r7, r1                                    r7 = r1
    add64 r7, 16                                    r7 += 16   ///  r7 = r7.wrapping_add(16 as i32 as i64 as u64)
    ldxdw r3, [r1+0x10]                     
    lddw r4, 0x7fffffffffffffff                     r4 load str located at 9223372036854775807
    jgt r4, r3, lbb_41612                           if r4 > r3 { pc += 1 }
    ja lbb_41627                                    if true { pc += 15 }
lbb_41612:
    add64 r3, 1                                     r3 += 1   ///  r3 = r3.wrapping_add(1 as i32 as i64 as u64)
    stxdw [r1+0x10], r3                     
    ldxdw r4, [r1+0x20]                     
    ldxdw r3, [r1+0x18]                     
    mov64 r1, r10                                   r1 = r10
    add64 r1, -80                                   r1 += -80   ///  r1 = r1.wrapping_add(-80 as i32 as i64 as u64)
    call function_41052                     
    ldxdw r1, [r10-0x50]                    
    jeq r1, 0, lbb_41633                            if r1 == (0 as i32 as i64 as u64) { pc += 12 }
    mov64 r2, r10                                   r2 = r10
    add64 r2, -80                                   r2 += -80   ///  r2 = r2.wrapping_add(-80 as i32 as i64 as u64)
    mov64 r1, r6                                    r1 = r6
    mov64 r3, 80                                    r3 = 80 as i32 as i64 as u64
    call function_48190                     
    ja lbb_41640                                    if true { pc += 13 }
lbb_41627:
    stxdw [r6+0x18], r7                     
    mov64 r1, 11                                    r1 = 11 as i32 as i64 as u64
    stxw [r6+0x8], r1                       
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    stxdw [r6+0x0], r1                      
    ja lbb_41643                                    if true { pc += 10 }
lbb_41633:
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    ldxb r2, [r10-0x48]                     
    jeq r2, 0, lbb_41637                            if r2 == (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r1, 2                                     r1 = 2 as i32 as i64 as u64
lbb_41637:
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
    stxdw [r6+0x0], r2                      
    stxw [r6+0x8], r1                       
lbb_41640:
    ldxdw r1, [r7+0x0]                      
    add64 r1, -1                                    r1 += -1   ///  r1 = r1.wrapping_add(-1 as i32 as i64 as u64)
    stxdw [r7+0x0], r1                      
lbb_41643:
    exit                                    

function_41644:
    mov64 r6, r1                                    r6 = r1
    ldxdw r1, [r3+0x0]                      
    ldxdw r4, [r1+0x0]                      
    lddw r5, 0x66d17b1817d5a706                     r5 load str located at 7408838205410486022
    jeq r4, r5, lbb_41652                           if r4 == r5 { pc += 2 }
lbb_41650:
    mov64 r4, 1                                     r4 = 1 as i32 as i64 as u64
    ja lbb_41665                                    if true { pc += 13 }
lbb_41652:
    ldxdw r4, [r1+0x8]                      
    lddw r5, 0xc0c2fd5504d4da35                     r5 load str located at -4556801331350414795
    jne r4, r5, lbb_41650                           if r4 != r5 { pc += -6 }
    ldxdw r4, [r1+0x10]                     
    lddw r5, 0xa57556218fc624c1                     r5 load str located at -6524213783030258495
    jne r4, r5, lbb_41650                           if r4 != r5 { pc += -10 }
    mov64 r4, 0                                     r4 = 0 as i32 as i64 as u64
    ldxdw r1, [r1+0x18]                     
    lddw r5, 0x85fcbbadb                            r5 load str located at 35966925531
    jne r1, r5, lbb_41650                           if r1 != r5 { pc += -15 }
lbb_41665:
    jeq r4, 0, lbb_41671                            if r4 == (0 as i32 as i64 as u64) { pc += 5 }
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    stxdw [r6+0x0], r1                      
    mov64 r1, 16                                    r1 = 16 as i32 as i64 as u64
    stxw [r6+0x8], r1                       
    ja lbb_41738                                    if true { pc += 67 }
lbb_41671:
    ldxdw r7, [r3+0x10]                     
    ldxdw r3, [r7+0x10]                     
    lddw r1, 0x7fffffffffffffff                     r1 load str located at 9223372036854775807
    jgt r1, r3, lbb_41677                           if r1 > r3 { pc += 1 }
    ja lbb_41739                                    if true { pc += 62 }
lbb_41677:
    mov64 r1, r3                                    r1 = r3
    add64 r1, 1                                     r1 += 1   ///  r1 = r1.wrapping_add(1 as i32 as i64 as u64)
    stxdw [r7+0x10], r1                     
    ldxdw r4, [r7+0x20]                     
    mov64 r1, r4                                    r1 = r4
    add64 r1, -2                                    r1 += -2   ///  r1 = r1.wrapping_add(-2 as i32 as i64 as u64)
    jgt r4, 1, lbb_41689                            if r4 > (1 as i32 as i64 as u64) { pc += 5 }
    mov64 r2, r4                                    r2 = r4
    lddw r3, 0x100066fb8 --> b"\x00\x00\x00\x00\xc52\x06\x00\x1a\x00\x00\x00\x00\x00\x00\x00\x9d\x00\x00…        r3 load str located at 4295389112
    call function_46562                     
    syscall [invalid]                       
lbb_41689:
    ldxdw r0, [r7+0x18]                     
    stxdw [r10-0x58], r0                    
    add64 r0, r1                                    r0 += r1   ///  r0 = r0.wrapping_add(r1)
    ldxh r0, [r0+0x0]                       
    mov64 r1, r0                                    r1 = r0
    mov64 r5, r2                                    r5 = r2
    add64 r1, r2                                    r1 += r2   ///  r1 = r1.wrapping_add(r2)
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
    mov64 r8, 1                                     r8 = 1 as i32 as i64 as u64
    mov64 r9, 1                                     r9 = 1 as i32 as i64 as u64
    jsgt r0, r1, lbb_41701                          if (r0 as i64) > (r1 as i64) { pc += 1 }
    mov64 r9, 0                                     r9 = 0 as i32 as i64 as u64
lbb_41701:
    jsgt r2, r5, lbb_41703                          if (r2 as i64) > (r5 as i64) { pc += 1 }
    mov64 r8, 0                                     r8 = 0 as i32 as i64 as u64
lbb_41703:
    xor64 r8, r9                                    r8 ^= r9   ///  r8 = r8.xor(r9)
    lddw r0, 0x7fffffffffffffff                     r0 load str located at 9223372036854775807
    jne r8, 0, lbb_41708                            if r8 != (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r0, r1                                    r0 = r1
lbb_41708:
    jsgt r2, r0, lbb_41722                          if (r2 as i64) > (r0 as i64) { pc += 13 }
    mov64 r1, r10                                   r1 = r10
    add64 r1, -80                                   r1 += -80   ///  r1 = r1.wrapping_add(-80 as i32 as i64 as u64)
    mov64 r2, r0                                    r2 = r0
    ldxdw r3, [r10-0x58]                    
    call function_41052                     
    ldxdw r1, [r10-0x50]                    
    jeq r1, 0, lbb_41728                            if r1 == (0 as i32 as i64 as u64) { pc += 12 }
    mov64 r2, r10                                   r2 = r10
    add64 r2, -80                                   r2 += -80   ///  r2 = r2.wrapping_add(-80 as i32 as i64 as u64)
    mov64 r1, r6                                    r1 = r6
    mov64 r3, 80                                    r3 = 80 as i32 as i64 as u64
    call function_48190                     
    ja lbb_41735                                    if true { pc += 13 }
lbb_41722:
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    stxdw [r6+0x0], r1                      
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    stxw [r6+0x8], r1                       
    stxdw [r7+0x10], r3                     
    ja lbb_41738                                    if true { pc += 10 }
lbb_41728:
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    ldxb r2, [r10-0x48]                     
    jeq r2, 0, lbb_41732                            if r2 == (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r1, 2                                     r1 = 2 as i32 as i64 as u64
lbb_41732:
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
    stxdw [r6+0x0], r2                      
    stxw [r6+0x8], r1                       
lbb_41735:
    ldxdw r1, [r7+0x10]                     
    add64 r1, -1                                    r1 += -1   ///  r1 = r1.wrapping_add(-1 as i32 as i64 as u64)
    stxdw [r7+0x10], r1                     
lbb_41738:
    exit                                    
lbb_41739:
    lddw r1, 0x100066fd0 --> b"\x00\x00\x00\x00\xc52\x06\x00\x1a\x00\x00\x00\x00\x00\x00\x00\x16\x01\x00…        r1 load str located at 4295389136
    call function_43759                     
    syscall [invalid]                       

function_41743:
    mov64 r3, r2                                    r3 = r2
    ldxw r2, [r1+0x0]                       
    jsgt r2, 11, lbb_41755                          if (r2 as i64) > (11 as i32 as i64) { pc += 9 }
    jsgt r2, 5, lbb_41781                           if (r2 as i64) > (5 as i32 as i64) { pc += 34 }
    jsgt r2, 2, lbb_41797                           if (r2 as i64) > (2 as i32 as i64) { pc += 49 }
    jeq r2, 0, lbb_41825                            if r2 == (0 as i32 as i64 as u64) { pc += 76 }
    jeq r2, 1, lbb_41861                            if r2 == (1 as i32 as i64 as u64) { pc += 111 }
    mov64 r1, r3                                    r1 = r3
    lddw r2, 0x1000634a2 --> b"An instruction's data contents was invalid"        r2 load str located at 4295373986
    mov64 r3, 42                                    r3 = 42 as i32 as i64 as u64
    ja lbb_41935                                    if true { pc += 180 }
lbb_41755:
    jsgt r2, 17, lbb_41789                          if (r2 as i64) > (17 as i32 as i64) { pc += 33 }
    jsgt r2, 14, lbb_41804                          if (r2 as i64) > (14 as i32 as i64) { pc += 47 }
    jeq r2, 12, lbb_41866                           if r2 == (12 as i32 as i64 as u64) { pc += 108 }
    jeq r2, 13, lbb_41871                           if r2 == (13 as i32 as i64 as u64) { pc += 112 }
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
    stxdw [r10-0x48], r2                    
    lddw r2, 0x100066ff8 --> b"\x00\x00\x00\x00\xa56\x06\x00\x0a\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00…        r2 load str located at 4295389176
    stxdw [r10-0x68], r2                    
    mov64 r2, 1                                     r2 = 1 as i32 as i64 as u64
    stxdw [r10-0x60], r2                    
    stxdw [r10-0x50], r2                    
    mov64 r2, r10                                   r2 = r10
    add64 r2, -168                                  r2 += -168   ///  r2 = r2.wrapping_add(-168 as i32 as i64 as u64)
    stxdw [r10-0x58], r2                    
    lddw r2, 0x10004b430 --> b"\xbf#\x00\x00\x00\x00\x00\x00y\x11\x00\x00\x00\x00\x00\x00y\x12\x10\x00\x…        r2 load str located at 4295275568
    stxdw [r10-0xa0], r2                    
    mov64 r2, r10                                   r2 = r10
    add64 r2, -120                                  r2 += -120   ///  r2 = r2.wrapping_add(-120 as i32 as i64 as u64)
    stxdw [r10-0xa8], r2                    
    add64 r1, 8                                     r1 += 8   ///  r1 = r1.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x78], r1                    
    mov64 r2, r10                                   r2 = r10
    add64 r2, -104                                  r2 += -104   ///  r2 = r2.wrapping_add(-104 as i32 as i64 as u64)
    ja lbb_41858                                    if true { pc += 77 }
lbb_41781:
    jsgt r2, 8, lbb_41811                           if (r2 as i64) > (8 as i32 as i64) { pc += 29 }
    jeq r2, 6, lbb_41876                            if r2 == (6 as i32 as i64 as u64) { pc += 93 }
    jeq r2, 7, lbb_41881                            if r2 == (7 as i32 as i64 as u64) { pc += 97 }
    mov64 r1, r3                                    r1 = r3
    lddw r2, 0x1000635a5 --> b"An initialize instruction was sent to an account that has already been in…        r2 load str located at 4295374245
    mov64 r3, 82                                    r3 = 82 as i32 as i64 as u64
    ja lbb_41935                                    if true { pc += 146 }
lbb_41789:
    jsgt r2, 20, lbb_41818                          if (r2 as i64) > (20 as i32 as i64) { pc += 28 }
    jeq r2, 18, lbb_41886                           if r2 == (18 as i32 as i64 as u64) { pc += 95 }
    jeq r2, 19, lbb_41891                           if r2 == (19 as i32 as i64 as u64) { pc += 99 }
    mov64 r1, r3                                    r1 = r3
    lddw r2, 0x1000636d4 --> b"Instruction trace length exceeded the maximum allowed per transaction"        r2 load str located at 4295374548
    mov64 r3, 69                                    r3 = 69 as i32 as i64 as u64
    ja lbb_41935                                    if true { pc += 138 }
lbb_41797:
    jeq r2, 3, lbb_41896                            if r2 == (3 as i32 as i64 as u64) { pc += 98 }
    jeq r2, 4, lbb_41901                            if r2 == (4 as i32 as i64 as u64) { pc += 102 }
    mov64 r1, r3                                    r1 = r3
    lddw r2, 0x100063511 --> b"An account's balance was too small to complete the instruction"        r2 load str located at 4295374097
    mov64 r3, 62                                    r3 = 62 as i32 as i64 as u64
    ja lbb_41935                                    if true { pc += 131 }
lbb_41804:
    jeq r2, 15, lbb_41906                           if r2 == (15 as i32 as i64 as u64) { pc += 101 }
    jeq r2, 16, lbb_41911                           if r2 == (16 as i32 as i64 as u64) { pc += 105 }
    mov64 r1, r3                                    r1 = r3
    lddw r2, 0x1000633c1 --> b"Provided owner is not allowed"        r2 load str located at 4295373761
    mov64 r3, 29                                    r3 = 29 as i32 as i64 as u64
    ja lbb_41935                                    if true { pc += 124 }
lbb_41811:
    jeq r2, 9, lbb_41916                            if r2 == (9 as i32 as i64 as u64) { pc += 104 }
    jeq r2, 10, lbb_41921                           if r2 == (10 as i32 as i64 as u64) { pc += 108 }
    mov64 r1, r3                                    r1 = r3
    lddw r2, 0x100063667 --> b"Failed to borrow a reference to account data, already borrowed"        r2 load str located at 4295374439
    mov64 r3, 62                                    r3 = 62 as i32 as i64 as u64
    ja lbb_41935                                    if true { pc += 117 }
lbb_41818:
    jeq r2, 21, lbb_41926                           if r2 == (21 as i32 as i64 as u64) { pc += 107 }
    jeq r2, 22, lbb_41931                           if r2 == (22 as i32 as i64 as u64) { pc += 111 }
    mov64 r1, r3                                    r1 = r3
    lddw r2, 0x100063392 --> b"Program arithmetic overflowed"        r2 load str located at 4295373714
    mov64 r3, 29                                    r3 = 29 as i32 as i64 as u64
    ja lbb_41935                                    if true { pc += 110 }
lbb_41825:
    add64 r1, 4                                     r1 += 4   ///  r1 = r1.wrapping_add(4 as i32 as i64 as u64)
    stxdw [r10-0xb0], r1                    
    lddw r1, 0x10004b460 --> b"y\x11\x00\x00\x00\x00\x00\x00\x85\x10\x00\x00e#\x00\x00\x95\x00\x00\x00\x…        r1 load str located at 4295275616
    stxdw [r10-0x70], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -176                                  r1 += -176   ///  r1 = r1.wrapping_add(-176 as i32 as i64 as u64)
    stxdw [r10-0x78], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -104                                  r1 += -104   ///  r1 = r1.wrapping_add(-104 as i32 as i64 as u64)
    stxdw [r10-0x88], r1                    
    lddw r1, 0x100066fe8 --> b"\x00\x00\x00\x00P4\x06\x00\x16\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x0…        r1 load str located at 4295389160
    stxdw [r10-0xa8], r1                    
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    stxdw [r10-0x80], r1                    
    stxdw [r10-0xa0], r1                    
    stxdw [r10-0x90], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -120                                  r1 += -120   ///  r1 = r1.wrapping_add(-120 as i32 as i64 as u64)
    stxdw [r10-0x98], r1                    
    mov64 r1, 3                                     r1 = 3 as i32 as i64 as u64
    stxb [r10-0x38], r1                     
    lddw r1, 0x400000020                            r1 load str located at 17179869216
    stxdw [r10-0x40], r1                    
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    stxdw [r10-0x48], r1                    
    mov64 r1, 2                                     r1 = 2 as i32 as i64 as u64
    stxdw [r10-0x58], r1                    
    stxdw [r10-0x68], r1                    
    mov64 r2, r10                                   r2 = r10
    add64 r2, -168                                  r2 += -168   ///  r2 = r2.wrapping_add(-168 as i32 as i64 as u64)
lbb_41858:
    mov64 r1, r3                                    r1 = r3
    call function_45907                     
    ja lbb_41936                                    if true { pc += 75 }
lbb_41861:
    mov64 r1, r3                                    r1 = r3
    lddw r2, 0x100063466 --> b"The arguments provided to a program instruction were invalid"        r2 load str located at 4295373926
    mov64 r3, 60                                    r3 = 60 as i32 as i64 as u64
    ja lbb_41935                                    if true { pc += 69 }
lbb_41866:
    mov64 r1, r3                                    r1 = r3
    lddw r2, 0x1000632df --> b"Length of the seed is too long for address generation"        r2 load str located at 4295373535
    mov64 r3, 53                                    r3 = 53 as i32 as i64 as u64
    ja lbb_41935                                    if true { pc += 64 }
lbb_41871:
    mov64 r1, r3                                    r1 = r3
    lddw r2, 0x100063314 --> b"Provided seeds do not result in a valid address"        r2 load str located at 4295373588
    mov64 r3, 47                                    r3 = 47 as i32 as i64 as u64
    ja lbb_41935                                    if true { pc += 59 }
lbb_41876:
    mov64 r1, r3                                    r1 = r3
    lddw r2, 0x10006354f --> b"The account did not have the expected program id"        r2 load str located at 4295374159
    mov64 r3, 48                                    r3 = 48 as i32 as i64 as u64
    ja lbb_41935                                    if true { pc += 54 }
lbb_41881:
    mov64 r1, r3                                    r1 = r3
    lddw r2, 0x10006357f --> b"A signature was required but not found"        r2 load str located at 4295374207
    mov64 r3, 38                                    r3 = 38 as i32 as i64 as u64
    ja lbb_41935                                    if true { pc += 49 }
lbb_41886:
    mov64 r1, r3                                    r1 = r3
    lddw r2, 0x1000633de --> b"Accounts data allocations exceeded the maximum allowed per transaction"        r2 load str located at 4295373790
    mov64 r3, 70                                    r3 = 70 as i32 as i64 as u64
    ja lbb_41935                                    if true { pc += 44 }
lbb_41891:
    mov64 r1, r3                                    r1 = r3
    lddw r2, 0x1000636af --> b"Account data reallocation was invalid"        r2 load str located at 4295374511
    mov64 r3, 37                                    r3 = 37 as i32 as i64 as u64
    ja lbb_41935                                    if true { pc += 39 }
lbb_41896:
    mov64 r1, r3                                    r1 = r3
    lddw r2, 0x1000634cc --> b"An account's data contents was invalid"        r2 load str located at 4295374028
    mov64 r3, 38                                    r3 = 38 as i32 as i64 as u64
    ja lbb_41935                                    if true { pc += 34 }
lbb_41901:
    mov64 r1, r3                                    r1 = r3
    lddw r2, 0x1000634f2 --> b"An account's data was too small"        r2 load str located at 4295374066
    mov64 r3, 31                                    r3 = 31 as i32 as i64 as u64
    ja lbb_41935                                    if true { pc += 29 }
lbb_41906:
    mov64 r1, r3                                    r1 = r3
    lddw r2, 0x100063343 --> b"An account does not have enough lamports to be rent-exempt"        r2 load str located at 4295373635
    mov64 r3, 58                                    r3 = 58 as i32 as i64 as u64
    ja lbb_41935                                    if true { pc += 24 }
lbb_41911:
    mov64 r1, r3                                    r1 = r3
    lddw r2, 0x1000633af --> b"Unsupported sysvar"        r2 load str located at 4295373743
    mov64 r3, 18                                    r3 = 18 as i32 as i64 as u64
    ja lbb_41935                                    if true { pc += 19 }
lbb_41916:
    mov64 r1, r3                                    r1 = r3
    lddw r2, 0x1000635f7 --> b"An attempt to operate on an account that hasn't been initialized"        r2 load str located at 4295374327
    mov64 r3, 64                                    r3 = 64 as i32 as i64 as u64
    ja lbb_41935                                    if true { pc += 14 }
lbb_41921:
    mov64 r1, r3                                    r1 = r3
    lddw r2, 0x100063637 --> b"The instruction expected additional account keys"        r2 load str located at 4295374391
    mov64 r3, 48                                    r3 = 48 as i32 as i64 as u64
    ja lbb_41935                                    if true { pc += 9 }
lbb_41926:
    mov64 r1, r3                                    r1 = r3
    lddw r2, 0x100063424 --> b"Builtin programs must consume compute units"        r2 load str located at 4295373860
    mov64 r3, 43                                    r3 = 43 as i32 as i64 as u64
    ja lbb_41935                                    if true { pc += 4 }
lbb_41931:
    mov64 r1, r3                                    r1 = r3
    lddw r2, 0x10006337d --> b"Invalid account owner"        r2 load str located at 4295373693
    mov64 r3, 21                                    r3 = 21 as i32 as i64 as u64
lbb_41935:
    call function_45901                     
lbb_41936:
    exit                                    

function_41937:
    ldxb r1, [r1+0x0]                       
    jeq r1, 0, lbb_41945                            if r1 == (0 as i32 as i64 as u64) { pc += 6 }
    jeq r1, 1, lbb_41950                            if r1 == (1 as i32 as i64 as u64) { pc += 10 }
    mov64 r1, r2                                    r1 = r2
    lddw r2, 0x1000633c1 --> b"Provided owner is not allowed"        r2 load str located at 4295373761
    mov64 r3, 29                                    r3 = 29 as i32 as i64 as u64
    ja lbb_41954                                    if true { pc += 9 }
lbb_41945:
    mov64 r1, r2                                    r1 = r2
    lddw r2, 0x1000632df --> b"Length of the seed is too long for address generation"        r2 load str located at 4295373535
    mov64 r3, 53                                    r3 = 53 as i32 as i64 as u64
    ja lbb_41954                                    if true { pc += 4 }
lbb_41950:
    mov64 r1, r2                                    r1 = r2
    lddw r2, 0x100063314 --> b"Provided seeds do not result in a valid address"        r2 load str located at 4295373588
    mov64 r3, 47                                    r3 = 47 as i32 as i64 as u64
lbb_41954:
    call function_45901                     
    exit                                    

function_41956:
    mov64 r6, r1                                    r6 = r1
    mov64 r7, r10                                   r7 = r10
    add64 r7, -40                                   r7 += -40   ///  r7 = r7.wrapping_add(-40 as i32 as i64 as u64)
    mov64 r8, 0                                     r8 = 0 as i32 as i64 as u64
    mov64 r1, r7                                    r1 = r7
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
    mov64 r3, 40                                    r3 = 40 as i32 as i64 as u64
    call function_48291                     
    mov64 r1, r7                                    r1 = r7
    syscall [invalid]                       
    jne r0, 0, lbb_41974                            if r0 != (0 as i32 as i64 as u64) { pc += 7 }
    mov64 r1, r6                                    r1 = r6
    add64 r1, 8                                     r1 += 8   ///  r1 = r1.wrapping_add(8 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -40                                   r2 += -40   ///  r2 = r2.wrapping_add(-40 as i32 as i64 as u64)
    mov64 r3, 40                                    r3 = 40 as i32 as i64 as u64
    call function_48190                     
    ja lbb_41979                                    if true { pc += 5 }
lbb_41974:
    mov64 r1, r6                                    r1 = r6
    add64 r1, 8                                     r1 += 8   ///  r1 = r1.wrapping_add(8 as i32 as i64 as u64)
    mov64 r2, r0                                    r2 = r0
    call function_40728                     
    mov64 r8, 1                                     r8 = 1 as i32 as i64 as u64
lbb_41979:
    stxdw [r6+0x0], r8                      
    exit                                    

function_41981:
    mov64 r6, r1                                    r6 = r1
    mov64 r1, 50                                    r1 = 50 as i32 as i64 as u64
    stxb [r10-0x8], r1                      
    lddw r1, 0x4000000000000000                     r1 load str located at 4611686018427387904
    stxdw [r10-0x10], r1                    
    mov64 r1, 3480                                  r1 = 3480 as i32 as i64 as u64
    stxdw [r10-0x18], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -24                                   r1 += -24   ///  r1 = r1.wrapping_add(-24 as i32 as i64 as u64)
    syscall [invalid]                       
    jne r0, 0, lbb_42002                            if r0 != (0 as i32 as i64 as u64) { pc += 9 }
    ldxdw r1, [r10-0x8]                     
    stxdw [r6+0x18], r1                     
    ldxdw r1, [r10-0x10]                    
    stxdw [r6+0x10], r1                     
    ldxdw r1, [r10-0x18]                    
    stxdw [r6+0x8], r1                      
    mov64 r1, 24                                    r1 = 24 as i32 as i64 as u64
    stxw [r6+0x0], r1                       
    ja lbb_42005                                    if true { pc += 3 }
lbb_42002:
    mov64 r1, r6                                    r1 = r6
    mov64 r2, r0                                    r2 = r0
    call function_40728                     
lbb_42005:
    exit                                    

function_42006:
    mov64 r4, r2                                    r4 = r2
    ldxdw r1, [r1+0x0]                      
    ldxb r1, [r1+0x0]                       
    jsgt r1, 1, lbb_42018                           if (r1 as i64) > (1 as i32 as i64) { pc += 8 }
    lddw r2, 0x100063720 --> b"TargetAlignmentGreaterAndInputNotAligned"        r2 load str located at 4295374624
    mov64 r3, 40                                    r3 = 40 as i32 as i64 as u64
    jeq r1, 0, lbb_42026                            if r1 == (0 as i32 as i64 as u64) { pc += 12 }
    lddw r2, 0x100063748 --> b"OutputSliceWouldHaveSlop"        r2 load str located at 4295374664
    mov64 r3, 24                                    r3 = 24 as i32 as i64 as u64
    ja lbb_42026                                    if true { pc += 8 }
lbb_42018:
    jeq r1, 2, lbb_42023                            if r1 == (2 as i32 as i64 as u64) { pc += 4 }
    lddw r2, 0x10006376c --> b"AlignmentMismatch"        r2 load str located at 4295374700
    mov64 r3, 17                                    r3 = 17 as i32 as i64 as u64
    ja lbb_42026                                    if true { pc += 3 }
lbb_42023:
    lddw r2, 0x100063760 --> b"SizeMismatch"        r2 load str located at 4295374688
    mov64 r3, 12                                    r3 = 12 as i32 as i64 as u64
lbb_42026:
    mov64 r1, r4                                    r1 = r4
    call function_45901                     
    exit                                    

function_42029:
    mov64 r3, r2                                    r3 = r2
    stxdw [r10-0x78], r1                    
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    stxdw [r10-0x50], r1                    
    lddw r1, 0x100067008 --> b"\x00\x00\x00\x00 7\x06\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x0…        r1 load str located at 4295389192
    stxdw [r10-0x70], r1                    
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    stxdw [r10-0x68], r1                    
    stxdw [r10-0x58], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -64                                   r1 += -64   ///  r1 = r1.wrapping_add(-64 as i32 as i64 as u64)
    stxdw [r10-0x60], r1                    
    lddw r1, 0x1000521d0 --> b"\xbf$\x00\x00\x00\x00\x00\x00y\x11\x00\x00\x00\x00\x00\x00q\x11\x00\x00\x…        r1 load str located at 4295303632
    stxdw [r10-0x38], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -120                                  r1 += -120   ///  r1 = r1.wrapping_add(-120 as i32 as i64 as u64)
    stxdw [r10-0x40], r1                    
    mov64 r2, r10                                   r2 = r10
    add64 r2, -112                                  r2 += -112   ///  r2 = r2.wrapping_add(-112 as i32 as i64 as u64)
    mov64 r1, r3                                    r1 = r3
    call function_45907                     
    exit                                    

function_42053:
    ldxdw r3, [r2+0x10]                     
    stxdw [r1+0x8], r3                      
    ldxdw r2, [r2+0x0]                      
    stxdw [r1+0x0], r2                      
    exit                                    

function_42058:
    lsh64 r1, 32                                    r1 <<= 32   ///  r1 = r1.wrapping_shl(32)
    rsh64 r1, 32                                    r1 >>= 32   ///  r1 = r1.wrapping_shr(32)
    jsgt r1, 19, lbb_42070                          if (r1 as i64) > (19 as i32 as i64) { pc += 9 }
    jsgt r1, 9, lbb_42085                           if (r1 as i64) > (9 as i32 as i64) { pc += 23 }
    jsgt r1, 4, lbb_42099                           if (r1 as i64) > (4 as i32 as i64) { pc += 36 }
    jsgt r1, 1, lbb_42117                           if (r1 as i64) > (1 as i32 as i64) { pc += 53 }
    mov64 r0, 0                                     r0 = 0 as i32 as i64 as u64
    jeq r1, 0, lbb_42214                            if r1 == (0 as i32 as i64 as u64) { pc += 148 }
    jeq r1, 1, lbb_42068                            if r1 == (1 as i32 as i64 as u64) { pc += 1 }
    ja lbb_42213                                    if true { pc += 145 }
lbb_42068:
    mov64 r0, 1                                     r0 = 1 as i32 as i64 as u64
    ja lbb_42214                                    if true { pc += 144 }
lbb_42070:
    jsgt r1, 29, lbb_42078                          if (r1 as i64) > (29 as i32 as i64) { pc += 7 }
    jsgt r1, 24, lbb_42105                          if (r1 as i64) > (24 as i32 as i64) { pc += 33 }
    jsgt r1, 21, lbb_42123                          if (r1 as i64) > (21 as i32 as i64) { pc += 50 }
    jeq r1, 20, lbb_42165                           if r1 == (20 as i32 as i64 as u64) { pc += 91 }
    jeq r1, 21, lbb_42076                           if r1 == (21 as i32 as i64 as u64) { pc += 1 }
    ja lbb_42213                                    if true { pc += 137 }
lbb_42076:
    mov64 r0, 21                                    r0 = 21 as i32 as i64 as u64
    ja lbb_42214                                    if true { pc += 136 }
lbb_42078:
    jsgt r1, 34, lbb_42092                          if (r1 as i64) > (34 as i32 as i64) { pc += 13 }
    jsgt r1, 31, lbb_42129                          if (r1 as i64) > (31 as i32 as i64) { pc += 49 }
    jeq r1, 30, lbb_42167                           if r1 == (30 as i32 as i64 as u64) { pc += 86 }
    jeq r1, 31, lbb_42083                           if r1 == (31 as i32 as i64 as u64) { pc += 1 }
    ja lbb_42213                                    if true { pc += 130 }
lbb_42083:
    mov64 r0, 31                                    r0 = 31 as i32 as i64 as u64
    ja lbb_42214                                    if true { pc += 129 }
lbb_42085:
    jsgt r1, 14, lbb_42111                          if (r1 as i64) > (14 as i32 as i64) { pc += 25 }
    jsgt r1, 11, lbb_42135                          if (r1 as i64) > (11 as i32 as i64) { pc += 48 }
    jeq r1, 10, lbb_42169                           if r1 == (10 as i32 as i64 as u64) { pc += 81 }
    jeq r1, 11, lbb_42090                           if r1 == (11 as i32 as i64 as u64) { pc += 1 }
    ja lbb_42213                                    if true { pc += 123 }
lbb_42090:
    mov64 r0, 11                                    r0 = 11 as i32 as i64 as u64
    ja lbb_42214                                    if true { pc += 122 }
lbb_42092:
    jsgt r1, 37, lbb_42141                          if (r1 as i64) > (37 as i32 as i64) { pc += 48 }
    jeq r1, 35, lbb_42171                           if r1 == (35 as i32 as i64 as u64) { pc += 77 }
    jeq r1, 36, lbb_42173                           if r1 == (36 as i32 as i64 as u64) { pc += 78 }
    jeq r1, 37, lbb_42097                           if r1 == (37 as i32 as i64 as u64) { pc += 1 }
    ja lbb_42213                                    if true { pc += 116 }
lbb_42097:
    mov64 r0, 37                                    r0 = 37 as i32 as i64 as u64
    ja lbb_42214                                    if true { pc += 115 }
lbb_42099:
    jsgt r1, 6, lbb_42147                           if (r1 as i64) > (6 as i32 as i64) { pc += 47 }
    jeq r1, 5, lbb_42175                            if r1 == (5 as i32 as i64 as u64) { pc += 74 }
    jeq r1, 6, lbb_42103                            if r1 == (6 as i32 as i64 as u64) { pc += 1 }
    ja lbb_42213                                    if true { pc += 110 }
lbb_42103:
    mov64 r0, 6                                     r0 = 6 as i32 as i64 as u64
    ja lbb_42214                                    if true { pc += 109 }
lbb_42105:
    jsgt r1, 26, lbb_42153                          if (r1 as i64) > (26 as i32 as i64) { pc += 47 }
    jeq r1, 25, lbb_42177                           if r1 == (25 as i32 as i64 as u64) { pc += 70 }
    jeq r1, 26, lbb_42109                           if r1 == (26 as i32 as i64 as u64) { pc += 1 }
    ja lbb_42213                                    if true { pc += 104 }
lbb_42109:
    mov64 r0, 26                                    r0 = 26 as i32 as i64 as u64
    ja lbb_42214                                    if true { pc += 103 }
lbb_42111:
    jsgt r1, 16, lbb_42159                          if (r1 as i64) > (16 as i32 as i64) { pc += 47 }
    jeq r1, 15, lbb_42179                           if r1 == (15 as i32 as i64 as u64) { pc += 66 }
    jeq r1, 16, lbb_42115                           if r1 == (16 as i32 as i64 as u64) { pc += 1 }
    ja lbb_42213                                    if true { pc += 98 }
lbb_42115:
    mov64 r0, 16                                    r0 = 16 as i32 as i64 as u64
    ja lbb_42214                                    if true { pc += 97 }
lbb_42117:
    jeq r1, 2, lbb_42181                            if r1 == (2 as i32 as i64 as u64) { pc += 63 }
    jeq r1, 3, lbb_42183                            if r1 == (3 as i32 as i64 as u64) { pc += 64 }
    jeq r1, 4, lbb_42121                            if r1 == (4 as i32 as i64 as u64) { pc += 1 }
    ja lbb_42213                                    if true { pc += 92 }
lbb_42121:
    mov64 r0, 4                                     r0 = 4 as i32 as i64 as u64
    ja lbb_42214                                    if true { pc += 91 }
lbb_42123:
    jeq r1, 22, lbb_42185                           if r1 == (22 as i32 as i64 as u64) { pc += 61 }
    jeq r1, 23, lbb_42187                           if r1 == (23 as i32 as i64 as u64) { pc += 62 }
    jeq r1, 24, lbb_42127                           if r1 == (24 as i32 as i64 as u64) { pc += 1 }
    ja lbb_42213                                    if true { pc += 86 }
lbb_42127:
    mov64 r0, 24                                    r0 = 24 as i32 as i64 as u64
    ja lbb_42214                                    if true { pc += 85 }
lbb_42129:
    jeq r1, 32, lbb_42189                           if r1 == (32 as i32 as i64 as u64) { pc += 59 }
    jeq r1, 33, lbb_42191                           if r1 == (33 as i32 as i64 as u64) { pc += 60 }
    jeq r1, 34, lbb_42133                           if r1 == (34 as i32 as i64 as u64) { pc += 1 }
    ja lbb_42213                                    if true { pc += 80 }
lbb_42133:
    mov64 r0, 34                                    r0 = 34 as i32 as i64 as u64
    ja lbb_42214                                    if true { pc += 79 }
lbb_42135:
    jeq r1, 12, lbb_42193                           if r1 == (12 as i32 as i64 as u64) { pc += 57 }
    jeq r1, 13, lbb_42195                           if r1 == (13 as i32 as i64 as u64) { pc += 58 }
    jeq r1, 14, lbb_42139                           if r1 == (14 as i32 as i64 as u64) { pc += 1 }
    ja lbb_42213                                    if true { pc += 74 }
lbb_42139:
    mov64 r0, 14                                    r0 = 14 as i32 as i64 as u64
    ja lbb_42214                                    if true { pc += 73 }
lbb_42141:
    jeq r1, 38, lbb_42197                           if r1 == (38 as i32 as i64 as u64) { pc += 55 }
    jeq r1, 39, lbb_42199                           if r1 == (39 as i32 as i64 as u64) { pc += 56 }
    jeq r1, 40, lbb_42145                           if r1 == (40 as i32 as i64 as u64) { pc += 1 }
    ja lbb_42213                                    if true { pc += 68 }
lbb_42145:
    mov64 r0, 40                                    r0 = 40 as i32 as i64 as u64
    ja lbb_42214                                    if true { pc += 67 }
lbb_42147:
    jeq r1, 7, lbb_42201                            if r1 == (7 as i32 as i64 as u64) { pc += 53 }
    jeq r1, 8, lbb_42203                            if r1 == (8 as i32 as i64 as u64) { pc += 54 }
    jeq r1, 9, lbb_42151                            if r1 == (9 as i32 as i64 as u64) { pc += 1 }
    ja lbb_42213                                    if true { pc += 62 }
lbb_42151:
    mov64 r0, 9                                     r0 = 9 as i32 as i64 as u64
    ja lbb_42214                                    if true { pc += 61 }
lbb_42153:
    jeq r1, 27, lbb_42205                           if r1 == (27 as i32 as i64 as u64) { pc += 51 }
    jeq r1, 28, lbb_42207                           if r1 == (28 as i32 as i64 as u64) { pc += 52 }
    jeq r1, 29, lbb_42157                           if r1 == (29 as i32 as i64 as u64) { pc += 1 }
    ja lbb_42213                                    if true { pc += 56 }
lbb_42157:
    mov64 r0, 29                                    r0 = 29 as i32 as i64 as u64
    ja lbb_42214                                    if true { pc += 55 }
lbb_42159:
    jeq r1, 17, lbb_42209                           if r1 == (17 as i32 as i64 as u64) { pc += 49 }
    jeq r1, 18, lbb_42211                           if r1 == (18 as i32 as i64 as u64) { pc += 50 }
    jeq r1, 19, lbb_42163                           if r1 == (19 as i32 as i64 as u64) { pc += 1 }
    ja lbb_42213                                    if true { pc += 50 }
lbb_42163:
    mov64 r0, 19                                    r0 = 19 as i32 as i64 as u64
    ja lbb_42214                                    if true { pc += 49 }
lbb_42165:
    mov64 r0, 20                                    r0 = 20 as i32 as i64 as u64
    ja lbb_42214                                    if true { pc += 47 }
lbb_42167:
    mov64 r0, 30                                    r0 = 30 as i32 as i64 as u64
    ja lbb_42214                                    if true { pc += 45 }
lbb_42169:
    mov64 r0, 10                                    r0 = 10 as i32 as i64 as u64
    ja lbb_42214                                    if true { pc += 43 }
lbb_42171:
    mov64 r0, 35                                    r0 = 35 as i32 as i64 as u64
    ja lbb_42214                                    if true { pc += 41 }
lbb_42173:
    mov64 r0, 36                                    r0 = 36 as i32 as i64 as u64
    ja lbb_42214                                    if true { pc += 39 }
lbb_42175:
    mov64 r0, 5                                     r0 = 5 as i32 as i64 as u64
    ja lbb_42214                                    if true { pc += 37 }
lbb_42177:
    mov64 r0, 25                                    r0 = 25 as i32 as i64 as u64
    ja lbb_42214                                    if true { pc += 35 }
lbb_42179:
    mov64 r0, 15                                    r0 = 15 as i32 as i64 as u64
    ja lbb_42214                                    if true { pc += 33 }
lbb_42181:
    mov64 r0, 2                                     r0 = 2 as i32 as i64 as u64
    ja lbb_42214                                    if true { pc += 31 }
lbb_42183:
    mov64 r0, 3                                     r0 = 3 as i32 as i64 as u64
    ja lbb_42214                                    if true { pc += 29 }
lbb_42185:
    mov64 r0, 22                                    r0 = 22 as i32 as i64 as u64
    ja lbb_42214                                    if true { pc += 27 }
lbb_42187:
    mov64 r0, 23                                    r0 = 23 as i32 as i64 as u64
    ja lbb_42214                                    if true { pc += 25 }
lbb_42189:
    mov64 r0, 32                                    r0 = 32 as i32 as i64 as u64
    ja lbb_42214                                    if true { pc += 23 }
lbb_42191:
    mov64 r0, 33                                    r0 = 33 as i32 as i64 as u64
    ja lbb_42214                                    if true { pc += 21 }
lbb_42193:
    mov64 r0, 12                                    r0 = 12 as i32 as i64 as u64
    ja lbb_42214                                    if true { pc += 19 }
lbb_42195:
    mov64 r0, 13                                    r0 = 13 as i32 as i64 as u64
    ja lbb_42214                                    if true { pc += 17 }
lbb_42197:
    mov64 r0, 38                                    r0 = 38 as i32 as i64 as u64
    ja lbb_42214                                    if true { pc += 15 }
lbb_42199:
    mov64 r0, 39                                    r0 = 39 as i32 as i64 as u64
    ja lbb_42214                                    if true { pc += 13 }
lbb_42201:
    mov64 r0, 7                                     r0 = 7 as i32 as i64 as u64
    ja lbb_42214                                    if true { pc += 11 }
lbb_42203:
    mov64 r0, 8                                     r0 = 8 as i32 as i64 as u64
    ja lbb_42214                                    if true { pc += 9 }
lbb_42205:
    mov64 r0, 27                                    r0 = 27 as i32 as i64 as u64
    ja lbb_42214                                    if true { pc += 7 }
lbb_42207:
    mov64 r0, 28                                    r0 = 28 as i32 as i64 as u64
    ja lbb_42214                                    if true { pc += 5 }
lbb_42209:
    mov64 r0, 17                                    r0 = 17 as i32 as i64 as u64
    ja lbb_42214                                    if true { pc += 3 }
lbb_42211:
    mov64 r0, 18                                    r0 = 18 as i32 as i64 as u64
    ja lbb_42214                                    if true { pc += 1 }
lbb_42213:
    mov64 r0, 41                                    r0 = 41 as i32 as i64 as u64
lbb_42214:
    exit                                    

function_42215:
    mov64 r1, 26                                    r1 = 26 as i32 as i64 as u64
    mov64 r2, 1                                     r2 = 1 as i32 as i64 as u64
    call function_21359                     
    mov64 r6, r0                                    r6 = r0
    jne r6, 0, lbb_42224                            if r6 != (0 as i32 as i64 as u64) { pc += 4 }
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    mov64 r2, 26                                    r2 = 26 as i32 as i64 as u64
    call function_43400                     
    syscall [invalid]                       
lbb_42224:
    mov64 r1, 29813                                 r1 = 29813 as i32 as i64 as u64
    stxh [r6+0x18], r1                      
    lddw r1, 0x706e6920666f2068                     r1 load str located at 8101528367564529768
    stxdw [r6+0x10], r1                     
    lddw r1, 0x74676e656c206465                     r1 load str located at 8387794212885652581
    stxdw [r6+0x8], r1                      
    lddw r1, 0x7463657078656e55                     r1 load str located at 8386658464824651349
    stxdw [r6+0x0], r1                      
    mov64 r1, 24                                    r1 = 24 as i32 as i64 as u64
    mov64 r2, 8                                     r2 = 8 as i32 as i64 as u64
    call function_21359                     
    jne r0, 0, lbb_42243                            if r0 != (0 as i32 as i64 as u64) { pc += 4 }
    mov64 r1, 8                                     r1 = 8 as i32 as i64 as u64
    mov64 r2, 24                                    r2 = 24 as i32 as i64 as u64
    call function_43400                     
    syscall [invalid]                       
lbb_42243:
    mov64 r1, 26                                    r1 = 26 as i32 as i64 as u64
    stxdw [r0+0x10], r1                     
    stxdw [r0+0x8], r1                      
    stxdw [r0+0x0], r6                      
    mov64 r1, 21                                    r1 = 21 as i32 as i64 as u64
    mov64 r2, r0                                    r2 = r0
    lddw r3, 0x100067038 --> b"\x00\x00\x00\x00\x88)\x05\x00\x18\x00\x00\x00\x00\x00\x00\x00\x08\x00\x00…        r3 load str located at 4295389240
    call function_42719                     
    exit                                    

function_42253:
    ldxdw r2, [r1+0x8]                      
    jeq r2, 0, lbb_42258                            if r2 == (0 as i32 as i64 as u64) { pc += 3 }
    ldxdw r1, [r1+0x0]                      
    mov64 r3, 1                                     r3 = 1 as i32 as i64 as u64
    call function_21385                     
lbb_42258:
    exit                                    

function_42259:
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
    stxdw [r1+0x0], r2                      
    exit                                    

function_42262:
    exit                                    

function_42263:
    lddw r2, 0x6c0d57f90468015e                     r2 load str located at 7785976057825853790
    stxdw [r1+0x8], r2                      
    lddw r2, 0xc9041a0db6177351                     r2 load str located at -3962013125987306671
    stxdw [r1+0x0], r2                      
    exit                                    

function_42270:
    mov64 r6, r1                                    r6 = r1
    mov64 r8, r6                                    r8 = r6
    and64 r8, 3                                     r8 &= 3   ///  r8 = r8.and(3)
    jsgt r8, 1, lbb_42277                           if (r8 as i64) > (1 as i32 as i64) { pc += 3 }
    jeq r8, 0, lbb_42283                            if r8 == (0 as i32 as i64 as u64) { pc += 8 }
    ldxb r0, [r6+0xf]                       
    ja lbb_42284                                    if true { pc += 7 }
lbb_42277:
    mov64 r7, r6                                    r7 = r6
    jeq r8, 2, lbb_42287                            if r8 == (2 as i32 as i64 as u64) { pc += 8 }
    mov64 r1, r6                                    r1 = r6
    rsh64 r1, 32                                    r1 >>= 32   ///  r1 = r1.wrapping_shr(32)
    call function_42058                     
    ja lbb_42284                                    if true { pc += 1 }
lbb_42283:
    ldxb r0, [r6+0x10]                      
lbb_42284:
    and64 r0, 255                                   r0 &= 255   ///  r0 = r0.and(255)
    mov64 r7, r6                                    r7 = r6
    jeq r0, 37, lbb_42289                           if r0 == (37 as i32 as i64 as u64) { pc += 2 }
lbb_42287:
    mov64 r0, r7                                    r0 = r7
    exit                                    
lbb_42289:
    call function_42215                     
    mov64 r7, r0                                    r7 = r0
    mov64 r1, r8                                    r1 = r8
    add64 r1, -2                                    r1 += -2   ///  r1 = r1.wrapping_add(-2 as i32 as i64 as u64)
    mov64 r2, 2                                     r2 = 2 as i32 as i64 as u64
    jgt r2, r1, lbb_42287                           if r2 > r1 { pc += -8 }
    jeq r8, 0, lbb_42287                            if r8 == (0 as i32 as i64 as u64) { pc += -9 }
    ldxdw r8, [r6-0x1]                      
    ldxdw r9, [r6+0x7]                      
    ldxdw r2, [r9+0x0]                      
    mov64 r1, r8                                    r1 = r8
    callx r2                                
    add64 r6, -1                                    r6 += -1   ///  r6 = r6.wrapping_add(-1 as i32 as i64 as u64)
    ldxdw r2, [r9+0x8]                      
    jeq r2, 0, lbb_42307                            if r2 == (0 as i32 as i64 as u64) { pc += 3 }
    ldxdw r3, [r9+0x10]                     
    mov64 r1, r8                                    r1 = r8
    call function_21385                     
lbb_42307:
    mov64 r1, r6                                    r1 = r6
    mov64 r2, 24                                    r2 = 24 as i32 as i64 as u64
    mov64 r3, 8                                     r3 = 8 as i32 as i64 as u64
    call function_21385                     
    ja lbb_42287                                    if true { pc += -25 }

function_42312:
    mov64 r3, r2                                    r3 = r2
    ldxdw r2, [r1+0x8]                      
    ldxdw r1, [r1+0x0]                      
    call function_46189                     
    exit                                    

function_42317:
    ldxdw r3, [r1+0x0]                      
    ldxdw r1, [r3+0x0]                      
    ldxdw r3, [r3+0x8]                      
    ldxdw r3, [r3+0x18]                     
    callx r3                                
    exit                                    

function_42323:
    mov64 r3, r2                                    r3 = r2
    ldxdw r2, [r1+0x8]                      
    ldxdw r1, [r1+0x0]                      
    call function_46428                     
    exit                                    

function_42328:
    ldxw r3, [r2+0x34]                      
    mov64 r4, r3                                    r4 = r3
    and64 r4, 16                                    r4 &= 16   ///  r4 = r4.and(16)
    jne r4, 0, lbb_42337                            if r4 != (0 as i32 as i64 as u64) { pc += 5 }
    and64 r3, 32                                    r3 &= 32   ///  r3 = r3.and(32)
    jeq r3, 0, lbb_42335                            if r3 == (0 as i32 as i64 as u64) { pc += 1 }
    ja lbb_42339                                    if true { pc += 4 }
lbb_42335:
    call function_48052                     
    ja lbb_42340                                    if true { pc += 3 }
lbb_42337:
    call function_47567                     
    ja lbb_42340                                    if true { pc += 1 }
lbb_42339:
    call function_47614                     
lbb_42340:
    exit                                    

function_42341:
    exit                                    

function_42342:
    exit                                    

function_42343:
    exit                                    

function_42344:
    ldxdw r2, [r1+0x8]                      
    jeq r2, 0, lbb_42349                            if r2 == (0 as i32 as i64 as u64) { pc += 3 }
    ldxdw r1, [r1+0x0]                      
    mov64 r3, 1                                     r3 = 1 as i32 as i64 as u64
    call function_21385                     
lbb_42349:
    exit                                    

function_42350:
    mov64 r3, r2                                    r3 = r2
    ldxdw r2, [r1+0x10]                     
    ldxdw r1, [r1+0x0]                      
    call function_46189                     
    exit                                    

function_42355:
    mov64 r3, r2                                    r3 = r2
    ldxdw r2, [r1+0x10]                     
    ldxdw r1, [r1+0x0]                      
    call function_46428                     
    exit                                    

function_42360:
    lsh64 r1, 32                                    r1 <<= 32   ///  r1 = r1.wrapping_shl(32)
    rsh64 r1, 32                                    r1 >>= 32   ///  r1 = r1.wrapping_shr(32)
    jsgt r1, 19, lbb_42372                          if (r1 as i64) > (19 as i32 as i64) { pc += 9 }
    jsgt r1, 9, lbb_42387                           if (r1 as i64) > (9 as i32 as i64) { pc += 23 }
    jsgt r1, 4, lbb_42401                           if (r1 as i64) > (4 as i32 as i64) { pc += 36 }
    jsgt r1, 1, lbb_42419                           if (r1 as i64) > (1 as i32 as i64) { pc += 53 }
    mov64 r0, 0                                     r0 = 0 as i32 as i64 as u64
    jeq r1, 0, lbb_42516                            if r1 == (0 as i32 as i64 as u64) { pc += 148 }
    jeq r1, 1, lbb_42370                            if r1 == (1 as i32 as i64 as u64) { pc += 1 }
    ja lbb_42515                                    if true { pc += 145 }
lbb_42370:
    mov64 r0, 1                                     r0 = 1 as i32 as i64 as u64
    ja lbb_42516                                    if true { pc += 144 }
lbb_42372:
    jsgt r1, 29, lbb_42380                          if (r1 as i64) > (29 as i32 as i64) { pc += 7 }
    jsgt r1, 24, lbb_42407                          if (r1 as i64) > (24 as i32 as i64) { pc += 33 }
    jsgt r1, 21, lbb_42425                          if (r1 as i64) > (21 as i32 as i64) { pc += 50 }
    jeq r1, 20, lbb_42467                           if r1 == (20 as i32 as i64 as u64) { pc += 91 }
    jeq r1, 21, lbb_42378                           if r1 == (21 as i32 as i64 as u64) { pc += 1 }
    ja lbb_42515                                    if true { pc += 137 }
lbb_42378:
    mov64 r0, 21                                    r0 = 21 as i32 as i64 as u64
    ja lbb_42516                                    if true { pc += 136 }
lbb_42380:
    jsgt r1, 34, lbb_42394                          if (r1 as i64) > (34 as i32 as i64) { pc += 13 }
    jsgt r1, 31, lbb_42431                          if (r1 as i64) > (31 as i32 as i64) { pc += 49 }
    jeq r1, 30, lbb_42469                           if r1 == (30 as i32 as i64 as u64) { pc += 86 }
    jeq r1, 31, lbb_42385                           if r1 == (31 as i32 as i64 as u64) { pc += 1 }
    ja lbb_42515                                    if true { pc += 130 }
lbb_42385:
    mov64 r0, 31                                    r0 = 31 as i32 as i64 as u64
    ja lbb_42516                                    if true { pc += 129 }
lbb_42387:
    jsgt r1, 14, lbb_42413                          if (r1 as i64) > (14 as i32 as i64) { pc += 25 }
    jsgt r1, 11, lbb_42437                          if (r1 as i64) > (11 as i32 as i64) { pc += 48 }
    jeq r1, 10, lbb_42471                           if r1 == (10 as i32 as i64 as u64) { pc += 81 }
    jeq r1, 11, lbb_42392                           if r1 == (11 as i32 as i64 as u64) { pc += 1 }
    ja lbb_42515                                    if true { pc += 123 }
lbb_42392:
    mov64 r0, 11                                    r0 = 11 as i32 as i64 as u64
    ja lbb_42516                                    if true { pc += 122 }
lbb_42394:
    jsgt r1, 37, lbb_42443                          if (r1 as i64) > (37 as i32 as i64) { pc += 48 }
    jeq r1, 35, lbb_42473                           if r1 == (35 as i32 as i64 as u64) { pc += 77 }
    jeq r1, 36, lbb_42475                           if r1 == (36 as i32 as i64 as u64) { pc += 78 }
    jeq r1, 37, lbb_42399                           if r1 == (37 as i32 as i64 as u64) { pc += 1 }
    ja lbb_42515                                    if true { pc += 116 }
lbb_42399:
    mov64 r0, 37                                    r0 = 37 as i32 as i64 as u64
    ja lbb_42516                                    if true { pc += 115 }
lbb_42401:
    jsgt r1, 6, lbb_42449                           if (r1 as i64) > (6 as i32 as i64) { pc += 47 }
    jeq r1, 5, lbb_42477                            if r1 == (5 as i32 as i64 as u64) { pc += 74 }
    jeq r1, 6, lbb_42405                            if r1 == (6 as i32 as i64 as u64) { pc += 1 }
    ja lbb_42515                                    if true { pc += 110 }
lbb_42405:
    mov64 r0, 6                                     r0 = 6 as i32 as i64 as u64
    ja lbb_42516                                    if true { pc += 109 }
lbb_42407:
    jsgt r1, 26, lbb_42455                          if (r1 as i64) > (26 as i32 as i64) { pc += 47 }
    jeq r1, 25, lbb_42479                           if r1 == (25 as i32 as i64 as u64) { pc += 70 }
    jeq r1, 26, lbb_42411                           if r1 == (26 as i32 as i64 as u64) { pc += 1 }
    ja lbb_42515                                    if true { pc += 104 }
lbb_42411:
    mov64 r0, 26                                    r0 = 26 as i32 as i64 as u64
    ja lbb_42516                                    if true { pc += 103 }
lbb_42413:
    jsgt r1, 16, lbb_42461                          if (r1 as i64) > (16 as i32 as i64) { pc += 47 }
    jeq r1, 15, lbb_42481                           if r1 == (15 as i32 as i64 as u64) { pc += 66 }
    jeq r1, 16, lbb_42417                           if r1 == (16 as i32 as i64 as u64) { pc += 1 }
    ja lbb_42515                                    if true { pc += 98 }
lbb_42417:
    mov64 r0, 16                                    r0 = 16 as i32 as i64 as u64
    ja lbb_42516                                    if true { pc += 97 }
lbb_42419:
    jeq r1, 2, lbb_42483                            if r1 == (2 as i32 as i64 as u64) { pc += 63 }
    jeq r1, 3, lbb_42485                            if r1 == (3 as i32 as i64 as u64) { pc += 64 }
    jeq r1, 4, lbb_42423                            if r1 == (4 as i32 as i64 as u64) { pc += 1 }
    ja lbb_42515                                    if true { pc += 92 }
lbb_42423:
    mov64 r0, 4                                     r0 = 4 as i32 as i64 as u64
    ja lbb_42516                                    if true { pc += 91 }
lbb_42425:
    jeq r1, 22, lbb_42487                           if r1 == (22 as i32 as i64 as u64) { pc += 61 }
    jeq r1, 23, lbb_42489                           if r1 == (23 as i32 as i64 as u64) { pc += 62 }
    jeq r1, 24, lbb_42429                           if r1 == (24 as i32 as i64 as u64) { pc += 1 }
    ja lbb_42515                                    if true { pc += 86 }
lbb_42429:
    mov64 r0, 24                                    r0 = 24 as i32 as i64 as u64
    ja lbb_42516                                    if true { pc += 85 }
lbb_42431:
    jeq r1, 32, lbb_42491                           if r1 == (32 as i32 as i64 as u64) { pc += 59 }
    jeq r1, 33, lbb_42493                           if r1 == (33 as i32 as i64 as u64) { pc += 60 }
    jeq r1, 34, lbb_42435                           if r1 == (34 as i32 as i64 as u64) { pc += 1 }
    ja lbb_42515                                    if true { pc += 80 }
lbb_42435:
    mov64 r0, 34                                    r0 = 34 as i32 as i64 as u64
    ja lbb_42516                                    if true { pc += 79 }
lbb_42437:
    jeq r1, 12, lbb_42495                           if r1 == (12 as i32 as i64 as u64) { pc += 57 }
    jeq r1, 13, lbb_42497                           if r1 == (13 as i32 as i64 as u64) { pc += 58 }
    jeq r1, 14, lbb_42441                           if r1 == (14 as i32 as i64 as u64) { pc += 1 }
    ja lbb_42515                                    if true { pc += 74 }
lbb_42441:
    mov64 r0, 14                                    r0 = 14 as i32 as i64 as u64
    ja lbb_42516                                    if true { pc += 73 }
lbb_42443:
    jeq r1, 38, lbb_42499                           if r1 == (38 as i32 as i64 as u64) { pc += 55 }
    jeq r1, 39, lbb_42501                           if r1 == (39 as i32 as i64 as u64) { pc += 56 }
    jeq r1, 40, lbb_42447                           if r1 == (40 as i32 as i64 as u64) { pc += 1 }
    ja lbb_42515                                    if true { pc += 68 }
lbb_42447:
    mov64 r0, 40                                    r0 = 40 as i32 as i64 as u64
    ja lbb_42516                                    if true { pc += 67 }
lbb_42449:
    jeq r1, 7, lbb_42503                            if r1 == (7 as i32 as i64 as u64) { pc += 53 }
    jeq r1, 8, lbb_42505                            if r1 == (8 as i32 as i64 as u64) { pc += 54 }
    jeq r1, 9, lbb_42453                            if r1 == (9 as i32 as i64 as u64) { pc += 1 }
    ja lbb_42515                                    if true { pc += 62 }
lbb_42453:
    mov64 r0, 9                                     r0 = 9 as i32 as i64 as u64
    ja lbb_42516                                    if true { pc += 61 }
lbb_42455:
    jeq r1, 27, lbb_42507                           if r1 == (27 as i32 as i64 as u64) { pc += 51 }
    jeq r1, 28, lbb_42509                           if r1 == (28 as i32 as i64 as u64) { pc += 52 }
    jeq r1, 29, lbb_42459                           if r1 == (29 as i32 as i64 as u64) { pc += 1 }
    ja lbb_42515                                    if true { pc += 56 }
lbb_42459:
    mov64 r0, 29                                    r0 = 29 as i32 as i64 as u64
    ja lbb_42516                                    if true { pc += 55 }
lbb_42461:
    jeq r1, 17, lbb_42511                           if r1 == (17 as i32 as i64 as u64) { pc += 49 }
    jeq r1, 18, lbb_42513                           if r1 == (18 as i32 as i64 as u64) { pc += 50 }
    jeq r1, 19, lbb_42465                           if r1 == (19 as i32 as i64 as u64) { pc += 1 }
    ja lbb_42515                                    if true { pc += 50 }
lbb_42465:
    mov64 r0, 19                                    r0 = 19 as i32 as i64 as u64
    ja lbb_42516                                    if true { pc += 49 }
lbb_42467:
    mov64 r0, 20                                    r0 = 20 as i32 as i64 as u64
    ja lbb_42516                                    if true { pc += 47 }
lbb_42469:
    mov64 r0, 30                                    r0 = 30 as i32 as i64 as u64
    ja lbb_42516                                    if true { pc += 45 }
lbb_42471:
    mov64 r0, 10                                    r0 = 10 as i32 as i64 as u64
    ja lbb_42516                                    if true { pc += 43 }
lbb_42473:
    mov64 r0, 35                                    r0 = 35 as i32 as i64 as u64
    ja lbb_42516                                    if true { pc += 41 }
lbb_42475:
    mov64 r0, 36                                    r0 = 36 as i32 as i64 as u64
    ja lbb_42516                                    if true { pc += 39 }
lbb_42477:
    mov64 r0, 5                                     r0 = 5 as i32 as i64 as u64
    ja lbb_42516                                    if true { pc += 37 }
lbb_42479:
    mov64 r0, 25                                    r0 = 25 as i32 as i64 as u64
    ja lbb_42516                                    if true { pc += 35 }
lbb_42481:
    mov64 r0, 15                                    r0 = 15 as i32 as i64 as u64
    ja lbb_42516                                    if true { pc += 33 }
lbb_42483:
    mov64 r0, 2                                     r0 = 2 as i32 as i64 as u64
    ja lbb_42516                                    if true { pc += 31 }
lbb_42485:
    mov64 r0, 3                                     r0 = 3 as i32 as i64 as u64
    ja lbb_42516                                    if true { pc += 29 }
lbb_42487:
    mov64 r0, 22                                    r0 = 22 as i32 as i64 as u64
    ja lbb_42516                                    if true { pc += 27 }
lbb_42489:
    mov64 r0, 23                                    r0 = 23 as i32 as i64 as u64
    ja lbb_42516                                    if true { pc += 25 }
lbb_42491:
    mov64 r0, 32                                    r0 = 32 as i32 as i64 as u64
    ja lbb_42516                                    if true { pc += 23 }
lbb_42493:
    mov64 r0, 33                                    r0 = 33 as i32 as i64 as u64
    ja lbb_42516                                    if true { pc += 21 }
lbb_42495:
    mov64 r0, 12                                    r0 = 12 as i32 as i64 as u64
    ja lbb_42516                                    if true { pc += 19 }
lbb_42497:
    mov64 r0, 13                                    r0 = 13 as i32 as i64 as u64
    ja lbb_42516                                    if true { pc += 17 }
lbb_42499:
    mov64 r0, 38                                    r0 = 38 as i32 as i64 as u64
    ja lbb_42516                                    if true { pc += 15 }
lbb_42501:
    mov64 r0, 39                                    r0 = 39 as i32 as i64 as u64
    ja lbb_42516                                    if true { pc += 13 }
lbb_42503:
    mov64 r0, 7                                     r0 = 7 as i32 as i64 as u64
    ja lbb_42516                                    if true { pc += 11 }
lbb_42505:
    mov64 r0, 8                                     r0 = 8 as i32 as i64 as u64
    ja lbb_42516                                    if true { pc += 9 }
lbb_42507:
    mov64 r0, 27                                    r0 = 27 as i32 as i64 as u64
    ja lbb_42516                                    if true { pc += 7 }
lbb_42509:
    mov64 r0, 28                                    r0 = 28 as i32 as i64 as u64
    ja lbb_42516                                    if true { pc += 5 }
lbb_42511:
    mov64 r0, 17                                    r0 = 17 as i32 as i64 as u64
    ja lbb_42516                                    if true { pc += 3 }
lbb_42513:
    mov64 r0, 18                                    r0 = 18 as i32 as i64 as u64
    ja lbb_42516                                    if true { pc += 1 }
lbb_42515:
    mov64 r0, 41                                    r0 = 41 as i32 as i64 as u64
lbb_42516:
    exit                                    

function_42517:
    call function_42735                     
    exit                                    

function_42519:
    mov64 r3, 16                                    r3 = 16 as i32 as i64 as u64
    and64 r2, 255                                   r2 &= 255   ///  r2 = r2.and(255)
    jsgt r2, 19, lbb_42532                          if (r2 as i64) > (19 as i32 as i64) { pc += 10 }
    jsgt r2, 9, lbb_42547                           if (r2 as i64) > (9 as i32 as i64) { pc += 24 }
    jsgt r2, 4, lbb_42560                           if (r2 as i64) > (4 as i32 as i64) { pc += 36 }
    jsgt r2, 1, lbb_42578                           if (r2 as i64) > (1 as i32 as i64) { pc += 53 }
    lddw r4, 0x10005fc98 --> b"entity not found\x00\x00\x00\x00\x00\x00\x00\x00\x01\x00\x00\x00\x00\x00\…        r4 load str located at 4295359640
    jeq r2, 0, lbb_42716                            if r2 == (0 as i32 as i64 as u64) { pc += 188 }
    lddw r4, 0x100063780 --> b"permission denied"        r4 load str located at 4295374720
    mov64 r3, 17                                    r3 = 17 as i32 as i64 as u64
    ja lbb_42716                                    if true { pc += 184 }
lbb_42532:
    jsgt r2, 29, lbb_42540                          if (r2 as i64) > (29 as i32 as i64) { pc += 7 }
    jsgt r2, 24, lbb_42566                          if (r2 as i64) > (24 as i32 as i64) { pc += 32 }
    jsgt r2, 21, lbb_42583                          if (r2 as i64) > (21 as i32 as i64) { pc += 48 }
    jeq r2, 20, lbb_42624                           if r2 == (20 as i32 as i64 as u64) { pc += 88 }
    lddw r4, 0x1000638f7 --> b"invalid data"        r4 load str located at 4295375095
    mov64 r3, 12                                    r3 = 12 as i32 as i64 as u64
    ja lbb_42716                                    if true { pc += 176 }
lbb_42540:
    jsgt r2, 34, lbb_42553                          if (r2 as i64) > (34 as i32 as i64) { pc += 12 }
    jsgt r2, 31, lbb_42588                          if (r2 as i64) > (31 as i32 as i64) { pc += 46 }
    jeq r2, 30, lbb_42628                           if r2 == (30 as i32 as i64 as u64) { pc += 85 }
    lddw r4, 0x100063975 --> b"cross-device link or rename"        r4 load str located at 4295375221
    mov64 r3, 27                                    r3 = 27 as i32 as i64 as u64
    ja lbb_42716                                    if true { pc += 169 }
lbb_42547:
    jsgt r2, 14, lbb_42572                          if (r2 as i64) > (14 as i32 as i64) { pc += 24 }
    jsgt r2, 11, lbb_42594                          if (r2 as i64) > (11 as i32 as i64) { pc += 45 }
    jeq r2, 10, lbb_42632                           if r2 == (10 as i32 as i64 as u64) { pc += 82 }
    lddw r4, 0x100063804 --> b"broken pipeentity already existsoperation would bl"        r4 load str located at 4295374852
    ja lbb_42691                                    if true { pc += 138 }
lbb_42553:
    jsgt r2, 37, lbb_42600                          if (r2 as i64) > (37 as i32 as i64) { pc += 46 }
    jeq r2, 35, lbb_42636                           if r2 == (35 as i32 as i64 as u64) { pc += 81 }
    jeq r2, 36, lbb_42640                           if r2 == (36 as i32 as i64 as u64) { pc += 84 }
    lddw r4, 0x1000639d4 --> b"unexpected end of file"        r4 load str located at 4295375316
    mov64 r3, 22                                    r3 = 22 as i32 as i64 as u64
    ja lbb_42716                                    if true { pc += 156 }
lbb_42560:
    jsgt r2, 6, lbb_42606                           if (r2 as i64) > (6 as i32 as i64) { pc += 45 }
    jeq r2, 5, lbb_42643                            if r2 == (5 as i32 as i64 as u64) { pc += 81 }
    lddw r4, 0x1000637b6 --> b"connection aborted"        r4 load str located at 4295374774
    mov64 r3, 18                                    r3 = 18 as i32 as i64 as u64
    ja lbb_42716                                    if true { pc += 150 }
lbb_42566:
    jsgt r2, 26, lbb_42612                          if (r2 as i64) > (26 as i32 as i64) { pc += 45 }
    jeq r2, 25, lbb_42647                           if r2 == (25 as i32 as i64 as u64) { pc += 79 }
    lddw r4, 0x10006392d --> b"filesystem quota exceeded"        r4 load str located at 4295375149
    mov64 r3, 25                                    r3 = 25 as i32 as i64 as u64
    ja lbb_42716                                    if true { pc += 144 }
lbb_42572:
    jsgt r2, 16, lbb_42618                          if (r2 as i64) > (16 as i32 as i64) { pc += 45 }
    jeq r2, 15, lbb_42651                           if r2 == (15 as i32 as i64 as u64) { pc += 77 }
    lddw r4, 0x100063856 --> b"directory not empty"        r4 load str located at 4295374934
    mov64 r3, 19                                    r3 = 19 as i32 as i64 as u64
    ja lbb_42716                                    if true { pc += 138 }
lbb_42578:
    jeq r2, 2, lbb_42655                            if r2 == (2 as i32 as i64 as u64) { pc += 76 }
    jeq r2, 3, lbb_42659                            if r2 == (3 as i32 as i64 as u64) { pc += 79 }
    lddw r4, 0x10005fce8 --> b"host unreachableinvalid filenamerange end index , "        r4 load str located at 4295359720
    ja lbb_42716                                    if true { pc += 133 }
lbb_42583:
    jeq r2, 22, lbb_42662                           if r2 == (22 as i32 as i64 as u64) { pc += 78 }
    jeq r2, 23, lbb_42666                           if r2 == (23 as i32 as i64 as u64) { pc += 81 }
    lddw r4, 0x10005fd98 --> b"no storage space\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\…        r4 load str located at 4295359896
    ja lbb_42716                                    if true { pc += 128 }
lbb_42588:
    jeq r2, 32, lbb_42670                           if r2 == (32 as i32 as i64 as u64) { pc += 81 }
    jeq r2, 33, lbb_42674                           if r2 == (33 as i32 as i64 as u64) { pc += 84 }
    lddw r4, 0x10006399e --> b"argument list too long"        r4 load str located at 4295375262
    mov64 r3, 22                                    r3 = 22 as i32 as i64 as u64
    ja lbb_42716                                    if true { pc += 122 }
lbb_42594:
    jeq r2, 12, lbb_42677                           if r2 == (12 as i32 as i64 as u64) { pc += 82 }
    jeq r2, 13, lbb_42681                           if r2 == (13 as i32 as i64 as u64) { pc += 85 }
    lddw r4, 0x100063839 --> b"not a directory"        r4 load str located at 4295374905
    mov64 r3, 15                                    r3 = 15 as i32 as i64 as u64
    ja lbb_42716                                    if true { pc += 116 }
lbb_42600:
    jeq r2, 38, lbb_42685                           if r2 == (38 as i32 as i64 as u64) { pc += 84 }
    jeq r2, 39, lbb_42689                           if r2 == (39 as i32 as i64 as u64) { pc += 87 }
    lddw r4, 0x100063a02 --> b"uncategorized error"        r4 load str located at 4295375362
    mov64 r3, 19                                    r3 = 19 as i32 as i64 as u64
    ja lbb_42716                                    if true { pc += 110 }
lbb_42606:
    jeq r2, 7, lbb_42693                            if r2 == (7 as i32 as i64 as u64) { pc += 86 }
    jeq r2, 8, lbb_42697                            if r2 == (8 as i32 as i64 as u64) { pc += 89 }
    lddw r4, 0x1000637e3 --> b"address not available"        r4 load str located at 4295374819
    mov64 r3, 21                                    r3 = 21 as i32 as i64 as u64
    ja lbb_42716                                    if true { pc += 104 }
lbb_42612:
    jeq r2, 27, lbb_42701                           if r2 == (27 as i32 as i64 as u64) { pc += 88 }
    jeq r2, 28, lbb_42705                           if r2 == (28 as i32 as i64 as u64) { pc += 91 }
    lddw r4, 0x100063961 --> b"executable file busy"        r4 load str located at 4295375201
    mov64 r3, 20                                    r3 = 20 as i32 as i64 as u64
    ja lbb_42716                                    if true { pc += 98 }
lbb_42618:
    jeq r2, 17, lbb_42709                           if r2 == (17 as i32 as i64 as u64) { pc += 90 }
    jeq r2, 18, lbb_42713                           if r2 == (18 as i32 as i64 as u64) { pc += 93 }
    lddw r4, 0x1000638c7 --> b"stale network file handle"        r4 load str located at 4295375047
    mov64 r3, 25                                    r3 = 25 as i32 as i64 as u64
    ja lbb_42716                                    if true { pc += 92 }
lbb_42624:
    lddw r4, 0x1000638e0 --> b"invalid input parameter"        r4 load str located at 4295375072
    mov64 r3, 23                                    r3 = 23 as i32 as i64 as u64
    ja lbb_42716                                    if true { pc += 88 }
lbb_42628:
    lddw r4, 0x100060978 --> b"deadlock"            r4 load str located at 4295362936
    mov64 r3, 8                                     r3 = 8 as i32 as i64 as u64
    ja lbb_42716                                    if true { pc += 84 }
lbb_42632:
    lddw r4, 0x1000637f8 --> b"network down"        r4 load str located at 4295374840
    mov64 r3, 12                                    r3 = 12 as i32 as i64 as u64
    ja lbb_42716                                    if true { pc += 80 }
lbb_42636:
    lddw r4, 0x1000639b4 --> b"operation interrupted"        r4 load str located at 4295375284
    mov64 r3, 21                                    r3 = 21 as i32 as i64 as u64
    ja lbb_42716                                    if true { pc += 76 }
lbb_42640:
    lddw r4, 0x1000639c9 --> b"unsupportedunexpected end of fileout of memoryothe"        r4 load str located at 4295375305
    ja lbb_42691                                    if true { pc += 48 }
lbb_42643:
    lddw r4, 0x1000637a3 --> b"network unreachable"        r4 load str located at 4295374755
    mov64 r3, 19                                    r3 = 19 as i32 as i64 as u64
    ja lbb_42716                                    if true { pc += 69 }
lbb_42647:
    lddw r4, 0x100063916 --> b"seek on unseekable file"        r4 load str located at 4295375126
    mov64 r3, 23                                    r3 = 23 as i32 as i64 as u64
    ja lbb_42716                                    if true { pc += 65 }
lbb_42651:
    lddw r4, 0x100063848 --> b"is a directory"        r4 load str located at 4295374920
    mov64 r3, 14                                    r3 = 14 as i32 as i64 as u64
    ja lbb_42716                                    if true { pc += 61 }
lbb_42655:
    lddw r4, 0x100063791 --> b"connection refused"        r4 load str located at 4295374737
    mov64 r3, 18                                    r3 = 18 as i32 as i64 as u64
    ja lbb_42716                                    if true { pc += 57 }
lbb_42659:
    lddw r4, 0x10005fc48 --> b"connection reset) when slicing `). Min allowed: ov"        r4 load str located at 4295359560
    ja lbb_42716                                    if true { pc += 54 }
lbb_42662:
    lddw r4, 0x100063903 --> b"timed out"           r4 load str located at 4295375107
    mov64 r3, 9                                     r3 = 9 as i32 as i64 as u64
    ja lbb_42716                                    if true { pc += 50 }
lbb_42666:
    lddw r4, 0x10006390c --> b"write zero"          r4 load str located at 4295375116
    mov64 r3, 10                                    r3 = 10 as i32 as i64 as u64
    ja lbb_42716                                    if true { pc += 46 }
lbb_42670:
    lddw r4, 0x100063990 --> b"too many links"        r4 load str located at 4295375248
    mov64 r3, 14                                    r3 = 14 as i32 as i64 as u64
    ja lbb_42716                                    if true { pc += 42 }
lbb_42674:
    lddw r4, 0x10005fcf8 --> b"invalid filenamerange end index , token_program= w"        r4 load str located at 4295359736
    ja lbb_42716                                    if true { pc += 39 }
lbb_42677:
    lddw r4, 0x10006380f --> b"entity already exists"        r4 load str located at 4295374863
    mov64 r3, 21                                    r3 = 21 as i32 as i64 as u64
    ja lbb_42716                                    if true { pc += 35 }
lbb_42681:
    lddw r4, 0x100063824 --> b"operation would block"        r4 load str located at 4295374884
    mov64 r3, 21                                    r3 = 21 as i32 as i64 as u64
    ja lbb_42716                                    if true { pc += 31 }
lbb_42685:
    lddw r4, 0x1000639ea --> b"out of memory"        r4 load str located at 4295375338
    mov64 r3, 13                                    r3 = 13 as i32 as i64 as u64
    ja lbb_42716                                    if true { pc += 27 }
lbb_42689:
    lddw r4, 0x1000639f7 --> b"other error"         r4 load str located at 4295375351
lbb_42691:
    mov64 r3, 11                                    r3 = 11 as i32 as i64 as u64
    ja lbb_42716                                    if true { pc += 23 }
lbb_42693:
    lddw r4, 0x1000637c8 --> b"not connected"        r4 load str located at 4295374792
    mov64 r3, 13                                    r3 = 13 as i32 as i64 as u64
    ja lbb_42716                                    if true { pc += 19 }
lbb_42697:
    lddw r4, 0x1000637d5 --> b"address in use"        r4 load str located at 4295374805
    mov64 r3, 14                                    r3 = 14 as i32 as i64 as u64
    ja lbb_42716                                    if true { pc += 15 }
lbb_42701:
    lddw r4, 0x100063946 --> b"file too large"        r4 load str located at 4295375174
    mov64 r3, 14                                    r3 = 14 as i32 as i64 as u64
    ja lbb_42716                                    if true { pc += 11 }
lbb_42705:
    lddw r4, 0x100063954 --> b"resource busy"        r4 load str located at 4295375188
    mov64 r3, 13                                    r3 = 13 as i32 as i64 as u64
    ja lbb_42716                                    if true { pc += 7 }
lbb_42709:
    lddw r4, 0x100063869 --> b"read-only filesystem or storage medium"        r4 load str located at 4295374953
    mov64 r3, 38                                    r3 = 38 as i32 as i64 as u64
    ja lbb_42716                                    if true { pc += 3 }
lbb_42713:
    lddw r4, 0x10006388f --> b"filesystem loop or indirection limit (e.g. symlink loop)"        r4 load str located at 4295374991
    mov64 r3, 56                                    r3 = 56 as i32 as i64 as u64
lbb_42716:
    stxdw [r1+0x8], r3                      
    stxdw [r1+0x0], r4                      
    exit                                    

function_42719:
    mov64 r7, r3                                    r7 = r3
    mov64 r6, r2                                    r6 = r2
    mov64 r8, r1                                    r8 = r1
    mov64 r1, 24                                    r1 = 24 as i32 as i64 as u64
    mov64 r2, 8                                     r2 = 8 as i32 as i64 as u64
    call function_21359                     
    jne r0, 0, lbb_42730                            if r0 != (0 as i32 as i64 as u64) { pc += 4 }
    mov64 r1, 8                                     r1 = 8 as i32 as i64 as u64
    mov64 r2, 24                                    r2 = 24 as i32 as i64 as u64
    call function_43400                     
    syscall [invalid]                       
lbb_42730:
    stxb [r0+0x10], r8                      
    stxdw [r0+0x8], r7                      
    stxdw [r0+0x0], r6                      
    add64 r0, 1                                     r0 += 1   ///  r0 = r0.wrapping_add(1 as i32 as i64 as u64)
    exit                                    

function_42735:
    mov64 r7, r2                                    r7 = r2
    ldxdw r6, [r1+0x0]                      
    mov64 r1, r6                                    r1 = r6
    and64 r1, 3                                     r1 &= 3   ///  r1 = r1.and(3)
    jsgt r1, 1, lbb_42771                           if (r1 as i64) > (1 as i32 as i64) { pc += 31 }
    jeq r1, 0, lbb_42793                            if r1 == (0 as i32 as i64 as u64) { pc += 52 }
    mov64 r1, r6                                    r1 = r6
    add64 r1, -1                                    r1 += -1   ///  r1 = r1.wrapping_add(-1 as i32 as i64 as u64)
    stxdw [r10-0x18], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -24                                   r1 += -24   ///  r1 = r1.wrapping_add(-24 as i32 as i64 as u64)
    stxdw [r10-0xfd8], r1                   
    lddw r1, 0x100067120 --> b"\x00\x00\x00\x00H,\x05\x00\x08\x00\x00\x00\x00\x00\x00\x00\x08\x00\x00\x0…        r1 load str located at 4295389472
    stxdw [r10-0xfd0], r1                   
    mov64 r1, 5                                     r1 = 5 as i32 as i64 as u64
    stxdw [r10-0xfe0], r1                   
    lddw r1, 0x100063a29 --> b"error (os error )ConnectionRefusedConnectionResetH"        r1 load str located at 4295375401
    stxdw [r10-0xfe8], r1                   
    lddw r1, 0x1000670c0 --> b"\x00\x00\x00\x00X,\x05\x00\x01\x00\x00\x00\x00\x00\x00\x00\x01\x00\x00\x0…        r1 load str located at 4295389376
    stxdw [r10-0xff0], r1                   
    add64 r6, 15                                    r6 += 15   ///  r6 = r6.wrapping_add(15 as i32 as i64 as u64)
    stxdw [r10-0xff8], r6                   
    mov64 r1, 4                                     r1 = 4 as i32 as i64 as u64
    stxdw [r10-0x1000], r1                  
    mov64 r5, r10                                   r5 = r10
    mov64 r1, r7                                    r1 = r7
    lddw r2, 0x100063a23 --> b"Custom"              r2 load str located at 4295375395
    mov64 r3, 6                                     r3 = 6 as i32 as i64 as u64
    lddw r4, 0x10005fbc0 --> b"kindbids != Some <= x1e-true to None    asksBadUne"        r4 load str located at 4295359424
    call function_45972                     
    ja lbb_42820                                    if true { pc += 49 }
lbb_42771:
    jeq r1, 2, lbb_42823                            if r1 == (2 as i32 as i64 as u64) { pc += 51 }
    rsh64 r6, 32                                    r6 >>= 32   ///  r6 = r6.wrapping_shr(32)
    mov64 r1, r6                                    r1 = r6
    call function_42360                     
    stxb [r10-0x30], r0                     
    mov64 r6, r10                                   r6 = r10
    add64 r6, -24                                   r6 += -24   ///  r6 = r6.wrapping_add(-24 as i32 as i64 as u64)
    mov64 r1, r6                                    r1 = r6
    mov64 r2, r7                                    r2 = r7
    lddw r3, 0x10005fbbc --> b"Kind"                r3 load str located at 4295359420
    mov64 r4, 4                                     r4 = 4 as i32 as i64 as u64
    call function_46086                     
    mov64 r2, r10                                   r2 = r10
    add64 r2, -48                                   r2 += -48   ///  r2 = r2.wrapping_add(-48 as i32 as i64 as u64)
    mov64 r1, r6                                    r1 = r6
    lddw r3, 0x1000670c0 --> b"\x00\x00\x00\x00X,\x05\x00\x01\x00\x00\x00\x00\x00\x00\x00\x01\x00\x00\x0…        r3 load str located at 4295389376
    call function_44672                     
    mov64 r1, r0                                    r1 = r0
    call function_44762                     
    ja lbb_42820                                    if true { pc += 27 }
lbb_42793:
    mov64 r8, r10                                   r8 = r10
    add64 r8, -24                                   r8 += -24   ///  r8 = r8.wrapping_add(-24 as i32 as i64 as u64)
    mov64 r1, r8                                    r1 = r8
    mov64 r2, r7                                    r2 = r7
    lddw r3, 0x100063a1e --> b"Error"               r3 load str located at 4295375390
    mov64 r4, 5                                     r4 = 5 as i32 as i64 as u64
    call function_45912                     
    mov64 r4, r6                                    r4 = r6
    add64 r4, 16                                    r4 += 16   ///  r4 = r4.wrapping_add(16 as i32 as i64 as u64)
    mov64 r1, r8                                    r1 = r8
    lddw r2, 0x10005fbc0 --> b"kind"                r2 load str located at 4295359424
    mov64 r3, 4                                     r3 = 4 as i32 as i64 as u64
    lddw r5, 0x1000670c0 --> b"\x00\x00\x00\x00X,\x05\x00\x01\x00\x00\x00\x00\x00\x00\x00\x01\x00\x00\x0…        r5 load str located at 4295389376
    call function_44516                     
    mov64 r1, r0                                    r1 = r0
    lddw r2, 0x100063a17 --> b"message"             r2 load str located at 4295375383
    mov64 r3, 7                                     r3 = 7 as i32 as i64 as u64
    mov64 r4, r6                                    r4 = r6
    lddw r5, 0x100067100 --> b"\x00\x00\x00\x00H,\x05\x00\x10\x00\x00\x00\x00\x00\x00\x00\x08\x00\x00\x0…        r5 load str located at 4295389440
    call function_44516                     
    mov64 r1, r0                                    r1 = r0
    call function_44641                     
lbb_42820:
    mov64 r6, r0                                    r6 = r0
lbb_42821:
    mov64 r0, r6                                    r0 = r6
    exit                                    
lbb_42823:
    rsh64 r6, 32                                    r6 >>= 32   ///  r6 = r6.wrapping_shr(32)
    stxw [r10-0x34], r6                     
    mov64 r6, r10                                   r6 = r10
    add64 r6, -48                                   r6 += -48   ///  r6 = r6.wrapping_add(-48 as i32 as i64 as u64)
    mov64 r1, r6                                    r1 = r6
    mov64 r2, r7                                    r2 = r7
    lddw r3, 0x100063a15 --> b"Os"                  r3 load str located at 4295375381
    mov64 r4, 2                                     r4 = 2 as i32 as i64 as u64
    call function_45912                     
    mov64 r4, r10                                   r4 = r10
    add64 r4, -52                                   r4 += -52   ///  r4 = r4.wrapping_add(-52 as i32 as i64 as u64)
    mov64 r1, r6                                    r1 = r6
    lddw r2, 0x10005fbac --> b"code"                r2 load str located at 4295359404
    mov64 r3, 4                                     r3 = 4 as i32 as i64 as u64
    lddw r5, 0x1000670a0 --> b"\x00\x00\x00\x00P,\x05\x00\x04\x00\x00\x00\x00\x00\x00\x00\x04\x00\x00\x0…        r5 load str located at 4295389344
    call function_44516                     
    mov64 r1, 39                                    r1 = 39 as i32 as i64 as u64
    stxb [r10-0x19], r1                     
    mov64 r4, r10                                   r4 = r10
    add64 r4, -25                                   r4 += -25   ///  r4 = r4.wrapping_add(-25 as i32 as i64 as u64)
    mov64 r1, r0                                    r1 = r0
    lddw r2, 0x10005fbc0 --> b"kind"                r2 load str located at 4295359424
    mov64 r3, 4                                     r3 = 4 as i32 as i64 as u64
    lddw r5, 0x1000670c0 --> b"\x00\x00\x00\x00X,\x05\x00\x01\x00\x00\x00\x00\x00\x00\x00\x01\x00\x00\x0…        r5 load str located at 4295389376
    call function_44516                     
    mov64 r6, r0                                    r6 = r0
    mov64 r7, 20                                    r7 = 20 as i32 as i64 as u64
    mov64 r1, 20                                    r1 = 20 as i32 as i64 as u64
    mov64 r2, 1                                     r2 = 1 as i32 as i64 as u64
    call function_21359                     
    jne r0, 0, lbb_42863                            if r0 != (0 as i32 as i64 as u64) { pc += 4 }
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    mov64 r2, 20                                    r2 = 20 as i32 as i64 as u64
    call function_43400                     
    syscall [invalid]                       
lbb_42863:
    mov64 r1, 1819633267                            r1 = 1819633267 as i32 as i64 as u64
    stxw [r0+0x10], r1                      
    lddw r1, 0x736563637573206e                     r1 load str located at 8315161565832880238
    stxdw [r0+0x8], r1                      
    lddw r1, 0x6f6974617265706f                     r1 load str located at 8028075772644520047
    stxdw [r0+0x0], r1                      
    stxdw [r10-0x8], r7                     
    stxdw [r10-0x10], r7                    
    stxdw [r10-0x18], r0                    
    mov64 r4, r10                                   r4 = r10
    add64 r4, -24                                   r4 += -24   ///  r4 = r4.wrapping_add(-24 as i32 as i64 as u64)
    mov64 r1, r6                                    r1 = r6
    lddw r2, 0x100063a17 --> b"message"             r2 load str located at 4295375383
    mov64 r3, 7                                     r3 = 7 as i32 as i64 as u64
    lddw r5, 0x1000670e0 --> b"\x00\x00\x00\x00`,\x05\x00\x18\x00\x00\x00\x00\x00\x00\x00\x08\x00\x00\x0…        r5 load str located at 4295389408
    call function_44516                     
    mov64 r1, r0                                    r1 = r0
    call function_44641                     
    mov64 r6, r0                                    r6 = r0
    ldxdw r2, [r10-0x10]                    
    jeq r2, 0, lbb_42821                            if r2 == (0 as i32 as i64 as u64) { pc += -67 }
    ldxdw r1, [r10-0x18]                    
    mov64 r3, 1                                     r3 = 1 as i32 as i64 as u64
    call function_21385                     
    ja lbb_42821                                    if true { pc += -71 }

function_42892:
    mov64 r6, r2                                    r6 = r2
    ldxdw r1, [r1+0x0]                      
    mov64 r2, r1                                    r2 = r1
    and64 r2, 3                                     r2 &= 3   ///  r2 = r2.and(3)
    jsgt r2, 1, lbb_42905                           if (r2 as i64) > (1 as i32 as i64) { pc += 8 }
    jeq r2, 0, lbb_42938                            if r2 == (0 as i32 as i64 as u64) { pc += 40 }
    ldxdw r2, [r1-0x1]                      
    ldxdw r1, [r1+0x7]                      
    ldxdw r3, [r1+0x20]                     
    mov64 r1, r2                                    r1 = r2
    mov64 r2, r6                                    r2 = r6
    callx r3                                
    ja lbb_42942                                    if true { pc += 37 }
lbb_42905:
    jeq r2, 2, lbb_42945                            if r2 == (2 as i32 as i64 as u64) { pc += 39 }
    rsh64 r1, 32                                    r1 >>= 32   ///  r1 = r1.wrapping_shr(32)
    call function_42360                     
    mov64 r1, r10                                   r1 = r10
    add64 r1, -224                                  r1 += -224   ///  r1 = r1.wrapping_add(-224 as i32 as i64 as u64)
    mov64 r2, r0                                    r2 = r0
    call function_42519                     
    lddw r1, 0x100052bb8 --> b"\xbf#\x00\x00\x00\x00\x00\x00y\x12\x08\x00\x00\x00\x00\x00y\x11\x00\x00\x…        r1 load str located at 4295306168
    stxdw [r10-0xc0], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -176                                  r1 += -176   ///  r1 = r1.wrapping_add(-176 as i32 as i64 as u64)
    stxdw [r10-0xc8], r1                    
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    stxdw [r10-0x70], r1                    
    lddw r1, 0x100067090 --> b"\x00\x00\x00\x00\x807\x06\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00…        r1 load str located at 4295389328
    stxdw [r10-0x90], r1                    
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    stxdw [r10-0x88], r1                    
    stxdw [r10-0x78], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -200                                  r1 += -200   ///  r1 = r1.wrapping_add(-200 as i32 as i64 as u64)
    stxdw [r10-0x80], r1                    
    ldxdw r1, [r10-0xd8]                    
    stxdw [r10-0xa8], r1                    
    ldxdw r1, [r10-0xe0]                    
    stxdw [r10-0xb0], r1                    
    mov64 r2, r10                                   r2 = r10
    add64 r2, -144                                  r2 += -144   ///  r2 = r2.wrapping_add(-144 as i32 as i64 as u64)
    mov64 r1, r6                                    r1 = r6
    call function_45907                     
    ja lbb_42942                                    if true { pc += 4 }
lbb_42938:
    ldxdw r2, [r1+0x8]                      
    ldxdw r1, [r1+0x0]                      
    mov64 r3, r6                                    r3 = r6
    call function_46428                     
lbb_42942:
    mov64 r6, r0                                    r6 = r0
lbb_42943:
    mov64 r0, r6                                    r0 = r6
    exit                                    
lbb_42945:
    rsh64 r1, 32                                    r1 >>= 32   ///  r1 = r1.wrapping_shr(32)
    stxw [r10-0xcc], r1                     
    mov64 r7, 20                                    r7 = 20 as i32 as i64 as u64
    mov64 r1, 20                                    r1 = 20 as i32 as i64 as u64
    mov64 r2, 1                                     r2 = 1 as i32 as i64 as u64
    call function_21359                     
    jne r0, 0, lbb_42956                            if r0 != (0 as i32 as i64 as u64) { pc += 4 }
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    mov64 r2, 20                                    r2 = 20 as i32 as i64 as u64
    call function_43400                     
    syscall [invalid]                       
lbb_42956:
    mov64 r1, 1819633267                            r1 = 1819633267 as i32 as i64 as u64
    stxw [r0+0x10], r1                      
    lddw r1, 0x736563637573206e                     r1 load str located at 8315161565832880238
    stxdw [r0+0x8], r1                      
    lddw r1, 0x6f6974617265706f                     r1 load str located at 8028075772644520047
    stxdw [r0+0x0], r1                      
    stxdw [r10-0xb8], r7                    
    stxdw [r10-0xc0], r7                    
    stxdw [r10-0xc8], r0                    
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    stxdw [r10-0x70], r1                    
    mov64 r1, 3                                     r1 = 3 as i32 as i64 as u64
    stxdw [r10-0x88], r1                    
    lddw r1, 0x100067140 --> b"\x00\x00\x00\x00\x807\x06\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00…        r1 load str located at 4295389504
    stxdw [r10-0x90], r1                    
    mov64 r1, 2                                     r1 = 2 as i32 as i64 as u64
    stxdw [r10-0x78], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -176                                  r1 += -176   ///  r1 = r1.wrapping_add(-176 as i32 as i64 as u64)
    stxdw [r10-0x80], r1                    
    lddw r1, 0x10005dec0 --> b"\xbf#\x00\x00\x00\x00\x00\x00a\x14\x00\x00\x00\x00\x00\x00g\x04\x00\x00 \…        r1 load str located at 4295352000
    stxdw [r10-0x98], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -204                                  r1 += -204   ///  r1 = r1.wrapping_add(-204 as i32 as i64 as u64)
    stxdw [r10-0xa0], r1                    
    lddw r1, 0x100052cb8 --> b"\xbf#\x00\x00\x00\x00\x00\x00y\x12\x10\x00\x00\x00\x00\x00y\x11\x00\x00\x…        r1 load str located at 4295306424
    stxdw [r10-0xa8], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -200                                  r1 += -200   ///  r1 = r1.wrapping_add(-200 as i32 as i64 as u64)
    stxdw [r10-0xb0], r1                    
    mov64 r2, r10                                   r2 = r10
    add64 r2, -144                                  r2 += -144   ///  r2 = r2.wrapping_add(-144 as i32 as i64 as u64)
    mov64 r1, r6                                    r1 = r6
    call function_45907                     
    mov64 r6, r0                                    r6 = r0
    ldxdw r2, [r10-0xc0]                    
    jeq r2, 0, lbb_42943                            if r2 == (0 as i32 as i64 as u64) { pc += -55 }
    ldxdw r1, [r10-0xc8]                    
    mov64 r3, 1                                     r3 = 1 as i32 as i64 as u64
    call function_21385                     
    ja lbb_42943                                    if true { pc += -59 }

function_43002:
    call function_43215                     
    syscall [invalid]                       

function_43004:
    call function_43212                     
    syscall [invalid]                       
    mov64 r4, r2                                    r4 = r2
    mov64 r3, 8                                     r3 = 8 as i32 as i64 as u64
    ldxb r1, [r1+0x0]                       
    jsgt r1, 19, lbb_43020                          if (r1 as i64) > (19 as i32 as i64) { pc += 10 }
    jsgt r1, 9, lbb_43034                           if (r1 as i64) > (9 as i32 as i64) { pc += 23 }
    jsgt r1, 4, lbb_43048                           if (r1 as i64) > (4 as i32 as i64) { pc += 36 }
    jsgt r1, 1, lbb_43066                           if (r1 as i64) > (1 as i32 as i64) { pc += 53 }
    lddw r2, 0x100060930 --> b"NotFoundTimedOut, owner= at idx , owner  (bytes ex"        r2 load str located at 4295362864
    jeq r1, 0, lbb_43207                            if r1 == (0 as i32 as i64 as u64) { pc += 191 }
    lddw r2, 0x10005fd88 --> b"PermissionDenied"        r2 load str located at 4295359880
    mov64 r3, 16                                    r3 = 16 as i32 as i64 as u64
    ja lbb_43207                                    if true { pc += 187 }
lbb_43020:
    jsgt r1, 29, lbb_43028                          if (r1 as i64) > (29 as i32 as i64) { pc += 7 }
    jsgt r1, 24, lbb_43054                          if (r1 as i64) > (24 as i32 as i64) { pc += 32 }
    jsgt r1, 21, lbb_43072                          if (r1 as i64) > (21 as i32 as i64) { pc += 49 }
    jeq r1, 20, lbb_43114                           if r1 == (20 as i32 as i64 as u64) { pc += 90 }
    lddw r2, 0x100063b39 --> b"InvalidData"         r2 load str located at 4295375673
    mov64 r3, 11                                    r3 = 11 as i32 as i64 as u64
    ja lbb_43207                                    if true { pc += 179 }
lbb_43028:
    jsgt r1, 34, lbb_43041                          if (r1 as i64) > (34 as i32 as i64) { pc += 12 }
    jsgt r1, 31, lbb_43078                          if (r1 as i64) > (31 as i32 as i64) { pc += 48 }
    jeq r1, 30, lbb_43118                           if r1 == (30 as i32 as i64 as u64) { pc += 87 }
    lddw r2, 0x100063ba4 --> b"CrossesDevicesTooManyLinksInvalidFilenameArgumentL"        r2 load str located at 4295375780
    ja lbb_43206                                    if true { pc += 172 }
lbb_43034:
    jsgt r1, 14, lbb_43060                          if (r1 as i64) > (14 as i32 as i64) { pc += 25 }
    jsgt r1, 11, lbb_43084                          if (r1 as i64) > (11 as i32 as i64) { pc += 48 }
    jeq r1, 10, lbb_43121                           if r1 == (10 as i32 as i64 as u64) { pc += 84 }
    lddw r2, 0x100063aac --> b"BrokenPipe"          r2 load str located at 4295375532
    mov64 r3, 10                                    r3 = 10 as i32 as i64 as u64
    ja lbb_43207                                    if true { pc += 166 }
lbb_43041:
    jsgt r1, 37, lbb_43090                          if (r1 as i64) > (37 as i32 as i64) { pc += 48 }
    jeq r1, 35, lbb_43125                           if r1 == (35 as i32 as i64 as u64) { pc += 82 }
    jeq r1, 36, lbb_43129                           if r1 == (36 as i32 as i64 as u64) { pc += 85 }
    lddw r2, 0x100063bf6 --> b"UnexpectedEof"        r2 load str located at 4295375862
    mov64 r3, 13                                    r3 = 13 as i32 as i64 as u64
    ja lbb_43207                                    if true { pc += 159 }
lbb_43048:
    jsgt r1, 6, lbb_43096                           if (r1 as i64) > (6 as i32 as i64) { pc += 47 }
    jeq r1, 5, lbb_43133                            if r1 == (5 as i32 as i64 as u64) { pc += 83 }
    lddw r2, 0x100063a7b --> b"ConnectionAborted"        r2 load str located at 4295375483
    mov64 r3, 17                                    r3 = 17 as i32 as i64 as u64
    ja lbb_43207                                    if true { pc += 153 }
lbb_43054:
    jsgt r1, 26, lbb_43102                          if (r1 as i64) > (26 as i32 as i64) { pc += 47 }
    jeq r1, 25, lbb_43137                           if r1 == (25 as i32 as i64 as u64) { pc += 81 }
    lddw r2, 0x100063b63 --> b"FilesystemQuotaExceeded"        r2 load str located at 4295375715
    mov64 r3, 23                                    r3 = 23 as i32 as i64 as u64
    ja lbb_43207                                    if true { pc += 147 }
lbb_43060:
    jsgt r1, 16, lbb_43108                          if (r1 as i64) > (16 as i32 as i64) { pc += 47 }
    jeq r1, 15, lbb_43141                           if r1 == (15 as i32 as i64 as u64) { pc += 79 }
    lddw r2, 0x100063ae6 --> b"DirectoryNotEmpty"        r2 load str located at 4295375590
    mov64 r3, 17                                    r3 = 17 as i32 as i64 as u64
    ja lbb_43207                                    if true { pc += 141 }
lbb_43066:
    jeq r1, 2, lbb_43145                            if r1 == (2 as i32 as i64 as u64) { pc += 78 }
    jeq r1, 3, lbb_43149                            if r1 == (3 as i32 as i64 as u64) { pc += 81 }
    lddw r2, 0x100063a5a --> b"HostUnreachable"        r2 load str located at 4295375450
    mov64 r3, 15                                    r3 = 15 as i32 as i64 as u64
    ja lbb_43207                                    if true { pc += 135 }
lbb_43072:
    jeq r1, 22, lbb_43153                           if r1 == (22 as i32 as i64 as u64) { pc += 80 }
    jeq r1, 23, lbb_43156                           if r1 == (23 as i32 as i64 as u64) { pc += 82 }
    lddw r2, 0x100063b4d --> b"StorageFull"         r2 load str located at 4295375693
    mov64 r3, 11                                    r3 = 11 as i32 as i64 as u64
    ja lbb_43207                                    if true { pc += 129 }
lbb_43078:
    jeq r1, 32, lbb_43160                           if r1 == (32 as i32 as i64 as u64) { pc += 81 }
    jeq r1, 33, lbb_43164                           if r1 == (33 as i32 as i64 as u64) { pc += 84 }
    lddw r2, 0x100063bcd --> b"ArgumentListTooLong"        r2 load str located at 4295375821
    mov64 r3, 19                                    r3 = 19 as i32 as i64 as u64
    ja lbb_43207                                    if true { pc += 123 }
lbb_43084:
    jeq r1, 12, lbb_43168                           if r1 == (12 as i32 as i64 as u64) { pc += 83 }
    jeq r1, 13, lbb_43172                           if r1 == (13 as i32 as i64 as u64) { pc += 86 }
    lddw r2, 0x100063acd --> b"NotADirectory"        r2 load str located at 4295375565
    mov64 r3, 13                                    r3 = 13 as i32 as i64 as u64
    ja lbb_43207                                    if true { pc += 117 }
lbb_43090:
    jeq r1, 38, lbb_43176                           if r1 == (38 as i32 as i64 as u64) { pc += 85 }
    jeq r1, 39, lbb_43180                           if r1 == (39 as i32 as i64 as u64) { pc += 88 }
    lddw r2, 0x100063c13 --> b"Uncategorized"        r2 load str located at 4295375891
    mov64 r3, 13                                    r3 = 13 as i32 as i64 as u64
    ja lbb_43207                                    if true { pc += 111 }
lbb_43096:
    jeq r1, 7, lbb_43184                            if r1 == (7 as i32 as i64 as u64) { pc += 87 }
    jeq r1, 8, lbb_43188                            if r1 == (8 as i32 as i64 as u64) { pc += 90 }
    lddw r2, 0x10005fdb8 --> b"AddrNotAvailable"        r2 load str located at 4295359928
    mov64 r3, 16                                    r3 = 16 as i32 as i64 as u64
    ja lbb_43207                                    if true { pc += 105 }
lbb_43102:
    jeq r1, 27, lbb_43192                           if r1 == (27 as i32 as i64 as u64) { pc += 89 }
    jeq r1, 28, lbb_43196                           if r1 == (28 as i32 as i64 as u64) { pc += 92 }
    lddw r2, 0x100063b92 --> b"ExecutableFileBusy"        r2 load str located at 4295375762
    mov64 r3, 18                                    r3 = 18 as i32 as i64 as u64
    ja lbb_43207                                    if true { pc += 99 }
lbb_43108:
    jeq r1, 17, lbb_43200                           if r1 == (17 as i32 as i64 as u64) { pc += 91 }
    jeq r1, 18, lbb_43204                           if r1 == (18 as i32 as i64 as u64) { pc += 94 }
    lddw r2, 0x100063b17 --> b"StaleNetworkFileHandle"        r2 load str located at 4295375639
    mov64 r3, 22                                    r3 = 22 as i32 as i64 as u64
    ja lbb_43207                                    if true { pc += 93 }
lbb_43114:
    lddw r2, 0x100063b2d --> b"InvalidInput"        r2 load str located at 4295375661
    mov64 r3, 12                                    r3 = 12 as i32 as i64 as u64
    ja lbb_43207                                    if true { pc += 89 }
lbb_43118:
    lddw r2, 0x100060970 --> b"DeadlockdeadlockAccount Expected 1 token mint acco"        r2 load str located at 4295362928
    ja lbb_43207                                    if true { pc += 86 }
lbb_43121:
    lddw r2, 0x100063aa1 --> b"NetworkDown"         r2 load str located at 4295375521
    mov64 r3, 11                                    r3 = 11 as i32 as i64 as u64
    ja lbb_43207                                    if true { pc += 82 }
lbb_43125:
    lddw r2, 0x100063be0 --> b"Interrupted"         r2 load str located at 4295375840
    mov64 r3, 11                                    r3 = 11 as i32 as i64 as u64
    ja lbb_43207                                    if true { pc += 78 }
lbb_43129:
    lddw r2, 0x100063beb --> b"Unsupported"         r2 load str located at 4295375851
    mov64 r3, 11                                    r3 = 11 as i32 as i64 as u64
    ja lbb_43207                                    if true { pc += 74 }
lbb_43133:
    lddw r2, 0x100063a69 --> b"NetworkUnreachable"        r2 load str located at 4295375465
    mov64 r3, 18                                    r3 = 18 as i32 as i64 as u64
    ja lbb_43207                                    if true { pc += 70 }
lbb_43137:
    lddw r2, 0x100063b58 --> b"NotSeekable"         r2 load str located at 4295375704
    mov64 r3, 11                                    r3 = 11 as i32 as i64 as u64
    ja lbb_43207                                    if true { pc += 66 }
lbb_43141:
    lddw r2, 0x100063ada --> b"IsADirectory"        r2 load str located at 4295375578
    mov64 r3, 12                                    r3 = 12 as i32 as i64 as u64
    ja lbb_43207                                    if true { pc += 62 }
lbb_43145:
    lddw r2, 0x100063a3a --> b"ConnectionRefused"        r2 load str located at 4295375418
    mov64 r3, 17                                    r3 = 17 as i32 as i64 as u64
    ja lbb_43207                                    if true { pc += 58 }
lbb_43149:
    lddw r2, 0x100063a4b --> b"ConnectionReset"        r2 load str located at 4295375435
    mov64 r3, 15                                    r3 = 15 as i32 as i64 as u64
    ja lbb_43207                                    if true { pc += 54 }
lbb_43153:
    lddw r2, 0x100060938 --> b"TimedOut, owner= at idx , owner  (bytes exponentma"        r2 load str located at 4295362872
    ja lbb_43207                                    if true { pc += 51 }
lbb_43156:
    lddw r2, 0x100063b44 --> b"WriteZero"           r2 load str located at 4295375684
    mov64 r3, 9                                     r3 = 9 as i32 as i64 as u64
    ja lbb_43207                                    if true { pc += 47 }
lbb_43160:
    lddw r2, 0x100063bb2 --> b"TooManyLinks"        r2 load str located at 4295375794
    mov64 r3, 12                                    r3 = 12 as i32 as i64 as u64
    ja lbb_43207                                    if true { pc += 43 }
lbb_43164:
    lddw r2, 0x100063bbe --> b"InvalidFilename"        r2 load str located at 4295375806
    mov64 r3, 15                                    r3 = 15 as i32 as i64 as u64
    ja lbb_43207                                    if true { pc += 39 }
lbb_43168:
    lddw r2, 0x100063ab6 --> b"AlreadyExists"        r2 load str located at 4295375542
    mov64 r3, 13                                    r3 = 13 as i32 as i64 as u64
    ja lbb_43207                                    if true { pc += 35 }
lbb_43172:
    lddw r2, 0x100063ac3 --> b"WouldBlock"          r2 load str located at 4295375555
    mov64 r3, 10                                    r3 = 10 as i32 as i64 as u64
    ja lbb_43207                                    if true { pc += 31 }
lbb_43176:
    lddw r2, 0x100063c03 --> b"OutOfMemory"         r2 load str located at 4295375875
    mov64 r3, 11                                    r3 = 11 as i32 as i64 as u64
    ja lbb_43207                                    if true { pc += 27 }
lbb_43180:
    lddw r2, 0x100063c0e --> b"Other"               r2 load str located at 4295375886
    mov64 r3, 5                                     r3 = 5 as i32 as i64 as u64
    ja lbb_43207                                    if true { pc += 23 }
lbb_43184:
    lddw r2, 0x100063a8c --> b"NotConnected"        r2 load str located at 4295375500
    mov64 r3, 12                                    r3 = 12 as i32 as i64 as u64
    ja lbb_43207                                    if true { pc += 19 }
lbb_43188:
    lddw r2, 0x100063a98 --> b"AddrInUse"           r2 load str located at 4295375512
    mov64 r3, 9                                     r3 = 9 as i32 as i64 as u64
    ja lbb_43207                                    if true { pc += 15 }
lbb_43192:
    lddw r2, 0x100063b7a --> b"FileTooLarge"        r2 load str located at 4295375738
    mov64 r3, 12                                    r3 = 12 as i32 as i64 as u64
    ja lbb_43207                                    if true { pc += 11 }
lbb_43196:
    lddw r2, 0x100063b86 --> b"ResourceBusy"        r2 load str located at 4295375750
    mov64 r3, 12                                    r3 = 12 as i32 as i64 as u64
    ja lbb_43207                                    if true { pc += 7 }
lbb_43200:
    lddw r2, 0x100063af7 --> b"ReadOnlyFilesystem"        r2 load str located at 4295375607
    mov64 r3, 18                                    r3 = 18 as i32 as i64 as u64
    ja lbb_43207                                    if true { pc += 3 }
lbb_43204:
    lddw r2, 0x100063b09 --> b"FilesystemLoop"        r2 load str located at 4295375625
lbb_43206:
    mov64 r3, 14                                    r3 = 14 as i32 as i64 as u64
lbb_43207:
    mov64 r1, r4                                    r1 = r4
    call function_45901                     
    exit                                    

function_43210:
    syscall [invalid]                       
    exit                                    

function_43212:
    call custom_panic                       
    syscall [invalid]                       
    syscall [invalid]                       

function_43215:
    syscall [invalid]                       
    syscall [invalid]                       

function_43217:
    lddw r1, 0x100063c20 --> b"Error: memory allocation failed, out of memory"        r1 load str located at 4295375904
    mov64 r2, 46                                    r2 = 46 as i32 as i64 as u64
    call function_43210                     
    call function_43002                     
    syscall [invalid]                       

function_43223:
    call function_43217                     
    syscall [invalid]                       
    mov64 r3, r2                                    r3 = r2
    lddw r2, 0x100067170 --> b"\x00\x00\x00\x00\x18H\x05\x00\x18\x00\x00\x00\x00\x00\x00\x00\x08\x00\x00…        r2 load str located at 4295389552
    call function_45367                     
    exit                                    

function_43230:
    exit                                    

function_43231:
    ldxdw r2, [r1+0x8]                      
    jeq r2, 0, lbb_43236                            if r2 == (0 as i32 as i64 as u64) { pc += 3 }
    ldxdw r1, [r1+0x0]                      
    mov64 r3, 1                                     r3 = 1 as i32 as i64 as u64
    call function_21385                     
lbb_43236:
    exit                                    

function_43237:
    mov64 r1, r2                                    r1 = r2
    lddw r2, 0x100063c50 --> b"Error"               r2 load str located at 4295375952
    mov64 r3, 5                                     r3 = 5 as i32 as i64 as u64
    call function_45901                     
    exit                                    

function_43243:
    mov64 r6, r1                                    r6 = r1
    mov64 r4, r2                                    r4 = r2
    add64 r4, r3                                    r4 += r3   ///  r4 = r4.wrapping_add(r3)
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    jgt r2, r4, lbb_43249                           if r2 > r4 { pc += 1 }
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
lbb_43249:
    and64 r1, 1                                     r1 &= 1   ///  r1 = r1.and(1)
    jne r1, 0, lbb_43286                            if r1 != (0 as i32 as i64 as u64) { pc += 35 }
    ldxdw r1, [r6+0x8]                      
    mov64 r7, r1                                    r7 = r1
    lsh64 r7, 1                                     r7 <<= 1   ///  r7 = r7.wrapping_shl(1)
    jgt r7, r4, lbb_43256                           if r7 > r4 { pc += 1 }
    mov64 r7, r4                                    r7 = r4
lbb_43256:
    jgt r7, 8, lbb_43258                            if r7 > (8 as i32 as i64 as u64) { pc += 1 }
    mov64 r7, 8                                     r7 = 8 as i32 as i64 as u64
lbb_43258:
    mov64 r2, r7                                    r2 = r7
    xor64 r2, -1                                    r2 ^= -1   ///  r2 = r2.xor(-1)
    rsh64 r2, 63                                    r2 >>= 63   ///  r2 = r2.wrapping_shr(63)
    jne r1, 0, lbb_43265                            if r1 != (0 as i32 as i64 as u64) { pc += 3 }
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    stxdw [r10-0x10], r1                    
    ja lbb_43270                                    if true { pc += 5 }
lbb_43265:
    ldxdw r3, [r6+0x0]                      
    stxdw [r10-0x8], r1                     
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    stxdw [r10-0x10], r1                    
    stxdw [r10-0x18], r3                    
lbb_43270:
    mov64 r1, r10                                   r1 = r10
    add64 r1, -48                                   r1 += -48   ///  r1 = r1.wrapping_add(-48 as i32 as i64 as u64)
    mov64 r4, r10                                   r4 = r10
    add64 r4, -24                                   r4 += -24   ///  r4 = r4.wrapping_add(-24 as i32 as i64 as u64)
    mov64 r3, r7                                    r3 = r7
    call function_43338                     
    ldxdw r1, [r10-0x28]                    
    ldxdw r2, [r10-0x30]                    
    jne r2, 0, lbb_43282                            if r2 != (0 as i32 as i64 as u64) { pc += 3 }
    stxdw [r6+0x8], r7                      
    stxdw [r6+0x0], r1                      
lbb_43281:
    exit                                    
lbb_43282:
    lddw r2, 0x8000000000000001                     r2 load str located at -9223372036854775807
    jeq r1, r2, lbb_43281                           if r1 == r2 { pc += -4 }
    jne r1, 0, lbb_43288                            if r1 != (0 as i32 as i64 as u64) { pc += 2 }
lbb_43286:
    call function_43383                     
    syscall [invalid]                       
lbb_43288:
    ldxdw r2, [r10-0x20]                    
    call function_43400                     
    syscall [invalid]                       

function_43291:
    mov64 r6, r1                                    r6 = r1
    add64 r2, 1                                     r2 += 1   ///  r2 = r2.wrapping_add(1 as i32 as i64 as u64)
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    jeq r2, 0, lbb_43296                            if r2 == (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
lbb_43296:
    and64 r1, 1                                     r1 &= 1   ///  r1 = r1.and(1)
    jne r1, 0, lbb_43333                            if r1 != (0 as i32 as i64 as u64) { pc += 35 }
    ldxdw r1, [r6+0x8]                      
    mov64 r7, r1                                    r7 = r1
    lsh64 r7, 1                                     r7 <<= 1   ///  r7 = r7.wrapping_shl(1)
    jgt r7, r2, lbb_43303                           if r7 > r2 { pc += 1 }
    mov64 r7, r2                                    r7 = r2
lbb_43303:
    jgt r7, 8, lbb_43305                            if r7 > (8 as i32 as i64 as u64) { pc += 1 }
    mov64 r7, 8                                     r7 = 8 as i32 as i64 as u64
lbb_43305:
    mov64 r2, r7                                    r2 = r7
    xor64 r2, -1                                    r2 ^= -1   ///  r2 = r2.xor(-1)
    rsh64 r2, 63                                    r2 >>= 63   ///  r2 = r2.wrapping_shr(63)
    jne r1, 0, lbb_43312                            if r1 != (0 as i32 as i64 as u64) { pc += 3 }
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    stxdw [r10-0x10], r1                    
    ja lbb_43317                                    if true { pc += 5 }
lbb_43312:
    ldxdw r3, [r6+0x0]                      
    stxdw [r10-0x8], r1                     
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    stxdw [r10-0x10], r1                    
    stxdw [r10-0x18], r3                    
lbb_43317:
    mov64 r1, r10                                   r1 = r10
    add64 r1, -48                                   r1 += -48   ///  r1 = r1.wrapping_add(-48 as i32 as i64 as u64)
    mov64 r4, r10                                   r4 = r10
    add64 r4, -24                                   r4 += -24   ///  r4 = r4.wrapping_add(-24 as i32 as i64 as u64)
    mov64 r3, r7                                    r3 = r7
    call function_43338                     
    ldxdw r1, [r10-0x28]                    
    ldxdw r2, [r10-0x30]                    
    jne r2, 0, lbb_43329                            if r2 != (0 as i32 as i64 as u64) { pc += 3 }
    stxdw [r6+0x8], r7                      
    stxdw [r6+0x0], r1                      
lbb_43328:
    exit                                    
lbb_43329:
    lddw r2, 0x8000000000000001                     r2 load str located at -9223372036854775807
    jeq r1, r2, lbb_43328                           if r1 == r2 { pc += -4 }
    jne r1, 0, lbb_43335                            if r1 != (0 as i32 as i64 as u64) { pc += 2 }
lbb_43333:
    call function_43383                     
    syscall [invalid]                       
lbb_43335:
    ldxdw r2, [r10-0x20]                    
    call function_43400                     
    syscall [invalid]                       

function_43338:
    mov64 r7, r3                                    r7 = r3
    mov64 r6, r1                                    r6 = r1
    jeq r2, 0, lbb_43354                            if r2 == (0 as i32 as i64 as u64) { pc += 13 }
    ldxdw r1, [r4+0x8]                      
    jeq r1, 0, lbb_43370                            if r1 == (0 as i32 as i64 as u64) { pc += 27 }
    ldxdw r2, [r4+0x10]                     
    jne r2, 0, lbb_43359                            if r2 != (0 as i32 as i64 as u64) { pc += 14 }
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    mov64 r0, 1                                     r0 = 1 as i32 as i64 as u64
    jeq r7, 0, lbb_43378                            if r7 == (0 as i32 as i64 as u64) { pc += 30 }
    mov64 r1, r7                                    r1 = r7
    mov64 r2, 1                                     r2 = 1 as i32 as i64 as u64
    call function_21359                     
    mov64 r1, r7                                    r1 = r7
    jeq r0, 0, lbb_43366                            if r0 == (0 as i32 as i64 as u64) { pc += 13 }
    ja lbb_43378                                    if true { pc += 24 }
lbb_43354:
    stxdw [r6+0x10], r7                     
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    stxdw [r6+0x8], r1                      
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    ja lbb_43381                                    if true { pc += 22 }
lbb_43359:
    ldxdw r1, [r4+0x0]                      
    mov64 r3, 1                                     r3 = 1 as i32 as i64 as u64
    mov64 r4, r7                                    r4 = r7
    call function_21386                     
    mov64 r1, r7                                    r1 = r7
    jeq r0, 0, lbb_43366                            if r0 == (0 as i32 as i64 as u64) { pc += 1 }
    ja lbb_43378                                    if true { pc += 12 }
lbb_43366:
    stxdw [r6+0x10], r7                     
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    stxdw [r6+0x8], r1                      
    ja lbb_43381                                    if true { pc += 11 }
lbb_43370:
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    mov64 r0, 1                                     r0 = 1 as i32 as i64 as u64
    jeq r7, 0, lbb_43378                            if r7 == (0 as i32 as i64 as u64) { pc += 5 }
    mov64 r1, r7                                    r1 = r7
    mov64 r2, 1                                     r2 = 1 as i32 as i64 as u64
    call function_21359                     
    mov64 r1, r7                                    r1 = r7
    jeq r0, 0, lbb_43366                            if r0 == (0 as i32 as i64 as u64) { pc += -12 }
lbb_43378:
    stxdw [r6+0x10], r1                     
    stxdw [r6+0x8], r0                      
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
lbb_43381:
    stxdw [r6+0x0], r1                      
    exit                                    

function_43383:
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    stxdw [r10-0x28], r1                    
    lddw r1, 0x1000671a0 --> b"\x00\x00\x00\x00q<\x06\x00\x11\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x0…        r1 load str located at 4295389600
    stxdw [r10-0x30], r1                    
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    stxdw [r10-0x10], r1                    
    stxdw [r10-0x18], r1                    
    lddw r1, 0x100063c50 --> b"Errorlibrary/alloc/src/raw_vec.rscapacity overflow"        r1 load str located at 4295375952
    stxdw [r10-0x20], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -48                                   r1 += -48   ///  r1 = r1.wrapping_add(-48 as i32 as i64 as u64)
    lddw r2, 0x1000671b0 --> b"\x00\x00\x00\x00U<\x06\x00\x1c\x00\x00\x00\x00\x00\x00\x00!\x02\x00\x00\x…        r2 load str located at 4295389616
    call function_44240                     
    syscall [invalid]                       

function_43400:
    mov64 r3, r1                                    r3 = r1
    mov64 r1, r2                                    r1 = r2
    mov64 r2, r3                                    r2 = r3
    call function_21446                     
    syscall [invalid]                       
    mov64 r3, r2                                    r3 = r2
    ldxdw r2, [r1+0x10]                     
    ldxdw r1, [r1+0x0]                      
    call function_46428                     
    exit                                    

function_43410:
    mov64 r3, r2                                    r3 = r2
    ldxdw r2, [r1+0x10]                     
    ldxdw r1, [r1+0x0]                      
    call function_46189                     
    exit                                    

function_43415:
    mov64 r7, r2                                    r7 = r2
    mov64 r6, r1                                    r6 = r1
    ldxdw r2, [r7+0x8]                      
    jeq r2, 0, lbb_43460                            if r2 == (0 as i32 as i64 as u64) { pc += 41 }
    ldxdw r1, [r7+0x0]                      
    mov64 r4, 0                                     r4 = 0 as i32 as i64 as u64
    mov64 r3, r1                                    r3 = r1
    add64 r3, 8                                     r3 += 8   ///  r3 = r3.wrapping_add(8 as i32 as i64 as u64)
lbb_43423:
    ldxdw r8, [r3+0x0]                      
    add64 r8, r4                                    r8 += r4   ///  r8 = r8.wrapping_add(r4)
    add64 r3, 16                                    r3 += 16   ///  r3 = r3.wrapping_add(16 as i32 as i64 as u64)
    add64 r2, -1                                    r2 += -1   ///  r2 = r2.wrapping_add(-1 as i32 as i64 as u64)
    mov64 r4, r8                                    r4 = r8
    jne r2, 0, lbb_43423                            if r2 != (0 as i32 as i64 as u64) { pc += -6 }
    ldxdw r2, [r7+0x18]                     
    jeq r2, 0, lbb_43445                            if r2 == (0 as i32 as i64 as u64) { pc += 14 }
    mov64 r4, 0                                     r4 = 0 as i32 as i64 as u64
    mov64 r3, 1                                     r3 = 1 as i32 as i64 as u64
    mov64 r5, 16                                    r5 = 16 as i32 as i64 as u64
    mov64 r2, 1                                     r2 = 1 as i32 as i64 as u64
    jgt r5, r8, lbb_43437                           if r5 > r8 { pc += 1 }
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
lbb_43437:
    ldxdw r1, [r1+0x8]                      
    jeq r1, 0, lbb_43440                            if r1 == (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
lbb_43440:
    jsgt r4, r8, lbb_43464                          if (r4 as i64) > (r8 as i64) { pc += 23 }
    and64 r2, r3                                    r2 &= r3   ///  r2 = r2.and(r3)
    and64 r2, 1                                     r2 &= 1   ///  r2 = r2.and(1)
    jne r2, 0, lbb_43464                            if r2 != (0 as i32 as i64 as u64) { pc += 20 }
lbb_43444:
    lsh64 r8, 1                                     r8 <<= 1   ///  r8 = r8.wrapping_shl(1)
lbb_43445:
    mov64 r0, 1                                     r0 = 1 as i32 as i64 as u64
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    jeq r8, 0, lbb_43466                            if r8 == (0 as i32 as i64 as u64) { pc += 18 }
    jsgt r8, -1, lbb_43451                          if (r8 as i64) > (-1 as i32 as i64) { pc += 2 }
    call function_43383                     
    syscall [invalid]                       
lbb_43451:
    mov64 r1, r8                                    r1 = r8
    mov64 r2, 1                                     r2 = 1 as i32 as i64 as u64
    call function_21359                     
    mov64 r1, r8                                    r1 = r8
    jne r0, 0, lbb_43466                            if r0 != (0 as i32 as i64 as u64) { pc += 10 }
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    mov64 r2, r8                                    r2 = r8
    call function_43400                     
    syscall [invalid]                       
lbb_43460:
    mov64 r8, 0                                     r8 = 0 as i32 as i64 as u64
    ldxdw r1, [r7+0x18]                     
    jeq r1, 0, lbb_43464                            if r1 == (0 as i32 as i64 as u64) { pc += 1 }
    ja lbb_43444                                    if true { pc += -20 }
lbb_43464:
    mov64 r0, 1                                     r0 = 1 as i32 as i64 as u64
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
lbb_43466:
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
    stxdw [r10-0x10], r2                    
    stxdw [r10-0x18], r1                    
    stxdw [r10-0x20], r0                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -32                                   r1 += -32   ///  r1 = r1.wrapping_add(-32 as i32 as i64 as u64)
    lddw r2, 0x100067170 --> b"\x00\x00\x00\x00\x18H\x05\x00\x18\x00\x00\x00\x00\x00\x00\x00\x08\x00\x00…        r2 load str located at 4295389552
    mov64 r3, r7                                    r3 = r7
    call function_45367                     
    jne r0, 0, lbb_43484                            if r0 != (0 as i32 as i64 as u64) { pc += 7 }
    ldxdw r1, [r10-0x10]                    
    stxdw [r6+0x10], r1                     
    ldxdw r1, [r10-0x18]                    
    stxdw [r6+0x8], r1                      
    ldxdw r1, [r10-0x20]                    
    stxdw [r6+0x0], r1                      
    exit                                    
lbb_43484:
    mov64 r3, r10                                   r3 = r10
    add64 r3, -1                                    r3 += -1   ///  r3 = r3.wrapping_add(-1 as i32 as i64 as u64)
    lddw r1, 0x100063c82 --> b"a formatting trait implementation returned an error"        r1 load str located at 4295376002
    mov64 r2, 51                                    r2 = 51 as i32 as i64 as u64
    lddw r4, 0x1000671c8 --> b"\x00\x00\x00\x00\x10H\x05\x00\x00\x00\x00\x00\x00\x00\x00\x00\x01\x00\x00…        r4 load str located at 4295389640
    lddw r5, 0x1000671e8 --> b"\x00\x00\x00\x00\xb5<\x06\x00\x18\x00\x00\x00\x00\x00\x00\x00d\x02\x00\x0…        r5 load str located at 4295389672
    call function_44299                     
    syscall [invalid]                       

function_43495:
    mov64 r7, r4                                    r7 = r4
    mov64 r8, r3                                    r8 = r3
    mov64 r9, r2                                    r9 = r2
    mov64 r6, r1                                    r6 = r1
    jne r7, 0, lbb_43505                            if r7 != (0 as i32 as i64 as u64) { pc += 5 }
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    stxdw [r10-0x20], r1                    
    stxdw [r10-0x28], r1                    
    mov64 r9, 1                                     r9 = 1 as i32 as i64 as u64
    ja lbb_43593                                    if true { pc += 88 }
lbb_43505:
    mov64 r1, r10                                   r1 = r10
    add64 r1, -56                                   r1 += -56   ///  r1 = r1.wrapping_add(-56 as i32 as i64 as u64)
    mov64 r2, r8                                    r2 = r8
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
    mov64 r4, r7                                    r4 = r7
    mov64 r5, 0                                     r5 = 0 as i32 as i64 as u64
    call function_48384                     
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    ldxdw r2, [r10-0x30]                    
    jne r2, 0, lbb_43516                            if r2 != (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
lbb_43516:
    stxdw [r10-0x48], r9                    
    stxdw [r10-0x40], r8                    
    jne r1, 1, lbb_43526                            if r1 != (1 as i32 as i64 as u64) { pc += 7 }
    lddw r1, 0x100063c71 --> b"capacity overflow"        r1 load str located at 4295375985
    mov64 r2, 17                                    r2 = 17 as i32 as i64 as u64
    lddw r3, 0x100067200 --> b"\x00\x00\x00\x00\xcd<\x06\x00\x1a\x00\x00\x00\x00\x00\x00\x00\xf7\x01\x00…        r3 load str located at 4295389696
    call function_44085                     
    syscall [invalid]                       
lbb_43526:
    ldxdw r8, [r10-0x38]                    
    mov64 r9, 1                                     r9 = 1 as i32 as i64 as u64
    jeq r8, 0, lbb_43541                            if r8 == (0 as i32 as i64 as u64) { pc += 12 }
    jsgt r8, -1, lbb_43532                          if (r8 as i64) > (-1 as i32 as i64) { pc += 2 }
    call function_43383                     
    syscall [invalid]                       
lbb_43532:
    mov64 r1, r8                                    r1 = r8
    mov64 r2, 1                                     r2 = 1 as i32 as i64 as u64
    call function_21359                     
    mov64 r9, r0                                    r9 = r0
    jne r9, 0, lbb_43541                            if r9 != (0 as i32 as i64 as u64) { pc += 4 }
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    mov64 r2, r8                                    r2 = r8
    call function_43400                     
    syscall [invalid]                       
lbb_43541:
    stxdw [r10-0x50], r6                    
    stxdw [r10-0x18], r9                    
    mov64 r6, 0                                     r6 = 0 as i32 as i64 as u64
    stxdw [r10-0x8], r6                     
    stxdw [r10-0x10], r8                    
    stxdw [r10-0x58], r8                    
    ldxdw r3, [r10-0x40]                    
    jge r8, r3, lbb_43557                           if r8 >= r3 { pc += 8 }
    mov64 r1, r10                                   r1 = r10
    add64 r1, -24                                   r1 += -24   ///  r1 = r1.wrapping_add(-24 as i32 as i64 as u64)
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
    mov64 r6, r3                                    r6 = r3
    call function_43243                     
    mov64 r3, r6                                    r3 = r6
    ldxdw r9, [r10-0x18]                    
    ldxdw r6, [r10-0x8]                     
lbb_43557:
    mov64 r1, r9                                    r1 = r9
    add64 r1, r6                                    r1 += r6   ///  r1 = r1.wrapping_add(r6)
    ldxdw r2, [r10-0x48]                    
    mov64 r8, r3                                    r8 = r3
    call function_48190                     
    add64 r6, r8                                    r6 += r8   ///  r6 = r6.wrapping_add(r8)
    mov64 r1, 2                                     r1 = 2 as i32 as i64 as u64
    jgt r1, r7, lbb_43576                           if r1 > r7 { pc += 11 }
lbb_43565:
    mov64 r8, r7                                    r8 = r7
    mov64 r1, r9                                    r1 = r9
    add64 r1, r6                                    r1 += r6   ///  r1 = r1.wrapping_add(r6)
    mov64 r2, r9                                    r2 = r9
    mov64 r3, r6                                    r3 = r6
    call function_48190                     
    lsh64 r6, 1                                     r6 <<= 1   ///  r6 = r6.wrapping_shl(1)
    rsh64 r7, 1                                     r7 >>= 1   ///  r7 = r7.wrapping_shr(1)
    mov64 r1, 4                                     r1 = 4 as i32 as i64 as u64
    jgt r1, r8, lbb_43576                           if r1 > r8 { pc += 1 }
    ja lbb_43565                                    if true { pc += -11 }
lbb_43576:
    mov64 r7, r10                                   r7 = r10
    add64 r7, -16                                   r7 += -16   ///  r7 = r7.wrapping_add(-16 as i32 as i64 as u64)
    stxdw [r10-0x8], r6                     
    ldxdw r8, [r10-0x58]                    
    jeq r8, r6, lbb_43588                           if r8 == r6 { pc += 7 }
    mov64 r1, r9                                    r1 = r9
    add64 r1, r6                                    r1 += r6   ///  r1 = r1.wrapping_add(r6)
    mov64 r3, r8                                    r3 = r8
    sub64 r3, r6                                    r3 -= r6   ///  r3 = r3.wrapping_sub(r6)
    mov64 r2, r9                                    r2 = r9
    call function_48190                     
    stxdw [r10-0x8], r8                     
lbb_43588:
    ldxdw r1, [r7+0x8]                      
    stxdw [r10-0x20], r1                    
    ldxdw r1, [r7+0x0]                      
    stxdw [r10-0x28], r1                    
    ldxdw r6, [r10-0x50]                    
lbb_43593:
    stxdw [r6+0x0], r9                      
    ldxdw r1, [r10-0x28]                    
    stxdw [r6+0x8], r1                      
    ldxdw r1, [r10-0x20]                    
    stxdw [r6+0x10], r1                     
    exit                                    

function_43599:
    mov64 r7, r2                                    r7 = r2
    mov64 r6, r1                                    r6 = r1
    mov64 r1, r7                                    r1 = r7
    lsh64 r1, 32                                    r1 <<= 32   ///  r1 = r1.wrapping_shl(32)
    rsh64 r1, 32                                    r1 >>= 32   ///  r1 = r1.wrapping_shr(32)
    mov64 r2, 128                                   r2 = 128 as i32 as i64 as u64
    jgt r2, r1, lbb_43630                           if r2 > r1 { pc += 24 }
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
    stxw [r10-0x4], r2                      
    mov64 r2, 2048                                  r2 = 2048 as i32 as i64 as u64
    jgt r2, r1, lbb_43642                           if r2 > r1 { pc += 32 }
    mov64 r1, r7                                    r1 = r7
    lsh64 r1, 32                                    r1 <<= 32   ///  r1 = r1.wrapping_shl(32)
    rsh64 r1, 32                                    r1 >>= 32   ///  r1 = r1.wrapping_shr(32)
    mov64 r2, 65536                                 r2 = 65536 as i32 as i64 as u64
    jgt r2, r1, lbb_43616                           if r2 > r1 { pc += 1 }
    ja lbb_43651                                    if true { pc += 35 }
lbb_43616:
    mov64 r1, r7                                    r1 = r7
    and64 r1, 63                                    r1 &= 63   ///  r1 = r1.and(63)
    or64 r1, 128                                    r1 |= 128   ///  r1 = r1.or(128)
    stxb [r10-0x2], r1                      
    mov64 r1, r7                                    r1 = r7
    rsh64 r1, 12                                    r1 >>= 12   ///  r1 = r1.wrapping_shr(12)
    or64 r1, 224                                    r1 |= 224   ///  r1 = r1.or(224)
    stxb [r10-0x4], r1                      
    rsh64 r7, 6                                     r7 >>= 6   ///  r7 = r7.wrapping_shr(6)
    and64 r7, 63                                    r7 &= 63   ///  r7 = r7.and(63)
    or64 r7, 128                                    r7 |= 128   ///  r7 = r7.or(128)
    stxb [r10-0x3], r7                      
    mov64 r7, 3                                     r7 = 3 as i32 as i64 as u64
    ja lbb_43670                                    if true { pc += 40 }
lbb_43630:
    ldxdw r2, [r6+0x10]                     
    ldxdw r1, [r6+0x8]                      
    jne r2, r1, lbb_43636                           if r2 != r1 { pc += 3 }
    mov64 r1, r6                                    r1 = r6
    call function_43291                     
    ldxdw r2, [r6+0x10]                     
lbb_43636:
    ldxdw r1, [r6+0x0]                      
    add64 r1, r2                                    r1 += r2   ///  r1 = r1.wrapping_add(r2)
    stxb [r1+0x0], r7                       
    add64 r2, 1                                     r2 += 1   ///  r2 = r2.wrapping_add(1 as i32 as i64 as u64)
    stxdw [r6+0x10], r2                     
    ja lbb_43687                                    if true { pc += 45 }
lbb_43642:
    mov64 r1, r7                                    r1 = r7
    and64 r1, 63                                    r1 &= 63   ///  r1 = r1.and(63)
    or64 r1, 128                                    r1 |= 128   ///  r1 = r1.or(128)
    stxb [r10-0x3], r1                      
    rsh64 r7, 6                                     r7 >>= 6   ///  r7 = r7.wrapping_shr(6)
    or64 r7, 192                                    r7 |= 192   ///  r7 = r7.or(192)
    stxb [r10-0x4], r7                      
    mov64 r7, 2                                     r7 = 2 as i32 as i64 as u64
    ja lbb_43670                                    if true { pc += 19 }
lbb_43651:
    mov64 r1, r7                                    r1 = r7
    and64 r1, 63                                    r1 &= 63   ///  r1 = r1.and(63)
    or64 r1, 128                                    r1 |= 128   ///  r1 = r1.or(128)
    stxb [r10-0x1], r1                      
    mov64 r1, r7                                    r1 = r7
    rsh64 r1, 6                                     r1 >>= 6   ///  r1 = r1.wrapping_shr(6)
    and64 r1, 63                                    r1 &= 63   ///  r1 = r1.and(63)
    or64 r1, 128                                    r1 |= 128   ///  r1 = r1.or(128)
    stxb [r10-0x2], r1                      
    mov64 r1, r7                                    r1 = r7
    rsh64 r1, 12                                    r1 >>= 12   ///  r1 = r1.wrapping_shr(12)
    and64 r1, 63                                    r1 &= 63   ///  r1 = r1.and(63)
    or64 r1, 128                                    r1 |= 128   ///  r1 = r1.or(128)
    stxb [r10-0x3], r1                      
    rsh64 r7, 18                                    r7 >>= 18   ///  r7 = r7.wrapping_shr(18)
    and64 r7, 7                                     r7 &= 7   ///  r7 = r7.and(7)
    or64 r7, 240                                    r7 |= 240   ///  r7 = r7.or(240)
    stxb [r10-0x4], r7                      
    mov64 r7, 4                                     r7 = 4 as i32 as i64 as u64
lbb_43670:
    ldxdw r8, [r6+0x10]                     
    ldxdw r1, [r6+0x8]                      
    sub64 r1, r8                                    r1 -= r8   ///  r1 = r1.wrapping_sub(r8)
    jge r1, r7, lbb_43679                           if r1 >= r7 { pc += 5 }
    mov64 r1, r6                                    r1 = r6
    mov64 r2, r8                                    r2 = r8
    mov64 r3, r7                                    r3 = r7
    call function_43243                     
    ldxdw r8, [r6+0x10]                     
lbb_43679:
    ldxdw r1, [r6+0x0]                      
    add64 r1, r8                                    r1 += r8   ///  r1 = r1.wrapping_add(r8)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -4                                    r2 += -4   ///  r2 = r2.wrapping_add(-4 as i32 as i64 as u64)
    mov64 r3, r7                                    r3 = r7
    call function_48190                     
    add64 r8, r7                                    r8 += r7   ///  r8 = r8.wrapping_add(r7)
    stxdw [r6+0x10], r8                     
lbb_43687:
    exit                                    

function_43688:
    mov64 r6, r3                                    r6 = r3
    mov64 r8, r2                                    r8 = r2
    mov64 r7, r1                                    r7 = r1
    ldxdw r9, [r7+0x10]                     
    ldxdw r1, [r7+0x8]                      
    sub64 r1, r9                                    r1 -= r9   ///  r1 = r1.wrapping_sub(r9)
    jge r1, r6, lbb_43700                           if r1 >= r6 { pc += 5 }
    mov64 r1, r7                                    r1 = r7
    mov64 r2, r9                                    r2 = r9
    mov64 r3, r6                                    r3 = r6
    call function_43243                     
    ldxdw r9, [r7+0x10]                     
lbb_43700:
    ldxdw r1, [r7+0x0]                      
    add64 r1, r9                                    r1 += r9   ///  r1 = r1.wrapping_add(r9)
    mov64 r2, r8                                    r2 = r8
    mov64 r3, r6                                    r3 = r6
    call function_48190                     
    add64 r9, r6                                    r9 += r6   ///  r9 = r9.wrapping_add(r6)
    stxdw [r7+0x10], r9                     
    mov64 r0, 0                                     r0 = 0 as i32 as i64 as u64
    exit                                    

function_43709:
    call function_43599                     
    mov64 r0, 0                                     r0 = 0 as i32 as i64 as u64
    exit                                    

function_43712:
    ldxdw r1, [r1+0x0]                      
lbb_43713:
    ja lbb_43713                                    if true { pc += -1 }

function_43714:
    exit                                    

function_43715:
    exit                                    

function_43716:
    mov64 r6, r2                                    r6 = r2
    mov64 r7, r1                                    r7 = r1
    call function_47863                     
    mov64 r8, 1                                     r8 = 1 as i32 as i64 as u64
    jne r0, 0, lbb_43742                            if r0 != (0 as i32 as i64 as u64) { pc += 21 }
    lddw r1, 0x100067228 --> b"\x00\x00\x00\x00;=\x06\x00\x02\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x0…        r1 load str located at 4295389736
    stxdw [r10-0x30], r1                    
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    stxdw [r10-0x10], r1                    
    stxdw [r10-0x18], r1                    
    lddw r1, 0x100063ce8 --> b"called `Option::unwrap()` on a `None` value)invali"        r1 load str located at 4295376104
    stxdw [r10-0x20], r1                    
    stxdw [r10-0x28], r8                    
    ldxdw r2, [r6+0x28]                     
    ldxdw r1, [r6+0x20]                     
    mov64 r3, r10                                   r3 = r10
    add64 r3, -48                                   r3 += -48   ///  r3 = r3.wrapping_add(-48 as i32 as i64 as u64)
    call function_45367                     
    jne r0, 0, lbb_43742                            if r0 != (0 as i32 as i64 as u64) { pc += 5 }
    add64 r7, 8                                     r7 += 8   ///  r7 = r7.wrapping_add(8 as i32 as i64 as u64)
    mov64 r1, r7                                    r1 = r7
    mov64 r2, r6                                    r2 = r6
    call function_47863                     
    mov64 r8, r0                                    r8 = r0
lbb_43742:
    mov64 r0, r8                                    r0 = r8
    exit                                    

function_43744:
    lddw r2, 0xbf0032581df6855a                     r2 load str located at -4683688258424109734
    stxdw [r1+0x8], r2                      
    lddw r2, 0xf6c0e91a5cd6f8ca                     r2 load str located at -666276445414819638
    stxdw [r1+0x0], r2                      
    exit                                    

function_43751:
    ldxdw r1, [r2+0x20]                     
    ldxdw r2, [r2+0x28]                     
    ldxdw r4, [r2+0x18]                     
    lddw r2, 0x100063d3d --> b"BorrowError"         r2 load str located at 4295376189
    mov64 r3, 11                                    r3 = 11 as i32 as i64 as u64
    callx r4                                
    exit                                    

function_43759:
    mov64 r6, r1                                    r6 = r1
    lddw r1, 0x100055858 --> b"y! \x00\x00\x00\x00\x00y"(\x00\x00\x00\x00\x00y$\x18\x00\x00\x00\x00\x00\…        r1 load str located at 4295317592
    stxdw [r10-0x10], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -1                                    r1 += -1   ///  r1 = r1.wrapping_add(-1 as i32 as i64 as u64)
    stxdw [r10-0x18], r1                    
    mov64 r7, r10                                   r7 = r10
    add64 r7, -72                                   r7 += -72   ///  r7 = r7.wrapping_add(-72 as i32 as i64 as u64)
    mov64 r4, r10                                   r4 = r10
    add64 r4, -24                                   r4 += -24   ///  r4 = r4.wrapping_add(-24 as i32 as i64 as u64)
    mov64 r1, r7                                    r1 = r7
    lddw r2, 0x100067238 --> b"\x00"                r2 load str located at 4295389752
    mov64 r3, 1                                     r3 = 1 as i32 as i64 as u64
    mov64 r5, 1                                     r5 = 1 as i32 as i64 as u64
    call function_45339                     
    mov64 r1, r7                                    r1 = r7
    mov64 r2, r6                                    r2 = r6
    call function_44240                     
    syscall [invalid]                       

function_43780:
    mov64 r7, r2                                    r7 = r2
    mov64 r6, r1                                    r6 = r1
    mov64 r1, r7                                    r1 = r7
    lsh64 r1, 32                                    r1 <<= 32   ///  r1 = r1.wrapping_shl(32)
    rsh64 r1, 32                                    r1 >>= 32   ///  r1 = r1.wrapping_shr(32)
    jsgt r1, 12, lbb_43796                          if (r1 as i64) > (12 as i32 as i64) { pc += 10 }
    jeq r1, 0, lbb_43809                            if r1 == (0 as i32 as i64 as u64) { pc += 22 }
    jeq r1, 9, lbb_43815                            if r1 == (9 as i32 as i64 as u64) { pc += 27 }
    jeq r1, 10, lbb_43790                           if r1 == (10 as i32 as i64 as u64) { pc += 1 }
    ja lbb_43829                                    if true { pc += 39 }
lbb_43790:
    mov64 r1, 512                                   r1 = 512 as i32 as i64 as u64
    stxh [r6+0xa], r1                       
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    stxdw [r6+0x2], r1                      
    mov64 r1, 28252                                 r1 = 28252 as i32 as i64 as u64
    ja lbb_43856                                    if true { pc += 60 }
lbb_43796:
    jsgt r1, 38, lbb_43827                          if (r1 as i64) > (38 as i32 as i64) { pc += 30 }
    jeq r1, 13, lbb_43821                           if r1 == (13 as i32 as i64 as u64) { pc += 23 }
    jeq r1, 34, lbb_43800                           if r1 == (34 as i32 as i64 as u64) { pc += 1 }
    ja lbb_43829                                    if true { pc += 29 }
lbb_43800:
    mov64 r1, r3                                    r1 = r3
    and64 r1, 65536                                 r1 &= 65536   ///  r1 = r1.and(65536)
    jeq r1, 0, lbb_43829                            if r1 == (0 as i32 as i64 as u64) { pc += 26 }
    mov64 r1, 512                                   r1 = 512 as i32 as i64 as u64
    stxh [r6+0xa], r1                       
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    stxdw [r6+0x2], r1                      
    mov64 r1, 8796                                  r1 = 8796 as i32 as i64 as u64
    ja lbb_43856                                    if true { pc += 47 }
lbb_43809:
    mov64 r1, 512                                   r1 = 512 as i32 as i64 as u64
    stxh [r6+0xa], r1                       
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    stxdw [r6+0x2], r1                      
    mov64 r1, 12380                                 r1 = 12380 as i32 as i64 as u64
    ja lbb_43856                                    if true { pc += 41 }
lbb_43815:
    mov64 r1, 512                                   r1 = 512 as i32 as i64 as u64
    stxh [r6+0xa], r1                       
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    stxdw [r6+0x2], r1                      
    mov64 r1, 29788                                 r1 = 29788 as i32 as i64 as u64
    ja lbb_43856                                    if true { pc += 35 }
lbb_43821:
    mov64 r1, 512                                   r1 = 512 as i32 as i64 as u64
    stxh [r6+0xa], r1                       
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    stxdw [r6+0x2], r1                      
    mov64 r1, 29276                                 r1 = 29276 as i32 as i64 as u64
    ja lbb_43856                                    if true { pc += 29 }
lbb_43827:
    jeq r1, 39, lbb_43842                           if r1 == (39 as i32 as i64 as u64) { pc += 14 }
    jeq r1, 92, lbb_43851                           if r1 == (92 as i32 as i64 as u64) { pc += 22 }
lbb_43829:
    and64 r3, 1                                     r3 &= 1   ///  r3 = r3.and(1)
    jeq r3, 0, lbb_43834                            if r3 == (0 as i32 as i64 as u64) { pc += 3 }
    mov64 r1, r7                                    r1 = r7
    call function_48088                     
    jne r0, 0, lbb_43962                            if r0 != (0 as i32 as i64 as u64) { pc += 128 }
lbb_43834:
    mov64 r1, r7                                    r1 = r7
    call function_47357                     
    jne r0, 0, lbb_43838                            if r0 != (0 as i32 as i64 as u64) { pc += 1 }
    ja lbb_43858                                    if true { pc += 20 }
lbb_43838:
    stxw [r6+0x4], r7                       
    mov64 r1, 128                                   r1 = 128 as i32 as i64 as u64
    stxb [r6+0x0], r1                       
    ja lbb_43857                                    if true { pc += 15 }
lbb_43842:
    mov64 r1, r3                                    r1 = r3
    and64 r1, 256                                   r1 &= 256   ///  r1 = r1.and(256)
    jeq r1, 0, lbb_43829                            if r1 == (0 as i32 as i64 as u64) { pc += -16 }
    mov64 r1, 512                                   r1 = 512 as i32 as i64 as u64
    stxh [r6+0xa], r1                       
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    stxdw [r6+0x2], r1                      
    mov64 r1, 10076                                 r1 = 10076 as i32 as i64 as u64
    ja lbb_43856                                    if true { pc += 5 }
lbb_43851:
    mov64 r1, 512                                   r1 = 512 as i32 as i64 as u64
    stxh [r6+0xa], r1                       
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    stxdw [r6+0x2], r1                      
    mov64 r1, 23644                                 r1 = 23644 as i32 as i64 as u64
lbb_43856:
    stxh [r6+0x0], r1                       
lbb_43857:
    exit                                    
lbb_43858:
    lddw r1, 0xfffffffc                             r1 load str located at 4294967292
    mov64 r2, r7                                    r2 = r7
    and64 r2, r1                                    r2 &= r1   ///  r2 = r2.and(r1)
    rsh64 r2, 1                                     r2 >>= 1   ///  r2 = r2.wrapping_shr(1)
    mov64 r1, r7                                    r1 = r7
    or64 r1, r2                                     r1 |= r2   ///  r1 = r1.or(r2)
    lddw r2, 0xfffffff8                             r2 load str located at 4294967288
    mov64 r3, r1                                    r3 = r1
    and64 r3, r2                                    r3 &= r2   ///  r3 = r3.and(r2)
    rsh64 r3, 2                                     r3 >>= 2   ///  r3 = r3.wrapping_shr(2)
    or64 r1, r3                                     r1 |= r3   ///  r1 = r1.or(r3)
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
    stxb [r10-0x8], r2                      
    stxh [r10-0xa], r2                      
    lddw r2, 0xffffffe0                             r2 load str located at 4294967264
    mov64 r3, r1                                    r3 = r1
    and64 r3, r2                                    r3 &= r2   ///  r3 = r3.and(r2)
    rsh64 r3, 4                                     r3 >>= 4   ///  r3 = r3.wrapping_shr(4)
    or64 r1, r3                                     r1 |= r3   ///  r1 = r1.or(r3)
    mov64 r2, r7                                    r2 = r7
    rsh64 r2, 4                                     r2 >>= 4   ///  r2 = r2.wrapping_shr(4)
    and64 r2, 15                                    r2 &= 15   ///  r2 = r2.and(15)
    mov64 r4, r7                                    r4 = r7
    rsh64 r4, 8                                     r4 >>= 8   ///  r4 = r4.wrapping_shr(8)
    and64 r4, 15                                    r4 &= 15   ///  r4 = r4.and(15)
    mov64 r0, r7                                    r0 = r7
    rsh64 r0, 12                                    r0 >>= 12   ///  r0 = r0.wrapping_shr(12)
    and64 r0, 15                                    r0 &= 15   ///  r0 = r0.and(15)
    mov64 r8, r7                                    r8 = r7
    rsh64 r8, 16                                    r8 >>= 16   ///  r8 = r8.wrapping_shr(16)
    and64 r8, 15                                    r8 &= 15   ///  r8 = r8.and(15)
    mov64 r5, r7                                    r5 = r7
    rsh64 r5, 20                                    r5 >>= 20   ///  r5 = r5.wrapping_shr(20)
    and64 r5, 15                                    r5 &= 15   ///  r5 = r5.and(15)
    lddw r9, 0x10005fdc8 --> b"0123456789abcdef\x00\x00\x06\x00\x00\x00\x00\x00\x01\x00\x00\x00\x00\x00\…        r9 load str located at 4295359944
    lddw r3, 0x10005fdc8 --> b"0123456789abcdef\x00\x00\x06\x00\x00\x00\x00\x00\x01\x00\x00\x00\x00\x00\…        r3 load str located at 4295359944
    add64 r3, r5                                    r3 += r5   ///  r3 = r3.wrapping_add(r5)
    lddw r5, 0x10005fdc8 --> b"0123456789abcdef\x00\x00\x06\x00\x00\x00\x00\x00\x01\x00\x00\x00\x00\x00\…        r5 load str located at 4295359944
    add64 r5, r8                                    r5 += r8   ///  r5 = r5.wrapping_add(r8)
    lddw r8, 0x10005fdc8 --> b"0123456789abcdef\x00\x00\x06\x00\x00\x00\x00\x00\x01\x00\x00\x00\x00\x00\…        r8 load str located at 4295359944
    add64 r8, r0                                    r8 += r0   ///  r8 = r8.wrapping_add(r0)
    lddw r0, 0x10005fdc8 --> b"0123456789abcdef\x00\x00\x06\x00\x00\x00\x00\x00\x01\x00\x00\x00\x00\x00\…        r0 load str located at 4295359944
    add64 r0, r4                                    r0 += r4   ///  r0 = r0.wrapping_add(r4)
    lddw r4, 0x10005fdc8 --> b"0123456789abcdef\x00\x00\x06\x00\x00\x00\x00\x00\x01\x00\x00\x00\x00\x00\…        r4 load str located at 4295359944
    add64 r4, r2                                    r4 += r2   ///  r4 = r4.wrapping_add(r2)
    and64 r7, 15                                    r7 &= 15   ///  r7 = r7.and(15)
    add64 r9, r7                                    r9 += r7   ///  r9 = r9.wrapping_add(r7)
    mov64 r2, 125                                   r2 = 125 as i32 as i64 as u64
    stxb [r10-0x1], r2                      
    ldxb r2, [r9+0x0]                       
    stxb [r10-0x2], r2                      
    ldxb r2, [r4+0x0]                       
    stxb [r10-0x3], r2                      
    ldxb r2, [r0+0x0]                       
    stxb [r10-0x4], r2                      
    ldxb r2, [r8+0x0]                       
    stxb [r10-0x5], r2                      
    ldxb r2, [r5+0x0]                       
    stxb [r10-0x6], r2                      
    ldxb r2, [r3+0x0]                       
    stxb [r10-0x7], r2                      
    lddw r2, 0xfffffe00                             r2 load str located at 4294966784
    mov64 r3, r1                                    r3 = r1
    and64 r3, r2                                    r3 &= r2   ///  r3 = r3.and(r2)
    rsh64 r3, 8                                     r3 >>= 8   ///  r3 = r3.wrapping_shr(8)
    or64 r1, r3                                     r1 |= r3   ///  r1 = r1.or(r3)
    lddw r2, 0xfffe0000                             r2 load str located at 4294836224
    mov64 r3, r1                                    r3 = r1
    and64 r3, r2                                    r3 &= r2   ///  r3 = r3.and(r2)
    rsh64 r3, 16                                    r3 >>= 16   ///  r3 = r3.wrapping_shr(16)
    or64 r1, r3                                     r1 |= r3   ///  r1 = r1.or(r3)
    xor64 r1, -1                                    r1 ^= -1   ///  r1 = r1.xor(-1)
    mov64 r2, r1                                    r2 = r1
    and64 r2, -2                                    r2 &= -2   ///  r2 = r2.and(-2)
    rsh64 r1, 1                                     r1 >>= 1   ///  r1 = r1.wrapping_shr(1)
    and64 r1, 1431655765                            r1 &= 1431655765   ///  r1 = r1.and(1431655765)
    sub64 r2, r1                                    r2 -= r1   ///  r2 = r2.wrapping_sub(r1)
    mov64 r1, r2                                    r1 = r2
    and64 r1, 858993459                             r1 &= 858993459   ///  r1 = r1.and(858993459)
    rsh64 r2, 2                                     r2 >>= 2   ///  r2 = r2.wrapping_shr(2)
    and64 r2, 858993459                             r2 &= 858993459   ///  r2 = r2.and(858993459)
    add64 r1, r2                                    r1 += r2   ///  r1 = r1.wrapping_add(r2)
    mov64 r2, r1                                    r2 = r1
    rsh64 r2, 4                                     r2 >>= 4   ///  r2 = r2.wrapping_shr(4)
    add64 r1, r2                                    r1 += r2   ///  r1 = r1.wrapping_add(r2)
    and64 r1, 252645135                             r1 &= 252645135   ///  r1 = r1.and(252645135)
    mul64 r1, 16843009                              r1 *= 16843009   ///  r1 = r1.wrapping_mul(16843009 as u64)
    rsh64 r1, 26                                    r1 >>= 26   ///  r1 = r1.wrapping_shr(26)
    and64 r1, 63                                    r1 &= 63   ///  r1 = r1.and(63)
    add64 r1, -2                                    r1 += -2   ///  r1 = r1.wrapping_add(-2 as i32 as i64 as u64)
    mov64 r2, 11                                    r2 = 11 as i32 as i64 as u64
    jgt r2, r1, lbb_44070                           if r2 > r1 { pc += 109 }
    ja lbb_44065                                    if true { pc += 103 }
lbb_43962:
    lddw r1, 0xfffffffc                             r1 load str located at 4294967292
    mov64 r2, r7                                    r2 = r7
    and64 r2, r1                                    r2 &= r1   ///  r2 = r2.and(r1)
    rsh64 r2, 1                                     r2 >>= 1   ///  r2 = r2.wrapping_shr(1)
    mov64 r1, r7                                    r1 = r7
    or64 r1, r2                                     r1 |= r2   ///  r1 = r1.or(r2)
    lddw r2, 0xfffffff8                             r2 load str located at 4294967288
    mov64 r3, r1                                    r3 = r1
    and64 r3, r2                                    r3 &= r2   ///  r3 = r3.and(r2)
    rsh64 r3, 2                                     r3 >>= 2   ///  r3 = r3.wrapping_shr(2)
    or64 r1, r3                                     r1 |= r3   ///  r1 = r1.or(r3)
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
    stxb [r10-0x8], r2                      
    stxh [r10-0xa], r2                      
    lddw r2, 0xffffffe0                             r2 load str located at 4294967264
    mov64 r3, r1                                    r3 = r1
    and64 r3, r2                                    r3 &= r2   ///  r3 = r3.and(r2)
    rsh64 r3, 4                                     r3 >>= 4   ///  r3 = r3.wrapping_shr(4)
    or64 r1, r3                                     r1 |= r3   ///  r1 = r1.or(r3)
    mov64 r2, r7                                    r2 = r7
    rsh64 r2, 4                                     r2 >>= 4   ///  r2 = r2.wrapping_shr(4)
    and64 r2, 15                                    r2 &= 15   ///  r2 = r2.and(15)
    mov64 r4, r7                                    r4 = r7
    rsh64 r4, 8                                     r4 >>= 8   ///  r4 = r4.wrapping_shr(8)
    and64 r4, 15                                    r4 &= 15   ///  r4 = r4.and(15)
    mov64 r0, r7                                    r0 = r7
    rsh64 r0, 12                                    r0 >>= 12   ///  r0 = r0.wrapping_shr(12)
    and64 r0, 15                                    r0 &= 15   ///  r0 = r0.and(15)
    mov64 r8, r7                                    r8 = r7
    rsh64 r8, 16                                    r8 >>= 16   ///  r8 = r8.wrapping_shr(16)
    and64 r8, 15                                    r8 &= 15   ///  r8 = r8.and(15)
    mov64 r5, r7                                    r5 = r7
    rsh64 r5, 20                                    r5 >>= 20   ///  r5 = r5.wrapping_shr(20)
    and64 r5, 15                                    r5 &= 15   ///  r5 = r5.and(15)
    lddw r9, 0x10005fdc8 --> b"0123456789abcdef\x00\x00\x06\x00\x00\x00\x00\x00\x01\x00\x00\x00\x00\x00\…        r9 load str located at 4295359944
    lddw r3, 0x10005fdc8 --> b"0123456789abcdef\x00\x00\x06\x00\x00\x00\x00\x00\x01\x00\x00\x00\x00\x00\…        r3 load str located at 4295359944
    add64 r3, r5                                    r3 += r5   ///  r3 = r3.wrapping_add(r5)
    lddw r5, 0x10005fdc8 --> b"0123456789abcdef\x00\x00\x06\x00\x00\x00\x00\x00\x01\x00\x00\x00\x00\x00\…        r5 load str located at 4295359944
    add64 r5, r8                                    r5 += r8   ///  r5 = r5.wrapping_add(r8)
    lddw r8, 0x10005fdc8 --> b"0123456789abcdef\x00\x00\x06\x00\x00\x00\x00\x00\x01\x00\x00\x00\x00\x00\…        r8 load str located at 4295359944
    add64 r8, r0                                    r8 += r0   ///  r8 = r8.wrapping_add(r0)
    lddw r0, 0x10005fdc8 --> b"0123456789abcdef\x00\x00\x06\x00\x00\x00\x00\x00\x01\x00\x00\x00\x00\x00\…        r0 load str located at 4295359944
    add64 r0, r4                                    r0 += r4   ///  r0 = r0.wrapping_add(r4)
    lddw r4, 0x10005fdc8 --> b"0123456789abcdef\x00\x00\x06\x00\x00\x00\x00\x00\x01\x00\x00\x00\x00\x00\…        r4 load str located at 4295359944
    add64 r4, r2                                    r4 += r2   ///  r4 = r4.wrapping_add(r2)
    and64 r7, 15                                    r7 &= 15   ///  r7 = r7.and(15)
    add64 r9, r7                                    r9 += r7   ///  r9 = r9.wrapping_add(r7)
    mov64 r2, 125                                   r2 = 125 as i32 as i64 as u64
    stxb [r10-0x1], r2                      
    ldxb r2, [r9+0x0]                       
    stxb [r10-0x2], r2                      
    ldxb r2, [r4+0x0]                       
    stxb [r10-0x3], r2                      
    ldxb r2, [r0+0x0]                       
    stxb [r10-0x4], r2                      
    ldxb r2, [r8+0x0]                       
    stxb [r10-0x5], r2                      
    ldxb r2, [r5+0x0]                       
    stxb [r10-0x6], r2                      
    ldxb r2, [r3+0x0]                       
    stxb [r10-0x7], r2                      
    lddw r2, 0xfffffe00                             r2 load str located at 4294966784
    mov64 r3, r1                                    r3 = r1
    and64 r3, r2                                    r3 &= r2   ///  r3 = r3.and(r2)
    rsh64 r3, 8                                     r3 >>= 8   ///  r3 = r3.wrapping_shr(8)
    or64 r1, r3                                     r1 |= r3   ///  r1 = r1.or(r3)
    lddw r2, 0xfffe0000                             r2 load str located at 4294836224
    mov64 r3, r1                                    r3 = r1
    and64 r3, r2                                    r3 &= r2   ///  r3 = r3.and(r2)
    rsh64 r3, 16                                    r3 >>= 16   ///  r3 = r3.wrapping_shr(16)
    or64 r1, r3                                     r1 |= r3   ///  r1 = r1.or(r3)
    xor64 r1, -1                                    r1 ^= -1   ///  r1 = r1.xor(-1)
    mov64 r2, r1                                    r2 = r1
    and64 r2, -2                                    r2 &= -2   ///  r2 = r2.and(-2)
    rsh64 r1, 1                                     r1 >>= 1   ///  r1 = r1.wrapping_shr(1)
    and64 r1, 1431655765                            r1 &= 1431655765   ///  r1 = r1.and(1431655765)
    sub64 r2, r1                                    r2 -= r1   ///  r2 = r2.wrapping_sub(r1)
    mov64 r1, r2                                    r1 = r2
    and64 r1, 858993459                             r1 &= 858993459   ///  r1 = r1.and(858993459)
    rsh64 r2, 2                                     r2 >>= 2   ///  r2 = r2.wrapping_shr(2)
    and64 r2, 858993459                             r2 &= 858993459   ///  r2 = r2.and(858993459)
    add64 r1, r2                                    r1 += r2   ///  r1 = r1.wrapping_add(r2)
    mov64 r2, r1                                    r2 = r1
    rsh64 r2, 4                                     r2 >>= 4   ///  r2 = r2.wrapping_shr(4)
    add64 r1, r2                                    r1 += r2   ///  r1 = r1.wrapping_add(r2)
    and64 r1, 252645135                             r1 &= 252645135   ///  r1 = r1.and(252645135)
    mul64 r1, 16843009                              r1 *= 16843009   ///  r1 = r1.wrapping_mul(16843009 as u64)
    rsh64 r1, 26                                    r1 >>= 26   ///  r1 = r1.wrapping_shr(26)
    and64 r1, 63                                    r1 &= 63   ///  r1 = r1.and(63)
    add64 r1, -2                                    r1 += -2   ///  r1 = r1.wrapping_add(-2 as i32 as i64 as u64)
    mov64 r2, 11                                    r2 = 11 as i32 as i64 as u64
    jgt r2, r1, lbb_44070                           if r2 > r1 { pc += 5 }
lbb_44065:
    mov64 r2, 10                                    r2 = 10 as i32 as i64 as u64
    lddw r3, 0x100067528 --> b"\x00\x00\x00\x00;F\x06\x00\x1a\x00\x00\x00\x00\x00\x00\x004\x00\x00\x00\x…        r3 load str located at 4295390504
    call function_46508                     
    syscall [invalid]                       
lbb_44070:
    mov64 r2, r10                                   r2 = r10
    add64 r2, -10                                   r2 += -10   ///  r2 = r2.wrapping_add(-10 as i32 as i64 as u64)
    add64 r2, r1                                    r2 += r1   ///  r2 = r2.wrapping_add(r1)
    mov64 r3, 123                                   r3 = 123 as i32 as i64 as u64
    stxb [r2+0x2], r3                       
    mov64 r3, 30044                                 r3 = 30044 as i32 as i64 as u64
    stxh [r2+0x0], r3                       
    ldxh r2, [r10-0x2]                      
    stxh [r6+0x8], r2                       
    ldxdw r2, [r10-0xa]                     
    stxdw [r6+0x0], r2                      
    mov64 r2, 10                                    r2 = 10 as i32 as i64 as u64
    stxb [r6+0xb], r2                       
    stxb [r6+0xa], r1                       
    ja lbb_43857                                    if true { pc += -228 }

function_44085:
    mov64 r6, r3                                    r6 = r3
    stxdw [r10-0x48], r2                    
    stxdw [r10-0x50], r1                    
    lddw r1, 0x10005dfb0 --> b"\xbf$\x00\x00\x00\x00\x00\x00y\x13\x08\x00\x00\x00\x00\x00y\x12\x00\x00\x…        r1 load str located at 4295352240
    stxdw [r10-0x8], r1                     
    mov64 r1, r10                                   r1 = r10
    add64 r1, -80                                   r1 += -80   ///  r1 = r1.wrapping_add(-80 as i32 as i64 as u64)
    stxdw [r10-0x10], r1                    
    mov64 r7, r10                                   r7 = r10
    add64 r7, -64                                   r7 += -64   ///  r7 = r7.wrapping_add(-64 as i32 as i64 as u64)
    mov64 r4, r10                                   r4 = r10
    add64 r4, -16                                   r4 += -16   ///  r4 = r4.wrapping_add(-16 as i32 as i64 as u64)
    mov64 r1, r7                                    r1 = r7
    lddw r2, 0x100067248 --> b"\x00"                r2 load str located at 4295389768
    mov64 r3, 1                                     r3 = 1 as i32 as i64 as u64
    mov64 r5, 1                                     r5 = 1 as i32 as i64 as u64
    call function_45339                     
    mov64 r1, r7                                    r1 = r7
    mov64 r2, r6                                    r2 = r6
    call function_44240                     
    syscall [invalid]                       

function_44108:
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
    stxdw [r10-0x70], r3                    
    lddw r3, 0x100067258 --> b"\x00\x00\x00\x00\xe8<\x06\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00…        r3 load str located at 4295389784
    stxdw [r10-0x90], r3                    
    mov64 r3, 3                                     r3 = 3 as i32 as i64 as u64
    stxdw [r10-0x88], r3                    
    stxdw [r10-0x78], r3                    
    mov64 r3, r10                                   r3 = r10
    add64 r3, -96                                   r3 += -96   ///  r3 = r3.wrapping_add(-96 as i32 as i64 as u64)
    stxdw [r10-0x80], r3                    
    mov64 r3, r1                                    r3 = r1
    add64 r3, 20                                    r3 += 20   ///  r3 = r3.wrapping_add(20 as i32 as i64 as u64)
    stxdw [r10-0x40], r3                    
    lddw r3, 0x10005df30 --> b"\xbf#\x00\x00\x00\x00\x00\x00a\x11\x00\x00\x00\x00\x00\x00\xb7\x02\x00\x0…        r3 load str located at 4295352112
    stxdw [r10-0x38], r3                    
    stxdw [r10-0x48], r3                    
    mov64 r3, r1                                    r3 = r1
    add64 r3, 16                                    r3 += 16   ///  r3 = r3.wrapping_add(16 as i32 as i64 as u64)
    stxdw [r10-0x50], r3                    
    lddw r3, 0x10005dfb0 --> b"\xbf$\x00\x00\x00\x00\x00\x00y\x13\x08\x00\x00\x00\x00\x00y\x12\x00\x00\x…        r3 load str located at 4295352240
    stxdw [r10-0x58], r3                    
    stxdw [r10-0x60], r1                    
    ldxdw r4, [r2+0x28]                     
    ldxdw r1, [r2+0x20]                     
    mov64 r3, r10                                   r3 = r10
    add64 r3, -144                                  r3 += -144   ///  r3 = r3.wrapping_add(-144 as i32 as i64 as u64)
    mov64 r2, r4                                    r2 = r4
    call function_45367                     
    exit                                    

function_44140:
    mov64 r8, r1                                    r8 = r1
    ldxdw r6, [r2+0x20]                     
    ldxdw r7, [r2+0x28]                     
    ldxdw r9, [r7+0x18]                     
    mov64 r1, r6                                    r1 = r6
    lddw r2, 0x100063d64 --> b"panicked at "        r2 load str located at 4295376228
    mov64 r3, 12                                    r3 = 12 as i32 as i64 as u64
    callx r9                                
    mov64 r1, r0                                    r1 = r0
    mov64 r0, 1                                     r0 = 1 as i32 as i64 as u64
    jne r1, 0, lbb_44239                            if r1 != (0 as i32 as i64 as u64) { pc += 87 }
    ldxdw r1, [r8+0x18]                     
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
    stxdw [r10-0x70], r2                    
    lddw r2, 0x100067258 --> b"\x00\x00\x00\x00\xe8<\x06\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00…        r2 load str located at 4295389784
    stxdw [r10-0x90], r2                    
    mov64 r2, 3                                     r2 = 3 as i32 as i64 as u64
    stxdw [r10-0x88], r2                    
    stxdw [r10-0x78], r2                    
    mov64 r2, r10                                   r2 = r10
    add64 r2, -96                                   r2 += -96   ///  r2 = r2.wrapping_add(-96 as i32 as i64 as u64)
    stxdw [r10-0x80], r2                    
    mov64 r2, r1                                    r2 = r1
    add64 r2, 20                                    r2 += 20   ///  r2 = r2.wrapping_add(20 as i32 as i64 as u64)
    stxdw [r10-0x40], r2                    
    lddw r2, 0x10005df30 --> b"\xbf#\x00\x00\x00\x00\x00\x00a\x11\x00\x00\x00\x00\x00\x00\xb7\x02\x00\x0…        r2 load str located at 4295352112
    stxdw [r10-0x38], r2                    
    stxdw [r10-0x48], r2                    
    mov64 r2, r1                                    r2 = r1
    add64 r2, 16                                    r2 += 16   ///  r2 = r2.wrapping_add(16 as i32 as i64 as u64)
    stxdw [r10-0x50], r2                    
    lddw r2, 0x10005dfb0 --> b"\xbf$\x00\x00\x00\x00\x00\x00y\x13\x08\x00\x00\x00\x00\x00y\x12\x00\x00\x…        r2 load str located at 4295352240
    stxdw [r10-0x58], r2                    
    stxdw [r10-0x60], r1                    
    mov64 r3, r10                                   r3 = r10
    add64 r3, -144                                  r3 += -144   ///  r3 = r3.wrapping_add(-144 as i32 as i64 as u64)
    mov64 r1, r6                                    r1 = r6
    mov64 r2, r7                                    r2 = r7
    call function_45367                     
    mov64 r1, r0                                    r1 = r0
    mov64 r0, 1                                     r0 = 1 as i32 as i64 as u64
    jne r1, 0, lbb_44239                            if r1 != (0 as i32 as i64 as u64) { pc += 53 }
    ldxdw r1, [r8+0x10]                     
    jeq r1, 0, lbb_44208                            if r1 == (0 as i32 as i64 as u64) { pc += 20 }
    stxdw [r10-0xa8], r1                    
    mov64 r1, r6                                    r1 = r6
    lddw r2, 0x100063d70 --> b":\x0a"               r2 load str located at 4295376240
    mov64 r3, 2                                     r3 = 2 as i32 as i64 as u64
    callx r9                                
    mov64 r1, r0                                    r1 = r0
    mov64 r0, 1                                     r0 = 1 as i32 as i64 as u64
    jne r1, 0, lbb_44239                            if r1 != (0 as i32 as i64 as u64) { pc += 42 }
    mov64 r8, r10                                   r8 = r10
    add64 r8, -96                                   r8 += -96   ///  r8 = r8.wrapping_add(-96 as i32 as i64 as u64)
    mov64 r1, r8                                    r1 = r8
    ldxdw r2, [r10-0xa8]                    
    mov64 r3, 48                                    r3 = 48 as i32 as i64 as u64
    call function_48190                     
    mov64 r1, r6                                    r1 = r6
    mov64 r2, r7                                    r2 = r7
    mov64 r3, r8                                    r3 = r8
    call function_45367                     
    ja lbb_44239                                    if true { pc += 31 }
lbb_44208:
    ldxdw r7, [r8+0x0]                      
    ldxdw r1, [r8+0x8]                      
    ldxdw r3, [r1+0x18]                     
    mov64 r1, r10                                   r1 = r10
    add64 r1, -160                                  r1 += -160   ///  r1 = r1.wrapping_add(-160 as i32 as i64 as u64)
    mov64 r2, r7                                    r2 = r7
    callx r3                                
    lddw r1, 0xfdbc168100b1ef64                     r1 load str located at -163230743173927068
    ldxdw r2, [r10-0x98]                    
    xor64 r2, r1                                    r2 ^= r1   ///  r2 = r2.xor(r1)
    lddw r1, 0xc1a2c89ccd1e7bc1                     r1 load str located at -4493808902380553279
    ldxdw r3, [r10-0xa0]                    
    xor64 r3, r1                                    r3 ^= r1   ///  r3 = r3.xor(r1)
    or64 r3, r2                                     r3 |= r2   ///  r3 = r3.or(r2)
    mov64 r0, 0                                     r0 = 0 as i32 as i64 as u64
    jeq r3, 0, lbb_44227                            if r3 == (0 as i32 as i64 as u64) { pc += 1 }
    ja lbb_44239                                    if true { pc += 12 }
lbb_44227:
    mov64 r1, r6                                    r1 = r6
    lddw r2, 0x100063d70 --> b":\x0a"               r2 load str located at 4295376240
    mov64 r3, 2                                     r3 = 2 as i32 as i64 as u64
    callx r9                                
    mov64 r1, r0                                    r1 = r0
    mov64 r0, 1                                     r0 = 1 as i32 as i64 as u64
    jne r1, 0, lbb_44239                            if r1 != (0 as i32 as i64 as u64) { pc += 4 }
    ldxdw r3, [r7+0x8]                      
    ldxdw r2, [r7+0x0]                      
    mov64 r1, r6                                    r1 = r6
    callx r9                                
lbb_44239:
    exit                                    

function_44240:
    mov64 r3, 1                                     r3 = 1 as i32 as i64 as u64
    stxh [r10-0x8], r3                      
    stxdw [r10-0x10], r2                    
    stxdw [r10-0x18], r1                    
    lddw r1, 0x100067288 --> b"\x00\x00\x00\x008W\x05\x00\x00\x00\x00\x00\x00\x00\x00\x00\x01\x00\x00\x0…        r1 load str located at 4295389832
    stxdw [r10-0x20], r1                    
    lddw r1, 0x100063ce8 --> b"called `Option::unwrap()` on a `None` value)invali"        r1 load str located at 4295376104
    stxdw [r10-0x28], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -40                                   r1 += -40   ///  r1 = r1.wrapping_add(-40 as i32 as i64 as u64)
    call function_43004                     
    syscall [invalid]                       

function_44254:
    mov64 r4, 1                                     r4 = 1 as i32 as i64 as u64
    stxdw [r10-0x38], r4                    
    mov64 r4, r10                                   r4 = r10
    add64 r4, -16                                   r4 += -16   ///  r4 = r4.wrapping_add(-16 as i32 as i64 as u64)
    stxdw [r10-0x40], r4                    
    mov64 r4, 0                                     r4 = 0 as i32 as i64 as u64
    stxdw [r10-0x20], r4                    
    stxdw [r10-0x28], r4                    
    lddw r4, 0x100063ce8 --> b"called `Option::unwrap()` on a `None` value)invali"        r4 load str located at 4295376104
    stxdw [r10-0x30], r4                    
    stxdw [r10-0x8], r2                     
    stxdw [r10-0x10], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -64                                   r1 += -64   ///  r1 = r1.wrapping_add(-64 as i32 as i64 as u64)
    mov64 r2, r3                                    r2 = r3
    call function_44240                     
    syscall [invalid]                       

function_44272:
    mov64 r6, r3                                    r6 = r3
    stxdw [r10-0x58], r2                    
    stxdw [r10-0x60], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -96                                   r1 += -96   ///  r1 = r1.wrapping_add(-96 as i32 as i64 as u64)
    stxdw [r10-0x10], r1                    
    lddw r1, 0x10005df58 --> b"\xbf#\x00\x00\x00\x00\x00\x00y\x11\x00\x00\x00\x00\x00\x00\xb7\x02\x00\x0…        r1 load str located at 4295352152
    stxdw [r10-0x8], r1                     
    stxdw [r10-0x18], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -88                                   r1 += -88   ///  r1 = r1.wrapping_add(-88 as i32 as i64 as u64)
    stxdw [r10-0x20], r1                    
    mov64 r7, r10                                   r7 = r10
    add64 r7, -80                                   r7 += -80   ///  r7 = r7.wrapping_add(-80 as i32 as i64 as u64)
    mov64 r4, r10                                   r4 = r10
    add64 r4, -32                                   r4 += -32   ///  r4 = r4.wrapping_add(-32 as i32 as i64 as u64)
    mov64 r1, r7                                    r1 = r7
    lddw r2, 0x1000672a8 --> b"\x00\x00"            r2 load str located at 4295389864
    mov64 r3, 2                                     r3 = 2 as i32 as i64 as u64
    mov64 r5, 2                                     r5 = 2 as i32 as i64 as u64
    call function_45339                     
    mov64 r1, r7                                    r1 = r7
    mov64 r2, r6                                    r2 = r6
    call function_44240                     
    syscall [invalid]                       

function_44299:
    mov64 r6, r5                                    r6 = r5
    stxdw [r10-0x68], r2                    
    stxdw [r10-0x70], r1                    
    stxdw [r10-0x58], r4                    
    stxdw [r10-0x60], r3                    
    lddw r1, 0x10005df80 --> b"y\x13\x00\x00\x00\x00\x00\x00y\x11\x08\x00\x00\x00\x00\x00y\x14\x18\x00\x…        r1 load str located at 4295352192
    stxdw [r10-0x8], r1                     
    mov64 r1, r10                                   r1 = r10
    add64 r1, -96                                   r1 += -96   ///  r1 = r1.wrapping_add(-96 as i32 as i64 as u64)
    stxdw [r10-0x10], r1                    
    lddw r1, 0x10005dfb0 --> b"\xbf$\x00\x00\x00\x00\x00\x00y\x13\x08\x00\x00\x00\x00\x00y\x12\x00\x00\x…        r1 load str located at 4295352240
    stxdw [r10-0x18], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -112                                  r1 += -112   ///  r1 = r1.wrapping_add(-112 as i32 as i64 as u64)
    stxdw [r10-0x20], r1                    
    mov64 r7, r10                                   r7 = r10
    add64 r7, -80                                   r7 += -80   ///  r7 = r7.wrapping_add(-80 as i32 as i64 as u64)
    mov64 r4, r10                                   r4 = r10
    add64 r4, -32                                   r4 += -32   ///  r4 = r4.wrapping_add(-32 as i32 as i64 as u64)
    mov64 r1, r7                                    r1 = r7
    lddw r2, 0x1000672c8 --> b"\x00\x00"            r2 load str located at 4295389896
    mov64 r3, 2                                     r3 = 2 as i32 as i64 as u64
    mov64 r5, 2                                     r5 = 2 as i32 as i64 as u64
    call function_45339                     
    mov64 r1, r7                                    r1 = r7
    mov64 r2, r6                                    r2 = r6
    call function_44240                     
    syscall [invalid]                       

function_44330:
    mov64 r7, r3                                    r7 = r3
    stxdw [r10-0x18], r2                    
    mov64 r6, 0                                     r6 = 0 as i32 as i64 as u64
    ldxdw r2, [r1+0x8]                      
    stxdw [r10-0x28], r2                    
    ldxdw r2, [r1+0x0]                      
    stxdw [r10-0x30], r2                    
    ldxdw r1, [r1+0x10]                     
    stxdw [r10-0x20], r1                    
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    stxdw [r10-0x10], r1                    
    mov64 r9, 0                                     r9 = 0 as i32 as i64 as u64
    ja lbb_44355                                    if true { pc += 12 }
lbb_44343:
    and64 r1, 1                                     r1 &= 1   ///  r1 = r1.and(1)
    ldxdw r4, [r10-0x20]                    
    stxb [r4+0x0], r1                       
    ldxdw r1, [r10-0x28]                    
    ldxdw r4, [r1+0x18]                     
    ldxdw r1, [r10-0x30]                    
    callx r4                                
    mov64 r1, r0                                    r1 = r0
    mov64 r0, 1                                     r0 = 1 as i32 as i64 as u64
    ldxdw r2, [r10-0x8]                     
    stxdw [r10-0x10], r2                    
    jne r1, 0, lbb_44487                            if r1 != (0 as i32 as i64 as u64) { pc += 132 }
lbb_44355:
    and64 r9, 255                                   r9 &= 255   ///  r9 = r9.and(255)
    mov64 r0, 0                                     r0 = 0 as i32 as i64 as u64
    jne r9, 0, lbb_44487                            if r9 != (0 as i32 as i64 as u64) { pc += 129 }
    jgt r6, r7, lbb_44454                           if r6 > r7 { pc += 95 }
    mov64 r1, r6                                    r1 = r6
lbb_44360:
    ldxdw r2, [r10-0x18]                    
    add64 r2, r1                                    r2 += r1   ///  r2 = r2.wrapping_add(r1)
    mov64 r3, r7                                    r3 = r7
    sub64 r3, r1                                    r3 -= r1   ///  r3 = r3.wrapping_sub(r1)
    mov64 r4, 16                                    r4 = 16 as i32 as i64 as u64
    jgt r4, r3, lbb_44426                           if r4 > r3 { pc += 60 }
    mov64 r6, r2                                    r6 = r2
    add64 r6, 7                                     r6 += 7   ///  r6 = r6.wrapping_add(7 as i32 as i64 as u64)
    and64 r6, -8                                    r6 &= -8   ///  r6 = r6.and(-8)
    mov64 r4, r6                                    r4 = r6
    sub64 r4, r2                                    r4 -= r2   ///  r4 = r4.wrapping_sub(r2)
    jeq r4, 0, lbb_44379                            if r4 == (0 as i32 as i64 as u64) { pc += 7 }
    mov64 r5, 0                                     r5 = 0 as i32 as i64 as u64
lbb_44373:
    mov64 r0, r2                                    r0 = r2
    add64 r0, r5                                    r0 += r5   ///  r0 = r0.wrapping_add(r5)
    ldxb r0, [r0+0x0]                       
    jeq r0, 10, lbb_44439                           if r0 == (10 as i32 as i64 as u64) { pc += 62 }
    add64 r5, 1                                     r5 += 1   ///  r5 = r5.wrapping_add(1 as i32 as i64 as u64)
    jgt r4, r5, lbb_44373                           if r4 > r5 { pc += -6 }
lbb_44379:
    stxdw [r10-0x38], r1                    
    mov64 r1, r3                                    r1 = r3
    add64 r1, -16                                   r1 += -16   ///  r1 = r1.wrapping_add(-16 as i32 as i64 as u64)
    stxdw [r10-0x8], r1                     
    jgt r4, r1, lbb_44412                           if r4 > r1 { pc += 28 }
    mov64 r0, 8                                     r0 = 8 as i32 as i64 as u64
    add64 r0, r6                                    r0 += r6   ///  r0 = r0.wrapping_add(r6)
    ja lbb_44391                                    if true { pc += 4 }
lbb_44387:
    add64 r0, 16                                    r0 += 16   ///  r0 = r0.wrapping_add(16 as i32 as i64 as u64)
    add64 r4, 16                                    r4 += 16   ///  r4 = r4.wrapping_add(16 as i32 as i64 as u64)
    ldxdw r1, [r10-0x8]                     
    jgt r4, r1, lbb_44412                           if r4 > r1 { pc += 21 }
lbb_44391:
    ldxdw r6, [r0-0x8]                      
    mov64 r8, r6                                    r8 = r6
    lddw r1, 0xa0a0a0a0a0a0a0a                      r1 load str located at 723401728380766730
    xor64 r8, r1                                    r8 ^= r1   ///  r8 = r8.xor(r1)
    lddw r5, 0xfefefefefefefeff                     r5 load str located at -72340172838076673
    add64 r8, r5                                    r8 += r5   ///  r8 = r8.wrapping_add(r5)
    xor64 r6, -1                                    r6 ^= -1   ///  r6 = r6.xor(-1)
    and64 r8, r6                                    r8 &= r6   ///  r8 = r8.and(r6)
    ldxdw r6, [r0+0x0]                      
    mov64 r9, r6                                    r9 = r6
    xor64 r9, r1                                    r9 ^= r1   ///  r9 = r9.xor(r1)
    add64 r9, r5                                    r9 += r5   ///  r9 = r9.wrapping_add(r5)
    xor64 r6, -1                                    r6 ^= -1   ///  r6 = r6.xor(-1)
    and64 r9, r6                                    r9 &= r6   ///  r9 = r9.and(r6)
    or64 r9, r8                                     r9 |= r8   ///  r9 = r9.or(r8)
    lddw r1, 0x8080808080808080                     r1 load str located at -9187201950435737472
    and64 r9, r1                                    r9 &= r1   ///  r9 = r9.and(r1)
    jeq r9, 0, lbb_44387                            if r9 == (0 as i32 as i64 as u64) { pc += -25 }
lbb_44412:
    mov64 r6, r7                                    r6 = r7
    ldxdw r1, [r10-0x38]                    
    jeq r3, r4, lbb_44454                           if r3 == r4 { pc += 39 }
    sub64 r3, r4                                    r3 -= r4   ///  r3 = r3.wrapping_sub(r4)
    add64 r2, r4                                    r2 += r4   ///  r2 = r2.wrapping_add(r4)
    mov64 r5, 0                                     r5 = 0 as i32 as i64 as u64
lbb_44418:
    mov64 r0, r2                                    r0 = r2
    add64 r0, r5                                    r0 += r5   ///  r0 = r0.wrapping_add(r5)
    ldxb r0, [r0+0x0]                       
    jeq r0, 10, lbb_44437                           if r0 == (10 as i32 as i64 as u64) { pc += 15 }
    add64 r5, 1                                     r5 += 1   ///  r5 = r5.wrapping_add(1 as i32 as i64 as u64)
    mov64 r6, r7                                    r6 = r7
    jgt r3, r5, lbb_44418                           if r3 > r5 { pc += -7 }
    ja lbb_44454                                    if true { pc += 28 }
lbb_44426:
    mov64 r6, r7                                    r6 = r7
    jeq r7, r1, lbb_44454                           if r7 == r1 { pc += 26 }
    mov64 r5, 0                                     r5 = 0 as i32 as i64 as u64
lbb_44429:
    mov64 r4, r2                                    r4 = r2
    add64 r4, r5                                    r4 += r5   ///  r4 = r4.wrapping_add(r5)
    ldxb r4, [r4+0x0]                       
    jeq r4, 10, lbb_44439                           if r4 == (10 as i32 as i64 as u64) { pc += 6 }
    add64 r5, 1                                     r5 += 1   ///  r5 = r5.wrapping_add(1 as i32 as i64 as u64)
    mov64 r6, r7                                    r6 = r7
    jgt r3, r5, lbb_44429                           if r3 > r5 { pc += -7 }
    ja lbb_44454                                    if true { pc += 17 }
lbb_44437:
    add64 r4, r5                                    r4 += r5   ///  r4 = r4.wrapping_add(r5)
    mov64 r5, r4                                    r5 = r4
lbb_44439:
    add64 r1, r5                                    r1 += r5   ///  r1 = r1.wrapping_add(r5)
    mov64 r6, r1                                    r6 = r1
    add64 r6, 1                                     r6 += 1   ///  r6 = r6.wrapping_add(1 as i32 as i64 as u64)
    jgt r7, r1, lbb_44446                           if r7 > r1 { pc += 3 }
lbb_44443:
    mov64 r1, r6                                    r1 = r6
    jgt r6, r7, lbb_44454                           if r6 > r7 { pc += 9 }
    ja lbb_44360                                    if true { pc += -86 }
lbb_44446:
    ldxdw r2, [r10-0x18]                    
    add64 r2, r1                                    r2 += r1   ///  r2 = r2.wrapping_add(r1)
    mov64 r9, 0                                     r9 = 0 as i32 as i64 as u64
    ldxb r1, [r2+0x0]                       
    stxdw [r10-0x8], r6                     
    mov64 r8, r6                                    r8 = r6
    jeq r1, 10, lbb_44460                           if r1 == (10 as i32 as i64 as u64) { pc += 7 }
    ja lbb_44443                                    if true { pc += -11 }
lbb_44454:
    mov64 r9, 1                                     r9 = 1 as i32 as i64 as u64
    ldxdw r1, [r10-0x10]                    
    stxdw [r10-0x8], r1                     
    mov64 r8, r7                                    r8 = r7
    mov64 r0, 0                                     r0 = 0 as i32 as i64 as u64
    jeq r1, r7, lbb_44487                           if r1 == r7 { pc += 27 }
lbb_44460:
    ldxdw r1, [r10-0x20]                    
    ldxb r1, [r1+0x0]                       
    jeq r1, 0, lbb_44473                            if r1 == (0 as i32 as i64 as u64) { pc += 10 }
    ldxdw r1, [r10-0x28]                    
    ldxdw r4, [r1+0x18]                     
    ldxdw r1, [r10-0x30]                    
    lddw r2, 0x10005fbe4 --> b"    "                r2 load str located at 4295359460
    mov64 r3, 4                                     r3 = 4 as i32 as i64 as u64
    callx r4                                
    mov64 r1, r0                                    r1 = r0
    mov64 r0, 1                                     r0 = 1 as i32 as i64 as u64
    jne r1, 0, lbb_44487                            if r1 != (0 as i32 as i64 as u64) { pc += 14 }
lbb_44473:
    ldxdw r2, [r10-0x18]                    
    ldxdw r4, [r10-0x10]                    
    add64 r2, r4                                    r2 += r4   ///  r2 = r2.wrapping_add(r4)
    mov64 r3, r8                                    r3 = r8
    sub64 r3, r4                                    r3 -= r4   ///  r3 = r3.wrapping_sub(r4)
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    jeq r8, r4, lbb_44343                           if r8 == r4 { pc += -137 }
    mov64 r1, r3                                    r1 = r3
    add64 r1, r2                                    r1 += r2   ///  r1 = r1.wrapping_add(r2)
    ldxb r4, [r1-0x1]                       
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    jeq r4, 10, lbb_44343                           if r4 == (10 as i32 as i64 as u64) { pc += -142 }
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    ja lbb_44343                                    if true { pc += -144 }
lbb_44487:
    exit                                    

function_44488:
    mov64 r6, r2                                    r6 = r2
    ldxdw r8, [r1+0x8]                      
    ldxdw r7, [r1+0x0]                      
    ldxdw r9, [r1+0x10]                     
    ldxb r1, [r9+0x0]                       
    jne r1, 0, lbb_44506                            if r1 != (0 as i32 as i64 as u64) { pc += 12 }
lbb_44494:
    mov64 r2, r6                                    r2 = r6
    lsh64 r2, 32                                    r2 <<= 32   ///  r2 = r2.wrapping_shl(32)
    rsh64 r2, 32                                    r2 >>= 32   ///  r2 = r2.wrapping_shr(32)
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    jeq r2, 10, lbb_44500                           if r2 == (10 as i32 as i64 as u64) { pc += 1 }
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
lbb_44500:
    stxb [r9+0x0], r1                       
    ldxdw r3, [r8+0x20]                     
    mov64 r1, r7                                    r1 = r7
    mov64 r2, r6                                    r2 = r6
    callx r3                                
    ja lbb_44515                                    if true { pc += 9 }
lbb_44506:
    ldxdw r4, [r8+0x18]                     
    mov64 r1, r7                                    r1 = r7
    lddw r2, 0x10005fbe4 --> b"    "                r2 load str located at 4295359460
    mov64 r3, 4                                     r3 = 4 as i32 as i64 as u64
    callx r4                                
    mov64 r1, r0                                    r1 = r0
    mov64 r0, 1                                     r0 = 1 as i32 as i64 as u64
    jeq r1, 0, lbb_44494                            if r1 == (0 as i32 as i64 as u64) { pc += -21 }
lbb_44515:
    exit                                    

function_44516:
    mov64 r8, r2                                    r8 = r2
    mov64 r6, r1                                    r6 = r1
    mov64 r2, 1                                     r2 = 1 as i32 as i64 as u64
    ldxb r1, [r6+0x8]                       
    mov64 r7, 1                                     r7 = 1 as i32 as i64 as u64
    jne r1, 0, lbb_44637                            if r1 != (0 as i32 as i64 as u64) { pc += 115 }
    stxdw [r10-0x68], r3                    
    ldxb r2, [r6+0x9]                       
    ldxdw r9, [r6+0x0]                      
    ldxw r1, [r9+0x34]                      
    mov64 r3, r1                                    r3 = r1
    and64 r3, 4                                     r3 &= 4   ///  r3 = r3.and(4)
    stxdw [r10-0x70], r4                    
    stxdw [r10-0x78], r5                    
    jne r3, 0, lbb_44571                            if r3 != (0 as i32 as i64 as u64) { pc += 40 }
    mov64 r1, r2                                    r1 = r2
    lddw r2, 0x100063d86 --> b" { ,  {\x0a,\x0a} }((\x0a,\x0a]library/core/src/fmt/num.rs0x00"        r2 load str located at 4295376262
    jeq r1, 0, lbb_44537                            if r1 == (0 as i32 as i64 as u64) { pc += 2 }
    lddw r2, 0x100063d89 --> b",  "                 r2 load str located at 4295376265
lbb_44537:
    mov64 r3, 3                                     r3 = 3 as i32 as i64 as u64
    jeq r1, 0, lbb_44540                            if r1 == (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r3, 2                                     r3 = 2 as i32 as i64 as u64
lbb_44540:
    ldxdw r1, [r9+0x20]                     
    ldxdw r4, [r9+0x28]                     
    ldxdw r4, [r4+0x18]                     
    callx r4                                
    mov64 r2, 1                                     r2 = 1 as i32 as i64 as u64
    ldxdw r3, [r10-0x68]                    
    jne r0, 0, lbb_44637                            if r0 != (0 as i32 as i64 as u64) { pc += 90 }
    ldxdw r1, [r9+0x20]                     
    ldxdw r2, [r9+0x28]                     
    ldxdw r4, [r2+0x18]                     
    mov64 r2, r8                                    r2 = r8
    callx r4                                
    mov64 r2, 1                                     r2 = 1 as i32 as i64 as u64
    jne r0, 0, lbb_44637                            if r0 != (0 as i32 as i64 as u64) { pc += 83 }
    ldxdw r1, [r9+0x20]                     
    ldxdw r2, [r9+0x28]                     
    ldxdw r4, [r2+0x18]                     
    lddw r2, 0x100063d84 --> b": "                  r2 load str located at 4295376260
    mov64 r3, 2                                     r3 = 2 as i32 as i64 as u64
    callx r4                                
    ldxdw r3, [r10-0x78]                    
    ldxdw r1, [r10-0x70]                    
    mov64 r2, 1                                     r2 = 1 as i32 as i64 as u64
    jne r0, 0, lbb_44637                            if r0 != (0 as i32 as i64 as u64) { pc += 72 }
    ldxdw r3, [r3+0x18]                     
    mov64 r2, r9                                    r2 = r9
    callx r3                                
    mov64 r2, 1                                     r2 = 1 as i32 as i64 as u64
    mov64 r7, r0                                    r7 = r0
    ja lbb_44637                                    if true { pc += 66 }
lbb_44571:
    jeq r2, 0, lbb_44573                            if r2 == (0 as i32 as i64 as u64) { pc += 1 }
    ja lbb_44583                                    if true { pc += 10 }
lbb_44573:
    ldxdw r1, [r9+0x20]                     
    ldxdw r2, [r9+0x28]                     
    ldxdw r4, [r2+0x18]                     
    lddw r2, 0x100063d8b --> b" {\x0a"              r2 load str located at 4295376267
    mov64 r3, 3                                     r3 = 3 as i32 as i64 as u64
    callx r4                                
    mov64 r2, 1                                     r2 = 1 as i32 as i64 as u64
    jne r0, 0, lbb_44637                            if r0 != (0 as i32 as i64 as u64) { pc += 55 }
    ldxw r1, [r9+0x34]                      
lbb_44583:
    stxb [r10-0x41], r7                     
    ldxdw r2, [r9+0x20]                     
    ldxdw r3, [r9+0x28]                     
    mov64 r4, r10                                   r4 = r10
    add64 r4, -65                                   r4 += -65   ///  r4 = r4.wrapping_add(-65 as i32 as i64 as u64)
    stxdw [r10-0x50], r4                    
    stxdw [r10-0x58], r3                    
    stxdw [r10-0x60], r2                    
    ldxdw r2, [r9+0x0]                      
    ldxdw r3, [r9+0x8]                      
    ldxdw r4, [r9+0x10]                     
    ldxdw r5, [r9+0x18]                     
    ldxw r0, [r9+0x30]                      
    ldxb r9, [r9+0x38]                      
    stxb [r10-0x8], r9                      
    stxw [r10-0x10], r0                     
    stxw [r10-0xc], r1                      
    lddw r1, 0x1000672e8 --> b"\x00\x00\x00\x000W\x05\x00\x18\x00\x00\x00\x00\x00\x00\x00\x08\x00\x00\x0…        r1 load str located at 4295389928
    stxdw [r10-0x18], r1                    
    stxdw [r10-0x28], r5                    
    stxdw [r10-0x30], r4                    
    stxdw [r10-0x38], r3                    
    stxdw [r10-0x40], r2                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -96                                   r1 += -96   ///  r1 = r1.wrapping_add(-96 as i32 as i64 as u64)
    stxdw [r10-0x20], r1                    
    mov64 r2, r8                                    r2 = r8
    ldxdw r3, [r10-0x68]                    
    call function_44330                     
    jne r0, 0, lbb_44636                            if r0 != (0 as i32 as i64 as u64) { pc += 22 }
    mov64 r1, r10                                   r1 = r10
    add64 r1, -96                                   r1 += -96   ///  r1 = r1.wrapping_add(-96 as i32 as i64 as u64)
    lddw r2, 0x100063d84 --> b": "                  r2 load str located at 4295376260
    mov64 r3, 2                                     r3 = 2 as i32 as i64 as u64
    call function_44330                     
    jne r0, 0, lbb_44636                            if r0 != (0 as i32 as i64 as u64) { pc += 15 }
    ldxdw r1, [r10-0x78]                    
    ldxdw r3, [r1+0x18]                     
    mov64 r2, r10                                   r2 = r10
    add64 r2, -64                                   r2 += -64   ///  r2 = r2.wrapping_add(-64 as i32 as i64 as u64)
    ldxdw r1, [r10-0x70]                    
    callx r3                                
    jne r0, 0, lbb_44636                            if r0 != (0 as i32 as i64 as u64) { pc += 8 }
    ldxdw r1, [r10-0x18]                    
    ldxdw r4, [r1+0x18]                     
    ldxdw r1, [r10-0x20]                    
    lddw r2, 0x100063d8e --> b",\x0a"               r2 load str located at 4295376270
    mov64 r3, 2                                     r3 = 2 as i32 as i64 as u64
    callx r4                                
    mov64 r7, r0                                    r7 = r0
lbb_44636:
    mov64 r2, 1                                     r2 = 1 as i32 as i64 as u64
lbb_44637:
    stxb [r6+0x9], r2                       
    stxb [r6+0x8], r7                       
    mov64 r0, r6                                    r0 = r6
    exit                                    

function_44641:
    mov64 r6, r1                                    r6 = r1
    ldxb r1, [r6+0x8]                       
    ldxb r2, [r6+0x9]                       
    jne r2, 0, lbb_44649                            if r2 != (0 as i32 as i64 as u64) { pc += 4 }
    mov64 r0, 1                                     r0 = 1 as i32 as i64 as u64
    jne r1, 0, lbb_44670                            if r1 != (0 as i32 as i64 as u64) { pc += 23 }
    mov64 r0, 0                                     r0 = 0 as i32 as i64 as u64
    ja lbb_44670                                    if true { pc += 21 }
lbb_44649:
    mov64 r0, 1                                     r0 = 1 as i32 as i64 as u64
    jne r1, 0, lbb_44669                            if r1 != (0 as i32 as i64 as u64) { pc += 18 }
    ldxdw r2, [r6+0x0]                      
    ldxw r1, [r2+0x34]                      
    and64 r1, 4                                     r1 &= 4   ///  r1 = r1.and(4)
    jne r1, 0, lbb_44662                            if r1 != (0 as i32 as i64 as u64) { pc += 7 }
    ldxdw r1, [r2+0x20]                     
    ldxdw r2, [r2+0x28]                     
    ldxdw r4, [r2+0x18]                     
    lddw r2, 0x100063d91 --> b" }"                  r2 load str located at 4295376273
    mov64 r3, 2                                     r3 = 2 as i32 as i64 as u64
    ja lbb_44668                                    if true { pc += 6 }
lbb_44662:
    ldxdw r1, [r2+0x20]                     
    ldxdw r2, [r2+0x28]                     
    ldxdw r4, [r2+0x18]                     
    lddw r2, 0x100063d90 --> b"}"                   r2 load str located at 4295376272
    mov64 r3, 1                                     r3 = 1 as i32 as i64 as u64
lbb_44668:
    callx r4                                
lbb_44669:
    stxb [r6+0x8], r0                       
lbb_44670:
    and64 r0, 1                                     r0 &= 1   ///  r0 = r0.and(1)
    exit                                    

function_44672:
    mov64 r4, r2                                    r4 = r2
    mov64 r6, r1                                    r6 = r1
    mov64 r8, 1                                     r8 = 1 as i32 as i64 as u64
    ldxdw r9, [r6+0x0]                      
    ldxb r1, [r6+0x10]                      
    jne r1, 0, lbb_44757                            if r1 != (0 as i32 as i64 as u64) { pc += 79 }
    ldxdw r7, [r6+0x8]                      
    ldxw r1, [r7+0x34]                      
    mov64 r2, r1                                    r2 = r1
    and64 r2, 4                                     r2 &= 4   ///  r2 = r2.and(4)
    stxdw [r10-0x68], r4                    
    stxdw [r10-0x70], r3                    
    jne r2, 0, lbb_44704                            if r2 != (0 as i32 as i64 as u64) { pc += 19 }
    lddw r2, 0x100063d93 --> b"((\x0a,\x0a]library/core/src/fmt/num.rs0x000102030405060"        r2 load str located at 4295376275
    jeq r9, 0, lbb_44690                            if r9 == (0 as i32 as i64 as u64) { pc += 2 }
    lddw r2, 0x100063d89 --> b","                   r2 load str located at 4295376265
lbb_44690:
    mov64 r3, 1                                     r3 = 1 as i32 as i64 as u64
    jeq r9, 0, lbb_44693                            if r9 == (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r3, 2                                     r3 = 2 as i32 as i64 as u64
lbb_44693:
    ldxdw r1, [r7+0x20]                     
    ldxdw r4, [r7+0x28]                     
    ldxdw r4, [r4+0x18]                     
    callx r4                                
    ldxdw r1, [r10-0x68]                    
    ldxdw r2, [r10-0x70]                    
    jne r0, 0, lbb_44757                            if r0 != (0 as i32 as i64 as u64) { pc += 57 }
    ldxdw r3, [r2+0x18]                     
    mov64 r2, r7                                    r2 = r7
    callx r3                                
    ja lbb_44756                                    if true { pc += 52 }
lbb_44704:
    jeq r9, 0, lbb_44706                            if r9 == (0 as i32 as i64 as u64) { pc += 1 }
    ja lbb_44715                                    if true { pc += 9 }
lbb_44706:
    ldxdw r1, [r7+0x20]                     
    ldxdw r2, [r7+0x28]                     
    ldxdw r4, [r2+0x18]                     
    lddw r2, 0x100063d94 --> b"(\x0a"               r2 load str located at 4295376276
    mov64 r3, 2                                     r3 = 2 as i32 as i64 as u64
    callx r4                                
    jne r0, 0, lbb_44757                            if r0 != (0 as i32 as i64 as u64) { pc += 43 }
    ldxw r1, [r7+0x34]                      
lbb_44715:
    stxb [r10-0x41], r8                     
    ldxdw r2, [r7+0x20]                     
    ldxdw r3, [r7+0x28]                     
    mov64 r4, r10                                   r4 = r10
    add64 r4, -65                                   r4 += -65   ///  r4 = r4.wrapping_add(-65 as i32 as i64 as u64)
    stxdw [r10-0x50], r4                    
    stxdw [r10-0x58], r3                    
    stxdw [r10-0x60], r2                    
    ldxdw r2, [r7+0x0]                      
    ldxdw r3, [r7+0x8]                      
    ldxdw r4, [r7+0x10]                     
    ldxdw r5, [r7+0x18]                     
    ldxw r0, [r7+0x30]                      
    ldxb r7, [r7+0x38]                      
    stxb [r10-0x8], r7                      
    stxw [r10-0x10], r0                     
    stxw [r10-0xc], r1                      
    lddw r1, 0x1000672e8 --> b"\x00\x00\x00\x000W\x05\x00\x18\x00\x00\x00\x00\x00\x00\x00\x08\x00\x00\x0…        r1 load str located at 4295389928
    stxdw [r10-0x18], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -96                                   r1 += -96   ///  r1 = r1.wrapping_add(-96 as i32 as i64 as u64)
    stxdw [r10-0x20], r1                    
    stxdw [r10-0x28], r5                    
    stxdw [r10-0x30], r4                    
    stxdw [r10-0x38], r3                    
    stxdw [r10-0x40], r2                    
    ldxdw r1, [r10-0x70]                    
    ldxdw r3, [r1+0x18]                     
    mov64 r2, r10                                   r2 = r10
    add64 r2, -64                                   r2 += -64   ///  r2 = r2.wrapping_add(-64 as i32 as i64 as u64)
    ldxdw r1, [r10-0x68]                    
    callx r3                                
    jne r0, 0, lbb_44757                            if r0 != (0 as i32 as i64 as u64) { pc += 8 }
    ldxdw r1, [r10-0x18]                    
    ldxdw r4, [r1+0x18]                     
    ldxdw r1, [r10-0x20]                    
    lddw r2, 0x100063d8e --> b",\x0a"               r2 load str located at 4295376270
    mov64 r3, 2                                     r3 = 2 as i32 as i64 as u64
    callx r4                                
lbb_44756:
    mov64 r8, r0                                    r8 = r0
lbb_44757:
    stxb [r6+0x10], r8                      
    add64 r9, 1                                     r9 += 1   ///  r9 = r9.wrapping_add(1 as i32 as i64 as u64)
    stxdw [r6+0x0], r9                      
    mov64 r0, r6                                    r0 = r6
    exit                                    

function_44762:
    mov64 r6, r1                                    r6 = r1
    ldxb r2, [r6+0x10]                      
    ldxdw r1, [r6+0x0]                      
    jne r1, 0, lbb_44771                            if r1 != (0 as i32 as i64 as u64) { pc += 5 }
    mov64 r1, r2                                    r1 = r2
    mov64 r7, 1                                     r7 = 1 as i32 as i64 as u64
    jne r1, 0, lbb_44799                            if r1 != (0 as i32 as i64 as u64) { pc += 30 }
    mov64 r7, 0                                     r7 = 0 as i32 as i64 as u64
    ja lbb_44799                                    if true { pc += 28 }
lbb_44771:
    mov64 r7, 1                                     r7 = 1 as i32 as i64 as u64
    jeq r2, 0, lbb_44774                            if r2 == (0 as i32 as i64 as u64) { pc += 1 }
    ja lbb_44798                                    if true { pc += 24 }
lbb_44774:
    ldxdw r8, [r6+0x8]                      
    jne r1, 1, lbb_44778                            if r1 != (1 as i32 as i64 as u64) { pc += 2 }
    ldxb r1, [r6+0x11]                      
    jne r1, 0, lbb_44787                            if r1 != (0 as i32 as i64 as u64) { pc += 9 }
lbb_44778:
    ldxdw r1, [r8+0x20]                     
    ldxdw r2, [r8+0x28]                     
    ldxdw r4, [r2+0x18]                     
    lddw r2, 0x100063d13 --> b")"                   r2 load str located at 4295376147
    mov64 r3, 1                                     r3 = 1 as i32 as i64 as u64
    callx r4                                
    mov64 r7, r0                                    r7 = r0
    ja lbb_44798                                    if true { pc += 11 }
lbb_44787:
    ldxw r1, [r8+0x34]                      
    and64 r1, 4                                     r1 &= 4   ///  r1 = r1.and(4)
    jne r1, 0, lbb_44778                            if r1 != (0 as i32 as i64 as u64) { pc += -12 }
    ldxdw r1, [r8+0x20]                     
    ldxdw r2, [r8+0x28]                     
    ldxdw r4, [r2+0x18]                     
    lddw r2, 0x100063d96 --> b","                   r2 load str located at 4295376278
    mov64 r3, 1                                     r3 = 1 as i32 as i64 as u64
    callx r4                                
    jeq r0, 0, lbb_44778                            if r0 == (0 as i32 as i64 as u64) { pc += -20 }
lbb_44798:
    stxb [r6+0x10], r7                      
lbb_44799:
    and64 r7, 1                                     r7 &= 1   ///  r7 = r7.and(1)
    mov64 r0, r7                                    r0 = r7
    exit                                    

function_44802:
    mov64 r8, r3                                    r8 = r3
    mov64 r6, r1                                    r6 = r1
    mov64 r3, 1                                     r3 = 1 as i32 as i64 as u64
    ldxb r1, [r6+0x8]                       
    mov64 r7, 1                                     r7 = 1 as i32 as i64 as u64
    jne r1, 0, lbb_44891                            if r1 != (0 as i32 as i64 as u64) { pc += 83 }
    ldxb r4, [r6+0x9]                       
    ldxdw r9, [r6+0x0]                      
    ldxw r1, [r9+0x34]                      
    mov64 r3, r1                                    r3 = r1
    and64 r3, 4                                     r3 &= 4   ///  r3 = r3.and(4)
    jne r3, 0, lbb_44835                            if r3 != (0 as i32 as i64 as u64) { pc += 21 }
    mov64 r1, r4                                    r1 = r4
    jeq r1, 0, lbb_44828                            if r1 == (0 as i32 as i64 as u64) { pc += 12 }
    ldxdw r1, [r9+0x20]                     
    ldxdw r3, [r9+0x28]                     
    mov64 r7, r2                                    r7 = r2
    ldxdw r4, [r3+0x18]                     
    lddw r2, 0x100063d89 --> b", "                  r2 load str located at 4295376265
    mov64 r3, 2                                     r3 = 2 as i32 as i64 as u64
    callx r4                                
    mov64 r2, r7                                    r2 = r7
    mov64 r3, 1                                     r3 = 1 as i32 as i64 as u64
    mov64 r7, 1                                     r7 = 1 as i32 as i64 as u64
    jne r0, 0, lbb_44891                            if r0 != (0 as i32 as i64 as u64) { pc += 63 }
lbb_44828:
    ldxdw r3, [r8+0x18]                     
    mov64 r1, r2                                    r1 = r2
    mov64 r2, r9                                    r2 = r9
    callx r3                                
    mov64 r3, 1                                     r3 = 1 as i32 as i64 as u64
    mov64 r7, r0                                    r7 = r0
    ja lbb_44891                                    if true { pc += 56 }
lbb_44835:
    stxdw [r10-0x68], r2                    
    mov64 r2, r4                                    r2 = r4
    jeq r2, 0, lbb_44839                            if r2 == (0 as i32 as i64 as u64) { pc += 1 }
    ja lbb_44849                                    if true { pc += 10 }
lbb_44839:
    ldxdw r1, [r9+0x20]                     
    ldxdw r2, [r9+0x28]                     
    ldxdw r4, [r2+0x18]                     
    lddw r2, 0x100063d97 --> b"\x0a"                r2 load str located at 4295376279
    mov64 r3, 1                                     r3 = 1 as i32 as i64 as u64
    callx r4                                
    mov64 r3, 1                                     r3 = 1 as i32 as i64 as u64
    jne r0, 0, lbb_44891                            if r0 != (0 as i32 as i64 as u64) { pc += 43 }
    ldxw r1, [r9+0x34]                      
lbb_44849:
    stxb [r10-0x41], r7                     
    ldxdw r2, [r9+0x20]                     
    ldxdw r3, [r9+0x28]                     
    mov64 r4, r10                                   r4 = r10
    add64 r4, -65                                   r4 += -65   ///  r4 = r4.wrapping_add(-65 as i32 as i64 as u64)
    stxdw [r10-0x50], r4                    
    stxdw [r10-0x58], r3                    
    stxdw [r10-0x60], r2                    
    ldxdw r2, [r9+0x0]                      
    ldxdw r3, [r9+0x8]                      
    ldxdw r4, [r9+0x10]                     
    ldxdw r5, [r9+0x18]                     
    ldxw r0, [r9+0x30]                      
    ldxb r9, [r9+0x38]                      
    stxb [r10-0x8], r9                      
    stxw [r10-0x10], r0                     
    stxw [r10-0xc], r1                      
    lddw r1, 0x1000672e8 --> b"\x00\x00\x00\x000W\x05\x00\x18\x00\x00\x00\x00\x00\x00\x00\x08\x00\x00\x0…        r1 load str located at 4295389928
    stxdw [r10-0x18], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -96                                   r1 += -96   ///  r1 = r1.wrapping_add(-96 as i32 as i64 as u64)
    stxdw [r10-0x20], r1                    
    stxdw [r10-0x28], r5                    
    stxdw [r10-0x30], r4                    
    stxdw [r10-0x38], r3                    
    stxdw [r10-0x40], r2                    
    ldxdw r3, [r8+0x18]                     
    mov64 r2, r10                                   r2 = r10
    add64 r2, -64                                   r2 += -64   ///  r2 = r2.wrapping_add(-64 as i32 as i64 as u64)
    ldxdw r1, [r10-0x68]                    
    callx r3                                
    jne r0, 0, lbb_44890                            if r0 != (0 as i32 as i64 as u64) { pc += 8 }
    ldxdw r1, [r10-0x18]                    
    ldxdw r4, [r1+0x18]                     
    ldxdw r1, [r10-0x20]                    
    lddw r2, 0x100063d8e --> b",\x0a"               r2 load str located at 4295376270
    mov64 r3, 2                                     r3 = 2 as i32 as i64 as u64
    callx r4                                
    mov64 r7, r0                                    r7 = r0
lbb_44890:
    mov64 r3, 1                                     r3 = 1 as i32 as i64 as u64
lbb_44891:
    stxb [r6+0x9], r3                       
    stxb [r6+0x8], r7                       
    mov64 r0, r6                                    r0 = r6
    exit                                    

function_44895:
    mov64 r0, 1                                     r0 = 1 as i32 as i64 as u64
    ldxb r2, [r1+0x8]                       
    jne r2, 0, lbb_44906                            if r2 != (0 as i32 as i64 as u64) { pc += 8 }
    ldxdw r2, [r1+0x0]                      
    ldxdw r1, [r2+0x20]                     
    ldxdw r2, [r2+0x28]                     
    ldxdw r4, [r2+0x18]                     
    lddw r2, 0x100063d98 --> b"]"                   r2 load str located at 4295376280
    mov64 r3, 1                                     r3 = 1 as i32 as i64 as u64
    callx r4                                
lbb_44906:
    exit                                    

function_44907:
    mov64 r9, r3                                    r9 = r3
    ldxdw r4, [r9+0x0]                      
    jgt r4, 19, lbb_44917                           if r4 > (19 as i32 as i64 as u64) { pc += 7 }
    lddw r1, 0x100063e7e --> b"assertion failed: *curr > 19"        r1 load str located at 4295376510
    mov64 r2, 28                                    r2 = 28 as i32 as i64 as u64
    lddw r3, 0x100067330 --> b"\x00\x00\x00\x00\x99=\x06\x00\x1b\x00\x00\x00\x00\x00\x00\x00\xec\x01\x00…        r3 load str located at 4295390000
    call function_44254                     
    syscall [invalid]                       
lbb_44917:
    lddw r5, 0x2386f26fc10000                       r5 load str located at 10000000000000000
    jgt r5, r1, lbb_45016                           if r5 > r1 { pc += 96 }
    mov64 r3, r1                                    r3 = r1
    div64 r3, r5                                    r3 /= r5   ///  r3 = r3 / r5
    mov64 r0, r3                                    r0 = r3
    mul64 r0, r5                                    r0 *= r5   ///  r0 = r0.wrapping_mul(r5)
    sub64 r1, r0                                    r1 -= r0   ///  r1 = r1.wrapping_sub(r0)
    mov64 r5, r4                                    r5 = r4
    add64 r5, -16                                   r5 += -16   ///  r5 = r5.wrapping_add(-16 as i32 as i64 as u64)
    stxdw [r10-0x8], r9                     
    stxdw [r9+0x0], r5                      
    lddw r0, 0x5af3107a4000                         r0 load str located at 100000000000000
    mov64 r7, r1                                    r7 = r1
    div64 r7, r0                                    r7 /= r0   ///  r7 = r7 / r0
    lsh64 r7, 1                                     r7 <<= 1   ///  r7 = r7.wrapping_shl(1)
    lddw r6, 0x100063db6 --> b"00010203040506070809101112131415161718192021222324"        r6 load str located at 4295376310
    lddw r0, 0x100063db6 --> b"00010203040506070809101112131415161718192021222324"        r0 load str located at 4295376310
    add64 r0, r7                                    r0 += r7   ///  r0 = r0.wrapping_add(r7)
    ldxh r0, [r0+0x0]                       
    mov64 r7, r2                                    r7 = r2
    stxdw [r10-0x10], r5                    
    add64 r7, r5                                    r7 += r5   ///  r7 = r7.wrapping_add(r5)
    stxh [r7+0x0], r0                       
    lddw r0, 0x2540be400                            r0 load str located at 10000000000
    mov64 r7, r1                                    r7 = r1
    div64 r7, r0                                    r7 /= r0   ///  r7 = r7 / r0
    mov64 r0, r7                                    r0 = r7
    div64 r0, 100                                   r0 /= 100   ///  r0 = r0 / (100 as u64)
    mul64 r0, 100                                   r0 *= 100   ///  r0 = r0.wrapping_mul(100 as u64)
    sub64 r7, r0                                    r7 -= r0   ///  r7 = r7.wrapping_sub(r0)
    mov64 r8, r1                                    r8 = r1
    div64 r8, 100000000                             r8 /= 100000000   ///  r8 = r8 / (100000000 as u64)
    lsh64 r8, 32                                    r8 <<= 32   ///  r8 = r8.wrapping_shl(32)
    rsh64 r8, 32                                    r8 >>= 32   ///  r8 = r8.wrapping_shr(32)
    mov64 r0, r8                                    r0 = r8
    div64 r0, 100                                   r0 /= 100   ///  r0 = r0 / (100 as u64)
    mul64 r0, 100                                   r0 *= 100   ///  r0 = r0.wrapping_mul(100 as u64)
    sub64 r8, r0                                    r8 -= r0   ///  r8 = r8.wrapping_sub(r0)
    lddw r0, 0xe8d4a51000                           r0 load str located at 1000000000000
    mov64 r9, r1                                    r9 = r1
    div64 r9, r0                                    r9 /= r0   ///  r9 = r9 / r0
    and64 r9, 65535                                 r9 &= 65535   ///  r9 = r9.and(65535)
    mov64 r0, r9                                    r0 = r9
    div64 r0, 100                                   r0 /= 100   ///  r0 = r0 / (100 as u64)
    mul64 r0, 100                                   r0 *= 100   ///  r0 = r0.wrapping_mul(100 as u64)
    sub64 r9, r0                                    r9 -= r0   ///  r9 = r9.wrapping_sub(r0)
    lsh64 r9, 1                                     r9 <<= 1   ///  r9 = r9.wrapping_shl(1)
    lsh64 r8, 1                                     r8 <<= 1   ///  r8 = r8.wrapping_shl(1)
    lddw r0, 0x100063db6 --> b"00010203040506070809101112131415161718192021222324"        r0 load str located at 4295376310
    add64 r0, r8                                    r0 += r8   ///  r0 = r0.wrapping_add(r8)
    lddw r8, 0x100063db6 --> b"00010203040506070809101112131415161718192021222324"        r8 load str located at 4295376310
    add64 r8, r9                                    r8 += r9   ///  r8 = r8.wrapping_add(r9)
    lsh64 r7, 1                                     r7 <<= 1   ///  r7 = r7.wrapping_shl(1)
    add64 r6, r7                                    r6 += r7   ///  r6 = r6.wrapping_add(r7)
    mov64 r7, r4                                    r7 = r4
    add64 r7, r2                                    r7 += r2   ///  r7 = r7.wrapping_add(r2)
    ldxh r6, [r6+0x0]                       
    stxh [r7-0xc], r6                       
    ldxh r6, [r8+0x0]                       
    stxh [r7-0xe], r6                       
    ldxh r0, [r0+0x0]                       
    stxh [r7-0xa], r0                       
    mov64 r7, r1                                    r7 = r1
    div64 r7, 1000000                               r7 /= 1000000   ///  r7 = r7 / (1000000 as u64)
    mov64 r0, r7                                    r0 = r7
    div64 r0, 100                                   r0 /= 100   ///  r0 = r0 / (100 as u64)
    mul64 r0, 100                                   r0 *= 100   ///  r0 = r0.wrapping_mul(100 as u64)
    sub64 r7, r0                                    r7 -= r0   ///  r7 = r7.wrapping_sub(r0)
    mov64 r6, r1                                    r6 = r1
    div64 r6, 10000                                 r6 /= 10000   ///  r6 = r6 / (10000 as u64)
    mov64 r0, r6                                    r0 = r6
    div64 r0, 100                                   r0 /= 100   ///  r0 = r0 / (100 as u64)
    mul64 r0, 100                                   r0 *= 100   ///  r0 = r0.wrapping_mul(100 as u64)
    sub64 r6, r0                                    r6 -= r0   ///  r6 = r6.wrapping_sub(r0)
    mov64 r0, r1                                    r0 = r1
    div64 r0, 100                                   r0 /= 100   ///  r0 = r0 / (100 as u64)
    mov64 r9, r0                                    r9 = r0
    div64 r9, 100                                   r9 /= 100   ///  r9 = r9 / (100 as u64)
    mul64 r9, 100                                   r9 *= 100   ///  r9 = r9.wrapping_mul(100 as u64)
    mov64 r8, r0                                    r8 = r0
    sub64 r8, r9                                    r8 -= r9   ///  r8 = r8.wrapping_sub(r9)
    mul64 r0, 100                                   r0 *= 100   ///  r0 = r0.wrapping_mul(100 as u64)
    sub64 r1, r0                                    r1 -= r0   ///  r1 = r1.wrapping_sub(r0)
    mov64 r9, r4                                    r9 = r4
    add64 r9, -8                                    r9 += -8   ///  r9 = r9.wrapping_add(-8 as i32 as i64 as u64)
    lsh64 r1, 1                                     r1 <<= 1   ///  r1 = r1.wrapping_shl(1)
    lsh64 r8, 1                                     r8 <<= 1   ///  r8 = r8.wrapping_shl(1)
    lsh64 r6, 1                                     r6 <<= 1   ///  r6 = r6.wrapping_shl(1)
    lsh64 r7, 1                                     r7 <<= 1   ///  r7 = r7.wrapping_shl(1)
    mov64 r0, r1                                    r0 = r1
    ja lbb_45054                                    if true { pc += 38 }
lbb_45016:
    mov64 r3, 100000000                             r3 = 100000000 as i32 as i64 as u64
    jgt r3, r1, lbb_45080                           if r3 > r1 { pc += 62 }
    stxdw [r10-0x8], r9                     
    mov64 r3, r1                                    r3 = r1
    div64 r3, 100000000                             r3 /= 100000000   ///  r3 = r3 / (100000000 as u64)
    mov64 r5, r3                                    r5 = r3
    mul64 r5, 100000000                             r5 *= 100000000   ///  r5 = r5.wrapping_mul(100000000 as u64)
    sub64 r1, r5                                    r1 -= r5   ///  r1 = r1.wrapping_sub(r5)
    mov64 r7, r1                                    r7 = r1
    lsh64 r7, 32                                    r7 <<= 32   ///  r7 = r7.wrapping_shl(32)
    rsh64 r7, 32                                    r7 >>= 32   ///  r7 = r7.wrapping_shr(32)
    mov64 r6, r7                                    r6 = r7
    div64 r6, 10000                                 r6 /= 10000   ///  r6 = r6 / (10000 as u64)
    and64 r6, 65535                                 r6 &= 65535   ///  r6 = r6.and(65535)
    mov64 r5, r6                                    r5 = r6
    div64 r5, 100                                   r5 /= 100   ///  r5 = r5 / (100 as u64)
    mul64 r5, 100                                   r5 *= 100   ///  r5 = r5.wrapping_mul(100 as u64)
    sub64 r6, r5                                    r6 -= r5   ///  r6 = r6.wrapping_sub(r5)
    mov64 r8, r7                                    r8 = r7
    div64 r8, 100                                   r8 /= 100   ///  r8 = r8 / (100 as u64)
    mov64 r5, r8                                    r5 = r8
    mul64 r5, 100                                   r5 *= 100   ///  r5 = r5.wrapping_mul(100 as u64)
    sub64 r1, r5                                    r1 -= r5   ///  r1 = r1.wrapping_sub(r5)
    mov64 r5, r8                                    r5 = r8
    div64 r5, 100                                   r5 /= 100   ///  r5 = r5 / (100 as u64)
    mul64 r5, 100                                   r5 *= 100   ///  r5 = r5.wrapping_mul(100 as u64)
    sub64 r8, r5                                    r8 -= r5   ///  r8 = r8.wrapping_sub(r5)
    mov64 r9, r4                                    r9 = r4
    add64 r9, -8                                    r9 += -8   ///  r9 = r9.wrapping_add(-8 as i32 as i64 as u64)
    div64 r7, 1000000                               r7 /= 1000000   ///  r7 = r7 / (1000000 as u64)
    lsh64 r7, 1                                     r7 <<= 1   ///  r7 = r7.wrapping_shl(1)
    lsh64 r8, 1                                     r8 <<= 1   ///  r8 = r8.wrapping_shl(1)
    lsh64 r1, 1                                     r1 <<= 1   ///  r1 = r1.wrapping_shl(1)
    lsh64 r1, 32                                    r1 <<= 32   ///  r1 = r1.wrapping_shl(32)
    rsh64 r1, 32                                    r1 >>= 32   ///  r1 = r1.wrapping_shr(32)
    lsh64 r6, 1                                     r6 <<= 1   ///  r6 = r6.wrapping_shl(1)
    mov64 r0, r1                                    r0 = r1
    stxdw [r10-0x10], r9                    
lbb_45054:
    mov64 r1, r3                                    r1 = r3
    mov64 r3, r2                                    r3 = r2
    add64 r3, r9                                    r3 += r9   ///  r3 = r3.wrapping_add(r9)
    lddw r9, 0x100063db6 --> b"00010203040506070809101112131415161718192021222324"        r9 load str located at 4295376310
    lddw r5, 0x100063db6 --> b"00010203040506070809101112131415161718192021222324"        r5 load str located at 4295376310
    add64 r5, r7                                    r5 += r7   ///  r5 = r5.wrapping_add(r7)
    ldxh r5, [r5+0x0]                       
    stxh [r3+0x0], r5                       
    add64 r4, r2                                    r4 += r2   ///  r4 = r4.wrapping_add(r2)
    lddw r3, 0x100063db6 --> b"00010203040506070809101112131415161718192021222324"        r3 load str located at 4295376310
    add64 r3, r0                                    r3 += r0   ///  r3 = r3.wrapping_add(r0)
    ldxh r3, [r3+0x0]                       
    stxh [r4-0x2], r3                       
    lddw r3, 0x100063db6 --> b"00010203040506070809101112131415161718192021222324"        r3 load str located at 4295376310
    add64 r3, r8                                    r3 += r8   ///  r3 = r3.wrapping_add(r8)
    ldxh r3, [r3+0x0]                       
    stxh [r4-0x4], r3                       
    add64 r9, r6                                    r9 += r6   ///  r9 = r9.wrapping_add(r6)
    ldxh r3, [r9+0x0]                       
    stxh [r4-0x6], r3                       
    ldxdw r4, [r10-0x10]                    
    ldxdw r9, [r10-0x8]                     
lbb_45080:
    mov64 r5, r1                                    r5 = r1
    lsh64 r5, 32                                    r5 <<= 32   ///  r5 = r5.wrapping_shl(32)
    rsh64 r5, 32                                    r5 >>= 32   ///  r5 = r5.wrapping_shr(32)
    mov64 r3, 10000                                 r3 = 10000 as i32 as i64 as u64
    jgt r3, r5, lbb_45115                           if r3 > r5 { pc += 30 }
    div64 r5, 10000                                 r5 /= 10000   ///  r5 = r5 / (10000 as u64)
    mov64 r3, r5                                    r3 = r5
    mul64 r3, 10000                                 r3 *= 10000   ///  r3 = r3.wrapping_mul(10000 as u64)
    sub64 r1, r3                                    r1 -= r3   ///  r1 = r1.wrapping_sub(r3)
    mov64 r0, r1                                    r0 = r1
    and64 r0, 65535                                 r0 &= 65535   ///  r0 = r0.and(65535)
    div64 r0, 100                                   r0 /= 100   ///  r0 = r0 / (100 as u64)
    lddw r3, 0x100063db6 --> b"00010203040506070809101112131415161718192021222324"        r3 load str located at 4295376310
    mov64 r6, r0                                    r6 = r0
    lsh64 r6, 1                                     r6 <<= 1   ///  r6 = r6.wrapping_shl(1)
    lddw r7, 0x100063db6 --> b"00010203040506070809101112131415161718192021222324"        r7 load str located at 4295376310
    add64 r7, r6                                    r7 += r6   ///  r7 = r7.wrapping_add(r6)
    ldxh r6, [r7+0x0]                       
    mov64 r7, r4                                    r7 = r4
    add64 r7, -4                                    r7 += -4   ///  r7 = r7.wrapping_add(-4 as i32 as i64 as u64)
    mov64 r8, r2                                    r8 = r2
    add64 r8, r7                                    r8 += r7   ///  r8 = r8.wrapping_add(r7)
    stxh [r8+0x0], r6                       
    add64 r4, r2                                    r4 += r2   ///  r4 = r4.wrapping_add(r2)
    mul64 r0, 100                                   r0 *= 100   ///  r0 = r0.wrapping_mul(100 as u64)
    sub64 r1, r0                                    r1 -= r0   ///  r1 = r1.wrapping_sub(r0)
    lsh64 r1, 1                                     r1 <<= 1   ///  r1 = r1.wrapping_shl(1)
    and64 r1, 65534                                 r1 &= 65534   ///  r1 = r1.and(65534)
    add64 r3, r1                                    r3 += r1   ///  r3 = r3.wrapping_add(r1)
    ldxh r1, [r3+0x0]                       
    stxh [r4-0x2], r1                       
    mov64 r4, r7                                    r4 = r7
    mov64 r1, r5                                    r1 = r5
lbb_45115:
    mov64 r5, r1                                    r5 = r1
    and64 r5, 65535                                 r5 &= 65535   ///  r5 = r5.and(65535)
    mov64 r3, 100                                   r3 = 100 as i32 as i64 as u64
    jgt r3, r5, lbb_45134                           if r3 > r5 { pc += 15 }
    div64 r5, 100                                   r5 /= 100   ///  r5 = r5 / (100 as u64)
    mov64 r3, r5                                    r3 = r5
    mul64 r3, 100                                   r3 *= 100   ///  r3 = r3.wrapping_mul(100 as u64)
    sub64 r1, r3                                    r1 -= r3   ///  r1 = r1.wrapping_sub(r3)
    lsh64 r1, 1                                     r1 <<= 1   ///  r1 = r1.wrapping_shl(1)
    and64 r1, 65534                                 r1 &= 65534   ///  r1 = r1.and(65534)
    lddw r3, 0x100063db6 --> b"00010203040506070809101112131415161718192021222324"        r3 load str located at 4295376310
    add64 r3, r1                                    r3 += r1   ///  r3 = r3.wrapping_add(r1)
    add64 r4, -2                                    r4 += -2   ///  r4 = r4.wrapping_add(-2 as i32 as i64 as u64)
    mov64 r1, r2                                    r1 = r2
    add64 r1, r4                                    r1 += r4   ///  r1 = r1.wrapping_add(r4)
    ldxh r3, [r3+0x0]                       
    stxh [r1+0x0], r3                       
    mov64 r1, r5                                    r1 = r5
lbb_45134:
    mov64 r3, r1                                    r3 = r1
    and64 r3, 65535                                 r3 &= 65535   ///  r3 = r3.and(65535)
    mov64 r5, 10                                    r5 = 10 as i32 as i64 as u64
    jgt r5, r3, lbb_45148                           if r5 > r3 { pc += 10 }
    lsh64 r1, 1                                     r1 <<= 1   ///  r1 = r1.wrapping_shl(1)
    and64 r1, 65534                                 r1 &= 65534   ///  r1 = r1.and(65534)
    lddw r3, 0x100063db6 --> b"00010203040506070809101112131415161718192021222324"        r3 load str located at 4295376310
    add64 r3, r1                                    r3 += r1   ///  r3 = r3.wrapping_add(r1)
    add64 r4, -2                                    r4 += -2   ///  r4 = r4.wrapping_add(-2 as i32 as i64 as u64)
    add64 r2, r4                                    r2 += r4   ///  r2 = r2.wrapping_add(r4)
    ldxh r1, [r3+0x0]                       
    stxh [r2+0x0], r1                       
    ja lbb_45152                                    if true { pc += 4 }
lbb_45148:
    add64 r4, -1                                    r4 += -1   ///  r4 = r4.wrapping_add(-1 as i32 as i64 as u64)
    add64 r2, r4                                    r2 += r4   ///  r2 = r2.wrapping_add(r4)
    add64 r1, 48                                    r1 += 48   ///  r1 = r1.wrapping_add(48 as i32 as i64 as u64)
    stxb [r2+0x0], r1                       
lbb_45152:
    stxdw [r9+0x0], r4                      
    exit                                    

function_45154:
    mov64 r4, r2                                    r4 = r2
    ldxdw r5, [r1+0x8]                      
    ldxdw r2, [r1+0x0]                      
    mov64 r1, r2                                    r1 = r2
    neg64 r1                                        r1 = -r1   ///  r1 = (r1 as i64).wrapping_neg() as u64
    mov64 r0, 0                                     r0 = 0 as i32 as i64 as u64
    jsgt r0, r5, lbb_45162                          if (r0 as i64) > (r5 as i64) { pc += 1 }
    mov64 r1, r2                                    r1 = r2
lbb_45162:
    mov64 r3, 1                                     r3 = 1 as i32 as i64 as u64
    mov64 r6, 1                                     r6 = 1 as i32 as i64 as u64
    jne r2, 0, lbb_45166                            if r2 != (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r6, 0                                     r6 = 0 as i32 as i64 as u64
lbb_45166:
    jsgt r5, -1, lbb_45168                          if (r5 as i64) > (-1 as i32 as i64) { pc += 1 }
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
lbb_45168:
    mov64 r2, r5                                    r2 = r5
    add64 r2, r6                                    r2 += r6   ///  r2 = r2.wrapping_add(r6)
    neg64 r2                                        r2 = -r2   ///  r2 = (r2 as i64).wrapping_neg() as u64
    jsgt r0, r5, lbb_45173                          if (r0 as i64) > (r5 as i64) { pc += 1 }
    mov64 r2, r5                                    r2 = r5
lbb_45173:
    call function_45175                     
    exit                                    

function_45175:
    stxdw [r10-0x98], r4                    
    stxdw [r10-0xa0], r3                    
    mov64 r6, r2                                    r6 = r2
    mov64 r8, r1                                    r8 = r1
    mov64 r1, 39                                    r1 = 39 as i32 as i64 as u64
    stxdw [r10-0x8], r1                     
    mov64 r1, 524288                                r1 = 524288 as i32 as i64 as u64
    jgt r1, r6, lbb_45252                           if r1 > r6 { pc += 69 }
    mov64 r1, r10                                   r1 = r10
    add64 r1, -96                                   r1 += -96   ///  r1 = r1.wrapping_add(-96 as i32 as i64 as u64)
    mov64 r2, r8                                    r2 = r8
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
    lddw r4, 0x9598f4f1e8361973                     r4 load str located at -7667109045778114189
    mov64 r5, 0                                     r5 = 0 as i32 as i64 as u64
    call function_48384                     
    mov64 r1, r10                                   r1 = r10
    add64 r1, -112                                  r1 += -112   ///  r1 = r1.wrapping_add(-112 as i32 as i64 as u64)
    mov64 r2, r8                                    r2 = r8
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
    lddw r4, 0x760f253edb4ab0d2                     r4 load str located at 8507059173023461586
    mov64 r5, 0                                     r5 = 0 as i32 as i64 as u64
    call function_48384                     
    mov64 r1, r10                                   r1 = r10
    add64 r1, -64                                   r1 += -64   ///  r1 = r1.wrapping_add(-64 as i32 as i64 as u64)
    mov64 r2, r6                                    r2 = r6
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
    lddw r4, 0x9598f4f1e8361973                     r4 load str located at -7667109045778114189
    mov64 r5, 0                                     r5 = 0 as i32 as i64 as u64
    call function_48384                     
    mov64 r1, r10                                   r1 = r10
    add64 r1, -80                                   r1 += -80   ///  r1 = r1.wrapping_add(-80 as i32 as i64 as u64)
    mov64 r2, r6                                    r2 = r6
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
    lddw r4, 0x760f253edb4ab0d2                     r4 load str located at 8507059173023461586
    mov64 r5, 0                                     r5 = 0 as i32 as i64 as u64
    call function_48384                     
    ldxdw r1, [r10-0x70]                    
    ldxdw r3, [r10-0x58]                    
    mov64 r4, r3                                    r4 = r3
    add64 r4, r1                                    r4 += r1   ///  r4 = r4.wrapping_add(r1)
    ldxdw r1, [r10-0x40]                    
    mov64 r2, r4                                    r2 = r4
    add64 r2, r1                                    r2 += r1   ///  r2 = r2.wrapping_add(r1)
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    mov64 r5, 1                                     r5 = 1 as i32 as i64 as u64
    jgt r4, r2, lbb_45226                           if r4 > r2 { pc += 1 }
    mov64 r5, 0                                     r5 = 0 as i32 as i64 as u64
lbb_45226:
    ldxdw r2, [r10-0x38]                    
    mov64 r0, 1                                     r0 = 1 as i32 as i64 as u64
    jgt r3, r4, lbb_45230                           if r3 > r4 { pc += 1 }
    mov64 r0, 0                                     r0 = 0 as i32 as i64 as u64
lbb_45230:
    add64 r2, r5                                    r2 += r5   ///  r2 = r2.wrapping_add(r5)
    ldxdw r5, [r10-0x68]                    
    add64 r5, r0                                    r5 += r0   ///  r5 = r5.wrapping_add(r0)
    ldxdw r3, [r10-0x50]                    
    mov64 r4, r5                                    r4 = r5
    add64 r4, r3                                    r4 += r3   ///  r4 = r4.wrapping_add(r3)
    mov64 r3, 1                                     r3 = 1 as i32 as i64 as u64
    jgt r5, r4, lbb_45239                           if r5 > r4 { pc += 1 }
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
lbb_45239:
    mov64 r9, r4                                    r9 = r4
    add64 r9, r2                                    r9 += r2   ///  r9 = r9.wrapping_add(r2)
    jgt r4, r9, lbb_45243                           if r4 > r9 { pc += 1 }
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
lbb_45243:
    ldxdw r6, [r10-0x48]                    
    add64 r6, r3                                    r6 += r3   ///  r6 = r6.wrapping_add(r3)
    add64 r6, r1                                    r6 += r1   ///  r6 = r6.wrapping_add(r1)
    rsh64 r9, 62                                    r9 >>= 62   ///  r9 = r9.wrapping_shr(62)
    mov64 r1, r6                                    r1 = r6
    lsh64 r1, 2                                     r1 <<= 2   ///  r1 = r1.wrapping_shl(2)
    or64 r9, r1                                     r9 |= r1   ///  r9 = r9.or(r1)
    rsh64 r6, 62                                    r6 >>= 62   ///  r6 = r6.wrapping_shr(62)
    ja lbb_45260                                    if true { pc += 8 }
lbb_45252:
    mov64 r9, r8                                    r9 = r8
    rsh64 r9, 19                                    r9 >>= 19   ///  r9 = r9.wrapping_shr(19)
    lsh64 r6, 45                                    r6 <<= 45   ///  r6 = r6.wrapping_shl(45)
    or64 r9, r6                                     r9 |= r6   ///  r9 = r9.or(r6)
    lddw r1, 0x1158e460913d                         r1 load str located at 19073486328125
    div64 r9, r1                                    r9 /= r1   ///  r9 = r9 / r1
    mov64 r6, 0                                     r6 = 0 as i32 as i64 as u64
lbb_45260:
    mov64 r1, r10                                   r1 = r10
    add64 r1, -128                                  r1 += -128   ///  r1 = r1.wrapping_add(-128 as i32 as i64 as u64)
    mov64 r2, r9                                    r2 = r9
    mov64 r3, r6                                    r3 = r6
    lddw r4, 0x7538dcfb76180000                     r4 load str located at 8446744073709551616
    mov64 r5, 0                                     r5 = 0 as i32 as i64 as u64
    call function_48384                     
    ldxdw r1, [r10-0x80]                    
    add64 r1, r8                                    r1 += r8   ///  r1 = r1.wrapping_add(r8)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -47                                   r2 += -47   ///  r2 = r2.wrapping_add(-47 as i32 as i64 as u64)
    mov64 r3, r10                                   r3 = r10
    add64 r3, -8                                    r3 += -8   ///  r3 = r3.wrapping_add(-8 as i32 as i64 as u64)
    call function_44907                     
    mov64 r1, r9                                    r1 = r9
    or64 r1, r6                                     r1 |= r6   ///  r1 = r1.or(r6)
    ldxdw r3, [r10-0x8]                     
    jne r1, 0, lbb_45294                            if r1 != (0 as i32 as i64 as u64) { pc += 15 }
lbb_45279:
    mov64 r1, r10                                   r1 = r10
    add64 r1, -47                                   r1 += -47   ///  r1 = r1.wrapping_add(-47 as i32 as i64 as u64)
    add64 r1, r3                                    r1 += r3   ///  r1 = r1.wrapping_add(r3)
    stxdw [r10-0x1000], r1                  
    mov64 r1, 39                                    r1 = 39 as i32 as i64 as u64
    sub64 r1, r3                                    r1 -= r3   ///  r1 = r1.wrapping_sub(r3)
    stxdw [r10-0xff8], r1                   
    mov64 r5, r10                                   r5 = r10
    ldxdw r1, [r10-0x98]                    
    ldxdw r2, [r10-0xa0]                    
    lddw r3, 0x100063ce8 --> b"called `Option::unwrap()` on a `None` value)invali"        r3 load str located at 4295376104
    mov64 r4, 0                                     r4 = 0 as i32 as i64 as u64
    call function_45507                     
    exit                                    
lbb_45294:
    add64 r3, -20                                   r3 += -20   ///  r3 = r3.wrapping_add(-20 as i32 as i64 as u64)
    mov64 r1, r10                                   r1 = r10
    add64 r1, -27                                   r1 += -27   ///  r1 = r1.wrapping_add(-27 as i32 as i64 as u64)
    mov64 r2, 48                                    r2 = 48 as i32 as i64 as u64
    call function_48291                     
    lsh64 r6, 45                                    r6 <<= 45   ///  r6 = r6.wrapping_shl(45)
    mov64 r8, r9                                    r8 = r9
    rsh64 r8, 19                                    r8 >>= 19   ///  r8 = r8.wrapping_shr(19)
    or64 r8, r6                                     r8 |= r6   ///  r8 = r8.or(r6)
    mov64 r1, 20                                    r1 = 20 as i32 as i64 as u64
    stxdw [r10-0x8], r1                     
    lddw r7, 0x1158e460913d                         r7 load str located at 19073486328125
    mov64 r6, r8                                    r6 = r8
    div64 r6, r7                                    r6 /= r7   ///  r6 = r6 / r7
    mov64 r1, r10                                   r1 = r10
    add64 r1, -144                                  r1 += -144   ///  r1 = r1.wrapping_add(-144 as i32 as i64 as u64)
    mov64 r2, r6                                    r2 = r6
    lddw r4, 0x7538dcfb76180000                     r4 load str located at 8446744073709551616
    mov64 r5, 0                                     r5 = 0 as i32 as i64 as u64
    call function_48384                     
    ldxdw r1, [r10-0x90]                    
    add64 r1, r9                                    r1 += r9   ///  r1 = r1.wrapping_add(r9)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -47                                   r2 += -47   ///  r2 = r2.wrapping_add(-47 as i32 as i64 as u64)
    mov64 r3, r10                                   r3 = r10
    add64 r3, -8                                    r3 += -8   ///  r3 = r3.wrapping_add(-8 as i32 as i64 as u64)
    call function_44907                     
    ldxdw r3, [r10-0x8]                     
    jgt r7, r8, lbb_45279                           if r7 > r8 { pc += -46 }
    add64 r3, -1                                    r3 += -1   ///  r3 = r3.wrapping_add(-1 as i32 as i64 as u64)
    mov64 r1, r10                                   r1 = r10
    add64 r1, -46                                   r1 += -46   ///  r1 = r1.wrapping_add(-46 as i32 as i64 as u64)
    mov64 r2, 48                                    r2 = 48 as i32 as i64 as u64
    call function_48291                     
    or64 r6, 48                                     r6 |= 48   ///  r6 = r6.or(48)
    stxb [r10-0x2f], r6                     
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
    ja lbb_45279                                    if true { pc += -55 }

function_45334:
    mov64 r3, r2                                    r3 = r2
    lddw r2, 0x1000672e8 --> b"\x00\x00\x00\x000W\x05\x00\x18\x00\x00\x00\x00\x00\x00\x00\x08\x00\x00\x0…        r2 load str located at 4295389928
    call function_45367                     
    exit                                    

function_45339:
    mov64 r0, r5                                    r0 = r5
    add64 r0, 1                                     r0 += 1   ///  r0 = r0.wrapping_add(1 as i32 as i64 as u64)
    jgt r3, r0, lbb_45350                           if r3 > r0 { pc += 8 }
    jgt r5, r3, lbb_45350                           if r5 > r3 { pc += 7 }
    mov64 r0, 0                                     r0 = 0 as i32 as i64 as u64
    stxdw [r1+0x20], r0                     
    stxdw [r1+0x8], r3                      
    stxdw [r1+0x0], r2                      
    stxdw [r1+0x18], r5                     
    stxdw [r1+0x10], r4                     
    exit                                    
lbb_45350:
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    stxdw [r10-0x28], r1                    
    lddw r1, 0x100067218 --> b"\x00\x00\x00\x00\x14=\x06\x00\x0c\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00…        r1 load str located at 4295389720
    stxdw [r10-0x30], r1                    
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    stxdw [r10-0x10], r1                    
    stxdw [r10-0x18], r1                    
    lddw r1, 0x100063ce8 --> b"called `Option::unwrap()` on a `None` value)invali"        r1 load str located at 4295376104
    stxdw [r10-0x20], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -48                                   r1 += -48   ///  r1 = r1.wrapping_add(-48 as i32 as i64 as u64)
    lddw r2, 0x100067348 --> b"\x00\x00\x00\x00 =\x06\x00\x1b\x00\x00\x00\x00\x00\x00\x00M\x01\x00\x00\x…        r2 load str located at 4295390024
    call function_44240                     
    syscall [invalid]                       

function_45367:
    mov64 r4, 3                                     r4 = 3 as i32 as i64 as u64
    stxb [r10-0x8], r4                      
    mov64 r4, 32                                    r4 = 32 as i32 as i64 as u64
    stxdw [r10-0x10], r4                    
    stxdw [r10-0x18], r2                    
    stxdw [r10-0x20], r1                    
    mov64 r7, 0                                     r7 = 0 as i32 as i64 as u64
    stxdw [r10-0x30], r7                    
    stxdw [r10-0x40], r7                    
    ldxdw r8, [r3+0x20]                     
    stxdw [r10-0x50], r3                    
    jne r8, 0, lbb_45408                            if r8 != (0 as i32 as i64 as u64) { pc += 29 }
    ldxdw r1, [r3+0x18]                     
    jeq r1, 0, lbb_45488                            if r1 == (0 as i32 as i64 as u64) { pc += 107 }
    ldxdw r2, [r10-0x50]                    
    ldxdw r6, [r2+0x10]                     
    lsh64 r1, 4                                     r1 <<= 4   ///  r1 = r1.wrapping_shl(4)
    mov64 r8, r6                                    r8 = r6
    add64 r8, r1                                    r8 += r1   ///  r8 = r8.wrapping_add(r1)
    ldxdw r9, [r2+0x0]                      
    add64 r9, 8                                     r9 += 8   ///  r9 = r9.wrapping_add(8 as i32 as i64 as u64)
    ja lbb_45405                                    if true { pc += 16 }
lbb_45389:
    ldxdw r1, [r10-0x18]                    
    ldxdw r4, [r1+0x18]                     
    ldxdw r2, [r9-0x8]                      
    ldxdw r1, [r10-0x20]                    
    callx r4                                
    jne r0, 0, lbb_45505                            if r0 != (0 as i32 as i64 as u64) { pc += 110 }
lbb_45395:
    ldxdw r3, [r6+0x8]                      
    ldxdw r1, [r6+0x0]                      
    mov64 r2, r10                                   r2 = r10
    add64 r2, -64                                   r2 += -64   ///  r2 = r2.wrapping_add(-64 as i32 as i64 as u64)
    callx r3                                
    jne r0, 0, lbb_45505                            if r0 != (0 as i32 as i64 as u64) { pc += 104 }
    add64 r7, 1                                     r7 += 1   ///  r7 = r7.wrapping_add(1 as i32 as i64 as u64)
    add64 r9, 16                                    r9 += 16   ///  r9 = r9.wrapping_add(16 as i32 as i64 as u64)
    add64 r6, 16                                    r6 += 16   ///  r6 = r6.wrapping_add(16 as i32 as i64 as u64)
    jeq r6, r8, lbb_45488                           if r6 == r8 { pc += 83 }
lbb_45405:
    ldxdw r3, [r9+0x0]                      
    jeq r3, 0, lbb_45395                            if r3 == (0 as i32 as i64 as u64) { pc += -12 }
    ja lbb_45389                                    if true { pc += -19 }
lbb_45408:
    ldxdw r9, [r3+0x28]                     
    jeq r9, 0, lbb_45488                            if r9 == (0 as i32 as i64 as u64) { pc += 78 }
    add64 r8, 24                                    r8 += 24   ///  r8 = r8.wrapping_add(24 as i32 as i64 as u64)
    mul64 r9, 56                                    r9 *= 56   ///  r9 = r9.wrapping_mul(56 as u64)
    ldxdw r1, [r10-0x50]                    
    ldxdw r2, [r1+0x10]                     
    stxdw [r10-0x48], r2                    
    ldxdw r6, [r1+0x0]                      
    add64 r6, 8                                     r6 += 8   ///  r6 = r6.wrapping_add(8 as i32 as i64 as u64)
    ja lbb_45435                                    if true { pc += 17 }
lbb_45418:
    stxdw [r10-0x28], r1                    
    stxdw [r10-0x30], r2                    
    ldxdw r1, [r8+0x8]                      
    lsh64 r1, 4                                     r1 <<= 4   ///  r1 = r1.wrapping_shl(4)
    ldxdw r2, [r10-0x48]                    
    add64 r2, r1                                    r2 += r1   ///  r2 = r2.wrapping_add(r1)
    ldxdw r3, [r2+0x8]                      
    ldxdw r1, [r2+0x0]                      
    mov64 r2, r10                                   r2 = r10
    add64 r2, -64                                   r2 += -64   ///  r2 = r2.wrapping_add(-64 as i32 as i64 as u64)
    callx r3                                
    jne r0, 0, lbb_45505                            if r0 != (0 as i32 as i64 as u64) { pc += 75 }
    add64 r7, 1                                     r7 += 1   ///  r7 = r7.wrapping_add(1 as i32 as i64 as u64)
    add64 r8, 56                                    r8 += 56   ///  r8 = r8.wrapping_add(56 as i32 as i64 as u64)
    add64 r6, 16                                    r6 += 16   ///  r6 = r6.wrapping_add(16 as i32 as i64 as u64)
    add64 r9, -56                                   r9 += -56   ///  r9 = r9.wrapping_add(-56 as i32 as i64 as u64)
    jeq r9, 0, lbb_45488                            if r9 == (0 as i32 as i64 as u64) { pc += 53 }
lbb_45435:
    ldxdw r3, [r6+0x0]                      
    jeq r3, 0, lbb_45443                            if r3 == (0 as i32 as i64 as u64) { pc += 6 }
    ldxdw r1, [r10-0x18]                    
    ldxdw r4, [r1+0x18]                     
    ldxdw r2, [r6-0x8]                      
    ldxdw r1, [r10-0x20]                    
    callx r4                                
    jne r0, 0, lbb_45505                            if r0 != (0 as i32 as i64 as u64) { pc += 62 }
lbb_45443:
    ldxw r1, [r8+0x10]                      
    stxw [r10-0x10], r1                     
    ldxb r1, [r8+0x18]                      
    stxb [r10-0x8], r1                      
    ldxw r1, [r8+0x14]                      
    stxw [r10-0xc], r1                      
    ldxdw r1, [r8+0x0]                      
    ldxdw r3, [r8-0x8]                      
    jeq r3, 0, lbb_45455                            if r3 == (0 as i32 as i64 as u64) { pc += 3 }
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
    jeq r3, 1, lbb_45457                            if r3 == (1 as i32 as i64 as u64) { pc += 3 }
    ja lbb_45467                                    if true { pc += 12 }
lbb_45455:
    mov64 r2, 1                                     r2 = 1 as i32 as i64 as u64
    ja lbb_45467                                    if true { pc += 10 }
lbb_45457:
    lsh64 r1, 4                                     r1 <<= 4   ///  r1 = r1.wrapping_shl(4)
    ldxdw r3, [r10-0x48]                    
    add64 r3, r1                                    r3 += r1   ///  r3 = r3.wrapping_add(r1)
    ldxdw r4, [r3+0x8]                      
    lddw r5, 0x100055720 --> b"y\x11\x00\x00\x00\x00\x00\x00\x05\x00\xff\xff\x00\x00\x00\x00\x95\x00\x00…        r5 load str located at 4295317280
    jne r4, r5, lbb_45467                           if r4 != r5 { pc += 3 }
    mov64 r2, 1                                     r2 = 1 as i32 as i64 as u64
    ldxdw r1, [r3+0x0]                      
    ldxdw r1, [r1+0x0]                      
lbb_45467:
    stxdw [r10-0x38], r1                    
    stxdw [r10-0x40], r2                    
    ldxdw r1, [r8-0x10]                     
    ldxdw r3, [r8-0x18]                     
    jeq r3, 0, lbb_45475                            if r3 == (0 as i32 as i64 as u64) { pc += 3 }
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
    jeq r3, 1, lbb_45477                            if r3 == (1 as i32 as i64 as u64) { pc += 3 }
    ja lbb_45418                                    if true { pc += -57 }
lbb_45475:
    mov64 r2, 1                                     r2 = 1 as i32 as i64 as u64
    ja lbb_45418                                    if true { pc += -59 }
lbb_45477:
    lsh64 r1, 4                                     r1 <<= 4   ///  r1 = r1.wrapping_shl(4)
    ldxdw r3, [r10-0x48]                    
    add64 r3, r1                                    r3 += r1   ///  r3 = r3.wrapping_add(r1)
    ldxdw r4, [r3+0x8]                      
    lddw r5, 0x100055720 --> b"y\x11\x00\x00\x00\x00\x00\x00\x05\x00\xff\xff\x00\x00\x00\x00\x95\x00\x00…        r5 load str located at 4295317280
    jne r4, r5, lbb_45418                           if r4 != r5 { pc += -66 }
    mov64 r2, 1                                     r2 = 1 as i32 as i64 as u64
    ldxdw r1, [r3+0x0]                      
    ldxdw r1, [r1+0x0]                      
    ja lbb_45418                                    if true { pc += -70 }
lbb_45488:
    ldxdw r1, [r10-0x50]                    
    ldxdw r1, [r1+0x8]                      
    jgt r1, r7, lbb_45492                           if r1 > r7 { pc += 1 }
    ja lbb_45503                                    if true { pc += 11 }
lbb_45492:
    lsh64 r7, 4                                     r7 <<= 4   ///  r7 = r7.wrapping_shl(4)
    ldxdw r1, [r10-0x50]                    
    ldxdw r1, [r1+0x0]                      
    add64 r1, r7                                    r1 += r7   ///  r1 = r1.wrapping_add(r7)
    ldxdw r3, [r1+0x8]                      
    ldxdw r2, [r1+0x0]                      
    ldxdw r1, [r10-0x18]                    
    ldxdw r4, [r1+0x18]                     
    ldxdw r1, [r10-0x20]                    
    callx r4                                
    jne r0, 0, lbb_45505                            if r0 != (0 as i32 as i64 as u64) { pc += 2 }
lbb_45503:
    mov64 r0, 0                                     r0 = 0 as i32 as i64 as u64
    ja lbb_45506                                    if true { pc += 1 }
lbb_45505:
    mov64 r0, 1                                     r0 = 1 as i32 as i64 as u64
lbb_45506:
    exit                                    

function_45507:
    mov64 r0, r4                                    r0 = r4
    mov64 r8, r1                                    r8 = r1
    ldxdw r9, [r5-0xff8]                    
    stxdw [r10-0x20], r9                    
    jne r2, 0, lbb_45517                            if r2 != (0 as i32 as i64 as u64) { pc += 5 }
    mov64 r1, 45                                    r1 = 45 as i32 as i64 as u64
    stxdw [r10-0x18], r1                    
    ldxw r7, [r8+0x34]                      
    add64 r9, 1                                     r9 += 1   ///  r9 = r9.wrapping_add(1 as i32 as i64 as u64)
    ja lbb_45523                                    if true { pc += 6 }
lbb_45517:
    mov64 r1, 1114112                               r1 = 1114112 as i32 as i64 as u64
    stxdw [r10-0x18], r1                    
    ldxw r7, [r8+0x34]                      
    mov64 r1, r7                                    r1 = r7
    and64 r1, 1                                     r1 &= 1   ///  r1 = r1.and(1)
    jne r1, 0, lbb_45583                            if r1 != (0 as i32 as i64 as u64) { pc += 60 }
lbb_45523:
    ldxdw r1, [r5-0x1000]                   
    stxdw [r10-0x28], r1                    
    mov64 r4, 0                                     r4 = 0 as i32 as i64 as u64
    mov64 r1, r7                                    r1 = r7
    and64 r1, 4                                     r1 &= 4   ///  r1 = r1.and(4)
    jeq r1, 0, lbb_45530                            if r1 == (0 as i32 as i64 as u64) { pc += 1 }
    ja lbb_45557                                    if true { pc += 27 }
lbb_45530:
    ldxdw r1, [r8+0x0]                      
    jne r1, 0, lbb_45542                            if r1 != (0 as i32 as i64 as u64) { pc += 10 }
    ldxdw r9, [r8+0x28]                     
    ldxdw r6, [r8+0x20]                     
    mov64 r1, r6                                    r1 = r6
    mov64 r2, r9                                    r2 = r9
    ldxdw r3, [r10-0x18]                    
    mov64 r5, r0                                    r5 = r0
    call function_45704                     
    mov64 r7, 1                                     r7 = 1 as i32 as i64 as u64
    jne r0, 0, lbb_45580                            if r0 != (0 as i32 as i64 as u64) { pc += 39 }
    ja lbb_45574                                    if true { pc += 32 }
lbb_45542:
    ldxdw r6, [r8+0x8]                      
    jgt r6, r9, lbb_45545                           if r6 > r9 { pc += 1 }
    ja lbb_45565                                    if true { pc += 20 }
lbb_45545:
    and64 r7, 8                                     r7 &= 8   ///  r7 = r7.and(8)
    jeq r7, 0, lbb_45548                            if r7 == (0 as i32 as i64 as u64) { pc += 1 }
    ja lbb_45611                                    if true { pc += 63 }
lbb_45548:
    sub64 r6, r9                                    r6 -= r9   ///  r6 = r6.wrapping_sub(r9)
    ldxb r9, [r8+0x38]                      
    stxdw [r10-0x30], r0                    
    stxdw [r10-0x38], r4                    
    jsgt r9, 1, lbb_45638                           if (r9 as i64) > (1 as i32 as i64) { pc += 85 }
    jeq r9, 0, lbb_45657                            if r9 == (0 as i32 as i64 as u64) { pc += 103 }
lbb_45554:
    mov64 r9, r6                                    r9 = r6
    mov64 r6, 0                                     r6 = 0 as i32 as i64 as u64
    ja lbb_45657                                    if true { pc += 100 }
lbb_45557:
    mov64 r1, 32                                    r1 = 32 as i32 as i64 as u64
    stxdw [r10-0x8], r3                     
    jgt r1, r0, lbb_45588                           if r1 > r0 { pc += 28 }
    mov64 r1, r3                                    r1 = r3
    mov64 r6, r0                                    r6 = r0
    mov64 r2, r0                                    r2 = r0
    call function_46791                     
    ja lbb_45599                                    if true { pc += 34 }
lbb_45565:
    ldxdw r9, [r8+0x28]                     
    ldxdw r6, [r8+0x20]                     
    mov64 r1, r6                                    r1 = r6
    mov64 r2, r9                                    r2 = r9
    ldxdw r3, [r10-0x18]                    
    mov64 r5, r0                                    r5 = r0
    call function_45704                     
    mov64 r7, 1                                     r7 = 1 as i32 as i64 as u64
    jne r0, 0, lbb_45580                            if r0 != (0 as i32 as i64 as u64) { pc += 6 }
lbb_45574:
    ldxdw r4, [r9+0x18]                     
    mov64 r1, r6                                    r1 = r6
    ldxdw r2, [r10-0x28]                    
    ldxdw r3, [r10-0x20]                    
    callx r4                                
    mov64 r7, r0                                    r7 = r0
lbb_45580:
    and64 r7, 1                                     r7 &= 1   ///  r7 = r7.and(1)
    mov64 r0, r7                                    r0 = r7
    exit                                    
lbb_45583:
    mov64 r1, 43                                    r1 = 43 as i32 as i64 as u64
    stxdw [r10-0x18], r1                    
    ldxdw r9, [r10-0x20]                    
    add64 r9, 1                                     r9 += 1   ///  r9 = r9.wrapping_add(1 as i32 as i64 as u64)
    ja lbb_45523                                    if true { pc += -65 }
lbb_45588:
    mov64 r1, r0                                    r1 = r0
    mov64 r0, 0                                     r0 = 0 as i32 as i64 as u64
    mov64 r6, r1                                    r6 = r1
    jeq r1, 0, lbb_45599                            if r1 == (0 as i32 as i64 as u64) { pc += 7 }
    ldxdw r1, [r10-0x8]                     
    mov64 r2, r6                                    r2 = r6
    ja lbb_45604                                    if true { pc += 9 }
lbb_45595:
    add64 r0, r3                                    r0 += r3   ///  r0 = r0.wrapping_add(r3)
    add64 r1, 1                                     r1 += 1   ///  r1 = r1.wrapping_add(1 as i32 as i64 as u64)
    add64 r2, -1                                    r2 += -1   ///  r2 = r2.wrapping_add(-1 as i32 as i64 as u64)
    jne r2, 0, lbb_45604                            if r2 != (0 as i32 as i64 as u64) { pc += 5 }
lbb_45599:
    add64 r0, r9                                    r0 += r9   ///  r0 = r0.wrapping_add(r9)
    ldxdw r4, [r10-0x8]                     
    mov64 r9, r0                                    r9 = r0
    mov64 r0, r6                                    r0 = r6
    ja lbb_45530                                    if true { pc += -74 }
lbb_45604:
    ldxb r4, [r1+0x0]                       
    lsh64 r4, 56                                    r4 <<= 56   ///  r4 = r4.wrapping_shl(56)
    arsh64 r4, 56                                   r4 >>= 56 (signed)   ///  r4 = (r4 as i64).wrapping_shr(56)
    mov64 r3, 1                                     r3 = 1 as i32 as i64 as u64
    jsgt r4, -65, lbb_45595                         if (r4 as i64) > (-65 as i32 as i64) { pc += -14 }
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
    ja lbb_45595                                    if true { pc += -16 }
lbb_45611:
    ldxw r1, [r8+0x30]                      
    stxdw [r10-0x40], r1                    
    mov64 r1, 48                                    r1 = 48 as i32 as i64 as u64
    stxw [r8+0x30], r1                      
    ldxb r1, [r8+0x38]                      
    stxdw [r10-0x48], r1                    
    mov64 r7, 1                                     r7 = 1 as i32 as i64 as u64
    stxb [r8+0x38], r7                      
    ldxdw r1, [r8+0x20]                     
    ldxdw r2, [r8+0x28]                     
    stxdw [r10-0x8], r1                     
    stxdw [r10-0x10], r2                    
    ldxdw r3, [r10-0x18]                    
    mov64 r5, r0                                    r5 = r0
    call function_45704                     
    jne r0, 0, lbb_45580                            if r0 != (0 as i32 as i64 as u64) { pc += -47 }
    sub64 r6, r9                                    r6 -= r9   ///  r6 = r6.wrapping_sub(r9)
    add64 r6, 1                                     r6 += 1   ///  r6 = r6.wrapping_add(1 as i32 as i64 as u64)
lbb_45629:
    add64 r6, -1                                    r6 += -1   ///  r6 = r6.wrapping_add(-1 as i32 as i64 as u64)
    jeq r6, 0, lbb_45640                            if r6 == (0 as i32 as i64 as u64) { pc += 9 }
    ldxdw r1, [r10-0x10]                    
    ldxdw r3, [r1+0x20]                     
    ldxdw r1, [r10-0x8]                     
    mov64 r2, 48                                    r2 = 48 as i32 as i64 as u64
    callx r3                                
    jne r0, 0, lbb_45580                            if r0 != (0 as i32 as i64 as u64) { pc += -57 }
    ja lbb_45629                                    if true { pc += -9 }
lbb_45638:
    jeq r9, 2, lbb_45653                            if r9 == (2 as i32 as i64 as u64) { pc += 14 }
    ja lbb_45554                                    if true { pc += -86 }
lbb_45640:
    ldxdw r1, [r10-0x10]                    
    ldxdw r4, [r1+0x18]                     
    ldxdw r1, [r10-0x8]                     
    ldxdw r2, [r10-0x28]                    
    ldxdw r3, [r10-0x20]                    
    callx r4                                
    jne r0, 0, lbb_45580                            if r0 != (0 as i32 as i64 as u64) { pc += -67 }
    ldxdw r1, [r10-0x48]                    
    stxb [r8+0x38], r1                      
    ldxdw r1, [r10-0x40]                    
    stxw [r8+0x30], r1                      
    mov64 r7, 0                                     r7 = 0 as i32 as i64 as u64
    ja lbb_45580                                    if true { pc += -73 }
lbb_45653:
    mov64 r9, r6                                    r9 = r6
    rsh64 r9, 1                                     r9 >>= 1   ///  r9 = r9.wrapping_shr(1)
    add64 r6, 1                                     r6 += 1   ///  r6 = r6.wrapping_add(1 as i32 as i64 as u64)
    rsh64 r6, 1                                     r6 >>= 1   ///  r6 = r6.wrapping_shr(1)
lbb_45657:
    add64 r9, 1                                     r9 += 1   ///  r9 = r9.wrapping_add(1 as i32 as i64 as u64)
    ldxw r1, [r8+0x30]                      
    stxdw [r10-0x10], r1                    
    ldxdw r1, [r8+0x28]                     
    stxdw [r10-0x8], r1                     
    ldxdw r8, [r8+0x20]                     
    mov64 r7, 1                                     r7 = 1 as i32 as i64 as u64
lbb_45664:
    add64 r9, -1                                    r9 += -1   ///  r9 = r9.wrapping_add(-1 as i32 as i64 as u64)
    jeq r9, 0, lbb_45673                            if r9 == (0 as i32 as i64 as u64) { pc += 7 }
    ldxdw r1, [r10-0x8]                     
    ldxdw r3, [r1+0x20]                     
    mov64 r1, r8                                    r1 = r8
    ldxdw r2, [r10-0x10]                    
    callx r3                                
    jne r0, 0, lbb_45580                            if r0 != (0 as i32 as i64 as u64) { pc += -92 }
    ja lbb_45664                                    if true { pc += -9 }
lbb_45673:
    mov64 r1, r8                                    r1 = r8
    ldxdw r2, [r10-0x8]                     
    ldxdw r3, [r10-0x18]                    
    ldxdw r4, [r10-0x38]                    
    ldxdw r5, [r10-0x30]                    
    call function_45704                     
    mov64 r7, 1                                     r7 = 1 as i32 as i64 as u64
    jne r0, 0, lbb_45580                            if r0 != (0 as i32 as i64 as u64) { pc += -101 }
    ldxdw r1, [r10-0x8]                     
    ldxdw r4, [r1+0x18]                     
    mov64 r1, r8                                    r1 = r8
    ldxdw r2, [r10-0x28]                    
    ldxdw r3, [r10-0x20]                    
    callx r4                                
    jne r0, 0, lbb_45580                            if r0 != (0 as i32 as i64 as u64) { pc += -108 }
    mov64 r7, 0                                     r7 = 0 as i32 as i64 as u64
lbb_45689:
    mov64 r1, r6                                    r1 = r6
    jeq r6, r7, lbb_45700                           if r6 == r7 { pc += 9 }
    ldxdw r1, [r10-0x8]                     
    ldxdw r3, [r1+0x20]                     
    mov64 r1, r8                                    r1 = r8
    ldxdw r2, [r10-0x10]                    
    callx r3                                
    add64 r7, 1                                     r7 += 1   ///  r7 = r7.wrapping_add(1 as i32 as i64 as u64)
    jeq r0, 0, lbb_45689                            if r0 == (0 as i32 as i64 as u64) { pc += -9 }
    add64 r7, -1                                    r7 += -1   ///  r7 = r7.wrapping_add(-1 as i32 as i64 as u64)
    mov64 r1, r7                                    r1 = r7
lbb_45700:
    mov64 r7, 1                                     r7 = 1 as i32 as i64 as u64
    jgt r6, r1, lbb_45580                           if r6 > r1 { pc += -122 }
    mov64 r7, 0                                     r7 = 0 as i32 as i64 as u64
    ja lbb_45580                                    if true { pc += -124 }

function_45704:
    mov64 r6, r5                                    r6 = r5
    mov64 r7, r4                                    r7 = r4
    mov64 r9, r2                                    r9 = r2
    mov64 r8, r1                                    r8 = r1
    mov64 r1, r3                                    r1 = r3
    lsh64 r1, 32                                    r1 <<= 32   ///  r1 = r1.wrapping_shl(32)
    rsh64 r1, 32                                    r1 >>= 32   ///  r1 = r1.wrapping_shr(32)
    jeq r1, 1114112, lbb_45719                      if r1 == (1114112 as i32 as i64 as u64) { pc += 7 }
    ldxdw r4, [r9+0x20]                     
    mov64 r1, r8                                    r1 = r8
    mov64 r2, r3                                    r2 = r3
    callx r4                                
    mov64 r1, r0                                    r1 = r0
    mov64 r0, 1                                     r0 = 1 as i32 as i64 as u64
    jne r1, 0, lbb_45721                            if r1 != (0 as i32 as i64 as u64) { pc += 2 }
lbb_45719:
    mov64 r0, 0                                     r0 = 0 as i32 as i64 as u64
    jne r7, 0, lbb_45722                            if r7 != (0 as i32 as i64 as u64) { pc += 1 }
lbb_45721:
    exit                                    
lbb_45722:
    ldxdw r4, [r9+0x18]                     
    mov64 r1, r8                                    r1 = r8
    mov64 r2, r7                                    r2 = r7
    mov64 r3, r6                                    r3 = r6
    callx r4                                
    ja lbb_45721                                    if true { pc += -7 }

function_45728:
    mov64 r8, r1                                    r8 = r1
    ldxdw r5, [r8+0x10]                     
    ldxdw r1, [r8+0x0]                      
    mov64 r4, r1                                    r4 = r1
    or64 r4, r5                                     r4 |= r5   ///  r4 = r4.or(r5)
    jeq r4, 0, lbb_45785                            if r4 == (0 as i32 as i64 as u64) { pc += 51 }
    stxdw [r10-0x8], r2                     
    stxdw [r10-0x10], r3                    
    jeq r5, 0, lbb_45805                            if r5 == (0 as i32 as i64 as u64) { pc += 68 }
    ldxdw r7, [r10-0x8]                     
    mov64 r3, r7                                    r3 = r7
    ldxdw r2, [r10-0x10]                    
    add64 r3, r2                                    r3 += r2   ///  r3 = r3.wrapping_add(r2)
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
    ldxdw r4, [r8+0x18]                     
    jeq r4, 0, lbb_45770                            if r4 == (0 as i32 as i64 as u64) { pc += 26 }
    mov64 r6, 0                                     r6 = 0 as i32 as i64 as u64
    ldxdw r7, [r10-0x8]                     
lbb_45746:
    mov64 r9, r7                                    r9 = r7
    jeq r9, r3, lbb_45805                           if r9 == r3 { pc += 57 }
    mov64 r7, r9                                    r7 = r9
    add64 r7, 1                                     r7 += 1   ///  r7 = r7.wrapping_add(1 as i32 as i64 as u64)
    ldxb r5, [r9+0x0]                       
    mov64 r0, r5                                    r0 = r5
    lsh64 r0, 56                                    r0 <<= 56   ///  r0 = r0.wrapping_shl(56)
    arsh64 r0, 56                                   r0 >>= 56 (signed)   ///  r0 = (r0 as i64).wrapping_shr(56)
    jsgt r0, -1, lbb_45766                          if (r0 as i64) > (-1 as i32 as i64) { pc += 11 }
    mov64 r7, r9                                    r7 = r9
    add64 r7, 2                                     r7 += 2   ///  r7 = r7.wrapping_add(2 as i32 as i64 as u64)
    mov64 r0, r5                                    r0 = r5
    mov64 r5, 224                                   r5 = 224 as i32 as i64 as u64
    jgt r5, r0, lbb_45766                           if r5 > r0 { pc += 6 }
    mov64 r7, r9                                    r7 = r9
    add64 r7, 3                                     r7 += 3   ///  r7 = r7.wrapping_add(3 as i32 as i64 as u64)
    mov64 r5, 240                                   r5 = 240 as i32 as i64 as u64
    jgt r5, r0, lbb_45766                           if r5 > r0 { pc += 2 }
    mov64 r7, r9                                    r7 = r9
    add64 r7, 4                                     r7 += 4   ///  r7 = r7.wrapping_add(4 as i32 as i64 as u64)
lbb_45766:
    add64 r6, 1                                     r6 += 1   ///  r6 = r6.wrapping_add(1 as i32 as i64 as u64)
    sub64 r2, r9                                    r2 -= r9   ///  r2 = r2.wrapping_sub(r9)
    add64 r2, r7                                    r2 += r7   ///  r2 = r2.wrapping_add(r7)
    jgt r4, r6, lbb_45746                           if r4 > r6 { pc += -24 }
lbb_45770:
    jeq r7, r3, lbb_45805                           if r7 == r3 { pc += 34 }
    ldxb r3, [r7+0x0]                       
    mov64 r4, r3                                    r4 = r3
    lsh64 r4, 56                                    r4 <<= 56   ///  r4 = r4.wrapping_shl(56)
    arsh64 r4, 56                                   r4 >>= 56 (signed)   ///  r4 = (r4 as i64).wrapping_shr(56)
    jsgt r4, -1, lbb_45778                          if (r4 as i64) > (-1 as i32 as i64) { pc += 2 }
    mov64 r4, 224                                   r4 = 224 as i32 as i64 as u64
    jgt r4, r3, lbb_45778                           if r4 > r3 { pc += 0 }
lbb_45778:
    ldxdw r0, [r10-0x10]                    
    ldxdw r6, [r10-0x8]                     
    jeq r2, 0, lbb_45798                            if r2 == (0 as i32 as i64 as u64) { pc += 17 }
    jgt r0, r2, lbb_45790                           if r0 > r2 { pc += 8 }
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
    jeq r2, r0, lbb_45798                           if r2 == r0 { pc += 14 }
    ja lbb_45799                                    if true { pc += 14 }
lbb_45785:
    ldxdw r1, [r8+0x20]                     
    ldxdw r4, [r8+0x28]                     
    ldxdw r4, [r4+0x18]                     
    callx r4                                
    ja lbb_45899                                    if true { pc += 109 }
lbb_45790:
    mov64 r4, r6                                    r4 = r6
    add64 r4, r2                                    r4 += r2   ///  r4 = r4.wrapping_add(r2)
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
    ldxb r4, [r4+0x0]                       
    lsh64 r4, 56                                    r4 <<= 56   ///  r4 = r4.wrapping_shl(56)
    arsh64 r4, 56                                   r4 >>= 56 (signed)   ///  r4 = (r4 as i64).wrapping_shr(56)
    mov64 r5, -64                                   r5 = -64 as i32 as i64 as u64
    jsgt r5, r4, lbb_45799                          if (r5 as i64) > (r4 as i64) { pc += 1 }
lbb_45798:
    mov64 r3, r6                                    r3 = r6
lbb_45799:
    jeq r3, 0, lbb_45801                            if r3 == (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r0, r2                                    r0 = r2
lbb_45801:
    stxdw [r10-0x10], r0                    
    jeq r3, 0, lbb_45804                            if r3 == (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r6, r3                                    r6 = r3
lbb_45804:
    stxdw [r10-0x8], r6                     
lbb_45805:
    jne r1, 0, lbb_45813                            if r1 != (0 as i32 as i64 as u64) { pc += 7 }
    ldxdw r1, [r8+0x20]                     
    ldxdw r2, [r8+0x28]                     
    ldxdw r4, [r2+0x18]                     
    ldxdw r2, [r10-0x8]                     
    ldxdw r3, [r10-0x10]                    
    callx r4                                
    ja lbb_45899                                    if true { pc += 86 }
lbb_45813:
    ldxdw r9, [r8+0x8]                      
    mov64 r1, 32                                    r1 = 32 as i32 as i64 as u64
    ldxdw r6, [r10-0x10]                    
    ldxdw r7, [r10-0x8]                     
    jgt r1, r6, lbb_45822                           if r1 > r6 { pc += 4 }
    mov64 r1, r7                                    r1 = r7
    mov64 r2, r6                                    r2 = r6
    call function_46791                     
    ja lbb_45831                                    if true { pc += 9 }
lbb_45822:
    mov64 r0, 0                                     r0 = 0 as i32 as i64 as u64
    jeq r6, 0, lbb_45831                            if r6 == (0 as i32 as i64 as u64) { pc += 7 }
    mov64 r1, r7                                    r1 = r7
    mov64 r2, r6                                    r2 = r6
    ja lbb_45840                                    if true { pc += 13 }
lbb_45827:
    add64 r0, r3                                    r0 += r3   ///  r0 = r0.wrapping_add(r3)
    add64 r1, 1                                     r1 += 1   ///  r1 = r1.wrapping_add(1 as i32 as i64 as u64)
    add64 r2, -1                                    r2 += -1   ///  r2 = r2.wrapping_add(-1 as i32 as i64 as u64)
    jne r2, 0, lbb_45840                            if r2 != (0 as i32 as i64 as u64) { pc += 9 }
lbb_45831:
    jge r0, r9, lbb_45847                           if r0 >= r9 { pc += 15 }
    sub64 r9, r0                                    r9 -= r0   ///  r9 = r9.wrapping_sub(r0)
    mov64 r6, 0                                     r6 = 0 as i32 as i64 as u64
    ldxb r1, [r8+0x38]                      
    jsgt r1, 1, lbb_45854                           if (r1 as i64) > (1 as i32 as i64) { pc += 18 }
    jeq r1, 0, lbb_45860                            if r1 == (0 as i32 as i64 as u64) { pc += 23 }
    mov64 r6, r9                                    r6 = r9
    mov64 r9, 0                                     r9 = 0 as i32 as i64 as u64
    ja lbb_45860                                    if true { pc += 20 }
lbb_45840:
    ldxb r4, [r1+0x0]                       
    lsh64 r4, 56                                    r4 <<= 56   ///  r4 = r4.wrapping_shl(56)
    arsh64 r4, 56                                   r4 >>= 56 (signed)   ///  r4 = (r4 as i64).wrapping_shr(56)
    mov64 r3, 1                                     r3 = 1 as i32 as i64 as u64
    jsgt r4, -65, lbb_45827                         if (r4 as i64) > (-65 as i32 as i64) { pc += -18 }
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
    ja lbb_45827                                    if true { pc += -20 }
lbb_45847:
    ldxdw r1, [r8+0x20]                     
    ldxdw r2, [r8+0x28]                     
    ldxdw r4, [r2+0x18]                     
    mov64 r2, r7                                    r2 = r7
    mov64 r3, r6                                    r3 = r6
    callx r4                                
    ja lbb_45899                                    if true { pc += 45 }
lbb_45854:
    jeq r1, 2, lbb_45856                            if r1 == (2 as i32 as i64 as u64) { pc += 1 }
    ja lbb_45860                                    if true { pc += 4 }
lbb_45856:
    mov64 r6, r9                                    r6 = r9
    rsh64 r6, 1                                     r6 >>= 1   ///  r6 = r6.wrapping_shr(1)
    add64 r9, 1                                     r9 += 1   ///  r9 = r9.wrapping_add(1 as i32 as i64 as u64)
    rsh64 r9, 1                                     r9 >>= 1   ///  r9 = r9.wrapping_shr(1)
lbb_45860:
    stxdw [r10-0x18], r9                    
    add64 r6, 1                                     r6 += 1   ///  r6 = r6.wrapping_add(1 as i32 as i64 as u64)
    ldxw r9, [r8+0x30]                      
    ldxdw r7, [r8+0x28]                     
    ldxdw r8, [r8+0x20]                     
lbb_45865:
    add64 r6, -1                                    r6 += -1   ///  r6 = r6.wrapping_add(-1 as i32 as i64 as u64)
    jeq r6, 0, lbb_45875                            if r6 == (0 as i32 as i64 as u64) { pc += 8 }
    ldxdw r3, [r7+0x20]                     
    mov64 r1, r8                                    r1 = r8
    mov64 r2, r9                                    r2 = r9
    callx r3                                
    mov64 r1, r0                                    r1 = r0
    mov64 r0, 1                                     r0 = 1 as i32 as i64 as u64
    jne r1, 0, lbb_45899                            if r1 != (0 as i32 as i64 as u64) { pc += 25 }
    ja lbb_45865                                    if true { pc += -10 }
lbb_45875:
    ldxdw r4, [r7+0x18]                     
    mov64 r1, r8                                    r1 = r8
    ldxdw r2, [r10-0x8]                     
    ldxdw r3, [r10-0x10]                    
    callx r4                                
    mov64 r1, r0                                    r1 = r0
    mov64 r0, 1                                     r0 = 1 as i32 as i64 as u64
    jne r1, 0, lbb_45899                            if r1 != (0 as i32 as i64 as u64) { pc += 16 }
    mov64 r6, 0                                     r6 = 0 as i32 as i64 as u64
lbb_45884:
    ldxdw r2, [r10-0x18]                    
    mov64 r1, r2                                    r1 = r2
    jeq r2, r6, lbb_45895                           if r2 == r6 { pc += 8 }
    ldxdw r3, [r7+0x20]                     
    mov64 r1, r8                                    r1 = r8
    mov64 r2, r9                                    r2 = r9
    callx r3                                
    add64 r6, 1                                     r6 += 1   ///  r6 = r6.wrapping_add(1 as i32 as i64 as u64)
    jeq r0, 0, lbb_45884                            if r0 == (0 as i32 as i64 as u64) { pc += -9 }
    add64 r6, -1                                    r6 += -1   ///  r6 = r6.wrapping_add(-1 as i32 as i64 as u64)
    mov64 r1, r6                                    r1 = r6
lbb_45895:
    mov64 r0, 1                                     r0 = 1 as i32 as i64 as u64
    ldxdw r2, [r10-0x18]                    
    jgt r2, r1, lbb_45899                           if r2 > r1 { pc += 1 }
    mov64 r0, 0                                     r0 = 0 as i32 as i64 as u64
lbb_45899:
    and64 r0, 1                                     r0 &= 1   ///  r0 = r0.and(1)
    exit                                    

function_45901:
    ldxdw r4, [r1+0x20]                     
    ldxdw r1, [r1+0x28]                     
    ldxdw r5, [r1+0x18]                     
    mov64 r1, r4                                    r1 = r4
    callx r5                                
    exit                                    

function_45907:
    mov64 r3, r2                                    r3 = r2
    ldxdw r2, [r1+0x28]                     
    ldxdw r1, [r1+0x20]                     
    call function_45367                     
    exit                                    

function_45912:
    mov64 r6, r2                                    r6 = r2
    mov64 r7, r1                                    r7 = r1
    ldxdw r1, [r6+0x28]                     
    ldxdw r5, [r1+0x18]                     
    ldxdw r1, [r6+0x20]                     
    mov64 r2, r3                                    r2 = r3
    mov64 r3, r4                                    r3 = r4
    callx r5                                
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    stxb [r7+0x9], r1                       
    stxb [r7+0x8], r0                       
    stxdw [r7+0x0], r6                      
    exit                                    

function_45925:
    mov64 r7, r5                                    r7 = r5
    mov64 r6, r4                                    r6 = r4
    mov64 r8, r1                                    r8 = r1
    ldxdw r1, [r8+0x28]                     
    ldxdw r4, [r1+0x18]                     
    ldxdw r1, [r8+0x20]                     
    callx r4                                
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    stxb [r10-0x7], r1                      
    stxb [r10-0x8], r0                      
    stxdw [r10-0x10], r8                    
    ldxdw r3, [r7-0x1000]                   
    ldxdw r4, [r7-0xff8]                    
    ldxdw r5, [r7-0xff0]                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -16                                   r1 += -16   ///  r1 = r1.wrapping_add(-16 as i32 as i64 as u64)
    mov64 r2, r6                                    r2 = r6
    call function_44516                     
    ldxb r1, [r10-0x8]                      
    ldxb r2, [r10-0x7]                      
    jne r2, 0, lbb_45950                            if r2 != (0 as i32 as i64 as u64) { pc += 4 }
    mov64 r0, 1                                     r0 = 1 as i32 as i64 as u64
    jne r1, 0, lbb_45970                            if r1 != (0 as i32 as i64 as u64) { pc += 22 }
    mov64 r0, 0                                     r0 = 0 as i32 as i64 as u64
    ja lbb_45970                                    if true { pc += 20 }
lbb_45950:
    mov64 r0, 1                                     r0 = 1 as i32 as i64 as u64
    jne r1, 0, lbb_45970                            if r1 != (0 as i32 as i64 as u64) { pc += 18 }
    ldxdw r2, [r10-0x10]                    
    ldxw r1, [r2+0x34]                      
    and64 r1, 4                                     r1 &= 4   ///  r1 = r1.and(4)
    jne r1, 0, lbb_45963                            if r1 != (0 as i32 as i64 as u64) { pc += 7 }
    ldxdw r1, [r2+0x20]                     
    ldxdw r2, [r2+0x28]                     
    ldxdw r4, [r2+0x18]                     
    lddw r2, 0x100063d91 --> b" }"                  r2 load str located at 4295376273
    mov64 r3, 2                                     r3 = 2 as i32 as i64 as u64
    ja lbb_45969                                    if true { pc += 6 }
lbb_45963:
    ldxdw r1, [r2+0x20]                     
    ldxdw r2, [r2+0x28]                     
    ldxdw r4, [r2+0x18]                     
    lddw r2, 0x100063d90 --> b"}"                   r2 load str located at 4295376272
    mov64 r3, 1                                     r3 = 1 as i32 as i64 as u64
lbb_45969:
    callx r4                                
lbb_45970:
    and64 r0, 1                                     r0 &= 1   ///  r0 = r0.and(1)
    exit                                    

function_45972:
    mov64 r6, r5                                    r6 = r5
    mov64 r7, r4                                    r7 = r4
    mov64 r8, r1                                    r8 = r1
    ldxdw r1, [r8+0x28]                     
    ldxdw r4, [r1+0x18]                     
    ldxdw r1, [r8+0x20]                     
    callx r4                                
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    stxb [r10-0x7], r1                      
    stxb [r10-0x8], r0                      
    stxdw [r10-0x10], r8                    
    ldxdw r3, [r6-0x1000]                   
    ldxdw r4, [r6-0xff8]                    
    ldxdw r5, [r6-0xff0]                    
    mov64 r8, r10                                   r8 = r10
    add64 r8, -16                                   r8 += -16   ///  r8 = r8.wrapping_add(-16 as i32 as i64 as u64)
    mov64 r1, r8                                    r1 = r8
    mov64 r2, r7                                    r2 = r7
    call function_44516                     
    ldxdw r2, [r6-0xfe8]                    
    ldxdw r3, [r6-0xfe0]                    
    ldxdw r4, [r6-0xfd8]                    
    ldxdw r5, [r6-0xfd0]                    
    mov64 r1, r8                                    r1 = r8
    call function_44516                     
    ldxb r1, [r10-0x8]                      
    ldxb r2, [r10-0x7]                      
    jne r2, 0, lbb_46004                            if r2 != (0 as i32 as i64 as u64) { pc += 4 }
    mov64 r0, 1                                     r0 = 1 as i32 as i64 as u64
    jne r1, 0, lbb_46024                            if r1 != (0 as i32 as i64 as u64) { pc += 22 }
    mov64 r0, 0                                     r0 = 0 as i32 as i64 as u64
    ja lbb_46024                                    if true { pc += 20 }
lbb_46004:
    mov64 r0, 1                                     r0 = 1 as i32 as i64 as u64
    jne r1, 0, lbb_46024                            if r1 != (0 as i32 as i64 as u64) { pc += 18 }
    ldxdw r2, [r10-0x10]                    
    ldxw r1, [r2+0x34]                      
    and64 r1, 4                                     r1 &= 4   ///  r1 = r1.and(4)
    jne r1, 0, lbb_46017                            if r1 != (0 as i32 as i64 as u64) { pc += 7 }
    ldxdw r1, [r2+0x20]                     
    ldxdw r2, [r2+0x28]                     
    ldxdw r4, [r2+0x18]                     
    lddw r2, 0x100063d91 --> b" }"                  r2 load str located at 4295376273
    mov64 r3, 2                                     r3 = 2 as i32 as i64 as u64
    ja lbb_46023                                    if true { pc += 6 }
lbb_46017:
    ldxdw r1, [r2+0x20]                     
    ldxdw r2, [r2+0x28]                     
    ldxdw r4, [r2+0x18]                     
    lddw r2, 0x100063d90 --> b"}"                   r2 load str located at 4295376272
    mov64 r3, 1                                     r3 = 1 as i32 as i64 as u64
lbb_46023:
    callx r4                                
lbb_46024:
    and64 r0, 1                                     r0 &= 1   ///  r0 = r0.and(1)
    exit                                    

function_46026:
    mov64 r6, r5                                    r6 = r5
    mov64 r8, r4                                    r8 = r4
    mov64 r7, r1                                    r7 = r1
    ldxdw r1, [r7+0x28]                     
    ldxdw r4, [r1+0x18]                     
    ldxdw r1, [r7+0x20]                     
    callx r4                                
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    stxb [r10-0x7], r1                      
    stxb [r10-0x8], r0                      
    stxdw [r10-0x10], r7                    
    ldxdw r3, [r6-0x1000]                   
    ldxdw r4, [r6-0xff8]                    
    ldxdw r5, [r6-0xff0]                    
    mov64 r7, r10                                   r7 = r10
    add64 r7, -16                                   r7 += -16   ///  r7 = r7.wrapping_add(-16 as i32 as i64 as u64)
    mov64 r1, r7                                    r1 = r7
    mov64 r2, r8                                    r2 = r8
    call function_44516                     
    ldxdw r2, [r6-0xfe8]                    
    ldxdw r3, [r6-0xfe0]                    
    ldxdw r4, [r6-0xfd8]                    
    ldxdw r5, [r6-0xfd0]                    
    mov64 r1, r7                                    r1 = r7
    call function_44516                     
    ldxdw r2, [r6-0xfc8]                    
    ldxdw r3, [r6-0xfc0]                    
    ldxdw r4, [r6-0xfb8]                    
    ldxdw r5, [r6-0xfb0]                    
    mov64 r1, r7                                    r1 = r7
    call function_44516                     
    ldxb r1, [r10-0x8]                      
    ldxb r2, [r10-0x7]                      
    jne r2, 0, lbb_46064                            if r2 != (0 as i32 as i64 as u64) { pc += 4 }
    mov64 r0, 1                                     r0 = 1 as i32 as i64 as u64
    jne r1, 0, lbb_46084                            if r1 != (0 as i32 as i64 as u64) { pc += 22 }
    mov64 r0, 0                                     r0 = 0 as i32 as i64 as u64
    ja lbb_46084                                    if true { pc += 20 }
lbb_46064:
    mov64 r0, 1                                     r0 = 1 as i32 as i64 as u64
    jne r1, 0, lbb_46084                            if r1 != (0 as i32 as i64 as u64) { pc += 18 }
    ldxdw r2, [r10-0x10]                    
    ldxw r1, [r2+0x34]                      
    and64 r1, 4                                     r1 &= 4   ///  r1 = r1.and(4)
    jne r1, 0, lbb_46077                            if r1 != (0 as i32 as i64 as u64) { pc += 7 }
    ldxdw r1, [r2+0x20]                     
    ldxdw r2, [r2+0x28]                     
    ldxdw r4, [r2+0x18]                     
    lddw r2, 0x100063d91 --> b" }"                  r2 load str located at 4295376273
    mov64 r3, 2                                     r3 = 2 as i32 as i64 as u64
    ja lbb_46083                                    if true { pc += 6 }
lbb_46077:
    ldxdw r1, [r2+0x20]                     
    ldxdw r2, [r2+0x28]                     
    ldxdw r4, [r2+0x18]                     
    lddw r2, 0x100063d90 --> b"}"                   r2 load str located at 4295376272
    mov64 r3, 1                                     r3 = 1 as i32 as i64 as u64
lbb_46083:
    callx r4                                
lbb_46084:
    and64 r0, 1                                     r0 &= 1   ///  r0 = r0.and(1)
    exit                                    

function_46086:
    mov64 r7, r4                                    r7 = r4
    mov64 r8, r2                                    r8 = r2
    mov64 r6, r1                                    r6 = r1
    ldxdw r1, [r8+0x28]                     
    ldxdw r4, [r1+0x18]                     
    ldxdw r1, [r8+0x20]                     
    mov64 r2, r3                                    r2 = r3
    mov64 r3, r7                                    r3 = r7
    callx r4                                
    stxb [r6+0x10], r0                      
    stxdw [r6+0x8], r8                      
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    mov64 r2, 1                                     r2 = 1 as i32 as i64 as u64
    jeq r7, 0, lbb_46101                            if r7 == (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
lbb_46101:
    stxb [r6+0x11], r2                      
    stxdw [r6+0x0], r1                      
    exit                                    

function_46104:
    mov64 r6, r5                                    r6 = r5
    mov64 r7, r4                                    r7 = r4
    mov64 r8, r3                                    r8 = r3
    mov64 r9, r1                                    r9 = r1
    ldxdw r1, [r9+0x28]                     
    ldxdw r4, [r1+0x18]                     
    ldxdw r1, [r9+0x20]                     
    callx r4                                
    stxb [r10-0x8], r0                      
    stxdw [r10-0x10], r9                    
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    mov64 r2, 1                                     r2 = 1 as i32 as i64 as u64
    jeq r8, 0, lbb_46118                            if r8 == (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
lbb_46118:
    stxb [r10-0x7], r2                      
    stxdw [r10-0x18], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -24                                   r1 += -24   ///  r1 = r1.wrapping_add(-24 as i32 as i64 as u64)
    mov64 r2, r7                                    r2 = r7
    mov64 r3, r6                                    r3 = r6
    call function_44672                     
    ldxb r2, [r10-0x8]                      
    ldxdw r1, [r10-0x18]                    
    jne r1, 0, lbb_46133                            if r1 != (0 as i32 as i64 as u64) { pc += 5 }
    mov64 r1, r2                                    r1 = r2
    mov64 r6, 1                                     r6 = 1 as i32 as i64 as u64
    jne r1, 0, lbb_46159                            if r1 != (0 as i32 as i64 as u64) { pc += 28 }
    mov64 r6, 0                                     r6 = 0 as i32 as i64 as u64
    ja lbb_46159                                    if true { pc += 26 }
lbb_46133:
    mov64 r6, 1                                     r6 = 1 as i32 as i64 as u64
    jne r2, 0, lbb_46159                            if r2 != (0 as i32 as i64 as u64) { pc += 24 }
    ldxdw r7, [r10-0x10]                    
    jne r1, 1, lbb_46139                            if r1 != (1 as i32 as i64 as u64) { pc += 2 }
    ldxb r1, [r10-0x7]                      
    jne r1, 0, lbb_46148                            if r1 != (0 as i32 as i64 as u64) { pc += 9 }
lbb_46139:
    ldxdw r1, [r7+0x20]                     
    ldxdw r2, [r7+0x28]                     
    ldxdw r4, [r2+0x18]                     
    lddw r2, 0x100063d13 --> b")"                   r2 load str located at 4295376147
    mov64 r3, 1                                     r3 = 1 as i32 as i64 as u64
    callx r4                                
    mov64 r6, r0                                    r6 = r0
    ja lbb_46159                                    if true { pc += 11 }
lbb_46148:
    ldxw r1, [r7+0x34]                      
    and64 r1, 4                                     r1 &= 4   ///  r1 = r1.and(4)
    jne r1, 0, lbb_46139                            if r1 != (0 as i32 as i64 as u64) { pc += -12 }
    ldxdw r1, [r7+0x20]                     
    ldxdw r2, [r7+0x28]                     
    ldxdw r4, [r2+0x18]                     
    lddw r2, 0x100063d96 --> b","                   r2 load str located at 4295376278
    mov64 r3, 1                                     r3 = 1 as i32 as i64 as u64
    callx r4                                
    jeq r0, 0, lbb_46139                            if r0 == (0 as i32 as i64 as u64) { pc += -20 }
lbb_46159:
    and64 r6, 1                                     r6 &= 1   ///  r6 = r6.and(1)
    mov64 r0, r6                                    r0 = r6
    exit                                    

function_46162:
    mov64 r6, r2                                    r6 = r2
    mov64 r7, r1                                    r7 = r1
    ldxdw r1, [r6+0x28]                     
    ldxdw r4, [r1+0x18]                     
    ldxdw r1, [r6+0x20]                     
    lddw r2, 0x100063d63 --> b"["                   r2 load str located at 4295376227
    mov64 r3, 1                                     r3 = 1 as i32 as i64 as u64
    callx r4                                
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    stxb [r7+0x9], r1                       
    stxb [r7+0x8], r0                       
    stxdw [r7+0x0], r6                      
    exit                                    

function_46176:
    ldxb r1, [r1+0x0]                       
    jne r1, 0, lbb_46183                            if r1 != (0 as i32 as i64 as u64) { pc += 5 }
    mov64 r1, r2                                    r1 = r2
    lddw r2, 0x100063e9a --> b"false"               r2 load str located at 4295376538
    mov64 r3, 5                                     r3 = 5 as i32 as i64 as u64
    ja lbb_46187                                    if true { pc += 4 }
lbb_46183:
    mov64 r1, r2                                    r1 = r2
    lddw r2, 0x10005fbd8 --> b"true"                r2 load str located at 4295359448
    mov64 r3, 4                                     r3 = 4 as i32 as i64 as u64
lbb_46187:
    call function_45728                     
    exit                                    

function_46189:
    mov64 r9, r2                                    r9 = r2
    mov64 r7, r1                                    r7 = r1
    ldxdw r6, [r3+0x20]                     
    ldxdw r1, [r3+0x28]                     
    stxdw [r10-0x40], r1                    
    ldxdw r3, [r1+0x20]                     
    mov64 r1, r6                                    r1 = r6
    mov64 r2, 34                                    r2 = 34 as i32 as i64 as u64
    stxdw [r10-0x28], r3                    
    callx r3                                
    mov64 r8, 1                                     r8 = 1 as i32 as i64 as u64
    jne r0, 0, lbb_46410                            if r0 != (0 as i32 as i64 as u64) { pc += 209 }
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
    jeq r9, 0, lbb_46398                            if r9 == (0 as i32 as i64 as u64) { pc += 194 }
    mov64 r1, r7                                    r1 = r7
    stxdw [r10-0x58], r9                    
    add64 r1, r9                                    r1 += r9   ///  r1 = r1.wrapping_add(r9)
    stxdw [r10-0x50], r1                    
    mov64 r9, 0                                     r9 = 0 as i32 as i64 as u64
    mov64 r3, r7                                    r3 = r7
    mov64 r8, 0                                     r8 = 0 as i32 as i64 as u64
    stxdw [r10-0x60], r7                    
    ja lbb_46220                                    if true { pc += 7 }
lbb_46213:
    add64 r9, r8                                    r9 += r8   ///  r9 = r9.wrapping_add(r8)
lbb_46214:
    ldxdw r1, [r10-0x30]                    
    sub64 r8, r1                                    r8 -= r1   ///  r8 = r8.wrapping_sub(r1)
    ldxdw r3, [r10-0x38]                    
    add64 r8, r3                                    r8 += r3   ///  r8 = r8.wrapping_add(r3)
    ldxdw r1, [r10-0x50]                    
    jeq r3, r1, lbb_46387                           if r3 == r1 { pc += 167 }
lbb_46220:
    ldxb r0, [r3+0x0]                       
    mov64 r1, r0                                    r1 = r0
    lsh64 r1, 56                                    r1 <<= 56   ///  r1 = r1.wrapping_shl(56)
    arsh64 r1, 56                                   r1 >>= 56 (signed)   ///  r1 = (r1 as i64).wrapping_shr(56)
    stxdw [r10-0x30], r3                    
    jsgt r1, -1, lbb_46263                          if (r1 as i64) > (-1 as i32 as i64) { pc += 37 }
    mov64 r1, r3                                    r1 = r3
    add64 r1, 2                                     r1 += 2   ///  r1 = r1.wrapping_add(2 as i32 as i64 as u64)
    stxdw [r10-0x38], r1                    
    ldxb r1, [r3+0x1]                       
    and64 r1, 63                                    r1 &= 63   ///  r1 = r1.and(63)
    mov64 r3, r0                                    r3 = r0
    and64 r3, 31                                    r3 &= 31   ///  r3 = r3.and(31)
    mov64 r2, r3                                    r2 = r3
    lsh64 r2, 6                                     r2 <<= 6   ///  r2 = r2.wrapping_shl(6)
    or64 r2, r1                                     r2 |= r1   ///  r2 = r2.or(r1)
    jgt r0, 223, lbb_46238                          if r0 > (223 as i32 as i64 as u64) { pc += 1 }
    ja lbb_46266                                    if true { pc += 28 }
lbb_46238:
    lsh64 r1, 6                                     r1 <<= 6   ///  r1 = r1.wrapping_shl(6)
    ldxdw r5, [r10-0x30]                    
    ldxb r4, [r5+0x2]                       
    and64 r4, 63                                    r4 &= 63   ///  r4 = r4.and(63)
    or64 r1, r4                                     r1 |= r4   ///  r1 = r1.or(r4)
    add64 r5, 3                                     r5 += 3   ///  r5 = r5.wrapping_add(3 as i32 as i64 as u64)
    stxdw [r10-0x38], r5                    
    mov64 r4, r3                                    r4 = r3
    lsh64 r4, 12                                    r4 <<= 12   ///  r4 = r4.wrapping_shl(12)
    mov64 r2, r1                                    r2 = r1
    or64 r2, r4                                     r2 |= r4   ///  r2 = r2.or(r4)
    mov64 r4, 240                                   r4 = 240 as i32 as i64 as u64
    jgt r4, r0, lbb_46266                           if r4 > r0 { pc += 15 }
    lsh64 r1, 6                                     r1 <<= 6   ///  r1 = r1.wrapping_shl(6)
    ldxdw r4, [r10-0x30]                    
    ldxb r2, [r4+0x3]                       
    and64 r2, 63                                    r2 &= 63   ///  r2 = r2.and(63)
    or64 r1, r2                                     r1 |= r2   ///  r1 = r1.or(r2)
    lsh64 r3, 18                                    r3 <<= 18   ///  r3 = r3.wrapping_shl(18)
    and64 r3, 1835008                               r3 &= 1835008   ///  r3 = r3.and(1835008)
    or64 r1, r3                                     r1 |= r3   ///  r1 = r1.or(r3)
    add64 r4, 4                                     r4 += 4   ///  r4 = r4.wrapping_add(4 as i32 as i64 as u64)
    stxdw [r10-0x38], r4                    
    mov64 r2, r1                                    r2 = r1
    ja lbb_46266                                    if true { pc += 3 }
lbb_46263:
    add64 r3, 1                                     r3 += 1   ///  r3 = r3.wrapping_add(1 as i32 as i64 as u64)
    stxdw [r10-0x38], r3                    
    mov64 r2, r0                                    r2 = r0
lbb_46266:
    mov64 r1, r10                                   r1 = r10
    add64 r1, -28                                   r1 += -28   ///  r1 = r1.wrapping_add(-28 as i32 as i64 as u64)
    stxdw [r10-0x48], r2                    
    mov64 r3, 65537                                 r3 = 65537 as i32 as i64 as u64
    call function_43780                     
    ldxb r1, [r10-0x1c]                     
    jeq r1, 128, lbb_46214                          if r1 == (128 as i32 as i64 as u64) { pc += -59 }
    ldxb r1, [r10-0x12]                     
    ldxb r2, [r10-0x11]                     
    sub64 r2, r1                                    r2 -= r1   ///  r2 = r2.wrapping_sub(r1)
    and64 r2, 255                                   r2 &= 255   ///  r2 = r2.and(255)
    jeq r2, 1, lbb_46214                            if r2 == (1 as i32 as i64 as u64) { pc += -64 }
    ldxdw r2, [r10-0x58]                    
    jgt r9, r8, lbb_46335                           if r9 > r8 { pc += 55 }
    jeq r9, 0, lbb_46291                            if r9 == (0 as i32 as i64 as u64) { pc += 10 }
    jgt r2, r9, lbb_46284                           if r2 > r9 { pc += 2 }
    jeq r9, r2, lbb_46291                           if r9 == r2 { pc += 8 }
    ja lbb_46335                                    if true { pc += 51 }
lbb_46284:
    mov64 r1, r7                                    r1 = r7
    add64 r1, r9                                    r1 += r9   ///  r1 = r1.wrapping_add(r9)
    ldxb r1, [r1+0x0]                       
    lsh64 r1, 56                                    r1 <<= 56   ///  r1 = r1.wrapping_shl(56)
    arsh64 r1, 56                                   r1 >>= 56 (signed)   ///  r1 = (r1 as i64).wrapping_shr(56)
    mov64 r3, -64                                   r3 = -64 as i32 as i64 as u64
    jsgt r3, r1, lbb_46335                          if (r3 as i64) > (r1 as i64) { pc += 44 }
lbb_46291:
    jeq r8, 0, lbb_46295                            if r8 == (0 as i32 as i64 as u64) { pc += 3 }
    jgt r2, r8, lbb_46329                           if r2 > r8 { pc += 36 }
    jeq r8, r2, lbb_46295                           if r8 == r2 { pc += 1 }
    ja lbb_46335                                    if true { pc += 40 }
lbb_46295:
    mov64 r2, r7                                    r2 = r7
    add64 r2, r9                                    r2 += r9   ///  r2 = r2.wrapping_add(r9)
    mov64 r3, r8                                    r3 = r8
    sub64 r3, r9                                    r3 -= r9   ///  r3 = r3.wrapping_sub(r9)
    ldxdw r1, [r10-0x40]                    
    ldxdw r4, [r1+0x18]                     
    mov64 r1, r6                                    r1 = r6
    callx r4                                
    jne r0, 0, lbb_46385                            if r0 != (0 as i32 as i64 as u64) { pc += 81 }
    ldxw r1, [r10-0x14]                     
    stxw [r10-0x8], r1                      
    ldxdw r1, [r10-0x1c]                    
    stxdw [r10-0x10], r1                    
    and64 r1, 255                                   r1 &= 255   ///  r1 = r1.and(255)
    jne r1, 128, lbb_46312                          if r1 != (128 as i32 as i64 as u64) { pc += 2 }
    mov64 r7, 128                                   r7 = 128 as i32 as i64 as u64
    ja lbb_46363                                    if true { pc += 51 }
lbb_46312:
    ldxb r7, [r10-0x5]                      
    ldxb r1, [r10-0x6]                      
lbb_46314:
    jge r1, r7, lbb_46372                           if r1 >= r7 { pc += 57 }
    mov64 r9, r1                                    r9 = r1
    add64 r9, 1                                     r9 += 1   ///  r9 = r9.wrapping_add(1 as i32 as i64 as u64)
    stxb [r10-0x6], r9                      
    jgt r1, 9, lbb_46350                            if r1 > (9 as i32 as i64 as u64) { pc += 31 }
    mov64 r2, r10                                   r2 = r10
    add64 r2, -16                                   r2 += -16   ///  r2 = r2.wrapping_add(-16 as i32 as i64 as u64)
    add64 r2, r1                                    r2 += r1   ///  r2 = r2.wrapping_add(r1)
    ldxb r2, [r2+0x0]                       
    mov64 r1, r6                                    r1 = r6
    ldxdw r3, [r10-0x28]                    
    callx r3                                
    mov64 r1, r9                                    r1 = r9
    jne r0, 0, lbb_46385                            if r0 != (0 as i32 as i64 as u64) { pc += 57 }
    ja lbb_46314                                    if true { pc += -15 }
lbb_46329:
    mov64 r1, r7                                    r1 = r7
    add64 r1, r8                                    r1 += r8   ///  r1 = r1.wrapping_add(r8)
    ldxb r1, [r1+0x0]                       
    lsh64 r1, 56                                    r1 <<= 56   ///  r1 = r1.wrapping_shl(56)
    arsh64 r1, 56                                   r1 >>= 56 (signed)   ///  r1 = (r1 as i64).wrapping_shr(56)
    jsgt r1, -65, lbb_46295                         if (r1 as i64) > (-65 as i32 as i64) { pc += -40 }
lbb_46335:
    mov64 r1, r7                                    r1 = r7
    mov64 r3, r9                                    r3 = r9
    mov64 r4, r8                                    r4 = r8
    lddw r5, 0x100067378 --> b"\x00\x00\x00\x00 =\x06\x00\x1b\x00\x00\x00\x00\x00\x00\x00.\x09\x00\x00"\…        r5 load str located at 4295390072
    call function_46980                     
    syscall [invalid]                       
lbb_46342:
    ldxb r1, [r10-0x6]                      
    ldxb r2, [r10-0x5]                      
    jge r1, r2, lbb_46372                           if r1 >= r2 { pc += 27 }
    mov64 r2, r1                                    r2 = r1
    add64 r2, 1                                     r2 += 1   ///  r2 = r2.wrapping_add(1 as i32 as i64 as u64)
    stxb [r10-0x6], r2                      
    mov64 r2, 10                                    r2 = 10 as i32 as i64 as u64
    jgt r2, r1, lbb_46355                           if r2 > r1 { pc += 5 }
lbb_46350:
    mov64 r2, 10                                    r2 = 10 as i32 as i64 as u64
    lddw r3, 0x100067540 --> b"\x00\x00\x00\x00;F\x06\x00\x1a\x00\x00\x00\x00\x00\x00\x00b\x00\x00\x00#\…        r3 load str located at 4295390528
    call function_44272                     
    syscall [invalid]                       
lbb_46355:
    mov64 r2, r10                                   r2 = r10
    add64 r2, -16                                   r2 += -16   ///  r2 = r2.wrapping_add(-16 as i32 as i64 as u64)
    add64 r2, r1                                    r2 += r1   ///  r2 = r2.wrapping_add(r1)
    ldxb r2, [r2+0x0]                       
lbb_46359:
    mov64 r1, r6                                    r1 = r6
    ldxdw r3, [r10-0x28]                    
    callx r3                                
    jne r0, 0, lbb_46385                            if r0 != (0 as i32 as i64 as u64) { pc += 22 }
lbb_46363:
    mov64 r1, r7                                    r1 = r7
    and64 r1, 255                                   r1 &= 255   ///  r1 = r1.and(255)
    jeq r1, 128, lbb_46367                          if r1 == (128 as i32 as i64 as u64) { pc += 1 }
    ja lbb_46342                                    if true { pc += -25 }
lbb_46367:
    mov64 r7, 0                                     r7 = 0 as i32 as i64 as u64
    stxw [r10-0x8], r7                      
    ldxw r2, [r10-0xc]                      
    stxdw [r10-0x10], r7                    
    ja lbb_46359                                    if true { pc += -13 }
lbb_46372:
    mov64 r9, 1                                     r9 = 1 as i32 as i64 as u64
    ldxdw r7, [r10-0x60]                    
    mov64 r1, 128                                   r1 = 128 as i32 as i64 as u64
    ldxdw r2, [r10-0x48]                    
    jgt r1, r2, lbb_46213                           if r1 > r2 { pc += -164 }
    mov64 r9, 2                                     r9 = 2 as i32 as i64 as u64
    mov64 r1, 2048                                  r1 = 2048 as i32 as i64 as u64
    jgt r1, r2, lbb_46213                           if r1 > r2 { pc += -167 }
    mov64 r9, 3                                     r9 = 3 as i32 as i64 as u64
    mov64 r1, 65536                                 r1 = 65536 as i32 as i64 as u64
    jgt r1, r2, lbb_46213                           if r1 > r2 { pc += -170 }
    mov64 r9, 4                                     r9 = 4 as i32 as i64 as u64
    ja lbb_46213                                    if true { pc += -172 }
lbb_46385:
    mov64 r8, 1                                     r8 = 1 as i32 as i64 as u64
    ja lbb_46410                                    if true { pc += 23 }
lbb_46387:
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    ldxdw r4, [r10-0x58]                    
    mov64 r3, r4                                    r3 = r4
    mov64 r8, 1                                     r8 = 1 as i32 as i64 as u64
    jeq r9, 0, lbb_46398                            if r9 == (0 as i32 as i64 as u64) { pc += 6 }
    jgt r4, r9, lbb_46412                           if r4 > r9 { pc += 19 }
    mov64 r3, r4                                    r3 = r4
    sub64 r3, r9                                    r3 -= r9   ///  r3 = r3.wrapping_sub(r9)
    mov64 r1, r9                                    r1 = r9
    jeq r4, r9, lbb_46398                           if r4 == r9 { pc += 1 }
    ja lbb_46421                                    if true { pc += 23 }
lbb_46398:
    add64 r7, r1                                    r7 += r1   ///  r7 = r7.wrapping_add(r1)
    ldxdw r1, [r10-0x40]                    
    ldxdw r4, [r1+0x18]                     
    mov64 r1, r6                                    r1 = r6
    mov64 r2, r7                                    r2 = r7
    callx r4                                
    jne r0, 0, lbb_46410                            if r0 != (0 as i32 as i64 as u64) { pc += 5 }
    mov64 r1, r6                                    r1 = r6
    mov64 r2, 34                                    r2 = 34 as i32 as i64 as u64
    ldxdw r3, [r10-0x28]                    
    callx r3                                
    mov64 r8, r0                                    r8 = r0
lbb_46410:
    mov64 r0, r8                                    r0 = r8
    exit                                    
lbb_46412:
    mov64 r3, r4                                    r3 = r4
    sub64 r3, r9                                    r3 -= r9   ///  r3 = r3.wrapping_sub(r9)
    mov64 r1, r7                                    r1 = r7
    add64 r1, r9                                    r1 += r9   ///  r1 = r1.wrapping_add(r9)
    ldxb r2, [r1+0x0]                       
    lsh64 r2, 56                                    r2 <<= 56   ///  r2 = r2.wrapping_shl(56)
    arsh64 r2, 56                                   r2 >>= 56 (signed)   ///  r2 = (r2 as i64).wrapping_shr(56)
    mov64 r1, r9                                    r1 = r9
    jsgt r2, -65, lbb_46398                         if (r2 as i64) > (-65 as i32 as i64) { pc += -23 }
lbb_46421:
    mov64 r1, r7                                    r1 = r7
    mov64 r2, r4                                    r2 = r4
    mov64 r3, r9                                    r3 = r9
    lddw r5, 0x100067360 --> b"\x00\x00\x00\x00 =\x06\x00\x1b\x00\x00\x00\x00\x00\x00\x005\x09\x00\x00\x…        r5 load str located at 4295390048
    call function_46980                     
    syscall [invalid]                       

function_46428:
    mov64 r4, r2                                    r4 = r2
    mov64 r2, r1                                    r2 = r1
    mov64 r1, r3                                    r1 = r3
    mov64 r3, r4                                    r3 = r4
    call function_45728                     
    exit                                    

function_46434:
    mov64 r8, r1                                    r8 = r1
    ldxdw r6, [r2+0x20]                     
    ldxdw r1, [r2+0x28]                     
    ldxdw r9, [r1+0x20]                     
    mov64 r1, r6                                    r1 = r6
    mov64 r2, 39                                    r2 = 39 as i32 as i64 as u64
    callx r9                                
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    jne r0, 0, lbb_46506                            if r0 != (0 as i32 as i64 as u64) { pc += 63 }
    ldxw r2, [r8+0x0]                       
    mov64 r1, r10                                   r1 = r10
    add64 r1, -16                                   r1 += -16   ///  r1 = r1.wrapping_add(-16 as i32 as i64 as u64)
    mov64 r3, 257                                   r3 = 257 as i32 as i64 as u64
    call function_43780                     
    ldxb r1, [r10-0x10]                     
    jne r1, 128, lbb_46453                          if r1 != (128 as i32 as i64 as u64) { pc += 3 }
    mov64 r7, 128                                   r7 = 128 as i32 as i64 as u64
    mov64 r8, 10                                    r8 = 10 as i32 as i64 as u64
    ja lbb_46488                                    if true { pc += 35 }
lbb_46453:
    ldxb r7, [r10-0x5]                      
    ldxb r1, [r10-0x6]                      
lbb_46455:
    jge r1, r7, lbb_46502                           if r1 >= r7 { pc += 46 }
    mov64 r8, r1                                    r8 = r1
    add64 r8, 1                                     r8 += 1   ///  r8 = r8.wrapping_add(1 as i32 as i64 as u64)
    stxb [r10-0x6], r8                      
    jgt r1, 9, lbb_46476                            if r1 > (9 as i32 as i64 as u64) { pc += 16 }
    mov64 r2, r10                                   r2 = r10
    add64 r2, -16                                   r2 += -16   ///  r2 = r2.wrapping_add(-16 as i32 as i64 as u64)
    add64 r2, r1                                    r2 += r1   ///  r2 = r2.wrapping_add(r1)
    ldxb r2, [r2+0x0]                       
    mov64 r1, r6                                    r1 = r6
    callx r9                                
    mov64 r1, r8                                    r1 = r8
    jne r0, 0, lbb_46500                            if r0 != (0 as i32 as i64 as u64) { pc += 32 }
    ja lbb_46455                                    if true { pc += -14 }
lbb_46469:
    ldxb r1, [r10-0x6]                      
    ldxb r2, [r10-0x5]                      
    jge r1, r2, lbb_46502                           if r1 >= r2 { pc += 30 }
    mov64 r2, r1                                    r2 = r1
    add64 r2, 1                                     r2 += 1   ///  r2 = r2.wrapping_add(1 as i32 as i64 as u64)
    stxb [r10-0x6], r2                      
    jgt r8, r1, lbb_46481                           if r8 > r1 { pc += 5 }
lbb_46476:
    mov64 r2, 10                                    r2 = 10 as i32 as i64 as u64
    lddw r3, 0x100067540 --> b"\x00\x00\x00\x00;F\x06\x00\x1a\x00\x00\x00\x00\x00\x00\x00b\x00\x00\x00#\…        r3 load str located at 4295390528
    call function_44272                     
    syscall [invalid]                       
lbb_46481:
    mov64 r2, r10                                   r2 = r10
    add64 r2, -16                                   r2 += -16   ///  r2 = r2.wrapping_add(-16 as i32 as i64 as u64)
    add64 r2, r1                                    r2 += r1   ///  r2 = r2.wrapping_add(r1)
    ldxb r2, [r2+0x0]                       
    mov64 r1, r6                                    r1 = r6
    callx r9                                
    jne r0, 0, lbb_46500                            if r0 != (0 as i32 as i64 as u64) { pc += 12 }
lbb_46488:
    mov64 r1, r7                                    r1 = r7
    and64 r1, 255                                   r1 &= 255   ///  r1 = r1.and(255)
    jeq r1, 128, lbb_46492                          if r1 == (128 as i32 as i64 as u64) { pc += 1 }
    ja lbb_46469                                    if true { pc += -23 }
lbb_46492:
    mov64 r7, 0                                     r7 = 0 as i32 as i64 as u64
    stxw [r10-0x8], r7                      
    ldxw r2, [r10-0xc]                      
    stxdw [r10-0x10], r7                    
    mov64 r1, r6                                    r1 = r6
    callx r9                                
    jne r0, 0, lbb_46500                            if r0 != (0 as i32 as i64 as u64) { pc += 1 }
    ja lbb_46488                                    if true { pc += -12 }
lbb_46500:
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    ja lbb_46506                                    if true { pc += 4 }
lbb_46502:
    mov64 r1, r6                                    r1 = r6
    mov64 r2, 39                                    r2 = 39 as i32 as i64 as u64
    callx r9                                
    mov64 r1, r0                                    r1 = r0
lbb_46506:
    mov64 r0, r1                                    r0 = r1
    exit                                    

function_46508:
    mov64 r6, r3                                    r6 = r3
    stxdw [r10-0x60], r1                    
    stxdw [r10-0x58], r2                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -88                                   r1 += -88   ///  r1 = r1.wrapping_add(-88 as i32 as i64 as u64)
    stxdw [r10-0x10], r1                    
    lddw r1, 0x10005df58 --> b"\xbf#\x00\x00\x00\x00\x00\x00y\x11\x00\x00\x00\x00\x00\x00\xb7\x02\x00\x0…        r1 load str located at 4295352152
    stxdw [r10-0x8], r1                     
    stxdw [r10-0x18], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -96                                   r1 += -96   ///  r1 = r1.wrapping_add(-96 as i32 as i64 as u64)
    stxdw [r10-0x20], r1                    
    mov64 r7, r10                                   r7 = r10
    add64 r7, -80                                   r7 += -80   ///  r7 = r7.wrapping_add(-80 as i32 as i64 as u64)
    mov64 r4, r10                                   r4 = r10
    add64 r4, -32                                   r4 += -32   ///  r4 = r4.wrapping_add(-32 as i32 as i64 as u64)
    mov64 r1, r7                                    r1 = r7
    lddw r2, 0x100067390 --> b"\x00\x00"            r2 load str located at 4295390096
    mov64 r3, 2                                     r3 = 2 as i32 as i64 as u64
    mov64 r5, 2                                     r5 = 2 as i32 as i64 as u64
    call function_45339                     
    mov64 r1, r7                                    r1 = r7
    mov64 r2, r6                                    r2 = r6
    call function_44240                     
    syscall [invalid]                       

function_46535:
    mov64 r6, r3                                    r6 = r3
    stxdw [r10-0x60], r1                    
    stxdw [r10-0x58], r2                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -88                                   r1 += -88   ///  r1 = r1.wrapping_add(-88 as i32 as i64 as u64)
    stxdw [r10-0x10], r1                    
    lddw r1, 0x10005df58 --> b"\xbf#\x00\x00\x00\x00\x00\x00y\x11\x00\x00\x00\x00\x00\x00\xb7\x02\x00\x0…        r1 load str located at 4295352152
    stxdw [r10-0x8], r1                     
    stxdw [r10-0x18], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -96                                   r1 += -96   ///  r1 = r1.wrapping_add(-96 as i32 as i64 as u64)
    stxdw [r10-0x20], r1                    
    mov64 r7, r10                                   r7 = r10
    add64 r7, -80                                   r7 += -80   ///  r7 = r7.wrapping_add(-80 as i32 as i64 as u64)
    mov64 r4, r10                                   r4 = r10
    add64 r4, -32                                   r4 += -32   ///  r4 = r4.wrapping_add(-32 as i32 as i64 as u64)
    mov64 r1, r7                                    r1 = r7
    lddw r2, 0x1000673b0 --> b"\x00\x00"            r2 load str located at 4295390128
    mov64 r3, 2                                     r3 = 2 as i32 as i64 as u64
    mov64 r5, 2                                     r5 = 2 as i32 as i64 as u64
    call function_45339                     
    mov64 r1, r7                                    r1 = r7
    mov64 r2, r6                                    r2 = r6
    call function_44240                     
    syscall [invalid]                       

function_46562:
    mov64 r6, r3                                    r6 = r3
    stxdw [r10-0x60], r1                    
    stxdw [r10-0x58], r2                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -88                                   r1 += -88   ///  r1 = r1.wrapping_add(-88 as i32 as i64 as u64)
    stxdw [r10-0x10], r1                    
    lddw r1, 0x10005df58 --> b"\xbf#\x00\x00\x00\x00\x00\x00y\x11\x00\x00\x00\x00\x00\x00\xb7\x02\x00\x0…        r1 load str located at 4295352152
    stxdw [r10-0x8], r1                     
    stxdw [r10-0x18], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -96                                   r1 += -96   ///  r1 = r1.wrapping_add(-96 as i32 as i64 as u64)
    stxdw [r10-0x20], r1                    
    mov64 r7, r10                                   r7 = r10
    add64 r7, -80                                   r7 += -80   ///  r7 = r7.wrapping_add(-80 as i32 as i64 as u64)
    mov64 r4, r10                                   r4 = r10
    add64 r4, -32                                   r4 += -32   ///  r4 = r4.wrapping_add(-32 as i32 as i64 as u64)
    mov64 r1, r7                                    r1 = r7
    lddw r2, 0x1000673d0 --> b"\x00\x00"            r2 load str located at 4295390160
    mov64 r3, 2                                     r3 = 2 as i32 as i64 as u64
    mov64 r5, 2                                     r5 = 2 as i32 as i64 as u64
    call function_45339                     
    mov64 r1, r7                                    r1 = r7
    mov64 r2, r6                                    r2 = r6
    call function_44240                     
    syscall [invalid]                       

function_46589:
    stxdw [r10-0x8], r1                     
    mov64 r1, r3                                    r1 = r3
    add64 r1, -15                                   r1 += -15   ///  r1 = r1.wrapping_add(-15 as i32 as i64 as u64)
    mov64 r4, 0                                     r4 = 0 as i32 as i64 as u64
    mov64 r5, 1                                     r5 = 1 as i32 as i64 as u64
    jgt r1, r3, lbb_46596                           if r1 > r3 { pc += 1 }
    mov64 r5, 0                                     r5 = 0 as i32 as i64 as u64
lbb_46596:
    jne r5, 0, lbb_46598                            if r5 != (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r4, r1                                    r4 = r1
lbb_46598:
    jeq r3, 0, lbb_46784                            if r3 == (0 as i32 as i64 as u64) { pc += 185 }
    mov64 r5, r2                                    r5 = r2
    add64 r5, 7                                     r5 += 7   ///  r5 = r5.wrapping_add(7 as i32 as i64 as u64)
    and64 r5, -8                                    r5 &= -8   ///  r5 = r5.and(-8)
    sub64 r5, r2                                    r5 -= r2   ///  r5 = r5.wrapping_sub(r2)
    mov64 r0, 0                                     r0 = 0 as i32 as i64 as u64
    lddw r8, 0x8080808080808080                     r8 load str located at -9187201950435737472
    mov64 r6, 0                                     r6 = 0 as i32 as i64 as u64
    ja lbb_46622                                    if true { pc += 14 }
lbb_46608:
    mov64 r1, r2                                    r1 = r2
    add64 r1, r7                                    r1 += r7   ///  r1 = r1.wrapping_add(r7)
    ldxb r1, [r1+0x0]                       
    lsh64 r1, 56                                    r1 <<= 56   ///  r1 = r1.wrapping_shl(56)
    arsh64 r1, 56                                   r1 >>= 56 (signed)   ///  r1 = (r1 as i64).wrapping_shr(56)
    mov64 r8, 1                                     r8 = 1 as i32 as i64 as u64
    mov64 r9, 1                                     r9 = 1 as i32 as i64 as u64
    jsgt r1, -65, lbb_46778                         if (r1 as i64) > (-65 as i32 as i64) { pc += 162 }
lbb_46616:
    add64 r7, 1                                     r7 += 1   ///  r7 = r7.wrapping_add(1 as i32 as i64 as u64)
    mov64 r6, r7                                    r6 = r7
    lddw r8, 0x8080808080808080                     r8 load str located at -9187201950435737472
    jgt r3, r6, lbb_46622                           if r3 > r6 { pc += 1 }
    ja lbb_46784                                    if true { pc += 162 }
lbb_46622:
    mov64 r1, r2                                    r1 = r2
    add64 r1, r6                                    r1 += r6   ///  r1 = r1.wrapping_add(r6)
    ldxb r7, [r1+0x0]                       
    mov64 r1, r7                                    r1 = r7
    lsh64 r1, 56                                    r1 <<= 56   ///  r1 = r1.wrapping_shl(56)
    arsh64 r1, 56                                   r1 >>= 56 (signed)   ///  r1 = (r1 as i64).wrapping_shr(56)
    jsgt r0, r1, lbb_46657                          if (r0 as i64) > (r1 as i64) { pc += 28 }
    mov64 r1, r5                                    r1 = r5
    sub64 r1, r6                                    r1 -= r6   ///  r1 = r1.wrapping_sub(r6)
    and64 r1, 7                                     r1 &= 7   ///  r1 = r1.and(7)
    jne r1, 0, lbb_46654                            if r1 != (0 as i32 as i64 as u64) { pc += 21 }
    jge r6, r4, lbb_46641                           if r6 >= r4 { pc += 7 }
lbb_46634:
    mov64 r1, r2                                    r1 = r2
    add64 r1, r6                                    r1 += r6   ///  r1 = r1.wrapping_add(r6)
    ldxdw r7, [r1+0x0]                      
    ldxdw r1, [r1+0x8]                      
    or64 r1, r7                                     r1 |= r7   ///  r1 = r1.or(r7)
    and64 r1, r8                                    r1 &= r8   ///  r1 = r1.and(r8)
    jeq r1, 0, lbb_46651                            if r1 == (0 as i32 as i64 as u64) { pc += 10 }
lbb_46641:
    jge r6, r3, lbb_46655                           if r6 >= r3 { pc += 13 }
lbb_46642:
    mov64 r1, r2                                    r1 = r2
    add64 r1, r6                                    r1 += r6   ///  r1 = r1.wrapping_add(r6)
    ldxb r1, [r1+0x0]                       
    lsh64 r1, 56                                    r1 <<= 56   ///  r1 = r1.wrapping_shl(56)
    arsh64 r1, 56                                   r1 >>= 56 (signed)   ///  r1 = (r1 as i64).wrapping_shr(56)
    jsgt r0, r1, lbb_46655                          if (r0 as i64) > (r1 as i64) { pc += 7 }
    add64 r6, 1                                     r6 += 1   ///  r6 = r6.wrapping_add(1 as i32 as i64 as u64)
    jgt r3, r6, lbb_46642                           if r3 > r6 { pc += -8 }
    ja lbb_46784                                    if true { pc += 133 }
lbb_46651:
    add64 r6, 16                                    r6 += 16   ///  r6 = r6.wrapping_add(16 as i32 as i64 as u64)
    jgt r4, r6, lbb_46634                           if r4 > r6 { pc += -19 }
    ja lbb_46641                                    if true { pc += -13 }
lbb_46654:
    add64 r6, 1                                     r6 += 1   ///  r6 = r6.wrapping_add(1 as i32 as i64 as u64)
lbb_46655:
    jgt r3, r6, lbb_46622                           if r3 > r6 { pc += -34 }
    ja lbb_46784                                    if true { pc += 127 }
lbb_46657:
    lddw r1, 0x100063ef6 --> b"\x01\x01\x01\x01\x01\x01\x01\x01\x01\x01\x01\x01\x01\x01\x01\x01\x01\x01\…        r1 load str located at 4295376630
    add64 r1, r7                                    r1 += r7   ///  r1 = r1.wrapping_add(r7)
    ldxb r1, [r1+0x0]                       
    jeq r1, 4, lbb_46671                            if r1 == (4 as i32 as i64 as u64) { pc += 9 }
    jeq r1, 3, lbb_46691                            if r1 == (3 as i32 as i64 as u64) { pc += 28 }
    mov64 r8, 1                                     r8 = 1 as i32 as i64 as u64
    mov64 r9, 1                                     r9 = 1 as i32 as i64 as u64
    jne r1, 2, lbb_46778                            if r1 != (2 as i32 as i64 as u64) { pc += 112 }
    mov64 r9, 0                                     r9 = 0 as i32 as i64 as u64
    mov64 r7, r6                                    r7 = r6
    add64 r7, 1                                     r7 += 1   ///  r7 = r7.wrapping_add(1 as i32 as i64 as u64)
    jgt r3, r7, lbb_46608                           if r3 > r7 { pc += -62 }
    ja lbb_46778                                    if true { pc += 107 }
lbb_46671:
    mov64 r1, r6                                    r1 = r6
    add64 r1, 1                                     r1 += 1   ///  r1 = r1.wrapping_add(1 as i32 as i64 as u64)
    mov64 r9, 0                                     r9 = 0 as i32 as i64 as u64
    jgt r3, r1, lbb_46676                           if r3 > r1 { pc += 1 }
    ja lbb_46778                                    if true { pc += 102 }
lbb_46676:
    mov64 r8, r2                                    r8 = r2
    add64 r8, r1                                    r8 += r1   ///  r8 = r8.wrapping_add(r1)
    ldxb r1, [r8+0x0]                       
    lsh64 r1, 56                                    r1 <<= 56   ///  r1 = r1.wrapping_shl(56)
    arsh64 r1, 56                                   r1 >>= 56 (signed)   ///  r1 = (r1 as i64).wrapping_shr(56)
    jeq r7, 240, lbb_46714                          if r7 == (240 as i32 as i64 as u64) { pc += 32 }
    jeq r7, 244, lbb_46726                          if r7 == (244 as i32 as i64 as u64) { pc += 43 }
    add64 r7, 15                                    r7 += 15   ///  r7 = r7.wrapping_add(15 as i32 as i64 as u64)
    and64 r7, 255                                   r7 &= 255   ///  r7 = r7.and(255)
    mov64 r8, 1                                     r8 = 1 as i32 as i64 as u64
    mov64 r9, 1                                     r9 = 1 as i32 as i64 as u64
    jgt r7, 2, lbb_46778                            if r7 > (2 as i32 as i64 as u64) { pc += 90 }
    mov64 r7, -64                                   r7 = -64 as i32 as i64 as u64
    jsgt r7, r1, lbb_46729                          if (r7 as i64) > (r1 as i64) { pc += 39 }
    ja lbb_46778                                    if true { pc += 87 }
lbb_46691:
    mov64 r9, 0                                     r9 = 0 as i32 as i64 as u64
    mov64 r1, r6                                    r1 = r6
    add64 r1, 1                                     r1 += 1   ///  r1 = r1.wrapping_add(1 as i32 as i64 as u64)
    jgt r3, r1, lbb_46696                           if r3 > r1 { pc += 1 }
    ja lbb_46778                                    if true { pc += 82 }
lbb_46696:
    mov64 r8, r2                                    r8 = r2
    add64 r8, r1                                    r8 += r1   ///  r8 = r8.wrapping_add(r1)
    ldxb r1, [r8+0x0]                       
    lsh64 r1, 56                                    r1 <<= 56   ///  r1 = r1.wrapping_shl(56)
    arsh64 r1, 56                                   r1 >>= 56 (signed)   ///  r1 = (r1 as i64).wrapping_shr(56)
    jeq r7, 224, lbb_46721                          if r7 == (224 as i32 as i64 as u64) { pc += 19 }
    jeq r7, 237, lbb_46761                          if r7 == (237 as i32 as i64 as u64) { pc += 58 }
    mov64 r8, r7                                    r8 = r7
    add64 r8, 31                                    r8 += 31   ///  r8 = r8.wrapping_add(31 as i32 as i64 as u64)
    and64 r8, 255                                   r8 &= 255   ///  r8 = r8.and(255)
    mov64 r9, 12                                    r9 = 12 as i32 as i64 as u64
    jgt r9, r8, lbb_46709                           if r9 > r8 { pc += 1 }
    ja lbb_46754                                    if true { pc += 45 }
lbb_46709:
    mov64 r8, 1                                     r8 = 1 as i32 as i64 as u64
    mov64 r9, 1                                     r9 = 1 as i32 as i64 as u64
    mov64 r7, -64                                   r7 = -64 as i32 as i64 as u64
    jsgt r7, r1, lbb_46764                          if (r7 as i64) > (r1 as i64) { pc += 51 }
    ja lbb_46778                                    if true { pc += 64 }
lbb_46714:
    add64 r1, 112                                   r1 += 112   ///  r1 = r1.wrapping_add(112 as i32 as i64 as u64)
    and64 r1, 255                                   r1 &= 255   ///  r1 = r1.and(255)
    mov64 r8, 1                                     r8 = 1 as i32 as i64 as u64
    mov64 r9, 1                                     r9 = 1 as i32 as i64 as u64
    mov64 r7, 48                                    r7 = 48 as i32 as i64 as u64
    jgt r7, r1, lbb_46729                           if r7 > r1 { pc += 9 }
    ja lbb_46778                                    if true { pc += 57 }
lbb_46721:
    and64 r1, -32                                   r1 &= -32   ///  r1 = r1.and(-32)
    mov64 r8, 1                                     r8 = 1 as i32 as i64 as u64
    mov64 r9, 1                                     r9 = 1 as i32 as i64 as u64
    jeq r1, -96, lbb_46764                          if r1 == (-96 as i32 as i64 as u64) { pc += 39 }
    ja lbb_46778                                    if true { pc += 52 }
lbb_46726:
    mov64 r8, 1                                     r8 = 1 as i32 as i64 as u64
    mov64 r9, 1                                     r9 = 1 as i32 as i64 as u64
    jsgt r1, -113, lbb_46778                        if (r1 as i64) > (-113 as i32 as i64) { pc += 49 }
lbb_46729:
    mov64 r1, r6                                    r1 = r6
    add64 r1, 2                                     r1 += 2   ///  r1 = r1.wrapping_add(2 as i32 as i64 as u64)
    mov64 r9, 0                                     r9 = 0 as i32 as i64 as u64
    jge r1, r3, lbb_46778                           if r1 >= r3 { pc += 45 }
    mov64 r7, r2                                    r7 = r2
    add64 r7, r1                                    r7 += r1   ///  r7 = r7.wrapping_add(r1)
    mov64 r8, 2                                     r8 = 2 as i32 as i64 as u64
    ldxb r1, [r7+0x0]                       
    lsh64 r1, 56                                    r1 <<= 56   ///  r1 = r1.wrapping_shl(56)
    arsh64 r1, 56                                   r1 >>= 56 (signed)   ///  r1 = (r1 as i64).wrapping_shr(56)
    mov64 r9, 1                                     r9 = 1 as i32 as i64 as u64
    jsgt r1, -65, lbb_46778                         if (r1 as i64) > (-65 as i32 as i64) { pc += 37 }
    mov64 r7, r6                                    r7 = r6
    add64 r7, 3                                     r7 += 3   ///  r7 = r7.wrapping_add(3 as i32 as i64 as u64)
    mov64 r9, 0                                     r9 = 0 as i32 as i64 as u64
    jge r7, r3, lbb_46778                           if r7 >= r3 { pc += 33 }
    mov64 r1, r2                                    r1 = r2
    add64 r1, r7                                    r1 += r7   ///  r1 = r1.wrapping_add(r7)
    mov64 r8, 3                                     r8 = 3 as i32 as i64 as u64
    ldxb r1, [r1+0x0]                       
    lsh64 r1, 56                                    r1 <<= 56   ///  r1 = r1.wrapping_shl(56)
    arsh64 r1, 56                                   r1 >>= 56 (signed)   ///  r1 = (r1 as i64).wrapping_shr(56)
    mov64 r9, 1                                     r9 = 1 as i32 as i64 as u64
    jsgt r1, -65, lbb_46778                         if (r1 as i64) > (-65 as i32 as i64) { pc += 25 }
    ja lbb_46616                                    if true { pc += -138 }
lbb_46754:
    and64 r7, 254                                   r7 &= 254   ///  r7 = r7.and(254)
    mov64 r8, 1                                     r8 = 1 as i32 as i64 as u64
    mov64 r9, 1                                     r9 = 1 as i32 as i64 as u64
    jne r7, 238, lbb_46778                          if r7 != (238 as i32 as i64 as u64) { pc += 20 }
    mov64 r7, -64                                   r7 = -64 as i32 as i64 as u64
    jsgt r7, r1, lbb_46764                          if (r7 as i64) > (r1 as i64) { pc += 4 }
    ja lbb_46778                                    if true { pc += 17 }
lbb_46761:
    mov64 r8, 1                                     r8 = 1 as i32 as i64 as u64
    mov64 r9, 1                                     r9 = 1 as i32 as i64 as u64
    jsgt r1, -97, lbb_46778                         if (r1 as i64) > (-97 as i32 as i64) { pc += 14 }
lbb_46764:
    mov64 r7, r6                                    r7 = r6
    add64 r7, 2                                     r7 += 2   ///  r7 = r7.wrapping_add(2 as i32 as i64 as u64)
    mov64 r9, 0                                     r9 = 0 as i32 as i64 as u64
    jgt r3, r7, lbb_46769                           if r3 > r7 { pc += 1 }
    ja lbb_46778                                    if true { pc += 9 }
lbb_46769:
    mov64 r1, r2                                    r1 = r2
    add64 r1, r7                                    r1 += r7   ///  r1 = r1.wrapping_add(r7)
    mov64 r8, 2                                     r8 = 2 as i32 as i64 as u64
    ldxb r1, [r1+0x0]                       
    lsh64 r1, 56                                    r1 <<= 56   ///  r1 = r1.wrapping_shl(56)
    arsh64 r1, 56                                   r1 >>= 56 (signed)   ///  r1 = (r1 as i64).wrapping_shr(56)
    mov64 r9, 1                                     r9 = 1 as i32 as i64 as u64
    jsgt r1, -65, lbb_46778                         if (r1 as i64) > (-65 as i32 as i64) { pc += 1 }
    ja lbb_46616                                    if true { pc += -162 }
lbb_46778:
    ldxdw r3, [r10-0x8]                     
    stxb [r3+0x11], r8                      
    stxb [r3+0x10], r9                      
    stxdw [r3+0x8], r6                      
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    ja lbb_46789                                    if true { pc += 5 }
lbb_46784:
    ldxdw r1, [r10-0x8]                     
    stxdw [r1+0x10], r3                     
    mov64 r3, r1                                    r3 = r1
    stxdw [r3+0x8], r2                      
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
lbb_46789:
    stxdw [r3+0x0], r1                      
    exit                                    

function_46791:
    mov64 r7, r1                                    r7 = r1
    add64 r7, 7                                     r7 += 7   ///  r7 = r7.wrapping_add(7 as i32 as i64 as u64)
    and64 r7, -8                                    r7 &= -8   ///  r7 = r7.and(-8)
    mov64 r4, r7                                    r4 = r7
    sub64 r4, r1                                    r4 -= r1   ///  r4 = r4.wrapping_sub(r1)
    jgt r4, r2, lbb_46935                           if r4 > r2 { pc += 138 }
    mov64 r5, r2                                    r5 = r2
    sub64 r5, r4                                    r5 -= r4   ///  r5 = r5.wrapping_sub(r4)
    mov64 r3, 8                                     r3 = 8 as i32 as i64 as u64
    jgt r3, r5, lbb_46935                           if r3 > r5 { pc += 134 }
    stxdw [r10-0x8], r4                     
    mov64 r2, r5                                    r2 = r5
    and64 r2, 7                                     r2 &= 7   ///  r2 = r2.and(7)
    mov64 r0, 0                                     r0 = 0 as i32 as i64 as u64
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
    jeq r7, r1, lbb_46814                           if r7 == r1 { pc += 7 }
    mov64 r6, r1                                    r6 = r1
    sub64 r6, r7                                    r6 -= r7   ///  r6 = r6.wrapping_sub(r7)
    mov64 r7, r1                                    r7 = r1
    ja lbb_46823                                    if true { pc += 12 }
lbb_46811:
    add64 r3, r9                                    r3 += r9   ///  r3 = r3.wrapping_add(r9)
    add64 r7, 1                                     r7 += 1   ///  r7 = r7.wrapping_add(1 as i32 as i64 as u64)
    jne r8, 1, lbb_46823                            if r8 != (1 as i32 as i64 as u64) { pc += 9 }
lbb_46814:
    ldxdw r4, [r10-0x8]                     
    add64 r1, r4                                    r1 += r4   ///  r1 = r1.wrapping_add(r4)
    jeq r2, 0, lbb_46838                            if r2 == (0 as i32 as i64 as u64) { pc += 21 }
    mov64 r0, r5                                    r0 = r5
    and64 r0, -8                                    r0 &= -8   ///  r0 = r0.and(-8)
    mov64 r4, r1                                    r4 = r1
    add64 r4, r0                                    r4 += r0   ///  r4 = r4.wrapping_add(r0)
    mov64 r0, 0                                     r0 = 0 as i32 as i64 as u64
    ja lbb_46843                                    if true { pc += 20 }
lbb_46823:
    ldxb r4, [r7+0x0]                       
    lsh64 r4, 56                                    r4 <<= 56   ///  r4 = r4.wrapping_shl(56)
    arsh64 r4, 56                                   r4 >>= 56 (signed)   ///  r4 = (r4 as i64).wrapping_shr(56)
    mov64 r8, 1                                     r8 = 1 as i32 as i64 as u64
    mov64 r9, 1                                     r9 = 1 as i32 as i64 as u64
    jsgt r4, -65, lbb_46830                         if (r4 as i64) > (-65 as i32 as i64) { pc += 1 }
    mov64 r9, 0                                     r9 = 0 as i32 as i64 as u64
lbb_46830:
    add64 r6, 1                                     r6 += 1   ///  r6 = r6.wrapping_add(1 as i32 as i64 as u64)
    jeq r6, 0, lbb_46811                            if r6 == (0 as i32 as i64 as u64) { pc += -21 }
    mov64 r8, 0                                     r8 = 0 as i32 as i64 as u64
    ja lbb_46811                                    if true { pc += -23 }
lbb_46834:
    add64 r0, r6                                    r0 += r6   ///  r0 = r0.wrapping_add(r6)
    add64 r4, 1                                     r4 += 1   ///  r4 = r4.wrapping_add(1 as i32 as i64 as u64)
    add64 r2, -1                                    r2 += -1   ///  r2 = r2.wrapping_add(-1 as i32 as i64 as u64)
    jne r2, 0, lbb_46843                            if r2 != (0 as i32 as i64 as u64) { pc += 5 }
lbb_46838:
    rsh64 r5, 3                                     r5 >>= 3   ///  r5 = r5.wrapping_shr(3)
    add64 r0, r3                                    r0 += r3   ///  r0 = r0.wrapping_add(r3)
    lddw r6, 0x101010101010101                      r6 load str located at 72340172838076673
    ja lbb_46916                                    if true { pc += 73 }
lbb_46843:
    ldxb r7, [r4+0x0]                       
    lsh64 r7, 56                                    r7 <<= 56   ///  r7 = r7.wrapping_shl(56)
    arsh64 r7, 56                                   r7 >>= 56 (signed)   ///  r7 = (r7 as i64).wrapping_shr(56)
    mov64 r6, 1                                     r6 = 1 as i32 as i64 as u64
    jsgt r7, -65, lbb_46834                         if (r7 as i64) > (-65 as i32 as i64) { pc += -14 }
    mov64 r6, 0                                     r6 = 0 as i32 as i64 as u64
    ja lbb_46834                                    if true { pc += -16 }
lbb_46850:
    ldxdw r8, [r2+0x0]                      
    mov64 r7, r8                                    r7 = r8
    rsh64 r7, 6                                     r7 >>= 6   ///  r7 = r7.wrapping_shr(6)
    xor64 r8, -1                                    r8 ^= -1   ///  r8 = r8.xor(-1)
    rsh64 r8, 7                                     r8 >>= 7   ///  r8 = r8.wrapping_shr(7)
    or64 r8, r7                                     r8 |= r7   ///  r8 = r8.or(r7)
    and64 r8, r6                                    r8 &= r6   ///  r8 = r8.and(r6)
    add64 r8, r4                                    r8 += r4   ///  r8 = r8.wrapping_add(r4)
    ldxdw r4, [r2+0x8]                      
    mov64 r7, r4                                    r7 = r4
    rsh64 r7, 6                                     r7 >>= 6   ///  r7 = r7.wrapping_shr(6)
    xor64 r4, -1                                    r4 ^= -1   ///  r4 = r4.xor(-1)
    rsh64 r4, 7                                     r4 >>= 7   ///  r4 = r4.wrapping_shr(7)
    or64 r4, r7                                     r4 |= r7   ///  r4 = r4.or(r7)
    and64 r4, r6                                    r4 &= r6   ///  r4 = r4.and(r6)
    add64 r4, r8                                    r4 += r8   ///  r4 = r4.wrapping_add(r8)
    ldxdw r8, [r2+0x10]                     
    mov64 r7, r8                                    r7 = r8
    rsh64 r7, 6                                     r7 >>= 6   ///  r7 = r7.wrapping_shr(6)
    xor64 r8, -1                                    r8 ^= -1   ///  r8 = r8.xor(-1)
    rsh64 r8, 7                                     r8 >>= 7   ///  r8 = r8.wrapping_shr(7)
    or64 r8, r7                                     r8 |= r7   ///  r8 = r8.or(r7)
    and64 r8, r6                                    r8 &= r6   ///  r8 = r8.and(r6)
    add64 r8, r4                                    r8 += r4   ///  r8 = r8.wrapping_add(r4)
    ldxdw r4, [r2+0x18]                     
    mov64 r7, r4                                    r7 = r4
    rsh64 r7, 6                                     r7 >>= 6   ///  r7 = r7.wrapping_shr(6)
    xor64 r4, -1                                    r4 ^= -1   ///  r4 = r4.xor(-1)
    rsh64 r4, 7                                     r4 >>= 7   ///  r4 = r4.wrapping_shr(7)
    or64 r4, r7                                     r4 |= r7   ///  r4 = r4.or(r7)
    and64 r4, r6                                    r4 &= r6   ///  r4 = r4.and(r6)
    add64 r4, r8                                    r4 += r8   ///  r4 = r4.wrapping_add(r8)
    add64 r2, 32                                    r2 += 32   ///  r2 = r2.wrapping_add(32 as i32 as i64 as u64)
    jne r2, r1, lbb_46850                           if r2 != r1 { pc += -34 }
lbb_46884:
    mov64 r1, r9                                    r1 = r9
    add64 r1, r5                                    r1 += r5   ///  r1 = r1.wrapping_add(r5)
    ldxdw r8, [r10-0x8]                     
    mov64 r2, r8                                    r2 = r8
    and64 r2, 3                                     r2 &= 3   ///  r2 = r2.and(3)
    mov64 r5, r3                                    r5 = r3
    sub64 r5, r8                                    r5 -= r8   ///  r5 = r5.wrapping_sub(r8)
    mov64 r7, r4                                    r7 = r4
    stxdw [r10-0x10], r9                    
    mov64 r9, r3                                    r9 = r3
    lddw r3, 0xff00ff00ff00ff                       r3 load str located at 71777214294589695
    and64 r7, r3                                    r7 &= r3   ///  r7 = r7.and(r3)
    rsh64 r4, 8                                     r4 >>= 8   ///  r4 = r4.wrapping_shr(8)
    and64 r4, r3                                    r4 &= r3   ///  r4 = r4.and(r3)
    add64 r4, r7                                    r4 += r7   ///  r4 = r4.wrapping_add(r7)
    lddw r7, 0x1000100010001                        r7 load str located at 281479271743489
    mul64 r4, r7                                    r4 *= r7   ///  r4 = r4.wrapping_mul(r7)
    rsh64 r4, 48                                    r4 >>= 48   ///  r4 = r4.wrapping_shr(48)
    add64 r4, r0                                    r4 += r0   ///  r4 = r4.wrapping_add(r0)
    mov64 r0, r4                                    r0 = r4
    jeq r2, 0, lbb_46916                            if r2 == (0 as i32 as i64 as u64) { pc += 9 }
    mov64 r0, 0                                     r0 = 0 as i32 as i64 as u64
    ldxdw r6, [r10-0x10]                    
    jeq r2, 0, lbb_46967                            if r2 == (0 as i32 as i64 as u64) { pc += 57 }
    and64 r8, 252                                   r8 &= 252   ///  r8 = r8.and(252)
    lsh64 r8, 3                                     r8 <<= 3   ///  r8 = r8.wrapping_shl(3)
    mov64 r1, 192                                   r1 = 192 as i32 as i64 as u64
    jgt r1, r9, lbb_46948                           if r1 > r9 { pc += 34 }
    mov64 r9, 192                                   r9 = 192 as i32 as i64 as u64
    ja lbb_46948                                    if true { pc += 32 }
lbb_46916:
    mov64 r3, r5                                    r3 = r5
    mov64 r9, r1                                    r9 = r1
    jeq r3, 0, lbb_46979                            if r3 == (0 as i32 as i64 as u64) { pc += 60 }
    mov64 r1, 192                                   r1 = 192 as i32 as i64 as u64
    mov64 r2, r3                                    r2 = r3
    jgt r1, r3, lbb_46923                           if r1 > r3 { pc += 1 }
    mov64 r2, 192                                   r2 = 192 as i32 as i64 as u64
lbb_46923:
    mov64 r5, r2                                    r5 = r2
    lsh64 r5, 3                                     r5 <<= 3   ///  r5 = r5.wrapping_shl(3)
    mov64 r4, 0                                     r4 = 0 as i32 as i64 as u64
    mov64 r1, 4                                     r1 = 4 as i32 as i64 as u64
    stxdw [r10-0x8], r2                     
    jgt r1, r2, lbb_46884                           if r1 > r2 { pc += -45 }
    mov64 r2, r5                                    r2 = r5
    and64 r2, 2016                                  r2 &= 2016   ///  r2 = r2.and(2016)
    mov64 r1, r9                                    r1 = r9
    add64 r1, r2                                    r1 += r2   ///  r1 = r1.wrapping_add(r2)
    mov64 r2, r9                                    r2 = r9
    ja lbb_46850                                    if true { pc += -85 }
lbb_46935:
    mov64 r0, 0                                     r0 = 0 as i32 as i64 as u64
    jeq r2, 0, lbb_46979                            if r2 == (0 as i32 as i64 as u64) { pc += 42 }
lbb_46937:
    ldxb r4, [r1+0x0]                       
    lsh64 r4, 56                                    r4 <<= 56   ///  r4 = r4.wrapping_shl(56)
    arsh64 r4, 56                                   r4 >>= 56 (signed)   ///  r4 = (r4 as i64).wrapping_shr(56)
    mov64 r3, 1                                     r3 = 1 as i32 as i64 as u64
    jsgt r4, -65, lbb_46943                         if (r4 as i64) > (-65 as i32 as i64) { pc += 1 }
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
lbb_46943:
    add64 r0, r3                                    r0 += r3   ///  r0 = r0.wrapping_add(r3)
    add64 r1, 1                                     r1 += 1   ///  r1 = r1.wrapping_add(1 as i32 as i64 as u64)
    add64 r2, -1                                    r2 += -1   ///  r2 = r2.wrapping_add(-1 as i32 as i64 as u64)
    jeq r2, 0, lbb_46979                            if r2 == (0 as i32 as i64 as u64) { pc += 32 }
    ja lbb_46937                                    if true { pc += -11 }
lbb_46948:
    add64 r6, r8                                    r6 += r8   ///  r6 = r6.wrapping_add(r8)
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
    and64 r9, 3                                     r9 &= 3   ///  r9 = r9.and(3)
    lsh64 r9, 3                                     r9 <<= 3   ///  r9 = r9.wrapping_shl(3)
    lddw r1, 0x101010101010101                      r1 load str located at 72340172838076673
lbb_46954:
    ldxdw r0, [r6+0x0]                      
    mov64 r5, r0                                    r5 = r0
    rsh64 r5, 6                                     r5 >>= 6   ///  r5 = r5.wrapping_shr(6)
    xor64 r0, -1                                    r0 ^= -1   ///  r0 = r0.xor(-1)
    rsh64 r0, 7                                     r0 >>= 7   ///  r0 = r0.wrapping_shr(7)
    or64 r0, r5                                     r0 |= r5   ///  r0 = r0.or(r5)
    and64 r0, r1                                    r0 &= r1   ///  r0 = r0.and(r1)
    add64 r0, r2                                    r0 += r2   ///  r0 = r0.wrapping_add(r2)
    add64 r6, 8                                     r6 += 8   ///  r6 = r6.wrapping_add(8 as i32 as i64 as u64)
    add64 r9, -8                                    r9 += -8   ///  r9 = r9.wrapping_add(-8 as i32 as i64 as u64)
    mov64 r2, r0                                    r2 = r0
    jeq r9, 0, lbb_46967                            if r9 == (0 as i32 as i64 as u64) { pc += 1 }
    ja lbb_46954                                    if true { pc += -13 }
lbb_46967:
    lddw r1, 0xff00ff00ff00ff                       r1 load str located at 71777214294589695
    mov64 r2, r0                                    r2 = r0
    and64 r2, r1                                    r2 &= r1   ///  r2 = r2.and(r1)
    rsh64 r0, 8                                     r0 >>= 8   ///  r0 = r0.wrapping_shr(8)
    and64 r0, r1                                    r0 &= r1   ///  r0 = r0.and(r1)
    add64 r0, r2                                    r0 += r2   ///  r0 = r0.wrapping_add(r2)
    lddw r1, 0x1000100010001                        r1 load str located at 281479271743489
    mul64 r0, r1                                    r0 *= r1   ///  r0 = r0.wrapping_mul(r1)
    rsh64 r0, 48                                    r0 >>= 48   ///  r0 = r0.wrapping_shr(48)
    add64 r0, r4                                    r0 += r4   ///  r0 = r0.wrapping_add(r4)
lbb_46979:
    exit                                    

function_46980:
    call function_46982                     
    syscall [invalid]                       

function_46982:
    mov64 r6, r5                                    r6 = r5
    stxdw [r10-0xc8], r4                    
    stxdw [r10-0xd0], r3                    
    mov64 r5, 257                                   r5 = 257 as i32 as i64 as u64
    jgt r5, r2, lbb_47010                           if r5 > r2 { pc += 23 }
    mov64 r5, 256                                   r5 = 256 as i32 as i64 as u64
    ldxb r0, [r1+0x100]                     
    lsh64 r0, 56                                    r0 <<= 56   ///  r0 = r0.wrapping_shl(56)
    arsh64 r0, 56                                   r0 >>= 56 (signed)   ///  r0 = (r0 as i64).wrapping_shr(56)
    jsgt r0, -65, lbb_47007                         if (r0 as i64) > (-65 as i32 as i64) { pc += 15 }
    mov64 r5, 255                                   r5 = 255 as i32 as i64 as u64
    ldxb r0, [r1+0xff]                      
    lsh64 r0, 56                                    r0 <<= 56   ///  r0 = r0.wrapping_shl(56)
    arsh64 r0, 56                                   r0 >>= 56 (signed)   ///  r0 = (r0 as i64).wrapping_shr(56)
    jsgt r0, -65, lbb_47007                         if (r0 as i64) > (-65 as i32 as i64) { pc += 10 }
    mov64 r5, 254                                   r5 = 254 as i32 as i64 as u64
    ldxb r0, [r1+0xfe]                      
    lsh64 r0, 56                                    r0 <<= 56   ///  r0 = r0.wrapping_shl(56)
    arsh64 r0, 56                                   r0 >>= 56 (signed)   ///  r0 = (r0 as i64).wrapping_shr(56)
    jsgt r0, -65, lbb_47007                         if (r0 as i64) > (-65 as i32 as i64) { pc += 5 }
    mov64 r5, 253                                   r5 = 253 as i32 as i64 as u64
    ldxb r0, [r1+0xfd]                      
    lsh64 r0, 56                                    r0 <<= 56   ///  r0 = r0.wrapping_shl(56)
    arsh64 r0, 56                                   r0 >>= 56 (signed)   ///  r0 = (r0 as i64).wrapping_shr(56)
    jsgt r0, -65, lbb_47007                         if (r0 as i64) > (-65 as i32 as i64) { pc += 0 }
lbb_47007:
    jgt r2, r5, lbb_47090                           if r2 > r5 { pc += 82 }
    jeq r5, r2, lbb_47011                           if r5 == r2 { pc += 2 }
    ja lbb_47096                                    if true { pc += 86 }
lbb_47010:
    mov64 r5, r2                                    r5 = r2
lbb_47011:
    lddw r0, 0x100063ff6 --> b"[...]begin <= end (`byte index  is not a char boun"        r0 load str located at 4295376886
    jgt r2, r5, lbb_47016                           if r2 > r5 { pc += 2 }
    lddw r0, 0x100063ce8 --> b"calle"               r0 load str located at 4295376104
lbb_47016:
    mov64 r7, 5                                     r7 = 5 as i32 as i64 as u64
    jgt r2, r5, lbb_47019                           if r2 > r5 { pc += 1 }
    mov64 r7, 0                                     r7 = 0 as i32 as i64 as u64
lbb_47019:
    stxdw [r10-0xb8], r5                    
    stxdw [r10-0xc0], r1                    
    stxdw [r10-0xa8], r7                    
    stxdw [r10-0xb0], r0                    
    jgt r3, r2, lbb_47057                           if r3 > r2 { pc += 33 }
    jgt r4, r2, lbb_47057                           if r4 > r2 { pc += 32 }
    jgt r3, r4, lbb_47027                           if r3 > r4 { pc += 1 }
    ja lbb_47101                                    if true { pc += 74 }
lbb_47027:
    mov64 r1, r10                                   r1 = r10
    add64 r1, -176                                  r1 += -176   ///  r1 = r1.wrapping_add(-176 as i32 as i64 as u64)
    stxdw [r10-0x20], r1                    
    lddw r1, 0x10005dfb0 --> b"\xbf$\x00\x00\x00\x00\x00\x00y\x13\x08\x00\x00\x00\x00\x00y\x12\x00\x00\x…        r1 load str located at 4295352240
    stxdw [r10-0x18], r1                    
    stxdw [r10-0x28], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -192                                  r1 += -192   ///  r1 = r1.wrapping_add(-192 as i32 as i64 as u64)
    stxdw [r10-0x30], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -200                                  r1 += -200   ///  r1 = r1.wrapping_add(-200 as i32 as i64 as u64)
    stxdw [r10-0x40], r1                    
    lddw r1, 0x10005df58 --> b"\xbf#\x00\x00\x00\x00\x00\x00y\x11\x00\x00\x00\x00\x00\x00\xb7\x02\x00\x0…        r1 load str located at 4295352152
    stxdw [r10-0x38], r1                    
    stxdw [r10-0x48], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -208                                  r1 += -208   ///  r1 = r1.wrapping_add(-208 as i32 as i64 as u64)
    stxdw [r10-0x50], r1                    
    mov64 r7, r10                                   r7 = r10
    add64 r7, -128                                  r7 += -128   ///  r7 = r7.wrapping_add(-128 as i32 as i64 as u64)
    mov64 r4, r10                                   r4 = r10
    add64 r4, -80                                   r4 += -80   ///  r4 = r4.wrapping_add(-80 as i32 as i64 as u64)
    mov64 r1, r7                                    r1 = r7
    lddw r2, 0x1000673f0 --> b"\x00\x00\x00\x00"        r2 load str located at 4295390192
    mov64 r3, 4                                     r3 = 4 as i32 as i64 as u64
    mov64 r5, 4                                     r5 = 4 as i32 as i64 as u64
    ja lbb_47085                                    if true { pc += 28 }
lbb_47057:
    jgt r3, r2, lbb_47059                           if r3 > r2 { pc += 1 }
    mov64 r3, r4                                    r3 = r4
lbb_47059:
    stxdw [r10-0x90], r3                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -176                                  r1 += -176   ///  r1 = r1.wrapping_add(-176 as i32 as i64 as u64)
    stxdw [r10-0x30], r1                    
    lddw r1, 0x10005dfb0 --> b"\xbf$\x00\x00\x00\x00\x00\x00y\x13\x08\x00\x00\x00\x00\x00y\x12\x00\x00\x…        r1 load str located at 4295352240
    stxdw [r10-0x28], r1                    
    stxdw [r10-0x38], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -192                                  r1 += -192   ///  r1 = r1.wrapping_add(-192 as i32 as i64 as u64)
    stxdw [r10-0x40], r1                    
    lddw r1, 0x10005df58 --> b"\xbf#\x00\x00\x00\x00\x00\x00y\x11\x00\x00\x00\x00\x00\x00\xb7\x02\x00\x0…        r1 load str located at 4295352152
    stxdw [r10-0x48], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -144                                  r1 += -144   ///  r1 = r1.wrapping_add(-144 as i32 as i64 as u64)
    stxdw [r10-0x50], r1                    
    mov64 r7, r10                                   r7 = r10
    add64 r7, -128                                  r7 += -128   ///  r7 = r7.wrapping_add(-128 as i32 as i64 as u64)
    mov64 r4, r10                                   r4 = r10
    add64 r4, -80                                   r4 += -80   ///  r4 = r4.wrapping_add(-80 as i32 as i64 as u64)
    mov64 r1, r7                                    r1 = r7
    lddw r2, 0x100067480 --> b"\x00\x00\x00"        r2 load str located at 4295390336
    mov64 r3, 3                                     r3 = 3 as i32 as i64 as u64
    mov64 r5, 3                                     r5 = 3 as i32 as i64 as u64
lbb_47085:
    call function_45339                     
    mov64 r1, r7                                    r1 = r7
    mov64 r2, r6                                    r2 = r6
    call function_44240                     
    syscall [invalid]                       
lbb_47090:
    mov64 r0, r1                                    r0 = r1
    add64 r0, r5                                    r0 += r5   ///  r0 = r0.wrapping_add(r5)
    ldxb r0, [r0+0x0]                       
    lsh64 r0, 56                                    r0 <<= 56   ///  r0 = r0.wrapping_shl(56)
    arsh64 r0, 56                                   r0 >>= 56 (signed)   ///  r0 = (r0 as i64).wrapping_shr(56)
    jsgt r0, -65, lbb_47011                         if (r0 as i64) > (-65 as i32 as i64) { pc += -85 }
lbb_47096:
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
    mov64 r4, r5                                    r4 = r5
    mov64 r5, r6                                    r5 = r6
    call function_46980                     
    syscall [invalid]                       
lbb_47101:
    jeq r3, 0, lbb_47110                            if r3 == (0 as i32 as i64 as u64) { pc += 8 }
    jge r3, r2, lbb_47110                           if r3 >= r2 { pc += 7 }
    mov64 r5, r1                                    r5 = r1
    add64 r5, r3                                    r5 += r3   ///  r5 = r5.wrapping_add(r3)
    ldxb r5, [r5+0x0]                       
    lsh64 r5, 56                                    r5 <<= 56   ///  r5 = r5.wrapping_shl(56)
    arsh64 r5, 56                                   r5 >>= 56 (signed)   ///  r5 = (r5 as i64).wrapping_shr(56)
    mov64 r0, -64                                   r0 = -64 as i32 as i64 as u64
    jsgt r0, r5, lbb_47111                          if (r0 as i64) > (r5 as i64) { pc += 1 }
lbb_47110:
    mov64 r3, r4                                    r3 = r4
lbb_47111:
    stxdw [r10-0xa0], r3                    
    mov64 r4, r2                                    r4 = r2
    jge r3, r2, lbb_47147                           if r3 >= r2 { pc += 33 }
    mov64 r4, r3                                    r4 = r3
    add64 r4, -3                                    r4 += -3   ///  r4 = r4.wrapping_add(-3 as i32 as i64 as u64)
    mov64 r5, 0                                     r5 = 0 as i32 as i64 as u64
    mov64 r0, 1                                     r0 = 1 as i32 as i64 as u64
    jgt r4, r3, lbb_47120                           if r4 > r3 { pc += 1 }
    mov64 r0, 0                                     r0 = 0 as i32 as i64 as u64
lbb_47120:
    jne r0, 0, lbb_47122                            if r0 != (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r5, r4                                    r5 = r4
lbb_47122:
    mov64 r0, r3                                    r0 = r3
    add64 r0, 1                                     r0 += 1   ///  r0 = r0.wrapping_add(1 as i32 as i64 as u64)
    jge r0, r5, lbb_47131                           if r0 >= r5 { pc += 6 }
    mov64 r1, r5                                    r1 = r5
    mov64 r2, r0                                    r2 = r0
    lddw r3, 0x1000674b0 --> b"\x00\x00\x00\x00W@\x06\x00\x1b\x00\x00\x00\x00\x00\x00\x00\x09\x01\x00\x0…        r3 load str located at 4295390384
    call function_46562                     
    syscall [invalid]                       
lbb_47131:
    mov64 r7, r1                                    r7 = r1
    add64 r7, r5                                    r7 += r5   ///  r7 = r7.wrapping_add(r5)
    mov64 r4, r1                                    r4 = r1
    add64 r4, r0                                    r4 += r0   ///  r4 = r4.wrapping_add(r0)
    sub64 r4, r7                                    r4 -= r7   ///  r4 = r4.wrapping_sub(r7)
    mov64 r0, r1                                    r0 = r1
    add64 r0, r3                                    r0 += r3   ///  r0 = r0.wrapping_add(r3)
    mov64 r3, -64                                   r3 = -64 as i32 as i64 as u64
lbb_47139:
    jeq r4, 0, lbb_47146                            if r4 == (0 as i32 as i64 as u64) { pc += 6 }
    add64 r4, -1                                    r4 += -1   ///  r4 = r4.wrapping_add(-1 as i32 as i64 as u64)
    ldxb r7, [r0+0x0]                       
    add64 r0, -1                                    r0 += -1   ///  r0 = r0.wrapping_add(-1 as i32 as i64 as u64)
    lsh64 r7, 56                                    r7 <<= 56   ///  r7 = r7.wrapping_shl(56)
    arsh64 r7, 56                                   r7 >>= 56 (signed)   ///  r7 = (r7 as i64).wrapping_shr(56)
    jsgt r3, r7, lbb_47139                          if (r3 as i64) > (r7 as i64) { pc += -7 }
lbb_47146:
    add64 r4, r5                                    r4 += r5   ///  r4 = r4.wrapping_add(r5)
lbb_47147:
    mov64 r3, r2                                    r3 = r2
    jeq r4, 0, lbb_47154                            if r4 == (0 as i32 as i64 as u64) { pc += 5 }
    jgt r2, r4, lbb_47195                           if r2 > r4 { pc += 45 }
    mov64 r3, r2                                    r3 = r2
    sub64 r3, r4                                    r3 -= r4   ///  r3 = r3.wrapping_sub(r4)
    jeq r2, r4, lbb_47154                           if r2 == r4 { pc += 1 }
    ja lbb_47203                                    if true { pc += 49 }
lbb_47154:
    jeq r3, 0, lbb_47189                            if r3 == (0 as i32 as i64 as u64) { pc += 34 }
    add64 r1, r4                                    r1 += r4   ///  r1 = r1.wrapping_add(r4)
    ldxb r5, [r1+0x0]                       
    mov64 r2, r5                                    r2 = r5
    lsh64 r2, 56                                    r2 <<= 56   ///  r2 = r2.wrapping_shl(56)
    arsh64 r2, 56                                   r2 >>= 56 (signed)   ///  r2 = (r2 as i64).wrapping_shr(56)
    jsgt r2, -1, lbb_47208                          if (r2 as i64) > (-1 as i32 as i64) { pc += 47 }
    ldxb r2, [r1+0x1]                       
    and64 r2, 63                                    r2 &= 63   ///  r2 = r2.and(63)
    mov64 r3, r5                                    r3 = r5
    and64 r3, 31                                    r3 &= 31   ///  r3 = r3.and(31)
    mov64 r0, r3                                    r0 = r3
    lsh64 r0, 6                                     r0 <<= 6   ///  r0 = r0.wrapping_shl(6)
    or64 r0, r2                                     r0 |= r2   ///  r0 = r0.or(r2)
    jgt r5, 223, lbb_47170                          if r5 > (223 as i32 as i64 as u64) { pc += 1 }
    ja lbb_47209                                    if true { pc += 39 }
lbb_47170:
    lsh64 r2, 6                                     r2 <<= 6   ///  r2 = r2.wrapping_shl(6)
    ldxb r0, [r1+0x2]                       
    and64 r0, 63                                    r0 &= 63   ///  r0 = r0.and(63)
    or64 r2, r0                                     r2 |= r0   ///  r2 = r2.or(r0)
    mov64 r7, r3                                    r7 = r3
    lsh64 r7, 12                                    r7 <<= 12   ///  r7 = r7.wrapping_shl(12)
    mov64 r0, r2                                    r0 = r2
    or64 r0, r7                                     r0 |= r7   ///  r0 = r0.or(r7)
    mov64 r7, 240                                   r7 = 240 as i32 as i64 as u64
    jgt r7, r5, lbb_47209                           if r7 > r5 { pc += 29 }
    lsh64 r2, 6                                     r2 <<= 6   ///  r2 = r2.wrapping_shl(6)
    ldxb r1, [r1+0x3]                       
    and64 r1, 63                                    r1 &= 63   ///  r1 = r1.and(63)
    or64 r2, r1                                     r2 |= r1   ///  r2 = r2.or(r1)
    lsh64 r3, 18                                    r3 <<= 18   ///  r3 = r3.wrapping_shl(18)
    and64 r3, 1835008                               r3 &= 1835008   ///  r3 = r3.and(1835008)
    or64 r2, r3                                     r2 |= r3   ///  r2 = r2.or(r3)
    mov64 r0, r2                                    r0 = r2
    ja lbb_47209                                    if true { pc += 20 }
lbb_47189:
    lddw r1, 0x100063ce8 --> b"called `Option::unwrap()` on a `None` value"        r1 load str located at 4295376104
    mov64 r2, 43                                    r2 = 43 as i32 as i64 as u64
    mov64 r3, r6                                    r3 = r6
    call function_44254                     
    syscall [invalid]                       
lbb_47195:
    mov64 r3, r2                                    r3 = r2
    sub64 r3, r4                                    r3 -= r4   ///  r3 = r3.wrapping_sub(r4)
    mov64 r5, r1                                    r5 = r1
    add64 r5, r4                                    r5 += r4   ///  r5 = r5.wrapping_add(r4)
    ldxb r5, [r5+0x0]                       
    lsh64 r5, 56                                    r5 <<= 56   ///  r5 = r5.wrapping_shl(56)
    arsh64 r5, 56                                   r5 >>= 56 (signed)   ///  r5 = (r5 as i64).wrapping_shr(56)
    jsgt r5, -65, lbb_47154                         if (r5 as i64) > (-65 as i32 as i64) { pc += -49 }
lbb_47203:
    mov64 r3, r4                                    r3 = r4
    mov64 r4, r2                                    r4 = r2
    mov64 r5, r6                                    r5 = r6
    call function_46980                     
    syscall [invalid]                       
lbb_47208:
    mov64 r0, r5                                    r0 = r5
lbb_47209:
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    stxw [r10-0x94], r0                     
    mov64 r2, 128                                   r2 = 128 as i32 as i64 as u64
    jgt r2, r0, lbb_47220                           if r2 > r0 { pc += 7 }
    mov64 r1, 2                                     r1 = 2 as i32 as i64 as u64
    mov64 r2, 2048                                  r2 = 2048 as i32 as i64 as u64
    jgt r2, r0, lbb_47220                           if r2 > r0 { pc += 4 }
    mov64 r1, 3                                     r1 = 3 as i32 as i64 as u64
    mov64 r2, 65536                                 r2 = 65536 as i32 as i64 as u64
    jgt r2, r0, lbb_47220                           if r2 > r0 { pc += 1 }
    mov64 r1, 4                                     r1 = 4 as i32 as i64 as u64
lbb_47220:
    stxdw [r10-0x90], r4                    
    add64 r1, r4                                    r1 += r4   ///  r1 = r1.wrapping_add(r4)
    stxdw [r10-0x88], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -176                                  r1 += -176   ///  r1 = r1.wrapping_add(-176 as i32 as i64 as u64)
    stxdw [r10-0x10], r1                    
    lddw r1, 0x10005dfb0 --> b"\xbf$\x00\x00\x00\x00\x00\x00y\x13\x08\x00\x00\x00\x00\x00y\x12\x00\x00\x…        r1 load str located at 4295352240
    stxdw [r10-0x8], r1                     
    stxdw [r10-0x18], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -192                                  r1 += -192   ///  r1 = r1.wrapping_add(-192 as i32 as i64 as u64)
    stxdw [r10-0x20], r1                    
    lddw r1, 0x100055740 --> b"\xbf&\x00\x00\x00\x00\x00\x00\xbf\x17\x00\x00\x00\x00\x00\x00\x85\x10\x00…        r1 load str located at 4295317312
    stxdw [r10-0x28], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -144                                  r1 += -144   ///  r1 = r1.wrapping_add(-144 as i32 as i64 as u64)
    stxdw [r10-0x30], r1                    
    lddw r1, 0x10005ac30 --> b"\xbf\x18\x00\x00\x00\x00\x00\x00y& \x00\x00\x00\x00\x00y!(\x00\x00\x00\x0…        r1 load str located at 4295339056
    stxdw [r10-0x38], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -148                                  r1 += -148   ///  r1 = r1.wrapping_add(-148 as i32 as i64 as u64)
    stxdw [r10-0x40], r1                    
    lddw r1, 0x10005df58 --> b"\xbf#\x00\x00\x00\x00\x00\x00y\x11\x00\x00\x00\x00\x00\x00\xb7\x02\x00\x0…        r1 load str located at 4295352152
    stxdw [r10-0x48], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -160                                  r1 += -160   ///  r1 = r1.wrapping_add(-160 as i32 as i64 as u64)
    stxdw [r10-0x50], r1                    
    mov64 r7, r10                                   r7 = r10
    add64 r7, -128                                  r7 += -128   ///  r7 = r7.wrapping_add(-128 as i32 as i64 as u64)
    mov64 r4, r10                                   r4 = r10
    add64 r4, -80                                   r4 += -80   ///  r4 = r4.wrapping_add(-80 as i32 as i64 as u64)
    mov64 r1, r7                                    r1 = r7
    lddw r2, 0x100067430 --> b"\x00\x00\x00\x00\x0a"        r2 load str located at 4295390256
    mov64 r3, 5                                     r3 = 5 as i32 as i64 as u64
    mov64 r5, 5                                     r5 = 5 as i32 as i64 as u64
    ja lbb_47085                                    if true { pc += -176 }

function_47261:
    mov64 r9, r1                                    r9 = r1
    ldxdw r1, [r5-0xff0]                    
    stxdw [r10-0x10], r1                    
    ldxdw r6, [r5-0xff8]                    
    jeq r3, 0, lbb_47307                            if r3 == (0 as i32 as i64 as u64) { pc += 41 }
    lsh64 r3, 1                                     r3 <<= 1   ///  r3 = r3.wrapping_shl(1)
    mov64 r1, r2                                    r1 = r2
    add64 r1, r3                                    r1 += r3   ///  r1 = r1.wrapping_add(r3)
    stxdw [r10-0x8], r1                     
    ldxdw r8, [r5-0x1000]                   
    mov64 r3, r9                                    r3 = r9
    and64 r3, 65280                                 r3 &= 65280   ///  r3 = r3.and(65280)
    rsh64 r3, 8                                     r3 >>= 8   ///  r3 = r3.wrapping_shr(8)
    mov64 r0, 0                                     r0 = 0 as i32 as i64 as u64
    stxdw [r10-0x20], r4                    
    stxdw [r10-0x18], r8                    
    ja lbb_47282                                    if true { pc += 4 }
lbb_47278:
    jgt r1, r3, lbb_47307                           if r1 > r3 { pc += 28 }
    mov64 r0, r5                                    r0 = r5
    ldxdw r1, [r10-0x8]                     
    jeq r2, r1, lbb_47307                           if r2 == r1 { pc += 25 }
lbb_47282:
    ldxb r7, [r2+0x1]                       
    mov64 r5, r0                                    r5 = r0
    add64 r5, r7                                    r5 += r7   ///  r5 = r5.wrapping_add(r7)
    ldxb r1, [r2+0x0]                       
    add64 r2, 2                                     r2 += 2   ///  r2 = r2.wrapping_add(2 as i32 as i64 as u64)
    jeq r1, r3, lbb_47289                           if r1 == r3 { pc += 1 }
    ja lbb_47278                                    if true { pc += -11 }
lbb_47289:
    jgt r0, r5, lbb_47345                           if r0 > r5 { pc += 55 }
    jgt r5, r8, lbb_47351                           if r5 > r8 { pc += 60 }
    add64 r4, r0                                    r4 += r0   ///  r4 = r4.wrapping_add(r0)
lbb_47292:
    jeq r7, 0, lbb_47301                            if r7 == (0 as i32 as i64 as u64) { pc += 8 }
    mov64 r0, 0                                     r0 = 0 as i32 as i64 as u64
    add64 r7, -1                                    r7 += -1   ///  r7 = r7.wrapping_add(-1 as i32 as i64 as u64)
    mov64 r1, r9                                    r1 = r9
    and64 r1, 255                                   r1 &= 255   ///  r1 = r1.and(255)
    ldxb r8, [r4+0x0]                       
    add64 r4, 1                                     r4 += 1   ///  r4 = r4.wrapping_add(1 as i32 as i64 as u64)
    jeq r8, r1, lbb_47336                           if r8 == r1 { pc += 36 }
    ja lbb_47292                                    if true { pc += -9 }
lbb_47301:
    mov64 r0, r5                                    r0 = r5
    ldxdw r4, [r10-0x20]                    
    ldxdw r8, [r10-0x18]                    
    ldxdw r1, [r10-0x8]                     
    jeq r2, r1, lbb_47307                           if r2 == r1 { pc += 1 }
    ja lbb_47282                                    if true { pc += -25 }
lbb_47307:
    mov64 r0, 1                                     r0 = 1 as i32 as i64 as u64
    ldxdw r1, [r10-0x10]                    
    jeq r1, 0, lbb_47336                            if r1 == (0 as i32 as i64 as u64) { pc += 26 }
    mov64 r2, r6                                    r2 = r6
    ldxdw r1, [r10-0x10]                    
    add64 r2, r1                                    r2 += r1   ///  r2 = r2.wrapping_add(r1)
    and64 r9, 65535                                 r9 &= 65535   ///  r9 = r9.and(65535)
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
lbb_47315:
    mov64 r5, r6                                    r5 = r6
    add64 r5, 1                                     r5 += 1   ///  r5 = r5.wrapping_add(1 as i32 as i64 as u64)
    ldxb r4, [r6+0x0]                       
    mov64 r7, r4                                    r7 = r4
    lsh64 r7, 56                                    r7 <<= 56   ///  r7 = r7.wrapping_shl(56)
    arsh64 r7, 56                                   r7 >>= 56 (signed)   ///  r7 = (r7 as i64).wrapping_shr(56)
    jsgt r3, r7, lbb_47324                          if (r3 as i64) > (r7 as i64) { pc += 2 }
    mov64 r6, r5                                    r6 = r5
    ja lbb_47330                                    if true { pc += 6 }
lbb_47324:
    jeq r5, r2, lbb_47338                           if r5 == r2 { pc += 13 }
    and64 r4, 127                                   r4 &= 127   ///  r4 = r4.and(127)
    lsh64 r4, 8                                     r4 <<= 8   ///  r4 = r4.wrapping_shl(8)
    ldxb r5, [r6+0x1]                       
    or64 r4, r5                                     r4 |= r5   ///  r4 = r4.or(r5)
    add64 r6, 2                                     r6 += 2   ///  r6 = r6.wrapping_add(2 as i32 as i64 as u64)
lbb_47330:
    sub64 r9, r4                                    r9 -= r4   ///  r9 = r9.wrapping_sub(r4)
    lsh64 r9, 32                                    r9 <<= 32   ///  r9 = r9.wrapping_shl(32)
    arsh64 r9, 32                                   r9 >>= 32 (signed)   ///  r9 = (r9 as i64).wrapping_shr(32)
    jsgt r3, r9, lbb_47336                          if (r3 as i64) > (r9 as i64) { pc += 2 }
    xor64 r0, 1                                     r0 ^= 1   ///  r0 = r0.xor(1)
    jne r6, r2, lbb_47315                           if r6 != r2 { pc += -21 }
lbb_47336:
    and64 r0, 1                                     r0 &= 1   ///  r0 = r0.and(1)
    exit                                    
lbb_47338:
    lddw r1, 0x100063ce8 --> b"called `Option::unwrap()` on a `None` value"        r1 load str located at 4295376104
    mov64 r2, 43                                    r2 = 43 as i32 as i64 as u64
    lddw r3, 0x1000674c8 --> b"\x00\x00\x00\x00r@\x06\x00%\x00\x00\x00\x00\x00\x00\x00\x1a\x00\x00\x006\…        r3 load str located at 4295390408
    call function_44254                     
    syscall [invalid]                       
lbb_47345:
    mov64 r1, r0                                    r1 = r0
    mov64 r2, r5                                    r2 = r5
    lddw r3, 0x1000674e0 --> b"\x00\x00\x00\x00r@\x06\x00%\x00\x00\x00\x00\x00\x00\x00\x0a\x00\x00\x00+\…        r3 load str located at 4295390432
    call function_46562                     
    syscall [invalid]                       
lbb_47351:
    mov64 r1, r5                                    r1 = r5
    ldxdw r2, [r10-0x18]                    
    lddw r3, 0x1000674e0 --> b"\x00\x00\x00\x00r@\x06\x00%\x00\x00\x00\x00\x00\x00\x00\x0a\x00\x00\x00+\…        r3 load str located at 4295390432
    call function_46535                     
    syscall [invalid]                       

function_47357:
    mov64 r0, 0                                     r0 = 0 as i32 as i64 as u64
    mov64 r2, r1                                    r2 = r1
    lsh64 r2, 32                                    r2 <<= 32   ///  r2 = r2.wrapping_shl(32)
    rsh64 r2, 32                                    r2 >>= 32   ///  r2 = r2.wrapping_shr(32)
    mov64 r3, 32                                    r3 = 32 as i32 as i64 as u64
    jgt r3, r2, lbb_47402                           if r3 > r2 { pc += 39 }
    mov64 r0, 1                                     r0 = 1 as i32 as i64 as u64
    mov64 r3, 127                                   r3 = 127 as i32 as i64 as u64
    jgt r3, r2, lbb_47402                           if r3 > r2 { pc += 36 }
    mov64 r2, r1                                    r2 = r1
    lsh64 r2, 32                                    r2 <<= 32   ///  r2 = r2.wrapping_shl(32)
    rsh64 r2, 32                                    r2 >>= 32   ///  r2 = r2.wrapping_shr(32)
    mov64 r3, 65536                                 r3 = 65536 as i32 as i64 as u64
    jgt r3, r2, lbb_47388                           if r3 > r2 { pc += 17 }
    mov64 r3, 131072                                r3 = 131072 as i32 as i64 as u64
    jgt r3, r2, lbb_47374                           if r3 > r2 { pc += 1 }
    ja lbb_47404                                    if true { pc += 30 }
lbb_47374:
    lddw r2, 0x1000641b3 --> b"^"{\x05\x03\x04-\x03f\x03\x01/.\x80\x82\x1d\x031\x0f\x1c\x04$\x09\x1e\x05…        r2 load str located at 4295377331
    stxdw [r10-0xff8], r2                   
    mov64 r2, 450                                   r2 = 450 as i32 as i64 as u64
    stxdw [r10-0xff0], r2                   
    mov64 r2, 196                                   r2 = 196 as i32 as i64 as u64
    stxdw [r10-0x1000], r2                  
    mov64 r5, r10                                   r5 = r10
    lddw r2, 0x100064097 --> b"\x00\x06\x01\x01\x03\x01\x04\x02\x05\x07\x07\x02\x08\x08\x09\x02\x0a\x05\…        r2 load str located at 4295377047
    mov64 r3, 44                                    r3 = 44 as i32 as i64 as u64
    lddw r4, 0x1000640ef --> b"\x0c';>NO\x8f\x9e\x9e\x9f{\x8b\x93\x96\xa2\xb2\xba\x86\xb1\x06\x07\x096=>…        r4 load str located at 4295377135
    ja lbb_47401                                    if true { pc += 13 }
lbb_47388:
    lddw r2, 0x1000644e4 --> b"\x00 _"\x82\xdf\x04\x82D\x08\x1b\x04\x06\x11\x81\xac\x0e\x80\xab\x05\x1f\…        r2 load str located at 4295378148
    stxdw [r10-0xff8], r2                   
    mov64 r2, 303                                   r2 = 303 as i32 as i64 as u64
    stxdw [r10-0xff0], r2                   
    mov64 r2, 287                                   r2 = 287 as i32 as i64 as u64
    stxdw [r10-0x1000], r2                  
    mov64 r5, r10                                   r5 = r10
    lddw r2, 0x100064375 --> b"\x00\x01\x03\x05\x05\x06\x06\x02\x07\x06\x08\x07\x09\x11\x0a\x1c\x0b\x19\…        r2 load str located at 4295377781
    mov64 r3, 40                                    r3 = 40 as i32 as i64 as u64
    lddw r4, 0x1000643c5 --> b"\xadxy\x8b\x8d\xa20WX\x8b\x8c\x90\x1c\xdd\x0e\x0fKL\xfb\xfc./?\]_\xe2\x84…        r4 load str located at 4295377861
lbb_47401:
    call function_47261                     
lbb_47402:
    and64 r0, 1                                     r0 &= 1   ///  r0 = r0.and(1)
    exit                                    
lbb_47404:
    mov64 r4, r1                                    r4 = r1
    add64 r4, -177978                               r4 += -177978   ///  r4 = r4.wrapping_add(-177978 as i32 as i64 as u64)
    lsh64 r4, 32                                    r4 <<= 32   ///  r4 = r4.wrapping_shl(32)
    rsh64 r4, 32                                    r4 >>= 32   ///  r4 = r4.wrapping_shr(32)
    mov64 r0, 0                                     r0 = 0 as i32 as i64 as u64
    mov64 r3, 1                                     r3 = 1 as i32 as i64 as u64
    mov64 r5, 6                                     r5 = 6 as i32 as i64 as u64
    mov64 r2, 1                                     r2 = 1 as i32 as i64 as u64
    jgt r5, r4, lbb_47414                           if r5 > r4 { pc += 1 }
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
lbb_47414:
    mov64 r5, r1                                    r5 = r1
    add64 r5, -183970                               r5 += -183970   ///  r5 = r5.wrapping_add(-183970 as i32 as i64 as u64)
    lsh64 r5, 32                                    r5 <<= 32   ///  r5 = r5.wrapping_shl(32)
    rsh64 r5, 32                                    r5 >>= 32   ///  r5 = r5.wrapping_shr(32)
    mov64 r6, 14                                    r6 = 14 as i32 as i64 as u64
    mov64 r4, 1                                     r4 = 1 as i32 as i64 as u64
    jgt r6, r5, lbb_47422                           if r6 > r5 { pc += 1 }
    mov64 r4, 0                                     r4 = 0 as i32 as i64 as u64
lbb_47422:
    mov64 r6, r1                                    r6 = r1
    add64 r6, -195102                               r6 += -195102   ///  r6 = r6.wrapping_add(-195102 as i32 as i64 as u64)
    lsh64 r6, 32                                    r6 <<= 32   ///  r6 = r6.wrapping_shl(32)
    rsh64 r6, 32                                    r6 >>= 32   ///  r6 = r6.wrapping_shr(32)
    mov64 r7, 1506                                  r7 = 1506 as i32 as i64 as u64
    mov64 r5, 1                                     r5 = 1 as i32 as i64 as u64
    jgt r7, r6, lbb_47430                           if r7 > r6 { pc += 1 }
    mov64 r5, 0                                     r5 = 0 as i32 as i64 as u64
lbb_47430:
    mov64 r6, r1                                    r6 = r1
    add64 r6, -191457                               r6 += -191457   ///  r6 = r6.wrapping_add(-191457 as i32 as i64 as u64)
    lsh64 r6, 32                                    r6 <<= 32   ///  r6 = r6.wrapping_shl(32)
    rsh64 r6, 32                                    r6 >>= 32   ///  r6 = r6.wrapping_shr(32)
    mov64 r7, 3103                                  r7 = 3103 as i32 as i64 as u64
    jgt r7, r6, lbb_47437                           if r7 > r6 { pc += 1 }
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
lbb_47437:
    lsh64 r3, 2                                     r3 <<= 2   ///  r3 = r3.wrapping_shl(2)
    lsh64 r5, 3                                     r5 <<= 3   ///  r5 = r5.wrapping_shl(3)
    or64 r5, r3                                     r5 |= r3   ///  r5 = r5.or(r3)
    lsh64 r4, 1                                     r4 <<= 1   ///  r4 = r4.wrapping_shl(1)
    or64 r2, r4                                     r2 |= r4   ///  r2 = r2.or(r4)
    or64 r2, r5                                     r2 |= r5   ///  r2 = r2.or(r5)
    jne r2, 0, lbb_47402                            if r2 != (0 as i32 as i64 as u64) { pc += -42 }
    mov64 r2, r1                                    r2 = r1
    add64 r2, -201547                               r2 += -201547   ///  r2 = r2.wrapping_add(-201547 as i32 as i64 as u64)
    lsh64 r2, 32                                    r2 <<= 32   ///  r2 = r2.wrapping_shl(32)
    rsh64 r2, 32                                    r2 >>= 32   ///  r2 = r2.wrapping_shr(32)
    mov64 r3, 5                                     r3 = 5 as i32 as i64 as u64
    jgt r3, r2, lbb_47402                           if r3 > r2 { pc += -48 }
    mov64 r2, r1                                    r2 = r1
    add64 r2, -205744                               r2 += -205744   ///  r2 = r2.wrapping_add(-205744 as i32 as i64 as u64)
    lsh64 r2, 32                                    r2 <<= 32   ///  r2 = r2.wrapping_shl(32)
    rsh64 r2, 32                                    r2 >>= 32   ///  r2 = r2.wrapping_shr(32)
    mov64 r3, 712016                                r3 = 712016 as i32 as i64 as u64
    jgt r3, r2, lbb_47402                           if r3 > r2 { pc += -54 }
    mov64 r2, r1                                    r2 = r1
    and64 r2, -32                                   r2 &= -32   ///  r2 = r2.and(-32)
    lsh64 r2, 32                                    r2 <<= 32   ///  r2 = r2.wrapping_shl(32)
    rsh64 r2, 32                                    r2 >>= 32   ///  r2 = r2.wrapping_shr(32)
    jeq r2, 173792, lbb_47402                       if r2 == (173792 as i32 as i64 as u64) { pc += -59 }
    mov64 r2, r1                                    r2 = r1
    and64 r2, -2                                    r2 &= -2   ///  r2 = r2.and(-2)
    lsh64 r2, 32                                    r2 <<= 32   ///  r2 = r2.wrapping_shl(32)
    rsh64 r2, 32                                    r2 >>= 32   ///  r2 = r2.wrapping_shr(32)
    jeq r2, 178206, lbb_47402                       if r2 == (178206 as i32 as i64 as u64) { pc += -64 }
    add64 r1, -1114112                              r1 += -1114112   ///  r1 = r1.wrapping_add(-1114112 as i32 as i64 as u64)
    lsh64 r1, 32                                    r1 <<= 32   ///  r1 = r1.wrapping_shl(32)
    rsh64 r1, 32                                    r1 >>= 32   ///  r1 = r1.wrapping_shr(32)
    mov64 r0, 1                                     r0 = 1 as i32 as i64 as u64
    lddw r2, 0xfffd01f0                             r2 load str located at 4294771184
    jgt r2, r1, lbb_47402                           if r2 > r1 { pc += -71 }
    mov64 r0, 0                                     r0 = 0 as i32 as i64 as u64
    ja lbb_47402                                    if true { pc += -73 }

function_47475:
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
    ldxb r5, [r1+0x0]                       
    mov64 r1, 10                                    r1 = 10 as i32 as i64 as u64
    mov64 r4, 16                                    r4 = 16 as i32 as i64 as u64
    ja lbb_47491                                    if true { pc += 11 }
lbb_47480:
    add64 r0, r6                                    r0 += r6   ///  r0 = r0.wrapping_add(r6)
    mov64 r6, r10                                   r6 = r10
    add64 r6, -128                                  r6 += -128   ///  r6 = r6.wrapping_add(-128 as i32 as i64 as u64)
    add64 r6, r3                                    r6 += r3   ///  r6 = r6.wrapping_add(r3)
    stxb [r6+0x7f], r0                      
    add64 r3, -1                                    r3 += -1   ///  r3 = r3.wrapping_add(-1 as i32 as i64 as u64)
    mov64 r0, r5                                    r0 = r5
    and64 r0, 255                                   r0 &= 255   ///  r0 = r0.and(255)
    mov64 r5, r0                                    r5 = r0
    rsh64 r5, 4                                     r5 >>= 4   ///  r5 = r5.wrapping_shr(4)
    jgt r4, r0, lbb_47497                           if r4 > r0 { pc += 6 }
lbb_47491:
    mov64 r6, r5                                    r6 = r5
    and64 r6, 15                                    r6 &= 15   ///  r6 = r6.and(15)
    mov64 r0, 48                                    r0 = 48 as i32 as i64 as u64
    jgt r1, r6, lbb_47480                           if r1 > r6 { pc += -15 }
    mov64 r0, 87                                    r0 = 87 as i32 as i64 as u64
    ja lbb_47480                                    if true { pc += -17 }
lbb_47497:
    mov64 r1, r3                                    r1 = r3
    add64 r1, 128                                   r1 += 128   ///  r1 = r1.wrapping_add(128 as i32 as i64 as u64)
    jgt r1, 128, lbb_47516                          if r1 > (128 as i32 as i64 as u64) { pc += 16 }
    mov64 r1, r3                                    r1 = r3
    neg64 r1                                        r1 = -r1   ///  r1 = (r1 as i64).wrapping_neg() as u64
    stxdw [r10-0xff8], r1                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -128                                  r1 += -128   ///  r1 = r1.wrapping_add(-128 as i32 as i64 as u64)
    add64 r1, r3                                    r1 += r3   ///  r1 = r1.wrapping_add(r3)
    add64 r1, 128                                   r1 += 128   ///  r1 = r1.wrapping_add(128 as i32 as i64 as u64)
    stxdw [r10-0x1000], r1                  
    mov64 r5, r10                                   r5 = r10
    mov64 r1, r2                                    r1 = r2
    mov64 r2, 1                                     r2 = 1 as i32 as i64 as u64
    lddw r3, 0x100063db4 --> b"0x"                  r3 load str located at 4295376308
    mov64 r4, 2                                     r4 = 2 as i32 as i64 as u64
    call function_45507                     
    exit                                    
lbb_47516:
    mov64 r2, 128                                   r2 = 128 as i32 as i64 as u64
    lddw r3, 0x100067318 --> b"\x00\x00\x00\x00\x99=\x06\x00\x1b\x00\x00\x00\x00\x00\x00\x00i\x00\x00\x0…        r3 load str located at 4295389976
    call function_46508                     
    syscall [invalid]                       

function_47521:
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
    ldxb r5, [r1+0x0]                       
    mov64 r1, 10                                    r1 = 10 as i32 as i64 as u64
    mov64 r4, 16                                    r4 = 16 as i32 as i64 as u64
    ja lbb_47537                                    if true { pc += 11 }
lbb_47526:
    add64 r0, r6                                    r0 += r6   ///  r0 = r0.wrapping_add(r6)
    mov64 r6, r10                                   r6 = r10
    add64 r6, -128                                  r6 += -128   ///  r6 = r6.wrapping_add(-128 as i32 as i64 as u64)
    add64 r6, r3                                    r6 += r3   ///  r6 = r6.wrapping_add(r3)
    stxb [r6+0x7f], r0                      
    add64 r3, -1                                    r3 += -1   ///  r3 = r3.wrapping_add(-1 as i32 as i64 as u64)
    mov64 r0, r5                                    r0 = r5
    and64 r0, 255                                   r0 &= 255   ///  r0 = r0.and(255)
    mov64 r5, r0                                    r5 = r0
    rsh64 r5, 4                                     r5 >>= 4   ///  r5 = r5.wrapping_shr(4)
    jgt r4, r0, lbb_47543                           if r4 > r0 { pc += 6 }
lbb_47537:
    mov64 r6, r5                                    r6 = r5
    and64 r6, 15                                    r6 &= 15   ///  r6 = r6.and(15)
    mov64 r0, 48                                    r0 = 48 as i32 as i64 as u64
    jgt r1, r6, lbb_47526                           if r1 > r6 { pc += -15 }
    mov64 r0, 55                                    r0 = 55 as i32 as i64 as u64
    ja lbb_47526                                    if true { pc += -17 }
lbb_47543:
    mov64 r1, r3                                    r1 = r3
    add64 r1, 128                                   r1 += 128   ///  r1 = r1.wrapping_add(128 as i32 as i64 as u64)
    jgt r1, 128, lbb_47562                          if r1 > (128 as i32 as i64 as u64) { pc += 16 }
    mov64 r1, r3                                    r1 = r3
    neg64 r1                                        r1 = -r1   ///  r1 = (r1 as i64).wrapping_neg() as u64
    stxdw [r10-0xff8], r1                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -128                                  r1 += -128   ///  r1 = r1.wrapping_add(-128 as i32 as i64 as u64)
    add64 r1, r3                                    r1 += r3   ///  r1 = r1.wrapping_add(r3)
    add64 r1, 128                                   r1 += 128   ///  r1 = r1.wrapping_add(128 as i32 as i64 as u64)
    stxdw [r10-0x1000], r1                  
    mov64 r5, r10                                   r5 = r10
    mov64 r1, r2                                    r1 = r2
    mov64 r2, 1                                     r2 = 1 as i32 as i64 as u64
    lddw r3, 0x100063db4 --> b"0x"                  r3 load str located at 4295376308
    mov64 r4, 2                                     r4 = 2 as i32 as i64 as u64
    call function_45507                     
    exit                                    
lbb_47562:
    mov64 r2, 128                                   r2 = 128 as i32 as i64 as u64
    lddw r3, 0x100067318 --> b"\x00\x00\x00\x00\x99=\x06\x00\x1b\x00\x00\x00\x00\x00\x00\x00i\x00\x00\x0…        r3 load str located at 4295389976
    call function_46508                     
    syscall [invalid]                       

function_47567:
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
    ldxw r5, [r1+0x0]                       
    mov64 r1, 10                                    r1 = 10 as i32 as i64 as u64
    mov64 r4, 16                                    r4 = 16 as i32 as i64 as u64
    ja lbb_47584                                    if true { pc += 12 }
lbb_47572:
    add64 r0, r6                                    r0 += r6   ///  r0 = r0.wrapping_add(r6)
    mov64 r6, r10                                   r6 = r10
    add64 r6, -128                                  r6 += -128   ///  r6 = r6.wrapping_add(-128 as i32 as i64 as u64)
    add64 r6, r3                                    r6 += r3   ///  r6 = r6.wrapping_add(r3)
    stxb [r6+0x7f], r0                      
    add64 r3, -1                                    r3 += -1   ///  r3 = r3.wrapping_add(-1 as i32 as i64 as u64)
    lsh64 r5, 32                                    r5 <<= 32   ///  r5 = r5.wrapping_shl(32)
    mov64 r0, r5                                    r0 = r5
    rsh64 r0, 32                                    r0 >>= 32   ///  r0 = r0.wrapping_shr(32)
    mov64 r5, r0                                    r5 = r0
    rsh64 r5, 4                                     r5 >>= 4   ///  r5 = r5.wrapping_shr(4)
    jgt r4, r0, lbb_47590                           if r4 > r0 { pc += 6 }
lbb_47584:
    mov64 r6, r5                                    r6 = r5
    and64 r6, 15                                    r6 &= 15   ///  r6 = r6.and(15)
    mov64 r0, 48                                    r0 = 48 as i32 as i64 as u64
    jgt r1, r6, lbb_47572                           if r1 > r6 { pc += -16 }
    mov64 r0, 87                                    r0 = 87 as i32 as i64 as u64
    ja lbb_47572                                    if true { pc += -18 }
lbb_47590:
    mov64 r1, r3                                    r1 = r3
    add64 r1, 128                                   r1 += 128   ///  r1 = r1.wrapping_add(128 as i32 as i64 as u64)
    jgt r1, 128, lbb_47609                          if r1 > (128 as i32 as i64 as u64) { pc += 16 }
    mov64 r1, r3                                    r1 = r3
    neg64 r1                                        r1 = -r1   ///  r1 = (r1 as i64).wrapping_neg() as u64
    stxdw [r10-0xff8], r1                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -128                                  r1 += -128   ///  r1 = r1.wrapping_add(-128 as i32 as i64 as u64)
    add64 r1, r3                                    r1 += r3   ///  r1 = r1.wrapping_add(r3)
    add64 r1, 128                                   r1 += 128   ///  r1 = r1.wrapping_add(128 as i32 as i64 as u64)
    stxdw [r10-0x1000], r1                  
    mov64 r5, r10                                   r5 = r10
    mov64 r1, r2                                    r1 = r2
    mov64 r2, 1                                     r2 = 1 as i32 as i64 as u64
    lddw r3, 0x100063db4 --> b"0x"                  r3 load str located at 4295376308
    mov64 r4, 2                                     r4 = 2 as i32 as i64 as u64
    call function_45507                     
    exit                                    
lbb_47609:
    mov64 r2, 128                                   r2 = 128 as i32 as i64 as u64
    lddw r3, 0x100067318 --> b"\x00\x00\x00\x00\x99=\x06\x00\x1b\x00\x00\x00\x00\x00\x00\x00i\x00\x00\x0…        r3 load str located at 4295389976
    call function_46508                     
    syscall [invalid]                       

function_47614:
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
    ldxw r5, [r1+0x0]                       
    mov64 r1, 10                                    r1 = 10 as i32 as i64 as u64
    mov64 r4, 16                                    r4 = 16 as i32 as i64 as u64
    ja lbb_47631                                    if true { pc += 12 }
lbb_47619:
    add64 r0, r6                                    r0 += r6   ///  r0 = r0.wrapping_add(r6)
    mov64 r6, r10                                   r6 = r10
    add64 r6, -128                                  r6 += -128   ///  r6 = r6.wrapping_add(-128 as i32 as i64 as u64)
    add64 r6, r3                                    r6 += r3   ///  r6 = r6.wrapping_add(r3)
    stxb [r6+0x7f], r0                      
    add64 r3, -1                                    r3 += -1   ///  r3 = r3.wrapping_add(-1 as i32 as i64 as u64)
    lsh64 r5, 32                                    r5 <<= 32   ///  r5 = r5.wrapping_shl(32)
    mov64 r0, r5                                    r0 = r5
    rsh64 r0, 32                                    r0 >>= 32   ///  r0 = r0.wrapping_shr(32)
    mov64 r5, r0                                    r5 = r0
    rsh64 r5, 4                                     r5 >>= 4   ///  r5 = r5.wrapping_shr(4)
    jgt r4, r0, lbb_47637                           if r4 > r0 { pc += 6 }
lbb_47631:
    mov64 r6, r5                                    r6 = r5
    and64 r6, 15                                    r6 &= 15   ///  r6 = r6.and(15)
    mov64 r0, 48                                    r0 = 48 as i32 as i64 as u64
    jgt r1, r6, lbb_47619                           if r1 > r6 { pc += -16 }
    mov64 r0, 55                                    r0 = 55 as i32 as i64 as u64
    ja lbb_47619                                    if true { pc += -18 }
lbb_47637:
    mov64 r1, r3                                    r1 = r3
    add64 r1, 128                                   r1 += 128   ///  r1 = r1.wrapping_add(128 as i32 as i64 as u64)
    jgt r1, 128, lbb_47656                          if r1 > (128 as i32 as i64 as u64) { pc += 16 }
    mov64 r1, r3                                    r1 = r3
    neg64 r1                                        r1 = -r1   ///  r1 = (r1 as i64).wrapping_neg() as u64
    stxdw [r10-0xff8], r1                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -128                                  r1 += -128   ///  r1 = r1.wrapping_add(-128 as i32 as i64 as u64)
    add64 r1, r3                                    r1 += r3   ///  r1 = r1.wrapping_add(r3)
    add64 r1, 128                                   r1 += 128   ///  r1 = r1.wrapping_add(128 as i32 as i64 as u64)
    stxdw [r10-0x1000], r1                  
    mov64 r5, r10                                   r5 = r10
    mov64 r1, r2                                    r1 = r2
    mov64 r2, 1                                     r2 = 1 as i32 as i64 as u64
    lddw r3, 0x100063db4 --> b"0x"                  r3 load str located at 4295376308
    mov64 r4, 2                                     r4 = 2 as i32 as i64 as u64
    call function_45507                     
    exit                                    
lbb_47656:
    mov64 r2, 128                                   r2 = 128 as i32 as i64 as u64
    lddw r3, 0x100067318 --> b"\x00\x00\x00\x00\x99=\x06\x00\x1b\x00\x00\x00\x00\x00\x00\x00i\x00\x00\x0…        r3 load str located at 4295389976
    call function_46508                     
    syscall [invalid]                       

function_47661:
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
    ldxdw r0, [r1+0x0]                      
    mov64 r1, 10                                    r1 = 10 as i32 as i64 as u64
    mov64 r4, 16                                    r4 = 16 as i32 as i64 as u64
    ja lbb_47675                                    if true { pc += 9 }
lbb_47666:
    add64 r0, r6                                    r0 += r6   ///  r0 = r0.wrapping_add(r6)
    mov64 r6, r10                                   r6 = r10
    add64 r6, -128                                  r6 += -128   ///  r6 = r6.wrapping_add(-128 as i32 as i64 as u64)
    add64 r6, r3                                    r6 += r3   ///  r6 = r6.wrapping_add(r3)
    stxb [r6+0x7f], r0                      
    add64 r3, -1                                    r3 += -1   ///  r3 = r3.wrapping_add(-1 as i32 as i64 as u64)
    mov64 r0, r5                                    r0 = r5
    rsh64 r0, 4                                     r0 >>= 4   ///  r0 = r0.wrapping_shr(4)
    jgt r4, r5, lbb_47682                           if r4 > r5 { pc += 7 }
lbb_47675:
    mov64 r5, r0                                    r5 = r0
    mov64 r6, r5                                    r6 = r5
    and64 r6, 15                                    r6 &= 15   ///  r6 = r6.and(15)
    mov64 r0, 48                                    r0 = 48 as i32 as i64 as u64
    jgt r1, r6, lbb_47666                           if r1 > r6 { pc += -14 }
    mov64 r0, 87                                    r0 = 87 as i32 as i64 as u64
    ja lbb_47666                                    if true { pc += -16 }
lbb_47682:
    mov64 r1, r3                                    r1 = r3
    add64 r1, 128                                   r1 += 128   ///  r1 = r1.wrapping_add(128 as i32 as i64 as u64)
    jgt r1, 128, lbb_47701                          if r1 > (128 as i32 as i64 as u64) { pc += 16 }
    mov64 r1, r3                                    r1 = r3
    neg64 r1                                        r1 = -r1   ///  r1 = (r1 as i64).wrapping_neg() as u64
    stxdw [r10-0xff8], r1                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -128                                  r1 += -128   ///  r1 = r1.wrapping_add(-128 as i32 as i64 as u64)
    add64 r1, r3                                    r1 += r3   ///  r1 = r1.wrapping_add(r3)
    add64 r1, 128                                   r1 += 128   ///  r1 = r1.wrapping_add(128 as i32 as i64 as u64)
    stxdw [r10-0x1000], r1                  
    mov64 r5, r10                                   r5 = r10
    mov64 r1, r2                                    r1 = r2
    mov64 r2, 1                                     r2 = 1 as i32 as i64 as u64
    lddw r3, 0x100063db4 --> b"0x"                  r3 load str located at 4295376308
    mov64 r4, 2                                     r4 = 2 as i32 as i64 as u64
    call function_45507                     
    exit                                    
lbb_47701:
    mov64 r2, 128                                   r2 = 128 as i32 as i64 as u64
    lddw r3, 0x100067318 --> b"\x00\x00\x00\x00\x99=\x06\x00\x1b\x00\x00\x00\x00\x00\x00\x00i\x00\x00\x0…        r3 load str located at 4295389976
    call function_46508                     
    syscall [invalid]                       

function_47706:
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
    ldxdw r0, [r1+0x0]                      
    mov64 r1, 10                                    r1 = 10 as i32 as i64 as u64
    mov64 r4, 16                                    r4 = 16 as i32 as i64 as u64
    ja lbb_47720                                    if true { pc += 9 }
lbb_47711:
    add64 r0, r6                                    r0 += r6   ///  r0 = r0.wrapping_add(r6)
    mov64 r6, r10                                   r6 = r10
    add64 r6, -128                                  r6 += -128   ///  r6 = r6.wrapping_add(-128 as i32 as i64 as u64)
    add64 r6, r3                                    r6 += r3   ///  r6 = r6.wrapping_add(r3)
    stxb [r6+0x7f], r0                      
    add64 r3, -1                                    r3 += -1   ///  r3 = r3.wrapping_add(-1 as i32 as i64 as u64)
    mov64 r0, r5                                    r0 = r5
    rsh64 r0, 4                                     r0 >>= 4   ///  r0 = r0.wrapping_shr(4)
    jgt r4, r5, lbb_47727                           if r4 > r5 { pc += 7 }
lbb_47720:
    mov64 r5, r0                                    r5 = r0
    mov64 r6, r5                                    r6 = r5
    and64 r6, 15                                    r6 &= 15   ///  r6 = r6.and(15)
    mov64 r0, 48                                    r0 = 48 as i32 as i64 as u64
    jgt r1, r6, lbb_47711                           if r1 > r6 { pc += -14 }
    mov64 r0, 55                                    r0 = 55 as i32 as i64 as u64
    ja lbb_47711                                    if true { pc += -16 }
lbb_47727:
    mov64 r1, r3                                    r1 = r3
    add64 r1, 128                                   r1 += 128   ///  r1 = r1.wrapping_add(128 as i32 as i64 as u64)
    jgt r1, 128, lbb_47746                          if r1 > (128 as i32 as i64 as u64) { pc += 16 }
    mov64 r1, r3                                    r1 = r3
    neg64 r1                                        r1 = -r1   ///  r1 = (r1 as i64).wrapping_neg() as u64
    stxdw [r10-0xff8], r1                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -128                                  r1 += -128   ///  r1 = r1.wrapping_add(-128 as i32 as i64 as u64)
    add64 r1, r3                                    r1 += r3   ///  r1 = r1.wrapping_add(r3)
    add64 r1, 128                                   r1 += 128   ///  r1 = r1.wrapping_add(128 as i32 as i64 as u64)
    stxdw [r10-0x1000], r1                  
    mov64 r5, r10                                   r5 = r10
    mov64 r1, r2                                    r1 = r2
    mov64 r2, 1                                     r2 = 1 as i32 as i64 as u64
    lddw r3, 0x100063db4 --> b"0x"                  r3 load str located at 4295376308
    mov64 r4, 2                                     r4 = 2 as i32 as i64 as u64
    call function_45507                     
    exit                                    
lbb_47746:
    mov64 r2, 128                                   r2 = 128 as i32 as i64 as u64
    lddw r3, 0x100067318 --> b"\x00\x00\x00\x00\x99=\x06\x00\x1b\x00\x00\x00\x00\x00\x00\x00i\x00\x00\x0…        r3 load str located at 4295389976
    call function_46508                     
    syscall [invalid]                       

function_47751:
    mov64 r3, r1                                    r3 = r1
    mov64 r1, 127                                   r1 = 127 as i32 as i64 as u64
    ldxdw r4, [r3+0x8]                      
    ldxdw r3, [r3+0x0]                      
    mov64 r5, 10                                    r5 = 10 as i32 as i64 as u64
    mov64 r0, 16                                    r0 = 16 as i32 as i64 as u64
    ja lbb_47766                                    if true { pc += 8 }
lbb_47758:
    rsh64 r3, 4                                     r3 >>= 4   ///  r3 = r3.wrapping_shr(4)
    mov64 r7, r4                                    r7 = r4
    lsh64 r7, 60                                    r7 <<= 60   ///  r7 = r7.wrapping_shl(60)
    or64 r3, r7                                     r3 |= r7   ///  r3 = r3.or(r7)
    add64 r1, -1                                    r1 += -1   ///  r1 = r1.wrapping_add(-1 as i32 as i64 as u64)
    rsh64 r4, 4                                     r4 >>= 4   ///  r4 = r4.wrapping_shr(4)
    and64 r6, 1                                     r6 &= 1   ///  r6 = r6.and(1)
    jne r6, 0, lbb_47784                            if r6 != (0 as i32 as i64 as u64) { pc += 18 }
lbb_47766:
    mov64 r6, 0                                     r6 = 0 as i32 as i64 as u64
    jeq r1, -1, lbb_47787                           if r1 == (-1 as i32 as i64 as u64) { pc += 19 }
    mov64 r7, r3                                    r7 = r3
    and64 r7, 15                                    r7 &= 15   ///  r7 = r7.and(15)
    mov64 r6, 48                                    r6 = 48 as i32 as i64 as u64
    jgt r5, r7, lbb_47773                           if r5 > r7 { pc += 1 }
    mov64 r6, 87                                    r6 = 87 as i32 as i64 as u64
lbb_47773:
    add64 r6, r7                                    r6 += r7   ///  r6 = r6.wrapping_add(r7)
    mov64 r7, r10                                   r7 = r10
    add64 r7, -128                                  r7 += -128   ///  r7 = r7.wrapping_add(-128 as i32 as i64 as u64)
    add64 r7, r1                                    r7 += r1   ///  r7 = r7.wrapping_add(r1)
    stxb [r7+0x0], r6                       
    mov64 r6, 1                                     r6 = 1 as i32 as i64 as u64
    jgt r0, r3, lbb_47781                           if r0 > r3 { pc += 1 }
    mov64 r6, 0                                     r6 = 0 as i32 as i64 as u64
lbb_47781:
    jeq r4, 0, lbb_47758                            if r4 == (0 as i32 as i64 as u64) { pc += -24 }
    mov64 r6, 0                                     r6 = 0 as i32 as i64 as u64
    ja lbb_47758                                    if true { pc += -26 }
lbb_47784:
    add64 r1, 1                                     r1 += 1   ///  r1 = r1.wrapping_add(1 as i32 as i64 as u64)
    mov64 r6, r1                                    r6 = r1
    jgt r1, 128, lbb_47802                          if r1 > (128 as i32 as i64 as u64) { pc += 15 }
lbb_47787:
    mov64 r1, r10                                   r1 = r10
    add64 r1, -128                                  r1 += -128   ///  r1 = r1.wrapping_add(-128 as i32 as i64 as u64)
    add64 r1, r6                                    r1 += r6   ///  r1 = r1.wrapping_add(r6)
    stxdw [r10-0x1000], r1                  
    mov64 r1, 128                                   r1 = 128 as i32 as i64 as u64
    sub64 r1, r6                                    r1 -= r6   ///  r1 = r1.wrapping_sub(r6)
    stxdw [r10-0xff8], r1                   
    mov64 r5, r10                                   r5 = r10
    mov64 r1, r2                                    r1 = r2
    mov64 r2, 1                                     r2 = 1 as i32 as i64 as u64
    lddw r3, 0x100063db4 --> b"0x"                  r3 load str located at 4295376308
    mov64 r4, 2                                     r4 = 2 as i32 as i64 as u64
    call function_45507                     
    exit                                    
lbb_47802:
    mov64 r2, 128                                   r2 = 128 as i32 as i64 as u64
    lddw r3, 0x100067318 --> b"\x00\x00\x00\x00\x99=\x06\x00\x1b\x00\x00\x00\x00\x00\x00\x00i\x00\x00\x0…        r3 load str located at 4295389976
    call function_46508                     
    syscall [invalid]                       

function_47807:
    mov64 r3, r1                                    r3 = r1
    mov64 r1, 127                                   r1 = 127 as i32 as i64 as u64
    ldxdw r4, [r3+0x8]                      
    ldxdw r3, [r3+0x0]                      
    mov64 r5, 10                                    r5 = 10 as i32 as i64 as u64
    mov64 r0, 16                                    r0 = 16 as i32 as i64 as u64
    ja lbb_47822                                    if true { pc += 8 }
lbb_47814:
    rsh64 r3, 4                                     r3 >>= 4   ///  r3 = r3.wrapping_shr(4)
    mov64 r7, r4                                    r7 = r4
    lsh64 r7, 60                                    r7 <<= 60   ///  r7 = r7.wrapping_shl(60)
    or64 r3, r7                                     r3 |= r7   ///  r3 = r3.or(r7)
    add64 r1, -1                                    r1 += -1   ///  r1 = r1.wrapping_add(-1 as i32 as i64 as u64)
    rsh64 r4, 4                                     r4 >>= 4   ///  r4 = r4.wrapping_shr(4)
    and64 r6, 1                                     r6 &= 1   ///  r6 = r6.and(1)
    jne r6, 0, lbb_47840                            if r6 != (0 as i32 as i64 as u64) { pc += 18 }
lbb_47822:
    mov64 r6, 0                                     r6 = 0 as i32 as i64 as u64
    jeq r1, -1, lbb_47843                           if r1 == (-1 as i32 as i64 as u64) { pc += 19 }
    mov64 r7, r3                                    r7 = r3
    and64 r7, 15                                    r7 &= 15   ///  r7 = r7.and(15)
    mov64 r6, 48                                    r6 = 48 as i32 as i64 as u64
    jgt r5, r7, lbb_47829                           if r5 > r7 { pc += 1 }
    mov64 r6, 55                                    r6 = 55 as i32 as i64 as u64
lbb_47829:
    add64 r6, r7                                    r6 += r7   ///  r6 = r6.wrapping_add(r7)
    mov64 r7, r10                                   r7 = r10
    add64 r7, -128                                  r7 += -128   ///  r7 = r7.wrapping_add(-128 as i32 as i64 as u64)
    add64 r7, r1                                    r7 += r1   ///  r7 = r7.wrapping_add(r1)
    stxb [r7+0x0], r6                       
    mov64 r6, 1                                     r6 = 1 as i32 as i64 as u64
    jgt r0, r3, lbb_47837                           if r0 > r3 { pc += 1 }
    mov64 r6, 0                                     r6 = 0 as i32 as i64 as u64
lbb_47837:
    jeq r4, 0, lbb_47814                            if r4 == (0 as i32 as i64 as u64) { pc += -24 }
    mov64 r6, 0                                     r6 = 0 as i32 as i64 as u64
    ja lbb_47814                                    if true { pc += -26 }
lbb_47840:
    add64 r1, 1                                     r1 += 1   ///  r1 = r1.wrapping_add(1 as i32 as i64 as u64)
    mov64 r6, r1                                    r6 = r1
    jgt r1, 128, lbb_47858                          if r1 > (128 as i32 as i64 as u64) { pc += 15 }
lbb_47843:
    mov64 r1, r10                                   r1 = r10
    add64 r1, -128                                  r1 += -128   ///  r1 = r1.wrapping_add(-128 as i32 as i64 as u64)
    add64 r1, r6                                    r1 += r6   ///  r1 = r1.wrapping_add(r6)
    stxdw [r10-0x1000], r1                  
    mov64 r1, 128                                   r1 = 128 as i32 as i64 as u64
    sub64 r1, r6                                    r1 -= r6   ///  r1 = r1.wrapping_sub(r6)
    stxdw [r10-0xff8], r1                   
    mov64 r5, r10                                   r5 = r10
    mov64 r1, r2                                    r1 = r2
    mov64 r2, 1                                     r2 = 1 as i32 as i64 as u64
    lddw r3, 0x100063db4 --> b"0x"                  r3 load str located at 4295376308
    mov64 r4, 2                                     r4 = 2 as i32 as i64 as u64
    call function_45507                     
    exit                                    
lbb_47858:
    mov64 r2, 128                                   r2 = 128 as i32 as i64 as u64
    lddw r3, 0x100067318 --> b"\x00\x00\x00\x00\x99=\x06\x00\x1b\x00\x00\x00\x00\x00\x00\x00i\x00\x00\x0…        r3 load str located at 4295389976
    call function_46508                     
    syscall [invalid]                       

function_47863:
    mov64 r3, r2                                    r3 = r2
    ldxw r2, [r3+0x34]                      
    mov64 r4, r2                                    r4 = r2
    and64 r4, 16                                    r4 &= 16   ///  r4 = r4.and(16)
    jne r4, 0, lbb_47875                            if r4 != (0 as i32 as i64 as u64) { pc += 7 }
    and64 r2, 32                                    r2 &= 32   ///  r2 = r2.and(32)
    jeq r2, 0, lbb_47871                            if r2 == (0 as i32 as i64 as u64) { pc += 1 }
    ja lbb_47915                                    if true { pc += 44 }
lbb_47871:
    ldxdw r1, [r1+0x0]                      
    mov64 r2, 1                                     r2 = 1 as i32 as i64 as u64
    call function_47945                     
    ja lbb_47914                                    if true { pc += 39 }
lbb_47875:
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
    ldxdw r0, [r1+0x0]                      
    mov64 r1, 10                                    r1 = 10 as i32 as i64 as u64
    mov64 r4, 16                                    r4 = 16 as i32 as i64 as u64
    ja lbb_47889                                    if true { pc += 9 }
lbb_47880:
    add64 r0, r6                                    r0 += r6   ///  r0 = r0.wrapping_add(r6)
    mov64 r6, r10                                   r6 = r10
    add64 r6, -128                                  r6 += -128   ///  r6 = r6.wrapping_add(-128 as i32 as i64 as u64)
    add64 r6, r2                                    r6 += r2   ///  r6 = r6.wrapping_add(r2)
    stxb [r6+0x7f], r0                      
    add64 r2, -1                                    r2 += -1   ///  r2 = r2.wrapping_add(-1 as i32 as i64 as u64)
    mov64 r0, r5                                    r0 = r5
    rsh64 r0, 4                                     r0 >>= 4   ///  r0 = r0.wrapping_shr(4)
    jgt r4, r5, lbb_47896                           if r4 > r5 { pc += 7 }
lbb_47889:
    mov64 r5, r0                                    r5 = r0
    mov64 r6, r5                                    r6 = r5
    and64 r6, 15                                    r6 &= 15   ///  r6 = r6.and(15)
    mov64 r0, 48                                    r0 = 48 as i32 as i64 as u64
    jgt r1, r6, lbb_47880                           if r1 > r6 { pc += -14 }
    mov64 r0, 87                                    r0 = 87 as i32 as i64 as u64
    ja lbb_47880                                    if true { pc += -16 }
lbb_47896:
    mov64 r1, r2                                    r1 = r2
    add64 r1, 128                                   r1 += 128   ///  r1 = r1.wrapping_add(128 as i32 as i64 as u64)
    jgt r1, 128, lbb_47940                          if r1 > (128 as i32 as i64 as u64) { pc += 41 }
lbb_47899:
    mov64 r1, r2                                    r1 = r2
    neg64 r1                                        r1 = -r1   ///  r1 = (r1 as i64).wrapping_neg() as u64
    stxdw [r10-0xff8], r1                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -128                                  r1 += -128   ///  r1 = r1.wrapping_add(-128 as i32 as i64 as u64)
    add64 r1, r2                                    r1 += r2   ///  r1 = r1.wrapping_add(r2)
    add64 r1, 128                                   r1 += 128   ///  r1 = r1.wrapping_add(128 as i32 as i64 as u64)
    stxdw [r10-0x1000], r1                  
    mov64 r5, r10                                   r5 = r10
    mov64 r1, r3                                    r1 = r3
    mov64 r2, 1                                     r2 = 1 as i32 as i64 as u64
    lddw r3, 0x100063db4 --> b"0x"                  r3 load str located at 4295376308
    mov64 r4, 2                                     r4 = 2 as i32 as i64 as u64
    call function_45507                     
lbb_47914:
    exit                                    
lbb_47915:
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
    ldxdw r0, [r1+0x0]                      
    mov64 r1, 10                                    r1 = 10 as i32 as i64 as u64
    mov64 r4, 16                                    r4 = 16 as i32 as i64 as u64
    ja lbb_47929                                    if true { pc += 9 }
lbb_47920:
    add64 r0, r6                                    r0 += r6   ///  r0 = r0.wrapping_add(r6)
    mov64 r6, r10                                   r6 = r10
    add64 r6, -128                                  r6 += -128   ///  r6 = r6.wrapping_add(-128 as i32 as i64 as u64)
    add64 r6, r2                                    r6 += r2   ///  r6 = r6.wrapping_add(r2)
    stxb [r6+0x7f], r0                      
    add64 r2, -1                                    r2 += -1   ///  r2 = r2.wrapping_add(-1 as i32 as i64 as u64)
    mov64 r0, r5                                    r0 = r5
    rsh64 r0, 4                                     r0 >>= 4   ///  r0 = r0.wrapping_shr(4)
    jgt r4, r5, lbb_47936                           if r4 > r5 { pc += 7 }
lbb_47929:
    mov64 r5, r0                                    r5 = r0
    mov64 r6, r5                                    r6 = r5
    and64 r6, 15                                    r6 &= 15   ///  r6 = r6.and(15)
    mov64 r0, 48                                    r0 = 48 as i32 as i64 as u64
    jgt r1, r6, lbb_47920                           if r1 > r6 { pc += -14 }
    mov64 r0, 55                                    r0 = 55 as i32 as i64 as u64
    ja lbb_47920                                    if true { pc += -16 }
lbb_47936:
    mov64 r1, r2                                    r1 = r2
    add64 r1, 128                                   r1 += 128   ///  r1 = r1.wrapping_add(128 as i32 as i64 as u64)
    jgt r1, 128, lbb_47940                          if r1 > (128 as i32 as i64 as u64) { pc += 1 }
    ja lbb_47899                                    if true { pc += -41 }
lbb_47940:
    mov64 r2, 128                                   r2 = 128 as i32 as i64 as u64
    lddw r3, 0x100067318 --> b"\x00\x00\x00\x00\x99=\x06\x00\x1b\x00\x00\x00\x00\x00\x00\x00i\x00\x00\x0…        r3 load str located at 4295389976
    call function_46508                     
    syscall [invalid]                       

function_47945:
    mov64 r4, 39                                    r4 = 39 as i32 as i64 as u64
    mov64 r5, 10000                                 r5 = 10000 as i32 as i64 as u64
    jgt r5, r1, lbb_47980                           if r5 > r1 { pc += 32 }
    mov64 r4, 0                                     r4 = 0 as i32 as i64 as u64
lbb_47949:
    mov64 r5, r1                                    r5 = r1
    div64 r1, 10000                                 r1 /= 10000   ///  r1 = r1 / (10000 as u64)
    mov64 r6, r1                                    r6 = r1
    mul64 r6, 10000                                 r6 *= 10000   ///  r6 = r6.wrapping_mul(10000 as u64)
    mov64 r0, r5                                    r0 = r5
    sub64 r0, r6                                    r0 -= r6   ///  r0 = r0.wrapping_sub(r6)
    mov64 r6, r0                                    r6 = r0
    and64 r6, 65535                                 r6 &= 65535   ///  r6 = r6.and(65535)
    div64 r6, 100                                   r6 /= 100   ///  r6 = r6 / (100 as u64)
    mov64 r7, r6                                    r7 = r6
    mul64 r7, 100                                   r7 *= 100   ///  r7 = r7.wrapping_mul(100 as u64)
    sub64 r0, r7                                    r0 -= r7   ///  r0 = r0.wrapping_sub(r7)
    mov64 r7, r10                                   r7 = r10
    add64 r7, -39                                   r7 += -39   ///  r7 = r7.wrapping_add(-39 as i32 as i64 as u64)
    add64 r7, r4                                    r7 += r4   ///  r7 = r7.wrapping_add(r4)
    lsh64 r6, 1                                     r6 <<= 1   ///  r6 = r6.wrapping_shl(1)
    lddw r8, 0x100063db6 --> b"00010203040506070809101112131415161718192021222324"        r8 load str located at 4295376310
    add64 r8, r6                                    r8 += r6   ///  r8 = r8.wrapping_add(r6)
    ldxh r6, [r8+0x0]                       
    stxh [r7+0x23], r6                      
    lsh64 r0, 1                                     r0 <<= 1   ///  r0 = r0.wrapping_shl(1)
    and64 r0, 65534                                 r0 &= 65534   ///  r0 = r0.and(65534)
    lddw r6, 0x100063db6 --> b"00010203040506070809101112131415161718192021222324"        r6 load str located at 4295376310
    add64 r6, r0                                    r6 += r0   ///  r6 = r6.wrapping_add(r0)
    ldxh r0, [r6+0x0]                       
    stxh [r7+0x25], r0                      
    add64 r4, -4                                    r4 += -4   ///  r4 = r4.wrapping_add(-4 as i32 as i64 as u64)
    jgt r5, 99999999, lbb_47949                     if r5 > (99999999 as i32 as i64 as u64) { pc += -30 }
    add64 r4, 39                                    r4 += 39   ///  r4 = r4.wrapping_add(39 as i32 as i64 as u64)
lbb_47980:
    jgt r1, 99, lbb_47982                           if r1 > (99 as i32 as i64 as u64) { pc += 1 }
    ja lbb_48000                                    if true { pc += 18 }
lbb_47982:
    mov64 r5, r1                                    r5 = r1
    and64 r5, 65535                                 r5 &= 65535   ///  r5 = r5.and(65535)
    div64 r5, 100                                   r5 /= 100   ///  r5 = r5 / (100 as u64)
    mov64 r0, r5                                    r0 = r5
    mul64 r0, 100                                   r0 *= 100   ///  r0 = r0.wrapping_mul(100 as u64)
    sub64 r1, r0                                    r1 -= r0   ///  r1 = r1.wrapping_sub(r0)
    lsh64 r1, 1                                     r1 <<= 1   ///  r1 = r1.wrapping_shl(1)
    and64 r1, 65534                                 r1 &= 65534   ///  r1 = r1.and(65534)
    lddw r0, 0x100063db6 --> b"00010203040506070809101112131415161718192021222324"        r0 load str located at 4295376310
    add64 r0, r1                                    r0 += r1   ///  r0 = r0.wrapping_add(r1)
    add64 r4, -2                                    r4 += -2   ///  r4 = r4.wrapping_add(-2 as i32 as i64 as u64)
    mov64 r1, r10                                   r1 = r10
    add64 r1, -39                                   r1 += -39   ///  r1 = r1.wrapping_add(-39 as i32 as i64 as u64)
    add64 r1, r4                                    r1 += r4   ///  r1 = r1.wrapping_add(r4)
    ldxh r0, [r0+0x0]                       
    stxh [r1+0x0], r0                       
    mov64 r1, r5                                    r1 = r5
lbb_48000:
    mov64 r5, 10                                    r5 = 10 as i32 as i64 as u64
    jgt r5, r1, lbb_48013                           if r5 > r1 { pc += 11 }
    lsh64 r1, 1                                     r1 <<= 1   ///  r1 = r1.wrapping_shl(1)
    lddw r5, 0x100063db6 --> b"00010203040506070809101112131415161718192021222324"        r5 load str located at 4295376310
    add64 r5, r1                                    r5 += r1   ///  r5 = r5.wrapping_add(r1)
    add64 r4, -2                                    r4 += -2   ///  r4 = r4.wrapping_add(-2 as i32 as i64 as u64)
    mov64 r1, r10                                   r1 = r10
    add64 r1, -39                                   r1 += -39   ///  r1 = r1.wrapping_add(-39 as i32 as i64 as u64)
    add64 r1, r4                                    r1 += r4   ///  r1 = r1.wrapping_add(r4)
    ldxh r5, [r5+0x0]                       
    stxh [r1+0x0], r5                       
    ja lbb_48019                                    if true { pc += 6 }
lbb_48013:
    add64 r4, -1                                    r4 += -1   ///  r4 = r4.wrapping_add(-1 as i32 as i64 as u64)
    mov64 r5, r10                                   r5 = r10
    add64 r5, -39                                   r5 += -39   ///  r5 = r5.wrapping_add(-39 as i32 as i64 as u64)
    add64 r5, r4                                    r5 += r4   ///  r5 = r5.wrapping_add(r4)
    add64 r1, 48                                    r1 += 48   ///  r1 = r1.wrapping_add(48 as i32 as i64 as u64)
    stxb [r5+0x0], r1                       
lbb_48019:
    mov64 r1, r10                                   r1 = r10
    add64 r1, -39                                   r1 += -39   ///  r1 = r1.wrapping_add(-39 as i32 as i64 as u64)
    add64 r1, r4                                    r1 += r4   ///  r1 = r1.wrapping_add(r4)
    stxdw [r10-0x1000], r1                  
    mov64 r1, 39                                    r1 = 39 as i32 as i64 as u64
    sub64 r1, r4                                    r1 -= r4   ///  r1 = r1.wrapping_sub(r4)
    stxdw [r10-0xff8], r1                   
    mov64 r5, r10                                   r5 = r10
    mov64 r1, r3                                    r1 = r3
    lddw r3, 0x100063ce8 --> b"called `Option::unwrap()` on a `None` value)invali"        r3 load str located at 4295376104
    mov64 r4, 0                                     r4 = 0 as i32 as i64 as u64
    call function_45507                     
    exit                                    

function_48033:
    mov64 r3, r2                                    r3 = r2
    ldxb r4, [r1+0x0]                       
    lsh64 r4, 56                                    r4 <<= 56   ///  r4 = r4.wrapping_shl(56)
    arsh64 r4, 56                                   r4 >>= 56 (signed)   ///  r4 = (r4 as i64).wrapping_shr(56)
    jsgt r4, -1, lbb_48041                          if (r4 as i64) > (-1 as i32 as i64) { pc += 3 }
    mov64 r1, r4                                    r1 = r4
    neg64 r1                                        r1 = -r1   ///  r1 = (r1 as i64).wrapping_neg() as u64
    ja lbb_48042                                    if true { pc += 1 }
lbb_48041:
    mov64 r1, r4                                    r1 = r4
lbb_48042:
    mov64 r2, 1                                     r2 = 1 as i32 as i64 as u64
    jsgt r4, -1, lbb_48045                          if (r4 as i64) > (-1 as i32 as i64) { pc += 1 }
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
lbb_48045:
    call function_47945                     
    exit                                    

function_48047:
    mov64 r3, r2                                    r3 = r2
    ldxb r1, [r1+0x0]                       
    mov64 r2, 1                                     r2 = 1 as i32 as i64 as u64
    call function_47945                     
    exit                                    

function_48052:
    mov64 r3, r2                                    r3 = r2
    ldxw r4, [r1+0x0]                       
    lsh64 r4, 32                                    r4 <<= 32   ///  r4 = r4.wrapping_shl(32)
    arsh64 r4, 32                                   r4 >>= 32 (signed)   ///  r4 = (r4 as i64).wrapping_shr(32)
    jsgt r4, -1, lbb_48060                          if (r4 as i64) > (-1 as i32 as i64) { pc += 3 }
    mov64 r1, r4                                    r1 = r4
    neg64 r1                                        r1 = -r1   ///  r1 = (r1 as i64).wrapping_neg() as u64
    ja lbb_48061                                    if true { pc += 1 }
lbb_48060:
    mov64 r1, r4                                    r1 = r4
lbb_48061:
    mov64 r2, 1                                     r2 = 1 as i32 as i64 as u64
    jsgt r4, -1, lbb_48064                          if (r4 as i64) > (-1 as i32 as i64) { pc += 1 }
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
lbb_48064:
    call function_47945                     
    exit                                    

function_48066:
    mov64 r3, r2                                    r3 = r2
    ldxw r1, [r1+0x0]                       
    mov64 r2, 1                                     r2 = 1 as i32 as i64 as u64
    call function_47945                     
    exit                                    

function_48071:
    mov64 r3, r2                                    r3 = r2
    ldxdw r1, [r1+0x0]                      
    mov64 r2, 1                                     r2 = 1 as i32 as i64 as u64
    call function_47945                     
    exit                                    

function_48076:
    ldxdw r3, [r1+0x0]                      
    ldxdw r1, [r1+0x8]                      
    ldxdw r4, [r1+0x18]                     
    mov64 r1, r3                                    r1 = r3
    callx r4                                
    exit                                    

function_48082:
    mov64 r4, r2                                    r4 = r2
    ldxdw r3, [r1+0x8]                      
    ldxdw r2, [r1+0x0]                      
    mov64 r1, r4                                    r1 = r4
    call function_45728                     
    exit                                    

function_48088:
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
    mov64 r3, 33                                    r3 = 33 as i32 as i64 as u64
    mov64 r4, r1                                    r4 = r1
    lsh64 r4, 11                                    r4 <<= 11   ///  r4 = r4.wrapping_shl(11)
    lsh64 r4, 32                                    r4 <<= 32   ///  r4 = r4.wrapping_shl(32)
    rsh64 r4, 32                                    r4 >>= 32   ///  r4 = r4.wrapping_shr(32)
    mov64 r5, 33                                    r5 = 33 as i32 as i64 as u64
    ja lbb_48106                                    if true { pc += 10 }
lbb_48096:
    jeq r6, 1, lbb_48102                            if r6 == (1 as i32 as i64 as u64) { pc += 5 }
    and64 r6, 255                                   r6 &= 255   ///  r6 = r6.and(255)
    jne r6, 255, lbb_48124                          if r6 != (255 as i32 as i64 as u64) { pc += 25 }
    mov64 r2, r3                                    r2 = r3
    add64 r2, 1                                     r2 += 1   ///  r2 = r2.wrapping_add(1 as i32 as i64 as u64)
    mov64 r3, r5                                    r3 = r5
lbb_48102:
    mov64 r5, r3                                    r5 = r3
    sub64 r3, r2                                    r3 -= r2   ///  r3 = r3.wrapping_sub(r2)
    jgt r5, r2, lbb_48106                           if r5 > r2 { pc += 1 }
    ja lbb_48126                                    if true { pc += 20 }
lbb_48106:
    rsh64 r3, 1                                     r3 >>= 1   ///  r3 = r3.wrapping_shr(1)
    add64 r3, r2                                    r3 += r2   ///  r3 = r3.wrapping_add(r2)
    mov64 r0, r3                                    r0 = r3
    lsh64 r0, 2                                     r0 <<= 2   ///  r0 = r0.wrapping_shl(2)
    lddw r6, 0x100064658 --> b"\x00\x03\x00\x00\x83\x04 \x00\x91\x05`\x00]\x13\xa0\x00\x12\x17 \x1f\x0c …        r6 load str located at 4295378520
    add64 r6, r0                                    r6 += r0   ///  r6 = r6.wrapping_add(r0)
    ldxw r0, [r6+0x0]                       
    lsh64 r0, 11                                    r0 <<= 11   ///  r0 = r0.wrapping_shl(11)
    lsh64 r0, 32                                    r0 <<= 32   ///  r0 = r0.wrapping_shl(32)
    rsh64 r0, 32                                    r0 >>= 32   ///  r0 = r0.wrapping_shr(32)
    mov64 r7, 1                                     r7 = 1 as i32 as i64 as u64
    jne r0, r4, lbb_48120                           if r0 != r4 { pc += 1 }
    mov64 r7, 0                                     r7 = 0 as i32 as i64 as u64
lbb_48120:
    mov64 r6, -1                                    r6 = -1 as i32 as i64 as u64
    jgt r4, r0, lbb_48096                           if r4 > r0 { pc += -26 }
    mov64 r6, r7                                    r6 = r7
    ja lbb_48096                                    if true { pc += -28 }
lbb_48124:
    add64 r3, 1                                     r3 += 1   ///  r3 = r3.wrapping_add(1 as i32 as i64 as u64)
    mov64 r2, r3                                    r2 = r3
lbb_48126:
    jgt r2, 32, lbb_48184                           if r2 > (32 as i32 as i64 as u64) { pc += 57 }
    mov64 r6, r2                                    r6 = r2
    lsh64 r6, 2                                     r6 <<= 2   ///  r6 = r6.wrapping_shl(2)
    lddw r4, 0x100064658 --> b"\x00\x03\x00\x00\x83\x04 \x00\x91\x05`\x00]\x13\xa0\x00\x12\x17 \x1f\x0c …        r4 load str located at 4295378520
    lddw r0, 0x100064658 --> b"\x00\x03\x00\x00\x83\x04 \x00\x91\x05`\x00]\x13\xa0\x00\x12\x17 \x1f\x0c …        r0 load str located at 4295378520
    add64 r0, r6                                    r0 += r6   ///  r0 = r0.wrapping_add(r6)
    mov64 r5, 31                                    r5 = 31 as i32 as i64 as u64
    mov64 r3, 727                                   r3 = 727 as i32 as i64 as u64
    ldxw r0, [r0+0x0]                       
    rsh64 r0, 21                                    r0 >>= 21   ///  r0 = r0.wrapping_shr(21)
    jeq r2, 32, lbb_48146                           if r2 == (32 as i32 as i64 as u64) { pc += 7 }
    add64 r6, r4                                    r6 += r4   ///  r6 = r6.wrapping_add(r4)
    mov64 r5, 0                                     r5 = 0 as i32 as i64 as u64
    ldxw r3, [r6+0x4]                       
    rsh64 r3, 21                                    r3 >>= 21   ///  r3 = r3.wrapping_shr(21)
    jeq r2, 0, lbb_48150                            if r2 == (0 as i32 as i64 as u64) { pc += 6 }
    add64 r2, -1                                    r2 += -1   ///  r2 = r2.wrapping_add(-1 as i32 as i64 as u64)
    mov64 r5, r2                                    r5 = r2
lbb_48146:
    lsh64 r5, 2                                     r5 <<= 2   ///  r5 = r5.wrapping_shl(2)
    add64 r4, r5                                    r4 += r5   ///  r4 = r4.wrapping_add(r5)
    ldxw r5, [r4+0x0]                       
    and64 r5, 2097151                               r5 &= 2097151   ///  r5 = r5.and(2097151)
lbb_48150:
    mov64 r2, r0                                    r2 = r0
    xor64 r2, -1                                    r2 ^= -1   ///  r2 = r2.xor(-1)
    add64 r3, r2                                    r3 += r2   ///  r3 = r3.wrapping_add(r2)
    jeq r3, 0, lbb_48176                            if r3 == (0 as i32 as i64 as u64) { pc += 22 }
    sub64 r1, r5                                    r1 -= r5   ///  r1 = r1.wrapping_sub(r5)
    lddw r5, 0x1000646dc --> b"\x00p\x00\x07\x00-\x01\x01\x01\x02\x01\x02\x01\x01H\x0b0\x15\x10\x01e\x07…        r5 load str located at 4295378652
    add64 r5, r0                                    r5 += r0   ///  r5 = r5.wrapping_add(r0)
    mov64 r4, 0                                     r4 = 0 as i32 as i64 as u64
    lsh64 r1, 32                                    r1 <<= 32   ///  r1 = r1.wrapping_shl(32)
    rsh64 r1, 32                                    r1 >>= 32   ///  r1 = r1.wrapping_shr(32)
    mov64 r6, 0                                     r6 = 0 as i32 as i64 as u64
lbb_48162:
    mov64 r2, r0                                    r2 = r0
    add64 r2, r4                                    r2 += r4   ///  r2 = r2.wrapping_add(r4)
    jgt r2, 726, lbb_48178                          if r2 > (726 as i32 as i64 as u64) { pc += 13 }
    mov64 r2, r5                                    r2 = r5
    add64 r2, r4                                    r2 += r4   ///  r2 = r2.wrapping_add(r4)
    ldxb r2, [r2+0x0]                       
    add64 r6, r2                                    r6 += r2   ///  r6 = r6.wrapping_add(r2)
    mov64 r2, r6                                    r2 = r6
    lsh64 r2, 32                                    r2 <<= 32   ///  r2 = r2.wrapping_shl(32)
    rsh64 r2, 32                                    r2 >>= 32   ///  r2 = r2.wrapping_shr(32)
    jgt r2, r1, lbb_48175                           if r2 > r1 { pc += 2 }
    add64 r4, 1                                     r4 += 1   ///  r4 = r4.wrapping_add(1 as i32 as i64 as u64)
    jgt r3, r4, lbb_48162                           if r3 > r4 { pc += -13 }
lbb_48175:
    add64 r0, r4                                    r0 += r4   ///  r0 = r0.wrapping_add(r4)
lbb_48176:
    and64 r0, 1                                     r0 &= 1   ///  r0 = r0.and(1)
    exit                                    
lbb_48178:
    mov64 r1, r2                                    r1 = r2
    mov64 r2, 727                                   r2 = 727 as i32 as i64 as u64
    lddw r3, 0x100067510 --> b"\x00\x00\x00\x00\x13F\x06\x00(\x00\x00\x00\x00\x00\x00\x00\\x00\x00\x00\x…        r3 load str located at 4295390480
    call function_44272                     
    syscall [invalid]                       
lbb_48184:
    mov64 r1, r2                                    r1 = r2
    mov64 r2, 33                                    r2 = 33 as i32 as i64 as u64
    lddw r3, 0x1000674f8 --> b"\x00\x00\x00\x00\x13F\x06\x00(\x00\x00\x00\x00\x00\x00\x00P\x00\x00\x00(\…        r3 load str located at 4295390456
    call function_44272                     
    syscall [invalid]                       

function_48190:
    mov64 r6, r1                                    r6 = r1
    mov64 r4, r3                                    r4 = r3
    rsh64 r4, 3                                     r4 >>= 3   ///  r4 = r4.wrapping_shr(3)
    mov64 r1, r4                                    r1 = r4
    mul64 r1, -7                                    r1 *= -7   ///  r1 = r1.wrapping_mul(-7 as u64)
    add64 r1, r3                                    r1 += r3   ///  r1 = r1.wrapping_add(r3)
    jgt r1, 15, lbb_48221                           if r1 > (15 as i32 as i64 as u64) { pc += 24 }
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    mov64 r5, 8                                     r5 = 8 as i32 as i64 as u64
    jgt r5, r3, lbb_48210                           if r5 > r3 { pc += 10 }
    mov64 r5, 0                                     r5 = 0 as i32 as i64 as u64
lbb_48201:
    mov64 r0, r6                                    r0 = r6
    add64 r0, r1                                    r0 += r1   ///  r0 = r0.wrapping_add(r1)
    mov64 r7, r2                                    r7 = r2
    add64 r7, r1                                    r7 += r1   ///  r7 = r7.wrapping_add(r1)
    ldxdw r7, [r7+0x0]                      
    stxdw [r0+0x0], r7                      
    add64 r1, 8                                     r1 += 8   ///  r1 = r1.wrapping_add(8 as i32 as i64 as u64)
    add64 r5, 1                                     r5 += 1   ///  r5 = r5.wrapping_add(1 as i32 as i64 as u64)
    jgt r4, r5, lbb_48201                           if r4 > r5 { pc += -9 }
lbb_48210:
    jsge r1, r3, lbb_48219                          if (r1 as i64) >= (r3 as i64) { pc += 8 }
lbb_48211:
    mov64 r4, r6                                    r4 = r6
    add64 r4, r1                                    r4 += r1   ///  r4 = r4.wrapping_add(r1)
    mov64 r5, r2                                    r5 = r2
    add64 r5, r1                                    r5 += r1   ///  r5 = r5.wrapping_add(r1)
    ldxb r5, [r5+0x0]                       
    stxb [r4+0x0], r5                       
    add64 r1, 1                                     r1 += 1   ///  r1 = r1.wrapping_add(1 as i32 as i64 as u64)
    jsgt r3, r1, lbb_48211                          if (r3 as i64) > (r1 as i64) { pc += -8 }
lbb_48219:
    mov64 r0, r6                                    r0 = r6
    exit                                    
lbb_48221:
    mov64 r1, r6                                    r1 = r6
    syscall [invalid]                       
    ja lbb_48219                                    if true { pc += -5 }

function_48224:
    mov64 r6, r1                                    r6 = r1
    mov64 r1, r3                                    r1 = r3
    rsh64 r1, 3                                     r1 >>= 3   ///  r1 = r1.wrapping_shr(3)
    mov64 r4, r1                                    r4 = r1
    mul64 r4, -7                                    r4 *= -7   ///  r4 = r4.wrapping_mul(-7 as u64)
    add64 r4, r3                                    r4 += r3   ///  r4 = r4.wrapping_add(r3)
    jgt r4, 15, lbb_48265                           if r4 > (15 as i32 as i64 as u64) { pc += 34 }
    jge r2, r6, lbb_48268                           if r2 >= r6 { pc += 36 }
    mov64 r4, r3                                    r4 = r3
    and64 r4, -8                                    r4 &= -8   ///  r4 = r4.and(-8)
    jsge r4, r3, lbb_48248                          if (r4 as i64) >= (r3 as i64) { pc += 13 }
    mov64 r5, r2                                    r5 = r2
    add64 r5, -1                                    r5 += -1   ///  r5 = r5.wrapping_add(-1 as i32 as i64 as u64)
    mov64 r0, r6                                    r0 = r6
    add64 r0, -1                                    r0 += -1   ///  r0 = r0.wrapping_add(-1 as i32 as i64 as u64)
    mov64 r7, r3                                    r7 = r3
lbb_48240:
    mov64 r8, r0                                    r8 = r0
    add64 r8, r7                                    r8 += r7   ///  r8 = r8.wrapping_add(r7)
    mov64 r9, r5                                    r9 = r5
    add64 r9, r7                                    r9 += r7   ///  r9 = r9.wrapping_add(r7)
    ldxb r9, [r9+0x0]                       
    stxb [r8+0x0], r9                       
    add64 r7, -1                                    r7 += -1   ///  r7 = r7.wrapping_add(-1 as i32 as i64 as u64)
    jsgt r7, r4, lbb_48240                          if (r7 as i64) > (r4 as i64) { pc += -8 }
lbb_48248:
    mov64 r4, 8                                     r4 = 8 as i32 as i64 as u64
    jgt r4, r3, lbb_48263                           if r4 > r3 { pc += 13 }
    mov64 r4, r1                                    r4 = r1
    lsh64 r4, 3                                     r4 <<= 3   ///  r4 = r4.wrapping_shl(3)
    add64 r4, -8                                    r4 += -8   ///  r4 = r4.wrapping_add(-8 as i32 as i64 as u64)
    add64 r2, r4                                    r2 += r4   ///  r2 = r2.wrapping_add(r4)
    mov64 r3, r6                                    r3 = r6
    add64 r3, r4                                    r3 += r4   ///  r3 = r3.wrapping_add(r4)
    add64 r1, 1                                     r1 += 1   ///  r1 = r1.wrapping_add(1 as i32 as i64 as u64)
lbb_48257:
    ldxdw r4, [r2+0x0]                      
    stxdw [r3+0x0], r4                      
    add64 r2, -8                                    r2 += -8   ///  r2 = r2.wrapping_add(-8 as i32 as i64 as u64)
    add64 r3, -8                                    r3 += -8   ///  r3 = r3.wrapping_add(-8 as i32 as i64 as u64)
    add64 r1, -1                                    r1 += -1   ///  r1 = r1.wrapping_add(-1 as i32 as i64 as u64)
    jsgt r1, 1, lbb_48257                           if (r1 as i64) > (1 as i32 as i64) { pc += -6 }
lbb_48263:
    mov64 r0, r6                                    r0 = r6
    exit                                    
lbb_48265:
    mov64 r1, r6                                    r1 = r6
    syscall [invalid]                       
    ja lbb_48263                                    if true { pc += -5 }
lbb_48268:
    mov64 r4, 0                                     r4 = 0 as i32 as i64 as u64
    mov64 r5, 8                                     r5 = 8 as i32 as i64 as u64
    jgt r5, r3, lbb_48281                           if r5 > r3 { pc += 10 }
    mov64 r5, 0                                     r5 = 0 as i32 as i64 as u64
lbb_48272:
    mov64 r0, r6                                    r0 = r6
    add64 r0, r4                                    r0 += r4   ///  r0 = r0.wrapping_add(r4)
    mov64 r7, r2                                    r7 = r2
    add64 r7, r4                                    r7 += r4   ///  r7 = r7.wrapping_add(r4)
    ldxdw r7, [r7+0x0]                      
    stxdw [r0+0x0], r7                      
    add64 r4, 8                                     r4 += 8   ///  r4 = r4.wrapping_add(8 as i32 as i64 as u64)
    add64 r5, 1                                     r5 += 1   ///  r5 = r5.wrapping_add(1 as i32 as i64 as u64)
    jgt r1, r5, lbb_48272                           if r1 > r5 { pc += -9 }
lbb_48281:
    jsge r4, r3, lbb_48263                          if (r4 as i64) >= (r3 as i64) { pc += -19 }
lbb_48282:
    mov64 r1, r6                                    r1 = r6
    add64 r1, r4                                    r1 += r4   ///  r1 = r1.wrapping_add(r4)
    mov64 r5, r2                                    r5 = r2
    add64 r5, r4                                    r5 += r4   ///  r5 = r5.wrapping_add(r4)
    ldxb r5, [r5+0x0]                       
    stxb [r1+0x0], r5                       
    add64 r4, 1                                     r4 += 1   ///  r4 = r4.wrapping_add(1 as i32 as i64 as u64)
    jsgt r3, r4, lbb_48282                          if (r3 as i64) > (r4 as i64) { pc += -8 }
    ja lbb_48263                                    if true { pc += -28 }

function_48291:
    mov64 r6, r1                                    r6 = r1
    mov64 r4, r3                                    r4 = r3
    rsh64 r4, 3                                     r4 >>= 3   ///  r4 = r4.wrapping_shr(3)
    mov64 r1, r4                                    r1 = r4
    mul64 r1, -7                                    r1 *= -7   ///  r1 = r1.wrapping_mul(-7 as u64)
    add64 r1, r3                                    r1 += r3   ///  r1 = r1.wrapping_add(r3)
    jgt r1, 15, lbb_48321                           if r1 > (15 as i32 as i64 as u64) { pc += 23 }
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    mov64 r5, 8                                     r5 = 8 as i32 as i64 as u64
    jgt r5, r3, lbb_48314                           if r5 > r3 { pc += 13 }
    mov64 r5, r2                                    r5 = r2
    and64 r5, 255                                   r5 &= 255   ///  r5 = r5.and(255)
    lddw r1, 0x101010101010101                      r1 load str located at 72340172838076673
    mul64 r5, r1                                    r5 *= r1   ///  r5 = r5.wrapping_mul(r1)
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    mov64 r0, 0                                     r0 = 0 as i32 as i64 as u64
lbb_48308:
    mov64 r7, r6                                    r7 = r6
    add64 r7, r1                                    r7 += r1   ///  r7 = r7.wrapping_add(r1)
    stxdw [r7+0x0], r5                      
    add64 r1, 8                                     r1 += 8   ///  r1 = r1.wrapping_add(8 as i32 as i64 as u64)
    add64 r0, 1                                     r0 += 1   ///  r0 = r0.wrapping_add(1 as i32 as i64 as u64)
    jgt r4, r0, lbb_48308                           if r4 > r0 { pc += -6 }
lbb_48314:
    jsge r1, r3, lbb_48324                          if (r1 as i64) >= (r3 as i64) { pc += 9 }
lbb_48315:
    mov64 r4, r6                                    r4 = r6
    add64 r4, r1                                    r4 += r1   ///  r4 = r4.wrapping_add(r1)
    stxb [r4+0x0], r2                       
    add64 r1, 1                                     r1 += 1   ///  r1 = r1.wrapping_add(1 as i32 as i64 as u64)
    jsgt r3, r1, lbb_48315                          if (r3 as i64) > (r1 as i64) { pc += -5 }
    ja lbb_48324                                    if true { pc += 3 }
lbb_48321:
    and64 r2, 255                                   r2 &= 255   ///  r2 = r2.and(255)
    mov64 r1, r6                                    r1 = r6
    syscall [invalid]                       
lbb_48324:
    mov64 r0, r6                                    r0 = r6
    exit                                    

function_48326:
    mov64 r0, 0                                     r0 = 0 as i32 as i64 as u64
    lddw r2, 0x3ff0000000000000                     r2 load str located at 4607182418800017408
    jgt r2, r1, lbb_48349                           if r2 > r1 { pc += 19 }
    lddw r2, 0x43f0000000000000                     r2 load str located at 4895412794951729152
    jgt r2, r1, lbb_48339                           if r2 > r1 { pc += 6 }
    mov64 r0, -1                                    r0 = -1 as i32 as i64 as u64
    lddw r2, 0x7ff0000000000001                     r2 load str located at 9218868437227405313
    jgt r2, r1, lbb_48349                           if r2 > r1 { pc += 12 }
    mov64 r0, 0                                     r0 = 0 as i32 as i64 as u64
    ja lbb_48349                                    if true { pc += 10 }
lbb_48339:
    mov64 r0, r1                                    r0 = r1
    lsh64 r0, 11                                    r0 <<= 11   ///  r0 = r0.wrapping_shl(11)
    lddw r2, 0x8000000000000000                     r2 load str located at -9223372036854775808
    or64 r0, r2                                     r0 |= r2   ///  r0 = r0.or(r2)
    rsh64 r1, 52                                    r1 >>= 52   ///  r1 = r1.wrapping_shr(52)
    mov64 r2, 62                                    r2 = 62 as i32 as i64 as u64
    sub64 r2, r1                                    r2 -= r1   ///  r2 = r2.wrapping_sub(r1)
    and64 r2, 63                                    r2 &= 63   ///  r2 = r2.and(63)
    rsh64 r0, r2                                    r0 >>= r2   ///  r0 = r0.wrapping_shr(r2 as u32)
lbb_48349:
    exit                                    

function_48350:
    lddw r0, 0xffffffff                             r0 load str located at 4294967295
    lddw r5, 0x7fffffffffffffff                     r5 load str located at 9223372036854775807
    mov64 r3, r1                                    r3 = r1
    and64 r3, r5                                    r3 &= r5   ///  r3 = r3.and(r5)
    lddw r6, 0x7ff0000000000000                     r6 load str located at 9218868437227405312
    jgt r3, r6, lbb_48381                           if r3 > r6 { pc += 22 }
    mov64 r4, r2                                    r4 = r2
    and64 r4, r5                                    r4 &= r5   ///  r4 = r4.and(r5)
    jgt r4, r6, lbb_48381                           if r4 > r6 { pc += 19 }
    or64 r4, r3                                     r4 |= r3   ///  r4 = r4.or(r3)
    mov64 r0, 0                                     r0 = 0 as i32 as i64 as u64
    jeq r4, 0, lbb_48381                            if r4 == (0 as i32 as i64 as u64) { pc += 16 }
    mov64 r3, r2                                    r3 = r2
    and64 r3, r1                                    r3 &= r1   ///  r3 = r3.and(r1)
    jsgt r3, -1, lbb_48374                          if (r3 as i64) > (-1 as i32 as i64) { pc += 6 }
    lddw r0, 0xffffffff                             r0 load str located at 4294967295
    jsgt r1, r2, lbb_48381                          if (r1 as i64) > (r2 as i64) { pc += 10 }
    mov64 r0, 1                                     r0 = 1 as i32 as i64 as u64
    jeq r1, r2, lbb_48380                           if r1 == r2 { pc += 7 }
    ja lbb_48381                                    if true { pc += 7 }
lbb_48374:
    lddw r0, 0xffffffff                             r0 load str located at 4294967295
    jsgt r2, r1, lbb_48381                          if (r2 as i64) > (r1 as i64) { pc += 4 }
    mov64 r0, 1                                     r0 = 1 as i32 as i64 as u64
    jeq r1, r2, lbb_48380                           if r1 == r2 { pc += 1 }
    ja lbb_48381                                    if true { pc += 1 }
lbb_48380:
    mov64 r0, 0                                     r0 = 0 as i32 as i64 as u64
lbb_48381:
    lsh64 r0, 32                                    r0 <<= 32   ///  r0 = r0.wrapping_shl(32)
    arsh64 r0, 32                                   r0 >>= 32 (signed)   ///  r0 = (r0 as i64).wrapping_shr(32)
    exit                                    

function_48384:
    stxdw [r10-0x10], r3                    
    stxdw [r10-0x8], r1                     
    mov64 r1, r2                                    r1 = r2
    lsh64 r1, 32                                    r1 <<= 32   ///  r1 = r1.wrapping_shl(32)
    rsh64 r1, 32                                    r1 >>= 32   ///  r1 = r1.wrapping_shr(32)
    mov64 r7, r4                                    r7 = r4
    lsh64 r7, 32                                    r7 <<= 32   ///  r7 = r7.wrapping_shl(32)
    rsh64 r7, 32                                    r7 >>= 32   ///  r7 = r7.wrapping_shr(32)
    mov64 r6, r2                                    r6 = r2
    rsh64 r6, 32                                    r6 >>= 32   ///  r6 = r6.wrapping_shr(32)
    mov64 r3, r7                                    r3 = r7
    mul64 r3, r1                                    r3 *= r1   ///  r3 = r3.wrapping_mul(r1)
    mul64 r7, r6                                    r7 *= r6   ///  r7 = r7.wrapping_mul(r6)
    mov64 r0, r4                                    r0 = r4
    rsh64 r0, 32                                    r0 >>= 32   ///  r0 = r0.wrapping_shr(32)
    mov64 r9, r0                                    r9 = r0
    mul64 r9, r1                                    r9 *= r1   ///  r9 = r9.wrapping_mul(r1)
    mov64 r1, r9                                    r1 = r9
    add64 r1, r7                                    r1 += r7   ///  r1 = r1.wrapping_add(r7)
    mov64 r8, 1                                     r8 = 1 as i32 as i64 as u64
    jgt r9, r1, lbb_48406                           if r9 > r1 { pc += 1 }
    mov64 r8, 0                                     r8 = 0 as i32 as i64 as u64
lbb_48406:
    mov64 r9, r1                                    r9 = r1
    lsh64 r9, 32                                    r9 <<= 32   ///  r9 = r9.wrapping_shl(32)
    mov64 r7, r3                                    r7 = r3
    add64 r7, r9                                    r7 += r9   ///  r7 = r7.wrapping_add(r9)
    mov64 r9, 1                                     r9 = 1 as i32 as i64 as u64
    jgt r3, r7, lbb_48413                           if r3 > r7 { pc += 1 }
    mov64 r9, 0                                     r9 = 0 as i32 as i64 as u64
lbb_48413:
    ldxdw r3, [r10-0x8]                     
    stxdw [r3+0x0], r7                      
    rsh64 r1, 32                                    r1 >>= 32   ///  r1 = r1.wrapping_shr(32)
    lsh64 r8, 32                                    r8 <<= 32   ///  r8 = r8.wrapping_shl(32)
    or64 r8, r1                                     r8 |= r1   ///  r8 = r8.or(r1)
    ldxdw r1, [r10-0x10]                    
    mul64 r4, r1                                    r4 *= r1   ///  r4 = r4.wrapping_mul(r1)
    mul64 r5, r2                                    r5 *= r2   ///  r5 = r5.wrapping_mul(r2)
    mul64 r0, r6                                    r0 *= r6   ///  r0 = r0.wrapping_mul(r6)
    add64 r0, r8                                    r0 += r8   ///  r0 = r0.wrapping_add(r8)
    add64 r5, r4                                    r5 += r4   ///  r5 = r5.wrapping_add(r4)
    add64 r0, r9                                    r0 += r9   ///  r0 = r0.wrapping_add(r9)
    add64 r0, r5                                    r0 += r5   ///  r0 = r0.wrapping_add(r5)
    stxdw [r3+0x8], r0                      
    exit                                    

function_48428:
    mov64 r8, r4                                    r8 = r4
    mov64 r7, r2                                    r7 = r2
    mov64 r6, r7                                    r6 = r7
    or64 r6, r3                                     r6 |= r3   ///  r6 = r6.or(r3)
    mov64 r0, 0                                     r0 = 0 as i32 as i64 as u64
    mov64 r4, 0                                     r4 = 0 as i32 as i64 as u64
    ldxdw r9, [r5-0xff8]                    
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
    jeq r6, 0, lbb_48571                            if r6 == (0 as i32 as i64 as u64) { pc += 134 }
    ldxdw r2, [r5-0x1000]                   
    mov64 r5, r8                                    r5 = r8
    mov64 r6, r2                                    r6 = r2
    or64 r5, r2                                     r5 |= r2   ///  r5 = r5.or(r2)
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
    jeq r5, 0, lbb_48571                            if r5 == (0 as i32 as i64 as u64) { pc += 128 }
    mov64 r0, r8                                    r0 = r8
    mov64 r5, r7                                    r5 = r7
    mov64 r4, 1                                     r4 = 1 as i32 as i64 as u64
    mov64 r2, 1                                     r2 = 1 as i32 as i64 as u64
    jne r0, 0, lbb_48449                            if r0 != (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
lbb_48449:
    stxdw [r10-0x58], r2                    
    jne r5, 0, lbb_48452                            if r5 != (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r4, 0                                     r4 = 0 as i32 as i64 as u64
lbb_48452:
    neg64 r8                                        r8 = -r8   ///  r8 = (r8 as i64).wrapping_neg() as u64
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
    jsgt r2, r6, lbb_48456                          if (r2 as i64) > (r6 as i64) { pc += 1 }
    mov64 r8, r0                                    r8 = r0
lbb_48456:
    stxdw [r10-0x70], r9                    
    stxdw [r10-0x68], r1                    
    neg64 r7                                        r7 = -r7   ///  r7 = (r7 as i64).wrapping_neg() as u64
    mov64 r0, 0                                     r0 = 0 as i32 as i64 as u64
    jsgt r0, r3, lbb_48462                          if (r0 as i64) > (r3 as i64) { pc += 1 }
    mov64 r7, r5                                    r7 = r5
lbb_48462:
    mov64 r9, r3                                    r9 = r3
    add64 r9, r4                                    r9 += r4   ///  r9 = r9.wrapping_add(r4)
    mov64 r1, r6                                    r1 = r6
    ldxdw r2, [r10-0x58]                    
    add64 r6, r2                                    r6 += r2   ///  r6 = r6.wrapping_add(r2)
    neg64 r6                                        r6 = -r6   ///  r6 = (r6 as i64).wrapping_neg() as u64
    jsgt r0, r1, lbb_48470                          if (r0 as i64) > (r1 as i64) { pc += 1 }
    mov64 r6, r1                                    r6 = r1
lbb_48470:
    neg64 r9                                        r9 = -r9   ///  r9 = (r9 as i64).wrapping_neg() as u64
    jsgt r0, r3, lbb_48473                          if (r0 as i64) > (r3 as i64) { pc += 1 }
    mov64 r9, r3                                    r9 = r3
lbb_48473:
    xor64 r1, r3                                    r1 ^= r3   ///  r1 = r1.xor(r3)
    stxdw [r10-0x58], r1                    
    jeq r9, 0, lbb_48504                            if r9 == (0 as i32 as i64 as u64) { pc += 28 }
    jeq r6, 0, lbb_48478                            if r6 == (0 as i32 as i64 as u64) { pc += 1 }
    ja lbb_48538                                    if true { pc += 60 }
lbb_48478:
    mov64 r1, r10                                   r1 = r10
    add64 r1, -32                                   r1 += -32   ///  r1 = r1.wrapping_add(-32 as i32 as i64 as u64)
    mov64 r2, r7                                    r2 = r7
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
    mov64 r4, r8                                    r4 = r8
    mov64 r5, r6                                    r5 = r6
    call function_48384                     
    mov64 r1, r10                                   r1 = r10
    add64 r1, -48                                   r1 += -48   ///  r1 = r1.wrapping_add(-48 as i32 as i64 as u64)
    mov64 r2, r9                                    r2 = r9
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
    mov64 r4, r8                                    r4 = r8
    mov64 r5, r6                                    r5 = r6
    call function_48384                     
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    stxdw [r10-0x60], r1                    
    ldxdw r8, [r10-0x20]                    
    ldxdw r2, [r10-0x30]                    
    ldxdw r1, [r10-0x18]                    
    mov64 r3, r1                                    r3 = r1
    add64 r3, r2                                    r3 += r2   ///  r3 = r3.wrapping_add(r2)
    jgt r1, r3, lbb_48549                           if r1 > r3 { pc += 49 }
    ldxdw r2, [r10-0x28]                    
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    jne r2, 0, lbb_48536                            if r2 != (0 as i32 as i64 as u64) { pc += 33 }
    ja lbb_48535                                    if true { pc += 31 }
lbb_48504:
    mov64 r1, r10                                   r1 = r10
    add64 r1, -64                                   r1 += -64   ///  r1 = r1.wrapping_add(-64 as i32 as i64 as u64)
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
    stxdw [r10-0x60], r2                    
    mov64 r2, r8                                    r2 = r8
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
    mov64 r4, r7                                    r4 = r7
    mov64 r5, r9                                    r5 = r9
    call function_48384                     
    ldxdw r1, [r10-0x38]                    
    ldxdw r8, [r10-0x40]                    
    mov64 r3, r1                                    r3 = r1
    jeq r6, 0, lbb_48549                            if r6 == (0 as i32 as i64 as u64) { pc += 32 }
    stxdw [r10-0x78], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -80                                   r1 += -80   ///  r1 = r1.wrapping_add(-80 as i32 as i64 as u64)
    mov64 r2, r6                                    r2 = r6
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
    mov64 r4, r7                                    r4 = r7
    mov64 r5, r9                                    r5 = r9
    call function_48384                     
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    stxdw [r10-0x60], r1                    
    ldxdw r2, [r10-0x50]                    
    ldxdw r1, [r10-0x78]                    
    mov64 r3, r1                                    r3 = r1
    add64 r3, r2                                    r3 += r2   ///  r3 = r3.wrapping_add(r2)
    jgt r1, r3, lbb_48549                           if r1 > r3 { pc += 17 }
    ldxdw r2, [r10-0x48]                    
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    jne r2, 0, lbb_48536                            if r2 != (0 as i32 as i64 as u64) { pc += 1 }
lbb_48535:
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
lbb_48536:
    stxdw [r10-0x60], r1                    
    ja lbb_48549                                    if true { pc += 11 }
lbb_48538:
    mov64 r1, r10                                   r1 = r10
    add64 r1, -16                                   r1 += -16   ///  r1 = r1.wrapping_add(-16 as i32 as i64 as u64)
    mov64 r2, r8                                    r2 = r8
    mov64 r3, r6                                    r3 = r6
    mov64 r4, r7                                    r4 = r7
    mov64 r5, r9                                    r5 = r9
    call function_48384                     
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    stxdw [r10-0x60], r1                    
    ldxdw r3, [r10-0x8]                     
    ldxdw r8, [r10-0x10]                    
lbb_48549:
    mov64 r2, r8                                    r2 = r8
    neg64 r2                                        r2 = -r2   ///  r2 = (r2 as i64).wrapping_neg() as u64
    mov64 r6, 0                                     r6 = 0 as i32 as i64 as u64
    ldxdw r1, [r10-0x58]                    
    jsgt r6, r1, lbb_48555                          if (r6 as i64) > (r1 as i64) { pc += 1 }
    mov64 r2, r8                                    r2 = r8
lbb_48555:
    mov64 r4, 1                                     r4 = 1 as i32 as i64 as u64
    mov64 r5, 1                                     r5 = 1 as i32 as i64 as u64
    ldxdw r1, [r10-0x68]                    
    ldxdw r9, [r10-0x70]                    
    jne r8, 0, lbb_48561                            if r8 != (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r5, 0                                     r5 = 0 as i32 as i64 as u64
lbb_48561:
    mov64 r0, r3                                    r0 = r3
    add64 r0, r5                                    r0 += r5   ///  r0 = r0.wrapping_add(r5)
    neg64 r0                                        r0 = -r0   ///  r0 = (r0 as i64).wrapping_neg() as u64
    ldxdw r5, [r10-0x58]                    
    jsgt r6, r5, lbb_48567                          if (r6 as i64) > (r5 as i64) { pc += 1 }
    mov64 r0, r3                                    r0 = r3
lbb_48567:
    mov64 r3, r0                                    r3 = r0
    xor64 r3, r5                                    r3 ^= r5   ///  r3 = r3.xor(r5)
    jsgt r6, r3, lbb_48571                          if (r6 as i64) > (r3 as i64) { pc += 1 }
    ldxdw r4, [r10-0x60]                    
lbb_48571:
    and64 r4, 1                                     r4 &= 1   ///  r4 = r4.and(1)
    stxw [r9+0x0], r4                       
    stxdw [r1+0x8], r0                      
    stxdw [r1+0x0], r2                      
    exit                                    

function_48576:
    call function_48578                     
    exit                                    

function_48578:
    mov64 r6, r2                                    r6 = r2
    mov64 r3, r6                                    r3 = r6
    xor64 r3, r1                                    r3 ^= r1   ///  r3 = r3.xor(r1)
    lddw r2, 0x8000000000000000                     r2 load str located at -9223372036854775808
    and64 r3, r2                                    r3 &= r2   ///  r3 = r3.and(r2)
    stxdw [r10-0x18], r3                    
    lddw r5, 0xfffffffffffff                        r5 load str located at 4503599627370495
    mov64 r2, r6                                    r2 = r6
    and64 r2, r5                                    r2 &= r5   ///  r2 = r2.and(r5)
    mov64 r4, r1                                    r4 = r1
    and64 r4, r5                                    r4 &= r5   ///  r4 = r4.and(r5)
    mov64 r7, r6                                    r7 = r6
    rsh64 r7, 52                                    r7 >>= 52   ///  r7 = r7.wrapping_shr(52)
    and64 r7, 2047                                  r7 &= 2047   ///  r7 = r7.and(2047)
    mov64 r8, r1                                    r8 = r1
    rsh64 r8, 52                                    r8 >>= 52   ///  r8 = r8.wrapping_shr(52)
    and64 r8, 2047                                  r8 &= 2047   ///  r8 = r8.and(2047)
    mov64 r5, r8                                    r5 = r8
    add64 r5, -2047                                 r5 += -2047   ///  r5 = r5.wrapping_add(-2047 as i32 as i64 as u64)
    mov64 r0, -2046                                 r0 = -2046 as i32 as i64 as u64
    jgt r0, r5, lbb_48605                           if r0 > r5 { pc += 4 }
    mov64 r9, 0                                     r9 = 0 as i32 as i64 as u64
    mov64 r5, r7                                    r5 = r7
    add64 r5, -2047                                 r5 += -2047   ///  r5 = r5.wrapping_add(-2047 as i32 as i64 as u64)
    jgt r5, -2047, lbb_48758                        if r5 > (-2047 as i32 as i64 as u64) { pc += 153 }
lbb_48605:
    lddw r9, 0x7fffffffffffffff                     r9 load str located at 9223372036854775807
    mov64 r5, r1                                    r5 = r1
    and64 r5, r9                                    r5 &= r9   ///  r5 = r5.and(r9)
    lddw r0, 0x7ff0000000000000                     r0 load str located at 9218868437227405312
    jgt r5, r0, lbb_48620                           if r5 > r0 { pc += 8 }
    mov64 r3, r6                                    r3 = r6
    and64 r3, r9                                    r3 &= r9   ///  r3 = r3.and(r9)
    jgt r3, r0, lbb_48616                           if r3 > r0 { pc += 1 }
    ja lbb_48625                                    if true { pc += 9 }
lbb_48616:
    lddw r1, 0x8000000000000                        r1 load str located at 2251799813685248
    or64 r6, r1                                     r6 |= r1   ///  r6 = r6.or(r1)
    ja lbb_48634                                    if true { pc += 14 }
lbb_48620:
    lddw r2, 0x8000000000000                        r2 load str located at 2251799813685248
    or64 r1, r2                                     r1 |= r2   ///  r1 = r1.or(r2)
    mov64 r0, r1                                    r0 = r1
    ja lbb_48830                                    if true { pc += 205 }
lbb_48625:
    jeq r5, r0, lbb_48627                           if r5 == r0 { pc += 1 }
    ja lbb_48636                                    if true { pc += 9 }
lbb_48627:
    lddw r0, 0x7ff8000000000000                     r0 load str located at 9221120237041090560
    jeq r3, 0, lbb_48830                            if r3 == (0 as i32 as i64 as u64) { pc += 200 }
    lddw r2, 0x8000000000000000                     r2 load str located at -9223372036854775808
    and64 r6, r2                                    r6 &= r2   ///  r6 = r6.and(r2)
    xor64 r6, r1                                    r6 ^= r1   ///  r6 = r6.xor(r1)
lbb_48634:
    mov64 r0, r6                                    r0 = r6
    ja lbb_48830                                    if true { pc += 194 }
lbb_48636:
    jeq r3, r0, lbb_48638                           if r3 == r0 { pc += 1 }
    ja lbb_48647                                    if true { pc += 9 }
lbb_48638:
    lddw r0, 0x7ff8000000000000                     r0 load str located at 9221120237041090560
    jeq r5, 0, lbb_48830                            if r5 == (0 as i32 as i64 as u64) { pc += 189 }
    lddw r2, 0x8000000000000000                     r2 load str located at -9223372036854775808
    and64 r1, r2                                    r1 &= r2   ///  r1 = r1.and(r2)
    xor64 r1, r6                                    r1 ^= r6   ///  r1 = r1.xor(r6)
    mov64 r0, r1                                    r0 = r1
    ja lbb_48830                                    if true { pc += 183 }
lbb_48647:
    jeq r5, 0, lbb_48831                            if r5 == (0 as i32 as i64 as u64) { pc += 183 }
    jeq r3, 0, lbb_48831                            if r3 == (0 as i32 as i64 as u64) { pc += 182 }
    mov64 r6, r3                                    r6 = r3
    mov64 r9, 0                                     r9 = 0 as i32 as i64 as u64
    lddw r1, 0x10000000000000                       r1 load str located at 4503599627370496
    jgt r1, r5, lbb_48655                           if r1 > r5 { pc += 1 }
    ja lbb_48705                                    if true { pc += 50 }
lbb_48655:
    mov64 r3, 64                                    r3 = 64 as i32 as i64 as u64
    jeq r4, 0, lbb_48700                            if r4 == (0 as i32 as i64 as u64) { pc += 43 }
    mov64 r3, r4                                    r3 = r4
    rsh64 r3, 1                                     r3 >>= 1   ///  r3 = r3.wrapping_shr(1)
    mov64 r1, r4                                    r1 = r4
    or64 r1, r3                                     r1 |= r3   ///  r1 = r1.or(r3)
    mov64 r3, r1                                    r3 = r1
    rsh64 r3, 2                                     r3 >>= 2   ///  r3 = r3.wrapping_shr(2)
    or64 r1, r3                                     r1 |= r3   ///  r1 = r1.or(r3)
    mov64 r3, r1                                    r3 = r1
    rsh64 r3, 4                                     r3 >>= 4   ///  r3 = r3.wrapping_shr(4)
    or64 r1, r3                                     r1 |= r3   ///  r1 = r1.or(r3)
    mov64 r3, r1                                    r3 = r1
    rsh64 r3, 8                                     r3 >>= 8   ///  r3 = r3.wrapping_shr(8)
    or64 r1, r3                                     r1 |= r3   ///  r1 = r1.or(r3)
    mov64 r3, r1                                    r3 = r1
    rsh64 r3, 16                                    r3 >>= 16   ///  r3 = r3.wrapping_shr(16)
    or64 r1, r3                                     r1 |= r3   ///  r1 = r1.or(r3)
    mov64 r3, r1                                    r3 = r1
    rsh64 r3, 32                                    r3 >>= 32   ///  r3 = r3.wrapping_shr(32)
    or64 r1, r3                                     r1 |= r3   ///  r1 = r1.or(r3)
    xor64 r1, -1                                    r1 ^= -1   ///  r1 = r1.xor(-1)
    lddw r3, 0x5555555555555555                     r3 load str located at 6148914691236517205
    mov64 r5, r1                                    r5 = r1
    rsh64 r5, 1                                     r5 >>= 1   ///  r5 = r5.wrapping_shr(1)
    and64 r5, r3                                    r5 &= r3   ///  r5 = r5.and(r3)
    sub64 r1, r5                                    r1 -= r5   ///  r1 = r1.wrapping_sub(r5)
    lddw r5, 0x3333333333333333                     r5 load str located at 3689348814741910323
    mov64 r3, r1                                    r3 = r1
    and64 r3, r5                                    r3 &= r5   ///  r3 = r3.and(r5)
    rsh64 r1, 2                                     r1 >>= 2   ///  r1 = r1.wrapping_shr(2)
    and64 r1, r5                                    r1 &= r5   ///  r1 = r1.and(r5)
    add64 r3, r1                                    r3 += r1   ///  r3 = r3.wrapping_add(r1)
    mov64 r1, r3                                    r1 = r3
    rsh64 r1, 4                                     r1 >>= 4   ///  r1 = r1.wrapping_shr(4)
    add64 r3, r1                                    r3 += r1   ///  r3 = r3.wrapping_add(r1)
    lddw r1, 0xf0f0f0f0f0f0f0f                      r1 load str located at 1085102592571150095
    and64 r3, r1                                    r3 &= r1   ///  r3 = r3.and(r1)
    lddw r1, 0x101010101010101                      r1 load str located at 72340172838076673
    mul64 r3, r1                                    r3 *= r1   ///  r3 = r3.wrapping_mul(r1)
    rsh64 r3, 56                                    r3 >>= 56   ///  r3 = r3.wrapping_shr(56)
lbb_48700:
    mov64 r9, 12                                    r9 = 12 as i32 as i64 as u64
    sub64 r9, r3                                    r9 -= r3   ///  r9 = r9.wrapping_sub(r3)
    add64 r3, 53                                    r3 += 53   ///  r3 = r3.wrapping_add(53 as i32 as i64 as u64)
    and64 r3, 63                                    r3 &= 63   ///  r3 = r3.and(63)
    lsh64 r4, r3                                    r4 <<= r3   ///  r4 = r4.wrapping_shl(r3 as u32)
lbb_48705:
    lddw r1, 0xfffffffffffff                        r1 load str located at 4503599627370495
    jgt r6, r1, lbb_48758                           if r6 > r1 { pc += 50 }
    mov64 r3, 64                                    r3 = 64 as i32 as i64 as u64
    jeq r2, 0, lbb_48753                            if r2 == (0 as i32 as i64 as u64) { pc += 43 }
    mov64 r3, r2                                    r3 = r2
    rsh64 r3, 1                                     r3 >>= 1   ///  r3 = r3.wrapping_shr(1)
    mov64 r1, r2                                    r1 = r2
    or64 r1, r3                                     r1 |= r3   ///  r1 = r1.or(r3)
    mov64 r3, r1                                    r3 = r1
    rsh64 r3, 2                                     r3 >>= 2   ///  r3 = r3.wrapping_shr(2)
    or64 r1, r3                                     r1 |= r3   ///  r1 = r1.or(r3)
    mov64 r3, r1                                    r3 = r1
    rsh64 r3, 4                                     r3 >>= 4   ///  r3 = r3.wrapping_shr(4)
    or64 r1, r3                                     r1 |= r3   ///  r1 = r1.or(r3)
    mov64 r3, r1                                    r3 = r1
    rsh64 r3, 8                                     r3 >>= 8   ///  r3 = r3.wrapping_shr(8)
    or64 r1, r3                                     r1 |= r3   ///  r1 = r1.or(r3)
    mov64 r3, r1                                    r3 = r1
    rsh64 r3, 16                                    r3 >>= 16   ///  r3 = r3.wrapping_shr(16)
    or64 r1, r3                                     r1 |= r3   ///  r1 = r1.or(r3)
    mov64 r3, r1                                    r3 = r1
    rsh64 r3, 32                                    r3 >>= 32   ///  r3 = r3.wrapping_shr(32)
    or64 r1, r3                                     r1 |= r3   ///  r1 = r1.or(r3)
    xor64 r1, -1                                    r1 ^= -1   ///  r1 = r1.xor(-1)
    lddw r3, 0x5555555555555555                     r3 load str located at 6148914691236517205
    mov64 r5, r1                                    r5 = r1
    rsh64 r5, 1                                     r5 >>= 1   ///  r5 = r5.wrapping_shr(1)
    and64 r5, r3                                    r5 &= r3   ///  r5 = r5.and(r3)
    sub64 r1, r5                                    r1 -= r5   ///  r1 = r1.wrapping_sub(r5)
    lddw r5, 0x3333333333333333                     r5 load str located at 3689348814741910323
    mov64 r3, r1                                    r3 = r1
    and64 r3, r5                                    r3 &= r5   ///  r3 = r3.and(r5)
    rsh64 r1, 2                                     r1 >>= 2   ///  r1 = r1.wrapping_shr(2)
    and64 r1, r5                                    r1 &= r5   ///  r1 = r1.and(r5)
    add64 r3, r1                                    r3 += r1   ///  r3 = r3.wrapping_add(r1)
    mov64 r1, r3                                    r1 = r3
    rsh64 r1, 4                                     r1 >>= 4   ///  r1 = r1.wrapping_shr(4)
    add64 r3, r1                                    r3 += r1   ///  r3 = r3.wrapping_add(r1)
    lddw r1, 0xf0f0f0f0f0f0f0f                      r1 load str located at 1085102592571150095
    and64 r3, r1                                    r3 &= r1   ///  r3 = r3.and(r1)
    lddw r1, 0x101010101010101                      r1 load str located at 72340172838076673
    mul64 r3, r1                                    r3 *= r1   ///  r3 = r3.wrapping_mul(r1)
    rsh64 r3, 56                                    r3 >>= 56   ///  r3 = r3.wrapping_shr(56)
lbb_48753:
    sub64 r9, r3                                    r9 -= r3   ///  r9 = r9.wrapping_sub(r3)
    add64 r3, 53                                    r3 += 53   ///  r3 = r3.wrapping_add(53 as i32 as i64 as u64)
    and64 r3, 63                                    r3 &= 63   ///  r3 = r3.and(63)
    lsh64 r2, r3                                    r2 <<= r3   ///  r2 = r2.wrapping_shl(r3 as u32)
    add64 r9, 12                                    r9 += 12   ///  r9 = r9.wrapping_add(12 as i32 as i64 as u64)
lbb_48758:
    lsh64 r2, 11                                    r2 <<= 11   ///  r2 = r2.wrapping_shl(11)
    lddw r1, 0x8000000000000000                     r1 load str located at -9223372036854775808
    or64 r2, r1                                     r2 |= r1   ///  r2 = r2.or(r1)
    lddw r6, 0x10000000000000                       r6 load str located at 4503599627370496
    or64 r4, r6                                     r4 |= r6   ///  r4 = r4.or(r6)
    mov64 r1, r10                                   r1 = r10
    add64 r1, -16                                   r1 += -16   ///  r1 = r1.wrapping_add(-16 as i32 as i64 as u64)
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
    mov64 r5, 0                                     r5 = 0 as i32 as i64 as u64
    call function_48384                     
    add64 r7, r8                                    r7 += r8   ///  r7 = r7.wrapping_add(r8)
    add64 r7, r9                                    r7 += r9   ///  r7 = r7.wrapping_add(r9)
    ldxdw r2, [r10-0x8]                     
    mov64 r3, r2                                    r3 = r2
    and64 r3, r6                                    r3 &= r6   ///  r3 = r3.and(r6)
    ldxdw r1, [r10-0x10]                    
    jeq r3, 0, lbb_48778                            if r3 == (0 as i32 as i64 as u64) { pc += 1 }
    ja lbb_48791                                    if true { pc += 13 }
lbb_48778:
    lsh64 r2, 1                                     r2 <<= 1   ///  r2 = r2.wrapping_shl(1)
    mov64 r3, r1                                    r3 = r1
    rsh64 r3, 63                                    r3 >>= 63   ///  r3 = r3.wrapping_shr(63)
    or64 r2, r3                                     r2 |= r3   ///  r2 = r2.or(r3)
    lsh64 r1, 1                                     r1 <<= 1   ///  r1 = r1.wrapping_shl(1)
    add64 r7, -1023                                 r7 += -1023   ///  r7 = r7.wrapping_add(-1023 as i32 as i64 as u64)
    ldxdw r0, [r10-0x18]                    
    jsgt r7, 2046, lbb_48787                        if (r7 as i64) > (2046 as i32 as i64) { pc += 1 }
    ja lbb_48794                                    if true { pc += 7 }
lbb_48787:
    lddw r1, 0x7ff0000000000000                     r1 load str located at 9218868437227405312
    or64 r0, r1                                     r0 |= r1   ///  r0 = r0.or(r1)
    ja lbb_48830                                    if true { pc += 39 }
lbb_48791:
    add64 r7, -1022                                 r7 += -1022   ///  r7 = r7.wrapping_add(-1022 as i32 as i64 as u64)
    ldxdw r0, [r10-0x18]                    
    jsgt r7, 2046, lbb_48787                        if (r7 as i64) > (2046 as i32 as i64) { pc += -7 }
lbb_48794:
    mov64 r3, 1                                     r3 = 1 as i32 as i64 as u64
    jsgt r3, r7, lbb_48802                          if (r3 as i64) > (r7 as i64) { pc += 6 }
    lddw r3, 0xfffffffffffff                        r3 load str located at 4503599627370495
    and64 r2, r3                                    r2 &= r3   ///  r2 = r2.and(r3)
    lsh64 r7, 52                                    r7 <<= 52   ///  r7 = r7.wrapping_shl(52)
    or64 r7, r2                                     r7 |= r2   ///  r7 = r7.or(r2)
    ja lbb_48817                                    if true { pc += 15 }
lbb_48802:
    sub64 r3, r7                                    r3 -= r7   ///  r3 = r3.wrapping_sub(r7)
    jgt r3, 63, lbb_48830                           if r3 > (63 as i32 as i64 as u64) { pc += 26 }
    add64 r7, 63                                    r7 += 63   ///  r7 = r7.wrapping_add(63 as i32 as i64 as u64)
    lsh64 r7, 32                                    r7 <<= 32   ///  r7 = r7.wrapping_shl(32)
    rsh64 r7, 32                                    r7 >>= 32   ///  r7 = r7.wrapping_shr(32)
    mov64 r4, r2                                    r4 = r2
    or64 r4, r1                                     r4 |= r1   ///  r4 = r4.or(r1)
    lsh64 r4, r7                                    r4 <<= r7   ///  r4 = r4.wrapping_shl(r7 as u32)
    lsh64 r3, 32                                    r3 <<= 32   ///  r3 = r3.wrapping_shl(32)
    rsh64 r3, 32                                    r3 >>= 32   ///  r3 = r3.wrapping_shr(32)
    rsh64 r1, r3                                    r1 >>= r3   ///  r1 = r1.wrapping_shr(r3 as u32)
    or64 r4, r1                                     r4 |= r1   ///  r4 = r4.or(r1)
    rsh64 r2, r3                                    r2 >>= r3   ///  r2 = r2.wrapping_shr(r3 as u32)
    mov64 r1, r4                                    r1 = r4
    mov64 r7, r2                                    r7 = r2
lbb_48817:
    mov64 r2, r7                                    r2 = r7
    or64 r2, r0                                     r2 |= r0   ///  r2 = r2.or(r0)
    lddw r3, 0x8000000000000000                     r3 load str located at -9223372036854775808
    jgt r1, r3, lbb_48823                           if r1 > r3 { pc += 1 }
    ja lbb_48825                                    if true { pc += 2 }
lbb_48823:
    add64 r2, 1                                     r2 += 1   ///  r2 = r2.wrapping_add(1 as i32 as i64 as u64)
    ja lbb_48829                                    if true { pc += 4 }
lbb_48825:
    mov64 r0, r2                                    r0 = r2
    jne r1, r3, lbb_48830                           if r1 != r3 { pc += 3 }
    and64 r7, 1                                     r7 &= 1   ///  r7 = r7.and(1)
    add64 r2, r7                                    r2 += r7   ///  r2 = r2.wrapping_add(r7)
lbb_48829:
    mov64 r0, r2                                    r0 = r2
lbb_48830:
    exit                                    
lbb_48831:
    ldxdw r0, [r10-0x18]                    
    ja lbb_48830                                    if true { pc += -3 }

function_48833:
    mov64 r0, 0                                     r0 = 0 as i32 as i64 as u64
    jeq r1, 0, lbb_48895                            if r1 == (0 as i32 as i64 as u64) { pc += 60 }
    mov64 r3, r1                                    r3 = r1
    rsh64 r3, 1                                     r3 >>= 1   ///  r3 = r3.wrapping_shr(1)
    mov64 r2, r1                                    r2 = r1
    or64 r2, r3                                     r2 |= r3   ///  r2 = r2.or(r3)
    mov64 r3, r2                                    r3 = r2
    rsh64 r3, 2                                     r3 >>= 2   ///  r3 = r3.wrapping_shr(2)
    or64 r2, r3                                     r2 |= r3   ///  r2 = r2.or(r3)
    mov64 r3, r2                                    r3 = r2
    rsh64 r3, 4                                     r3 >>= 4   ///  r3 = r3.wrapping_shr(4)
    or64 r2, r3                                     r2 |= r3   ///  r2 = r2.or(r3)
    mov64 r3, r2                                    r3 = r2
    rsh64 r3, 8                                     r3 >>= 8   ///  r3 = r3.wrapping_shr(8)
    or64 r2, r3                                     r2 |= r3   ///  r2 = r2.or(r3)
    mov64 r3, r2                                    r3 = r2
    rsh64 r3, 16                                    r3 >>= 16   ///  r3 = r3.wrapping_shr(16)
    or64 r2, r3                                     r2 |= r3   ///  r2 = r2.or(r3)
    mov64 r3, r2                                    r3 = r2
    rsh64 r3, 32                                    r3 >>= 32   ///  r3 = r3.wrapping_shr(32)
    or64 r2, r3                                     r2 |= r3   ///  r2 = r2.or(r3)
    xor64 r2, -1                                    r2 ^= -1   ///  r2 = r2.xor(-1)
    lddw r3, 0x5555555555555555                     r3 load str located at 6148914691236517205
    mov64 r4, r2                                    r4 = r2
    rsh64 r4, 1                                     r4 >>= 1   ///  r4 = r4.wrapping_shr(1)
    and64 r4, r3                                    r4 &= r3   ///  r4 = r4.and(r3)
    sub64 r2, r4                                    r2 -= r4   ///  r2 = r2.wrapping_sub(r4)
    lddw r4, 0x3333333333333333                     r4 load str located at 3689348814741910323
    mov64 r3, r2                                    r3 = r2
    and64 r3, r4                                    r3 &= r4   ///  r3 = r3.and(r4)
    rsh64 r2, 2                                     r2 >>= 2   ///  r2 = r2.wrapping_shr(2)
    and64 r2, r4                                    r2 &= r4   ///  r2 = r2.and(r4)
    add64 r3, r2                                    r3 += r2   ///  r3 = r3.wrapping_add(r2)
    mov64 r2, r3                                    r2 = r3
    rsh64 r2, 4                                     r2 >>= 4   ///  r2 = r2.wrapping_shr(4)
    add64 r3, r2                                    r3 += r2   ///  r3 = r3.wrapping_add(r2)
    lddw r2, 0xf0f0f0f0f0f0f0f                      r2 load str located at 1085102592571150095
    and64 r3, r2                                    r3 &= r2   ///  r3 = r3.and(r2)
    lddw r2, 0x101010101010101                      r2 load str located at 72340172838076673
    mul64 r3, r2                                    r3 *= r2   ///  r3 = r3.wrapping_mul(r2)
    rsh64 r3, 56                                    r3 >>= 56   ///  r3 = r3.wrapping_shr(56)
    lsh64 r1, r3                                    r1 <<= r3   ///  r1 = r1.wrapping_shl(r3 as u32)
    lsh64 r3, 52                                    r3 <<= 52   ///  r3 = r3.wrapping_shl(52)
    mov64 r2, r1                                    r2 = r1
    rsh64 r2, 11                                    r2 >>= 11   ///  r2 = r2.wrapping_shr(11)
    mov64 r0, r2                                    r0 = r2
    sub64 r0, r3                                    r0 -= r3   ///  r0 = r0.wrapping_sub(r3)
    xor64 r2, -1                                    r2 ^= -1   ///  r2 = r2.xor(-1)
    lsh64 r1, 53                                    r1 <<= 53   ///  r1 = r1.wrapping_shl(53)
    mov64 r3, r1                                    r3 = r1
    rsh64 r3, 63                                    r3 >>= 63   ///  r3 = r3.wrapping_shr(63)
    and64 r3, r2                                    r3 &= r2   ///  r3 = r3.and(r2)
    sub64 r1, r3                                    r1 -= r3   ///  r1 = r1.wrapping_sub(r3)
    rsh64 r1, 63                                    r1 >>= 63   ///  r1 = r1.wrapping_shr(63)
    add64 r0, r1                                    r0 += r1   ///  r0 = r0.wrapping_add(r1)
    lddw r1, 0x43d0000000000000                     r1 load str located at 4886405595696988160
    add64 r0, r1                                    r0 += r1   ///  r0 = r0.wrapping_add(r1)
lbb_48895:
    exit                                    

function_48896:
    lddw r0, 0xffffffff                             r0 load str located at 4294967295
    lddw r5, 0x7fffffffffffffff                     r5 load str located at 9223372036854775807
    mov64 r3, r1                                    r3 = r1
    and64 r3, r5                                    r3 &= r5   ///  r3 = r3.and(r5)
    lddw r6, 0x7ff0000000000000                     r6 load str located at 9218868437227405312
    jgt r3, r6, lbb_48927                           if r3 > r6 { pc += 22 }
    mov64 r4, r2                                    r4 = r2
    and64 r4, r5                                    r4 &= r5   ///  r4 = r4.and(r5)
    jgt r4, r6, lbb_48927                           if r4 > r6 { pc += 19 }
    or64 r4, r3                                     r4 |= r3   ///  r4 = r4.or(r3)
    mov64 r0, 0                                     r0 = 0 as i32 as i64 as u64
    jeq r4, 0, lbb_48927                            if r4 == (0 as i32 as i64 as u64) { pc += 16 }
    mov64 r3, r2                                    r3 = r2
    and64 r3, r1                                    r3 &= r1   ///  r3 = r3.and(r1)
    jsgt r3, -1, lbb_48920                          if (r3 as i64) > (-1 as i32 as i64) { pc += 6 }
    lddw r0, 0xffffffff                             r0 load str located at 4294967295
    jsgt r1, r2, lbb_48927                          if (r1 as i64) > (r2 as i64) { pc += 10 }
    mov64 r0, 1                                     r0 = 1 as i32 as i64 as u64
    jeq r1, r2, lbb_48926                           if r1 == r2 { pc += 7 }
    ja lbb_48927                                    if true { pc += 7 }
lbb_48920:
    lddw r0, 0xffffffff                             r0 load str located at 4294967295
    jsgt r2, r1, lbb_48927                          if (r2 as i64) > (r1 as i64) { pc += 4 }
    mov64 r0, 1                                     r0 = 1 as i32 as i64 as u64
    jeq r1, r2, lbb_48926                           if r1 == r2 { pc += 1 }
    ja lbb_48927                                    if true { pc += 1 }
lbb_48926:
    mov64 r0, 0                                     r0 = 0 as i32 as i64 as u64
lbb_48927:
    lsh64 r0, 32                                    r0 <<= 32   ///  r0 = r0.wrapping_shl(32)
    arsh64 r0, 32                                   r0 >>= 32 (signed)   ///  r0 = (r0 as i64).wrapping_shr(32)
    exit                                    
