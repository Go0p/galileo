function_0:
    mov64 r0, 26                                    r0 = 26 as i32 as i64 as u64
    ldxdw r2, [r1+0x48]                     
    ldxdw r3, [r1+0x50]                     
    stxdw [r10-0x10], r3                    
    jge r2, r3, lbb_99                              if r2 >= r3 { pc += 94 }
    mov64 r3, r2                                    r3 = r2
    mul64 r3, 56                                    r3 *= 56   ///  r3 = r3.wrapping_mul(56 as u64)
    ldxdw r4, [r1+0x38]                     
    add64 r4, r3                                    r4 += r3   ///  r4 = r4.wrapping_add(r3)
    ldxdw r3, [r1+0x20]                     
    mov64 r5, r2                                    r5 = r2
    add64 r5, r3                                    r5 += r3   ///  r5 = r5.wrapping_add(r3)
    mov64 r3, r5                                    r3 = r5
    lsh64 r3, 3                                     r3 <<= 3   ///  r3 = r3.wrapping_shl(3)
    ldxdw r6, [r1+0x0]                      
    add64 r6, r3                                    r6 += r3   ///  r6 = r6.wrapping_add(r3)
    lsh64 r5, 4                                     r5 <<= 4   ///  r5 = r5.wrapping_shl(4)
    stxdw [r10-0x18], r1                    
    ldxdw r3, [r1+0x10]                     
    add64 r5, r3                                    r5 += r3   ///  r5 = r5.wrapping_add(r3)
    add64 r5, 8                                     r5 += 8   ///  r5 = r5.wrapping_add(8 as i32 as i64 as u64)
    ja lbb_43                                       if true { pc += 21 }
lbb_22:
    ldxdw r1, [r3+0x50]                     
    mov64 r7, r3                                    r7 = r3
    add64 r7, 40                                    r7 += 40   ///  r7 = r7.wrapping_add(40 as i32 as i64 as u64)
    stxdw [r4+0x20], r7                     
    mov64 r7, r3                                    r7 = r3
    add64 r7, 88                                    r7 += 88   ///  r7 = r7.wrapping_add(88 as i32 as i64 as u64)
    stxdw [r4+0x18], r7                     
    stxdw [r4+0x10], r1                     
    add64 r3, 72                                    r3 += 72   ///  r3 = r3.wrapping_add(72 as i32 as i64 as u64)
    stxdw [r4+0x8], r3                      
    stxdw [r4+0x0], r0                      
    stxb [r4+0x32], r8                      
    stxb [r4+0x31], r9                      
    ldxdw r1, [r10-0x8]                     
    stxb [r4+0x30], r1                      
    add64 r5, 16                                    r5 += 16   ///  r5 = r5.wrapping_add(16 as i32 as i64 as u64)
    add64 r6, 8                                     r6 += 8   ///  r6 = r6.wrapping_add(8 as i32 as i64 as u64)
    stdw [r4+0x28], 0                       
    add64 r4, 56                                    r4 += 56   ///  r4 = r4.wrapping_add(56 as i32 as i64 as u64)
    ldxdw r1, [r10-0x10]                    
    jge r2, r1, lbb_95                              if r2 >= r1 { pc += 52 }
lbb_43:
    add64 r2, 1                                     r2 += 1   ///  r2 = r2.wrapping_add(1 as i32 as i64 as u64)
    ldxdw r3, [r6+0x0]                      
    ldxdw r3, [r3+0x0]                      
    ldxdw r1, [r5-0x8]                      
    ldxdw r0, [r1+0x0]                      
    ldxdw r8, [r3+0x8]                      
    jne r8, r0, lbb_100                             if r8 != r0 { pc += 50 }
    mov64 r0, 1                                     r0 = 1 as i32 as i64 as u64
    ldxdw r8, [r1+0x8]                      
    ldxdw r9, [r3+0x10]                     
    jne r9, r8, lbb_97                              if r9 != r8 { pc += 43 }
    ldxdw r8, [r1+0x10]                     
    ldxdw r9, [r3+0x18]                     
    jne r9, r8, lbb_97                              if r9 != r8 { pc += 40 }
    ldxdw r1, [r1+0x18]                     
    ldxdw r8, [r3+0x20]                     
    jne r8, r1, lbb_97                              if r8 != r1 { pc += 37 }
    ldxb r0, [r5+0x0]                       
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    jne r0, 0, lbb_64                               if r0 != (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r1, 119                                   r1 = 119 as i32 as i64 as u64
lbb_64:
    ldxb r0, [r3+0x0]                       
    or64 r1, r0                                     r1 |= r0   ///  r1 = r1.or(r0)
    and64 r1, 255                                   r1 &= 255   ///  r1 = r1.and(255)
    jne r1, 255, lbb_93                             if r1 != (255 as i32 as i64 as u64) { pc += 25 }
    ldxb r1, [r3+0x1]                       
    mov64 r8, 1                                     r8 = 1 as i32 as i64 as u64
    mov64 r0, 1                                     r0 = 1 as i32 as i64 as u64
    jeq r1, 0, lbb_81                               if r1 == (0 as i32 as i64 as u64) { pc += 9 }
    stxdw [r10-0x8], r0                     
    ldxb r1, [r3+0x2]                       
    mov64 r9, 1                                     r9 = 1 as i32 as i64 as u64
    jeq r1, 0, lbb_86                               if r1 == (0 as i32 as i64 as u64) { pc += 10 }
lbb_76:
    mov64 r0, r3                                    r0 = r3
    add64 r0, 8                                     r0 += 8   ///  r0 = r0.wrapping_add(8 as i32 as i64 as u64)
    ldxb r1, [r3+0x3]                       
    jne r1, 0, lbb_22                               if r1 != (0 as i32 as i64 as u64) { pc += -58 }
    ja lbb_91                                       if true { pc += 10 }
lbb_81:
    mov64 r0, 0                                     r0 = 0 as i32 as i64 as u64
    stxdw [r10-0x8], r0                     
    ldxb r1, [r3+0x2]                       
    mov64 r9, 1                                     r9 = 1 as i32 as i64 as u64
    jne r1, 0, lbb_76                               if r1 != (0 as i32 as i64 as u64) { pc += -10 }
lbb_86:
    mov64 r9, 0                                     r9 = 0 as i32 as i64 as u64
    mov64 r0, r3                                    r0 = r3
    add64 r0, 8                                     r0 += 8   ///  r0 = r0.wrapping_add(8 as i32 as i64 as u64)
    ldxb r1, [r3+0x3]                       
    jne r1, 0, lbb_22                               if r1 != (0 as i32 as i64 as u64) { pc += -69 }
lbb_91:
    mov64 r8, 0                                     r8 = 0 as i32 as i64 as u64
    ja lbb_22                                       if true { pc += -71 }
lbb_93:
    mov64 r0, 11                                    r0 = 11 as i32 as i64 as u64
    ja lbb_97                                       if true { pc += 2 }
lbb_95:
    mov64 r0, 26                                    r0 = 26 as i32 as i64 as u64
    ldxdw r2, [r10-0x10]                    
lbb_97:
    ldxdw r1, [r10-0x18]                    
    stxdw [r1+0x48], r2                     
lbb_99:
    exit                                    
lbb_100:
    mov64 r0, 1                                     r0 = 1 as i32 as i64 as u64
    ja lbb_97                                       if true { pc += -5 }

function_102:
    ldxdw r3, [r2+0x8]                      
    jeq r3, 1, lbb_349                              if r3 == (1 as i32 as i64 as u64) { pc += 245 }
    jeq r3, 0, lbb_354                              if r3 == (0 as i32 as i64 as u64) { pc += 249 }
    jle r3, 2, lbb_359                              if r3 <= (2 as i32 as i64 as u64) { pc += 253 }
    jeq r3, 3, lbb_364                              if r3 == (3 as i32 as i64 as u64) { pc += 257 }
    jle r3, 4, lbb_369                              if r3 <= (4 as i32 as i64 as u64) { pc += 261 }
    jeq r3, 5, lbb_374                              if r3 == (5 as i32 as i64 as u64) { pc += 265 }
    jle r3, 6, lbb_379                              if r3 <= (6 as i32 as i64 as u64) { pc += 269 }
    jeq r3, 7, lbb_384                              if r3 == (7 as i32 as i64 as u64) { pc += 273 }
    jle r3, 8, lbb_389                              if r3 <= (8 as i32 as i64 as u64) { pc += 277 }
    stxdw [r10-0x508], r1                   
    jeq r3, 9, lbb_394                              if r3 == (9 as i32 as i64 as u64) { pc += 280 }
    ldxdw r3, [r2+0x0]                      
    ldxdw r5, [r2+0x58]                     
    stxdw [r10-0x528], r5                   
    ldxdw r4, [r2+0x50]                     
    stxdw [r10-0x518], r4                   
    ldxdw r1, [r2+0x48]                     
    stxdw [r10-0x510], r1                   
    ldxdw r0, [r2+0x28]                     
    stxdw [r10-0x500], r0                   
    ldxdw r0, [r2+0x40]                     
    stxdw [r10-0x4f8], r0                   
    ldxdw r0, [r2+0x20]                     
    stxdw [r10-0x520], r0                   
    ldxdw r2, [r2+0x10]                     
    stxdw [r10-0x530], r2                   
    ldxdw r0, [r3+0x48]                     
    add64 r0, 8                                     r0 += 8   ///  r0 = r0.wrapping_add(8 as i32 as i64 as u64)
    ldxdw r1, [r1+0x0]                      
    stxdw [r10-0x538], r1                   
    ldxdw r1, [r3+0x0]                      
    stxdw [r10-0x540], r1                   
    ldxdw r1, [r3+0x8]                      
    stxdw [r10-0x548], r1                   
    ldxdw r1, [r3+0x10]                     
    stxdw [r10-0x550], r1                   
    ldxdw r1, [r3+0x18]                     
    stxdw [r10-0x558], r1                   
    ldxdw r1, [r3+0x20]                     
    stxdw [r10-0x560], r1                   
    ldxdw r9, [r4+0x0]                      
    ldxdw r8, [r3+0x28]                     
    ldxdw r7, [r3+0x30]                     
    ldxdw r6, [r5+0x0]                      
    ldxdw r5, [r3+0x38]                     
    ldxdw r1, [r10-0x4f8]                   
    ldxdw r4, [r1+0x0]                      
    ldxdw r1, [r10-0x500]                   
    ldxdw r2, [r1+0x0]                      
    ldxdw r1, [r3+0x40]                     
    stxdw [r10-0x410], r0                   
    add64 r1, 8                                     r1 += 8   ///  r1 = r1.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x420], r1                   
    add64 r2, 8                                     r2 += 8   ///  r2 = r2.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x430], r2                   
    add64 r4, 8                                     r4 += 8   ///  r4 = r4.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x440], r4                   
    add64 r5, 8                                     r5 += 8   ///  r5 = r5.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x450], r5                   
    add64 r6, 8                                     r6 += 8   ///  r6 = r6.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x460], r6                   
    add64 r7, 8                                     r7 += 8   ///  r7 = r7.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x470], r7                   
    add64 r8, 8                                     r8 += 8   ///  r8 = r8.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x480], r8                   
    add64 r9, 8                                     r9 += 8   ///  r9 = r9.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x490], r9                   
    ldxdw r1, [r10-0x560]                   
    add64 r1, 8                                     r1 += 8   ///  r1 = r1.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x4a0], r1                   
    ldxdw r1, [r10-0x558]                   
    add64 r1, 8                                     r1 += 8   ///  r1 = r1.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x4b0], r1                   
    ldxdw r1, [r10-0x550]                   
    add64 r1, 8                                     r1 += 8   ///  r1 = r1.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x4c0], r1                   
    ldxdw r1, [r10-0x548]                   
    add64 r1, 8                                     r1 += 8   ///  r1 = r1.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x4d0], r1                   
    ldxdw r1, [r10-0x540]                   
    add64 r1, 8                                     r1 += 8   ///  r1 = r1.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x4e0], r1                   
    ldxdw r1, [r10-0x538]                   
    add64 r1, 8                                     r1 += 8   ///  r1 = r1.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x4f0], r1                   
    sth [r10-0x408], 0                      
    sth [r10-0x418], 0                      
    sth [r10-0x428], 0                      
    sth [r10-0x438], 0                      
    sth [r10-0x448], 1                      
    sth [r10-0x458], 1                      
    sth [r10-0x468], 1                      
    sth [r10-0x478], 0                      
    sth [r10-0x488], 1                      
    sth [r10-0x498], 1                      
    sth [r10-0x4a8], 0                      
    sth [r10-0x4b8], 0                      
    sth [r10-0x4c8], 1                      
    sth [r10-0x4d8], 1                      
    sth [r10-0x4e8], 257                    
    ldxdw r1, [r10-0x530]                   
    stxdw [r10-0x3f8], r1                   
    lddw r1, 0xc88775e1919ec6f8                     r1 load str located at -3997096532596832520
    stxdw [r10-0x400], r1                   
    stdw [r10-0x3f0], 0                     
    ldxdw r1, [r10-0x520]                   
    ldxdw r5, [r1+0x0]                      
    mov64 r1, r3                                    r1 = r3
    add64 r1, 72                                    r1 += 72   ///  r1 = r1.wrapping_add(72 as i32 as i64 as u64)
    stxdw [r10-0x378], r1                   
    mov64 r1, r3                                    r1 = r3
    add64 r1, 64                                    r1 += 64   ///  r1 = r1.wrapping_add(64 as i32 as i64 as u64)
    stxdw [r10-0x380], r1                   
    ldxdw r1, [r10-0x500]                   
    stxdw [r10-0x388], r1                   
    ldxdw r1, [r10-0x4f8]                   
    stxdw [r10-0x390], r1                   
    mov64 r1, r3                                    r1 = r3
    add64 r1, 56                                    r1 += 56   ///  r1 = r1.wrapping_add(56 as i32 as i64 as u64)
    stxdw [r10-0x398], r1                   
    ldxdw r1, [r10-0x528]                   
    stxdw [r10-0x3a0], r1                   
    mov64 r1, r3                                    r1 = r3
    add64 r1, 48                                    r1 += 48   ///  r1 = r1.wrapping_add(48 as i32 as i64 as u64)
    stxdw [r10-0x3a8], r1                   
    mov64 r1, r3                                    r1 = r3
    add64 r1, 40                                    r1 += 40   ///  r1 = r1.wrapping_add(40 as i32 as i64 as u64)
    stxdw [r10-0x3b0], r1                   
    ldxdw r1, [r10-0x518]                   
    stxdw [r10-0x3b8], r1                   
    mov64 r1, r3                                    r1 = r3
    add64 r1, 32                                    r1 += 32   ///  r1 = r1.wrapping_add(32 as i32 as i64 as u64)
    stxdw [r10-0x3c0], r1                   
    mov64 r1, r3                                    r1 = r3
    add64 r1, 24                                    r1 += 24   ///  r1 = r1.wrapping_add(24 as i32 as i64 as u64)
    stxdw [r10-0x3c8], r1                   
    mov64 r1, r3                                    r1 = r3
    add64 r1, 16                                    r1 += 16   ///  r1 = r1.wrapping_add(16 as i32 as i64 as u64)
    stxdw [r10-0x3d0], r1                   
    mov64 r1, r3                                    r1 = r3
    add64 r1, 8                                     r1 += 8   ///  r1 = r1.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x3d8], r1                   
    stxdw [r10-0x3e0], r3                   
    ldxdw r1, [r10-0x510]                   
    stxdw [r10-0x3e8], r1                   
    mov64 r2, r10                                   r2 = r10
    add64 r2, -1000                                 r2 += -1000   ///  r2 = r2.wrapping_add(-1000 as i32 as i64 as u64)
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
    mov64 r4, r10                                   r4 = r10
    add64 r4, -1256                                 r4 += -1256   ///  r4 = r4.wrapping_add(-1256 as i32 as i64 as u64)
    add64 r5, 8                                     r5 += 8   ///  r5 = r5.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x4f8], r5                   
    ja lbb_277                                      if true { pc += 20 }
lbb_257:
    mov64 r1, r10                                   r1 = r10
    add64 r1, -880                                  r1 += -880   ///  r1 = r1.wrapping_add(-880 as i32 as i64 as u64)
    add64 r1, r3                                    r1 += r3   ///  r1 = r1.wrapping_add(r3)
    stxb [r1+0x32], r7                      
    stxb [r1+0x31], r9                      
    stxb [r1+0x30], r0                      
    mov64 r0, r5                                    r0 = r5
    add64 r0, 40                                    r0 += 40   ///  r0 = r0.wrapping_add(40 as i32 as i64 as u64)
    stxdw [r1+0x20], r0                     
    mov64 r0, r5                                    r0 = r5
    add64 r0, 88                                    r0 += 88   ///  r0 = r0.wrapping_add(88 as i32 as i64 as u64)
    stxdw [r1+0x18], r0                     
    stxdw [r1+0x10], r6                     
    add64 r5, 72                                    r5 += 72   ///  r5 = r5.wrapping_add(72 as i32 as i64 as u64)
    stxdw [r1+0x8], r5                      
    stdw [r1+0x28], 0                       
    add64 r4, 16                                    r4 += 16   ///  r4 = r4.wrapping_add(16 as i32 as i64 as u64)
    add64 r2, 8                                     r2 += 8   ///  r2 = r2.wrapping_add(8 as i32 as i64 as u64)
    add64 r3, 56                                    r3 += 56   ///  r3 = r3.wrapping_add(56 as i32 as i64 as u64)
    jeq r3, 840, lbb_327                            if r3 == (840 as i32 as i64 as u64) { pc += 50 }
lbb_277:
    mov64 r0, r10                                   r0 = r10
    add64 r0, -880                                  r0 += -880   ///  r0 = r0.wrapping_add(-880 as i32 as i64 as u64)
    mov64 r6, 1                                     r6 = 1 as i32 as i64 as u64
    ldxdw r1, [r2+0x0]                      
    ldxdw r5, [r1+0x0]                      
    ldxdw r7, [r4-0x8]                      
    ldxdw r1, [r7+0x0]                      
    ldxdw r8, [r5+0x8]                      
    jne r8, r1, lbb_346                             if r8 != r1 { pc += 60 }
    ldxdw r1, [r7+0x8]                      
    ldxdw r8, [r5+0x10]                     
    jne r8, r1, lbb_346                             if r8 != r1 { pc += 57 }
    ldxdw r1, [r7+0x10]                     
    ldxdw r8, [r5+0x18]                     
    jne r8, r1, lbb_346                             if r8 != r1 { pc += 54 }
    ldxdw r1, [r7+0x18]                     
    ldxdw r7, [r5+0x20]                     
    jne r7, r1, lbb_346                             if r7 != r1 { pc += 51 }
    ldxb r6, [r4+0x0]                       
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    jne r6, 0, lbb_299                              if r6 != (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r1, 119                                   r1 = 119 as i32 as i64 as u64
lbb_299:
    ldxb r6, [r5+0x0]                       
    or64 r1, r6                                     r1 |= r6   ///  r1 = r1.or(r6)
    and64 r1, 255                                   r1 &= 255   ///  r1 = r1.and(255)
    jne r1, 255, lbb_325                            if r1 != (255 as i32 as i64 as u64) { pc += 22 }
    add64 r0, r3                                    r0 += r3   ///  r0 = r0.wrapping_add(r3)
    mov64 r7, r5                                    r7 = r5
    add64 r7, 8                                     r7 += 8   ///  r7 = r7.wrapping_add(8 as i32 as i64 as u64)
    ldxdw r6, [r5+0x50]                     
    ldxb r8, [r5+0x3]                       
    ldxb r1, [r5+0x2]                       
    ldxb r9, [r5+0x1]                       
    stxdw [r0+0x0], r7                      
    mov64 r7, 1                                     r7 = 1 as i32 as i64 as u64
    mov64 r0, 1                                     r0 = 1 as i32 as i64 as u64
    jeq r9, 0, lbb_318                              if r9 == (0 as i32 as i64 as u64) { pc += 4 }
    mov64 r9, 1                                     r9 = 1 as i32 as i64 as u64
    jeq r1, 0, lbb_321                              if r1 == (0 as i32 as i64 as u64) { pc += 5 }
lbb_316:
    jne r8, 0, lbb_257                              if r8 != (0 as i32 as i64 as u64) { pc += -60 }
    ja lbb_323                                      if true { pc += 5 }
lbb_318:
    mov64 r0, 0                                     r0 = 0 as i32 as i64 as u64
    mov64 r9, 1                                     r9 = 1 as i32 as i64 as u64
    jne r1, 0, lbb_316                              if r1 != (0 as i32 as i64 as u64) { pc += -5 }
lbb_321:
    mov64 r9, 0                                     r9 = 0 as i32 as i64 as u64
    jne r8, 0, lbb_257                              if r8 != (0 as i32 as i64 as u64) { pc += -66 }
lbb_323:
    mov64 r7, 0                                     r7 = 0 as i32 as i64 as u64
    ja lbb_257                                      if true { pc += -68 }
lbb_325:
    mov64 r6, 11                                    r6 = 11 as i32 as i64 as u64
    ja lbb_346                                      if true { pc += 19 }
lbb_327:
    mov64 r1, r10                                   r1 = r10
    add64 r1, -1024                                 r1 += -1024   ///  r1 = r1.wrapping_add(-1024 as i32 as i64 as u64)
    stxdw [r10-0x10], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -1264                                 r1 += -1264   ///  r1 = r1.wrapping_add(-1264 as i32 as i64 as u64)
    stxdw [r10-0x20], r1                    
    ldxdw r1, [r10-0x4f8]                   
    stxdw [r10-0x28], r1                    
    stdw [r10-0x8], 24                      
    stdw [r10-0x18], 15                     
    mov64 r1, r10                                   r1 = r10
    add64 r1, -40                                   r1 += -40   ///  r1 = r1.wrapping_add(-40 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -880                                  r2 += -880   ///  r2 = r2.wrapping_add(-880 as i32 as i64 as u64)
    mov64 r3, 15                                    r3 = 15 as i32 as i64 as u64
    mov64 r4, 8                                     r4 = 8 as i32 as i64 as u64
    mov64 r5, 0                                     r5 = 0 as i32 as i64 as u64
    syscall [invalid]                       
    mov64 r6, 26                                    r6 = 26 as i32 as i64 as u64
lbb_346:
    ldxdw r1, [r10-0x508]                   
    stxw [r1+0x0], r6                       
    exit                                    
lbb_349:
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    mov64 r2, 1                                     r2 = 1 as i32 as i64 as u64
    lddw r3, 0x100025d98 --> b"\x00\x00\x00\x00\xb8Y\x02\x00\x10\x00\x00\x00\x00\x00\x00\x00( \x00\x00!\…        r3 load str located at 4295122328
    call function_18489                     
lbb_354:
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
    lddw r3, 0x100025d80 --> b"\x00\x00\x00\x00\xb8Y\x02\x00\x10\x00\x00\x00\x00\x00\x00\x00( \x00\x00\x…        r3 load str located at 4295122304
    call function_18489                     
lbb_359:
    mov64 r1, 2                                     r1 = 2 as i32 as i64 as u64
    mov64 r2, 2                                     r2 = 2 as i32 as i64 as u64
    lddw r3, 0x100025db0 --> b"\x00\x00\x00\x00\xb8Y\x02\x00\x10\x00\x00\x00\x00\x00\x00\x00( \x00\x008\…        r3 load str located at 4295122352
    call function_18489                     
lbb_364:
    mov64 r1, 3                                     r1 = 3 as i32 as i64 as u64
    mov64 r2, 3                                     r2 = 3 as i32 as i64 as u64
    lddw r3, 0x100025dc8 --> b"\x00\x00\x00\x00\xb8Y\x02\x00\x10\x00\x00\x00\x00\x00\x00\x00( \x00\x00O\…        r3 load str located at 4295122376
    call function_18489                     
lbb_369:
    mov64 r1, 4                                     r1 = 4 as i32 as i64 as u64
    mov64 r2, 4                                     r2 = 4 as i32 as i64 as u64
    lddw r3, 0x100025de0 --> b"\x00\x00\x00\x00\xb8Y\x02\x00\x10\x00\x00\x00\x00\x00\x00\x00) \x00\x00\x…        r3 load str located at 4295122400
    call function_18489                     
lbb_374:
    mov64 r1, 5                                     r1 = 5 as i32 as i64 as u64
    mov64 r2, 5                                     r2 = 5 as i32 as i64 as u64
    lddw r3, 0x100025df8 --> b"\x00\x00\x00\x00\xb8Y\x02\x00\x10\x00\x00\x00\x00\x00\x00\x00) \x00\x00!\…        r3 load str located at 4295122424
    call function_18489                     
lbb_379:
    mov64 r1, 6                                     r1 = 6 as i32 as i64 as u64
    mov64 r2, 6                                     r2 = 6 as i32 as i64 as u64
    lddw r3, 0x100025e10 --> b"\x00\x00\x00\x00\xb8Y\x02\x00\x10\x00\x00\x00\x00\x00\x00\x00) \x00\x008\…        r3 load str located at 4295122448
    call function_18489                     
lbb_384:
    mov64 r1, 7                                     r1 = 7 as i32 as i64 as u64
    mov64 r2, 7                                     r2 = 7 as i32 as i64 as u64
    lddw r3, 0x100025e28 --> b"\x00\x00\x00\x00\xb8Y\x02\x00\x10\x00\x00\x00\x00\x00\x00\x00) \x00\x00O\…        r3 load str located at 4295122472
    call function_18489                     
lbb_389:
    mov64 r1, 8                                     r1 = 8 as i32 as i64 as u64
    mov64 r2, 8                                     r2 = 8 as i32 as i64 as u64
    lddw r3, 0x100025e40 --> b"\x00\x00\x00\x00\xb8Y\x02\x00\x10\x00\x00\x00\x00\x00\x00\x00* \x00\x00\x…        r3 load str located at 4295122496
    call function_18489                     
lbb_394:
    mov64 r1, 9                                     r1 = 9 as i32 as i64 as u64
    mov64 r2, 9                                     r2 = 9 as i32 as i64 as u64
    lddw r3, 0x100025e58 --> b"\x00\x00\x00\x00\xb8Y\x02\x00\x10\x00\x00\x00\x00\x00\x00\x00* \x00\x00!\…        r3 load str located at 4295122520
    call function_18489                     
    ldxdw r3, [r2+0x8]                      
    jeq r3, 1, lbb_731                              if r3 == (1 as i32 as i64 as u64) { pc += 330 }
    jeq r3, 0, lbb_736                              if r3 == (0 as i32 as i64 as u64) { pc += 334 }
    jle r3, 2, lbb_741                              if r3 <= (2 as i32 as i64 as u64) { pc += 338 }
    jeq r3, 3, lbb_746                              if r3 == (3 as i32 as i64 as u64) { pc += 342 }
    jle r3, 4, lbb_751                              if r3 <= (4 as i32 as i64 as u64) { pc += 346 }
    jeq r3, 5, lbb_756                              if r3 == (5 as i32 as i64 as u64) { pc += 350 }
    jle r3, 6, lbb_761                              if r3 <= (6 as i32 as i64 as u64) { pc += 354 }
    jeq r3, 7, lbb_766                              if r3 == (7 as i32 as i64 as u64) { pc += 358 }
    jle r3, 8, lbb_771                              if r3 <= (8 as i32 as i64 as u64) { pc += 362 }
    jeq r3, 9, lbb_776                              if r3 == (9 as i32 as i64 as u64) { pc += 366 }
    jle r3, 10, lbb_781                             if r3 <= (10 as i32 as i64 as u64) { pc += 370 }
    jeq r3, 11, lbb_786                             if r3 == (11 as i32 as i64 as u64) { pc += 374 }
    ldxdw r8, [r2+0x50]                     
    ldxdw r5, [r8+0x0]                      
    ldxdw r3, [r5+0x50]                     
    jlt r3, 32, lbb_729                             if r3 < (32 as i32 as i64 as u64) { pc += 313 }
    ldxdw r9, [r2+0x0]                      
    ldxdw r4, [r2+0x58]                     
    ldxdw r3, [r2+0x48]                     
    ldxdw r0, [r2+0x28]                     
    stxdw [r10-0x5b0], r0                   
    ldxdw r0, [r2+0x40]                     
    stxdw [r10-0x5a8], r0                   
    ldxdw r0, [r9+0x10]                     
    mov64 r6, r0                                    r6 = r0
    add64 r6, 8                                     r6 += 8   ///  r6 = r6.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x648], r6                   
    ldxdw r6, [r6+0x0]                      
    ldxdw r7, [r5+0x58]                     
    stxdw [r10-0x5b8], r1                   
    jne r7, r6, lbb_447                             if r7 != r6 { pc += 16 }
    ldxdw r6, [r0+0x10]                     
    ldxdw r7, [r5+0x60]                     
    jne r7, r6, lbb_447                             if r7 != r6 { pc += 13 }
    ldxdw r6, [r0+0x18]                     
    ldxdw r7, [r5+0x68]                     
    jne r7, r6, lbb_447                             if r7 != r6 { pc += 10 }
    ldxdw r0, [r0+0x20]                     
    ldxdw r5, [r5+0x70]                     
    mov64 r6, 1                                     r6 = 1 as i32 as i64 as u64
    jeq r5, r0, lbb_442                             if r5 == r0 { pc += 1 }
    mov64 r6, 0                                     r6 = 0 as i32 as i64 as u64
lbb_442:
    stxdw [r10-0x638], r6                   
    jne r5, r0, lbb_727                             if r5 != r0 { pc += 283 }
    mov64 r1, r8                                    r1 = r8
    mov64 r8, r4                                    r8 = r4
    ja lbb_450                                      if true { pc += 3 }
lbb_447:
    mov64 r1, r4                                    r1 = r4
    mov64 r4, 0                                     r4 = 0 as i32 as i64 as u64
    stxdw [r10-0x638], r4                   
lbb_450:
    ldxdw r4, [r2+0x20]                     
    stxdw [r10-0x5f8], r4                   
    ldxdw r2, [r2+0x10]                     
    stxdw [r10-0x610], r2                   
    mov64 r2, r9                                    r2 = r9
    add64 r2, 88                                    r2 += 88   ///  r2 = r2.wrapping_add(88 as i32 as i64 as u64)
    stxdw [r10-0x608], r2                   
    mov64 r2, r9                                    r2 = r9
    add64 r2, 8                                     r2 += 8   ///  r2 = r2.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x5d8], r2                   
    mov64 r2, r9                                    r2 = r9
    add64 r2, 16                                    r2 += 16   ///  r2 = r2.wrapping_add(16 as i32 as i64 as u64)
    stxdw [r10-0x5e0], r2                   
    mov64 r2, r9                                    r2 = r9
    add64 r2, 24                                    r2 += 24   ///  r2 = r2.wrapping_add(24 as i32 as i64 as u64)
    stxdw [r10-0x5e8], r2                   
    mov64 r2, r9                                    r2 = r9
    add64 r2, 32                                    r2 += 32   ///  r2 = r2.wrapping_add(32 as i32 as i64 as u64)
    stxdw [r10-0x5f0], r2                   
    mov64 r2, r9                                    r2 = r9
    add64 r2, 40                                    r2 += 40   ///  r2 = r2.wrapping_add(40 as i32 as i64 as u64)
    stxdw [r10-0x600], r2                   
    mov64 r2, r9                                    r2 = r9
    add64 r2, 48                                    r2 += 48   ///  r2 = r2.wrapping_add(48 as i32 as i64 as u64)
    stxdw [r10-0x618], r2                   
    mov64 r2, r9                                    r2 = r9
    add64 r2, 56                                    r2 += 56   ///  r2 = r2.wrapping_add(56 as i32 as i64 as u64)
    stxdw [r10-0x620], r2                   
    mov64 r2, r9                                    r2 = r9
    add64 r2, 64                                    r2 += 64   ///  r2 = r2.wrapping_add(64 as i32 as i64 as u64)
    stxdw [r10-0x628], r2                   
    mov64 r2, r9                                    r2 = r9
    add64 r2, 72                                    r2 += 72   ///  r2 = r2.wrapping_add(72 as i32 as i64 as u64)
    stxdw [r10-0x630], r2                   
    mov64 r2, r9                                    r2 = r9
    add64 r2, 80                                    r2 += 80   ///  r2 = r2.wrapping_add(80 as i32 as i64 as u64)
    stxdw [r10-0x640], r2                   
    ldxdw r2, [r9+0x0]                      
    stxdw [r10-0x650], r2                   
    ldxdw r2, [r9+0x8]                      
    stxdw [r10-0x658], r2                   
    ldxdw r2, [r9+0x18]                     
    stxdw [r10-0x660], r2                   
    ldxdw r2, [r9+0x20]                     
    stxdw [r10-0x668], r2                   
    ldxdw r2, [r9+0x28]                     
    stxdw [r10-0x670], r2                   
    stxdw [r10-0x5d0], r1                   
    ldxdw r1, [r1+0x0]                      
    stxdw [r10-0x678], r1                   
    stxdw [r10-0x5c0], r8                   
    ldxdw r1, [r8+0x0]                      
    stxdw [r10-0x680], r1                   
    stxdw [r10-0x5c8], r3                   
    ldxdw r1, [r3+0x0]                      
    stxdw [r10-0x688], r1                   
    ldxdw r8, [r9+0x30]                     
    ldxdw r7, [r9+0x38]                     
    ldxdw r6, [r9+0x40]                     
    ldxdw r0, [r9+0x48]                     
    ldxdw r1, [r10-0x5a8]                   
    ldxdw r5, [r1+0x0]                      
    ldxdw r1, [r10-0x5b0]                   
    ldxdw r4, [r1+0x0]                      
    ldxdw r2, [r9+0x50]                     
    ldxdw r3, [r9+0x58]                     
    ldxdw r1, [r10-0x648]                   
    stxdw [r10-0x580], r1                   
    add64 r3, 8                                     r3 += 8   ///  r3 = r3.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x4a0], r3                   
    add64 r2, 8                                     r2 += 8   ///  r2 = r2.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x4b0], r2                   
    add64 r4, 8                                     r4 += 8   ///  r4 = r4.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x4c0], r4                   
    add64 r5, 8                                     r5 += 8   ///  r5 = r5.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x4d0], r5                   
    add64 r0, 8                                     r0 += 8   ///  r0 = r0.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x4e0], r0                   
    add64 r6, 8                                     r6 += 8   ///  r6 = r6.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x4f0], r6                   
    add64 r7, 8                                     r7 += 8   ///  r7 = r7.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x500], r7                   
    add64 r8, 8                                     r8 += 8   ///  r8 = r8.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x510], r8                   
    ldxdw r1, [r10-0x688]                   
    add64 r1, 8                                     r1 += 8   ///  r1 = r1.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x520], r1                   
    ldxdw r1, [r10-0x680]                   
    add64 r1, 8                                     r1 += 8   ///  r1 = r1.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x530], r1                   
    ldxdw r1, [r10-0x678]                   
    add64 r1, 8                                     r1 += 8   ///  r1 = r1.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x540], r1                   
    ldxdw r1, [r10-0x670]                   
    add64 r1, 8                                     r1 += 8   ///  r1 = r1.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x550], r1                   
    ldxdw r1, [r10-0x668]                   
    add64 r1, 8                                     r1 += 8   ///  r1 = r1.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x560], r1                   
    ldxdw r1, [r10-0x660]                   
    add64 r1, 8                                     r1 += 8   ///  r1 = r1.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x570], r1                   
    ldxdw r1, [r10-0x658]                   
    add64 r1, 8                                     r1 += 8   ///  r1 = r1.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x590], r1                   
    ldxdw r1, [r10-0x650]                   
    add64 r1, 8                                     r1 += 8   ///  r1 = r1.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x5a0], r1                   
    ldxdw r3, [r10-0x638]                   
    and64 r3, 1                                     r3 &= 1   ///  r3 = r3.and(1)
    mov64 r2, 1                                     r2 = 1 as i32 as i64 as u64
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    jeq r3, 0, lbb_564                              if r3 == (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
lbb_564:
    neg64 r2                                        r2 = -r2   ///  r2 = (r2 as i64).wrapping_neg() as u64
    sth [r10-0x498], 0                      
    sth [r10-0x4a8], 0                      
    sth [r10-0x4b8], 0                      
    sth [r10-0x4c8], 0                      
    sth [r10-0x4d8], 0                      
    sth [r10-0x4e8], 1                      
    sth [r10-0x4f8], 1                      
    sth [r10-0x508], 1                      
    sth [r10-0x518], 257                    
    sth [r10-0x528], 1                      
    sth [r10-0x538], 1                      
    sth [r10-0x548], 1                      
    sth [r10-0x558], 1                      
    sth [r10-0x568], 0                      
    sth [r10-0x578], 0                      
    sth [r10-0x588], 1                      
    sth [r10-0x598], 0                      
    stxdw [r10-0x478], r2                   
    mov64 r2, r3                                    r2 = r3
    add64 r2, -1                                    r2 += -1   ///  r2 = r2.wrapping_add(-1 as i32 as i64 as u64)
    stxdw [r10-0x480], r2                   
    stxb [r10-0x470], r3                    
    ldxdw r2, [r10-0x610]                   
    stxdw [r10-0x488], r2                   
    lddw r2, 0xc88775e1919ec6f8                     r2 load str located at -3997096532596832520
    stxdw [r10-0x490], r2                   
    ldxdw r2, [r10-0x5f8]                   
    ldxdw r4, [r2+0x0]                      
    ldxdw r2, [r10-0x608]                   
    stxdw [r10-0x3e8], r2                   
    ldxdw r2, [r10-0x640]                   
    stxdw [r10-0x3f0], r2                   
    ldxdw r2, [r10-0x5b0]                   
    stxdw [r10-0x3f8], r2                   
    ldxdw r2, [r10-0x5a8]                   
    stxdw [r10-0x400], r2                   
    ldxdw r2, [r10-0x630]                   
    stxdw [r10-0x408], r2                   
    ldxdw r2, [r10-0x628]                   
    stxdw [r10-0x410], r2                   
    ldxdw r2, [r10-0x620]                   
    stxdw [r10-0x418], r2                   
    ldxdw r2, [r10-0x618]                   
    stxdw [r10-0x420], r2                   
    ldxdw r2, [r10-0x5c8]                   
    stxdw [r10-0x428], r2                   
    ldxdw r2, [r10-0x5c0]                   
    stxdw [r10-0x430], r2                   
    ldxdw r2, [r10-0x5d0]                   
    stxdw [r10-0x438], r2                   
    ldxdw r2, [r10-0x600]                   
    stxdw [r10-0x440], r2                   
    ldxdw r2, [r10-0x5f0]                   
    stxdw [r10-0x448], r2                   
    ldxdw r2, [r10-0x5e8]                   
    stxdw [r10-0x450], r2                   
    ldxdw r2, [r10-0x5e0]                   
    stxdw [r10-0x458], r2                   
    ldxdw r2, [r10-0x5d8]                   
    stxdw [r10-0x460], r2                   
    stxdw [r10-0x468], r9                   
    mov64 r2, r10                                   r2 = r10
    add64 r2, -1128                                 r2 += -1128   ///  r2 = r2.wrapping_add(-1128 as i32 as i64 as u64)
    mov64 r3, r10                                   r3 = r10
    add64 r3, -1432                                 r3 += -1432   ///  r3 = r3.wrapping_add(-1432 as i32 as i64 as u64)
    add64 r4, 8                                     r4 += 8   ///  r4 = r4.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x5a8], r4                   
    ja lbb_654                                      if true { pc += 20 }
lbb_634:
    mov64 r7, r10                                   r7 = r10
    add64 r7, -992                                  r7 += -992   ///  r7 = r7.wrapping_add(-992 as i32 as i64 as u64)
    add64 r7, r1                                    r7 += r1   ///  r7 = r7.wrapping_add(r1)
    stxb [r7+0x32], r6                      
    stxb [r7+0x31], r8                      
    stxb [r7+0x30], r5                      
    mov64 r5, r4                                    r5 = r4
    add64 r5, 40                                    r5 += 40   ///  r5 = r5.wrapping_add(40 as i32 as i64 as u64)
    stxdw [r7+0x20], r5                     
    mov64 r5, r4                                    r5 = r4
    add64 r5, 88                                    r5 += 88   ///  r5 = r5.wrapping_add(88 as i32 as i64 as u64)
    stxdw [r7+0x18], r5                     
    stxdw [r7+0x10], r0                     
    add64 r4, 72                                    r4 += 72   ///  r4 = r4.wrapping_add(72 as i32 as i64 as u64)
    stxdw [r7+0x8], r4                      
    stdw [r7+0x28], 0                       
    add64 r3, 16                                    r3 += 16   ///  r3 = r3.wrapping_add(16 as i32 as i64 as u64)
    add64 r2, 8                                     r2 += 8   ///  r2 = r2.wrapping_add(8 as i32 as i64 as u64)
    add64 r1, 56                                    r1 += 56   ///  r1 = r1.wrapping_add(56 as i32 as i64 as u64)
    jeq r1, 952, lbb_704                            if r1 == (952 as i32 as i64 as u64) { pc += 50 }
lbb_654:
    mov64 r5, r10                                   r5 = r10
    add64 r5, -992                                  r5 += -992   ///  r5 = r5.wrapping_add(-992 as i32 as i64 as u64)
    mov64 r0, 1                                     r0 = 1 as i32 as i64 as u64
    ldxdw r4, [r2+0x0]                      
    ldxdw r4, [r4+0x0]                      
    ldxdw r6, [r3-0x8]                      
    ldxdw r7, [r6+0x0]                      
    ldxdw r8, [r4+0x8]                      
    jne r8, r7, lbb_723                             if r8 != r7 { pc += 60 }
    ldxdw r7, [r6+0x8]                      
    ldxdw r8, [r4+0x10]                     
    jne r8, r7, lbb_723                             if r8 != r7 { pc += 57 }
    ldxdw r7, [r6+0x10]                     
    ldxdw r8, [r4+0x18]                     
    jne r8, r7, lbb_723                             if r8 != r7 { pc += 54 }
    ldxdw r6, [r6+0x18]                     
    ldxdw r7, [r4+0x20]                     
    jne r7, r6, lbb_723                             if r7 != r6 { pc += 51 }
    ldxb r6, [r3+0x0]                       
    mov64 r0, 0                                     r0 = 0 as i32 as i64 as u64
    jne r6, 0, lbb_676                              if r6 != (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r0, 119                                   r0 = 119 as i32 as i64 as u64
lbb_676:
    ldxb r6, [r4+0x0]                       
    or64 r0, r6                                     r0 |= r6   ///  r0 = r0.or(r6)
    and64 r0, 255                                   r0 &= 255   ///  r0 = r0.and(255)
    jne r0, 255, lbb_702                            if r0 != (255 as i32 as i64 as u64) { pc += 22 }
    add64 r5, r1                                    r5 += r1   ///  r5 = r5.wrapping_add(r1)
    mov64 r6, r4                                    r6 = r4
    add64 r6, 8                                     r6 += 8   ///  r6 = r6.wrapping_add(8 as i32 as i64 as u64)
    ldxdw r0, [r4+0x50]                     
    ldxb r7, [r4+0x3]                       
    ldxb r9, [r4+0x2]                       
    ldxb r8, [r4+0x1]                       
    stxdw [r5+0x0], r6                      
    mov64 r6, 1                                     r6 = 1 as i32 as i64 as u64
    mov64 r5, 1                                     r5 = 1 as i32 as i64 as u64
    jeq r8, 0, lbb_695                              if r8 == (0 as i32 as i64 as u64) { pc += 4 }
    mov64 r8, 1                                     r8 = 1 as i32 as i64 as u64
    jeq r9, 0, lbb_698                              if r9 == (0 as i32 as i64 as u64) { pc += 5 }
lbb_693:
    jne r7, 0, lbb_634                              if r7 != (0 as i32 as i64 as u64) { pc += -60 }
    ja lbb_700                                      if true { pc += 5 }
lbb_695:
    mov64 r5, 0                                     r5 = 0 as i32 as i64 as u64
    mov64 r8, 1                                     r8 = 1 as i32 as i64 as u64
    jne r9, 0, lbb_693                              if r9 != (0 as i32 as i64 as u64) { pc += -5 }
lbb_698:
    mov64 r8, 0                                     r8 = 0 as i32 as i64 as u64
    jne r7, 0, lbb_634                              if r7 != (0 as i32 as i64 as u64) { pc += -66 }
lbb_700:
    mov64 r6, 0                                     r6 = 0 as i32 as i64 as u64
    ja lbb_634                                      if true { pc += -68 }
lbb_702:
    mov64 r0, 11                                    r0 = 11 as i32 as i64 as u64
    ja lbb_723                                      if true { pc += 19 }
lbb_704:
    mov64 r1, r10                                   r1 = r10
    add64 r1, -1168                                 r1 += -1168   ///  r1 = r1.wrapping_add(-1168 as i32 as i64 as u64)
    stxdw [r10-0x10], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -1440                                 r1 += -1440   ///  r1 = r1.wrapping_add(-1440 as i32 as i64 as u64)
    stxdw [r10-0x20], r1                    
    ldxdw r1, [r10-0x5a8]                   
    stxdw [r10-0x28], r1                    
    stdw [r10-0x8], 33                      
    stdw [r10-0x18], 17                     
    mov64 r1, r10                                   r1 = r10
    add64 r1, -40                                   r1 += -40   ///  r1 = r1.wrapping_add(-40 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -992                                  r2 += -992   ///  r2 = r2.wrapping_add(-992 as i32 as i64 as u64)
    mov64 r3, 17                                    r3 = 17 as i32 as i64 as u64
    mov64 r4, 8                                     r4 = 8 as i32 as i64 as u64
    mov64 r5, 0                                     r5 = 0 as i32 as i64 as u64
    syscall [invalid]                       
    mov64 r0, 26                                    r0 = 26 as i32 as i64 as u64
lbb_723:
    ldxdw r1, [r10-0x5b8]                   
lbb_724:
    stxw [r1+0x0], r0                       
    stw [r1+0x4], 0                         
    exit                                    
lbb_727:
    mov64 r1, r4                                    r1 = r4
    ja lbb_450                                      if true { pc += -279 }
lbb_729:
    mov64 r0, 3                                     r0 = 3 as i32 as i64 as u64
    ja lbb_724                                      if true { pc += -7 }
lbb_731:
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    mov64 r2, 1                                     r2 = 1 as i32 as i64 as u64
    lddw r3, 0x100025e88 --> b"\x00\x00\x00\x00\xb8Y\x02\x00\x10\x00\x00\x00\x00\x00\x00\x004 \x00\x00!\…        r3 load str located at 4295122568
    call function_18489                     
lbb_736:
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
    lddw r3, 0x100025e70 --> b"\x00\x00\x00\x00\xb8Y\x02\x00\x10\x00\x00\x00\x00\x00\x00\x004 \x00\x00\x…        r3 load str located at 4295122544
    call function_18489                     
lbb_741:
    mov64 r1, 2                                     r1 = 2 as i32 as i64 as u64
    mov64 r2, 2                                     r2 = 2 as i32 as i64 as u64
    lddw r3, 0x100025ea0 --> b"\x00\x00\x00\x00\xb8Y\x02\x00\x10\x00\x00\x00\x00\x00\x00\x004 \x00\x008\…        r3 load str located at 4295122592
    call function_18489                     
lbb_746:
    mov64 r1, 3                                     r1 = 3 as i32 as i64 as u64
    mov64 r2, 3                                     r2 = 3 as i32 as i64 as u64
    lddw r3, 0x100025eb8 --> b"\x00\x00\x00\x00\xb8Y\x02\x00\x10\x00\x00\x00\x00\x00\x00\x004 \x00\x00O\…        r3 load str located at 4295122616
    call function_18489                     
lbb_751:
    mov64 r1, 4                                     r1 = 4 as i32 as i64 as u64
    mov64 r2, 4                                     r2 = 4 as i32 as i64 as u64
    lddw r3, 0x100025ed0 --> b"\x00\x00\x00\x00\xb8Y\x02\x00\x10\x00\x00\x00\x00\x00\x00\x005 \x00\x00\x…        r3 load str located at 4295122640
    call function_18489                     
lbb_756:
    mov64 r1, 5                                     r1 = 5 as i32 as i64 as u64
    mov64 r2, 5                                     r2 = 5 as i32 as i64 as u64
    lddw r3, 0x100025ee8 --> b"\x00\x00\x00\x00\xb8Y\x02\x00\x10\x00\x00\x00\x00\x00\x00\x005 \x00\x00#\…        r3 load str located at 4295122664
    call function_18489                     
lbb_761:
    mov64 r1, 6                                     r1 = 6 as i32 as i64 as u64
    mov64 r2, 6                                     r2 = 6 as i32 as i64 as u64
    lddw r3, 0x100025f00 --> b"\x00\x00\x00\x00\xb8Y\x02\x00\x10\x00\x00\x00\x00\x00\x00\x005 \x00\x00:\…        r3 load str located at 4295122688
    call function_18489                     
lbb_766:
    mov64 r1, 7                                     r1 = 7 as i32 as i64 as u64
    mov64 r2, 7                                     r2 = 7 as i32 as i64 as u64
    lddw r3, 0x100025f18 --> b"\x00\x00\x00\x00\xb8Y\x02\x00\x10\x00\x00\x00\x00\x00\x00\x005 \x00\x00Q\…        r3 load str located at 4295122712
    call function_18489                     
lbb_771:
    mov64 r1, 8                                     r1 = 8 as i32 as i64 as u64
    mov64 r2, 8                                     r2 = 8 as i32 as i64 as u64
    lddw r3, 0x100025f30 --> b"\x00\x00\x00\x00\xb8Y\x02\x00\x10\x00\x00\x00\x00\x00\x00\x006 \x00\x00\x…        r3 load str located at 4295122736
    call function_18489                     
lbb_776:
    mov64 r1, 9                                     r1 = 9 as i32 as i64 as u64
    mov64 r2, 9                                     r2 = 9 as i32 as i64 as u64
    lddw r3, 0x100025f48 --> b"\x00\x00\x00\x00\xb8Y\x02\x00\x10\x00\x00\x00\x00\x00\x00\x006 \x00\x00!\…        r3 load str located at 4295122760
    call function_18489                     
lbb_781:
    mov64 r1, 10                                    r1 = 10 as i32 as i64 as u64
    mov64 r2, 10                                    r2 = 10 as i32 as i64 as u64
    lddw r3, 0x100025f60 --> b"\x00\x00\x00\x00\xb8Y\x02\x00\x10\x00\x00\x00\x00\x00\x00\x006 \x00\x008\…        r3 load str located at 4295122784
    call function_18489                     
lbb_786:
    mov64 r1, 11                                    r1 = 11 as i32 as i64 as u64
    mov64 r2, 11                                    r2 = 11 as i32 as i64 as u64
    lddw r3, 0x100025f78 --> b"\x00\x00\x00\x00\xb8Y\x02\x00\x10\x00\x00\x00\x00\x00\x00\x006 \x00\x00P\…        r3 load str located at 4295122808
    call function_18489                     
    ldxdw r3, [r2+0x8]                      
    jeq r3, 1, lbb_1018                             if r3 == (1 as i32 as i64 as u64) { pc += 225 }
    jeq r3, 0, lbb_1023                             if r3 == (0 as i32 as i64 as u64) { pc += 229 }
    jle r3, 2, lbb_1028                             if r3 <= (2 as i32 as i64 as u64) { pc += 233 }
    jeq r3, 3, lbb_1033                             if r3 == (3 as i32 as i64 as u64) { pc += 237 }
    ldxdw r5, [r2+0x50]                     
    mov64 r6, 3                                     r6 = 3 as i32 as i64 as u64
    ldxdw r0, [r5+0x0]                      
    ldxdw r3, [r0+0x50]                     
    jlt r3, 32, lbb_1012                            if r3 < (32 as i32 as i64 as u64) { pc += 211 }
    ldxdw r9, [r2+0x0]                      
    mov64 r4, r9                                    r4 = r9
    add64 r4, 8                                     r4 += 8   ///  r4 = r4.wrapping_add(8 as i32 as i64 as u64)
    ldxdw r7, [r4+0x0]                      
    ldxdw r3, [r7+0x50]                     
    jlt r3, 32, lbb_1012                            if r3 < (32 as i32 as i64 as u64) { pc += 205 }
    ldxdw r3, [r2+0x58]                     
    ldxdw r6, [r2+0x48]                     
    stxdw [r10-0x328], r6                   
    ldxdw r8, [r2+0x28]                     
    stxdw [r10-0x320], r8                   
    ldxdw r6, [r2+0x20]                     
    ldxdw r2, [r2+0x10]                     
    stxdw [r10-0x350], r2                   
    mov64 r2, r9                                    r2 = r9
    add64 r2, 24                                    r2 += 24   ///  r2 = r2.wrapping_add(24 as i32 as i64 as u64)
    stxdw [r10-0x348], r2                   
    mov64 r2, r9                                    r2 = r9
    add64 r2, 16                                    r2 += 16   ///  r2 = r2.wrapping_add(16 as i32 as i64 as u64)
    stxdw [r10-0x340], r2                   
    ldxdw r2, [r7+0x58]                     
    ldxdw r8, [r0+0x58]                     
    stxdw [r10-0x330], r1                   
    stxdw [r10-0x338], r4                   
    jne r8, r2, lbb_842                             if r8 != r2 { pc += 16 }
    ldxdw r2, [r7+0x60]                     
    ldxdw r8, [r0+0x60]                     
    jne r8, r2, lbb_842                             if r8 != r2 { pc += 13 }
    ldxdw r2, [r7+0x68]                     
    ldxdw r8, [r0+0x68]                     
    jne r8, r2, lbb_842                             if r8 != r2 { pc += 10 }
    ldxdw r2, [r7+0x70]                     
    ldxdw r0, [r0+0x70]                     
    mov64 r8, 1                                     r8 = 1 as i32 as i64 as u64
    jeq r0, r2, lbb_837                             if r0 == r2 { pc += 1 }
    mov64 r8, 0                                     r8 = 0 as i32 as i64 as u64
lbb_837:
    stxdw [r10-0x380], r8                   
    jne r0, r2, lbb_1015                            if r0 != r2 { pc += 176 }
    mov64 r2, r5                                    r2 = r5
    mov64 r5, r3                                    r5 = r3
    ja lbb_1016                                     if true { pc += 174 }
lbb_842:
    mov64 r2, r3                                    r2 = r3
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    stxdw [r10-0x380], r1                   
lbb_845:
    stxdw [r10-0x360], r5                   
    add64 r7, 8                                     r7 += 8   ///  r7 = r7.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x370], r7                   
    stxdw [r10-0x368], r6                   
    ldxdw r4, [r6+0x0]                      
    ldxdw r3, [r9+0x0]                      
    stxdw [r10-0x378], r3                   
    stxdw [r10-0x358], r2                   
    ldxdw r2, [r2+0x0]                      
    ldxdw r0, [r5+0x0]                      
    mov64 r7, r9                                    r7 = r9
    ldxdw r9, [r7+0x10]                     
    ldxdw r5, [r10-0x328]                   
    ldxdw r6, [r5+0x0]                      
    ldxdw r5, [r10-0x320]                   
    ldxdw r5, [r5+0x0]                      
    ldxdw r8, [r7+0x18]                     
    ldxdw r3, [r10-0x370]                   
    stxdw [r10-0x2e8], r3                   
    add64 r8, 8                                     r8 += 8   ///  r8 = r8.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x2a8], r8                   
    add64 r5, 8                                     r5 += 8   ///  r5 = r5.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x2b8], r5                   
    add64 r6, 8                                     r6 += 8   ///  r6 = r6.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x2c8], r6                   
    add64 r9, 8                                     r9 += 8   ///  r9 = r9.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x2d8], r9                   
    add64 r0, 8                                     r0 += 8   ///  r0 = r0.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x2f8], r0                   
    add64 r2, 8                                     r2 += 8   ///  r2 = r2.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x308], r2                   
    ldxdw r2, [r10-0x378]                   
    add64 r2, 8                                     r2 += 8   ///  r2 = r2.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x318], r2                   
    add64 r4, 8                                     r4 += 8   ///  r4 = r4.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x370], r4                   
    stxdw [r10-0x298], r4                   
    sth [r10-0x290], 0                      
    sth [r10-0x2a0], 0                      
    sth [r10-0x2b0], 0                      
    sth [r10-0x2c0], 257                    
    sth [r10-0x2d0], 1                      
    sth [r10-0x2e0], 1                      
    sth [r10-0x2f0], 1                      
    sth [r10-0x300], 1                      
    sth [r10-0x310], 1                      
    ldxdw r2, [r10-0x380]                   
    and64 r2, 1                                     r2 &= 1   ///  r2 = r2.and(1)
    stxb [r10-0x278], r2                    
    ldxdw r2, [r10-0x350]                   
    stxdw [r10-0x280], r2                   
    lddw r2, 0xfba64eede70c61a7                     r2 load str located at -313476340365106777
    stxdw [r10-0x288], r2                   
    stdw [r10-0x277], 0                     
    ldxdw r2, [r10-0x368]                   
    stxdw [r10-0x228], r2                   
    ldxdw r2, [r10-0x348]                   
    stxdw [r10-0x230], r2                   
    ldxdw r2, [r10-0x320]                   
    stxdw [r10-0x238], r2                   
    ldxdw r2, [r10-0x328]                   
    stxdw [r10-0x240], r2                   
    ldxdw r2, [r10-0x340]                   
    stxdw [r10-0x248], r2                   
    ldxdw r2, [r10-0x338]                   
    stxdw [r10-0x250], r2                   
    ldxdw r2, [r10-0x360]                   
    stxdw [r10-0x258], r2                   
    ldxdw r2, [r10-0x358]                   
    stxdw [r10-0x260], r2                   
    stxdw [r10-0x268], r7                   
    mov64 r3, r10                                   r3 = r10
    add64 r3, -616                                  r3 += -616   ///  r3 = r3.wrapping_add(-616 as i32 as i64 as u64)
    mov64 r4, r10                                   r4 = r10
    add64 r4, -784                                  r4 += -784   ///  r4 = r4.wrapping_add(-784 as i32 as i64 as u64)
    ja lbb_942                                      if true { pc += 20 }
lbb_922:
    mov64 r7, r10                                   r7 = r10
    add64 r7, -544                                  r7 += -544   ///  r7 = r7.wrapping_add(-544 as i32 as i64 as u64)
    add64 r7, r1                                    r7 += r1   ///  r7 = r7.wrapping_add(r1)
    stxb [r7+0x32], r0                      
    stxb [r7+0x31], r8                      
    stxb [r7+0x30], r2                      
    mov64 r2, r5                                    r2 = r5
    add64 r2, 40                                    r2 += 40   ///  r2 = r2.wrapping_add(40 as i32 as i64 as u64)
    stxdw [r7+0x20], r2                     
    mov64 r2, r5                                    r2 = r5
    add64 r2, 88                                    r2 += 88   ///  r2 = r2.wrapping_add(88 as i32 as i64 as u64)
    stxdw [r7+0x18], r2                     
    stxdw [r7+0x10], r6                     
    add64 r5, 72                                    r5 += 72   ///  r5 = r5.wrapping_add(72 as i32 as i64 as u64)
    stxdw [r7+0x8], r5                      
    stdw [r7+0x28], 0                       
    add64 r4, 16                                    r4 += 16   ///  r4 = r4.wrapping_add(16 as i32 as i64 as u64)
    add64 r3, 8                                     r3 += 8   ///  r3 = r3.wrapping_add(8 as i32 as i64 as u64)
    add64 r1, 56                                    r1 += 56   ///  r1 = r1.wrapping_add(56 as i32 as i64 as u64)
    jeq r1, 504, lbb_992                            if r1 == (504 as i32 as i64 as u64) { pc += 50 }
lbb_942:
    mov64 r0, r10                                   r0 = r10
    add64 r0, -544                                  r0 += -544   ///  r0 = r0.wrapping_add(-544 as i32 as i64 as u64)
    mov64 r6, 1                                     r6 = 1 as i32 as i64 as u64
    ldxdw r2, [r3+0x0]                      
    ldxdw r5, [r2+0x0]                      
    ldxdw r2, [r4-0x8]                      
    ldxdw r7, [r2+0x0]                      
    ldxdw r8, [r5+0x8]                      
    jne r8, r7, lbb_1011                            if r8 != r7 { pc += 60 }
    ldxdw r7, [r2+0x8]                      
    ldxdw r8, [r5+0x10]                     
    jne r8, r7, lbb_1011                            if r8 != r7 { pc += 57 }
    ldxdw r7, [r2+0x10]                     
    ldxdw r8, [r5+0x18]                     
    jne r8, r7, lbb_1011                            if r8 != r7 { pc += 54 }
    ldxdw r2, [r2+0x18]                     
    ldxdw r7, [r5+0x20]                     
    jne r7, r2, lbb_1011                            if r7 != r2 { pc += 51 }
    ldxb r6, [r4+0x0]                       
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
    jne r6, 0, lbb_964                              if r6 != (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r2, 119                                   r2 = 119 as i32 as i64 as u64
lbb_964:
    ldxb r6, [r5+0x0]                       
    or64 r2, r6                                     r2 |= r6   ///  r2 = r2.or(r6)
    and64 r2, 255                                   r2 &= 255   ///  r2 = r2.and(255)
    jne r2, 255, lbb_990                            if r2 != (255 as i32 as i64 as u64) { pc += 22 }
    add64 r0, r1                                    r0 += r1   ///  r0 = r0.wrapping_add(r1)
    mov64 r2, r5                                    r2 = r5
    add64 r2, 8                                     r2 += 8   ///  r2 = r2.wrapping_add(8 as i32 as i64 as u64)
    ldxdw r6, [r5+0x50]                     
    ldxb r7, [r5+0x3]                       
    ldxb r9, [r5+0x2]                       
    ldxb r8, [r5+0x1]                       
    stxdw [r0+0x0], r2                      
    mov64 r0, 1                                     r0 = 1 as i32 as i64 as u64
    mov64 r2, 1                                     r2 = 1 as i32 as i64 as u64
    jeq r8, 0, lbb_983                              if r8 == (0 as i32 as i64 as u64) { pc += 4 }
    mov64 r8, 1                                     r8 = 1 as i32 as i64 as u64
    jeq r9, 0, lbb_986                              if r9 == (0 as i32 as i64 as u64) { pc += 5 }
lbb_981:
    jne r7, 0, lbb_922                              if r7 != (0 as i32 as i64 as u64) { pc += -60 }
    ja lbb_988                                      if true { pc += 5 }
lbb_983:
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
    mov64 r8, 1                                     r8 = 1 as i32 as i64 as u64
    jne r9, 0, lbb_981                              if r9 != (0 as i32 as i64 as u64) { pc += -5 }
lbb_986:
    mov64 r8, 0                                     r8 = 0 as i32 as i64 as u64
    jne r7, 0, lbb_922                              if r7 != (0 as i32 as i64 as u64) { pc += -66 }
lbb_988:
    mov64 r0, 0                                     r0 = 0 as i32 as i64 as u64
    ja lbb_922                                      if true { pc += -68 }
lbb_990:
    mov64 r6, 11                                    r6 = 11 as i32 as i64 as u64
    ja lbb_1011                                     if true { pc += 19 }
lbb_992:
    mov64 r1, r10                                   r1 = r10
    add64 r1, -648                                  r1 += -648   ///  r1 = r1.wrapping_add(-648 as i32 as i64 as u64)
    stxdw [r10-0x10], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -792                                  r1 += -792   ///  r1 = r1.wrapping_add(-792 as i32 as i64 as u64)
    stxdw [r10-0x20], r1                    
    ldxdw r1, [r10-0x370]                   
    stxdw [r10-0x28], r1                    
    stdw [r10-0x8], 25                      
    stdw [r10-0x18], 9                      
    mov64 r1, r10                                   r1 = r10
    add64 r1, -40                                   r1 += -40   ///  r1 = r1.wrapping_add(-40 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -544                                  r2 += -544   ///  r2 = r2.wrapping_add(-544 as i32 as i64 as u64)
    mov64 r3, 9                                     r3 = 9 as i32 as i64 as u64
    mov64 r4, 8                                     r4 = 8 as i32 as i64 as u64
    mov64 r5, 0                                     r5 = 0 as i32 as i64 as u64
    syscall [invalid]                       
    mov64 r6, 26                                    r6 = 26 as i32 as i64 as u64
lbb_1011:
    ldxdw r1, [r10-0x330]                   
lbb_1012:
    stxw [r1+0x0], r6                       
    stw [r1+0x4], 0                         
    exit                                    
lbb_1015:
    mov64 r2, r3                                    r2 = r3
lbb_1016:
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    ja lbb_845                                      if true { pc += -173 }
lbb_1018:
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    mov64 r2, 1                                     r2 = 1 as i32 as i64 as u64
    lddw r3, 0x100025fa8 --> b"\x00\x00\x00\x00\xb8Y\x02\x00\x10\x00\x00\x00\x00\x00\x00\x00@ \x00\x00!\…        r3 load str located at 4295122856
    call function_18489                     
lbb_1023:
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
    lddw r3, 0x100025f90 --> b"\x00\x00\x00\x00\xb8Y\x02\x00\x10\x00\x00\x00\x00\x00\x00\x00@ \x00\x00\x…        r3 load str located at 4295122832
    call function_18489                     
lbb_1028:
    mov64 r1, 2                                     r1 = 2 as i32 as i64 as u64
    mov64 r2, 2                                     r2 = 2 as i32 as i64 as u64
    lddw r3, 0x100025fc0 --> b"\x00\x00\x00\x00\xb8Y\x02\x00\x10\x00\x00\x00\x00\x00\x00\x00@ \x00\x008\…        r3 load str located at 4295122880
    call function_18489                     
lbb_1033:
    mov64 r1, 3                                     r1 = 3 as i32 as i64 as u64
    mov64 r2, 3                                     r2 = 3 as i32 as i64 as u64
    lddw r3, 0x100025fd8 --> b"\x00\x00\x00\x00\xb8Y\x02\x00\x10\x00\x00\x00\x00\x00\x00\x00@ \x00\x00O\…        r3 load str located at 4295122904
    call function_18489                     
    ldxdw r3, [r2+0x8]                      
    jeq r3, 1, lbb_1348                             if r3 == (1 as i32 as i64 as u64) { pc += 308 }
    jeq r3, 0, lbb_1353                             if r3 == (0 as i32 as i64 as u64) { pc += 312 }
    jle r3, 2, lbb_1358                             if r3 <= (2 as i32 as i64 as u64) { pc += 316 }
    jeq r3, 3, lbb_1363                             if r3 == (3 as i32 as i64 as u64) { pc += 320 }
    jle r3, 4, lbb_1368                             if r3 <= (4 as i32 as i64 as u64) { pc += 324 }
    jeq r3, 5, lbb_1373                             if r3 == (5 as i32 as i64 as u64) { pc += 328 }
    jle r3, 6, lbb_1378                             if r3 <= (6 as i32 as i64 as u64) { pc += 332 }
    ldxdw r9, [r2+0x50]                     
    ldxdw r5, [r9+0x0]                      
    ldxdw r3, [r5+0x50]                     
    jlt r3, 32, lbb_1346                            if r3 < (32 as i32 as i64 as u64) { pc += 296 }
    stxdw [r10-0x468], r1                   
    ldxdw r8, [r2+0x0]                      
    ldxdw r4, [r2+0x58]                     
    ldxdw r3, [r8+0x18]                     
    mov64 r1, r3                                    r1 = r3
    add64 r1, 8                                     r1 += 8   ///  r1 = r1.wrapping_add(8 as i32 as i64 as u64)
    mov64 r7, 0                                     r7 = 0 as i32 as i64 as u64
    ldxdw r0, [r1+0x0]                      
    ldxdw r6, [r5+0x58]                     
    stxdw [r10-0x478], r1                   
    jne r6, r0, lbb_1076                            if r6 != r0 { pc += 15 }
    ldxdw r0, [r3+0x10]                     
    ldxdw r6, [r5+0x60]                     
    jne r6, r0, lbb_1076                            if r6 != r0 { pc += 12 }
    ldxdw r0, [r3+0x18]                     
    ldxdw r6, [r5+0x68]                     
    jne r6, r0, lbb_1076                            if r6 != r0 { pc += 9 }
    ldxdw r0, [r3+0x20]                     
    ldxdw r5, [r5+0x70]                     
    mov64 r7, 1                                     r7 = 1 as i32 as i64 as u64
    jeq r5, r0, lbb_1072                            if r5 == r0 { pc += 1 }
    mov64 r7, 0                                     r7 = 0 as i32 as i64 as u64
lbb_1072:
    jne r5, r0, lbb_1076                            if r5 != r0 { pc += 3 }
    stxdw [r10-0x460], r9                   
    mov64 r9, r4                                    r9 = r4
    ja lbb_1077                                     if true { pc += 1 }
lbb_1076:
    stxdw [r10-0x460], r4                   
lbb_1077:
    ldxdw r6, [r2+0x30]                     
    ldxdw r0, [r2+0x28]                     
    mov64 r1, r8                                    r1 = r8
    add64 r1, 32                                    r1 += 32   ///  r1 = r1.wrapping_add(32 as i32 as i64 as u64)
    stxdw [r10-0x458], r1                   
    ldxdw r4, [r3+0x28]                     
    lddw r5, 0xde8f75eee1f6dd06                     r5 load str located at -2409577606766207738
    mov64 r1, r0                                    r1 = r0
    jne r4, r5, lbb_1103                            if r4 != r5 { pc += 16 }
    ldxdw r4, [r3+0x30]                     
    mov64 r1, r0                                    r1 = r0
    lddw r5, 0xdacd6ce4bc5d4218                     r5 load str located at -2680366473547005416
    jne r4, r5, lbb_1103                            if r4 != r5 { pc += 11 }
    ldxdw r4, [r3+0x38]                     
    lddw r5, 0x270db9834dfc1ab6                     r5 load str located at 2814109315776649910
    mov64 r1, r0                                    r1 = r0
    jne r4, r5, lbb_1103                            if r4 != r5 { pc += 6 }
    ldxdw r3, [r3+0x40]                     
    lddw r4, 0xfc8ba1d828f9bdfe                     r4 load str located at -248927404616466946
    mov64 r1, r0                                    r1 = r0
    jne r3, r4, lbb_1103                            if r3 != r4 { pc += 1 }
    mov64 r1, r6                                    r1 = r6
lbb_1103:
    stxdw [r10-0x4c0], r6                   
    ldxdw r3, [r2+0x48]                     
    ldxdw r6, [r2+0x40]                     
    ldxdw r4, [r2+0x20]                     
    stxdw [r10-0x490], r4                   
    ldxdw r2, [r2+0x10]                     
    stxdw [r10-0x4a8], r2                   
    mov64 r2, r8                                    r2 = r8
    add64 r2, 48                                    r2 += 48   ///  r2 = r2.wrapping_add(48 as i32 as i64 as u64)
    stxdw [r10-0x498], r2                   
    mov64 r2, r8                                    r2 = r8
    add64 r2, 8                                     r2 += 8   ///  r2 = r2.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x480], r2                   
    mov64 r2, r8                                    r2 = r8
    add64 r2, 16                                    r2 += 16   ///  r2 = r2.wrapping_add(16 as i32 as i64 as u64)
    stxdw [r10-0x488], r2                   
    mov64 r2, r8                                    r2 = r8
    add64 r2, 24                                    r2 += 24   ///  r2 = r2.wrapping_add(24 as i32 as i64 as u64)
    stxdw [r10-0x4a0], r2                   
    mov64 r2, r8                                    r2 = r8
    add64 r2, 40                                    r2 += 40   ///  r2 = r2.wrapping_add(40 as i32 as i64 as u64)
    stxdw [r10-0x4b0], r2                   
    and64 r7, 1                                     r7 &= 1   ///  r7 = r7.and(1)
    stxdw [r10-0x470], r7                   
    ldxdw r2, [r10-0x458]                   
    ldxdw r7, [r2+0x0]                      
    ldxdw r4, [r7+0x28]                     
    lddw r2, 0xde8f75eee1f6dd06                     r2 load str located at -2409577606766207738
    jne r4, r2, lbb_1146                            if r4 != r2 { pc += 13 }
    ldxdw r4, [r7+0x30]                     
    lddw r5, 0xdacd6ce4bc5d4218                     r5 load str located at -2680366473547005416
    jne r4, r5, lbb_1146                            if r4 != r5 { pc += 9 }
    ldxdw r4, [r7+0x38]                     
    lddw r5, 0x270db9834dfc1ab6                     r5 load str located at 2814109315776649910
    jne r4, r5, lbb_1146                            if r4 != r5 { pc += 5 }
    ldxdw r4, [r7+0x40]                     
    lddw r5, 0xfc8ba1d828f9bdfe                     r5 load str located at -248927404616466946
    jne r4, r5, lbb_1146                            if r4 != r5 { pc += 1 }
    ldxdw r0, [r10-0x4c0]                   
lbb_1146:
    add64 r7, 8                                     r7 += 8   ///  r7 = r7.wrapping_add(8 as i32 as i64 as u64)
    ldxdw r2, [r3+0x0]                      
    stxdw [r10-0x4e0], r2                   
    ldxdw r2, [r8+0x0]                      
    stxdw [r10-0x4e8], r2                   
    stxdw [r10-0x4b8], r6                   
    ldxdw r2, [r6+0x0]                      
    stxdw [r10-0x4f0], r2                   
    ldxdw r2, [r10-0x460]                   
    ldxdw r2, [r2+0x0]                      
    stxdw [r10-0x4f8], r2                   
    mov64 r2, r8                                    r2 = r8
    ldxdw r8, [r9+0x0]                      
    ldxdw r6, [r2+0x8]                      
    ldxdw r5, [r2+0x10]                     
    stxdw [r10-0x4c8], r2                   
    stxdw [r10-0x4d8], r1                   
    ldxdw r4, [r1+0x0]                      
    ldxdw r1, [r0+0x0]                      
    stxdw [r10-0x4d0], r9                   
    ldxdw r9, [r2+0x28]                     
    stxdw [r10-0x4c0], r3                   
    ldxdw r3, [r2+0x30]                     
    stxdw [r10-0x3b0], r7                   
    ldxdw r7, [r10-0x478]                   
    stxdw [r10-0x3d0], r7                   
    add64 r3, 8                                     r3 += 8   ///  r3 = r3.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x390], r3                   
    add64 r9, 8                                     r9 += 8   ///  r9 = r9.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x3a0], r9                   
    add64 r1, 8                                     r1 += 8   ///  r1 = r1.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x3c0], r1                   
    add64 r4, 8                                     r4 += 8   ///  r4 = r4.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x3e0], r4                   
    add64 r5, 8                                     r5 += 8   ///  r5 = r5.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x3f0], r5                   
    add64 r6, 8                                     r6 += 8   ///  r6 = r6.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x400], r6                   
    add64 r8, 8                                     r8 += 8   ///  r8 = r8.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x410], r8                   
    ldxdw r1, [r10-0x4f8]                   
    add64 r1, 8                                     r1 += 8   ///  r1 = r1.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x420], r1                   
    ldxdw r1, [r10-0x4f0]                   
    add64 r1, 8                                     r1 += 8   ///  r1 = r1.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x430], r1                   
    ldxdw r1, [r10-0x4e8]                   
    add64 r1, 8                                     r1 += 8   ///  r1 = r1.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x440], r1                   
    ldxdw r1, [r10-0x4e0]                   
    add64 r1, 8                                     r1 += 8   ///  r1 = r1.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x450], r1                   
    sth [r10-0x388], 1                      
    sth [r10-0x398], 1                      
    sth [r10-0x3a8], 0                      
    sth [r10-0x3b8], 0                      
    sth [r10-0x3c8], 0                      
    sth [r10-0x3d8], 0                      
    sth [r10-0x3e8], 1                      
    sth [r10-0x3f8], 1                      
    sth [r10-0x408], 1                      
    sth [r10-0x418], 1                      
    sth [r10-0x428], 0                      
    sth [r10-0x438], 1                      
    sth [r10-0x448], 257                    
    ldxdw r1, [r10-0x470]                   
    stxb [r10-0x36a], r1                    
    ldxdw r1, [r10-0x4a8]                   
    stxdw [r10-0x37a], r1                   
    stb [r10-0x369], 1                      
    stb [r10-0x37b], 4                      
    stdw [r10-0x372], 0                     
    ldxdw r1, [r10-0x490]                   
    ldxdw r2, [r1+0x0]                      
    ldxdw r1, [r10-0x498]                   
    stxdw [r10-0x308], r1                   
    ldxdw r1, [r10-0x4b0]                   
    stxdw [r10-0x310], r1                   
    ldxdw r1, [r10-0x458]                   
    stxdw [r10-0x318], r1                   
    stxdw [r10-0x320], r0                   
    ldxdw r1, [r10-0x4a0]                   
    stxdw [r10-0x328], r1                   
    ldxdw r1, [r10-0x4d8]                   
    stxdw [r10-0x330], r1                   
    ldxdw r1, [r10-0x488]                   
    stxdw [r10-0x338], r1                   
    ldxdw r1, [r10-0x480]                   
    stxdw [r10-0x340], r1                   
    ldxdw r1, [r10-0x4d0]                   
    stxdw [r10-0x348], r1                   
    ldxdw r1, [r10-0x460]                   
    stxdw [r10-0x350], r1                   
    ldxdw r1, [r10-0x4b8]                   
    stxdw [r10-0x358], r1                   
    ldxdw r1, [r10-0x4c8]                   
    stxdw [r10-0x360], r1                   
    ldxdw r1, [r10-0x4c0]                   
    stxdw [r10-0x368], r1                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -872                                  r1 += -872   ///  r1 = r1.wrapping_add(-872 as i32 as i64 as u64)
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
    mov64 r4, r10                                   r4 = r10
    add64 r4, -1096                                 r4 += -1096   ///  r4 = r4.wrapping_add(-1096 as i32 as i64 as u64)
    add64 r2, 8                                     r2 += 8   ///  r2 = r2.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x458], r2                   
    ja lbb_1273                                     if true { pc += 20 }
lbb_1253:
    mov64 r0, r10                                   r0 = r10
    add64 r0, -768                                  r0 += -768   ///  r0 = r0.wrapping_add(-768 as i32 as i64 as u64)
    add64 r0, r3                                    r0 += r3   ///  r0 = r0.wrapping_add(r3)
    stxb [r0+0x32], r7                      
    stxb [r0+0x31], r9                      
    stxb [r0+0x30], r5                      
    mov64 r5, r2                                    r5 = r2
    add64 r5, 40                                    r5 += 40   ///  r5 = r5.wrapping_add(40 as i32 as i64 as u64)
    stxdw [r0+0x20], r5                     
    mov64 r5, r2                                    r5 = r2
    add64 r5, 88                                    r5 += 88   ///  r5 = r5.wrapping_add(88 as i32 as i64 as u64)
    stxdw [r0+0x18], r5                     
    stxdw [r0+0x10], r6                     
    add64 r2, 72                                    r2 += 72   ///  r2 = r2.wrapping_add(72 as i32 as i64 as u64)
    stxdw [r0+0x8], r2                      
    stdw [r0+0x28], 0                       
    add64 r4, 16                                    r4 += 16   ///  r4 = r4.wrapping_add(16 as i32 as i64 as u64)
    add64 r1, 8                                     r1 += 8   ///  r1 = r1.wrapping_add(8 as i32 as i64 as u64)
    add64 r3, 56                                    r3 += 56   ///  r3 = r3.wrapping_add(56 as i32 as i64 as u64)
    jeq r3, 728, lbb_1323                           if r3 == (728 as i32 as i64 as u64) { pc += 50 }
lbb_1273:
    mov64 r5, r10                                   r5 = r10
    add64 r5, -768                                  r5 += -768   ///  r5 = r5.wrapping_add(-768 as i32 as i64 as u64)
    mov64 r6, 1                                     r6 = 1 as i32 as i64 as u64
    ldxdw r2, [r1+0x0]                      
    ldxdw r2, [r2+0x0]                      
    ldxdw r7, [r4-0x8]                      
    ldxdw r0, [r7+0x0]                      
    ldxdw r8, [r2+0x8]                      
    jne r8, r0, lbb_1342                            if r8 != r0 { pc += 60 }
    ldxdw r0, [r7+0x8]                      
    ldxdw r8, [r2+0x10]                     
    jne r8, r0, lbb_1342                            if r8 != r0 { pc += 57 }
    ldxdw r0, [r7+0x10]                     
    ldxdw r8, [r2+0x18]                     
    jne r8, r0, lbb_1342                            if r8 != r0 { pc += 54 }
    ldxdw r0, [r7+0x18]                     
    ldxdw r7, [r2+0x20]                     
    jne r7, r0, lbb_1342                            if r7 != r0 { pc += 51 }
    ldxb r6, [r4+0x0]                       
    mov64 r0, 0                                     r0 = 0 as i32 as i64 as u64
    jne r6, 0, lbb_1295                             if r6 != (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r0, 119                                   r0 = 119 as i32 as i64 as u64
lbb_1295:
    ldxb r6, [r2+0x0]                       
    or64 r0, r6                                     r0 |= r6   ///  r0 = r0.or(r6)
    and64 r0, 255                                   r0 &= 255   ///  r0 = r0.and(255)
    jne r0, 255, lbb_1321                           if r0 != (255 as i32 as i64 as u64) { pc += 22 }
    add64 r5, r3                                    r5 += r3   ///  r5 = r5.wrapping_add(r3)
    mov64 r7, r2                                    r7 = r2
    add64 r7, 8                                     r7 += 8   ///  r7 = r7.wrapping_add(8 as i32 as i64 as u64)
    ldxdw r6, [r2+0x50]                     
    ldxb r8, [r2+0x3]                       
    ldxb r0, [r2+0x2]                       
    ldxb r9, [r2+0x1]                       
    stxdw [r5+0x0], r7                      
    mov64 r7, 1                                     r7 = 1 as i32 as i64 as u64
    mov64 r5, 1                                     r5 = 1 as i32 as i64 as u64
    jeq r9, 0, lbb_1314                             if r9 == (0 as i32 as i64 as u64) { pc += 4 }
    mov64 r9, 1                                     r9 = 1 as i32 as i64 as u64
    jeq r0, 0, lbb_1317                             if r0 == (0 as i32 as i64 as u64) { pc += 5 }
lbb_1312:
    jne r8, 0, lbb_1253                             if r8 != (0 as i32 as i64 as u64) { pc += -60 }
    ja lbb_1319                                     if true { pc += 5 }
lbb_1314:
    mov64 r5, 0                                     r5 = 0 as i32 as i64 as u64
    mov64 r9, 1                                     r9 = 1 as i32 as i64 as u64
    jne r0, 0, lbb_1312                             if r0 != (0 as i32 as i64 as u64) { pc += -5 }
lbb_1317:
    mov64 r9, 0                                     r9 = 0 as i32 as i64 as u64
    jne r8, 0, lbb_1253                             if r8 != (0 as i32 as i64 as u64) { pc += -66 }
lbb_1319:
    mov64 r7, 0                                     r7 = 0 as i32 as i64 as u64
    ja lbb_1253                                     if true { pc += -68 }
lbb_1321:
    mov64 r6, 11                                    r6 = 11 as i32 as i64 as u64
    ja lbb_1342                                     if true { pc += 19 }
lbb_1323:
    mov64 r1, r10                                   r1 = r10
    add64 r1, -891                                  r1 += -891   ///  r1 = r1.wrapping_add(-891 as i32 as i64 as u64)
    stxdw [r10-0x10], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -1104                                 r1 += -1104   ///  r1 = r1.wrapping_add(-1104 as i32 as i64 as u64)
    stxdw [r10-0x20], r1                    
    ldxdw r1, [r10-0x458]                   
    stxdw [r10-0x28], r1                    
    stdw [r10-0x8], 19                      
    stdw [r10-0x18], 13                     
    mov64 r1, r10                                   r1 = r10
    add64 r1, -40                                   r1 += -40   ///  r1 = r1.wrapping_add(-40 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -768                                  r2 += -768   ///  r2 = r2.wrapping_add(-768 as i32 as i64 as u64)
    mov64 r3, 13                                    r3 = 13 as i32 as i64 as u64
    mov64 r4, 8                                     r4 = 8 as i32 as i64 as u64
    mov64 r5, 0                                     r5 = 0 as i32 as i64 as u64
    syscall [invalid]                       
    mov64 r6, 26                                    r6 = 26 as i32 as i64 as u64
lbb_1342:
    ldxdw r1, [r10-0x468]                   
lbb_1343:
    stxw [r1+0x0], r6                       
    stw [r1+0x4], 0                         
    exit                                    
lbb_1346:
    mov64 r6, 3                                     r6 = 3 as i32 as i64 as u64
    ja lbb_1343                                     if true { pc += -5 }
lbb_1348:
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    mov64 r2, 1                                     r2 = 1 as i32 as i64 as u64
    lddw r3, 0x100026008 --> b"\x00\x00\x00\x00\xb8Y\x02\x00\x10\x00\x00\x00\x00\x00\x00\x00K \x00\x00!\…        r3 load str located at 4295122952
    call function_18489                     
lbb_1353:
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
    lddw r3, 0x100025ff0 --> b"\x00\x00\x00\x00\xb8Y\x02\x00\x10\x00\x00\x00\x00\x00\x00\x00K \x00\x00\x…        r3 load str located at 4295122928
    call function_18489                     
lbb_1358:
    mov64 r1, 2                                     r1 = 2 as i32 as i64 as u64
    mov64 r2, 2                                     r2 = 2 as i32 as i64 as u64
    lddw r3, 0x100026020 --> b"\x00\x00\x00\x00\xb8Y\x02\x00\x10\x00\x00\x00\x00\x00\x00\x00K \x00\x008\…        r3 load str located at 4295122976
    call function_18489                     
lbb_1363:
    mov64 r1, 3                                     r1 = 3 as i32 as i64 as u64
    mov64 r2, 3                                     r2 = 3 as i32 as i64 as u64
    lddw r3, 0x100026038 --> b"\x00\x00\x00\x00\xb8Y\x02\x00\x10\x00\x00\x00\x00\x00\x00\x00K \x00\x00O\…        r3 load str located at 4295123000
    call function_18489                     
lbb_1368:
    mov64 r1, 4                                     r1 = 4 as i32 as i64 as u64
    mov64 r2, 4                                     r2 = 4 as i32 as i64 as u64
    lddw r3, 0x100026050 --> b"\x00\x00\x00\x00\xb8Y\x02\x00\x10\x00\x00\x00\x00\x00\x00\x00L \x00\x00\x…        r3 load str located at 4295123024
    call function_18489                     
lbb_1373:
    mov64 r1, 5                                     r1 = 5 as i32 as i64 as u64
    mov64 r2, 5                                     r2 = 5 as i32 as i64 as u64
    lddw r3, 0x100026068 --> b"\x00\x00\x00\x00\xb8Y\x02\x00\x10\x00\x00\x00\x00\x00\x00\x00L \x00\x00!\…        r3 load str located at 4295123048
    call function_18489                     
lbb_1378:
    mov64 r1, 6                                     r1 = 6 as i32 as i64 as u64
    mov64 r2, 6                                     r2 = 6 as i32 as i64 as u64
    lddw r3, 0x100026080 --> b"\x00\x00\x00\x00\xb8Y\x02\x00\x10\x00\x00\x00\x00\x00\x00\x00L \x00\x008\…        r3 load str located at 4295123072
    call function_18489                     
    ldxdw r8, [r2+0x28]                     
    ldxdw r5, [r2+0x20]                     
    ldxb r3, [r2+0x64]                      
    stxdw [r10-0x4a8], r1                   
    stxdw [r10-0x4b0], r5                   
    stxdw [r10-0x4b8], r8                   
    jeq r3, 0, lbb_1447                             if r3 == (0 as i32 as i64 as u64) { pc += 57 }
    ldxdw r3, [r2+0x8]                      
    jeq r3, 0, lbb_1873                             if r3 == (0 as i32 as i64 as u64) { pc += 481 }
    jeq r3, 1, lbb_1883                             if r3 == (1 as i32 as i64 as u64) { pc += 490 }
    jle r3, 2, lbb_1893                             if r3 <= (2 as i32 as i64 as u64) { pc += 499 }
    jeq r3, 3, lbb_1903                             if r3 == (3 as i32 as i64 as u64) { pc += 508 }
    jle r3, 4, lbb_1913                             if r3 <= (4 as i32 as i64 as u64) { pc += 517 }
    jeq r3, 5, lbb_1923                             if r3 == (5 as i32 as i64 as u64) { pc += 526 }
    ldxdw r6, [r2+0x50]                     
    mov64 r9, 3                                     r9 = 3 as i32 as i64 as u64
    ldxdw r3, [r6+0x0]                      
    ldxdw r4, [r3+0x50]                     
    jlt r4, 32, lbb_1865                            if r4 < (32 as i32 as i64 as u64) { pc += 463 }
    ldxdw r0, [r2+0x0]                      
    mov64 r4, r0                                    r4 = r0
    add64 r4, 16                                    r4 += 16   ///  r4 = r4.wrapping_add(16 as i32 as i64 as u64)
    stxdw [r10-0x4c8], r4                   
    ldxdw r7, [r4+0x0]                      
    ldxdw r4, [r7+0x50]                     
    jlt r4, 32, lbb_1865                            if r4 < (32 as i32 as i64 as u64) { pc += 456 }
    ldxdw r4, [r2+0x58]                     
    ldxdw r5, [r2+0x48]                     
    stxdw [r10-0x4c0], r5                   
    ldxdw r5, [r2+0x30]                     
    stxdw [r10-0x4e0], r5                   
    mov64 r5, r0                                    r5 = r0
    add64 r5, 8                                     r5 += 8   ///  r5 = r5.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x4d0], r5                   
    mov64 r5, r0                                    r5 = r0
    add64 r5, 24                                    r5 += 24   ///  r5 = r5.wrapping_add(24 as i32 as i64 as u64)
    stxdw [r10-0x4d8], r5                   
    ldxdw r2, [r2+0x10]                     
    stxdw [r10-0x4f8], r2                   
    mov64 r2, r0                                    r2 = r0
    add64 r2, 40                                    r2 += 40   ///  r2 = r2.wrapping_add(40 as i32 as i64 as u64)
    stxdw [r10-0x4e8], r2                   
    mov64 r9, r0                                    r9 = r0
    add64 r0, 32                                    r0 += 32   ///  r0 = r0.wrapping_add(32 as i32 as i64 as u64)
    stxdw [r10-0x4f0], r0                   
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
    ldxdw r5, [r7+0x58]                     
    ldxdw r0, [r3+0x58]                     
    jne r0, r5, lbb_1655                            if r0 != r5 { pc += 223 }
    ldxdw r5, [r7+0x60]                     
    ldxdw r0, [r3+0x60]                     
    jne r0, r5, lbb_1655                            if r0 != r5 { pc += 220 }
    ldxdw r5, [r7+0x68]                     
    ldxdw r0, [r3+0x68]                     
    jne r0, r5, lbb_1655                            if r0 != r5 { pc += 217 }
    ldxdw r5, [r7+0x70]                     
    ldxdw r3, [r3+0x70]                     
    mov64 r0, 1                                     r0 = 1 as i32 as i64 as u64
    jeq r3, r5, lbb_1443                            if r3 == r5 { pc += 1 }
    mov64 r0, 0                                     r0 = 0 as i32 as i64 as u64
lbb_1443:
    stxdw [r10-0x530], r0                   
    jne r3, r5, lbb_1870                            if r3 != r5 { pc += 425 }
    mov64 r3, r4                                    r3 = r4
    ja lbb_1659                                     if true { pc += 212 }
lbb_1447:
    ldxdw r3, [r2+0x8]                      
    jeq r3, 0, lbb_1878                             if r3 == (0 as i32 as i64 as u64) { pc += 429 }
    jeq r3, 1, lbb_1888                             if r3 == (1 as i32 as i64 as u64) { pc += 438 }
    jle r3, 2, lbb_1898                             if r3 <= (2 as i32 as i64 as u64) { pc += 447 }
    jeq r3, 3, lbb_1908                             if r3 == (3 as i32 as i64 as u64) { pc += 456 }
    jle r3, 4, lbb_1918                             if r3 <= (4 as i32 as i64 as u64) { pc += 465 }
    ldxdw r0, [r2+0x50]                     
    mov64 r9, 3                                     r9 = 3 as i32 as i64 as u64
    ldxdw r3, [r0+0x0]                      
    ldxdw r4, [r3+0x50]                     
    jlt r4, 32, lbb_1865                            if r4 < (32 as i32 as i64 as u64) { pc += 407 }
    ldxdw r7, [r2+0x0]                      
    mov64 r4, r7                                    r4 = r7
    add64 r4, 16                                    r4 += 16   ///  r4 = r4.wrapping_add(16 as i32 as i64 as u64)
    stxdw [r10-0x4c8], r4                   
    ldxdw r6, [r4+0x0]                      
    ldxdw r4, [r6+0x50]                     
    jlt r4, 32, lbb_1865                            if r4 < (32 as i32 as i64 as u64) { pc += 400 }
    ldxdw r9, [r2+0x58]                     
    ldxdw r4, [r2+0x48]                     
    stxdw [r10-0x4c0], r4                   
    mov64 r4, r7                                    r4 = r7
    add64 r4, 8                                     r4 += 8   ///  r4 = r4.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x4d8], r4                   
    ldxdw r2, [r2+0x10]                     
    stxdw [r10-0x4f0], r2                   
    mov64 r2, r7                                    r2 = r7
    add64 r2, 32                                    r2 += 32   ///  r2 = r2.wrapping_add(32 as i32 as i64 as u64)
    stxdw [r10-0x4e8], r2                   
    stxdw [r10-0x4d0], r7                   
    add64 r7, 24                                    r7 += 24   ///  r7 = r7.wrapping_add(24 as i32 as i64 as u64)
    stxdw [r10-0x4e0], r7                   
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
    ldxdw r4, [r6+0x58]                     
    ldxdw r7, [r3+0x58]                     
    jne r7, r4, lbb_1500                            if r7 != r4 { pc += 17 }
    ldxdw r4, [r6+0x60]                     
    ldxdw r7, [r3+0x60]                     
    jne r7, r4, lbb_1500                            if r7 != r4 { pc += 14 }
    ldxdw r4, [r6+0x68]                     
    ldxdw r7, [r3+0x68]                     
    jne r7, r4, lbb_1500                            if r7 != r4 { pc += 11 }
    ldxdw r4, [r6+0x70]                     
    ldxdw r7, [r3+0x70]                     
    mov64 r3, 1                                     r3 = 1 as i32 as i64 as u64
    jeq r7, r4, lbb_1494                            if r7 == r4 { pc += 1 }
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
lbb_1494:
    stxdw [r10-0x510], r3                   
    mov64 r5, r8                                    r5 = r8
    jne r7, r4, lbb_1868                            if r7 != r4 { pc += 371 }
    mov64 r1, r0                                    r1 = r0
    mov64 r0, r9                                    r0 = r9
    ja lbb_1504                                     if true { pc += 4 }
lbb_1500:
    mov64 r5, r8                                    r5 = r8
    mov64 r1, r9                                    r1 = r9
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
    stxdw [r10-0x510], r3                   
lbb_1504:
    stxdw [r10-0x500], r1                   
    stxdw [r10-0x4f8], r0                   
    add64 r6, 8                                     r6 += 8   ///  r6 = r6.wrapping_add(8 as i32 as i64 as u64)
    ldxdw r3, [r10-0x4c0]                   
    ldxdw r3, [r3+0x0]                      
    stxdw [r10-0x508], r3                   
    ldxdw r9, [r10-0x4d0]                   
    ldxdw r7, [r9+0x0]                      
    ldxdw r4, [r9+0x8]                      
    ldxdw r8, [r1+0x0]                      
    ldxdw r3, [r0+0x0]                      
    ldxdw r0, [r9+0x18]                     
    ldxdw r1, [r5+0x0]                      
    ldxdw r5, [r9+0x20]                     
    stxdw [r10-0x430], r6                   
    stxdw [r10-0x450], r6                   
    add64 r5, 8                                     r5 += 8   ///  r5 = r5.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x3f0], r5                   
    add64 r1, 8                                     r1 += 8   ///  r1 = r1.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x400], r1                   
    add64 r0, 8                                     r0 += 8   ///  r0 = r0.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x410], r0                   
    stxdw [r10-0x420], r0                   
    stxdw [r10-0x440], r0                   
    add64 r3, 8                                     r3 += 8   ///  r3 = r3.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x460], r3                   
    add64 r8, 8                                     r8 += 8   ///  r8 = r8.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x470], r8                   
    add64 r4, 8                                     r4 += 8   ///  r4 = r4.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x480], r4                   
    add64 r7, 8                                     r7 += 8   ///  r7 = r7.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x490], r7                   
    ldxdw r1, [r10-0x508]                   
    add64 r1, 8                                     r1 += 8   ///  r1 = r1.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x4a0], r1                   
    sth [r10-0x3e8], 0                      
    sth [r10-0x3f8], 0                      
    sth [r10-0x408], 1                      
    sth [r10-0x418], 1                      
    sth [r10-0x428], 1                      
    sth [r10-0x438], 1                      
    sth [r10-0x448], 1                      
    sth [r10-0x458], 1                      
    sth [r10-0x468], 1                      
    sth [r10-0x478], 1                      
    sth [r10-0x488], 0                      
    sth [r10-0x498], 257                    
    ldxdw r1, [r10-0x4f0]                   
    stxdw [r10-0x3b8], r1                   
    ldxdw r1, [r10-0x510]                   
    and64 r1, 1                                     r1 &= 1   ///  r1 = r1.and(1)
    stxb [r10-0x3b9], r1                    
    stb [r10-0x3ba], 12                     
    stdw [r10-0x3b0], 0                     
    ldxdw r1, [r10-0x4b0]                   
    ldxdw r3, [r1+0x0]                      
    ldxdw r1, [r10-0x4e8]                   
    stxdw [r10-0x350], r1                   
    ldxdw r1, [r10-0x4b8]                   
    stxdw [r10-0x358], r1                   
    ldxdw r1, [r10-0x4e0]                   
    stxdw [r10-0x360], r1                   
    stxdw [r10-0x368], r1                   
    stxdw [r10-0x378], r1                   
    ldxdw r1, [r10-0x4c8]                   
    stxdw [r10-0x370], r1                   
    stxdw [r10-0x380], r1                   
    ldxdw r1, [r10-0x4f8]                   
    stxdw [r10-0x388], r1                   
    ldxdw r1, [r10-0x500]                   
    stxdw [r10-0x390], r1                   
    ldxdw r1, [r10-0x4d8]                   
    stxdw [r10-0x398], r1                   
    stxdw [r10-0x3a0], r9                   
    ldxdw r1, [r10-0x4c0]                   
    stxdw [r10-0x3a8], r1                   
    mov64 r4, r10                                   r4 = r10
    add64 r4, -936                                  r4 += -936   ///  r4 = r4.wrapping_add(-936 as i32 as i64 as u64)
    mov64 r5, r10                                   r5 = r10
    add64 r5, -1176                                 r5 += -1176   ///  r5 = r5.wrapping_add(-1176 as i32 as i64 as u64)
    add64 r3, 8                                     r3 += 8   ///  r3 = r3.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x4b0], r3                   
    ja lbb_1607                                     if true { pc += 20 }
lbb_1587:
    mov64 r3, r10                                   r3 = r10
    add64 r3, -824                                  r3 += -824   ///  r3 = r3.wrapping_add(-824 as i32 as i64 as u64)
    add64 r3, r2                                    r3 += r2   ///  r3 = r3.wrapping_add(r2)
    stxb [r3+0x32], r7                      
    stxb [r3+0x31], r9                      
    stxb [r3+0x30], r6                      
    mov64 r6, r0                                    r6 = r0
    add64 r6, 40                                    r6 += 40   ///  r6 = r6.wrapping_add(40 as i32 as i64 as u64)
    stxdw [r3+0x20], r6                     
    mov64 r6, r0                                    r6 = r0
    add64 r6, 88                                    r6 += 88   ///  r6 = r6.wrapping_add(88 as i32 as i64 as u64)
    stxdw [r3+0x18], r6                     
    stxdw [r3+0x10], r1                     
    add64 r0, 72                                    r0 += 72   ///  r0 = r0.wrapping_add(72 as i32 as i64 as u64)
    stxdw [r3+0x8], r0                      
    stdw [r3+0x28], 0                       
    add64 r5, 16                                    r5 += 16   ///  r5 = r5.wrapping_add(16 as i32 as i64 as u64)
    add64 r4, 8                                     r4 += 8   ///  r4 = r4.wrapping_add(8 as i32 as i64 as u64)
    add64 r2, 56                                    r2 += 56   ///  r2 = r2.wrapping_add(56 as i32 as i64 as u64)
    jeq r2, 672, lbb_1829                           if r2 == (672 as i32 as i64 as u64) { pc += 222 }
lbb_1607:
    mov64 r6, r10                                   r6 = r10
    add64 r6, -824                                  r6 += -824   ///  r6 = r6.wrapping_add(-824 as i32 as i64 as u64)
    mov64 r9, 1                                     r9 = 1 as i32 as i64 as u64
    ldxdw r3, [r4+0x0]                      
    ldxdw r0, [r3+0x0]                      
    ldxdw r7, [r5-0x8]                      
    ldxdw r3, [r7+0x0]                      
    ldxdw r8, [r0+0x8]                      
    jne r8, r3, lbb_1864                            if r8 != r3 { pc += 248 }
    ldxdw r3, [r7+0x8]                      
    ldxdw r8, [r0+0x10]                     
    jne r8, r3, lbb_1864                            if r8 != r3 { pc += 245 }
    ldxdw r3, [r7+0x10]                     
    ldxdw r8, [r0+0x18]                     
    jne r8, r3, lbb_1864                            if r8 != r3 { pc += 242 }
    ldxdw r3, [r7+0x18]                     
    ldxdw r7, [r0+0x20]                     
    jne r7, r3, lbb_1864                            if r7 != r3 { pc += 239 }
    ldxb r3, [r5+0x0]                       
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    jne r3, 0, lbb_1629                             if r3 != (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r1, 119                                   r1 = 119 as i32 as i64 as u64
lbb_1629:
    ldxb r3, [r0+0x0]                       
    or64 r1, r3                                     r1 |= r3   ///  r1 = r1.or(r3)
    and64 r1, 255                                   r1 &= 255   ///  r1 = r1.and(255)
    jne r1, 255, lbb_1827                           if r1 != (255 as i32 as i64 as u64) { pc += 194 }
    add64 r6, r2                                    r6 += r2   ///  r6 = r6.wrapping_add(r2)
    mov64 r7, r0                                    r7 = r0
    add64 r7, 8                                     r7 += 8   ///  r7 = r7.wrapping_add(8 as i32 as i64 as u64)
    ldxdw r1, [r0+0x50]                     
    ldxb r8, [r0+0x3]                       
    ldxb r3, [r0+0x2]                       
    ldxb r9, [r0+0x1]                       
    stxdw [r6+0x0], r7                      
    mov64 r7, 1                                     r7 = 1 as i32 as i64 as u64
    mov64 r6, 1                                     r6 = 1 as i32 as i64 as u64
    jne r9, 0, lbb_1649                             if r9 != (0 as i32 as i64 as u64) { pc += 5 }
    mov64 r6, 0                                     r6 = 0 as i32 as i64 as u64
    mov64 r9, 1                                     r9 = 1 as i32 as i64 as u64
    jeq r3, 0, lbb_1651                             if r3 == (0 as i32 as i64 as u64) { pc += 4 }
lbb_1647:
    jne r8, 0, lbb_1587                             if r8 != (0 as i32 as i64 as u64) { pc += -61 }
    ja lbb_1653                                     if true { pc += 4 }
lbb_1649:
    mov64 r9, 1                                     r9 = 1 as i32 as i64 as u64
    jne r3, 0, lbb_1647                             if r3 != (0 as i32 as i64 as u64) { pc += -4 }
lbb_1651:
    mov64 r9, 0                                     r9 = 0 as i32 as i64 as u64
    jne r8, 0, lbb_1587                             if r8 != (0 as i32 as i64 as u64) { pc += -66 }
lbb_1653:
    mov64 r7, 0                                     r7 = 0 as i32 as i64 as u64
    ja lbb_1587                                     if true { pc += -68 }
lbb_1655:
    mov64 r3, r6                                    r3 = r6
    mov64 r6, r4                                    r6 = r4
    mov64 r4, 0                                     r4 = 0 as i32 as i64 as u64
    stxdw [r10-0x530], r4                   
lbb_1659:
    stxdw [r10-0x508], r6                   
    add64 r7, 8                                     r7 += 8   ///  r7 = r7.wrapping_add(8 as i32 as i64 as u64)
    ldxdw r4, [r10-0x4c0]                   
    ldxdw r1, [r4+0x0]                      
    stxdw [r10-0x518], r1                   
    ldxdw r1, [r9+0x0]                      
    stxdw [r10-0x520], r1                   
    ldxdw r1, [r9+0x8]                      
    stxdw [r10-0x528], r1                   
    ldxdw r4, [r6+0x0]                      
    stxdw [r10-0x500], r3                   
    ldxdw r3, [r3+0x0]                      
    stxdw [r10-0x510], r9                   
    ldxdw r0, [r9+0x18]                     
    ldxdw r6, [r8+0x0]                      
    ldxdw r1, [r9+0x20]                     
    ldxdw r5, [r9+0x28]                     
    ldxdw r9, [r10-0x4e0]                   
    ldxdw r8, [r9+0x0]                      
    stxdw [r10-0x430], r7                   
    stxdw [r10-0x450], r7                   
    add64 r8, 8                                     r8 += 8   ///  r8 = r8.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x3d0], r8                   
    add64 r5, 8                                     r5 += 8   ///  r5 = r5.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x3e0], r5                   
    add64 r1, 8                                     r1 += 8   ///  r1 = r1.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x3f0], r1                   
    add64 r6, 8                                     r6 += 8   ///  r6 = r6.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x400], r6                   
    add64 r0, 8                                     r0 += 8   ///  r0 = r0.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x410], r0                   
    stxdw [r10-0x420], r0                   
    stxdw [r10-0x440], r0                   
    add64 r3, 8                                     r3 += 8   ///  r3 = r3.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x460], r3                   
    add64 r4, 8                                     r4 += 8   ///  r4 = r4.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x470], r4                   
    ldxdw r1, [r10-0x528]                   
    add64 r1, 8                                     r1 += 8   ///  r1 = r1.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x480], r1                   
    ldxdw r1, [r10-0x520]                   
    add64 r1, 8                                     r1 += 8   ///  r1 = r1.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x490], r1                   
    ldxdw r1, [r10-0x518]                   
    add64 r1, 8                                     r1 += 8   ///  r1 = r1.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x4a0], r1                   
    sth [r10-0x3c8], 0                      
    sth [r10-0x3d8], 0                      
    sth [r10-0x3e8], 0                      
    sth [r10-0x3f8], 0                      
    sth [r10-0x408], 1                      
    sth [r10-0x418], 1                      
    sth [r10-0x428], 1                      
    sth [r10-0x438], 1                      
    sth [r10-0x448], 1                      
    sth [r10-0x458], 1                      
    sth [r10-0x468], 1                      
    sth [r10-0x478], 1                      
    sth [r10-0x488], 0                      
    sth [r10-0x498], 257                    
    ldxdw r1, [r10-0x4f8]                   
    stxdw [r10-0x3b8], r1                   
    ldxdw r1, [r10-0x530]                   
    and64 r1, 1                                     r1 &= 1   ///  r1 = r1.and(1)
    stxb [r10-0x3b9], r1                    
    stb [r10-0x3ba], 12                     
    stdw [r10-0x3b0], 0                     
    ldxdw r1, [r10-0x4b0]                   
    ldxdw r3, [r1+0x0]                      
    stxdw [r10-0x340], r9                   
    ldxdw r1, [r10-0x4e8]                   
    stxdw [r10-0x348], r1                   
    ldxdw r1, [r10-0x4f0]                   
    stxdw [r10-0x350], r1                   
    ldxdw r1, [r10-0x4b8]                   
    stxdw [r10-0x358], r1                   
    ldxdw r1, [r10-0x4d8]                   
    stxdw [r10-0x360], r1                   
    stxdw [r10-0x368], r1                   
    stxdw [r10-0x378], r1                   
    ldxdw r1, [r10-0x4c8]                   
    stxdw [r10-0x370], r1                   
    stxdw [r10-0x380], r1                   
    ldxdw r1, [r10-0x500]                   
    stxdw [r10-0x388], r1                   
    ldxdw r1, [r10-0x508]                   
    stxdw [r10-0x390], r1                   
    ldxdw r1, [r10-0x4d0]                   
    stxdw [r10-0x398], r1                   
    ldxdw r1, [r10-0x510]                   
    stxdw [r10-0x3a0], r1                   
    ldxdw r1, [r10-0x4c0]                   
    stxdw [r10-0x3a8], r1                   
    mov64 r4, r10                                   r4 = r10
    add64 r4, -936                                  r4 += -936   ///  r4 = r4.wrapping_add(-936 as i32 as i64 as u64)
    mov64 r5, r10                                   r5 = r10
    add64 r5, -1176                                 r5 += -1176   ///  r5 = r5.wrapping_add(-1176 as i32 as i64 as u64)
    add64 r3, 8                                     r3 += 8   ///  r3 = r3.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x4b0], r3                   
    ja lbb_1779                                     if true { pc += 20 }
lbb_1759:
    mov64 r3, r10                                   r3 = r10
    add64 r3, -824                                  r3 += -824   ///  r3 = r3.wrapping_add(-824 as i32 as i64 as u64)
    add64 r3, r2                                    r3 += r2   ///  r3 = r3.wrapping_add(r2)
    stxb [r3+0x32], r7                      
    stxb [r3+0x31], r9                      
    stxb [r3+0x30], r6                      
    mov64 r6, r0                                    r6 = r0
    add64 r6, 40                                    r6 += 40   ///  r6 = r6.wrapping_add(40 as i32 as i64 as u64)
    stxdw [r3+0x20], r6                     
    mov64 r6, r0                                    r6 = r0
    add64 r6, 88                                    r6 += 88   ///  r6 = r6.wrapping_add(88 as i32 as i64 as u64)
    stxdw [r3+0x18], r6                     
    stxdw [r3+0x10], r1                     
    add64 r0, 72                                    r0 += 72   ///  r0 = r0.wrapping_add(72 as i32 as i64 as u64)
    stxdw [r3+0x8], r0                      
    stdw [r3+0x28], 0                       
    add64 r5, 16                                    r5 += 16   ///  r5 = r5.wrapping_add(16 as i32 as i64 as u64)
    add64 r4, 8                                     r4 += 8   ///  r4 = r4.wrapping_add(8 as i32 as i64 as u64)
    add64 r2, 56                                    r2 += 56   ///  r2 = r2.wrapping_add(56 as i32 as i64 as u64)
    jeq r2, 784, lbb_1845                           if r2 == (784 as i32 as i64 as u64) { pc += 66 }
lbb_1779:
    mov64 r6, r10                                   r6 = r10
    add64 r6, -824                                  r6 += -824   ///  r6 = r6.wrapping_add(-824 as i32 as i64 as u64)
    mov64 r9, 1                                     r9 = 1 as i32 as i64 as u64
    ldxdw r3, [r4+0x0]                      
    ldxdw r0, [r3+0x0]                      
    ldxdw r7, [r5-0x8]                      
    ldxdw r3, [r7+0x0]                      
    ldxdw r8, [r0+0x8]                      
    jne r8, r3, lbb_1864                            if r8 != r3 { pc += 76 }
    ldxdw r3, [r7+0x8]                      
    ldxdw r8, [r0+0x10]                     
    jne r8, r3, lbb_1864                            if r8 != r3 { pc += 73 }
    ldxdw r3, [r7+0x10]                     
    ldxdw r8, [r0+0x18]                     
    jne r8, r3, lbb_1864                            if r8 != r3 { pc += 70 }
    ldxdw r3, [r7+0x18]                     
    ldxdw r7, [r0+0x20]                     
    jne r7, r3, lbb_1864                            if r7 != r3 { pc += 67 }
    ldxb r3, [r5+0x0]                       
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    jne r3, 0, lbb_1801                             if r3 != (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r1, 119                                   r1 = 119 as i32 as i64 as u64
lbb_1801:
    ldxb r3, [r0+0x0]                       
    or64 r1, r3                                     r1 |= r3   ///  r1 = r1.or(r3)
    and64 r1, 255                                   r1 &= 255   ///  r1 = r1.and(255)
    jne r1, 255, lbb_1827                           if r1 != (255 as i32 as i64 as u64) { pc += 22 }
    add64 r6, r2                                    r6 += r2   ///  r6 = r6.wrapping_add(r2)
    mov64 r7, r0                                    r7 = r0
    add64 r7, 8                                     r7 += 8   ///  r7 = r7.wrapping_add(8 as i32 as i64 as u64)
    ldxdw r1, [r0+0x50]                     
    ldxb r8, [r0+0x3]                       
    ldxb r3, [r0+0x2]                       
    ldxb r9, [r0+0x1]                       
    stxdw [r6+0x0], r7                      
    mov64 r7, 1                                     r7 = 1 as i32 as i64 as u64
    mov64 r6, 1                                     r6 = 1 as i32 as i64 as u64
    jne r9, 0, lbb_1821                             if r9 != (0 as i32 as i64 as u64) { pc += 5 }
    mov64 r6, 0                                     r6 = 0 as i32 as i64 as u64
    mov64 r9, 1                                     r9 = 1 as i32 as i64 as u64
    jeq r3, 0, lbb_1823                             if r3 == (0 as i32 as i64 as u64) { pc += 4 }
lbb_1819:
    jne r8, 0, lbb_1759                             if r8 != (0 as i32 as i64 as u64) { pc += -61 }
    ja lbb_1825                                     if true { pc += 4 }
lbb_1821:
    mov64 r9, 1                                     r9 = 1 as i32 as i64 as u64
    jne r3, 0, lbb_1819                             if r3 != (0 as i32 as i64 as u64) { pc += -4 }
lbb_1823:
    mov64 r9, 0                                     r9 = 0 as i32 as i64 as u64
    jne r8, 0, lbb_1759                             if r8 != (0 as i32 as i64 as u64) { pc += -66 }
lbb_1825:
    mov64 r7, 0                                     r7 = 0 as i32 as i64 as u64
    ja lbb_1759                                     if true { pc += -68 }
lbb_1827:
    mov64 r9, 11                                    r9 = 11 as i32 as i64 as u64
    ja lbb_1864                                     if true { pc += 35 }
lbb_1829:
    mov64 r1, r10                                   r1 = r10
    add64 r1, -954                                  r1 += -954   ///  r1 = r1.wrapping_add(-954 as i32 as i64 as u64)
    stxdw [r10-0x10], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -1184                                 r1 += -1184   ///  r1 = r1.wrapping_add(-1184 as i32 as i64 as u64)
    stxdw [r10-0x20], r1                    
    ldxdw r1, [r10-0x4b0]                   
    stxdw [r10-0x28], r1                    
    stdw [r10-0x8], 18                      
    stdw [r10-0x18], 12                     
    mov64 r1, r10                                   r1 = r10
    add64 r1, -40                                   r1 += -40   ///  r1 = r1.wrapping_add(-40 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -824                                  r2 += -824   ///  r2 = r2.wrapping_add(-824 as i32 as i64 as u64)
    mov64 r3, 12                                    r3 = 12 as i32 as i64 as u64
    ja lbb_1860                                     if true { pc += 15 }
lbb_1845:
    mov64 r1, r10                                   r1 = r10
    add64 r1, -954                                  r1 += -954   ///  r1 = r1.wrapping_add(-954 as i32 as i64 as u64)
    stxdw [r10-0x10], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -1184                                 r1 += -1184   ///  r1 = r1.wrapping_add(-1184 as i32 as i64 as u64)
    stxdw [r10-0x20], r1                    
    ldxdw r1, [r10-0x4b0]                   
    stxdw [r10-0x28], r1                    
    stdw [r10-0x8], 18                      
    stdw [r10-0x18], 14                     
    mov64 r1, r10                                   r1 = r10
    add64 r1, -40                                   r1 += -40   ///  r1 = r1.wrapping_add(-40 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -824                                  r2 += -824   ///  r2 = r2.wrapping_add(-824 as i32 as i64 as u64)
    mov64 r3, 14                                    r3 = 14 as i32 as i64 as u64
lbb_1860:
    mov64 r4, 8                                     r4 = 8 as i32 as i64 as u64
    mov64 r5, 0                                     r5 = 0 as i32 as i64 as u64
    syscall [invalid]                       
    mov64 r9, 26                                    r9 = 26 as i32 as i64 as u64
lbb_1864:
    ldxdw r1, [r10-0x4a8]                   
lbb_1865:
    stxw [r1+0x0], r9                       
    stw [r1+0x4], 0                         
    exit                                    
lbb_1868:
    mov64 r1, r9                                    r1 = r9
    ja lbb_1504                                     if true { pc += -366 }
lbb_1870:
    mov64 r3, r6                                    r3 = r6
    mov64 r6, r4                                    r6 = r4
    ja lbb_1659                                     if true { pc += -214 }
lbb_1873:
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
    lddw r3, 0x100026110 --> b"\x00\x00\x00\x00\xb8Y\x02\x00\x10\x00\x00\x00\x00\x00\x00\x00V \x00\x00\x…        r3 load str located at 4295123216
    call function_18489                     
lbb_1878:
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
    lddw r3, 0x100026098 --> b"\x00\x00\x00\x00\xb8Y\x02\x00\x10\x00\x00\x00\x00\x00\x00\x00] \x00\x00\x…        r3 load str located at 4295123096
    call function_18489                     
lbb_1883:
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    mov64 r2, 1                                     r2 = 1 as i32 as i64 as u64
    lddw r3, 0x100026128 --> b"\x00\x00\x00\x00\xb8Y\x02\x00\x10\x00\x00\x00\x00\x00\x00\x00V \x00\x00%\…        r3 load str located at 4295123240
    call function_18489                     
lbb_1888:
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    mov64 r2, 1                                     r2 = 1 as i32 as i64 as u64
    lddw r3, 0x1000260b0 --> b"\x00\x00\x00\x00\xb8Y\x02\x00\x10\x00\x00\x00\x00\x00\x00\x00] \x00\x00%\…        r3 load str located at 4295123120
    call function_18489                     
lbb_1893:
    mov64 r1, 2                                     r1 = 2 as i32 as i64 as u64
    mov64 r2, 2                                     r2 = 2 as i32 as i64 as u64
    lddw r3, 0x100026140 --> b"\x00\x00\x00\x00\xb8Y\x02\x00\x10\x00\x00\x00\x00\x00\x00\x00V \x00\x00<\…        r3 load str located at 4295123264
    call function_18489                     
lbb_1898:
    mov64 r1, 2                                     r1 = 2 as i32 as i64 as u64
    mov64 r2, 2                                     r2 = 2 as i32 as i64 as u64
    lddw r3, 0x1000260c8 --> b"\x00\x00\x00\x00\xb8Y\x02\x00\x10\x00\x00\x00\x00\x00\x00\x00] \x00\x00<\…        r3 load str located at 4295123144
    call function_18489                     
lbb_1903:
    mov64 r1, 3                                     r1 = 3 as i32 as i64 as u64
    mov64 r2, 3                                     r2 = 3 as i32 as i64 as u64
    lddw r3, 0x100026158 --> b"\x00\x00\x00\x00\xb8Y\x02\x00\x10\x00\x00\x00\x00\x00\x00\x00V \x00\x00S\…        r3 load str located at 4295123288
    call function_18489                     
lbb_1908:
    mov64 r1, 3                                     r1 = 3 as i32 as i64 as u64
    mov64 r2, 3                                     r2 = 3 as i32 as i64 as u64
    lddw r3, 0x1000260e0 --> b"\x00\x00\x00\x00\xb8Y\x02\x00\x10\x00\x00\x00\x00\x00\x00\x00] \x00\x00S\…        r3 load str located at 4295123168
    call function_18489                     
lbb_1913:
    mov64 r1, 4                                     r1 = 4 as i32 as i64 as u64
    mov64 r2, 4                                     r2 = 4 as i32 as i64 as u64
    lddw r3, 0x100026170 --> b"\x00\x00\x00\x00\xb8Y\x02\x00\x10\x00\x00\x00\x00\x00\x00\x00W \x00\x00\x…        r3 load str located at 4295123312
    call function_18489                     
lbb_1918:
    mov64 r1, 4                                     r1 = 4 as i32 as i64 as u64
    mov64 r2, 4                                     r2 = 4 as i32 as i64 as u64
    lddw r3, 0x1000260f8 --> b"\x00\x00\x00\x00\xb8Y\x02\x00\x10\x00\x00\x00\x00\x00\x00\x00^ \x00\x00\x…        r3 load str located at 4295123192
    call function_18489                     
lbb_1923:
    mov64 r1, 5                                     r1 = 5 as i32 as i64 as u64
    mov64 r2, 5                                     r2 = 5 as i32 as i64 as u64
    lddw r3, 0x100026188 --> b"\x00\x00\x00\x00\xb8Y\x02\x00\x10\x00\x00\x00\x00\x00\x00\x00W \x00\x00%\…        r3 load str located at 4295123336
    call function_18489                     
    ldxdw r3, [r2+0x8]                      
    jeq r3, 1, lbb_2218                             if r3 == (1 as i32 as i64 as u64) { pc += 288 }
    jeq r3, 0, lbb_2223                             if r3 == (0 as i32 as i64 as u64) { pc += 292 }
    jle r3, 2, lbb_2228                             if r3 <= (2 as i32 as i64 as u64) { pc += 296 }
    jeq r3, 3, lbb_2233                             if r3 == (3 as i32 as i64 as u64) { pc += 300 }
    jle r3, 4, lbb_2238                             if r3 <= (4 as i32 as i64 as u64) { pc += 304 }
    jeq r3, 5, lbb_2243                             if r3 == (5 as i32 as i64 as u64) { pc += 308 }
    jle r3, 6, lbb_2248                             if r3 <= (6 as i32 as i64 as u64) { pc += 312 }
    jeq r3, 7, lbb_2253                             if r3 == (7 as i32 as i64 as u64) { pc += 316 }
    jle r3, 8, lbb_2258                             if r3 <= (8 as i32 as i64 as u64) { pc += 320 }
    jeq r3, 9, lbb_2263                             if r3 == (9 as i32 as i64 as u64) { pc += 324 }
    jle r3, 10, lbb_2268                            if r3 <= (10 as i32 as i64 as u64) { pc += 328 }
    ldxdw r7, [r2+0x50]                     
    ldxdw r0, [r7+0x0]                      
    ldxdw r3, [r0+0x50]                     
    jlt r3, 32, lbb_2216                            if r3 < (32 as i32 as i64 as u64) { pc += 272 }
    ldxdw r6, [r2+0x0]                      
    ldxdw r3, [r2+0x58]                     
    ldxdw r8, [r2+0x48]                     
    ldxdw r9, [r2+0x28]                     
    ldxdw r4, [r2+0x20]                     
    stxdw [r10-0x558], r4                   
    ldxdw r2, [r2+0x10]                     
    stxdw [r10-0x578], r2                   
    mov64 r2, r6                                    r2 = r6
    add64 r2, 80                                    r2 += 80   ///  r2 = r2.wrapping_add(80 as i32 as i64 as u64)
    stxdw [r10-0x568], r2                   
    mov64 r2, r6                                    r2 = r6
    add64 r2, 8                                     r2 += 8   ///  r2 = r2.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x548], r2                   
    mov64 r2, r6                                    r2 = r6
    add64 r2, 16                                    r2 += 16   ///  r2 = r2.wrapping_add(16 as i32 as i64 as u64)
    stxdw [r10-0x550], r2                   
    mov64 r2, r6                                    r2 = r6
    add64 r2, 24                                    r2 += 24   ///  r2 = r2.wrapping_add(24 as i32 as i64 as u64)
    stxdw [r10-0x560], r2                   
    mov64 r2, r6                                    r2 = r6
    add64 r2, 32                                    r2 += 32   ///  r2 = r2.wrapping_add(32 as i32 as i64 as u64)
    stxdw [r10-0x570], r2                   
    mov64 r2, r6                                    r2 = r6
    add64 r2, 40                                    r2 += 40   ///  r2 = r2.wrapping_add(40 as i32 as i64 as u64)
    stxdw [r10-0x580], r2                   
    mov64 r2, r6                                    r2 = r6
    add64 r2, 48                                    r2 += 48   ///  r2 = r2.wrapping_add(48 as i32 as i64 as u64)
    stxdw [r10-0x588], r2                   
    mov64 r2, r6                                    r2 = r6
    add64 r2, 56                                    r2 += 56   ///  r2 = r2.wrapping_add(56 as i32 as i64 as u64)
    stxdw [r10-0x590], r2                   
    mov64 r2, r6                                    r2 = r6
    add64 r2, 64                                    r2 += 64   ///  r2 = r2.wrapping_add(64 as i32 as i64 as u64)
    stxdw [r10-0x598], r2                   
    mov64 r2, r6                                    r2 = r6
    add64 r2, 72                                    r2 += 72   ///  r2 = r2.wrapping_add(72 as i32 as i64 as u64)
    stxdw [r10-0x5a0], r2                   
    ldxdw r2, [r6+0x8]                      
    mov64 r4, r2                                    r4 = r2
    add64 r4, 8                                     r4 += 8   ///  r4 = r4.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x5d0], r4                   
    ldxdw r4, [r4+0x0]                      
    ldxdw r5, [r0+0x58]                     
    stxdw [r10-0x540], r1                   
    jne r5, r4, lbb_2002                            if r5 != r4 { pc += 12 }
    ldxdw r4, [r2+0x10]                     
    ldxdw r5, [r0+0x60]                     
    jne r5, r4, lbb_2002                            if r5 != r4 { pc += 9 }
    ldxdw r4, [r2+0x18]                     
    ldxdw r5, [r0+0x68]                     
    jne r5, r4, lbb_2002                            if r5 != r4 { pc += 6 }
    ldxdw r2, [r2+0x20]                     
    ldxdw r4, [r0+0x70]                     
    jne r4, r2, lbb_2002                            if r4 != r2 { pc += 3 }
    mov64 r1, r7                                    r1 = r7
    mov64 r7, r3                                    r7 = r3
    ja lbb_2003                                     if true { pc += 1 }
lbb_2002:
    mov64 r1, r3                                    r1 = r3
lbb_2003:
    stxdw [r10-0x5c0], r1                   
    stxdw [r10-0x5b8], r7                   
    ldxdw r2, [r6+0x0]                      
    stxdw [r10-0x5c8], r2                   
    ldxdw r2, [r8+0x0]                      
    stxdw [r10-0x5d8], r2                   
    ldxdw r2, [r9+0x0]                      
    stxdw [r10-0x5e0], r2                   
    ldxdw r1, [r1+0x0]                      
    stxdw [r10-0x5e8], r1                   
    ldxdw r1, [r7+0x0]                      
    stxdw [r10-0x5f0], r1                   
    ldxdw r1, [r6+0x10]                     
    stxdw [r10-0x5f8], r1                   
    ldxdw r4, [r6+0x18]                     
    ldxdw r3, [r6+0x20]                     
    stxdw [r10-0x5a8], r8                   
    ldxdw r8, [r6+0x28]                     
    ldxdw r0, [r6+0x30]                     
    stxdw [r10-0x5b0], r9                   
    ldxdw r9, [r6+0x38]                     
    ldxdw r7, [r6+0x40]                     
    ldxdw r2, [r6+0x48]                     
    ldxdw r1, [r6+0x50]                     
    ldxdw r5, [r10-0x5d0]                   
    stxdw [r10-0x4f8], r5                   
    add64 r1, 8                                     r1 += 8   ///  r1 = r1.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x448], r1                   
    add64 r2, 8                                     r2 += 8   ///  r2 = r2.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x458], r2                   
    add64 r7, 8                                     r7 += 8   ///  r7 = r7.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x468], r7                   
    add64 r9, 8                                     r9 += 8   ///  r9 = r9.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x478], r9                   
    add64 r0, 8                                     r0 += 8   ///  r0 = r0.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x488], r0                   
    add64 r8, 8                                     r8 += 8   ///  r8 = r8.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x498], r8                   
    add64 r3, 8                                     r3 += 8   ///  r3 = r3.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x4a8], r3                   
    add64 r4, 8                                     r4 += 8   ///  r4 = r4.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x4b8], r4                   
    ldxdw r1, [r10-0x5f8]                   
    add64 r1, 8                                     r1 += 8   ///  r1 = r1.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x4c8], r1                   
    ldxdw r1, [r10-0x5f0]                   
    add64 r1, 8                                     r1 += 8   ///  r1 = r1.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x4d8], r1                   
    ldxdw r1, [r10-0x5e8]                   
    add64 r1, 8                                     r1 += 8   ///  r1 = r1.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x508], r1                   
    ldxdw r1, [r10-0x5e0]                   
    add64 r1, 8                                     r1 += 8   ///  r1 = r1.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x4e8], r1                   
    stxdw [r10-0x518], r1                   
    ldxdw r1, [r10-0x5d8]                   
    add64 r1, 8                                     r1 += 8   ///  r1 = r1.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x528], r1                   
    ldxdw r1, [r10-0x5c8]                   
    add64 r1, 8                                     r1 += 8   ///  r1 = r1.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x538], r1                   
    sth [r10-0x440], 1                      
    sth [r10-0x450], 1                      
    sth [r10-0x460], 1                      
    sth [r10-0x470], 1                      
    sth [r10-0x480], 0                      
    sth [r10-0x490], 0                      
    sth [r10-0x4a0], 1                      
    sth [r10-0x4b0], 0                      
    sth [r10-0x4c0], 0                      
    sth [r10-0x4d0], 1                      
    sth [r10-0x4e0], 0                      
    sth [r10-0x4f0], 0                      
    sth [r10-0x500], 1                      
    sth [r10-0x510], 0                      
    sth [r10-0x520], 257                    
    sth [r10-0x530], 0                      
    ldxdw r1, [r10-0x578]                   
    stxdw [r10-0x430], r1                   
    stb [r10-0x431], 1                      
    ldxdw r1, [r10-0x558]                   
    ldxdw r4, [r1+0x0]                      
    ldxdw r1, [r10-0x568]                   
    stxdw [r10-0x3b0], r1                   
    ldxdw r1, [r10-0x5a0]                   
    stxdw [r10-0x3b8], r1                   
    ldxdw r1, [r10-0x598]                   
    stxdw [r10-0x3c0], r1                   
    ldxdw r1, [r10-0x590]                   
    stxdw [r10-0x3c8], r1                   
    ldxdw r1, [r10-0x588]                   
    stxdw [r10-0x3d0], r1                   
    ldxdw r1, [r10-0x580]                   
    stxdw [r10-0x3d8], r1                   
    ldxdw r1, [r10-0x570]                   
    stxdw [r10-0x3e0], r1                   
    ldxdw r1, [r10-0x560]                   
    stxdw [r10-0x3e8], r1                   
    ldxdw r1, [r10-0x550]                   
    stxdw [r10-0x3f0], r1                   
    ldxdw r1, [r10-0x5b8]                   
    stxdw [r10-0x3f8], r1                   
    ldxdw r1, [r10-0x548]                   
    stxdw [r10-0x408], r1                   
    ldxdw r1, [r10-0x5c0]                   
    stxdw [r10-0x410], r1                   
    ldxdw r1, [r10-0x5b0]                   
    stxdw [r10-0x400], r1                   
    stxdw [r10-0x418], r1                   
    ldxdw r1, [r10-0x5a8]                   
    stxdw [r10-0x420], r1                   
    stxdw [r10-0x428], r6                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -1064                                 r1 += -1064   ///  r1 = r1.wrapping_add(-1064 as i32 as i64 as u64)
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
    mov64 r3, r10                                   r3 = r10
    add64 r3, -1328                                 r3 += -1328   ///  r3 = r3.wrapping_add(-1328 as i32 as i64 as u64)
    add64 r4, 8                                     r4 += 8   ///  r4 = r4.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x548], r4                   
    ja lbb_2143                                     if true { pc += 20 }
lbb_2123:
    mov64 r7, r10                                   r7 = r10
    add64 r7, -936                                  r7 += -936   ///  r7 = r7.wrapping_add(-936 as i32 as i64 as u64)
    add64 r7, r2                                    r7 += r2   ///  r7 = r7.wrapping_add(r2)
    stxb [r7+0x32], r6                      
    stxb [r7+0x31], r8                      
    stxb [r7+0x30], r5                      
    mov64 r5, r4                                    r5 = r4
    add64 r5, 40                                    r5 += 40   ///  r5 = r5.wrapping_add(40 as i32 as i64 as u64)
    stxdw [r7+0x20], r5                     
    mov64 r5, r4                                    r5 = r4
    add64 r5, 88                                    r5 += 88   ///  r5 = r5.wrapping_add(88 as i32 as i64 as u64)
    stxdw [r7+0x18], r5                     
    stxdw [r7+0x10], r0                     
    add64 r4, 72                                    r4 += 72   ///  r4 = r4.wrapping_add(72 as i32 as i64 as u64)
    stxdw [r7+0x8], r4                      
    stdw [r7+0x28], 0                       
    add64 r3, 16                                    r3 += 16   ///  r3 = r3.wrapping_add(16 as i32 as i64 as u64)
    add64 r1, 8                                     r1 += 8   ///  r1 = r1.wrapping_add(8 as i32 as i64 as u64)
    add64 r2, 56                                    r2 += 56   ///  r2 = r2.wrapping_add(56 as i32 as i64 as u64)
    jeq r2, 896, lbb_2193                           if r2 == (896 as i32 as i64 as u64) { pc += 50 }
lbb_2143:
    mov64 r5, r10                                   r5 = r10
    add64 r5, -936                                  r5 += -936   ///  r5 = r5.wrapping_add(-936 as i32 as i64 as u64)
    mov64 r0, 1                                     r0 = 1 as i32 as i64 as u64
    ldxdw r4, [r1+0x0]                      
    ldxdw r4, [r4+0x0]                      
    ldxdw r6, [r3-0x8]                      
    ldxdw r7, [r6+0x0]                      
    ldxdw r8, [r4+0x8]                      
    jne r8, r7, lbb_2212                            if r8 != r7 { pc += 60 }
    ldxdw r7, [r6+0x8]                      
    ldxdw r8, [r4+0x10]                     
    jne r8, r7, lbb_2212                            if r8 != r7 { pc += 57 }
    ldxdw r7, [r6+0x10]                     
    ldxdw r8, [r4+0x18]                     
    jne r8, r7, lbb_2212                            if r8 != r7 { pc += 54 }
    ldxdw r6, [r6+0x18]                     
    ldxdw r7, [r4+0x20]                     
    jne r7, r6, lbb_2212                            if r7 != r6 { pc += 51 }
    ldxb r6, [r3+0x0]                       
    mov64 r0, 0                                     r0 = 0 as i32 as i64 as u64
    jne r6, 0, lbb_2165                             if r6 != (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r0, 119                                   r0 = 119 as i32 as i64 as u64
lbb_2165:
    ldxb r6, [r4+0x0]                       
    or64 r0, r6                                     r0 |= r6   ///  r0 = r0.or(r6)
    and64 r0, 255                                   r0 &= 255   ///  r0 = r0.and(255)
    jne r0, 255, lbb_2191                           if r0 != (255 as i32 as i64 as u64) { pc += 22 }
    add64 r5, r2                                    r5 += r2   ///  r5 = r5.wrapping_add(r2)
    mov64 r6, r4                                    r6 = r4
    add64 r6, 8                                     r6 += 8   ///  r6 = r6.wrapping_add(8 as i32 as i64 as u64)
    ldxdw r0, [r4+0x50]                     
    ldxb r7, [r4+0x3]                       
    ldxb r9, [r4+0x2]                       
    ldxb r8, [r4+0x1]                       
    stxdw [r5+0x0], r6                      
    mov64 r6, 1                                     r6 = 1 as i32 as i64 as u64
    mov64 r5, 1                                     r5 = 1 as i32 as i64 as u64
    jeq r8, 0, lbb_2184                             if r8 == (0 as i32 as i64 as u64) { pc += 4 }
    mov64 r8, 1                                     r8 = 1 as i32 as i64 as u64
    jeq r9, 0, lbb_2187                             if r9 == (0 as i32 as i64 as u64) { pc += 5 }
lbb_2182:
    jne r7, 0, lbb_2123                             if r7 != (0 as i32 as i64 as u64) { pc += -60 }
    ja lbb_2189                                     if true { pc += 5 }
lbb_2184:
    mov64 r5, 0                                     r5 = 0 as i32 as i64 as u64
    mov64 r8, 1                                     r8 = 1 as i32 as i64 as u64
    jne r9, 0, lbb_2182                             if r9 != (0 as i32 as i64 as u64) { pc += -5 }
lbb_2187:
    mov64 r8, 0                                     r8 = 0 as i32 as i64 as u64
    jne r7, 0, lbb_2123                             if r7 != (0 as i32 as i64 as u64) { pc += -66 }
lbb_2189:
    mov64 r6, 0                                     r6 = 0 as i32 as i64 as u64
    ja lbb_2123                                     if true { pc += -68 }
lbb_2191:
    mov64 r0, 11                                    r0 = 11 as i32 as i64 as u64
    ja lbb_2212                                     if true { pc += 19 }
lbb_2193:
    mov64 r1, r10                                   r1 = r10
    add64 r1, -1073                                 r1 += -1073   ///  r1 = r1.wrapping_add(-1073 as i32 as i64 as u64)
    stxdw [r10-0x10], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -1336                                 r1 += -1336   ///  r1 = r1.wrapping_add(-1336 as i32 as i64 as u64)
    stxdw [r10-0x20], r1                    
    ldxdw r1, [r10-0x548]                   
    stxdw [r10-0x28], r1                    
    stdw [r10-0x8], 9                       
    stdw [r10-0x18], 16                     
    mov64 r1, r10                                   r1 = r10
    add64 r1, -40                                   r1 += -40   ///  r1 = r1.wrapping_add(-40 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -936                                  r2 += -936   ///  r2 = r2.wrapping_add(-936 as i32 as i64 as u64)
    mov64 r3, 16                                    r3 = 16 as i32 as i64 as u64
    mov64 r4, 8                                     r4 = 8 as i32 as i64 as u64
    mov64 r5, 0                                     r5 = 0 as i32 as i64 as u64
    syscall [invalid]                       
    mov64 r0, 26                                    r0 = 26 as i32 as i64 as u64
lbb_2212:
    ldxdw r1, [r10-0x540]                   
lbb_2213:
    stxw [r1+0x0], r0                       
    stw [r1+0x4], 0                         
    exit                                    
lbb_2216:
    mov64 r0, 3                                     r0 = 3 as i32 as i64 as u64
    ja lbb_2213                                     if true { pc += -5 }
lbb_2218:
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    mov64 r2, 1                                     r2 = 1 as i32 as i64 as u64
    lddw r3, 0x1000261b8 --> b"\x00\x00\x00\x00\xb8Y\x02\x00\x10\x00\x00\x00\x00\x00\x00\x00k \x00\x00!\…        r3 load str located at 4295123384
    call function_18489                     
lbb_2223:
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
    lddw r3, 0x1000261a0 --> b"\x00\x00\x00\x00\xb8Y\x02\x00\x10\x00\x00\x00\x00\x00\x00\x00k \x00\x00\x…        r3 load str located at 4295123360
    call function_18489                     
lbb_2228:
    mov64 r1, 2                                     r1 = 2 as i32 as i64 as u64
    mov64 r2, 2                                     r2 = 2 as i32 as i64 as u64
    lddw r3, 0x1000261d0 --> b"\x00\x00\x00\x00\xb8Y\x02\x00\x10\x00\x00\x00\x00\x00\x00\x00k \x00\x008\…        r3 load str located at 4295123408
    call function_18489                     
lbb_2233:
    mov64 r1, 3                                     r1 = 3 as i32 as i64 as u64
    mov64 r2, 3                                     r2 = 3 as i32 as i64 as u64
    lddw r3, 0x1000261e8 --> b"\x00\x00\x00\x00\xb8Y\x02\x00\x10\x00\x00\x00\x00\x00\x00\x00k \x00\x00O\…        r3 load str located at 4295123432
    call function_18489                     
lbb_2238:
    mov64 r1, 4                                     r1 = 4 as i32 as i64 as u64
    mov64 r2, 4                                     r2 = 4 as i32 as i64 as u64
    lddw r3, 0x100026200 --> b"\x00\x00\x00\x00\xb8Y\x02\x00\x10\x00\x00\x00\x00\x00\x00\x00l \x00\x00\x…        r3 load str located at 4295123456
    call function_18489                     
lbb_2243:
    mov64 r1, 5                                     r1 = 5 as i32 as i64 as u64
    mov64 r2, 5                                     r2 = 5 as i32 as i64 as u64
    lddw r3, 0x100026218 --> b"\x00\x00\x00\x00\xb8Y\x02\x00\x10\x00\x00\x00\x00\x00\x00\x00l \x00\x00!\…        r3 load str located at 4295123480
    call function_18489                     
lbb_2248:
    mov64 r1, 6                                     r1 = 6 as i32 as i64 as u64
    mov64 r2, 6                                     r2 = 6 as i32 as i64 as u64
    lddw r3, 0x100026230 --> b"\x00\x00\x00\x00\xb8Y\x02\x00\x10\x00\x00\x00\x00\x00\x00\x00l \x00\x008\…        r3 load str located at 4295123504
    call function_18489                     
lbb_2253:
    mov64 r1, 7                                     r1 = 7 as i32 as i64 as u64
    mov64 r2, 7                                     r2 = 7 as i32 as i64 as u64
    lddw r3, 0x100026248 --> b"\x00\x00\x00\x00\xb8Y\x02\x00\x10\x00\x00\x00\x00\x00\x00\x00l \x00\x00O\…        r3 load str located at 4295123528
    call function_18489                     
lbb_2258:
    mov64 r1, 8                                     r1 = 8 as i32 as i64 as u64
    mov64 r2, 8                                     r2 = 8 as i32 as i64 as u64
    lddw r3, 0x100026260 --> b"\x00\x00\x00\x00\xb8Y\x02\x00\x10\x00\x00\x00\x00\x00\x00\x00m \x00\x00\x…        r3 load str located at 4295123552
    call function_18489                     
lbb_2263:
    mov64 r1, 9                                     r1 = 9 as i32 as i64 as u64
    mov64 r2, 9                                     r2 = 9 as i32 as i64 as u64
    lddw r3, 0x100026278 --> b"\x00\x00\x00\x00\xb8Y\x02\x00\x10\x00\x00\x00\x00\x00\x00\x00m \x00\x00!\…        r3 load str located at 4295123576
    call function_18489                     
lbb_2268:
    mov64 r1, 10                                    r1 = 10 as i32 as i64 as u64
    mov64 r2, 10                                    r2 = 10 as i32 as i64 as u64
    lddw r3, 0x100026290 --> b"\x00\x00\x00\x00\xb8Y\x02\x00\x10\x00\x00\x00\x00\x00\x00\x00m \x00\x008\…        r3 load str located at 4295123600
    call function_18489                     
    ldxdw r3, [r2+0x8]                      
    jeq r3, 1, lbb_2586                             if r3 == (1 as i32 as i64 as u64) { pc += 311 }
    jeq r3, 0, lbb_2591                             if r3 == (0 as i32 as i64 as u64) { pc += 315 }
    jle r3, 2, lbb_2596                             if r3 <= (2 as i32 as i64 as u64) { pc += 319 }
    jeq r3, 3, lbb_2601                             if r3 == (3 as i32 as i64 as u64) { pc += 323 }
    jle r3, 4, lbb_2606                             if r3 <= (4 as i32 as i64 as u64) { pc += 327 }
    jeq r3, 5, lbb_2611                             if r3 == (5 as i32 as i64 as u64) { pc += 331 }
    jle r3, 6, lbb_2616                             if r3 <= (6 as i32 as i64 as u64) { pc += 335 }
    jeq r3, 7, lbb_2621                             if r3 == (7 as i32 as i64 as u64) { pc += 339 }
    ldxdw r3, [r2+0x50]                     
    stxdw [r10-0x458], r3                   
    ldxdw r5, [r3+0x0]                      
    ldxdw r3, [r5+0x50]                     
    jlt r3, 32, lbb_2584                            if r3 < (32 as i32 as i64 as u64) { pc += 297 }
    ldxdw r7, [r2+0x0]                      
    ldxdw r4, [r2+0x58]                     
    ldxdw r3, [r7+0x28]                     
    mov64 r0, r3                                    r0 = r3
    add64 r0, 8                                     r0 += 8   ///  r0 = r0.wrapping_add(8 as i32 as i64 as u64)
    mov64 r9, 0                                     r9 = 0 as i32 as i64 as u64
    stxdw [r10-0x488], r0                   
    ldxdw r0, [r0+0x0]                      
    ldxdw r6, [r5+0x58]                     
    jne r6, r0, lbb_2313                            if r6 != r0 { pc += 16 }
    ldxdw r0, [r3+0x10]                     
    ldxdw r6, [r5+0x60]                     
    jne r6, r0, lbb_2313                            if r6 != r0 { pc += 13 }
    ldxdw r0, [r3+0x18]                     
    ldxdw r6, [r5+0x68]                     
    jne r6, r0, lbb_2313                            if r6 != r0 { pc += 10 }
    ldxdw r0, [r3+0x20]                     
    ldxdw r5, [r5+0x70]                     
    mov64 r9, 1                                     r9 = 1 as i32 as i64 as u64
    jeq r5, r0, lbb_2308                            if r5 == r0 { pc += 1 }
    mov64 r9, 0                                     r9 = 0 as i32 as i64 as u64
lbb_2308:
    jne r5, r0, lbb_2313                            if r5 != r0 { pc += 4 }
    ldxdw r5, [r10-0x458]                   
    stxdw [r10-0x468], r5                   
    stxdw [r10-0x458], r4                   
    ja lbb_2314                                     if true { pc += 1 }
lbb_2313:
    stxdw [r10-0x468], r4                   
lbb_2314:
    ldxdw r4, [r2+0x30]                     
    stxdw [r10-0x4d0], r4                   
    ldxdw r6, [r2+0x28]                     
    mov64 r0, r7                                    r0 = r7
    add64 r0, 48                                    r0 += 48   ///  r0 = r0.wrapping_add(48 as i32 as i64 as u64)
    ldxdw r4, [r3+0x28]                     
    lddw r5, 0xde8f75eee1f6dd06                     r5 load str located at -2409577606766207738
    mov64 r8, r6                                    r8 = r6
    jne r4, r5, lbb_2340                            if r4 != r5 { pc += 16 }
    ldxdw r4, [r3+0x30]                     
    lddw r5, 0xdacd6ce4bc5d4218                     r5 load str located at -2680366473547005416
    mov64 r8, r6                                    r8 = r6
    jne r4, r5, lbb_2340                            if r4 != r5 { pc += 11 }
    ldxdw r4, [r3+0x38]                     
    lddw r5, 0x270db9834dfc1ab6                     r5 load str located at 2814109315776649910
    mov64 r8, r6                                    r8 = r6
    jne r4, r5, lbb_2340                            if r4 != r5 { pc += 6 }
    ldxdw r3, [r3+0x40]                     
    lddw r4, 0xfc8ba1d828f9bdfe                     r4 load str located at -248927404616466946
    mov64 r8, r6                                    r8 = r6
    jne r3, r4, lbb_2340                            if r3 != r4 { pc += 1 }
    ldxdw r8, [r10-0x4d0]                   
lbb_2340:
    stxdw [r10-0x460], r6                   
    ldxdw r4, [r2+0x48]                     
    ldxdw r3, [r2+0x20]                     
    stxdw [r10-0x4a8], r3                   
    ldxdw r2, [r2+0x10]                     
    stxdw [r10-0x4c0], r2                   
    mov64 r2, r7                                    r2 = r7
    add64 r2, 56                                    r2 += 56   ///  r2 = r2.wrapping_add(56 as i32 as i64 as u64)
    stxdw [r10-0x4b0], r2                   
    mov64 r5, r7                                    r5 = r7
    add64 r5, 8                                     r5 += 8   ///  r5 = r5.wrapping_add(8 as i32 as i64 as u64)
    mov64 r2, r7                                    r2 = r7
    add64 r2, 16                                    r2 += 16   ///  r2 = r2.wrapping_add(16 as i32 as i64 as u64)
    stxdw [r10-0x498], r2                   
    mov64 r2, r7                                    r2 = r7
    add64 r2, 24                                    r2 += 24   ///  r2 = r2.wrapping_add(24 as i32 as i64 as u64)
    stxdw [r10-0x4a0], r2                   
    mov64 r2, r7                                    r2 = r7
    add64 r2, 32                                    r2 += 32   ///  r2 = r2.wrapping_add(32 as i32 as i64 as u64)
    stxdw [r10-0x4b8], r2                   
    mov64 r2, r7                                    r2 = r7
    add64 r2, 40                                    r2 += 40   ///  r2 = r2.wrapping_add(40 as i32 as i64 as u64)
    stxdw [r10-0x4c8], r2                   
    xor64 r9, 1                                     r9 ^= 1   ///  r9 = r9.xor(1)
    ldxdw r6, [r0+0x0]                      
    ldxdw r2, [r6+0x28]                     
    lddw r3, 0xde8f75eee1f6dd06                     r3 load str located at -2409577606766207738
    stxdw [r10-0x470], r1                   
    stxdw [r10-0x478], r9                   
    stxdw [r10-0x480], r0                   
    stxdw [r10-0x490], r5                   
    jne r2, r3, lbb_2387                            if r2 != r3 { pc += 14 }
    ldxdw r2, [r6+0x30]                     
    lddw r3, 0xdacd6ce4bc5d4218                     r3 load str located at -2680366473547005416
    jne r2, r3, lbb_2387                            if r2 != r3 { pc += 10 }
    ldxdw r2, [r6+0x38]                     
    lddw r3, 0x270db9834dfc1ab6                     r3 load str located at 2814109315776649910
    jne r2, r3, lbb_2387                            if r2 != r3 { pc += 6 }
    ldxdw r2, [r6+0x40]                     
    lddw r3, 0xfc8ba1d828f9bdfe                     r3 load str located at -248927404616466946
    jne r2, r3, lbb_2387                            if r2 != r3 { pc += 2 }
    ldxdw r1, [r10-0x4d0]                   
    stxdw [r10-0x460], r1                   
lbb_2387:
    add64 r6, 8                                     r6 += 8   ///  r6 = r6.wrapping_add(8 as i32 as i64 as u64)
    ldxdw r1, [r4+0x0]                      
    stxdw [r10-0x4e0], r1                   
    ldxdw r1, [r7+0x0]                      
    stxdw [r10-0x4e8], r1                   
    ldxdw r1, [r7+0x8]                      
    stxdw [r10-0x4f0], r1                   
    ldxdw r0, [r7+0x10]                     
    ldxdw r3, [r7+0x18]                     
    mov64 r2, r7                                    r2 = r7
    ldxdw r7, [r2+0x20]                     
    ldxdw r1, [r10-0x468]                   
    ldxdw r9, [r1+0x0]                      
    stxdw [r10-0x4d0], r4                   
    ldxdw r1, [r10-0x458]                   
    ldxdw r5, [r1+0x0]                      
    stxdw [r10-0x4d8], r8                   
    ldxdw r1, [r8+0x0]                      
    ldxdw r4, [r10-0x460]                   
    ldxdw r8, [r4+0x0]                      
    ldxdw r4, [r2+0x38]                     
    stxdw [r10-0x3c0], r6                   
    ldxdw r6, [r10-0x488]                   
    stxdw [r10-0x3d0], r6                   
    add64 r4, 8                                     r4 += 8   ///  r4 = r4.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x390], r4                   
    add64 r8, 8                                     r8 += 8   ///  r8 = r8.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x3a0], r8                   
    add64 r1, 8                                     r1 += 8   ///  r1 = r1.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x3b0], r1                   
    add64 r5, 8                                     r5 += 8   ///  r5 = r5.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x3e0], r5                   
    add64 r9, 8                                     r9 += 8   ///  r9 = r9.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x3f0], r9                   
    add64 r7, 8                                     r7 += 8   ///  r7 = r7.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x400], r7                   
    add64 r3, 8                                     r3 += 8   ///  r3 = r3.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x410], r3                   
    add64 r0, 8                                     r0 += 8   ///  r0 = r0.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x420], r0                   
    ldxdw r1, [r10-0x4f0]                   
    add64 r1, 8                                     r1 += 8   ///  r1 = r1.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x430], r1                   
    ldxdw r1, [r10-0x4e8]                   
    add64 r1, 8                                     r1 += 8   ///  r1 = r1.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x440], r1                   
    ldxdw r1, [r10-0x4e0]                   
    add64 r1, 8                                     r1 += 8   ///  r1 = r1.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x450], r1                   
    sth [r10-0x388], 0                      
    sth [r10-0x398], 0                      
    sth [r10-0x3a8], 0                      
    sth [r10-0x3b8], 0                      
    sth [r10-0x3c8], 0                      
    sth [r10-0x3d8], 1                      
    sth [r10-0x3e8], 1                      
    sth [r10-0x3f8], 1                      
    sth [r10-0x408], 1                      
    sth [r10-0x418], 0                      
    sth [r10-0x428], 0                      
    sth [r10-0x438], 1                      
    sth [r10-0x448], 257                    
    ldxdw r1, [r10-0x478]                   
    and64 r1, 1                                     r1 &= 1   ///  r1 = r1.and(1)
    stxb [r10-0x369], r1                    
    ldxdw r1, [r10-0x4c0]                   
    stxdw [r10-0x379], r1                   
    stb [r10-0x37a], 7                      
    stdw [r10-0x371], 0                     
    ldxdw r1, [r10-0x4a8]                   
    ldxdw r4, [r1+0x0]                      
    ldxdw r1, [r10-0x4b0]                   
    stxdw [r10-0x308], r1                   
    ldxdw r1, [r10-0x460]                   
    stxdw [r10-0x310], r1                   
    ldxdw r1, [r10-0x4d8]                   
    stxdw [r10-0x318], r1                   
    ldxdw r1, [r10-0x480]                   
    stxdw [r10-0x320], r1                   
    ldxdw r1, [r10-0x4c8]                   
    stxdw [r10-0x328], r1                   
    ldxdw r1, [r10-0x458]                   
    stxdw [r10-0x330], r1                   
    ldxdw r1, [r10-0x468]                   
    stxdw [r10-0x338], r1                   
    ldxdw r1, [r10-0x4b8]                   
    stxdw [r10-0x340], r1                   
    ldxdw r1, [r10-0x4a0]                   
    stxdw [r10-0x348], r1                   
    ldxdw r1, [r10-0x498]                   
    stxdw [r10-0x350], r1                   
    ldxdw r1, [r10-0x490]                   
    stxdw [r10-0x358], r1                   
    stxdw [r10-0x360], r2                   
    ldxdw r1, [r10-0x4d0]                   
    stxdw [r10-0x368], r1                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -872                                  r1 += -872   ///  r1 = r1.wrapping_add(-872 as i32 as i64 as u64)
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
    mov64 r3, r10                                   r3 = r10
    add64 r3, -1096                                 r3 += -1096   ///  r3 = r3.wrapping_add(-1096 as i32 as i64 as u64)
    add64 r4, 8                                     r4 += 8   ///  r4 = r4.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x458], r4                   
    ja lbb_2511                                     if true { pc += 20 }
lbb_2491:
    mov64 r4, r10                                   r4 = r10
    add64 r4, -768                                  r4 += -768   ///  r4 = r4.wrapping_add(-768 as i32 as i64 as u64)
    add64 r4, r2                                    r4 += r2   ///  r4 = r4.wrapping_add(r2)
    stxb [r4+0x32], r7                      
    stxb [r4+0x31], r9                      
    stxb [r4+0x30], r0                      
    mov64 r0, r5                                    r0 = r5
    add64 r0, 40                                    r0 += 40   ///  r0 = r0.wrapping_add(40 as i32 as i64 as u64)
    stxdw [r4+0x20], r0                     
    mov64 r0, r5                                    r0 = r5
    add64 r0, 88                                    r0 += 88   ///  r0 = r0.wrapping_add(88 as i32 as i64 as u64)
    stxdw [r4+0x18], r0                     
    stxdw [r4+0x10], r6                     
    add64 r5, 72                                    r5 += 72   ///  r5 = r5.wrapping_add(72 as i32 as i64 as u64)
    stxdw [r4+0x8], r5                      
    stdw [r4+0x28], 0                       
    add64 r3, 16                                    r3 += 16   ///  r3 = r3.wrapping_add(16 as i32 as i64 as u64)
    add64 r1, 8                                     r1 += 8   ///  r1 = r1.wrapping_add(8 as i32 as i64 as u64)
    add64 r2, 56                                    r2 += 56   ///  r2 = r2.wrapping_add(56 as i32 as i64 as u64)
    jeq r2, 728, lbb_2561                           if r2 == (728 as i32 as i64 as u64) { pc += 50 }
lbb_2511:
    mov64 r0, r10                                   r0 = r10
    add64 r0, -768                                  r0 += -768   ///  r0 = r0.wrapping_add(-768 as i32 as i64 as u64)
    mov64 r6, 1                                     r6 = 1 as i32 as i64 as u64
    ldxdw r4, [r1+0x0]                      
    ldxdw r5, [r4+0x0]                      
    ldxdw r7, [r3-0x8]                      
    ldxdw r4, [r7+0x0]                      
    ldxdw r8, [r5+0x8]                      
    jne r8, r4, lbb_2580                            if r8 != r4 { pc += 60 }
    ldxdw r4, [r7+0x8]                      
    ldxdw r8, [r5+0x10]                     
    jne r8, r4, lbb_2580                            if r8 != r4 { pc += 57 }
    ldxdw r4, [r7+0x10]                     
    ldxdw r8, [r5+0x18]                     
    jne r8, r4, lbb_2580                            if r8 != r4 { pc += 54 }
    ldxdw r4, [r7+0x18]                     
    ldxdw r7, [r5+0x20]                     
    jne r7, r4, lbb_2580                            if r7 != r4 { pc += 51 }
    ldxb r6, [r3+0x0]                       
    mov64 r4, 0                                     r4 = 0 as i32 as i64 as u64
    jne r6, 0, lbb_2533                             if r6 != (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r4, 119                                   r4 = 119 as i32 as i64 as u64
lbb_2533:
    ldxb r6, [r5+0x0]                       
    or64 r4, r6                                     r4 |= r6   ///  r4 = r4.or(r6)
    and64 r4, 255                                   r4 &= 255   ///  r4 = r4.and(255)
    jne r4, 255, lbb_2559                           if r4 != (255 as i32 as i64 as u64) { pc += 22 }
    add64 r0, r2                                    r0 += r2   ///  r0 = r0.wrapping_add(r2)
    mov64 r7, r5                                    r7 = r5
    add64 r7, 8                                     r7 += 8   ///  r7 = r7.wrapping_add(8 as i32 as i64 as u64)
    ldxdw r6, [r5+0x50]                     
    ldxb r8, [r5+0x3]                       
    ldxb r4, [r5+0x2]                       
    ldxb r9, [r5+0x1]                       
    stxdw [r0+0x0], r7                      
    mov64 r7, 1                                     r7 = 1 as i32 as i64 as u64
    mov64 r0, 1                                     r0 = 1 as i32 as i64 as u64
    jeq r9, 0, lbb_2552                             if r9 == (0 as i32 as i64 as u64) { pc += 4 }
    mov64 r9, 1                                     r9 = 1 as i32 as i64 as u64
    jeq r4, 0, lbb_2555                             if r4 == (0 as i32 as i64 as u64) { pc += 5 }
lbb_2550:
    jne r8, 0, lbb_2491                             if r8 != (0 as i32 as i64 as u64) { pc += -60 }
    ja lbb_2557                                     if true { pc += 5 }
lbb_2552:
    mov64 r0, 0                                     r0 = 0 as i32 as i64 as u64
    mov64 r9, 1                                     r9 = 1 as i32 as i64 as u64
    jne r4, 0, lbb_2550                             if r4 != (0 as i32 as i64 as u64) { pc += -5 }
lbb_2555:
    mov64 r9, 0                                     r9 = 0 as i32 as i64 as u64
    jne r8, 0, lbb_2491                             if r8 != (0 as i32 as i64 as u64) { pc += -66 }
lbb_2557:
    mov64 r7, 0                                     r7 = 0 as i32 as i64 as u64
    ja lbb_2491                                     if true { pc += -68 }
lbb_2559:
    mov64 r6, 11                                    r6 = 11 as i32 as i64 as u64
    ja lbb_2580                                     if true { pc += 19 }
lbb_2561:
    mov64 r1, r10                                   r1 = r10
    add64 r1, -890                                  r1 += -890   ///  r1 = r1.wrapping_add(-890 as i32 as i64 as u64)
    stxdw [r10-0x10], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -1104                                 r1 += -1104   ///  r1 = r1.wrapping_add(-1104 as i32 as i64 as u64)
    stxdw [r10-0x20], r1                    
    ldxdw r1, [r10-0x458]                   
    stxdw [r10-0x28], r1                    
    stdw [r10-0x8], 18                      
    stdw [r10-0x18], 13                     
    mov64 r1, r10                                   r1 = r10
    add64 r1, -40                                   r1 += -40   ///  r1 = r1.wrapping_add(-40 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -768                                  r2 += -768   ///  r2 = r2.wrapping_add(-768 as i32 as i64 as u64)
    mov64 r3, 13                                    r3 = 13 as i32 as i64 as u64
    mov64 r4, 8                                     r4 = 8 as i32 as i64 as u64
    mov64 r5, 0                                     r5 = 0 as i32 as i64 as u64
    syscall [invalid]                       
    mov64 r6, 26                                    r6 = 26 as i32 as i64 as u64
lbb_2580:
    ldxdw r1, [r10-0x470]                   
lbb_2581:
    stxw [r1+0x0], r6                       
    stw [r1+0x4], 0                         
    exit                                    
lbb_2584:
    mov64 r6, 3                                     r6 = 3 as i32 as i64 as u64
    ja lbb_2581                                     if true { pc += -5 }
lbb_2586:
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    mov64 r2, 1                                     r2 = 1 as i32 as i64 as u64
    lddw r3, 0x1000262c0 --> b"\x00\x00\x00\x00\xb8Y\x02\x00\x10\x00\x00\x00\x00\x00\x00\x00y \x00\x00!\…        r3 load str located at 4295123648
    call function_18489                     
lbb_2591:
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
    lddw r3, 0x1000262a8 --> b"\x00\x00\x00\x00\xb8Y\x02\x00\x10\x00\x00\x00\x00\x00\x00\x00y \x00\x00\x…        r3 load str located at 4295123624
    call function_18489                     
lbb_2596:
    mov64 r1, 2                                     r1 = 2 as i32 as i64 as u64
    mov64 r2, 2                                     r2 = 2 as i32 as i64 as u64
    lddw r3, 0x1000262d8 --> b"\x00\x00\x00\x00\xb8Y\x02\x00\x10\x00\x00\x00\x00\x00\x00\x00y \x00\x008\…        r3 load str located at 4295123672
    call function_18489                     
lbb_2601:
    mov64 r1, 3                                     r1 = 3 as i32 as i64 as u64
    mov64 r2, 3                                     r2 = 3 as i32 as i64 as u64
    lddw r3, 0x1000262f0 --> b"\x00\x00\x00\x00\xb8Y\x02\x00\x10\x00\x00\x00\x00\x00\x00\x00y \x00\x00O\…        r3 load str located at 4295123696
    call function_18489                     
lbb_2606:
    mov64 r1, 4                                     r1 = 4 as i32 as i64 as u64
    mov64 r2, 4                                     r2 = 4 as i32 as i64 as u64
    lddw r3, 0x100026308 --> b"\x00\x00\x00\x00\xb8Y\x02\x00\x10\x00\x00\x00\x00\x00\x00\x00z \x00\x00\x…        r3 load str located at 4295123720
    call function_18489                     
lbb_2611:
    mov64 r1, 5                                     r1 = 5 as i32 as i64 as u64
    mov64 r2, 5                                     r2 = 5 as i32 as i64 as u64
    lddw r3, 0x100026320 --> b"\x00\x00\x00\x00\xb8Y\x02\x00\x10\x00\x00\x00\x00\x00\x00\x00z \x00\x00!\…        r3 load str located at 4295123744
    call function_18489                     
lbb_2616:
    mov64 r1, 6                                     r1 = 6 as i32 as i64 as u64
    mov64 r2, 6                                     r2 = 6 as i32 as i64 as u64
    lddw r3, 0x100026338 --> b"\x00\x00\x00\x00\xb8Y\x02\x00\x10\x00\x00\x00\x00\x00\x00\x00z \x00\x008\…        r3 load str located at 4295123768
    call function_18489                     
lbb_2621:
    mov64 r1, 7                                     r1 = 7 as i32 as i64 as u64
    mov64 r2, 7                                     r2 = 7 as i32 as i64 as u64
    lddw r3, 0x100026350 --> b"\x00\x00\x00\x00\xb8Y\x02\x00\x10\x00\x00\x00\x00\x00\x00\x00z \x00\x00O\…        r3 load str located at 4295123792
    call function_18489                     
    ldxdw r3, [r2+0x8]                      
    jeq r3, 1, lbb_2935                             if r3 == (1 as i32 as i64 as u64) { pc += 307 }
    jeq r3, 0, lbb_2940                             if r3 == (0 as i32 as i64 as u64) { pc += 311 }
    jle r3, 2, lbb_2945                             if r3 <= (2 as i32 as i64 as u64) { pc += 315 }
    jeq r3, 3, lbb_2950                             if r3 == (3 as i32 as i64 as u64) { pc += 319 }
    jle r3, 4, lbb_2955                             if r3 <= (4 as i32 as i64 as u64) { pc += 323 }
    jeq r3, 5, lbb_2960                             if r3 == (5 as i32 as i64 as u64) { pc += 327 }
    jle r3, 6, lbb_2965                             if r3 <= (6 as i32 as i64 as u64) { pc += 331 }
    jeq r3, 7, lbb_2970                             if r3 == (7 as i32 as i64 as u64) { pc += 335 }
    jle r3, 8, lbb_2975                             if r3 <= (8 as i32 as i64 as u64) { pc += 339 }
    jeq r3, 9, lbb_2980                             if r3 == (9 as i32 as i64 as u64) { pc += 343 }
    ldxdw r8, [r2+0x50]                     
    ldxdw r4, [r8+0x0]                      
    ldxdw r3, [r4+0x50]                     
    jlt r3, 32, lbb_2933                            if r3 < (32 as i32 as i64 as u64) { pc += 292 }
    stxdw [r10-0x550], r1                   
    ldxdw r5, [r2+0x0]                      
    ldxdw r3, [r2+0x58]                     
    ldxdw r6, [r5+0x10]                     
    mov64 r9, r6                                    r9 = r6
    add64 r9, 8                                     r9 += 8   ///  r9 = r9.wrapping_add(8 as i32 as i64 as u64)
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    ldxdw r0, [r9+0x0]                      
    ldxdw r7, [r4+0x58]                     
    stxdw [r10-0x598], r9                   
    jne r7, r0, lbb_2667                            if r7 != r0 { pc += 15 }
    ldxdw r0, [r6+0x10]                     
    ldxdw r7, [r4+0x60]                     
    jne r7, r0, lbb_2667                            if r7 != r0 { pc += 12 }
    ldxdw r0, [r6+0x18]                     
    ldxdw r7, [r4+0x68]                     
    jne r7, r0, lbb_2667                            if r7 != r0 { pc += 9 }
    ldxdw r0, [r6+0x20]                     
    ldxdw r4, [r4+0x70]                     
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    jeq r4, r0, lbb_2663                            if r4 == r0 { pc += 1 }
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
lbb_2663:
    jne r4, r0, lbb_2667                            if r4 != r0 { pc += 3 }
    mov64 r4, r8                                    r4 = r8
    mov64 r8, r3                                    r8 = r3
    ja lbb_2668                                     if true { pc += 1 }
lbb_2667:
    mov64 r4, r3                                    r4 = r3
lbb_2668:
    ldxdw r7, [r2+0x48]                     
    ldxdw r6, [r2+0x40]                     
    ldxdw r3, [r2+0x30]                     
    ldxdw r0, [r2+0x28]                     
    ldxdw r9, [r2+0x20]                     
    stxdw [r10-0x570], r9                   
    ldxdw r2, [r2+0x10]                     
    stxdw [r10-0x588], r2                   
    mov64 r2, r5                                    r2 = r5
    add64 r2, 72                                    r2 += 72   ///  r2 = r2.wrapping_add(72 as i32 as i64 as u64)
    stxdw [r10-0x578], r2                   
    mov64 r2, r5                                    r2 = r5
    add64 r2, 8                                     r2 += 8   ///  r2 = r2.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x558], r2                   
    mov64 r2, r5                                    r2 = r5
    add64 r2, 16                                    r2 += 16   ///  r2 = r2.wrapping_add(16 as i32 as i64 as u64)
    stxdw [r10-0x560], r2                   
    mov64 r2, r5                                    r2 = r5
    add64 r2, 24                                    r2 += 24   ///  r2 = r2.wrapping_add(24 as i32 as i64 as u64)
    stxdw [r10-0x568], r2                   
    mov64 r2, r5                                    r2 = r5
    add64 r2, 32                                    r2 += 32   ///  r2 = r2.wrapping_add(32 as i32 as i64 as u64)
    stxdw [r10-0x580], r2                   
    mov64 r2, r5                                    r2 = r5
    add64 r2, 40                                    r2 += 40   ///  r2 = r2.wrapping_add(40 as i32 as i64 as u64)
    stxdw [r10-0x590], r2                   
    mov64 r2, r5                                    r2 = r5
    add64 r2, 48                                    r2 += 48   ///  r2 = r2.wrapping_add(48 as i32 as i64 as u64)
    stxdw [r10-0x5a0], r2                   
    mov64 r2, r5                                    r2 = r5
    add64 r2, 56                                    r2 += 56   ///  r2 = r2.wrapping_add(56 as i32 as i64 as u64)
    stxdw [r10-0x5a8], r2                   
    mov64 r2, r5                                    r2 = r5
    add64 r2, 64                                    r2 += 64   ///  r2 = r2.wrapping_add(64 as i32 as i64 as u64)
    stxdw [r10-0x5b0], r2                   
    and64 r1, 1                                     r1 &= 1   ///  r1 = r1.and(1)
    lddw r2, 0xad837f01a485e633                     r2 load str located at -5943767438166989261
    jne r1, 0, lbb_2709                             if r1 != (0 as i32 as i64 as u64) { pc += 2 }
    lddw r2, 0xeaebda01123d0666                     r2 load str located at -1518880751171598746
lbb_2709:
    stxdw [r10-0x5e8], r2                   
    ldxdw r1, [r3+0x0]                      
    stxdw [r10-0x5f0], r1                   
    ldxdw r1, [r0+0x0]                      
    stxdw [r10-0x5f8], r1                   
    ldxdw r1, [r5+0x0]                      
    stxdw [r10-0x600], r1                   
    ldxdw r1, [r6+0x0]                      
    stxdw [r10-0x608], r1                   
    ldxdw r1, [r5+0x8]                      
    stxdw [r10-0x610], r1                   
    ldxdw r1, [r7+0x0]                      
    stxdw [r10-0x618], r1                   
    stxdw [r10-0x5c8], r7                   
    ldxdw r1, [r5+0x18]                     
    stxdw [r10-0x620], r1                   
    stxdw [r10-0x5b8], r0                   
    ldxdw r0, [r4+0x0]                      
    stxdw [r10-0x5e0], r8                   
    ldxdw r8, [r8+0x0]                      
    stxdw [r10-0x5d8], r4                   
    ldxdw r4, [r5+0x20]                     
    stxdw [r10-0x5c0], r3                   
    ldxdw r3, [r5+0x28]                     
    ldxdw r2, [r5+0x30]                     
    ldxdw r1, [r5+0x38]                     
    stxdw [r10-0x5d0], r6                   
    ldxdw r6, [r5+0x40]                     
    ldxdw r9, [r5+0x48]                     
    ldxdw r7, [r10-0x598]                   
    stxdw [r10-0x4e8], r7                   
    add64 r9, 8                                     r9 += 8   ///  r9 = r9.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x458], r9                   
    add64 r6, 8                                     r6 += 8   ///  r6 = r6.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x468], r6                   
    add64 r1, 8                                     r1 += 8   ///  r1 = r1.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x478], r1                   
    add64 r2, 8                                     r2 += 8   ///  r2 = r2.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x488], r2                   
    add64 r3, 8                                     r3 += 8   ///  r3 = r3.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x498], r3                   
    add64 r4, 8                                     r4 += 8   ///  r4 = r4.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x4a8], r4                   
    add64 r8, 8                                     r8 += 8   ///  r8 = r8.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x4b8], r8                   
    add64 r0, 8                                     r0 += 8   ///  r0 = r0.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x4c8], r0                   
    ldxdw r1, [r10-0x620]                   
    add64 r1, 8                                     r1 += 8   ///  r1 = r1.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x4d8], r1                   
    ldxdw r1, [r10-0x618]                   
    add64 r1, 8                                     r1 += 8   ///  r1 = r1.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x4f8], r1                   
    ldxdw r1, [r10-0x610]                   
    add64 r1, 8                                     r1 += 8   ///  r1 = r1.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x508], r1                   
    ldxdw r1, [r10-0x608]                   
    add64 r1, 8                                     r1 += 8   ///  r1 = r1.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x518], r1                   
    ldxdw r1, [r10-0x600]                   
    add64 r1, 8                                     r1 += 8   ///  r1 = r1.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x528], r1                   
    ldxdw r1, [r10-0x5f8]                   
    add64 r1, 8                                     r1 += 8   ///  r1 = r1.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x538], r1                   
    ldxdw r1, [r10-0x5f0]                   
    add64 r1, 8                                     r1 += 8   ///  r1 = r1.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x548], r1                   
    sth [r10-0x450], 0                      
    sth [r10-0x460], 0                      
    sth [r10-0x470], 0                      
    sth [r10-0x480], 1                      
    sth [r10-0x490], 1                      
    sth [r10-0x4a0], 1                      
    sth [r10-0x4b0], 1                      
    sth [r10-0x4c0], 1                      
    sth [r10-0x4d0], 0                      
    sth [r10-0x4e0], 0                      
    sth [r10-0x4f0], 257                    
    sth [r10-0x500], 1                      
    sth [r10-0x510], 0                      
    sth [r10-0x520], 0                      
    sth [r10-0x530], 0                      
    sth [r10-0x540], 0                      
    ldxdw r1, [r10-0x588]                   
    stxdw [r10-0x440], r1                   
    ldxdw r1, [r10-0x5e8]                   
    stxdw [r10-0x448], r1                   
    stw [r10-0x430], 0                      
    stdw [r10-0x438], 0                     
    ldxdw r1, [r10-0x570]                   
    ldxdw r2, [r1+0x0]                      
    ldxdw r1, [r10-0x578]                   
    stxdw [r10-0x3b0], r1                   
    ldxdw r1, [r10-0x5b0]                   
    stxdw [r10-0x3b8], r1                   
    ldxdw r1, [r10-0x5a8]                   
    stxdw [r10-0x3c0], r1                   
    ldxdw r1, [r10-0x5a0]                   
    stxdw [r10-0x3c8], r1                   
    ldxdw r1, [r10-0x590]                   
    stxdw [r10-0x3d0], r1                   
    ldxdw r1, [r10-0x580]                   
    stxdw [r10-0x3d8], r1                   
    ldxdw r1, [r10-0x5e0]                   
    stxdw [r10-0x3e0], r1                   
    ldxdw r1, [r10-0x5d8]                   
    stxdw [r10-0x3e8], r1                   
    ldxdw r1, [r10-0x568]                   
    stxdw [r10-0x3f0], r1                   
    ldxdw r1, [r10-0x560]                   
    stxdw [r10-0x3f8], r1                   
    ldxdw r1, [r10-0x5c8]                   
    stxdw [r10-0x400], r1                   
    ldxdw r1, [r10-0x558]                   
    stxdw [r10-0x408], r1                   
    ldxdw r1, [r10-0x5d0]                   
    stxdw [r10-0x410], r1                   
    stxdw [r10-0x418], r5                   
    ldxdw r1, [r10-0x5b8]                   
    stxdw [r10-0x420], r1                   
    ldxdw r1, [r10-0x5c0]                   
    stxdw [r10-0x428], r1                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -1064                                 r1 += -1064   ///  r1 = r1.wrapping_add(-1064 as i32 as i64 as u64)
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
    mov64 r4, r10                                   r4 = r10
    add64 r4, -1344                                 r4 += -1344   ///  r4 = r4.wrapping_add(-1344 as i32 as i64 as u64)
    add64 r2, 8                                     r2 += 8   ///  r2 = r2.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x558], r2                   
    ja lbb_2860                                     if true { pc += 20 }
lbb_2840:
    mov64 r7, r10                                   r7 = r10
    add64 r7, -936                                  r7 += -936   ///  r7 = r7.wrapping_add(-936 as i32 as i64 as u64)
    add64 r7, r3                                    r7 += r3   ///  r7 = r7.wrapping_add(r3)
    stxb [r7+0x32], r6                      
    stxb [r7+0x31], r9                      
    stxb [r7+0x30], r5                      
    mov64 r5, r2                                    r5 = r2
    add64 r5, 40                                    r5 += 40   ///  r5 = r5.wrapping_add(40 as i32 as i64 as u64)
    stxdw [r7+0x20], r5                     
    mov64 r5, r2                                    r5 = r2
    add64 r5, 88                                    r5 += 88   ///  r5 = r5.wrapping_add(88 as i32 as i64 as u64)
    stxdw [r7+0x18], r5                     
    stxdw [r7+0x10], r0                     
    add64 r2, 72                                    r2 += 72   ///  r2 = r2.wrapping_add(72 as i32 as i64 as u64)
    stxdw [r7+0x8], r2                      
    stdw [r7+0x28], 0                       
    add64 r4, 16                                    r4 += 16   ///  r4 = r4.wrapping_add(16 as i32 as i64 as u64)
    add64 r1, 8                                     r1 += 8   ///  r1 = r1.wrapping_add(8 as i32 as i64 as u64)
    add64 r3, 56                                    r3 += 56   ///  r3 = r3.wrapping_add(56 as i32 as i64 as u64)
    jeq r3, 896, lbb_2910                           if r3 == (896 as i32 as i64 as u64) { pc += 50 }
lbb_2860:
    mov64 r5, r10                                   r5 = r10
    add64 r5, -936                                  r5 += -936   ///  r5 = r5.wrapping_add(-936 as i32 as i64 as u64)
    mov64 r0, 1                                     r0 = 1 as i32 as i64 as u64
    ldxdw r2, [r1+0x0]                      
    ldxdw r2, [r2+0x0]                      
    ldxdw r6, [r4-0x8]                      
    ldxdw r7, [r6+0x0]                      
    ldxdw r8, [r2+0x8]                      
    jne r8, r7, lbb_2929                            if r8 != r7 { pc += 60 }
    ldxdw r7, [r6+0x8]                      
    ldxdw r8, [r2+0x10]                     
    jne r8, r7, lbb_2929                            if r8 != r7 { pc += 57 }
    ldxdw r7, [r6+0x10]                     
    ldxdw r8, [r2+0x18]                     
    jne r8, r7, lbb_2929                            if r8 != r7 { pc += 54 }
    ldxdw r6, [r6+0x18]                     
    ldxdw r7, [r2+0x20]                     
    jne r7, r6, lbb_2929                            if r7 != r6 { pc += 51 }
    ldxb r6, [r4+0x0]                       
    mov64 r0, 0                                     r0 = 0 as i32 as i64 as u64
    jne r6, 0, lbb_2882                             if r6 != (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r0, 119                                   r0 = 119 as i32 as i64 as u64
lbb_2882:
    ldxb r6, [r2+0x0]                       
    or64 r0, r6                                     r0 |= r6   ///  r0 = r0.or(r6)
    and64 r0, 255                                   r0 &= 255   ///  r0 = r0.and(255)
    jne r0, 255, lbb_2908                           if r0 != (255 as i32 as i64 as u64) { pc += 22 }
    add64 r5, r3                                    r5 += r3   ///  r5 = r5.wrapping_add(r3)
    mov64 r6, r2                                    r6 = r2
    add64 r6, 8                                     r6 += 8   ///  r6 = r6.wrapping_add(8 as i32 as i64 as u64)
    ldxdw r0, [r2+0x50]                     
    ldxb r7, [r2+0x3]                       
    ldxb r8, [r2+0x2]                       
    ldxb r9, [r2+0x1]                       
    stxdw [r5+0x0], r6                      
    mov64 r6, 1                                     r6 = 1 as i32 as i64 as u64
    mov64 r5, 1                                     r5 = 1 as i32 as i64 as u64
    jeq r9, 0, lbb_2901                             if r9 == (0 as i32 as i64 as u64) { pc += 4 }
    mov64 r9, 1                                     r9 = 1 as i32 as i64 as u64
    jeq r8, 0, lbb_2904                             if r8 == (0 as i32 as i64 as u64) { pc += 5 }
lbb_2899:
    jne r7, 0, lbb_2840                             if r7 != (0 as i32 as i64 as u64) { pc += -60 }
    ja lbb_2906                                     if true { pc += 5 }
lbb_2901:
    mov64 r5, 0                                     r5 = 0 as i32 as i64 as u64
    mov64 r9, 1                                     r9 = 1 as i32 as i64 as u64
    jne r8, 0, lbb_2899                             if r8 != (0 as i32 as i64 as u64) { pc += -5 }
lbb_2904:
    mov64 r9, 0                                     r9 = 0 as i32 as i64 as u64
    jne r7, 0, lbb_2840                             if r7 != (0 as i32 as i64 as u64) { pc += -66 }
lbb_2906:
    mov64 r6, 0                                     r6 = 0 as i32 as i64 as u64
    ja lbb_2840                                     if true { pc += -68 }
lbb_2908:
    mov64 r0, 11                                    r0 = 11 as i32 as i64 as u64
    ja lbb_2929                                     if true { pc += 19 }
lbb_2910:
    mov64 r1, r10                                   r1 = r10
    add64 r1, -1096                                 r1 += -1096   ///  r1 = r1.wrapping_add(-1096 as i32 as i64 as u64)
    stxdw [r10-0x10], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -1352                                 r1 += -1352   ///  r1 = r1.wrapping_add(-1352 as i32 as i64 as u64)
    stxdw [r10-0x20], r1                    
    ldxdw r1, [r10-0x558]                   
    stxdw [r10-0x28], r1                    
    stdw [r10-0x8], 28                      
    stdw [r10-0x18], 16                     
    mov64 r1, r10                                   r1 = r10
    add64 r1, -40                                   r1 += -40   ///  r1 = r1.wrapping_add(-40 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -936                                  r2 += -936   ///  r2 = r2.wrapping_add(-936 as i32 as i64 as u64)
    mov64 r3, 16                                    r3 = 16 as i32 as i64 as u64
    mov64 r4, 8                                     r4 = 8 as i32 as i64 as u64
    mov64 r5, 0                                     r5 = 0 as i32 as i64 as u64
    syscall [invalid]                       
    mov64 r0, 26                                    r0 = 26 as i32 as i64 as u64
lbb_2929:
    ldxdw r1, [r10-0x550]                   
lbb_2930:
    stxw [r1+0x0], r0                       
    stw [r1+0x4], 0                         
    exit                                    
lbb_2933:
    mov64 r0, 3                                     r0 = 3 as i32 as i64 as u64
    ja lbb_2930                                     if true { pc += -5 }
lbb_2935:
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    mov64 r2, 1                                     r2 = 1 as i32 as i64 as u64
    lddw r3, 0x100026380 --> b"\x00\x00\x00\x00\xb8Y\x02\x00\x10\x00\x00\x00\x00\x00\x00\x00\x86 \x00\x0…        r3 load str located at 4295123840
    call function_18489                     
lbb_2940:
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
    lddw r3, 0x100026368 --> b"\x00\x00\x00\x00\xb8Y\x02\x00\x10\x00\x00\x00\x00\x00\x00\x00\x86 \x00\x0…        r3 load str located at 4295123816
    call function_18489                     
lbb_2945:
    mov64 r1, 2                                     r1 = 2 as i32 as i64 as u64
    mov64 r2, 2                                     r2 = 2 as i32 as i64 as u64
    lddw r3, 0x100026398 --> b"\x00\x00\x00\x00\xb8Y\x02\x00\x10\x00\x00\x00\x00\x00\x00\x00\x86 \x00\x0…        r3 load str located at 4295123864
    call function_18489                     
lbb_2950:
    mov64 r1, 3                                     r1 = 3 as i32 as i64 as u64
    mov64 r2, 3                                     r2 = 3 as i32 as i64 as u64
    lddw r3, 0x1000263b0 --> b"\x00\x00\x00\x00\xb8Y\x02\x00\x10\x00\x00\x00\x00\x00\x00\x00\x86 \x00\x0…        r3 load str located at 4295123888
    call function_18489                     
lbb_2955:
    mov64 r1, 4                                     r1 = 4 as i32 as i64 as u64
    mov64 r2, 4                                     r2 = 4 as i32 as i64 as u64
    lddw r3, 0x1000263c8 --> b"\x00\x00\x00\x00\xb8Y\x02\x00\x10\x00\x00\x00\x00\x00\x00\x00\x87 \x00\x0…        r3 load str located at 4295123912
    call function_18489                     
lbb_2960:
    mov64 r1, 5                                     r1 = 5 as i32 as i64 as u64
    mov64 r2, 5                                     r2 = 5 as i32 as i64 as u64
    lddw r3, 0x1000263e0 --> b"\x00\x00\x00\x00\xb8Y\x02\x00\x10\x00\x00\x00\x00\x00\x00\x00\x87 \x00\x0…        r3 load str located at 4295123936
    call function_18489                     
lbb_2965:
    mov64 r1, 6                                     r1 = 6 as i32 as i64 as u64
    mov64 r2, 6                                     r2 = 6 as i32 as i64 as u64
    lddw r3, 0x1000263f8 --> b"\x00\x00\x00\x00\xb8Y\x02\x00\x10\x00\x00\x00\x00\x00\x00\x00\x87 \x00\x0…        r3 load str located at 4295123960
    call function_18489                     
lbb_2970:
    mov64 r1, 7                                     r1 = 7 as i32 as i64 as u64
    mov64 r2, 7                                     r2 = 7 as i32 as i64 as u64
    lddw r3, 0x100026410 --> b"\x00\x00\x00\x00\xb8Y\x02\x00\x10\x00\x00\x00\x00\x00\x00\x00\x87 \x00\x0…        r3 load str located at 4295123984
    call function_18489                     
lbb_2975:
    mov64 r1, 8                                     r1 = 8 as i32 as i64 as u64
    mov64 r2, 8                                     r2 = 8 as i32 as i64 as u64
    lddw r3, 0x100026428 --> b"\x00\x00\x00\x00\xb8Y\x02\x00\x10\x00\x00\x00\x00\x00\x00\x00\x88 \x00\x0…        r3 load str located at 4295124008
    call function_18489                     
lbb_2980:
    mov64 r1, 9                                     r1 = 9 as i32 as i64 as u64
    mov64 r2, 9                                     r2 = 9 as i32 as i64 as u64
    lddw r3, 0x100026440 --> b"\x00\x00\x00\x00\xb8Y\x02\x00\x10\x00\x00\x00\x00\x00\x00\x00\x88 \x00\x0…        r3 load str located at 4295124032
    call function_18489                     
    ldxdw r3, [r2+0x8]                      
    jeq r3, 1, lbb_3313                             if r3 == (1 as i32 as i64 as u64) { pc += 326 }
    jeq r3, 0, lbb_3318                             if r3 == (0 as i32 as i64 as u64) { pc += 330 }
    jle r3, 2, lbb_3323                             if r3 <= (2 as i32 as i64 as u64) { pc += 334 }
    jeq r3, 3, lbb_3328                             if r3 == (3 as i32 as i64 as u64) { pc += 338 }
    jle r3, 4, lbb_3333                             if r3 <= (4 as i32 as i64 as u64) { pc += 342 }
    jeq r3, 5, lbb_3338                             if r3 == (5 as i32 as i64 as u64) { pc += 346 }
    jle r3, 6, lbb_3343                             if r3 <= (6 as i32 as i64 as u64) { pc += 350 }
    jeq r3, 7, lbb_3348                             if r3 == (7 as i32 as i64 as u64) { pc += 354 }
    jle r3, 8, lbb_3353                             if r3 <= (8 as i32 as i64 as u64) { pc += 358 }
    ldxdw r7, [r2+0x50]                     
    ldxdw r4, [r7+0x0]                      
    ldxdw r3, [r4+0x50]                     
    jlt r3, 32, lbb_3311                            if r3 < (32 as i32 as i64 as u64) { pc += 312 }
    ldxdw r5, [r2+0x0]                      
    ldxdw r3, [r2+0x58]                     
    stxdw [r10-0x4c0], r5                   
    ldxdw r5, [r5+0x10]                     
    mov64 r8, r5                                    r8 = r5
    add64 r8, 8                                     r8 += 8   ///  r8 = r8.wrapping_add(8 as i32 as i64 as u64)
    mov64 r0, 0                                     r0 = 0 as i32 as i64 as u64
    stxdw [r10-0x4d0], r0                   
    ldxdw r0, [r8+0x0]                      
    ldxdw r6, [r4+0x58]                     
    stxdw [r10-0x508], r8                   
    jne r6, r0, lbb_3028                            if r6 != r0 { pc += 17 }
    ldxdw r0, [r5+0x10]                     
    ldxdw r6, [r4+0x60]                     
    jne r6, r0, lbb_3028                            if r6 != r0 { pc += 14 }
    ldxdw r0, [r5+0x18]                     
    ldxdw r6, [r4+0x68]                     
    jne r6, r0, lbb_3028                            if r6 != r0 { pc += 11 }
    ldxdw r0, [r5+0x20]                     
    ldxdw r4, [r4+0x70]                     
    mov64 r6, 1                                     r6 = 1 as i32 as i64 as u64
    stxdw [r10-0x4d0], r6                   
    jeq r4, r0, lbb_3024                            if r4 == r0 { pc += 2 }
    mov64 r6, 0                                     r6 = 0 as i32 as i64 as u64
    stxdw [r10-0x4d0], r6                   
lbb_3024:
    jne r4, r0, lbb_3028                            if r4 != r0 { pc += 3 }
    mov64 r8, r7                                    r8 = r7
    mov64 r7, r3                                    r7 = r3
    ja lbb_3029                                     if true { pc += 1 }
lbb_3028:
    mov64 r8, r3                                    r8 = r3
lbb_3029:
    ldxdw r3, [r2+0x30]                     
    stxdw [r10-0x4e0], r3                   
    ldxdw r9, [r2+0x28]                     
    ldxdw r4, [r10-0x4c0]                   
    add64 r4, 24                                    r4 += 24   ///  r4 = r4.wrapping_add(24 as i32 as i64 as u64)
    ldxdw r3, [r5+0x28]                     
    lddw r6, 0xde8f75eee1f6dd06                     r6 load str located at -2409577606766207738
    stxdw [r10-0x4c8], r9                   
    jne r3, r6, lbb_3056                            if r3 != r6 { pc += 17 }
    ldxdw r3, [r5+0x30]                     
    lddw r0, 0xdacd6ce4bc5d4218                     r0 load str located at -2680366473547005416
    stxdw [r10-0x4c8], r9                   
    jne r3, r0, lbb_3056                            if r3 != r0 { pc += 12 }
    ldxdw r3, [r5+0x38]                     
    lddw r0, 0x270db9834dfc1ab6                     r0 load str located at 2814109315776649910
    stxdw [r10-0x4c8], r9                   
    jne r3, r0, lbb_3056                            if r3 != r0 { pc += 7 }
    ldxdw r3, [r5+0x40]                     
    lddw r5, 0xfc8ba1d828f9bdfe                     r5 load str located at -248927404616466946
    stxdw [r10-0x4c8], r9                   
    jne r3, r5, lbb_3056                            if r3 != r5 { pc += 2 }
    ldxdw r3, [r10-0x4e0]                   
    stxdw [r10-0x4c8], r3                   
lbb_3056:
    ldxdw r3, [r2+0x48]                     
    stxdw [r10-0x4f8], r4                   
    ldxdw r4, [r4+0x0]                      
    ldxdw r5, [r4+0x28]                     
    stxdw [r10-0x4d8], r1                   
    jne r5, r6, lbb_3079                            if r5 != r6 { pc += 17 }
    mov64 r0, r3                                    r0 = r3
    ldxdw r3, [r4+0x30]                     
    lddw r5, 0xdacd6ce4bc5d4218                     r5 load str located at -2680366473547005416
    jne r3, r5, lbb_3078                            if r3 != r5 { pc += 11 }
    ldxdw r3, [r4+0x38]                     
    lddw r5, 0x270db9834dfc1ab6                     r5 load str located at 2814109315776649910
    jne r3, r5, lbb_3078                            if r3 != r5 { pc += 7 }
    ldxdw r1, [r4+0x40]                     
    lddw r5, 0xfc8ba1d828f9bdfe                     r5 load str located at -248927404616466946
    mov64 r3, r0                                    r3 = r0
    jne r1, r5, lbb_3079                            if r1 != r5 { pc += 3 }
    ldxdw r9, [r10-0x4e0]                   
    ja lbb_3079                                     if true { pc += 1 }
lbb_3078:
    mov64 r3, r0                                    r3 = r0
lbb_3079:
    ldxdw r1, [r2+0x20]                     
    stxdw [r10-0x510], r1                   
    ldxdw r1, [r2+0x10]                     
    stxdw [r10-0x518], r1                   
    add64 r4, 8                                     r4 += 8   ///  r4 = r4.wrapping_add(8 as i32 as i64 as u64)
    ldxdw r1, [r10-0x4c8]                   
    ldxdw r1, [r1+0x0]                      
    stxdw [r10-0x520], r1                   
    stxdw [r10-0x4f0], r9                   
    ldxdw r1, [r9+0x0]                      
    stxdw [r10-0x528], r1                   
    ldxdw r0, [r10-0x4c0]                   
    ldxdw r1, [r0+0x0]                      
    stxdw [r10-0x530], r1                   
    stxdw [r10-0x500], r3                   
    ldxdw r5, [r3+0x0]                      
    ldxdw r2, [r0+0x8]                      
    stxdw [r10-0x4e8], r8                   
    ldxdw r8, [r8+0x0]                      
    stxdw [r10-0x4e0], r7                   
    ldxdw r9, [r7+0x0]                      
    ldxdw r6, [r0+0x20]                     
    ldxdw r1, [r0+0x28]                     
    ldxdw r7, [r0+0x30]                     
    ldxdw r3, [r0+0x38]                     
    ldxdw r0, [r0+0x40]                     
    stxdw [r10-0x458], r4                   
    ldxdw r4, [r10-0x508]                   
    stxdw [r10-0x468], r4                   
    add64 r0, 8                                     r0 += 8   ///  r0 = r0.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x3e8], r0                   
    add64 r3, 8                                     r3 += 8   ///  r3 = r3.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x3f8], r3                   
    add64 r7, 8                                     r7 += 8   ///  r7 = r7.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x408], r7                   
    add64 r1, 8                                     r1 += 8   ///  r1 = r1.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x418], r1                   
    add64 r6, 8                                     r6 += 8   ///  r6 = r6.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x428], r6                   
    add64 r9, 8                                     r9 += 8   ///  r9 = r9.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x438], r9                   
    add64 r8, 8                                     r8 += 8   ///  r8 = r8.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x448], r8                   
    add64 r2, 8                                     r2 += 8   ///  r2 = r2.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x478], r2                   
    add64 r5, 8                                     r5 += 8   ///  r5 = r5.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x488], r5                   
    ldxdw r1, [r10-0x530]                   
    add64 r1, 8                                     r1 += 8   ///  r1 = r1.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x498], r1                   
    ldxdw r1, [r10-0x528]                   
    add64 r1, 8                                     r1 += 8   ///  r1 = r1.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x4a8], r1                   
    ldxdw r1, [r10-0x520]                   
    add64 r1, 8                                     r1 += 8   ///  r1 = r1.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x4b8], r1                   
    ldxdw r7, [r10-0x4d0]                   
    and64 r7, 1                                     r7 &= 1   ///  r7 = r7.and(1)
    lddw r1, 0x100013b50 --> b"\xb7\x00\x00\x00\x0b\x00\x00\x00\x05\x00\x13\x00\x00\x00\x00\x00\xbf\xa1\…        r1 load str located at 4295048016
    jne r7, 0, lbb_3142                             if r7 != (0 as i32 as i64 as u64) { pc += 2 }
    lddw r1, 0x35bb7f32a81b33af                     r1 load str located at 3871828160200520623
lbb_3142:
    stxdw [r10-0x4d0], r1                   
    ldxdw r4, [r10-0x4c0]                   
    mov64 r3, r4                                    r3 = r4
    add64 r3, 64                                    r3 += 64   ///  r3 = r3.wrapping_add(64 as i32 as i64 as u64)
    mov64 r6, r4                                    r6 = r4
    add64 r6, 8                                     r6 += 8   ///  r6 = r6.wrapping_add(8 as i32 as i64 as u64)
    mov64 r5, r4                                    r5 = r4
    add64 r5, 16                                    r5 += 16   ///  r5 = r5.wrapping_add(16 as i32 as i64 as u64)
    mov64 r9, r4                                    r9 = r4
    add64 r9, 32                                    r9 += 32   ///  r9 = r9.wrapping_add(32 as i32 as i64 as u64)
    mov64 r0, r4                                    r0 = r4
    add64 r0, 40                                    r0 += 40   ///  r0 = r0.wrapping_add(40 as i32 as i64 as u64)
    mov64 r1, r4                                    r1 = r4
    add64 r1, 48                                    r1 += 48   ///  r1 = r1.wrapping_add(48 as i32 as i64 as u64)
    add64 r4, 56                                    r4 += 56   ///  r4 = r4.wrapping_add(56 as i32 as i64 as u64)
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
    mov64 r8, 0                                     r8 = 0 as i32 as i64 as u64
    jne r7, 0, lbb_3162                             if r7 != (0 as i32 as i64 as u64) { pc += 2 }
    lddw r8, 0xfffec4b1                             r8 load str located at 4294886577
lbb_3162:
    sth [r10-0x3e0], 1                      
    sth [r10-0x3f0], 1                      
    sth [r10-0x400], 1                      
    sth [r10-0x410], 1                      
    sth [r10-0x420], 1                      
    sth [r10-0x430], 1                      
    sth [r10-0x440], 1                      
    sth [r10-0x450], 0                      
    sth [r10-0x460], 0                      
    sth [r10-0x470], 1                      
    sth [r10-0x480], 257                    
    sth [r10-0x490], 0                      
    sth [r10-0x4a0], 0                      
    sth [r10-0x4b0], 0                      
    stxdw [r10-0x3b8], r8                   
    ldxdw r8, [r10-0x4d0]                   
    stxdw [r10-0x3c0], r8                   
    stxb [r10-0x3af], r7                    
    ldxdw r7, [r10-0x518]                   
    stxdw [r10-0x3d0], r7                   
    lddw r7, 0xc88775e1919ec6f8                     r7 load str located at -3997096532596832520
    stxdw [r10-0x3d8], r7                   
    stb [r10-0x3ae], 0                      
    stb [r10-0x3b0], 1                      
    stdw [r10-0x3c8], 0                     
    ldxdw r7, [r10-0x510]                   
    ldxdw r7, [r7+0x0]                      
    stxdw [r10-0x340], r3                   
    stxdw [r10-0x348], r4                   
    stxdw [r10-0x350], r1                   
    stxdw [r10-0x358], r0                   
    stxdw [r10-0x360], r9                   
    ldxdw r1, [r10-0x4e0]                   
    stxdw [r10-0x368], r1                   
    ldxdw r1, [r10-0x4e8]                   
    stxdw [r10-0x370], r1                   
    ldxdw r1, [r10-0x4f8]                   
    stxdw [r10-0x378], r1                   
    stxdw [r10-0x380], r5                   
    stxdw [r10-0x388], r6                   
    ldxdw r1, [r10-0x500]                   
    stxdw [r10-0x390], r1                   
    ldxdw r1, [r10-0x4c0]                   
    stxdw [r10-0x398], r1                   
    ldxdw r1, [r10-0x4f0]                   
    stxdw [r10-0x3a0], r1                   
    ldxdw r1, [r10-0x4c8]                   
    stxdw [r10-0x3a8], r1                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -936                                  r1 += -936   ///  r1 = r1.wrapping_add(-936 as i32 as i64 as u64)
    mov64 r3, r10                                   r3 = r10
    add64 r3, -1200                                 r3 += -1200   ///  r3 = r3.wrapping_add(-1200 as i32 as i64 as u64)
    add64 r7, 8                                     r7 += 8   ///  r7 = r7.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x4c0], r7                   
    ja lbb_3238                                     if true { pc += 20 }
lbb_3218:
    mov64 r7, r10                                   r7 = r10
    add64 r7, -824                                  r7 += -824   ///  r7 = r7.wrapping_add(-824 as i32 as i64 as u64)
    add64 r7, r2                                    r7 += r2   ///  r7 = r7.wrapping_add(r2)
    stxb [r7+0x32], r0                      
    stxb [r7+0x31], r9                      
    stxb [r7+0x30], r4                      
    mov64 r4, r5                                    r4 = r5
    add64 r4, 40                                    r4 += 40   ///  r4 = r4.wrapping_add(40 as i32 as i64 as u64)
    stxdw [r7+0x20], r4                     
    mov64 r4, r5                                    r4 = r5
    add64 r4, 88                                    r4 += 88   ///  r4 = r4.wrapping_add(88 as i32 as i64 as u64)
    stxdw [r7+0x18], r4                     
    stxdw [r7+0x10], r6                     
    add64 r5, 72                                    r5 += 72   ///  r5 = r5.wrapping_add(72 as i32 as i64 as u64)
    stxdw [r7+0x8], r5                      
    stdw [r7+0x28], 0                       
    add64 r3, 16                                    r3 += 16   ///  r3 = r3.wrapping_add(16 as i32 as i64 as u64)
    add64 r1, 8                                     r1 += 8   ///  r1 = r1.wrapping_add(8 as i32 as i64 as u64)
    add64 r2, 56                                    r2 += 56   ///  r2 = r2.wrapping_add(56 as i32 as i64 as u64)
    jeq r2, 784, lbb_3288                           if r2 == (784 as i32 as i64 as u64) { pc += 50 }
lbb_3238:
    mov64 r0, r10                                   r0 = r10
    add64 r0, -824                                  r0 += -824   ///  r0 = r0.wrapping_add(-824 as i32 as i64 as u64)
    mov64 r6, 1                                     r6 = 1 as i32 as i64 as u64
    ldxdw r4, [r1+0x0]                      
    ldxdw r5, [r4+0x0]                      
    ldxdw r4, [r3-0x8]                      
    ldxdw r7, [r4+0x0]                      
    ldxdw r8, [r5+0x8]                      
    jne r8, r7, lbb_3307                            if r8 != r7 { pc += 60 }
    ldxdw r7, [r4+0x8]                      
    ldxdw r8, [r5+0x10]                     
    jne r8, r7, lbb_3307                            if r8 != r7 { pc += 57 }
    ldxdw r7, [r4+0x10]                     
    ldxdw r8, [r5+0x18]                     
    jne r8, r7, lbb_3307                            if r8 != r7 { pc += 54 }
    ldxdw r4, [r4+0x18]                     
    ldxdw r7, [r5+0x20]                     
    jne r7, r4, lbb_3307                            if r7 != r4 { pc += 51 }
    ldxb r6, [r3+0x0]                       
    mov64 r4, 0                                     r4 = 0 as i32 as i64 as u64
    jne r6, 0, lbb_3260                             if r6 != (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r4, 119                                   r4 = 119 as i32 as i64 as u64
lbb_3260:
    ldxb r6, [r5+0x0]                       
    or64 r4, r6                                     r4 |= r6   ///  r4 = r4.or(r6)
    and64 r4, 255                                   r4 &= 255   ///  r4 = r4.and(255)
    jne r4, 255, lbb_3286                           if r4 != (255 as i32 as i64 as u64) { pc += 22 }
    add64 r0, r2                                    r0 += r2   ///  r0 = r0.wrapping_add(r2)
    mov64 r4, r5                                    r4 = r5
    add64 r4, 8                                     r4 += 8   ///  r4 = r4.wrapping_add(8 as i32 as i64 as u64)
    ldxdw r6, [r5+0x50]                     
    ldxb r7, [r5+0x3]                       
    ldxb r8, [r5+0x2]                       
    ldxb r9, [r5+0x1]                       
    stxdw [r0+0x0], r4                      
    mov64 r0, 1                                     r0 = 1 as i32 as i64 as u64
    mov64 r4, 1                                     r4 = 1 as i32 as i64 as u64
    jne r9, 0, lbb_3280                             if r9 != (0 as i32 as i64 as u64) { pc += 5 }
    mov64 r4, 0                                     r4 = 0 as i32 as i64 as u64
    mov64 r9, 1                                     r9 = 1 as i32 as i64 as u64
    jeq r8, 0, lbb_3282                             if r8 == (0 as i32 as i64 as u64) { pc += 4 }
lbb_3278:
    jne r7, 0, lbb_3218                             if r7 != (0 as i32 as i64 as u64) { pc += -61 }
    ja lbb_3284                                     if true { pc += 4 }
lbb_3280:
    mov64 r9, 1                                     r9 = 1 as i32 as i64 as u64
    jne r8, 0, lbb_3278                             if r8 != (0 as i32 as i64 as u64) { pc += -4 }
lbb_3282:
    mov64 r9, 0                                     r9 = 0 as i32 as i64 as u64
    jne r7, 0, lbb_3218                             if r7 != (0 as i32 as i64 as u64) { pc += -66 }
lbb_3284:
    mov64 r0, 0                                     r0 = 0 as i32 as i64 as u64
    ja lbb_3218                                     if true { pc += -68 }
lbb_3286:
    mov64 r6, 11                                    r6 = 11 as i32 as i64 as u64
    ja lbb_3307                                     if true { pc += 19 }
lbb_3288:
    mov64 r1, r10                                   r1 = r10
    add64 r1, -984                                  r1 += -984   ///  r1 = r1.wrapping_add(-984 as i32 as i64 as u64)
    stxdw [r10-0x10], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -1208                                 r1 += -1208   ///  r1 = r1.wrapping_add(-1208 as i32 as i64 as u64)
    stxdw [r10-0x20], r1                    
    ldxdw r1, [r10-0x4c0]                   
    stxdw [r10-0x28], r1                    
    stdw [r10-0x8], 43                      
    stdw [r10-0x18], 14                     
    mov64 r1, r10                                   r1 = r10
    add64 r1, -40                                   r1 += -40   ///  r1 = r1.wrapping_add(-40 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -824                                  r2 += -824   ///  r2 = r2.wrapping_add(-824 as i32 as i64 as u64)
    mov64 r3, 14                                    r3 = 14 as i32 as i64 as u64
    mov64 r4, 8                                     r4 = 8 as i32 as i64 as u64
    mov64 r5, 0                                     r5 = 0 as i32 as i64 as u64
    syscall [invalid]                       
    mov64 r6, 26                                    r6 = 26 as i32 as i64 as u64
lbb_3307:
    ldxdw r1, [r10-0x4d8]                   
lbb_3308:
    stxw [r1+0x0], r6                       
    stw [r1+0x4], 0                         
    exit                                    
lbb_3311:
    mov64 r6, 3                                     r6 = 3 as i32 as i64 as u64
    ja lbb_3308                                     if true { pc += -5 }
lbb_3313:
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    mov64 r2, 1                                     r2 = 1 as i32 as i64 as u64
    lddw r3, 0x100026470 --> b"\x00\x00\x00\x00\xb8Y\x02\x00\x10\x00\x00\x00\x00\x00\x00\x00\x94 \x00\x0…        r3 load str located at 4295124080
    call function_18489                     
lbb_3318:
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
    lddw r3, 0x100026458 --> b"\x00\x00\x00\x00\xb8Y\x02\x00\x10\x00\x00\x00\x00\x00\x00\x00\x94 \x00\x0…        r3 load str located at 4295124056
    call function_18489                     
lbb_3323:
    mov64 r1, 2                                     r1 = 2 as i32 as i64 as u64
    mov64 r2, 2                                     r2 = 2 as i32 as i64 as u64
    lddw r3, 0x100026488 --> b"\x00\x00\x00\x00\xb8Y\x02\x00\x10\x00\x00\x00\x00\x00\x00\x00\x94 \x00\x0…        r3 load str located at 4295124104
    call function_18489                     
lbb_3328:
    mov64 r1, 3                                     r1 = 3 as i32 as i64 as u64
    mov64 r2, 3                                     r2 = 3 as i32 as i64 as u64
    lddw r3, 0x1000264a0 --> b"\x00\x00\x00\x00\xb8Y\x02\x00\x10\x00\x00\x00\x00\x00\x00\x00\x94 \x00\x0…        r3 load str located at 4295124128
    call function_18489                     
lbb_3333:
    mov64 r1, 4                                     r1 = 4 as i32 as i64 as u64
    mov64 r2, 4                                     r2 = 4 as i32 as i64 as u64
    lddw r3, 0x1000264b8 --> b"\x00\x00\x00\x00\xb8Y\x02\x00\x10\x00\x00\x00\x00\x00\x00\x00\x95 \x00\x0…        r3 load str located at 4295124152
    call function_18489                     
lbb_3338:
    mov64 r1, 5                                     r1 = 5 as i32 as i64 as u64
    mov64 r2, 5                                     r2 = 5 as i32 as i64 as u64
    lddw r3, 0x1000264d0 --> b"\x00\x00\x00\x00\xb8Y\x02\x00\x10\x00\x00\x00\x00\x00\x00\x00\x95 \x00\x0…        r3 load str located at 4295124176
    call function_18489                     
lbb_3343:
    mov64 r1, 6                                     r1 = 6 as i32 as i64 as u64
    mov64 r2, 6                                     r2 = 6 as i32 as i64 as u64
    lddw r3, 0x1000264e8 --> b"\x00\x00\x00\x00\xb8Y\x02\x00\x10\x00\x00\x00\x00\x00\x00\x00\x95 \x00\x0…        r3 load str located at 4295124200
    call function_18489                     
lbb_3348:
    mov64 r1, 7                                     r1 = 7 as i32 as i64 as u64
    mov64 r2, 7                                     r2 = 7 as i32 as i64 as u64
    lddw r3, 0x100026500 --> b"\x00\x00\x00\x00\xb8Y\x02\x00\x10\x00\x00\x00\x00\x00\x00\x00\x95 \x00\x0…        r3 load str located at 4295124224
    call function_18489                     
lbb_3353:
    mov64 r1, 8                                     r1 = 8 as i32 as i64 as u64
    mov64 r2, 8                                     r2 = 8 as i32 as i64 as u64
    lddw r3, 0x100026518 --> b"\x00\x00\x00\x00\xb8Y\x02\x00\x10\x00\x00\x00\x00\x00\x00\x00\x96 \x00\x0…        r3 load str located at 4295124248
    call function_18489                     
    ldxdw r8, [r2+0x8]                      
    jeq r8, 1, lbb_3674                             if r8 == (1 as i32 as i64 as u64) { pc += 314 }
    jeq r8, 0, lbb_3679                             if r8 == (0 as i32 as i64 as u64) { pc += 318 }
    jle r8, 2, lbb_3684                             if r8 <= (2 as i32 as i64 as u64) { pc += 322 }
    jeq r8, 3, lbb_3689                             if r8 == (3 as i32 as i64 as u64) { pc += 326 }
    jle r8, 4, lbb_3694                             if r8 <= (4 as i32 as i64 as u64) { pc += 330 }
    jeq r8, 5, lbb_3699                             if r8 == (5 as i32 as i64 as u64) { pc += 334 }
    jle r8, 6, lbb_3704                             if r8 <= (6 as i32 as i64 as u64) { pc += 338 }
    jeq r8, 7, lbb_3709                             if r8 == (7 as i32 as i64 as u64) { pc += 342 }
    jle r8, 8, lbb_3714                             if r8 <= (8 as i32 as i64 as u64) { pc += 346 }
    jeq r8, 9, lbb_3719                             if r8 == (9 as i32 as i64 as u64) { pc += 350 }
    jle r8, 10, lbb_3724                            if r8 <= (10 as i32 as i64 as u64) { pc += 354 }
    mov64 r5, 3                                     r5 = 3 as i32 as i64 as u64
    mov64 r7, r8                                    r7 = r8
    add64 r7, 6                                     r7 += 6   ///  r7 = r7.wrapping_add(6 as i32 as i64 as u64)
    jgt r7, 32, lbb_3666                            if r7 > (32 as i32 as i64 as u64) { pc += 292 }
    ldxdw r0, [r2+0x50]                     
    ldxdw r4, [r0+0x0]                      
    ldxdw r3, [r4+0x50]                     
    jlt r3, 32, lbb_3667                            if r3 < (32 as i32 as i64 as u64) { pc += 289 }
    stxdw [r10-0x228], r0                   
    stxdw [r10-0x300], r1                   
    ldxdw r5, [r2+0x58]                     
    ldxdw r0, [r2+0x0]                      
    mov64 r1, r0                                    r1 = r0
    add64 r1, 8                                     r1 += 8   ///  r1 = r1.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x248], r1                   
    ldxdw r3, [r1+0x0]                      
    mov64 r1, r3                                    r1 = r3
    add64 r1, 8                                     r1 += 8   ///  r1 = r1.wrapping_add(8 as i32 as i64 as u64)
    mov64 r9, 0                                     r9 = 0 as i32 as i64 as u64
    stxdw [r10-0x258], r1                   
    ldxdw r1, [r1+0x0]                      
    ldxdw r6, [r4+0x58]                     
    jne r6, r1, lbb_3409                            if r6 != r1 { pc += 16 }
    ldxdw r1, [r3+0x10]                     
    ldxdw r6, [r4+0x60]                     
    jne r6, r1, lbb_3409                            if r6 != r1 { pc += 13 }
    ldxdw r1, [r3+0x18]                     
    ldxdw r6, [r4+0x68]                     
    jne r6, r1, lbb_3409                            if r6 != r1 { pc += 10 }
    ldxdw r1, [r3+0x20]                     
    ldxdw r4, [r4+0x70]                     
    mov64 r9, 1                                     r9 = 1 as i32 as i64 as u64
    jeq r4, r1, lbb_3404                            if r4 == r1 { pc += 1 }
    mov64 r9, 0                                     r9 = 0 as i32 as i64 as u64
lbb_3404:
    jne r4, r1, lbb_3409                            if r4 != r1 { pc += 4 }
    ldxdw r1, [r10-0x228]                   
    stxdw [r10-0x238], r1                   
    stxdw [r10-0x228], r5                   
    ja lbb_3410                                     if true { pc += 1 }
lbb_3409:
    stxdw [r10-0x238], r5                   
lbb_3410:
    stxdw [r10-0x2f0], r9                   
    ldxdw r6, [r2+0x30]                     
    ldxdw r5, [r2+0x28]                     
    mov64 r9, r0                                    r9 = r0
    add64 r9, 16                                    r9 += 16   ///  r9 = r9.wrapping_add(16 as i32 as i64 as u64)
    ldxdw r1, [r3+0x28]                     
    lddw r4, 0xde8f75eee1f6dd06                     r4 load str located at -2409577606766207738
    stxdw [r10-0x220], r5                   
    jne r1, r4, lbb_3436                            if r1 != r4 { pc += 16 }
    ldxdw r1, [r3+0x30]                     
    stxdw [r10-0x220], r5                   
    lddw r4, 0xdacd6ce4bc5d4218                     r4 load str located at -2680366473547005416
    jne r1, r4, lbb_3436                            if r1 != r4 { pc += 11 }
    ldxdw r1, [r3+0x38]                     
    lddw r4, 0x270db9834dfc1ab6                     r4 load str located at 2814109315776649910
    stxdw [r10-0x220], r5                   
    jne r1, r4, lbb_3436                            if r1 != r4 { pc += 6 }
    ldxdw r1, [r3+0x40]                     
    lddw r3, 0xfc8ba1d828f9bdfe                     r3 load str located at -248927404616466946
    stxdw [r10-0x220], r5                   
    jne r1, r3, lbb_3436                            if r1 != r3 { pc += 1 }
    stxdw [r10-0x220], r6                   
lbb_3436:
    stxdw [r10-0x2a8], r6                   
    ldxdw r1, [r2+0x48]                     
    stxdw [r10-0x230], r1                   
    ldxdw r6, [r2+0x20]                     
    mov64 r1, r0                                    r1 = r0
    add64 r1, 80                                    r1 += 80   ///  r1 = r1.wrapping_add(80 as i32 as i64 as u64)
    stxdw [r10-0x280], r1                   
    mov64 r1, r0                                    r1 = r0
    add64 r1, 24                                    r1 += 24   ///  r1 = r1.wrapping_add(24 as i32 as i64 as u64)
    stxdw [r10-0x260], r1                   
    mov64 r1, r0                                    r1 = r0
    add64 r1, 32                                    r1 += 32   ///  r1 = r1.wrapping_add(32 as i32 as i64 as u64)
    stxdw [r10-0x268], r1                   
    mov64 r1, r0                                    r1 = r0
    add64 r1, 40                                    r1 += 40   ///  r1 = r1.wrapping_add(40 as i32 as i64 as u64)
    stxdw [r10-0x270], r1                   
    mov64 r1, r0                                    r1 = r0
    add64 r1, 48                                    r1 += 48   ///  r1 = r1.wrapping_add(48 as i32 as i64 as u64)
    stxdw [r10-0x278], r1                   
    mov64 r1, r0                                    r1 = r0
    add64 r1, 56                                    r1 += 56   ///  r1 = r1.wrapping_add(56 as i32 as i64 as u64)
    stxdw [r10-0x288], r1                   
    mov64 r1, r0                                    r1 = r0
    add64 r1, 64                                    r1 += 64   ///  r1 = r1.wrapping_add(64 as i32 as i64 as u64)
    stxdw [r10-0x290], r1                   
    mov64 r1, r0                                    r1 = r0
    add64 r1, 72                                    r1 += 72   ///  r1 = r1.wrapping_add(72 as i32 as i64 as u64)
    stxdw [r10-0x298], r1                   
    stxdw [r10-0x250], r9                   
    ldxdw r9, [r9+0x0]                      
    ldxdw r1, [r9+0x28]                     
    lddw r3, 0xde8f75eee1f6dd06                     r3 load str located at -2409577606766207738
    stxdw [r10-0x2e8], r7                   
    stxdw [r10-0x240], r8                   
    jne r1, r3, lbb_3485                            if r1 != r3 { pc += 13 }
    ldxdw r1, [r9+0x30]                     
    lddw r3, 0xdacd6ce4bc5d4218                     r3 load str located at -2680366473547005416
    jne r1, r3, lbb_3485                            if r1 != r3 { pc += 9 }
    ldxdw r1, [r9+0x38]                     
    lddw r3, 0x270db9834dfc1ab6                     r3 load str located at 2814109315776649910
    jne r1, r3, lbb_3485                            if r1 != r3 { pc += 5 }
    ldxdw r1, [r9+0x40]                     
    lddw r3, 0xfc8ba1d828f9bdfe                     r3 load str located at -248927404616466946
    jne r1, r3, lbb_3485                            if r1 != r3 { pc += 1 }
    ldxdw r5, [r10-0x2a8]                   
lbb_3485:
    stxdw [r10-0x2a8], r5                   
    ldxdw r1, [r2+0x10]                     
    stxdw [r10-0x2f8], r1                   
    add64 r9, 8                                     r9 += 8   ///  r9 = r9.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x2a0], r6                   
    ldxdw r1, [r6+0x0]                      
    stxdw [r10-0x2e0], r1                   
    ldxdw r1, [r0+0x0]                      
    stxdw [r10-0x2b0], r1                   
    ldxdw r1, [r0+0x18]                     
    stxdw [r10-0x2b8], r1                   
    ldxdw r1, [r0+0x20]                     
    stxdw [r10-0x2c0], r1                   
    ldxdw r1, [r0+0x28]                     
    stxdw [r10-0x2c8], r1                   
    ldxdw r1, [r0+0x30]                     
    stxdw [r10-0x2d0], r1                   
    ldxdw r1, [r10-0x238]                   
    ldxdw r1, [r1+0x0]                      
    stxdw [r10-0x2d8], r1                   
    ldxdw r1, [r10-0x228]                   
    ldxdw r6, [r1+0x0]                      
    ldxdw r1, [r10-0x230]                   
    ldxdw r3, [r1+0x0]                      
    ldxdw r1, [r10-0x220]                   
    ldxdw r2, [r1+0x0]                      
    ldxdw r1, [r5+0x0]                      
    ldxdw r5, [r0+0x38]                     
    ldxdw r8, [r0+0x40]                     
    ldxdw r7, [r0+0x48]                     
    ldxdw r4, [r0+0x50]                     
    stxdw [r10-0x1f0], r9                   
    ldxdw r9, [r10-0x258]                   
    stxdw [r10-0x200], r9                   
    add64 r4, 8                                     r4 += 8   ///  r4 = r4.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x120], r4                   
    add64 r7, 8                                     r7 += 8   ///  r7 = r7.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x130], r7                   
    add64 r8, 8                                     r8 += 8   ///  r8 = r8.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x140], r8                   
    add64 r5, 8                                     r5 += 8   ///  r5 = r5.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x150], r5                   
    ldxdw r5, [r10-0x2e0]                   
    add64 r1, 8                                     r1 += 8   ///  r1 = r1.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x160], r1                   
    add64 r2, 8                                     r2 += 8   ///  r2 = r2.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x170], r2                   
    add64 r3, 8                                     r3 += 8   ///  r3 = r3.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x180], r3                   
    add64 r6, 8                                     r6 += 8   ///  r6 = r6.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x190], r6                   
    ldxdw r1, [r10-0x2d8]                   
    add64 r1, 8                                     r1 += 8   ///  r1 = r1.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x1a0], r1                   
    ldxdw r1, [r10-0x2d0]                   
    add64 r1, 8                                     r1 += 8   ///  r1 = r1.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x1b0], r1                   
    ldxdw r1, [r10-0x2c8]                   
    add64 r1, 8                                     r1 += 8   ///  r1 = r1.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x1c0], r1                   
    ldxdw r1, [r10-0x2c0]                   
    add64 r1, 8                                     r1 += 8   ///  r1 = r1.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x1d0], r1                   
    ldxdw r1, [r10-0x2b8]                   
    add64 r1, 8                                     r1 += 8   ///  r1 = r1.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x1e0], r1                   
    ldxdw r1, [r10-0x2b0]                   
    add64 r1, 8                                     r1 += 8   ///  r1 = r1.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x210], r1                   
    add64 r5, 8                                     r5 += 8   ///  r5 = r5.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0xf0], r5                    
    stxdw [r10-0x100], r5                   
    stxdw [r10-0x110], r5                   
    sth [r10-0xe8], 0                       
    sth [r10-0xf8], 0                       
    sth [r10-0x108], 0                      
    sth [r10-0x118], 0                      
    sth [r10-0x128], 0                      
    sth [r10-0x138], 1                      
    sth [r10-0x148], 0                      
    sth [r10-0x158], 0                      
    sth [r10-0x168], 0                      
    sth [r10-0x178], 257                    
    sth [r10-0x188], 1                      
    sth [r10-0x198], 1                      
    sth [r10-0x1a8], 1                      
    sth [r10-0x1b8], 1                      
    sth [r10-0x1c8], 1                      
    sth [r10-0x1d8], 1                      
    sth [r10-0x1e8], 0                      
    sth [r10-0x1f8], 0                      
    sth [r10-0x208], 1                      
    ldxdw r1, [r10-0x2a0]                   
    stxdw [r10-0x50], r1                    
    stxdw [r10-0x58], r1                    
    stxdw [r10-0x60], r1                    
    ldxdw r1, [r10-0x280]                   
    stxdw [r10-0x68], r1                    
    ldxdw r1, [r10-0x298]                   
    stxdw [r10-0x70], r1                    
    ldxdw r1, [r10-0x290]                   
    stxdw [r10-0x78], r1                    
    ldxdw r1, [r10-0x288]                   
    stxdw [r10-0x80], r1                    
    ldxdw r1, [r10-0x2a8]                   
    stxdw [r10-0x88], r1                    
    ldxdw r1, [r10-0x220]                   
    stxdw [r10-0x90], r1                    
    ldxdw r1, [r10-0x230]                   
    stxdw [r10-0x98], r1                    
    ldxdw r1, [r10-0x228]                   
    stxdw [r10-0xa0], r1                    
    ldxdw r1, [r10-0x238]                   
    stxdw [r10-0xa8], r1                    
    ldxdw r1, [r10-0x278]                   
    stxdw [r10-0xb0], r1                    
    ldxdw r1, [r10-0x270]                   
    stxdw [r10-0xb8], r1                    
    ldxdw r1, [r10-0x268]                   
    stxdw [r10-0xc0], r1                    
    ldxdw r1, [r10-0x260]                   
    stxdw [r10-0xc8], r1                    
    ldxdw r1, [r10-0x250]                   
    stxdw [r10-0xd0], r1                    
    ldxdw r1, [r10-0x248]                   
    stxdw [r10-0xd8], r1                    
    stxdw [r10-0xe0], r0                    
    ldxdw r3, [r10-0x240]                   
    jeq r3, 11, lbb_3629                            if r3 == (11 as i32 as i64 as u64) { pc += 15 }
    mov64 r1, r0                                    r1 = r0
    add64 r1, 88                                    r1 += 88   ///  r1 = r1.wrapping_add(88 as i32 as i64 as u64)
    ldxdw r2, [r1+0x0]                      
    stxdw [r10-0x58], r1                    
    add64 r2, 8                                     r2 += 8   ///  r2 = r2.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x100], r2                   
    sth [r10-0xf8], 1                       
    jeq r3, 12, lbb_3629                            if r3 == (12 as i32 as i64 as u64) { pc += 7 }
    ldxdw r1, [r0+0x60]                     
    add64 r0, 96                                    r0 += 96   ///  r0 = r0.wrapping_add(96 as i32 as i64 as u64)
    stxdw [r10-0x50], r0                    
    add64 r1, 8                                     r1 += 8   ///  r1 = r1.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0xf0], r1                    
    sth [r10-0xe8], 1                       
    jne r3, 13, lbb_3729                            if r3 != (13 as i32 as i64 as u64) { pc += 100 }
lbb_3629:
    ldxdw r1, [r10-0x2f8]                   
    stxdw [r10-0x40], r1                    
    lddw r1, 0xc88775e1919ec6f8                     r1 load str located at -3997096532596832520
    stxdw [r10-0x48], r1                    
    sth [r10-0x30], 0                       
    ldxdw r1, [r10-0x2f0]                   
    and64 r1, 1                                     r1 &= 1   ///  r1 = r1.and(1)
    stxb [r10-0x30], r1                     
    stdw [r10-0x38], 0                      
    ldxdw r4, [r10-0x2e8]                   
    jge r4, 20, lbb_3669                            if r4 >= (20 as i32 as i64 as u64) { pc += 28 }
    mov64 r1, r10                                   r1 = r10
    add64 r1, -528                                  r1 += -528   ///  r1 = r1.wrapping_add(-528 as i32 as i64 as u64)
    stxdw [r10-0x10], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -72                                   r1 += -72   ///  r1 = r1.wrapping_add(-72 as i32 as i64 as u64)
    stxdw [r10-0x20], r1                    
    stxdw [r10-0x28], r5                    
    stxdw [r10-0x8], r4                     
    stdw [r10-0x18], 26                     
    stdw [r10-0xff8], 0                     
    stdw [r10-0x1000], 8                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -536                                  r1 += -536   ///  r1 = r1.wrapping_add(-536 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -40                                   r2 += -40   ///  r2 = r2.wrapping_add(-40 as i32 as i64 as u64)
    mov64 r3, r10                                   r3 = r10
    add64 r3, -224                                  r3 += -224   ///  r3 = r3.wrapping_add(-224 as i32 as i64 as u64)
    mov64 r5, r10                                   r5 = r10
    call function_18367                     
    ldxw r2, [r10-0x214]                    
    ldxw r5, [r10-0x218]                    
    ldxdw r1, [r10-0x300]                   
lbb_3663:
    stxw [r1+0x4], r2                       
    stxw [r1+0x0], r5                       
    exit                                    
lbb_3666:
    ja lbb_3663                                     if true { pc += -4 }
lbb_3667:
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
    ja lbb_3663                                     if true { pc += -6 }
lbb_3669:
    mov64 r1, r4                                    r1 = r4
    mov64 r2, 19                                    r2 = 19 as i32 as i64 as u64
    lddw r3, 0x100025ca8 --> b"\x00\x00\x00\x00\xb8Y\x02\x00\x10\x00\x00\x00\x00\x00\x00\x00\x9c\x17\x00…        r3 load str located at 4295122088
    call function_18737                     
lbb_3674:
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    mov64 r2, 1                                     r2 = 1 as i32 as i64 as u64
    lddw r3, 0x100026548 --> b"\x00\x00\x00\x00\xb8Y\x02\x00\x10\x00\x00\x00\x00\x00\x00\x00\xb0 \x00\x0…        r3 load str located at 4295124296
    call function_18489                     
lbb_3679:
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
    lddw r3, 0x100026530 --> b"\x00\x00\x00\x00\xb8Y\x02\x00\x10\x00\x00\x00\x00\x00\x00\x00\xb0 \x00\x0…        r3 load str located at 4295124272
    call function_18489                     
lbb_3684:
    mov64 r1, 2                                     r1 = 2 as i32 as i64 as u64
    mov64 r2, 2                                     r2 = 2 as i32 as i64 as u64
    lddw r3, 0x100026560 --> b"\x00\x00\x00\x00\xb8Y\x02\x00\x10\x00\x00\x00\x00\x00\x00\x00\xb0 \x00\x0…        r3 load str located at 4295124320
    call function_18489                     
lbb_3689:
    mov64 r1, 3                                     r1 = 3 as i32 as i64 as u64
    mov64 r2, 3                                     r2 = 3 as i32 as i64 as u64
    lddw r3, 0x100026578 --> b"\x00\x00\x00\x00\xb8Y\x02\x00\x10\x00\x00\x00\x00\x00\x00\x00\xb0 \x00\x0…        r3 load str located at 4295124344
    call function_18489                     
lbb_3694:
    mov64 r1, 4                                     r1 = 4 as i32 as i64 as u64
    mov64 r2, 4                                     r2 = 4 as i32 as i64 as u64
    lddw r3, 0x100026590 --> b"\x00\x00\x00\x00\xb8Y\x02\x00\x10\x00\x00\x00\x00\x00\x00\x00\xb1 \x00\x0…        r3 load str located at 4295124368
    call function_18489                     
lbb_3699:
    mov64 r1, 5                                     r1 = 5 as i32 as i64 as u64
    mov64 r2, 5                                     r2 = 5 as i32 as i64 as u64
    lddw r3, 0x1000265a8 --> b"\x00\x00\x00\x00\xb8Y\x02\x00\x10\x00\x00\x00\x00\x00\x00\x00\xb1 \x00\x0…        r3 load str located at 4295124392
    call function_18489                     
lbb_3704:
    mov64 r1, 6                                     r1 = 6 as i32 as i64 as u64
    mov64 r2, 6                                     r2 = 6 as i32 as i64 as u64
    lddw r3, 0x1000265c0 --> b"\x00\x00\x00\x00\xb8Y\x02\x00\x10\x00\x00\x00\x00\x00\x00\x00\xb1 \x00\x0…        r3 load str located at 4295124416
    call function_18489                     
lbb_3709:
    mov64 r1, 7                                     r1 = 7 as i32 as i64 as u64
    mov64 r2, 7                                     r2 = 7 as i32 as i64 as u64
    lddw r3, 0x1000265d8 --> b"\x00\x00\x00\x00\xb8Y\x02\x00\x10\x00\x00\x00\x00\x00\x00\x00\xb1 \x00\x0…        r3 load str located at 4295124440
    call function_18489                     
lbb_3714:
    mov64 r1, 8                                     r1 = 8 as i32 as i64 as u64
    mov64 r2, 8                                     r2 = 8 as i32 as i64 as u64
    lddw r3, 0x1000265f0 --> b"\x00\x00\x00\x00\xb8Y\x02\x00\x10\x00\x00\x00\x00\x00\x00\x00\xb2 \x00\x0…        r3 load str located at 4295124464
    call function_18489                     
lbb_3719:
    mov64 r1, 9                                     r1 = 9 as i32 as i64 as u64
    mov64 r2, 9                                     r2 = 9 as i32 as i64 as u64
    lddw r3, 0x100026608 --> b"\x00\x00\x00\x00\xb8Y\x02\x00\x10\x00\x00\x00\x00\x00\x00\x00\xb2 \x00\x0…        r3 load str located at 4295124488
    call function_18489                     
lbb_3724:
    mov64 r1, 10                                    r1 = 10 as i32 as i64 as u64
    mov64 r2, 10                                    r2 = 10 as i32 as i64 as u64
    lddw r3, 0x100026620 --> b"\x00\x00\x00\x00\xb8Y\x02\x00\x10\x00\x00\x00\x00\x00\x00\x00\xb2 \x00\x0…        r3 load str located at 4295124512
    call function_18489                     
lbb_3729:
    mov64 r1, 19                                    r1 = 19 as i32 as i64 as u64
    mov64 r2, 19                                    r2 = 19 as i32 as i64 as u64
    lddw r3, 0x100025cc0 --> b"\x00\x00\x00\x00\xb8Y\x02\x00\x10\x00\x00\x00\x00\x00\x00\x00\x8d\x17\x00…        r3 load str located at 4295122112
    call function_18489                     
    ldxdw r3, [r2+0x8]                      
    jeq r3, 1, lbb_3996                             if r3 == (1 as i32 as i64 as u64) { pc += 260 }
    jeq r3, 0, lbb_4001                             if r3 == (0 as i32 as i64 as u64) { pc += 264 }
    jle r3, 2, lbb_4006                             if r3 <= (2 as i32 as i64 as u64) { pc += 268 }
    jeq r3, 3, lbb_4011                             if r3 == (3 as i32 as i64 as u64) { pc += 272 }
    jle r3, 4, lbb_4016                             if r3 <= (4 as i32 as i64 as u64) { pc += 276 }
    ldxdw r0, [r2+0x50]                     
    mov64 r3, 3                                     r3 = 3 as i32 as i64 as u64
    ldxdw r9, [r0+0x0]                      
    ldxdw r4, [r9+0x50]                     
    jlt r4, 32, lbb_3993                            if r4 < (32 as i32 as i64 as u64) { pc += 248 }
    ldxdw r8, [r2+0x0]                      
    mov64 r4, r8                                    r4 = r8
    add64 r4, 16                                    r4 += 16   ///  r4 = r4.wrapping_add(16 as i32 as i64 as u64)
    stxdw [r10-0x3a8], r4                   
    ldxdw r5, [r4+0x0]                      
    ldxdw r4, [r5+0x50]                     
    jlt r4, 32, lbb_3993                            if r4 < (32 as i32 as i64 as u64) { pc += 241 }
    ldxdw r4, [r2+0x58]                     
    stxdw [r10-0x3a0], r4                   
    ldxdw r4, [r2+0x48]                     
    stxdw [r10-0x3b0], r4                   
    ldxdw r4, [r2+0x28]                     
    stxdw [r10-0x3c0], r4                   
    ldxdw r4, [r2+0x20]                     
    stxdw [r10-0x3b8], r4                   
    mov64 r4, r8                                    r4 = r8
    add64 r4, 24                                    r4 += 24   ///  r4 = r4.wrapping_add(24 as i32 as i64 as u64)
    ldxdw r6, [r5+0x58]                     
    ldxdw r7, [r9+0x58]                     
    stxdw [r10-0x3c8], r9                   
    stxdw [r10-0x3e0], r1                   
    stxdw [r10-0x3e8], r0                   
    jne r7, r6, lbb_3780                            if r7 != r6 { pc += 12 }
    ldxdw r6, [r5+0x60]                     
    ldxdw r7, [r9+0x60]                     
    jne r7, r6, lbb_3780                            if r7 != r6 { pc += 9 }
    ldxdw r6, [r5+0x68]                     
    ldxdw r7, [r9+0x68]                     
    jne r7, r6, lbb_3780                            if r7 != r6 { pc += 6 }
    ldxdw r5, [r5+0x70]                     
    ldxdw r6, [r9+0x70]                     
    jne r6, r5, lbb_3780                            if r6 != r5 { pc += 3 }
    ldxdw r0, [r10-0x3a8]                   
    stxdw [r10-0x3a8], r4                   
    ja lbb_3781                                     if true { pc += 1 }
lbb_3780:
    mov64 r0, r4                                    r0 = r4
lbb_3781:
    ldxdw r4, [r10-0x3b0]                   
    ldxdw r1, [r2+0x10]                     
    stxdw [r10-0x400], r1                   
    ldxdw r1, [r10-0x3b8]                   
    ldxdw r7, [r1+0x0]                      
    ldxdw r1, [r4+0x0]                      
    stxdw [r10-0x3d0], r1                   
    ldxdw r1, [r10-0x3a0]                   
    ldxdw r5, [r1+0x0]                      
    ldxdw r2, [r10-0x3c0]                   
    ldxdw r6, [r2+0x0]                      
    stxdw [r10-0x3f8], r0                   
    ldxdw r9, [r0+0x0]                      
    ldxdw r2, [r10-0x3a8]                   
    ldxdw r0, [r2+0x0]                      
    ldxdw r1, [r8+0x0]                      
    stxdw [r10-0x3d8], r1                   
    ldxdw r2, [r8+0x8]                      
    stxdw [r10-0x3f0], r8                   
    ldxdw r8, [r8+0x20]                     
    ldxdw r1, [r10-0x3c8]                   
    mov64 r4, r1                                    r4 = r1
    add64 r4, 8                                     r4 += 8   ///  r4 = r4.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x358], r4                   
    add64 r8, 8                                     r8 += 8   ///  r8 = r8.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x308], r8                   
    add64 r0, 8                                     r0 += 8   ///  r0 = r0.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x318], r0                   
    add64 r9, 8                                     r9 += 8   ///  r9 = r9.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x328], r9                   
    ldxdw r4, [r10-0x3a0]                   
    add64 r6, 8                                     r6 += 8   ///  r6 = r6.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x338], r6                   
    add64 r5, 8                                     r5 += 8   ///  r5 = r5.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x348], r5                   
    add64 r2, 8                                     r2 += 8   ///  r2 = r2.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x368], r2                   
    ldxdw r2, [r10-0x3d8]                   
    add64 r2, 8                                     r2 += 8   ///  r2 = r2.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x378], r2                   
    ldxdw r2, [r10-0x3d0]                   
    add64 r2, 8                                     r2 += 8   ///  r2 = r2.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x388], r2                   
    add64 r7, 8                                     r7 += 8   ///  r7 = r7.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x3d0], r7                   
    stxdw [r10-0x398], r7                   
    sth [r10-0x300], 0                      
    sth [r10-0x310], 1                      
    sth [r10-0x320], 1                      
    sth [r10-0x330], 0                      
    sth [r10-0x340], 1                      
    sth [r10-0x350], 1                      
    sth [r10-0x360], 0                      
    sth [r10-0x370], 1                      
    sth [r10-0x380], 257                    
    sth [r10-0x390], 0                      
    ldxdw r1, [r1+0x50]                     
    jlt r1, 32, lbb_3992                            if r1 < (32 as i32 as i64 as u64) { pc += 153 }
    ldxdw r7, [r4+0x0]                      
    ldxdw r1, [r7+0x50]                     
    jlt r1, 32, lbb_3992                            if r1 < (32 as i32 as i64 as u64) { pc += 150 }
    ldxdw r8, [r10-0x3f0]                   
    mov64 r5, r8                                    r5 = r8
    add64 r5, 32                                    r5 += 32   ///  r5 = r5.wrapping_add(32 as i32 as i64 as u64)
    mov64 r3, r8                                    r3 = r8
    add64 r3, 8                                     r3 += 8   ///  r3 = r3.wrapping_add(8 as i32 as i64 as u64)
    ldxdw r9, [r10-0x3c8]                   
    mov64 r1, r9                                    r1 = r9
    add64 r1, 88                                    r1 += 88   ///  r1 = r1.wrapping_add(88 as i32 as i64 as u64)
    ldxw r2, [r9+0x5f]                      
    ldxw r4, [r9+0x5b]                      
    ldxdw r0, [r7+0x5b]                     
    ldxdw r6, [r10-0x400]                   
    stxdw [r10-0x2f1], r6                   
    stb [r10-0x2f2], 4                      
    ldxh r6, [r1+0x0]                       
    stxh [r10-0x2e9], r6                    
    ldxb r1, [r1+0x2]                       
    stxb [r10-0x2e7], r1                    
    stxw [r10-0x2e2], r2                    
    stxw [r10-0x2e6], r4                    
    ldxdw r1, [r9+0x63]                     
    stxdw [r10-0x2de], r1                   
    ldxdw r1, [r9+0x6b]                     
    stxdw [r10-0x2d6], r1                   
    ldxdw r1, [r9+0x70]                     
    stxdw [r10-0x2d1], r1                   
    ldxh r1, [r7+0x58]                      
    stxh [r10-0x2c9], r1                    
    ldxb r1, [r7+0x5a]                      
    stxb [r10-0x2c7], r1                    
    stxdw [r10-0x2c6], r0                   
    ldxdw r1, [r7+0x63]                     
    stxdw [r10-0x2be], r1                   
    ldxdw r1, [r7+0x6b]                     
    stxdw [r10-0x2b6], r1                   
    ldxdw r1, [r7+0x70]                     
    stxdw [r10-0x2b1], r1                   
    stb [r10-0x2a9], 0                      
    stxdw [r10-0x260], r5                   
    ldxdw r1, [r10-0x3a8]                   
    stxdw [r10-0x268], r1                   
    ldxdw r1, [r10-0x3f8]                   
    stxdw [r10-0x270], r1                   
    ldxdw r1, [r10-0x3c0]                   
    stxdw [r10-0x278], r1                   
    ldxdw r1, [r10-0x3a0]                   
    stxdw [r10-0x280], r1                   
    ldxdw r1, [r10-0x3e8]                   
    stxdw [r10-0x288], r1                   
    stxdw [r10-0x290], r3                   
    stxdw [r10-0x298], r8                   
    ldxdw r1, [r10-0x3b0]                   
    stxdw [r10-0x2a0], r1                   
    ldxdw r1, [r10-0x3b8]                   
    stxdw [r10-0x2a8], r1                   
    mov64 r2, r10                                   r2 = r10
    add64 r2, -680                                  r2 += -680   ///  r2 = r2.wrapping_add(-680 as i32 as i64 as u64)
    mov64 r4, 0                                     r4 = 0 as i32 as i64 as u64
    mov64 r5, r10                                   r5 = r10
    add64 r5, -912                                  r5 += -912   ///  r5 = r5.wrapping_add(-912 as i32 as i64 as u64)
    ja lbb_3923                                     if true { pc += 20 }
lbb_3903:
    mov64 r7, r10                                   r7 = r10
    add64 r7, -600                                  r7 += -600   ///  r7 = r7.wrapping_add(-600 as i32 as i64 as u64)
    add64 r7, r4                                    r7 += r4   ///  r7 = r7.wrapping_add(r4)
    stxb [r7+0x32], r6                      
    stxb [r7+0x31], r8                      
    stxb [r7+0x30], r1                      
    mov64 r1, r0                                    r1 = r0
    add64 r1, 40                                    r1 += 40   ///  r1 = r1.wrapping_add(40 as i32 as i64 as u64)
    stxdw [r7+0x20], r1                     
    mov64 r1, r0                                    r1 = r0
    add64 r1, 88                                    r1 += 88   ///  r1 = r1.wrapping_add(88 as i32 as i64 as u64)
    stxdw [r7+0x18], r1                     
    stxdw [r7+0x10], r3                     
    add64 r0, 72                                    r0 += 72   ///  r0 = r0.wrapping_add(72 as i32 as i64 as u64)
    stxdw [r7+0x8], r0                      
    stdw [r7+0x28], 0                       
    add64 r5, 16                                    r5 += 16   ///  r5 = r5.wrapping_add(16 as i32 as i64 as u64)
    add64 r2, 8                                     r2 += 8   ///  r2 = r2.wrapping_add(8 as i32 as i64 as u64)
    add64 r4, 56                                    r4 += 56   ///  r4 = r4.wrapping_add(56 as i32 as i64 as u64)
    jeq r4, 560, lbb_3973                           if r4 == (560 as i32 as i64 as u64) { pc += 50 }
lbb_3923:
    mov64 r6, r10                                   r6 = r10
    add64 r6, -600                                  r6 += -600   ///  r6 = r6.wrapping_add(-600 as i32 as i64 as u64)
    mov64 r3, 1                                     r3 = 1 as i32 as i64 as u64
    ldxdw r1, [r2+0x0]                      
    ldxdw r0, [r1+0x0]                      
    ldxdw r1, [r5-0x8]                      
    ldxdw r7, [r1+0x0]                      
    ldxdw r8, [r0+0x8]                      
    jne r8, r7, lbb_3992                            if r8 != r7 { pc += 60 }
    ldxdw r7, [r1+0x8]                      
    ldxdw r8, [r0+0x10]                     
    jne r8, r7, lbb_3992                            if r8 != r7 { pc += 57 }
    ldxdw r7, [r1+0x10]                     
    ldxdw r8, [r0+0x18]                     
    jne r8, r7, lbb_3992                            if r8 != r7 { pc += 54 }
    ldxdw r1, [r1+0x18]                     
    ldxdw r7, [r0+0x20]                     
    jne r7, r1, lbb_3992                            if r7 != r1 { pc += 51 }
    ldxb r3, [r5+0x0]                       
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    jne r3, 0, lbb_3945                             if r3 != (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r1, 119                                   r1 = 119 as i32 as i64 as u64
lbb_3945:
    ldxb r3, [r0+0x0]                       
    or64 r1, r3                                     r1 |= r3   ///  r1 = r1.or(r3)
    and64 r1, 255                                   r1 &= 255   ///  r1 = r1.and(255)
    jne r1, 255, lbb_3971                           if r1 != (255 as i32 as i64 as u64) { pc += 22 }
    add64 r6, r4                                    r6 += r4   ///  r6 = r6.wrapping_add(r4)
    mov64 r1, r0                                    r1 = r0
    add64 r1, 8                                     r1 += 8   ///  r1 = r1.wrapping_add(8 as i32 as i64 as u64)
    ldxdw r3, [r0+0x50]                     
    ldxb r7, [r0+0x3]                       
    ldxb r9, [r0+0x2]                       
    ldxb r8, [r0+0x1]                       
    stxdw [r6+0x0], r1                      
    mov64 r6, 1                                     r6 = 1 as i32 as i64 as u64
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    jeq r8, 0, lbb_3964                             if r8 == (0 as i32 as i64 as u64) { pc += 4 }
    mov64 r8, 1                                     r8 = 1 as i32 as i64 as u64
    jeq r9, 0, lbb_3967                             if r9 == (0 as i32 as i64 as u64) { pc += 5 }
lbb_3962:
    jne r7, 0, lbb_3903                             if r7 != (0 as i32 as i64 as u64) { pc += -60 }
    ja lbb_3969                                     if true { pc += 5 }
lbb_3964:
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    mov64 r8, 1                                     r8 = 1 as i32 as i64 as u64
    jne r9, 0, lbb_3962                             if r9 != (0 as i32 as i64 as u64) { pc += -5 }
lbb_3967:
    mov64 r8, 0                                     r8 = 0 as i32 as i64 as u64
    jne r7, 0, lbb_3903                             if r7 != (0 as i32 as i64 as u64) { pc += -66 }
lbb_3969:
    mov64 r6, 0                                     r6 = 0 as i32 as i64 as u64
    ja lbb_3903                                     if true { pc += -68 }
lbb_3971:
    mov64 r3, 11                                    r3 = 11 as i32 as i64 as u64
    ja lbb_3992                                     if true { pc += 19 }
lbb_3973:
    mov64 r1, r10                                   r1 = r10
    add64 r1, -754                                  r1 += -754   ///  r1 = r1.wrapping_add(-754 as i32 as i64 as u64)
    stxdw [r10-0x10], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -920                                  r1 += -920   ///  r1 = r1.wrapping_add(-920 as i32 as i64 as u64)
    stxdw [r10-0x20], r1                    
    ldxdw r1, [r10-0x3d0]                   
    stxdw [r10-0x28], r1                    
    stdw [r10-0x8], 74                      
    stdw [r10-0x18], 10                     
    mov64 r1, r10                                   r1 = r10
    add64 r1, -40                                   r1 += -40   ///  r1 = r1.wrapping_add(-40 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -600                                  r2 += -600   ///  r2 = r2.wrapping_add(-600 as i32 as i64 as u64)
    mov64 r3, 10                                    r3 = 10 as i32 as i64 as u64
    mov64 r4, 8                                     r4 = 8 as i32 as i64 as u64
    mov64 r5, 0                                     r5 = 0 as i32 as i64 as u64
    syscall [invalid]                       
    mov64 r3, 26                                    r3 = 26 as i32 as i64 as u64
lbb_3992:
    ldxdw r1, [r10-0x3e0]                   
lbb_3993:
    stxw [r1+0x0], r3                       
    stw [r1+0x4], 0                         
    exit                                    
lbb_3996:
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    mov64 r2, 1                                     r2 = 1 as i32 as i64 as u64
    lddw r3, 0x100026650 --> b"\x00\x00\x00\x00\xb8Y\x02\x00\x10\x00\x00\x00\x00\x00\x00\x00\xc3 \x00\x0…        r3 load str located at 4295124560
    call function_18489                     
lbb_4001:
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
    lddw r3, 0x100026638 --> b"\x00\x00\x00\x00\xb8Y\x02\x00\x10\x00\x00\x00\x00\x00\x00\x00\xc3 \x00\x0…        r3 load str located at 4295124536
    call function_18489                     
lbb_4006:
    mov64 r1, 2                                     r1 = 2 as i32 as i64 as u64
    mov64 r2, 2                                     r2 = 2 as i32 as i64 as u64
    lddw r3, 0x100026668 --> b"\x00\x00\x00\x00\xb8Y\x02\x00\x10\x00\x00\x00\x00\x00\x00\x00\xc3 \x00\x0…        r3 load str located at 4295124584
    call function_18489                     
lbb_4011:
    mov64 r1, 3                                     r1 = 3 as i32 as i64 as u64
    mov64 r2, 3                                     r2 = 3 as i32 as i64 as u64
    lddw r3, 0x100026680 --> b"\x00\x00\x00\x00\xb8Y\x02\x00\x10\x00\x00\x00\x00\x00\x00\x00\xc3 \x00\x0…        r3 load str located at 4295124608
    call function_18489                     
lbb_4016:
    mov64 r1, 4                                     r1 = 4 as i32 as i64 as u64
    mov64 r2, 4                                     r2 = 4 as i32 as i64 as u64
    lddw r3, 0x100026698 --> b"\x00\x00\x00\x00\xb8Y\x02\x00\x10\x00\x00\x00\x00\x00\x00\x00\xc4 \x00\x0…        r3 load str located at 4295124632
    call function_18489                     
    ldxdw r3, [r2+0x8]                      
    jeq r3, 1, lbb_4322                             if r3 == (1 as i32 as i64 as u64) { pc += 299 }
    jeq r3, 0, lbb_4327                             if r3 == (0 as i32 as i64 as u64) { pc += 303 }
    jle r3, 2, lbb_4332                             if r3 <= (2 as i32 as i64 as u64) { pc += 307 }
    jeq r3, 3, lbb_4337                             if r3 == (3 as i32 as i64 as u64) { pc += 311 }
    jle r3, 4, lbb_4342                             if r3 <= (4 as i32 as i64 as u64) { pc += 315 }
    jeq r3, 5, lbb_4347                             if r3 == (5 as i32 as i64 as u64) { pc += 319 }
    jle r3, 6, lbb_4352                             if r3 <= (6 as i32 as i64 as u64) { pc += 323 }
    ldxdw r3, [r2+0x50]                     
    stxdw [r10-0x410], r3                   
    ldxdw r5, [r3+0x0]                      
    ldxdw r3, [r5+0x50]                     
    jlt r3, 32, lbb_4320                            if r3 < (32 as i32 as i64 as u64) { pc += 286 }
    ldxdw r7, [r2+0x0]                      
    ldxdw r4, [r2+0x58]                     
    ldxdw r3, [r7+0x20]                     
    mov64 r0, r3                                    r0 = r3
    add64 r0, 8                                     r0 += 8   ///  r0 = r0.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x428], r0                   
    ldxdw r0, [r0+0x0]                      
    ldxdw r6, [r5+0x58]                     
    jne r6, r0, lbb_4059                            if r6 != r0 { pc += 16 }
    ldxdw r0, [r3+0x10]                     
    ldxdw r6, [r5+0x60]                     
    jne r6, r0, lbb_4059                            if r6 != r0 { pc += 13 }
    ldxdw r0, [r3+0x18]                     
    ldxdw r6, [r5+0x68]                     
    jne r6, r0, lbb_4059                            if r6 != r0 { pc += 10 }
    ldxdw r0, [r3+0x20]                     
    ldxdw r5, [r5+0x70]                     
    mov64 r6, 1                                     r6 = 1 as i32 as i64 as u64
    jeq r5, r0, lbb_4054                            if r5 == r0 { pc += 1 }
    mov64 r6, 0                                     r6 = 0 as i32 as i64 as u64
lbb_4054:
    stxdw [r10-0x420], r6                   
    jne r5, r0, lbb_4061                            if r5 != r0 { pc += 5 }
    ldxdw r6, [r10-0x410]                   
    stxdw [r10-0x410], r4                   
    ja lbb_4062                                     if true { pc += 3 }
lbb_4059:
    mov64 r5, 0                                     r5 = 0 as i32 as i64 as u64
    stxdw [r10-0x420], r5                   
lbb_4061:
    mov64 r6, r4                                    r6 = r4
lbb_4062:
    ldxdw r9, [r2+0x30]                     
    ldxdw r8, [r2+0x28]                     
    mov64 r0, r7                                    r0 = r7
    add64 r0, 40                                    r0 += 40   ///  r0 = r0.wrapping_add(40 as i32 as i64 as u64)
    ldxdw r4, [r3+0x28]                     
    lddw r5, 0xde8f75eee1f6dd06                     r5 load str located at -2409577606766207738
    stxdw [r10-0x408], r8                   
    jne r4, r5, lbb_4087                            if r4 != r5 { pc += 16 }
    ldxdw r4, [r3+0x30]                     
    lddw r5, 0xdacd6ce4bc5d4218                     r5 load str located at -2680366473547005416
    stxdw [r10-0x408], r8                   
    jne r4, r5, lbb_4087                            if r4 != r5 { pc += 11 }
    ldxdw r4, [r3+0x38]                     
    lddw r5, 0x270db9834dfc1ab6                     r5 load str located at 2814109315776649910
    stxdw [r10-0x408], r8                   
    jne r4, r5, lbb_4087                            if r4 != r5 { pc += 6 }
    ldxdw r3, [r3+0x40]                     
    lddw r4, 0xfc8ba1d828f9bdfe                     r4 load str located at -248927404616466946
    stxdw [r10-0x408], r8                   
    jne r3, r4, lbb_4087                            if r3 != r4 { pc += 1 }
    stxdw [r10-0x408], r9                   
lbb_4087:
    stxdw [r10-0x470], r9                   
    ldxdw r9, [r2+0x48]                     
    ldxdw r3, [r2+0x20]                     
    stxdw [r10-0x448], r3                   
    ldxdw r2, [r2+0x10]                     
    stxdw [r10-0x468], r2                   
    mov64 r2, r7                                    r2 = r7
    add64 r2, 48                                    r2 += 48   ///  r2 = r2.wrapping_add(48 as i32 as i64 as u64)
    stxdw [r10-0x458], r2                   
    mov64 r2, r7                                    r2 = r7
    add64 r2, 8                                     r2 += 8   ///  r2 = r2.wrapping_add(8 as i32 as i64 as u64)
    mov64 r3, r7                                    r3 = r7
    add64 r3, 16                                    r3 += 16   ///  r3 = r3.wrapping_add(16 as i32 as i64 as u64)
    stxdw [r10-0x440], r3                   
    mov64 r3, r7                                    r3 = r7
    add64 r3, 24                                    r3 += 24   ///  r3 = r3.wrapping_add(24 as i32 as i64 as u64)
    stxdw [r10-0x450], r3                   
    mov64 r3, r7                                    r3 = r7
    add64 r3, 32                                    r3 += 32   ///  r3 = r3.wrapping_add(32 as i32 as i64 as u64)
    stxdw [r10-0x460], r3                   
    ldxdw r5, [r0+0x0]                      
    ldxdw r3, [r5+0x28]                     
    lddw r4, 0xde8f75eee1f6dd06                     r4 load str located at -2409577606766207738
    stxdw [r10-0x418], r1                   
    stxdw [r10-0x430], r0                   
    stxdw [r10-0x438], r2                   
    jne r3, r4, lbb_4130                            if r3 != r4 { pc += 15 }
    ldxdw r3, [r5+0x30]                     
    lddw r4, 0xdacd6ce4bc5d4218                     r4 load str located at -2680366473547005416
    jne r3, r4, lbb_4130                            if r3 != r4 { pc += 11 }
    ldxdw r3, [r5+0x38]                     
    lddw r4, 0x270db9834dfc1ab6                     r4 load str located at 2814109315776649910
    jne r3, r4, lbb_4130                            if r3 != r4 { pc += 7 }
    ldxdw r3, [r5+0x40]                     
    lddw r4, 0xfc8ba1d828f9bdfe                     r4 load str located at -248927404616466946
    mov64 r1, r8                                    r1 = r8
    jne r3, r4, lbb_4131                            if r3 != r4 { pc += 3 }
    ldxdw r1, [r10-0x470]                   
    ja lbb_4131                                     if true { pc += 1 }
lbb_4130:
    mov64 r1, r8                                    r1 = r8
lbb_4131:
    add64 r5, 8                                     r5 += 8   ///  r5 = r5.wrapping_add(8 as i32 as i64 as u64)
    ldxdw r2, [r7+0x0]                      
    stxdw [r10-0x488], r2                   
    ldxdw r2, [r7+0x8]                      
    stxdw [r10-0x490], r2                   
    ldxdw r0, [r9+0x0]                      
    mov64 r3, r7                                    r3 = r7
    ldxdw r7, [r3+0x10]                     
    ldxdw r8, [r3+0x18]                     
    ldxdw r4, [r6+0x0]                      
    stxdw [r10-0x478], r6                   
    stxdw [r10-0x470], r9                   
    ldxdw r2, [r10-0x410]                   
    ldxdw r6, [r2+0x0]                      
    ldxdw r2, [r10-0x408]                   
    ldxdw r2, [r2+0x0]                      
    stxdw [r10-0x480], r1                   
    ldxdw r1, [r1+0x0]                      
    ldxdw r9, [r3+0x30]                     
    stxdw [r10-0x380], r5                   
    ldxdw r5, [r10-0x428]                   
    stxdw [r10-0x390], r5                   
    add64 r9, 8                                     r9 += 8   ///  r9 = r9.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x350], r9                   
    add64 r1, 8                                     r1 += 8   ///  r1 = r1.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x360], r1                   
    add64 r2, 8                                     r2 += 8   ///  r2 = r2.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x370], r2                   
    add64 r6, 8                                     r6 += 8   ///  r6 = r6.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x3a0], r6                   
    add64 r4, 8                                     r4 += 8   ///  r4 = r4.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x3b0], r4                   
    add64 r8, 8                                     r8 += 8   ///  r8 = r8.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x3c0], r8                   
    add64 r7, 8                                     r7 += 8   ///  r7 = r7.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x3d0], r7                   
    add64 r0, 8                                     r0 += 8   ///  r0 = r0.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x3e0], r0                   
    ldxdw r1, [r10-0x490]                   
    add64 r1, 8                                     r1 += 8   ///  r1 = r1.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x3f0], r1                   
    ldxdw r1, [r10-0x488]                   
    add64 r1, 8                                     r1 += 8   ///  r1 = r1.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x400], r1                   
    sth [r10-0x348], 0                      
    sth [r10-0x358], 0                      
    sth [r10-0x368], 0                      
    sth [r10-0x378], 0                      
    sth [r10-0x388], 0                      
    sth [r10-0x398], 1                      
    sth [r10-0x3a8], 1                      
    sth [r10-0x3b8], 1                      
    sth [r10-0x3c8], 1                      
    sth [r10-0x3d8], 257                    
    sth [r10-0x3e8], 1                      
    sth [r10-0x3f8], 0                      
    ldxdw r1, [r10-0x468]                   
    stxdw [r10-0x338], r1                   
    ldxdw r1, [r10-0x420]                   
    and64 r1, 1                                     r1 &= 1   ///  r1 = r1.and(1)
    stxb [r10-0x339], r1                    
    stb [r10-0x33a], 16                     
    stdw [r10-0x330], 0                     
    ldxdw r1, [r10-0x448]                   
    ldxdw r2, [r1+0x0]                      
    ldxdw r1, [r10-0x458]                   
    stxdw [r10-0x2d0], r1                   
    ldxdw r1, [r10-0x480]                   
    stxdw [r10-0x2d8], r1                   
    ldxdw r1, [r10-0x408]                   
    stxdw [r10-0x2e0], r1                   
    ldxdw r1, [r10-0x430]                   
    stxdw [r10-0x2e8], r1                   
    ldxdw r1, [r10-0x460]                   
    stxdw [r10-0x2f0], r1                   
    ldxdw r1, [r10-0x410]                   
    stxdw [r10-0x2f8], r1                   
    ldxdw r1, [r10-0x478]                   
    stxdw [r10-0x300], r1                   
    ldxdw r1, [r10-0x450]                   
    stxdw [r10-0x308], r1                   
    ldxdw r1, [r10-0x440]                   
    stxdw [r10-0x310], r1                   
    ldxdw r1, [r10-0x470]                   
    stxdw [r10-0x318], r1                   
    ldxdw r1, [r10-0x438]                   
    stxdw [r10-0x320], r1                   
    stxdw [r10-0x328], r3                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -808                                  r1 += -808   ///  r1 = r1.wrapping_add(-808 as i32 as i64 as u64)
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
    mov64 r4, r10                                   r4 = r10
    add64 r4, -1016                                 r4 += -1016   ///  r4 = r4.wrapping_add(-1016 as i32 as i64 as u64)
    add64 r2, 8                                     r2 += 8   ///  r2 = r2.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x408], r2                   
    ja lbb_4247                                     if true { pc += 20 }
lbb_4227:
    mov64 r0, r10                                   r0 = r10
    add64 r0, -712                                  r0 += -712   ///  r0 = r0.wrapping_add(-712 as i32 as i64 as u64)
    add64 r0, r3                                    r0 += r3   ///  r0 = r0.wrapping_add(r3)
    stxb [r0+0x32], r7                      
    stxb [r0+0x31], r9                      
    stxb [r0+0x30], r5                      
    mov64 r5, r2                                    r5 = r2
    add64 r5, 40                                    r5 += 40   ///  r5 = r5.wrapping_add(40 as i32 as i64 as u64)
    stxdw [r0+0x20], r5                     
    mov64 r5, r2                                    r5 = r2
    add64 r5, 88                                    r5 += 88   ///  r5 = r5.wrapping_add(88 as i32 as i64 as u64)
    stxdw [r0+0x18], r5                     
    stxdw [r0+0x10], r6                     
    add64 r2, 72                                    r2 += 72   ///  r2 = r2.wrapping_add(72 as i32 as i64 as u64)
    stxdw [r0+0x8], r2                      
    stdw [r0+0x28], 0                       
    add64 r4, 16                                    r4 += 16   ///  r4 = r4.wrapping_add(16 as i32 as i64 as u64)
    add64 r1, 8                                     r1 += 8   ///  r1 = r1.wrapping_add(8 as i32 as i64 as u64)
    add64 r3, 56                                    r3 += 56   ///  r3 = r3.wrapping_add(56 as i32 as i64 as u64)
    jeq r3, 672, lbb_4297                           if r3 == (672 as i32 as i64 as u64) { pc += 50 }
lbb_4247:
    mov64 r5, r10                                   r5 = r10
    add64 r5, -712                                  r5 += -712   ///  r5 = r5.wrapping_add(-712 as i32 as i64 as u64)
    mov64 r6, 1                                     r6 = 1 as i32 as i64 as u64
    ldxdw r2, [r1+0x0]                      
    ldxdw r2, [r2+0x0]                      
    ldxdw r7, [r4-0x8]                      
    ldxdw r0, [r7+0x0]                      
    ldxdw r8, [r2+0x8]                      
    jne r8, r0, lbb_4316                            if r8 != r0 { pc += 60 }
    ldxdw r0, [r7+0x8]                      
    ldxdw r8, [r2+0x10]                     
    jne r8, r0, lbb_4316                            if r8 != r0 { pc += 57 }
    ldxdw r0, [r7+0x10]                     
    ldxdw r8, [r2+0x18]                     
    jne r8, r0, lbb_4316                            if r8 != r0 { pc += 54 }
    ldxdw r0, [r7+0x18]                     
    ldxdw r7, [r2+0x20]                     
    jne r7, r0, lbb_4316                            if r7 != r0 { pc += 51 }
    ldxb r6, [r4+0x0]                       
    mov64 r0, 0                                     r0 = 0 as i32 as i64 as u64
    jne r6, 0, lbb_4269                             if r6 != (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r0, 119                                   r0 = 119 as i32 as i64 as u64
lbb_4269:
    ldxb r6, [r2+0x0]                       
    or64 r0, r6                                     r0 |= r6   ///  r0 = r0.or(r6)
    and64 r0, 255                                   r0 &= 255   ///  r0 = r0.and(255)
    jne r0, 255, lbb_4295                           if r0 != (255 as i32 as i64 as u64) { pc += 22 }
    add64 r5, r3                                    r5 += r3   ///  r5 = r5.wrapping_add(r3)
    mov64 r7, r2                                    r7 = r2
    add64 r7, 8                                     r7 += 8   ///  r7 = r7.wrapping_add(8 as i32 as i64 as u64)
    ldxdw r6, [r2+0x50]                     
    ldxb r8, [r2+0x3]                       
    ldxb r0, [r2+0x2]                       
    ldxb r9, [r2+0x1]                       
    stxdw [r5+0x0], r7                      
    mov64 r7, 1                                     r7 = 1 as i32 as i64 as u64
    mov64 r5, 1                                     r5 = 1 as i32 as i64 as u64
    jne r9, 0, lbb_4289                             if r9 != (0 as i32 as i64 as u64) { pc += 5 }
    mov64 r5, 0                                     r5 = 0 as i32 as i64 as u64
    mov64 r9, 1                                     r9 = 1 as i32 as i64 as u64
    jeq r0, 0, lbb_4291                             if r0 == (0 as i32 as i64 as u64) { pc += 4 }
lbb_4287:
    jne r8, 0, lbb_4227                             if r8 != (0 as i32 as i64 as u64) { pc += -61 }
    ja lbb_4293                                     if true { pc += 4 }
lbb_4289:
    mov64 r9, 1                                     r9 = 1 as i32 as i64 as u64
    jne r0, 0, lbb_4287                             if r0 != (0 as i32 as i64 as u64) { pc += -4 }
lbb_4291:
    mov64 r9, 0                                     r9 = 0 as i32 as i64 as u64
    jne r8, 0, lbb_4227                             if r8 != (0 as i32 as i64 as u64) { pc += -66 }
lbb_4293:
    mov64 r7, 0                                     r7 = 0 as i32 as i64 as u64
    ja lbb_4227                                     if true { pc += -68 }
lbb_4295:
    mov64 r6, 11                                    r6 = 11 as i32 as i64 as u64
    ja lbb_4316                                     if true { pc += 19 }
lbb_4297:
    mov64 r1, r10                                   r1 = r10
    add64 r1, -826                                  r1 += -826   ///  r1 = r1.wrapping_add(-826 as i32 as i64 as u64)
    stxdw [r10-0x10], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -1024                                 r1 += -1024   ///  r1 = r1.wrapping_add(-1024 as i32 as i64 as u64)
    stxdw [r10-0x20], r1                    
    ldxdw r1, [r10-0x408]                   
    stxdw [r10-0x28], r1                    
    stdw [r10-0x8], 18                      
    stdw [r10-0x18], 12                     
    mov64 r1, r10                                   r1 = r10
    add64 r1, -40                                   r1 += -40   ///  r1 = r1.wrapping_add(-40 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -712                                  r2 += -712   ///  r2 = r2.wrapping_add(-712 as i32 as i64 as u64)
    mov64 r3, 12                                    r3 = 12 as i32 as i64 as u64
    mov64 r4, 8                                     r4 = 8 as i32 as i64 as u64
    mov64 r5, 0                                     r5 = 0 as i32 as i64 as u64
    syscall [invalid]                       
    mov64 r6, 26                                    r6 = 26 as i32 as i64 as u64
lbb_4316:
    ldxdw r1, [r10-0x418]                   
lbb_4317:
    stxw [r1+0x0], r6                       
    stw [r1+0x4], 0                         
    exit                                    
lbb_4320:
    mov64 r6, 3                                     r6 = 3 as i32 as i64 as u64
    ja lbb_4317                                     if true { pc += -5 }
lbb_4322:
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    mov64 r2, 1                                     r2 = 1 as i32 as i64 as u64
    lddw r3, 0x1000266c8 --> b"\x00\x00\x00\x00\xb8Y\x02\x00\x10\x00\x00\x00\x00\x00\x00\x00\xcf \x00\x0…        r3 load str located at 4295124680
    call function_18489                     
lbb_4327:
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
    lddw r3, 0x1000266b0 --> b"\x00\x00\x00\x00\xb8Y\x02\x00\x10\x00\x00\x00\x00\x00\x00\x00\xcf \x00\x0…        r3 load str located at 4295124656
    call function_18489                     
lbb_4332:
    mov64 r1, 2                                     r1 = 2 as i32 as i64 as u64
    mov64 r2, 2                                     r2 = 2 as i32 as i64 as u64
    lddw r3, 0x1000266e0 --> b"\x00\x00\x00\x00\xb8Y\x02\x00\x10\x00\x00\x00\x00\x00\x00\x00\xcf \x00\x0…        r3 load str located at 4295124704
    call function_18489                     
lbb_4337:
    mov64 r1, 3                                     r1 = 3 as i32 as i64 as u64
    mov64 r2, 3                                     r2 = 3 as i32 as i64 as u64
    lddw r3, 0x1000266f8 --> b"\x00\x00\x00\x00\xb8Y\x02\x00\x10\x00\x00\x00\x00\x00\x00\x00\xcf \x00\x0…        r3 load str located at 4295124728
    call function_18489                     
lbb_4342:
    mov64 r1, 4                                     r1 = 4 as i32 as i64 as u64
    mov64 r2, 4                                     r2 = 4 as i32 as i64 as u64
    lddw r3, 0x100026710 --> b"\x00\x00\x00\x00\xb8Y\x02\x00\x10\x00\x00\x00\x00\x00\x00\x00\xd0 \x00\x0…        r3 load str located at 4295124752
    call function_18489                     
lbb_4347:
    mov64 r1, 5                                     r1 = 5 as i32 as i64 as u64
    mov64 r2, 5                                     r2 = 5 as i32 as i64 as u64
    lddw r3, 0x100026728 --> b"\x00\x00\x00\x00\xb8Y\x02\x00\x10\x00\x00\x00\x00\x00\x00\x00\xd0 \x00\x0…        r3 load str located at 4295124776
    call function_18489                     
lbb_4352:
    mov64 r1, 6                                     r1 = 6 as i32 as i64 as u64
    mov64 r2, 6                                     r2 = 6 as i32 as i64 as u64
    lddw r3, 0x100026740 --> b"\x00\x00\x00\x00\xb8Y\x02\x00\x10\x00\x00\x00\x00\x00\x00\x00\xd0 \x00\x0…        r3 load str located at 4295124800
    call function_18489                     
    ldxdw r3, [r2+0x8]                      
    jeq r3, 1, lbb_4608                             if r3 == (1 as i32 as i64 as u64) { pc += 249 }
    jeq r3, 0, lbb_4613                             if r3 == (0 as i32 as i64 as u64) { pc += 253 }
    jle r3, 2, lbb_4618                             if r3 <= (2 as i32 as i64 as u64) { pc += 257 }
    jeq r3, 3, lbb_4623                             if r3 == (3 as i32 as i64 as u64) { pc += 261 }
    jle r3, 4, lbb_4628                             if r3 <= (4 as i32 as i64 as u64) { pc += 265 }
    ldxdw r6, [r2+0x50]                     
    mov64 r5, 3                                     r5 = 3 as i32 as i64 as u64
    ldxdw r0, [r6+0x0]                      
    ldxdw r3, [r0+0x50]                     
    jlt r3, 32, lbb_4593                            if r3 < (32 as i32 as i64 as u64) { pc += 225 }
    ldxdw r9, [r2+0x0]                      
    mov64 r8, r9                                    r8 = r9
    add64 r8, 8                                     r8 += 8   ///  r8 = r8.wrapping_add(8 as i32 as i64 as u64)
    ldxdw r3, [r8+0x0]                      
    ldxdw r4, [r3+0x50]                     
    jlt r4, 32, lbb_4593                            if r4 < (32 as i32 as i64 as u64) { pc += 219 }
    ldxdw r4, [r2+0x58]                     
    ldxdw r5, [r2+0x48]                     
    stxdw [r10-0x318], r5                   
    ldxdw r5, [r2+0x28]                     
    stxdw [r10-0x320], r5                   
    ldxdw r5, [r2+0x20]                     
    stxdw [r10-0x330], r5                   
    mov64 r5, 0                                     r5 = 0 as i32 as i64 as u64
    stxdw [r10-0x328], r5                   
    ldxdw r5, [r3+0x58]                     
    ldxdw r7, [r0+0x58]                     
    stxdw [r10-0x338], r1                   
    stxdw [r10-0x340], r8                   
    jne r7, r5, lbb_4404                            if r7 != r5 { pc += 16 }
    ldxdw r5, [r3+0x60]                     
    ldxdw r7, [r0+0x60]                     
    jne r7, r5, lbb_4404                            if r7 != r5 { pc += 13 }
    ldxdw r5, [r3+0x68]                     
    ldxdw r7, [r0+0x68]                     
    jne r7, r5, lbb_4404                            if r7 != r5 { pc += 10 }
    ldxdw r5, [r3+0x70]                     
    ldxdw r0, [r0+0x70]                     
    mov64 r7, 1                                     r7 = 1 as i32 as i64 as u64
    jeq r0, r5, lbb_4399                            if r0 == r5 { pc += 1 }
    mov64 r7, 0                                     r7 = 0 as i32 as i64 as u64
lbb_4399:
    stxdw [r10-0x328], r7                   
    jne r0, r5, lbb_4404                            if r0 != r5 { pc += 3 }
    mov64 r5, r6                                    r5 = r6
    mov64 r6, r4                                    r6 = r4
    ja lbb_4405                                     if true { pc += 1 }
lbb_4404:
    mov64 r5, r4                                    r5 = r4
lbb_4405:
    ldxdw r1, [r10-0x318]                   
    stxdw [r10-0x350], r6                   
    ldxdw r2, [r2+0x10]                     
    stxdw [r10-0x358], r2                   
    ldxdw r2, [r1+0x0]                      
    stxdw [r10-0x348], r5                   
    ldxdw r5, [r5+0x0]                      
    ldxdw r0, [r6+0x0]                      
    ldxdw r4, [r9+0x0]                      
    ldxdw r7, [r9+0x10]                     
    ldxdw r1, [r9+0x18]                     
    ldxdw r6, [r9+0x20]                     
    ldxdw r8, [r10-0x320]                   
    ldxdw r8, [r8+0x0]                      
    add64 r3, 8                                     r3 += 8   ///  r3 = r3.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x2d0], r3                   
    add64 r8, 8                                     r8 += 8   ///  r8 = r8.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x290], r8                   
    add64 r6, 8                                     r6 += 8   ///  r6 = r6.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x2a0], r6                   
    add64 r1, 8                                     r1 += 8   ///  r1 = r1.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x2b0], r1                   
    add64 r7, 8                                     r7 += 8   ///  r7 = r7.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x2c0], r7                   
    add64 r0, 8                                     r0 += 8   ///  r0 = r0.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x2e0], r0                   
    add64 r5, 8                                     r5 += 8   ///  r5 = r5.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x2f0], r5                   
    add64 r4, 8                                     r4 += 8   ///  r4 = r4.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x300], r4                   
    add64 r2, 8                                     r2 += 8   ///  r2 = r2.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x310], r2                   
    sth [r10-0x288], 0                      
    sth [r10-0x298], 0                      
    sth [r10-0x2a8], 0                      
    sth [r10-0x2b8], 1                      
    sth [r10-0x2c8], 1                      
    sth [r10-0x2d8], 1                      
    sth [r10-0x2e8], 1                      
    sth [r10-0x2f8], 1                      
    sth [r10-0x308], 257                    
    stxdw [r10-0x258], r2                   
    lddw r1, 0x1000259d8 --> b"blacklist\x01\x09attempt to divide with overflow but the"        r1 load str located at 4295121368
    stxdw [r10-0x268], r1                   
    stdw [r10-0x250], 32                    
    stdw [r10-0x260], 9                     
    ldxdw r1, [r10-0x330]                   
    ldxdw r6, [r1+0x0]                      
    stb [r10-0x28], 255                     
    add64 r6, 8                                     r6 += 8   ///  r6 = r6.wrapping_add(8 as i32 as i64 as u64)
    mov64 r1, r10                                   r1 = r10
    add64 r1, -616                                  r1 += -616   ///  r1 = r1.wrapping_add(-616 as i32 as i64 as u64)
    mov64 r4, r10                                   r4 = r10
    add64 r4, -544                                  r4 += -544   ///  r4 = r4.wrapping_add(-544 as i32 as i64 as u64)
    mov64 r5, r10                                   r5 = r10
    add64 r5, -40                                   r5 += -40   ///  r5 = r5.wrapping_add(-40 as i32 as i64 as u64)
    mov64 r2, 2                                     r2 = 2 as i32 as i64 as u64
    mov64 r3, r6                                    r3 = r6
    syscall [invalid]                       
    jne r0, 0, lbb_4596                             if r0 != (0 as i32 as i64 as u64) { pc += 130 }
    stxdw [r10-0x330], r6                   
    mov64 r1, r9                                    r1 = r9
    add64 r1, 32                                    r1 += 32   ///  r1 = r1.wrapping_add(32 as i32 as i64 as u64)
    mov64 r2, r9                                    r2 = r9
    add64 r2, 16                                    r2 += 16   ///  r2 = r2.wrapping_add(16 as i32 as i64 as u64)
    mov64 r3, r9                                    r3 = r9
    add64 r3, 24                                    r3 += 24   ///  r3 = r3.wrapping_add(24 as i32 as i64 as u64)
    ldxb r4, [r10-0x28]                     
    ldxdw r5, [r10-0x358]                   
    stxdw [r10-0x278], r5                   
    stxb [r10-0x279], r4                    
    ldxdw r4, [r10-0x328]                   
    xor64 r4, -1                                    r4 ^= -1   ///  r4 = r4.xor(-1)
    and64 r4, 1                                     r4 &= 1   ///  r4 = r4.and(1)
    stxb [r10-0x27a], r4                    
    stb [r10-0x27b], 2                      
    stdw [r10-0x270], 0                     
    ldxdw r4, [r10-0x320]                   
    stxdw [r10-0x228], r4                   
    stxdw [r10-0x230], r1                   
    stxdw [r10-0x238], r3                   
    stxdw [r10-0x240], r2                   
    ldxdw r1, [r10-0x340]                   
    stxdw [r10-0x248], r1                   
    ldxdw r1, [r10-0x350]                   
    stxdw [r10-0x250], r1                   
    ldxdw r1, [r10-0x348]                   
    stxdw [r10-0x258], r1                   
    stxdw [r10-0x260], r9                   
    ldxdw r1, [r10-0x318]                   
    stxdw [r10-0x268], r1                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -616                                  r1 += -616   ///  r1 = r1.wrapping_add(-616 as i32 as i64 as u64)
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
    mov64 r3, r10                                   r3 = r10
    add64 r3, -776                                  r3 += -776   ///  r3 = r3.wrapping_add(-776 as i32 as i64 as u64)
    ja lbb_4523                                     if true { pc += 20 }
lbb_4503:
    mov64 r7, r10                                   r7 = r10
    add64 r7, -544                                  r7 += -544   ///  r7 = r7.wrapping_add(-544 as i32 as i64 as u64)
    add64 r7, r2                                    r7 += r2   ///  r7 = r7.wrapping_add(r2)
    stxb [r7+0x32], r6                      
    stxb [r7+0x31], r9                      
    stxb [r7+0x30], r0                      
    mov64 r0, r4                                    r0 = r4
    add64 r0, 40                                    r0 += 40   ///  r0 = r0.wrapping_add(40 as i32 as i64 as u64)
    stxdw [r7+0x20], r0                     
    mov64 r0, r4                                    r0 = r4
    add64 r0, 88                                    r0 += 88   ///  r0 = r0.wrapping_add(88 as i32 as i64 as u64)
    stxdw [r7+0x18], r0                     
    stxdw [r7+0x10], r5                     
    add64 r4, 72                                    r4 += 72   ///  r4 = r4.wrapping_add(72 as i32 as i64 as u64)
    stxdw [r7+0x8], r4                      
    stdw [r7+0x28], 0                       
    add64 r3, 16                                    r3 += 16   ///  r3 = r3.wrapping_add(16 as i32 as i64 as u64)
    add64 r1, 8                                     r1 += 8   ///  r1 = r1.wrapping_add(8 as i32 as i64 as u64)
    add64 r2, 56                                    r2 += 56   ///  r2 = r2.wrapping_add(56 as i32 as i64 as u64)
    jeq r2, 504, lbb_4573                           if r2 == (504 as i32 as i64 as u64) { pc += 50 }
lbb_4523:
    mov64 r0, r10                                   r0 = r10
    add64 r0, -544                                  r0 += -544   ///  r0 = r0.wrapping_add(-544 as i32 as i64 as u64)
    mov64 r5, 1                                     r5 = 1 as i32 as i64 as u64
    ldxdw r4, [r1+0x0]                      
    ldxdw r4, [r4+0x0]                      
    ldxdw r6, [r3-0x8]                      
    ldxdw r7, [r6+0x0]                      
    ldxdw r8, [r4+0x8]                      
    jne r8, r7, lbb_4592                            if r8 != r7 { pc += 60 }
    ldxdw r7, [r6+0x8]                      
    ldxdw r8, [r4+0x10]                     
    jne r8, r7, lbb_4592                            if r8 != r7 { pc += 57 }
    ldxdw r7, [r6+0x10]                     
    ldxdw r8, [r4+0x18]                     
    jne r8, r7, lbb_4592                            if r8 != r7 { pc += 54 }
    ldxdw r6, [r6+0x18]                     
    ldxdw r7, [r4+0x20]                     
    jne r7, r6, lbb_4592                            if r7 != r6 { pc += 51 }
    ldxb r6, [r3+0x0]                       
    mov64 r5, 0                                     r5 = 0 as i32 as i64 as u64
    jne r6, 0, lbb_4545                             if r6 != (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r5, 119                                   r5 = 119 as i32 as i64 as u64
lbb_4545:
    ldxb r6, [r4+0x0]                       
    or64 r5, r6                                     r5 |= r6   ///  r5 = r5.or(r6)
    and64 r5, 255                                   r5 &= 255   ///  r5 = r5.and(255)
    jne r5, 255, lbb_4571                           if r5 != (255 as i32 as i64 as u64) { pc += 22 }
    add64 r0, r2                                    r0 += r2   ///  r0 = r0.wrapping_add(r2)
    mov64 r6, r4                                    r6 = r4
    add64 r6, 8                                     r6 += 8   ///  r6 = r6.wrapping_add(8 as i32 as i64 as u64)
    ldxdw r5, [r4+0x50]                     
    ldxb r8, [r4+0x3]                       
    ldxb r7, [r4+0x2]                       
    ldxb r9, [r4+0x1]                       
    stxdw [r0+0x0], r6                      
    mov64 r6, 1                                     r6 = 1 as i32 as i64 as u64
    mov64 r0, 1                                     r0 = 1 as i32 as i64 as u64
    jeq r9, 0, lbb_4564                             if r9 == (0 as i32 as i64 as u64) { pc += 4 }
    mov64 r9, 1                                     r9 = 1 as i32 as i64 as u64
    jeq r7, 0, lbb_4567                             if r7 == (0 as i32 as i64 as u64) { pc += 5 }
lbb_4562:
    jne r8, 0, lbb_4503                             if r8 != (0 as i32 as i64 as u64) { pc += -60 }
    ja lbb_4569                                     if true { pc += 5 }
lbb_4564:
    mov64 r0, 0                                     r0 = 0 as i32 as i64 as u64
    mov64 r9, 1                                     r9 = 1 as i32 as i64 as u64
    jne r7, 0, lbb_4562                             if r7 != (0 as i32 as i64 as u64) { pc += -5 }
lbb_4567:
    mov64 r9, 0                                     r9 = 0 as i32 as i64 as u64
    jne r8, 0, lbb_4503                             if r8 != (0 as i32 as i64 as u64) { pc += -66 }
lbb_4569:
    mov64 r6, 0                                     r6 = 0 as i32 as i64 as u64
    ja lbb_4503                                     if true { pc += -68 }
lbb_4571:
    mov64 r5, 11                                    r5 = 11 as i32 as i64 as u64
    ja lbb_4592                                     if true { pc += 19 }
lbb_4573:
    mov64 r1, r10                                   r1 = r10
    add64 r1, -635                                  r1 += -635   ///  r1 = r1.wrapping_add(-635 as i32 as i64 as u64)
    stxdw [r10-0x10], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -784                                  r1 += -784   ///  r1 = r1.wrapping_add(-784 as i32 as i64 as u64)
    stxdw [r10-0x20], r1                    
    ldxdw r1, [r10-0x330]                   
    stxdw [r10-0x28], r1                    
    stdw [r10-0x8], 19                      
    stdw [r10-0x18], 9                      
    mov64 r1, r10                                   r1 = r10
    add64 r1, -40                                   r1 += -40   ///  r1 = r1.wrapping_add(-40 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -544                                  r2 += -544   ///  r2 = r2.wrapping_add(-544 as i32 as i64 as u64)
    mov64 r3, 9                                     r3 = 9 as i32 as i64 as u64
    mov64 r4, 8                                     r4 = 8 as i32 as i64 as u64
    mov64 r5, 0                                     r5 = 0 as i32 as i64 as u64
    syscall [invalid]                       
    mov64 r5, 26                                    r5 = 26 as i32 as i64 as u64
lbb_4592:
    ldxdw r1, [r10-0x338]                   
lbb_4593:
    stxw [r1+0x0], r5                       
    stw [r1+0x4], 0                         
    exit                                    
lbb_4596:
    lddw r1, 0x100025b18 --> b"\x00\x00\x00\x00xY\x02\x001\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x…        r1 load str located at 4295121688
    stxdw [r10-0x220], r1                   
    stdw [r10-0x200], 0                     
    stdw [r10-0x218], 1                     
    stdw [r10-0x208], 0                     
    stdw [r10-0x210], 8                     
    mov64 r1, r10                                   r1 = r10
    add64 r1, -544                                  r1 += -544   ///  r1 = r1.wrapping_add(-544 as i32 as i64 as u64)
    lddw r2, 0x100025b28 --> b"\x00\x00\x00\x00\xa9Y\x02\x00\x0d\x00\x00\x00\x00\x00\x00\x00\x81\x00\x00…        r2 load str located at 4295121704
    call function_18483                     
lbb_4608:
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    mov64 r2, 1                                     r2 = 1 as i32 as i64 as u64
    lddw r3, 0x100026770 --> b"\x00\x00\x00\x00\xb8Y\x02\x00\x10\x00\x00\x00\x00\x00\x00\x00\xe2 \x00\x0…        r3 load str located at 4295124848
    call function_18489                     
lbb_4613:
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
    lddw r3, 0x100026758 --> b"\x00\x00\x00\x00\xb8Y\x02\x00\x10\x00\x00\x00\x00\x00\x00\x00\xe2 \x00\x0…        r3 load str located at 4295124824
    call function_18489                     
lbb_4618:
    mov64 r1, 2                                     r1 = 2 as i32 as i64 as u64
    mov64 r2, 2                                     r2 = 2 as i32 as i64 as u64
    lddw r3, 0x100026788 --> b"\x00\x00\x00\x00\xb8Y\x02\x00\x10\x00\x00\x00\x00\x00\x00\x00\xe2 \x00\x0…        r3 load str located at 4295124872
    call function_18489                     
lbb_4623:
    mov64 r1, 3                                     r1 = 3 as i32 as i64 as u64
    mov64 r2, 3                                     r2 = 3 as i32 as i64 as u64
    lddw r3, 0x1000267a0 --> b"\x00\x00\x00\x00\xb8Y\x02\x00\x10\x00\x00\x00\x00\x00\x00\x00\xe2 \x00\x0…        r3 load str located at 4295124896
    call function_18489                     
lbb_4628:
    mov64 r1, 4                                     r1 = 4 as i32 as i64 as u64
    mov64 r2, 4                                     r2 = 4 as i32 as i64 as u64
    lddw r3, 0x1000267b8 --> b"\x00\x00\x00\x00\xb8Y\x02\x00\x10\x00\x00\x00\x00\x00\x00\x00\xe3 \x00\x0…        r3 load str located at 4295124920
    call function_18489                     
    ldxdw r3, [r2+0x8]                      
    jeq r3, 1, lbb_4871                             if r3 == (1 as i32 as i64 as u64) { pc += 236 }
    jeq r3, 0, lbb_4876                             if r3 == (0 as i32 as i64 as u64) { pc += 240 }
    jle r3, 2, lbb_4881                             if r3 <= (2 as i32 as i64 as u64) { pc += 244 }
    jeq r3, 3, lbb_4886                             if r3 == (3 as i32 as i64 as u64) { pc += 248 }
    jle r3, 4, lbb_4891                             if r3 <= (4 as i32 as i64 as u64) { pc += 252 }
    ldxdw r9, [r2+0x50]                     
    mov64 r6, 3                                     r6 = 3 as i32 as i64 as u64
    ldxdw r5, [r9+0x0]                      
    ldxdw r3, [r5+0x50]                     
    jlt r3, 32, lbb_4868                            if r3 < (32 as i32 as i64 as u64) { pc += 224 }
    ldxdw r8, [r2+0x0]                      
    mov64 r4, r8                                    r4 = r8
    add64 r4, 8                                     r4 += 8   ///  r4 = r4.wrapping_add(8 as i32 as i64 as u64)
    ldxdw r0, [r4+0x0]                      
    ldxdw r3, [r0+0x50]                     
    jlt r3, 32, lbb_4868                            if r3 < (32 as i32 as i64 as u64) { pc += 218 }
    stxdw [r10-0x328], r4                   
    stxdw [r10-0x320], r1                   
    ldxdw r3, [r2+0x58]                     
    mov64 r7, 0                                     r7 = 0 as i32 as i64 as u64
    ldxdw r4, [r0+0x58]                     
    ldxdw r6, [r5+0x58]                     
    jne r6, r4, lbb_4672                            if r6 != r4 { pc += 15 }
    ldxdw r4, [r0+0x60]                     
    ldxdw r6, [r5+0x60]                     
    jne r6, r4, lbb_4672                            if r6 != r4 { pc += 12 }
    ldxdw r4, [r0+0x68]                     
    ldxdw r6, [r5+0x68]                     
    jne r6, r4, lbb_4672                            if r6 != r4 { pc += 9 }
    ldxdw r4, [r0+0x70]                     
    ldxdw r5, [r5+0x70]                     
    mov64 r7, 1                                     r7 = 1 as i32 as i64 as u64
    jeq r5, r4, lbb_4668                            if r5 == r4 { pc += 1 }
    mov64 r7, 0                                     r7 = 0 as i32 as i64 as u64
lbb_4668:
    jne r5, r4, lbb_4672                            if r5 != r4 { pc += 3 }
    mov64 r5, r9                                    r5 = r9
    mov64 r9, r3                                    r9 = r3
    ja lbb_4673                                     if true { pc += 1 }
lbb_4672:
    mov64 r5, r3                                    r5 = r3
lbb_4673:
    mov64 r6, r9                                    r6 = r9
    ldxdw r1, [r2+0x48]                     
    ldxdw r3, [r2+0x28]                     
    ldxdw r4, [r2+0x20]                     
    stxdw [r10-0x338], r4                   
    ldxdw r4, [r2+0x18]                     
    stxdw [r10-0x348], r4                   
    ldxdw r2, [r2+0x10]                     
    stxdw [r10-0x358], r2                   
    mov64 r2, r8                                    r2 = r8
    add64 r2, 32                                    r2 += 32   ///  r2 = r2.wrapping_add(32 as i32 as i64 as u64)
    stxdw [r10-0x340], r2                   
    mov64 r2, r8                                    r2 = r8
    add64 r2, 16                                    r2 += 16   ///  r2 = r2.wrapping_add(16 as i32 as i64 as u64)
    stxdw [r10-0x330], r2                   
    mov64 r2, r8                                    r2 = r8
    add64 r2, 24                                    r2 += 24   ///  r2 = r2.wrapping_add(24 as i32 as i64 as u64)
    stxdw [r10-0x350], r2                   
    and64 r7, 1                                     r7 &= 1   ///  r7 = r7.and(1)
    mov64 r2, 56                                    r2 = 56 as i32 as i64 as u64
    jne r7, 0, lbb_4695                             if r7 != (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r2, 57                                    r2 = 57 as i32 as i64 as u64
lbb_4695:
    stxdw [r10-0x380], r2                   
    add64 r0, 8                                     r0 += 8   ///  r0 = r0.wrapping_add(8 as i32 as i64 as u64)
    ldxdw r7, [r1+0x0]                      
    ldxdw r4, [r8+0x0]                      
    stxdw [r10-0x360], r1                   
    mov64 r1, r8                                    r1 = r8
    ldxdw r8, [r1+0x10]                     
    ldxdw r9, [r5+0x0]                      
    stxdw [r10-0x370], r6                   
    stxdw [r10-0x368], r5                   
    ldxdw r5, [r6+0x0]                      
    ldxdw r6, [r1+0x18]                     
    stxdw [r10-0x378], r3                   
    ldxdw r2, [r3+0x0]                      
    ldxdw r3, [r1+0x20]                     
    stxdw [r10-0x2f8], r0                   
    add64 r3, 8                                     r3 += 8   ///  r3 = r3.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x298], r3                   
    add64 r2, 8                                     r2 += 8   ///  r2 = r2.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x2a8], r2                   
    add64 r6, 8                                     r6 += 8   ///  r6 = r6.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x2b8], r6                   
    add64 r5, 8                                     r5 += 8   ///  r5 = r5.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x2c8], r5                   
    add64 r9, 8                                     r9 += 8   ///  r9 = r9.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x2d8], r9                   
    add64 r8, 8                                     r8 += 8   ///  r8 = r8.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x2e8], r8                   
    add64 r4, 8                                     r4 += 8   ///  r4 = r4.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x308], r4                   
    add64 r7, 8                                     r7 += 8   ///  r7 = r7.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x318], r7                   
    sth [r10-0x290], 0                      
    sth [r10-0x2a0], 0                      
    sth [r10-0x2b0], 0                      
    sth [r10-0x2c0], 1                      
    sth [r10-0x2d0], 1                      
    sth [r10-0x2e0], 1                      
    sth [r10-0x2f0], 1                      
    sth [r10-0x300], 1                      
    sth [r10-0x310], 257                    
    lddw r2, 0x3dc3e9bae0ff2dff                     r2 load str located at 4450657845620190719
    stxdw [r10-0x277], r2                   
    ldxdw r2, [r10-0x380]                   
    stxb [r10-0x278], r2                    
    lddw r2, 0xc3eabae3ff2eff3b                     r2 load str located at -4329442603361697989
    ldxdw r3, [r10-0x358]                   
    xor64 r3, r2                                    r3 ^= r2   ///  r3 = r3.xor(r2)
    stxdw [r10-0x280], r3                   
    lddw r2, 0xc3ebbae2ff2fff3a                     r2 load str located at -4329161132679889094
    ldxdw r3, [r10-0x348]                   
    xor64 r3, r2                                    r3 ^= r2   ///  r3 = r3.xor(r2)
    stxdw [r10-0x288], r3                   
    ldxdw r2, [r10-0x338]                   
    ldxdw r5, [r2+0x0]                      
    ldxdw r2, [r10-0x340]                   
    stxdw [r10-0x228], r2                   
    ldxdw r2, [r10-0x378]                   
    stxdw [r10-0x230], r2                   
    ldxdw r2, [r10-0x350]                   
    stxdw [r10-0x238], r2                   
    ldxdw r2, [r10-0x370]                   
    stxdw [r10-0x240], r2                   
    ldxdw r2, [r10-0x368]                   
    stxdw [r10-0x248], r2                   
    ldxdw r2, [r10-0x330]                   
    stxdw [r10-0x250], r2                   
    ldxdw r2, [r10-0x328]                   
    stxdw [r10-0x258], r2                   
    stxdw [r10-0x260], r1                   
    ldxdw r1, [r10-0x360]                   
    stxdw [r10-0x268], r1                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -616                                  r1 += -616   ///  r1 = r1.wrapping_add(-616 as i32 as i64 as u64)
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
    mov64 r4, r10                                   r4 = r10
    add64 r4, -784                                  r4 += -784   ///  r4 = r4.wrapping_add(-784 as i32 as i64 as u64)
    add64 r5, 8                                     r5 += 8   ///  r5 = r5.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x328], r5                   
    ja lbb_4798                                     if true { pc += 20 }
lbb_4778:
    mov64 r0, r10                                   r0 = r10
    add64 r0, -544                                  r0 += -544   ///  r0 = r0.wrapping_add(-544 as i32 as i64 as u64)
    add64 r0, r3                                    r0 += r3   ///  r0 = r0.wrapping_add(r3)
    stxb [r0+0x32], r7                      
    stxb [r0+0x31], r9                      
    stxb [r0+0x30], r2                      
    mov64 r2, r5                                    r2 = r5
    add64 r2, 40                                    r2 += 40   ///  r2 = r2.wrapping_add(40 as i32 as i64 as u64)
    stxdw [r0+0x20], r2                     
    mov64 r2, r5                                    r2 = r5
    add64 r2, 88                                    r2 += 88   ///  r2 = r2.wrapping_add(88 as i32 as i64 as u64)
    stxdw [r0+0x18], r2                     
    stxdw [r0+0x10], r6                     
    add64 r5, 72                                    r5 += 72   ///  r5 = r5.wrapping_add(72 as i32 as i64 as u64)
    stxdw [r0+0x8], r5                      
    stdw [r0+0x28], 0                       
    add64 r4, 16                                    r4 += 16   ///  r4 = r4.wrapping_add(16 as i32 as i64 as u64)
    add64 r1, 8                                     r1 += 8   ///  r1 = r1.wrapping_add(8 as i32 as i64 as u64)
    add64 r3, 56                                    r3 += 56   ///  r3 = r3.wrapping_add(56 as i32 as i64 as u64)
    jeq r3, 504, lbb_4848                           if r3 == (504 as i32 as i64 as u64) { pc += 50 }
lbb_4798:
    mov64 r2, r10                                   r2 = r10
    add64 r2, -544                                  r2 += -544   ///  r2 = r2.wrapping_add(-544 as i32 as i64 as u64)
    mov64 r6, 1                                     r6 = 1 as i32 as i64 as u64
    ldxdw r5, [r1+0x0]                      
    ldxdw r5, [r5+0x0]                      
    ldxdw r7, [r4-0x8]                      
    ldxdw r0, [r7+0x0]                      
    ldxdw r8, [r5+0x8]                      
    jne r8, r0, lbb_4867                            if r8 != r0 { pc += 60 }
    ldxdw r0, [r7+0x8]                      
    ldxdw r8, [r5+0x10]                     
    jne r8, r0, lbb_4867                            if r8 != r0 { pc += 57 }
    ldxdw r0, [r7+0x10]                     
    ldxdw r8, [r5+0x18]                     
    jne r8, r0, lbb_4867                            if r8 != r0 { pc += 54 }
    ldxdw r0, [r7+0x18]                     
    ldxdw r7, [r5+0x20]                     
    jne r7, r0, lbb_4867                            if r7 != r0 { pc += 51 }
    ldxb r6, [r4+0x0]                       
    mov64 r0, 0                                     r0 = 0 as i32 as i64 as u64
    jne r6, 0, lbb_4820                             if r6 != (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r0, 119                                   r0 = 119 as i32 as i64 as u64
lbb_4820:
    ldxb r6, [r5+0x0]                       
    or64 r0, r6                                     r0 |= r6   ///  r0 = r0.or(r6)
    and64 r0, 255                                   r0 &= 255   ///  r0 = r0.and(255)
    jne r0, 255, lbb_4846                           if r0 != (255 as i32 as i64 as u64) { pc += 22 }
    add64 r2, r3                                    r2 += r3   ///  r2 = r2.wrapping_add(r3)
    mov64 r7, r5                                    r7 = r5
    add64 r7, 8                                     r7 += 8   ///  r7 = r7.wrapping_add(8 as i32 as i64 as u64)
    ldxdw r6, [r5+0x50]                     
    ldxb r8, [r5+0x3]                       
    ldxb r0, [r5+0x2]                       
    ldxb r9, [r5+0x1]                       
    stxdw [r2+0x0], r7                      
    mov64 r7, 1                                     r7 = 1 as i32 as i64 as u64
    mov64 r2, 1                                     r2 = 1 as i32 as i64 as u64
    jeq r9, 0, lbb_4839                             if r9 == (0 as i32 as i64 as u64) { pc += 4 }
    mov64 r9, 1                                     r9 = 1 as i32 as i64 as u64
    jeq r0, 0, lbb_4842                             if r0 == (0 as i32 as i64 as u64) { pc += 5 }
lbb_4837:
    jne r8, 0, lbb_4778                             if r8 != (0 as i32 as i64 as u64) { pc += -60 }
    ja lbb_4844                                     if true { pc += 5 }
lbb_4839:
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
    mov64 r9, 1                                     r9 = 1 as i32 as i64 as u64
    jne r0, 0, lbb_4837                             if r0 != (0 as i32 as i64 as u64) { pc += -5 }
lbb_4842:
    mov64 r9, 0                                     r9 = 0 as i32 as i64 as u64
    jne r8, 0, lbb_4778                             if r8 != (0 as i32 as i64 as u64) { pc += -66 }
lbb_4844:
    mov64 r7, 0                                     r7 = 0 as i32 as i64 as u64
    ja lbb_4778                                     if true { pc += -68 }
lbb_4846:
    mov64 r6, 11                                    r6 = 11 as i32 as i64 as u64
    ja lbb_4867                                     if true { pc += 19 }
lbb_4848:
    mov64 r1, r10                                   r1 = r10
    add64 r1, -648                                  r1 += -648   ///  r1 = r1.wrapping_add(-648 as i32 as i64 as u64)
    stxdw [r10-0x10], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -792                                  r1 += -792   ///  r1 = r1.wrapping_add(-792 as i32 as i64 as u64)
    stxdw [r10-0x20], r1                    
    ldxdw r1, [r10-0x328]                   
    stxdw [r10-0x28], r1                    
    stdw [r10-0x8], 25                      
    stdw [r10-0x18], 9                      
    mov64 r1, r10                                   r1 = r10
    add64 r1, -40                                   r1 += -40   ///  r1 = r1.wrapping_add(-40 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -544                                  r2 += -544   ///  r2 = r2.wrapping_add(-544 as i32 as i64 as u64)
    mov64 r3, 9                                     r3 = 9 as i32 as i64 as u64
    mov64 r4, 8                                     r4 = 8 as i32 as i64 as u64
    mov64 r5, 0                                     r5 = 0 as i32 as i64 as u64
    syscall [invalid]                       
    mov64 r6, 26                                    r6 = 26 as i32 as i64 as u64
lbb_4867:
    ldxdw r1, [r10-0x320]                   
lbb_4868:
    stxw [r1+0x0], r6                       
    stw [r1+0x4], 0                         
    exit                                    
lbb_4871:
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    mov64 r2, 1                                     r2 = 1 as i32 as i64 as u64
    lddw r3, 0x1000267e8 --> b"\x00\x00\x00\x00\xb8Y\x02\x00\x10\x00\x00\x00\x00\x00\x00\x00\xeb \x00\x0…        r3 load str located at 4295124968
    call function_18489                     
lbb_4876:
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
    lddw r3, 0x1000267d0 --> b"\x00\x00\x00\x00\xb8Y\x02\x00\x10\x00\x00\x00\x00\x00\x00\x00\xeb \x00\x0…        r3 load str located at 4295124944
    call function_18489                     
lbb_4881:
    mov64 r1, 2                                     r1 = 2 as i32 as i64 as u64
    mov64 r2, 2                                     r2 = 2 as i32 as i64 as u64
    lddw r3, 0x100026800 --> b"\x00\x00\x00\x00\xb8Y\x02\x00\x10\x00\x00\x00\x00\x00\x00\x00\xeb \x00\x0…        r3 load str located at 4295124992
    call function_18489                     
lbb_4886:
    mov64 r1, 3                                     r1 = 3 as i32 as i64 as u64
    mov64 r2, 3                                     r2 = 3 as i32 as i64 as u64
    lddw r3, 0x100026818 --> b"\x00\x00\x00\x00\xb8Y\x02\x00\x10\x00\x00\x00\x00\x00\x00\x00\xeb \x00\x0…        r3 load str located at 4295125016
    call function_18489                     
lbb_4891:
    mov64 r1, 4                                     r1 = 4 as i32 as i64 as u64
    mov64 r2, 4                                     r2 = 4 as i32 as i64 as u64
    lddw r3, 0x100026830 --> b"\x00\x00\x00\x00\xb8Y\x02\x00\x10\x00\x00\x00\x00\x00\x00\x00\xec \x00\x0…        r3 load str located at 4295125040
    call function_18489                     
    ldxdw r3, [r2+0x8]                      
    jeq r3, 1, lbb_5198                             if r3 == (1 as i32 as i64 as u64) { pc += 300 }
    jeq r3, 0, lbb_5203                             if r3 == (0 as i32 as i64 as u64) { pc += 304 }
    jle r3, 2, lbb_5208                             if r3 <= (2 as i32 as i64 as u64) { pc += 308 }
    jeq r3, 3, lbb_5213                             if r3 == (3 as i32 as i64 as u64) { pc += 312 }
    jle r3, 4, lbb_5218                             if r3 <= (4 as i32 as i64 as u64) { pc += 316 }
    jeq r3, 5, lbb_5223                             if r3 == (5 as i32 as i64 as u64) { pc += 320 }
    ldxdw r3, [r2+0x50]                     
    stxdw [r10-0x458], r3                   
    ldxdw r5, [r3+0x0]                      
    ldxdw r3, [r5+0x50]                     
    jlt r3, 32, lbb_5196                            if r3 < (32 as i32 as i64 as u64) { pc += 288 }
    stxdw [r10-0x470], r1                   
    ldxdw r7, [r2+0x0]                      
    ldxdw r4, [r2+0x58]                     
    ldxdw r3, [r7+0x10]                     
    mov64 r1, r3                                    r1 = r3
    add64 r1, 8                                     r1 += 8   ///  r1 = r1.wrapping_add(8 as i32 as i64 as u64)
    ldxdw r0, [r1+0x0]                      
    ldxdw r6, [r5+0x58]                     
    stxdw [r10-0x480], r1                   
    jne r6, r0, lbb_4931                            if r6 != r0 { pc += 13 }
    ldxdw r0, [r3+0x10]                     
    ldxdw r6, [r5+0x60]                     
    jne r6, r0, lbb_4931                            if r6 != r0 { pc += 10 }
    ldxdw r0, [r3+0x18]                     
    ldxdw r6, [r5+0x68]                     
    jne r6, r0, lbb_4931                            if r6 != r0 { pc += 7 }
    ldxdw r0, [r3+0x20]                     
    ldxdw r5, [r5+0x70]                     
    jne r5, r0, lbb_4931                            if r5 != r0 { pc += 4 }
    ldxdw r1, [r10-0x458]                   
    stxdw [r10-0x468], r1                   
    stxdw [r10-0x458], r4                   
    ja lbb_4932                                     if true { pc += 1 }
lbb_4931:
    stxdw [r10-0x468], r4                   
lbb_4932:
    ldxdw r4, [r2+0x30]                     
    ldxdw r1, [r2+0x28]                     
    mov64 r9, r7                                    r9 = r7
    add64 r9, 24                                    r9 += 24   ///  r9 = r9.wrapping_add(24 as i32 as i64 as u64)
    ldxdw r0, [r3+0x28]                     
    lddw r5, 0xde8f75eee1f6dd06                     r5 load str located at -2409577606766207738
    mov64 r8, r1                                    r8 = r1
    jne r0, r5, lbb_4957                            if r0 != r5 { pc += 16 }
    ldxdw r0, [r3+0x30]                     
    lddw r6, 0xdacd6ce4bc5d4218                     r6 load str located at -2680366473547005416
    mov64 r8, r1                                    r8 = r1
    jne r0, r6, lbb_4957                            if r0 != r6 { pc += 11 }
    ldxdw r0, [r3+0x38]                     
    lddw r6, 0x270db9834dfc1ab6                     r6 load str located at 2814109315776649910
    mov64 r8, r1                                    r8 = r1
    jne r0, r6, lbb_4957                            if r0 != r6 { pc += 6 }
    ldxdw r3, [r3+0x40]                     
    lddw r0, 0xfc8ba1d828f9bdfe                     r0 load str located at -248927404616466946
    mov64 r8, r1                                    r8 = r1
    jne r3, r0, lbb_4957                            if r3 != r0 { pc += 1 }
    mov64 r8, r4                                    r8 = r4
lbb_4957:
    stxdw [r10-0x460], r1                   
    ldxb r1, [r2+0x62]                      
    stxdw [r10-0x478], r9                   
    ldxdw r6, [r9+0x0]                      
    ldxdw r0, [r6+0x28]                     
    jne r0, r5, lbb_4976                            if r0 != r5 { pc += 13 }
    ldxdw r5, [r6+0x30]                     
    lddw r0, 0xdacd6ce4bc5d4218                     r0 load str located at -2680366473547005416
    jne r5, r0, lbb_4976                            if r5 != r0 { pc += 9 }
    ldxdw r5, [r6+0x38]                     
    lddw r0, 0x270db9834dfc1ab6                     r0 load str located at 2814109315776649910
    jne r5, r0, lbb_4976                            if r5 != r0 { pc += 5 }
    ldxdw r5, [r6+0x40]                     
    lddw r0, 0xfc8ba1d828f9bdfe                     r0 load str located at -248927404616466946
    jne r5, r0, lbb_4976                            if r5 != r0 { pc += 1 }
    stxdw [r10-0x460], r4                   
lbb_4976:
    ldxdw r4, [r2+0x48]                     
    ldxdw r9, [r2+0x40]                     
    ldxdw r5, [r2+0x20]                     
    ldxdw r2, [r2+0x10]                     
    stxdw [r10-0x4a8], r2                   
    mov64 r2, r7                                    r2 = r7
    add64 r2, 40                                    r2 += 40   ///  r2 = r2.wrapping_add(40 as i32 as i64 as u64)
    stxdw [r10-0x498], r2                   
    mov64 r2, r7                                    r2 = r7
    add64 r2, 8                                     r2 += 8   ///  r2 = r2.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x488], r2                   
    mov64 r2, r7                                    r2 = r7
    add64 r2, 16                                    r2 += 16   ///  r2 = r2.wrapping_add(16 as i32 as i64 as u64)
    stxdw [r10-0x490], r2                   
    mov64 r2, r7                                    r2 = r7
    add64 r2, 32                                    r2 += 32   ///  r2 = r2.wrapping_add(32 as i32 as i64 as u64)
    stxdw [r10-0x4a0], r2                   
    and64 r1, 1                                     r1 &= 1   ///  r1 = r1.and(1)
    lddw r2, 0xeaebda01123d0666                     r2 load str located at -1518880751171598746
    jne r1, 0, lbb_4999                             if r1 != (0 as i32 as i64 as u64) { pc += 2 }
    lddw r2, 0xad837f01a485e633                     r2 load str located at -5943767438166989261
lbb_4999:
    stxdw [r10-0x4d0], r2                   
    add64 r6, 8                                     r6 += 8   ///  r6 = r6.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x4f0], r6                   
    stxdw [r10-0x4b8], r5                   
    ldxdw r0, [r5+0x0]                      
    ldxdw r1, [r7+0x0]                      
    stxdw [r10-0x4d8], r1                   
    ldxdw r1, [r4+0x0]                      
    stxdw [r10-0x4e0], r1                   
    ldxdw r1, [r7+0x8]                      
    stxdw [r10-0x4e8], r1                   
    stxdw [r10-0x4c0], r7                   
    ldxdw r1, [r10-0x468]                   
    ldxdw r5, [r1+0x0]                      
    ldxdw r1, [r10-0x458]                   
    ldxdw r6, [r1+0x0]                      
    stxdw [r10-0x4b0], r4                   
    ldxdw r4, [r7+0x20]                     
    ldxdw r2, [r7+0x28]                     
    stxdw [r10-0x4c8], r8                   
    ldxdw r8, [r8+0x0]                      
    ldxdw r1, [r10-0x460]                   
    ldxdw r1, [r1+0x0]                      
    mov64 r7, r9                                    r7 = r9
    ldxdw r3, [r7+0x0]                      
    ldxdw r9, [r10-0x4f0]                   
    stxdw [r10-0x410], r9                   
    ldxdw r9, [r10-0x480]                   
    stxdw [r10-0x420], r9                   
    add64 r3, 8                                     r3 += 8   ///  r3 = r3.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x3a0], r3                   
    add64 r1, 8                                     r1 += 8   ///  r1 = r1.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x3b0], r1                   
    add64 r8, 8                                     r8 += 8   ///  r8 = r8.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x3c0], r8                   
    add64 r2, 8                                     r2 += 8   ///  r2 = r2.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x3d0], r2                   
    add64 r4, 8                                     r4 += 8   ///  r4 = r4.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x3e0], r4                   
    add64 r6, 8                                     r6 += 8   ///  r6 = r6.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x3f0], r6                   
    add64 r5, 8                                     r5 += 8   ///  r5 = r5.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x400], r5                   
    ldxdw r1, [r10-0x4e8]                   
    add64 r1, 8                                     r1 += 8   ///  r1 = r1.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x430], r1                   
    ldxdw r1, [r10-0x4e0]                   
    add64 r1, 8                                     r1 += 8   ///  r1 = r1.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x440], r1                   
    ldxdw r1, [r10-0x4d8]                   
    add64 r1, 8                                     r1 += 8   ///  r1 = r1.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x450], r1                   
    add64 r0, 8                                     r0 += 8   ///  r0 = r0.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x480], r0                   
    stxdw [r10-0x390], r0                   
    sth [r10-0x388], 0                      
    sth [r10-0x398], 0                      
    sth [r10-0x3a8], 0                      
    sth [r10-0x3b8], 0                      
    sth [r10-0x3c8], 1                      
    sth [r10-0x3d8], 1                      
    sth [r10-0x3e8], 1                      
    sth [r10-0x3f8], 1                      
    sth [r10-0x408], 0                      
    sth [r10-0x418], 0                      
    sth [r10-0x428], 0                      
    sth [r10-0x438], 257                    
    sth [r10-0x448], 1                      
    ldxdw r1, [r10-0x4a8]                   
    stxdw [r10-0x378], r1                   
    ldxdw r1, [r10-0x4d0]                   
    stxdw [r10-0x380], r1                   
    stdw [r10-0x370], 0                     
    ldxdw r1, [r10-0x4b8]                   
    stxdw [r10-0x308], r1                   
    stxdw [r10-0x310], r7                   
    ldxdw r1, [r10-0x460]                   
    stxdw [r10-0x318], r1                   
    ldxdw r1, [r10-0x4c8]                   
    stxdw [r10-0x320], r1                   
    ldxdw r1, [r10-0x498]                   
    stxdw [r10-0x328], r1                   
    ldxdw r1, [r10-0x4a0]                   
    stxdw [r10-0x330], r1                   
    ldxdw r1, [r10-0x458]                   
    stxdw [r10-0x338], r1                   
    ldxdw r1, [r10-0x468]                   
    stxdw [r10-0x340], r1                   
    ldxdw r1, [r10-0x478]                   
    stxdw [r10-0x348], r1                   
    ldxdw r1, [r10-0x490]                   
    stxdw [r10-0x350], r1                   
    ldxdw r1, [r10-0x488]                   
    stxdw [r10-0x358], r1                   
    ldxdw r1, [r10-0x4b0]                   
    stxdw [r10-0x360], r1                   
    ldxdw r1, [r10-0x4c0]                   
    stxdw [r10-0x368], r1                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -872                                  r1 += -872   ///  r1 = r1.wrapping_add(-872 as i32 as i64 as u64)
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
    mov64 r4, r10                                   r4 = r10
    add64 r4, -1096                                 r4 += -1096   ///  r4 = r4.wrapping_add(-1096 as i32 as i64 as u64)
    ja lbb_5123                                     if true { pc += 20 }
lbb_5103:
    mov64 r7, r10                                   r7 = r10
    add64 r7, -768                                  r7 += -768   ///  r7 = r7.wrapping_add(-768 as i32 as i64 as u64)
    add64 r7, r3                                    r7 += r3   ///  r7 = r7.wrapping_add(r3)
    stxb [r7+0x32], r6                      
    stxb [r7+0x31], r8                      
    stxb [r7+0x30], r5                      
    mov64 r5, r2                                    r5 = r2
    add64 r5, 40                                    r5 += 40   ///  r5 = r5.wrapping_add(40 as i32 as i64 as u64)
    stxdw [r7+0x20], r5                     
    mov64 r5, r2                                    r5 = r2
    add64 r5, 88                                    r5 += 88   ///  r5 = r5.wrapping_add(88 as i32 as i64 as u64)
    stxdw [r7+0x18], r5                     
    stxdw [r7+0x10], r0                     
    add64 r2, 72                                    r2 += 72   ///  r2 = r2.wrapping_add(72 as i32 as i64 as u64)
    stxdw [r7+0x8], r2                      
    stdw [r7+0x28], 0                       
    add64 r4, 16                                    r4 += 16   ///  r4 = r4.wrapping_add(16 as i32 as i64 as u64)
    add64 r1, 8                                     r1 += 8   ///  r1 = r1.wrapping_add(8 as i32 as i64 as u64)
    add64 r3, 56                                    r3 += 56   ///  r3 = r3.wrapping_add(56 as i32 as i64 as u64)
    jeq r3, 728, lbb_5173                           if r3 == (728 as i32 as i64 as u64) { pc += 50 }
lbb_5123:
    mov64 r5, r10                                   r5 = r10
    add64 r5, -768                                  r5 += -768   ///  r5 = r5.wrapping_add(-768 as i32 as i64 as u64)
    mov64 r0, 1                                     r0 = 1 as i32 as i64 as u64
    ldxdw r2, [r1+0x0]                      
    ldxdw r2, [r2+0x0]                      
    ldxdw r6, [r4-0x8]                      
    ldxdw r7, [r6+0x0]                      
    ldxdw r8, [r2+0x8]                      
    jne r8, r7, lbb_5192                            if r8 != r7 { pc += 60 }
    ldxdw r7, [r6+0x8]                      
    ldxdw r8, [r2+0x10]                     
    jne r8, r7, lbb_5192                            if r8 != r7 { pc += 57 }
    ldxdw r7, [r6+0x10]                     
    ldxdw r8, [r2+0x18]                     
    jne r8, r7, lbb_5192                            if r8 != r7 { pc += 54 }
    ldxdw r6, [r6+0x18]                     
    ldxdw r7, [r2+0x20]                     
    jne r7, r6, lbb_5192                            if r7 != r6 { pc += 51 }
    ldxb r6, [r4+0x0]                       
    mov64 r0, 0                                     r0 = 0 as i32 as i64 as u64
    jne r6, 0, lbb_5145                             if r6 != (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r0, 119                                   r0 = 119 as i32 as i64 as u64
lbb_5145:
    ldxb r6, [r2+0x0]                       
    or64 r0, r6                                     r0 |= r6   ///  r0 = r0.or(r6)
    and64 r0, 255                                   r0 &= 255   ///  r0 = r0.and(255)
    jne r0, 255, lbb_5171                           if r0 != (255 as i32 as i64 as u64) { pc += 22 }
    add64 r5, r3                                    r5 += r3   ///  r5 = r5.wrapping_add(r3)
    mov64 r6, r2                                    r6 = r2
    add64 r6, 8                                     r6 += 8   ///  r6 = r6.wrapping_add(8 as i32 as i64 as u64)
    ldxdw r0, [r2+0x50]                     
    ldxb r7, [r2+0x3]                       
    ldxb r9, [r2+0x2]                       
    ldxb r8, [r2+0x1]                       
    stxdw [r5+0x0], r6                      
    mov64 r6, 1                                     r6 = 1 as i32 as i64 as u64
    mov64 r5, 1                                     r5 = 1 as i32 as i64 as u64
    jeq r8, 0, lbb_5164                             if r8 == (0 as i32 as i64 as u64) { pc += 4 }
    mov64 r8, 1                                     r8 = 1 as i32 as i64 as u64
    jeq r9, 0, lbb_5167                             if r9 == (0 as i32 as i64 as u64) { pc += 5 }
lbb_5162:
    jne r7, 0, lbb_5103                             if r7 != (0 as i32 as i64 as u64) { pc += -60 }
    ja lbb_5169                                     if true { pc += 5 }
lbb_5164:
    mov64 r5, 0                                     r5 = 0 as i32 as i64 as u64
    mov64 r8, 1                                     r8 = 1 as i32 as i64 as u64
    jne r9, 0, lbb_5162                             if r9 != (0 as i32 as i64 as u64) { pc += -5 }
lbb_5167:
    mov64 r8, 0                                     r8 = 0 as i32 as i64 as u64
    jne r7, 0, lbb_5103                             if r7 != (0 as i32 as i64 as u64) { pc += -66 }
lbb_5169:
    mov64 r6, 0                                     r6 = 0 as i32 as i64 as u64
    ja lbb_5103                                     if true { pc += -68 }
lbb_5171:
    mov64 r0, 11                                    r0 = 11 as i32 as i64 as u64
    ja lbb_5192                                     if true { pc += 19 }
lbb_5173:
    mov64 r1, r10                                   r1 = r10
    add64 r1, -896                                  r1 += -896   ///  r1 = r1.wrapping_add(-896 as i32 as i64 as u64)
    stxdw [r10-0x10], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -1104                                 r1 += -1104   ///  r1 = r1.wrapping_add(-1104 as i32 as i64 as u64)
    stxdw [r10-0x20], r1                    
    ldxdw r1, [r10-0x480]                   
    stxdw [r10-0x28], r1                    
    stdw [r10-0x8], 24                      
    stdw [r10-0x18], 13                     
    mov64 r1, r10                                   r1 = r10
    add64 r1, -40                                   r1 += -40   ///  r1 = r1.wrapping_add(-40 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -768                                  r2 += -768   ///  r2 = r2.wrapping_add(-768 as i32 as i64 as u64)
    mov64 r3, 13                                    r3 = 13 as i32 as i64 as u64
    mov64 r4, 8                                     r4 = 8 as i32 as i64 as u64
    mov64 r5, 0                                     r5 = 0 as i32 as i64 as u64
    syscall [invalid]                       
    mov64 r0, 26                                    r0 = 26 as i32 as i64 as u64
lbb_5192:
    ldxdw r1, [r10-0x470]                   
lbb_5193:
    stxw [r1+0x0], r0                       
    stw [r1+0x4], 0                         
    exit                                    
lbb_5196:
    mov64 r0, 3                                     r0 = 3 as i32 as i64 as u64
    ja lbb_5193                                     if true { pc += -5 }
lbb_5198:
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    mov64 r2, 1                                     r2 = 1 as i32 as i64 as u64
    lddw r3, 0x100026860 --> b"\x00\x00\x00\x00\xb8Y\x02\x00\x10\x00\x00\x00\x00\x00\x00\x00\xf7 \x00\x0…        r3 load str located at 4295125088
    call function_18489                     
lbb_5203:
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
    lddw r3, 0x100026848 --> b"\x00\x00\x00\x00\xb8Y\x02\x00\x10\x00\x00\x00\x00\x00\x00\x00\xf7 \x00\x0…        r3 load str located at 4295125064
    call function_18489                     
lbb_5208:
    mov64 r1, 2                                     r1 = 2 as i32 as i64 as u64
    mov64 r2, 2                                     r2 = 2 as i32 as i64 as u64
    lddw r3, 0x100026878 --> b"\x00\x00\x00\x00\xb8Y\x02\x00\x10\x00\x00\x00\x00\x00\x00\x00\xf7 \x00\x0…        r3 load str located at 4295125112
    call function_18489                     
lbb_5213:
    mov64 r1, 3                                     r1 = 3 as i32 as i64 as u64
    mov64 r2, 3                                     r2 = 3 as i32 as i64 as u64
    lddw r3, 0x100026890 --> b"\x00\x00\x00\x00\xb8Y\x02\x00\x10\x00\x00\x00\x00\x00\x00\x00\xf7 \x00\x0…        r3 load str located at 4295125136
    call function_18489                     
lbb_5218:
    mov64 r1, 4                                     r1 = 4 as i32 as i64 as u64
    mov64 r2, 4                                     r2 = 4 as i32 as i64 as u64
    lddw r3, 0x1000268a8 --> b"\x00\x00\x00\x00\xb8Y\x02\x00\x10\x00\x00\x00\x00\x00\x00\x00\xf8 \x00\x0…        r3 load str located at 4295125160
    call function_18489                     
lbb_5223:
    mov64 r1, 5                                     r1 = 5 as i32 as i64 as u64
    mov64 r2, 5                                     r2 = 5 as i32 as i64 as u64
    lddw r3, 0x1000268c0 --> b"\x00\x00\x00\x00\xb8Y\x02\x00\x10\x00\x00\x00\x00\x00\x00\x00\xf8 \x00\x0…        r3 load str located at 4295125184
    call function_18489                     
    ldxdw r3, [r2+0x8]                      
    jeq r3, 1, lbb_5496                             if r3 == (1 as i32 as i64 as u64) { pc += 266 }
    jeq r3, 0, lbb_5501                             if r3 == (0 as i32 as i64 as u64) { pc += 270 }
    jle r3, 2, lbb_5506                             if r3 <= (2 as i32 as i64 as u64) { pc += 274 }
    jeq r3, 3, lbb_5511                             if r3 == (3 as i32 as i64 as u64) { pc += 278 }
    jle r3, 4, lbb_5516                             if r3 <= (4 as i32 as i64 as u64) { pc += 282 }
    jeq r3, 5, lbb_5521                             if r3 == (5 as i32 as i64 as u64) { pc += 286 }
    jle r3, 6, lbb_5526                             if r3 <= (6 as i32 as i64 as u64) { pc += 290 }
    jeq r3, 7, lbb_5531                             if r3 == (7 as i32 as i64 as u64) { pc += 294 }
    jle r3, 8, lbb_5536                             if r3 <= (8 as i32 as i64 as u64) { pc += 298 }
    jeq r3, 9, lbb_5541                             if r3 == (9 as i32 as i64 as u64) { pc += 302 }
    ldxdw r7, [r2+0x50]                     
    ldxdw r5, [r7+0x0]                      
    ldxdw r3, [r5+0x50]                     
    jlt r3, 32, lbb_5494                            if r3 < (32 as i32 as i64 as u64) { pc += 251 }
    ldxdw r9, [r2+0x0]                      
    ldxdw r3, [r2+0x58]                     
    ldxdw r8, [r2+0x48]                     
    ldxdw r4, [r2+0x20]                     
    stxdw [r10-0x470], r4                   
    ldxdw r2, [r2+0x10]                     
    stxdw [r10-0x490], r2                   
    mov64 r2, r9                                    r2 = r9
    add64 r2, 72                                    r2 += 72   ///  r2 = r2.wrapping_add(72 as i32 as i64 as u64)
    stxdw [r10-0x480], r2                   
    mov64 r2, r9                                    r2 = r9
    add64 r2, 8                                     r2 += 8   ///  r2 = r2.wrapping_add(8 as i32 as i64 as u64)
    mov64 r4, r9                                    r4 = r9
    add64 r4, 16                                    r4 += 16   ///  r4 = r4.wrapping_add(16 as i32 as i64 as u64)
    stxdw [r10-0x468], r4                   
    mov64 r4, r9                                    r4 = r9
    add64 r4, 24                                    r4 += 24   ///  r4 = r4.wrapping_add(24 as i32 as i64 as u64)
    stxdw [r10-0x478], r4                   
    mov64 r4, r9                                    r4 = r9
    add64 r4, 32                                    r4 += 32   ///  r4 = r4.wrapping_add(32 as i32 as i64 as u64)
    stxdw [r10-0x488], r4                   
    mov64 r4, r9                                    r4 = r9
    add64 r4, 40                                    r4 += 40   ///  r4 = r4.wrapping_add(40 as i32 as i64 as u64)
    stxdw [r10-0x498], r4                   
    mov64 r4, r9                                    r4 = r9
    add64 r4, 48                                    r4 += 48   ///  r4 = r4.wrapping_add(48 as i32 as i64 as u64)
    stxdw [r10-0x4a0], r4                   
    mov64 r4, r9                                    r4 = r9
    add64 r4, 56                                    r4 += 56   ///  r4 = r4.wrapping_add(56 as i32 as i64 as u64)
    stxdw [r10-0x4a8], r4                   
    mov64 r4, r9                                    r4 = r9
    add64 r4, 64                                    r4 += 64   ///  r4 = r4.wrapping_add(64 as i32 as i64 as u64)
    stxdw [r10-0x4b0], r4                   
    ldxdw r4, [r9+0x38]                     
    mov64 r0, r4                                    r0 = r4
    add64 r0, 8                                     r0 += 8   ///  r0 = r0.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x4c8], r0                   
    ldxdw r0, [r0+0x0]                      
    ldxdw r6, [r5+0x58]                     
    stxdw [r10-0x458], r1                   
    stxdw [r10-0x460], r2                   
    jne r6, r0, lbb_5297                            if r6 != r0 { pc += 12 }
    ldxdw r0, [r4+0x10]                     
    ldxdw r6, [r5+0x60]                     
    jne r6, r0, lbb_5297                            if r6 != r0 { pc += 9 }
    ldxdw r0, [r4+0x18]                     
    ldxdw r6, [r5+0x68]                     
    jne r6, r0, lbb_5297                            if r6 != r0 { pc += 6 }
    ldxdw r4, [r4+0x20]                     
    ldxdw r0, [r5+0x70]                     
    jne r0, r4, lbb_5297                            if r0 != r4 { pc += 3 }
    mov64 r1, r7                                    r1 = r7
    mov64 r7, r3                                    r7 = r3
    ja lbb_5298                                     if true { pc += 1 }
lbb_5297:
    mov64 r1, r3                                    r1 = r3
lbb_5298:
    stxdw [r10-0x4d0], r7                   
    stxdw [r10-0x4c0], r1                   
    ldxdw r2, [r8+0x0]                      
    stxdw [r10-0x4d8], r2                   
    ldxdw r2, [r9+0x0]                      
    stxdw [r10-0x4e0], r2                   
    ldxdw r2, [r9+0x8]                      
    stxdw [r10-0x4e8], r2                   
    ldxdw r2, [r9+0x10]                     
    stxdw [r10-0x4f0], r2                   
    ldxdw r6, [r1+0x0]                      
    ldxdw r4, [r7+0x0]                      
    ldxdw r0, [r9+0x18]                     
    ldxdw r3, [r9+0x20]                     
    ldxdw r2, [r9+0x28]                     
    ldxdw r5, [r9+0x30]                     
    ldxdw r7, [r9+0x40]                     
    stxdw [r10-0x4b8], r8                   
    ldxdw r8, [r9+0x48]                     
    ldxdw r1, [r10-0x4c8]                   
    stxdw [r10-0x3b0], r1                   
    add64 r8, 8                                     r8 += 8   ///  r8 = r8.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x390], r8                   
    add64 r7, 8                                     r7 += 8   ///  r7 = r7.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x3a0], r7                   
    add64 r5, 8                                     r5 += 8   ///  r5 = r5.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x3c0], r5                   
    add64 r2, 8                                     r2 += 8   ///  r2 = r2.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x3d0], r2                   
    add64 r3, 8                                     r3 += 8   ///  r3 = r3.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x3e0], r3                   
    add64 r0, 8                                     r0 += 8   ///  r0 = r0.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x3f0], r0                   
    add64 r4, 8                                     r4 += 8   ///  r4 = r4.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x400], r4                   
    add64 r6, 8                                     r6 += 8   ///  r6 = r6.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x410], r6                   
    ldxdw r1, [r10-0x4f0]                   
    add64 r1, 8                                     r1 += 8   ///  r1 = r1.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x420], r1                   
    ldxdw r1, [r10-0x4e8]                   
    add64 r1, 8                                     r1 += 8   ///  r1 = r1.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x430], r1                   
    ldxdw r1, [r10-0x4e0]                   
    add64 r1, 8                                     r1 += 8   ///  r1 = r1.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x440], r1                   
    ldxdw r1, [r10-0x4d8]                   
    add64 r1, 8                                     r1 += 8   ///  r1 = r1.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x450], r1                   
    sth [r10-0x388], 1                      
    sth [r10-0x398], 0                      
    sth [r10-0x3a8], 0                      
    sth [r10-0x3b8], 0                      
    sth [r10-0x3c8], 0                      
    sth [r10-0x3d8], 1                      
    sth [r10-0x3e8], 1                      
    sth [r10-0x3f8], 1                      
    sth [r10-0x408], 1                      
    sth [r10-0x418], 1                      
    sth [r10-0x428], 0                      
    sth [r10-0x438], 0                      
    sth [r10-0x448], 257                    
    ldxdw r2, [r10-0x490]                   
    stxdw [r10-0x378], r2                   
    lddw r2, 0xdfdf1aa0bbc052ef                     r2 load str located at -2315102405798112529
    stxdw [r10-0x380], r2                   
    stdw [r10-0x370], 0                     
    ldxdw r2, [r10-0x470]                   
    ldxdw r4, [r2+0x0]                      
    ldxdw r2, [r10-0x480]                   
    stxdw [r10-0x308], r2                   
    ldxdw r2, [r10-0x4b0]                   
    stxdw [r10-0x310], r2                   
    ldxdw r2, [r10-0x4a8]                   
    stxdw [r10-0x318], r2                   
    ldxdw r2, [r10-0x4a0]                   
    stxdw [r10-0x320], r2                   
    ldxdw r2, [r10-0x498]                   
    stxdw [r10-0x328], r2                   
    ldxdw r2, [r10-0x488]                   
    stxdw [r10-0x330], r2                   
    ldxdw r2, [r10-0x478]                   
    stxdw [r10-0x338], r2                   
    ldxdw r1, [r10-0x4d0]                   
    stxdw [r10-0x340], r1                   
    ldxdw r1, [r10-0x4c0]                   
    stxdw [r10-0x348], r1                   
    ldxdw r1, [r10-0x468]                   
    stxdw [r10-0x350], r1                   
    ldxdw r1, [r10-0x460]                   
    stxdw [r10-0x358], r1                   
    stxdw [r10-0x360], r9                   
    ldxdw r1, [r10-0x4b8]                   
    stxdw [r10-0x368], r1                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -872                                  r1 += -872   ///  r1 = r1.wrapping_add(-872 as i32 as i64 as u64)
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
    mov64 r3, r10                                   r3 = r10
    add64 r3, -1096                                 r3 += -1096   ///  r3 = r3.wrapping_add(-1096 as i32 as i64 as u64)
    add64 r4, 8                                     r4 += 8   ///  r4 = r4.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x460], r4                   
    ja lbb_5421                                     if true { pc += 20 }
lbb_5401:
    mov64 r7, r10                                   r7 = r10
    add64 r7, -768                                  r7 += -768   ///  r7 = r7.wrapping_add(-768 as i32 as i64 as u64)
    add64 r7, r2                                    r7 += r2   ///  r7 = r7.wrapping_add(r2)
    stxb [r7+0x32], r6                      
    stxb [r7+0x31], r8                      
    stxb [r7+0x30], r5                      
    mov64 r5, r4                                    r5 = r4
    add64 r5, 40                                    r5 += 40   ///  r5 = r5.wrapping_add(40 as i32 as i64 as u64)
    stxdw [r7+0x20], r5                     
    mov64 r5, r4                                    r5 = r4
    add64 r5, 88                                    r5 += 88   ///  r5 = r5.wrapping_add(88 as i32 as i64 as u64)
    stxdw [r7+0x18], r5                     
    stxdw [r7+0x10], r0                     
    add64 r4, 72                                    r4 += 72   ///  r4 = r4.wrapping_add(72 as i32 as i64 as u64)
    stxdw [r7+0x8], r4                      
    stdw [r7+0x28], 0                       
    add64 r3, 16                                    r3 += 16   ///  r3 = r3.wrapping_add(16 as i32 as i64 as u64)
    add64 r1, 8                                     r1 += 8   ///  r1 = r1.wrapping_add(8 as i32 as i64 as u64)
    add64 r2, 56                                    r2 += 56   ///  r2 = r2.wrapping_add(56 as i32 as i64 as u64)
    jeq r2, 728, lbb_5471                           if r2 == (728 as i32 as i64 as u64) { pc += 50 }
lbb_5421:
    mov64 r5, r10                                   r5 = r10
    add64 r5, -768                                  r5 += -768   ///  r5 = r5.wrapping_add(-768 as i32 as i64 as u64)
    mov64 r0, 1                                     r0 = 1 as i32 as i64 as u64
    ldxdw r4, [r1+0x0]                      
    ldxdw r4, [r4+0x0]                      
    ldxdw r6, [r3-0x8]                      
    ldxdw r7, [r6+0x0]                      
    ldxdw r8, [r4+0x8]                      
    jne r8, r7, lbb_5490                            if r8 != r7 { pc += 60 }
    ldxdw r7, [r6+0x8]                      
    ldxdw r8, [r4+0x10]                     
    jne r8, r7, lbb_5490                            if r8 != r7 { pc += 57 }
    ldxdw r7, [r6+0x10]                     
    ldxdw r8, [r4+0x18]                     
    jne r8, r7, lbb_5490                            if r8 != r7 { pc += 54 }
    ldxdw r6, [r6+0x18]                     
    ldxdw r7, [r4+0x20]                     
    jne r7, r6, lbb_5490                            if r7 != r6 { pc += 51 }
    ldxb r6, [r3+0x0]                       
    mov64 r0, 0                                     r0 = 0 as i32 as i64 as u64
    jne r6, 0, lbb_5443                             if r6 != (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r0, 119                                   r0 = 119 as i32 as i64 as u64
lbb_5443:
    ldxb r6, [r4+0x0]                       
    or64 r0, r6                                     r0 |= r6   ///  r0 = r0.or(r6)
    and64 r0, 255                                   r0 &= 255   ///  r0 = r0.and(255)
    jne r0, 255, lbb_5469                           if r0 != (255 as i32 as i64 as u64) { pc += 22 }
    add64 r5, r2                                    r5 += r2   ///  r5 = r5.wrapping_add(r2)
    mov64 r6, r4                                    r6 = r4
    add64 r6, 8                                     r6 += 8   ///  r6 = r6.wrapping_add(8 as i32 as i64 as u64)
    ldxdw r0, [r4+0x50]                     
    ldxb r7, [r4+0x3]                       
    ldxb r9, [r4+0x2]                       
    ldxb r8, [r4+0x1]                       
    stxdw [r5+0x0], r6                      
    mov64 r6, 1                                     r6 = 1 as i32 as i64 as u64
    mov64 r5, 1                                     r5 = 1 as i32 as i64 as u64
    jeq r8, 0, lbb_5462                             if r8 == (0 as i32 as i64 as u64) { pc += 4 }
    mov64 r8, 1                                     r8 = 1 as i32 as i64 as u64
    jeq r9, 0, lbb_5465                             if r9 == (0 as i32 as i64 as u64) { pc += 5 }
lbb_5460:
    jne r7, 0, lbb_5401                             if r7 != (0 as i32 as i64 as u64) { pc += -60 }
    ja lbb_5467                                     if true { pc += 5 }
lbb_5462:
    mov64 r5, 0                                     r5 = 0 as i32 as i64 as u64
    mov64 r8, 1                                     r8 = 1 as i32 as i64 as u64
    jne r9, 0, lbb_5460                             if r9 != (0 as i32 as i64 as u64) { pc += -5 }
lbb_5465:
    mov64 r8, 0                                     r8 = 0 as i32 as i64 as u64
    jne r7, 0, lbb_5401                             if r7 != (0 as i32 as i64 as u64) { pc += -66 }
lbb_5467:
    mov64 r6, 0                                     r6 = 0 as i32 as i64 as u64
    ja lbb_5401                                     if true { pc += -68 }
lbb_5469:
    mov64 r0, 11                                    r0 = 11 as i32 as i64 as u64
    ja lbb_5490                                     if true { pc += 19 }
lbb_5471:
    mov64 r1, r10                                   r1 = r10
    add64 r1, -896                                  r1 += -896   ///  r1 = r1.wrapping_add(-896 as i32 as i64 as u64)
    stxdw [r10-0x10], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -1104                                 r1 += -1104   ///  r1 = r1.wrapping_add(-1104 as i32 as i64 as u64)
    stxdw [r10-0x20], r1                    
    ldxdw r1, [r10-0x460]                   
    stxdw [r10-0x28], r1                    
    stdw [r10-0x8], 24                      
    stdw [r10-0x18], 13                     
    mov64 r1, r10                                   r1 = r10
    add64 r1, -40                                   r1 += -40   ///  r1 = r1.wrapping_add(-40 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -768                                  r2 += -768   ///  r2 = r2.wrapping_add(-768 as i32 as i64 as u64)
    mov64 r3, 13                                    r3 = 13 as i32 as i64 as u64
    mov64 r4, 8                                     r4 = 8 as i32 as i64 as u64
    mov64 r5, 0                                     r5 = 0 as i32 as i64 as u64
    syscall [invalid]                       
    mov64 r0, 26                                    r0 = 26 as i32 as i64 as u64
lbb_5490:
    ldxdw r1, [r10-0x458]                   
lbb_5491:
    stxw [r1+0x0], r0                       
    stw [r1+0x4], 0                         
    exit                                    
lbb_5494:
    mov64 r0, 3                                     r0 = 3 as i32 as i64 as u64
    ja lbb_5491                                     if true { pc += -5 }
lbb_5496:
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    mov64 r2, 1                                     r2 = 1 as i32 as i64 as u64
    lddw r3, 0x1000268f0 --> b"\x00\x00\x00\x00\xb8Y\x02\x00\x10\x00\x00\x00\x00\x00\x00\x00\x0b!\x00\x0…        r3 load str located at 4295125232
    call function_18489                     
lbb_5501:
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
    lddw r3, 0x1000268d8 --> b"\x00\x00\x00\x00\xb8Y\x02\x00\x10\x00\x00\x00\x00\x00\x00\x00\x0b!\x00\x0…        r3 load str located at 4295125208
    call function_18489                     
lbb_5506:
    mov64 r1, 2                                     r1 = 2 as i32 as i64 as u64
    mov64 r2, 2                                     r2 = 2 as i32 as i64 as u64
    lddw r3, 0x100026908 --> b"\x00\x00\x00\x00\xb8Y\x02\x00\x10\x00\x00\x00\x00\x00\x00\x00\x0b!\x00\x0…        r3 load str located at 4295125256
    call function_18489                     
lbb_5511:
    mov64 r1, 3                                     r1 = 3 as i32 as i64 as u64
    mov64 r2, 3                                     r2 = 3 as i32 as i64 as u64
    lddw r3, 0x100026920 --> b"\x00\x00\x00\x00\xb8Y\x02\x00\x10\x00\x00\x00\x00\x00\x00\x00\x0b!\x00\x0…        r3 load str located at 4295125280
    call function_18489                     
lbb_5516:
    mov64 r1, 4                                     r1 = 4 as i32 as i64 as u64
    mov64 r2, 4                                     r2 = 4 as i32 as i64 as u64
    lddw r3, 0x100026938 --> b"\x00\x00\x00\x00\xb8Y\x02\x00\x10\x00\x00\x00\x00\x00\x00\x00\x0c!\x00\x0…        r3 load str located at 4295125304
    call function_18489                     
lbb_5521:
    mov64 r1, 5                                     r1 = 5 as i32 as i64 as u64
    mov64 r2, 5                                     r2 = 5 as i32 as i64 as u64
    lddw r3, 0x100026950 --> b"\x00\x00\x00\x00\xb8Y\x02\x00\x10\x00\x00\x00\x00\x00\x00\x00\x0c!\x00\x0…        r3 load str located at 4295125328
    call function_18489                     
lbb_5526:
    mov64 r1, 6                                     r1 = 6 as i32 as i64 as u64
    mov64 r2, 6                                     r2 = 6 as i32 as i64 as u64
    lddw r3, 0x100026968 --> b"\x00\x00\x00\x00\xb8Y\x02\x00\x10\x00\x00\x00\x00\x00\x00\x00\x0c!\x00\x0…        r3 load str located at 4295125352
    call function_18489                     
lbb_5531:
    mov64 r1, 7                                     r1 = 7 as i32 as i64 as u64
    mov64 r2, 7                                     r2 = 7 as i32 as i64 as u64
    lddw r3, 0x100026980 --> b"\x00\x00\x00\x00\xb8Y\x02\x00\x10\x00\x00\x00\x00\x00\x00\x00\x0c!\x00\x0…        r3 load str located at 4295125376
    call function_18489                     
lbb_5536:
    mov64 r1, 8                                     r1 = 8 as i32 as i64 as u64
    mov64 r2, 8                                     r2 = 8 as i32 as i64 as u64
    lddw r3, 0x100026998 --> b"\x00\x00\x00\x00\xb8Y\x02\x00\x10\x00\x00\x00\x00\x00\x00\x00\x0d!\x00\x0…        r3 load str located at 4295125400
    call function_18489                     
lbb_5541:
    mov64 r1, 9                                     r1 = 9 as i32 as i64 as u64
    mov64 r2, 9                                     r2 = 9 as i32 as i64 as u64
    lddw r3, 0x1000269b0 --> b"\x00\x00\x00\x00\xb8Y\x02\x00\x10\x00\x00\x00\x00\x00\x00\x00\x0d!\x00\x0…        r3 load str located at 4295125424
    call function_18489                     
    ldxdw r3, [r2+0x8]                      
    jeq r3, 1, lbb_5763                             if r3 == (1 as i32 as i64 as u64) { pc += 215 }
    jeq r3, 0, lbb_5768                             if r3 == (0 as i32 as i64 as u64) { pc += 219 }
    jle r3, 2, lbb_5773                             if r3 <= (2 as i32 as i64 as u64) { pc += 223 }
    jeq r3, 3, lbb_5778                             if r3 == (3 as i32 as i64 as u64) { pc += 227 }
    ldxdw r9, [r2+0x50]                     
    mov64 r6, 3                                     r6 = 3 as i32 as i64 as u64
    ldxdw r3, [r9+0x0]                      
    ldxdw r4, [r3+0x50]                     
    jlt r4, 32, lbb_5760                            if r4 < (32 as i32 as i64 as u64) { pc += 204 }
    ldxdw r4, [r2+0x0]                      
    mov64 r7, r4                                    r7 = r4
    add64 r7, 16                                    r7 += 16   ///  r7 = r7.wrapping_add(16 as i32 as i64 as u64)
    ldxdw r0, [r7+0x0]                      
    ldxdw r5, [r0+0x50]                     
    jlt r5, 32, lbb_5760                            if r5 < (32 as i32 as i64 as u64) { pc += 198 }
    stxdw [r10-0x328], r7                   
    ldxdw r5, [r2+0x58]                     
    ldxdw r6, [r2+0x48]                     
    stxdw [r10-0x318], r6                   
    ldxdw r6, [r2+0x28]                     
    stxdw [r10-0x330], r6                   
    ldxdw r6, [r2+0x20]                     
    ldxb r7, [r2+0x62]                      
    stxdw [r10-0x348], r7                   
    ldxdw r2, [r2+0x10]                     
    stxdw [r10-0x350], r2                   
    mov64 r2, r4                                    r2 = r4
    add64 r2, 24                                    r2 += 24   ///  r2 = r2.wrapping_add(24 as i32 as i64 as u64)
    stxdw [r10-0x340], r2                   
    mov64 r2, r4                                    r2 = r4
    add64 r2, 8                                     r2 += 8   ///  r2 = r2.wrapping_add(8 as i32 as i64 as u64)
    ldxdw r8, [r0+0x58]                     
    ldxdw r7, [r3+0x58]                     
    stxdw [r10-0x320], r1                   
    stxdw [r10-0x338], r2                   
    jne r7, r8, lbb_5595                            if r7 != r8 { pc += 12 }
    ldxdw r7, [r0+0x60]                     
    ldxdw r8, [r3+0x60]                     
    jne r8, r7, lbb_5595                            if r8 != r7 { pc += 9 }
    ldxdw r7, [r0+0x68]                     
    ldxdw r8, [r3+0x68]                     
    jne r8, r7, lbb_5595                            if r8 != r7 { pc += 6 }
    ldxdw r7, [r0+0x70]                     
    ldxdw r3, [r3+0x70]                     
    jne r3, r7, lbb_5595                            if r3 != r7 { pc += 3 }
    mov64 r2, r9                                    r2 = r9
    mov64 r9, r5                                    r9 = r5
    ja lbb_5596                                     if true { pc += 1 }
lbb_5595:
    mov64 r2, r5                                    r2 = r5
lbb_5596:
    stxdw [r10-0x368], r9                   
    stxdw [r10-0x360], r2                   
    add64 r0, 8                                     r0 += 8   ///  r0 = r0.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x358], r6                   
    ldxdw r6, [r6+0x0]                      
    ldxdw r1, [r4+0x0]                      
    ldxdw r8, [r4+0x8]                      
    ldxdw r3, [r10-0x318]                   
    ldxdw r7, [r3+0x0]                      
    ldxdw r3, [r2+0x0]                      
    ldxdw r2, [r9+0x0]                      
    ldxdw r9, [r4+0x18]                     
    stxdw [r10-0x370], r4                   
    ldxdw r4, [r10-0x330]                   
    ldxdw r5, [r4+0x0]                      
    stxdw [r10-0x2b0], r0                   
    add64 r5, 8                                     r5 += 8   ///  r5 = r5.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x290], r5                   
    add64 r9, 8                                     r9 += 8   ///  r9 = r9.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x2a0], r9                   
    add64 r2, 8                                     r2 += 8   ///  r2 = r2.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x2c0], r2                   
    add64 r3, 8                                     r3 += 8   ///  r3 = r3.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x2d0], r3                   
    add64 r7, 8                                     r7 += 8   ///  r7 = r7.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x2e0], r7                   
    add64 r8, 8                                     r8 += 8   ///  r8 = r8.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x2f0], r8                   
    add64 r1, 8                                     r1 += 8   ///  r1 = r1.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x300], r1                   
    add64 r6, 8                                     r6 += 8   ///  r6 = r6.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x378], r6                   
    stxdw [r10-0x310], r6                   
    sth [r10-0x288], 0                      
    sth [r10-0x298], 1                      
    sth [r10-0x2a8], 1                      
    sth [r10-0x2b8], 1                      
    sth [r10-0x2c8], 1                      
    sth [r10-0x2d8], 257                    
    sth [r10-0x2e8], 1                      
    sth [r10-0x2f8], 0                      
    sth [r10-0x308], 0                      
    stdw [r10-0x278], 0                     
    stdw [r10-0x280], 0                     
    ldxdw r1, [r10-0x350]                   
    stxdw [r10-0x27d], r1                   
    ldxdw r1, [r10-0x348]                   
    xor64 r1, -1                                    r1 ^= -1   ///  r1 = r1.xor(-1)
    and64 r1, 1                                     r1 &= 1   ///  r1 = r1.and(1)
    stxb [r10-0x27f], r1                    
    stw [r10-0x271], 0                      
    stxdw [r10-0x228], r4                   
    ldxdw r1, [r10-0x340]                   
    stxdw [r10-0x230], r1                   
    ldxdw r1, [r10-0x328]                   
    stxdw [r10-0x238], r1                   
    ldxdw r1, [r10-0x368]                   
    stxdw [r10-0x240], r1                   
    ldxdw r1, [r10-0x360]                   
    stxdw [r10-0x248], r1                   
    ldxdw r1, [r10-0x318]                   
    stxdw [r10-0x250], r1                   
    ldxdw r1, [r10-0x338]                   
    stxdw [r10-0x258], r1                   
    ldxdw r1, [r10-0x370]                   
    stxdw [r10-0x260], r1                   
    ldxdw r1, [r10-0x358]                   
    stxdw [r10-0x268], r1                   
    mov64 r2, r10                                   r2 = r10
    add64 r2, -616                                  r2 += -616   ///  r2 = r2.wrapping_add(-616 as i32 as i64 as u64)
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
    mov64 r4, r10                                   r4 = r10
    add64 r4, -776                                  r4 += -776   ///  r4 = r4.wrapping_add(-776 as i32 as i64 as u64)
    ja lbb_5690                                     if true { pc += 20 }
lbb_5670:
    mov64 r7, r10                                   r7 = r10
    add64 r7, -544                                  r7 += -544   ///  r7 = r7.wrapping_add(-544 as i32 as i64 as u64)
    add64 r7, r3                                    r7 += r3   ///  r7 = r7.wrapping_add(r3)
    stxb [r7+0x32], r6                      
    stxb [r7+0x31], r8                      
    stxb [r7+0x30], r1                      
    mov64 r1, r5                                    r1 = r5
    add64 r1, 40                                    r1 += 40   ///  r1 = r1.wrapping_add(40 as i32 as i64 as u64)
    stxdw [r7+0x20], r1                     
    mov64 r1, r5                                    r1 = r5
    add64 r1, 88                                    r1 += 88   ///  r1 = r1.wrapping_add(88 as i32 as i64 as u64)
    stxdw [r7+0x18], r1                     
    stxdw [r7+0x10], r0                     
    add64 r5, 72                                    r5 += 72   ///  r5 = r5.wrapping_add(72 as i32 as i64 as u64)
    stxdw [r7+0x8], r5                      
    stdw [r7+0x28], 0                       
    add64 r4, 16                                    r4 += 16   ///  r4 = r4.wrapping_add(16 as i32 as i64 as u64)
    add64 r2, 8                                     r2 += 8   ///  r2 = r2.wrapping_add(8 as i32 as i64 as u64)
    add64 r3, 56                                    r3 += 56   ///  r3 = r3.wrapping_add(56 as i32 as i64 as u64)
    jeq r3, 504, lbb_5740                           if r3 == (504 as i32 as i64 as u64) { pc += 50 }
lbb_5690:
    mov64 r1, r10                                   r1 = r10
    add64 r1, -544                                  r1 += -544   ///  r1 = r1.wrapping_add(-544 as i32 as i64 as u64)
    mov64 r6, 1                                     r6 = 1 as i32 as i64 as u64
    ldxdw r5, [r2+0x0]                      
    ldxdw r5, [r5+0x0]                      
    ldxdw r0, [r4-0x8]                      
    ldxdw r7, [r0+0x0]                      
    ldxdw r8, [r5+0x8]                      
    jne r8, r7, lbb_5759                            if r8 != r7 { pc += 60 }
    ldxdw r7, [r0+0x8]                      
    ldxdw r8, [r5+0x10]                     
    jne r8, r7, lbb_5759                            if r8 != r7 { pc += 57 }
    ldxdw r7, [r0+0x10]                     
    ldxdw r8, [r5+0x18]                     
    jne r8, r7, lbb_5759                            if r8 != r7 { pc += 54 }
    ldxdw r0, [r0+0x18]                     
    ldxdw r7, [r5+0x20]                     
    jne r7, r0, lbb_5759                            if r7 != r0 { pc += 51 }
    ldxb r6, [r4+0x0]                       
    mov64 r0, 0                                     r0 = 0 as i32 as i64 as u64
    jne r6, 0, lbb_5712                             if r6 != (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r0, 119                                   r0 = 119 as i32 as i64 as u64
lbb_5712:
    ldxb r6, [r5+0x0]                       
    or64 r0, r6                                     r0 |= r6   ///  r0 = r0.or(r6)
    and64 r0, 255                                   r0 &= 255   ///  r0 = r0.and(255)
    jne r0, 255, lbb_5738                           if r0 != (255 as i32 as i64 as u64) { pc += 22 }
    add64 r1, r3                                    r1 += r3   ///  r1 = r1.wrapping_add(r3)
    mov64 r6, r5                                    r6 = r5
    add64 r6, 8                                     r6 += 8   ///  r6 = r6.wrapping_add(8 as i32 as i64 as u64)
    ldxdw r0, [r5+0x50]                     
    ldxb r7, [r5+0x3]                       
    ldxb r9, [r5+0x2]                       
    ldxb r8, [r5+0x1]                       
    stxdw [r1+0x0], r6                      
    mov64 r6, 1                                     r6 = 1 as i32 as i64 as u64
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    jeq r8, 0, lbb_5731                             if r8 == (0 as i32 as i64 as u64) { pc += 4 }
    mov64 r8, 1                                     r8 = 1 as i32 as i64 as u64
    jeq r9, 0, lbb_5734                             if r9 == (0 as i32 as i64 as u64) { pc += 5 }
lbb_5729:
    jne r7, 0, lbb_5670                             if r7 != (0 as i32 as i64 as u64) { pc += -60 }
    ja lbb_5736                                     if true { pc += 5 }
lbb_5731:
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    mov64 r8, 1                                     r8 = 1 as i32 as i64 as u64
    jne r9, 0, lbb_5729                             if r9 != (0 as i32 as i64 as u64) { pc += -5 }
lbb_5734:
    mov64 r8, 0                                     r8 = 0 as i32 as i64 as u64
    jne r7, 0, lbb_5670                             if r7 != (0 as i32 as i64 as u64) { pc += -66 }
lbb_5736:
    mov64 r6, 0                                     r6 = 0 as i32 as i64 as u64
    ja lbb_5670                                     if true { pc += -68 }
lbb_5738:
    mov64 r6, 11                                    r6 = 11 as i32 as i64 as u64
    ja lbb_5759                                     if true { pc += 19 }
lbb_5740:
    mov64 r1, r10                                   r1 = r10
    add64 r1, -640                                  r1 += -640   ///  r1 = r1.wrapping_add(-640 as i32 as i64 as u64)
    stxdw [r10-0x10], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -784                                  r1 += -784   ///  r1 = r1.wrapping_add(-784 as i32 as i64 as u64)
    stxdw [r10-0x20], r1                    
    ldxdw r1, [r10-0x378]                   
    stxdw [r10-0x28], r1                    
    stdw [r10-0x8], 19                      
    stdw [r10-0x18], 9                      
    mov64 r1, r10                                   r1 = r10
    add64 r1, -40                                   r1 += -40   ///  r1 = r1.wrapping_add(-40 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -544                                  r2 += -544   ///  r2 = r2.wrapping_add(-544 as i32 as i64 as u64)
    mov64 r3, 9                                     r3 = 9 as i32 as i64 as u64
    mov64 r4, 8                                     r4 = 8 as i32 as i64 as u64
    mov64 r5, 0                                     r5 = 0 as i32 as i64 as u64
    syscall [invalid]                       
    mov64 r6, 26                                    r6 = 26 as i32 as i64 as u64
lbb_5759:
    ldxdw r1, [r10-0x320]                   
lbb_5760:
    stxw [r1+0x0], r6                       
    stw [r1+0x4], 0                         
    exit                                    
lbb_5763:
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    mov64 r2, 1                                     r2 = 1 as i32 as i64 as u64
    lddw r3, 0x1000269e0 --> b"\x00\x00\x00\x00\xb8Y\x02\x00\x10\x00\x00\x00\x00\x00\x00\x00\x16!\x00\x0…        r3 load str located at 4295125472
    call function_18489                     
lbb_5768:
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
    lddw r3, 0x1000269c8 --> b"\x00\x00\x00\x00\xb8Y\x02\x00\x10\x00\x00\x00\x00\x00\x00\x00\x16!\x00\x0…        r3 load str located at 4295125448
    call function_18489                     
lbb_5773:
    mov64 r1, 2                                     r1 = 2 as i32 as i64 as u64
    mov64 r2, 2                                     r2 = 2 as i32 as i64 as u64
    lddw r3, 0x1000269f8 --> b"\x00\x00\x00\x00\xb8Y\x02\x00\x10\x00\x00\x00\x00\x00\x00\x00\x16!\x00\x0…        r3 load str located at 4295125496
    call function_18489                     
lbb_5778:
    mov64 r1, 3                                     r1 = 3 as i32 as i64 as u64
    mov64 r2, 3                                     r2 = 3 as i32 as i64 as u64
    lddw r3, 0x100026a10 --> b"\x00\x00\x00\x00\xb8Y\x02\x00\x10\x00\x00\x00\x00\x00\x00\x00\x16!\x00\x0…        r3 load str located at 4295125520
    call function_18489                     
    ldxdw r3, [r2+0x8]                      
    jeq r3, 1, lbb_6075                             if r3 == (1 as i32 as i64 as u64) { pc += 290 }
    jeq r3, 0, lbb_6080                             if r3 == (0 as i32 as i64 as u64) { pc += 294 }
    jle r3, 2, lbb_6085                             if r3 <= (2 as i32 as i64 as u64) { pc += 298 }
    jeq r3, 3, lbb_6090                             if r3 == (3 as i32 as i64 as u64) { pc += 302 }
    jle r3, 4, lbb_6095                             if r3 <= (4 as i32 as i64 as u64) { pc += 306 }
    jeq r3, 5, lbb_6100                             if r3 == (5 as i32 as i64 as u64) { pc += 310 }
    jle r3, 6, lbb_6105                             if r3 <= (6 as i32 as i64 as u64) { pc += 314 }
    jeq r3, 7, lbb_6110                             if r3 == (7 as i32 as i64 as u64) { pc += 318 }
    stxdw [r10-0x500], r1                   
    ldxdw r0, [r2+0x0]                      
    ldxdw r6, [r2+0x30]                     
    ldxdw r8, [r2+0x28]                     
    mov64 r5, r0                                    r5 = r0
    add64 r5, 40                                    r5 += 40   ///  r5 = r5.wrapping_add(40 as i32 as i64 as u64)
    ldxdw r1, [r0+0x20]                     
    ldxdw r3, [r1+0x28]                     
    lddw r4, 0xde8f75eee1f6dd06                     r4 load str located at -2409577606766207738
    mov64 r7, r8                                    r7 = r8
    jne r3, r4, lbb_5820                            if r3 != r4 { pc += 16 }
    ldxdw r4, [r1+0x30]                     
    lddw r3, 0xdacd6ce4bc5d4218                     r3 load str located at -2680366473547005416
    mov64 r7, r8                                    r7 = r8
    jne r4, r3, lbb_5820                            if r4 != r3 { pc += 11 }
    ldxdw r4, [r1+0x38]                     
    lddw r3, 0x270db9834dfc1ab6                     r3 load str located at 2814109315776649910
    mov64 r7, r8                                    r7 = r8
    jne r4, r3, lbb_5820                            if r4 != r3 { pc += 6 }
    ldxdw r4, [r1+0x40]                     
    lddw r3, 0xfc8ba1d828f9bdfe                     r3 load str located at -248927404616466946
    mov64 r7, r8                                    r7 = r8
    jne r4, r3, lbb_5820                            if r4 != r3 { pc += 1 }
    mov64 r7, r6                                    r7 = r6
lbb_5820:
    stxdw [r10-0x550], r6                   
    stxdw [r10-0x548], r1                   
    ldxdw r9, [r2+0x58]                     
    ldxdw r4, [r2+0x50]                     
    ldxdw r3, [r2+0x48]                     
    ldxdw r1, [r2+0x20]                     
    stxdw [r10-0x4f8], r1                   
    ldxdw r1, [r2+0x10]                     
    stxdw [r10-0x538], r1                   
    mov64 r1, r0                                    r1 = r0
    add64 r1, 56                                    r1 += 56   ///  r1 = r1.wrapping_add(56 as i32 as i64 as u64)
    stxdw [r10-0x530], r1                   
    mov64 r2, r0                                    r2 = r0
    add64 r2, 8                                     r2 += 8   ///  r2 = r2.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x510], r2                   
    mov64 r1, r0                                    r1 = r0
    add64 r1, 16                                    r1 += 16   ///  r1 = r1.wrapping_add(16 as i32 as i64 as u64)
    stxdw [r10-0x518], r1                   
    mov64 r1, r0                                    r1 = r0
    add64 r1, 24                                    r1 += 24   ///  r1 = r1.wrapping_add(24 as i32 as i64 as u64)
    stxdw [r10-0x520], r1                   
    mov64 r1, r0                                    r1 = r0
    add64 r1, 32                                    r1 += 32   ///  r1 = r1.wrapping_add(32 as i32 as i64 as u64)
    stxdw [r10-0x528], r1                   
    mov64 r1, r0                                    r1 = r0
    add64 r1, 48                                    r1 += 48   ///  r1 = r1.wrapping_add(48 as i32 as i64 as u64)
    stxdw [r10-0x540], r1                   
    ldxdw r6, [r5+0x0]                      
    ldxdw r2, [r6+0x28]                     
    lddw r1, 0xde8f75eee1f6dd06                     r1 load str located at -2409577606766207738
    stxdw [r10-0x508], r5                   
    jne r2, r1, lbb_5870                            if r2 != r1 { pc += 17 }
    mov64 r1, r3                                    r1 = r3
    ldxdw r3, [r6+0x30]                     
    lddw r2, 0xdacd6ce4bc5d4218                     r2 load str located at -2680366473547005416
    jne r3, r2, lbb_5869                            if r3 != r2 { pc += 11 }
    ldxdw r3, [r6+0x38]                     
    lddw r2, 0x270db9834dfc1ab6                     r2 load str located at 2814109315776649910
    jne r3, r2, lbb_5869                            if r3 != r2 { pc += 7 }
    ldxdw r5, [r6+0x40]                     
    lddw r2, 0xfc8ba1d828f9bdfe                     r2 load str located at -248927404616466946
    mov64 r3, r1                                    r3 = r1
    jne r5, r2, lbb_5870                            if r5 != r2 { pc += 3 }
    ldxdw r8, [r10-0x550]                   
    ja lbb_5870                                     if true { pc += 1 }
lbb_5869:
    mov64 r3, r1                                    r3 = r1
lbb_5870:
    stxdw [r10-0x560], r3                   
    add64 r6, 8                                     r6 += 8   ///  r6 = r6.wrapping_add(8 as i32 as i64 as u64)
    ldxdw r1, [r10-0x4f8]                   
    ldxdw r2, [r1+0x0]                      
    ldxdw r1, [r0+0x0]                      
    stxdw [r10-0x570], r1                   
    ldxdw r1, [r0+0x8]                      
    stxdw [r10-0x578], r1                   
    ldxdw r1, [r4+0x0]                      
    stxdw [r10-0x580], r1                   
    ldxdw r1, [r9+0x0]                      
    stxdw [r10-0x588], r1                   
    mov64 r5, r8                                    r5 = r8
    stxdw [r10-0x568], r5                   
    ldxdw r1, [r0+0x10]                     
    stxdw [r10-0x590], r1                   
    stxdw [r10-0x550], r9                   
    ldxdw r9, [r0+0x18]                     
    ldxdw r1, [r3+0x0]                      
    ldxdw r8, [r7+0x0]                      
    ldxdw r3, [r5+0x0]                      
    stxdw [r10-0x558], r4                   
    ldxdw r4, [r0+0x30]                     
    ldxdw r5, [r0+0x38]                     
    stxdw [r10-0x480], r6                   
    ldxdw r6, [r10-0x548]                   
    add64 r6, 8                                     r6 += 8   ///  r6 = r6.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x490], r6                   
    add64 r5, 8                                     r5 += 8   ///  r5 = r5.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x410], r5                   
    add64 r4, 8                                     r4 += 8   ///  r4 = r4.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x430], r4                   
    add64 r3, 8                                     r3 += 8   ///  r3 = r3.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x450], r3                   
    add64 r8, 8                                     r8 += 8   ///  r8 = r8.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x460], r8                   
    add64 r1, 8                                     r1 += 8   ///  r1 = r1.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x470], r1                   
    add64 r9, 8                                     r9 += 8   ///  r9 = r9.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x4a0], r9                   
    ldxdw r1, [r10-0x590]                   
    add64 r1, 8                                     r1 += 8   ///  r1 = r1.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x4b0], r1                   
    ldxdw r1, [r10-0x588]                   
    add64 r1, 8                                     r1 += 8   ///  r1 = r1.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x4c0], r1                   
    ldxdw r1, [r10-0x580]                   
    add64 r1, 8                                     r1 += 8   ///  r1 = r1.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x4d0], r1                   
    ldxdw r1, [r10-0x578]                   
    add64 r1, 8                                     r1 += 8   ///  r1 = r1.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x4e0], r1                   
    ldxdw r1, [r10-0x570]                   
    add64 r1, 8                                     r1 += 8   ///  r1 = r1.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x4f0], r1                   
    add64 r2, 8                                     r2 += 8   ///  r2 = r2.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x420], r2                   
    stxdw [r10-0x548], r2                   
    stxdw [r10-0x440], r2                   
    sth [r10-0x408], 0                      
    sth [r10-0x418], 0                      
    sth [r10-0x428], 0                      
    sth [r10-0x438], 0                      
    sth [r10-0x448], 0                      
    sth [r10-0x458], 0                      
    sth [r10-0x468], 257                    
    sth [r10-0x478], 0                      
    sth [r10-0x488], 0                      
    sth [r10-0x498], 1                      
    sth [r10-0x4a8], 1                      
    sth [r10-0x4b8], 1                      
    sth [r10-0x4c8], 1                      
    sth [r10-0x4d8], 1                      
    sth [r10-0x4e8], 0                      
    ldxdw r1, [r10-0x538]                   
    stxdw [r10-0x3f8], r1                   
    lddw r1, 0xc88775e1919ec6f8                     r1 load str located at -3997096532596832520
    stxdw [r10-0x400], r1                   
    stdw [r10-0x3f0], 0                     
    ldxdw r1, [r10-0x530]                   
    stxdw [r10-0x378], r1                   
    ldxdw r1, [r10-0x540]                   
    stxdw [r10-0x388], r1                   
    ldxdw r1, [r10-0x4f8]                   
    stxdw [r10-0x380], r1                   
    stxdw [r10-0x390], r1                   
    ldxdw r1, [r10-0x568]                   
    stxdw [r10-0x398], r1                   
    stxdw [r10-0x3a0], r7                   
    ldxdw r1, [r10-0x560]                   
    stxdw [r10-0x3a8], r1                   
    ldxdw r1, [r10-0x508]                   
    stxdw [r10-0x3b0], r1                   
    ldxdw r1, [r10-0x528]                   
    stxdw [r10-0x3b8], r1                   
    ldxdw r1, [r10-0x520]                   
    stxdw [r10-0x3c0], r1                   
    ldxdw r1, [r10-0x518]                   
    stxdw [r10-0x3c8], r1                   
    ldxdw r1, [r10-0x550]                   
    stxdw [r10-0x3d0], r1                   
    ldxdw r1, [r10-0x558]                   
    stxdw [r10-0x3d8], r1                   
    ldxdw r1, [r10-0x510]                   
    stxdw [r10-0x3e0], r1                   
    stxdw [r10-0x3e8], r0                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -1000                                 r1 += -1000   ///  r1 = r1.wrapping_add(-1000 as i32 as i64 as u64)
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
    mov64 r3, r10                                   r3 = r10
    add64 r3, -1256                                 r3 += -1256   ///  r3 = r3.wrapping_add(-1256 as i32 as i64 as u64)
    ja lbb_6003                                     if true { pc += 20 }
lbb_5983:
    mov64 r7, r10                                   r7 = r10
    add64 r7, -880                                  r7 += -880   ///  r7 = r7.wrapping_add(-880 as i32 as i64 as u64)
    add64 r7, r2                                    r7 += r2   ///  r7 = r7.wrapping_add(r2)
    stxb [r7+0x32], r6                      
    stxb [r7+0x31], r8                      
    stxb [r7+0x30], r5                      
    mov64 r5, r4                                    r5 = r4
    add64 r5, 40                                    r5 += 40   ///  r5 = r5.wrapping_add(40 as i32 as i64 as u64)
    stxdw [r7+0x20], r5                     
    mov64 r5, r4                                    r5 = r4
    add64 r5, 88                                    r5 += 88   ///  r5 = r5.wrapping_add(88 as i32 as i64 as u64)
    stxdw [r7+0x18], r5                     
    stxdw [r7+0x10], r0                     
    add64 r4, 72                                    r4 += 72   ///  r4 = r4.wrapping_add(72 as i32 as i64 as u64)
    stxdw [r7+0x8], r4                      
    stdw [r7+0x28], 0                       
    add64 r3, 16                                    r3 += 16   ///  r3 = r3.wrapping_add(16 as i32 as i64 as u64)
    add64 r1, 8                                     r1 += 8   ///  r1 = r1.wrapping_add(8 as i32 as i64 as u64)
    add64 r2, 56                                    r2 += 56   ///  r2 = r2.wrapping_add(56 as i32 as i64 as u64)
    jeq r2, 840, lbb_6053                           if r2 == (840 as i32 as i64 as u64) { pc += 50 }
lbb_6003:
    mov64 r5, r10                                   r5 = r10
    add64 r5, -880                                  r5 += -880   ///  r5 = r5.wrapping_add(-880 as i32 as i64 as u64)
    mov64 r0, 1                                     r0 = 1 as i32 as i64 as u64
    ldxdw r4, [r1+0x0]                      
    ldxdw r4, [r4+0x0]                      
    ldxdw r6, [r3-0x8]                      
    ldxdw r7, [r6+0x0]                      
    ldxdw r8, [r4+0x8]                      
    jne r8, r7, lbb_6072                            if r8 != r7 { pc += 60 }
    ldxdw r7, [r6+0x8]                      
    ldxdw r8, [r4+0x10]                     
    jne r8, r7, lbb_6072                            if r8 != r7 { pc += 57 }
    ldxdw r7, [r6+0x10]                     
    ldxdw r8, [r4+0x18]                     
    jne r8, r7, lbb_6072                            if r8 != r7 { pc += 54 }
    ldxdw r6, [r6+0x18]                     
    ldxdw r7, [r4+0x20]                     
    jne r7, r6, lbb_6072                            if r7 != r6 { pc += 51 }
    ldxb r6, [r3+0x0]                       
    mov64 r0, 0                                     r0 = 0 as i32 as i64 as u64
    jne r6, 0, lbb_6025                             if r6 != (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r0, 119                                   r0 = 119 as i32 as i64 as u64
lbb_6025:
    ldxb r6, [r4+0x0]                       
    or64 r0, r6                                     r0 |= r6   ///  r0 = r0.or(r6)
    and64 r0, 255                                   r0 &= 255   ///  r0 = r0.and(255)
    jne r0, 255, lbb_6051                           if r0 != (255 as i32 as i64 as u64) { pc += 22 }
    add64 r5, r2                                    r5 += r2   ///  r5 = r5.wrapping_add(r2)
    mov64 r6, r4                                    r6 = r4
    add64 r6, 8                                     r6 += 8   ///  r6 = r6.wrapping_add(8 as i32 as i64 as u64)
    ldxdw r0, [r4+0x50]                     
    ldxb r7, [r4+0x3]                       
    ldxb r9, [r4+0x2]                       
    ldxb r8, [r4+0x1]                       
    stxdw [r5+0x0], r6                      
    mov64 r6, 1                                     r6 = 1 as i32 as i64 as u64
    mov64 r5, 1                                     r5 = 1 as i32 as i64 as u64
    jne r8, 0, lbb_6045                             if r8 != (0 as i32 as i64 as u64) { pc += 5 }
    mov64 r5, 0                                     r5 = 0 as i32 as i64 as u64
    mov64 r8, 1                                     r8 = 1 as i32 as i64 as u64
    jeq r9, 0, lbb_6047                             if r9 == (0 as i32 as i64 as u64) { pc += 4 }
lbb_6043:
    jne r7, 0, lbb_5983                             if r7 != (0 as i32 as i64 as u64) { pc += -61 }
    ja lbb_6049                                     if true { pc += 4 }
lbb_6045:
    mov64 r8, 1                                     r8 = 1 as i32 as i64 as u64
    jne r9, 0, lbb_6043                             if r9 != (0 as i32 as i64 as u64) { pc += -4 }
lbb_6047:
    mov64 r8, 0                                     r8 = 0 as i32 as i64 as u64
    jne r7, 0, lbb_5983                             if r7 != (0 as i32 as i64 as u64) { pc += -66 }
lbb_6049:
    mov64 r6, 0                                     r6 = 0 as i32 as i64 as u64
    ja lbb_5983                                     if true { pc += -68 }
lbb_6051:
    mov64 r0, 11                                    r0 = 11 as i32 as i64 as u64
    ja lbb_6072                                     if true { pc += 19 }
lbb_6053:
    mov64 r1, r10                                   r1 = r10
    add64 r1, -1024                                 r1 += -1024   ///  r1 = r1.wrapping_add(-1024 as i32 as i64 as u64)
    stxdw [r10-0x10], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -1264                                 r1 += -1264   ///  r1 = r1.wrapping_add(-1264 as i32 as i64 as u64)
    stxdw [r10-0x20], r1                    
    ldxdw r1, [r10-0x548]                   
    stxdw [r10-0x28], r1                    
    stdw [r10-0x8], 24                      
    stdw [r10-0x18], 15                     
    mov64 r1, r10                                   r1 = r10
    add64 r1, -40                                   r1 += -40   ///  r1 = r1.wrapping_add(-40 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -880                                  r2 += -880   ///  r2 = r2.wrapping_add(-880 as i32 as i64 as u64)
    mov64 r3, 15                                    r3 = 15 as i32 as i64 as u64
    mov64 r4, 8                                     r4 = 8 as i32 as i64 as u64
    mov64 r5, 0                                     r5 = 0 as i32 as i64 as u64
    syscall [invalid]                       
    mov64 r0, 26                                    r0 = 26 as i32 as i64 as u64
lbb_6072:
    ldxdw r1, [r10-0x500]                   
    stxw [r1+0x0], r0                       
    exit                                    
lbb_6075:
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    mov64 r2, 1                                     r2 = 1 as i32 as i64 as u64
    lddw r3, 0x100026a40 --> b"\x00\x00\x00\x00\xb8Y\x02\x00\x10\x00\x00\x00\x00\x00\x00\x00 !\x00\x00!\…        r3 load str located at 4295125568
    call function_18489                     
lbb_6080:
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
    lddw r3, 0x100026a28 --> b"\x00\x00\x00\x00\xb8Y\x02\x00\x10\x00\x00\x00\x00\x00\x00\x00 !\x00\x00\x…        r3 load str located at 4295125544
    call function_18489                     
lbb_6085:
    mov64 r1, 2                                     r1 = 2 as i32 as i64 as u64
    mov64 r2, 2                                     r2 = 2 as i32 as i64 as u64
    lddw r3, 0x100026a58 --> b"\x00\x00\x00\x00\xb8Y\x02\x00\x10\x00\x00\x00\x00\x00\x00\x00 !\x00\x008\…        r3 load str located at 4295125592
    call function_18489                     
lbb_6090:
    mov64 r1, 3                                     r1 = 3 as i32 as i64 as u64
    mov64 r2, 3                                     r2 = 3 as i32 as i64 as u64
    lddw r3, 0x100026a70 --> b"\x00\x00\x00\x00\xb8Y\x02\x00\x10\x00\x00\x00\x00\x00\x00\x00 !\x00\x00O\…        r3 load str located at 4295125616
    call function_18489                     
lbb_6095:
    mov64 r1, 4                                     r1 = 4 as i32 as i64 as u64
    mov64 r2, 4                                     r2 = 4 as i32 as i64 as u64
    lddw r3, 0x100026a88 --> b"\x00\x00\x00\x00\xb8Y\x02\x00\x10\x00\x00\x00\x00\x00\x00\x00!!\x00\x00\x…        r3 load str located at 4295125640
    call function_18489                     
lbb_6100:
    mov64 r1, 5                                     r1 = 5 as i32 as i64 as u64
    mov64 r2, 5                                     r2 = 5 as i32 as i64 as u64
    lddw r3, 0x100026aa0 --> b"\x00\x00\x00\x00\xb8Y\x02\x00\x10\x00\x00\x00\x00\x00\x00\x00!!\x00\x00!\…        r3 load str located at 4295125664
    call function_18489                     
lbb_6105:
    mov64 r1, 6                                     r1 = 6 as i32 as i64 as u64
    mov64 r2, 6                                     r2 = 6 as i32 as i64 as u64
    lddw r3, 0x100026ab8 --> b"\x00\x00\x00\x00\xb8Y\x02\x00\x10\x00\x00\x00\x00\x00\x00\x00!!\x00\x008\…        r3 load str located at 4295125688
    call function_18489                     
lbb_6110:
    mov64 r1, 7                                     r1 = 7 as i32 as i64 as u64
    mov64 r2, 7                                     r2 = 7 as i32 as i64 as u64
    lddw r3, 0x100026ad0 --> b"\x00\x00\x00\x00\xb8Y\x02\x00\x10\x00\x00\x00\x00\x00\x00\x00!!\x00\x00N\…        r3 load str located at 4295125712
    call function_18489                     
    ldxdw r3, [r2+0x8]                      
    jeq r3, 1, lbb_6344                             if r3 == (1 as i32 as i64 as u64) { pc += 227 }
    jeq r3, 0, lbb_6349                             if r3 == (0 as i32 as i64 as u64) { pc += 231 }
    jle r3, 2, lbb_6354                             if r3 <= (2 as i32 as i64 as u64) { pc += 235 }
    jeq r3, 3, lbb_6359                             if r3 == (3 as i32 as i64 as u64) { pc += 239 }
    jle r3, 4, lbb_6364                             if r3 <= (4 as i32 as i64 as u64) { pc += 243 }
    jeq r3, 5, lbb_6369                             if r3 == (5 as i32 as i64 as u64) { pc += 247 }
    ldxdw r9, [r2+0x50]                     
    mov64 r6, 3                                     r6 = 3 as i32 as i64 as u64
    ldxdw r4, [r9+0x0]                      
    ldxdw r3, [r4+0x50]                     
    jlt r3, 32, lbb_6341                            if r3 < (32 as i32 as i64 as u64) { pc += 214 }
    ldxdw r3, [r2+0x0]                      
    mov64 r8, r3                                    r8 = r3
    add64 r8, 16                                    r8 += 16   ///  r8 = r8.wrapping_add(16 as i32 as i64 as u64)
    ldxdw r7, [r8+0x0]                      
    ldxdw r0, [r7+0x50]                     
    jlt r0, 32, lbb_6341                            if r0 < (32 as i32 as i64 as u64) { pc += 208 }
    ldxdw r5, [r2+0x58]                     
    ldxdw r6, [r2+0x48]                     
    ldxdw r0, [r2+0x28]                     
    stxdw [r10-0x380], r0                   
    ldxdw r0, [r2+0x20]                     
    stxdw [r10-0x388], r0                   
    ldxdw r2, [r2+0x10]                     
    stxdw [r10-0x3a0], r2                   
    mov64 r2, r3                                    r2 = r3
    add64 r2, 40                                    r2 += 40   ///  r2 = r2.wrapping_add(40 as i32 as i64 as u64)
    stxdw [r10-0x390], r2                   
    mov64 r2, r3                                    r2 = r3
    add64 r2, 8                                     r2 += 8   ///  r2 = r2.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x378], r2                   
    mov64 r2, r3                                    r2 = r3
    add64 r2, 24                                    r2 += 24   ///  r2 = r2.wrapping_add(24 as i32 as i64 as u64)
    stxdw [r10-0x398], r2                   
    mov64 r2, r3                                    r2 = r3
    add64 r2, 32                                    r2 += 32   ///  r2 = r2.wrapping_add(32 as i32 as i64 as u64)
    stxdw [r10-0x3a8], r2                   
    ldxdw r2, [r7+0x58]                     
    ldxdw r0, [r4+0x58]                     
    stxdw [r10-0x368], r1                   
    stxdw [r10-0x370], r8                   
    jne r0, r2, lbb_6170                            if r0 != r2 { pc += 12 }
    ldxdw r2, [r7+0x60]                     
    ldxdw r0, [r4+0x60]                     
    jne r0, r2, lbb_6170                            if r0 != r2 { pc += 9 }
    ldxdw r2, [r7+0x68]                     
    ldxdw r0, [r4+0x68]                     
    jne r0, r2, lbb_6170                            if r0 != r2 { pc += 6 }
    ldxdw r2, [r7+0x70]                     
    ldxdw r4, [r4+0x70]                     
    jne r4, r2, lbb_6170                            if r4 != r2 { pc += 3 }
    mov64 r1, r9                                    r1 = r9
    mov64 r9, r5                                    r9 = r5
    ja lbb_6171                                     if true { pc += 1 }
lbb_6170:
    mov64 r1, r5                                    r1 = r5
lbb_6171:
    stxdw [r10-0x3b8], r1                   
    add64 r7, 8                                     r7 += 8   ///  r7 = r7.wrapping_add(8 as i32 as i64 as u64)
    ldxdw r2, [r3+0x0]                      
    stxdw [r10-0x3c8], r2                   
    ldxdw r2, [r3+0x8]                      
    stxdw [r10-0x3d0], r2                   
    ldxdw r0, [r6+0x0]                      
    ldxdw r2, [r1+0x0]                      
    ldxdw r8, [r3+0x18]                     
    stxdw [r10-0x3c0], r9                   
    ldxdw r9, [r9+0x0]                      
    stxdw [r10-0x3b0], r6                   
    ldxdw r6, [r3+0x20]                     
    ldxdw r5, [r3+0x28]                     
    mov64 r4, r7                                    r4 = r7
    ldxdw r7, [r10-0x380]                   
    ldxdw r1, [r7+0x0]                      
    stxdw [r10-0x320], r4                   
    add64 r1, 8                                     r1 += 8   ///  r1 = r1.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x2d0], r1                   
    add64 r5, 8                                     r5 += 8   ///  r5 = r5.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x2e0], r5                   
    add64 r6, 8                                     r6 += 8   ///  r6 = r6.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x2f0], r6                   
    add64 r9, 8                                     r9 += 8   ///  r9 = r9.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x300], r9                   
    add64 r8, 8                                     r8 += 8   ///  r8 = r8.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x310], r8                   
    add64 r2, 8                                     r2 += 8   ///  r2 = r2.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x330], r2                   
    add64 r0, 8                                     r0 += 8   ///  r0 = r0.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x340], r0                   
    ldxdw r1, [r10-0x3d0]                   
    add64 r1, 8                                     r1 += 8   ///  r1 = r1.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x350], r1                   
    ldxdw r1, [r10-0x3c8]                   
    add64 r1, 8                                     r1 += 8   ///  r1 = r1.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x360], r1                   
    sth [r10-0x2c8], 0                      
    sth [r10-0x2d8], 1                      
    sth [r10-0x2e8], 1                      
    sth [r10-0x2f8], 1                      
    sth [r10-0x308], 1                      
    sth [r10-0x318], 1                      
    sth [r10-0x328], 1                      
    sth [r10-0x338], 257                    
    sth [r10-0x348], 0                      
    sth [r10-0x358], 0                      
    ldxdw r1, [r10-0x3a0]                   
    stxdw [r10-0x2b8], r1                   
    stb [r10-0x2b9], 1                      
    stdw [r10-0x2b0], 0                     
    ldxdw r1, [r10-0x388]                   
    ldxdw r1, [r1+0x0]                      
    stxdw [r10-0x260], r7                   
    ldxdw r2, [r10-0x390]                   
    stxdw [r10-0x268], r2                   
    ldxdw r2, [r10-0x3a8]                   
    stxdw [r10-0x270], r2                   
    ldxdw r2, [r10-0x3c0]                   
    stxdw [r10-0x278], r2                   
    ldxdw r2, [r10-0x398]                   
    stxdw [r10-0x280], r2                   
    ldxdw r2, [r10-0x370]                   
    stxdw [r10-0x288], r2                   
    ldxdw r2, [r10-0x3b8]                   
    stxdw [r10-0x290], r2                   
    ldxdw r2, [r10-0x3b0]                   
    stxdw [r10-0x298], r2                   
    ldxdw r2, [r10-0x378]                   
    stxdw [r10-0x2a0], r2                   
    stxdw [r10-0x2a8], r3                   
    mov64 r2, r10                                   r2 = r10
    add64 r2, -680                                  r2 += -680   ///  r2 = r2.wrapping_add(-680 as i32 as i64 as u64)
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
    mov64 r4, r10                                   r4 = r10
    add64 r4, -856                                  r4 += -856   ///  r4 = r4.wrapping_add(-856 as i32 as i64 as u64)
    add64 r1, 8                                     r1 += 8   ///  r1 = r1.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x370], r1                   
    ja lbb_6271                                     if true { pc += 20 }
lbb_6251:
    mov64 r1, r10                                   r1 = r10
    add64 r1, -600                                  r1 += -600   ///  r1 = r1.wrapping_add(-600 as i32 as i64 as u64)
    add64 r1, r3                                    r1 += r3   ///  r1 = r1.wrapping_add(r3)
    stxb [r1+0x32], r7                      
    stxb [r1+0x31], r9                      
    stxb [r1+0x30], r0                      
    mov64 r0, r5                                    r0 = r5
    add64 r0, 40                                    r0 += 40   ///  r0 = r0.wrapping_add(40 as i32 as i64 as u64)
    stxdw [r1+0x20], r0                     
    mov64 r0, r5                                    r0 = r5
    add64 r0, 88                                    r0 += 88   ///  r0 = r0.wrapping_add(88 as i32 as i64 as u64)
    stxdw [r1+0x18], r0                     
    stxdw [r1+0x10], r6                     
    add64 r5, 72                                    r5 += 72   ///  r5 = r5.wrapping_add(72 as i32 as i64 as u64)
    stxdw [r1+0x8], r5                      
    stdw [r1+0x28], 0                       
    add64 r4, 16                                    r4 += 16   ///  r4 = r4.wrapping_add(16 as i32 as i64 as u64)
    add64 r2, 8                                     r2 += 8   ///  r2 = r2.wrapping_add(8 as i32 as i64 as u64)
    add64 r3, 56                                    r3 += 56   ///  r3 = r3.wrapping_add(56 as i32 as i64 as u64)
    jeq r3, 560, lbb_6321                           if r3 == (560 as i32 as i64 as u64) { pc += 50 }
lbb_6271:
    mov64 r0, r10                                   r0 = r10
    add64 r0, -600                                  r0 += -600   ///  r0 = r0.wrapping_add(-600 as i32 as i64 as u64)
    mov64 r6, 1                                     r6 = 1 as i32 as i64 as u64
    ldxdw r1, [r2+0x0]                      
    ldxdw r5, [r1+0x0]                      
    ldxdw r7, [r4-0x8]                      
    ldxdw r1, [r7+0x0]                      
    ldxdw r8, [r5+0x8]                      
    jne r8, r1, lbb_6340                            if r8 != r1 { pc += 60 }
    ldxdw r1, [r7+0x8]                      
    ldxdw r8, [r5+0x10]                     
    jne r8, r1, lbb_6340                            if r8 != r1 { pc += 57 }
    ldxdw r1, [r7+0x10]                     
    ldxdw r8, [r5+0x18]                     
    jne r8, r1, lbb_6340                            if r8 != r1 { pc += 54 }
    ldxdw r1, [r7+0x18]                     
    ldxdw r7, [r5+0x20]                     
    jne r7, r1, lbb_6340                            if r7 != r1 { pc += 51 }
    ldxb r6, [r4+0x0]                       
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    jne r6, 0, lbb_6293                             if r6 != (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r1, 119                                   r1 = 119 as i32 as i64 as u64
lbb_6293:
    ldxb r6, [r5+0x0]                       
    or64 r1, r6                                     r1 |= r6   ///  r1 = r1.or(r6)
    and64 r1, 255                                   r1 &= 255   ///  r1 = r1.and(255)
    jne r1, 255, lbb_6319                           if r1 != (255 as i32 as i64 as u64) { pc += 22 }
    add64 r0, r3                                    r0 += r3   ///  r0 = r0.wrapping_add(r3)
    mov64 r7, r5                                    r7 = r5
    add64 r7, 8                                     r7 += 8   ///  r7 = r7.wrapping_add(8 as i32 as i64 as u64)
    ldxdw r6, [r5+0x50]                     
    ldxb r8, [r5+0x3]                       
    ldxb r1, [r5+0x2]                       
    ldxb r9, [r5+0x1]                       
    stxdw [r0+0x0], r7                      
    mov64 r7, 1                                     r7 = 1 as i32 as i64 as u64
    mov64 r0, 1                                     r0 = 1 as i32 as i64 as u64
    jeq r9, 0, lbb_6312                             if r9 == (0 as i32 as i64 as u64) { pc += 4 }
    mov64 r9, 1                                     r9 = 1 as i32 as i64 as u64
    jeq r1, 0, lbb_6315                             if r1 == (0 as i32 as i64 as u64) { pc += 5 }
lbb_6310:
    jne r8, 0, lbb_6251                             if r8 != (0 as i32 as i64 as u64) { pc += -60 }
    ja lbb_6317                                     if true { pc += 5 }
lbb_6312:
    mov64 r0, 0                                     r0 = 0 as i32 as i64 as u64
    mov64 r9, 1                                     r9 = 1 as i32 as i64 as u64
    jne r1, 0, lbb_6310                             if r1 != (0 as i32 as i64 as u64) { pc += -5 }
lbb_6315:
    mov64 r9, 0                                     r9 = 0 as i32 as i64 as u64
    jne r8, 0, lbb_6251                             if r8 != (0 as i32 as i64 as u64) { pc += -66 }
lbb_6317:
    mov64 r7, 0                                     r7 = 0 as i32 as i64 as u64
    ja lbb_6251                                     if true { pc += -68 }
lbb_6319:
    mov64 r6, 11                                    r6 = 11 as i32 as i64 as u64
    ja lbb_6340                                     if true { pc += 19 }
lbb_6321:
    mov64 r1, r10                                   r1 = r10
    add64 r1, -697                                  r1 += -697   ///  r1 = r1.wrapping_add(-697 as i32 as i64 as u64)
    stxdw [r10-0x10], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -864                                  r1 += -864   ///  r1 = r1.wrapping_add(-864 as i32 as i64 as u64)
    stxdw [r10-0x20], r1                    
    ldxdw r1, [r10-0x370]                   
    stxdw [r10-0x28], r1                    
    stdw [r10-0x8], 17                      
    stdw [r10-0x18], 10                     
    mov64 r1, r10                                   r1 = r10
    add64 r1, -40                                   r1 += -40   ///  r1 = r1.wrapping_add(-40 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -600                                  r2 += -600   ///  r2 = r2.wrapping_add(-600 as i32 as i64 as u64)
    mov64 r3, 10                                    r3 = 10 as i32 as i64 as u64
    mov64 r4, 8                                     r4 = 8 as i32 as i64 as u64
    mov64 r5, 0                                     r5 = 0 as i32 as i64 as u64
    syscall [invalid]                       
    mov64 r6, 26                                    r6 = 26 as i32 as i64 as u64
lbb_6340:
    ldxdw r1, [r10-0x368]                   
lbb_6341:
    stxw [r1+0x0], r6                       
    stw [r1+0x4], 0                         
    exit                                    
lbb_6344:
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    mov64 r2, 1                                     r2 = 1 as i32 as i64 as u64
    lddw r3, 0x100026b00 --> b"\x00\x00\x00\x00\xb8Y\x02\x00\x10\x00\x00\x00\x00\x00\x00\x00*!\x00\x00!\…        r3 load str located at 4295125760
    call function_18489                     
lbb_6349:
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
    lddw r3, 0x100026ae8 --> b"\x00\x00\x00\x00\xb8Y\x02\x00\x10\x00\x00\x00\x00\x00\x00\x00*!\x00\x00\x…        r3 load str located at 4295125736
    call function_18489                     
lbb_6354:
    mov64 r1, 2                                     r1 = 2 as i32 as i64 as u64
    mov64 r2, 2                                     r2 = 2 as i32 as i64 as u64
    lddw r3, 0x100026b18 --> b"\x00\x00\x00\x00\xb8Y\x02\x00\x10\x00\x00\x00\x00\x00\x00\x00*!\x00\x008\…        r3 load str located at 4295125784
    call function_18489                     
lbb_6359:
    mov64 r1, 3                                     r1 = 3 as i32 as i64 as u64
    mov64 r2, 3                                     r2 = 3 as i32 as i64 as u64
    lddw r3, 0x100026b30 --> b"\x00\x00\x00\x00\xb8Y\x02\x00\x10\x00\x00\x00\x00\x00\x00\x00*!\x00\x00O\…        r3 load str located at 4295125808
    call function_18489                     
lbb_6364:
    mov64 r1, 4                                     r1 = 4 as i32 as i64 as u64
    mov64 r2, 4                                     r2 = 4 as i32 as i64 as u64
    lddw r3, 0x100026b48 --> b"\x00\x00\x00\x00\xb8Y\x02\x00\x10\x00\x00\x00\x00\x00\x00\x00+!\x00\x00\x…        r3 load str located at 4295125832
    call function_18489                     
lbb_6369:
    mov64 r1, 5                                     r1 = 5 as i32 as i64 as u64
    mov64 r2, 5                                     r2 = 5 as i32 as i64 as u64
    lddw r3, 0x100026b60 --> b"\x00\x00\x00\x00\xb8Y\x02\x00\x10\x00\x00\x00\x00\x00\x00\x00+!\x00\x00!\…        r3 load str located at 4295125856
    call function_18489                     
    ldxdw r3, [r2+0x8]                      
    ldxdw r9, [r2+0x0]                      
    ldxdw r4, [r2+0x58]                     
    stxdw [r10-0x790], r4                   
    ldxdw r0, [r2+0x50]                     
    ldxdw r4, [r2+0x48]                     
    stxdw [r10-0x798], r4                   
    ldxdw r4, [r2+0x40]                     
    stxdw [r10-0x7a0], r4                   
    ldxdw r4, [r2+0x30]                     
    stxdw [r10-0x7c0], r4                   
    ldxdw r4, [r2+0x28]                     
    stxdw [r10-0x780], r4                   
    ldxdw r4, [r2+0x20]                     
    stxdw [r10-0x7a8], r4                   
    ldxb r4, [r2+0x62]                      
    stxdw [r10-0x7b0], r1                   
    jeq r4, 0, lbb_6784                             if r4 == (0 as i32 as i64 as u64) { pc += 392 }
    jeq r3, 0, lbb_7193                             if r3 == (0 as i32 as i64 as u64) { pc += 800 }
    jeq r3, 1, lbb_7203                             if r3 == (1 as i32 as i64 as u64) { pc += 809 }
    jle r3, 2, lbb_7213                             if r3 <= (2 as i32 as i64 as u64) { pc += 818 }
    jeq r3, 3, lbb_7223                             if r3 == (3 as i32 as i64 as u64) { pc += 827 }
    jle r3, 4, lbb_7233                             if r3 <= (4 as i32 as i64 as u64) { pc += 836 }
    jeq r3, 5, lbb_7243                             if r3 == (5 as i32 as i64 as u64) { pc += 845 }
    jle r3, 6, lbb_7253                             if r3 <= (6 as i32 as i64 as u64) { pc += 854 }
    jeq r3, 7, lbb_7263                             if r3 == (7 as i32 as i64 as u64) { pc += 863 }
    jle r3, 8, lbb_7273                             if r3 <= (8 as i32 as i64 as u64) { pc += 872 }
    jeq r3, 9, lbb_7283                             if r3 == (9 as i32 as i64 as u64) { pc += 881 }
    jle r3, 10, lbb_7293                            if r3 <= (10 as i32 as i64 as u64) { pc += 890 }
    jeq r3, 11, lbb_7303                            if r3 == (11 as i32 as i64 as u64) { pc += 899 }
    jle r3, 12, lbb_7313                            if r3 <= (12 as i32 as i64 as u64) { pc += 908 }
    jeq r3, 13, lbb_7323                            if r3 == (13 as i32 as i64 as u64) { pc += 917 }
    jle r3, 14, lbb_7333                            if r3 <= (14 as i32 as i64 as u64) { pc += 926 }
    jeq r3, 15, lbb_7338                            if r3 == (15 as i32 as i64 as u64) { pc += 930 }
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
    stxdw [r10-0x788], r3                   
    mov64 r3, 3                                     r3 = 3 as i32 as i64 as u64
    ldxdw r4, [r0+0x0]                      
    ldxdw r5, [r4+0x50]                     
    jlt r5, 32, lbb_7189                            if r5 < (32 as i32 as i64 as u64) { pc += 775 }
    mov64 r5, r9                                    r5 = r9
    add64 r5, 40                                    r5 += 40   ///  r5 = r5.wrapping_add(40 as i32 as i64 as u64)
    stxdw [r10-0x7c8], r5                   
    ldxdw r6, [r5+0x0]                      
    ldxdw r5, [r6+0x50]                     
    jlt r5, 32, lbb_7189                            if r5 < (32 as i32 as i64 as u64) { pc += 769 }
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
    stxdw [r10-0x788], r3                   
    ldxdw r3, [r6+0x58]                     
    ldxdw r5, [r4+0x58]                     
    jne r5, r3, lbb_6438                            if r5 != r3 { pc += 13 }
    ldxdw r3, [r6+0x60]                     
    ldxdw r5, [r4+0x60]                     
    jne r5, r3, lbb_6438                            if r5 != r3 { pc += 10 }
    ldxdw r3, [r6+0x68]                     
    ldxdw r5, [r4+0x68]                     
    jne r5, r3, lbb_6438                            if r5 != r3 { pc += 7 }
    ldxdw r3, [r6+0x70]                     
    ldxdw r4, [r4+0x70]                     
    mov64 r5, 1                                     r5 = 1 as i32 as i64 as u64
    stxdw [r10-0x788], r5                   
    jeq r4, r3, lbb_6438                            if r4 == r3 { pc += 2 }
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
    stxdw [r10-0x788], r3                   
lbb_6438:
    stxdw [r10-0x7b8], r6                   
    ldxdw r3, [r10-0x788]                   
    and64 r3, 1                                     r3 &= 1   ///  r3 = r3.and(1)
    mov64 r8, r0                                    r8 = r0
    jne r3, 0, lbb_6444                             if r3 != (0 as i32 as i64 as u64) { pc += 1 }
    ldxdw r8, [r10-0x790]                   
lbb_6444:
    mov64 r4, r9                                    r4 = r9
    add64 r4, 16                                    r4 += 16   ///  r4 = r4.wrapping_add(16 as i32 as i64 as u64)
    jne r3, 0, lbb_6448                             if r3 != (0 as i32 as i64 as u64) { pc += 1 }
    stxdw [r10-0x790], r0                   
lbb_6448:
    mov64 r7, r9                                    r7 = r9
    add64 r7, 24                                    r7 += 24   ///  r7 = r7.wrapping_add(24 as i32 as i64 as u64)
    stxdw [r10-0x7d0], r4                   
    ldxdw r6, [r4+0x0]                      
    ldxdw r4, [r6+0x28]                     
    lddw r3, 0xde8f75eee1f6dd06                     r3 load str located at -2409577606766207738
    ldxdw r0, [r10-0x780]                   
    mov64 r5, r0                                    r5 = r0
    jne r4, r3, lbb_6474                            if r4 != r3 { pc += 16 }
    ldxdw r4, [r6+0x30]                     
    mov64 r5, r0                                    r5 = r0
    lddw r3, 0xdacd6ce4bc5d4218                     r3 load str located at -2680366473547005416
    jne r4, r3, lbb_6474                            if r4 != r3 { pc += 11 }
    ldxdw r4, [r6+0x38]                     
    lddw r3, 0x270db9834dfc1ab6                     r3 load str located at 2814109315776649910
    mov64 r5, r0                                    r5 = r0
    jne r4, r3, lbb_6474                            if r4 != r3 { pc += 6 }
    ldxdw r4, [r6+0x40]                     
    lddw r3, 0xfc8ba1d828f9bdfe                     r3 load str located at -248927404616466946
    mov64 r5, r0                                    r5 = r0
    jne r4, r3, lbb_6474                            if r4 != r3 { pc += 1 }
    ldxdw r5, [r10-0x7c0]                   
lbb_6474:
    stxdw [r10-0x858], r6                   
    mov64 r4, r9                                    r4 = r9
    add64 r4, 8                                     r4 += 8   ///  r4 = r4.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x7e0], r4                   
    mov64 r4, r9                                    r4 = r9
    add64 r4, 32                                    r4 += 32   ///  r4 = r4.wrapping_add(32 as i32 as i64 as u64)
    stxdw [r10-0x7e8], r4                   
    mov64 r4, r9                                    r4 = r9
    add64 r4, 48                                    r4 += 48   ///  r4 = r4.wrapping_add(48 as i32 as i64 as u64)
    stxdw [r10-0x7f0], r4                   
    mov64 r4, r9                                    r4 = r9
    add64 r4, 56                                    r4 += 56   ///  r4 = r4.wrapping_add(56 as i32 as i64 as u64)
    stxdw [r10-0x7f8], r4                   
    mov64 r4, r9                                    r4 = r9
    add64 r4, 64                                    r4 += 64   ///  r4 = r4.wrapping_add(64 as i32 as i64 as u64)
    stxdw [r10-0x800], r4                   
    mov64 r4, r9                                    r4 = r9
    add64 r4, 72                                    r4 += 72   ///  r4 = r4.wrapping_add(72 as i32 as i64 as u64)
    stxdw [r10-0x808], r4                   
    mov64 r4, r9                                    r4 = r9
    add64 r4, 80                                    r4 += 80   ///  r4 = r4.wrapping_add(80 as i32 as i64 as u64)
    stxdw [r10-0x810], r4                   
    mov64 r4, r9                                    r4 = r9
    add64 r4, 88                                    r4 += 88   ///  r4 = r4.wrapping_add(88 as i32 as i64 as u64)
    stxdw [r10-0x818], r4                   
    mov64 r4, r9                                    r4 = r9
    add64 r4, 96                                    r4 += 96   ///  r4 = r4.wrapping_add(96 as i32 as i64 as u64)
    stxdw [r10-0x820], r4                   
    mov64 r4, r9                                    r4 = r9
    add64 r4, 104                                   r4 += 104   ///  r4 = r4.wrapping_add(104 as i32 as i64 as u64)
    stxdw [r10-0x828], r4                   
    ldxdw r2, [r2+0x10]                     
    stxdw [r10-0x840], r2                   
    mov64 r2, r9                                    r2 = r9
    add64 r2, 120                                   r2 += 120   ///  r2 = r2.wrapping_add(120 as i32 as i64 as u64)
    stxdw [r10-0x830], r2                   
    mov64 r2, r9                                    r2 = r9
    add64 r2, 112                                   r2 += 112   ///  r2 = r2.wrapping_add(112 as i32 as i64 as u64)
    stxdw [r10-0x838], r2                   
    ldxdw r4, [r7+0x0]                      
    ldxdw r2, [r4+0x28]                     
    lddw r3, 0xde8f75eee1f6dd06                     r3 load str located at -2409577606766207738
    stxdw [r10-0x7d8], r7                   
    jne r2, r3, lbb_6533                            if r2 != r3 { pc += 14 }
    ldxdw r2, [r4+0x30]                     
    lddw r3, 0xdacd6ce4bc5d4218                     r3 load str located at -2680366473547005416
    jne r2, r3, lbb_6533                            if r2 != r3 { pc += 10 }
    ldxdw r2, [r4+0x38]                     
    lddw r3, 0x270db9834dfc1ab6                     r3 load str located at 2814109315776649910
    jne r2, r3, lbb_6533                            if r2 != r3 { pc += 6 }
    ldxdw r2, [r4+0x40]                     
    lddw r3, 0xfc8ba1d828f9bdfe                     r3 load str located at -248927404616466946
    jne r2, r3, lbb_6533                            if r2 != r3 { pc += 2 }
    ldxdw r1, [r10-0x7c0]                   
    stxdw [r10-0x780], r1                   
lbb_6533:
    ldxdw r0, [r10-0x7b8]                   
    add64 r0, 8                                     r0 += 8   ///  r0 = r0.wrapping_add(8 as i32 as i64 as u64)
    ldxdw r1, [r10-0x7a8]                   
    ldxdw r1, [r1+0x0]                      
    stxdw [r10-0x7b8], r1                   
    ldxdw r1, [r9+0x0]                      
    stxdw [r10-0x7c0], r1                   
    ldxdw r1, [r10-0x798]                   
    ldxdw r1, [r1+0x0]                      
    stxdw [r10-0x860], r1                   
    ldxdw r1, [r9+0x8]                      
    stxdw [r10-0x868], r1                   
    ldxdw r1, [r10-0x790]                   
    ldxdw r1, [r1+0x0]                      
    stxdw [r10-0x870], r1                   
    stxdw [r10-0x848], r8                   
    ldxdw r1, [r8+0x0]                      
    stxdw [r10-0x878], r1                   
    ldxdw r1, [r9+0x20]                     
    stxdw [r10-0x880], r1                   
    ldxdw r1, [r9+0x30]                     
    stxdw [r10-0x888], r1                   
    ldxdw r1, [r9+0x38]                     
    stxdw [r10-0x890], r1                   
    stxdw [r10-0x850], r5                   
    ldxdw r1, [r5+0x0]                      
    stxdw [r10-0x898], r1                   
    ldxdw r1, [r10-0x780]                   
    ldxdw r1, [r1+0x0]                      
    stxdw [r10-0x8a0], r1                   
    ldxdw r1, [r10-0x7a0]                   
    ldxdw r1, [r1+0x0]                      
    stxdw [r10-0x8a8], r1                   
    ldxdw r1, [r9+0x40]                     
    stxdw [r10-0x8b0], r1                   
    ldxdw r1, [r9+0x48]                     
    ldxdw r3, [r9+0x50]                     
    ldxdw r2, [r9+0x58]                     
    ldxdw r5, [r9+0x60]                     
    ldxdw r8, [r9+0x68]                     
    ldxdw r7, [r9+0x70]                     
    ldxdw r6, [r9+0x78]                     
    stxdw [r10-0x6f8], r0                   
    add64 r4, 8                                     r4 += 8   ///  r4 = r4.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x738], r4                   
    ldxdw r4, [r10-0x858]                   
    add64 r4, 8                                     r4 += 8   ///  r4 = r4.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x748], r4                   
    add64 r6, 8                                     r6 += 8   ///  r6 = r6.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x618], r6                   
    add64 r7, 8                                     r7 += 8   ///  r7 = r7.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x628], r7                   
    add64 r8, 8                                     r8 += 8   ///  r8 = r8.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x638], r8                   
    add64 r5, 8                                     r5 += 8   ///  r5 = r5.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x648], r5                   
    add64 r2, 8                                     r2 += 8   ///  r2 = r2.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x658], r2                   
    add64 r3, 8                                     r3 += 8   ///  r3 = r3.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x668], r3                   
    add64 r1, 8                                     r1 += 8   ///  r1 = r1.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x688], r1                   
    ldxdw r1, [r10-0x8b0]                   
    add64 r1, 8                                     r1 += 8   ///  r1 = r1.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x698], r1                   
    ldxdw r1, [r10-0x8a8]                   
    add64 r1, 8                                     r1 += 8   ///  r1 = r1.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x6a8], r1                   
    ldxdw r1, [r10-0x8a0]                   
    add64 r1, 8                                     r1 += 8   ///  r1 = r1.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x6b8], r1                   
    ldxdw r1, [r10-0x898]                   
    add64 r1, 8                                     r1 += 8   ///  r1 = r1.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x6c8], r1                   
    ldxdw r1, [r10-0x890]                   
    add64 r1, 8                                     r1 += 8   ///  r1 = r1.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x6d8], r1                   
    ldxdw r1, [r10-0x888]                   
    add64 r1, 8                                     r1 += 8   ///  r1 = r1.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x6e8], r1                   
    ldxdw r1, [r10-0x880]                   
    add64 r1, 8                                     r1 += 8   ///  r1 = r1.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x708], r1                   
    ldxdw r1, [r10-0x878]                   
    add64 r1, 8                                     r1 += 8   ///  r1 = r1.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x718], r1                   
    ldxdw r1, [r10-0x870]                   
    add64 r1, 8                                     r1 += 8   ///  r1 = r1.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x728], r1                   
    ldxdw r1, [r10-0x868]                   
    add64 r1, 8                                     r1 += 8   ///  r1 = r1.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x758], r1                   
    ldxdw r1, [r10-0x860]                   
    add64 r1, 8                                     r1 += 8   ///  r1 = r1.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x768], r1                   
    ldxdw r1, [r10-0x7c0]                   
    add64 r1, 8                                     r1 += 8   ///  r1 = r1.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x778], r1                   
    ldxdw r1, [r10-0x7b8]                   
    add64 r1, 8                                     r1 += 8   ///  r1 = r1.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x7b8], r1                   
    stxdw [r10-0x678], r1                   
    sth [r10-0x610], 0                      
    sth [r10-0x620], 0                      
    sth [r10-0x630], 1                      
    sth [r10-0x640], 1                      
    sth [r10-0x650], 1                      
    sth [r10-0x660], 1                      
    sth [r10-0x670], 0                      
    sth [r10-0x680], 0                      
    sth [r10-0x690], 0                      
    sth [r10-0x6a0], 0                      
    sth [r10-0x6b0], 0                      
    sth [r10-0x6c0], 0                      
    sth [r10-0x6d0], 1                      
    sth [r10-0x6e0], 0                      
    sth [r10-0x6f0], 1                      
    sth [r10-0x700], 1                      
    sth [r10-0x710], 1                      
    sth [r10-0x720], 1                      
    sth [r10-0x730], 0                      
    sth [r10-0x740], 0                      
    sth [r10-0x750], 0                      
    sth [r10-0x760], 257                    
    sth [r10-0x770], 1                      
    ldxdw r1, [r10-0x840]                   
    stxdw [r10-0x600], r1                   
    lddw r2, 0x70e8d9b452152ec6                     r2 load str located at 8135992095339261638
    stxdw [r10-0x608], r2                   
    stb [r10-0x5f0], 0                      
    stdw [r10-0x5f8], 1                     
    ldxdw r1, [r10-0x830]                   
    stxdw [r10-0x538], r1                   
    ldxdw r1, [r10-0x838]                   
    stxdw [r10-0x540], r1                   
    ldxdw r1, [r10-0x828]                   
    stxdw [r10-0x548], r1                   
    ldxdw r1, [r10-0x820]                   
    stxdw [r10-0x550], r1                   
    ldxdw r1, [r10-0x818]                   
    stxdw [r10-0x558], r1                   
    ldxdw r1, [r10-0x810]                   
    stxdw [r10-0x560], r1                   
    ldxdw r1, [r10-0x7a8]                   
    stxdw [r10-0x568], r1                   
    ldxdw r1, [r10-0x808]                   
    stxdw [r10-0x570], r1                   
    ldxdw r1, [r10-0x800]                   
    stxdw [r10-0x578], r1                   
    ldxdw r1, [r10-0x7a0]                   
    stxdw [r10-0x580], r1                   
    ldxdw r1, [r10-0x780]                   
    stxdw [r10-0x588], r1                   
    ldxdw r1, [r10-0x850]                   
    stxdw [r10-0x590], r1                   
    ldxdw r1, [r10-0x7f8]                   
    stxdw [r10-0x598], r1                   
    ldxdw r1, [r10-0x7f0]                   
    stxdw [r10-0x5a0], r1                   
    ldxdw r1, [r10-0x7c8]                   
    stxdw [r10-0x5a8], r1                   
    ldxdw r1, [r10-0x7e8]                   
    stxdw [r10-0x5b0], r1                   
    ldxdw r1, [r10-0x848]                   
    stxdw [r10-0x5b8], r1                   
    ldxdw r1, [r10-0x790]                   
    stxdw [r10-0x5c0], r1                   
    ldxdw r1, [r10-0x7d8]                   
    stxdw [r10-0x5c8], r1                   
    ldxdw r1, [r10-0x7d0]                   
    stxdw [r10-0x5d0], r1                   
    ldxdw r1, [r10-0x7e0]                   
    stxdw [r10-0x5d8], r1                   
    ldxdw r1, [r10-0x798]                   
    stxdw [r10-0x5e0], r1                   
    stxdw [r10-0x5e8], r9                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -1512                                 r1 += -1512   ///  r1 = r1.wrapping_add(-1512 as i32 as i64 as u64)
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
    mov64 r4, r10                                   r4 = r10
    add64 r4, -1904                                 r4 += -1904   ///  r4 = r4.wrapping_add(-1904 as i32 as i64 as u64)
    ja lbb_6736                                     if true { pc += 20 }
lbb_6716:
    mov64 r7, r10                                   r7 = r10
    add64 r7, -1328                                 r7 += -1328   ///  r7 = r7.wrapping_add(-1328 as i32 as i64 as u64)
    add64 r7, r2                                    r7 += r2   ///  r7 = r7.wrapping_add(r2)
    stxb [r7+0x32], r6                      
    stxb [r7+0x31], r8                      
    stxb [r7+0x30], r0                      
    mov64 r0, r5                                    r0 = r5
    add64 r0, 40                                    r0 += 40   ///  r0 = r0.wrapping_add(40 as i32 as i64 as u64)
    stxdw [r7+0x20], r0                     
    mov64 r0, r5                                    r0 = r5
    add64 r0, 88                                    r0 += 88   ///  r0 = r0.wrapping_add(88 as i32 as i64 as u64)
    stxdw [r7+0x18], r0                     
    stxdw [r7+0x10], r3                     
    add64 r5, 72                                    r5 += 72   ///  r5 = r5.wrapping_add(72 as i32 as i64 as u64)
    stxdw [r7+0x8], r5                      
    stdw [r7+0x28], 0                       
    add64 r4, 16                                    r4 += 16   ///  r4 = r4.wrapping_add(16 as i32 as i64 as u64)
    add64 r1, 8                                     r1 += 8   ///  r1 = r1.wrapping_add(8 as i32 as i64 as u64)
    add64 r2, 56                                    r2 += 56   ///  r2 = r2.wrapping_add(56 as i32 as i64 as u64)
    jeq r2, 1288, lbb_7169                          if r2 == (1288 as i32 as i64 as u64) { pc += 433 }
lbb_6736:
    mov64 r0, r10                                   r0 = r10
    add64 r0, -1328                                 r0 += -1328   ///  r0 = r0.wrapping_add(-1328 as i32 as i64 as u64)
    mov64 r3, 1                                     r3 = 1 as i32 as i64 as u64
    ldxdw r5, [r1+0x0]                      
    ldxdw r5, [r5+0x0]                      
    ldxdw r6, [r4-0x8]                      
    ldxdw r7, [r6+0x0]                      
    ldxdw r8, [r5+0x8]                      
    jne r8, r7, lbb_7188                            if r8 != r7 { pc += 443 }
    ldxdw r7, [r6+0x8]                      
    ldxdw r8, [r5+0x10]                     
    jne r8, r7, lbb_7188                            if r8 != r7 { pc += 440 }
    ldxdw r7, [r6+0x10]                     
    ldxdw r8, [r5+0x18]                     
    jne r8, r7, lbb_7188                            if r8 != r7 { pc += 437 }
    ldxdw r6, [r6+0x18]                     
    ldxdw r7, [r5+0x20]                     
    jne r7, r6, lbb_7188                            if r7 != r6 { pc += 434 }
    ldxb r6, [r4+0x0]                       
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
    jne r6, 0, lbb_6758                             if r6 != (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r3, 119                                   r3 = 119 as i32 as i64 as u64
lbb_6758:
    ldxb r6, [r5+0x0]                       
    or64 r3, r6                                     r3 |= r6   ///  r3 = r3.or(r6)
    and64 r3, 255                                   r3 &= 255   ///  r3 = r3.and(255)
    jne r3, 255, lbb_7149                           if r3 != (255 as i32 as i64 as u64) { pc += 387 }
    add64 r0, r2                                    r0 += r2   ///  r0 = r0.wrapping_add(r2)
    mov64 r6, r5                                    r6 = r5
    add64 r6, 8                                     r6 += 8   ///  r6 = r6.wrapping_add(8 as i32 as i64 as u64)
    ldxdw r3, [r5+0x50]                     
    ldxb r7, [r5+0x3]                       
    ldxb r9, [r5+0x2]                       
    ldxb r8, [r5+0x1]                       
    stxdw [r0+0x0], r6                      
    mov64 r6, 1                                     r6 = 1 as i32 as i64 as u64
    mov64 r0, 1                                     r0 = 1 as i32 as i64 as u64
    jne r8, 0, lbb_6778                             if r8 != (0 as i32 as i64 as u64) { pc += 5 }
    mov64 r0, 0                                     r0 = 0 as i32 as i64 as u64
    mov64 r8, 1                                     r8 = 1 as i32 as i64 as u64
    jeq r9, 0, lbb_6780                             if r9 == (0 as i32 as i64 as u64) { pc += 4 }
lbb_6776:
    jne r7, 0, lbb_6716                             if r7 != (0 as i32 as i64 as u64) { pc += -61 }
    ja lbb_6782                                     if true { pc += 4 }
lbb_6778:
    mov64 r8, 1                                     r8 = 1 as i32 as i64 as u64
    jne r9, 0, lbb_6776                             if r9 != (0 as i32 as i64 as u64) { pc += -4 }
lbb_6780:
    mov64 r8, 0                                     r8 = 0 as i32 as i64 as u64
    jne r7, 0, lbb_6716                             if r7 != (0 as i32 as i64 as u64) { pc += -66 }
lbb_6782:
    mov64 r6, 0                                     r6 = 0 as i32 as i64 as u64
    ja lbb_6716                                     if true { pc += -68 }
lbb_6784:
    jeq r3, 0, lbb_7198                             if r3 == (0 as i32 as i64 as u64) { pc += 413 }
    jeq r3, 1, lbb_7208                             if r3 == (1 as i32 as i64 as u64) { pc += 422 }
    jle r3, 2, lbb_7218                             if r3 <= (2 as i32 as i64 as u64) { pc += 431 }
    jeq r3, 3, lbb_7228                             if r3 == (3 as i32 as i64 as u64) { pc += 440 }
    jle r3, 4, lbb_7238                             if r3 <= (4 as i32 as i64 as u64) { pc += 449 }
    jeq r3, 5, lbb_7248                             if r3 == (5 as i32 as i64 as u64) { pc += 458 }
    jle r3, 6, lbb_7258                             if r3 <= (6 as i32 as i64 as u64) { pc += 467 }
    jeq r3, 7, lbb_7268                             if r3 == (7 as i32 as i64 as u64) { pc += 476 }
    jle r3, 8, lbb_7278                             if r3 <= (8 as i32 as i64 as u64) { pc += 485 }
    jeq r3, 9, lbb_7288                             if r3 == (9 as i32 as i64 as u64) { pc += 494 }
    jle r3, 10, lbb_7298                            if r3 <= (10 as i32 as i64 as u64) { pc += 503 }
    jeq r3, 11, lbb_7308                            if r3 == (11 as i32 as i64 as u64) { pc += 512 }
    jle r3, 14, lbb_7318                            if r3 <= (14 as i32 as i64 as u64) { pc += 521 }
    jeq r3, 15, lbb_7328                            if r3 == (15 as i32 as i64 as u64) { pc += 530 }
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
    stxdw [r10-0x788], r3                   
    mov64 r3, 3                                     r3 = 3 as i32 as i64 as u64
    ldxdw r4, [r0+0x0]                      
    ldxdw r5, [r4+0x50]                     
    jlt r5, 32, lbb_7189                            if r5 < (32 as i32 as i64 as u64) { pc += 385 }
    mov64 r5, r9                                    r5 = r9
    add64 r5, 40                                    r5 += 40   ///  r5 = r5.wrapping_add(40 as i32 as i64 as u64)
    stxdw [r10-0x7c8], r5                   
    ldxdw r6, [r5+0x0]                      
    ldxdw r5, [r6+0x50]                     
    jlt r5, 32, lbb_7189                            if r5 < (32 as i32 as i64 as u64) { pc += 379 }
    mov64 r3, r9                                    r3 = r9
    add64 r3, 16                                    r3 += 16   ///  r3 = r3.wrapping_add(16 as i32 as i64 as u64)
    stxdw [r10-0x7b8], r3                   
    ldxdw r3, [r6+0x58]                     
    ldxdw r5, [r4+0x58]                     
    stxdw [r10-0x810], r6                   
    jne r5, r3, lbb_6829                            if r5 != r3 { pc += 12 }
    ldxdw r3, [r6+0x60]                     
    ldxdw r5, [r4+0x60]                     
    jne r5, r3, lbb_6829                            if r5 != r3 { pc += 9 }
    ldxdw r3, [r6+0x68]                     
    ldxdw r5, [r4+0x68]                     
    jne r5, r3, lbb_6829                            if r5 != r3 { pc += 6 }
    ldxdw r3, [r6+0x70]                     
    ldxdw r4, [r4+0x70]                     
    jne r4, r3, lbb_6829                            if r4 != r3 { pc += 3 }
    ldxdw r7, [r10-0x790]                   
    stxdw [r10-0x790], r0                   
    ja lbb_6830                                     if true { pc += 1 }
lbb_6829:
    mov64 r7, r0                                    r7 = r0
lbb_6830:
    mov64 r8, r9                                    r8 = r9
    add64 r8, 24                                    r8 += 24   ///  r8 = r8.wrapping_add(24 as i32 as i64 as u64)
    ldxdw r3, [r10-0x7b8]                   
    ldxdw r4, [r3+0x0]                      
    ldxdw r3, [r4+0x28]                     
    lddw r5, 0xde8f75eee1f6dd06                     r5 load str located at -2409577606766207738
    ldxdw r0, [r10-0x780]                   
    mov64 r6, r0                                    r6 = r0
    jne r3, r5, lbb_6856                            if r3 != r5 { pc += 16 }
    ldxdw r3, [r4+0x30]                     
    mov64 r6, r0                                    r6 = r0
    lddw r5, 0xdacd6ce4bc5d4218                     r5 load str located at -2680366473547005416
    jne r3, r5, lbb_6856                            if r3 != r5 { pc += 11 }
    ldxdw r3, [r4+0x38]                     
    lddw r5, 0x270db9834dfc1ab6                     r5 load str located at 2814109315776649910
    mov64 r6, r0                                    r6 = r0
    jne r3, r5, lbb_6856                            if r3 != r5 { pc += 6 }
    ldxdw r3, [r4+0x40]                     
    lddw r5, 0xfc8ba1d828f9bdfe                     r5 load str located at -248927404616466946
    mov64 r6, r0                                    r6 = r0
    jne r3, r5, lbb_6856                            if r3 != r5 { pc += 1 }
    ldxdw r6, [r10-0x7c0]                   
lbb_6856:
    stxdw [r10-0x838], r4                   
    mov64 r3, r9                                    r3 = r9
    add64 r3, 8                                     r3 += 8   ///  r3 = r3.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x7d8], r3                   
    mov64 r3, r9                                    r3 = r9
    add64 r3, 32                                    r3 += 32   ///  r3 = r3.wrapping_add(32 as i32 as i64 as u64)
    stxdw [r10-0x7e0], r3                   
    mov64 r3, r9                                    r3 = r9
    add64 r3, 48                                    r3 += 48   ///  r3 = r3.wrapping_add(48 as i32 as i64 as u64)
    stxdw [r10-0x7e8], r3                   
    mov64 r3, r9                                    r3 = r9
    add64 r3, 56                                    r3 += 56   ///  r3 = r3.wrapping_add(56 as i32 as i64 as u64)
    stxdw [r10-0x7f0], r3                   
    mov64 r3, r9                                    r3 = r9
    add64 r3, 64                                    r3 += 64   ///  r3 = r3.wrapping_add(64 as i32 as i64 as u64)
    stxdw [r10-0x7f8], r3                   
    mov64 r3, r9                                    r3 = r9
    add64 r3, 72                                    r3 += 72   ///  r3 = r3.wrapping_add(72 as i32 as i64 as u64)
    stxdw [r10-0x800], r3                   
    mov64 r3, r9                                    r3 = r9
    add64 r3, 80                                    r3 += 80   ///  r3 = r3.wrapping_add(80 as i32 as i64 as u64)
    stxdw [r10-0x808], r3                   
    mov64 r3, r9                                    r3 = r9
    add64 r3, 88                                    r3 += 88   ///  r3 = r3.wrapping_add(88 as i32 as i64 as u64)
    stxdw [r10-0x818], r3                   
    ldxdw r2, [r2+0x10]                     
    stxdw [r10-0x830], r2                   
    mov64 r2, r9                                    r2 = r9
    add64 r2, 120                                   r2 += 120   ///  r2 = r2.wrapping_add(120 as i32 as i64 as u64)
    stxdw [r10-0x820], r2                   
    mov64 r2, r9                                    r2 = r9
    add64 r2, 112                                   r2 += 112   ///  r2 = r2.wrapping_add(112 as i32 as i64 as u64)
    stxdw [r10-0x828], r2                   
    ldxdw r4, [r8+0x0]                      
    ldxdw r2, [r4+0x28]                     
    lddw r3, 0xde8f75eee1f6dd06                     r3 load str located at -2409577606766207738
    stxdw [r10-0x7d0], r8                   
    jne r2, r3, lbb_6910                            if r2 != r3 { pc += 15 }
    ldxdw r2, [r4+0x30]                     
    lddw r3, 0xdacd6ce4bc5d4218                     r3 load str located at -2680366473547005416
    jne r2, r3, lbb_6910                            if r2 != r3 { pc += 11 }
    ldxdw r2, [r4+0x38]                     
    lddw r3, 0x270db9834dfc1ab6                     r3 load str located at 2814109315776649910
    jne r2, r3, lbb_6910                            if r2 != r3 { pc += 7 }
    mov64 r2, r6                                    r2 = r6
    ldxdw r1, [r4+0x40]                     
    lddw r3, 0xfc8ba1d828f9bdfe                     r3 load str located at -248927404616466946
    jne r1, r3, lbb_6911                            if r1 != r3 { pc += 3 }
    ldxdw r0, [r10-0x7c0]                   
    ja lbb_6911                                     if true { pc += 1 }
lbb_6910:
    mov64 r2, r6                                    r2 = r6
lbb_6911:
    stxdw [r10-0x780], r0                   
    ldxdw r5, [r10-0x810]                   
    add64 r5, 8                                     r5 += 8   ///  r5 = r5.wrapping_add(8 as i32 as i64 as u64)
    ldxdw r1, [r10-0x7a8]                   
    ldxdw r1, [r1+0x0]                      
    stxdw [r10-0x788], r1                   
    ldxdw r1, [r9+0x0]                      
    stxdw [r10-0x810], r1                   
    ldxdw r1, [r10-0x798]                   
    ldxdw r1, [r1+0x0]                      
    stxdw [r10-0x848], r1                   
    ldxdw r1, [r9+0x8]                      
    stxdw [r10-0x850], r1                   
    ldxdw r1, [r7+0x0]                      
    stxdw [r10-0x858], r1                   
    stxdw [r10-0x7c0], r7                   
    ldxdw r1, [r10-0x790]                   
    ldxdw r1, [r1+0x0]                      
    stxdw [r10-0x860], r1                   
    ldxdw r1, [r9+0x20]                     
    stxdw [r10-0x868], r1                   
    ldxdw r1, [r9+0x30]                     
    stxdw [r10-0x870], r1                   
    ldxdw r1, [r9+0x38]                     
    stxdw [r10-0x878], r1                   
    stxdw [r10-0x840], r2                   
    ldxdw r1, [r2+0x0]                      
    stxdw [r10-0x880], r1                   
    ldxdw r1, [r0+0x0]                      
    stxdw [r10-0x888], r1                   
    ldxdw r1, [r10-0x7a0]                   
    ldxdw r1, [r1+0x0]                      
    ldxdw r3, [r9+0x40]                     
    ldxdw r2, [r9+0x48]                     
    ldxdw r8, [r9+0x50]                     
    ldxdw r7, [r9+0x58]                     
    ldxdw r6, [r9+0x70]                     
    ldxdw r0, [r9+0x78]                     
    stxdw [r10-0x6f8], r5                   
    add64 r4, 8                                     r4 += 8   ///  r4 = r4.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x738], r4                   
    ldxdw r4, [r10-0x838]                   
    add64 r4, 8                                     r4 += 8   ///  r4 = r4.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x748], r4                   
    add64 r0, 8                                     r0 += 8   ///  r0 = r0.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x638], r0                   
    add64 r6, 8                                     r6 += 8   ///  r6 = r6.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x648], r6                   
    add64 r7, 8                                     r7 += 8   ///  r7 = r7.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x658], r7                   
    add64 r8, 8                                     r8 += 8   ///  r8 = r8.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x668], r8                   
    add64 r2, 8                                     r2 += 8   ///  r2 = r2.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x688], r2                   
    add64 r3, 8                                     r3 += 8   ///  r3 = r3.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x698], r3                   
    add64 r1, 8                                     r1 += 8   ///  r1 = r1.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x6a8], r1                   
    ldxdw r1, [r10-0x888]                   
    add64 r1, 8                                     r1 += 8   ///  r1 = r1.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x6b8], r1                   
    ldxdw r1, [r10-0x880]                   
    add64 r1, 8                                     r1 += 8   ///  r1 = r1.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x6c8], r1                   
    ldxdw r1, [r10-0x878]                   
    add64 r1, 8                                     r1 += 8   ///  r1 = r1.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x6d8], r1                   
    ldxdw r1, [r10-0x870]                   
    add64 r1, 8                                     r1 += 8   ///  r1 = r1.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x6e8], r1                   
    ldxdw r1, [r10-0x868]                   
    add64 r1, 8                                     r1 += 8   ///  r1 = r1.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x708], r1                   
    ldxdw r1, [r10-0x860]                   
    add64 r1, 8                                     r1 += 8   ///  r1 = r1.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x718], r1                   
    ldxdw r1, [r10-0x858]                   
    add64 r1, 8                                     r1 += 8   ///  r1 = r1.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x728], r1                   
    ldxdw r1, [r10-0x850]                   
    add64 r1, 8                                     r1 += 8   ///  r1 = r1.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x758], r1                   
    ldxdw r1, [r10-0x848]                   
    add64 r1, 8                                     r1 += 8   ///  r1 = r1.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x768], r1                   
    ldxdw r1, [r10-0x810]                   
    add64 r1, 8                                     r1 += 8   ///  r1 = r1.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x778], r1                   
    ldxdw r1, [r10-0x788]                   
    add64 r1, 8                                     r1 += 8   ///  r1 = r1.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x788], r1                   
    stxdw [r10-0x678], r1                   
    sth [r10-0x630], 0                      
    sth [r10-0x640], 0                      
    sth [r10-0x650], 1                      
    sth [r10-0x660], 1                      
    sth [r10-0x670], 0                      
    sth [r10-0x680], 0                      
    sth [r10-0x690], 0                      
    sth [r10-0x6a0], 0                      
    sth [r10-0x6b0], 0                      
    sth [r10-0x6c0], 0                      
    sth [r10-0x6d0], 1                      
    sth [r10-0x6e0], 0                      
    sth [r10-0x6f0], 1                      
    sth [r10-0x700], 1                      
    sth [r10-0x710], 1                      
    sth [r10-0x720], 1                      
    sth [r10-0x730], 0                      
    sth [r10-0x740], 0                      
    sth [r10-0x750], 0                      
    sth [r10-0x760], 257                    
    sth [r10-0x770], 1                      
    ldxdw r1, [r10-0x830]                   
    stxdw [r10-0x600], r1                   
    lddw r2, 0xad837f01a485e633                     r2 load str located at -5943767438166989261
    stxdw [r10-0x608], r2                   
    stdw [r10-0x5f8], 0                     
    ldxdw r1, [r10-0x820]                   
    stxdw [r10-0x548], r1                   
    ldxdw r1, [r10-0x828]                   
    stxdw [r10-0x550], r1                   
    ldxdw r1, [r10-0x818]                   
    stxdw [r10-0x558], r1                   
    ldxdw r1, [r10-0x808]                   
    stxdw [r10-0x560], r1                   
    ldxdw r1, [r10-0x7a8]                   
    stxdw [r10-0x568], r1                   
    ldxdw r1, [r10-0x800]                   
    stxdw [r10-0x570], r1                   
    ldxdw r1, [r10-0x7f8]                   
    stxdw [r10-0x578], r1                   
    ldxdw r1, [r10-0x7a0]                   
    stxdw [r10-0x580], r1                   
    ldxdw r1, [r10-0x780]                   
    stxdw [r10-0x588], r1                   
    ldxdw r1, [r10-0x840]                   
    stxdw [r10-0x590], r1                   
    ldxdw r1, [r10-0x7f0]                   
    stxdw [r10-0x598], r1                   
    ldxdw r1, [r10-0x7e8]                   
    stxdw [r10-0x5a0], r1                   
    ldxdw r1, [r10-0x7c8]                   
    stxdw [r10-0x5a8], r1                   
    ldxdw r1, [r10-0x7e0]                   
    stxdw [r10-0x5b0], r1                   
    ldxdw r1, [r10-0x790]                   
    stxdw [r10-0x5b8], r1                   
    ldxdw r1, [r10-0x7c0]                   
    stxdw [r10-0x5c0], r1                   
    ldxdw r1, [r10-0x7d0]                   
    stxdw [r10-0x5c8], r1                   
    ldxdw r1, [r10-0x7b8]                   
    stxdw [r10-0x5d0], r1                   
    ldxdw r1, [r10-0x7d8]                   
    stxdw [r10-0x5d8], r1                   
    ldxdw r1, [r10-0x798]                   
    stxdw [r10-0x5e0], r1                   
    stxdw [r10-0x5e8], r9                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -1512                                 r1 += -1512   ///  r1 = r1.wrapping_add(-1512 as i32 as i64 as u64)
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
    mov64 r4, r10                                   r4 = r10
    add64 r4, -1904                                 r4 += -1904   ///  r4 = r4.wrapping_add(-1904 as i32 as i64 as u64)
    ja lbb_7097                                     if true { pc += 20 }
lbb_7077:
    mov64 r7, r10                                   r7 = r10
    add64 r7, -1328                                 r7 += -1328   ///  r7 = r7.wrapping_add(-1328 as i32 as i64 as u64)
    add64 r7, r2                                    r7 += r2   ///  r7 = r7.wrapping_add(r2)
    stxb [r7+0x32], r6                      
    stxb [r7+0x31], r8                      
    stxb [r7+0x30], r0                      
    mov64 r0, r5                                    r0 = r5
    add64 r0, 40                                    r0 += 40   ///  r0 = r0.wrapping_add(40 as i32 as i64 as u64)
    stxdw [r7+0x20], r0                     
    mov64 r0, r5                                    r0 = r5
    add64 r0, 88                                    r0 += 88   ///  r0 = r0.wrapping_add(88 as i32 as i64 as u64)
    stxdw [r7+0x18], r0                     
    stxdw [r7+0x10], r3                     
    add64 r5, 72                                    r5 += 72   ///  r5 = r5.wrapping_add(72 as i32 as i64 as u64)
    stxdw [r7+0x8], r5                      
    stdw [r7+0x28], 0                       
    add64 r4, 16                                    r4 += 16   ///  r4 = r4.wrapping_add(16 as i32 as i64 as u64)
    add64 r1, 8                                     r1 += 8   ///  r1 = r1.wrapping_add(8 as i32 as i64 as u64)
    add64 r2, 56                                    r2 += 56   ///  r2 = r2.wrapping_add(56 as i32 as i64 as u64)
    jeq r2, 1176, lbb_7151                          if r2 == (1176 as i32 as i64 as u64) { pc += 54 }
lbb_7097:
    mov64 r0, r10                                   r0 = r10
    add64 r0, -1328                                 r0 += -1328   ///  r0 = r0.wrapping_add(-1328 as i32 as i64 as u64)
    mov64 r3, 1                                     r3 = 1 as i32 as i64 as u64
    ldxdw r5, [r1+0x0]                      
    ldxdw r5, [r5+0x0]                      
    ldxdw r6, [r4-0x8]                      
    ldxdw r7, [r6+0x0]                      
    ldxdw r8, [r5+0x8]                      
    jne r8, r7, lbb_7146                            if r8 != r7 { pc += 40 }
    ldxdw r7, [r6+0x8]                      
    ldxdw r8, [r5+0x10]                     
    jne r8, r7, lbb_7146                            if r8 != r7 { pc += 37 }
    ldxdw r7, [r6+0x10]                     
    ldxdw r8, [r5+0x18]                     
    jne r8, r7, lbb_7146                            if r8 != r7 { pc += 34 }
    ldxdw r6, [r6+0x18]                     
    ldxdw r7, [r5+0x20]                     
    jne r7, r6, lbb_7146                            if r7 != r6 { pc += 31 }
    ldxb r6, [r4+0x0]                       
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
    jne r6, 0, lbb_7119                             if r6 != (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r3, 119                                   r3 = 119 as i32 as i64 as u64
lbb_7119:
    ldxb r6, [r5+0x0]                       
    or64 r3, r6                                     r3 |= r6   ///  r3 = r3.or(r6)
    and64 r3, 255                                   r3 &= 255   ///  r3 = r3.and(255)
    jne r3, 255, lbb_7145                           if r3 != (255 as i32 as i64 as u64) { pc += 22 }
    add64 r0, r2                                    r0 += r2   ///  r0 = r0.wrapping_add(r2)
    mov64 r6, r5                                    r6 = r5
    add64 r6, 8                                     r6 += 8   ///  r6 = r6.wrapping_add(8 as i32 as i64 as u64)
    ldxdw r3, [r5+0x50]                     
    ldxb r7, [r5+0x3]                       
    ldxb r9, [r5+0x2]                       
    ldxb r8, [r5+0x1]                       
    stxdw [r0+0x0], r6                      
    mov64 r6, 1                                     r6 = 1 as i32 as i64 as u64
    mov64 r0, 1                                     r0 = 1 as i32 as i64 as u64
    jne r8, 0, lbb_7139                             if r8 != (0 as i32 as i64 as u64) { pc += 5 }
    mov64 r0, 0                                     r0 = 0 as i32 as i64 as u64
    mov64 r8, 1                                     r8 = 1 as i32 as i64 as u64
    jeq r9, 0, lbb_7141                             if r9 == (0 as i32 as i64 as u64) { pc += 4 }
lbb_7137:
    jne r7, 0, lbb_7077                             if r7 != (0 as i32 as i64 as u64) { pc += -61 }
    ja lbb_7143                                     if true { pc += 4 }
lbb_7139:
    mov64 r8, 1                                     r8 = 1 as i32 as i64 as u64
    jne r9, 0, lbb_7137                             if r9 != (0 as i32 as i64 as u64) { pc += -4 }
lbb_7141:
    mov64 r8, 0                                     r8 = 0 as i32 as i64 as u64
    jne r7, 0, lbb_7077                             if r7 != (0 as i32 as i64 as u64) { pc += -66 }
lbb_7143:
    mov64 r6, 0                                     r6 = 0 as i32 as i64 as u64
    ja lbb_7077                                     if true { pc += -68 }
lbb_7145:
    mov64 r3, 11                                    r3 = 11 as i32 as i64 as u64
lbb_7146:
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    stxdw [r10-0x788], r1                   
    ja lbb_7188                                     if true { pc += 39 }
lbb_7149:
    mov64 r3, 11                                    r3 = 11 as i32 as i64 as u64
    ja lbb_7188                                     if true { pc += 37 }
lbb_7151:
    mov64 r1, r10                                   r1 = r10
    add64 r1, -1544                                 r1 += -1544   ///  r1 = r1.wrapping_add(-1544 as i32 as i64 as u64)
    stxdw [r10-0x10], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -1912                                 r1 += -1912   ///  r1 = r1.wrapping_add(-1912 as i32 as i64 as u64)
    stxdw [r10-0x20], r1                    
    ldxdw r1, [r10-0x788]                   
    stxdw [r10-0x28], r1                    
    stdw [r10-0x8], 24                      
    stdw [r10-0x18], 21                     
    mov64 r1, r10                                   r1 = r10
    add64 r1, -40                                   r1 += -40   ///  r1 = r1.wrapping_add(-40 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -1328                                 r2 += -1328   ///  r2 = r2.wrapping_add(-1328 as i32 as i64 as u64)
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
    stxdw [r10-0x788], r3                   
    mov64 r3, 21                                    r3 = 21 as i32 as i64 as u64
    ja lbb_7184                                     if true { pc += 15 }
lbb_7169:
    mov64 r1, r10                                   r1 = r10
    add64 r1, -1544                                 r1 += -1544   ///  r1 = r1.wrapping_add(-1544 as i32 as i64 as u64)
    stxdw [r10-0x10], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -1912                                 r1 += -1912   ///  r1 = r1.wrapping_add(-1912 as i32 as i64 as u64)
    stxdw [r10-0x20], r1                    
    ldxdw r1, [r10-0x7b8]                   
    stxdw [r10-0x28], r1                    
    stdw [r10-0x8], 25                      
    stdw [r10-0x18], 23                     
    mov64 r1, r10                                   r1 = r10
    add64 r1, -40                                   r1 += -40   ///  r1 = r1.wrapping_add(-40 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -1328                                 r2 += -1328   ///  r2 = r2.wrapping_add(-1328 as i32 as i64 as u64)
    mov64 r3, 23                                    r3 = 23 as i32 as i64 as u64
lbb_7184:
    mov64 r4, 8                                     r4 = 8 as i32 as i64 as u64
    mov64 r5, 0                                     r5 = 0 as i32 as i64 as u64
    syscall [invalid]                       
    mov64 r3, 26                                    r3 = 26 as i32 as i64 as u64
lbb_7188:
    ldxdw r1, [r10-0x7b0]                   
lbb_7189:
    ldxdw r2, [r10-0x788]                   
    stxw [r1+0x4], r2                       
    stxw [r1+0x0], r3                       
    exit                                    
lbb_7193:
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
    lddw r3, 0x100026cc8 --> b"\x00\x00\x00\x00\xb8Y\x02\x00\x10\x00\x00\x00\x00\x00\x00\x006!\x00\x00\x…        r3 load str located at 4295126216
    call function_18489                     
lbb_7198:
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
    lddw r3, 0x100026b78 --> b"\x00\x00\x00\x00\xb8Y\x02\x00\x10\x00\x00\x00\x00\x00\x00\x00@!\x00\x00\x…        r3 load str located at 4295125880
    call function_18489                     
lbb_7203:
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    mov64 r2, 1                                     r2 = 1 as i32 as i64 as u64
    lddw r3, 0x100026ce0 --> b"\x00\x00\x00\x00\xb8Y\x02\x00\x10\x00\x00\x00\x00\x00\x00\x006!\x00\x00!\…        r3 load str located at 4295126240
    call function_18489                     
lbb_7208:
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    mov64 r2, 1                                     r2 = 1 as i32 as i64 as u64
    lddw r3, 0x100026b90 --> b"\x00\x00\x00\x00\xb8Y\x02\x00\x10\x00\x00\x00\x00\x00\x00\x00@!\x00\x00%\…        r3 load str located at 4295125904
    call function_18489                     
lbb_7213:
    mov64 r1, 2                                     r1 = 2 as i32 as i64 as u64
    mov64 r2, 2                                     r2 = 2 as i32 as i64 as u64
    lddw r3, 0x100026cf8 --> b"\x00\x00\x00\x00\xb8Y\x02\x00\x10\x00\x00\x00\x00\x00\x00\x006!\x00\x008\…        r3 load str located at 4295126264
    call function_18489                     
lbb_7218:
    mov64 r1, 2                                     r1 = 2 as i32 as i64 as u64
    mov64 r2, 2                                     r2 = 2 as i32 as i64 as u64
    lddw r3, 0x100026ba8 --> b"\x00\x00\x00\x00\xb8Y\x02\x00\x10\x00\x00\x00\x00\x00\x00\x00@!\x00\x00<\…        r3 load str located at 4295125928
    call function_18489                     
lbb_7223:
    mov64 r1, 3                                     r1 = 3 as i32 as i64 as u64
    mov64 r2, 3                                     r2 = 3 as i32 as i64 as u64
    lddw r3, 0x100026d10 --> b"\x00\x00\x00\x00\xb8Y\x02\x00\x10\x00\x00\x00\x00\x00\x00\x006!\x00\x00O\…        r3 load str located at 4295126288
    call function_18489                     
lbb_7228:
    mov64 r1, 3                                     r1 = 3 as i32 as i64 as u64
    mov64 r2, 3                                     r2 = 3 as i32 as i64 as u64
    lddw r3, 0x100026bc0 --> b"\x00\x00\x00\x00\xb8Y\x02\x00\x10\x00\x00\x00\x00\x00\x00\x00@!\x00\x00S\…        r3 load str located at 4295125952
    call function_18489                     
lbb_7233:
    mov64 r1, 4                                     r1 = 4 as i32 as i64 as u64
    mov64 r2, 4                                     r2 = 4 as i32 as i64 as u64
    lddw r3, 0x100026d28 --> b"\x00\x00\x00\x00\xb8Y\x02\x00\x10\x00\x00\x00\x00\x00\x00\x007!\x00\x00\x…        r3 load str located at 4295126312
    call function_18489                     
lbb_7238:
    mov64 r1, 4                                     r1 = 4 as i32 as i64 as u64
    mov64 r2, 4                                     r2 = 4 as i32 as i64 as u64
    lddw r3, 0x100026bd8 --> b"\x00\x00\x00\x00\xb8Y\x02\x00\x10\x00\x00\x00\x00\x00\x00\x00A!\x00\x00\x…        r3 load str located at 4295125976
    call function_18489                     
lbb_7243:
    mov64 r1, 5                                     r1 = 5 as i32 as i64 as u64
    mov64 r2, 5                                     r2 = 5 as i32 as i64 as u64
    lddw r3, 0x100026d40 --> b"\x00\x00\x00\x00\xb8Y\x02\x00\x10\x00\x00\x00\x00\x00\x00\x007!\x00\x00!\…        r3 load str located at 4295126336
    call function_18489                     
lbb_7248:
    mov64 r1, 5                                     r1 = 5 as i32 as i64 as u64
    mov64 r2, 5                                     r2 = 5 as i32 as i64 as u64
    lddw r3, 0x100026bf0 --> b"\x00\x00\x00\x00\xb8Y\x02\x00\x10\x00\x00\x00\x00\x00\x00\x00A!\x00\x00%\…        r3 load str located at 4295126000
    call function_18489                     
lbb_7253:
    mov64 r1, 6                                     r1 = 6 as i32 as i64 as u64
    mov64 r2, 6                                     r2 = 6 as i32 as i64 as u64
    lddw r3, 0x100026d58 --> b"\x00\x00\x00\x00\xb8Y\x02\x00\x10\x00\x00\x00\x00\x00\x00\x007!\x00\x008\…        r3 load str located at 4295126360
    call function_18489                     
lbb_7258:
    mov64 r1, 6                                     r1 = 6 as i32 as i64 as u64
    mov64 r2, 6                                     r2 = 6 as i32 as i64 as u64
    lddw r3, 0x100026c08 --> b"\x00\x00\x00\x00\xb8Y\x02\x00\x10\x00\x00\x00\x00\x00\x00\x00A!\x00\x00<\…        r3 load str located at 4295126024
    call function_18489                     
lbb_7263:
    mov64 r1, 7                                     r1 = 7 as i32 as i64 as u64
    mov64 r2, 7                                     r2 = 7 as i32 as i64 as u64
    lddw r3, 0x100026d70 --> b"\x00\x00\x00\x00\xb8Y\x02\x00\x10\x00\x00\x00\x00\x00\x00\x007!\x00\x00O\…        r3 load str located at 4295126384
    call function_18489                     
lbb_7268:
    mov64 r1, 7                                     r1 = 7 as i32 as i64 as u64
    mov64 r2, 7                                     r2 = 7 as i32 as i64 as u64
    lddw r3, 0x100026c20 --> b"\x00\x00\x00\x00\xb8Y\x02\x00\x10\x00\x00\x00\x00\x00\x00\x00A!\x00\x00S\…        r3 load str located at 4295126048
    call function_18489                     
lbb_7273:
    mov64 r1, 8                                     r1 = 8 as i32 as i64 as u64
    mov64 r2, 8                                     r2 = 8 as i32 as i64 as u64
    lddw r3, 0x100026d88 --> b"\x00\x00\x00\x00\xb8Y\x02\x00\x10\x00\x00\x00\x00\x00\x00\x008!\x00\x00\x…        r3 load str located at 4295126408
    call function_18489                     
lbb_7278:
    mov64 r1, 8                                     r1 = 8 as i32 as i64 as u64
    mov64 r2, 8                                     r2 = 8 as i32 as i64 as u64
    lddw r3, 0x100026c38 --> b"\x00\x00\x00\x00\xb8Y\x02\x00\x10\x00\x00\x00\x00\x00\x00\x00B!\x00\x00\x…        r3 load str located at 4295126072
    call function_18489                     
lbb_7283:
    mov64 r1, 9                                     r1 = 9 as i32 as i64 as u64
    mov64 r2, 9                                     r2 = 9 as i32 as i64 as u64
    lddw r3, 0x100026da0 --> b"\x00\x00\x00\x00\xb8Y\x02\x00\x10\x00\x00\x00\x00\x00\x00\x008!\x00\x00!\…        r3 load str located at 4295126432
    call function_18489                     
lbb_7288:
    mov64 r1, 9                                     r1 = 9 as i32 as i64 as u64
    mov64 r2, 9                                     r2 = 9 as i32 as i64 as u64
    lddw r3, 0x100026c50 --> b"\x00\x00\x00\x00\xb8Y\x02\x00\x10\x00\x00\x00\x00\x00\x00\x00B!\x00\x00%\…        r3 load str located at 4295126096
    call function_18489                     
lbb_7293:
    mov64 r1, 10                                    r1 = 10 as i32 as i64 as u64
    mov64 r2, 10                                    r2 = 10 as i32 as i64 as u64
    lddw r3, 0x100026db8 --> b"\x00\x00\x00\x00\xb8Y\x02\x00\x10\x00\x00\x00\x00\x00\x00\x008!\x00\x008\…        r3 load str located at 4295126456
    call function_18489                     
lbb_7298:
    mov64 r1, 10                                    r1 = 10 as i32 as i64 as u64
    mov64 r2, 10                                    r2 = 10 as i32 as i64 as u64
    lddw r3, 0x100026c68 --> b"\x00\x00\x00\x00\xb8Y\x02\x00\x10\x00\x00\x00\x00\x00\x00\x00B!\x00\x00<\…        r3 load str located at 4295126120
    call function_18489                     
lbb_7303:
    mov64 r1, 11                                    r1 = 11 as i32 as i64 as u64
    mov64 r2, 11                                    r2 = 11 as i32 as i64 as u64
    lddw r3, 0x100026dd0 --> b"\x00\x00\x00\x00\xb8Y\x02\x00\x10\x00\x00\x00\x00\x00\x00\x008!\x00\x00P\…        r3 load str located at 4295126480
    call function_18489                     
lbb_7308:
    mov64 r1, 11                                    r1 = 11 as i32 as i64 as u64
    mov64 r2, 11                                    r2 = 11 as i32 as i64 as u64
    lddw r3, 0x100026c80 --> b"\x00\x00\x00\x00\xb8Y\x02\x00\x10\x00\x00\x00\x00\x00\x00\x00B!\x00\x00T\…        r3 load str located at 4295126144
    call function_18489                     
lbb_7313:
    mov64 r1, 12                                    r1 = 12 as i32 as i64 as u64
    mov64 r2, 12                                    r2 = 12 as i32 as i64 as u64
    lddw r3, 0x100026de8 --> b"\x00\x00\x00\x00\xb8Y\x02\x00\x10\x00\x00\x00\x00\x00\x00\x009!\x00\x00\x…        r3 load str located at 4295126504
    call function_18489                     
lbb_7318:
    mov64 r1, 14                                    r1 = 14 as i32 as i64 as u64
    mov64 r2, r3                                    r2 = r3
    lddw r3, 0x100026c98 --> b"\x00\x00\x00\x00\xb8Y\x02\x00\x10\x00\x00\x00\x00\x00\x00\x00C!\x00\x00\x…        r3 load str located at 4295126168
    call function_18489                     
lbb_7323:
    mov64 r1, 13                                    r1 = 13 as i32 as i64 as u64
    mov64 r2, 13                                    r2 = 13 as i32 as i64 as u64
    lddw r3, 0x100026e00 --> b"\x00\x00\x00\x00\xb8Y\x02\x00\x10\x00\x00\x00\x00\x00\x00\x009!\x00\x00"\…        r3 load str located at 4295126528
    call function_18489                     
lbb_7328:
    mov64 r1, 15                                    r1 = 15 as i32 as i64 as u64
    mov64 r2, 15                                    r2 = 15 as i32 as i64 as u64
    lddw r3, 0x100026cb0 --> b"\x00\x00\x00\x00\xb8Y\x02\x00\x10\x00\x00\x00\x00\x00\x00\x00C!\x00\x00'\…        r3 load str located at 4295126192
    call function_18489                     
lbb_7333:
    mov64 r1, 14                                    r1 = 14 as i32 as i64 as u64
    mov64 r2, 14                                    r2 = 14 as i32 as i64 as u64
    lddw r3, 0x100026e18 --> b"\x00\x00\x00\x00\xb8Y\x02\x00\x10\x00\x00\x00\x00\x00\x00\x009!\x00\x00:\…        r3 load str located at 4295126552
    call function_18489                     
lbb_7338:
    mov64 r1, 15                                    r1 = 15 as i32 as i64 as u64
    mov64 r2, 15                                    r2 = 15 as i32 as i64 as u64
    lddw r3, 0x100026e30 --> b"\x00\x00\x00\x00\xb8Y\x02\x00\x10\x00\x00\x00\x00\x00\x00\x009!\x00\x00R\…        r3 load str located at 4295126576
    call function_18489                     
    mov64 r4, r2                                    r4 = r2
    ldxdw r9, [r4+0x8]                      
    mov64 r3, r9                                    r3 = r9
    add64 r3, -9                                    r3 += -9   ///  r3 = r3.wrapping_add(-9 as i32 as i64 as u64)
    mov64 r7, 0                                     r7 = 0 as i32 as i64 as u64
    mov64 r2, 1                                     r2 = 1 as i32 as i64 as u64
    jgt r3, r9, lbb_7410                            if r3 > r9 { pc += 60 }
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
    jeq r2, 0, lbb_7411                             if r2 == (0 as i32 as i64 as u64) { pc += 59 }
lbb_7352:
    jeq r9, 1, lbb_7413                             if r9 == (1 as i32 as i64 as u64) { pc += 60 }
lbb_7353:
    jeq r9, 0, lbb_7714                             if r9 == (0 as i32 as i64 as u64) { pc += 360 }
    jle r9, 2, lbb_7719                             if r9 <= (2 as i32 as i64 as u64) { pc += 364 }
    jeq r9, 3, lbb_7724                             if r9 == (3 as i32 as i64 as u64) { pc += 368 }
    jle r9, 4, lbb_7729                             if r9 <= (4 as i32 as i64 as u64) { pc += 372 }
    jeq r9, 5, lbb_7734                             if r9 == (5 as i32 as i64 as u64) { pc += 376 }
    jle r9, 6, lbb_7739                             if r9 <= (6 as i32 as i64 as u64) { pc += 380 }
    jeq r9, 7, lbb_7744                             if r9 == (7 as i32 as i64 as u64) { pc += 384 }
    stxdw [r10-0x260], r1                   
    jle r9, 8, lbb_7749                             if r9 <= (8 as i32 as i64 as u64) { pc += 387 }
    mov64 r5, 3                                     r5 = 3 as i32 as i64 as u64
    mov64 r6, r7                                    r6 = r7
    add64 r6, 16                                    r6 += 16   ///  r6 = r6.wrapping_add(16 as i32 as i64 as u64)
    jgt r6, 32, lbb_7708                            if r6 > (32 as i32 as i64 as u64) { pc += 342 }
    ldxdw r8, [r4+0x0]                      
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
    ldxdw r1, [r8+0x0]                      
    ldxdw r2, [r1+0x50]                     
    jlt r2, 848, lbb_7704                           if r2 < (848 as i32 as i64 as u64) { pc += 333 }
    stxdw [r10-0x268], r1                   
    ldxdw r1, [r4+0x50]                     
    ldxdw r0, [r1+0x0]                      
    ldxdw r2, [r0+0x50]                     
    jlt r2, 32, lbb_7704                            if r2 < (32 as i32 as i64 as u64) { pc += 328 }
    stxdw [r10-0x270], r7                   
    stxdw [r10-0x230], r1                   
    mov64 r1, r8                                    r1 = r8
    add64 r1, 32                                    r1 += 32   ///  r1 = r1.wrapping_add(32 as i32 as i64 as u64)
    ldxdw r7, [r1+0x0]                      
    ldxdw r2, [r7+0x50]                     
    jlt r2, 32, lbb_7704                            if r2 < (32 as i32 as i64 as u64) { pc += 321 }
    stxdw [r10-0x280], r1                   
    ldxdw r5, [r4+0x58]                     
    mov64 r1, r8                                    r1 = r8
    add64 r8, 56                                    r8 += 56   ///  r8 = r8.wrapping_add(56 as i32 as i64 as u64)
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
    stxdw [r10-0x258], r2                   
    ldxdw r2, [r7+0x58]                     
    ldxdw r3, [r0+0x58]                     
    stxdw [r10-0x290], r7                   
    jne r3, r2, lbb_7418                            if r3 != r2 { pc += 25 }
    ldxdw r2, [r7+0x60]                     
    ldxdw r3, [r0+0x60]                     
    jne r3, r2, lbb_7418                            if r3 != r2 { pc += 22 }
    ldxdw r2, [r7+0x68]                     
    ldxdw r3, [r0+0x68]                     
    jne r3, r2, lbb_7418                            if r3 != r2 { pc += 19 }
    ldxdw r2, [r7+0x70]                     
    ldxdw r3, [r0+0x70]                     
    mov64 r0, 1                                     r0 = 1 as i32 as i64 as u64
    jeq r3, r2, lbb_7404                            if r3 == r2 { pc += 1 }
    mov64 r0, 0                                     r0 = 0 as i32 as i64 as u64
lbb_7404:
    stxdw [r10-0x258], r0                   
    jne r3, r2, lbb_7418                            if r3 != r2 { pc += 12 }
    ldxdw r2, [r10-0x230]                   
    stxdw [r10-0x240], r2                   
    stxdw [r10-0x230], r5                   
    ja lbb_7419                                     if true { pc += 9 }
lbb_7410:
    jne r2, 0, lbb_7352                             if r2 != (0 as i32 as i64 as u64) { pc += -59 }
lbb_7411:
    mov64 r7, r3                                    r7 = r3
    jne r9, 1, lbb_7353                             if r9 != (1 as i32 as i64 as u64) { pc += -60 }
lbb_7413:
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    mov64 r2, 1                                     r2 = 1 as i32 as i64 as u64
    lddw r3, 0x100026e60 --> b"\x00\x00\x00\x00\xb8Y\x02\x00\x10\x00\x00\x00\x00\x00\x00\x00S!\x00\x00!\…        r3 load str located at 4295126624
    call function_18489                     
lbb_7418:
    stxdw [r10-0x240], r5                   
lbb_7419:
    ldxdw r2, [r4+0x20]                     
    stxdw [r10-0x238], r2                   
    mov64 r7, r1                                    r7 = r1
    add64 r7, 64                                    r7 += 64   ///  r7 = r7.wrapping_add(64 as i32 as i64 as u64)
    ldxdw r2, [r8+0x0]                      
    ldxdw r3, [r2+0x8]                      
    lddw r5, 0x8481abfe57889b06                     r5 load str located at -8898642279828776186
    jne r3, r5, lbb_7441                            if r3 != r5 { pc += 13 }
    ldxdw r3, [r2+0x10]                     
    lddw r0, 0x35c01846637f68fb                     r0 load str located at 3873122370134698235
    jne r3, r0, lbb_7441                            if r3 != r0 { pc += 9 }
    ldxdw r3, [r2+0x18]                     
    lddw r0, 0x553beb1adc39c4da                     r0 load str located at 6141761017446253786
    jne r3, r0, lbb_7441                            if r3 != r0 { pc += 5 }
    ldxdw r2, [r2+0x20]                     
    lddw r3, 0x100000000f0a098                      r3 load str located at 72057594053697688
    jne r2, r3, lbb_7441                            if r2 != r3 { pc += 1 }
    ldxdw r8, [r10-0x238]                   
lbb_7441:
    ldxdw r0, [r4+0x48]                     
    ldxdw r2, [r4+0x40]                     
    stxdw [r10-0x250], r2                   
    ldxdw r2, [r4+0x28]                     
    stxdw [r10-0x248], r2                   
    mov64 r2, r1                                    r2 = r1
    mov64 r3, r2                                    r3 = r2
    add64 r3, 8                                     r3 += 8   ///  r3 = r3.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x298], r3                   
    mov64 r3, r2                                    r3 = r2
    add64 r3, 16                                    r3 += 16   ///  r3 = r3.wrapping_add(16 as i32 as i64 as u64)
    stxdw [r10-0x2a0], r3                   
    mov64 r3, r2                                    r3 = r2
    add64 r3, 24                                    r3 += 24   ///  r3 = r3.wrapping_add(24 as i32 as i64 as u64)
    stxdw [r10-0x2a8], r3                   
    mov64 r3, r2                                    r3 = r2
    add64 r3, 40                                    r3 += 40   ///  r3 = r3.wrapping_add(40 as i32 as i64 as u64)
    stxdw [r10-0x2b0], r3                   
    add64 r2, 48                                    r2 += 48   ///  r2 = r2.wrapping_add(48 as i32 as i64 as u64)
    stxdw [r10-0x2b8], r2                   
    ldxdw r3, [r7+0x0]                      
    ldxdw r2, [r3+0x8]                      
    stxdw [r10-0x300], r6                   
    stxdw [r10-0x278], r9                   
    jne r2, r5, lbb_7483                            if r2 != r5 { pc += 17 }
    ldxdw r5, [r3+0x10]                     
    lddw r2, 0x35c01846637f68fb                     r2 load str located at 3873122370134698235
    jne r5, r2, lbb_7483                            if r5 != r2 { pc += 13 }
    ldxdw r5, [r3+0x18]                     
    lddw r2, 0x553beb1adc39c4da                     r2 load str located at 6141761017446253786
    jne r5, r2, lbb_7483                            if r5 != r2 { pc += 9 }
    mov64 r5, r8                                    r5 = r8
    ldxdw r6, [r3+0x20]                     
    lddw r2, 0x100000000f0a098                      r2 load str located at 72057594053697688
    jne r6, r2, lbb_7484                            if r6 != r2 { pc += 5 }
    ldxdw r2, [r10-0x238]                   
    ldxdw r3, [r2+0x0]                      
    mov64 r7, r2                                    r7 = r2
    ja lbb_7484                                     if true { pc += 1 }
lbb_7483:
    mov64 r5, r8                                    r5 = r8
lbb_7484:
    stxdw [r10-0x2c8], r7                   
    ldxdw r2, [r4+0x10]                     
    stxdw [r10-0x310], r2                   
    ldxdw r7, [r10-0x268]                   
    ldxdw r2, [r7+0x220]                    
    stxdw [r10-0x308], r2                   
    ldxdw r2, [r7+0x218]                    
    stxdw [r10-0x288], r2                   
    add64 r3, 8                                     r3 += 8   ///  r3 = r3.wrapping_add(8 as i32 as i64 as u64)
    ldxdw r2, [r10-0x238]                   
    ldxdw r6, [r2+0x0]                      
    stxdw [r10-0x2c0], r0                   
    ldxdw r2, [r0+0x0]                      
    stxdw [r10-0x2d8], r2                   
    mov64 r8, r1                                    r8 = r1
    ldxdw r1, [r8+0x8]                      
    stxdw [r10-0x2e0], r1                   
    ldxdw r1, [r8+0x10]                     
    stxdw [r10-0x2e8], r1                   
    ldxdw r1, [r8+0x18]                     
    stxdw [r10-0x2f0], r1                   
    ldxdw r1, [r8+0x28]                     
    stxdw [r10-0x2f8], r1                   
    ldxdw r4, [r8+0x30]                     
    ldxdw r1, [r10-0x240]                   
    ldxdw r9, [r1+0x0]                      
    ldxdw r1, [r10-0x230]                   
    ldxdw r2, [r1+0x0]                      
    stxdw [r10-0x2d0], r5                   
    ldxdw r5, [r5+0x0]                      
    ldxdw r1, [r10-0x248]                   
    ldxdw r1, [r1+0x0]                      
    ldxdw r0, [r10-0x250]                   
    ldxdw r0, [r0+0x0]                      
    stxdw [r10-0x160], r3                   
    mov64 r3, r6                                    r3 = r6
    ldxdw r6, [r10-0x290]                   
    add64 r6, 8                                     r6 += 8   ///  r6 = r6.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x1c0], r6                   
    add64 r7, 8                                     r7 += 8   ///  r7 = r7.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x200], r7                   
    add64 r0, 8                                     r0 += 8   ///  r0 = r0.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x140], r0                   
    add64 r1, 8                                     r1 += 8   ///  r1 = r1.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x150], r1                   
    add64 r5, 8                                     r5 += 8   ///  r5 = r5.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x170], r5                   
    add64 r2, 8                                     r2 += 8   ///  r2 = r2.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x180], r2                   
    add64 r9, 8                                     r9 += 8   ///  r9 = r9.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x190], r9                   
    add64 r4, 8                                     r4 += 8   ///  r4 = r4.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x1a0], r4                   
    ldxdw r1, [r10-0x2f8]                   
    add64 r1, 8                                     r1 += 8   ///  r1 = r1.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x1b0], r1                   
    ldxdw r1, [r10-0x2f0]                   
    add64 r1, 8                                     r1 += 8   ///  r1 = r1.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x1d0], r1                   
    ldxdw r1, [r10-0x2e8]                   
    add64 r1, 8                                     r1 += 8   ///  r1 = r1.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x1e0], r1                   
    ldxdw r1, [r10-0x2e0]                   
    add64 r1, 8                                     r1 += 8   ///  r1 = r1.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x1f0], r1                   
    ldxdw r1, [r10-0x2d8]                   
    add64 r1, 8                                     r1 += 8   ///  r1 = r1.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x210], r1                   
    stxdw [r10-0x220], r1                   
    add64 r3, 8                                     r3 += 8   ///  r3 = r3.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x100], r3                   
    stxdw [r10-0x110], r3                   
    stxdw [r10-0x120], r3                   
    mov64 r7, r3                                    r7 = r3
    stxdw [r10-0x130], r3                   
    sth [r10-0xf8], 0                       
    sth [r10-0x108], 0                      
    sth [r10-0x118], 0                      
    sth [r10-0x128], 0                      
    sth [r10-0x138], 0                      
    sth [r10-0x148], 0                      
    sth [r10-0x158], 0                      
    sth [r10-0x168], 0                      
    sth [r10-0x178], 1                      
    sth [r10-0x188], 1                      
    sth [r10-0x198], 1                      
    sth [r10-0x1a8], 1                      
    sth [r10-0x1b8], 1                      
    sth [r10-0x1c8], 1                      
    sth [r10-0x1d8], 1                      
    sth [r10-0x1e8], 0                      
    sth [r10-0x1f8], 1                      
    sth [r10-0x208], 257                    
    sth [r10-0x218], 257                    
    ldxdw r1, [r10-0x238]                   
    stxdw [r10-0x78], r1                    
    ldxdw r1, [r10-0x250]                   
    stxdw [r10-0x80], r1                    
    ldxdw r1, [r10-0x248]                   
    stxdw [r10-0x88], r1                    
    ldxdw r1, [r10-0x2c8]                   
    stxdw [r10-0x90], r1                    
    ldxdw r1, [r10-0x2d0]                   
    stxdw [r10-0x98], r1                    
    ldxdw r1, [r10-0x230]                   
    stxdw [r10-0xa0], r1                    
    ldxdw r1, [r10-0x240]                   
    stxdw [r10-0xa8], r1                    
    ldxdw r1, [r10-0x2b8]                   
    stxdw [r10-0xb0], r1                    
    ldxdw r1, [r10-0x2b0]                   
    stxdw [r10-0xb8], r1                    
    ldxdw r1, [r10-0x280]                   
    stxdw [r10-0xc0], r1                    
    ldxdw r1, [r10-0x2a8]                   
    stxdw [r10-0xc8], r1                    
    ldxdw r1, [r10-0x2a0]                   
    stxdw [r10-0xd0], r1                    
    ldxdw r1, [r10-0x298]                   
    stxdw [r10-0xd8], r1                    
    stxdw [r10-0xe0], r8                    
    ldxdw r1, [r10-0x2c0]                   
    stxdw [r10-0x58], r1                    
    stxdw [r10-0x60], r1                    
    stxdw [r10-0x68], r1                    
    stxdw [r10-0x70], r1                    
    stxdw [r10-0xe8], r1                    
    stxdw [r10-0xf0], r1                    
    ldxdw r3, [r10-0x270]                   
    ldxdw r1, [r10-0x278]                   
    jeq r1, 9, lbb_7638                             if r1 == (9 as i32 as i64 as u64) { pc += 23 }
    mov64 r1, r8                                    r1 = r8
    add64 r1, 72                                    r1 += 72   ///  r1 = r1.wrapping_add(72 as i32 as i64 as u64)
    ldxdw r2, [r1+0x0]                      
    stxdw [r10-0x70], r1                    
    add64 r2, 8                                     r2 += 8   ///  r2 = r2.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x120], r2                   
    sth [r10-0x118], 1                      
    jeq r3, 1, lbb_7638                             if r3 == (1 as i32 as i64 as u64) { pc += 15 }
    ldxdw r1, [r8+0x50]                     
    mov64 r2, r8                                    r2 = r8
    add64 r2, 80                                    r2 += 80   ///  r2 = r2.wrapping_add(80 as i32 as i64 as u64)
    stxdw [r10-0x68], r2                    
    add64 r1, 8                                     r1 += 8   ///  r1 = r1.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x110], r1                   
    sth [r10-0x108], 1                      
    jeq r3, 2, lbb_7638                             if r3 == (2 as i32 as i64 as u64) { pc += 7 }
    ldxdw r1, [r8+0x58]                     
    add64 r8, 88                                    r8 += 88   ///  r8 = r8.wrapping_add(88 as i32 as i64 as u64)
    stxdw [r10-0x60], r8                    
    add64 r1, 8                                     r1 += 8   ///  r1 = r1.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x100], r1                   
    sth [r10-0xf8], 1                       
    jne r3, 3, lbb_7769                             if r3 != (3 as i32 as i64 as u64) { pc += 131 }
lbb_7638:
    ldxdw r4, [r10-0x258]                   
    and64 r4, 1                                     r4 &= 1   ///  r4 = r4.and(1)
    ldxdw r6, [r10-0x300]                   
    ldxdw r8, [r10-0x308]                   
    ldxdw r9, [r10-0x310]                   
    jeq r4, 0, lbb_7657                             if r4 == (0 as i32 as i64 as u64) { pc += 13 }
    ldxdw r2, [r10-0x288]                   
    jeq r2, 0, lbb_7754                             if r2 == (0 as i32 as i64 as u64) { pc += 108 }
    jeq r8, 0, lbb_7763                             if r8 == (0 as i32 as i64 as u64) { pc += 116 }
    lddw r1, 0x7fffffffffffffff                     r1 load str located at 9223372036854775807
    mov64 r5, 1                                     r5 = 1 as i32 as i64 as u64
    lddw r3, 0x8000000000000000                     r3 load str located at -9223372036854775808
    jne r9, r3, lbb_7669                            if r9 != r3 { pc += 16 }
    jne r8, -1, lbb_7669                            if r8 != (-1 as i32 as i64 as u64) { pc += 15 }
    lddw r1, 0x100025c30 --> b"\x00\x00\x00\x00\xb8Y\x02\x00\x10\x00\x00\x00\x00\x00\x00\x00m\x0f\x00\x0…        r1 load str located at 4295121968
    call function_18897                     
lbb_7657:
    ldxdw r2, [r10-0x288]                   
    jeq r2, 0, lbb_7757                             if r2 == (0 as i32 as i64 as u64) { pc += 98 }
    lddw r1, 0x8000000000000000                     r1 load str located at -9223372036854775808
    jne r9, r1, lbb_7663                            if r9 != r1 { pc += 1 }
    jeq r2, -1, lbb_7760                            if r2 == (-1 as i32 as i64 as u64) { pc += 97 }
lbb_7663:
    lddw r5, 0x7fffffffffffffff                     r5 load str located at 9223372036854775807
    mov64 r1, r9                                    r1 = r9
    lddw r9, 0x7fffffffffffffff                     r9 load str located at 9223372036854775807
    jeq r8, 0, lbb_7766                             if r8 == (0 as i32 as i64 as u64) { pc += 97 }
lbb_7669:
    stxdw [r10-0x47], r5                    
    stxb [r10-0x48], r4                     
    lddw r3, 0x55cbc71a03472c03                     r3 load str located at 6182253828034210819
    stxdw [r10-0x50], r3                    
    call function_19182                     
    stxdw [r10-0x37], r0                    
    mov64 r1, r9                                    r1 = r9
    mov64 r2, r8                                    r2 = r8
    call function_19182                     
    stxdw [r10-0x3f], r0                    
    sth [r10-0x2f], 12803                   
    jge r6, 20, lbb_7709                            if r6 >= (20 as i32 as i64 as u64) { pc += 27 }
    mov64 r1, r10                                   r1 = r10
    add64 r1, -544                                  r1 += -544   ///  r1 = r1.wrapping_add(-544 as i32 as i64 as u64)
    stxdw [r10-0x10], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -80                                   r1 += -80   ///  r1 = r1.wrapping_add(-80 as i32 as i64 as u64)
    stxdw [r10-0x20], r1                    
    stxdw [r10-0x28], r7                    
    stxdw [r10-0x8], r6                     
    stdw [r10-0x18], 35                     
    stdw [r10-0xff8], 0                     
    stdw [r10-0x1000], 8                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -552                                  r1 += -552   ///  r1 = r1.wrapping_add(-552 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -40                                   r2 += -40   ///  r2 = r2.wrapping_add(-40 as i32 as i64 as u64)
    mov64 r3, r10                                   r3 = r10
    add64 r3, -240                                  r3 += -240   ///  r3 = r3.wrapping_add(-240 as i32 as i64 as u64)
    mov64 r5, r10                                   r5 = r10
    mov64 r4, r6                                    r4 = r6
    call function_18367                     
    ldxw r3, [r10-0x224]                    
    ldxw r5, [r10-0x228]                    
lbb_7704:
    ldxdw r1, [r10-0x260]                   
    stxw [r1+0x4], r3                       
    stxw [r1+0x0], r5                       
    exit                                    
lbb_7708:
    ja lbb_7704                                     if true { pc += -5 }
lbb_7709:
    mov64 r1, r6                                    r1 = r6
    mov64 r2, 19                                    r2 = 19 as i32 as i64 as u64
    lddw r3, 0x100025c78 --> b"\x00\x00\x00\x00\xb8Y\x02\x00\x10\x00\x00\x00\x00\x00\x00\x00\x8d\x0f\x00…        r3 load str located at 4295122040
    call function_18737                     
lbb_7714:
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
    lddw r3, 0x100026e48 --> b"\x00\x00\x00\x00\xb8Y\x02\x00\x10\x00\x00\x00\x00\x00\x00\x00S!\x00\x00\x…        r3 load str located at 4295126600
    call function_18489                     
lbb_7719:
    mov64 r1, 2                                     r1 = 2 as i32 as i64 as u64
    mov64 r2, 2                                     r2 = 2 as i32 as i64 as u64
    lddw r3, 0x100026e78 --> b"\x00\x00\x00\x00\xb8Y\x02\x00\x10\x00\x00\x00\x00\x00\x00\x00S!\x00\x008\…        r3 load str located at 4295126648
    call function_18489                     
lbb_7724:
    mov64 r1, 3                                     r1 = 3 as i32 as i64 as u64
    mov64 r2, 3                                     r2 = 3 as i32 as i64 as u64
    lddw r3, 0x100026e90 --> b"\x00\x00\x00\x00\xb8Y\x02\x00\x10\x00\x00\x00\x00\x00\x00\x00S!\x00\x00O\…        r3 load str located at 4295126672
    call function_18489                     
lbb_7729:
    mov64 r1, 4                                     r1 = 4 as i32 as i64 as u64
    mov64 r2, 4                                     r2 = 4 as i32 as i64 as u64
    lddw r3, 0x100026ea8 --> b"\x00\x00\x00\x00\xb8Y\x02\x00\x10\x00\x00\x00\x00\x00\x00\x00T!\x00\x00\x…        r3 load str located at 4295126696
    call function_18489                     
lbb_7734:
    mov64 r1, 5                                     r1 = 5 as i32 as i64 as u64
    mov64 r2, 5                                     r2 = 5 as i32 as i64 as u64
    lddw r3, 0x100026ec0 --> b"\x00\x00\x00\x00\xb8Y\x02\x00\x10\x00\x00\x00\x00\x00\x00\x00T!\x00\x00!\…        r3 load str located at 4295126720
    call function_18489                     
lbb_7739:
    mov64 r1, 6                                     r1 = 6 as i32 as i64 as u64
    mov64 r2, 6                                     r2 = 6 as i32 as i64 as u64
    lddw r3, 0x100026ed8 --> b"\x00\x00\x00\x00\xb8Y\x02\x00\x10\x00\x00\x00\x00\x00\x00\x00T!\x00\x008\…        r3 load str located at 4295126744
    call function_18489                     
lbb_7744:
    mov64 r1, 7                                     r1 = 7 as i32 as i64 as u64
    mov64 r2, 7                                     r2 = 7 as i32 as i64 as u64
    lddw r3, 0x100026ef0 --> b"\x00\x00\x00\x00\xb8Y\x02\x00\x10\x00\x00\x00\x00\x00\x00\x00T!\x00\x00O\…        r3 load str located at 4295126768
    call function_18489                     
lbb_7749:
    mov64 r1, 8                                     r1 = 8 as i32 as i64 as u64
    mov64 r2, 8                                     r2 = 8 as i32 as i64 as u64
    lddw r3, 0x100026f08 --> b"\x00\x00\x00\x00\xb8Y\x02\x00\x10\x00\x00\x00\x00\x00\x00\x00U!\x00\x00\x…        r3 load str located at 4295126792
    call function_18489                     
lbb_7754:
    lddw r1, 0x100025c18 --> b"\x00\x00\x00\x00\xb8Y\x02\x00\x10\x00\x00\x00\x00\x00\x00\x00l\x0f\x00\x0…        r1 load str located at 4295121944
    call function_18908                     
lbb_7757:
    lddw r1, 0x100025c48 --> b"\x00\x00\x00\x00\xb8Y\x02\x00\x10\x00\x00\x00\x00\x00\x00\x00q\x0f\x00\x0…        r1 load str located at 4295121992
    call function_18908                     
lbb_7760:
    lddw r1, 0x100025c48 --> b"\x00\x00\x00\x00\xb8Y\x02\x00\x10\x00\x00\x00\x00\x00\x00\x00q\x0f\x00\x0…        r1 load str located at 4295121992
    call function_18897                     
lbb_7763:
    lddw r1, 0x100025c30 --> b"\x00\x00\x00\x00\xb8Y\x02\x00\x10\x00\x00\x00\x00\x00\x00\x00m\x0f\x00\x0…        r1 load str located at 4295121968
    call function_18908                     
lbb_7766:
    lddw r1, 0x100025c60 --> b"\x00\x00\x00\x00\xb8Y\x02\x00\x10\x00\x00\x00\x00\x00\x00\x00r\x0f\x00\x0…        r1 load str located at 4295122016
    call function_18908                     
lbb_7769:
    mov64 r1, 19                                    r1 = 19 as i32 as i64 as u64
    mov64 r2, 19                                    r2 = 19 as i32 as i64 as u64
    lddw r3, 0x100025c90 --> b"\x00\x00\x00\x00\xb8Y\x02\x00\x10\x00\x00\x00\x00\x00\x00\x00R\x0f\x00\x0…        r3 load str located at 4295122064
    call function_18489                     
    stw [r1+0x0], 26                        
    exit                                    

function_7776:
    ldxdw r3, [r2+0x8]                      
    jeq r3, 1, lbb_8037                             if r3 == (1 as i32 as i64 as u64) { pc += 259 }
    jeq r3, 0, lbb_8042                             if r3 == (0 as i32 as i64 as u64) { pc += 263 }
    jle r3, 2, lbb_8047                             if r3 <= (2 as i32 as i64 as u64) { pc += 267 }
    jeq r3, 3, lbb_8052                             if r3 == (3 as i32 as i64 as u64) { pc += 271 }
    jle r3, 4, lbb_8057                             if r3 <= (4 as i32 as i64 as u64) { pc += 275 }
    jeq r3, 5, lbb_8062                             if r3 == (5 as i32 as i64 as u64) { pc += 279 }
    jle r3, 6, lbb_8067                             if r3 <= (6 as i32 as i64 as u64) { pc += 283 }
    jeq r3, 7, lbb_8072                             if r3 == (7 as i32 as i64 as u64) { pc += 287 }
    ldxdw r3, [r2+0x50]                     
    mov64 r0, 3                                     r0 = 3 as i32 as i64 as u64
    stxdw [r10-0x410], r3                   
    ldxdw r5, [r3+0x0]                      
    ldxdw r3, [r5+0x50]                     
    jlt r3, 32, lbb_8034                            if r3 < (32 as i32 as i64 as u64) { pc += 243 }
    ldxdw r9, [r2+0x0]                      
    mov64 r7, r9                                    r7 = r9
    add64 r7, 24                                    r7 += 24   ///  r7 = r7.wrapping_add(24 as i32 as i64 as u64)
    ldxdw r3, [r7+0x0]                      
    ldxdw r6, [r3+0x50]                     
    jlt r6, 32, lbb_8034                            if r6 < (32 as i32 as i64 as u64) { pc += 237 }
    ldxdw r8, [r2+0x58]                     
    ldxdw r4, [r2+0x48]                     
    ldxdw r0, [r2+0x28]                     
    stxdw [r10-0x420], r0                   
    ldxdw r0, [r2+0x20]                     
    stxdw [r10-0x448], r0                   
    ldxb r0, [r2+0x62]                      
    stxdw [r10-0x460], r0                   
    ldxdw r2, [r2+0x10]                     
    stxdw [r10-0x470], r2                   
    mov64 r2, r9                                    r2 = r9
    add64 r2, 56                                    r2 += 56   ///  r2 = r2.wrapping_add(56 as i32 as i64 as u64)
    stxdw [r10-0x450], r2                   
    mov64 r6, r9                                    r6 = r9
    add64 r6, 8                                     r6 += 8   ///  r6 = r6.wrapping_add(8 as i32 as i64 as u64)
    mov64 r2, r9                                    r2 = r9
    add64 r2, 16                                    r2 += 16   ///  r2 = r2.wrapping_add(16 as i32 as i64 as u64)
    stxdw [r10-0x440], r2                   
    mov64 r2, r9                                    r2 = r9
    add64 r2, 32                                    r2 += 32   ///  r2 = r2.wrapping_add(32 as i32 as i64 as u64)
    stxdw [r10-0x458], r2                   
    mov64 r2, r9                                    r2 = r9
    add64 r2, 40                                    r2 += 40   ///  r2 = r2.wrapping_add(40 as i32 as i64 as u64)
    stxdw [r10-0x468], r2                   
    mov64 r2, r9                                    r2 = r9
    add64 r2, 48                                    r2 += 48   ///  r2 = r2.wrapping_add(48 as i32 as i64 as u64)
    stxdw [r10-0x478], r2                   
    ldxdw r2, [r3+0x58]                     
    ldxdw r0, [r5+0x58]                     
    stxdw [r10-0x428], r1                   
    stxdw [r10-0x430], r7                   
    stxdw [r10-0x438], r6                   
    stxdw [r10-0x418], r4                   
    jne r0, r2, lbb_7843                            if r0 != r2 { pc += 12 }
    ldxdw r2, [r3+0x60]                     
    ldxdw r0, [r5+0x60]                     
    jne r0, r2, lbb_7843                            if r0 != r2 { pc += 9 }
    ldxdw r2, [r3+0x68]                     
    ldxdw r0, [r5+0x68]                     
    jne r0, r2, lbb_7843                            if r0 != r2 { pc += 6 }
    ldxdw r2, [r3+0x70]                     
    ldxdw r5, [r5+0x70]                     
    jne r5, r2, lbb_7843                            if r5 != r2 { pc += 3 }
    ldxdw r1, [r10-0x410]                   
    stxdw [r10-0x410], r8                   
    ja lbb_7844                                     if true { pc += 1 }
lbb_7843:
    mov64 r1, r8                                    r1 = r8
lbb_7844:
    stxdw [r10-0x480], r1                   
    add64 r3, 8                                     r3 += 8   ///  r3 = r3.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x498], r3                   
    ldxdw r2, [r9+0x0]                      
    stxdw [r10-0x4a0], r2                   
    ldxdw r5, [r9+0x8]                      
    stxdw [r10-0x488], r5                   
    ldxdw r5, [r9+0x10]                     
    stxdw [r10-0x490], r5                   
    ldxdw r6, [r9+0x20]                     
    ldxdw r5, [r1+0x0]                      
    ldxdw r1, [r10-0x410]                   
    ldxdw r0, [r1+0x0]                      
    ldxdw r8, [r9+0x28]                     
    ldxdw r4, [r9+0x30]                     
    ldxdw r3, [r9+0x38]                     
    ldxdw r1, [r10-0x418]                   
    ldxdw r7, [r1+0x0]                      
    ldxdw r1, [r10-0x420]                   
    ldxdw r1, [r1+0x0]                      
    ldxdw r2, [r10-0x498]                   
    stxdw [r10-0x3d8], r2                   
    add64 r1, 8                                     r1 += 8   ///  r1 = r1.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x358], r1                   
    add64 r7, 8                                     r7 += 8   ///  r7 = r7.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x368], r7                   
    add64 r3, 8                                     r3 += 8   ///  r3 = r3.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x378], r3                   
    add64 r4, 8                                     r4 += 8   ///  r4 = r4.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x388], r4                   
    add64 r8, 8                                     r8 += 8   ///  r8 = r8.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x398], r8                   
    add64 r0, 8                                     r0 += 8   ///  r0 = r0.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x3a8], r0                   
    add64 r5, 8                                     r5 += 8   ///  r5 = r5.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x3b8], r5                   
    add64 r6, 8                                     r6 += 8   ///  r6 = r6.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x3c8], r6                   
    ldxdw r1, [r10-0x490]                   
    add64 r1, 8                                     r1 += 8   ///  r1 = r1.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x3e8], r1                   
    ldxdw r1, [r10-0x488]                   
    add64 r1, 8                                     r1 += 8   ///  r1 = r1.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x3f8], r1                   
    ldxdw r1, [r10-0x4a0]                   
    add64 r1, 8                                     r1 += 8   ///  r1 = r1.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x408], r1                   
    sth [r10-0x350], 0                      
    sth [r10-0x360], 256                    
    sth [r10-0x370], 0                      
    sth [r10-0x380], 0                      
    sth [r10-0x390], 1                      
    sth [r10-0x3a0], 1                      
    sth [r10-0x3b0], 1                      
    sth [r10-0x3c0], 1                      
    sth [r10-0x3d0], 1                      
    sth [r10-0x3e0], 0                      
    sth [r10-0x3f0], 0                      
    sth [r10-0x400], 1                      
    ldxdw r1, [r10-0x470]                   
    stxdw [r10-0x33f], r1                   
    ldxdw r1, [r10-0x460]                   
    stxb [r10-0x340], r1                    
    lddw r1, 0x885b5beb4c3f4b41                     r1 load str located at -8621195995516023999
    stxdw [r10-0x348], r1                   
    stdw [r10-0x337], 0                     
    ldxdw r1, [r10-0x448]                   
    ldxdw r2, [r1+0x0]                      
    ldxdw r1, [r10-0x420]                   
    stxdw [r10-0x2d0], r1                   
    ldxdw r1, [r10-0x418]                   
    stxdw [r10-0x2d8], r1                   
    ldxdw r1, [r10-0x450]                   
    stxdw [r10-0x2e0], r1                   
    ldxdw r1, [r10-0x478]                   
    stxdw [r10-0x2e8], r1                   
    ldxdw r1, [r10-0x468]                   
    stxdw [r10-0x2f0], r1                   
    ldxdw r1, [r10-0x410]                   
    stxdw [r10-0x2f8], r1                   
    ldxdw r1, [r10-0x480]                   
    stxdw [r10-0x300], r1                   
    ldxdw r1, [r10-0x458]                   
    stxdw [r10-0x308], r1                   
    ldxdw r1, [r10-0x430]                   
    stxdw [r10-0x310], r1                   
    ldxdw r1, [r10-0x440]                   
    stxdw [r10-0x318], r1                   
    ldxdw r1, [r10-0x438]                   
    stxdw [r10-0x320], r1                   
    stxdw [r10-0x328], r9                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -808                                  r1 += -808   ///  r1 = r1.wrapping_add(-808 as i32 as i64 as u64)
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
    mov64 r4, r10                                   r4 = r10
    add64 r4, -1024                                 r4 += -1024   ///  r4 = r4.wrapping_add(-1024 as i32 as i64 as u64)
    add64 r2, 8                                     r2 += 8   ///  r2 = r2.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x410], r2                   
    ja lbb_7964                                     if true { pc += 20 }
lbb_7944:
    mov64 r7, r10                                   r7 = r10
    add64 r7, -712                                  r7 += -712   ///  r7 = r7.wrapping_add(-712 as i32 as i64 as u64)
    add64 r7, r3                                    r7 += r3   ///  r7 = r7.wrapping_add(r3)
    stxb [r7+0x32], r6                      
    stxb [r7+0x31], r8                      
    stxb [r7+0x30], r2                      
    mov64 r2, r5                                    r2 = r5
    add64 r2, 40                                    r2 += 40   ///  r2 = r2.wrapping_add(40 as i32 as i64 as u64)
    stxdw [r7+0x20], r2                     
    mov64 r2, r5                                    r2 = r5
    add64 r2, 88                                    r2 += 88   ///  r2 = r2.wrapping_add(88 as i32 as i64 as u64)
    stxdw [r7+0x18], r2                     
    stxdw [r7+0x10], r0                     
    add64 r5, 72                                    r5 += 72   ///  r5 = r5.wrapping_add(72 as i32 as i64 as u64)
    stxdw [r7+0x8], r5                      
    stdw [r7+0x28], 0                       
    add64 r4, 16                                    r4 += 16   ///  r4 = r4.wrapping_add(16 as i32 as i64 as u64)
    add64 r1, 8                                     r1 += 8   ///  r1 = r1.wrapping_add(8 as i32 as i64 as u64)
    add64 r3, 56                                    r3 += 56   ///  r3 = r3.wrapping_add(56 as i32 as i64 as u64)
    jeq r3, 672, lbb_8014                           if r3 == (672 as i32 as i64 as u64) { pc += 50 }
lbb_7964:
    mov64 r2, r10                                   r2 = r10
    add64 r2, -712                                  r2 += -712   ///  r2 = r2.wrapping_add(-712 as i32 as i64 as u64)
    mov64 r0, 1                                     r0 = 1 as i32 as i64 as u64
    ldxdw r5, [r1+0x0]                      
    ldxdw r5, [r5+0x0]                      
    ldxdw r6, [r4-0x8]                      
    ldxdw r7, [r6+0x0]                      
    ldxdw r8, [r5+0x8]                      
    jne r8, r7, lbb_8033                            if r8 != r7 { pc += 60 }
    ldxdw r7, [r6+0x8]                      
    ldxdw r8, [r5+0x10]                     
    jne r8, r7, lbb_8033                            if r8 != r7 { pc += 57 }
    ldxdw r7, [r6+0x10]                     
    ldxdw r8, [r5+0x18]                     
    jne r8, r7, lbb_8033                            if r8 != r7 { pc += 54 }
    ldxdw r6, [r6+0x18]                     
    ldxdw r7, [r5+0x20]                     
    jne r7, r6, lbb_8033                            if r7 != r6 { pc += 51 }
    ldxb r6, [r4+0x0]                       
    mov64 r0, 0                                     r0 = 0 as i32 as i64 as u64
    jne r6, 0, lbb_7986                             if r6 != (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r0, 119                                   r0 = 119 as i32 as i64 as u64
lbb_7986:
    ldxb r6, [r5+0x0]                       
    or64 r0, r6                                     r0 |= r6   ///  r0 = r0.or(r6)
    and64 r0, 255                                   r0 &= 255   ///  r0 = r0.and(255)
    jne r0, 255, lbb_8012                           if r0 != (255 as i32 as i64 as u64) { pc += 22 }
    add64 r2, r3                                    r2 += r3   ///  r2 = r2.wrapping_add(r3)
    mov64 r6, r5                                    r6 = r5
    add64 r6, 8                                     r6 += 8   ///  r6 = r6.wrapping_add(8 as i32 as i64 as u64)
    ldxdw r0, [r5+0x50]                     
    ldxb r7, [r5+0x3]                       
    ldxb r9, [r5+0x2]                       
    ldxb r8, [r5+0x1]                       
    stxdw [r2+0x0], r6                      
    mov64 r6, 1                                     r6 = 1 as i32 as i64 as u64
    mov64 r2, 1                                     r2 = 1 as i32 as i64 as u64
    jeq r8, 0, lbb_8005                             if r8 == (0 as i32 as i64 as u64) { pc += 4 }
    mov64 r8, 1                                     r8 = 1 as i32 as i64 as u64
    jeq r9, 0, lbb_8008                             if r9 == (0 as i32 as i64 as u64) { pc += 5 }
lbb_8003:
    jne r7, 0, lbb_7944                             if r7 != (0 as i32 as i64 as u64) { pc += -60 }
    ja lbb_8010                                     if true { pc += 5 }
lbb_8005:
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
    mov64 r8, 1                                     r8 = 1 as i32 as i64 as u64
    jne r9, 0, lbb_8003                             if r9 != (0 as i32 as i64 as u64) { pc += -5 }
lbb_8008:
    mov64 r8, 0                                     r8 = 0 as i32 as i64 as u64
    jne r7, 0, lbb_7944                             if r7 != (0 as i32 as i64 as u64) { pc += -66 }
lbb_8010:
    mov64 r6, 0                                     r6 = 0 as i32 as i64 as u64
    ja lbb_7944                                     if true { pc += -68 }
lbb_8012:
    mov64 r0, 11                                    r0 = 11 as i32 as i64 as u64
    ja lbb_8033                                     if true { pc += 19 }
lbb_8014:
    mov64 r1, r10                                   r1 = r10
    add64 r1, -840                                  r1 += -840   ///  r1 = r1.wrapping_add(-840 as i32 as i64 as u64)
    stxdw [r10-0x10], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -1032                                 r1 += -1032   ///  r1 = r1.wrapping_add(-1032 as i32 as i64 as u64)
    stxdw [r10-0x20], r1                    
    ldxdw r1, [r10-0x410]                   
    stxdw [r10-0x28], r1                    
    stdw [r10-0x8], 25                      
    stdw [r10-0x18], 12                     
    mov64 r1, r10                                   r1 = r10
    add64 r1, -40                                   r1 += -40   ///  r1 = r1.wrapping_add(-40 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -712                                  r2 += -712   ///  r2 = r2.wrapping_add(-712 as i32 as i64 as u64)
    mov64 r3, 12                                    r3 = 12 as i32 as i64 as u64
    mov64 r4, 8                                     r4 = 8 as i32 as i64 as u64
    mov64 r5, 0                                     r5 = 0 as i32 as i64 as u64
    syscall [invalid]                       
    mov64 r0, 26                                    r0 = 26 as i32 as i64 as u64
lbb_8033:
    ldxdw r1, [r10-0x428]                   
lbb_8034:
    stxw [r1+0x0], r0                       
    stw [r1+0x4], 0                         
    exit                                    
lbb_8037:
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    mov64 r2, 1                                     r2 = 1 as i32 as i64 as u64
    lddw r3, 0x100026f38 --> b"\x00\x00\x00\x00\xb8Y\x02\x00\x10\x00\x00\x00\x00\x00\x00\x00i!\x00\x00!\…        r3 load str located at 4295126840
    call function_18489                     
lbb_8042:
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
    lddw r3, 0x100026f20 --> b"\x00\x00\x00\x00\xb8Y\x02\x00\x10\x00\x00\x00\x00\x00\x00\x00i!\x00\x00\x…        r3 load str located at 4295126816
    call function_18489                     
lbb_8047:
    mov64 r1, 2                                     r1 = 2 as i32 as i64 as u64
    mov64 r2, 2                                     r2 = 2 as i32 as i64 as u64
    lddw r3, 0x100026f50 --> b"\x00\x00\x00\x00\xb8Y\x02\x00\x10\x00\x00\x00\x00\x00\x00\x00i!\x00\x008\…        r3 load str located at 4295126864
    call function_18489                     
lbb_8052:
    mov64 r1, 3                                     r1 = 3 as i32 as i64 as u64
    mov64 r2, 3                                     r2 = 3 as i32 as i64 as u64
    lddw r3, 0x100026f68 --> b"\x00\x00\x00\x00\xb8Y\x02\x00\x10\x00\x00\x00\x00\x00\x00\x00i!\x00\x00O\…        r3 load str located at 4295126888
    call function_18489                     
lbb_8057:
    mov64 r1, 4                                     r1 = 4 as i32 as i64 as u64
    mov64 r2, 4                                     r2 = 4 as i32 as i64 as u64
    lddw r3, 0x100026f80 --> b"\x00\x00\x00\x00\xb8Y\x02\x00\x10\x00\x00\x00\x00\x00\x00\x00j!\x00\x00\x…        r3 load str located at 4295126912
    call function_18489                     
lbb_8062:
    mov64 r1, 5                                     r1 = 5 as i32 as i64 as u64
    mov64 r2, 5                                     r2 = 5 as i32 as i64 as u64
    lddw r3, 0x100026f98 --> b"\x00\x00\x00\x00\xb8Y\x02\x00\x10\x00\x00\x00\x00\x00\x00\x00j!\x00\x00!\…        r3 load str located at 4295126936
    call function_18489                     
lbb_8067:
    mov64 r1, 6                                     r1 = 6 as i32 as i64 as u64
    mov64 r2, 6                                     r2 = 6 as i32 as i64 as u64
    lddw r3, 0x100026fb0 --> b"\x00\x00\x00\x00\xb8Y\x02\x00\x10\x00\x00\x00\x00\x00\x00\x00j!\x00\x008\…        r3 load str located at 4295126960
    call function_18489                     
lbb_8072:
    mov64 r1, 7                                     r1 = 7 as i32 as i64 as u64
    mov64 r2, 7                                     r2 = 7 as i32 as i64 as u64
    lddw r3, 0x100026fc8 --> b"\x00\x00\x00\x00\xb8Y\x02\x00\x10\x00\x00\x00\x00\x00\x00\x00j!\x00\x00O\…        r3 load str located at 4295126984
    call function_18489                     
    mov64 r3, r1                                    r3 = r1
    ldxdw r1, [r2+0x58]                     
    stxdw [r10-0x7d8], r1                   
    ldxdw r4, [r2+0x50]                     
    ldxdw r7, [r2+0x48]                     
    ldxdw r8, [r2+0x28]                     
    ldxdw r9, [r2+0x20]                     
    ldxdw r6, [r2+0x0]                      
    ldxdw r1, [r2+0x8]                      
    stxdw [r10-0x7e8], r3                   
    stxdw [r10-0x7f0], r7                   
    stxdw [r10-0x7f8], r8                   
    stxdw [r10-0x800], r9                   
    stxdw [r10-0x7d0], r4                   
    jle r1, 18, lbb_8126                            if r1 <= (18 as i32 as i64 as u64) { pc += 34 }
    mov64 r0, 0                                     r0 = 0 as i32 as i64 as u64
    mov64 r5, 3                                     r5 = 3 as i32 as i64 as u64
    ldxdw r1, [r4+0x0]                      
    ldxdw r4, [r1+0x50]                     
    jlt r4, 32, lbb_8921                            if r4 < (32 as i32 as i64 as u64) { pc += 824 }
    mov64 r3, r9                                    r3 = r9
    mov64 r9, r7                                    r9 = r7
    mov64 r7, r8                                    r7 = r8
    mov64 r4, r6                                    r4 = r6
    add64 r4, 48                                    r4 += 48   ///  r4 = r4.wrapping_add(48 as i32 as i64 as u64)
    stxdw [r10-0x880], r4                   
    ldxdw r8, [r4+0x0]                      
    ldxdw r4, [r8+0x50]                     
    jlt r4, 32, lbb_8921                            if r4 < (32 as i32 as i64 as u64) { pc += 815 }
    ldxdw r4, [r8+0x58]                     
    ldxdw r5, [r1+0x58]                     
    stxdw [r10-0x7e0], r8                   
    jne r5, r4, lbb_8199                            if r5 != r4 { pc += 89 }
    ldxdw r4, [r8+0x60]                     
    ldxdw r5, [r1+0x60]                     
    jne r5, r4, lbb_8199                            if r5 != r4 { pc += 86 }
    ldxdw r4, [r8+0x68]                     
    ldxdw r5, [r1+0x68]                     
    mov64 r8, r7                                    r8 = r7
    mov64 r7, r9                                    r7 = r9
    mov64 r9, r3                                    r9 = r3
    jne r5, r4, lbb_8202                            if r5 != r4 { pc += 83 }
    ldxdw r4, [r10-0x7e0]                   
    ldxdw r4, [r4+0x70]                     
    ldxdw r1, [r1+0x70]                     
    mov64 r0, 1                                     r0 = 1 as i32 as i64 as u64
    jeq r1, r4, lbb_8202                            if r1 == r4 { pc += 78 }
    mov64 r0, 0                                     r0 = 0 as i32 as i64 as u64
    ja lbb_8202                                     if true { pc += 76 }
lbb_8126:
    jeq r1, 0, lbb_8925                             if r1 == (0 as i32 as i64 as u64) { pc += 798 }
    jeq r1, 1, lbb_8930                             if r1 == (1 as i32 as i64 as u64) { pc += 802 }
    jle r1, 2, lbb_8935                             if r1 <= (2 as i32 as i64 as u64) { pc += 806 }
    jeq r1, 3, lbb_8940                             if r1 == (3 as i32 as i64 as u64) { pc += 810 }
    jle r1, 4, lbb_8945                             if r1 <= (4 as i32 as i64 as u64) { pc += 814 }
    jeq r1, 5, lbb_8950                             if r1 == (5 as i32 as i64 as u64) { pc += 818 }
    jle r1, 6, lbb_8955                             if r1 <= (6 as i32 as i64 as u64) { pc += 822 }
    jeq r1, 7, lbb_8960                             if r1 == (7 as i32 as i64 as u64) { pc += 826 }
    jle r1, 8, lbb_8965                             if r1 <= (8 as i32 as i64 as u64) { pc += 830 }
    jeq r1, 9, lbb_8970                             if r1 == (9 as i32 as i64 as u64) { pc += 834 }
    jle r1, 10, lbb_8975                            if r1 <= (10 as i32 as i64 as u64) { pc += 838 }
    jeq r1, 11, lbb_8980                            if r1 == (11 as i32 as i64 as u64) { pc += 842 }
    mov64 r0, 0                                     r0 = 0 as i32 as i64 as u64
    mov64 r5, 3                                     r5 = 3 as i32 as i64 as u64
    ldxdw r4, [r4+0x0]                      
    ldxdw r1, [r4+0x50]                     
    jlt r1, 32, lbb_8921                            if r1 < (32 as i32 as i64 as u64) { pc += 778 }
    mov64 r1, r6                                    r1 = r6
    add64 r1, 48                                    r1 += 48   ///  r1 = r1.wrapping_add(48 as i32 as i64 as u64)
    stxdw [r10-0x7e0], r1                   
    ldxdw r3, [r1+0x0]                      
    ldxdw r1, [r3+0x50]                     
    jlt r1, 32, lbb_8921                            if r1 < (32 as i32 as i64 as u64) { pc += 772 }
    mov64 r1, r6                                    r1 = r6
    add64 r1, 8                                     r1 += 8   ///  r1 = r1.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x808], r1                   
    mov64 r1, r6                                    r1 = r6
    add64 r1, 16                                    r1 += 16   ///  r1 = r1.wrapping_add(16 as i32 as i64 as u64)
    stxdw [r10-0x810], r1                   
    mov64 r1, r6                                    r1 = r6
    add64 r1, 24                                    r1 += 24   ///  r1 = r1.wrapping_add(24 as i32 as i64 as u64)
    stxdw [r10-0x818], r1                   
    mov64 r1, r6                                    r1 = r6
    add64 r1, 32                                    r1 += 32   ///  r1 = r1.wrapping_add(32 as i32 as i64 as u64)
    stxdw [r10-0x820], r1                   
    mov64 r1, r6                                    r1 = r6
    add64 r1, 40                                    r1 += 40   ///  r1 = r1.wrapping_add(40 as i32 as i64 as u64)
    stxdw [r10-0x828], r1                   
    mov64 r1, r6                                    r1 = r6
    add64 r1, 56                                    r1 += 56   ///  r1 = r1.wrapping_add(56 as i32 as i64 as u64)
    stxdw [r10-0x830], r1                   
    mov64 r1, r6                                    r1 = r6
    add64 r1, 64                                    r1 += 64   ///  r1 = r1.wrapping_add(64 as i32 as i64 as u64)
    stxdw [r10-0x838], r1                   
    mov64 r1, r6                                    r1 = r6
    add64 r1, 72                                    r1 += 72   ///  r1 = r1.wrapping_add(72 as i32 as i64 as u64)
    stxdw [r10-0x840], r1                   
    ldxdw r1, [r2+0x10]                     
    stxdw [r10-0x858], r1                   
    mov64 r1, r6                                    r1 = r6
    add64 r1, 88                                    r1 += 88   ///  r1 = r1.wrapping_add(88 as i32 as i64 as u64)
    stxdw [r10-0x850], r1                   
    mov64 r1, r6                                    r1 = r6
    add64 r1, 80                                    r1 += 80   ///  r1 = r1.wrapping_add(80 as i32 as i64 as u64)
    stxdw [r10-0x848], r1                   
    ldxdw r1, [r3+0x58]                     
    ldxdw r2, [r4+0x58]                     
    mov64 r0, r3                                    r0 = r3
    jne r2, r1, lbb_8668                            if r2 != r1 { pc += 483 }
    ldxdw r1, [r0+0x60]                     
    ldxdw r2, [r4+0x60]                     
    mov64 r5, r8                                    r5 = r8
    jne r2, r1, lbb_8695                            if r2 != r1 { pc += 506 }
    ldxdw r1, [r0+0x68]                     
    ldxdw r2, [r4+0x68]                     
    jne r2, r1, lbb_8695                            if r2 != r1 { pc += 503 }
    ldxdw r1, [r0+0x70]                     
    ldxdw r2, [r4+0x70]                     
    jne r2, r1, lbb_8695                            if r2 != r1 { pc += 500 }
    mov64 r1, r5                                    r1 = r5
    ldxdw r2, [r10-0x7d0]                   
    ldxdw r3, [r10-0x7d8]                   
    ja lbb_8698                                     if true { pc += 499 }
lbb_8199:
    mov64 r8, r7                                    r8 = r7
    mov64 r7, r9                                    r7 = r9
    mov64 r9, r3                                    r9 = r3
lbb_8202:
    mov64 r1, r0                                    r1 = r0
    and64 r1, 1                                     r1 &= 1   ///  r1 = r1.and(1)
    ldxdw r3, [r10-0x7d0]                   
    stxdw [r10-0x850], r3                   
    jne r1, 0, lbb_8210                             if r1 != (0 as i32 as i64 as u64) { pc += 3 }
    ldxdw r4, [r10-0x7d8]                   
    stxdw [r10-0x850], r4                   
    ldxdw r3, [r10-0x7d0]                   
lbb_8210:
    stxdw [r10-0x888], r0                   
    jne r1, 0, lbb_8213                             if r1 != (0 as i32 as i64 as u64) { pc += 1 }
    stxdw [r10-0x7d8], r3                   
lbb_8213:
    ldxdw r3, [r6+0x48]                     
    ldxdw r1, [r6+0x18]                     
    ldxdw r4, [r1+0x8]                      
    add64 r1, 8                                     r1 += 8   ///  r1 = r1.wrapping_add(8 as i32 as i64 as u64)
    ldxdw r5, [r3+0x8]                      
    add64 r3, 8                                     r3 += 8   ///  r3 = r3.wrapping_add(8 as i32 as i64 as u64)
    jne r5, r4, lbb_8230                            if r5 != r4 { pc += 10 }
    ldxdw r4, [r1+0x8]                      
    ldxdw r5, [r3+0x8]                      
    jne r5, r4, lbb_8230                            if r5 != r4 { pc += 7 }
    ldxdw r4, [r1+0x10]                     
    ldxdw r5, [r3+0x10]                     
    jne r5, r4, lbb_8230                            if r5 != r4 { pc += 4 }
    mov64 r4, 0                                     r4 = 0 as i32 as i64 as u64
    ldxdw r5, [r1+0x18]                     
    ldxdw r0, [r3+0x18]                     
    jeq r0, r5, lbb_8231                            if r0 == r5 { pc += 1 }
lbb_8230:
    mov64 r4, 1                                     r4 = 1 as i32 as i64 as u64
lbb_8231:
    stxdw [r10-0x898], r3                   
    mov64 r3, r6                                    r3 = r6
    add64 r3, 80                                    r3 += 80   ///  r3 = r3.wrapping_add(80 as i32 as i64 as u64)
    mov64 r5, 1                                     r5 = 1 as i32 as i64 as u64
    jeq r4, 0, lbb_8237                             if r4 == (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r5, 0                                     r5 = 0 as i32 as i64 as u64
lbb_8237:
    stxdw [r10-0x8a8], r5                   
    ldxdw r0, [r3+0x0]                      
    ldxdw r4, [r1+0x0]                      
    ldxdw r5, [r0+0x8]                      
    add64 r0, 8                                     r0 += 8   ///  r0 = r0.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x858], r0                   
    jne r5, r4, lbb_8257                            if r5 != r4 { pc += 13 }
    ldxdw r4, [r1+0x8]                      
    ldxdw r5, [r10-0x858]                   
    ldxdw r5, [r5+0x8]                      
    jne r5, r4, lbb_8257                            if r5 != r4 { pc += 9 }
    ldxdw r4, [r1+0x10]                     
    ldxdw r5, [r10-0x858]                   
    ldxdw r5, [r5+0x10]                     
    jne r5, r4, lbb_8257                            if r5 != r4 { pc += 5 }
    mov64 r4, 0                                     r4 = 0 as i32 as i64 as u64
    ldxdw r5, [r1+0x18]                     
    ldxdw r0, [r10-0x858]                   
    ldxdw r0, [r0+0x18]                     
    jeq r0, r5, lbb_8258                            if r0 == r5 { pc += 1 }
lbb_8257:
    mov64 r4, 1                                     r4 = 1 as i32 as i64 as u64
lbb_8258:
    mov64 r5, r6                                    r5 = r6
    add64 r5, 88                                    r5 += 88   ///  r5 = r5.wrapping_add(88 as i32 as i64 as u64)
    mov64 r0, 1                                     r0 = 1 as i32 as i64 as u64
    jeq r4, 0, lbb_8263                             if r4 == (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r0, 0                                     r0 = 0 as i32 as i64 as u64
lbb_8263:
    stxdw [r10-0x8b8], r0                   
    stxdw [r10-0x8a0], r5                   
    ldxdw r0, [r5+0x0]                      
    ldxdw r4, [r1+0x0]                      
    ldxdw r5, [r0+0x8]                      
    add64 r0, 8                                     r0 += 8   ///  r0 = r0.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x860], r0                   
    jne r5, r4, lbb_8284                            if r5 != r4 { pc += 13 }
    ldxdw r4, [r1+0x8]                      
    ldxdw r5, [r10-0x860]                   
    ldxdw r5, [r5+0x8]                      
    jne r5, r4, lbb_8284                            if r5 != r4 { pc += 9 }
    ldxdw r4, [r1+0x10]                     
    ldxdw r5, [r10-0x860]                   
    ldxdw r5, [r5+0x10]                     
    jne r5, r4, lbb_8284                            if r5 != r4 { pc += 5 }
    mov64 r4, 0                                     r4 = 0 as i32 as i64 as u64
    ldxdw r5, [r1+0x18]                     
    ldxdw r0, [r10-0x860]                   
    ldxdw r0, [r0+0x18]                     
    jeq r0, r5, lbb_8285                            if r0 == r5 { pc += 1 }
lbb_8284:
    mov64 r4, 1                                     r4 = 1 as i32 as i64 as u64
lbb_8285:
    mov64 r5, r6                                    r5 = r6
    add64 r5, 96                                    r5 += 96   ///  r5 = r5.wrapping_add(96 as i32 as i64 as u64)
    mov64 r0, 1                                     r0 = 1 as i32 as i64 as u64
    jeq r4, 0, lbb_8290                             if r4 == (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r0, 0                                     r0 = 0 as i32 as i64 as u64
lbb_8290:
    stxdw [r10-0x8c8], r0                   
    stxdw [r10-0x8b0], r5                   
    ldxdw r0, [r5+0x0]                      
    ldxdw r4, [r1+0x0]                      
    ldxdw r5, [r0+0x8]                      
    add64 r0, 8                                     r0 += 8   ///  r0 = r0.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x868], r0                   
    jne r5, r4, lbb_8311                            if r5 != r4 { pc += 13 }
    ldxdw r4, [r1+0x8]                      
    ldxdw r5, [r10-0x868]                   
    ldxdw r5, [r5+0x8]                      
    jne r5, r4, lbb_8311                            if r5 != r4 { pc += 9 }
    ldxdw r4, [r1+0x10]                     
    ldxdw r5, [r10-0x868]                   
    ldxdw r5, [r5+0x10]                     
    jne r5, r4, lbb_8311                            if r5 != r4 { pc += 5 }
    mov64 r4, 0                                     r4 = 0 as i32 as i64 as u64
    ldxdw r5, [r1+0x18]                     
    ldxdw r0, [r10-0x868]                   
    ldxdw r0, [r0+0x18]                     
    jeq r0, r5, lbb_8312                            if r0 == r5 { pc += 1 }
lbb_8311:
    mov64 r4, 1                                     r4 = 1 as i32 as i64 as u64
lbb_8312:
    stxdw [r10-0x890], r3                   
    mov64 r3, r6                                    r3 = r6
    add64 r3, 104                                   r3 += 104   ///  r3 = r3.wrapping_add(104 as i32 as i64 as u64)
    mov64 r5, 1                                     r5 = 1 as i32 as i64 as u64
    jeq r4, 0, lbb_8318                             if r4 == (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r5, 0                                     r5 = 0 as i32 as i64 as u64
lbb_8318:
    stxdw [r10-0x8d8], r5                   
    ldxb r5, [r2+0x62]                      
    stxdw [r10-0x8c0], r3                   
    ldxdw r3, [r3+0x0]                      
    ldxdw r4, [r1+0x0]                      
    ldxdw r0, [r3+0x8]                      
    add64 r3, 8                                     r3 += 8   ///  r3 = r3.wrapping_add(8 as i32 as i64 as u64)
    jne r0, r4, lbb_8337                            if r0 != r4 { pc += 11 }
    ldxdw r4, [r1+0x8]                      
    ldxdw r0, [r3+0x8]                      
    jne r0, r4, lbb_8337                            if r0 != r4 { pc += 8 }
    ldxdw r4, [r1+0x10]                     
    ldxdw r0, [r3+0x10]                     
    jne r0, r4, lbb_8337                            if r0 != r4 { pc += 5 }
    mov64 r4, 0                                     r4 = 0 as i32 as i64 as u64
    stxdw [r10-0x878], r4                   
    ldxdw r4, [r1+0x18]                     
    ldxdw r0, [r3+0x18]                     
    jeq r0, r4, lbb_8339                            if r0 == r4 { pc += 2 }
lbb_8337:
    mov64 r4, 1                                     r4 = 1 as i32 as i64 as u64
    stxdw [r10-0x878], r4                   
lbb_8339:
    and64 r5, 1                                     r5 &= 1   ///  r5 = r5.and(1)
    lddw r4, 0x92e365f17f52d7e6                     r4 load str located at -7862328436561094682
    jne r5, 0, lbb_8345                             if r5 != (0 as i32 as i64 as u64) { pc += 2 }
    lddw r4, 0x7374db461c4ea2e4                     r4 load str located at 8319515505829257956
lbb_8345:
    stxdw [r10-0x8d0], r4                   
    ldxdw r0, [r9+0x0]                      
    ldxdw r4, [r6+0x40]                     
    stxdw [r10-0x848], r4                   
    ldxdw r4, [r8+0x0]                      
    stxdw [r10-0x840], r4                   
    ldxdw r4, [r6+0x38]                     
    stxdw [r10-0x838], r4                   
    ldxdw r4, [r6+0x28]                     
    stxdw [r10-0x830], r4                   
    ldxdw r4, [r6+0x20]                     
    stxdw [r10-0x828], r4                   
    ldxdw r4, [r6+0x10]                     
    stxdw [r10-0x810], r4                   
    ldxdw r4, [r6+0x8]                      
    stxdw [r10-0x808], r4                   
    ldxdw r4, [r6+0x0]                      
    stxdw [r10-0x7d0], r4                   
    ldxdw r9, [r7+0x0]                      
    ldxdw r4, [r10-0x7d8]                   
    ldxdw r4, [r4+0x0]                      
    stxdw [r10-0x820], r4                   
    ldxdw r4, [r10-0x850]                   
    ldxdw r4, [r4+0x0]                      
    stxdw [r10-0x818], r4                   
    mov64 r4, 24                                    r4 = 24 as i32 as i64 as u64
    stxdw [r10-0x958], r4                   
    ldxdw r4, [r10-0x7e0]                   
    jne r5, 0, lbb_8376                             if r5 != (0 as i32 as i64 as u64) { pc += 2 }
    mov64 r5, 25                                    r5 = 25 as i32 as i64 as u64
    stxdw [r10-0x958], r5                   
lbb_8376:
    ldxdw r2, [r2+0x10]                     
    stxdw [r10-0x930], r2                   
    mov64 r2, r6                                    r2 = r6
    add64 r2, 144                                   r2 += 144   ///  r2 = r2.wrapping_add(144 as i32 as i64 as u64)
    stxdw [r10-0x8e0], r2                   
    mov64 r2, r6                                    r2 = r6
    add64 r2, 136                                   r2 += 136   ///  r2 = r2.wrapping_add(136 as i32 as i64 as u64)
    stxdw [r10-0x908], r2                   
    mov64 r2, r6                                    r2 = r6
    add64 r2, 128                                   r2 += 128   ///  r2 = r2.wrapping_add(128 as i32 as i64 as u64)
    stxdw [r10-0x918], r2                   
    mov64 r2, r6                                    r2 = r6
    add64 r2, 120                                   r2 += 120   ///  r2 = r2.wrapping_add(120 as i32 as i64 as u64)
    stxdw [r10-0x928], r2                   
    mov64 r2, r6                                    r2 = r6
    add64 r2, 112                                   r2 += 112   ///  r2 = r2.wrapping_add(112 as i32 as i64 as u64)
    stxdw [r10-0x940], r2                   
    mov64 r2, r6                                    r2 = r6
    add64 r2, 72                                    r2 += 72   ///  r2 = r2.wrapping_add(72 as i32 as i64 as u64)
    stxdw [r10-0x900], r2                   
    mov64 r2, r6                                    r2 = r6
    add64 r2, 64                                    r2 += 64   ///  r2 = r2.wrapping_add(64 as i32 as i64 as u64)
    stxdw [r10-0x8f8], r2                   
    mov64 r2, r6                                    r2 = r6
    add64 r2, 56                                    r2 += 56   ///  r2 = r2.wrapping_add(56 as i32 as i64 as u64)
    stxdw [r10-0x8f0], r2                   
    mov64 r2, r6                                    r2 = r6
    add64 r2, 40                                    r2 += 40   ///  r2 = r2.wrapping_add(40 as i32 as i64 as u64)
    stxdw [r10-0x8e8], r2                   
    mov64 r2, r6                                    r2 = r6
    add64 r2, 32                                    r2 += 32   ///  r2 = r2.wrapping_add(32 as i32 as i64 as u64)
    stxdw [r10-0x910], r2                   
    mov64 r2, r6                                    r2 = r6
    add64 r2, 24                                    r2 += 24   ///  r2 = r2.wrapping_add(24 as i32 as i64 as u64)
    stxdw [r10-0x920], r2                   
    mov64 r2, r6                                    r2 = r6
    add64 r2, 16                                    r2 += 16   ///  r2 = r2.wrapping_add(16 as i32 as i64 as u64)
    stxdw [r10-0x938], r2                   
    mov64 r2, r6                                    r2 = r6
    add64 r2, 8                                     r2 += 8   ///  r2 = r2.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x948], r2                   
    add64 r4, 8                                     r4 += 8   ///  r4 = r4.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x7e0], r4                   
    add64 r0, 8                                     r0 += 8   ///  r0 = r0.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x870], r0                   
    ldxdw r2, [r10-0x848]                   
    add64 r2, 8                                     r2 += 8   ///  r2 = r2.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x848], r2                   
    ldxdw r2, [r10-0x840]                   
    add64 r2, 8                                     r2 += 8   ///  r2 = r2.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x840], r2                   
    ldxdw r2, [r10-0x838]                   
    add64 r2, 8                                     r2 += 8   ///  r2 = r2.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x838], r2                   
    ldxdw r2, [r10-0x830]                   
    add64 r2, 8                                     r2 += 8   ///  r2 = r2.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x830], r2                   
    ldxdw r2, [r10-0x828]                   
    add64 r2, 8                                     r2 += 8   ///  r2 = r2.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x828], r2                   
    ldxdw r2, [r10-0x810]                   
    add64 r2, 8                                     r2 += 8   ///  r2 = r2.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x810], r2                   
    ldxdw r2, [r10-0x808]                   
    add64 r2, 8                                     r2 += 8   ///  r2 = r2.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x808], r2                   
    ldxdw r2, [r10-0x7d0]                   
    add64 r2, 8                                     r2 += 8   ///  r2 = r2.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x7d0], r2                   
    add64 r9, 8                                     r9 += 8   ///  r9 = r9.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x950], r9                   
    ldxdw r2, [r10-0x820]                   
    add64 r2, 8                                     r2 += 8   ///  r2 = r2.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x820], r2                   
    ldxdw r2, [r10-0x818]                   
    add64 r2, 8                                     r2 += 8   ///  r2 = r2.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x818], r2                   
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
    mov64 r9, 1                                     r9 = 1 as i32 as i64 as u64
    ldxdw r4, [r10-0x878]                   
    jeq r4, 0, lbb_8458                             if r4 == (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r9, 0                                     r9 = 0 as i32 as i64 as u64
lbb_8458:
    ldxdw r5, [r6+0x70]                     
    ldxdw r0, [r6+0x78]                     
    ldxdw r7, [r6+0x80]                     
    ldxdw r4, [r6+0x88]                     
    ldxdw r8, [r6+0x90]                     
    stxb [r10-0x6a0], r9                    
    stxdw [r10-0x6a8], r3                   
    ldxdw r3, [r10-0x8d8]                   
    stxb [r10-0x6b0], r3                    
    ldxdw r3, [r10-0x868]                   
    stxdw [r10-0x6b8], r3                   
    ldxdw r3, [r10-0x8c8]                   
    stxb [r10-0x6c0], r3                    
    ldxdw r3, [r10-0x860]                   
    stxdw [r10-0x6c8], r3                   
    ldxdw r3, [r10-0x8b8]                   
    stxb [r10-0x6d0], r3                    
    ldxdw r3, [r10-0x858]                   
    stxdw [r10-0x6d8], r3                   
    ldxdw r3, [r10-0x8a8]                   
    stxb [r10-0x6e0], r3                    
    ldxdw r3, [r10-0x898]                   
    stxdw [r10-0x6e8], r3                   
    ldxdw r3, [r10-0x870]                   
    stxdw [r10-0x6f8], r3                   
    ldxdw r3, [r10-0x848]                   
    stxdw [r10-0x708], r3                   
    ldxdw r3, [r10-0x840]                   
    stxdw [r10-0x718], r3                   
    ldxdw r3, [r10-0x838]                   
    stxdw [r10-0x728], r3                   
    ldxdw r3, [r10-0x7e0]                   
    stxdw [r10-0x738], r3                   
    ldxdw r3, [r10-0x830]                   
    stxdw [r10-0x748], r3                   
    ldxdw r3, [r10-0x828]                   
    stxdw [r10-0x758], r3                   
    stxdw [r10-0x768], r1                   
    ldxdw r1, [r10-0x810]                   
    stxdw [r10-0x778], r1                   
    ldxdw r1, [r10-0x808]                   
    stxdw [r10-0x788], r1                   
    ldxdw r1, [r10-0x7d0]                   
    stxdw [r10-0x798], r1                   
    ldxdw r1, [r10-0x820]                   
    stxdw [r10-0x7a8], r1                   
    ldxdw r1, [r10-0x818]                   
    stxdw [r10-0x7b8], r1                   
    ldxdw r1, [r10-0x950]                   
    stxdw [r10-0x7c8], r1                   
    add64 r8, 8                                     r8 += 8   ///  r8 = r8.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x658], r8                   
    add64 r4, 8                                     r4 += 8   ///  r4 = r4.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x668], r4                   
    add64 r7, 8                                     r7 += 8   ///  r7 = r7.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x678], r7                   
    add64 r0, 8                                     r0 += 8   ///  r0 = r0.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x688], r0                   
    add64 r5, 8                                     r5 += 8   ///  r5 = r5.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x698], r5                   
    sth [r10-0x650], 0                      
    sth [r10-0x660], 0                      
    sth [r10-0x670], 0                      
    sth [r10-0x680], 0                      
    sth [r10-0x690], 0                      
    stb [r10-0x69f], 0                      
    stb [r10-0x6af], 0                      
    stb [r10-0x6bf], 0                      
    stb [r10-0x6cf], 0                      
    stb [r10-0x6df], 0                      
    sth [r10-0x6f0], 0                      
    sth [r10-0x700], 0                      
    sth [r10-0x710], 0                      
    sth [r10-0x720], 1                      
    sth [r10-0x730], 1                      
    sth [r10-0x740], 0                      
    sth [r10-0x750], 0                      
    sth [r10-0x760], 1                      
    sth [r10-0x770], 1                      
    sth [r10-0x780], 0                      
    sth [r10-0x790], 0                      
    sth [r10-0x7a0], 1                      
    sth [r10-0x7b0], 1                      
    sth [r10-0x7c0], 257                    
    ldxdw r1, [r10-0x930]                   
    stxdw [r10-0x640], r1                   
    ldxdw r1, [r10-0x8d0]                   
    stxdw [r10-0x648], r1                   
    stb [r10-0x630], 0                      
    stdw [r10-0x638], 0                     
    ldxdw r1, [r10-0x8e0]                   
    stxdw [r10-0x570], r1                   
    ldxdw r1, [r10-0x908]                   
    stxdw [r10-0x578], r1                   
    ldxdw r1, [r10-0x918]                   
    stxdw [r10-0x580], r1                   
    ldxdw r1, [r10-0x928]                   
    stxdw [r10-0x588], r1                   
    ldxdw r1, [r10-0x940]                   
    stxdw [r10-0x590], r1                   
    ldxdw r1, [r10-0x8c0]                   
    stxdw [r10-0x598], r1                   
    ldxdw r1, [r10-0x8b0]                   
    stxdw [r10-0x5a0], r1                   
    ldxdw r1, [r10-0x8a0]                   
    stxdw [r10-0x5a8], r1                   
    ldxdw r1, [r10-0x890]                   
    stxdw [r10-0x5b0], r1                   
    ldxdw r1, [r10-0x900]                   
    stxdw [r10-0x5b8], r1                   
    ldxdw r1, [r10-0x800]                   
    stxdw [r10-0x5c0], r1                   
    ldxdw r1, [r10-0x8f8]                   
    stxdw [r10-0x5c8], r1                   
    ldxdw r1, [r10-0x7f8]                   
    stxdw [r10-0x5d0], r1                   
    ldxdw r1, [r10-0x8f0]                   
    stxdw [r10-0x5d8], r1                   
    ldxdw r1, [r10-0x880]                   
    stxdw [r10-0x5e0], r1                   
    ldxdw r1, [r10-0x8e8]                   
    stxdw [r10-0x5e8], r1                   
    ldxdw r1, [r10-0x910]                   
    stxdw [r10-0x5f0], r1                   
    ldxdw r1, [r10-0x920]                   
    stxdw [r10-0x5f8], r1                   
    ldxdw r1, [r10-0x938]                   
    stxdw [r10-0x600], r1                   
    ldxdw r1, [r10-0x948]                   
    stxdw [r10-0x608], r1                   
    stxdw [r10-0x610], r6                   
    ldxdw r1, [r10-0x7d8]                   
    stxdw [r10-0x618], r1                   
    ldxdw r1, [r10-0x850]                   
    stxdw [r10-0x620], r1                   
    ldxdw r1, [r10-0x7f0]                   
    stxdw [r10-0x628], r1                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -1576                                 r1 += -1576   ///  r1 = r1.wrapping_add(-1576 as i32 as i64 as u64)
    mov64 r3, r10                                   r3 = r10
    add64 r3, -1984                                 r3 += -1984   ///  r3 = r3.wrapping_add(-1984 as i32 as i64 as u64)
    ja lbb_8620                                     if true { pc += 20 }
lbb_8600:
    mov64 r7, r10                                   r7 = r10
    add64 r7, -1384                                 r7 += -1384   ///  r7 = r7.wrapping_add(-1384 as i32 as i64 as u64)
    add64 r7, r2                                    r7 += r2   ///  r7 = r7.wrapping_add(r2)
    stxb [r7+0x32], r6                      
    stxb [r7+0x31], r8                      
    stxb [r7+0x30], r0                      
    mov64 r0, r4                                    r0 = r4
    add64 r0, 40                                    r0 += 40   ///  r0 = r0.wrapping_add(40 as i32 as i64 as u64)
    stxdw [r7+0x20], r0                     
    mov64 r0, r4                                    r0 = r4
    add64 r0, 88                                    r0 += 88   ///  r0 = r0.wrapping_add(88 as i32 as i64 as u64)
    stxdw [r7+0x18], r0                     
    stxdw [r7+0x10], r5                     
    add64 r4, 72                                    r4 += 72   ///  r4 = r4.wrapping_add(72 as i32 as i64 as u64)
    stxdw [r7+0x8], r4                      
    stdw [r7+0x28], 0                       
    add64 r3, 16                                    r3 += 16   ///  r3 = r3.wrapping_add(16 as i32 as i64 as u64)
    add64 r1, 8                                     r1 += 8   ///  r1 = r1.wrapping_add(8 as i32 as i64 as u64)
    add64 r2, 56                                    r2 += 56   ///  r2 = r2.wrapping_add(56 as i32 as i64 as u64)
    jeq r2, 1344, lbb_8673                          if r2 == (1344 as i32 as i64 as u64) { pc += 53 }
lbb_8620:
    mov64 r0, r10                                   r0 = r10
    add64 r0, -1384                                 r0 += -1384   ///  r0 = r0.wrapping_add(-1384 as i32 as i64 as u64)
    mov64 r5, 1                                     r5 = 1 as i32 as i64 as u64
    ldxdw r4, [r1+0x0]                      
    ldxdw r4, [r4+0x0]                      
    ldxdw r6, [r3-0x8]                      
    ldxdw r7, [r6+0x0]                      
    ldxdw r8, [r4+0x8]                      
    jne r8, r7, lbb_8693                            if r8 != r7 { pc += 64 }
    ldxdw r7, [r6+0x8]                      
    ldxdw r8, [r4+0x10]                     
    jne r8, r7, lbb_8693                            if r8 != r7 { pc += 61 }
    ldxdw r7, [r6+0x10]                     
    ldxdw r8, [r4+0x18]                     
    jne r8, r7, lbb_8693                            if r8 != r7 { pc += 58 }
    ldxdw r6, [r6+0x18]                     
    ldxdw r7, [r4+0x20]                     
    jne r7, r6, lbb_8693                            if r7 != r6 { pc += 55 }
    ldxb r6, [r3+0x0]                       
    mov64 r5, 0                                     r5 = 0 as i32 as i64 as u64
    jne r6, 0, lbb_8642                             if r6 != (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r5, 119                                   r5 = 119 as i32 as i64 as u64
lbb_8642:
    ldxb r6, [r4+0x0]                       
    or64 r5, r6                                     r5 |= r6   ///  r5 = r5.or(r6)
    and64 r5, 255                                   r5 &= 255   ///  r5 = r5.and(255)
    jne r5, 255, lbb_8670                           if r5 != (255 as i32 as i64 as u64) { pc += 24 }
    add64 r0, r2                                    r0 += r2   ///  r0 = r0.wrapping_add(r2)
    mov64 r6, r4                                    r6 = r4
    add64 r6, 8                                     r6 += 8   ///  r6 = r6.wrapping_add(8 as i32 as i64 as u64)
    ldxdw r5, [r4+0x50]                     
    ldxb r7, [r4+0x3]                       
    ldxb r9, [r4+0x2]                       
    ldxb r8, [r4+0x1]                       
    stxdw [r0+0x0], r6                      
    mov64 r6, 1                                     r6 = 1 as i32 as i64 as u64
    mov64 r0, 1                                     r0 = 1 as i32 as i64 as u64
    jeq r8, 0, lbb_8661                             if r8 == (0 as i32 as i64 as u64) { pc += 4 }
    mov64 r8, 1                                     r8 = 1 as i32 as i64 as u64
    jeq r9, 0, lbb_8664                             if r9 == (0 as i32 as i64 as u64) { pc += 5 }
lbb_8659:
    jne r7, 0, lbb_8600                             if r7 != (0 as i32 as i64 as u64) { pc += -60 }
    ja lbb_8666                                     if true { pc += 5 }
lbb_8661:
    mov64 r0, 0                                     r0 = 0 as i32 as i64 as u64
    mov64 r8, 1                                     r8 = 1 as i32 as i64 as u64
    jne r9, 0, lbb_8659                             if r9 != (0 as i32 as i64 as u64) { pc += -5 }
lbb_8664:
    mov64 r8, 0                                     r8 = 0 as i32 as i64 as u64
    jne r7, 0, lbb_8600                             if r7 != (0 as i32 as i64 as u64) { pc += -66 }
lbb_8666:
    mov64 r6, 0                                     r6 = 0 as i32 as i64 as u64
    ja lbb_8600                                     if true { pc += -68 }
lbb_8668:
    mov64 r1, r8                                    r1 = r8
    ja lbb_8696                                     if true { pc += 26 }
lbb_8670:
    mov64 r5, 11                                    r5 = 11 as i32 as i64 as u64
    ldxdw r0, [r10-0x888]                   
    ja lbb_8921                                     if true { pc += 248 }
lbb_8673:
    ldxdw r1, [r10-0x958]                   
    stxdw [r10-0x8], r1                     
    mov64 r1, r10                                   r1 = r10
    add64 r1, -1608                                 r1 += -1608   ///  r1 = r1.wrapping_add(-1608 as i32 as i64 as u64)
    stxdw [r10-0x10], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -1992                                 r1 += -1992   ///  r1 = r1.wrapping_add(-1992 as i32 as i64 as u64)
    stxdw [r10-0x20], r1                    
    ldxdw r1, [r10-0x870]                   
    stxdw [r10-0x28], r1                    
    stdw [r10-0x18], 24                     
    mov64 r1, r10                                   r1 = r10
    add64 r1, -40                                   r1 += -40   ///  r1 = r1.wrapping_add(-40 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -1384                                 r2 += -1384   ///  r2 = r2.wrapping_add(-1384 as i32 as i64 as u64)
    mov64 r3, 24                                    r3 = 24 as i32 as i64 as u64
    mov64 r4, 8                                     r4 = 8 as i32 as i64 as u64
    mov64 r5, 0                                     r5 = 0 as i32 as i64 as u64
    syscall [invalid]                       
    mov64 r5, 26                                    r5 = 26 as i32 as i64 as u64
lbb_8693:
    ldxdw r0, [r10-0x888]                   
    ja lbb_8921                                     if true { pc += 226 }
lbb_8695:
    mov64 r1, r5                                    r1 = r5
lbb_8696:
    ldxdw r2, [r10-0x7d8]                   
    ldxdw r3, [r10-0x7d0]                   
lbb_8698:
    stxdw [r10-0x860], r2                   
    stxdw [r10-0x7d0], r3                   
    add64 r0, 8                                     r0 += 8   ///  r0 = r0.wrapping_add(8 as i32 as i64 as u64)
    ldxdw r4, [r9+0x0]                      
    stxdw [r10-0x7d8], r4                   
    ldxdw r4, [r7+0x0]                      
    stxdw [r10-0x868], r4                   
    ldxdw r2, [r2+0x0]                      
    stxdw [r10-0x870], r2                   
    ldxdw r2, [r3+0x0]                      
    stxdw [r10-0x878], r2                   
    ldxdw r2, [r6+0x0]                      
    stxdw [r10-0x880], r2                   
    ldxdw r2, [r6+0x8]                      
    stxdw [r10-0x888], r2                   
    ldxdw r2, [r6+0x10]                     
    stxdw [r10-0x890], r2                   
    ldxdw r2, [r6+0x18]                     
    stxdw [r10-0x898], r2                   
    ldxdw r5, [r6+0x20]                     
    ldxdw r2, [r6+0x28]                     
    ldxdw r7, [r6+0x38]                     
    ldxdw r9, [r6+0x40]                     
    ldxdw r8, [r6+0x48]                     
    mov64 r4, r0                                    r4 = r0
    ldxdw r0, [r6+0x50]                     
    ldxdw r1, [r1+0x0]                      
    ldxdw r3, [r6+0x58]                     
    stxdw [r10-0x738], r4                   
    add64 r3, 8                                     r3 += 8   ///  r3 = r3.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x6d8], r3                   
    add64 r1, 8                                     r1 += 8   ///  r1 = r1.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x6e8], r1                   
    add64 r0, 8                                     r0 += 8   ///  r0 = r0.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x6f8], r0                   
    add64 r8, 8                                     r8 += 8   ///  r8 = r8.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x708], r8                   
    add64 r9, 8                                     r9 += 8   ///  r9 = r9.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x718], r9                   
    add64 r7, 8                                     r7 += 8   ///  r7 = r7.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x728], r7                   
    add64 r2, 8                                     r2 += 8   ///  r2 = r2.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x748], r2                   
    add64 r5, 8                                     r5 += 8   ///  r5 = r5.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x758], r5                   
    ldxdw r1, [r10-0x898]                   
    add64 r1, 8                                     r1 += 8   ///  r1 = r1.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x768], r1                   
    ldxdw r1, [r10-0x890]                   
    add64 r1, 8                                     r1 += 8   ///  r1 = r1.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x778], r1                   
    ldxdw r1, [r10-0x888]                   
    add64 r1, 8                                     r1 += 8   ///  r1 = r1.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x788], r1                   
    ldxdw r1, [r10-0x880]                   
    add64 r1, 8                                     r1 += 8   ///  r1 = r1.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x798], r1                   
    ldxdw r1, [r10-0x878]                   
    add64 r1, 8                                     r1 += 8   ///  r1 = r1.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x7a8], r1                   
    ldxdw r1, [r10-0x870]                   
    add64 r1, 8                                     r1 += 8   ///  r1 = r1.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x7b8], r1                   
    ldxdw r1, [r10-0x868]                   
    add64 r1, 8                                     r1 += 8   ///  r1 = r1.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x7c8], r1                   
    ldxdw r1, [r10-0x7d8]                   
    add64 r1, 8                                     r1 += 8   ///  r1 = r1.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x7d8], r1                   
    stxdw [r10-0x6c8], r1                   
    sth [r10-0x6c0], 0                      
    sth [r10-0x6d0], 0                      
    sth [r10-0x6e0], 0                      
    sth [r10-0x6f0], 1                      
    sth [r10-0x700], 0                      
    sth [r10-0x710], 0                      
    sth [r10-0x720], 1                      
    sth [r10-0x730], 1                      
    sth [r10-0x740], 0                      
    sth [r10-0x750], 0                      
    sth [r10-0x760], 1                      
    sth [r10-0x770], 1                      
    sth [r10-0x780], 0                      
    sth [r10-0x790], 0                      
    sth [r10-0x7a0], 1                      
    sth [r10-0x7b0], 1                      
    sth [r10-0x7c0], 257                    
    ldxdw r1, [r10-0x858]                   
    stxdw [r10-0x640], r1                   
    lddw r1, 0x885b5beb4c3f4b41                     r1 load str located at -8621195995516023999
    stxdw [r10-0x648], r1                   
    stdw [r10-0x638], 0                     
    ldxdw r1, [r10-0x800]                   
    stxdw [r10-0x5a8], r1                   
    ldxdw r1, [r10-0x850]                   
    stxdw [r10-0x5b0], r1                   
    ldxdw r1, [r10-0x7f8]                   
    stxdw [r10-0x5b8], r1                   
    ldxdw r1, [r10-0x848]                   
    stxdw [r10-0x5c0], r1                   
    ldxdw r1, [r10-0x840]                   
    stxdw [r10-0x5c8], r1                   
    ldxdw r1, [r10-0x838]                   
    stxdw [r10-0x5d0], r1                   
    ldxdw r1, [r10-0x830]                   
    stxdw [r10-0x5d8], r1                   
    ldxdw r1, [r10-0x7e0]                   
    stxdw [r10-0x5e0], r1                   
    ldxdw r1, [r10-0x828]                   
    stxdw [r10-0x5e8], r1                   
    ldxdw r1, [r10-0x820]                   
    stxdw [r10-0x5f0], r1                   
    ldxdw r1, [r10-0x818]                   
    stxdw [r10-0x5f8], r1                   
    ldxdw r1, [r10-0x810]                   
    stxdw [r10-0x600], r1                   
    ldxdw r1, [r10-0x808]                   
    stxdw [r10-0x608], r1                   
    stxdw [r10-0x610], r6                   
    ldxdw r1, [r10-0x7d0]                   
    stxdw [r10-0x618], r1                   
    ldxdw r1, [r10-0x860]                   
    stxdw [r10-0x620], r1                   
    ldxdw r1, [r10-0x7f0]                   
    stxdw [r10-0x628], r1                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -1576                                 r1 += -1576   ///  r1 = r1.wrapping_add(-1576 as i32 as i64 as u64)
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
    mov64 r3, r10                                   r3 = r10
    add64 r3, -1984                                 r3 += -1984   ///  r3 = r3.wrapping_add(-1984 as i32 as i64 as u64)
    ja lbb_8850                                     if true { pc += 20 }
lbb_8830:
    mov64 r7, r10                                   r7 = r10
    add64 r7, -1384                                 r7 += -1384   ///  r7 = r7.wrapping_add(-1384 as i32 as i64 as u64)
    add64 r7, r2                                    r7 += r2   ///  r7 = r7.wrapping_add(r2)
    stxb [r7+0x32], r6                      
    stxb [r7+0x31], r8                      
    stxb [r7+0x30], r0                      
    mov64 r0, r4                                    r0 = r4
    add64 r0, 40                                    r0 += 40   ///  r0 = r0.wrapping_add(40 as i32 as i64 as u64)
    stxdw [r7+0x20], r0                     
    mov64 r0, r4                                    r0 = r4
    add64 r0, 88                                    r0 += 88   ///  r0 = r0.wrapping_add(88 as i32 as i64 as u64)
    stxdw [r7+0x18], r0                     
    stxdw [r7+0x10], r5                     
    add64 r4, 72                                    r4 += 72   ///  r4 = r4.wrapping_add(72 as i32 as i64 as u64)
    stxdw [r7+0x8], r4                      
    stdw [r7+0x28], 0                       
    add64 r3, 16                                    r3 += 16   ///  r3 = r3.wrapping_add(16 as i32 as i64 as u64)
    add64 r1, 8                                     r1 += 8   ///  r1 = r1.wrapping_add(8 as i32 as i64 as u64)
    add64 r2, 56                                    r2 += 56   ///  r2 = r2.wrapping_add(56 as i32 as i64 as u64)
    jeq r2, 952, lbb_8901                           if r2 == (952 as i32 as i64 as u64) { pc += 51 }
lbb_8850:
    mov64 r0, r10                                   r0 = r10
    add64 r0, -1384                                 r0 += -1384   ///  r0 = r0.wrapping_add(-1384 as i32 as i64 as u64)
    mov64 r5, 1                                     r5 = 1 as i32 as i64 as u64
    ldxdw r4, [r1+0x0]                      
    ldxdw r4, [r4+0x0]                      
    ldxdw r6, [r3-0x8]                      
    ldxdw r7, [r6+0x0]                      
    ldxdw r8, [r4+0x8]                      
    jne r8, r7, lbb_8899                            if r8 != r7 { pc += 40 }
    ldxdw r7, [r6+0x8]                      
    ldxdw r8, [r4+0x10]                     
    jne r8, r7, lbb_8899                            if r8 != r7 { pc += 37 }
    ldxdw r7, [r6+0x10]                     
    ldxdw r8, [r4+0x18]                     
    jne r8, r7, lbb_8899                            if r8 != r7 { pc += 34 }
    ldxdw r6, [r6+0x18]                     
    ldxdw r7, [r4+0x20]                     
    jne r7, r6, lbb_8899                            if r7 != r6 { pc += 31 }
    ldxb r6, [r3+0x0]                       
    mov64 r5, 0                                     r5 = 0 as i32 as i64 as u64
    jne r6, 0, lbb_8872                             if r6 != (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r5, 119                                   r5 = 119 as i32 as i64 as u64
lbb_8872:
    ldxb r6, [r4+0x0]                       
    or64 r5, r6                                     r5 |= r6   ///  r5 = r5.or(r6)
    and64 r5, 255                                   r5 &= 255   ///  r5 = r5.and(255)
    jne r5, 255, lbb_8898                           if r5 != (255 as i32 as i64 as u64) { pc += 22 }
    add64 r0, r2                                    r0 += r2   ///  r0 = r0.wrapping_add(r2)
    mov64 r6, r4                                    r6 = r4
    add64 r6, 8                                     r6 += 8   ///  r6 = r6.wrapping_add(8 as i32 as i64 as u64)
    ldxdw r5, [r4+0x50]                     
    ldxb r7, [r4+0x3]                       
    ldxb r9, [r4+0x2]                       
    ldxb r8, [r4+0x1]                       
    stxdw [r0+0x0], r6                      
    mov64 r6, 1                                     r6 = 1 as i32 as i64 as u64
    mov64 r0, 1                                     r0 = 1 as i32 as i64 as u64
    jeq r8, 0, lbb_8891                             if r8 == (0 as i32 as i64 as u64) { pc += 4 }
    mov64 r8, 1                                     r8 = 1 as i32 as i64 as u64
    jeq r9, 0, lbb_8894                             if r9 == (0 as i32 as i64 as u64) { pc += 5 }
lbb_8889:
    jne r7, 0, lbb_8830                             if r7 != (0 as i32 as i64 as u64) { pc += -60 }
    ja lbb_8896                                     if true { pc += 5 }
lbb_8891:
    mov64 r0, 0                                     r0 = 0 as i32 as i64 as u64
    mov64 r8, 1                                     r8 = 1 as i32 as i64 as u64
    jne r9, 0, lbb_8889                             if r9 != (0 as i32 as i64 as u64) { pc += -5 }
lbb_8894:
    mov64 r8, 0                                     r8 = 0 as i32 as i64 as u64
    jne r7, 0, lbb_8830                             if r7 != (0 as i32 as i64 as u64) { pc += -66 }
lbb_8896:
    mov64 r6, 0                                     r6 = 0 as i32 as i64 as u64
    ja lbb_8830                                     if true { pc += -68 }
lbb_8898:
    mov64 r5, 11                                    r5 = 11 as i32 as i64 as u64
lbb_8899:
    mov64 r0, 0                                     r0 = 0 as i32 as i64 as u64
    ja lbb_8921                                     if true { pc += 20 }
lbb_8901:
    mov64 r1, r10                                   r1 = r10
    add64 r1, -1608                                 r1 += -1608   ///  r1 = r1.wrapping_add(-1608 as i32 as i64 as u64)
    stxdw [r10-0x10], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -1992                                 r1 += -1992   ///  r1 = r1.wrapping_add(-1992 as i32 as i64 as u64)
    stxdw [r10-0x20], r1                    
    ldxdw r1, [r10-0x7d8]                   
    stxdw [r10-0x28], r1                    
    stdw [r10-0x8], 24                      
    stdw [r10-0x18], 17                     
    mov64 r1, r10                                   r1 = r10
    add64 r1, -40                                   r1 += -40   ///  r1 = r1.wrapping_add(-40 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -1384                                 r2 += -1384   ///  r2 = r2.wrapping_add(-1384 as i32 as i64 as u64)
    mov64 r3, 17                                    r3 = 17 as i32 as i64 as u64
    mov64 r4, 8                                     r4 = 8 as i32 as i64 as u64
    mov64 r5, 0                                     r5 = 0 as i32 as i64 as u64
    syscall [invalid]                       
    mov64 r0, 0                                     r0 = 0 as i32 as i64 as u64
    mov64 r5, 26                                    r5 = 26 as i32 as i64 as u64
lbb_8921:
    ldxdw r1, [r10-0x7e8]                   
    stxw [r1+0x4], r0                       
    stxw [r1+0x0], r5                       
    exit                                    
lbb_8925:
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
    lddw r3, 0x100026fe0 --> b"\x00\x00\x00\x00\xb8Y\x02\x00\x10\x00\x00\x00\x00\x00\x00\x00\x8a!\x00\x0…        r3 load str located at 4295127008
    call function_18489                     
lbb_8930:
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    mov64 r2, 1                                     r2 = 1 as i32 as i64 as u64
    lddw r3, 0x100026ff8 --> b"\x00\x00\x00\x00\xb8Y\x02\x00\x10\x00\x00\x00\x00\x00\x00\x00\x8a!\x00\x0…        r3 load str located at 4295127032
    call function_18489                     
lbb_8935:
    mov64 r1, 2                                     r1 = 2 as i32 as i64 as u64
    mov64 r2, 2                                     r2 = 2 as i32 as i64 as u64
    lddw r3, 0x100027010 --> b"\x00\x00\x00\x00\xb8Y\x02\x00\x10\x00\x00\x00\x00\x00\x00\x00\x8a!\x00\x0…        r3 load str located at 4295127056
    call function_18489                     
lbb_8940:
    mov64 r1, 3                                     r1 = 3 as i32 as i64 as u64
    mov64 r2, 3                                     r2 = 3 as i32 as i64 as u64
    lddw r3, 0x100027028 --> b"\x00\x00\x00\x00\xb8Y\x02\x00\x10\x00\x00\x00\x00\x00\x00\x00\x8a!\x00\x0…        r3 load str located at 4295127080
    call function_18489                     
lbb_8945:
    mov64 r1, 4                                     r1 = 4 as i32 as i64 as u64
    mov64 r2, 4                                     r2 = 4 as i32 as i64 as u64
    lddw r3, 0x100027040 --> b"\x00\x00\x00\x00\xb8Y\x02\x00\x10\x00\x00\x00\x00\x00\x00\x00\x8b!\x00\x0…        r3 load str located at 4295127104
    call function_18489                     
lbb_8950:
    mov64 r1, 5                                     r1 = 5 as i32 as i64 as u64
    mov64 r2, 5                                     r2 = 5 as i32 as i64 as u64
    lddw r3, 0x100027058 --> b"\x00\x00\x00\x00\xb8Y\x02\x00\x10\x00\x00\x00\x00\x00\x00\x00\x8b!\x00\x0…        r3 load str located at 4295127128
    call function_18489                     
lbb_8955:
    mov64 r1, 6                                     r1 = 6 as i32 as i64 as u64
    mov64 r2, 6                                     r2 = 6 as i32 as i64 as u64
    lddw r3, 0x100027070 --> b"\x00\x00\x00\x00\xb8Y\x02\x00\x10\x00\x00\x00\x00\x00\x00\x00\x8b!\x00\x0…        r3 load str located at 4295127152
    call function_18489                     
lbb_8960:
    mov64 r1, 7                                     r1 = 7 as i32 as i64 as u64
    mov64 r2, 7                                     r2 = 7 as i32 as i64 as u64
    lddw r3, 0x100027088 --> b"\x00\x00\x00\x00\xb8Y\x02\x00\x10\x00\x00\x00\x00\x00\x00\x00\x8b!\x00\x0…        r3 load str located at 4295127176
    call function_18489                     
lbb_8965:
    mov64 r1, 8                                     r1 = 8 as i32 as i64 as u64
    mov64 r2, 8                                     r2 = 8 as i32 as i64 as u64
    lddw r3, 0x1000270a0 --> b"\x00\x00\x00\x00\xb8Y\x02\x00\x10\x00\x00\x00\x00\x00\x00\x00\x8c!\x00\x0…        r3 load str located at 4295127200
    call function_18489                     
lbb_8970:
    mov64 r1, 9                                     r1 = 9 as i32 as i64 as u64
    mov64 r2, 9                                     r2 = 9 as i32 as i64 as u64
    lddw r3, 0x1000270b8 --> b"\x00\x00\x00\x00\xb8Y\x02\x00\x10\x00\x00\x00\x00\x00\x00\x00\x8c!\x00\x0…        r3 load str located at 4295127224
    call function_18489                     
lbb_8975:
    mov64 r1, 10                                    r1 = 10 as i32 as i64 as u64
    mov64 r2, 10                                    r2 = 10 as i32 as i64 as u64
    lddw r3, 0x1000270d0 --> b"\x00\x00\x00\x00\xb8Y\x02\x00\x10\x00\x00\x00\x00\x00\x00\x00\x8c!\x00\x0…        r3 load str located at 4295127248
    call function_18489                     
lbb_8980:
    mov64 r1, 11                                    r1 = 11 as i32 as i64 as u64
    mov64 r2, 11                                    r2 = 11 as i32 as i64 as u64
    lddw r3, 0x1000270e8 --> b"\x00\x00\x00\x00\xb8Y\x02\x00\x10\x00\x00\x00\x00\x00\x00\x00\x8c!\x00\x0…        r3 load str located at 4295127272
    call function_18489                     
    ldxdw r3, [r2+0x8]                      
    jeq r3, 1, lbb_9222                             if r3 == (1 as i32 as i64 as u64) { pc += 235 }
    jeq r3, 0, lbb_9227                             if r3 == (0 as i32 as i64 as u64) { pc += 239 }
    jle r3, 2, lbb_9232                             if r3 <= (2 as i32 as i64 as u64) { pc += 243 }
    jeq r3, 3, lbb_9237                             if r3 == (3 as i32 as i64 as u64) { pc += 247 }
    jle r3, 4, lbb_9242                             if r3 <= (4 as i32 as i64 as u64) { pc += 251 }
    jeq r3, 5, lbb_9247                             if r3 == (5 as i32 as i64 as u64) { pc += 255 }
    ldxdw r4, [r2+0x50]                     
    mov64 r0, 3                                     r0 = 3 as i32 as i64 as u64
    ldxdw r9, [r4+0x0]                      
    ldxdw r3, [r9+0x50]                     
    jlt r3, 32, lbb_9219                            if r3 < (32 as i32 as i64 as u64) { pc += 222 }
    ldxdw r3, [r2+0x0]                      
    mov64 r8, r3                                    r8 = r3
    add64 r8, 16                                    r8 += 16   ///  r8 = r8.wrapping_add(16 as i32 as i64 as u64)
    ldxdw r5, [r8+0x0]                      
    ldxdw r6, [r5+0x50]                     
    jlt r6, 32, lbb_9219                            if r6 < (32 as i32 as i64 as u64) { pc += 216 }
    ldxdw r0, [r2+0x58]                     
    stxdw [r10-0x378], r0                   
    ldxdw r0, [r2+0x48]                     
    stxdw [r10-0x370], r0                   
    ldxdw r0, [r2+0x28]                     
    stxdw [r10-0x390], r0                   
    ldxdw r0, [r2+0x20]                     
    stxdw [r10-0x398], r0                   
    ldxdw r2, [r2+0x10]                     
    stxdw [r10-0x3a8], r2                   
    mov64 r2, r3                                    r2 = r3
    add64 r2, 40                                    r2 += 40   ///  r2 = r2.wrapping_add(40 as i32 as i64 as u64)
    stxdw [r10-0x3a0], r2                   
    mov64 r0, r3                                    r0 = r3
    add64 r0, 8                                     r0 += 8   ///  r0 = r0.wrapping_add(8 as i32 as i64 as u64)
    mov64 r2, r3                                    r2 = r3
    add64 r2, 24                                    r2 += 24   ///  r2 = r2.wrapping_add(24 as i32 as i64 as u64)
    stxdw [r10-0x368], r2                   
    mov64 r2, r3                                    r2 = r3
    add64 r2, 32                                    r2 += 32   ///  r2 = r2.wrapping_add(32 as i32 as i64 as u64)
    ldxdw r7, [r5+0x58]                     
    mov64 r6, r9                                    r6 = r9
    ldxdw r9, [r6+0x58]                     
    stxdw [r10-0x380], r1                   
    stxdw [r10-0x388], r4                   
    jne r9, r7, lbb_9043                            if r9 != r7 { pc += 14 }
    ldxdw r7, [r5+0x60]                     
    ldxdw r9, [r6+0x60]                     
    jne r9, r7, lbb_9043                            if r9 != r7 { pc += 11 }
    ldxdw r7, [r5+0x68]                     
    ldxdw r9, [r6+0x68]                     
    jne r9, r7, lbb_9043                            if r9 != r7 { pc += 8 }
    ldxdw r5, [r5+0x70]                     
    ldxdw r7, [r6+0x70]                     
    jne r7, r5, lbb_9043                            if r7 != r5 { pc += 5 }
    ldxdw r4, [r10-0x368]                   
    stxdw [r10-0x368], r0                   
    mov64 r1, r8                                    r1 = r8
    mov64 r8, r2                                    r8 = r2
    ja lbb_9045                                     if true { pc += 2 }
lbb_9043:
    mov64 r4, r0                                    r4 = r0
    mov64 r1, r2                                    r1 = r2
lbb_9045:
    stxdw [r10-0x3c8], r8                   
    stxdw [r10-0x3c0], r4                   
    stxdw [r10-0x3b0], r1                   
    add64 r6, 8                                     r6 += 8   ///  r6 = r6.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x3d0], r6                   
    ldxdw r2, [r3+0x0]                      
    stxdw [r10-0x3d8], r2                   
    ldxdw r5, [r10-0x368]                   
    ldxdw r0, [r5+0x0]                      
    ldxdw r7, [r1+0x0]                      
    ldxdw r9, [r4+0x0]                      
    ldxdw r5, [r8+0x0]                      
    ldxdw r1, [r10-0x378]                   
    ldxdw r6, [r1+0x0]                      
    ldxdw r4, [r10-0x370]                   
    ldxdw r8, [r4+0x0]                      
    ldxdw r1, [r10-0x390]                   
    ldxdw r4, [r1+0x0]                      
    stxdw [r10-0x3b8], r3                   
    ldxdw r3, [r3+0x28]                     
    ldxdw r2, [r10-0x3d0]                   
    stxdw [r10-0x310], r2                   
    add64 r3, 8                                     r3 += 8   ///  r3 = r3.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x2d0], r3                   
    add64 r4, 8                                     r4 += 8   ///  r4 = r4.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x2e0], r4                   
    add64 r8, 8                                     r8 += 8   ///  r8 = r8.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x2f0], r8                   
    add64 r6, 8                                     r6 += 8   ///  r6 = r6.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x300], r6                   
    add64 r5, 8                                     r5 += 8   ///  r5 = r5.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x320], r5                   
    add64 r9, 8                                     r9 += 8   ///  r9 = r9.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x330], r9                   
    add64 r7, 8                                     r7 += 8   ///  r7 = r7.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x340], r7                   
    add64 r0, 8                                     r0 += 8   ///  r0 = r0.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x350], r0                   
    ldxdw r2, [r10-0x3d8]                   
    add64 r2, 8                                     r2 += 8   ///  r2 = r2.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x360], r2                   
    sth [r10-0x2c8], 0                      
    sth [r10-0x2d8], 0                      
    sth [r10-0x2e8], 257                    
    sth [r10-0x2f8], 1                      
    sth [r10-0x308], 1                      
    sth [r10-0x318], 1                      
    sth [r10-0x328], 1                      
    sth [r10-0x338], 1                      
    sth [r10-0x348], 1                      
    sth [r10-0x358], 1                      
    ldxdw r2, [r10-0x3a8]                   
    stxdw [r10-0x2b8], r2                   
    stb [r10-0x2b9], 6                      
    stdw [r10-0x2b0], 0                     
    ldxdw r2, [r10-0x398]                   
    ldxdw r2, [r2+0x0]                      
    ldxdw r3, [r10-0x3a0]                   
    stxdw [r10-0x260], r3                   
    stxdw [r10-0x268], r1                   
    ldxdw r3, [r10-0x370]                   
    stxdw [r10-0x270], r3                   
    ldxdw r1, [r10-0x378]                   
    stxdw [r10-0x278], r1                   
    ldxdw r1, [r10-0x388]                   
    stxdw [r10-0x280], r1                   
    ldxdw r1, [r10-0x3c8]                   
    stxdw [r10-0x288], r1                   
    ldxdw r1, [r10-0x3c0]                   
    stxdw [r10-0x290], r1                   
    ldxdw r1, [r10-0x3b0]                   
    stxdw [r10-0x298], r1                   
    ldxdw r1, [r10-0x368]                   
    stxdw [r10-0x2a0], r1                   
    ldxdw r1, [r10-0x3b8]                   
    stxdw [r10-0x2a8], r1                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -680                                  r1 += -680   ///  r1 = r1.wrapping_add(-680 as i32 as i64 as u64)
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
    mov64 r4, r10                                   r4 = r10
    add64 r4, -856                                  r4 += -856   ///  r4 = r4.wrapping_add(-856 as i32 as i64 as u64)
    add64 r2, 8                                     r2 += 8   ///  r2 = r2.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x368], r2                   
    ja lbb_9149                                     if true { pc += 20 }
lbb_9129:
    mov64 r2, r10                                   r2 = r10
    add64 r2, -600                                  r2 += -600   ///  r2 = r2.wrapping_add(-600 as i32 as i64 as u64)
    add64 r2, r3                                    r2 += r3   ///  r2 = r2.wrapping_add(r3)
    stxb [r2+0x32], r7                      
    stxb [r2+0x31], r9                      
    stxb [r2+0x30], r6                      
    mov64 r6, r5                                    r6 = r5
    add64 r6, 40                                    r6 += 40   ///  r6 = r6.wrapping_add(40 as i32 as i64 as u64)
    stxdw [r2+0x20], r6                     
    mov64 r6, r5                                    r6 = r5
    add64 r6, 88                                    r6 += 88   ///  r6 = r6.wrapping_add(88 as i32 as i64 as u64)
    stxdw [r2+0x18], r6                     
    stxdw [r2+0x10], r0                     
    add64 r5, 72                                    r5 += 72   ///  r5 = r5.wrapping_add(72 as i32 as i64 as u64)
    stxdw [r2+0x8], r5                      
    stdw [r2+0x28], 0                       
    add64 r4, 16                                    r4 += 16   ///  r4 = r4.wrapping_add(16 as i32 as i64 as u64)
    add64 r1, 8                                     r1 += 8   ///  r1 = r1.wrapping_add(8 as i32 as i64 as u64)
    add64 r3, 56                                    r3 += 56   ///  r3 = r3.wrapping_add(56 as i32 as i64 as u64)
    jeq r3, 560, lbb_9199                           if r3 == (560 as i32 as i64 as u64) { pc += 50 }
lbb_9149:
    mov64 r6, r10                                   r6 = r10
    add64 r6, -600                                  r6 += -600   ///  r6 = r6.wrapping_add(-600 as i32 as i64 as u64)
    mov64 r0, 1                                     r0 = 1 as i32 as i64 as u64
    ldxdw r2, [r1+0x0]                      
    ldxdw r5, [r2+0x0]                      
    ldxdw r7, [r4-0x8]                      
    ldxdw r2, [r7+0x0]                      
    ldxdw r8, [r5+0x8]                      
    jne r8, r2, lbb_9218                            if r8 != r2 { pc += 60 }
    ldxdw r2, [r7+0x8]                      
    ldxdw r8, [r5+0x10]                     
    jne r8, r2, lbb_9218                            if r8 != r2 { pc += 57 }
    ldxdw r2, [r7+0x10]                     
    ldxdw r8, [r5+0x18]                     
    jne r8, r2, lbb_9218                            if r8 != r2 { pc += 54 }
    ldxdw r2, [r7+0x18]                     
    ldxdw r7, [r5+0x20]                     
    jne r7, r2, lbb_9218                            if r7 != r2 { pc += 51 }
    ldxb r0, [r4+0x0]                       
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
    jne r0, 0, lbb_9171                             if r0 != (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r2, 119                                   r2 = 119 as i32 as i64 as u64
lbb_9171:
    ldxb r0, [r5+0x0]                       
    or64 r2, r0                                     r2 |= r0   ///  r2 = r2.or(r0)
    and64 r2, 255                                   r2 &= 255   ///  r2 = r2.and(255)
    jne r2, 255, lbb_9197                           if r2 != (255 as i32 as i64 as u64) { pc += 22 }
    add64 r6, r3                                    r6 += r3   ///  r6 = r6.wrapping_add(r3)
    mov64 r7, r5                                    r7 = r5
    add64 r7, 8                                     r7 += 8   ///  r7 = r7.wrapping_add(8 as i32 as i64 as u64)
    ldxdw r0, [r5+0x50]                     
    ldxb r8, [r5+0x3]                       
    ldxb r2, [r5+0x2]                       
    ldxb r9, [r5+0x1]                       
    stxdw [r6+0x0], r7                      
    mov64 r7, 1                                     r7 = 1 as i32 as i64 as u64
    mov64 r6, 1                                     r6 = 1 as i32 as i64 as u64
    jeq r9, 0, lbb_9190                             if r9 == (0 as i32 as i64 as u64) { pc += 4 }
    mov64 r9, 1                                     r9 = 1 as i32 as i64 as u64
    jeq r2, 0, lbb_9193                             if r2 == (0 as i32 as i64 as u64) { pc += 5 }
lbb_9188:
    jne r8, 0, lbb_9129                             if r8 != (0 as i32 as i64 as u64) { pc += -60 }
    ja lbb_9195                                     if true { pc += 5 }
lbb_9190:
    mov64 r6, 0                                     r6 = 0 as i32 as i64 as u64
    mov64 r9, 1                                     r9 = 1 as i32 as i64 as u64
    jne r2, 0, lbb_9188                             if r2 != (0 as i32 as i64 as u64) { pc += -5 }
lbb_9193:
    mov64 r9, 0                                     r9 = 0 as i32 as i64 as u64
    jne r8, 0, lbb_9129                             if r8 != (0 as i32 as i64 as u64) { pc += -66 }
lbb_9195:
    mov64 r7, 0                                     r7 = 0 as i32 as i64 as u64
    ja lbb_9129                                     if true { pc += -68 }
lbb_9197:
    mov64 r0, 11                                    r0 = 11 as i32 as i64 as u64
    ja lbb_9218                                     if true { pc += 19 }
lbb_9199:
    mov64 r1, r10                                   r1 = r10
    add64 r1, -697                                  r1 += -697   ///  r1 = r1.wrapping_add(-697 as i32 as i64 as u64)
    stxdw [r10-0x10], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -864                                  r1 += -864   ///  r1 = r1.wrapping_add(-864 as i32 as i64 as u64)
    stxdw [r10-0x20], r1                    
    ldxdw r1, [r10-0x368]                   
    stxdw [r10-0x28], r1                    
    stdw [r10-0x8], 17                      
    stdw [r10-0x18], 10                     
    mov64 r1, r10                                   r1 = r10
    add64 r1, -40                                   r1 += -40   ///  r1 = r1.wrapping_add(-40 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -600                                  r2 += -600   ///  r2 = r2.wrapping_add(-600 as i32 as i64 as u64)
    mov64 r3, 10                                    r3 = 10 as i32 as i64 as u64
    mov64 r4, 8                                     r4 = 8 as i32 as i64 as u64
    mov64 r5, 0                                     r5 = 0 as i32 as i64 as u64
    syscall [invalid]                       
    mov64 r0, 26                                    r0 = 26 as i32 as i64 as u64
lbb_9218:
    ldxdw r1, [r10-0x380]                   
lbb_9219:
    stxw [r1+0x0], r0                       
    stw [r1+0x4], 0                         
    exit                                    
lbb_9222:
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    mov64 r2, 1                                     r2 = 1 as i32 as i64 as u64
    lddw r3, 0x100027118 --> b"\x00\x00\x00\x00\xb8Y\x02\x00\x10\x00\x00\x00\x00\x00\x00\x00\x96!\x00\x0…        r3 load str located at 4295127320
    call function_18489                     
lbb_9227:
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
    lddw r3, 0x100027100 --> b"\x00\x00\x00\x00\xb8Y\x02\x00\x10\x00\x00\x00\x00\x00\x00\x00\x96!\x00\x0…        r3 load str located at 4295127296
    call function_18489                     
lbb_9232:
    mov64 r1, 2                                     r1 = 2 as i32 as i64 as u64
    mov64 r2, 2                                     r2 = 2 as i32 as i64 as u64
    lddw r3, 0x100027130 --> b"\x00\x00\x00\x00\xb8Y\x02\x00\x10\x00\x00\x00\x00\x00\x00\x00\x96!\x00\x0…        r3 load str located at 4295127344
    call function_18489                     
lbb_9237:
    mov64 r1, 3                                     r1 = 3 as i32 as i64 as u64
    mov64 r2, 3                                     r2 = 3 as i32 as i64 as u64
    lddw r3, 0x100027148 --> b"\x00\x00\x00\x00\xb8Y\x02\x00\x10\x00\x00\x00\x00\x00\x00\x00\x96!\x00\x0…        r3 load str located at 4295127368
    call function_18489                     
lbb_9242:
    mov64 r1, 4                                     r1 = 4 as i32 as i64 as u64
    mov64 r2, 4                                     r2 = 4 as i32 as i64 as u64
    lddw r3, 0x100027160 --> b"\x00\x00\x00\x00\xb8Y\x02\x00\x10\x00\x00\x00\x00\x00\x00\x00\x97!\x00\x0…        r3 load str located at 4295127392
    call function_18489                     
lbb_9247:
    mov64 r1, 5                                     r1 = 5 as i32 as i64 as u64
    mov64 r2, 5                                     r2 = 5 as i32 as i64 as u64
    lddw r3, 0x100027178 --> b"\x00\x00\x00\x00\xb8Y\x02\x00\x10\x00\x00\x00\x00\x00\x00\x00\x97!\x00\x0…        r3 load str located at 4295127416
    call function_18489                     
    ldxdw r3, [r2+0x8]                      
    jeq r3, 1, lbb_9546                             if r3 == (1 as i32 as i64 as u64) { pc += 292 }
    jeq r3, 0, lbb_9551                             if r3 == (0 as i32 as i64 as u64) { pc += 296 }
    jle r3, 2, lbb_9556                             if r3 <= (2 as i32 as i64 as u64) { pc += 300 }
    jeq r3, 3, lbb_9561                             if r3 == (3 as i32 as i64 as u64) { pc += 304 }
    jle r3, 4, lbb_9566                             if r3 <= (4 as i32 as i64 as u64) { pc += 308 }
    jeq r3, 5, lbb_9571                             if r3 == (5 as i32 as i64 as u64) { pc += 312 }
    jle r3, 6, lbb_9576                             if r3 <= (6 as i32 as i64 as u64) { pc += 316 }
    jeq r3, 7, lbb_9581                             if r3 == (7 as i32 as i64 as u64) { pc += 320 }
    jle r3, 8, lbb_9586                             if r3 <= (8 as i32 as i64 as u64) { pc += 324 }
    jeq r3, 9, lbb_9591                             if r3 == (9 as i32 as i64 as u64) { pc += 328 }
    ldxdw r3, [r2+0x50]                     
    mov64 r5, 3                                     r5 = 3 as i32 as i64 as u64
    stxdw [r10-0x500], r3                   
    ldxdw r6, [r3+0x0]                      
    ldxdw r3, [r6+0x50]                     
    jlt r3, 32, lbb_9543                            if r3 < (32 as i32 as i64 as u64) { pc += 274 }
    ldxdw r0, [r2+0x0]                      
    mov64 r3, r0                                    r3 = r0
    add64 r3, 16                                    r3 += 16   ///  r3 = r3.wrapping_add(16 as i32 as i64 as u64)
    ldxdw r8, [r3+0x0]                      
    ldxdw r4, [r8+0x50]                     
    jlt r4, 32, lbb_9543                            if r4 < (32 as i32 as i64 as u64) { pc += 268 }
    ldxdw r7, [r2+0x58]                     
    mov64 r5, r8                                    r5 = r8
    ldxdw r8, [r2+0x48]                     
    ldxdw r4, [r2+0x30]                     
    stxdw [r10-0x528], r4                   
    ldxdw r4, [r2+0x28]                     
    stxdw [r10-0x508], r4                   
    ldxdw r4, [r2+0x20]                     
    stxdw [r10-0x540], r4                   
    ldxdw r2, [r2+0x10]                     
    stxdw [r10-0x560], r2                   
    mov64 r2, r0                                    r2 = r0
    add64 r2, 72                                    r2 += 72   ///  r2 = r2.wrapping_add(72 as i32 as i64 as u64)
    stxdw [r10-0x538], r2                   
    mov64 r9, r0                                    r9 = r0
    add64 r9, 8                                     r9 += 8   ///  r9 = r9.wrapping_add(8 as i32 as i64 as u64)
    mov64 r2, r0                                    r2 = r0
    add64 r2, 24                                    r2 += 24   ///  r2 = r2.wrapping_add(24 as i32 as i64 as u64)
    stxdw [r10-0x530], r2                   
    mov64 r2, r0                                    r2 = r0
    add64 r2, 32                                    r2 += 32   ///  r2 = r2.wrapping_add(32 as i32 as i64 as u64)
    stxdw [r10-0x548], r2                   
    mov64 r2, r0                                    r2 = r0
    add64 r2, 40                                    r2 += 40   ///  r2 = r2.wrapping_add(40 as i32 as i64 as u64)
    stxdw [r10-0x550], r2                   
    mov64 r2, r0                                    r2 = r0
    add64 r2, 48                                    r2 += 48   ///  r2 = r2.wrapping_add(48 as i32 as i64 as u64)
    stxdw [r10-0x558], r2                   
    mov64 r2, r0                                    r2 = r0
    add64 r2, 56                                    r2 += 56   ///  r2 = r2.wrapping_add(56 as i32 as i64 as u64)
    stxdw [r10-0x568], r2                   
    mov64 r2, r0                                    r2 = r0
    add64 r2, 64                                    r2 += 64   ///  r2 = r2.wrapping_add(64 as i32 as i64 as u64)
    stxdw [r10-0x570], r2                   
    ldxdw r2, [r5+0x58]                     
    ldxdw r4, [r6+0x58]                     
    stxdw [r10-0x510], r1                   
    stxdw [r10-0x518], r3                   
    stxdw [r10-0x520], r9                   
    jne r4, r2, lbb_9328                            if r4 != r2 { pc += 13 }
    ldxdw r2, [r5+0x60]                     
    ldxdw r4, [r6+0x60]                     
    jne r4, r2, lbb_9328                            if r4 != r2 { pc += 10 }
    ldxdw r2, [r5+0x68]                     
    ldxdw r4, [r6+0x68]                     
    jne r4, r2, lbb_9328                            if r4 != r2 { pc += 7 }
    mov64 r4, r5                                    r4 = r5
    ldxdw r2, [r5+0x70]                     
    ldxdw r1, [r6+0x70]                     
    jne r1, r2, lbb_9329                            if r1 != r2 { pc += 4 }
    ldxdw r1, [r10-0x500]                   
    stxdw [r10-0x500], r7                   
    ja lbb_9330                                     if true { pc += 2 }
lbb_9328:
    mov64 r4, r5                                    r4 = r5
lbb_9329:
    mov64 r1, r7                                    r1 = r7
lbb_9330:
    stxdw [r10-0x580], r1                   
    add64 r4, 8                                     r4 += 8   ///  r4 = r4.wrapping_add(8 as i32 as i64 as u64)
    ldxdw r2, [r8+0x0]                      
    stxdw [r10-0x588], r2                   
    ldxdw r2, [r0+0x0]                      
    stxdw [r10-0x590], r2                   
    ldxdw r2, [r0+0x8]                      
    stxdw [r10-0x598], r2                   
    ldxdw r1, [r1+0x0]                      
    stxdw [r10-0x5a0], r1                   
    ldxdw r1, [r10-0x500]                   
    ldxdw r1, [r1+0x0]                      
    stxdw [r10-0x5a8], r1                   
    ldxdw r1, [r0+0x18]                     
    stxdw [r10-0x5b0], r1                   
    ldxdw r1, [r0+0x20]                     
    stxdw [r10-0x5b8], r1                   
    ldxdw r5, [r0+0x28]                     
    stxdw [r10-0x578], r8                   
    ldxdw r8, [r0+0x30]                     
    ldxdw r9, [r0+0x38]                     
    ldxdw r6, [r0+0x40]                     
    ldxdw r7, [r0+0x48]                     
    ldxdw r1, [r10-0x508]                   
    ldxdw r1, [r1+0x0]                      
    ldxdw r2, [r10-0x528]                   
    ldxdw r3, [r2+0x0]                      
    stxdw [r10-0x4a8], r4                   
    add64 r3, 8                                     r3 += 8   ///  r3 = r3.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x418], r3                   
    add64 r1, 8                                     r1 += 8   ///  r1 = r1.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x428], r1                   
    add64 r7, 8                                     r7 += 8   ///  r7 = r7.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x438], r7                   
    add64 r6, 8                                     r6 += 8   ///  r6 = r6.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x448], r6                   
    add64 r9, 8                                     r9 += 8   ///  r9 = r9.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x458], r9                   
    add64 r8, 8                                     r8 += 8   ///  r8 = r8.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x468], r8                   
    add64 r5, 8                                     r5 += 8   ///  r5 = r5.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x478], r5                   
    ldxdw r1, [r10-0x5b8]                   
    add64 r1, 8                                     r1 += 8   ///  r1 = r1.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x488], r1                   
    ldxdw r1, [r10-0x5b0]                   
    add64 r1, 8                                     r1 += 8   ///  r1 = r1.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x498], r1                   
    ldxdw r1, [r10-0x5a8]                   
    add64 r1, 8                                     r1 += 8   ///  r1 = r1.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x4b8], r1                   
    ldxdw r1, [r10-0x5a0]                   
    add64 r1, 8                                     r1 += 8   ///  r1 = r1.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x4c8], r1                   
    ldxdw r1, [r10-0x598]                   
    add64 r1, 8                                     r1 += 8   ///  r1 = r1.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x4d8], r1                   
    ldxdw r1, [r10-0x590]                   
    add64 r1, 8                                     r1 += 8   ///  r1 = r1.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x4e8], r1                   
    ldxdw r1, [r10-0x588]                   
    add64 r1, 8                                     r1 += 8   ///  r1 = r1.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x4f8], r1                   
    sth [r10-0x410], 0                      
    sth [r10-0x420], 0                      
    sth [r10-0x430], 0                      
    sth [r10-0x440], 0                      
    sth [r10-0x450], 0                      
    sth [r10-0x460], 0                      
    sth [r10-0x470], 1                      
    sth [r10-0x480], 1                      
    sth [r10-0x490], 1                      
    sth [r10-0x4a0], 1                      
    sth [r10-0x4b0], 1                      
    sth [r10-0x4c0], 1                      
    sth [r10-0x4d0], 0                      
    sth [r10-0x4e0], 0                      
    sth [r10-0x4f0], 257                    
    ldxdw r1, [r10-0x560]                   
    stxdw [r10-0x3ff], r1                   
    lddw r1, 0x621ec91a0bed042b                     r1 load str located at 7070309578724672555
    stxdw [r10-0x408], r1                   
    stb [r10-0x400], 1                      
    stdw [r10-0x3f7], 0                     
    ldxdw r1, [r10-0x540]                   
    ldxdw r4, [r1+0x0]                      
    stxdw [r10-0x378], r2                   
    ldxdw r1, [r10-0x508]                   
    stxdw [r10-0x380], r1                   
    ldxdw r1, [r10-0x538]                   
    stxdw [r10-0x388], r1                   
    ldxdw r1, [r10-0x570]                   
    stxdw [r10-0x390], r1                   
    ldxdw r1, [r10-0x568]                   
    stxdw [r10-0x398], r1                   
    ldxdw r1, [r10-0x558]                   
    stxdw [r10-0x3a0], r1                   
    ldxdw r1, [r10-0x550]                   
    stxdw [r10-0x3a8], r1                   
    ldxdw r1, [r10-0x548]                   
    stxdw [r10-0x3b0], r1                   
    ldxdw r1, [r10-0x530]                   
    stxdw [r10-0x3b8], r1                   
    ldxdw r1, [r10-0x518]                   
    stxdw [r10-0x3c0], r1                   
    ldxdw r1, [r10-0x500]                   
    stxdw [r10-0x3c8], r1                   
    ldxdw r1, [r10-0x580]                   
    stxdw [r10-0x3d0], r1                   
    ldxdw r1, [r10-0x520]                   
    stxdw [r10-0x3d8], r1                   
    stxdw [r10-0x3e0], r0                   
    ldxdw r1, [r10-0x578]                   
    stxdw [r10-0x3e8], r1                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -1000                                 r1 += -1000   ///  r1 = r1.wrapping_add(-1000 as i32 as i64 as u64)
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
    mov64 r3, r10                                   r3 = r10
    add64 r3, -1264                                 r3 += -1264   ///  r3 = r3.wrapping_add(-1264 as i32 as i64 as u64)
    add64 r4, 8                                     r4 += 8   ///  r4 = r4.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x500], r4                   
    ja lbb_9473                                     if true { pc += 20 }
lbb_9453:
    mov64 r7, r10                                   r7 = r10
    add64 r7, -880                                  r7 += -880   ///  r7 = r7.wrapping_add(-880 as i32 as i64 as u64)
    add64 r7, r2                                    r7 += r2   ///  r7 = r7.wrapping_add(r2)
    stxb [r7+0x32], r6                      
    stxb [r7+0x31], r8                      
    stxb [r7+0x30], r0                      
    mov64 r0, r4                                    r0 = r4
    add64 r0, 40                                    r0 += 40   ///  r0 = r0.wrapping_add(40 as i32 as i64 as u64)
    stxdw [r7+0x20], r0                     
    mov64 r0, r4                                    r0 = r4
    add64 r0, 88                                    r0 += 88   ///  r0 = r0.wrapping_add(88 as i32 as i64 as u64)
    stxdw [r7+0x18], r0                     
    stxdw [r7+0x10], r5                     
    add64 r4, 72                                    r4 += 72   ///  r4 = r4.wrapping_add(72 as i32 as i64 as u64)
    stxdw [r7+0x8], r4                      
    stdw [r7+0x28], 0                       
    add64 r3, 16                                    r3 += 16   ///  r3 = r3.wrapping_add(16 as i32 as i64 as u64)
    add64 r1, 8                                     r1 += 8   ///  r1 = r1.wrapping_add(8 as i32 as i64 as u64)
    add64 r2, 56                                    r2 += 56   ///  r2 = r2.wrapping_add(56 as i32 as i64 as u64)
    jeq r2, 840, lbb_9523                           if r2 == (840 as i32 as i64 as u64) { pc += 50 }
lbb_9473:
    mov64 r0, r10                                   r0 = r10
    add64 r0, -880                                  r0 += -880   ///  r0 = r0.wrapping_add(-880 as i32 as i64 as u64)
    mov64 r5, 1                                     r5 = 1 as i32 as i64 as u64
    ldxdw r4, [r1+0x0]                      
    ldxdw r4, [r4+0x0]                      
    ldxdw r6, [r3-0x8]                      
    ldxdw r7, [r6+0x0]                      
    ldxdw r8, [r4+0x8]                      
    jne r8, r7, lbb_9542                            if r8 != r7 { pc += 60 }
    ldxdw r7, [r6+0x8]                      
    ldxdw r8, [r4+0x10]                     
    jne r8, r7, lbb_9542                            if r8 != r7 { pc += 57 }
    ldxdw r7, [r6+0x10]                     
    ldxdw r8, [r4+0x18]                     
    jne r8, r7, lbb_9542                            if r8 != r7 { pc += 54 }
    ldxdw r6, [r6+0x18]                     
    ldxdw r7, [r4+0x20]                     
    jne r7, r6, lbb_9542                            if r7 != r6 { pc += 51 }
    ldxb r6, [r3+0x0]                       
    mov64 r5, 0                                     r5 = 0 as i32 as i64 as u64
    jne r6, 0, lbb_9495                             if r6 != (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r5, 119                                   r5 = 119 as i32 as i64 as u64
lbb_9495:
    ldxb r6, [r4+0x0]                       
    or64 r5, r6                                     r5 |= r6   ///  r5 = r5.or(r6)
    and64 r5, 255                                   r5 &= 255   ///  r5 = r5.and(255)
    jne r5, 255, lbb_9521                           if r5 != (255 as i32 as i64 as u64) { pc += 22 }
    add64 r0, r2                                    r0 += r2   ///  r0 = r0.wrapping_add(r2)
    mov64 r6, r4                                    r6 = r4
    add64 r6, 8                                     r6 += 8   ///  r6 = r6.wrapping_add(8 as i32 as i64 as u64)
    ldxdw r5, [r4+0x50]                     
    ldxb r7, [r4+0x3]                       
    ldxb r9, [r4+0x2]                       
    ldxb r8, [r4+0x1]                       
    stxdw [r0+0x0], r6                      
    mov64 r6, 1                                     r6 = 1 as i32 as i64 as u64
    mov64 r0, 1                                     r0 = 1 as i32 as i64 as u64
    jeq r8, 0, lbb_9514                             if r8 == (0 as i32 as i64 as u64) { pc += 4 }
    mov64 r8, 1                                     r8 = 1 as i32 as i64 as u64
    jeq r9, 0, lbb_9517                             if r9 == (0 as i32 as i64 as u64) { pc += 5 }
lbb_9512:
    jne r7, 0, lbb_9453                             if r7 != (0 as i32 as i64 as u64) { pc += -60 }
    ja lbb_9519                                     if true { pc += 5 }
lbb_9514:
    mov64 r0, 0                                     r0 = 0 as i32 as i64 as u64
    mov64 r8, 1                                     r8 = 1 as i32 as i64 as u64
    jne r9, 0, lbb_9512                             if r9 != (0 as i32 as i64 as u64) { pc += -5 }
lbb_9517:
    mov64 r8, 0                                     r8 = 0 as i32 as i64 as u64
    jne r7, 0, lbb_9453                             if r7 != (0 as i32 as i64 as u64) { pc += -66 }
lbb_9519:
    mov64 r6, 0                                     r6 = 0 as i32 as i64 as u64
    ja lbb_9453                                     if true { pc += -68 }
lbb_9521:
    mov64 r5, 11                                    r5 = 11 as i32 as i64 as u64
    ja lbb_9542                                     if true { pc += 19 }
lbb_9523:
    mov64 r1, r10                                   r1 = r10
    add64 r1, -1032                                 r1 += -1032   ///  r1 = r1.wrapping_add(-1032 as i32 as i64 as u64)
    stxdw [r10-0x10], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -1272                                 r1 += -1272   ///  r1 = r1.wrapping_add(-1272 as i32 as i64 as u64)
    stxdw [r10-0x20], r1                    
    ldxdw r1, [r10-0x500]                   
    stxdw [r10-0x28], r1                    
    stdw [r10-0x8], 25                      
    stdw [r10-0x18], 15                     
    mov64 r1, r10                                   r1 = r10
    add64 r1, -40                                   r1 += -40   ///  r1 = r1.wrapping_add(-40 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -880                                  r2 += -880   ///  r2 = r2.wrapping_add(-880 as i32 as i64 as u64)
    mov64 r3, 15                                    r3 = 15 as i32 as i64 as u64
    mov64 r4, 8                                     r4 = 8 as i32 as i64 as u64
    mov64 r5, 0                                     r5 = 0 as i32 as i64 as u64
    syscall [invalid]                       
    mov64 r5, 26                                    r5 = 26 as i32 as i64 as u64
lbb_9542:
    ldxdw r1, [r10-0x510]                   
lbb_9543:
    stxw [r1+0x0], r5                       
    stw [r1+0x4], 0                         
    exit                                    
lbb_9546:
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    mov64 r2, 1                                     r2 = 1 as i32 as i64 as u64
    lddw r3, 0x1000271a8 --> b"\x00\x00\x00\x00\xb8Y\x02\x00\x10\x00\x00\x00\x00\x00\x00\x00\xa3!\x00\x0…        r3 load str located at 4295127464
    call function_18489                     
lbb_9551:
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
    lddw r3, 0x100027190 --> b"\x00\x00\x00\x00\xb8Y\x02\x00\x10\x00\x00\x00\x00\x00\x00\x00\xa3!\x00\x0…        r3 load str located at 4295127440
    call function_18489                     
lbb_9556:
    mov64 r1, 2                                     r1 = 2 as i32 as i64 as u64
    mov64 r2, 2                                     r2 = 2 as i32 as i64 as u64
    lddw r3, 0x1000271c0 --> b"\x00\x00\x00\x00\xb8Y\x02\x00\x10\x00\x00\x00\x00\x00\x00\x00\xa3!\x00\x0…        r3 load str located at 4295127488
    call function_18489                     
lbb_9561:
    mov64 r1, 3                                     r1 = 3 as i32 as i64 as u64
    mov64 r2, 3                                     r2 = 3 as i32 as i64 as u64
    lddw r3, 0x1000271d8 --> b"\x00\x00\x00\x00\xb8Y\x02\x00\x10\x00\x00\x00\x00\x00\x00\x00\xa3!\x00\x0…        r3 load str located at 4295127512
    call function_18489                     
lbb_9566:
    mov64 r1, 4                                     r1 = 4 as i32 as i64 as u64
    mov64 r2, 4                                     r2 = 4 as i32 as i64 as u64
    lddw r3, 0x1000271f0 --> b"\x00\x00\x00\x00\xb8Y\x02\x00\x10\x00\x00\x00\x00\x00\x00\x00\xa4!\x00\x0…        r3 load str located at 4295127536
    call function_18489                     
lbb_9571:
    mov64 r1, 5                                     r1 = 5 as i32 as i64 as u64
    mov64 r2, 5                                     r2 = 5 as i32 as i64 as u64
    lddw r3, 0x100027208 --> b"\x00\x00\x00\x00\xb8Y\x02\x00\x10\x00\x00\x00\x00\x00\x00\x00\xa4!\x00\x0…        r3 load str located at 4295127560
    call function_18489                     
lbb_9576:
    mov64 r1, 6                                     r1 = 6 as i32 as i64 as u64
    mov64 r2, 6                                     r2 = 6 as i32 as i64 as u64
    lddw r3, 0x100027220 --> b"\x00\x00\x00\x00\xb8Y\x02\x00\x10\x00\x00\x00\x00\x00\x00\x00\xa4!\x00\x0…        r3 load str located at 4295127584
    call function_18489                     
lbb_9581:
    mov64 r1, 7                                     r1 = 7 as i32 as i64 as u64
    mov64 r2, 7                                     r2 = 7 as i32 as i64 as u64
    lddw r3, 0x100027238 --> b"\x00\x00\x00\x00\xb8Y\x02\x00\x10\x00\x00\x00\x00\x00\x00\x00\xa4!\x00\x0…        r3 load str located at 4295127608
    call function_18489                     
lbb_9586:
    mov64 r1, 8                                     r1 = 8 as i32 as i64 as u64
    mov64 r2, 8                                     r2 = 8 as i32 as i64 as u64
    lddw r3, 0x100027250 --> b"\x00\x00\x00\x00\xb8Y\x02\x00\x10\x00\x00\x00\x00\x00\x00\x00\xa5!\x00\x0…        r3 load str located at 4295127632
    call function_18489                     
lbb_9591:
    mov64 r1, 9                                     r1 = 9 as i32 as i64 as u64
    mov64 r2, 9                                     r2 = 9 as i32 as i64 as u64
    lddw r3, 0x100027268 --> b"\x00\x00\x00\x00\xb8Y\x02\x00\x10\x00\x00\x00\x00\x00\x00\x00\xa5!\x00\x0…        r3 load str located at 4295127656
    call function_18489                     
    ldxdw r3, [r2+0x8]                      
    jeq r3, 1, lbb_9821                             if r3 == (1 as i32 as i64 as u64) { pc += 223 }
    jeq r3, 0, lbb_9826                             if r3 == (0 as i32 as i64 as u64) { pc += 227 }
    jle r3, 2, lbb_9831                             if r3 <= (2 as i32 as i64 as u64) { pc += 231 }
    jeq r3, 3, lbb_9836                             if r3 == (3 as i32 as i64 as u64) { pc += 235 }
    jle r3, 4, lbb_9841                             if r3 <= (4 as i32 as i64 as u64) { pc += 239 }
    jeq r3, 5, lbb_9846                             if r3 == (5 as i32 as i64 as u64) { pc += 243 }
    jle r3, 6, lbb_9851                             if r3 <= (6 as i32 as i64 as u64) { pc += 247 }
    jeq r3, 7, lbb_9856                             if r3 == (7 as i32 as i64 as u64) { pc += 251 }
    stxdw [r10-0x458], r1                   
    jle r3, 8, lbb_9861                             if r3 <= (8 as i32 as i64 as u64) { pc += 254 }
    ldxdw r3, [r2+0x0]                      
    ldxdw r0, [r2+0x58]                     
    stxdw [r10-0x470], r0                   
    ldxdw r4, [r2+0x50]                     
    stxdw [r10-0x468], r4                   
    ldxdw r1, [r2+0x48]                     
    stxdw [r10-0x460], r1                   
    ldxdw r9, [r2+0x28]                     
    ldxdw r5, [r2+0x20]                     
    stxdw [r10-0x478], r5                   
    ldxdw r2, [r2+0x10]                     
    stxdw [r10-0x480], r2                   
    ldxdw r5, [r3+0x40]                     
    add64 r5, 8                                     r5 += 8   ///  r5 = r5.wrapping_add(8 as i32 as i64 as u64)
    ldxdw r2, [r3+0x0]                      
    stxdw [r10-0x488], r2                   
    ldxdw r2, [r3+0x8]                      
    stxdw [r10-0x490], r2                   
    ldxdw r1, [r1+0x0]                      
    stxdw [r10-0x498], r1                   
    ldxdw r1, [r4+0x0]                      
    stxdw [r10-0x4a0], r1                   
    ldxdw r1, [r0+0x0]                      
    stxdw [r10-0x4a8], r1                   
    ldxdw r8, [r3+0x10]                     
    ldxdw r7, [r3+0x18]                     
    ldxdw r6, [r3+0x20]                     
    ldxdw r0, [r3+0x28]                     
    ldxdw r4, [r9+0x0]                      
    ldxdw r2, [r3+0x30]                     
    ldxdw r1, [r3+0x38]                     
    stxdw [r10-0x390], r5                   
    add64 r1, 8                                     r1 += 8   ///  r1 = r1.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x3a0], r1                   
    add64 r2, 8                                     r2 += 8   ///  r2 = r2.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x3b0], r2                   
    add64 r4, 8                                     r4 += 8   ///  r4 = r4.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x3c0], r4                   
    add64 r0, 8                                     r0 += 8   ///  r0 = r0.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x3d0], r0                   
    add64 r6, 8                                     r6 += 8   ///  r6 = r6.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x3e0], r6                   
    add64 r7, 8                                     r7 += 8   ///  r7 = r7.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x3f0], r7                   
    add64 r8, 8                                     r8 += 8   ///  r8 = r8.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x400], r8                   
    ldxdw r1, [r10-0x4a8]                   
    add64 r1, 8                                     r1 += 8   ///  r1 = r1.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x410], r1                   
    ldxdw r1, [r10-0x4a0]                   
    add64 r1, 8                                     r1 += 8   ///  r1 = r1.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x420], r1                   
    ldxdw r1, [r10-0x498]                   
    add64 r1, 8                                     r1 += 8   ///  r1 = r1.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x430], r1                   
    ldxdw r1, [r10-0x490]                   
    add64 r1, 8                                     r1 += 8   ///  r1 = r1.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x440], r1                   
    ldxdw r1, [r10-0x488]                   
    add64 r1, 8                                     r1 += 8   ///  r1 = r1.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x450], r1                   
    sth [r10-0x388], 0                      
    sth [r10-0x398], 0                      
    sth [r10-0x3a8], 0                      
    sth [r10-0x3b8], 0                      
    sth [r10-0x3c8], 1                      
    sth [r10-0x3d8], 1                      
    sth [r10-0x3e8], 1                      
    sth [r10-0x3f8], 1                      
    sth [r10-0x408], 1                      
    sth [r10-0x418], 1                      
    sth [r10-0x428], 257                    
    sth [r10-0x438], 1                      
    sth [r10-0x448], 0                      
    ldxdw r1, [r10-0x480]                   
    stxdw [r10-0x378], r1                   
    lddw r1, 0xc88775e1919ec6f8                     r1 load str located at -3997096532596832520
    stxdw [r10-0x380], r1                   
    stdw [r10-0x370], 0                     
    ldxdw r1, [r10-0x478]                   
    ldxdw r5, [r1+0x0]                      
    mov64 r1, r3                                    r1 = r3
    add64 r1, 64                                    r1 += 64   ///  r1 = r1.wrapping_add(64 as i32 as i64 as u64)
    stxdw [r10-0x308], r1                   
    mov64 r1, r3                                    r1 = r3
    add64 r1, 56                                    r1 += 56   ///  r1 = r1.wrapping_add(56 as i32 as i64 as u64)
    stxdw [r10-0x310], r1                   
    mov64 r1, r3                                    r1 = r3
    add64 r1, 48                                    r1 += 48   ///  r1 = r1.wrapping_add(48 as i32 as i64 as u64)
    stxdw [r10-0x318], r1                   
    stxdw [r10-0x320], r9                   
    mov64 r1, r3                                    r1 = r3
    add64 r1, 40                                    r1 += 40   ///  r1 = r1.wrapping_add(40 as i32 as i64 as u64)
    stxdw [r10-0x328], r1                   
    mov64 r1, r3                                    r1 = r3
    add64 r1, 32                                    r1 += 32   ///  r1 = r1.wrapping_add(32 as i32 as i64 as u64)
    stxdw [r10-0x330], r1                   
    mov64 r1, r3                                    r1 = r3
    add64 r1, 24                                    r1 += 24   ///  r1 = r1.wrapping_add(24 as i32 as i64 as u64)
    stxdw [r10-0x338], r1                   
    mov64 r1, r3                                    r1 = r3
    add64 r1, 16                                    r1 += 16   ///  r1 = r1.wrapping_add(16 as i32 as i64 as u64)
    stxdw [r10-0x340], r1                   
    ldxdw r1, [r10-0x470]                   
    stxdw [r10-0x348], r1                   
    ldxdw r1, [r10-0x468]                   
    stxdw [r10-0x350], r1                   
    ldxdw r1, [r10-0x460]                   
    stxdw [r10-0x358], r1                   
    mov64 r1, r3                                    r1 = r3
    add64 r1, 8                                     r1 += 8   ///  r1 = r1.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x360], r1                   
    stxdw [r10-0x368], r3                   
    mov64 r2, r10                                   r2 = r10
    add64 r2, -872                                  r2 += -872   ///  r2 = r2.wrapping_add(-872 as i32 as i64 as u64)
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
    mov64 r4, r10                                   r4 = r10
    add64 r4, -1096                                 r4 += -1096   ///  r4 = r4.wrapping_add(-1096 as i32 as i64 as u64)
    add64 r5, 8                                     r5 += 8   ///  r5 = r5.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x460], r5                   
    ja lbb_9749                                     if true { pc += 20 }
lbb_9729:
    mov64 r1, r10                                   r1 = r10
    add64 r1, -768                                  r1 += -768   ///  r1 = r1.wrapping_add(-768 as i32 as i64 as u64)
    add64 r1, r3                                    r1 += r3   ///  r1 = r1.wrapping_add(r3)
    stxb [r1+0x32], r7                      
    stxb [r1+0x31], r9                      
    stxb [r1+0x30], r0                      
    mov64 r0, r5                                    r0 = r5
    add64 r0, 40                                    r0 += 40   ///  r0 = r0.wrapping_add(40 as i32 as i64 as u64)
    stxdw [r1+0x20], r0                     
    mov64 r0, r5                                    r0 = r5
    add64 r0, 88                                    r0 += 88   ///  r0 = r0.wrapping_add(88 as i32 as i64 as u64)
    stxdw [r1+0x18], r0                     
    stxdw [r1+0x10], r6                     
    add64 r5, 72                                    r5 += 72   ///  r5 = r5.wrapping_add(72 as i32 as i64 as u64)
    stxdw [r1+0x8], r5                      
    stdw [r1+0x28], 0                       
    add64 r4, 16                                    r4 += 16   ///  r4 = r4.wrapping_add(16 as i32 as i64 as u64)
    add64 r2, 8                                     r2 += 8   ///  r2 = r2.wrapping_add(8 as i32 as i64 as u64)
    add64 r3, 56                                    r3 += 56   ///  r3 = r3.wrapping_add(56 as i32 as i64 as u64)
    jeq r3, 728, lbb_9799                           if r3 == (728 as i32 as i64 as u64) { pc += 50 }
lbb_9749:
    mov64 r0, r10                                   r0 = r10
    add64 r0, -768                                  r0 += -768   ///  r0 = r0.wrapping_add(-768 as i32 as i64 as u64)
    mov64 r7, 1                                     r7 = 1 as i32 as i64 as u64
    ldxdw r1, [r2+0x0]                      
    ldxdw r5, [r1+0x0]                      
    ldxdw r6, [r4-0x8]                      
    ldxdw r1, [r6+0x0]                      
    ldxdw r8, [r5+0x8]                      
    jne r8, r1, lbb_9818                            if r8 != r1 { pc += 60 }
    ldxdw r1, [r6+0x8]                      
    ldxdw r8, [r5+0x10]                     
    jne r8, r1, lbb_9818                            if r8 != r1 { pc += 57 }
    ldxdw r1, [r6+0x10]                     
    ldxdw r8, [r5+0x18]                     
    jne r8, r1, lbb_9818                            if r8 != r1 { pc += 54 }
    ldxdw r1, [r6+0x18]                     
    ldxdw r6, [r5+0x20]                     
    jne r6, r1, lbb_9818                            if r6 != r1 { pc += 51 }
    ldxb r6, [r4+0x0]                       
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    jne r6, 0, lbb_9771                             if r6 != (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r1, 119                                   r1 = 119 as i32 as i64 as u64
lbb_9771:
    ldxb r6, [r5+0x0]                       
    or64 r1, r6                                     r1 |= r6   ///  r1 = r1.or(r6)
    and64 r1, 255                                   r1 &= 255   ///  r1 = r1.and(255)
    jne r1, 255, lbb_9797                           if r1 != (255 as i32 as i64 as u64) { pc += 22 }
    add64 r0, r3                                    r0 += r3   ///  r0 = r0.wrapping_add(r3)
    mov64 r7, r5                                    r7 = r5
    add64 r7, 8                                     r7 += 8   ///  r7 = r7.wrapping_add(8 as i32 as i64 as u64)
    ldxdw r6, [r5+0x50]                     
    ldxb r8, [r5+0x3]                       
    ldxb r1, [r5+0x2]                       
    ldxb r9, [r5+0x1]                       
    stxdw [r0+0x0], r7                      
    mov64 r7, 1                                     r7 = 1 as i32 as i64 as u64
    mov64 r0, 1                                     r0 = 1 as i32 as i64 as u64
    jeq r9, 0, lbb_9790                             if r9 == (0 as i32 as i64 as u64) { pc += 4 }
    mov64 r9, 1                                     r9 = 1 as i32 as i64 as u64
    jeq r1, 0, lbb_9793                             if r1 == (0 as i32 as i64 as u64) { pc += 5 }
lbb_9788:
    jne r8, 0, lbb_9729                             if r8 != (0 as i32 as i64 as u64) { pc += -60 }
    ja lbb_9795                                     if true { pc += 5 }
lbb_9790:
    mov64 r0, 0                                     r0 = 0 as i32 as i64 as u64
    mov64 r9, 1                                     r9 = 1 as i32 as i64 as u64
    jne r1, 0, lbb_9788                             if r1 != (0 as i32 as i64 as u64) { pc += -5 }
lbb_9793:
    mov64 r9, 0                                     r9 = 0 as i32 as i64 as u64
    jne r8, 0, lbb_9729                             if r8 != (0 as i32 as i64 as u64) { pc += -66 }
lbb_9795:
    mov64 r7, 0                                     r7 = 0 as i32 as i64 as u64
    ja lbb_9729                                     if true { pc += -68 }
lbb_9797:
    mov64 r7, 11                                    r7 = 11 as i32 as i64 as u64
    ja lbb_9818                                     if true { pc += 19 }
lbb_9799:
    mov64 r1, r10                                   r1 = r10
    add64 r1, -896                                  r1 += -896   ///  r1 = r1.wrapping_add(-896 as i32 as i64 as u64)
    stxdw [r10-0x10], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -1104                                 r1 += -1104   ///  r1 = r1.wrapping_add(-1104 as i32 as i64 as u64)
    stxdw [r10-0x20], r1                    
    ldxdw r1, [r10-0x460]                   
    stxdw [r10-0x28], r1                    
    stdw [r10-0x8], 24                      
    stdw [r10-0x18], 13                     
    mov64 r1, r10                                   r1 = r10
    add64 r1, -40                                   r1 += -40   ///  r1 = r1.wrapping_add(-40 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -768                                  r2 += -768   ///  r2 = r2.wrapping_add(-768 as i32 as i64 as u64)
    mov64 r3, 13                                    r3 = 13 as i32 as i64 as u64
    mov64 r4, 8                                     r4 = 8 as i32 as i64 as u64
    mov64 r5, 0                                     r5 = 0 as i32 as i64 as u64
    syscall [invalid]                       
    mov64 r7, 26                                    r7 = 26 as i32 as i64 as u64
lbb_9818:
    ldxdw r1, [r10-0x458]                   
    stxw [r1+0x0], r7                       
    exit                                    
lbb_9821:
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    mov64 r2, 1                                     r2 = 1 as i32 as i64 as u64
    lddw r3, 0x100027298 --> b"\x00\x00\x00\x00\xb8Y\x02\x00\x10\x00\x00\x00\x00\x00\x00\x00\xb7!\x00\x0…        r3 load str located at 4295127704
    call function_18489                     
lbb_9826:
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
    lddw r3, 0x100027280 --> b"\x00\x00\x00\x00\xb8Y\x02\x00\x10\x00\x00\x00\x00\x00\x00\x00\xb7!\x00\x0…        r3 load str located at 4295127680
    call function_18489                     
lbb_9831:
    mov64 r1, 2                                     r1 = 2 as i32 as i64 as u64
    mov64 r2, 2                                     r2 = 2 as i32 as i64 as u64
    lddw r3, 0x1000272b0 --> b"\x00\x00\x00\x00\xb8Y\x02\x00\x10\x00\x00\x00\x00\x00\x00\x00\xb7!\x00\x0…        r3 load str located at 4295127728
    call function_18489                     
lbb_9836:
    mov64 r1, 3                                     r1 = 3 as i32 as i64 as u64
    mov64 r2, 3                                     r2 = 3 as i32 as i64 as u64
    lddw r3, 0x1000272c8 --> b"\x00\x00\x00\x00\xb8Y\x02\x00\x10\x00\x00\x00\x00\x00\x00\x00\xb7!\x00\x0…        r3 load str located at 4295127752
    call function_18489                     
lbb_9841:
    mov64 r1, 4                                     r1 = 4 as i32 as i64 as u64
    mov64 r2, 4                                     r2 = 4 as i32 as i64 as u64
    lddw r3, 0x1000272e0 --> b"\x00\x00\x00\x00\xb8Y\x02\x00\x10\x00\x00\x00\x00\x00\x00\x00\xb8!\x00\x0…        r3 load str located at 4295127776
    call function_18489                     
lbb_9846:
    mov64 r1, 5                                     r1 = 5 as i32 as i64 as u64
    mov64 r2, 5                                     r2 = 5 as i32 as i64 as u64
    lddw r3, 0x1000272f8 --> b"\x00\x00\x00\x00\xb8Y\x02\x00\x10\x00\x00\x00\x00\x00\x00\x00\xb8!\x00\x0…        r3 load str located at 4295127800
    call function_18489                     
lbb_9851:
    mov64 r1, 6                                     r1 = 6 as i32 as i64 as u64
    mov64 r2, 6                                     r2 = 6 as i32 as i64 as u64
    lddw r3, 0x100027310 --> b"\x00\x00\x00\x00\xb8Y\x02\x00\x10\x00\x00\x00\x00\x00\x00\x00\xb8!\x00\x0…        r3 load str located at 4295127824
    call function_18489                     
lbb_9856:
    mov64 r1, 7                                     r1 = 7 as i32 as i64 as u64
    mov64 r2, 7                                     r2 = 7 as i32 as i64 as u64
    lddw r3, 0x100027328 --> b"\x00\x00\x00\x00\xb8Y\x02\x00\x10\x00\x00\x00\x00\x00\x00\x00\xb8!\x00\x0…        r3 load str located at 4295127848
    call function_18489                     
lbb_9861:
    mov64 r1, 8                                     r1 = 8 as i32 as i64 as u64
    mov64 r2, 8                                     r2 = 8 as i32 as i64 as u64
    lddw r3, 0x100027340 --> b"\x00\x00\x00\x00\xb8Y\x02\x00\x10\x00\x00\x00\x00\x00\x00\x00\xb9!\x00\x0…        r3 load str located at 4295127872
    call function_18489                     
    ldxdw r3, [r2+0x8]                      
    jeq r3, 1, lbb_10079                            if r3 == (1 as i32 as i64 as u64) { pc += 211 }
    jeq r3, 0, lbb_10084                            if r3 == (0 as i32 as i64 as u64) { pc += 215 }
    jle r3, 2, lbb_10089                            if r3 <= (2 as i32 as i64 as u64) { pc += 219 }
    jeq r3, 3, lbb_10094                            if r3 == (3 as i32 as i64 as u64) { pc += 223 }
    ldxdw r5, [r2+0x50]                     
    mov64 r0, 3                                     r0 = 3 as i32 as i64 as u64
    ldxdw r3, [r5+0x0]                      
    ldxdw r4, [r3+0x50]                     
    jlt r4, 32, lbb_10076                           if r4 < (32 as i32 as i64 as u64) { pc += 200 }
    ldxdw r8, [r2+0x0]                      
    mov64 r7, r8                                    r7 = r8
    add64 r7, 8                                     r7 += 8   ///  r7 = r7.wrapping_add(8 as i32 as i64 as u64)
    ldxdw r4, [r7+0x0]                      
    ldxdw r6, [r4+0x50]                     
    jlt r6, 32, lbb_10076                           if r6 < (32 as i32 as i64 as u64) { pc += 194 }
    stxdw [r10-0x2e0], r7                   
    ldxdw r9, [r2+0x58]                     
    ldxdw r0, [r2+0x48]                     
    stxdw [r10-0x2c8], r0                   
    ldxdw r0, [r2+0x28]                     
    stxdw [r10-0x2d0], r0                   
    ldxdw r0, [r2+0x20]                     
    stxdw [r10-0x2e8], r0                   
    ldxb r6, [r2+0x62]                      
    ldxdw r2, [r2+0x10]                     
    stxdw [r10-0x300], r2                   
    mov64 r2, r8                                    r2 = r8
    add64 r2, 24                                    r2 += 24   ///  r2 = r2.wrapping_add(24 as i32 as i64 as u64)
    stxdw [r10-0x2f8], r2                   
    mov64 r2, r8                                    r2 = r8
    add64 r2, 16                                    r2 += 16   ///  r2 = r2.wrapping_add(16 as i32 as i64 as u64)
    ldxdw r0, [r4+0x58]                     
    ldxdw r7, [r3+0x58]                     
    stxdw [r10-0x2d8], r1                   
    stxdw [r10-0x2f0], r2                   
    jne r7, r0, lbb_9915                            if r7 != r0 { pc += 12 }
    ldxdw r0, [r4+0x60]                     
    ldxdw r7, [r3+0x60]                     
    jne r7, r0, lbb_9915                            if r7 != r0 { pc += 9 }
    ldxdw r0, [r4+0x68]                     
    ldxdw r7, [r3+0x68]                     
    jne r7, r0, lbb_9915                            if r7 != r0 { pc += 6 }
    ldxdw r0, [r4+0x70]                     
    ldxdw r3, [r3+0x70]                     
    jne r3, r0, lbb_9915                            if r3 != r0 { pc += 3 }
    mov64 r1, r5                                    r1 = r5
    mov64 r5, r9                                    r5 = r9
    ja lbb_9916                                     if true { pc += 1 }
lbb_9915:
    mov64 r1, r9                                    r1 = r9
lbb_9916:
    stxdw [r10-0x318], r5                   
    stxdw [r10-0x308], r1                   
    add64 r4, 8                                     r4 += 8   ///  r4 = r4.wrapping_add(8 as i32 as i64 as u64)
    ldxdw r3, [r10-0x2c8]                   
    ldxdw r9, [r3+0x0]                      
    ldxdw r0, [r8+0x0]                      
    ldxdw r7, [r8+0x10]                     
    ldxdw r3, [r1+0x0]                      
    ldxdw r2, [r5+0x0]                      
    mov64 r1, r8                                    r1 = r8
    stxdw [r10-0x310], r1                   
    ldxdw r5, [r10-0x2d0]                   
    ldxdw r8, [r5+0x0]                      
    ldxdw r5, [r1+0x18]                     
    stxdw [r10-0x2a0], r4                   
    add64 r5, 8                                     r5 += 8   ///  r5 = r5.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x250], r5                   
    add64 r8, 8                                     r8 += 8   ///  r8 = r8.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x260], r8                   
    add64 r2, 8                                     r2 += 8   ///  r2 = r2.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x270], r2                   
    add64 r3, 8                                     r3 += 8   ///  r3 = r3.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x280], r3                   
    add64 r7, 8                                     r7 += 8   ///  r7 = r7.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x290], r7                   
    add64 r0, 8                                     r0 += 8   ///  r0 = r0.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x2b0], r0                   
    add64 r9, 8                                     r9 += 8   ///  r9 = r9.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x2c0], r9                   
    sth [r10-0x248], 0                      
    sth [r10-0x258], 0                      
    sth [r10-0x268], 1                      
    sth [r10-0x278], 1                      
    sth [r10-0x288], 1                      
    sth [r10-0x298], 1                      
    sth [r10-0x2a8], 1                      
    sth [r10-0x2b8], 257                    
    xor64 r6, -1                                    r6 ^= -1   ///  r6 = r6.xor(-1)
    and64 r6, 1                                     r6 &= 1   ///  r6 = r6.and(1)
    stxb [r10-0x229], r6                    
    ldxdw r2, [r10-0x300]                   
    stxdw [r10-0x239], r2                   
    stb [r10-0x23a], 7                      
    stdw [r10-0x231], 0                     
    ldxdw r1, [r10-0x2e8]                   
    ldxdw r1, [r1+0x0]                      
    ldxdw r2, [r10-0x2f8]                   
    stxdw [r10-0x1f0], r2                   
    ldxdw r2, [r10-0x2d0]                   
    stxdw [r10-0x1f8], r2                   
    ldxdw r2, [r10-0x318]                   
    stxdw [r10-0x200], r2                   
    ldxdw r2, [r10-0x308]                   
    stxdw [r10-0x208], r2                   
    ldxdw r2, [r10-0x2f0]                   
    stxdw [r10-0x210], r2                   
    ldxdw r2, [r10-0x2e0]                   
    stxdw [r10-0x218], r2                   
    ldxdw r2, [r10-0x310]                   
    stxdw [r10-0x220], r2                   
    ldxdw r2, [r10-0x2c8]                   
    stxdw [r10-0x228], r2                   
    mov64 r2, r10                                   r2 = r10
    add64 r2, -552                                  r2 += -552   ///  r2 = r2.wrapping_add(-552 as i32 as i64 as u64)
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
    mov64 r4, r10                                   r4 = r10
    add64 r4, -696                                  r4 += -696   ///  r4 = r4.wrapping_add(-696 as i32 as i64 as u64)
    add64 r1, 8                                     r1 += 8   ///  r1 = r1.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x2c8], r1                   
    ja lbb_10006                                    if true { pc += 20 }
lbb_9986:
    mov64 r1, r10                                   r1 = r10
    add64 r1, -488                                  r1 += -488   ///  r1 = r1.wrapping_add(-488 as i32 as i64 as u64)
    add64 r1, r3                                    r1 += r3   ///  r1 = r1.wrapping_add(r3)
    stxb [r1+0x32], r7                      
    stxb [r1+0x31], r9                      
    stxb [r1+0x30], r6                      
    mov64 r6, r5                                    r6 = r5
    add64 r6, 40                                    r6 += 40   ///  r6 = r6.wrapping_add(40 as i32 as i64 as u64)
    stxdw [r1+0x20], r6                     
    mov64 r6, r5                                    r6 = r5
    add64 r6, 88                                    r6 += 88   ///  r6 = r6.wrapping_add(88 as i32 as i64 as u64)
    stxdw [r1+0x18], r6                     
    stxdw [r1+0x10], r0                     
    add64 r5, 72                                    r5 += 72   ///  r5 = r5.wrapping_add(72 as i32 as i64 as u64)
    stxdw [r1+0x8], r5                      
    stdw [r1+0x28], 0                       
    add64 r4, 16                                    r4 += 16   ///  r4 = r4.wrapping_add(16 as i32 as i64 as u64)
    add64 r2, 8                                     r2 += 8   ///  r2 = r2.wrapping_add(8 as i32 as i64 as u64)
    add64 r3, 56                                    r3 += 56   ///  r3 = r3.wrapping_add(56 as i32 as i64 as u64)
    jeq r3, 448, lbb_10056                          if r3 == (448 as i32 as i64 as u64) { pc += 50 }
lbb_10006:
    mov64 r6, r10                                   r6 = r10
    add64 r6, -488                                  r6 += -488   ///  r6 = r6.wrapping_add(-488 as i32 as i64 as u64)
    mov64 r0, 1                                     r0 = 1 as i32 as i64 as u64
    ldxdw r1, [r2+0x0]                      
    ldxdw r5, [r1+0x0]                      
    ldxdw r7, [r4-0x8]                      
    ldxdw r1, [r7+0x0]                      
    ldxdw r8, [r5+0x8]                      
    jne r8, r1, lbb_10075                           if r8 != r1 { pc += 60 }
    ldxdw r1, [r7+0x8]                      
    ldxdw r8, [r5+0x10]                     
    jne r8, r1, lbb_10075                           if r8 != r1 { pc += 57 }
    ldxdw r1, [r7+0x10]                     
    ldxdw r8, [r5+0x18]                     
    jne r8, r1, lbb_10075                           if r8 != r1 { pc += 54 }
    ldxdw r1, [r7+0x18]                     
    ldxdw r7, [r5+0x20]                     
    jne r7, r1, lbb_10075                           if r7 != r1 { pc += 51 }
    ldxb r0, [r4+0x0]                       
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    jne r0, 0, lbb_10028                            if r0 != (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r1, 119                                   r1 = 119 as i32 as i64 as u64
lbb_10028:
    ldxb r0, [r5+0x0]                       
    or64 r1, r0                                     r1 |= r0   ///  r1 = r1.or(r0)
    and64 r1, 255                                   r1 &= 255   ///  r1 = r1.and(255)
    jne r1, 255, lbb_10054                          if r1 != (255 as i32 as i64 as u64) { pc += 22 }
    add64 r6, r3                                    r6 += r3   ///  r6 = r6.wrapping_add(r3)
    mov64 r7, r5                                    r7 = r5
    add64 r7, 8                                     r7 += 8   ///  r7 = r7.wrapping_add(8 as i32 as i64 as u64)
    ldxdw r0, [r5+0x50]                     
    ldxb r8, [r5+0x3]                       
    ldxb r1, [r5+0x2]                       
    ldxb r9, [r5+0x1]                       
    stxdw [r6+0x0], r7                      
    mov64 r7, 1                                     r7 = 1 as i32 as i64 as u64
    mov64 r6, 1                                     r6 = 1 as i32 as i64 as u64
    jeq r9, 0, lbb_10047                            if r9 == (0 as i32 as i64 as u64) { pc += 4 }
    mov64 r9, 1                                     r9 = 1 as i32 as i64 as u64
    jeq r1, 0, lbb_10050                            if r1 == (0 as i32 as i64 as u64) { pc += 5 }
lbb_10045:
    jne r8, 0, lbb_9986                             if r8 != (0 as i32 as i64 as u64) { pc += -60 }
    ja lbb_10052                                    if true { pc += 5 }
lbb_10047:
    mov64 r6, 0                                     r6 = 0 as i32 as i64 as u64
    mov64 r9, 1                                     r9 = 1 as i32 as i64 as u64
    jne r1, 0, lbb_10045                            if r1 != (0 as i32 as i64 as u64) { pc += -5 }
lbb_10050:
    mov64 r9, 0                                     r9 = 0 as i32 as i64 as u64
    jne r8, 0, lbb_9986                             if r8 != (0 as i32 as i64 as u64) { pc += -66 }
lbb_10052:
    mov64 r7, 0                                     r7 = 0 as i32 as i64 as u64
    ja lbb_9986                                     if true { pc += -68 }
lbb_10054:
    mov64 r0, 11                                    r0 = 11 as i32 as i64 as u64
    ja lbb_10075                                    if true { pc += 19 }
lbb_10056:
    mov64 r1, r10                                   r1 = r10
    add64 r1, -570                                  r1 += -570   ///  r1 = r1.wrapping_add(-570 as i32 as i64 as u64)
    stxdw [r10-0x10], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -704                                  r1 += -704   ///  r1 = r1.wrapping_add(-704 as i32 as i64 as u64)
    stxdw [r10-0x20], r1                    
    ldxdw r1, [r10-0x2c8]                   
    stxdw [r10-0x28], r1                    
    stdw [r10-0x8], 18                      
    stdw [r10-0x18], 8                      
    mov64 r1, r10                                   r1 = r10
    add64 r1, -40                                   r1 += -40   ///  r1 = r1.wrapping_add(-40 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -488                                  r2 += -488   ///  r2 = r2.wrapping_add(-488 as i32 as i64 as u64)
    mov64 r3, 8                                     r3 = 8 as i32 as i64 as u64
    mov64 r4, 8                                     r4 = 8 as i32 as i64 as u64
    mov64 r5, 0                                     r5 = 0 as i32 as i64 as u64
    syscall [invalid]                       
    mov64 r0, 26                                    r0 = 26 as i32 as i64 as u64
lbb_10075:
    ldxdw r1, [r10-0x2d8]                   
lbb_10076:
    stxw [r1+0x0], r0                       
    stw [r1+0x4], 0                         
    exit                                    
lbb_10079:
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    mov64 r2, 1                                     r2 = 1 as i32 as i64 as u64
    lddw r3, 0x100027370 --> b"\x00\x00\x00\x00\xb8Y\x02\x00\x10\x00\x00\x00\x00\x00\x00\x00\xc1!\x00\x0…        r3 load str located at 4295127920
    call function_18489                     
lbb_10084:
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
    lddw r3, 0x100027358 --> b"\x00\x00\x00\x00\xb8Y\x02\x00\x10\x00\x00\x00\x00\x00\x00\x00\xc1!\x00\x0…        r3 load str located at 4295127896
    call function_18489                     
lbb_10089:
    mov64 r1, 2                                     r1 = 2 as i32 as i64 as u64
    mov64 r2, 2                                     r2 = 2 as i32 as i64 as u64
    lddw r3, 0x100027388 --> b"\x00\x00\x00\x00\xb8Y\x02\x00\x10\x00\x00\x00\x00\x00\x00\x00\xc1!\x00\x0…        r3 load str located at 4295127944
    call function_18489                     
lbb_10094:
    mov64 r1, 3                                     r1 = 3 as i32 as i64 as u64
    mov64 r2, 3                                     r2 = 3 as i32 as i64 as u64
    lddw r3, 0x1000273a0 --> b"\x00\x00\x00\x00\xb8Y\x02\x00\x10\x00\x00\x00\x00\x00\x00\x00\xc1!\x00\x0…        r3 load str located at 4295127968
    call function_18489                     
    ldxdw r3, [r2+0x8]                      
    jeq r3, 1, lbb_10349                            if r3 == (1 as i32 as i64 as u64) { pc += 248 }
    jeq r3, 0, lbb_10354                            if r3 == (0 as i32 as i64 as u64) { pc += 252 }
    jle r3, 2, lbb_10359                            if r3 <= (2 as i32 as i64 as u64) { pc += 256 }
    jeq r3, 3, lbb_10364                            if r3 == (3 as i32 as i64 as u64) { pc += 260 }
    ldxdw r3, [r2+0x0]                      
    mov64 r6, 3                                     r6 = 3 as i32 as i64 as u64
    ldxdw r0, [r3+0x8]                      
    ldxdw r4, [r0+0x50]                     
    jlt r4, 120, lbb_10346                          if r4 < (120 as i32 as i64 as u64) { pc += 237 }
    ldxdw r4, [r2+0x50]                     
    stxdw [r10-0x338], r4                   
    ldxdw r8, [r4+0x0]                      
    ldxdw r4, [r8+0x50]                     
    jlt r4, 32, lbb_10346                           if r4 < (32 as i32 as i64 as u64) { pc += 232 }
    mov64 r5, r3                                    r5 = r3
    add64 r5, 16                                    r5 += 16   ///  r5 = r5.wrapping_add(16 as i32 as i64 as u64)
    ldxdw r7, [r5+0x0]                      
    ldxdw r4, [r7+0x50]                     
    jlt r4, 32, lbb_10346                           if r4 < (32 as i32 as i64 as u64) { pc += 227 }
    stxdw [r10-0x358], r5                   
    ldxdw r5, [r2+0x58]                     
    ldxdw r4, [r2+0x48]                     
    stxdw [r10-0x340], r4                   
    ldxdw r4, [r2+0x28]                     
    stxdw [r10-0x348], r4                   
    ldxdw r6, [r2+0x20]                     
    mov64 r4, 0                                     r4 = 0 as i32 as i64 as u64
    stxdw [r10-0x350], r4                   
    ldxdw r4, [r7+0x58]                     
    ldxdw r9, [r8+0x58]                     
    stxdw [r10-0x360], r1                   
    jne r9, r4, lbb_10148                           if r9 != r4 { pc += 16 }
    ldxdw r4, [r7+0x60]                     
    ldxdw r9, [r8+0x60]                     
    jne r9, r4, lbb_10148                           if r9 != r4 { pc += 13 }
    ldxdw r4, [r7+0x68]                     
    ldxdw r9, [r8+0x68]                     
    jne r9, r4, lbb_10148                           if r9 != r4 { pc += 10 }
    ldxdw r4, [r7+0x70]                     
    ldxdw r8, [r8+0x70]                     
    mov64 r9, 1                                     r9 = 1 as i32 as i64 as u64
    jeq r8, r4, lbb_10143                           if r8 == r4 { pc += 1 }
    mov64 r9, 0                                     r9 = 0 as i32 as i64 as u64
lbb_10143:
    stxdw [r10-0x350], r9                   
    jne r8, r4, lbb_10148                           if r8 != r4 { pc += 3 }
    ldxdw r4, [r10-0x338]                   
    stxdw [r10-0x338], r5                   
    ja lbb_10149                                    if true { pc += 1 }
lbb_10148:
    mov64 r4, r5                                    r4 = r5
lbb_10149:
    ldxdw r1, [r2+0x10]                     
    stxdw [r10-0x378], r1                   
    ldxdw r1, [r0+0xc8]                     
    stxdw [r10-0x380], r1                   
    stxdw [r10-0x368], r6                   
    ldxdw r6, [r6+0x0]                      
    ldxdw r1, [r10-0x340]                   
    ldxdw r1, [r1+0x0]                      
    stxdw [r10-0x370], r4                   
    ldxdw r4, [r4+0x0]                      
    ldxdw r2, [r10-0x338]                   
    ldxdw r2, [r2+0x0]                      
    ldxdw r9, [r3+0x0]                      
    ldxdw r8, [r3+0x18]                     
    ldxdw r5, [r10-0x348]                   
    ldxdw r5, [r5+0x0]                      
    add64 r7, 8                                     r7 += 8   ///  r7 = r7.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x2d0], r7                   
    add64 r0, 8                                     r0 += 8   ///  r0 = r0.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x310], r0                   
    add64 r5, 8                                     r5 += 8   ///  r5 = r5.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x2b0], r5                   
    add64 r8, 8                                     r8 += 8   ///  r8 = r8.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x2c0], r8                   
    add64 r2, 8                                     r2 += 8   ///  r2 = r2.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x2e0], r2                   
    add64 r4, 8                                     r4 += 8   ///  r4 = r4.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x2f0], r4                   
    add64 r1, 8                                     r1 += 8   ///  r1 = r1.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x300], r1                   
    add64 r9, 8                                     r9 += 8   ///  r9 = r9.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x320], r9                   
    add64 r6, 8                                     r6 += 8   ///  r6 = r6.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x388], r6                   
    stxdw [r10-0x330], r6                   
    sth [r10-0x2a8], 0                      
    sth [r10-0x2b8], 1                      
    sth [r10-0x2c8], 1                      
    sth [r10-0x2d8], 1                      
    sth [r10-0x2e8], 1                      
    sth [r10-0x2f8], 257                    
    sth [r10-0x308], 1                      
    sth [r10-0x318], 0                      
    sth [r10-0x328], 0                      
    ldxdw r1, [r10-0x350]                   
    and64 r1, 1                                     r1 &= 1   ///  r1 = r1.and(1)
    jeq r1, 0, lbb_10215                            if r1 == (0 as i32 as i64 as u64) { pc += 19 }
    ldxdw r4, [r10-0x358]                   
    ldxdw r1, [r10-0x380]                   
    jeq r1, 0, lbb_10369                            if r1 == (0 as i32 as i64 as u64) { pc += 170 }
    mov64 r0, r10                                   r0 = r10
    add64 r0, -670                                  r0 += -670   ///  r0 = r0.wrapping_add(-670 as i32 as i64 as u64)
    mov64 r6, r10                                   r6 = r10
    add64 r6, -668                                  r6 += -668   ///  r6 = r6.wrapping_add(-668 as i32 as i64 as u64)
    ldxdw r5, [r10-0x378]                   
    div64 r5, r1                                    r5 /= r1   ///  r5 = r5 / r1
    mov64 r7, 1                                     r7 = 1 as i32 as i64 as u64
    stdw [r10-0x2a0], 0                     
    stdw [r10-0x271], 0                     
    stdw [r10-0x278], 0                     
    stdw [r10-0x280], 0                     
    stdw [r10-0x288], 0                     
    stdw [r10-0x290], 0                     
    stdw [r10-0x298], 0                     
    stb [r10-0x29f], 2                      
    ja lbb_10229                                    if true { pc += 14 }
lbb_10215:
    mov64 r0, r10                                   r0 = r10
    add64 r0, -671                                  r0 += -671   ///  r0 = r0.wrapping_add(-671 as i32 as i64 as u64)
    mov64 r6, r10                                   r6 = r10
    add64 r6, -660                                  r6 += -660   ///  r6 = r6.wrapping_add(-660 as i32 as i64 as u64)
    mov64 r7, 2                                     r7 = 2 as i32 as i64 as u64
    stdw [r10-0x271], 0                     
    stdw [r10-0x278], 0                     
    stdw [r10-0x280], 0                     
    stdw [r10-0x288], 0                     
    stdw [r10-0x290], 0                     
    stdw [r10-0x298], 0                     
    stdw [r10-0x2a0], 0                     
    ldxdw r4, [r10-0x358]                   
    ldxdw r5, [r10-0x378]                   
lbb_10229:
    mov64 r1, r3                                    r1 = r3
    add64 r1, 24                                    r1 += 24   ///  r1 = r1.wrapping_add(24 as i32 as i64 as u64)
    mov64 r2, r3                                    r2 = r3
    add64 r2, 8                                     r2 += 8   ///  r2 = r2.wrapping_add(8 as i32 as i64 as u64)
    stxb [r0+0x0], r7                       
    stxdw [r6+0x0], r5                      
    stb [r10-0x27c], 2                      
    ldxdw r5, [r10-0x348]                   
    stxdw [r10-0x228], r5                   
    stxdw [r10-0x230], r1                   
    stxdw [r10-0x238], r4                   
    ldxdw r1, [r10-0x338]                   
    stxdw [r10-0x240], r1                   
    ldxdw r1, [r10-0x370]                   
    stxdw [r10-0x248], r1                   
    ldxdw r1, [r10-0x340]                   
    stxdw [r10-0x250], r1                   
    stxdw [r10-0x258], r2                   
    stxdw [r10-0x260], r3                   
    ldxdw r1, [r10-0x368]                   
    stxdw [r10-0x268], r1                   
    mov64 r2, r10                                   r2 = r10
    add64 r2, -616                                  r2 += -616   ///  r2 = r2.wrapping_add(-616 as i32 as i64 as u64)
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
    mov64 r4, r10                                   r4 = r10
    add64 r4, -808                                  r4 += -808   ///  r4 = r4.wrapping_add(-808 as i32 as i64 as u64)
    ja lbb_10276                                    if true { pc += 20 }
lbb_10256:
    mov64 r7, r10                                   r7 = r10
    add64 r7, -544                                  r7 += -544   ///  r7 = r7.wrapping_add(-544 as i32 as i64 as u64)
    add64 r7, r3                                    r7 += r3   ///  r7 = r7.wrapping_add(r3)
    stxb [r7+0x32], r0                      
    stxb [r7+0x31], r8                      
    stxb [r7+0x30], r1                      
    mov64 r1, r5                                    r1 = r5
    add64 r1, 40                                    r1 += 40   ///  r1 = r1.wrapping_add(40 as i32 as i64 as u64)
    stxdw [r7+0x20], r1                     
    mov64 r1, r5                                    r1 = r5
    add64 r1, 88                                    r1 += 88   ///  r1 = r1.wrapping_add(88 as i32 as i64 as u64)
    stxdw [r7+0x18], r1                     
    stxdw [r7+0x10], r6                     
    add64 r5, 72                                    r5 += 72   ///  r5 = r5.wrapping_add(72 as i32 as i64 as u64)
    stxdw [r7+0x8], r5                      
    stdw [r7+0x28], 0                       
    add64 r4, 16                                    r4 += 16   ///  r4 = r4.wrapping_add(16 as i32 as i64 as u64)
    add64 r2, 8                                     r2 += 8   ///  r2 = r2.wrapping_add(8 as i32 as i64 as u64)
    add64 r3, 56                                    r3 += 56   ///  r3 = r3.wrapping_add(56 as i32 as i64 as u64)
    jeq r3, 504, lbb_10326                          if r3 == (504 as i32 as i64 as u64) { pc += 50 }
lbb_10276:
    mov64 r0, r10                                   r0 = r10
    add64 r0, -544                                  r0 += -544   ///  r0 = r0.wrapping_add(-544 as i32 as i64 as u64)
    mov64 r6, 1                                     r6 = 1 as i32 as i64 as u64
    ldxdw r1, [r2+0x0]                      
    ldxdw r5, [r1+0x0]                      
    ldxdw r1, [r4-0x8]                      
    ldxdw r7, [r1+0x0]                      
    ldxdw r8, [r5+0x8]                      
    jne r8, r7, lbb_10345                           if r8 != r7 { pc += 60 }
    ldxdw r7, [r1+0x8]                      
    ldxdw r8, [r5+0x10]                     
    jne r8, r7, lbb_10345                           if r8 != r7 { pc += 57 }
    ldxdw r7, [r1+0x10]                     
    ldxdw r8, [r5+0x18]                     
    jne r8, r7, lbb_10345                           if r8 != r7 { pc += 54 }
    ldxdw r1, [r1+0x18]                     
    ldxdw r7, [r5+0x20]                     
    jne r7, r1, lbb_10345                           if r7 != r1 { pc += 51 }
    ldxb r6, [r4+0x0]                       
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    jne r6, 0, lbb_10298                            if r6 != (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r1, 119                                   r1 = 119 as i32 as i64 as u64
lbb_10298:
    ldxb r6, [r5+0x0]                       
    or64 r1, r6                                     r1 |= r6   ///  r1 = r1.or(r6)
    and64 r1, 255                                   r1 &= 255   ///  r1 = r1.and(255)
    jne r1, 255, lbb_10324                          if r1 != (255 as i32 as i64 as u64) { pc += 22 }
    add64 r0, r3                                    r0 += r3   ///  r0 = r0.wrapping_add(r3)
    mov64 r1, r5                                    r1 = r5
    add64 r1, 8                                     r1 += 8   ///  r1 = r1.wrapping_add(8 as i32 as i64 as u64)
    ldxdw r6, [r5+0x50]                     
    ldxb r7, [r5+0x3]                       
    ldxb r9, [r5+0x2]                       
    ldxb r8, [r5+0x1]                       
    stxdw [r0+0x0], r1                      
    mov64 r0, 1                                     r0 = 1 as i32 as i64 as u64
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    jeq r8, 0, lbb_10317                            if r8 == (0 as i32 as i64 as u64) { pc += 4 }
    mov64 r8, 1                                     r8 = 1 as i32 as i64 as u64
    jeq r9, 0, lbb_10320                            if r9 == (0 as i32 as i64 as u64) { pc += 5 }
lbb_10315:
    jne r7, 0, lbb_10256                            if r7 != (0 as i32 as i64 as u64) { pc += -60 }
    ja lbb_10322                                    if true { pc += 5 }
lbb_10317:
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    mov64 r8, 1                                     r8 = 1 as i32 as i64 as u64
    jne r9, 0, lbb_10315                            if r9 != (0 as i32 as i64 as u64) { pc += -5 }
lbb_10320:
    mov64 r8, 0                                     r8 = 0 as i32 as i64 as u64
    jne r7, 0, lbb_10256                            if r7 != (0 as i32 as i64 as u64) { pc += -66 }
lbb_10322:
    mov64 r0, 0                                     r0 = 0 as i32 as i64 as u64
    ja lbb_10256                                    if true { pc += -68 }
lbb_10324:
    mov64 r6, 11                                    r6 = 11 as i32 as i64 as u64
    ja lbb_10345                                    if true { pc += 19 }
lbb_10326:
    mov64 r1, r10                                   r1 = r10
    add64 r1, -672                                  r1 += -672   ///  r1 = r1.wrapping_add(-672 as i32 as i64 as u64)
    stxdw [r10-0x10], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -816                                  r1 += -816   ///  r1 = r1.wrapping_add(-816 as i32 as i64 as u64)
    stxdw [r10-0x20], r1                    
    ldxdw r1, [r10-0x388]                   
    stxdw [r10-0x28], r1                    
    stdw [r10-0x8], 55                      
    stdw [r10-0x18], 9                      
    mov64 r1, r10                                   r1 = r10
    add64 r1, -40                                   r1 += -40   ///  r1 = r1.wrapping_add(-40 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -544                                  r2 += -544   ///  r2 = r2.wrapping_add(-544 as i32 as i64 as u64)
    mov64 r3, 9                                     r3 = 9 as i32 as i64 as u64
    mov64 r4, 8                                     r4 = 8 as i32 as i64 as u64
    mov64 r5, 0                                     r5 = 0 as i32 as i64 as u64
    syscall [invalid]                       
    mov64 r6, 26                                    r6 = 26 as i32 as i64 as u64
lbb_10345:
    ldxdw r1, [r10-0x360]                   
lbb_10346:
    stxw [r1+0x0], r6                       
    stw [r1+0x4], 0                         
    exit                                    
lbb_10349:
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    mov64 r2, 1                                     r2 = 1 as i32 as i64 as u64
    lddw r3, 0x1000273d0 --> b"\x00\x00\x00\x00\xb8Y\x02\x00\x10\x00\x00\x00\x00\x00\x00\x00\xca!\x00\x0…        r3 load str located at 4295128016
    call function_18489                     
lbb_10354:
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
    lddw r3, 0x1000273b8 --> b"\x00\x00\x00\x00\xb8Y\x02\x00\x10\x00\x00\x00\x00\x00\x00\x00\xca!\x00\x0…        r3 load str located at 4295127992
    call function_18489                     
lbb_10359:
    mov64 r1, 2                                     r1 = 2 as i32 as i64 as u64
    mov64 r2, 2                                     r2 = 2 as i32 as i64 as u64
    lddw r3, 0x1000273e8 --> b"\x00\x00\x00\x00\xb8Y\x02\x00\x10\x00\x00\x00\x00\x00\x00\x00\xca!\x00\x0…        r3 load str located at 4295128040
    call function_18489                     
lbb_10364:
    mov64 r1, 3                                     r1 = 3 as i32 as i64 as u64
    mov64 r2, 3                                     r2 = 3 as i32 as i64 as u64
    lddw r3, 0x100027400 --> b"\x00\x00\x00\x00\xb8Y\x02\x00\x10\x00\x00\x00\x00\x00\x00\x00\xca!\x00\x0…        r3 load str located at 4295128064
    call function_18489                     
lbb_10369:
    lddw r1, 0x100025c00 --> b"\x00\x00\x00\x00\xb8Y\x02\x00\x10\x00\x00\x00\x00\x00\x00\x00\xe9\x08\x00…        r1 load str located at 4295121920
    call function_18908                     
    ldxdw r3, [r2+0x8]                      
    jeq r3, 1, lbb_10598                            if r3 == (1 as i32 as i64 as u64) { pc += 224 }
    jeq r3, 0, lbb_10603                            if r3 == (0 as i32 as i64 as u64) { pc += 228 }
    jle r3, 2, lbb_10608                            if r3 <= (2 as i32 as i64 as u64) { pc += 232 }
    jeq r3, 3, lbb_10613                            if r3 == (3 as i32 as i64 as u64) { pc += 236 }
    jle r3, 4, lbb_10618                            if r3 <= (4 as i32 as i64 as u64) { pc += 240 }
    jeq r3, 5, lbb_10623                            if r3 == (5 as i32 as i64 as u64) { pc += 244 }
    jle r3, 6, lbb_10628                            if r3 <= (6 as i32 as i64 as u64) { pc += 248 }
    jeq r3, 7, lbb_10633                            if r3 == (7 as i32 as i64 as u64) { pc += 252 }
    jle r3, 8, lbb_10638                            if r3 <= (8 as i32 as i64 as u64) { pc += 256 }
    ldxdw r4, [r2+0x50]                     
    ldxdw r0, [r2+0x58]                     
    ldxb r3, [r2+0x63]                      
    mov64 r6, r4                                    r6 = r4
    jne r3, 0, lbb_10388                            if r3 != (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r6, r0                                    r6 = r0
lbb_10388:
    jne r3, 0, lbb_10390                            if r3 != (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r0, r4                                    r0 = r4
lbb_10390:
    stxdw [r10-0x408], r1                   
    ldxdw r5, [r2+0x0]                      
    ldxdw r7, [r2+0x48]                     
    ldxdw r1, [r2+0x20]                     
    stxdw [r10-0x410], r1                   
    lddw r1, 0x697357265b0e7f8a                     r1 load str located at 7598512818552209290
    jne r3, 0, lbb_10400                            if r3 != (0 as i32 as i64 as u64) { pc += 2 }
    lddw r1, 0xae87b0e6bb283d6d                     r1 load str located at -5870529084225208979
lbb_10400:
    stxdw [r10-0x428], r1                   
    ldxdw r2, [r2+0x10]                     
    stxdw [r10-0x418], r2                   
    ldxdw r4, [r5+0x40]                     
    add64 r4, 8                                     r4 += 8   ///  r4 = r4.wrapping_add(8 as i32 as i64 as u64)
    ldxdw r8, [r0+0x0]                      
    stxdw [r10-0x430], r6                   
    ldxdw r6, [r6+0x0]                      
    ldxdw r1, [r7+0x0]                      
    stxdw [r10-0x440], r1                   
    ldxdw r1, [r5+0x0]                      
    stxdw [r10-0x448], r1                   
    ldxdw r1, [r5+0x8]                      
    stxdw [r10-0x450], r1                   
    ldxdw r9, [r5+0x10]                     
    stxdw [r10-0x420], r7                   
    ldxdw r7, [r5+0x18]                     
    stxdw [r10-0x438], r0                   
    ldxdw r0, [r5+0x20]                     
    ldxdw r3, [r5+0x28]                     
    ldxdw r2, [r5+0x30]                     
    ldxdw r1, [r5+0x38]                     
    stxdw [r10-0x350], r4                   
    add64 r1, 8                                     r1 += 8   ///  r1 = r1.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x360], r1                   
    add64 r2, 8                                     r2 += 8   ///  r2 = r2.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x370], r2                   
    add64 r3, 8                                     r3 += 8   ///  r3 = r3.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x380], r3                   
    add64 r0, 8                                     r0 += 8   ///  r0 = r0.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x390], r0                   
    add64 r6, 8                                     r6 += 8   ///  r6 = r6.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x3a0], r6                   
    add64 r8, 8                                     r8 += 8   ///  r8 = r8.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x3b0], r8                   
    add64 r7, 8                                     r7 += 8   ///  r7 = r7.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x3c0], r7                   
    add64 r9, 8                                     r9 += 8   ///  r9 = r9.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x3d0], r9                   
    ldxdw r1, [r10-0x450]                   
    add64 r1, 8                                     r1 += 8   ///  r1 = r1.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x3e0], r1                   
    ldxdw r1, [r10-0x448]                   
    add64 r1, 8                                     r1 += 8   ///  r1 = r1.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x3f0], r1                   
    ldxdw r1, [r10-0x440]                   
    add64 r1, 8                                     r1 += 8   ///  r1 = r1.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x400], r1                   
    sth [r10-0x348], 0                      
    sth [r10-0x358], 0                      
    sth [r10-0x368], 0                      
    sth [r10-0x378], 1                      
    sth [r10-0x388], 1                      
    sth [r10-0x398], 1                      
    sth [r10-0x3a8], 1                      
    sth [r10-0x3b8], 1                      
    sth [r10-0x3c8], 0                      
    sth [r10-0x3d8], 0                      
    sth [r10-0x3e8], 0                      
    sth [r10-0x3f8], 257                    
    mov64 r1, r5                                    r1 = r5
    add64 r1, 64                                    r1 += 64   ///  r1 = r1.wrapping_add(64 as i32 as i64 as u64)
    stxdw [r10-0x2e8], r1                   
    mov64 r1, r5                                    r1 = r5
    add64 r1, 56                                    r1 += 56   ///  r1 = r1.wrapping_add(56 as i32 as i64 as u64)
    stxdw [r10-0x2f0], r1                   
    mov64 r1, r5                                    r1 = r5
    add64 r1, 48                                    r1 += 48   ///  r1 = r1.wrapping_add(48 as i32 as i64 as u64)
    stxdw [r10-0x2f8], r1                   
    mov64 r1, r5                                    r1 = r5
    add64 r1, 40                                    r1 += 40   ///  r1 = r1.wrapping_add(40 as i32 as i64 as u64)
    stxdw [r10-0x300], r1                   
    mov64 r1, r5                                    r1 = r5
    add64 r1, 32                                    r1 += 32   ///  r1 = r1.wrapping_add(32 as i32 as i64 as u64)
    stxdw [r10-0x308], r1                   
    ldxdw r1, [r10-0x430]                   
    stxdw [r10-0x310], r1                   
    ldxdw r1, [r10-0x438]                   
    stxdw [r10-0x318], r1                   
    mov64 r1, r5                                    r1 = r5
    add64 r1, 24                                    r1 += 24   ///  r1 = r1.wrapping_add(24 as i32 as i64 as u64)
    stxdw [r10-0x320], r1                   
    mov64 r1, r5                                    r1 = r5
    add64 r1, 16                                    r1 += 16   ///  r1 = r1.wrapping_add(16 as i32 as i64 as u64)
    stxdw [r10-0x328], r1                   
    mov64 r1, r5                                    r1 = r5
    add64 r1, 8                                     r1 += 8   ///  r1 = r1.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x330], r1                   
    stxdw [r10-0x338], r5                   
    ldxdw r1, [r10-0x420]                   
    stxdw [r10-0x340], r1                   
    ldxdw r1, [r10-0x418]                   
    stxdw [r10-0x2d8], r1                   
    ldxdw r1, [r10-0x428]                   
    stxdw [r10-0x2e0], r1                   
    mov64 r2, r10                                   r2 = r10
    add64 r2, -832                                  r2 += -832   ///  r2 = r2.wrapping_add(-832 as i32 as i64 as u64)
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
    mov64 r4, r10                                   r4 = r10
    add64 r4, -1016                                 r4 += -1016   ///  r4 = r4.wrapping_add(-1016 as i32 as i64 as u64)
    stdw [r10-0x2d0], 0                     
    ldxdw r1, [r10-0x410]                   
    ldxdw r1, [r1+0x0]                      
    add64 r1, 8                                     r1 += 8   ///  r1 = r1.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x410], r1                   
    ja lbb_10526                                    if true { pc += 20 }
lbb_10506:
    mov64 r1, r10                                   r1 = r10
    add64 r1, -712                                  r1 += -712   ///  r1 = r1.wrapping_add(-712 as i32 as i64 as u64)
    add64 r1, r3                                    r1 += r3   ///  r1 = r1.wrapping_add(r3)
    stxb [r1+0x32], r6                      
    stxb [r1+0x31], r9                      
    stxb [r1+0x30], r0                      
    mov64 r0, r5                                    r0 = r5
    add64 r0, 40                                    r0 += 40   ///  r0 = r0.wrapping_add(40 as i32 as i64 as u64)
    stxdw [r1+0x20], r0                     
    mov64 r0, r5                                    r0 = r5
    add64 r0, 88                                    r0 += 88   ///  r0 = r0.wrapping_add(88 as i32 as i64 as u64)
    stxdw [r1+0x18], r0                     
    stxdw [r1+0x10], r7                     
    add64 r5, 72                                    r5 += 72   ///  r5 = r5.wrapping_add(72 as i32 as i64 as u64)
    stxdw [r1+0x8], r5                      
    stdw [r1+0x28], 0                       
    add64 r4, 16                                    r4 += 16   ///  r4 = r4.wrapping_add(16 as i32 as i64 as u64)
    add64 r2, 8                                     r2 += 8   ///  r2 = r2.wrapping_add(8 as i32 as i64 as u64)
    add64 r3, 56                                    r3 += 56   ///  r3 = r3.wrapping_add(56 as i32 as i64 as u64)
    jeq r3, 672, lbb_10576                          if r3 == (672 as i32 as i64 as u64) { pc += 50 }
lbb_10526:
    mov64 r0, r10                                   r0 = r10
    add64 r0, -712                                  r0 += -712   ///  r0 = r0.wrapping_add(-712 as i32 as i64 as u64)
    mov64 r7, 1                                     r7 = 1 as i32 as i64 as u64
    ldxdw r1, [r2+0x0]                      
    ldxdw r5, [r1+0x0]                      
    ldxdw r6, [r4-0x8]                      
    ldxdw r1, [r6+0x0]                      
    ldxdw r8, [r5+0x8]                      
    jne r8, r1, lbb_10595                           if r8 != r1 { pc += 60 }
    ldxdw r1, [r6+0x8]                      
    ldxdw r8, [r5+0x10]                     
    jne r8, r1, lbb_10595                           if r8 != r1 { pc += 57 }
    ldxdw r1, [r6+0x10]                     
    ldxdw r8, [r5+0x18]                     
    jne r8, r1, lbb_10595                           if r8 != r1 { pc += 54 }
    ldxdw r1, [r6+0x18]                     
    ldxdw r6, [r5+0x20]                     
    jne r6, r1, lbb_10595                           if r6 != r1 { pc += 51 }
    ldxb r6, [r4+0x0]                       
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    jne r6, 0, lbb_10548                            if r6 != (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r1, 119                                   r1 = 119 as i32 as i64 as u64
lbb_10548:
    ldxb r6, [r5+0x0]                       
    or64 r1, r6                                     r1 |= r6   ///  r1 = r1.or(r6)
    and64 r1, 255                                   r1 &= 255   ///  r1 = r1.and(255)
    jne r1, 255, lbb_10574                          if r1 != (255 as i32 as i64 as u64) { pc += 22 }
    add64 r0, r3                                    r0 += r3   ///  r0 = r0.wrapping_add(r3)
    mov64 r6, r5                                    r6 = r5
    add64 r6, 8                                     r6 += 8   ///  r6 = r6.wrapping_add(8 as i32 as i64 as u64)
    ldxdw r7, [r5+0x50]                     
    ldxb r8, [r5+0x3]                       
    ldxb r1, [r5+0x2]                       
    ldxb r9, [r5+0x1]                       
    stxdw [r0+0x0], r6                      
    mov64 r6, 1                                     r6 = 1 as i32 as i64 as u64
    mov64 r0, 1                                     r0 = 1 as i32 as i64 as u64
    jeq r9, 0, lbb_10567                            if r9 == (0 as i32 as i64 as u64) { pc += 4 }
    mov64 r9, 1                                     r9 = 1 as i32 as i64 as u64
    jeq r1, 0, lbb_10570                            if r1 == (0 as i32 as i64 as u64) { pc += 5 }
lbb_10565:
    jne r8, 0, lbb_10506                            if r8 != (0 as i32 as i64 as u64) { pc += -60 }
    ja lbb_10572                                    if true { pc += 5 }
lbb_10567:
    mov64 r0, 0                                     r0 = 0 as i32 as i64 as u64
    mov64 r9, 1                                     r9 = 1 as i32 as i64 as u64
    jne r1, 0, lbb_10565                            if r1 != (0 as i32 as i64 as u64) { pc += -5 }
lbb_10570:
    mov64 r9, 0                                     r9 = 0 as i32 as i64 as u64
    jne r8, 0, lbb_10506                            if r8 != (0 as i32 as i64 as u64) { pc += -66 }
lbb_10572:
    mov64 r6, 0                                     r6 = 0 as i32 as i64 as u64
    ja lbb_10506                                    if true { pc += -68 }
lbb_10574:
    mov64 r7, 11                                    r7 = 11 as i32 as i64 as u64
    ja lbb_10595                                    if true { pc += 19 }
lbb_10576:
    mov64 r1, r10                                   r1 = r10
    add64 r1, -736                                  r1 += -736   ///  r1 = r1.wrapping_add(-736 as i32 as i64 as u64)
    stxdw [r10-0x10], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -1024                                 r1 += -1024   ///  r1 = r1.wrapping_add(-1024 as i32 as i64 as u64)
    stxdw [r10-0x20], r1                    
    ldxdw r1, [r10-0x410]                   
    stxdw [r10-0x28], r1                    
    stdw [r10-0x8], 24                      
    stdw [r10-0x18], 12                     
    mov64 r1, r10                                   r1 = r10
    add64 r1, -40                                   r1 += -40   ///  r1 = r1.wrapping_add(-40 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -712                                  r2 += -712   ///  r2 = r2.wrapping_add(-712 as i32 as i64 as u64)
    mov64 r3, 12                                    r3 = 12 as i32 as i64 as u64
    mov64 r4, 8                                     r4 = 8 as i32 as i64 as u64
    mov64 r5, 0                                     r5 = 0 as i32 as i64 as u64
    syscall [invalid]                       
    mov64 r7, 26                                    r7 = 26 as i32 as i64 as u64
lbb_10595:
    ldxdw r1, [r10-0x408]                   
    stxw [r1+0x0], r7                       
    exit                                    
lbb_10598:
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    mov64 r2, 1                                     r2 = 1 as i32 as i64 as u64
    lddw r3, 0x100027430 --> b"\x00\x00\x00\x00\xb8Y\x02\x00\x10\x00\x00\x00\x00\x00\x00\x00\xd5!\x00\x0…        r3 load str located at 4295128112
    call function_18489                     
lbb_10603:
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
    lddw r3, 0x100027418 --> b"\x00\x00\x00\x00\xb8Y\x02\x00\x10\x00\x00\x00\x00\x00\x00\x00\xd5!\x00\x0…        r3 load str located at 4295128088
    call function_18489                     
lbb_10608:
    mov64 r1, 2                                     r1 = 2 as i32 as i64 as u64
    mov64 r2, 2                                     r2 = 2 as i32 as i64 as u64
    lddw r3, 0x100027448 --> b"\x00\x00\x00\x00\xb8Y\x02\x00\x10\x00\x00\x00\x00\x00\x00\x00\xd5!\x00\x0…        r3 load str located at 4295128136
    call function_18489                     
lbb_10613:
    mov64 r1, 3                                     r1 = 3 as i32 as i64 as u64
    mov64 r2, 3                                     r2 = 3 as i32 as i64 as u64
    lddw r3, 0x100027460 --> b"\x00\x00\x00\x00\xb8Y\x02\x00\x10\x00\x00\x00\x00\x00\x00\x00\xd5!\x00\x0…        r3 load str located at 4295128160
    call function_18489                     
lbb_10618:
    mov64 r1, 4                                     r1 = 4 as i32 as i64 as u64
    mov64 r2, 4                                     r2 = 4 as i32 as i64 as u64
    lddw r3, 0x100027478 --> b"\x00\x00\x00\x00\xb8Y\x02\x00\x10\x00\x00\x00\x00\x00\x00\x00\xd6!\x00\x0…        r3 load str located at 4295128184
    call function_18489                     
lbb_10623:
    mov64 r1, 5                                     r1 = 5 as i32 as i64 as u64
    mov64 r2, 5                                     r2 = 5 as i32 as i64 as u64
    lddw r3, 0x100027490 --> b"\x00\x00\x00\x00\xb8Y\x02\x00\x10\x00\x00\x00\x00\x00\x00\x00\xd6!\x00\x0…        r3 load str located at 4295128208
    call function_18489                     
lbb_10628:
    mov64 r1, 6                                     r1 = 6 as i32 as i64 as u64
    mov64 r2, 6                                     r2 = 6 as i32 as i64 as u64
    lddw r3, 0x1000274a8 --> b"\x00\x00\x00\x00\xb8Y\x02\x00\x10\x00\x00\x00\x00\x00\x00\x00\xd6!\x00\x0…        r3 load str located at 4295128232
    call function_18489                     
lbb_10633:
    mov64 r1, 7                                     r1 = 7 as i32 as i64 as u64
    mov64 r2, 7                                     r2 = 7 as i32 as i64 as u64
    lddw r3, 0x1000274c0 --> b"\x00\x00\x00\x00\xb8Y\x02\x00\x10\x00\x00\x00\x00\x00\x00\x00\xd6!\x00\x0…        r3 load str located at 4295128256
    call function_18489                     
lbb_10638:
    mov64 r1, 8                                     r1 = 8 as i32 as i64 as u64
    mov64 r2, 8                                     r2 = 8 as i32 as i64 as u64
    lddw r3, 0x1000274d8 --> b"\x00\x00\x00\x00\xb8Y\x02\x00\x10\x00\x00\x00\x00\x00\x00\x00\xd7!\x00\x0…        r3 load str located at 4295128280
    call function_18489                     
    ldxdw r3, [r2+0x8]                      
    jeq r3, 1, lbb_10868                            if r3 == (1 as i32 as i64 as u64) { pc += 223 }
    jeq r3, 0, lbb_10873                            if r3 == (0 as i32 as i64 as u64) { pc += 227 }
    jle r3, 2, lbb_10878                            if r3 <= (2 as i32 as i64 as u64) { pc += 231 }
    jeq r3, 3, lbb_10883                            if r3 == (3 as i32 as i64 as u64) { pc += 235 }
    jle r3, 4, lbb_10888                            if r3 <= (4 as i32 as i64 as u64) { pc += 239 }
    jeq r3, 5, lbb_10893                            if r3 == (5 as i32 as i64 as u64) { pc += 243 }
    jle r3, 6, lbb_10898                            if r3 <= (6 as i32 as i64 as u64) { pc += 247 }
    jeq r3, 7, lbb_10903                            if r3 == (7 as i32 as i64 as u64) { pc += 251 }
    jle r3, 8, lbb_10908                            if r3 <= (8 as i32 as i64 as u64) { pc += 255 }
    stxdw [r10-0x458], r1                   
    jeq r3, 9, lbb_10913                            if r3 == (9 as i32 as i64 as u64) { pc += 258 }
    ldxdw r4, [r2+0x0]                      
    ldxdw r3, [r2+0x48]                     
    stxdw [r10-0x470], r3                   
    ldxdw r1, [r2+0x20]                     
    stxdw [r10-0x460], r1                   
    ldxdw r6, [r2+0x58]                     
    stxdw [r10-0x480], r6                   
    ldxdw r0, [r2+0x50]                     
    stxdw [r10-0x478], r0                   
    ldxdw r1, [r2+0x10]                     
    stxdw [r10-0x468], r1                   
    ldxdw r5, [r4+0x48]                     
    add64 r5, 8                                     r5 += 8   ///  r5 = r5.wrapping_add(8 as i32 as i64 as u64)
    ldxdw r1, [r3+0x0]                      
    stxdw [r10-0x488], r1                   
    ldxdw r1, [r4+0x0]                      
    stxdw [r10-0x490], r1                   
    ldxdw r1, [r4+0x8]                      
    stxdw [r10-0x498], r1                   
    ldxdw r1, [r4+0x10]                     
    stxdw [r10-0x4a0], r1                   
    ldxdw r9, [r0+0x0]                      
    ldxdw r8, [r6+0x0]                      
    ldxdw r7, [r4+0x18]                     
    ldxdw r6, [r4+0x20]                     
    ldxdw r0, [r4+0x28]                     
    ldxdw r3, [r4+0x30]                     
    ldxdw r2, [r4+0x38]                     
    ldxdw r1, [r4+0x40]                     
    stxdw [r10-0x390], r5                   
    add64 r1, 8                                     r1 += 8   ///  r1 = r1.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x3a0], r1                   
    add64 r2, 8                                     r2 += 8   ///  r2 = r2.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x3b0], r2                   
    add64 r3, 8                                     r3 += 8   ///  r3 = r3.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x3c0], r3                   
    add64 r0, 8                                     r0 += 8   ///  r0 = r0.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x3d0], r0                   
    add64 r6, 8                                     r6 += 8   ///  r6 = r6.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x3e0], r6                   
    add64 r7, 8                                     r7 += 8   ///  r7 = r7.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x3f0], r7                   
    add64 r8, 8                                     r8 += 8   ///  r8 = r8.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x400], r8                   
    add64 r9, 8                                     r9 += 8   ///  r9 = r9.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x410], r9                   
    ldxdw r1, [r10-0x4a0]                   
    add64 r1, 8                                     r1 += 8   ///  r1 = r1.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x420], r1                   
    ldxdw r1, [r10-0x498]                   
    add64 r1, 8                                     r1 += 8   ///  r1 = r1.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x430], r1                   
    ldxdw r1, [r10-0x490]                   
    add64 r1, 8                                     r1 += 8   ///  r1 = r1.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x440], r1                   
    ldxdw r1, [r10-0x488]                   
    add64 r1, 8                                     r1 += 8   ///  r1 = r1.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x450], r1                   
    sth [r10-0x388], 1                      
    sth [r10-0x398], 0                      
    sth [r10-0x3a8], 0                      
    sth [r10-0x3b8], 0                      
    sth [r10-0x3c8], 0                      
    sth [r10-0x3d8], 1                      
    sth [r10-0x3e8], 1                      
    sth [r10-0x3f8], 1                      
    sth [r10-0x408], 1                      
    sth [r10-0x418], 1                      
    sth [r10-0x428], 0                      
    sth [r10-0x438], 0                      
    sth [r10-0x448], 257                    
    mov64 r1, r4                                    r1 = r4
    add64 r1, 72                                    r1 += 72   ///  r1 = r1.wrapping_add(72 as i32 as i64 as u64)
    stxdw [r10-0x320], r1                   
    mov64 r1, r4                                    r1 = r4
    add64 r1, 64                                    r1 += 64   ///  r1 = r1.wrapping_add(64 as i32 as i64 as u64)
    stxdw [r10-0x328], r1                   
    mov64 r1, r4                                    r1 = r4
    add64 r1, 56                                    r1 += 56   ///  r1 = r1.wrapping_add(56 as i32 as i64 as u64)
    stxdw [r10-0x330], r1                   
    mov64 r1, r4                                    r1 = r4
    add64 r1, 48                                    r1 += 48   ///  r1 = r1.wrapping_add(48 as i32 as i64 as u64)
    stxdw [r10-0x338], r1                   
    mov64 r1, r4                                    r1 = r4
    add64 r1, 40                                    r1 += 40   ///  r1 = r1.wrapping_add(40 as i32 as i64 as u64)
    stxdw [r10-0x340], r1                   
    mov64 r1, r4                                    r1 = r4
    add64 r1, 32                                    r1 += 32   ///  r1 = r1.wrapping_add(32 as i32 as i64 as u64)
    stxdw [r10-0x348], r1                   
    mov64 r1, r4                                    r1 = r4
    add64 r1, 24                                    r1 += 24   ///  r1 = r1.wrapping_add(24 as i32 as i64 as u64)
    stxdw [r10-0x350], r1                   
    ldxdw r1, [r10-0x480]                   
    stxdw [r10-0x358], r1                   
    ldxdw r1, [r10-0x478]                   
    stxdw [r10-0x360], r1                   
    mov64 r1, r4                                    r1 = r4
    add64 r1, 16                                    r1 += 16   ///  r1 = r1.wrapping_add(16 as i32 as i64 as u64)
    stxdw [r10-0x368], r1                   
    mov64 r1, r4                                    r1 = r4
    add64 r1, 8                                     r1 += 8   ///  r1 = r1.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x370], r1                   
    stxdw [r10-0x378], r4                   
    ldxdw r1, [r10-0x470]                   
    stxdw [r10-0x380], r1                   
    ldxdw r1, [r10-0x468]                   
    stxdw [r10-0x310], r1                   
    lddw r1, 0xde331ec4da5abe8f                     r1 load str located at -2435569142651502961
    stxdw [r10-0x318], r1                   
    mov64 r2, r10                                   r2 = r10
    add64 r2, -896                                  r2 += -896   ///  r2 = r2.wrapping_add(-896 as i32 as i64 as u64)
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
    mov64 r4, r10                                   r4 = r10
    add64 r4, -1096                                 r4 += -1096   ///  r4 = r4.wrapping_add(-1096 as i32 as i64 as u64)
    stdw [r10-0x308], 0                     
    ldxdw r1, [r10-0x460]                   
    ldxdw r1, [r1+0x0]                      
    add64 r1, 8                                     r1 += 8   ///  r1 = r1.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x460], r1                   
    ja lbb_10796                                    if true { pc += 20 }
lbb_10776:
    mov64 r1, r10                                   r1 = r10
    add64 r1, -768                                  r1 += -768   ///  r1 = r1.wrapping_add(-768 as i32 as i64 as u64)
    add64 r1, r3                                    r1 += r3   ///  r1 = r1.wrapping_add(r3)
    stxb [r1+0x32], r6                      
    stxb [r1+0x31], r9                      
    stxb [r1+0x30], r0                      
    mov64 r0, r5                                    r0 = r5
    add64 r0, 40                                    r0 += 40   ///  r0 = r0.wrapping_add(40 as i32 as i64 as u64)
    stxdw [r1+0x20], r0                     
    mov64 r0, r5                                    r0 = r5
    add64 r0, 88                                    r0 += 88   ///  r0 = r0.wrapping_add(88 as i32 as i64 as u64)
    stxdw [r1+0x18], r0                     
    stxdw [r1+0x10], r7                     
    add64 r5, 72                                    r5 += 72   ///  r5 = r5.wrapping_add(72 as i32 as i64 as u64)
    stxdw [r1+0x8], r5                      
    stdw [r1+0x28], 0                       
    add64 r4, 16                                    r4 += 16   ///  r4 = r4.wrapping_add(16 as i32 as i64 as u64)
    add64 r2, 8                                     r2 += 8   ///  r2 = r2.wrapping_add(8 as i32 as i64 as u64)
    add64 r3, 56                                    r3 += 56   ///  r3 = r3.wrapping_add(56 as i32 as i64 as u64)
    jeq r3, 728, lbb_10846                          if r3 == (728 as i32 as i64 as u64) { pc += 50 }
lbb_10796:
    mov64 r0, r10                                   r0 = r10
    add64 r0, -768                                  r0 += -768   ///  r0 = r0.wrapping_add(-768 as i32 as i64 as u64)
    mov64 r7, 1                                     r7 = 1 as i32 as i64 as u64
    ldxdw r1, [r2+0x0]                      
    ldxdw r5, [r1+0x0]                      
    ldxdw r6, [r4-0x8]                      
    ldxdw r1, [r6+0x0]                      
    ldxdw r8, [r5+0x8]                      
    jne r8, r1, lbb_10865                           if r8 != r1 { pc += 60 }
    ldxdw r1, [r6+0x8]                      
    ldxdw r8, [r5+0x10]                     
    jne r8, r1, lbb_10865                           if r8 != r1 { pc += 57 }
    ldxdw r1, [r6+0x10]                     
    ldxdw r8, [r5+0x18]                     
    jne r8, r1, lbb_10865                           if r8 != r1 { pc += 54 }
    ldxdw r1, [r6+0x18]                     
    ldxdw r6, [r5+0x20]                     
    jne r6, r1, lbb_10865                           if r6 != r1 { pc += 51 }
    ldxb r6, [r4+0x0]                       
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    jne r6, 0, lbb_10818                            if r6 != (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r1, 119                                   r1 = 119 as i32 as i64 as u64
lbb_10818:
    ldxb r6, [r5+0x0]                       
    or64 r1, r6                                     r1 |= r6   ///  r1 = r1.or(r6)
    and64 r1, 255                                   r1 &= 255   ///  r1 = r1.and(255)
    jne r1, 255, lbb_10844                          if r1 != (255 as i32 as i64 as u64) { pc += 22 }
    add64 r0, r3                                    r0 += r3   ///  r0 = r0.wrapping_add(r3)
    mov64 r6, r5                                    r6 = r5
    add64 r6, 8                                     r6 += 8   ///  r6 = r6.wrapping_add(8 as i32 as i64 as u64)
    ldxdw r7, [r5+0x50]                     
    ldxb r8, [r5+0x3]                       
    ldxb r1, [r5+0x2]                       
    ldxb r9, [r5+0x1]                       
    stxdw [r0+0x0], r6                      
    mov64 r6, 1                                     r6 = 1 as i32 as i64 as u64
    mov64 r0, 1                                     r0 = 1 as i32 as i64 as u64
    jeq r9, 0, lbb_10837                            if r9 == (0 as i32 as i64 as u64) { pc += 4 }
    mov64 r9, 1                                     r9 = 1 as i32 as i64 as u64
    jeq r1, 0, lbb_10840                            if r1 == (0 as i32 as i64 as u64) { pc += 5 }
lbb_10835:
    jne r8, 0, lbb_10776                            if r8 != (0 as i32 as i64 as u64) { pc += -60 }
    ja lbb_10842                                    if true { pc += 5 }
lbb_10837:
    mov64 r0, 0                                     r0 = 0 as i32 as i64 as u64
    mov64 r9, 1                                     r9 = 1 as i32 as i64 as u64
    jne r1, 0, lbb_10835                            if r1 != (0 as i32 as i64 as u64) { pc += -5 }
lbb_10840:
    mov64 r9, 0                                     r9 = 0 as i32 as i64 as u64
    jne r8, 0, lbb_10776                            if r8 != (0 as i32 as i64 as u64) { pc += -66 }
lbb_10842:
    mov64 r6, 0                                     r6 = 0 as i32 as i64 as u64
    ja lbb_10776                                    if true { pc += -68 }
lbb_10844:
    mov64 r7, 11                                    r7 = 11 as i32 as i64 as u64
    ja lbb_10865                                    if true { pc += 19 }
lbb_10846:
    mov64 r1, r10                                   r1 = r10
    add64 r1, -792                                  r1 += -792   ///  r1 = r1.wrapping_add(-792 as i32 as i64 as u64)
    stxdw [r10-0x10], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -1104                                 r1 += -1104   ///  r1 = r1.wrapping_add(-1104 as i32 as i64 as u64)
    stxdw [r10-0x20], r1                    
    ldxdw r1, [r10-0x460]                   
    stxdw [r10-0x28], r1                    
    stdw [r10-0x8], 24                      
    stdw [r10-0x18], 13                     
    mov64 r1, r10                                   r1 = r10
    add64 r1, -40                                   r1 += -40   ///  r1 = r1.wrapping_add(-40 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -768                                  r2 += -768   ///  r2 = r2.wrapping_add(-768 as i32 as i64 as u64)
    mov64 r3, 13                                    r3 = 13 as i32 as i64 as u64
    mov64 r4, 8                                     r4 = 8 as i32 as i64 as u64
    mov64 r5, 0                                     r5 = 0 as i32 as i64 as u64
    syscall [invalid]                       
    mov64 r7, 26                                    r7 = 26 as i32 as i64 as u64
lbb_10865:
    ldxdw r1, [r10-0x458]                   
    stxw [r1+0x0], r7                       
    exit                                    
lbb_10868:
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    mov64 r2, 1                                     r2 = 1 as i32 as i64 as u64
    lddw r3, 0x100027508 --> b"\x00\x00\x00\x00\xb8Y\x02\x00\x10\x00\x00\x00\x00\x00\x00\x00\xe1!\x00\x0…        r3 load str located at 4295128328
    call function_18489                     
lbb_10873:
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
    lddw r3, 0x1000274f0 --> b"\x00\x00\x00\x00\xb8Y\x02\x00\x10\x00\x00\x00\x00\x00\x00\x00\xe1!\x00\x0…        r3 load str located at 4295128304
    call function_18489                     
lbb_10878:
    mov64 r1, 2                                     r1 = 2 as i32 as i64 as u64
    mov64 r2, 2                                     r2 = 2 as i32 as i64 as u64
    lddw r3, 0x100027520 --> b"\x00\x00\x00\x00\xb8Y\x02\x00\x10\x00\x00\x00\x00\x00\x00\x00\xe1!\x00\x0…        r3 load str located at 4295128352
    call function_18489                     
lbb_10883:
    mov64 r1, 3                                     r1 = 3 as i32 as i64 as u64
    mov64 r2, 3                                     r2 = 3 as i32 as i64 as u64
    lddw r3, 0x100027538 --> b"\x00\x00\x00\x00\xb8Y\x02\x00\x10\x00\x00\x00\x00\x00\x00\x00\xe3!\x00\x0…        r3 load str located at 4295128376
    call function_18489                     
lbb_10888:
    mov64 r1, 4                                     r1 = 4 as i32 as i64 as u64
    mov64 r2, 4                                     r2 = 4 as i32 as i64 as u64
    lddw r3, 0x100027550 --> b"\x00\x00\x00\x00\xb8Y\x02\x00\x10\x00\x00\x00\x00\x00\x00\x00\xe3!\x00\x0…        r3 load str located at 4295128400
    call function_18489                     
lbb_10893:
    mov64 r1, 5                                     r1 = 5 as i32 as i64 as u64
    mov64 r2, 5                                     r2 = 5 as i32 as i64 as u64
    lddw r3, 0x100027568 --> b"\x00\x00\x00\x00\xb8Y\x02\x00\x10\x00\x00\x00\x00\x00\x00\x00\xe3!\x00\x0…        r3 load str located at 4295128424
    call function_18489                     
lbb_10898:
    mov64 r1, 6                                     r1 = 6 as i32 as i64 as u64
    mov64 r2, 6                                     r2 = 6 as i32 as i64 as u64
    lddw r3, 0x100027580 --> b"\x00\x00\x00\x00\xb8Y\x02\x00\x10\x00\x00\x00\x00\x00\x00\x00\xe3!\x00\x0…        r3 load str located at 4295128448
    call function_18489                     
lbb_10903:
    mov64 r1, 7                                     r1 = 7 as i32 as i64 as u64
    mov64 r2, 7                                     r2 = 7 as i32 as i64 as u64
    lddw r3, 0x100027598 --> b"\x00\x00\x00\x00\xb8Y\x02\x00\x10\x00\x00\x00\x00\x00\x00\x00\xe4!\x00\x0…        r3 load str located at 4295128472
    call function_18489                     
lbb_10908:
    mov64 r1, 8                                     r1 = 8 as i32 as i64 as u64
    mov64 r2, 8                                     r2 = 8 as i32 as i64 as u64
    lddw r3, 0x1000275b0 --> b"\x00\x00\x00\x00\xb8Y\x02\x00\x10\x00\x00\x00\x00\x00\x00\x00\xe4!\x00\x0…        r3 load str located at 4295128496
    call function_18489                     
lbb_10913:
    mov64 r1, 9                                     r1 = 9 as i32 as i64 as u64
    mov64 r2, 9                                     r2 = 9 as i32 as i64 as u64
    lddw r3, 0x1000275c8 --> b"\x00\x00\x00\x00\xb8Y\x02\x00\x10\x00\x00\x00\x00\x00\x00\x00\xe4!\x00\x0…        r3 load str located at 4295128520
    call function_18489                     
    ldxdw r0, [r2+0x8]                      
    mov64 r4, r0                                    r4 = r0
    add64 r4, -11                                   r4 += -11   ///  r4 = r4.wrapping_add(-11 as i32 as i64 as u64)
    mov64 r5, 0                                     r5 = 0 as i32 as i64 as u64
    mov64 r3, 1                                     r3 = 1 as i32 as i64 as u64
    jle r4, r0, lbb_11098                           if r4 <= r0 { pc += 174 }
    jeq r3, 0, lbb_11100                            if r3 == (0 as i32 as i64 as u64) { pc += 175 }
lbb_10925:
    jeq r0, 1, lbb_11102                            if r0 == (1 as i32 as i64 as u64) { pc += 176 }
lbb_10926:
    jeq r0, 0, lbb_11173                            if r0 == (0 as i32 as i64 as u64) { pc += 246 }
    jle r0, 2, lbb_11178                            if r0 <= (2 as i32 as i64 as u64) { pc += 250 }
    jeq r0, 3, lbb_11183                            if r0 == (3 as i32 as i64 as u64) { pc += 254 }
    jle r0, 4, lbb_11188                            if r0 <= (4 as i32 as i64 as u64) { pc += 258 }
    jeq r0, 5, lbb_11193                            if r0 == (5 as i32 as i64 as u64) { pc += 262 }
    jle r0, 6, lbb_11198                            if r0 <= (6 as i32 as i64 as u64) { pc += 266 }
    jeq r0, 7, lbb_11203                            if r0 == (7 as i32 as i64 as u64) { pc += 270 }
    jle r0, 8, lbb_11208                            if r0 <= (8 as i32 as i64 as u64) { pc += 274 }
    jeq r0, 9, lbb_11213                            if r0 == (9 as i32 as i64 as u64) { pc += 278 }
    jle r0, 10, lbb_11218                           if r0 <= (10 as i32 as i64 as u64) { pc += 282 }
    mov64 r3, r5                                    r3 = r5
    add64 r3, 15                                    r3 += 15   ///  r3 = r3.wrapping_add(15 as i32 as i64 as u64)
    jgt r3, 32, lbb_11171                           if r3 > (32 as i32 as i64 as u64) { pc += 232 }
    stxdw [r10-0x220], r3                   
    stxdw [r10-0x290], r5                   
    stxdw [r10-0x288], r1                   
    ldxdw r4, [r2+0x58]                     
    stxdw [r10-0x240], r4                   
    ldxdw r3, [r2+0x50]                     
    stxdw [r10-0x238], r3                   
    ldxdw r1, [r2+0x48]                     
    stxdw [r10-0x218], r1                   
    ldxdw r5, [r2+0x28]                     
    stxdw [r10-0x248], r5                   
    ldxdw r1, [r2+0x20]                     
    stxdw [r10-0x230], r0                   
    ldxdw r0, [r2+0x0]                      
    ldxdw r2, [r2+0x10]                     
    stxdw [r10-0x228], r2                   
    ldxdw r1, [r1+0x0]                      
    stxdw [r10-0x280], r1                   
    ldxdw r5, [r5+0x0]                      
    add64 r5, 8                                     r5 += 8   ///  r5 = r5.wrapping_add(8 as i32 as i64 as u64)
    ldxdw r1, [r0+0x0]                      
    stxdw [r10-0x250], r1                   
    ldxdw r1, [r3+0x0]                      
    stxdw [r10-0x258], r1                   
    ldxdw r1, [r4+0x0]                      
    stxdw [r10-0x260], r1                   
    ldxdw r1, [r0+0x8]                      
    stxdw [r10-0x268], r1                   
    ldxdw r1, [r0+0x10]                     
    stxdw [r10-0x270], r1                   
    ldxdw r1, [r0+0x18]                     
    stxdw [r10-0x278], r1                   
    ldxdw r2, [r0+0x20]                     
    ldxdw r1, [r0+0x28]                     
    ldxdw r3, [r0+0x30]                     
    ldxdw r9, [r0+0x38]                     
    ldxdw r7, [r0+0x40]                     
    ldxdw r8, [r0+0x48]                     
    ldxdw r4, [r10-0x218]                   
    ldxdw r6, [r4+0x0]                      
    ldxdw r4, [r0+0x50]                     
    stxdw [r10-0x128], r5                   
    ldxdw r5, [r10-0x280]                   
    add64 r4, 8                                     r4 += 8   ///  r4 = r4.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x138], r4                   
    add64 r6, 8                                     r6 += 8   ///  r6 = r6.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x148], r6                   
    add64 r8, 8                                     r8 += 8   ///  r8 = r8.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x158], r8                   
    add64 r7, 8                                     r7 += 8   ///  r7 = r7.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x168], r7                   
    add64 r9, 8                                     r9 += 8   ///  r9 = r9.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x178], r9                   
    add64 r3, 8                                     r3 += 8   ///  r3 = r3.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x188], r3                   
    add64 r1, 8                                     r1 += 8   ///  r1 = r1.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x198], r1                   
    add64 r2, 8                                     r2 += 8   ///  r2 = r2.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x1a8], r2                   
    ldxdw r1, [r10-0x278]                   
    add64 r1, 8                                     r1 += 8   ///  r1 = r1.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x1b8], r1                   
    ldxdw r1, [r10-0x270]                   
    add64 r1, 8                                     r1 += 8   ///  r1 = r1.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x1c8], r1                   
    ldxdw r1, [r10-0x268]                   
    add64 r1, 8                                     r1 += 8   ///  r1 = r1.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x1d8], r1                   
    ldxdw r1, [r10-0x260]                   
    add64 r1, 8                                     r1 += 8   ///  r1 = r1.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x1e8], r1                   
    ldxdw r1, [r10-0x258]                   
    add64 r1, 8                                     r1 += 8   ///  r1 = r1.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x1f8], r1                   
    ldxdw r1, [r10-0x250]                   
    add64 r1, 8                                     r1 += 8   ///  r1 = r1.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x208], r1                   
    add64 r5, 8                                     r5 += 8   ///  r5 = r5.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0xe8], r5                    
    stxdw [r10-0xf8], r5                    
    stxdw [r10-0x108], r5                   
    stxdw [r10-0x118], r5                   
    sth [r10-0xe0], 0                       
    sth [r10-0xf0], 0                       
    sth [r10-0x100], 0                      
    sth [r10-0x110], 0                      
    sth [r10-0x120], 0                      
    sth [r10-0x130], 0                      
    sth [r10-0x140], 257                    
    sth [r10-0x150], 1                      
    sth [r10-0x160], 1                      
    sth [r10-0x170], 1                      
    sth [r10-0x180], 1                      
    sth [r10-0x190], 1                      
    sth [r10-0x1a0], 1                      
    sth [r10-0x1b0], 1                      
    sth [r10-0x1c0], 1                      
    sth [r10-0x1d0], 1                      
    sth [r10-0x1e0], 1                      
    sth [r10-0x1f0], 1                      
    sth [r10-0x200], 1                      
    ldxdw r1, [r10-0x248]                   
    stxdw [r10-0x68], r1                    
    mov64 r1, r0                                    r1 = r0
    add64 r1, 80                                    r1 += 80   ///  r1 = r1.wrapping_add(80 as i32 as i64 as u64)
    stxdw [r10-0x70], r1                    
    ldxdw r1, [r10-0x218]                   
    stxdw [r10-0x48], r1                    
    stxdw [r10-0x50], r1                    
    stxdw [r10-0x58], r1                    
    stxdw [r10-0x60], r1                    
    stxdw [r10-0x78], r1                    
    mov64 r1, r0                                    r1 = r0
    add64 r1, 72                                    r1 += 72   ///  r1 = r1.wrapping_add(72 as i32 as i64 as u64)
    stxdw [r10-0x80], r1                    
    mov64 r1, r0                                    r1 = r0
    add64 r1, 64                                    r1 += 64   ///  r1 = r1.wrapping_add(64 as i32 as i64 as u64)
    stxdw [r10-0x88], r1                    
    mov64 r1, r0                                    r1 = r0
    add64 r1, 56                                    r1 += 56   ///  r1 = r1.wrapping_add(56 as i32 as i64 as u64)
    stxdw [r10-0x90], r1                    
    mov64 r1, r0                                    r1 = r0
    add64 r1, 48                                    r1 += 48   ///  r1 = r1.wrapping_add(48 as i32 as i64 as u64)
    stxdw [r10-0x98], r1                    
    mov64 r1, r0                                    r1 = r0
    add64 r1, 40                                    r1 += 40   ///  r1 = r1.wrapping_add(40 as i32 as i64 as u64)
    stxdw [r10-0xa0], r1                    
    mov64 r1, r0                                    r1 = r0
    add64 r1, 32                                    r1 += 32   ///  r1 = r1.wrapping_add(32 as i32 as i64 as u64)
    stxdw [r10-0xa8], r1                    
    mov64 r1, r0                                    r1 = r0
    add64 r1, 24                                    r1 += 24   ///  r1 = r1.wrapping_add(24 as i32 as i64 as u64)
    stxdw [r10-0xb0], r1                    
    mov64 r1, r0                                    r1 = r0
    add64 r1, 16                                    r1 += 16   ///  r1 = r1.wrapping_add(16 as i32 as i64 as u64)
    stxdw [r10-0xb8], r1                    
    mov64 r1, r0                                    r1 = r0
    add64 r1, 8                                     r1 += 8   ///  r1 = r1.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0xc0], r1                    
    ldxdw r1, [r10-0x240]                   
    stxdw [r10-0xc8], r1                    
    ldxdw r1, [r10-0x238]                   
    stxdw [r10-0xd0], r1                    
    stxdw [r10-0xd8], r0                    
    ldxdw r1, [r10-0x230]                   
    jne r1, 11, lbb_11107                           if r1 != (11 as i32 as i64 as u64) { pc += 22 }
    ldxdw r1, [r10-0x228]                   
    stxdw [r10-0x38], r1                    
    lddw r1, 0xc88775e1919ec6f8                     r1 load str located at -3997096532596832520
    stxdw [r10-0x40], r1                    
    stdw [r10-0x30], 0                      
    ldxdw r4, [r10-0x220]                   
    jlt r4, 20, lbb_11146                           if r4 < (20 as i32 as i64 as u64) { pc += 53 }
    mov64 r1, r4                                    r1 = r4
    mov64 r2, 19                                    r2 = 19 as i32 as i64 as u64
    lddw r3, 0x100025b58 --> b"\x00\x00\x00\x00\xb8Y\x02\x00\x10\x00\x00\x00\x00\x00\x00\x00\xbe\x05\x00…        r3 load str located at 4295121752
    call function_18737                     
lbb_11098:
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
    jne r3, 0, lbb_10925                            if r3 != (0 as i32 as i64 as u64) { pc += -175 }
lbb_11100:
    mov64 r5, r4                                    r5 = r4
    jne r0, 1, lbb_10926                            if r0 != (1 as i32 as i64 as u64) { pc += -176 }
lbb_11102:
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    mov64 r2, 1                                     r2 = 1 as i32 as i64 as u64
    lddw r3, 0x1000275f8 --> b"\x00\x00\x00\x00\xb8Y\x02\x00\x10\x00\x00\x00\x00\x00\x00\x00\xf2!\x00\x0…        r3 load str located at 4295128568
    call function_18489                     
lbb_11107:
    ldxdw r4, [r10-0x228]                   
    mov64 r1, r0                                    r1 = r0
    add64 r1, 88                                    r1 += 88   ///  r1 = r1.wrapping_add(88 as i32 as i64 as u64)
    ldxdw r2, [r1+0x0]                      
    stxdw [r10-0x60], r1                    
    add64 r2, 8                                     r2 += 8   ///  r2 = r2.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x118], r2                   
    sth [r10-0x110], 0                      
    ldxdw r3, [r10-0x290]                   
    jeq r3, 1, lbb_11140                            if r3 == (1 as i32 as i64 as u64) { pc += 23 }
    ldxdw r1, [r0+0x60]                     
    mov64 r2, r0                                    r2 = r0
    add64 r2, 96                                    r2 += 96   ///  r2 = r2.wrapping_add(96 as i32 as i64 as u64)
    stxdw [r10-0x58], r2                    
    add64 r1, 8                                     r1 += 8   ///  r1 = r1.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x108], r1                   
    sth [r10-0x100], 0                      
    jeq r3, 2, lbb_11140                            if r3 == (2 as i32 as i64 as u64) { pc += 15 }
    ldxdw r1, [r0+0x68]                     
    mov64 r2, r0                                    r2 = r0
    add64 r2, 104                                   r2 += 104   ///  r2 = r2.wrapping_add(104 as i32 as i64 as u64)
    stxdw [r10-0x50], r2                    
    add64 r1, 8                                     r1 += 8   ///  r1 = r1.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0xf8], r1                    
    sth [r10-0xf0], 0                       
    jeq r3, 3, lbb_11140                            if r3 == (3 as i32 as i64 as u64) { pc += 7 }
    ldxdw r1, [r0+0x70]                     
    add64 r0, 112                                   r0 += 112   ///  r0 = r0.wrapping_add(112 as i32 as i64 as u64)
    stxdw [r10-0x48], r0                    
    add64 r1, 8                                     r1 += 8   ///  r1 = r1.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0xe8], r1                    
    sth [r10-0xe0], 0                       
    jne r3, 4, lbb_11223                            if r3 != (4 as i32 as i64 as u64) { pc += 83 }
lbb_11140:
    stxdw [r10-0x38], r4                    
    lddw r1, 0xc88775e1919ec6f8                     r1 load str located at -3997096532596832520
    stxdw [r10-0x40], r1                    
    stdw [r10-0x30], 0                      
    ldxdw r4, [r10-0x220]                   
lbb_11146:
    mov64 r1, r10                                   r1 = r10
    add64 r1, -520                                  r1 += -520   ///  r1 = r1.wrapping_add(-520 as i32 as i64 as u64)
    stxdw [r10-0x10], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -64                                   r1 += -64   ///  r1 = r1.wrapping_add(-64 as i32 as i64 as u64)
    stxdw [r10-0x20], r1                    
    stxdw [r10-0x28], r5                    
    stxdw [r10-0x8], r4                     
    stdw [r10-0x18], 24                     
    stdw [r10-0xff8], 0                     
    stdw [r10-0x1000], 8                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -528                                  r1 += -528   ///  r1 = r1.wrapping_add(-528 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -40                                   r2 += -40   ///  r2 = r2.wrapping_add(-40 as i32 as i64 as u64)
    mov64 r3, r10                                   r3 = r10
    add64 r3, -216                                  r3 += -216   ///  r3 = r3.wrapping_add(-216 as i32 as i64 as u64)
    mov64 r5, r10                                   r5 = r10
    call function_18367                     
    ldxw r2, [r10-0x20c]                    
    ldxw r3, [r10-0x210]                    
    ldxdw r1, [r10-0x288]                   
lbb_11168:
    stxw [r1+0x4], r2                       
    stxw [r1+0x0], r3                       
    exit                                    
lbb_11171:
    mov64 r3, 3                                     r3 = 3 as i32 as i64 as u64
    ja lbb_11168                                    if true { pc += -5 }
lbb_11173:
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
    lddw r3, 0x1000275e0 --> b"\x00\x00\x00\x00\xb8Y\x02\x00\x10\x00\x00\x00\x00\x00\x00\x00\xf2!\x00\x0…        r3 load str located at 4295128544
    call function_18489                     
lbb_11178:
    mov64 r1, 2                                     r1 = 2 as i32 as i64 as u64
    mov64 r2, 2                                     r2 = 2 as i32 as i64 as u64
    lddw r3, 0x100027610 --> b"\x00\x00\x00\x00\xb8Y\x02\x00\x10\x00\x00\x00\x00\x00\x00\x00\xf2!\x00\x0…        r3 load str located at 4295128592
    call function_18489                     
lbb_11183:
    mov64 r1, 3                                     r1 = 3 as i32 as i64 as u64
    mov64 r2, 3                                     r2 = 3 as i32 as i64 as u64
    lddw r3, 0x100027628 --> b"\x00\x00\x00\x00\xb8Y\x02\x00\x10\x00\x00\x00\x00\x00\x00\x00\xf2!\x00\x0…        r3 load str located at 4295128616
    call function_18489                     
lbb_11188:
    mov64 r1, 4                                     r1 = 4 as i32 as i64 as u64
    mov64 r2, 4                                     r2 = 4 as i32 as i64 as u64
    lddw r3, 0x100027640 --> b"\x00\x00\x00\x00\xb8Y\x02\x00\x10\x00\x00\x00\x00\x00\x00\x00\xf3!\x00\x0…        r3 load str located at 4295128640
    call function_18489                     
lbb_11193:
    mov64 r1, 5                                     r1 = 5 as i32 as i64 as u64
    mov64 r2, 5                                     r2 = 5 as i32 as i64 as u64
    lddw r3, 0x100027658 --> b"\x00\x00\x00\x00\xb8Y\x02\x00\x10\x00\x00\x00\x00\x00\x00\x00\xf3!\x00\x0…        r3 load str located at 4295128664
    call function_18489                     
lbb_11198:
    mov64 r1, 6                                     r1 = 6 as i32 as i64 as u64
    mov64 r2, 6                                     r2 = 6 as i32 as i64 as u64
    lddw r3, 0x100027670 --> b"\x00\x00\x00\x00\xb8Y\x02\x00\x10\x00\x00\x00\x00\x00\x00\x00\xf3!\x00\x0…        r3 load str located at 4295128688
    call function_18489                     
lbb_11203:
    mov64 r1, 7                                     r1 = 7 as i32 as i64 as u64
    mov64 r2, 7                                     r2 = 7 as i32 as i64 as u64
    lddw r3, 0x100027688 --> b"\x00\x00\x00\x00\xb8Y\x02\x00\x10\x00\x00\x00\x00\x00\x00\x00\xf3!\x00\x0…        r3 load str located at 4295128712
    call function_18489                     
lbb_11208:
    mov64 r1, 8                                     r1 = 8 as i32 as i64 as u64
    mov64 r2, 8                                     r2 = 8 as i32 as i64 as u64
    lddw r3, 0x1000276a0 --> b"\x00\x00\x00\x00\xb8Y\x02\x00\x10\x00\x00\x00\x00\x00\x00\x00\xf4!\x00\x0…        r3 load str located at 4295128736
    call function_18489                     
lbb_11213:
    mov64 r1, 9                                     r1 = 9 as i32 as i64 as u64
    mov64 r2, 9                                     r2 = 9 as i32 as i64 as u64
    lddw r3, 0x1000276b8 --> b"\x00\x00\x00\x00\xb8Y\x02\x00\x10\x00\x00\x00\x00\x00\x00\x00\xf4!\x00\x0…        r3 load str located at 4295128760
    call function_18489                     
lbb_11218:
    mov64 r1, 10                                    r1 = 10 as i32 as i64 as u64
    mov64 r2, 10                                    r2 = 10 as i32 as i64 as u64
    lddw r3, 0x1000276d0 --> b"\x00\x00\x00\x00\xb8Y\x02\x00\x10\x00\x00\x00\x00\x00\x00\x00\xf4!\x00\x0…        r3 load str located at 4295128784
    call function_18489                     
lbb_11223:
    mov64 r1, 19                                    r1 = 19 as i32 as i64 as u64
    mov64 r2, 19                                    r2 = 19 as i32 as i64 as u64
    lddw r3, 0x100025b70 --> b"\x00\x00\x00\x00\xb8Y\x02\x00\x10\x00\x00\x00\x00\x00\x00\x00\xb1\x05\x00…        r3 load str located at 4295121776
    call function_18489                     
    ldxdw r3, [r2+0x8]                      
    jeq r3, 1, lbb_11403                            if r3 == (1 as i32 as i64 as u64) { pc += 173 }
    jeq r3, 0, lbb_11408                            if r3 == (0 as i32 as i64 as u64) { pc += 177 }
    jle r3, 2, lbb_11413                            if r3 <= (2 as i32 as i64 as u64) { pc += 181 }
    stxdw [r10-0x2d0], r1                   
    jeq r3, 3, lbb_11418                            if r3 == (3 as i32 as i64 as u64) { pc += 184 }
    ldxdw r4, [r2+0x0]                      
    ldxdw r3, [r2+0x28]                     
    stxdw [r10-0x2e0], r3                   
    ldxdw r1, [r2+0x20]                     
    stxdw [r10-0x2c8], r1                   
    ldxdw r1, [r2+0x10]                     
    stxdw [r10-0x2d8], r1                   
    ldxdw r7, [r2+0x58]                     
    ldxdw r1, [r2+0x50]                     
    stxdw [r10-0x2f0], r1                   
    ldxdw r2, [r2+0x48]                     
    stxdw [r10-0x2e8], r2                   
    ldxdw r6, [r2+0x0]                      
    add64 r6, 8                                     r6 += 8   ///  r6 = r6.wrapping_add(8 as i32 as i64 as u64)
    ldxdw r8, [r3+0x0]                      
    ldxdw r9, [r4+0x0]                      
    ldxdw r0, [r4+0x8]                      
    ldxdw r5, [r4+0x10]                     
    ldxdw r3, [r4+0x18]                     
    ldxdw r2, [r1+0x0]                      
    ldxdw r1, [r7+0x0]                      
    stxdw [r10-0x250], r6                   
    add64 r1, 8                                     r1 += 8   ///  r1 = r1.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x260], r1                   
    add64 r2, 8                                     r2 += 8   ///  r2 = r2.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x270], r2                   
    add64 r3, 8                                     r3 += 8   ///  r3 = r3.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x280], r3                   
    add64 r5, 8                                     r5 += 8   ///  r5 = r5.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x290], r5                   
    add64 r0, 8                                     r0 += 8   ///  r0 = r0.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x2a0], r0                   
    add64 r9, 8                                     r9 += 8   ///  r9 = r9.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x2b0], r9                   
    add64 r8, 8                                     r8 += 8   ///  r8 = r8.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x2c0], r8                   
    sth [r10-0x248], 257                    
    sth [r10-0x258], 1                      
    sth [r10-0x268], 1                      
    sth [r10-0x278], 1                      
    sth [r10-0x288], 1                      
    sth [r10-0x298], 0                      
    sth [r10-0x2a8], 1                      
    sth [r10-0x2b8], 0                      
    ldxdw r1, [r10-0x2e8]                   
    stxdw [r10-0x208], r1                   
    stxdw [r10-0x210], r7                   
    ldxdw r1, [r10-0x2f0]                   
    stxdw [r10-0x218], r1                   
    mov64 r1, r4                                    r1 = r4
    add64 r1, 24                                    r1 += 24   ///  r1 = r1.wrapping_add(24 as i32 as i64 as u64)
    stxdw [r10-0x220], r1                   
    mov64 r1, r4                                    r1 = r4
    add64 r1, 16                                    r1 += 16   ///  r1 = r1.wrapping_add(16 as i32 as i64 as u64)
    stxdw [r10-0x228], r1                   
    mov64 r1, r4                                    r1 = r4
    add64 r1, 8                                     r1 += 8   ///  r1 = r1.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x230], r1                   
    stxdw [r10-0x238], r4                   
    ldxdw r1, [r10-0x2e0]                   
    stxdw [r10-0x240], r1                   
    ldxdw r1, [r10-0x2d8]                   
    stxdw [r10-0x1f8], r1                   
    mov64 r2, r10                                   r2 = r10
    add64 r2, -576                                  r2 += -576   ///  r2 = r2.wrapping_add(-576 as i32 as i64 as u64)
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
    mov64 r4, r10                                   r4 = r10
    add64 r4, -696                                  r4 += -696   ///  r4 = r4.wrapping_add(-696 as i32 as i64 as u64)
    stb [r10-0x1f9], 16                     
    stdw [r10-0x1f0], 0                     
    ldxdw r1, [r10-0x2c8]                   
    ldxdw r1, [r1+0x0]                      
    add64 r1, 8                                     r1 += 8   ///  r1 = r1.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x2d8], r1                   
    ja lbb_11330                                    if true { pc += 21 }
lbb_11309:
    mov64 r1, r10                                   r1 = r10
    add64 r1, -488                                  r1 += -488   ///  r1 = r1.wrapping_add(-488 as i32 as i64 as u64)
    add64 r1, r3                                    r1 += r3   ///  r1 = r1.wrapping_add(r3)
    stxb [r1+0x32], r8                      
    stxb [r1+0x31], r6                      
    stxb [r1+0x30], r0                      
    mov64 r0, r5                                    r0 = r5
    add64 r0, 40                                    r0 += 40   ///  r0 = r0.wrapping_add(40 as i32 as i64 as u64)
    stxdw [r1+0x20], r0                     
    mov64 r0, r5                                    r0 = r5
    add64 r0, 88                                    r0 += 88   ///  r0 = r0.wrapping_add(88 as i32 as i64 as u64)
    stxdw [r1+0x18], r0                     
    ldxdw r0, [r10-0x2c8]                   
    stxdw [r1+0x10], r0                     
    add64 r5, 72                                    r5 += 72   ///  r5 = r5.wrapping_add(72 as i32 as i64 as u64)
    stxdw [r1+0x8], r5                      
    stdw [r1+0x28], 0                       
    add64 r4, 16                                    r4 += 16   ///  r4 = r4.wrapping_add(16 as i32 as i64 as u64)
    add64 r2, 8                                     r2 += 8   ///  r2 = r2.wrapping_add(8 as i32 as i64 as u64)
    add64 r3, 56                                    r3 += 56   ///  r3 = r3.wrapping_add(56 as i32 as i64 as u64)
    jeq r3, 448, lbb_11381                          if r3 == (448 as i32 as i64 as u64) { pc += 51 }
lbb_11330:
    mov64 r0, r10                                   r0 = r10
    add64 r0, -488                                  r0 += -488   ///  r0 = r0.wrapping_add(-488 as i32 as i64 as u64)
    mov64 r7, 1                                     r7 = 1 as i32 as i64 as u64
    ldxdw r1, [r2+0x0]                      
    ldxdw r5, [r1+0x0]                      
    ldxdw r6, [r4-0x8]                      
    ldxdw r1, [r6+0x0]                      
    ldxdw r8, [r5+0x8]                      
    jne r8, r1, lbb_11400                           if r8 != r1 { pc += 61 }
    ldxdw r1, [r6+0x8]                      
    ldxdw r8, [r5+0x10]                     
    jne r8, r1, lbb_11400                           if r8 != r1 { pc += 58 }
    ldxdw r1, [r6+0x10]                     
    ldxdw r8, [r5+0x18]                     
    jne r8, r1, lbb_11400                           if r8 != r1 { pc += 55 }
    ldxdw r1, [r6+0x18]                     
    ldxdw r6, [r5+0x20]                     
    jne r6, r1, lbb_11400                           if r6 != r1 { pc += 52 }
    ldxb r6, [r4+0x0]                       
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    jne r6, 0, lbb_11352                            if r6 != (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r1, 119                                   r1 = 119 as i32 as i64 as u64
lbb_11352:
    ldxb r6, [r5+0x0]                       
    or64 r1, r6                                     r1 |= r6   ///  r1 = r1.or(r6)
    and64 r1, 255                                   r1 &= 255   ///  r1 = r1.and(255)
    jne r1, 255, lbb_11379                          if r1 != (255 as i32 as i64 as u64) { pc += 23 }
    add64 r0, r3                                    r0 += r3   ///  r0 = r0.wrapping_add(r3)
    mov64 r6, r5                                    r6 = r5
    add64 r6, 8                                     r6 += 8   ///  r6 = r6.wrapping_add(8 as i32 as i64 as u64)
    ldxdw r1, [r5+0x50]                     
    stxdw [r10-0x2c8], r1                   
    ldxb r9, [r5+0x3]                       
    ldxb r1, [r5+0x2]                       
    ldxb r7, [r5+0x1]                       
    stxdw [r0+0x0], r6                      
    mov64 r8, 1                                     r8 = 1 as i32 as i64 as u64
    mov64 r0, 1                                     r0 = 1 as i32 as i64 as u64
    jeq r7, 0, lbb_11372                            if r7 == (0 as i32 as i64 as u64) { pc += 4 }
    mov64 r6, 1                                     r6 = 1 as i32 as i64 as u64
    jeq r1, 0, lbb_11375                            if r1 == (0 as i32 as i64 as u64) { pc += 5 }
lbb_11370:
    jne r9, 0, lbb_11309                            if r9 != (0 as i32 as i64 as u64) { pc += -62 }
    ja lbb_11377                                    if true { pc += 5 }
lbb_11372:
    mov64 r0, 0                                     r0 = 0 as i32 as i64 as u64
    mov64 r6, 1                                     r6 = 1 as i32 as i64 as u64
    jne r1, 0, lbb_11370                            if r1 != (0 as i32 as i64 as u64) { pc += -5 }
lbb_11375:
    mov64 r6, 0                                     r6 = 0 as i32 as i64 as u64
    jne r9, 0, lbb_11309                            if r9 != (0 as i32 as i64 as u64) { pc += -68 }
lbb_11377:
    mov64 r8, 0                                     r8 = 0 as i32 as i64 as u64
    ja lbb_11309                                    if true { pc += -70 }
lbb_11379:
    mov64 r7, 11                                    r7 = 11 as i32 as i64 as u64
    ja lbb_11400                                    if true { pc += 19 }
lbb_11381:
    mov64 r1, r10                                   r1 = r10
    add64 r1, -505                                  r1 += -505   ///  r1 = r1.wrapping_add(-505 as i32 as i64 as u64)
    stxdw [r10-0x10], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -704                                  r1 += -704   ///  r1 = r1.wrapping_add(-704 as i32 as i64 as u64)
    stxdw [r10-0x20], r1                    
    ldxdw r1, [r10-0x2d8]                   
    stxdw [r10-0x28], r1                    
    stdw [r10-0x8], 17                      
    stdw [r10-0x18], 8                      
    mov64 r1, r10                                   r1 = r10
    add64 r1, -40                                   r1 += -40   ///  r1 = r1.wrapping_add(-40 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -488                                  r2 += -488   ///  r2 = r2.wrapping_add(-488 as i32 as i64 as u64)
    mov64 r3, 8                                     r3 = 8 as i32 as i64 as u64
    mov64 r4, 8                                     r4 = 8 as i32 as i64 as u64
    mov64 r5, 0                                     r5 = 0 as i32 as i64 as u64
    syscall [invalid]                       
    mov64 r7, 26                                    r7 = 26 as i32 as i64 as u64
lbb_11400:
    ldxdw r1, [r10-0x2d0]                   
    stxw [r1+0x0], r7                       
    exit                                    
lbb_11403:
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    mov64 r2, 1                                     r2 = 1 as i32 as i64 as u64
    lddw r3, 0x100027700 --> b"\x00\x00\x00\x00\xb8Y\x02\x00\x10\x00\x00\x00\x00\x00\x00\x00\xfd!\x00\x0…        r3 load str located at 4295128832
    call function_18489                     
lbb_11408:
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
    lddw r3, 0x1000276e8 --> b"\x00\x00\x00\x00\xb8Y\x02\x00\x10\x00\x00\x00\x00\x00\x00\x00\xfd!\x00\x0…        r3 load str located at 4295128808
    call function_18489                     
lbb_11413:
    mov64 r1, 2                                     r1 = 2 as i32 as i64 as u64
    mov64 r2, 2                                     r2 = 2 as i32 as i64 as u64
    lddw r3, 0x100027718 --> b"\x00\x00\x00\x00\xb8Y\x02\x00\x10\x00\x00\x00\x00\x00\x00\x00\xfd!\x00\x0…        r3 load str located at 4295128856
    call function_18489                     
lbb_11418:
    mov64 r1, 3                                     r1 = 3 as i32 as i64 as u64
    mov64 r2, 3                                     r2 = 3 as i32 as i64 as u64
    lddw r3, 0x100027730 --> b"\x00\x00\x00\x00\xb8Y\x02\x00\x10\x00\x00\x00\x00\x00\x00\x00\xfe!\x00\x0…        r3 load str located at 4295128880
    call function_18489                     
    mov64 r7, r1                                    r7 = r1
    ldxdw r1, [r2+0x8]                      
    jeq r1, 1, lbb_11759                            if r1 == (1 as i32 as i64 as u64) { pc += 333 }
    jeq r1, 0, lbb_11764                            if r1 == (0 as i32 as i64 as u64) { pc += 337 }
    jle r1, 2, lbb_11769                            if r1 <= (2 as i32 as i64 as u64) { pc += 341 }
    jeq r1, 3, lbb_11774                            if r1 == (3 as i32 as i64 as u64) { pc += 345 }
    jle r1, 4, lbb_11779                            if r1 <= (4 as i32 as i64 as u64) { pc += 349 }
    jeq r1, 5, lbb_11784                            if r1 == (5 as i32 as i64 as u64) { pc += 353 }
    jle r1, 6, lbb_11789                            if r1 <= (6 as i32 as i64 as u64) { pc += 357 }
    jeq r1, 7, lbb_11794                            if r1 == (7 as i32 as i64 as u64) { pc += 361 }
    jle r1, 8, lbb_11799                            if r1 <= (8 as i32 as i64 as u64) { pc += 365 }
    ldxdw r0, [r2+0x50]                     
    ldxdw r4, [r0+0x0]                      
    ldxdw r1, [r4+0x50]                     
    jlt r1, 32, lbb_11757                           if r1 < (32 as i32 as i64 as u64) { pc += 319 }
    ldxdw r8, [r2+0x0]                      
    ldxdw r3, [r2+0x58]                     
    ldxdw r6, [r8+0x8]                      
    mov64 r9, r6                                    r9 = r6
    add64 r9, 8                                     r9 += 8   ///  r9 = r9.wrapping_add(8 as i32 as i64 as u64)
    ldxdw r1, [r9+0x0]                      
    ldxdw r5, [r4+0x58]                     
    stxdw [r10-0x560], r9                   
    jne r5, r1, lbb_11459                           if r5 != r1 { pc += 12 }
    ldxdw r1, [r6+0x10]                     
    ldxdw r5, [r4+0x60]                     
    jne r5, r1, lbb_11459                           if r5 != r1 { pc += 9 }
    ldxdw r1, [r6+0x18]                     
    ldxdw r5, [r4+0x68]                     
    jne r5, r1, lbb_11459                           if r5 != r1 { pc += 6 }
    ldxdw r1, [r6+0x20]                     
    ldxdw r4, [r4+0x70]                     
    jne r4, r1, lbb_11459                           if r4 != r1 { pc += 3 }
    mov64 r9, r0                                    r9 = r0
    mov64 r0, r3                                    r0 = r3
    ja lbb_11460                                    if true { pc += 1 }
lbb_11459:
    mov64 r9, r3                                    r9 = r3
lbb_11460:
    ldxdw r1, [r2+0x30]                     
    stxdw [r10-0x538], r1                   
    ldxdw r5, [r2+0x28]                     
    mov64 r1, r8                                    r1 = r8
    add64 r1, 16                                    r1 += 16   ///  r1 = r1.wrapping_add(16 as i32 as i64 as u64)
    stxdw [r10-0x520], r1                   
    ldxdw r1, [r6+0x28]                     
    lddw r3, 0xde8f75eee1f6dd06                     r3 load str located at -2409577606766207738
    stxdw [r10-0x510], r5                   
    jne r1, r3, lbb_11488                           if r1 != r3 { pc += 17 }
    ldxdw r1, [r6+0x30]                     
    lddw r4, 0xdacd6ce4bc5d4218                     r4 load str located at -2680366473547005416
    stxdw [r10-0x510], r5                   
    jne r1, r4, lbb_11488                           if r1 != r4 { pc += 12 }
    ldxdw r1, [r6+0x38]                     
    lddw r4, 0x270db9834dfc1ab6                     r4 load str located at 2814109315776649910
    stxdw [r10-0x510], r5                   
    jne r1, r4, lbb_11488                           if r1 != r4 { pc += 7 }
    ldxdw r1, [r6+0x40]                     
    lddw r4, 0xfc8ba1d828f9bdfe                     r4 load str located at -248927404616466946
    stxdw [r10-0x510], r5                   
    jne r1, r4, lbb_11488                           if r1 != r4 { pc += 2 }
    ldxdw r1, [r10-0x538]                   
    stxdw [r10-0x510], r1                   
lbb_11488:
    stxdw [r10-0x518], r5                   
    ldxdw r6, [r2+0x48]                     
    ldxdw r4, [r2+0x38]                     
    ldxb r1, [r2+0x62]                      
    stxdw [r10-0x528], r1                   
    ldxdw r1, [r10-0x520]                   
    ldxdw r5, [r1+0x0]                      
    ldxdw r1, [r5+0x28]                     
    stxdw [r10-0x530], r7                   
    jne r1, r3, lbb_11512                           if r1 != r3 { pc += 14 }
    ldxdw r1, [r5+0x30]                     
    lddw r3, 0xdacd6ce4bc5d4218                     r3 load str located at -2680366473547005416
    jne r1, r3, lbb_11512                           if r1 != r3 { pc += 10 }
    ldxdw r1, [r5+0x38]                     
    lddw r3, 0x270db9834dfc1ab6                     r3 load str located at 2814109315776649910
    jne r1, r3, lbb_11512                           if r1 != r3 { pc += 6 }
    ldxdw r1, [r5+0x40]                     
    lddw r3, 0xfc8ba1d828f9bdfe                     r3 load str located at -248927404616466946
    jne r1, r3, lbb_11512                           if r1 != r3 { pc += 2 }
    ldxdw r1, [r10-0x538]                   
    stxdw [r10-0x518], r1                   
lbb_11512:
    ldxdw r1, [r2+0x20]                     
    stxdw [r10-0x568], r1                   
    ldxdw r1, [r2+0x10]                     
    stxdw [r10-0x570], r1                   
    add64 r5, 8                                     r5 += 8   ///  r5 = r5.wrapping_add(8 as i32 as i64 as u64)
    ldxdw r1, [r10-0x510]                   
    ldxdw r1, [r1+0x0]                      
    stxdw [r10-0x578], r1                   
    ldxdw r1, [r10-0x518]                   
    ldxdw r1, [r1+0x0]                      
    stxdw [r10-0x580], r1                   
    stxdw [r10-0x550], r4                   
    ldxdw r1, [r4+0x0]                      
    stxdw [r10-0x588], r1                   
    stxdw [r10-0x558], r6                   
    ldxdw r1, [r6+0x0]                      
    stxdw [r10-0x590], r1                   
    ldxdw r3, [r8+0x0]                      
    stxdw [r10-0x548], r9                   
    ldxdw r2, [r9+0x0]                      
    ldxdw r7, [r8+0x18]                     
    stxdw [r10-0x540], r0                   
    ldxdw r4, [r0+0x0]                      
    ldxdw r1, [r8+0x20]                     
    ldxdw r0, [r8+0x28]                     
    mov64 r6, r8                                    r6 = r8
    ldxdw r8, [r6+0x30]                     
    ldxdw r9, [r6+0x38]                     
    stxdw [r10-0x538], r6                   
    ldxdw r6, [r6+0x40]                     
    stxdw [r10-0x4a8], r5                   
    ldxdw r5, [r10-0x560]                   
    stxdw [r10-0x4b8], r5                   
    add64 r6, 8                                     r6 += 8   ///  r6 = r6.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x428], r6                   
    add64 r9, 8                                     r9 += 8   ///  r9 = r9.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x438], r9                   
    add64 r8, 8                                     r8 += 8   ///  r8 = r8.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x448], r8                   
    add64 r0, 8                                     r0 += 8   ///  r0 = r0.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x458], r0                   
    add64 r1, 8                                     r1 += 8   ///  r1 = r1.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x468], r1                   
    add64 r4, 8                                     r4 += 8   ///  r4 = r4.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x478], r4                   
    add64 r7, 8                                     r7 += 8   ///  r7 = r7.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x488], r7                   
    add64 r2, 8                                     r2 += 8   ///  r2 = r2.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x498], r2                   
    add64 r3, 8                                     r3 += 8   ///  r3 = r3.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x4c8], r3                   
    ldxdw r1, [r10-0x590]                   
    add64 r1, 8                                     r1 += 8   ///  r1 = r1.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x4d8], r1                   
    ldxdw r1, [r10-0x588]                   
    add64 r1, 8                                     r1 += 8   ///  r1 = r1.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x4e8], r1                   
    ldxdw r1, [r10-0x580]                   
    add64 r1, 8                                     r1 += 8   ///  r1 = r1.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x4f8], r1                   
    ldxdw r1, [r10-0x578]                   
    add64 r1, 8                                     r1 += 8   ///  r1 = r1.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x508], r1                   
    ldxdw r6, [r10-0x528]                   
    and64 r6, 1                                     r6 &= 1   ///  r6 = r6.and(1)
    lddw r1, 0x100013b50 --> b"\xb7\x00\x00\x00\x0b\x00\x00\x00\x05\x00\x13\x00\x00\x00\x00\x00\xbf\xa1\…        r1 load str located at 4295048016
    jne r6, 0, lbb_11582                            if r6 != (0 as i32 as i64 as u64) { pc += 2 }
    lddw r1, 0x35bb7f32a81b33af                     r1 load str located at 3871828160200520623
lbb_11582:
    stxdw [r10-0x578], r1                   
    ldxdw r8, [r10-0x538]                   
    mov64 r9, r8                                    r9 = r8
    add64 r9, 64                                    r9 += 64   ///  r9 = r9.wrapping_add(64 as i32 as i64 as u64)
    mov64 r1, r8                                    r1 = r8
    add64 r1, 8                                     r1 += 8   ///  r1 = r1.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x560], r1                   
    mov64 r0, r8                                    r0 = r8
    add64 r0, 24                                    r0 += 24   ///  r0 = r0.wrapping_add(24 as i32 as i64 as u64)
    mov64 r3, r8                                    r3 = r8
    add64 r3, 32                                    r3 += 32   ///  r3 = r3.wrapping_add(32 as i32 as i64 as u64)
    mov64 r7, r8                                    r7 = r8
    add64 r7, 40                                    r7 += 40   ///  r7 = r7.wrapping_add(40 as i32 as i64 as u64)
    mov64 r5, r8                                    r5 = r8
    add64 r5, 48                                    r5 += 48   ///  r5 = r5.wrapping_add(48 as i32 as i64 as u64)
    mov64 r1, r8                                    r1 = r8
    add64 r1, 56                                    r1 += 56   ///  r1 = r1.wrapping_add(56 as i32 as i64 as u64)
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
    mov64 r4, 0                                     r4 = 0 as i32 as i64 as u64
    jne r6, 0, lbb_11604                            if r6 != (0 as i32 as i64 as u64) { pc += 2 }
    lddw r4, 0xfffec4b1                             r4 load str located at 4294886577
lbb_11604:
    sth [r10-0x420], 1                      
    sth [r10-0x430], 1                      
    sth [r10-0x440], 1                      
    sth [r10-0x450], 1                      
    sth [r10-0x460], 1                      
    sth [r10-0x470], 1                      
    sth [r10-0x480], 1                      
    sth [r10-0x490], 1                      
    sth [r10-0x4a0], 0                      
    sth [r10-0x4b0], 0                      
    sth [r10-0x4c0], 1                      
    sth [r10-0x4d0], 257                    
    sth [r10-0x4e0], 0                      
    sth [r10-0x4f0], 0                      
    sth [r10-0x500], 0                      
    stxdw [r10-0x3f8], r4                   
    ldxdw r4, [r10-0x578]                   
    stxdw [r10-0x400], r4                   
    ldxdw r4, [r10-0x528]                   
    stxb [r10-0x3ef], r4                    
    ldxdw r4, [r10-0x570]                   
    stxdw [r10-0x410], r4                   
    lddw r4, 0x621ec91a0bed042b                     r4 load str located at 7070309578724672555
    stxdw [r10-0x418], r4                   
    stb [r10-0x3ee], 0                      
    stb [r10-0x3f0], 1                      
    stdw [r10-0x408], 0                     
    ldxdw r4, [r10-0x568]                   
    ldxdw r4, [r4+0x0]                      
    stxdw [r10-0x378], r9                   
    stxdw [r10-0x380], r1                   
    stxdw [r10-0x388], r5                   
    stxdw [r10-0x390], r7                   
    stxdw [r10-0x398], r3                   
    ldxdw r1, [r10-0x540]                   
    stxdw [r10-0x3a0], r1                   
    stxdw [r10-0x3a8], r0                   
    ldxdw r1, [r10-0x548]                   
    stxdw [r10-0x3b0], r1                   
    ldxdw r1, [r10-0x520]                   
    stxdw [r10-0x3b8], r1                   
    ldxdw r1, [r10-0x560]                   
    stxdw [r10-0x3c0], r1                   
    stxdw [r10-0x3c8], r8                   
    ldxdw r1, [r10-0x558]                   
    stxdw [r10-0x3d0], r1                   
    ldxdw r1, [r10-0x550]                   
    stxdw [r10-0x3d8], r1                   
    ldxdw r1, [r10-0x518]                   
    stxdw [r10-0x3e0], r1                   
    ldxdw r1, [r10-0x510]                   
    stxdw [r10-0x3e8], r1                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -1000                                 r1 += -1000   ///  r1 = r1.wrapping_add(-1000 as i32 as i64 as u64)
    mov64 r3, r10                                   r3 = r10
    add64 r3, -1280                                 r3 += -1280   ///  r3 = r3.wrapping_add(-1280 as i32 as i64 as u64)
    add64 r4, 8                                     r4 += 8   ///  r4 = r4.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x510], r4                   
    ja lbb_11684                                    if true { pc += 20 }
lbb_11664:
    mov64 r6, r10                                   r6 = r10
    add64 r6, -880                                  r6 += -880   ///  r6 = r6.wrapping_add(-880 as i32 as i64 as u64)
    add64 r6, r2                                    r6 += r2   ///  r6 = r6.wrapping_add(r2)
    stxb [r6+0x32], r7                      
    stxb [r6+0x31], r9                      
    stxb [r6+0x30], r5                      
    mov64 r5, r4                                    r5 = r4
    add64 r5, 40                                    r5 += 40   ///  r5 = r5.wrapping_add(40 as i32 as i64 as u64)
    stxdw [r6+0x20], r5                     
    mov64 r5, r4                                    r5 = r4
    add64 r5, 88                                    r5 += 88   ///  r5 = r5.wrapping_add(88 as i32 as i64 as u64)
    stxdw [r6+0x18], r5                     
    stxdw [r6+0x10], r0                     
    add64 r4, 72                                    r4 += 72   ///  r4 = r4.wrapping_add(72 as i32 as i64 as u64)
    stxdw [r6+0x8], r4                      
    stdw [r6+0x28], 0                       
    add64 r3, 16                                    r3 += 16   ///  r3 = r3.wrapping_add(16 as i32 as i64 as u64)
    add64 r1, 8                                     r1 += 8   ///  r1 = r1.wrapping_add(8 as i32 as i64 as u64)
    add64 r2, 56                                    r2 += 56   ///  r2 = r2.wrapping_add(56 as i32 as i64 as u64)
    jeq r2, 840, lbb_11734                          if r2 == (840 as i32 as i64 as u64) { pc += 50 }
lbb_11684:
    mov64 r5, r10                                   r5 = r10
    add64 r5, -880                                  r5 += -880   ///  r5 = r5.wrapping_add(-880 as i32 as i64 as u64)
    mov64 r0, 1                                     r0 = 1 as i32 as i64 as u64
    ldxdw r4, [r1+0x0]                      
    ldxdw r4, [r4+0x0]                      
    ldxdw r7, [r3-0x8]                      
    ldxdw r6, [r7+0x0]                      
    ldxdw r8, [r4+0x8]                      
    jne r8, r6, lbb_11753                           if r8 != r6 { pc += 60 }
    ldxdw r6, [r7+0x8]                      
    ldxdw r8, [r4+0x10]                     
    jne r8, r6, lbb_11753                           if r8 != r6 { pc += 57 }
    ldxdw r6, [r7+0x10]                     
    ldxdw r8, [r4+0x18]                     
    jne r8, r6, lbb_11753                           if r8 != r6 { pc += 54 }
    ldxdw r6, [r7+0x18]                     
    ldxdw r7, [r4+0x20]                     
    jne r7, r6, lbb_11753                           if r7 != r6 { pc += 51 }
    ldxb r6, [r3+0x0]                       
    mov64 r0, 0                                     r0 = 0 as i32 as i64 as u64
    jne r6, 0, lbb_11706                            if r6 != (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r0, 119                                   r0 = 119 as i32 as i64 as u64
lbb_11706:
    ldxb r6, [r4+0x0]                       
    or64 r0, r6                                     r0 |= r6   ///  r0 = r0.or(r6)
    and64 r0, 255                                   r0 &= 255   ///  r0 = r0.and(255)
    jne r0, 255, lbb_11732                          if r0 != (255 as i32 as i64 as u64) { pc += 22 }
    add64 r5, r2                                    r5 += r2   ///  r5 = r5.wrapping_add(r2)
    mov64 r7, r4                                    r7 = r4
    add64 r7, 8                                     r7 += 8   ///  r7 = r7.wrapping_add(8 as i32 as i64 as u64)
    ldxdw r0, [r4+0x50]                     
    ldxb r8, [r4+0x3]                       
    ldxb r6, [r4+0x2]                       
    ldxb r9, [r4+0x1]                       
    stxdw [r5+0x0], r7                      
    mov64 r7, 1                                     r7 = 1 as i32 as i64 as u64
    mov64 r5, 1                                     r5 = 1 as i32 as i64 as u64
    jeq r9, 0, lbb_11725                            if r9 == (0 as i32 as i64 as u64) { pc += 4 }
    mov64 r9, 1                                     r9 = 1 as i32 as i64 as u64
    jeq r6, 0, lbb_11728                            if r6 == (0 as i32 as i64 as u64) { pc += 5 }
lbb_11723:
    jne r8, 0, lbb_11664                            if r8 != (0 as i32 as i64 as u64) { pc += -60 }
    ja lbb_11730                                    if true { pc += 5 }
lbb_11725:
    mov64 r5, 0                                     r5 = 0 as i32 as i64 as u64
    mov64 r9, 1                                     r9 = 1 as i32 as i64 as u64
    jne r6, 0, lbb_11723                            if r6 != (0 as i32 as i64 as u64) { pc += -5 }
lbb_11728:
    mov64 r9, 0                                     r9 = 0 as i32 as i64 as u64
    jne r8, 0, lbb_11664                            if r8 != (0 as i32 as i64 as u64) { pc += -66 }
lbb_11730:
    mov64 r7, 0                                     r7 = 0 as i32 as i64 as u64
    ja lbb_11664                                    if true { pc += -68 }
lbb_11732:
    mov64 r0, 11                                    r0 = 11 as i32 as i64 as u64
    ja lbb_11753                                    if true { pc += 19 }
lbb_11734:
    mov64 r1, r10                                   r1 = r10
    add64 r1, -1048                                 r1 += -1048   ///  r1 = r1.wrapping_add(-1048 as i32 as i64 as u64)
    stxdw [r10-0x10], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -1288                                 r1 += -1288   ///  r1 = r1.wrapping_add(-1288 as i32 as i64 as u64)
    stxdw [r10-0x20], r1                    
    ldxdw r1, [r10-0x510]                   
    stxdw [r10-0x28], r1                    
    stdw [r10-0x8], 43                      
    stdw [r10-0x18], 15                     
    mov64 r1, r10                                   r1 = r10
    add64 r1, -40                                   r1 += -40   ///  r1 = r1.wrapping_add(-40 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -880                                  r2 += -880   ///  r2 = r2.wrapping_add(-880 as i32 as i64 as u64)
    mov64 r3, 15                                    r3 = 15 as i32 as i64 as u64
    mov64 r4, 8                                     r4 = 8 as i32 as i64 as u64
    mov64 r5, 0                                     r5 = 0 as i32 as i64 as u64
    syscall [invalid]                       
    mov64 r0, 26                                    r0 = 26 as i32 as i64 as u64
lbb_11753:
    ldxdw r7, [r10-0x530]                   
lbb_11754:
    stxw [r7+0x0], r0                       
    stw [r7+0x4], 0                         
    exit                                    
lbb_11757:
    mov64 r0, 3                                     r0 = 3 as i32 as i64 as u64
    ja lbb_11754                                    if true { pc += -5 }
lbb_11759:
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    mov64 r2, 1                                     r2 = 1 as i32 as i64 as u64
    lddw r3, 0x100027760 --> b"\x00\x00\x00\x00\xb8Y\x02\x00\x10\x00\x00\x00\x00\x00\x00\x00\x08"\x00\x0…        r3 load str located at 4295128928
    call function_18489                     
lbb_11764:
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
    lddw r3, 0x100027748 --> b"\x00\x00\x00\x00\xb8Y\x02\x00\x10\x00\x00\x00\x00\x00\x00\x00\x08"\x00\x0…        r3 load str located at 4295128904
    call function_18489                     
lbb_11769:
    mov64 r1, 2                                     r1 = 2 as i32 as i64 as u64
    mov64 r2, 2                                     r2 = 2 as i32 as i64 as u64
    lddw r3, 0x100027778 --> b"\x00\x00\x00\x00\xb8Y\x02\x00\x10\x00\x00\x00\x00\x00\x00\x00\x08"\x00\x0…        r3 load str located at 4295128952
    call function_18489                     
lbb_11774:
    mov64 r1, 3                                     r1 = 3 as i32 as i64 as u64
    mov64 r2, 3                                     r2 = 3 as i32 as i64 as u64
    lddw r3, 0x100027790 --> b"\x00\x00\x00\x00\xb8Y\x02\x00\x10\x00\x00\x00\x00\x00\x00\x00\x09"\x00\x0…        r3 load str located at 4295128976
    call function_18489                     
lbb_11779:
    mov64 r1, 4                                     r1 = 4 as i32 as i64 as u64
    mov64 r2, 4                                     r2 = 4 as i32 as i64 as u64
    lddw r3, 0x1000277a8 --> b"\x00\x00\x00\x00\xb8Y\x02\x00\x10\x00\x00\x00\x00\x00\x00\x00\x0a"\x00\x0…        r3 load str located at 4295129000
    call function_18489                     
lbb_11784:
    mov64 r1, 5                                     r1 = 5 as i32 as i64 as u64
    mov64 r2, 5                                     r2 = 5 as i32 as i64 as u64
    lddw r3, 0x1000277c0 --> b"\x00\x00\x00\x00\xb8Y\x02\x00\x10\x00\x00\x00\x00\x00\x00\x00\x0a"\x00\x0…        r3 load str located at 4295129024
    call function_18489                     
lbb_11789:
    mov64 r1, 6                                     r1 = 6 as i32 as i64 as u64
    mov64 r2, 6                                     r2 = 6 as i32 as i64 as u64
    lddw r3, 0x1000277d8 --> b"\x00\x00\x00\x00\xb8Y\x02\x00\x10\x00\x00\x00\x00\x00\x00\x00\x0a"\x00\x0…        r3 load str located at 4295129048
    call function_18489                     
lbb_11794:
    mov64 r1, 7                                     r1 = 7 as i32 as i64 as u64
    mov64 r2, 7                                     r2 = 7 as i32 as i64 as u64
    lddw r3, 0x1000277f0 --> b"\x00\x00\x00\x00\xb8Y\x02\x00\x10\x00\x00\x00\x00\x00\x00\x00\x0a"\x00\x0…        r3 load str located at 4295129072
    call function_18489                     
lbb_11799:
    mov64 r1, 8                                     r1 = 8 as i32 as i64 as u64
    mov64 r2, 8                                     r2 = 8 as i32 as i64 as u64
    lddw r3, 0x100027808 --> b"\x00\x00\x00\x00\xb8Y\x02\x00\x10\x00\x00\x00\x00\x00\x00\x00\x0b"\x00\x0…        r3 load str located at 4295129096
    call function_18489                     
    mov64 r7, r1                                    r7 = r1
    ldxdw r6, [r2+0x28]                     
    ldxdw r1, [r2+0x20]                     
    stxdw [r10-0x640], r1                   
    ldxb r3, [r2+0x64]                      
    stxdw [r10-0x650], r7                   
    jeq r3, 0, lbb_11904                            if r3 == (0 as i32 as i64 as u64) { pc += 93 }
    ldxdw r3, [r2+0x8]                      
    jeq r3, 0, lbb_12391                            if r3 == (0 as i32 as i64 as u64) { pc += 578 }
    jeq r3, 1, lbb_12401                            if r3 == (1 as i32 as i64 as u64) { pc += 587 }
    jle r3, 2, lbb_12411                            if r3 <= (2 as i32 as i64 as u64) { pc += 596 }
    jeq r3, 3, lbb_12421                            if r3 == (3 as i32 as i64 as u64) { pc += 605 }
    jle r3, 4, lbb_12431                            if r3 <= (4 as i32 as i64 as u64) { pc += 614 }
    jeq r3, 5, lbb_12441                            if r3 == (5 as i32 as i64 as u64) { pc += 623 }
    jle r3, 6, lbb_12451                            if r3 <= (6 as i32 as i64 as u64) { pc += 632 }
    jeq r3, 7, lbb_12461                            if r3 == (7 as i32 as i64 as u64) { pc += 641 }
    jle r3, 8, lbb_12471                            if r3 <= (8 as i32 as i64 as u64) { pc += 650 }
    jeq r3, 9, lbb_12481                            if r3 == (9 as i32 as i64 as u64) { pc += 659 }
    ldxdw r8, [r2+0x0]                      
    ldxdw r4, [r2+0x30]                     
    mov64 r9, r8                                    r9 = r8
    add64 r9, 32                                    r9 += 32   ///  r9 = r9.wrapping_add(32 as i32 as i64 as u64)
    ldxdw r1, [r8+0x18]                     
    ldxdw r3, [r1+0x28]                     
    lddw r5, 0xde8f75eee1f6dd06                     r5 load str located at -2409577606766207738
    mov64 r0, r6                                    r0 = r6
    jne r3, r5, lbb_11848                           if r3 != r5 { pc += 16 }
    ldxdw r3, [r1+0x30]                     
    lddw r5, 0xdacd6ce4bc5d4218                     r5 load str located at -2680366473547005416
    mov64 r0, r6                                    r0 = r6
    jne r3, r5, lbb_11848                           if r3 != r5 { pc += 11 }
    ldxdw r3, [r1+0x38]                     
    lddw r5, 0x270db9834dfc1ab6                     r5 load str located at 2814109315776649910
    mov64 r0, r6                                    r0 = r6
    jne r3, r5, lbb_11848                           if r3 != r5 { pc += 6 }
    ldxdw r3, [r1+0x40]                     
    lddw r5, 0xfc8ba1d828f9bdfe                     r5 load str located at -248927404616466946
    mov64 r0, r6                                    r0 = r6
    jne r3, r5, lbb_11848                           if r3 != r5 { pc += 1 }
    mov64 r0, r4                                    r0 = r4
lbb_11848:
    stxdw [r10-0x648], r4                   
    stxdw [r10-0x6b8], r1                   
    ldxdw r3, [r2+0x48]                     
    ldxdw r1, [r2+0x38]                     
    stxdw [r10-0x660], r1                   
    mov64 r5, r8                                    r5 = r8
    add64 r5, 8                                     r5 += 8   ///  r5 = r5.wrapping_add(8 as i32 as i64 as u64)
    ldxdw r1, [r2+0x58]                     
    stxdw [r10-0x658], r1                   
    ldxdw r1, [r2+0x50]                     
    mov64 r4, r8                                    r4 = r8
    add64 r4, 16                                    r4 += 16   ///  r4 = r4.wrapping_add(16 as i32 as i64 as u64)
    stxdw [r10-0x678], r4                   
    mov64 r4, r8                                    r4 = r8
    add64 r4, 24                                    r4 += 24   ///  r4 = r4.wrapping_add(24 as i32 as i64 as u64)
    stxdw [r10-0x680], r4                   
    mov64 r4, r8                                    r4 = r8
    add64 r4, 40                                    r4 += 40   ///  r4 = r4.wrapping_add(40 as i32 as i64 as u64)
    stxdw [r10-0x688], r4                   
    mov64 r4, r8                                    r4 = r8
    add64 r4, 48                                    r4 += 48   ///  r4 = r4.wrapping_add(48 as i32 as i64 as u64)
    stxdw [r10-0x690], r4                   
    mov64 r4, r8                                    r4 = r8
    add64 r4, 56                                    r4 += 56   ///  r4 = r4.wrapping_add(56 as i32 as i64 as u64)
    stxdw [r10-0x698], r4                   
    ldxdw r2, [r2+0x10]                     
    stxdw [r10-0x6b0], r2                   
    mov64 r2, r8                                    r2 = r8
    add64 r2, 72                                    r2 += 72   ///  r2 = r2.wrapping_add(72 as i32 as i64 as u64)
    stxdw [r10-0x6a0], r2                   
    mov64 r2, r8                                    r2 = r8
    add64 r2, 64                                    r2 += 64   ///  r2 = r2.wrapping_add(64 as i32 as i64 as u64)
    stxdw [r10-0x6a8], r2                   
    stxdw [r10-0x668], r9                   
    ldxdw r9, [r9+0x0]                      
    ldxdw r2, [r9+0x28]                     
    lddw r4, 0xde8f75eee1f6dd06                     r4 load str located at -2409577606766207738
    stxdw [r10-0x670], r5                   
    jne r2, r4, lbb_12158                           if r2 != r4 { pc += 270 }
    mov64 r4, r3                                    r4 = r3
    ldxdw r3, [r9+0x30]                     
    lddw r2, 0xdacd6ce4bc5d4218                     r2 load str located at -2680366473547005416
    jne r3, r2, lbb_12157                           if r3 != r2 { pc += 264 }
    ldxdw r3, [r9+0x38]                     
    lddw r2, 0x270db9834dfc1ab6                     r2 load str located at 2814109315776649910
    jne r3, r2, lbb_12157                           if r3 != r2 { pc += 260 }
    ldxdw r5, [r9+0x40]                     
    lddw r2, 0xfc8ba1d828f9bdfe                     r2 load str located at -248927404616466946
    mov64 r3, r4                                    r3 = r4
    jne r5, r2, lbb_12158                           if r5 != r2 { pc += 256 }
    ldxdw r6, [r10-0x648]                   
    ja lbb_12158                                    if true { pc += 254 }
lbb_11904:
    ldxdw r3, [r2+0x8]                      
    jeq r3, 0, lbb_12396                            if r3 == (0 as i32 as i64 as u64) { pc += 490 }
    jeq r3, 1, lbb_12406                            if r3 == (1 as i32 as i64 as u64) { pc += 499 }
    jle r3, 2, lbb_12416                            if r3 <= (2 as i32 as i64 as u64) { pc += 508 }
    jeq r3, 3, lbb_12426                            if r3 == (3 as i32 as i64 as u64) { pc += 517 }
    jle r3, 4, lbb_12436                            if r3 <= (4 as i32 as i64 as u64) { pc += 526 }
    jeq r3, 5, lbb_12446                            if r3 == (5 as i32 as i64 as u64) { pc += 535 }
    jle r3, 6, lbb_12456                            if r3 <= (6 as i32 as i64 as u64) { pc += 544 }
    jeq r3, 7, lbb_12466                            if r3 == (7 as i32 as i64 as u64) { pc += 553 }
    jle r3, 8, lbb_12476                            if r3 <= (8 as i32 as i64 as u64) { pc += 562 }
    stxdw [r10-0x648], r6                   
    jeq r3, 9, lbb_12486                            if r3 == (9 as i32 as i64 as u64) { pc += 570 }
    ldxdw r4, [r2+0x0]                      
    ldxdw r5, [r2+0x48]                     
    stxdw [r10-0x6a0], r5                   
    mov64 r1, r4                                    r1 = r4
    add64 r1, 8                                     r1 += 8   ///  r1 = r1.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x658], r1                   
    ldxdw r6, [r2+0x58]                     
    stxdw [r10-0x698], r6                   
    ldxdw r3, [r2+0x50]                     
    stxdw [r10-0x688], r3                   
    mov64 r1, r4                                    r1 = r4
    add64 r1, 16                                    r1 += 16   ///  r1 = r1.wrapping_add(16 as i32 as i64 as u64)
    stxdw [r10-0x660], r1                   
    mov64 r1, r4                                    r1 = r4
    add64 r1, 24                                    r1 += 24   ///  r1 = r1.wrapping_add(24 as i32 as i64 as u64)
    stxdw [r10-0x668], r1                   
    mov64 r1, r4                                    r1 = r4
    add64 r1, 32                                    r1 += 32   ///  r1 = r1.wrapping_add(32 as i32 as i64 as u64)
    stxdw [r10-0x670], r1                   
    mov64 r1, r4                                    r1 = r4
    add64 r1, 40                                    r1 += 40   ///  r1 = r1.wrapping_add(40 as i32 as i64 as u64)
    stxdw [r10-0x678], r1                   
    mov64 r1, r4                                    r1 = r4
    add64 r1, 48                                    r1 += 48   ///  r1 = r1.wrapping_add(48 as i32 as i64 as u64)
    stxdw [r10-0x680], r1                   
    mov64 r1, r4                                    r1 = r4
    add64 r1, 56                                    r1 += 56   ///  r1 = r1.wrapping_add(56 as i32 as i64 as u64)
    stxdw [r10-0x690], r1                   
    ldxdw r1, [r2+0x10]                     
    stxdw [r10-0x6a8], r1                   
    ldxdw r0, [r4+0x48]                     
    add64 r0, 8                                     r0 += 8   ///  r0 = r0.wrapping_add(8 as i32 as i64 as u64)
    ldxdw r1, [r10-0x640]                   
    ldxdw r7, [r1+0x0]                      
    ldxdw r1, [r4+0x0]                      
    stxdw [r10-0x6b0], r1                   
    ldxdw r1, [r4+0x8]                      
    stxdw [r10-0x6b8], r1                   
    ldxdw r1, [r4+0x10]                     
    stxdw [r10-0x6c0], r1                   
    ldxdw r1, [r3+0x0]                      
    stxdw [r10-0x6c8], r1                   
    ldxdw r1, [r6+0x0]                      
    stxdw [r10-0x6d0], r1                   
    ldxdw r1, [r4+0x18]                     
    stxdw [r10-0x6d8], r1                   
    ldxdw r9, [r4+0x20]                     
    ldxdw r8, [r4+0x28]                     
    ldxdw r6, [r5+0x0]                      
    ldxdw r1, [r10-0x648]                   
    ldxdw r3, [r1+0x0]                      
    ldxdw r5, [r4+0x30]                     
    ldxdw r2, [r4+0x38]                     
    ldxdw r1, [r4+0x40]                     
    stxdw [r10-0x528], r0                   
    add64 r1, 8                                     r1 += 8   ///  r1 = r1.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x538], r1                   
    add64 r2, 8                                     r2 += 8   ///  r2 = r2.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x548], r2                   
    add64 r5, 8                                     r5 += 8   ///  r5 = r5.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x568], r5                   
    add64 r3, 8                                     r3 += 8   ///  r3 = r3.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x578], r3                   
    stxdw [r10-0x588], r3                   
    add64 r6, 8                                     r6 += 8   ///  r6 = r6.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x598], r6                   
    add64 r8, 8                                     r8 += 8   ///  r8 = r8.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x5b8], r8                   
    add64 r9, 8                                     r9 += 8   ///  r9 = r9.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x5c8], r9                   
    ldxdw r1, [r10-0x6d8]                   
    add64 r1, 8                                     r1 += 8   ///  r1 = r1.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x5d8], r1                   
    ldxdw r1, [r10-0x6d0]                   
    add64 r1, 8                                     r1 += 8   ///  r1 = r1.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x5e8], r1                   
    ldxdw r1, [r10-0x6c8]                   
    add64 r1, 8                                     r1 += 8   ///  r1 = r1.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x5f8], r1                   
    ldxdw r1, [r10-0x6c0]                   
    add64 r1, 8                                     r1 += 8   ///  r1 = r1.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x608], r1                   
    ldxdw r1, [r10-0x6b8]                   
    add64 r1, 8                                     r1 += 8   ///  r1 = r1.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x618], r1                   
    ldxdw r1, [r10-0x6b0]                   
    add64 r1, 8                                     r1 += 8   ///  r1 = r1.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x638], r1                   
    add64 r7, 8                                     r7 += 8   ///  r7 = r7.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x558], r7                   
    stxdw [r10-0x5a8], r7                   
    stxdw [r10-0x6b0], r7                   
    stxdw [r10-0x628], r7                   
    sth [r10-0x520], 1                      
    sth [r10-0x530], 1                      
    sth [r10-0x540], 1                      
    sth [r10-0x550], 0                      
    sth [r10-0x560], 0                      
    sth [r10-0x570], 0                      
    sth [r10-0x580], 0                      
    sth [r10-0x590], 257                    
    sth [r10-0x5a0], 0                      
    sth [r10-0x5b0], 1                      
    sth [r10-0x5c0], 0                      
    sth [r10-0x5d0], 0                      
    sth [r10-0x5e0], 1                      
    sth [r10-0x5f0], 1                      
    sth [r10-0x600], 1                      
    sth [r10-0x610], 1                      
    sth [r10-0x620], 0                      
    sth [r10-0x630], 1                      
    ldxdw r1, [r10-0x6a8]                   
    stxdw [r10-0x500], r1                   
    lddw r1, 0xc88775e1919ec6f8                     r1 load str located at -3997096532596832520
    stxdw [r10-0x508], r1                   
    stdw [r10-0x4f8], 0                     
    mov64 r1, r4                                    r1 = r4
    add64 r1, 72                                    r1 += 72   ///  r1 = r1.wrapping_add(72 as i32 as i64 as u64)
    stxdw [r10-0x460], r1                   
    mov64 r1, r4                                    r1 = r4
    add64 r1, 64                                    r1 += 64   ///  r1 = r1.wrapping_add(64 as i32 as i64 as u64)
    stxdw [r10-0x468], r1                   
    ldxdw r1, [r10-0x690]                   
    stxdw [r10-0x470], r1                   
    ldxdw r1, [r10-0x680]                   
    stxdw [r10-0x480], r1                   
    ldxdw r1, [r10-0x648]                   
    stxdw [r10-0x488], r1                   
    stxdw [r10-0x490], r1                   
    ldxdw r1, [r10-0x6a0]                   
    stxdw [r10-0x498], r1                   
    ldxdw r1, [r10-0x678]                   
    stxdw [r10-0x4a8], r1                   
    ldxdw r1, [r10-0x670]                   
    stxdw [r10-0x4b0], r1                   
    ldxdw r1, [r10-0x668]                   
    stxdw [r10-0x4b8], r1                   
    ldxdw r1, [r10-0x698]                   
    stxdw [r10-0x4c0], r1                   
    ldxdw r1, [r10-0x688]                   
    stxdw [r10-0x4c8], r1                   
    ldxdw r1, [r10-0x660]                   
    stxdw [r10-0x4d0], r1                   
    ldxdw r1, [r10-0x658]                   
    stxdw [r10-0x4d8], r1                   
    ldxdw r1, [r10-0x640]                   
    stxdw [r10-0x478], r1                   
    stxdw [r10-0x4a0], r1                   
    stxdw [r10-0x4e0], r1                   
    stxdw [r10-0x4e8], r4                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -1256                                 r1 += -1256   ///  r1 = r1.wrapping_add(-1256 as i32 as i64 as u64)
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
    mov64 r4, r10                                   r4 = r10
    add64 r4, -1584                                 r4 += -1584   ///  r4 = r4.wrapping_add(-1584 as i32 as i64 as u64)
    ja lbb_12093                                    if true { pc += 20 }
lbb_12073:
    mov64 r7, r10                                   r7 = r10
    add64 r7, -1104                                 r7 += -1104   ///  r7 = r7.wrapping_add(-1104 as i32 as i64 as u64)
    add64 r7, r3                                    r7 += r3   ///  r7 = r7.wrapping_add(r3)
    stxb [r7+0x32], r6                      
    stxb [r7+0x31], r8                      
    stxb [r7+0x30], r2                      
    mov64 r2, r0                                    r2 = r0
    add64 r2, 40                                    r2 += 40   ///  r2 = r2.wrapping_add(40 as i32 as i64 as u64)
    stxdw [r7+0x20], r2                     
    mov64 r2, r0                                    r2 = r0
    add64 r2, 88                                    r2 += 88   ///  r2 = r2.wrapping_add(88 as i32 as i64 as u64)
    stxdw [r7+0x18], r2                     
    stxdw [r7+0x10], r5                     
    add64 r0, 72                                    r0 += 72   ///  r0 = r0.wrapping_add(72 as i32 as i64 as u64)
    stxdw [r7+0x8], r0                      
    stdw [r7+0x28], 0                       
    add64 r4, 16                                    r4 += 16   ///  r4 = r4.wrapping_add(16 as i32 as i64 as u64)
    add64 r1, 8                                     r1 += 8   ///  r1 = r1.wrapping_add(8 as i32 as i64 as u64)
    add64 r3, 56                                    r3 += 56   ///  r3 = r3.wrapping_add(56 as i32 as i64 as u64)
    jeq r3, 1008, lbb_12141                         if r3 == (1008 as i32 as i64 as u64) { pc += 48 }
lbb_12093:
    mov64 r2, r10                                   r2 = r10
    add64 r2, -1104                                 r2 += -1104   ///  r2 = r2.wrapping_add(-1104 as i32 as i64 as u64)
    mov64 r5, 1                                     r5 = 1 as i32 as i64 as u64
    ldxdw r0, [r1+0x0]                      
    ldxdw r0, [r0+0x0]                      
    ldxdw r6, [r4-0x8]                      
    ldxdw r7, [r6+0x0]                      
    ldxdw r8, [r0+0x8]                      
    jne r8, r7, lbb_12388                           if r8 != r7 { pc += 286 }
    ldxdw r7, [r6+0x8]                      
    ldxdw r8, [r0+0x10]                     
    jne r8, r7, lbb_12388                           if r8 != r7 { pc += 283 }
    ldxdw r7, [r6+0x10]                     
    ldxdw r8, [r0+0x18]                     
    jne r8, r7, lbb_12388                           if r8 != r7 { pc += 280 }
    ldxdw r6, [r6+0x18]                     
    ldxdw r7, [r0+0x20]                     
    jne r7, r6, lbb_12388                           if r7 != r6 { pc += 277 }
    ldxb r6, [r4+0x0]                       
    mov64 r5, 0                                     r5 = 0 as i32 as i64 as u64
    jne r6, 0, lbb_12115                            if r6 != (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r5, 119                                   r5 = 119 as i32 as i64 as u64
lbb_12115:
    ldxb r6, [r0+0x0]                       
    or64 r5, r6                                     r5 |= r6   ///  r5 = r5.or(r6)
    and64 r5, 255                                   r5 &= 255   ///  r5 = r5.and(255)
    jne r5, 255, lbb_12367                          if r5 != (255 as i32 as i64 as u64) { pc += 248 }
    add64 r2, r3                                    r2 += r3   ///  r2 = r2.wrapping_add(r3)
    mov64 r6, r0                                    r6 = r0
    add64 r6, 8                                     r6 += 8   ///  r6 = r6.wrapping_add(8 as i32 as i64 as u64)
    ldxdw r5, [r0+0x50]                     
    ldxb r7, [r0+0x3]                       
    ldxb r9, [r0+0x2]                       
    ldxb r8, [r0+0x1]                       
    stxdw [r2+0x0], r6                      
    mov64 r6, 1                                     r6 = 1 as i32 as i64 as u64
    mov64 r2, 1                                     r2 = 1 as i32 as i64 as u64
    jne r8, 0, lbb_12135                            if r8 != (0 as i32 as i64 as u64) { pc += 5 }
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
    mov64 r8, 1                                     r8 = 1 as i32 as i64 as u64
    jeq r9, 0, lbb_12137                            if r9 == (0 as i32 as i64 as u64) { pc += 4 }
lbb_12133:
    jne r7, 0, lbb_12073                            if r7 != (0 as i32 as i64 as u64) { pc += -61 }
    ja lbb_12139                                    if true { pc += 4 }
lbb_12135:
    mov64 r8, 1                                     r8 = 1 as i32 as i64 as u64
    jne r9, 0, lbb_12133                            if r9 != (0 as i32 as i64 as u64) { pc += -4 }
lbb_12137:
    mov64 r8, 0                                     r8 = 0 as i32 as i64 as u64
    jne r7, 0, lbb_12073                            if r7 != (0 as i32 as i64 as u64) { pc += -66 }
lbb_12139:
    mov64 r6, 0                                     r6 = 0 as i32 as i64 as u64
    ja lbb_12073                                    if true { pc += -68 }
lbb_12141:
    mov64 r1, r10                                   r1 = r10
    add64 r1, -1288                                 r1 += -1288   ///  r1 = r1.wrapping_add(-1288 as i32 as i64 as u64)
    stxdw [r10-0x10], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -1592                                 r1 += -1592   ///  r1 = r1.wrapping_add(-1592 as i32 as i64 as u64)
    stxdw [r10-0x20], r1                    
    ldxdw r1, [r10-0x6b0]                   
    stxdw [r10-0x28], r1                    
    stdw [r10-0x8], 24                      
    stdw [r10-0x18], 18                     
    mov64 r1, r10                                   r1 = r10
    add64 r1, -40                                   r1 += -40   ///  r1 = r1.wrapping_add(-40 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -1104                                 r2 += -1104   ///  r2 = r2.wrapping_add(-1104 as i32 as i64 as u64)
    mov64 r3, 18                                    r3 = 18 as i32 as i64 as u64
    ja lbb_12384                                    if true { pc += 227 }
lbb_12157:
    mov64 r3, r4                                    r3 = r4
lbb_12158:
    stxdw [r10-0x6c8], r3                   
    add64 r9, 8                                     r9 += 8   ///  r9 = r9.wrapping_add(8 as i32 as i64 as u64)
    ldxdw r2, [r10-0x640]                   
    ldxdw r2, [r2+0x0]                      
    ldxdw r4, [r8+0x0]                      
    stxdw [r10-0x6d8], r4                   
    ldxdw r4, [r8+0x8]                      
    stxdw [r10-0x6e0], r4                   
    ldxdw r4, [r8+0x10]                     
    stxdw [r10-0x6e8], r4                   
    stxdw [r10-0x6c0], r1                   
    ldxdw r1, [r1+0x0]                      
    stxdw [r10-0x6f0], r1                   
    ldxdw r1, [r10-0x658]                   
    ldxdw r1, [r1+0x0]                      
    stxdw [r10-0x6f8], r1                   
    ldxdw r1, [r8+0x28]                     
    stxdw [r10-0x700], r1                   
    ldxdw r1, [r3+0x0]                      
    stxdw [r10-0x708], r1                   
    stxdw [r10-0x648], r6                   
    stxdw [r10-0x6d0], r0                   
    ldxdw r4, [r0+0x0]                      
    ldxdw r3, [r6+0x0]                      
    ldxdw r1, [r10-0x660]                   
    ldxdw r1, [r1+0x0]                      
    ldxdw r0, [r8+0x30]                     
    ldxdw r6, [r8+0x38]                     
    ldxdw r7, [r8+0x40]                     
    ldxdw r5, [r8+0x48]                     
    stxdw [r10-0x5c8], r9                   
    ldxdw r9, [r10-0x6b8]                   
    add64 r9, 8                                     r9 += 8   ///  r9 = r9.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x5d8], r9                   
    add64 r5, 8                                     r5 += 8   ///  r5 = r5.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x518], r5                   
    add64 r7, 8                                     r7 += 8   ///  r7 = r7.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x528], r7                   
    add64 r6, 8                                     r6 += 8   ///  r6 = r6.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x538], r6                   
    add64 r0, 8                                     r0 += 8   ///  r0 = r0.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x558], r0                   
    add64 r1, 8                                     r1 += 8   ///  r1 = r1.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x568], r1                   
    add64 r3, 8                                     r3 += 8   ///  r3 = r3.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x578], r3                   
    add64 r4, 8                                     r4 += 8   ///  r4 = r4.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x588], r4                   
    ldxdw r1, [r10-0x708]                   
    add64 r1, 8                                     r1 += 8   ///  r1 = r1.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x598], r1                   
    ldxdw r1, [r10-0x700]                   
    add64 r1, 8                                     r1 += 8   ///  r1 = r1.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x5b8], r1                   
    ldxdw r1, [r10-0x6f8]                   
    add64 r1, 8                                     r1 += 8   ///  r1 = r1.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x5e8], r1                   
    ldxdw r1, [r10-0x6f0]                   
    add64 r1, 8                                     r1 += 8   ///  r1 = r1.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x5f8], r1                   
    ldxdw r1, [r10-0x6e8]                   
    add64 r1, 8                                     r1 += 8   ///  r1 = r1.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x608], r1                   
    ldxdw r1, [r10-0x6e0]                   
    add64 r1, 8                                     r1 += 8   ///  r1 = r1.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x618], r1                   
    ldxdw r1, [r10-0x6d8]                   
    add64 r1, 8                                     r1 += 8   ///  r1 = r1.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x638], r1                   
    add64 r2, 8                                     r2 += 8   ///  r2 = r2.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x548], r2                   
    stxdw [r10-0x5a8], r2                   
    stxdw [r10-0x6b8], r2                   
    stxdw [r10-0x628], r2                   
    sth [r10-0x510], 1                      
    sth [r10-0x520], 1                      
    sth [r10-0x530], 1                      
    sth [r10-0x540], 0                      
    sth [r10-0x550], 0                      
    sth [r10-0x560], 0                      
    sth [r10-0x570], 0                      
    sth [r10-0x580], 0                      
    sth [r10-0x590], 257                    
    sth [r10-0x5a0], 0                      
    sth [r10-0x5b0], 1                      
    sth [r10-0x5c0], 0                      
    sth [r10-0x5d0], 0                      
    sth [r10-0x5e0], 1                      
    sth [r10-0x5f0], 1                      
    sth [r10-0x600], 1                      
    sth [r10-0x610], 1                      
    sth [r10-0x620], 0                      
    sth [r10-0x630], 1                      
    ldxdw r1, [r10-0x6b0]                   
    stxdw [r10-0x500], r1                   
    lddw r1, 0x885b5beb4c3f4b41                     r1 load str located at -8621195995516023999
    stxdw [r10-0x508], r1                   
    stw [r10-0x4f0], 0                      
    stdw [r10-0x4f8], 0                     
    ldxdw r1, [r10-0x6a0]                   
    stxdw [r10-0x458], r1                   
    ldxdw r1, [r10-0x6a8]                   
    stxdw [r10-0x460], r1                   
    ldxdw r1, [r10-0x698]                   
    stxdw [r10-0x468], r1                   
    ldxdw r1, [r10-0x690]                   
    stxdw [r10-0x478], r1                   
    ldxdw r1, [r10-0x660]                   
    stxdw [r10-0x480], r1                   
    ldxdw r1, [r10-0x648]                   
    stxdw [r10-0x488], r1                   
    ldxdw r1, [r10-0x6d0]                   
    stxdw [r10-0x490], r1                   
    ldxdw r1, [r10-0x6c8]                   
    stxdw [r10-0x498], r1                   
    ldxdw r1, [r10-0x688]                   
    stxdw [r10-0x4a8], r1                   
    ldxdw r1, [r10-0x668]                   
    stxdw [r10-0x4b0], r1                   
    ldxdw r1, [r10-0x680]                   
    stxdw [r10-0x4b8], r1                   
    ldxdw r1, [r10-0x658]                   
    stxdw [r10-0x4c0], r1                   
    ldxdw r1, [r10-0x6c0]                   
    stxdw [r10-0x4c8], r1                   
    ldxdw r1, [r10-0x678]                   
    stxdw [r10-0x4d0], r1                   
    ldxdw r1, [r10-0x670]                   
    stxdw [r10-0x4d8], r1                   
    ldxdw r1, [r10-0x640]                   
    stxdw [r10-0x470], r1                   
    stxdw [r10-0x4a0], r1                   
    stxdw [r10-0x4e0], r1                   
    stxdw [r10-0x4e8], r8                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -1256                                 r1 += -1256   ///  r1 = r1.wrapping_add(-1256 as i32 as i64 as u64)
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
    mov64 r4, r10                                   r4 = r10
    add64 r4, -1584                                 r4 += -1584   ///  r4 = r4.wrapping_add(-1584 as i32 as i64 as u64)
    ja lbb_12319                                    if true { pc += 20 }
lbb_12299:
    mov64 r7, r10                                   r7 = r10
    add64 r7, -1104                                 r7 += -1104   ///  r7 = r7.wrapping_add(-1104 as i32 as i64 as u64)
    add64 r7, r3                                    r7 += r3   ///  r7 = r7.wrapping_add(r3)
    stxb [r7+0x32], r6                      
    stxb [r7+0x31], r8                      
    stxb [r7+0x30], r5                      
    mov64 r5, r0                                    r5 = r0
    add64 r5, 40                                    r5 += 40   ///  r5 = r5.wrapping_add(40 as i32 as i64 as u64)
    stxdw [r7+0x20], r5                     
    mov64 r5, r0                                    r5 = r0
    add64 r5, 88                                    r5 += 88   ///  r5 = r5.wrapping_add(88 as i32 as i64 as u64)
    stxdw [r7+0x18], r5                     
    stxdw [r7+0x10], r2                     
    add64 r0, 72                                    r0 += 72   ///  r0 = r0.wrapping_add(72 as i32 as i64 as u64)
    stxdw [r7+0x8], r0                      
    stdw [r7+0x28], 0                       
    add64 r4, 16                                    r4 += 16   ///  r4 = r4.wrapping_add(16 as i32 as i64 as u64)
    add64 r1, 8                                     r1 += 8   ///  r1 = r1.wrapping_add(8 as i32 as i64 as u64)
    add64 r3, 56                                    r3 += 56   ///  r3 = r3.wrapping_add(56 as i32 as i64 as u64)
    jeq r3, 1064, lbb_12369                         if r3 == (1064 as i32 as i64 as u64) { pc += 50 }
lbb_12319:
    mov64 r6, r10                                   r6 = r10
    add64 r6, -1104                                 r6 += -1104   ///  r6 = r6.wrapping_add(-1104 as i32 as i64 as u64)
    mov64 r5, 1                                     r5 = 1 as i32 as i64 as u64
    ldxdw r2, [r1+0x0]                      
    ldxdw r0, [r2+0x0]                      
    ldxdw r2, [r4-0x8]                      
    ldxdw r7, [r2+0x0]                      
    ldxdw r8, [r0+0x8]                      
    jne r8, r7, lbb_12388                           if r8 != r7 { pc += 60 }
    ldxdw r7, [r2+0x8]                      
    ldxdw r8, [r0+0x10]                     
    jne r8, r7, lbb_12388                           if r8 != r7 { pc += 57 }
    ldxdw r7, [r2+0x10]                     
    ldxdw r8, [r0+0x18]                     
    jne r8, r7, lbb_12388                           if r8 != r7 { pc += 54 }
    ldxdw r2, [r2+0x18]                     
    ldxdw r7, [r0+0x20]                     
    jne r7, r2, lbb_12388                           if r7 != r2 { pc += 51 }
    ldxb r5, [r4+0x0]                       
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
    jne r5, 0, lbb_12341                            if r5 != (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r2, 119                                   r2 = 119 as i32 as i64 as u64
lbb_12341:
    ldxb r5, [r0+0x0]                       
    or64 r2, r5                                     r2 |= r5   ///  r2 = r2.or(r5)
    and64 r2, 255                                   r2 &= 255   ///  r2 = r2.and(255)
    jne r2, 255, lbb_12367                          if r2 != (255 as i32 as i64 as u64) { pc += 22 }
    add64 r6, r3                                    r6 += r3   ///  r6 = r6.wrapping_add(r3)
    mov64 r5, r0                                    r5 = r0
    add64 r5, 8                                     r5 += 8   ///  r5 = r5.wrapping_add(8 as i32 as i64 as u64)
    ldxdw r2, [r0+0x50]                     
    ldxb r7, [r0+0x3]                       
    ldxb r9, [r0+0x2]                       
    ldxb r8, [r0+0x1]                       
    stxdw [r6+0x0], r5                      
    mov64 r6, 1                                     r6 = 1 as i32 as i64 as u64
    mov64 r5, 1                                     r5 = 1 as i32 as i64 as u64
    jne r8, 0, lbb_12361                            if r8 != (0 as i32 as i64 as u64) { pc += 5 }
    mov64 r5, 0                                     r5 = 0 as i32 as i64 as u64
    mov64 r8, 1                                     r8 = 1 as i32 as i64 as u64
    jeq r9, 0, lbb_12363                            if r9 == (0 as i32 as i64 as u64) { pc += 4 }
lbb_12359:
    jne r7, 0, lbb_12299                            if r7 != (0 as i32 as i64 as u64) { pc += -61 }
    ja lbb_12365                                    if true { pc += 4 }
lbb_12361:
    mov64 r8, 1                                     r8 = 1 as i32 as i64 as u64
    jne r9, 0, lbb_12359                            if r9 != (0 as i32 as i64 as u64) { pc += -4 }
lbb_12363:
    mov64 r8, 0                                     r8 = 0 as i32 as i64 as u64
    jne r7, 0, lbb_12299                            if r7 != (0 as i32 as i64 as u64) { pc += -66 }
lbb_12365:
    mov64 r6, 0                                     r6 = 0 as i32 as i64 as u64
    ja lbb_12299                                    if true { pc += -68 }
lbb_12367:
    mov64 r5, 11                                    r5 = 11 as i32 as i64 as u64
    ja lbb_12388                                    if true { pc += 19 }
lbb_12369:
    mov64 r1, r10                                   r1 = r10
    add64 r1, -1288                                 r1 += -1288   ///  r1 = r1.wrapping_add(-1288 as i32 as i64 as u64)
    stxdw [r10-0x10], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -1592                                 r1 += -1592   ///  r1 = r1.wrapping_add(-1592 as i32 as i64 as u64)
    stxdw [r10-0x20], r1                    
    ldxdw r1, [r10-0x6b8]                   
    stxdw [r10-0x28], r1                    
    stdw [r10-0x8], 28                      
    stdw [r10-0x18], 19                     
    mov64 r1, r10                                   r1 = r10
    add64 r1, -40                                   r1 += -40   ///  r1 = r1.wrapping_add(-40 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -1104                                 r2 += -1104   ///  r2 = r2.wrapping_add(-1104 as i32 as i64 as u64)
    mov64 r3, 19                                    r3 = 19 as i32 as i64 as u64
lbb_12384:
    mov64 r4, 8                                     r4 = 8 as i32 as i64 as u64
    mov64 r5, 0                                     r5 = 0 as i32 as i64 as u64
    syscall [invalid]                       
    mov64 r5, 26                                    r5 = 26 as i32 as i64 as u64
lbb_12388:
    ldxdw r1, [r10-0x650]                   
    stxw [r1+0x0], r5                       
    exit                                    
lbb_12391:
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
    lddw r3, 0x100027910 --> b"\x00\x00\x00\x00\xb8Y\x02\x00\x10\x00\x00\x00\x00\x00\x00\x00\x14"\x00\x0…        r3 load str located at 4295129360
    call function_18489                     
lbb_12396:
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
    lddw r3, 0x100027820 --> b"\x00\x00\x00\x00\xb8Y\x02\x00\x10\x00\x00\x00\x00\x00\x00\x00\x1d"\x00\x0…        r3 load str located at 4295129120
    call function_18489                     
lbb_12401:
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    mov64 r2, 1                                     r2 = 1 as i32 as i64 as u64
    lddw r3, 0x100027928 --> b"\x00\x00\x00\x00\xb8Y\x02\x00\x10\x00\x00\x00\x00\x00\x00\x00\x14"\x00\x0…        r3 load str located at 4295129384
    call function_18489                     
lbb_12406:
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    mov64 r2, 1                                     r2 = 1 as i32 as i64 as u64
    lddw r3, 0x100027838 --> b"\x00\x00\x00\x00\xb8Y\x02\x00\x10\x00\x00\x00\x00\x00\x00\x00\x1d"\x00\x0…        r3 load str located at 4295129144
    call function_18489                     
lbb_12411:
    mov64 r1, 2                                     r1 = 2 as i32 as i64 as u64
    mov64 r2, 2                                     r2 = 2 as i32 as i64 as u64
    lddw r3, 0x100027940 --> b"\x00\x00\x00\x00\xb8Y\x02\x00\x10\x00\x00\x00\x00\x00\x00\x00\x14"\x00\x0…        r3 load str located at 4295129408
    call function_18489                     
lbb_12416:
    mov64 r1, 2                                     r1 = 2 as i32 as i64 as u64
    mov64 r2, 2                                     r2 = 2 as i32 as i64 as u64
    lddw r3, 0x100027850 --> b"\x00\x00\x00\x00\xb8Y\x02\x00\x10\x00\x00\x00\x00\x00\x00\x00\x1d"\x00\x0…        r3 load str located at 4295129168
    call function_18489                     
lbb_12421:
    mov64 r1, 3                                     r1 = 3 as i32 as i64 as u64
    mov64 r2, 3                                     r2 = 3 as i32 as i64 as u64
    lddw r3, 0x100027958 --> b"\x00\x00\x00\x00\xb8Y\x02\x00\x10\x00\x00\x00\x00\x00\x00\x00\x16"\x00\x0…        r3 load str located at 4295129432
    call function_18489                     
lbb_12426:
    mov64 r1, 3                                     r1 = 3 as i32 as i64 as u64
    mov64 r2, 3                                     r2 = 3 as i32 as i64 as u64
    lddw r3, 0x100027868 --> b"\x00\x00\x00\x00\xb8Y\x02\x00\x10\x00\x00\x00\x00\x00\x00\x00\x1f"\x00\x0…        r3 load str located at 4295129192
    call function_18489                     
lbb_12431:
    mov64 r1, 4                                     r1 = 4 as i32 as i64 as u64
    mov64 r2, 4                                     r2 = 4 as i32 as i64 as u64
    lddw r3, 0x100027970 --> b"\x00\x00\x00\x00\xb8Y\x02\x00\x10\x00\x00\x00\x00\x00\x00\x00\x16"\x00\x0…        r3 load str located at 4295129456
    call function_18489                     
lbb_12436:
    mov64 r1, 4                                     r1 = 4 as i32 as i64 as u64
    mov64 r2, 4                                     r2 = 4 as i32 as i64 as u64
    lddw r3, 0x100027880 --> b"\x00\x00\x00\x00\xb8Y\x02\x00\x10\x00\x00\x00\x00\x00\x00\x00\x1f"\x00\x0…        r3 load str located at 4295129216
    call function_18489                     
lbb_12441:
    mov64 r1, 5                                     r1 = 5 as i32 as i64 as u64
    mov64 r2, 5                                     r2 = 5 as i32 as i64 as u64
    lddw r3, 0x100027988 --> b"\x00\x00\x00\x00\xb8Y\x02\x00\x10\x00\x00\x00\x00\x00\x00\x00\x16"\x00\x0…        r3 load str located at 4295129480
    call function_18489                     
lbb_12446:
    mov64 r1, 5                                     r1 = 5 as i32 as i64 as u64
    mov64 r2, 5                                     r2 = 5 as i32 as i64 as u64
    lddw r3, 0x100027898 --> b"\x00\x00\x00\x00\xb8Y\x02\x00\x10\x00\x00\x00\x00\x00\x00\x00\x1f"\x00\x0…        r3 load str located at 4295129240
    call function_18489                     
lbb_12451:
    mov64 r1, 6                                     r1 = 6 as i32 as i64 as u64
    mov64 r2, 6                                     r2 = 6 as i32 as i64 as u64
    lddw r3, 0x1000279a0 --> b"\x00\x00\x00\x00\xb8Y\x02\x00\x10\x00\x00\x00\x00\x00\x00\x00\x16"\x00\x0…        r3 load str located at 4295129504
    call function_18489                     
lbb_12456:
    mov64 r1, 6                                     r1 = 6 as i32 as i64 as u64
    mov64 r2, 6                                     r2 = 6 as i32 as i64 as u64
    lddw r3, 0x1000278b0 --> b"\x00\x00\x00\x00\xb8Y\x02\x00\x10\x00\x00\x00\x00\x00\x00\x00\x1f"\x00\x0…        r3 load str located at 4295129264
    call function_18489                     
lbb_12461:
    mov64 r1, 7                                     r1 = 7 as i32 as i64 as u64
    mov64 r2, 7                                     r2 = 7 as i32 as i64 as u64
    lddw r3, 0x1000279b8 --> b"\x00\x00\x00\x00\xb8Y\x02\x00\x10\x00\x00\x00\x00\x00\x00\x00\x17"\x00\x0…        r3 load str located at 4295129528
    call function_18489                     
lbb_12466:
    mov64 r1, 7                                     r1 = 7 as i32 as i64 as u64
    mov64 r2, 7                                     r2 = 7 as i32 as i64 as u64
    lddw r3, 0x1000278c8 --> b"\x00\x00\x00\x00\xb8Y\x02\x00\x10\x00\x00\x00\x00\x00\x00\x00 "\x00\x00\x…        r3 load str located at 4295129288
    call function_18489                     
lbb_12471:
    mov64 r1, 8                                     r1 = 8 as i32 as i64 as u64
    mov64 r2, 8                                     r2 = 8 as i32 as i64 as u64
    lddw r3, 0x1000279d0 --> b"\x00\x00\x00\x00\xb8Y\x02\x00\x10\x00\x00\x00\x00\x00\x00\x00\x17"\x00\x0…        r3 load str located at 4295129552
    call function_18489                     
lbb_12476:
    mov64 r1, 8                                     r1 = 8 as i32 as i64 as u64
    mov64 r2, 8                                     r2 = 8 as i32 as i64 as u64
    lddw r3, 0x1000278e0 --> b"\x00\x00\x00\x00\xb8Y\x02\x00\x10\x00\x00\x00\x00\x00\x00\x00 "\x00\x00%\…        r3 load str located at 4295129312
    call function_18489                     
lbb_12481:
    mov64 r1, 9                                     r1 = 9 as i32 as i64 as u64
    mov64 r2, 9                                     r2 = 9 as i32 as i64 as u64
    lddw r3, 0x1000279e8 --> b"\x00\x00\x00\x00\xb8Y\x02\x00\x10\x00\x00\x00\x00\x00\x00\x00\x17"\x00\x0…        r3 load str located at 4295129576
    call function_18489                     
lbb_12486:
    mov64 r1, 9                                     r1 = 9 as i32 as i64 as u64
    mov64 r2, 9                                     r2 = 9 as i32 as i64 as u64
    lddw r3, 0x1000278f8 --> b"\x00\x00\x00\x00\xb8Y\x02\x00\x10\x00\x00\x00\x00\x00\x00\x00 "\x00\x00<\…        r3 load str located at 4295129336
    call function_18489                     
    stxdw [r10-0x220], r1                   
    ldxdw r9, [r2+0x28]                     
    ldxdw r5, [r2+0x20]                     
    ldxdw r8, [r2+0x8]                      
    ldxdw r6, [r2+0x0]                      
    ldxb r3, [r2+0x64]                      
    stxdw [r10-0x238], r8                   
    stxdw [r10-0x228], r9                   
    stxdw [r10-0x230], r5                   
    mov64 r7, r6                                    r7 = r6
    jeq r3, 0, lbb_12574                            if r3 == (0 as i32 as i64 as u64) { pc += 72 }
    add64 r7, 56                                    r7 += 56   ///  r7 = r7.wrapping_add(56 as i32 as i64 as u64)
    mov64 r0, r7                                    r0 = r7
    jle r8, 6, lbb_13108                            if r8 <= (6 as i32 as i64 as u64) { pc += 603 }
    mov64 r4, r8                                    r4 = r8
    add64 r4, -7                                    r4 += -7   ///  r4 = r4.wrapping_add(-7 as i32 as i64 as u64)
    mov64 r3, r4                                    r3 = r4
    jle r8, 6, lbb_13113                            if r8 <= (6 as i32 as i64 as u64) { pc += 604 }
lbb_12509:
    jeq r8, 0, lbb_13115                            if r8 == (0 as i32 as i64 as u64) { pc += 605 }
lbb_12510:
    jeq r8, 1, lbb_13150                            if r8 == (1 as i32 as i64 as u64) { pc += 639 }
    jle r8, 2, lbb_13160                            if r8 <= (2 as i32 as i64 as u64) { pc += 648 }
    jeq r8, 3, lbb_13170                            if r8 == (3 as i32 as i64 as u64) { pc += 657 }
    jle r8, 4, lbb_13180                            if r8 <= (4 as i32 as i64 as u64) { pc += 666 }
    jeq r8, 5, lbb_13190                            if r8 == (5 as i32 as i64 as u64) { pc += 675 }
    stxdw [r10-0x260], r4                   
    jle r8, 6, lbb_13195                            if r8 <= (6 as i32 as i64 as u64) { pc += 678 }
    mov64 r4, 3                                     r4 = 3 as i32 as i64 as u64
    mov64 r1, r8                                    r1 = r8
    add64 r1, -27                                   r1 += -27   ///  r1 = r1.wrapping_add(-27 as i32 as i64 as u64)
    jlt r1, -33, lbb_13136                          if r1 < (-33 as i32 as i64 as u64) { pc += 615 }
    ldxdw r1, [r2+0x50]                     
    stxdw [r10-0x240], r1                   
    ldxdw r5, [r1+0x0]                      
    ldxdw r1, [r5+0x50]                     
    jlt r1, 32, lbb_13145                           if r1 < (32 as i32 as i64 as u64) { pc += 619 }
    stxdw [r10-0x2e0], r0                   
    stxdw [r10-0x2d8], r3                   
    ldxdw r1, [r2+0x48]                     
    stxdw [r10-0x248], r1                   
    ldxdw r1, [r2+0x38]                     
    stxdw [r10-0x258], r1                   
    ldxdw r1, [r2+0x30]                     
    stxdw [r10-0x250], r1                   
    mov64 r1, r6                                    r1 = r6
    add64 r1, 8                                     r1 += 8   ///  r1 = r1.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x268], r1                   
    mov64 r1, r6                                    r1 = r6
    add64 r1, 16                                    r1 += 16   ///  r1 = r1.wrapping_add(16 as i32 as i64 as u64)
    stxdw [r10-0x270], r1                   
    mov64 r1, r6                                    r1 = r6
    add64 r1, 24                                    r1 += 24   ///  r1 = r1.wrapping_add(24 as i32 as i64 as u64)
    stxdw [r10-0x278], r1                   
    ldxdw r0, [r2+0x58]                     
    mov64 r1, r6                                    r1 = r6
    add64 r1, 32                                    r1 += 32   ///  r1 = r1.wrapping_add(32 as i32 as i64 as u64)
    stxdw [r10-0x280], r1                   
    ldxdw r2, [r2+0x10]                     
    mov64 r1, r6                                    r1 = r6
    add64 r1, 48                                    r1 += 48   ///  r1 = r1.wrapping_add(48 as i32 as i64 as u64)
    stxdw [r10-0x288], r1                   
    mov64 r4, r6                                    r4 = r6
    add64 r6, 40                                    r6 += 40   ///  r6 = r6.wrapping_add(40 as i32 as i64 as u64)
    stxdw [r10-0x290], r6                   
    ldxdw r3, [r6+0x0]                      
    mov64 r1, r3                                    r1 = r3
    add64 r1, 8                                     r1 += 8   ///  r1 = r1.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x2a0], r1                   
    ldxdw r1, [r1+0x0]                      
    ldxdw r6, [r5+0x58]                     
    jne r6, r1, lbb_12633                           if r6 != r1 { pc += 72 }
    ldxdw r1, [r3+0x10]                     
    ldxdw r6, [r5+0x60]                     
    jne r6, r1, lbb_12633                           if r6 != r1 { pc += 69 }
    ldxdw r1, [r3+0x18]                     
    ldxdw r6, [r5+0x68]                     
    jne r6, r1, lbb_12633                           if r6 != r1 { pc += 66 }
    ldxdw r1, [r3+0x20]                     
    ldxdw r3, [r5+0x70]                     
    jne r3, r1, lbb_12633                           if r3 != r1 { pc += 63 }
    mov64 r6, r9                                    r6 = r9
    ldxdw r5, [r10-0x240]                   
    stxdw [r10-0x240], r0                   
    ja lbb_12635                                    if true { pc += 61 }
lbb_12574:
    add64 r7, 40                                    r7 += 40   ///  r7 = r7.wrapping_add(40 as i32 as i64 as u64)
    mov64 r5, r7                                    r5 = r7
    jle r8, 4, lbb_13120                            if r8 <= (4 as i32 as i64 as u64) { pc += 543 }
    mov64 r3, r8                                    r3 = r8
    add64 r3, -5                                    r3 += -5   ///  r3 = r3.wrapping_add(-5 as i32 as i64 as u64)
    mov64 r0, r3                                    r0 = r3
    jle r8, 4, lbb_13125                            if r8 <= (4 as i32 as i64 as u64) { pc += 544 }
lbb_12581:
    jeq r8, 0, lbb_13127                            if r8 == (0 as i32 as i64 as u64) { pc += 545 }
lbb_12582:
    jeq r8, 1, lbb_13155                            if r8 == (1 as i32 as i64 as u64) { pc += 572 }
    jle r8, 2, lbb_13165                            if r8 <= (2 as i32 as i64 as u64) { pc += 581 }
    jeq r8, 3, lbb_13175                            if r8 == (3 as i32 as i64 as u64) { pc += 590 }
    stxdw [r10-0x248], r3                   
    jle r8, 4, lbb_13185                            if r8 <= (4 as i32 as i64 as u64) { pc += 598 }
    mov64 r4, 3                                     r4 = 3 as i32 as i64 as u64
    mov64 r3, r8                                    r3 = r8
    add64 r3, -29                                   r3 += -29   ///  r3 = r3.wrapping_add(-29 as i32 as i64 as u64)
    jlt r3, -33, lbb_13136                          if r3 < (-33 as i32 as i64 as u64) { pc += 545 }
    stxdw [r10-0x298], r5                   
    ldxdw r3, [r2+0x50]                     
    mov64 r5, 0                                     r5 = 0 as i32 as i64 as u64
    stxdw [r10-0x240], r3                   
    ldxdw r1, [r3+0x0]                      
    ldxdw r3, [r1+0x50]                     
    jlt r3, 32, lbb_13104                           if r3 < (32 as i32 as i64 as u64) { pc += 506 }
    stxdw [r10-0x2a0], r0                   
    mov64 r3, r6                                    r3 = r6
    add64 r3, 16                                    r3 += 16   ///  r3 = r3.wrapping_add(16 as i32 as i64 as u64)
    stxdw [r10-0x250], r3                   
    ldxdw r9, [r3+0x0]                      
    ldxdw r0, [r9+0x50]                     
    ldxdw r3, [r10-0x220]                   
    jlt r0, 32, lbb_13105                           if r0 < (32 as i32 as i64 as u64) { pc += 499 }
    ldxdw r4, [r2+0x48]                     
    stxdw [r10-0x260], r4                   
    mov64 r0, r6                                    r0 = r6
    add64 r0, 8                                     r0 += 8   ///  r0 = r0.wrapping_add(8 as i32 as i64 as u64)
    ldxdw r4, [r2+0x58]                     
    mov64 r5, r6                                    r5 = r6
    add64 r5, 32                                    r5 += 32   ///  r5 = r5.wrapping_add(32 as i32 as i64 as u64)
    stxdw [r10-0x268], r5                   
    mov64 r5, r6                                    r5 = r6
    add64 r5, 24                                    r5 += 24   ///  r5 = r5.wrapping_add(24 as i32 as i64 as u64)
    stxdw [r10-0x270], r5                   
    ldxdw r5, [r9+0x58]                     
    ldxdw r8, [r1+0x58]                     
    stxdw [r10-0x258], r0                   
    jne r8, r5, lbb_12884                           if r8 != r5 { pc += 263 }
    ldxdw r5, [r9+0x60]                     
    ldxdw r8, [r1+0x60]                     
    jne r8, r5, lbb_12884                           if r8 != r5 { pc += 260 }
    ldxdw r5, [r9+0x68]                     
    ldxdw r8, [r1+0x68]                     
    jne r8, r5, lbb_12884                           if r8 != r5 { pc += 257 }
    ldxdw r5, [r9+0x70]                     
    ldxdw r8, [r1+0x70]                     
    jne r8, r5, lbb_12884                           if r8 != r5 { pc += 254 }
    ldxdw r5, [r10-0x240]                   
    stxdw [r10-0x240], r4                   
    ja lbb_12885                                    if true { pc += 252 }
lbb_12633:
    mov64 r6, r9                                    r6 = r9
    mov64 r5, r0                                    r5 = r0
lbb_12635:
    ldxdw r3, [r10-0x230]                   
    stxdw [r10-0x298], r5                   
    stxdw [r10-0x200], r2                   
    lddw r1, 0x621ec91a0bed042b                     r1 load str located at 7070309578724672555
    stxdw [r10-0x208], r1                   
    stdw [r10-0x1e8], 0                     
    stdw [r10-0x1f0], 0                     
    stdw [r10-0x1f8], 0                     
    stb [r10-0x1e0], 1                      
    ldxdw r1, [r3+0x0]                      
    stxdw [r10-0x2c8], r1                   
    ldxdw r1, [r10-0x248]                   
    ldxdw r1, [r1+0x0]                      
    stxdw [r10-0x230], r1                   
    ldxdw r1, [r4+0x0]                      
    stxdw [r10-0x2a8], r1                   
    ldxdw r1, [r4+0x8]                      
    stxdw [r10-0x2b0], r1                   
    ldxdw r1, [r5+0x0]                      
    stxdw [r10-0x2b8], r1                   
    ldxdw r1, [r10-0x240]                   
    ldxdw r1, [r1+0x0]                      
    stxdw [r10-0x2c0], r1                   
    ldxdw r8, [r4+0x10]                     
    ldxdw r0, [r4+0x18]                     
    ldxdw r5, [r4+0x20]                     
    mov64 r3, r4                                    r3 = r4
    ldxdw r6, [r6+0x0]                      
    ldxdw r1, [r10-0x250]                   
    ldxdw r4, [r1+0x0]                      
    ldxdw r1, [r10-0x258]                   
    ldxdw r2, [r1+0x0]                      
    ldxdw r1, [r3+0x30]                     
    ldxdw r9, [r10-0x2a0]                   
    stxdw [r10-0x128], r9                   
    add64 r1, 8                                     r1 += 8   ///  r1 = r1.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x118], r1                   
    add64 r2, 8                                     r2 += 8   ///  r2 = r2.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x138], r2                   
    add64 r4, 8                                     r4 += 8   ///  r4 = r4.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x148], r4                   
    add64 r6, 8                                     r6 += 8   ///  r6 = r6.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x158], r6                   
    ldxdw r6, [r10-0x2c8]                   
    add64 r5, 8                                     r5 += 8   ///  r5 = r5.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x168], r5                   
    add64 r0, 8                                     r0 += 8   ///  r0 = r0.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x178], r0                   
    add64 r8, 8                                     r8 += 8   ///  r8 = r8.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x188], r8                   
    ldxdw r1, [r10-0x2c0]                   
    add64 r1, 8                                     r1 += 8   ///  r1 = r1.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x198], r1                   
    ldxdw r1, [r10-0x2b8]                   
    add64 r1, 8                                     r1 += 8   ///  r1 = r1.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x1a8], r1                   
    ldxdw r1, [r10-0x2b0]                   
    add64 r1, 8                                     r1 += 8   ///  r1 = r1.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x1b8], r1                   
    ldxdw r1, [r10-0x2a8]                   
    add64 r1, 8                                     r1 += 8   ///  r1 = r1.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x1c8], r1                   
    ldxdw r1, [r10-0x230]                   
    add64 r1, 8                                     r1 += 8   ///  r1 = r1.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x1d8], r1                   
    add64 r6, 8                                     r6 += 8   ///  r6 = r6.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0xc8], r6                    
    stxdw [r10-0xd8], r6                    
    stxdw [r10-0xe8], r6                    
    stxdw [r10-0xf8], r6                    
    stxdw [r10-0x108], r6                   
    sth [r10-0xc0], 0                       
    sth [r10-0xd0], 0                       
    sth [r10-0xe0], 0                       
    sth [r10-0xf0], 0                       
    sth [r10-0x100], 0                      
    sth [r10-0x110], 0                      
    sth [r10-0x120], 0                      
    sth [r10-0x130], 0                      
    sth [r10-0x140], 0                      
    sth [r10-0x150], 0                      
    sth [r10-0x160], 1                      
    sth [r10-0x170], 1                      
    sth [r10-0x180], 1                      
    sth [r10-0x190], 1                      
    sth [r10-0x1a0], 1                      
    sth [r10-0x1b0], 1                      
    sth [r10-0x1c0], 0                      
    sth [r10-0x1d0], 257                    
    ldxdw r1, [r10-0x288]                   
    stxdw [r10-0x58], r1                    
    ldxdw r1, [r10-0x290]                   
    stxdw [r10-0x60], r1                    
    ldxdw r1, [r10-0x258]                   
    stxdw [r10-0x68], r1                    
    ldxdw r1, [r10-0x250]                   
    stxdw [r10-0x70], r1                    
    ldxdw r1, [r10-0x228]                   
    stxdw [r10-0x78], r1                    
    ldxdw r1, [r10-0x280]                   
    stxdw [r10-0x80], r1                    
    ldxdw r1, [r10-0x278]                   
    stxdw [r10-0x88], r1                    
    ldxdw r1, [r10-0x270]                   
    stxdw [r10-0x90], r1                    
    ldxdw r1, [r10-0x240]                   
    stxdw [r10-0x98], r1                    
    ldxdw r1, [r10-0x298]                   
    stxdw [r10-0xa0], r1                    
    ldxdw r2, [r10-0x268]                   
    stxdw [r10-0xa8], r2                    
    stxdw [r10-0xb0], r3                    
    ldxdw r1, [r10-0x248]                   
    stxdw [r10-0x30], r1                    
    stxdw [r10-0x38], r1                    
    stxdw [r10-0x40], r1                    
    stxdw [r10-0x48], r1                    
    stxdw [r10-0x50], r1                    
    stxdw [r10-0xb8], r1                    
    mov64 r4, 13                                    r4 = 13 as i32 as i64 as u64
    ldxdw r1, [r10-0x260]                   
    jeq r1, 0, lbb_12862                            if r1 == (0 as i32 as i64 as u64) { pc += 104 }
    ldxdw r1, [r2+0x0]                      
    ldxdw r2, [r1+0x50]                     
    jle r2, 236, lbb_13137                          if r2 <= (236 as i32 as i64 as u64) { pc += 376 }
    jle r2, 272, lbb_13141                          if r2 <= (272 as i32 as i64 as u64) { pc += 379 }
    ldxh r8, [r1+0x143]                     
    jeq r8, 0, lbb_13147                            if r8 == (0 as i32 as i64 as u64) { pc += 383 }
    mul64 r8, 60                                    r8 *= 60   ///  r8 = r8.wrapping_mul(60 as u64)
    ldxw r9, [r1+0x165]                     
    lsh64 r9, 32                                    r9 <<= 32   ///  r9 = r9.wrapping_shl(32)
    arsh64 r9, 32                                   r9 >>= 32 (signed)   ///  r9 = (r9 as i64).wrapping_shr(32)
    mov64 r1, r9                                    r1 = r9
    mov64 r2, r8                                    r2 = r8
    call function_19182                     
    jsgt r9, -1, lbb_12778                          if (r9 as i64) > (-1 as i32 as i64) { pc += 6 }
    neg64 r9                                        r9 = -r9   ///  r9 = (r9 as i64).wrapping_neg() as u64
    lsh64 r9, 32                                    r9 <<= 32   ///  r9 = r9.wrapping_shl(32)
    rsh64 r9, 32                                    r9 >>= 32   ///  r9 = r9.wrapping_shr(32)
    mod64 r9, r8                                    r9 %= r8   ///  r9 = r9 % r8
    jeq r9, 0, lbb_12778                            if r9 == (0 as i32 as i64 as u64) { pc += 1 }
    add64 r0, -1                                    r0 += -1   ///  r0 = r0.wrapping_add(-1 as i32 as i64 as u64)
lbb_12778:
    mul64 r0, r8                                    r0 *= r8   ///  r0 = r0.wrapping_mul(r8)
    mov64 r3, 8                                     r3 = 8 as i32 as i64 as u64
    ldxdw r5, [r10-0x238]                   
    mov64 r4, r5                                    r4 = r5
    lsh64 r4, 3                                     r4 <<= 3   ///  r4 = r4.wrapping_shl(3)
    add64 r4, -56                                   r4 += -56   ///  r4 = r4.wrapping_add(-56 as i32 as i64 as u64)
    lsh64 r0, 32                                    r0 <<= 32   ///  r0 = r0.wrapping_shl(32)
    rsh64 r0, 32                                    r0 >>= 32   ///  r0 = r0.wrapping_shr(32)
lbb_12786:
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    jeq r4, 0, lbb_12799                            if r4 == (0 as i32 as i64 as u64) { pc += 11 }
    jeq r5, r3, lbb_12799                           if r5 == r3 { pc += 10 }
    ldxdw r1, [r7+0x0]                      
    ldxdw r2, [r1+0x50]                     
    jle r2, 43, lbb_13132                           if r2 <= (43 as i32 as i64 as u64) { pc += 340 }
    add64 r7, 8                                     r7 += 8   ///  r7 = r7.wrapping_add(8 as i32 as i64 as u64)
    add64 r3, 1                                     r3 += 1   ///  r3 = r3.wrapping_add(1 as i32 as i64 as u64)
    add64 r4, -8                                    r4 += -8   ///  r4 = r4.wrapping_add(-8 as i32 as i64 as u64)
    ldxw r1, [r1+0x80]                      
    jne r1, r0, lbb_12786                           if r1 != r0 { pc += -11 }
    add64 r3, -9                                    r3 += -9   ///  r3 = r3.wrapping_add(-9 as i32 as i64 as u64)
    mov64 r1, r3                                    r1 = r3
lbb_12799:
    ldxdw r0, [r10-0x2d8]                   
    ldxdw r5, [r10-0x2e0]                   
    mov64 r4, 13                                    r4 = 13 as i32 as i64 as u64
    jge r1, r0, lbb_12862                           if r1 >= r0 { pc += 59 }
    mov64 r2, r1                                    r2 = r1
    lsh64 r2, 3                                     r2 <<= 3   ///  r2 = r2.wrapping_shl(3)
    mov64 r3, r5                                    r3 = r5
    add64 r3, r2                                    r3 += r2   ///  r3 = r3.wrapping_add(r2)
    ldxdw r2, [r3+0x0]                      
    stxdw [r10-0x50], r3                    
    add64 r2, 8                                     r2 += 8   ///  r2 = r2.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x108], r2                   
    mov64 r4, 14                                    r4 = 14 as i32 as i64 as u64
    sth [r10-0x100], 1                      
    mov64 r2, r1                                    r2 = r1
    add64 r2, 1                                     r2 += 1   ///  r2 = r2.wrapping_add(1 as i32 as i64 as u64)
    jge r2, r0, lbb_12862                           if r2 >= r0 { pc += 46 }
    lsh64 r2, 3                                     r2 <<= 3   ///  r2 = r2.wrapping_shl(3)
    mov64 r3, r5                                    r3 = r5
    add64 r3, r2                                    r3 += r2   ///  r3 = r3.wrapping_add(r2)
    ldxdw r2, [r3+0x0]                      
    stxdw [r10-0x48], r3                    
    add64 r2, 8                                     r2 += 8   ///  r2 = r2.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0xf8], r2                    
    mov64 r4, 15                                    r4 = 15 as i32 as i64 as u64
    sth [r10-0xf0], 1                       
    mov64 r2, r1                                    r2 = r1
    add64 r2, 2                                     r2 += 2   ///  r2 = r2.wrapping_add(2 as i32 as i64 as u64)
    jge r2, r0, lbb_12862                           if r2 >= r0 { pc += 34 }
    lsh64 r2, 3                                     r2 <<= 3   ///  r2 = r2.wrapping_shl(3)
    mov64 r3, r5                                    r3 = r5
    add64 r3, r2                                    r3 += r2   ///  r3 = r3.wrapping_add(r2)
    ldxdw r2, [r3+0x0]                      
    stxdw [r10-0x40], r3                    
    add64 r2, 8                                     r2 += 8   ///  r2 = r2.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0xe8], r2                    
    mov64 r4, 16                                    r4 = 16 as i32 as i64 as u64
    sth [r10-0xe0], 1                       
    mov64 r2, r1                                    r2 = r1
    add64 r2, 3                                     r2 += 3   ///  r2 = r2.wrapping_add(3 as i32 as i64 as u64)
    jge r2, r0, lbb_12862                           if r2 >= r0 { pc += 22 }
    lsh64 r2, 3                                     r2 <<= 3   ///  r2 = r2.wrapping_shl(3)
    mov64 r3, r5                                    r3 = r5
    add64 r3, r2                                    r3 += r2   ///  r3 = r3.wrapping_add(r2)
    ldxdw r2, [r3+0x0]                      
    stxdw [r10-0x38], r3                    
    add64 r2, 8                                     r2 += 8   ///  r2 = r2.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0xd8], r2                    
    mov64 r4, 17                                    r4 = 17 as i32 as i64 as u64
    sth [r10-0xd0], 1                       
    mov64 r2, r1                                    r2 = r1
    add64 r2, 4                                     r2 += 4   ///  r2 = r2.wrapping_add(4 as i32 as i64 as u64)
    jge r2, r0, lbb_12862                           if r2 >= r0 { pc += 10 }
    lsh64 r2, 3                                     r2 <<= 3   ///  r2 = r2.wrapping_shl(3)
    add64 r5, r2                                    r5 += r2   ///  r5 = r5.wrapping_add(r2)
    ldxdw r2, [r5+0x0]                      
    stxdw [r10-0x30], r5                    
    add64 r2, 8                                     r2 += 8   ///  r2 = r2.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0xc8], r2                    
    mov64 r4, 18                                    r4 = 18 as i32 as i64 as u64
    sth [r10-0xc0], 1                       
    add64 r1, 5                                     r1 += 5   ///  r1 = r1.wrapping_add(5 as i32 as i64 as u64)
    jlt r1, r0, lbb_13200                           if r1 < r0 { pc += 338 }
lbb_12862:
    mov64 r1, r10                                   r1 = r10
    add64 r1, -472                                  r1 += -472   ///  r1 = r1.wrapping_add(-472 as i32 as i64 as u64)
    stxdw [r10-0x10], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -520                                  r1 += -520   ///  r1 = r1.wrapping_add(-520 as i32 as i64 as u64)
    stxdw [r10-0x20], r1                    
    stxdw [r10-0x28], r6                    
    stxdw [r10-0x8], r4                     
    stdw [r10-0x18], 41                     
    stdw [r10-0xff8], 0                     
    stdw [r10-0x1000], 8                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -536                                  r1 += -536   ///  r1 = r1.wrapping_add(-536 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -40                                   r2 += -40   ///  r2 = r2.wrapping_add(-40 as i32 as i64 as u64)
    mov64 r3, r10                                   r3 = r10
    add64 r3, -184                                  r3 += -184   ///  r3 = r3.wrapping_add(-184 as i32 as i64 as u64)
    mov64 r5, r10                                   r5 = r10
    call function_18367                     
    ldxw r5, [r10-0x214]                    
    ldxw r4, [r10-0x218]                    
    ja lbb_13104                                    if true { pc += 220 }
lbb_12884:
    mov64 r5, r4                                    r5 = r4
lbb_12885:
    ldxdw r1, [r2+0x10]                     
    stxdw [r10-0x290], r1                   
    ldxdw r1, [r10-0x230]                   
    ldxdw r1, [r1+0x0]                      
    stxdw [r10-0x288], r1                   
    add64 r9, 8                                     r9 += 8   ///  r9 = r9.wrapping_add(8 as i32 as i64 as u64)
    ldxdw r2, [r10-0x260]                   
    ldxdw r1, [r2+0x0]                      
    stxdw [r10-0x230], r1                   
    ldxdw r1, [r6+0x0]                      
    stxdw [r10-0x280], r1                   
    ldxdw r4, [r6+0x8]                      
    stxdw [r10-0x278], r5                   
    ldxdw r5, [r5+0x0]                      
    ldxdw r1, [r10-0x240]                   
    ldxdw r8, [r1+0x0]                      
    ldxdw r0, [r6+0x18]                     
    stxdw [r10-0x2d0], r6                   
    ldxdw r6, [r6+0x20]                     
    ldxdw r3, [r10-0x228]                   
    ldxdw r1, [r3+0x0]                      
    stxdw [r10-0x188], r9                   
    add64 r1, 8                                     r1 += 8   ///  r1 = r1.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x158], r1                   
    add64 r6, 8                                     r6 += 8   ///  r6 = r6.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x168], r6                   
    ldxdw r6, [r10-0x288]                   
    add64 r0, 8                                     r0 += 8   ///  r0 = r0.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x178], r0                   
    add64 r8, 8                                     r8 += 8   ///  r8 = r8.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x198], r8                   
    add64 r5, 8                                     r5 += 8   ///  r5 = r5.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x1a8], r5                   
    add64 r4, 8                                     r4 += 8   ///  r4 = r4.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x1b8], r4                   
    ldxdw r1, [r10-0x280]                   
    add64 r1, 8                                     r1 += 8   ///  r1 = r1.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x1c8], r1                   
    ldxdw r1, [r10-0x230]                   
    add64 r1, 8                                     r1 += 8   ///  r1 = r1.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x1d8], r1                   
    add64 r6, 8                                     r6 += 8   ///  r6 = r6.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x108], r6                   
    stxdw [r10-0x118], r6                   
    stxdw [r10-0x128], r6                   
    stxdw [r10-0x138], r6                   
    stxdw [r10-0x148], r6                   
    sth [r10-0x100], 0                      
    sth [r10-0x110], 0                      
    sth [r10-0x120], 0                      
    sth [r10-0x130], 0                      
    sth [r10-0x140], 0                      
    sth [r10-0x150], 0                      
    sth [r10-0x160], 1                      
    sth [r10-0x170], 1                      
    sth [r10-0x180], 1                      
    sth [r10-0x190], 1                      
    sth [r10-0x1a0], 1                      
    sth [r10-0x1b0], 1                      
    sth [r10-0x1c0], 0                      
    sth [r10-0x1d0], 257                    
    stxdw [r10-0x78], r3                    
    ldxdw r1, [r10-0x268]                   
    stxdw [r10-0x80], r1                    
    ldxdw r1, [r10-0x270]                   
    stxdw [r10-0x88], r1                    
    ldxdw r1, [r10-0x250]                   
    stxdw [r10-0x90], r1                    
    ldxdw r1, [r10-0x240]                   
    stxdw [r10-0x98], r1                    
    ldxdw r1, [r10-0x278]                   
    stxdw [r10-0xa0], r1                    
    ldxdw r3, [r10-0x258]                   
    stxdw [r10-0xa8], r3                    
    ldxdw r1, [r10-0x2d0]                   
    stxdw [r10-0xb0], r1                    
    stxdw [r10-0x50], r2                    
    stxdw [r10-0x58], r2                    
    stxdw [r10-0x60], r2                    
    stxdw [r10-0x68], r2                    
    stxdw [r10-0x70], r2                    
    stxdw [r10-0xb8], r2                    
    mov64 r4, 9                                     r4 = 9 as i32 as i64 as u64
    ldxdw r1, [r10-0x248]                   
    jeq r1, 0, lbb_13074                            if r1 == (0 as i32 as i64 as u64) { pc += 104 }
    ldxdw r1, [r3+0x0]                      
    ldxdw r2, [r1+0x50]                     
    jle r2, 236, lbb_13137                          if r2 <= (236 as i32 as i64 as u64) { pc += 164 }
    jle r2, 272, lbb_13141                          if r2 <= (272 as i32 as i64 as u64) { pc += 167 }
    ldxh r8, [r1+0x143]                     
    jeq r8, 0, lbb_13147                            if r8 == (0 as i32 as i64 as u64) { pc += 171 }
    mul64 r8, 60                                    r8 *= 60   ///  r8 = r8.wrapping_mul(60 as u64)
    ldxw r9, [r1+0x165]                     
    lsh64 r9, 32                                    r9 <<= 32   ///  r9 = r9.wrapping_shl(32)
    arsh64 r9, 32                                   r9 >>= 32 (signed)   ///  r9 = (r9 as i64).wrapping_shr(32)
    mov64 r1, r9                                    r1 = r9
    mov64 r2, r8                                    r2 = r8
    call function_19182                     
    jsgt r9, -1, lbb_12990                          if (r9 as i64) > (-1 as i32 as i64) { pc += 6 }
    neg64 r9                                        r9 = -r9   ///  r9 = (r9 as i64).wrapping_neg() as u64
    lsh64 r9, 32                                    r9 <<= 32   ///  r9 = r9.wrapping_shl(32)
    rsh64 r9, 32                                    r9 >>= 32   ///  r9 = r9.wrapping_shr(32)
    mod64 r9, r8                                    r9 %= r8   ///  r9 = r9 % r8
    jeq r9, 0, lbb_12990                            if r9 == (0 as i32 as i64 as u64) { pc += 1 }
    add64 r0, -1                                    r0 += -1   ///  r0 = r0.wrapping_add(-1 as i32 as i64 as u64)
lbb_12990:
    mul64 r0, r8                                    r0 *= r8   ///  r0 = r0.wrapping_mul(r8)
    mov64 r3, 6                                     r3 = 6 as i32 as i64 as u64
    ldxdw r5, [r10-0x238]                   
    mov64 r4, r5                                    r4 = r5
    lsh64 r4, 3                                     r4 <<= 3   ///  r4 = r4.wrapping_shl(3)
    add64 r4, -40                                   r4 += -40   ///  r4 = r4.wrapping_add(-40 as i32 as i64 as u64)
    lsh64 r0, 32                                    r0 <<= 32   ///  r0 = r0.wrapping_shl(32)
    rsh64 r0, 32                                    r0 >>= 32   ///  r0 = r0.wrapping_shr(32)
lbb_12998:
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    jeq r4, 0, lbb_13011                            if r4 == (0 as i32 as i64 as u64) { pc += 11 }
    jeq r5, r3, lbb_13011                           if r5 == r3 { pc += 10 }
    ldxdw r1, [r7+0x0]                      
    ldxdw r2, [r1+0x50]                     
    jle r2, 43, lbb_13132                           if r2 <= (43 as i32 as i64 as u64) { pc += 128 }
    add64 r7, 8                                     r7 += 8   ///  r7 = r7.wrapping_add(8 as i32 as i64 as u64)
    add64 r4, -8                                    r4 += -8   ///  r4 = r4.wrapping_add(-8 as i32 as i64 as u64)
    add64 r3, 1                                     r3 += 1   ///  r3 = r3.wrapping_add(1 as i32 as i64 as u64)
    ldxw r1, [r1+0x80]                      
    jne r1, r0, lbb_12998                           if r1 != r0 { pc += -11 }
    add64 r3, -7                                    r3 += -7   ///  r3 = r3.wrapping_add(-7 as i32 as i64 as u64)
    mov64 r1, r3                                    r1 = r3
lbb_13011:
    ldxdw r0, [r10-0x2a0]                   
    ldxdw r5, [r10-0x298]                   
    mov64 r4, 9                                     r4 = 9 as i32 as i64 as u64
    jge r1, r0, lbb_13074                           if r1 >= r0 { pc += 59 }
    mov64 r2, r1                                    r2 = r1
    lsh64 r2, 3                                     r2 <<= 3   ///  r2 = r2.wrapping_shl(3)
    mov64 r3, r5                                    r3 = r5
    add64 r3, r2                                    r3 += r2   ///  r3 = r3.wrapping_add(r2)
    ldxdw r2, [r3+0x0]                      
    stxdw [r10-0x70], r3                    
    add64 r2, 8                                     r2 += 8   ///  r2 = r2.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x148], r2                   
    mov64 r4, 10                                    r4 = 10 as i32 as i64 as u64
    sth [r10-0x140], 1                      
    mov64 r2, r1                                    r2 = r1
    add64 r2, 1                                     r2 += 1   ///  r2 = r2.wrapping_add(1 as i32 as i64 as u64)
    jge r2, r0, lbb_13074                           if r2 >= r0 { pc += 46 }
    lsh64 r2, 3                                     r2 <<= 3   ///  r2 = r2.wrapping_shl(3)
    mov64 r3, r5                                    r3 = r5
    add64 r3, r2                                    r3 += r2   ///  r3 = r3.wrapping_add(r2)
    ldxdw r2, [r3+0x0]                      
    stxdw [r10-0x68], r3                    
    add64 r2, 8                                     r2 += 8   ///  r2 = r2.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x138], r2                   
    mov64 r4, 11                                    r4 = 11 as i32 as i64 as u64
    sth [r10-0x130], 1                      
    mov64 r2, r1                                    r2 = r1
    add64 r2, 2                                     r2 += 2   ///  r2 = r2.wrapping_add(2 as i32 as i64 as u64)
    jge r2, r0, lbb_13074                           if r2 >= r0 { pc += 34 }
    lsh64 r2, 3                                     r2 <<= 3   ///  r2 = r2.wrapping_shl(3)
    mov64 r3, r5                                    r3 = r5
    add64 r3, r2                                    r3 += r2   ///  r3 = r3.wrapping_add(r2)
    ldxdw r2, [r3+0x0]                      
    stxdw [r10-0x60], r3                    
    add64 r2, 8                                     r2 += 8   ///  r2 = r2.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x128], r2                   
    mov64 r4, 12                                    r4 = 12 as i32 as i64 as u64
    sth [r10-0x120], 1                      
    mov64 r2, r1                                    r2 = r1
    add64 r2, 3                                     r2 += 3   ///  r2 = r2.wrapping_add(3 as i32 as i64 as u64)
    jge r2, r0, lbb_13074                           if r2 >= r0 { pc += 22 }
    lsh64 r2, 3                                     r2 <<= 3   ///  r2 = r2.wrapping_shl(3)
    mov64 r3, r5                                    r3 = r5
    add64 r3, r2                                    r3 += r2   ///  r3 = r3.wrapping_add(r2)
    ldxdw r2, [r3+0x0]                      
    stxdw [r10-0x58], r3                    
    add64 r2, 8                                     r2 += 8   ///  r2 = r2.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x118], r2                   
    mov64 r4, 13                                    r4 = 13 as i32 as i64 as u64
    sth [r10-0x110], 1                      
    mov64 r2, r1                                    r2 = r1
    add64 r2, 4                                     r2 += 4   ///  r2 = r2.wrapping_add(4 as i32 as i64 as u64)
    jge r2, r0, lbb_13074                           if r2 >= r0 { pc += 10 }
    lsh64 r2, 3                                     r2 <<= 3   ///  r2 = r2.wrapping_shl(3)
    add64 r5, r2                                    r5 += r2   ///  r5 = r5.wrapping_add(r2)
    ldxdw r2, [r5+0x0]                      
    stxdw [r10-0x50], r5                    
    add64 r2, 8                                     r2 += 8   ///  r2 = r2.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x108], r2                   
    mov64 r4, 14                                    r4 = 14 as i32 as i64 as u64
    sth [r10-0x100], 1                      
    add64 r1, 5                                     r1 += 5   ///  r1 = r1.wrapping_add(5 as i32 as i64 as u64)
    jlt r1, r0, lbb_13205                           if r1 < r0 { pc += 131 }
lbb_13074:
    ldxdw r1, [r10-0x290]                   
    stxdw [r10-0x200], r1                   
    lddw r1, 0xc88775e1919ec6f8                     r1 load str located at -3997096532596832520
    stxdw [r10-0x208], r1                   
    stdw [r10-0x1e8], 0                     
    stdw [r10-0x1f0], 0                     
    stdw [r10-0x1f8], 0                     
    stb [r10-0x1e0], 1                      
    mov64 r1, r10                                   r1 = r10
    add64 r1, -472                                  r1 += -472   ///  r1 = r1.wrapping_add(-472 as i32 as i64 as u64)
    stxdw [r10-0x10], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -520                                  r1 += -520   ///  r1 = r1.wrapping_add(-520 as i32 as i64 as u64)
    stxdw [r10-0x20], r1                    
    stxdw [r10-0x28], r6                    
    stxdw [r10-0x8], r4                     
    stdw [r10-0x18], 41                     
    stdw [r10-0xff8], 0                     
    stdw [r10-0x1000], 8                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -528                                  r1 += -528   ///  r1 = r1.wrapping_add(-528 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -40                                   r2 += -40   ///  r2 = r2.wrapping_add(-40 as i32 as i64 as u64)
    mov64 r3, r10                                   r3 = r10
    add64 r3, -184                                  r3 += -184   ///  r3 = r3.wrapping_add(-184 as i32 as i64 as u64)
    mov64 r5, r10                                   r5 = r10
    call function_18367                     
    ldxw r5, [r10-0x20c]                    
    ldxw r4, [r10-0x210]                    
lbb_13104:
    ldxdw r3, [r10-0x220]                   
lbb_13105:
    stxw [r3+0x4], r5                       
    stxw [r3+0x0], r4                       
    exit                                    
lbb_13108:
    mov64 r0, 8                                     r0 = 8 as i32 as i64 as u64
    mov64 r4, r8                                    r4 = r8
    add64 r4, -7                                    r4 += -7   ///  r4 = r4.wrapping_add(-7 as i32 as i64 as u64)
    mov64 r3, r4                                    r3 = r4
    jgt r8, 6, lbb_12509                            if r8 > (6 as i32 as i64 as u64) { pc += -604 }
lbb_13113:
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
    jne r8, 0, lbb_12510                            if r8 != (0 as i32 as i64 as u64) { pc += -605 }
lbb_13115:
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
    lddw r3, 0x100027a78 --> b"\x00\x00\x00\x00\xb8Y\x02\x00\x10\x00\x00\x00\x00\x00\x00\x001"\x00\x00\x…        r3 load str located at 4295129720
    call function_18489                     
lbb_13120:
    mov64 r5, 8                                     r5 = 8 as i32 as i64 as u64
    mov64 r3, r8                                    r3 = r8
    add64 r3, -5                                    r3 += -5   ///  r3 = r3.wrapping_add(-5 as i32 as i64 as u64)
    mov64 r0, r3                                    r0 = r3
    jgt r8, 4, lbb_12581                            if r8 > (4 as i32 as i64 as u64) { pc += -544 }
lbb_13125:
    mov64 r0, 0                                     r0 = 0 as i32 as i64 as u64
    jne r8, 0, lbb_12582                            if r8 != (0 as i32 as i64 as u64) { pc += -545 }
lbb_13127:
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
    lddw r3, 0x100027a00 --> b"\x00\x00\x00\x00\xb8Y\x02\x00\x10\x00\x00\x00\x00\x00\x00\x00>"\x00\x00\x…        r3 load str located at 4295129600
    call function_18489                     
lbb_13132:
    mov64 r1, 44                                    r1 = 44 as i32 as i64 as u64
    lddw r3, 0x100025bb8 --> b"\x00\x00\x00\x00\xb8Y\x02\x00\x10\x00\x00\x00\x00\x00\x00\x00\x87\x06\x00…        r3 load str located at 4295121848
    call function_18737                     
lbb_13136:
    ja lbb_13104                                    if true { pc += -33 }
lbb_13137:
    mov64 r1, 237                                   r1 = 237 as i32 as i64 as u64
    lddw r3, 0x100025b88 --> b"\x00\x00\x00\x00\xb8Y\x02\x00\x10\x00\x00\x00\x00\x00\x00\x00}\x06\x00\x0…        r3 load str located at 4295121800
    call function_18737                     
lbb_13141:
    mov64 r1, 273                                   r1 = 273 as i32 as i64 as u64
    lddw r3, 0x100025ba0 --> b"\x00\x00\x00\x00\xb8Y\x02\x00\x10\x00\x00\x00\x00\x00\x00\x00\x7f\x06\x00…        r3 load str located at 4295121824
    call function_18737                     
lbb_13145:
    mov64 r5, 0                                     r5 = 0 as i32 as i64 as u64
    ja lbb_13104                                    if true { pc += -43 }
lbb_13147:
    lddw r1, 0x100025bd0 --> b"\x00\x00\x00\x00\xb8Y\x02\x00\x10\x00\x00\x00\x00\x00\x00\x00\x8e\x06\x00…        r1 load str located at 4295121872
    call function_18908                     
lbb_13150:
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    mov64 r2, 1                                     r2 = 1 as i32 as i64 as u64
    lddw r3, 0x100027a90 --> b"\x00\x00\x00\x00\xb8Y\x02\x00\x10\x00\x00\x00\x00\x00\x00\x001"\x00\x00%\…        r3 load str located at 4295129744
    call function_18489                     
lbb_13155:
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    mov64 r2, 1                                     r2 = 1 as i32 as i64 as u64
    lddw r3, 0x100027a18 --> b"\x00\x00\x00\x00\xb8Y\x02\x00\x10\x00\x00\x00\x00\x00\x00\x00>"\x00\x00%\…        r3 load str located at 4295129624
    call function_18489                     
lbb_13160:
    mov64 r1, 2                                     r1 = 2 as i32 as i64 as u64
    mov64 r2, 2                                     r2 = 2 as i32 as i64 as u64
    lddw r3, 0x100027aa8 --> b"\x00\x00\x00\x00\xb8Y\x02\x00\x10\x00\x00\x00\x00\x00\x00\x001"\x00\x00<\…        r3 load str located at 4295129768
    call function_18489                     
lbb_13165:
    mov64 r1, 2                                     r1 = 2 as i32 as i64 as u64
    mov64 r2, 2                                     r2 = 2 as i32 as i64 as u64
    lddw r3, 0x100027a30 --> b"\x00\x00\x00\x00\xb8Y\x02\x00\x10\x00\x00\x00\x00\x00\x00\x00>"\x00\x00<\…        r3 load str located at 4295129648
    call function_18489                     
lbb_13170:
    mov64 r1, 3                                     r1 = 3 as i32 as i64 as u64
    mov64 r2, 3                                     r2 = 3 as i32 as i64 as u64
    lddw r3, 0x100027ac0 --> b"\x00\x00\x00\x00\xb8Y\x02\x00\x10\x00\x00\x00\x00\x00\x00\x001"\x00\x00S\…        r3 load str located at 4295129792
    call function_18489                     
lbb_13175:
    mov64 r1, 3                                     r1 = 3 as i32 as i64 as u64
    mov64 r2, 3                                     r2 = 3 as i32 as i64 as u64
    lddw r3, 0x100027a48 --> b"\x00\x00\x00\x00\xb8Y\x02\x00\x10\x00\x00\x00\x00\x00\x00\x00>"\x00\x00S\…        r3 load str located at 4295129672
    call function_18489                     
lbb_13180:
    mov64 r1, 4                                     r1 = 4 as i32 as i64 as u64
    mov64 r2, 4                                     r2 = 4 as i32 as i64 as u64
    lddw r3, 0x100027ad8 --> b"\x00\x00\x00\x00\xb8Y\x02\x00\x10\x00\x00\x00\x00\x00\x00\x002"\x00\x00\x…        r3 load str located at 4295129816
    call function_18489                     
lbb_13185:
    mov64 r1, 4                                     r1 = 4 as i32 as i64 as u64
    mov64 r2, 4                                     r2 = 4 as i32 as i64 as u64
    lddw r3, 0x100027a60 --> b"\x00\x00\x00\x00\xb8Y\x02\x00\x10\x00\x00\x00\x00\x00\x00\x00?"\x00\x00\x…        r3 load str located at 4295129696
    call function_18489                     
lbb_13190:
    mov64 r1, 5                                     r1 = 5 as i32 as i64 as u64
    mov64 r2, 5                                     r2 = 5 as i32 as i64 as u64
    lddw r3, 0x100027af0 --> b"\x00\x00\x00\x00\xb8Y\x02\x00\x10\x00\x00\x00\x00\x00\x00\x003"\x00\x00\x…        r3 load str located at 4295129840
    call function_18489                     
lbb_13195:
    mov64 r1, 6                                     r1 = 6 as i32 as i64 as u64
    mov64 r2, 6                                     r2 = 6 as i32 as i64 as u64
    lddw r3, 0x100027b08 --> b"\x00\x00\x00\x00\xb8Y\x02\x00\x10\x00\x00\x00\x00\x00\x00\x003"\x00\x00%\…        r3 load str located at 4295129864
    call function_18489                     
lbb_13200:
    mov64 r1, 18                                    r1 = 18 as i32 as i64 as u64
    mov64 r2, 18                                    r2 = 18 as i32 as i64 as u64
    lddw r3, 0x100025be8 --> b"\x00\x00\x00\x00\xb8Y\x02\x00\x10\x00\x00\x00\x00\x00\x00\x00\x01\x07\x00…        r3 load str located at 4295121896
    call function_18489                     
lbb_13205:
    mov64 r1, 14                                    r1 = 14 as i32 as i64 as u64
    mov64 r2, 14                                    r2 = 14 as i32 as i64 as u64
    lddw r3, 0x100025b40 --> b"\x00\x00\x00\x00\xb8Y\x02\x00\x10\x00\x00\x00\x00\x00\x00\x00\xab\x03\x00…        r3 load str located at 4295121728
    call function_18489                     
    mov64 r4, r1                                    r4 = r1
    mov64 r6, 3                                     r6 = 3 as i32 as i64 as u64
    ldxdw r3, [r2+0x50]                     
    ldxdw r5, [r3+0x0]                      
    ldxdw r1, [r5+0x50]                     
    jlt r1, 32, lbb_14950                           if r1 < (32 as i32 as i64 as u64) { pc += 1734 }
    stxdw [r10-0x838], r3                   
    stxdw [r10-0x748], r2                   
    ldxdw r1, [r2+0x58]                     
    stxdw [r10-0x840], r1                   
    ldxdw r8, [r1+0x0]                      
    ldxdw r1, [r8+0x50]                     
    jlt r1, 32, lbb_14950                           if r1 < (32 as i32 as i64 as u64) { pc += 1727 }
    stxdw [r10-0x670], r4                   
    ldxb r1, [r5+0x77]                      
    stxdw [r10-0x738], r1                   
    ldxb r1, [r5+0x76]                      
    stxdw [r10-0x730], r1                   
    ldxb r1, [r5+0x75]                      
    stxdw [r10-0x728], r1                   
    ldxb r1, [r5+0x74]                      
    stxdw [r10-0x720], r1                   
    ldxb r1, [r5+0x73]                      
    stxdw [r10-0x718], r1                   
    ldxb r1, [r5+0x72]                      
    stxdw [r10-0x710], r1                   
    ldxb r1, [r5+0x71]                      
    stxdw [r10-0x708], r1                   
    ldxb r1, [r5+0x70]                      
    stxdw [r10-0x700], r1                   
    ldxb r1, [r5+0x6f]                      
    stxdw [r10-0x6f8], r1                   
    ldxb r1, [r5+0x6e]                      
    stxdw [r10-0x6f0], r1                   
    ldxb r1, [r5+0x6d]                      
    stxdw [r10-0x6e8], r1                   
    ldxb r1, [r5+0x6c]                      
    stxdw [r10-0x6e0], r1                   
    ldxb r1, [r5+0x6b]                      
    stxdw [r10-0x6d8], r1                   
    ldxb r1, [r5+0x6a]                      
    stxdw [r10-0x6d0], r1                   
    ldxb r1, [r5+0x69]                      
    stxdw [r10-0x6c8], r1                   
    ldxb r1, [r5+0x68]                      
    stxdw [r10-0x6c0], r1                   
    ldxb r1, [r5+0x67]                      
    stxdw [r10-0x6b8], r1                   
    ldxb r1, [r5+0x66]                      
    stxdw [r10-0x6b0], r1                   
    ldxb r1, [r5+0x65]                      
    stxdw [r10-0x6a8], r1                   
    ldxb r1, [r5+0x64]                      
    stxdw [r10-0x6a0], r1                   
    ldxb r1, [r5+0x63]                      
    stxdw [r10-0x698], r1                   
    ldxb r1, [r5+0x5a]                      
    stxdw [r10-0x688], r1                   
    ldxb r1, [r5+0x59]                      
    stxdw [r10-0x690], r1                   
    ldxw r9, [r5+0x5f]                      
    mov64 r1, r9                                    r1 = r9
    rsh64 r1, 24                                    r1 >>= 24   ///  r1 = r1.wrapping_shr(24)
    stxdw [r10-0x678], r1                   
    mov64 r2, r9                                    r2 = r9
    rsh64 r2, 16                                    r2 >>= 16   ///  r2 = r2.wrapping_shr(16)
    mov64 r6, r9                                    r6 = r9
    rsh64 r6, 8                                     r6 >>= 8   ///  r6 = r6.wrapping_shr(8)
    ldxw r7, [r5+0x5b]                      
    mov64 r1, r7                                    r1 = r7
    rsh64 r1, 24                                    r1 >>= 24   ///  r1 = r1.wrapping_shr(24)
    stxdw [r10-0x680], r1                   
    mov64 r4, r7                                    r4 = r7
    rsh64 r4, 16                                    r4 >>= 16   ///  r4 = r4.wrapping_shr(16)
    mov64 r3, r7                                    r3 = r7
    rsh64 r3, 8                                     r3 >>= 8   ///  r3 = r3.wrapping_shr(8)
    mov64 r1, r8                                    r1 = r8
    ldxb r0, [r1+0x77]                      
    stxdw [r10-0x830], r0                   
    ldxb r8, [r1+0x76]                      
    stxdw [r10-0x828], r8                   
    ldxb r8, [r1+0x75]                      
    stxdw [r10-0x820], r8                   
    ldxb r8, [r1+0x74]                      
    stxdw [r10-0x818], r8                   
    ldxb r8, [r1+0x73]                      
    stxdw [r10-0x810], r8                   
    ldxb r8, [r1+0x72]                      
    stxdw [r10-0x808], r8                   
    ldxb r8, [r1+0x71]                      
    stxdw [r10-0x800], r8                   
    ldxb r8, [r1+0x70]                      
    stxdw [r10-0x7f8], r8                   
    ldxb r8, [r1+0x6f]                      
    stxdw [r10-0x7f0], r8                   
    ldxb r8, [r1+0x6e]                      
    stxdw [r10-0x7e8], r8                   
    ldxb r8, [r1+0x6d]                      
    stxdw [r10-0x7e0], r8                   
    ldxb r8, [r1+0x6c]                      
    stxdw [r10-0x7d8], r8                   
    ldxb r8, [r1+0x6b]                      
    stxdw [r10-0x7d0], r8                   
    ldxb r8, [r1+0x6a]                      
    stxdw [r10-0x7c8], r8                   
    ldxb r8, [r1+0x69]                      
    stxdw [r10-0x7c0], r8                   
    ldxb r8, [r1+0x68]                      
    stxdw [r10-0x7b8], r8                   
    ldxb r8, [r1+0x67]                      
    stxdw [r10-0x7b0], r8                   
    ldxb r8, [r1+0x66]                      
    stxdw [r10-0x7a8], r8                   
    ldxb r8, [r1+0x65]                      
    stxdw [r10-0x798], r8                   
    ldxb r8, [r1+0x64]                      
    stxdw [r10-0x7a0], r8                   
    ldxb r8, [r1+0x63]                      
    stxdw [r10-0x750], r8                   
    ldxb r0, [r1+0x5a]                      
    stxdw [r10-0x788], r0                   
    ldxb r0, [r1+0x59]                      
    stxdw [r10-0x790], r0                   
    ldxb r0, [r1+0x58]                      
    stxdw [r10-0x740], r0                   
    ldxw r0, [r1+0x5f]                      
    mov64 r8, r0                                    r8 = r0
    rsh64 r8, 24                                    r8 >>= 24   ///  r8 = r8.wrapping_shr(24)
    stxdw [r10-0x760], r8                   
    mov64 r8, r0                                    r8 = r0
    rsh64 r8, 16                                    r8 >>= 16   ///  r8 = r8.wrapping_shr(16)
    stxdw [r10-0x758], r8                   
    stxdw [r10-0x768], r0                   
    rsh64 r0, 8                                     r0 >>= 8   ///  r0 = r0.wrapping_shr(8)
    stxdw [r10-0x780], r0                   
    stxdw [r10-0x850], r1                   
    ldxw r1, [r1+0x5b]                      
    mov64 r8, r1                                    r8 = r1
    rsh64 r8, 24                                    r8 >>= 24   ///  r8 = r8.wrapping_shr(24)
    mov64 r0, r1                                    r0 = r1
    rsh64 r0, 16                                    r0 >>= 16   ///  r0 = r0.wrapping_shr(16)
    stxdw [r10-0x770], r0                   
    stxdw [r10-0x778], r1                   
    rsh64 r1, 8                                     r1 >>= 8   ///  r1 = r1.wrapping_shr(8)
    mov64 r0, r1                                    r0 = r1
    stxdw [r10-0x848], r5                   
    ldxb r5, [r5+0x58]                      
    jeq r5, 57, lbb_14011                           if r5 == (57 as i32 as i64 as u64) { pc += 653 }
    jeq r5, 67, lbb_13643                           if r5 == (67 as i32 as i64 as u64) { pc += 284 }
    jne r5, 252, lbb_14315                          if r5 != (252 as i32 as i64 as u64) { pc += 955 }
    ldxdw r1, [r10-0x690]                   
    mov64 r5, r1                                    r5 = r1
    jne r5, 209, lbb_14315                          if r5 != (209 as i32 as i64 as u64) { pc += 952 }
    ldxdw r1, [r10-0x688]                   
    mov64 r5, r1                                    r5 = r1
    jne r5, 65, lbb_14315                           if r5 != (65 as i32 as i64 as u64) { pc += 949 }
    and64 r7, 255                                   r7 &= 255   ///  r7 = r7.and(255)
    jne r7, 233, lbb_14315                          if r7 != (233 as i32 as i64 as u64) { pc += 947 }
    and64 r3, 255                                   r3 &= 255   ///  r3 = r3.and(255)
    jne r3, 131, lbb_14315                          if r3 != (131 as i32 as i64 as u64) { pc += 945 }
    and64 r4, 255                                   r4 &= 255   ///  r4 = r4.and(255)
    jne r4, 44, lbb_14315                           if r4 != (44 as i32 as i64 as u64) { pc += 943 }
    ldxdw r1, [r10-0x680]                   
    jne r1, 175, lbb_14315                          if r1 != (175 as i32 as i64 as u64) { pc += 941 }
    and64 r9, 255                                   r9 &= 255   ///  r9 = r9.and(255)
    jne r9, 16, lbb_14315                           if r9 != (16 as i32 as i64 as u64) { pc += 939 }
    and64 r6, 255                                   r6 &= 255   ///  r6 = r6.and(255)
    jne r6, 173, lbb_14315                          if r6 != (173 as i32 as i64 as u64) { pc += 937 }
    and64 r2, 255                                   r2 &= 255   ///  r2 = r2.and(255)
    jne r2, 145, lbb_14315                          if r2 != (145 as i32 as i64 as u64) { pc += 935 }
    ldxdw r1, [r10-0x678]                   
    jne r1, 116, lbb_14315                          if r1 != (116 as i32 as i64 as u64) { pc += 933 }
    ldxdw r1, [r10-0x698]                   
    jne r1, 149, lbb_14315                          if r1 != (149 as i32 as i64 as u64) { pc += 931 }
    ldxdw r1, [r10-0x6a0]                   
    ldxdw r4, [r10-0x670]                   
    mov64 r6, 0                                     r6 = 0 as i32 as i64 as u64
    jne r1, 202, lbb_14950                          if r1 != (202 as i32 as i64 as u64) { pc += 1562 }
    ldxdw r1, [r10-0x6a8]                   
    jne r1, 15, lbb_14950                           if r1 != (15 as i32 as i64 as u64) { pc += 1560 }
    ldxdw r1, [r10-0x6b0]                   
    jne r1, 39, lbb_14950                           if r1 != (39 as i32 as i64 as u64) { pc += 1558 }
    ldxdw r1, [r10-0x6b8]                   
    jne r1, 27, lbb_14950                           if r1 != (27 as i32 as i64 as u64) { pc += 1556 }
    ldxdw r1, [r10-0x6c0]                   
    jne r1, 91, lbb_14950                           if r1 != (91 as i32 as i64 as u64) { pc += 1554 }
    ldxdw r1, [r10-0x6c8]                   
    jne r1, 41, lbb_14950                           if r1 != (41 as i32 as i64 as u64) { pc += 1552 }
    ldxdw r1, [r10-0x6d0]                   
    jne r1, 60, lbb_14950                           if r1 != (60 as i32 as i64 as u64) { pc += 1550 }
    ldxdw r1, [r10-0x6d8]                   
    jne r1, 212, lbb_14950                          if r1 != (212 as i32 as i64 as u64) { pc += 1548 }
    ldxdw r1, [r10-0x6e0]                   
    jne r1, 112, lbb_14950                          if r1 != (112 as i32 as i64 as u64) { pc += 1546 }
    ldxdw r1, [r10-0x6e8]                   
    jne r1, 39, lbb_14950                           if r1 != (39 as i32 as i64 as u64) { pc += 1544 }
    ldxdw r1, [r10-0x6f0]                   
    jne r1, 234, lbb_14950                          if r1 != (234 as i32 as i64 as u64) { pc += 1542 }
    ldxdw r1, [r10-0x6f8]                   
    jne r1, 115, lbb_14950                          if r1 != (115 as i32 as i64 as u64) { pc += 1540 }
    ldxdw r1, [r10-0x700]                   
    jne r1, 112, lbb_14950                          if r1 != (112 as i32 as i64 as u64) { pc += 1538 }
    ldxdw r1, [r10-0x708]                   
    jne r1, 7, lbb_14950                            if r1 != (7 as i32 as i64 as u64) { pc += 1536 }
    ldxdw r1, [r10-0x710]                   
    jne r1, 237, lbb_14950                          if r1 != (237 as i32 as i64 as u64) { pc += 1534 }
    ldxdw r1, [r10-0x718]                   
    jne r1, 64, lbb_14950                           if r1 != (64 as i32 as i64 as u64) { pc += 1532 }
    ldxdw r1, [r10-0x720]                   
    jne r1, 235, lbb_14950                          if r1 != (235 as i32 as i64 as u64) { pc += 1530 }
    ldxdw r1, [r10-0x728]                   
    jne r1, 57, lbb_14950                           if r1 != (57 as i32 as i64 as u64) { pc += 1528 }
    ldxdw r1, [r10-0x730]                   
    jne r1, 160, lbb_14950                          if r1 != (160 as i32 as i64 as u64) { pc += 1526 }
    ldxdw r1, [r10-0x738]                   
    jne r1, 189, lbb_14950                          if r1 != (189 as i32 as i64 as u64) { pc += 1524 }
    ldxdw r1, [r10-0x740]                   
    jeq r1, 57, lbb_14636                           if r1 == (57 as i32 as i64 as u64) { pc += 1208 }
    jne r1, 67, lbb_14950                           if r1 != (67 as i32 as i64 as u64) { pc += 1521 }
    ldxdw r1, [r10-0x790]                   
    jne r1, 119, lbb_14950                          if r1 != (119 as i32 as i64 as u64) { pc += 1519 }
    ldxdw r1, [r10-0x788]                   
    jne r1, 55, lbb_14950                           if r1 != (55 as i32 as i64 as u64) { pc += 1517 }
    ldxdw r1, [r10-0x778]                   
    and64 r1, 255                                   r1 &= 255   ///  r1 = r1.and(255)
    jne r1, 28, lbb_14950                           if r1 != (28 as i32 as i64 as u64) { pc += 1514 }
    and64 r0, 255                                   r0 &= 255   ///  r0 = r0.and(255)
    jne r0, 116, lbb_14950                          if r0 != (116 as i32 as i64 as u64) { pc += 1512 }
    ldxdw r0, [r10-0x770]                   
    and64 r0, 255                                   r0 &= 255   ///  r0 = r0.and(255)
    jne r0, 248, lbb_14950                          if r0 != (248 as i32 as i64 as u64) { pc += 1509 }
    jne r8, 110, lbb_14950                          if r8 != (110 as i32 as i64 as u64) { pc += 1508 }
    ldxdw r1, [r10-0x768]                   
    and64 r1, 255                                   r1 &= 255   ///  r1 = r1.and(255)
    jne r1, 161, lbb_14950                          if r1 != (161 as i32 as i64 as u64) { pc += 1505 }
    ldxdw r1, [r10-0x780]                   
    and64 r1, 255                                   r1 &= 255   ///  r1 = r1.and(255)
    jne r1, 139, lbb_14950                          if r1 != (139 as i32 as i64 as u64) { pc += 1502 }
    ldxdw r1, [r10-0x758]                   
    and64 r1, 255                                   r1 &= 255   ///  r1 = r1.and(255)
    jne r1, 241, lbb_14950                          if r1 != (241 as i32 as i64 as u64) { pc += 1499 }
    ldxdw r1, [r10-0x760]                   
    jne r1, 127, lbb_14950                          if r1 != (127 as i32 as i64 as u64) { pc += 1497 }
    ldxdw r1, [r10-0x750]                   
    jne r1, 177, lbb_14950                          if r1 != (177 as i32 as i64 as u64) { pc += 1495 }
    ldxdw r1, [r10-0x7a0]                   
    jne r1, 96, lbb_14950                           if r1 != (96 as i32 as i64 as u64) { pc += 1493 }
    ldxdw r1, [r10-0x798]                   
    jne r1, 51, lbb_14950                           if r1 != (51 as i32 as i64 as u64) { pc += 1491 }
    ldxdw r1, [r10-0x7a8]                   
    jne r1, 132, lbb_14950                          if r1 != (132 as i32 as i64 as u64) { pc += 1489 }
    ldxdw r1, [r10-0x7b0]                   
    jne r1, 82, lbb_14950                           if r1 != (82 as i32 as i64 as u64) { pc += 1487 }
    ldxdw r1, [r10-0x7b8]                   
    jne r1, 170, lbb_14950                          if r1 != (170 as i32 as i64 as u64) { pc += 1485 }
    ldxdw r1, [r10-0x7c0]                   
    jne r1, 99, lbb_14950                           if r1 != (99 as i32 as i64 as u64) { pc += 1483 }
    ldxdw r1, [r10-0x7c8]                   
    jne r1, 250, lbb_14950                          if r1 != (250 as i32 as i64 as u64) { pc += 1481 }
    ldxdw r1, [r10-0x7d0]                   
    jne r1, 220, lbb_14950                          if r1 != (220 as i32 as i64 as u64) { pc += 1479 }
    ldxdw r1, [r10-0x7d8]                   
    jne r1, 172, lbb_14950                          if r1 != (172 as i32 as i64 as u64) { pc += 1477 }
    ldxdw r1, [r10-0x7e0]                   
    jne r1, 213, lbb_14950                          if r1 != (213 as i32 as i64 as u64) { pc += 1475 }
    ldxdw r1, [r10-0x7e8]                   
    jne r1, 163, lbb_14950                          if r1 != (163 as i32 as i64 as u64) { pc += 1473 }
    ldxdw r1, [r10-0x7f0]                   
    jne r1, 31, lbb_14950                           if r1 != (31 as i32 as i64 as u64) { pc += 1471 }
    ldxdw r1, [r10-0x7f8]                   
    jne r1, 179, lbb_14950                          if r1 != (179 as i32 as i64 as u64) { pc += 1469 }
    ldxdw r1, [r10-0x800]                   
    jne r1, 172, lbb_14950                          if r1 != (172 as i32 as i64 as u64) { pc += 1467 }
    ldxdw r1, [r10-0x808]                   
    jne r1, 245, lbb_14950                          if r1 != (245 as i32 as i64 as u64) { pc += 1465 }
    ldxdw r1, [r10-0x810]                   
    jne r1, 75, lbb_14950                           if r1 != (75 as i32 as i64 as u64) { pc += 1463 }
    ldxdw r1, [r10-0x818]                   
    jne r1, 165, lbb_14950                          if r1 != (165 as i32 as i64 as u64) { pc += 1461 }
    ldxdw r1, [r10-0x820]                   
    jne r1, 46, lbb_14950                           if r1 != (46 as i32 as i64 as u64) { pc += 1459 }
    ldxdw r1, [r10-0x828]                   
    jne r1, 136, lbb_14950                          if r1 != (136 as i32 as i64 as u64) { pc += 1457 }
    ldxdw r1, [r10-0x830]                   
    jne r1, 173, lbb_14950                          if r1 != (173 as i32 as i64 as u64) { pc += 1455 }
    ldxdw r1, [r10-0x748]                   
    ldxdw r1, [r1+0x8]                      
    jeq r1, 1, lbb_14998                            if r1 == (1 as i32 as i64 as u64) { pc += 1500 }
    jeq r1, 0, lbb_15018                            if r1 == (0 as i32 as i64 as u64) { pc += 1519 }
    jle r1, 2, lbb_15038                            if r1 <= (2 as i32 as i64 as u64) { pc += 1538 }
    jeq r1, 3, lbb_15058                            if r1 == (3 as i32 as i64 as u64) { pc += 1557 }
    jle r1, 4, lbb_15078                            if r1 <= (4 as i32 as i64 as u64) { pc += 1576 }
    jeq r1, 5, lbb_15098                            if r1 == (5 as i32 as i64 as u64) { pc += 1595 }
    jle r1, 6, lbb_15118                            if r1 <= (6 as i32 as i64 as u64) { pc += 1614 }
    jeq r1, 7, lbb_15138                            if r1 == (7 as i32 as i64 as u64) { pc += 1633 }
    jle r1, 8, lbb_15158                            if r1 <= (8 as i32 as i64 as u64) { pc += 1652 }
    jeq r1, 9, lbb_15178                            if r1 == (9 as i32 as i64 as u64) { pc += 1671 }
    jle r1, 10, lbb_15198                           if r1 <= (10 as i32 as i64 as u64) { pc += 1690 }
    jeq r1, 11, lbb_15218                           if r1 == (11 as i32 as i64 as u64) { pc += 1709 }
    ldxdw r1, [r10-0x748]                   
    ldxdw r2, [r1+0x0]                      
    ldxdw r3, [r1+0x48]                     
    stxdw [r10-0x6b8], r3                   
    ldxdw r4, [r1+0x40]                     
    stxdw [r10-0x680], r4                   
    ldxdw r4, [r1+0x28]                     
    stxdw [r10-0x678], r4                   
    ldxdw r5, [r1+0x20]                     
    stxdw [r10-0x6d8], r5                   
    mov64 r4, r2                                    r4 = r2
    add64 r4, 8                                     r4 += 8   ///  r4 = r4.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x688], r4                   
    mov64 r4, r2                                    r4 = r2
    add64 r4, 16                                    r4 += 16   ///  r4 = r4.wrapping_add(16 as i32 as i64 as u64)
    stxdw [r10-0x690], r4                   
    mov64 r4, r2                                    r4 = r2
    add64 r4, 24                                    r4 += 24   ///  r4 = r4.wrapping_add(24 as i32 as i64 as u64)
    stxdw [r10-0x698], r4                   
    mov64 r4, r2                                    r4 = r2
    add64 r4, 32                                    r4 += 32   ///  r4 = r4.wrapping_add(32 as i32 as i64 as u64)
    stxdw [r10-0x6a0], r4                   
    mov64 r4, r2                                    r4 = r2
    add64 r4, 40                                    r4 += 40   ///  r4 = r4.wrapping_add(40 as i32 as i64 as u64)
    stxdw [r10-0x6a8], r4                   
    mov64 r4, r2                                    r4 = r2
    add64 r4, 48                                    r4 += 48   ///  r4 = r4.wrapping_add(48 as i32 as i64 as u64)
    stxdw [r10-0x6b0], r4                   
    mov64 r4, r2                                    r4 = r2
    add64 r4, 56                                    r4 += 56   ///  r4 = r4.wrapping_add(56 as i32 as i64 as u64)
    stxdw [r10-0x6c0], r4                   
    mov64 r4, r2                                    r4 = r2
    add64 r4, 64                                    r4 += 64   ///  r4 = r4.wrapping_add(64 as i32 as i64 as u64)
    stxdw [r10-0x6c8], r4                   
    mov64 r4, r2                                    r4 = r2
    add64 r4, 72                                    r4 += 72   ///  r4 = r4.wrapping_add(72 as i32 as i64 as u64)
    stxdw [r10-0x6d0], r4                   
    ldxdw r1, [r1+0x10]                     
    stxdw [r10-0x6e0], r1                   
    ldxdw r0, [r10-0x850]                   
    add64 r0, 8                                     r0 += 8   ///  r0 = r0.wrapping_add(8 as i32 as i64 as u64)
    ldxdw r1, [r5+0x0]                      
    stxdw [r10-0x718], r1                   
    ldxdw r1, [r3+0x0]                      
    stxdw [r10-0x6e8], r1                   
    ldxdw r1, [r2+0x0]                      
    stxdw [r10-0x6f0], r1                   
    ldxdw r1, [r2+0x8]                      
    stxdw [r10-0x6f8], r1                   
    ldxdw r1, [r2+0x10]                     
    stxdw [r10-0x700], r1                   
    ldxdw r1, [r2+0x18]                     
    stxdw [r10-0x708], r1                   
    ldxdw r1, [r2+0x20]                     
    stxdw [r10-0x710], r1                   
    ldxdw r1, [r2+0x28]                     
    stxdw [r10-0x720], r1                   
    ldxdw r9, [r2+0x30]                     
    ldxdw r8, [r2+0x38]                     
    ldxdw r7, [r2+0x40]                     
    ldxdw r6, [r2+0x48]                     
    ldxdw r1, [r10-0x678]                   
    ldxdw r5, [r1+0x0]                      
    ldxdw r4, [r2+0x50]                     
    ldxdw r1, [r10-0x680]                   
    ldxdw r3, [r1+0x0]                      
    ldxdw r1, [r2+0x58]                     
    stxdw [r10-0x5d8], r0                   
    ldxdw r0, [r10-0x848]                   
    add64 r0, 8                                     r0 += 8   ///  r0 = r0.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x5e8], r0                   
    add64 r1, 8                                     r1 += 8   ///  r1 = r1.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x568], r1                   
    add64 r3, 8                                     r3 += 8   ///  r3 = r3.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x578], r3                   
    add64 r4, 8                                     r4 += 8   ///  r4 = r4.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x588], r4                   
    add64 r5, 8                                     r5 += 8   ///  r5 = r5.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x598], r5                   
    add64 r6, 8                                     r6 += 8   ///  r6 = r6.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x5a8], r6                   
    add64 r7, 8                                     r7 += 8   ///  r7 = r7.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x5b8], r7                   
    ldxdw r7, [r10-0x718]                   
    add64 r8, 8                                     r8 += 8   ///  r8 = r8.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x5c8], r8                   
    add64 r9, 8                                     r9 += 8   ///  r9 = r9.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x5f8], r9                   
    ldxdw r1, [r10-0x720]                   
    add64 r1, 8                                     r1 += 8   ///  r1 = r1.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x608], r1                   
    ldxdw r1, [r10-0x710]                   
    add64 r1, 8                                     r1 += 8   ///  r1 = r1.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x618], r1                   
    ldxdw r1, [r10-0x708]                   
    add64 r1, 8                                     r1 += 8   ///  r1 = r1.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x628], r1                   
    ldxdw r1, [r10-0x700]                   
    add64 r1, 8                                     r1 += 8   ///  r1 = r1.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x638], r1                   
    ldxdw r1, [r10-0x6f8]                   
    add64 r1, 8                                     r1 += 8   ///  r1 = r1.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x648], r1                   
    ldxdw r1, [r10-0x6f0]                   
    add64 r1, 8                                     r1 += 8   ///  r1 = r1.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x658], r1                   
    ldxdw r1, [r10-0x6e8]                   
    add64 r1, 8                                     r1 += 8   ///  r1 = r1.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x668], r1                   
    add64 r7, 8                                     r7 += 8   ///  r7 = r7.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x558], r7                   
    sth [r10-0x550], 0                      
    sth [r10-0x560], 0                      
    sth [r10-0x570], 0                      
    sth [r10-0x580], 0                      
    sth [r10-0x590], 0                      
    sth [r10-0x5a0], 0                      
    sth [r10-0x5b0], 1                      
    sth [r10-0x5c0], 0                      
    sth [r10-0x5d0], 1                      
    sth [r10-0x5e0], 1                      
    sth [r10-0x5f0], 0                      
    sth [r10-0x600], 1                      
    sth [r10-0x610], 1                      
    sth [r10-0x620], 0                      
    sth [r10-0x630], 0                      
    sth [r10-0x640], 0                      
    sth [r10-0x650], 1                      
    sth [r10-0x660], 257                    
    ldxdw r1, [r10-0x6e0]                   
    stxdw [r10-0x530], r1                   
    lddw r1, 0xeed605d346d7ebc4                     r1 load str located at -1236794642681828412
    ja lbb_13925                                    if true { pc += 282 }
lbb_13643:
    ldxdw r1, [r10-0x690]                   
    mov64 r5, r1                                    r5 = r1
    jne r5, 119, lbb_14315                          if r5 != (119 as i32 as i64 as u64) { pc += 669 }
    ldxdw r1, [r10-0x688]                   
    mov64 r5, r1                                    r5 = r1
    jne r5, 55, lbb_14315                           if r5 != (55 as i32 as i64 as u64) { pc += 666 }
    and64 r7, 255                                   r7 &= 255   ///  r7 = r7.and(255)
    jne r7, 28, lbb_14315                           if r7 != (28 as i32 as i64 as u64) { pc += 664 }
    and64 r3, 255                                   r3 &= 255   ///  r3 = r3.and(255)
    jne r3, 116, lbb_14315                          if r3 != (116 as i32 as i64 as u64) { pc += 662 }
    and64 r4, 255                                   r4 &= 255   ///  r4 = r4.and(255)
    jne r4, 248, lbb_14315                          if r4 != (248 as i32 as i64 as u64) { pc += 660 }
    ldxdw r1, [r10-0x680]                   
    jne r1, 110, lbb_14315                          if r1 != (110 as i32 as i64 as u64) { pc += 658 }
    and64 r9, 255                                   r9 &= 255   ///  r9 = r9.and(255)
    jne r9, 161, lbb_14315                          if r9 != (161 as i32 as i64 as u64) { pc += 656 }
    and64 r6, 255                                   r6 &= 255   ///  r6 = r6.and(255)
    jne r6, 139, lbb_14315                          if r6 != (139 as i32 as i64 as u64) { pc += 654 }
    and64 r2, 255                                   r2 &= 255   ///  r2 = r2.and(255)
    jne r2, 241, lbb_14315                          if r2 != (241 as i32 as i64 as u64) { pc += 652 }
    ldxdw r1, [r10-0x678]                   
    jne r1, 127, lbb_14315                          if r1 != (127 as i32 as i64 as u64) { pc += 650 }
    ldxdw r1, [r10-0x698]                   
    jne r1, 177, lbb_14315                          if r1 != (177 as i32 as i64 as u64) { pc += 648 }
    ldxdw r1, [r10-0x6a0]                   
    ldxdw r4, [r10-0x670]                   
    mov64 r6, 0                                     r6 = 0 as i32 as i64 as u64
    jne r1, 96, lbb_14950                           if r1 != (96 as i32 as i64 as u64) { pc += 1279 }
    ldxdw r1, [r10-0x6a8]                   
    jne r1, 51, lbb_14950                           if r1 != (51 as i32 as i64 as u64) { pc += 1277 }
    ldxdw r1, [r10-0x6b0]                   
    jne r1, 132, lbb_14950                          if r1 != (132 as i32 as i64 as u64) { pc += 1275 }
    ldxdw r1, [r10-0x6b8]                   
    jne r1, 82, lbb_14950                           if r1 != (82 as i32 as i64 as u64) { pc += 1273 }
    ldxdw r1, [r10-0x6c0]                   
    jne r1, 170, lbb_14950                          if r1 != (170 as i32 as i64 as u64) { pc += 1271 }
    ldxdw r1, [r10-0x6c8]                   
    jne r1, 99, lbb_14950                           if r1 != (99 as i32 as i64 as u64) { pc += 1269 }
    ldxdw r1, [r10-0x6d0]                   
    jne r1, 250, lbb_14950                          if r1 != (250 as i32 as i64 as u64) { pc += 1267 }
    ldxdw r1, [r10-0x6d8]                   
    jne r1, 220, lbb_14950                          if r1 != (220 as i32 as i64 as u64) { pc += 1265 }
    ldxdw r1, [r10-0x6e0]                   
    jne r1, 172, lbb_14950                          if r1 != (172 as i32 as i64 as u64) { pc += 1263 }
    ldxdw r1, [r10-0x6e8]                   
    jne r1, 213, lbb_14950                          if r1 != (213 as i32 as i64 as u64) { pc += 1261 }
    ldxdw r1, [r10-0x6f0]                   
    jne r1, 163, lbb_14950                          if r1 != (163 as i32 as i64 as u64) { pc += 1259 }
    ldxdw r1, [r10-0x6f8]                   
    jne r1, 31, lbb_14950                           if r1 != (31 as i32 as i64 as u64) { pc += 1257 }
    ldxdw r1, [r10-0x700]                   
    jne r1, 179, lbb_14950                          if r1 != (179 as i32 as i64 as u64) { pc += 1255 }
    ldxdw r1, [r10-0x708]                   
    jne r1, 172, lbb_14950                          if r1 != (172 as i32 as i64 as u64) { pc += 1253 }
    ldxdw r1, [r10-0x710]                   
    jne r1, 245, lbb_14950                          if r1 != (245 as i32 as i64 as u64) { pc += 1251 }
    ldxdw r1, [r10-0x718]                   
    jne r1, 75, lbb_14950                           if r1 != (75 as i32 as i64 as u64) { pc += 1249 }
    ldxdw r1, [r10-0x720]                   
    jne r1, 165, lbb_14950                          if r1 != (165 as i32 as i64 as u64) { pc += 1247 }
    ldxdw r1, [r10-0x728]                   
    jne r1, 46, lbb_14950                           if r1 != (46 as i32 as i64 as u64) { pc += 1245 }
    ldxdw r1, [r10-0x730]                   
    jne r1, 136, lbb_14950                          if r1 != (136 as i32 as i64 as u64) { pc += 1243 }
    ldxdw r1, [r10-0x738]                   
    jne r1, 173, lbb_14950                          if r1 != (173 as i32 as i64 as u64) { pc += 1241 }
    ldxdw r1, [r10-0x740]                   
    jeq r1, 57, lbb_14318                           if r1 == (57 as i32 as i64 as u64) { pc += 607 }
    jne r1, 252, lbb_14950                          if r1 != (252 as i32 as i64 as u64) { pc += 1238 }
    ldxdw r1, [r10-0x790]                   
    jne r1, 209, lbb_14950                          if r1 != (209 as i32 as i64 as u64) { pc += 1236 }
    ldxdw r1, [r10-0x788]                   
    jne r1, 65, lbb_14950                           if r1 != (65 as i32 as i64 as u64) { pc += 1234 }
    ldxdw r1, [r10-0x778]                   
    and64 r1, 255                                   r1 &= 255   ///  r1 = r1.and(255)
    jne r1, 233, lbb_14950                          if r1 != (233 as i32 as i64 as u64) { pc += 1231 }
    and64 r0, 255                                   r0 &= 255   ///  r0 = r0.and(255)
    jne r0, 131, lbb_14950                          if r0 != (131 as i32 as i64 as u64) { pc += 1229 }
    ldxdw r0, [r10-0x770]                   
    and64 r0, 255                                   r0 &= 255   ///  r0 = r0.and(255)
    jne r0, 44, lbb_14950                           if r0 != (44 as i32 as i64 as u64) { pc += 1226 }
    jne r8, 175, lbb_14950                          if r8 != (175 as i32 as i64 as u64) { pc += 1225 }
    ldxdw r1, [r10-0x768]                   
    and64 r1, 255                                   r1 &= 255   ///  r1 = r1.and(255)
    jne r1, 16, lbb_14950                           if r1 != (16 as i32 as i64 as u64) { pc += 1222 }
    ldxdw r1, [r10-0x780]                   
    and64 r1, 255                                   r1 &= 255   ///  r1 = r1.and(255)
    jne r1, 173, lbb_14950                          if r1 != (173 as i32 as i64 as u64) { pc += 1219 }
    ldxdw r1, [r10-0x758]                   
    and64 r1, 255                                   r1 &= 255   ///  r1 = r1.and(255)
    jne r1, 145, lbb_14950                          if r1 != (145 as i32 as i64 as u64) { pc += 1216 }
    ldxdw r1, [r10-0x760]                   
    jne r1, 116, lbb_14950                          if r1 != (116 as i32 as i64 as u64) { pc += 1214 }
    ldxdw r1, [r10-0x750]                   
    jne r1, 149, lbb_14950                          if r1 != (149 as i32 as i64 as u64) { pc += 1212 }
    ldxdw r1, [r10-0x7a0]                   
    jne r1, 202, lbb_14950                          if r1 != (202 as i32 as i64 as u64) { pc += 1210 }
    ldxdw r1, [r10-0x798]                   
    jne r1, 15, lbb_14950                           if r1 != (15 as i32 as i64 as u64) { pc += 1208 }
    ldxdw r1, [r10-0x7a8]                   
    jne r1, 39, lbb_14950                           if r1 != (39 as i32 as i64 as u64) { pc += 1206 }
    ldxdw r1, [r10-0x7b0]                   
    jne r1, 27, lbb_14950                           if r1 != (27 as i32 as i64 as u64) { pc += 1204 }
    ldxdw r1, [r10-0x7b8]                   
    jne r1, 91, lbb_14950                           if r1 != (91 as i32 as i64 as u64) { pc += 1202 }
    ldxdw r1, [r10-0x7c0]                   
    jne r1, 41, lbb_14950                           if r1 != (41 as i32 as i64 as u64) { pc += 1200 }
    ldxdw r1, [r10-0x7c8]                   
    jne r1, 60, lbb_14950                           if r1 != (60 as i32 as i64 as u64) { pc += 1198 }
    ldxdw r1, [r10-0x7d0]                   
    jne r1, 212, lbb_14950                          if r1 != (212 as i32 as i64 as u64) { pc += 1196 }
    ldxdw r1, [r10-0x7d8]                   
    jne r1, 112, lbb_14950                          if r1 != (112 as i32 as i64 as u64) { pc += 1194 }
    ldxdw r1, [r10-0x7e0]                   
    jne r1, 39, lbb_14950                           if r1 != (39 as i32 as i64 as u64) { pc += 1192 }
    ldxdw r1, [r10-0x7e8]                   
    jne r1, 234, lbb_14950                          if r1 != (234 as i32 as i64 as u64) { pc += 1190 }
    ldxdw r1, [r10-0x7f0]                   
    jne r1, 115, lbb_14950                          if r1 != (115 as i32 as i64 as u64) { pc += 1188 }
    ldxdw r1, [r10-0x7f8]                   
    jne r1, 112, lbb_14950                          if r1 != (112 as i32 as i64 as u64) { pc += 1186 }
    ldxdw r1, [r10-0x800]                   
    jne r1, 7, lbb_14950                            if r1 != (7 as i32 as i64 as u64) { pc += 1184 }
    ldxdw r1, [r10-0x808]                   
    jne r1, 237, lbb_14950                          if r1 != (237 as i32 as i64 as u64) { pc += 1182 }
    ldxdw r1, [r10-0x810]                   
    jne r1, 64, lbb_14950                           if r1 != (64 as i32 as i64 as u64) { pc += 1180 }
    ldxdw r1, [r10-0x818]                   
    jne r1, 235, lbb_14950                          if r1 != (235 as i32 as i64 as u64) { pc += 1178 }
    ldxdw r1, [r10-0x820]                   
    jne r1, 57, lbb_14950                           if r1 != (57 as i32 as i64 as u64) { pc += 1176 }
    ldxdw r1, [r10-0x828]                   
    jne r1, 160, lbb_14950                          if r1 != (160 as i32 as i64 as u64) { pc += 1174 }
    ldxdw r1, [r10-0x830]                   
    jne r1, 189, lbb_14950                          if r1 != (189 as i32 as i64 as u64) { pc += 1172 }
    ldxdw r1, [r10-0x748]                   
    ldxdw r1, [r1+0x8]                      
    jeq r1, 1, lbb_15003                            if r1 == (1 as i32 as i64 as u64) { pc += 1222 }
    jeq r1, 0, lbb_15023                            if r1 == (0 as i32 as i64 as u64) { pc += 1241 }
    jle r1, 2, lbb_15043                            if r1 <= (2 as i32 as i64 as u64) { pc += 1260 }
    jeq r1, 3, lbb_15063                            if r1 == (3 as i32 as i64 as u64) { pc += 1279 }
    jle r1, 4, lbb_15083                            if r1 <= (4 as i32 as i64 as u64) { pc += 1298 }
    jeq r1, 5, lbb_15103                            if r1 == (5 as i32 as i64 as u64) { pc += 1317 }
    jle r1, 6, lbb_15123                            if r1 <= (6 as i32 as i64 as u64) { pc += 1336 }
    jeq r1, 7, lbb_15143                            if r1 == (7 as i32 as i64 as u64) { pc += 1355 }
    jle r1, 8, lbb_15163                            if r1 <= (8 as i32 as i64 as u64) { pc += 1374 }
    jeq r1, 9, lbb_15183                            if r1 == (9 as i32 as i64 as u64) { pc += 1393 }
    jle r1, 10, lbb_15203                           if r1 <= (10 as i32 as i64 as u64) { pc += 1412 }
    jeq r1, 11, lbb_15223                           if r1 == (11 as i32 as i64 as u64) { pc += 1431 }
    ldxdw r1, [r10-0x748]                   
    ldxdw r2, [r1+0x0]                      
    ldxdw r3, [r1+0x48]                     
    stxdw [r10-0x6b8], r3                   
    ldxdw r4, [r1+0x40]                     
    stxdw [r10-0x680], r4                   
    ldxdw r4, [r1+0x28]                     
    stxdw [r10-0x678], r4                   
    ldxdw r5, [r1+0x20]                     
    stxdw [r10-0x6d8], r5                   
    mov64 r4, r2                                    r4 = r2
    add64 r4, 8                                     r4 += 8   ///  r4 = r4.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x688], r4                   
    mov64 r4, r2                                    r4 = r2
    add64 r4, 16                                    r4 += 16   ///  r4 = r4.wrapping_add(16 as i32 as i64 as u64)
    stxdw [r10-0x690], r4                   
    mov64 r4, r2                                    r4 = r2
    add64 r4, 24                                    r4 += 24   ///  r4 = r4.wrapping_add(24 as i32 as i64 as u64)
    stxdw [r10-0x698], r4                   
    mov64 r4, r2                                    r4 = r2
    add64 r4, 32                                    r4 += 32   ///  r4 = r4.wrapping_add(32 as i32 as i64 as u64)
    stxdw [r10-0x6a0], r4                   
    mov64 r4, r2                                    r4 = r2
    add64 r4, 40                                    r4 += 40   ///  r4 = r4.wrapping_add(40 as i32 as i64 as u64)
    stxdw [r10-0x6a8], r4                   
    mov64 r4, r2                                    r4 = r2
    add64 r4, 48                                    r4 += 48   ///  r4 = r4.wrapping_add(48 as i32 as i64 as u64)
    stxdw [r10-0x6b0], r4                   
    mov64 r4, r2                                    r4 = r2
    add64 r4, 56                                    r4 += 56   ///  r4 = r4.wrapping_add(56 as i32 as i64 as u64)
    stxdw [r10-0x6c0], r4                   
    mov64 r4, r2                                    r4 = r2
    add64 r4, 64                                    r4 += 64   ///  r4 = r4.wrapping_add(64 as i32 as i64 as u64)
    stxdw [r10-0x6c8], r4                   
    mov64 r4, r2                                    r4 = r2
    add64 r4, 72                                    r4 += 72   ///  r4 = r4.wrapping_add(72 as i32 as i64 as u64)
    stxdw [r10-0x6d0], r4                   
    ldxdw r1, [r1+0x10]                     
    stxdw [r10-0x6e0], r1                   
    ldxdw r0, [r10-0x850]                   
    add64 r0, 8                                     r0 += 8   ///  r0 = r0.wrapping_add(8 as i32 as i64 as u64)
    ldxdw r1, [r5+0x0]                      
    stxdw [r10-0x718], r1                   
    ldxdw r1, [r3+0x0]                      
    stxdw [r10-0x6e8], r1                   
    ldxdw r1, [r2+0x0]                      
    stxdw [r10-0x6f0], r1                   
    ldxdw r1, [r2+0x8]                      
    stxdw [r10-0x6f8], r1                   
    ldxdw r1, [r2+0x10]                     
    stxdw [r10-0x700], r1                   
    ldxdw r1, [r2+0x18]                     
    stxdw [r10-0x708], r1                   
    ldxdw r1, [r2+0x20]                     
    stxdw [r10-0x710], r1                   
    ldxdw r1, [r2+0x28]                     
    stxdw [r10-0x720], r1                   
    ldxdw r9, [r2+0x30]                     
    ldxdw r8, [r2+0x38]                     
    ldxdw r7, [r2+0x40]                     
    ldxdw r6, [r2+0x48]                     
    ldxdw r1, [r10-0x678]                   
    ldxdw r5, [r1+0x0]                      
    ldxdw r4, [r2+0x50]                     
    ldxdw r1, [r10-0x680]                   
    ldxdw r3, [r1+0x0]                      
    ldxdw r1, [r2+0x58]                     
    stxdw [r10-0x5d8], r0                   
    ldxdw r0, [r10-0x848]                   
    add64 r0, 8                                     r0 += 8   ///  r0 = r0.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x5e8], r0                   
    add64 r1, 8                                     r1 += 8   ///  r1 = r1.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x568], r1                   
    add64 r3, 8                                     r3 += 8   ///  r3 = r3.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x578], r3                   
    add64 r4, 8                                     r4 += 8   ///  r4 = r4.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x588], r4                   
    add64 r5, 8                                     r5 += 8   ///  r5 = r5.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x598], r5                   
    add64 r6, 8                                     r6 += 8   ///  r6 = r6.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x5a8], r6                   
    add64 r7, 8                                     r7 += 8   ///  r7 = r7.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x5b8], r7                   
    ldxdw r7, [r10-0x718]                   
    add64 r8, 8                                     r8 += 8   ///  r8 = r8.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x5c8], r8                   
    add64 r9, 8                                     r9 += 8   ///  r9 = r9.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x5f8], r9                   
    ldxdw r1, [r10-0x720]                   
    add64 r1, 8                                     r1 += 8   ///  r1 = r1.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x608], r1                   
    ldxdw r1, [r10-0x710]                   
    add64 r1, 8                                     r1 += 8   ///  r1 = r1.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x618], r1                   
    ldxdw r1, [r10-0x708]                   
    add64 r1, 8                                     r1 += 8   ///  r1 = r1.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x628], r1                   
    ldxdw r1, [r10-0x700]                   
    add64 r1, 8                                     r1 += 8   ///  r1 = r1.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x638], r1                   
    ldxdw r1, [r10-0x6f8]                   
    add64 r1, 8                                     r1 += 8   ///  r1 = r1.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x648], r1                   
    ldxdw r1, [r10-0x6f0]                   
    add64 r1, 8                                     r1 += 8   ///  r1 = r1.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x658], r1                   
    ldxdw r1, [r10-0x6e8]                   
    add64 r1, 8                                     r1 += 8   ///  r1 = r1.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x668], r1                   
    add64 r7, 8                                     r7 += 8   ///  r7 = r7.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x558], r7                   
    sth [r10-0x550], 0                      
    sth [r10-0x560], 0                      
    sth [r10-0x570], 0                      
    sth [r10-0x580], 0                      
    sth [r10-0x590], 0                      
    sth [r10-0x5a0], 0                      
    sth [r10-0x5b0], 0                      
    sth [r10-0x5c0], 1                      
    sth [r10-0x5d0], 1                      
    sth [r10-0x5e0], 1                      
    sth [r10-0x5f0], 0                      
    sth [r10-0x600], 1                      
    sth [r10-0x610], 1                      
    sth [r10-0x620], 0                      
    sth [r10-0x630], 0                      
    sth [r10-0x640], 0                      
    sth [r10-0x650], 1                      
    sth [r10-0x660], 257                    
    ldxdw r1, [r10-0x6e0]                   
    stxdw [r10-0x530], r1                   
    lddw r1, 0xe9a082aa61062e45                     r1 load str located at -1612144998314791355
lbb_13925:
    stxdw [r10-0x538], r1                   
    stb [r10-0x528], 0                      
    ldxdw r1, [r10-0x6d8]                   
    stxdw [r10-0x498], r1                   
    mov64 r1, r2                                    r1 = r2
    add64 r1, 88                                    r1 += 88   ///  r1 = r1.wrapping_add(88 as i32 as i64 as u64)
    stxdw [r10-0x4a0], r1                   
    ldxdw r1, [r10-0x680]                   
    stxdw [r10-0x4a8], r1                   
    mov64 r1, r2                                    r1 = r2
    add64 r1, 80                                    r1 += 80   ///  r1 = r1.wrapping_add(80 as i32 as i64 as u64)
    stxdw [r10-0x4b0], r1                   
    ldxdw r1, [r10-0x678]                   
    stxdw [r10-0x4b8], r1                   
    ldxdw r1, [r10-0x6d0]                   
    stxdw [r10-0x4c0], r1                   
    ldxdw r1, [r10-0x6c8]                   
    stxdw [r10-0x4c8], r1                   
    ldxdw r1, [r10-0x6c0]                   
    stxdw [r10-0x4d0], r1                   
    ldxdw r1, [r10-0x840]                   
    stxdw [r10-0x4d8], r1                   
    ldxdw r1, [r10-0x838]                   
    stxdw [r10-0x4e0], r1                   
    ldxdw r1, [r10-0x6b0]                   
    stxdw [r10-0x4e8], r1                   
    ldxdw r1, [r10-0x6a8]                   
    stxdw [r10-0x4f0], r1                   
    ldxdw r1, [r10-0x6a0]                   
    stxdw [r10-0x4f8], r1                   
    ldxdw r1, [r10-0x698]                   
    stxdw [r10-0x500], r1                   
    ldxdw r1, [r10-0x690]                   
    stxdw [r10-0x508], r1                   
    ldxdw r1, [r10-0x688]                   
    stxdw [r10-0x510], r1                   
    stxdw [r10-0x518], r2                   
    ldxdw r1, [r10-0x6b8]                   
    stxdw [r10-0x520], r1                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -152                                  r1 += -152   ///  r1 = r1.wrapping_add(-152 as i32 as i64 as u64)
    stxdw [r10-0x20], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -1160                                 r1 += -1160   ///  r1 = r1.wrapping_add(-1160 as i32 as i64 as u64)
    stxdw [r10-0x28], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -1352                                 r1 += -1352   ///  r1 = r1.wrapping_add(-1352 as i32 as i64 as u64)
    stxdw [r10-0x48], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -1640                                 r1 += -1640   ///  r1 = r1.wrapping_add(-1640 as i32 as i64 as u64)
    stxdw [r10-0x50], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -1168                                 r1 += -1168   ///  r1 = r1.wrapping_add(-1168 as i32 as i64 as u64)
    stxdw [r10-0x58], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -1312                                 r1 += -1312   ///  r1 = r1.wrapping_add(-1312 as i32 as i64 as u64)
    stxdw [r10-0x60], r1                    
    stdw [r10-0x8], 18                      
    stdw [r10-0x10], 18                     
    stdw [r10-0x18], 0                      
    stdw [r10-0x30], 18                     
    stdw [r10-0x38], 18                     
    stdw [r10-0x40], 0                      
    mov64 r1, r10                                   r1 = r10
    add64 r1, -96                                   r1 += -96   ///  r1 = r1.wrapping_add(-96 as i32 as i64 as u64)
    call function_0                         
    mov64 r6, r0                                    r6 = r0
    mov64 r1, r6                                    r1 = r6
    lsh64 r1, 32                                    r1 <<= 32   ///  r1 = r1.wrapping_shl(32)
    rsh64 r1, 32                                    r1 >>= 32   ///  r1 = r1.wrapping_shr(32)
    jne r1, 26, lbb_14949                           if r1 != (26 as i32 as i64 as u64) { pc += 953 }
    mov64 r1, r10                                   r1 = r10
    add64 r1, -1336                                 r1 += -1336   ///  r1 = r1.wrapping_add(-1336 as i32 as i64 as u64)
    stxdw [r10-0x48], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -1640                                 r1 += -1640   ///  r1 = r1.wrapping_add(-1640 as i32 as i64 as u64)
    stxdw [r10-0x58], r1                    
    stxdw [r10-0x60], r7                    
    stdw [r10-0x40], 17                     
    stdw [r10-0x50], 18                     
    mov64 r1, r10                                   r1 = r10
    add64 r1, -96                                   r1 += -96   ///  r1 = r1.wrapping_add(-96 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -1160                                 r2 += -1160   ///  r2 = r2.wrapping_add(-1160 as i32 as i64 as u64)
    mov64 r3, 18                                    r3 = 18 as i32 as i64 as u64
    ja lbb_14946                                    if true { pc += 935 }
lbb_14011:
    ldxdw r1, [r10-0x690]                   
    mov64 r5, r1                                    r5 = r1
    jne r5, 131, lbb_14315                          if r5 != (131 as i32 as i64 as u64) { pc += 301 }
    ldxdw r1, [r10-0x688]                   
    mov64 r5, r1                                    r5 = r1
    jne r5, 77, lbb_14315                           if r5 != (77 as i32 as i64 as u64) { pc += 298 }
    and64 r7, 255                                   r7 &= 255   ///  r7 = r7.and(255)
    jne r7, 239, lbb_14315                          if r7 != (239 as i32 as i64 as u64) { pc += 296 }
    and64 r3, 255                                   r3 &= 255   ///  r3 = r3.and(255)
    jne r3, 157, lbb_14315                          if r3 != (157 as i32 as i64 as u64) { pc += 294 }
    and64 r4, 255                                   r4 &= 255   ///  r4 = r4.and(255)
    jne r4, 208, lbb_14315                          if r4 != (208 as i32 as i64 as u64) { pc += 292 }
    ldxdw r1, [r10-0x680]                   
    jne r1, 131, lbb_14315                          if r1 != (131 as i32 as i64 as u64) { pc += 290 }
    and64 r9, 255                                   r9 &= 255   ///  r9 = r9.and(255)
    jne r9, 246, lbb_14315                          if r9 != (246 as i32 as i64 as u64) { pc += 288 }
    and64 r6, 255                                   r6 &= 255   ///  r6 = r6.and(255)
    jne r6, 140, lbb_14315                          if r6 != (140 as i32 as i64 as u64) { pc += 286 }
    and64 r2, 255                                   r2 &= 255   ///  r2 = r2.and(255)
    jne r2, 63, lbb_14315                           if r2 != (63 as i32 as i64 as u64) { pc += 284 }
    ldxdw r1, [r10-0x678]                   
    jne r1, 218, lbb_14315                          if r1 != (218 as i32 as i64 as u64) { pc += 282 }
    ldxdw r1, [r10-0x698]                   
    jne r1, 76, lbb_14315                           if r1 != (76 as i32 as i64 as u64) { pc += 280 }
    ldxdw r1, [r10-0x6a0]                   
    ldxdw r4, [r10-0x670]                   
    mov64 r6, 0                                     r6 = 0 as i32 as i64 as u64
    jne r1, 237, lbb_14950                          if r1 != (237 as i32 as i64 as u64) { pc += 911 }
    ldxdw r1, [r10-0x6a8]                   
    jne r1, 164, lbb_14950                          if r1 != (164 as i32 as i64 as u64) { pc += 909 }
    ldxdw r1, [r10-0x6b0]                   
    jne r1, 0, lbb_14950                            if r1 != (0 as i32 as i64 as u64) { pc += 907 }
    ldxdw r1, [r10-0x6b8]                   
    jne r1, 43, lbb_14950                           if r1 != (43 as i32 as i64 as u64) { pc += 905 }
    ldxdw r1, [r10-0x6c0]                   
    jne r1, 111, lbb_14950                          if r1 != (111 as i32 as i64 as u64) { pc += 903 }
    ldxdw r1, [r10-0x6c8]                   
    jne r1, 50, lbb_14950                           if r1 != (50 as i32 as i64 as u64) { pc += 901 }
    ldxdw r1, [r10-0x6d0]                   
    jne r1, 88, lbb_14950                           if r1 != (88 as i32 as i64 as u64) { pc += 899 }
    ldxdw r1, [r10-0x6d8]                   
    jne r1, 172, lbb_14950                          if r1 != (172 as i32 as i64 as u64) { pc += 897 }
    ldxdw r1, [r10-0x6e0]                   
    jne r1, 215, lbb_14950                          if r1 != (215 as i32 as i64 as u64) { pc += 895 }
    ldxdw r1, [r10-0x6e8]                   
    jne r1, 74, lbb_14950                           if r1 != (74 as i32 as i64 as u64) { pc += 893 }
    ldxdw r1, [r10-0x6f0]                   
    jne r1, 147, lbb_14950                          if r1 != (147 as i32 as i64 as u64) { pc += 891 }
    ldxdw r1, [r10-0x6f8]                   
    jne r1, 226, lbb_14950                          if r1 != (226 as i32 as i64 as u64) { pc += 889 }
    ldxdw r1, [r10-0x700]                   
    jne r1, 42, lbb_14950                           if r1 != (42 as i32 as i64 as u64) { pc += 887 }
    ldxdw r1, [r10-0x708]                   
    jne r1, 44, lbb_14950                           if r1 != (44 as i32 as i64 as u64) { pc += 885 }
    ldxdw r1, [r10-0x710]                   
    jne r1, 65, lbb_14950                           if r1 != (65 as i32 as i64 as u64) { pc += 883 }
    ldxdw r1, [r10-0x718]                   
    jne r1, 105, lbb_14950                          if r1 != (105 as i32 as i64 as u64) { pc += 881 }
    ldxdw r1, [r10-0x720]                   
    jne r1, 237, lbb_14950                          if r1 != (237 as i32 as i64 as u64) { pc += 879 }
    ldxdw r1, [r10-0x728]                   
    jne r1, 157, lbb_14950                          if r1 != (157 as i32 as i64 as u64) { pc += 877 }
    ldxdw r1, [r10-0x730]                   
    jne r1, 16, lbb_14950                           if r1 != (16 as i32 as i64 as u64) { pc += 875 }
    ldxdw r1, [r10-0x738]                   
    jne r1, 34, lbb_14950                           if r1 != (34 as i32 as i64 as u64) { pc += 873 }
    ldxdw r1, [r10-0x740]                   
    jeq r1, 67, lbb_14385                           if r1 == (67 as i32 as i64 as u64) { pc += 306 }
    jne r1, 252, lbb_14950                          if r1 != (252 as i32 as i64 as u64) { pc += 870 }
    ldxdw r1, [r10-0x790]                   
    jne r1, 209, lbb_14950                          if r1 != (209 as i32 as i64 as u64) { pc += 868 }
    ldxdw r1, [r10-0x788]                   
    jne r1, 65, lbb_14950                           if r1 != (65 as i32 as i64 as u64) { pc += 866 }
    ldxdw r1, [r10-0x778]                   
    and64 r1, 255                                   r1 &= 255   ///  r1 = r1.and(255)
    jne r1, 233, lbb_14950                          if r1 != (233 as i32 as i64 as u64) { pc += 863 }
    and64 r0, 255                                   r0 &= 255   ///  r0 = r0.and(255)
    jne r0, 131, lbb_14950                          if r0 != (131 as i32 as i64 as u64) { pc += 861 }
    ldxdw r0, [r10-0x770]                   
    and64 r0, 255                                   r0 &= 255   ///  r0 = r0.and(255)
    jne r0, 44, lbb_14950                           if r0 != (44 as i32 as i64 as u64) { pc += 858 }
    jne r8, 175, lbb_14950                          if r8 != (175 as i32 as i64 as u64) { pc += 857 }
    ldxdw r1, [r10-0x768]                   
    and64 r1, 255                                   r1 &= 255   ///  r1 = r1.and(255)
    jne r1, 16, lbb_14950                           if r1 != (16 as i32 as i64 as u64) { pc += 854 }
    ldxdw r1, [r10-0x780]                   
    and64 r1, 255                                   r1 &= 255   ///  r1 = r1.and(255)
    jne r1, 173, lbb_14950                          if r1 != (173 as i32 as i64 as u64) { pc += 851 }
    ldxdw r1, [r10-0x758]                   
    and64 r1, 255                                   r1 &= 255   ///  r1 = r1.and(255)
    jne r1, 145, lbb_14950                          if r1 != (145 as i32 as i64 as u64) { pc += 848 }
    ldxdw r1, [r10-0x760]                   
    jne r1, 116, lbb_14950                          if r1 != (116 as i32 as i64 as u64) { pc += 846 }
    ldxdw r1, [r10-0x750]                   
    jne r1, 149, lbb_14950                          if r1 != (149 as i32 as i64 as u64) { pc += 844 }
    ldxdw r1, [r10-0x7a0]                   
    jne r1, 202, lbb_14950                          if r1 != (202 as i32 as i64 as u64) { pc += 842 }
    ldxdw r1, [r10-0x798]                   
    jne r1, 15, lbb_14950                           if r1 != (15 as i32 as i64 as u64) { pc += 840 }
    ldxdw r1, [r10-0x7a8]                   
    jne r1, 39, lbb_14950                           if r1 != (39 as i32 as i64 as u64) { pc += 838 }
    ldxdw r1, [r10-0x7b0]                   
    jne r1, 27, lbb_14950                           if r1 != (27 as i32 as i64 as u64) { pc += 836 }
    ldxdw r1, [r10-0x7b8]                   
    jne r1, 91, lbb_14950                           if r1 != (91 as i32 as i64 as u64) { pc += 834 }
    ldxdw r1, [r10-0x7c0]                   
    jne r1, 41, lbb_14950                           if r1 != (41 as i32 as i64 as u64) { pc += 832 }
    ldxdw r1, [r10-0x7c8]                   
    jne r1, 60, lbb_14950                           if r1 != (60 as i32 as i64 as u64) { pc += 830 }
    ldxdw r1, [r10-0x7d0]                   
    jne r1, 212, lbb_14950                          if r1 != (212 as i32 as i64 as u64) { pc += 828 }
    ldxdw r1, [r10-0x7d8]                   
    jne r1, 112, lbb_14950                          if r1 != (112 as i32 as i64 as u64) { pc += 826 }
    ldxdw r1, [r10-0x7e0]                   
    jne r1, 39, lbb_14950                           if r1 != (39 as i32 as i64 as u64) { pc += 824 }
    ldxdw r1, [r10-0x7e8]                   
    jne r1, 234, lbb_14950                          if r1 != (234 as i32 as i64 as u64) { pc += 822 }
    ldxdw r1, [r10-0x7f0]                   
    jne r1, 115, lbb_14950                          if r1 != (115 as i32 as i64 as u64) { pc += 820 }
    ldxdw r1, [r10-0x7f8]                   
    jne r1, 112, lbb_14950                          if r1 != (112 as i32 as i64 as u64) { pc += 818 }
    ldxdw r1, [r10-0x800]                   
    jne r1, 7, lbb_14950                            if r1 != (7 as i32 as i64 as u64) { pc += 816 }
    ldxdw r1, [r10-0x808]                   
    jne r1, 237, lbb_14950                          if r1 != (237 as i32 as i64 as u64) { pc += 814 }
    ldxdw r1, [r10-0x810]                   
    jne r1, 64, lbb_14950                           if r1 != (64 as i32 as i64 as u64) { pc += 812 }
    ldxdw r1, [r10-0x818]                   
    jne r1, 235, lbb_14950                          if r1 != (235 as i32 as i64 as u64) { pc += 810 }
    ldxdw r1, [r10-0x820]                   
    jne r1, 57, lbb_14950                           if r1 != (57 as i32 as i64 as u64) { pc += 808 }
    ldxdw r1, [r10-0x828]                   
    jne r1, 160, lbb_14950                          if r1 != (160 as i32 as i64 as u64) { pc += 806 }
    ldxdw r1, [r10-0x830]                   
    jne r1, 189, lbb_14950                          if r1 != (189 as i32 as i64 as u64) { pc += 804 }
    ldxdw r1, [r10-0x748]                   
    ldxdw r1, [r1+0x8]                      
    jeq r1, 1, lbb_15008                            if r1 == (1 as i32 as i64 as u64) { pc += 859 }
    jeq r1, 0, lbb_15028                            if r1 == (0 as i32 as i64 as u64) { pc += 878 }
    jle r1, 2, lbb_15048                            if r1 <= (2 as i32 as i64 as u64) { pc += 897 }
    jeq r1, 3, lbb_15068                            if r1 == (3 as i32 as i64 as u64) { pc += 916 }
    jle r1, 4, lbb_15088                            if r1 <= (4 as i32 as i64 as u64) { pc += 935 }
    jeq r1, 5, lbb_15108                            if r1 == (5 as i32 as i64 as u64) { pc += 954 }
    jle r1, 6, lbb_15128                            if r1 <= (6 as i32 as i64 as u64) { pc += 973 }
    jeq r1, 7, lbb_15148                            if r1 == (7 as i32 as i64 as u64) { pc += 992 }
    jle r1, 8, lbb_15168                            if r1 <= (8 as i32 as i64 as u64) { pc += 1011 }
    jeq r1, 9, lbb_15188                            if r1 == (9 as i32 as i64 as u64) { pc += 1030 }
    jle r1, 10, lbb_15208                           if r1 <= (10 as i32 as i64 as u64) { pc += 1049 }
    jeq r1, 11, lbb_15228                           if r1 == (11 as i32 as i64 as u64) { pc += 1068 }
    jle r1, 12, lbb_15238                           if r1 <= (12 as i32 as i64 as u64) { pc += 1077 }
    ldxdw r1, [r10-0x748]                   
    ldxdw r2, [r1+0x0]                      
    ldxdw r3, [r1+0x48]                     
    stxdw [r10-0x6c0], r3                   
    ldxdw r4, [r1+0x40]                     
    stxdw [r10-0x678], r4                   
    ldxdw r4, [r1+0x28]                     
    stxdw [r10-0x680], r4                   
    ldxdw r5, [r1+0x20]                     
    stxdw [r10-0x6e0], r5                   
    mov64 r4, r2                                    r4 = r2
    add64 r4, 8                                     r4 += 8   ///  r4 = r4.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x688], r4                   
    mov64 r4, r2                                    r4 = r2
    add64 r4, 16                                    r4 += 16   ///  r4 = r4.wrapping_add(16 as i32 as i64 as u64)
    stxdw [r10-0x690], r4                   
    mov64 r4, r2                                    r4 = r2
    add64 r4, 24                                    r4 += 24   ///  r4 = r4.wrapping_add(24 as i32 as i64 as u64)
    stxdw [r10-0x698], r4                   
    mov64 r4, r2                                    r4 = r2
    add64 r4, 32                                    r4 += 32   ///  r4 = r4.wrapping_add(32 as i32 as i64 as u64)
    stxdw [r10-0x6a0], r4                   
    mov64 r4, r2                                    r4 = r2
    add64 r4, 40                                    r4 += 40   ///  r4 = r4.wrapping_add(40 as i32 as i64 as u64)
    stxdw [r10-0x6a8], r4                   
    mov64 r4, r2                                    r4 = r2
    add64 r4, 48                                    r4 += 48   ///  r4 = r4.wrapping_add(48 as i32 as i64 as u64)
    stxdw [r10-0x6b0], r4                   
    mov64 r4, r2                                    r4 = r2
    add64 r4, 56                                    r4 += 56   ///  r4 = r4.wrapping_add(56 as i32 as i64 as u64)
    stxdw [r10-0x6b8], r4                   
    mov64 r4, r2                                    r4 = r2
    add64 r4, 64                                    r4 += 64   ///  r4 = r4.wrapping_add(64 as i32 as i64 as u64)
    stxdw [r10-0x6c8], r4                   
    mov64 r4, r2                                    r4 = r2
    add64 r4, 72                                    r4 += 72   ///  r4 = r4.wrapping_add(72 as i32 as i64 as u64)
    stxdw [r10-0x6d0], r4                   
    mov64 r4, r2                                    r4 = r2
    add64 r4, 80                                    r4 += 80   ///  r4 = r4.wrapping_add(80 as i32 as i64 as u64)
    stxdw [r10-0x6d8], r4                   
    ldxdw r1, [r1+0x10]                     
    stxdw [r10-0x6e8], r1                   
    ldxdw r0, [r10-0x850]                   
    add64 r0, 8                                     r0 += 8   ///  r0 = r0.wrapping_add(8 as i32 as i64 as u64)
    ldxdw r1, [r5+0x0]                      
    stxdw [r10-0x728], r1                   
    ldxdw r1, [r3+0x0]                      
    stxdw [r10-0x6f0], r1                   
    ldxdw r1, [r2+0x0]                      
    stxdw [r10-0x6f8], r1                   
    ldxdw r1, [r2+0x8]                      
    stxdw [r10-0x700], r1                   
    ldxdw r1, [r2+0x10]                     
    stxdw [r10-0x708], r1                   
    ldxdw r1, [r2+0x18]                     
    stxdw [r10-0x710], r1                   
    ldxdw r1, [r2+0x20]                     
    stxdw [r10-0x718], r1                   
    ldxdw r1, [r2+0x28]                     
    stxdw [r10-0x720], r1                   
    ldxdw r1, [r2+0x30]                     
    stxdw [r10-0x730], r1                   
    ldxdw r9, [r2+0x38]                     
    ldxdw r8, [r2+0x40]                     
    ldxdw r7, [r2+0x48]                     
    ldxdw r6, [r2+0x50]                     
    ldxdw r1, [r10-0x678]                   
    ldxdw r5, [r1+0x0]                      
    ldxdw r1, [r10-0x680]                   
    ldxdw r4, [r1+0x0]                      
    ldxdw r3, [r2+0x58]                     
    ldxdw r1, [r2+0x60]                     
    stxdw [r10-0x5d8], r0                   
    ldxdw r0, [r10-0x848]                   
    add64 r0, 8                                     r0 += 8   ///  r0 = r0.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x5e8], r0                   
    add64 r1, 8                                     r1 += 8   ///  r1 = r1.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x558], r1                   
    add64 r3, 8                                     r3 += 8   ///  r3 = r3.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x568], r3                   
    add64 r4, 8                                     r4 += 8   ///  r4 = r4.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x578], r4                   
    add64 r5, 8                                     r5 += 8   ///  r5 = r5.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x588], r5                   
    add64 r6, 8                                     r6 += 8   ///  r6 = r6.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x598], r6                   
    add64 r7, 8                                     r7 += 8   ///  r7 = r7.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x5a8], r7                   
    ldxdw r7, [r10-0x728]                   
    add64 r8, 8                                     r8 += 8   ///  r8 = r8.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x5b8], r8                   
    add64 r9, 8                                     r9 += 8   ///  r9 = r9.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x5c8], r9                   
    ldxdw r1, [r10-0x730]                   
    add64 r1, 8                                     r1 += 8   ///  r1 = r1.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x5f8], r1                   
    ldxdw r1, [r10-0x720]                   
    add64 r1, 8                                     r1 += 8   ///  r1 = r1.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x608], r1                   
    ldxdw r1, [r10-0x718]                   
    add64 r1, 8                                     r1 += 8   ///  r1 = r1.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x618], r1                   
    ldxdw r1, [r10-0x710]                   
    add64 r1, 8                                     r1 += 8   ///  r1 = r1.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x628], r1                   
    ldxdw r1, [r10-0x708]                   
    add64 r1, 8                                     r1 += 8   ///  r1 = r1.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x638], r1                   
    ldxdw r1, [r10-0x700]                   
    add64 r1, 8                                     r1 += 8   ///  r1 = r1.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x648], r1                   
    ldxdw r1, [r10-0x6f8]                   
    add64 r1, 8                                     r1 += 8   ///  r1 = r1.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x658], r1                   
    ldxdw r1, [r10-0x6f0]                   
    add64 r1, 8                                     r1 += 8   ///  r1 = r1.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x668], r1                   
    add64 r7, 8                                     r7 += 8   ///  r7 = r7.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x548], r7                   
    sth [r10-0x540], 0                      
    sth [r10-0x550], 0                      
    sth [r10-0x560], 0                      
    sth [r10-0x570], 0                      
    sth [r10-0x580], 0                      
    sth [r10-0x590], 0                      
    sth [r10-0x5a0], 1                      
    sth [r10-0x5b0], 0                      
    sth [r10-0x5c0], 1                      
    sth [r10-0x5d0], 1                      
    sth [r10-0x5e0], 1                      
    sth [r10-0x5f0], 0                      
    sth [r10-0x600], 1                      
    sth [r10-0x610], 1                      
    sth [r10-0x620], 0                      
    sth [r10-0x630], 0                      
    sth [r10-0x640], 0                      
    sth [r10-0x650], 1                      
    sth [r10-0x660], 257                    
    ldxdw r1, [r10-0x6e8]                   
    stxdw [r10-0x530], r1                   
    lddw r1, 0x2cae832e20d7a684                     r1 load str located at 3219655017759221380
    stxdw [r10-0x538], r1                   
    stb [r10-0x528], 0                      
    ldxdw r1, [r10-0x6e0]                   
    stxdw [r10-0x490], r1                   
    mov64 r1, r2                                    r1 = r2
    add64 r1, 96                                    r1 += 96   ///  r1 = r1.wrapping_add(96 as i32 as i64 as u64)
    stxdw [r10-0x498], r1                   
    mov64 r1, r2                                    r1 = r2
    add64 r1, 88                                    r1 += 88   ///  r1 = r1.wrapping_add(88 as i32 as i64 as u64)
    stxdw [r10-0x4a0], r1                   
    ldxdw r1, [r10-0x680]                   
    ja lbb_14870                                    if true { pc += 555 }
lbb_14315:
    ldxdw r4, [r10-0x670]                   
    mov64 r6, 0                                     r6 = 0 as i32 as i64 as u64
    ja lbb_14950                                    if true { pc += 632 }
lbb_14318:
    ldxdw r1, [r10-0x790]                   
    jne r1, 131, lbb_14950                          if r1 != (131 as i32 as i64 as u64) { pc += 630 }
    ldxdw r1, [r10-0x788]                   
    jne r1, 77, lbb_14950                           if r1 != (77 as i32 as i64 as u64) { pc += 628 }
    ldxdw r1, [r10-0x778]                   
    and64 r1, 255                                   r1 &= 255   ///  r1 = r1.and(255)
    jne r1, 239, lbb_14950                          if r1 != (239 as i32 as i64 as u64) { pc += 625 }
    and64 r0, 255                                   r0 &= 255   ///  r0 = r0.and(255)
    jne r0, 157, lbb_14950                          if r0 != (157 as i32 as i64 as u64) { pc += 623 }
    ldxdw r0, [r10-0x770]                   
    and64 r0, 255                                   r0 &= 255   ///  r0 = r0.and(255)
    jne r0, 208, lbb_14950                          if r0 != (208 as i32 as i64 as u64) { pc += 620 }
    jne r8, 131, lbb_14950                          if r8 != (131 as i32 as i64 as u64) { pc += 619 }
    ldxdw r1, [r10-0x768]                   
    and64 r1, 255                                   r1 &= 255   ///  r1 = r1.and(255)
    jne r1, 246, lbb_14950                          if r1 != (246 as i32 as i64 as u64) { pc += 616 }
    ldxdw r1, [r10-0x780]                   
    and64 r1, 255                                   r1 &= 255   ///  r1 = r1.and(255)
    jne r1, 140, lbb_14950                          if r1 != (140 as i32 as i64 as u64) { pc += 613 }
    ldxdw r1, [r10-0x758]                   
    and64 r1, 255                                   r1 &= 255   ///  r1 = r1.and(255)
    jne r1, 63, lbb_14950                           if r1 != (63 as i32 as i64 as u64) { pc += 610 }
    ldxdw r1, [r10-0x760]                   
    jne r1, 218, lbb_14950                          if r1 != (218 as i32 as i64 as u64) { pc += 608 }
    ldxdw r1, [r10-0x750]                   
    jne r1, 76, lbb_14950                           if r1 != (76 as i32 as i64 as u64) { pc += 606 }
    ldxdw r1, [r10-0x7a0]                   
    jne r1, 237, lbb_14950                          if r1 != (237 as i32 as i64 as u64) { pc += 604 }
    ldxdw r1, [r10-0x798]                   
    jne r1, 164, lbb_14950                          if r1 != (164 as i32 as i64 as u64) { pc += 602 }
    ldxdw r1, [r10-0x7a8]                   
    jne r1, 0, lbb_14950                            if r1 != (0 as i32 as i64 as u64) { pc += 600 }
    ldxdw r1, [r10-0x7b0]                   
    jne r1, 43, lbb_14950                           if r1 != (43 as i32 as i64 as u64) { pc += 598 }
    ldxdw r1, [r10-0x7b8]                   
    jne r1, 111, lbb_14950                          if r1 != (111 as i32 as i64 as u64) { pc += 596 }
    ldxdw r1, [r10-0x7c0]                   
    jne r1, 50, lbb_14950                           if r1 != (50 as i32 as i64 as u64) { pc += 594 }
    ldxdw r1, [r10-0x7c8]                   
    jne r1, 88, lbb_14950                           if r1 != (88 as i32 as i64 as u64) { pc += 592 }
    ldxdw r1, [r10-0x7d0]                   
    jne r1, 172, lbb_14950                          if r1 != (172 as i32 as i64 as u64) { pc += 590 }
    ldxdw r1, [r10-0x7d8]                   
    jne r1, 215, lbb_14950                          if r1 != (215 as i32 as i64 as u64) { pc += 588 }
    ldxdw r1, [r10-0x7e0]                   
    jne r1, 74, lbb_14950                           if r1 != (74 as i32 as i64 as u64) { pc += 586 }
    ldxdw r1, [r10-0x7e8]                   
    jne r1, 147, lbb_14950                          if r1 != (147 as i32 as i64 as u64) { pc += 584 }
    ldxdw r1, [r10-0x7f0]                   
    jne r1, 226, lbb_14950                          if r1 != (226 as i32 as i64 as u64) { pc += 582 }
    ldxdw r1, [r10-0x7f8]                   
    jne r1, 42, lbb_14950                           if r1 != (42 as i32 as i64 as u64) { pc += 580 }
    ldxdw r1, [r10-0x800]                   
    jne r1, 44, lbb_14950                           if r1 != (44 as i32 as i64 as u64) { pc += 578 }
    ldxdw r1, [r10-0x808]                   
    jne r1, 65, lbb_14950                           if r1 != (65 as i32 as i64 as u64) { pc += 576 }
    ldxdw r1, [r10-0x810]                   
    jne r1, 105, lbb_14950                          if r1 != (105 as i32 as i64 as u64) { pc += 574 }
    ldxdw r1, [r10-0x818]                   
    jne r1, 237, lbb_14950                          if r1 != (237 as i32 as i64 as u64) { pc += 572 }
    ldxdw r1, [r10-0x820]                   
    jne r1, 157, lbb_14950                          if r1 != (157 as i32 as i64 as u64) { pc += 570 }
    ldxdw r1, [r10-0x828]                   
    jne r1, 16, lbb_14950                           if r1 != (16 as i32 as i64 as u64) { pc += 568 }
    ldxdw r1, [r10-0x830]                   
    jeq r1, 34, lbb_14451                           if r1 == (34 as i32 as i64 as u64) { pc += 67 }
    ja lbb_14950                                    if true { pc += 565 }
lbb_14385:
    ldxdw r1, [r10-0x790]                   
    jne r1, 119, lbb_14950                          if r1 != (119 as i32 as i64 as u64) { pc += 563 }
    ldxdw r1, [r10-0x788]                   
    jne r1, 55, lbb_14950                           if r1 != (55 as i32 as i64 as u64) { pc += 561 }
    ldxdw r1, [r10-0x778]                   
    and64 r1, 255                                   r1 &= 255   ///  r1 = r1.and(255)
    jne r1, 28, lbb_14950                           if r1 != (28 as i32 as i64 as u64) { pc += 558 }
    and64 r0, 255                                   r0 &= 255   ///  r0 = r0.and(255)
    jne r0, 116, lbb_14950                          if r0 != (116 as i32 as i64 as u64) { pc += 556 }
    ldxdw r0, [r10-0x770]                   
    and64 r0, 255                                   r0 &= 255   ///  r0 = r0.and(255)
    jne r0, 248, lbb_14950                          if r0 != (248 as i32 as i64 as u64) { pc += 553 }
    jne r8, 110, lbb_14950                          if r8 != (110 as i32 as i64 as u64) { pc += 552 }
    ldxdw r1, [r10-0x768]                   
    and64 r1, 255                                   r1 &= 255   ///  r1 = r1.and(255)
    jne r1, 161, lbb_14950                          if r1 != (161 as i32 as i64 as u64) { pc += 549 }
    ldxdw r1, [r10-0x780]                   
    and64 r1, 255                                   r1 &= 255   ///  r1 = r1.and(255)
    jne r1, 139, lbb_14950                          if r1 != (139 as i32 as i64 as u64) { pc += 546 }
    ldxdw r1, [r10-0x758]                   
    and64 r1, 255                                   r1 &= 255   ///  r1 = r1.and(255)
    jne r1, 241, lbb_14950                          if r1 != (241 as i32 as i64 as u64) { pc += 543 }
    ldxdw r1, [r10-0x760]                   
    jne r1, 127, lbb_14950                          if r1 != (127 as i32 as i64 as u64) { pc += 541 }
    ldxdw r1, [r10-0x750]                   
    jne r1, 177, lbb_14950                          if r1 != (177 as i32 as i64 as u64) { pc += 539 }
    ldxdw r1, [r10-0x7a0]                   
    jne r1, 96, lbb_14950                           if r1 != (96 as i32 as i64 as u64) { pc += 537 }
    ldxdw r1, [r10-0x798]                   
    jne r1, 51, lbb_14950                           if r1 != (51 as i32 as i64 as u64) { pc += 535 }
    ldxdw r1, [r10-0x7a8]                   
    jne r1, 132, lbb_14950                          if r1 != (132 as i32 as i64 as u64) { pc += 533 }
    ldxdw r1, [r10-0x7b0]                   
    jne r1, 82, lbb_14950                           if r1 != (82 as i32 as i64 as u64) { pc += 531 }
    ldxdw r1, [r10-0x7b8]                   
    jne r1, 170, lbb_14950                          if r1 != (170 as i32 as i64 as u64) { pc += 529 }
    ldxdw r1, [r10-0x7c0]                   
    jne r1, 99, lbb_14950                           if r1 != (99 as i32 as i64 as u64) { pc += 527 }
    ldxdw r1, [r10-0x7c8]                   
    jne r1, 250, lbb_14950                          if r1 != (250 as i32 as i64 as u64) { pc += 525 }
    ldxdw r1, [r10-0x7d0]                   
    jne r1, 220, lbb_14950                          if r1 != (220 as i32 as i64 as u64) { pc += 523 }
    ldxdw r1, [r10-0x7d8]                   
    jne r1, 172, lbb_14950                          if r1 != (172 as i32 as i64 as u64) { pc += 521 }
    ldxdw r1, [r10-0x7e0]                   
    jne r1, 213, lbb_14950                          if r1 != (213 as i32 as i64 as u64) { pc += 519 }
    ldxdw r1, [r10-0x7e8]                   
    jne r1, 163, lbb_14950                          if r1 != (163 as i32 as i64 as u64) { pc += 517 }
    ldxdw r1, [r10-0x7f0]                   
    jne r1, 31, lbb_14950                           if r1 != (31 as i32 as i64 as u64) { pc += 515 }
    ldxdw r1, [r10-0x7f8]                   
    jne r1, 179, lbb_14950                          if r1 != (179 as i32 as i64 as u64) { pc += 513 }
    ldxdw r1, [r10-0x800]                   
    jne r1, 172, lbb_14950                          if r1 != (172 as i32 as i64 as u64) { pc += 511 }
    ldxdw r1, [r10-0x808]                   
    jne r1, 245, lbb_14950                          if r1 != (245 as i32 as i64 as u64) { pc += 509 }
    ldxdw r1, [r10-0x810]                   
    jne r1, 75, lbb_14950                           if r1 != (75 as i32 as i64 as u64) { pc += 507 }
    ldxdw r1, [r10-0x818]                   
    jne r1, 165, lbb_14950                          if r1 != (165 as i32 as i64 as u64) { pc += 505 }
    ldxdw r1, [r10-0x820]                   
    jne r1, 46, lbb_14950                           if r1 != (46 as i32 as i64 as u64) { pc += 503 }
    ldxdw r1, [r10-0x828]                   
    jne r1, 136, lbb_14950                          if r1 != (136 as i32 as i64 as u64) { pc += 501 }
    ldxdw r1, [r10-0x830]                   
    jne r1, 173, lbb_14950                          if r1 != (173 as i32 as i64 as u64) { pc += 499 }
lbb_14451:
    ldxdw r1, [r10-0x748]                   
    ldxdw r1, [r1+0x8]                      
    jeq r1, 0, lbb_14953                            if r1 == (0 as i32 as i64 as u64) { pc += 499 }
    jeq r1, 1, lbb_14958                            if r1 == (1 as i32 as i64 as u64) { pc += 503 }
    jle r1, 2, lbb_14963                            if r1 <= (2 as i32 as i64 as u64) { pc += 507 }
    jeq r1, 3, lbb_14968                            if r1 == (3 as i32 as i64 as u64) { pc += 511 }
    jle r1, 4, lbb_14973                            if r1 <= (4 as i32 as i64 as u64) { pc += 515 }
    jeq r1, 5, lbb_14978                            if r1 == (5 as i32 as i64 as u64) { pc += 519 }
    jle r1, 6, lbb_14983                            if r1 <= (6 as i32 as i64 as u64) { pc += 523 }
    jeq r1, 7, lbb_14988                            if r1 == (7 as i32 as i64 as u64) { pc += 527 }
    jle r1, 8, lbb_14993                            if r1 <= (8 as i32 as i64 as u64) { pc += 531 }
    ldxdw r1, [r10-0x748]                   
    ldxdw r2, [r1+0x0]                      
    ldxdw r3, [r1+0x48]                     
    stxdw [r10-0x6a8], r3                   
    ldxdw r4, [r1+0x28]                     
    stxdw [r10-0x678], r4                   
    ldxdw r5, [r1+0x20]                     
    stxdw [r10-0x6c0], r5                   
    mov64 r4, r2                                    r4 = r2
    add64 r4, 8                                     r4 += 8   ///  r4 = r4.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x680], r4                   
    mov64 r4, r2                                    r4 = r2
    add64 r4, 16                                    r4 += 16   ///  r4 = r4.wrapping_add(16 as i32 as i64 as u64)
    stxdw [r10-0x688], r4                   
    mov64 r4, r2                                    r4 = r2
    add64 r4, 24                                    r4 += 24   ///  r4 = r4.wrapping_add(24 as i32 as i64 as u64)
    stxdw [r10-0x690], r4                   
    mov64 r4, r2                                    r4 = r2
    add64 r4, 32                                    r4 += 32   ///  r4 = r4.wrapping_add(32 as i32 as i64 as u64)
    stxdw [r10-0x698], r4                   
    mov64 r4, r2                                    r4 = r2
    add64 r4, 40                                    r4 += 40   ///  r4 = r4.wrapping_add(40 as i32 as i64 as u64)
    stxdw [r10-0x6a0], r4                   
    mov64 r4, r2                                    r4 = r2
    add64 r4, 48                                    r4 += 48   ///  r4 = r4.wrapping_add(48 as i32 as i64 as u64)
    stxdw [r10-0x6b0], r4                   
    ldxdw r1, [r1+0x10]                     
    stxdw [r10-0x6b8], r1                   
    ldxdw r0, [r10-0x850]                   
    add64 r0, 8                                     r0 += 8   ///  r0 = r0.wrapping_add(8 as i32 as i64 as u64)
    ldxdw r1, [r5+0x0]                      
    stxdw [r10-0x6e0], r1                   
    ldxdw r1, [r3+0x0]                      
    stxdw [r10-0x6c8], r1                   
    ldxdw r1, [r2+0x0]                      
    stxdw [r10-0x6d0], r1                   
    ldxdw r1, [r2+0x8]                      
    stxdw [r10-0x6d8], r1                   
    ldxdw r9, [r2+0x10]                     
    ldxdw r8, [r2+0x18]                     
    ldxdw r7, [r2+0x20]                     
    ldxdw r6, [r2+0x28]                     
    ldxdw r5, [r2+0x30]                     
    ldxdw r4, [r2+0x38]                     
    ldxdw r1, [r10-0x678]                   
    ldxdw r3, [r1+0x0]                      
    ldxdw r1, [r2+0x40]                     
    stxdw [r10-0x5c8], r0                   
    ldxdw r0, [r10-0x848]                   
    add64 r0, 8                                     r0 += 8   ///  r0 = r0.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x5f8], r0                   
    add64 r1, 8                                     r1 += 8   ///  r1 = r1.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x5a8], r1                   
    add64 r3, 8                                     r3 += 8   ///  r3 = r3.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x5b8], r3                   
    add64 r4, 8                                     r4 += 8   ///  r4 = r4.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x5d8], r4                   
    add64 r5, 8                                     r5 += 8   ///  r5 = r5.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x5e8], r5                   
    add64 r6, 8                                     r6 += 8   ///  r6 = r6.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x608], r6                   
    add64 r7, 8                                     r7 += 8   ///  r7 = r7.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x618], r7                   
    ldxdw r7, [r10-0x6e0]                   
    add64 r8, 8                                     r8 += 8   ///  r8 = r8.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x628], r8                   
    add64 r9, 8                                     r9 += 8   ///  r9 = r9.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x638], r9                   
    ldxdw r1, [r10-0x6d8]                   
    add64 r1, 8                                     r1 += 8   ///  r1 = r1.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x648], r1                   
    ldxdw r1, [r10-0x6d0]                   
    add64 r1, 8                                     r1 += 8   ///  r1 = r1.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x658], r1                   
    ldxdw r1, [r10-0x6c8]                   
    add64 r1, 8                                     r1 += 8   ///  r1 = r1.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x668], r1                   
    add64 r7, 8                                     r7 += 8   ///  r7 = r7.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x598], r7                   
    sth [r10-0x590], 0                      
    sth [r10-0x5a0], 0                      
    sth [r10-0x5b0], 0                      
    sth [r10-0x5c0], 1                      
    sth [r10-0x5d0], 0                      
    sth [r10-0x5e0], 1                      
    sth [r10-0x5f0], 1                      
    sth [r10-0x600], 0                      
    sth [r10-0x610], 0                      
    sth [r10-0x620], 0                      
    sth [r10-0x630], 1                      
    sth [r10-0x640], 0                      
    sth [r10-0x650], 1                      
    sth [r10-0x660], 257                    
    ldxdw r1, [r10-0x6b8]                   
    stxdw [r10-0x530], r1                   
    lddw r1, 0x2cae832e20d7a684                     r1 load str located at 3219655017759221380
    stxdw [r10-0x538], r1                   
    ldxdw r1, [r10-0x6c0]                   
    stxdw [r10-0x4b8], r1                   
    mov64 r1, r2                                    r1 = r2
    add64 r1, 64                                    r1 += 64   ///  r1 = r1.wrapping_add(64 as i32 as i64 as u64)
    stxdw [r10-0x4c0], r1                   
    ldxdw r1, [r10-0x678]                   
    stxdw [r10-0x4c8], r1                   
    ldxdw r1, [r10-0x840]                   
    stxdw [r10-0x4d0], r1                   
    mov64 r1, r2                                    r1 = r2
    add64 r1, 56                                    r1 += 56   ///  r1 = r1.wrapping_add(56 as i32 as i64 as u64)
    stxdw [r10-0x4d8], r1                   
    ldxdw r1, [r10-0x6b0]                   
    stxdw [r10-0x4e0], r1                   
    ldxdw r1, [r10-0x838]                   
    stxdw [r10-0x4e8], r1                   
    ldxdw r1, [r10-0x6a0]                   
    stxdw [r10-0x4f0], r1                   
    ldxdw r1, [r10-0x698]                   
    stxdw [r10-0x4f8], r1                   
    ldxdw r1, [r10-0x690]                   
    stxdw [r10-0x500], r1                   
    ldxdw r1, [r10-0x688]                   
    stxdw [r10-0x508], r1                   
    ldxdw r1, [r10-0x680]                   
    stxdw [r10-0x510], r1                   
    stxdw [r10-0x518], r2                   
    ldxdw r1, [r10-0x6a8]                   
    stxdw [r10-0x520], r1                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -376                                  r1 += -376   ///  r1 = r1.wrapping_add(-376 as i32 as i64 as u64)
    stxdw [r10-0x20], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -1160                                 r1 += -1160   ///  r1 = r1.wrapping_add(-1160 as i32 as i64 as u64)
    stxdw [r10-0x28], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -1416                                 r1 += -1416   ///  r1 = r1.wrapping_add(-1416 as i32 as i64 as u64)
    stxdw [r10-0x48], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -1640                                 r1 += -1640   ///  r1 = r1.wrapping_add(-1640 as i32 as i64 as u64)
    stxdw [r10-0x50], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -1200                                 r1 += -1200   ///  r1 = r1.wrapping_add(-1200 as i32 as i64 as u64)
    stxdw [r10-0x58], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -1312                                 r1 += -1312   ///  r1 = r1.wrapping_add(-1312 as i32 as i64 as u64)
    stxdw [r10-0x60], r1                    
    stdw [r10-0x8], 14                      
    stdw [r10-0x10], 14                     
    stdw [r10-0x18], 0                      
    stdw [r10-0x30], 14                     
    stdw [r10-0x38], 14                     
    stdw [r10-0x40], 0                      
    mov64 r1, r10                                   r1 = r10
    add64 r1, -96                                   r1 += -96   ///  r1 = r1.wrapping_add(-96 as i32 as i64 as u64)
    call function_0                         
    mov64 r6, r0                                    r6 = r0
    mov64 r1, r6                                    r1 = r6
    lsh64 r1, 32                                    r1 <<= 32   ///  r1 = r1.wrapping_shl(32)
    rsh64 r1, 32                                    r1 >>= 32   ///  r1 = r1.wrapping_shr(32)
    jne r1, 26, lbb_14949                           if r1 != (26 as i32 as i64 as u64) { pc += 328 }
    mov64 r1, r10                                   r1 = r10
    add64 r1, -1336                                 r1 += -1336   ///  r1 = r1.wrapping_add(-1336 as i32 as i64 as u64)
    stxdw [r10-0x48], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -1640                                 r1 += -1640   ///  r1 = r1.wrapping_add(-1640 as i32 as i64 as u64)
    stxdw [r10-0x58], r1                    
    stxdw [r10-0x60], r7                    
    stdw [r10-0x40], 16                     
    stdw [r10-0x50], 14                     
    mov64 r1, r10                                   r1 = r10
    add64 r1, -96                                   r1 += -96   ///  r1 = r1.wrapping_add(-96 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -1160                                 r2 += -1160   ///  r2 = r2.wrapping_add(-1160 as i32 as i64 as u64)
    mov64 r3, 14                                    r3 = 14 as i32 as i64 as u64
    ja lbb_14946                                    if true { pc += 310 }
lbb_14636:
    ldxdw r1, [r10-0x790]                   
    jne r1, 131, lbb_14950                          if r1 != (131 as i32 as i64 as u64) { pc += 312 }
    ldxdw r1, [r10-0x788]                   
    jne r1, 77, lbb_14950                           if r1 != (77 as i32 as i64 as u64) { pc += 310 }
    ldxdw r1, [r10-0x778]                   
    and64 r1, 255                                   r1 &= 255   ///  r1 = r1.and(255)
    jne r1, 239, lbb_14950                          if r1 != (239 as i32 as i64 as u64) { pc += 307 }
    and64 r0, 255                                   r0 &= 255   ///  r0 = r0.and(255)
    jne r0, 157, lbb_14950                          if r0 != (157 as i32 as i64 as u64) { pc += 305 }
    ldxdw r0, [r10-0x770]                   
    and64 r0, 255                                   r0 &= 255   ///  r0 = r0.and(255)
    jne r0, 208, lbb_14950                          if r0 != (208 as i32 as i64 as u64) { pc += 302 }
    jne r8, 131, lbb_14950                          if r8 != (131 as i32 as i64 as u64) { pc += 301 }
    ldxdw r1, [r10-0x768]                   
    and64 r1, 255                                   r1 &= 255   ///  r1 = r1.and(255)
    jne r1, 246, lbb_14950                          if r1 != (246 as i32 as i64 as u64) { pc += 298 }
    ldxdw r1, [r10-0x780]                   
    and64 r1, 255                                   r1 &= 255   ///  r1 = r1.and(255)
    jne r1, 140, lbb_14950                          if r1 != (140 as i32 as i64 as u64) { pc += 295 }
    ldxdw r1, [r10-0x758]                   
    and64 r1, 255                                   r1 &= 255   ///  r1 = r1.and(255)
    jne r1, 63, lbb_14950                           if r1 != (63 as i32 as i64 as u64) { pc += 292 }
    ldxdw r1, [r10-0x760]                   
    jne r1, 218, lbb_14950                          if r1 != (218 as i32 as i64 as u64) { pc += 290 }
    ldxdw r1, [r10-0x750]                   
    jne r1, 76, lbb_14950                           if r1 != (76 as i32 as i64 as u64) { pc += 288 }
    ldxdw r1, [r10-0x7a0]                   
    jne r1, 237, lbb_14950                          if r1 != (237 as i32 as i64 as u64) { pc += 286 }
    ldxdw r1, [r10-0x798]                   
    jne r1, 164, lbb_14950                          if r1 != (164 as i32 as i64 as u64) { pc += 284 }
    ldxdw r1, [r10-0x7a8]                   
    jne r1, 0, lbb_14950                            if r1 != (0 as i32 as i64 as u64) { pc += 282 }
    ldxdw r1, [r10-0x7b0]                   
    jne r1, 43, lbb_14950                           if r1 != (43 as i32 as i64 as u64) { pc += 280 }
    ldxdw r1, [r10-0x7b8]                   
    jne r1, 111, lbb_14950                          if r1 != (111 as i32 as i64 as u64) { pc += 278 }
    ldxdw r1, [r10-0x7c0]                   
    jne r1, 50, lbb_14950                           if r1 != (50 as i32 as i64 as u64) { pc += 276 }
    ldxdw r1, [r10-0x7c8]                   
    jne r1, 88, lbb_14950                           if r1 != (88 as i32 as i64 as u64) { pc += 274 }
    ldxdw r1, [r10-0x7d0]                   
    jne r1, 172, lbb_14950                          if r1 != (172 as i32 as i64 as u64) { pc += 272 }
    ldxdw r1, [r10-0x7d8]                   
    jne r1, 215, lbb_14950                          if r1 != (215 as i32 as i64 as u64) { pc += 270 }
    ldxdw r1, [r10-0x7e0]                   
    jne r1, 74, lbb_14950                           if r1 != (74 as i32 as i64 as u64) { pc += 268 }
    ldxdw r1, [r10-0x7e8]                   
    jne r1, 147, lbb_14950                          if r1 != (147 as i32 as i64 as u64) { pc += 266 }
    ldxdw r1, [r10-0x7f0]                   
    jne r1, 226, lbb_14950                          if r1 != (226 as i32 as i64 as u64) { pc += 264 }
    ldxdw r1, [r10-0x7f8]                   
    jne r1, 42, lbb_14950                           if r1 != (42 as i32 as i64 as u64) { pc += 262 }
    ldxdw r1, [r10-0x800]                   
    jne r1, 44, lbb_14950                           if r1 != (44 as i32 as i64 as u64) { pc += 260 }
    ldxdw r1, [r10-0x808]                   
    jne r1, 65, lbb_14950                           if r1 != (65 as i32 as i64 as u64) { pc += 258 }
    ldxdw r1, [r10-0x810]                   
    jne r1, 105, lbb_14950                          if r1 != (105 as i32 as i64 as u64) { pc += 256 }
    ldxdw r1, [r10-0x818]                   
    jne r1, 237, lbb_14950                          if r1 != (237 as i32 as i64 as u64) { pc += 254 }
    ldxdw r1, [r10-0x820]                   
    jne r1, 157, lbb_14950                          if r1 != (157 as i32 as i64 as u64) { pc += 252 }
    ldxdw r1, [r10-0x828]                   
    jne r1, 16, lbb_14950                           if r1 != (16 as i32 as i64 as u64) { pc += 250 }
    ldxdw r1, [r10-0x830]                   
    jne r1, 34, lbb_14950                           if r1 != (34 as i32 as i64 as u64) { pc += 248 }
    ldxdw r1, [r10-0x748]                   
    ldxdw r1, [r1+0x8]                      
    jeq r1, 1, lbb_15013                            if r1 == (1 as i32 as i64 as u64) { pc += 308 }
    jeq r1, 0, lbb_15033                            if r1 == (0 as i32 as i64 as u64) { pc += 327 }
    jle r1, 2, lbb_15053                            if r1 <= (2 as i32 as i64 as u64) { pc += 346 }
    jeq r1, 3, lbb_15073                            if r1 == (3 as i32 as i64 as u64) { pc += 365 }
    jle r1, 4, lbb_15093                            if r1 <= (4 as i32 as i64 as u64) { pc += 384 }
    jeq r1, 5, lbb_15113                            if r1 == (5 as i32 as i64 as u64) { pc += 403 }
    jle r1, 6, lbb_15133                            if r1 <= (6 as i32 as i64 as u64) { pc += 422 }
    jeq r1, 7, lbb_15153                            if r1 == (7 as i32 as i64 as u64) { pc += 441 }
    jle r1, 8, lbb_15173                            if r1 <= (8 as i32 as i64 as u64) { pc += 460 }
    jeq r1, 9, lbb_15193                            if r1 == (9 as i32 as i64 as u64) { pc += 479 }
    jle r1, 10, lbb_15213                           if r1 <= (10 as i32 as i64 as u64) { pc += 498 }
    jeq r1, 11, lbb_15233                           if r1 == (11 as i32 as i64 as u64) { pc += 517 }
    jle r1, 12, lbb_15243                           if r1 <= (12 as i32 as i64 as u64) { pc += 526 }
    ldxdw r1, [r10-0x748]                   
    ldxdw r2, [r1+0x0]                      
    ldxdw r3, [r1+0x48]                     
    stxdw [r10-0x6c0], r3                   
    ldxdw r4, [r1+0x40]                     
    stxdw [r10-0x680], r4                   
    ldxdw r4, [r1+0x28]                     
    stxdw [r10-0x678], r4                   
    ldxdw r5, [r1+0x20]                     
    stxdw [r10-0x6e0], r5                   
    mov64 r4, r2                                    r4 = r2
    add64 r4, 8                                     r4 += 8   ///  r4 = r4.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x688], r4                   
    mov64 r4, r2                                    r4 = r2
    add64 r4, 16                                    r4 += 16   ///  r4 = r4.wrapping_add(16 as i32 as i64 as u64)
    stxdw [r10-0x690], r4                   
    mov64 r4, r2                                    r4 = r2
    add64 r4, 24                                    r4 += 24   ///  r4 = r4.wrapping_add(24 as i32 as i64 as u64)
    stxdw [r10-0x698], r4                   
    mov64 r4, r2                                    r4 = r2
    add64 r4, 32                                    r4 += 32   ///  r4 = r4.wrapping_add(32 as i32 as i64 as u64)
    stxdw [r10-0x6a0], r4                   
    mov64 r4, r2                                    r4 = r2
    add64 r4, 40                                    r4 += 40   ///  r4 = r4.wrapping_add(40 as i32 as i64 as u64)
    stxdw [r10-0x6a8], r4                   
    mov64 r4, r2                                    r4 = r2
    add64 r4, 48                                    r4 += 48   ///  r4 = r4.wrapping_add(48 as i32 as i64 as u64)
    stxdw [r10-0x6b0], r4                   
    mov64 r4, r2                                    r4 = r2
    add64 r4, 56                                    r4 += 56   ///  r4 = r4.wrapping_add(56 as i32 as i64 as u64)
    stxdw [r10-0x6b8], r4                   
    mov64 r4, r2                                    r4 = r2
    add64 r4, 64                                    r4 += 64   ///  r4 = r4.wrapping_add(64 as i32 as i64 as u64)
    stxdw [r10-0x6c8], r4                   
    mov64 r4, r2                                    r4 = r2
    add64 r4, 72                                    r4 += 72   ///  r4 = r4.wrapping_add(72 as i32 as i64 as u64)
    stxdw [r10-0x6d0], r4                   
    mov64 r4, r2                                    r4 = r2
    add64 r4, 80                                    r4 += 80   ///  r4 = r4.wrapping_add(80 as i32 as i64 as u64)
    stxdw [r10-0x6d8], r4                   
    ldxdw r1, [r1+0x10]                     
    stxdw [r10-0x6e8], r1                   
    ldxdw r0, [r10-0x850]                   
    add64 r0, 8                                     r0 += 8   ///  r0 = r0.wrapping_add(8 as i32 as i64 as u64)
    ldxdw r1, [r5+0x0]                      
    stxdw [r10-0x728], r1                   
    ldxdw r1, [r3+0x0]                      
    stxdw [r10-0x6f0], r1                   
    ldxdw r1, [r2+0x0]                      
    stxdw [r10-0x6f8], r1                   
    ldxdw r1, [r2+0x8]                      
    stxdw [r10-0x700], r1                   
    ldxdw r1, [r2+0x10]                     
    stxdw [r10-0x708], r1                   
    ldxdw r1, [r2+0x18]                     
    stxdw [r10-0x710], r1                   
    ldxdw r1, [r2+0x20]                     
    stxdw [r10-0x718], r1                   
    ldxdw r1, [r2+0x28]                     
    stxdw [r10-0x720], r1                   
    ldxdw r1, [r2+0x30]                     
    stxdw [r10-0x730], r1                   
    ldxdw r9, [r2+0x38]                     
    ldxdw r8, [r2+0x40]                     
    ldxdw r7, [r2+0x48]                     
    ldxdw r6, [r2+0x50]                     
    ldxdw r1, [r10-0x678]                   
    ldxdw r5, [r1+0x0]                      
    ldxdw r4, [r2+0x58]                     
    ldxdw r1, [r10-0x680]                   
    ldxdw r3, [r1+0x0]                      
    ldxdw r1, [r2+0x60]                     
    stxdw [r10-0x5d8], r0                   
    ldxdw r0, [r10-0x848]                   
    add64 r0, 8                                     r0 += 8   ///  r0 = r0.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x5e8], r0                   
    add64 r1, 8                                     r1 += 8   ///  r1 = r1.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x558], r1                   
    add64 r3, 8                                     r3 += 8   ///  r3 = r3.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x568], r3                   
    add64 r4, 8                                     r4 += 8   ///  r4 = r4.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x578], r4                   
    add64 r5, 8                                     r5 += 8   ///  r5 = r5.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x588], r5                   
    add64 r6, 8                                     r6 += 8   ///  r6 = r6.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x598], r6                   
    add64 r7, 8                                     r7 += 8   ///  r7 = r7.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x5a8], r7                   
    ldxdw r7, [r10-0x728]                   
    add64 r8, 8                                     r8 += 8   ///  r8 = r8.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x5b8], r8                   
    add64 r9, 8                                     r9 += 8   ///  r9 = r9.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x5c8], r9                   
    ldxdw r1, [r10-0x730]                   
    add64 r1, 8                                     r1 += 8   ///  r1 = r1.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x5f8], r1                   
    ldxdw r1, [r10-0x720]                   
    add64 r1, 8                                     r1 += 8   ///  r1 = r1.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x608], r1                   
    ldxdw r1, [r10-0x718]                   
    add64 r1, 8                                     r1 += 8   ///  r1 = r1.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x618], r1                   
    ldxdw r1, [r10-0x710]                   
    add64 r1, 8                                     r1 += 8   ///  r1 = r1.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x628], r1                   
    ldxdw r1, [r10-0x708]                   
    add64 r1, 8                                     r1 += 8   ///  r1 = r1.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x638], r1                   
    ldxdw r1, [r10-0x700]                   
    add64 r1, 8                                     r1 += 8   ///  r1 = r1.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x648], r1                   
    ldxdw r1, [r10-0x6f8]                   
    add64 r1, 8                                     r1 += 8   ///  r1 = r1.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x658], r1                   
    ldxdw r1, [r10-0x6f0]                   
    add64 r1, 8                                     r1 += 8   ///  r1 = r1.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x668], r1                   
    add64 r7, 8                                     r7 += 8   ///  r7 = r7.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x548], r7                   
    sth [r10-0x540], 0                      
    sth [r10-0x550], 0                      
    sth [r10-0x560], 0                      
    sth [r10-0x570], 0                      
    sth [r10-0x580], 0                      
    sth [r10-0x590], 0                      
    sth [r10-0x5a0], 0                      
    sth [r10-0x5b0], 1                      
    sth [r10-0x5c0], 0                      
    sth [r10-0x5d0], 1                      
    sth [r10-0x5e0], 1                      
    sth [r10-0x5f0], 0                      
    sth [r10-0x600], 1                      
    sth [r10-0x610], 1                      
    sth [r10-0x620], 0                      
    sth [r10-0x630], 0                      
    sth [r10-0x640], 0                      
    sth [r10-0x650], 1                      
    sth [r10-0x660], 257                    
    ldxdw r1, [r10-0x6e8]                   
    stxdw [r10-0x530], r1                   
    lddw r1, 0xe7dfba979ddd9c5b                     r1 load str located at -1738465770790347685
    stxdw [r10-0x538], r1                   
    stb [r10-0x528], 0                      
    ldxdw r1, [r10-0x6e0]                   
    stxdw [r10-0x490], r1                   
    mov64 r1, r2                                    r1 = r2
    add64 r1, 96                                    r1 += 96   ///  r1 = r1.wrapping_add(96 as i32 as i64 as u64)
    stxdw [r10-0x498], r1                   
    ldxdw r1, [r10-0x680]                   
    stxdw [r10-0x4a0], r1                   
    mov64 r1, r2                                    r1 = r2
    add64 r1, 88                                    r1 += 88   ///  r1 = r1.wrapping_add(88 as i32 as i64 as u64)
lbb_14870:
    stxdw [r10-0x4a8], r1                   
    ldxdw r1, [r10-0x678]                   
    stxdw [r10-0x4b0], r1                   
    ldxdw r1, [r10-0x6d8]                   
    stxdw [r10-0x4b8], r1                   
    ldxdw r1, [r10-0x6d0]                   
    stxdw [r10-0x4c0], r1                   
    ldxdw r1, [r10-0x6c8]                   
    stxdw [r10-0x4c8], r1                   
    ldxdw r1, [r10-0x6b8]                   
    stxdw [r10-0x4d0], r1                   
    ldxdw r1, [r10-0x840]                   
    stxdw [r10-0x4d8], r1                   
    ldxdw r1, [r10-0x838]                   
    stxdw [r10-0x4e0], r1                   
    ldxdw r1, [r10-0x6b0]                   
    stxdw [r10-0x4e8], r1                   
    ldxdw r1, [r10-0x6a8]                   
    stxdw [r10-0x4f0], r1                   
    ldxdw r1, [r10-0x6a0]                   
    stxdw [r10-0x4f8], r1                   
    ldxdw r1, [r10-0x698]                   
    stxdw [r10-0x500], r1                   
    ldxdw r1, [r10-0x690]                   
    stxdw [r10-0x508], r1                   
    ldxdw r1, [r10-0x688]                   
    stxdw [r10-0x510], r1                   
    stxdw [r10-0x518], r2                   
    ldxdw r1, [r10-0x6c0]                   
    stxdw [r10-0x520], r1                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -96                                   r1 += -96   ///  r1 = r1.wrapping_add(-96 as i32 as i64 as u64)
    stxdw [r10-0x20], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -1160                                 r1 += -1160   ///  r1 = r1.wrapping_add(-1160 as i32 as i64 as u64)
    stxdw [r10-0x28], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -1336                                 r1 += -1336   ///  r1 = r1.wrapping_add(-1336 as i32 as i64 as u64)
    stxdw [r10-0x48], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -1640                                 r1 += -1640   ///  r1 = r1.wrapping_add(-1640 as i32 as i64 as u64)
    stxdw [r10-0x50], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -1160                                 r1 += -1160   ///  r1 = r1.wrapping_add(-1160 as i32 as i64 as u64)
    stxdw [r10-0x58], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -1312                                 r1 += -1312   ///  r1 = r1.wrapping_add(-1312 as i32 as i64 as u64)
    stxdw [r10-0x60], r1                    
    stdw [r10-0x8], 19                      
    stdw [r10-0x10], 19                     
    stdw [r10-0x18], 0                      
    stdw [r10-0x30], 19                     
    stdw [r10-0x38], 19                     
    stdw [r10-0x40], 0                      
    mov64 r1, r10                                   r1 = r10
    add64 r1, -96                                   r1 += -96   ///  r1 = r1.wrapping_add(-96 as i32 as i64 as u64)
    call function_0                         
    mov64 r6, r0                                    r6 = r0
    mov64 r1, r6                                    r1 = r6
    lsh64 r1, 32                                    r1 <<= 32   ///  r1 = r1.wrapping_shl(32)
    rsh64 r1, 32                                    r1 >>= 32   ///  r1 = r1.wrapping_shr(32)
    jne r1, 26, lbb_14949                           if r1 != (26 as i32 as i64 as u64) { pc += 17 }
    mov64 r1, r10                                   r1 = r10
    add64 r1, -1336                                 r1 += -1336   ///  r1 = r1.wrapping_add(-1336 as i32 as i64 as u64)
    stxdw [r10-0x48], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -1640                                 r1 += -1640   ///  r1 = r1.wrapping_add(-1640 as i32 as i64 as u64)
    stxdw [r10-0x58], r1                    
    stxdw [r10-0x60], r7                    
    stdw [r10-0x40], 17                     
    stdw [r10-0x50], 19                     
    mov64 r1, r10                                   r1 = r10
    add64 r1, -96                                   r1 += -96   ///  r1 = r1.wrapping_add(-96 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -1160                                 r2 += -1160   ///  r2 = r2.wrapping_add(-1160 as i32 as i64 as u64)
    mov64 r3, 19                                    r3 = 19 as i32 as i64 as u64
lbb_14946:
    mov64 r4, 8                                     r4 = 8 as i32 as i64 as u64
    mov64 r5, 0                                     r5 = 0 as i32 as i64 as u64
    syscall [invalid]                       
lbb_14949:
    ldxdw r4, [r10-0x670]                   
lbb_14950:
    stxw [r4+0x0], r6                       
    stw [r4+0x4], 1781                      
    exit                                    
lbb_14953:
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
    lddw r3, 0x100027fd0 --> b"\x00\x00\x00\x00\xb8Y\x02\x00\x10\x00\x00\x00\x00\x00\x00\x00v"\x00\x00\x…        r3 load str located at 4295131088
    call function_18489                     
lbb_14958:
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    mov64 r2, 1                                     r2 = 1 as i32 as i64 as u64
    lddw r3, 0x100027fe8 --> b"\x00\x00\x00\x00\xb8Y\x02\x00\x10\x00\x00\x00\x00\x00\x00\x00v"\x00\x00)\…        r3 load str located at 4295131112
    call function_18489                     
lbb_14963:
    mov64 r1, 2                                     r1 = 2 as i32 as i64 as u64
    mov64 r2, 2                                     r2 = 2 as i32 as i64 as u64
    lddw r3, 0x100028000 --> b"\x00\x00\x00\x00\xb8Y\x02\x00\x10\x00\x00\x00\x00\x00\x00\x00v"\x00\x00@\…        r3 load str located at 4295131136
    call function_18489                     
lbb_14968:
    mov64 r1, 3                                     r1 = 3 as i32 as i64 as u64
    mov64 r2, 3                                     r2 = 3 as i32 as i64 as u64
    lddw r3, 0x100028018 --> b"\x00\x00\x00\x00\xb8Y\x02\x00\x10\x00\x00\x00\x00\x00\x00\x00v"\x00\x00W\…        r3 load str located at 4295131160
    call function_18489                     
lbb_14973:
    mov64 r1, 4                                     r1 = 4 as i32 as i64 as u64
    mov64 r2, 4                                     r2 = 4 as i32 as i64 as u64
    lddw r3, 0x100028030 --> b"\x00\x00\x00\x00\xb8Y\x02\x00\x10\x00\x00\x00\x00\x00\x00\x00w"\x00\x00\x…        r3 load str located at 4295131184
    call function_18489                     
lbb_14978:
    mov64 r1, 5                                     r1 = 5 as i32 as i64 as u64
    mov64 r2, 5                                     r2 = 5 as i32 as i64 as u64
    lddw r3, 0x100028048 --> b"\x00\x00\x00\x00\xb8Y\x02\x00\x10\x00\x00\x00\x00\x00\x00\x00w"\x00\x00)\…        r3 load str located at 4295131208
    call function_18489                     
lbb_14983:
    mov64 r1, 6                                     r1 = 6 as i32 as i64 as u64
    mov64 r2, 6                                     r2 = 6 as i32 as i64 as u64
    lddw r3, 0x100028060 --> b"\x00\x00\x00\x00\xb8Y\x02\x00\x10\x00\x00\x00\x00\x00\x00\x00w"\x00\x00@\…        r3 load str located at 4295131232
    call function_18489                     
lbb_14988:
    mov64 r1, 7                                     r1 = 7 as i32 as i64 as u64
    mov64 r2, 7                                     r2 = 7 as i32 as i64 as u64
    lddw r3, 0x100028078 --> b"\x00\x00\x00\x00\xb8Y\x02\x00\x10\x00\x00\x00\x00\x00\x00\x00w"\x00\x00W\…        r3 load str located at 4295131256
    call function_18489                     
lbb_14993:
    mov64 r1, 8                                     r1 = 8 as i32 as i64 as u64
    mov64 r2, 8                                     r2 = 8 as i32 as i64 as u64
    lddw r3, 0x100028090 --> b"\x00\x00\x00\x00\xb8Y\x02\x00\x10\x00\x00\x00\x00\x00\x00\x00x"\x00\x00\x…        r3 load str located at 4295131280
    call function_18489                     
lbb_14998:
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    mov64 r2, 1                                     r2 = 1 as i32 as i64 as u64
    lddw r3, 0x100027b38 --> b"\x00\x00\x00\x00\xb8Y\x02\x00\x10\x00\x00\x00\x00\x00\x00\x00P"\x00\x00)\…        r3 load str located at 4295129912
    call function_18489                     
lbb_15003:
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    mov64 r2, 1                                     r2 = 1 as i32 as i64 as u64
    lddw r3, 0x100027ec8 --> b"\x00\x00\x00\x00\xb8Y\x02\x00\x10\x00\x00\x00\x00\x00\x00\x00c"\x00\x00)\…        r3 load str located at 4295130824
    call function_18489                     
lbb_15008:
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    mov64 r2, 1                                     r2 = 1 as i32 as i64 as u64
    lddw r3, 0x100027d90 --> b"\x00\x00\x00\x00\xb8Y\x02\x00\x10\x00\x00\x00\x00\x00\x00\x00Y"\x00\x00)\…        r3 load str located at 4295130512
    call function_18489                     
lbb_15013:
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    mov64 r2, 1                                     r2 = 1 as i32 as i64 as u64
    lddw r3, 0x100027c58 --> b"\x00\x00\x00\x00\xb8Y\x02\x00\x10\x00\x00\x00\x00\x00\x00\x00l"\x00\x00)\…        r3 load str located at 4295130200
    call function_18489                     
lbb_15018:
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
    lddw r3, 0x100027b20 --> b"\x00\x00\x00\x00\xb8Y\x02\x00\x10\x00\x00\x00\x00\x00\x00\x00P"\x00\x00\x…        r3 load str located at 4295129888
    call function_18489                     
lbb_15023:
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
    lddw r3, 0x100027eb0 --> b"\x00\x00\x00\x00\xb8Y\x02\x00\x10\x00\x00\x00\x00\x00\x00\x00c"\x00\x00\x…        r3 load str located at 4295130800
    call function_18489                     
lbb_15028:
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
    lddw r3, 0x100027d78 --> b"\x00\x00\x00\x00\xb8Y\x02\x00\x10\x00\x00\x00\x00\x00\x00\x00Y"\x00\x00\x…        r3 load str located at 4295130488
    call function_18489                     
lbb_15033:
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
    lddw r3, 0x100027c40 --> b"\x00\x00\x00\x00\xb8Y\x02\x00\x10\x00\x00\x00\x00\x00\x00\x00l"\x00\x00\x…        r3 load str located at 4295130176
    call function_18489                     
lbb_15038:
    mov64 r1, 2                                     r1 = 2 as i32 as i64 as u64
    mov64 r2, 2                                     r2 = 2 as i32 as i64 as u64
    lddw r3, 0x100027b50 --> b"\x00\x00\x00\x00\xb8Y\x02\x00\x10\x00\x00\x00\x00\x00\x00\x00P"\x00\x00@\…        r3 load str located at 4295129936
    call function_18489                     
lbb_15043:
    mov64 r1, 2                                     r1 = 2 as i32 as i64 as u64
    mov64 r2, 2                                     r2 = 2 as i32 as i64 as u64
    lddw r3, 0x100027ee0 --> b"\x00\x00\x00\x00\xb8Y\x02\x00\x10\x00\x00\x00\x00\x00\x00\x00c"\x00\x00@\…        r3 load str located at 4295130848
    call function_18489                     
lbb_15048:
    mov64 r1, 2                                     r1 = 2 as i32 as i64 as u64
    mov64 r2, 2                                     r2 = 2 as i32 as i64 as u64
    lddw r3, 0x100027da8 --> b"\x00\x00\x00\x00\xb8Y\x02\x00\x10\x00\x00\x00\x00\x00\x00\x00Y"\x00\x00@\…        r3 load str located at 4295130536
    call function_18489                     
lbb_15053:
    mov64 r1, 2                                     r1 = 2 as i32 as i64 as u64
    mov64 r2, 2                                     r2 = 2 as i32 as i64 as u64
    lddw r3, 0x100027c70 --> b"\x00\x00\x00\x00\xb8Y\x02\x00\x10\x00\x00\x00\x00\x00\x00\x00l"\x00\x00@\…        r3 load str located at 4295130224
    call function_18489                     
lbb_15058:
    mov64 r1, 3                                     r1 = 3 as i32 as i64 as u64
    mov64 r2, 3                                     r2 = 3 as i32 as i64 as u64
    lddw r3, 0x100027b68 --> b"\x00\x00\x00\x00\xb8Y\x02\x00\x10\x00\x00\x00\x00\x00\x00\x00P"\x00\x00W\…        r3 load str located at 4295129960
    call function_18489                     
lbb_15063:
    mov64 r1, 3                                     r1 = 3 as i32 as i64 as u64
    mov64 r2, 3                                     r2 = 3 as i32 as i64 as u64
    lddw r3, 0x100027ef8 --> b"\x00\x00\x00\x00\xb8Y\x02\x00\x10\x00\x00\x00\x00\x00\x00\x00c"\x00\x00W\…        r3 load str located at 4295130872
    call function_18489                     
lbb_15068:
    mov64 r1, 3                                     r1 = 3 as i32 as i64 as u64
    mov64 r2, 3                                     r2 = 3 as i32 as i64 as u64
    lddw r3, 0x100027dc0 --> b"\x00\x00\x00\x00\xb8Y\x02\x00\x10\x00\x00\x00\x00\x00\x00\x00Y"\x00\x00W\…        r3 load str located at 4295130560
    call function_18489                     
lbb_15073:
    mov64 r1, 3                                     r1 = 3 as i32 as i64 as u64
    mov64 r2, 3                                     r2 = 3 as i32 as i64 as u64
    lddw r3, 0x100027c88 --> b"\x00\x00\x00\x00\xb8Y\x02\x00\x10\x00\x00\x00\x00\x00\x00\x00l"\x00\x00W\…        r3 load str located at 4295130248
    call function_18489                     
lbb_15078:
    mov64 r1, 4                                     r1 = 4 as i32 as i64 as u64
    mov64 r2, 4                                     r2 = 4 as i32 as i64 as u64
    lddw r3, 0x100027b80 --> b"\x00\x00\x00\x00\xb8Y\x02\x00\x10\x00\x00\x00\x00\x00\x00\x00Q"\x00\x00\x…        r3 load str located at 4295129984
    call function_18489                     
lbb_15083:
    mov64 r1, 4                                     r1 = 4 as i32 as i64 as u64
    mov64 r2, 4                                     r2 = 4 as i32 as i64 as u64
    lddw r3, 0x100027f10 --> b"\x00\x00\x00\x00\xb8Y\x02\x00\x10\x00\x00\x00\x00\x00\x00\x00d"\x00\x00\x…        r3 load str located at 4295130896
    call function_18489                     
lbb_15088:
    mov64 r1, 4                                     r1 = 4 as i32 as i64 as u64
    mov64 r2, 4                                     r2 = 4 as i32 as i64 as u64
    lddw r3, 0x100027dd8 --> b"\x00\x00\x00\x00\xb8Y\x02\x00\x10\x00\x00\x00\x00\x00\x00\x00Z"\x00\x00\x…        r3 load str located at 4295130584
    call function_18489                     
lbb_15093:
    mov64 r1, 4                                     r1 = 4 as i32 as i64 as u64
    mov64 r2, 4                                     r2 = 4 as i32 as i64 as u64
    lddw r3, 0x100027ca0 --> b"\x00\x00\x00\x00\xb8Y\x02\x00\x10\x00\x00\x00\x00\x00\x00\x00m"\x00\x00\x…        r3 load str located at 4295130272
    call function_18489                     
lbb_15098:
    mov64 r1, 5                                     r1 = 5 as i32 as i64 as u64
    mov64 r2, 5                                     r2 = 5 as i32 as i64 as u64
    lddw r3, 0x100027b98 --> b"\x00\x00\x00\x00\xb8Y\x02\x00\x10\x00\x00\x00\x00\x00\x00\x00Q"\x00\x00)\…        r3 load str located at 4295130008
    call function_18489                     
lbb_15103:
    mov64 r1, 5                                     r1 = 5 as i32 as i64 as u64
    mov64 r2, 5                                     r2 = 5 as i32 as i64 as u64
    lddw r3, 0x100027f28 --> b"\x00\x00\x00\x00\xb8Y\x02\x00\x10\x00\x00\x00\x00\x00\x00\x00d"\x00\x00)\…        r3 load str located at 4295130920
    call function_18489                     
lbb_15108:
    mov64 r1, 5                                     r1 = 5 as i32 as i64 as u64
    mov64 r2, 5                                     r2 = 5 as i32 as i64 as u64
    lddw r3, 0x100027df0 --> b"\x00\x00\x00\x00\xb8Y\x02\x00\x10\x00\x00\x00\x00\x00\x00\x00Z"\x00\x00)\…        r3 load str located at 4295130608
    call function_18489                     
lbb_15113:
    mov64 r1, 5                                     r1 = 5 as i32 as i64 as u64
    mov64 r2, 5                                     r2 = 5 as i32 as i64 as u64
    lddw r3, 0x100027cb8 --> b"\x00\x00\x00\x00\xb8Y\x02\x00\x10\x00\x00\x00\x00\x00\x00\x00m"\x00\x00)\…        r3 load str located at 4295130296
    call function_18489                     
lbb_15118:
    mov64 r1, 6                                     r1 = 6 as i32 as i64 as u64
    mov64 r2, 6                                     r2 = 6 as i32 as i64 as u64
    lddw r3, 0x100027bb0 --> b"\x00\x00\x00\x00\xb8Y\x02\x00\x10\x00\x00\x00\x00\x00\x00\x00Q"\x00\x00@\…        r3 load str located at 4295130032
    call function_18489                     
lbb_15123:
    mov64 r1, 6                                     r1 = 6 as i32 as i64 as u64
    mov64 r2, 6                                     r2 = 6 as i32 as i64 as u64
    lddw r3, 0x100027f40 --> b"\x00\x00\x00\x00\xb8Y\x02\x00\x10\x00\x00\x00\x00\x00\x00\x00d"\x00\x00@\…        r3 load str located at 4295130944
    call function_18489                     
lbb_15128:
    mov64 r1, 6                                     r1 = 6 as i32 as i64 as u64
    mov64 r2, 6                                     r2 = 6 as i32 as i64 as u64
    lddw r3, 0x100027e08 --> b"\x00\x00\x00\x00\xb8Y\x02\x00\x10\x00\x00\x00\x00\x00\x00\x00Z"\x00\x00@\…        r3 load str located at 4295130632
    call function_18489                     
lbb_15133:
    mov64 r1, 6                                     r1 = 6 as i32 as i64 as u64
    mov64 r2, 6                                     r2 = 6 as i32 as i64 as u64
    lddw r3, 0x100027cd0 --> b"\x00\x00\x00\x00\xb8Y\x02\x00\x10\x00\x00\x00\x00\x00\x00\x00m"\x00\x00@\…        r3 load str located at 4295130320
    call function_18489                     
lbb_15138:
    mov64 r1, 7                                     r1 = 7 as i32 as i64 as u64
    mov64 r2, 7                                     r2 = 7 as i32 as i64 as u64
    lddw r3, 0x100027bc8 --> b"\x00\x00\x00\x00\xb8Y\x02\x00\x10\x00\x00\x00\x00\x00\x00\x00Q"\x00\x00W\…        r3 load str located at 4295130056
    call function_18489                     
lbb_15143:
    mov64 r1, 7                                     r1 = 7 as i32 as i64 as u64
    mov64 r2, 7                                     r2 = 7 as i32 as i64 as u64
    lddw r3, 0x100027f58 --> b"\x00\x00\x00\x00\xb8Y\x02\x00\x10\x00\x00\x00\x00\x00\x00\x00d"\x00\x00W\…        r3 load str located at 4295130968
    call function_18489                     
lbb_15148:
    mov64 r1, 7                                     r1 = 7 as i32 as i64 as u64
    mov64 r2, 7                                     r2 = 7 as i32 as i64 as u64
    lddw r3, 0x100027e20 --> b"\x00\x00\x00\x00\xb8Y\x02\x00\x10\x00\x00\x00\x00\x00\x00\x00Z"\x00\x00W\…        r3 load str located at 4295130656
    call function_18489                     
lbb_15153:
    mov64 r1, 7                                     r1 = 7 as i32 as i64 as u64
    mov64 r2, 7                                     r2 = 7 as i32 as i64 as u64
    lddw r3, 0x100027ce8 --> b"\x00\x00\x00\x00\xb8Y\x02\x00\x10\x00\x00\x00\x00\x00\x00\x00m"\x00\x00W\…        r3 load str located at 4295130344
    call function_18489                     
lbb_15158:
    mov64 r1, 8                                     r1 = 8 as i32 as i64 as u64
    mov64 r2, 8                                     r2 = 8 as i32 as i64 as u64
    lddw r3, 0x100027be0 --> b"\x00\x00\x00\x00\xb8Y\x02\x00\x10\x00\x00\x00\x00\x00\x00\x00R"\x00\x00\x…        r3 load str located at 4295130080
    call function_18489                     
lbb_15163:
    mov64 r1, 8                                     r1 = 8 as i32 as i64 as u64
    mov64 r2, 8                                     r2 = 8 as i32 as i64 as u64
    lddw r3, 0x100027f70 --> b"\x00\x00\x00\x00\xb8Y\x02\x00\x10\x00\x00\x00\x00\x00\x00\x00e"\x00\x00\x…        r3 load str located at 4295130992
    call function_18489                     
lbb_15168:
    mov64 r1, 8                                     r1 = 8 as i32 as i64 as u64
    mov64 r2, 8                                     r2 = 8 as i32 as i64 as u64
    lddw r3, 0x100027e38 --> b"\x00\x00\x00\x00\xb8Y\x02\x00\x10\x00\x00\x00\x00\x00\x00\x00["\x00\x00\x…        r3 load str located at 4295130680
    call function_18489                     
lbb_15173:
    mov64 r1, 8                                     r1 = 8 as i32 as i64 as u64
    mov64 r2, 8                                     r2 = 8 as i32 as i64 as u64
    lddw r3, 0x100027d00 --> b"\x00\x00\x00\x00\xb8Y\x02\x00\x10\x00\x00\x00\x00\x00\x00\x00n"\x00\x00\x…        r3 load str located at 4295130368
    call function_18489                     
lbb_15178:
    mov64 r1, 9                                     r1 = 9 as i32 as i64 as u64
    mov64 r2, 9                                     r2 = 9 as i32 as i64 as u64
    lddw r3, 0x100027bf8 --> b"\x00\x00\x00\x00\xb8Y\x02\x00\x10\x00\x00\x00\x00\x00\x00\x00R"\x00\x00)\…        r3 load str located at 4295130104
    call function_18489                     
lbb_15183:
    mov64 r1, 9                                     r1 = 9 as i32 as i64 as u64
    mov64 r2, 9                                     r2 = 9 as i32 as i64 as u64
    lddw r3, 0x100027f88 --> b"\x00\x00\x00\x00\xb8Y\x02\x00\x10\x00\x00\x00\x00\x00\x00\x00e"\x00\x00)\…        r3 load str located at 4295131016
    call function_18489                     
lbb_15188:
    mov64 r1, 9                                     r1 = 9 as i32 as i64 as u64
    mov64 r2, 9                                     r2 = 9 as i32 as i64 as u64
    lddw r3, 0x100027e50 --> b"\x00\x00\x00\x00\xb8Y\x02\x00\x10\x00\x00\x00\x00\x00\x00\x00["\x00\x00)\…        r3 load str located at 4295130704
    call function_18489                     
lbb_15193:
    mov64 r1, 9                                     r1 = 9 as i32 as i64 as u64
    mov64 r2, 9                                     r2 = 9 as i32 as i64 as u64
    lddw r3, 0x100027d18 --> b"\x00\x00\x00\x00\xb8Y\x02\x00\x10\x00\x00\x00\x00\x00\x00\x00n"\x00\x00)\…        r3 load str located at 4295130392
    call function_18489                     
lbb_15198:
    mov64 r1, 10                                    r1 = 10 as i32 as i64 as u64
    mov64 r2, 10                                    r2 = 10 as i32 as i64 as u64
    lddw r3, 0x100027c10 --> b"\x00\x00\x00\x00\xb8Y\x02\x00\x10\x00\x00\x00\x00\x00\x00\x00R"\x00\x00@\…        r3 load str located at 4295130128
    call function_18489                     
lbb_15203:
    mov64 r1, 10                                    r1 = 10 as i32 as i64 as u64
    mov64 r2, 10                                    r2 = 10 as i32 as i64 as u64
    lddw r3, 0x100027fa0 --> b"\x00\x00\x00\x00\xb8Y\x02\x00\x10\x00\x00\x00\x00\x00\x00\x00e"\x00\x00@\…        r3 load str located at 4295131040
    call function_18489                     
lbb_15208:
    mov64 r1, 10                                    r1 = 10 as i32 as i64 as u64
    mov64 r2, 10                                    r2 = 10 as i32 as i64 as u64
    lddw r3, 0x100027e68 --> b"\x00\x00\x00\x00\xb8Y\x02\x00\x10\x00\x00\x00\x00\x00\x00\x00["\x00\x00@\…        r3 load str located at 4295130728
    call function_18489                     
lbb_15213:
    mov64 r1, 10                                    r1 = 10 as i32 as i64 as u64
    mov64 r2, 10                                    r2 = 10 as i32 as i64 as u64
    lddw r3, 0x100027d30 --> b"\x00\x00\x00\x00\xb8Y\x02\x00\x10\x00\x00\x00\x00\x00\x00\x00n"\x00\x00@\…        r3 load str located at 4295130416
    call function_18489                     
lbb_15218:
    mov64 r1, 11                                    r1 = 11 as i32 as i64 as u64
    mov64 r2, 11                                    r2 = 11 as i32 as i64 as u64
    lddw r3, 0x100027c28 --> b"\x00\x00\x00\x00\xb8Y\x02\x00\x10\x00\x00\x00\x00\x00\x00\x00R"\x00\x00X\…        r3 load str located at 4295130152
    call function_18489                     
lbb_15223:
    mov64 r1, 11                                    r1 = 11 as i32 as i64 as u64
    mov64 r2, 11                                    r2 = 11 as i32 as i64 as u64
    lddw r3, 0x100027fb8 --> b"\x00\x00\x00\x00\xb8Y\x02\x00\x10\x00\x00\x00\x00\x00\x00\x00e"\x00\x00X\…        r3 load str located at 4295131064
    call function_18489                     
lbb_15228:
    mov64 r1, 11                                    r1 = 11 as i32 as i64 as u64
    mov64 r2, 11                                    r2 = 11 as i32 as i64 as u64
    lddw r3, 0x100027e80 --> b"\x00\x00\x00\x00\xb8Y\x02\x00\x10\x00\x00\x00\x00\x00\x00\x00["\x00\x00X\…        r3 load str located at 4295130752
    call function_18489                     
lbb_15233:
    mov64 r1, 11                                    r1 = 11 as i32 as i64 as u64
    mov64 r2, 11                                    r2 = 11 as i32 as i64 as u64
    lddw r3, 0x100027d48 --> b"\x00\x00\x00\x00\xb8Y\x02\x00\x10\x00\x00\x00\x00\x00\x00\x00n"\x00\x00X\…        r3 load str located at 4295130440
    call function_18489                     
lbb_15238:
    mov64 r1, 12                                    r1 = 12 as i32 as i64 as u64
    mov64 r2, 12                                    r2 = 12 as i32 as i64 as u64
    lddw r3, 0x100027e98 --> b"\x00\x00\x00\x00\xb8Y\x02\x00\x10\x00\x00\x00\x00\x00\x00\x00\"\x00\x00\x…        r3 load str located at 4295130776
    call function_18489                     
lbb_15243:
    mov64 r1, 12                                    r1 = 12 as i32 as i64 as u64
    mov64 r2, 12                                    r2 = 12 as i32 as i64 as u64
    lddw r3, 0x100027d60 --> b"\x00\x00\x00\x00\xb8Y\x02\x00\x10\x00\x00\x00\x00\x00\x00\x00o"\x00\x00\x…        r3 load str located at 4295130464
    call function_18489                     

entrypoint:
    mov64 r8, r1                                    r8 = r1
    add64 r8, 8                                     r8 += 8   ///  r8 = r8.wrapping_add(8 as i32 as i64 as u64)
    ldxdw r2, [r1+0x0]                      
    jeq r2, 0, lbb_15267                            if r2 == (0 as i32 as i64 as u64) { pc += 15 }
    stxdw [r10-0xa40], r8                   
    ldxdw r3, [r1+0x58]                     
    mov64 r8, r1                                    r8 = r1
    add64 r8, r3                                    r8 += r3   ///  r8 = r8.wrapping_add(r3)
    add64 r8, 10351                                 r8 += 10351   ///  r8 = r8.wrapping_add(10351 as i32 as i64 as u64)
    and64 r8, -8                                    r8 &= -8   ///  r8 = r8.and(-8)
    jeq r2, 1, lbb_15267                            if r2 == (1 as i32 as i64 as u64) { pc += 8 }
    jne r2, 2, lbb_15354                            if r2 != (2 as i32 as i64 as u64) { pc += 94 }
    ldxb r3, [r8+0x0]                       
    jne r3, 255, lbb_18029                          if r3 != (255 as i32 as i64 as u64) { pc += 2767 }
    stxdw [r10-0xa38], r8                   
lbb_15263:
    ldxdw r3, [r8+0x50]                     
    add64 r8, r3                                    r8 += r3   ///  r8 = r8.wrapping_add(r3)
    add64 r8, 10343                                 r8 += 10343   ///  r8 = r8.wrapping_add(10343 as i32 as i64 as u64)
    and64 r8, -8                                    r8 &= -8   ///  r8 = r8.and(-8)
lbb_15267:
    ldxdw r3, [r8+0x0]                      
    jeq r3, 0, lbb_18150                            if r3 == (0 as i32 as i64 as u64) { pc += 2881 }
    ldxb r4, [r8+0x8]                       
    jsle r4, 3, lbb_15293                           if (r4 as i64) <= (3 as i32 as i64) { pc += 22 }
    jsle r4, 5, lbb_15334                           if (r4 as i64) <= (5 as i32 as i64) { pc += 62 }
    jeq r4, 6, lbb_15636                            if r4 == (6 as i32 as i64 as u64) { pc += 363 }
    jeq r4, 7, lbb_15672                            if r4 == (7 as i32 as i64 as u64) { pc += 398 }
    jne r4, 8, lbb_18150                            if r4 != (8 as i32 as i64 as u64) { pc += 2875 }
    jlt r2, 8, lbb_18134                            if r2 < (8 as i32 as i64 as u64) { pc += 2858 }
    ldxdw r2, [r1+0x10]                     
    lddw r3, 0xca896837f7826fd2                     r3 load str located at -3852433416653738030
    jne r2, r3, lbb_17063                           if r2 != r3 { pc += 1783 }
    ldxdw r2, [r1+0x18]                     
    lddw r3, 0x88adfc86574fea83                     r3 load str located at -8597938459659736445
    jne r2, r3, lbb_17643                           if r2 != r3 { pc += 2359 }
    ldxdw r2, [r1+0x20]                     
    lddw r3, 0x384d82dd1cab4e18                     r3 load str located at 4057042725511056920
    jne r2, r3, lbb_17643                           if r2 != r3 { pc += 2355 }
    ldxdw r1, [r1+0x28]                     
    lddw r2, 0x54a5fa76c74e4713                     r2 load str located at 6099556658400085779
    jeq r1, r2, lbb_17078                           if r1 == r2 { pc += 1786 }
    ja lbb_17643                                    if true { pc += 2350 }
lbb_15293:
    jsgt r4, 1, lbb_15314                           if (r4 as i64) > (1 as i32 as i64) { pc += 20 }
    jeq r4, 0, lbb_15467                            if r4 == (0 as i32 as i64 as u64) { pc += 172 }
    jne r4, 1, lbb_18150                            if r4 != (1 as i32 as i64 as u64) { pc += 2854 }
    jlt r2, 9, lbb_18134                            if r2 < (9 as i32 as i64 as u64) { pc += 2837 }
    ldxdw r4, [r1+0x10]                     
    lddw r5, 0xca896837f7826fd2                     r5 load str located at -3852433416653738030
    jne r4, r5, lbb_16062                           if r4 != r5 { pc += 761 }
    ldxdw r4, [r1+0x18]                     
    lddw r5, 0x88adfc86574fea83                     r5 load str located at -8597938459659736445
    jne r4, r5, lbb_17643                           if r4 != r5 { pc += 2338 }
    ldxdw r4, [r1+0x20]                     
    lddw r5, 0x384d82dd1cab4e18                     r5 load str located at 4057042725511056920
    jne r4, r5, lbb_17643                           if r4 != r5 { pc += 2334 }
    ldxdw r1, [r1+0x28]                     
    lddw r4, 0x54a5fa76c74e4713                     r4 load str located at 6099556658400085779
    jeq r1, r4, lbb_16077                           if r1 == r4 { pc += 764 }
    ja lbb_17643                                    if true { pc += 2329 }
lbb_15314:
    jeq r4, 2, lbb_15485                            if r4 == (2 as i32 as i64 as u64) { pc += 170 }
    jne r4, 3, lbb_18150                            if r4 != (3 as i32 as i64 as u64) { pc += 2834 }
    jlt r2, 9, lbb_18134                            if r2 < (9 as i32 as i64 as u64) { pc += 2817 }
    ldxdw r3, [r1+0x10]                     
    lddw r4, 0xca896837f7826fd2                     r4 load str located at -3852433416653738030
    jne r3, r4, lbb_16455                           if r3 != r4 { pc += 1134 }
    ldxdw r3, [r1+0x18]                     
    lddw r4, 0x88adfc86574fea83                     r4 load str located at -8597938459659736445
    jne r3, r4, lbb_17643                           if r3 != r4 { pc += 2318 }
    ldxdw r3, [r1+0x20]                     
    lddw r4, 0x384d82dd1cab4e18                     r4 load str located at 4057042725511056920
    jne r3, r4, lbb_17643                           if r3 != r4 { pc += 2314 }
    ldxdw r3, [r1+0x28]                     
    lddw r4, 0x54a5fa76c74e4713                     r4 load str located at 6099556658400085779
    jeq r3, r4, lbb_16470                           if r3 == r4 { pc += 1137 }
    ja lbb_17643                                    if true { pc += 2309 }
lbb_15334:
    jeq r4, 4, lbb_15654                            if r4 == (4 as i32 as i64 as u64) { pc += 319 }
    jne r4, 5, lbb_18150                            if r4 != (5 as i32 as i64 as u64) { pc += 2814 }
    jne r2, 3, lbb_18134                            if r2 != (3 as i32 as i64 as u64) { pc += 2797 }
    ldxdw r3, [r1+0x10]                     
    lddw r4, 0xca896837f7826fd2                     r4 load str located at -3852433416653738030
    jne r3, r4, lbb_16663                           if r3 != r4 { pc += 1322 }
    ldxdw r3, [r1+0x18]                     
    lddw r4, 0x88adfc86574fea83                     r4 load str located at -8597938459659736445
    jne r3, r4, lbb_17643                           if r3 != r4 { pc += 2298 }
    ldxdw r3, [r1+0x20]                     
    lddw r4, 0x384d82dd1cab4e18                     r4 load str located at 4057042725511056920
    jne r3, r4, lbb_17643                           if r3 != r4 { pc += 2294 }
    ldxdw r1, [r1+0x28]                     
    lddw r3, 0x54a5fa76c74e4713                     r3 load str located at 6099556658400085779
    jeq r1, r3, lbb_16678                           if r1 == r3 { pc += 1325 }
    ja lbb_17643                                    if true { pc += 2289 }
lbb_15354:
    mov64 r3, r10                                   r3 = r10
    add64 r3, -2624                                 r3 += -2624   ///  r3 = r3.wrapping_add(-2624 as i32 as i64 as u64)
    mov64 r4, r2                                    r4 = r2
    jlt r2, 6, lbb_15446                            if r2 < (6 as i32 as i64 as u64) { pc += 88 }
    mov64 r3, r10                                   r3 = r10
    add64 r3, -2624                                 r3 += -2624   ///  r3 = r3.wrapping_add(-2624 as i32 as i64 as u64)
    mov64 r4, r2                                    r4 = r2
lbb_15361:
    ldxb r5, [r8+0x0]                       
    jne r5, 255, lbb_15400                          if r5 != (255 as i32 as i64 as u64) { pc += 37 }
    stxdw [r3+0x8], r8                      
    ldxdw r5, [r8+0x50]                     
    add64 r8, r5                                    r8 += r5   ///  r8 = r8.wrapping_add(r5)
    add64 r8, 10343                                 r8 += 10343   ///  r8 = r8.wrapping_add(10343 as i32 as i64 as u64)
    and64 r8, -8                                    r8 &= -8   ///  r8 = r8.and(-8)
    ldxb r5, [r8+0x0]                       
    jne r5, 255, lbb_15409                          if r5 != (255 as i32 as i64 as u64) { pc += 39 }
lbb_15370:
    stxdw [r3+0x10], r8                     
    ldxdw r5, [r8+0x50]                     
    add64 r8, r5                                    r8 += r5   ///  r8 = r8.wrapping_add(r5)
    add64 r8, 10343                                 r8 += 10343   ///  r8 = r8.wrapping_add(10343 as i32 as i64 as u64)
    and64 r8, -8                                    r8 &= -8   ///  r8 = r8.and(-8)
    ldxb r5, [r8+0x0]                       
    jne r5, 255, lbb_15418                          if r5 != (255 as i32 as i64 as u64) { pc += 41 }
lbb_15377:
    stxdw [r3+0x18], r8                     
    ldxdw r5, [r8+0x50]                     
    add64 r8, r5                                    r8 += r5   ///  r8 = r8.wrapping_add(r5)
    add64 r8, 10343                                 r8 += 10343   ///  r8 = r8.wrapping_add(10343 as i32 as i64 as u64)
    and64 r8, -8                                    r8 &= -8   ///  r8 = r8.and(-8)
    ldxb r5, [r8+0x0]                       
    jne r5, 255, lbb_15427                          if r5 != (255 as i32 as i64 as u64) { pc += 43 }
lbb_15384:
    stxdw [r3+0x20], r8                     
    ldxdw r5, [r8+0x50]                     
    add64 r8, r5                                    r8 += r5   ///  r8 = r8.wrapping_add(r5)
    add64 r8, 10343                                 r8 += 10343   ///  r8 = r8.wrapping_add(10343 as i32 as i64 as u64)
    and64 r8, -8                                    r8 &= -8   ///  r8 = r8.and(-8)
    add64 r3, 40                                    r3 += 40   ///  r3 = r3.wrapping_add(40 as i32 as i64 as u64)
    ldxb r5, [r8+0x0]                       
    jne r5, 255, lbb_15437                          if r5 != (255 as i32 as i64 as u64) { pc += 45 }
lbb_15392:
    stxdw [r3+0x0], r8                      
    ldxdw r5, [r8+0x50]                     
    add64 r8, r5                                    r8 += r5   ///  r8 = r8.wrapping_add(r5)
    add64 r8, 10343                                 r8 += 10343   ///  r8 = r8.wrapping_add(10343 as i32 as i64 as u64)
    and64 r8, -8                                    r8 &= -8   ///  r8 = r8.and(-8)
    add64 r4, -5                                    r4 += -5   ///  r4 = r4.wrapping_add(-5 as i32 as i64 as u64)
    jgt r4, 5, lbb_15361                            if r4 > (5 as i32 as i64 as u64) { pc += -38 }
    ja lbb_15446                                    if true { pc += 46 }
lbb_15400:
    lsh64 r5, 3                                     r5 <<= 3   ///  r5 = r5.wrapping_shl(3)
    mov64 r0, r10                                   r0 = r10
    add64 r0, -2624                                 r0 += -2624   ///  r0 = r0.wrapping_add(-2624 as i32 as i64 as u64)
    add64 r0, r5                                    r0 += r5   ///  r0 = r0.wrapping_add(r5)
    ldxdw r5, [r0+0x0]                      
    stxdw [r3+0x8], r5                      
    add64 r8, 8                                     r8 += 8   ///  r8 = r8.wrapping_add(8 as i32 as i64 as u64)
    ldxb r5, [r8+0x0]                       
    jeq r5, 255, lbb_15370                          if r5 == (255 as i32 as i64 as u64) { pc += -39 }
lbb_15409:
    lsh64 r5, 3                                     r5 <<= 3   ///  r5 = r5.wrapping_shl(3)
    mov64 r0, r10                                   r0 = r10
    add64 r0, -2624                                 r0 += -2624   ///  r0 = r0.wrapping_add(-2624 as i32 as i64 as u64)
    add64 r0, r5                                    r0 += r5   ///  r0 = r0.wrapping_add(r5)
    ldxdw r5, [r0+0x0]                      
    stxdw [r3+0x10], r5                     
    add64 r8, 8                                     r8 += 8   ///  r8 = r8.wrapping_add(8 as i32 as i64 as u64)
    ldxb r5, [r8+0x0]                       
    jeq r5, 255, lbb_15377                          if r5 == (255 as i32 as i64 as u64) { pc += -41 }
lbb_15418:
    lsh64 r5, 3                                     r5 <<= 3   ///  r5 = r5.wrapping_shl(3)
    mov64 r0, r10                                   r0 = r10
    add64 r0, -2624                                 r0 += -2624   ///  r0 = r0.wrapping_add(-2624 as i32 as i64 as u64)
    add64 r0, r5                                    r0 += r5   ///  r0 = r0.wrapping_add(r5)
    ldxdw r5, [r0+0x0]                      
    stxdw [r3+0x18], r5                     
    add64 r8, 8                                     r8 += 8   ///  r8 = r8.wrapping_add(8 as i32 as i64 as u64)
    ldxb r5, [r8+0x0]                       
    jeq r5, 255, lbb_15384                          if r5 == (255 as i32 as i64 as u64) { pc += -43 }
lbb_15427:
    lsh64 r5, 3                                     r5 <<= 3   ///  r5 = r5.wrapping_shl(3)
    mov64 r0, r10                                   r0 = r10
    add64 r0, -2624                                 r0 += -2624   ///  r0 = r0.wrapping_add(-2624 as i32 as i64 as u64)
    add64 r0, r5                                    r0 += r5   ///  r0 = r0.wrapping_add(r5)
    ldxdw r5, [r0+0x0]                      
    stxdw [r3+0x20], r5                     
    add64 r8, 8                                     r8 += 8   ///  r8 = r8.wrapping_add(8 as i32 as i64 as u64)
    add64 r3, 40                                    r3 += 40   ///  r3 = r3.wrapping_add(40 as i32 as i64 as u64)
    ldxb r5, [r8+0x0]                       
    jeq r5, 255, lbb_15392                          if r5 == (255 as i32 as i64 as u64) { pc += -45 }
lbb_15437:
    lsh64 r5, 3                                     r5 <<= 3   ///  r5 = r5.wrapping_shl(3)
    mov64 r0, r10                                   r0 = r10
    add64 r0, -2624                                 r0 += -2624   ///  r0 = r0.wrapping_add(-2624 as i32 as i64 as u64)
    add64 r0, r5                                    r0 += r5   ///  r0 = r0.wrapping_add(r5)
    ldxdw r5, [r0+0x0]                      
    stxdw [r3+0x0], r5                      
    add64 r8, 8                                     r8 += 8   ///  r8 = r8.wrapping_add(8 as i32 as i64 as u64)
    add64 r4, -5                                    r4 += -5   ///  r4 = r4.wrapping_add(-5 as i32 as i64 as u64)
    jgt r4, 5, lbb_15361                            if r4 > (5 as i32 as i64 as u64) { pc += -85 }
lbb_15446:
    jsle r4, 2, lbb_15690                           if (r4 as i64) <= (2 as i32 as i64) { pc += 243 }
    jeq r4, 3, lbb_15695                            if r4 == (3 as i32 as i64 as u64) { pc += 247 }
    jne r4, 4, lbb_15706                            if r4 != (4 as i32 as i64 as u64) { pc += 257 }
    ldxb r4, [r8+0x0]                       
    jne r4, 255, lbb_18262                          if r4 != (255 as i32 as i64 as u64) { pc += 2811 }
    stxdw [r3+0x8], r8                      
    ldxdw r4, [r8+0x50]                     
    add64 r8, r4                                    r8 += r4   ///  r8 = r8.wrapping_add(r4)
    add64 r8, 10343                                 r8 += 10343   ///  r8 = r8.wrapping_add(10343 as i32 as i64 as u64)
    and64 r8, -8                                    r8 &= -8   ///  r8 = r8.and(-8)
    ldxb r4, [r8+0x0]                       
    jne r4, 255, lbb_18271                          if r4 != (255 as i32 as i64 as u64) { pc += 2813 }
lbb_15458:
    stxdw [r3+0x10], r8                     
    ldxdw r4, [r8+0x50]                     
    add64 r8, r4                                    r8 += r4   ///  r8 = r8.wrapping_add(r4)
    add64 r8, 10343                                 r8 += 10343   ///  r8 = r8.wrapping_add(10343 as i32 as i64 as u64)
    and64 r8, -8                                    r8 &= -8   ///  r8 = r8.and(-8)
    ldxb r4, [r8+0x0]                       
    jne r4, 255, lbb_18280                          if r4 != (255 as i32 as i64 as u64) { pc += 2815 }
lbb_15465:
    stxdw [r3+0x18], r8                     
    ja lbb_15263                                    if true { pc += -204 }
lbb_15467:
    jlt r2, 8, lbb_18134                            if r2 < (8 as i32 as i64 as u64) { pc += 2666 }
    ldxdw r4, [r1+0x10]                     
    lddw r5, 0xca896837f7826fd2                     r5 load str located at -3852433416653738030
    jne r4, r5, lbb_16711                           if r4 != r5 { pc += 1239 }
    ldxdw r4, [r1+0x18]                     
    lddw r5, 0x88adfc86574fea83                     r5 load str located at -8597938459659736445
    jne r4, r5, lbb_17643                           if r4 != r5 { pc += 2167 }
    ldxdw r4, [r1+0x20]                     
    lddw r5, 0x384d82dd1cab4e18                     r5 load str located at 4057042725511056920
    jne r4, r5, lbb_17643                           if r4 != r5 { pc += 2163 }
    ldxdw r1, [r1+0x28]                     
    lddw r4, 0x54a5fa76c74e4713                     r4 load str located at 6099556658400085779
    jeq r1, r4, lbb_16726                           if r1 == r4 { pc += 1242 }
    ja lbb_17643                                    if true { pc += 2158 }
lbb_15485:
    jeq r2, 0, lbb_18346                            if r2 == (0 as i32 as i64 as u64) { pc += 2860 }
    mov64 r6, r1                                    r6 = r1
    add64 r6, 16                                    r6 += 16   ///  r6 = r6.wrapping_add(16 as i32 as i64 as u64)
    ldxdw r3, [r1+0x10]                     
    lddw r4, 0xca896837f7826fd2                     r4 load str located at -3852433416653738030
    jne r3, r4, lbb_15505                           if r3 != r4 { pc += 13 }
    ldxdw r3, [r6+0x8]                      
    lddw r4, 0x88adfc86574fea83                     r4 load str located at -8597938459659736445
    jne r3, r4, lbb_15505                           if r3 != r4 { pc += 9 }
    ldxdw r3, [r6+0x10]                     
    lddw r4, 0x384d82dd1cab4e18                     r4 load str located at 4057042725511056920
    jne r3, r4, lbb_15505                           if r3 != r4 { pc += 5 }
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
    ldxdw r4, [r6+0x18]                     
    lddw r5, 0x54a5fa76c74e4713                     r5 load str located at 6099556658400085779
    jeq r4, r5, lbb_15506                           if r4 == r5 { pc += 1 }
lbb_15505:
    mov64 r3, 1                                     r3 = 1 as i32 as i64 as u64
lbb_15506:
    jeq r3, 0, lbb_15526                            if r3 == (0 as i32 as i64 as u64) { pc += 19 }
    ldxdw r3, [r6+0x0]                      
    lddw r4, 0x4cfbdb8200836fd2                     r4 load str located at 5547268717437743058
    jne r3, r4, lbb_15524                           if r3 != r4 { pc += 13 }
    ldxdw r3, [r6+0x8]                      
    lddw r4, 0x33559cb08794b05b                     r4 load str located at 3699034950957576283
    jne r3, r4, lbb_15524                           if r3 != r4 { pc += 9 }
    ldxdw r3, [r6+0x10]                     
    lddw r4, 0xa2e8696d479bf0b2                     r4 load str located at -6707995726894600014
    jne r3, r4, lbb_15524                           if r3 != r4 { pc += 5 }
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
    ldxdw r4, [r6+0x18]                     
    lddw r5, 0xb50d9a20d7d2fe4c                     r5 load str located at -5400490912296796596
    jeq r4, r5, lbb_15525                           if r4 == r5 { pc += 1 }
lbb_15524:
    mov64 r3, 1                                     r3 = 1 as i32 as i64 as u64
lbb_15525:
    jne r3, 0, lbb_17643                            if r3 != (0 as i32 as i64 as u64) { pc += 2117 }
lbb_15526:
    ldxb r9, [r8+0x9]                       
    mov64 r3, r9                                    r3 = r9
    lsh64 r3, 1                                     r3 <<= 1   ///  r3 = r3.wrapping_shl(1)
    add64 r3, 8                                     r3 += 8   ///  r3 = r3.wrapping_add(8 as i32 as i64 as u64)
    jne r3, r2, lbb_18134                           if r3 != r2 { pc += 2603 }
    ldxdw r2, [r8+0xa]                      
    stxdw [r10-0xad0], r6                   
    jeq r2, 0, lbb_15624                            if r2 == (0 as i32 as i64 as u64) { pc += 90 }
    ldxdw r3, [r10-0xa30]                   
    ldxdw r4, [r3+0x50]                     
    jlt r4, 32, lbb_18174                           if r4 < (32 as i32 as i64 as u64) { pc += 2637 }
    ldxdw r4, [r10-0xa28]                   
    ldxdw r5, [r4+0x50]                     
    jlt r5, 32, lbb_18174                           if r5 < (32 as i32 as i64 as u64) { pc += 2634 }
    ldxdw r5, [r4+0x58]                     
    ldxdw r0, [r3+0x58]                     
    jne r0, r5, lbb_18174                           if r0 != r5 { pc += 2631 }
    ldxdw r5, [r4+0x60]                     
    ldxdw r0, [r3+0x60]                     
    jne r0, r5, lbb_18174                           if r0 != r5 { pc += 2628 }
    ldxdw r5, [r4+0x68]                     
    ldxdw r0, [r3+0x68]                     
    jne r0, r5, lbb_18174                           if r0 != r5 { pc += 2625 }
    ldxdw r5, [r4+0x70]                     
    ldxdw r0, [r3+0x70]                     
    jne r0, r5, lbb_18174                           if r0 != r5 { pc += 2622 }
    mov64 r0, r6                                    r0 = r6
    mov64 r6, r1                                    r6 = r1
    mov64 r1, r10                                   r1 = r10
    add64 r1, -2600                                 r1 += -2600   ///  r1 = r1.wrapping_add(-2600 as i32 as i64 as u64)
    mov64 r5, r10                                   r5 = r10
    add64 r5, -2608                                 r5 += -2608   ///  r5 = r5.wrapping_add(-2608 as i32 as i64 as u64)
    ldxdw r7, [r10-0xa18]                   
    stxdw [r10-0x230], r0                   
    add64 r4, 8                                     r4 += 8   ///  r4 = r4.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x240], r4                   
    add64 r3, 8                                     r3 += 8   ///  r3 = r3.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x250], r3                   
    sth [r10-0x228], 257                    
    sth [r10-0x238], 1                      
    sth [r10-0x248], 1                      
    stxdw [r10-0x6b], r2                    
    stb [r10-0x6c], 3                       
    mov64 r2, r10                                   r2 = r10
    add64 r2, -2624                                 r2 += -2624   ///  r2 = r2.wrapping_add(-2624 as i32 as i64 as u64)
    stxdw [r10-0x1e0], r2                   
    stxdw [r10-0x1e8], r1                   
    stxdw [r10-0x1f0], r5                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -280                                  r1 += -280   ///  r1 = r1.wrapping_add(-280 as i32 as i64 as u64)
    stxdw [r10-0x20], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -448                                  r1 += -448   ///  r1 = r1.wrapping_add(-448 as i32 as i64 as u64)
    stxdw [r10-0x28], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -544                                  r1 += -544   ///  r1 = r1.wrapping_add(-544 as i32 as i64 as u64)
    stxdw [r10-0x48], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -592                                  r1 += -592   ///  r1 = r1.wrapping_add(-592 as i32 as i64 as u64)
    stxdw [r10-0x50], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -472                                  r1 += -472   ///  r1 = r1.wrapping_add(-472 as i32 as i64 as u64)
    stxdw [r10-0x58], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -496                                  r1 += -496   ///  r1 = r1.wrapping_add(-496 as i32 as i64 as u64)
    stxdw [r10-0x60], r1                    
    stdw [r10-0x8], 3                       
    stdw [r10-0x10], 3                      
    stdw [r10-0x18], 0                      
    stdw [r10-0x30], 3                      
    stdw [r10-0x38], 3                      
    stdw [r10-0x40], 0                      
    mov64 r1, r10                                   r1 = r10
    add64 r1, -96                                   r1 += -96   ///  r1 = r1.wrapping_add(-96 as i32 as i64 as u64)
    call function_0                         
    mov64 r1, r0                                    r1 = r0
    lsh64 r1, 32                                    r1 <<= 32   ///  r1 = r1.wrapping_shl(32)
    rsh64 r1, 32                                    r1 >>= 32   ///  r1 = r1.wrapping_shr(32)
    jne r1, 26, lbb_17921                           if r1 != (26 as i32 as i64 as u64) { pc += 2316 }
    mov64 r1, r10                                   r1 = r10
    add64 r1, -108                                  r1 += -108   ///  r1 = r1.wrapping_add(-108 as i32 as i64 as u64)
    stxdw [r10-0x48], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -592                                  r1 += -592   ///  r1 = r1.wrapping_add(-592 as i32 as i64 as u64)
    stxdw [r10-0x58], r1                    
    add64 r7, 8                                     r7 += 8   ///  r7 = r7.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x60], r7                    
    stdw [r10-0x40], 9                      
    stdw [r10-0x50], 3                      
    mov64 r1, r10                                   r1 = r10
    add64 r1, -96                                   r1 += -96   ///  r1 = r1.wrapping_add(-96 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -448                                  r2 += -448   ///  r2 = r2.wrapping_add(-448 as i32 as i64 as u64)
    mov64 r3, 3                                     r3 = 3 as i32 as i64 as u64
    mov64 r4, 8                                     r4 = 8 as i32 as i64 as u64
    mov64 r5, 0                                     r5 = 0 as i32 as i64 as u64
    syscall [invalid]                       
    mov64 r1, r6                                    r1 = r6
lbb_15624:
    jeq r9, 0, lbb_17909                            if r9 == (0 as i32 as i64 as u64) { pc += 2284 }
    mov64 r2, r10                                   r2 = r10
    add64 r2, -2576                                 r2 += -2576   ///  r2 = r2.wrapping_add(-2576 as i32 as i64 as u64)
    stxdw [r10-0xae8], r2                   
    mov64 r4, r10                                   r4 = r10
    add64 r4, -2584                                 r4 += -2584   ///  r4 = r4.wrapping_add(-2584 as i32 as i64 as u64)
    mov64 r8, 0                                     r8 = 0 as i32 as i64 as u64
    mov64 r5, r10                                   r5 = r10
    add64 r5, -2552                                 r5 += -2552   ///  r5 = r5.wrapping_add(-2552 as i32 as i64 as u64)
    stxdw [r10-0xad8], r9                   
    stxdw [r10-0xae0], r4                   
    ja lbb_15758                                    if true { pc += 122 }
lbb_15636:
    jne r2, 3, lbb_18134                            if r2 != (3 as i32 as i64 as u64) { pc += 2497 }
    ldxdw r3, [r1+0x10]                     
    lddw r4, 0xca896837f7826fd2                     r4 load str located at -3852433416653738030
    jne r3, r4, lbb_16976                           if r3 != r4 { pc += 1335 }
    ldxdw r3, [r1+0x18]                     
    lddw r4, 0x88adfc86574fea83                     r4 load str located at -8597938459659736445
    jne r3, r4, lbb_17643                           if r3 != r4 { pc += 1998 }
    ldxdw r3, [r1+0x20]                     
    lddw r4, 0x384d82dd1cab4e18                     r4 load str located at 4057042725511056920
    jne r3, r4, lbb_17643                           if r3 != r4 { pc += 1994 }
    ldxdw r1, [r1+0x28]                     
    lddw r3, 0x54a5fa76c74e4713                     r3 load str located at 6099556658400085779
    jeq r1, r3, lbb_16991                           if r1 == r3 { pc += 1338 }
    ja lbb_17643                                    if true { pc += 1989 }
lbb_15654:
    jlt r2, 8, lbb_18134                            if r2 < (8 as i32 as i64 as u64) { pc += 2479 }
    ldxdw r3, [r1+0x10]                     
    lddw r4, 0xca896837f7826fd2                     r4 load str located at -3852433416653738030
    jne r3, r4, lbb_17030                           if r3 != r4 { pc += 1371 }
    ldxdw r3, [r1+0x18]                     
    lddw r4, 0x88adfc86574fea83                     r4 load str located at -8597938459659736445
    jne r3, r4, lbb_17643                           if r3 != r4 { pc += 1980 }
    ldxdw r3, [r1+0x20]                     
    lddw r4, 0x384d82dd1cab4e18                     r4 load str located at 4057042725511056920
    jne r3, r4, lbb_17643                           if r3 != r4 { pc += 1976 }
    ldxdw r3, [r1+0x28]                     
    lddw r4, 0x54a5fa76c74e4713                     r4 load str located at 6099556658400085779
    jeq r3, r4, lbb_17045                           if r3 == r4 { pc += 1374 }
    ja lbb_17643                                    if true { pc += 1971 }
lbb_15672:
    jlt r2, 9, lbb_18134                            if r2 < (9 as i32 as i64 as u64) { pc += 2461 }
    ldxdw r3, [r1+0x10]                     
    lddw r4, 0xca896837f7826fd2                     r4 load str located at -3852433416653738030
    jne r3, r4, lbb_17096                           if r3 != r4 { pc += 1419 }
    ldxdw r3, [r1+0x18]                     
    lddw r4, 0x88adfc86574fea83                     r4 load str located at -8597938459659736445
    jne r3, r4, lbb_17643                           if r3 != r4 { pc += 1962 }
    ldxdw r3, [r1+0x20]                     
    lddw r4, 0x384d82dd1cab4e18                     r4 load str located at 4057042725511056920
    jne r3, r4, lbb_17643                           if r3 != r4 { pc += 1958 }
    ldxdw r3, [r1+0x28]                     
    lddw r4, 0x54a5fa76c74e4713                     r4 load str located at 6099556658400085779
    jeq r3, r4, lbb_17111                           if r3 == r4 { pc += 1422 }
    ja lbb_17643                                    if true { pc += 1953 }
lbb_15690:
    jeq r4, 1, lbb_15267                            if r4 == (1 as i32 as i64 as u64) { pc += -424 }
    ldxb r4, [r8+0x0]                       
    jne r4, 255, lbb_18321                          if r4 != (255 as i32 as i64 as u64) { pc += 2628 }
    stxdw [r3+0x8], r8                      
    ja lbb_15263                                    if true { pc += -432 }
lbb_15695:
    ldxb r4, [r8+0x0]                       
    jne r4, 255, lbb_18246                          if r4 != (255 as i32 as i64 as u64) { pc += 2549 }
    stxdw [r3+0x8], r8                      
    ldxdw r4, [r8+0x50]                     
    add64 r8, r4                                    r8 += r4   ///  r8 = r8.wrapping_add(r4)
    add64 r8, 10343                                 r8 += 10343   ///  r8 = r8.wrapping_add(10343 as i32 as i64 as u64)
    and64 r8, -8                                    r8 &= -8   ///  r8 = r8.and(-8)
    ldxb r4, [r8+0x0]                       
    jne r4, 255, lbb_18255                          if r4 != (255 as i32 as i64 as u64) { pc += 2551 }
lbb_15704:
    stxdw [r3+0x10], r8                     
    ja lbb_15263                                    if true { pc += -443 }
lbb_15706:
    ldxb r4, [r8+0x0]                       
    jne r4, 255, lbb_18287                          if r4 != (255 as i32 as i64 as u64) { pc += 2579 }
    stxdw [r3+0x8], r8                      
    ldxdw r4, [r8+0x50]                     
    add64 r8, r4                                    r8 += r4   ///  r8 = r8.wrapping_add(r4)
    add64 r8, 10343                                 r8 += 10343   ///  r8 = r8.wrapping_add(10343 as i32 as i64 as u64)
    and64 r8, -8                                    r8 &= -8   ///  r8 = r8.and(-8)
    ldxb r4, [r8+0x0]                       
    jne r4, 255, lbb_18296                          if r4 != (255 as i32 as i64 as u64) { pc += 2581 }
lbb_15715:
    stxdw [r3+0x10], r8                     
    ldxdw r4, [r8+0x50]                     
    add64 r8, r4                                    r8 += r4   ///  r8 = r8.wrapping_add(r4)
    add64 r8, 10343                                 r8 += 10343   ///  r8 = r8.wrapping_add(10343 as i32 as i64 as u64)
    and64 r8, -8                                    r8 &= -8   ///  r8 = r8.and(-8)
    ldxb r4, [r8+0x0]                       
    jne r4, 255, lbb_18305                          if r4 != (255 as i32 as i64 as u64) { pc += 2583 }
lbb_15722:
    stxdw [r3+0x18], r8                     
    ldxdw r4, [r8+0x50]                     
    add64 r8, r4                                    r8 += r4   ///  r8 = r8.wrapping_add(r4)
    add64 r8, 10343                                 r8 += 10343   ///  r8 = r8.wrapping_add(10343 as i32 as i64 as u64)
    and64 r8, -8                                    r8 &= -8   ///  r8 = r8.and(-8)
    ldxb r4, [r8+0x0]                       
    jne r4, 255, lbb_18314                          if r4 != (255 as i32 as i64 as u64) { pc += 2585 }
lbb_15729:
    stxdw [r3+0x20], r8                     
    ja lbb_15263                                    if true { pc += -468 }
lbb_15731:
    add64 r8, 1                                     r8 += 1   ///  r8 = r8.wrapping_add(1 as i32 as i64 as u64)
    ldxdw r2, [r10-0xac0]                   
    add64 r2, 8                                     r2 += 8   ///  r2 = r2.wrapping_add(8 as i32 as i64 as u64)
    stxb [r10-0x78], r4                     
    stdw [r10-0x80], 0                      
    lddw r1, 0x1000259e1 --> b"\x01\x09attempt to divide with overflow but the index is"        r1 load str located at 4295121377
    stxdw [r10-0x238], r1                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -96                                   r1 += -96   ///  r1 = r1.wrapping_add(-96 as i32 as i64 as u64)
    stxdw [r10-0x248], r1                   
    stxdw [r10-0x250], r2                   
    stdw [r10-0x230], 1                     
    stdw [r10-0x240], 6                     
    mov64 r1, r10                                   r1 = r10
    add64 r1, -592                                  r1 += -592   ///  r1 = r1.wrapping_add(-592 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -448                                  r2 += -448   ///  r2 = r2.wrapping_add(-448 as i32 as i64 as u64)
    mov64 r3, 6                                     r3 = 6 as i32 as i64 as u64
    mov64 r4, 8                                     r4 = 8 as i32 as i64 as u64
    mov64 r5, 0                                     r5 = 0 as i32 as i64 as u64
    syscall [invalid]                       
    ldxdw r5, [r10-0xab8]                   
    add64 r5, 16                                    r5 += 16   ///  r5 = r5.wrapping_add(16 as i32 as i64 as u64)
    mov64 r1, r7                                    r1 = r7
    ldxdw r4, [r10-0xae0]                   
    jge r8, r9, lbb_18136                           if r8 >= r9 { pc += 2378 }
lbb_15758:
    stxdw [r10-0xab0], r8                   
    ldxdw r9, [r5-0x8]                      
    ldxdw r3, [r9+0x28]                     
    mov64 r2, r4                                    r2 = r4
    lddw r0, 0xde8f75eee1f6dd06                     r0 load str located at -2409577606766207738
    jne r3, r0, lbb_15781                           if r3 != r0 { pc += 16 }
    ldxdw r3, [r9+0x30]                     
    mov64 r2, r4                                    r2 = r4
    lddw r0, 0xdacd6ce4bc5d4218                     r0 load str located at -2680366473547005416
    jne r3, r0, lbb_15781                           if r3 != r0 { pc += 11 }
    ldxdw r3, [r9+0x38]                     
    mov64 r2, r4                                    r2 = r4
    lddw r0, 0x270db9834dfc1ab6                     r0 load str located at 2814109315776649910
    jne r3, r0, lbb_15781                           if r3 != r0 { pc += 6 }
    ldxdw r3, [r9+0x40]                     
    mov64 r2, r4                                    r2 = r4
    lddw r0, 0xfc8ba1d828f9bdfe                     r0 load str located at -248927404616466946
    jne r3, r0, lbb_15781                           if r3 != r0 { pc += 1 }
    ldxdw r2, [r10-0xae8]                   
lbb_15781:
    mov64 r3, 1                                     r3 = 1 as i32 as i64 as u64
    stxdw [r10-0xa78], r3                   
    ldxdw r3, [r10-0xa08]                   
    stxdw [r10-0xac0], r3                   
    stxdw [r10-0xab8], r5                   
    ldxdw r4, [r5+0x0]                      
    ldxdw r2, [r2+0x0]                      
    ldxdw r3, [r10-0xa20]                   
    stxdw [r10-0xa98], r3                   
    add64 r3, 8                                     r3 += 8   ///  r3 = r3.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0xaa8], r3                   
    stxdw [r10-0x20], r3                    
    mov64 r3, r9                                    r3 = r9
    add64 r3, 8                                     r3 += 8   ///  r3 = r3.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0xaa0], r3                   
    stxdw [r10-0x30], r3                    
    ldxdw r8, [r10-0xa38]                   
    mov64 r7, r8                                    r7 = r8
    add64 r7, 8                                     r7 += 8   ///  r7 = r7.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x40], r7                    
    stxdw [r10-0xa70], r2                   
    add64 r2, 8                                     r2 += 8   ///  r2 = r2.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0xac8], r2                   
    stxdw [r10-0x10], r2                    
    mov64 r6, r4                                    r6 = r4
    add64 r6, 8                                     r6 += 8   ///  r6 = r6.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x50], r6                    
    ldxdw r3, [r10-0xad0]                   
    stxdw [r10-0x60], r3                    
    sth [r10-0x8], 0                        
    sth [r10-0x18], 0                       
    sth [r10-0x28], 0                       
    sth [r10-0x38], 0                       
    sth [r10-0x48], 1                       
    sth [r10-0x58], 257                     
    ldxdw r2, [r10-0xa40]                   
    ldxdw r5, [r3+0x0]                      
    ldxdw r0, [r2+0x8]                      
    jne r0, r5, lbb_17924                           if r0 != r5 { pc += 2104 }
    ldxdw r5, [r1+0x18]                     
    ldxdw r0, [r2+0x10]                     
    jne r0, r5, lbb_17924                           if r0 != r5 { pc += 2101 }
    ldxdw r5, [r1+0x20]                     
    ldxdw r0, [r2+0x18]                     
    jne r0, r5, lbb_17924                           if r0 != r5 { pc += 2098 }
    ldxdw r5, [r1+0x28]                     
    ldxdw r0, [r2+0x20]                     
    jne r0, r5, lbb_17924                           if r0 != r5 { pc += 2095 }
    ldxb r5, [r2+0x0]                       
    jne r5, 255, lbb_17922                          if r5 != (255 as i32 as i64 as u64) { pc += 2091 }
    mov64 r3, 11                                    r3 = 11 as i32 as i64 as u64
    stxdw [r10-0xa78], r3                   
    ldxb r5, [r2+0x1]                       
    mov64 r3, 1                                     r3 = 1 as i32 as i64 as u64
    stxdw [r10-0xa80], r3                   
    jne r5, 0, lbb_16023                            if r5 != (0 as i32 as i64 as u64) { pc += 186 }
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
    ldxb r0, [r2+0x2]                       
    mov64 r5, 1                                     r5 = 1 as i32 as i64 as u64
    jeq r0, 0, lbb_16026                            if r0 == (0 as i32 as i64 as u64) { pc += 185 }
lbb_15841:
    stxdw [r10-0xa90], r5                   
    stxdw [r10-0xa88], r3                   
    ldxb r0, [r2+0x3]                       
    jne r0, 0, lbb_15847                            if r0 != (0 as i32 as i64 as u64) { pc += 2 }
lbb_15845:
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
    stxdw [r10-0xa80], r3                   
lbb_15847:
    mov64 r0, r2                                    r0 = r2
    add64 r0, 8                                     r0 += 8   ///  r0 = r0.wrapping_add(8 as i32 as i64 as u64)
    ldxdw r5, [r2+0x50]                     
    mov64 r3, r2                                    r3 = r2
    add64 r3, 40                                    r3 += 40   ///  r3 = r3.wrapping_add(40 as i32 as i64 as u64)
    stxdw [r10-0x1a0], r3                   
    mov64 r3, r2                                    r3 = r2
    add64 r3, 88                                    r3 += 88   ///  r3 = r3.wrapping_add(88 as i32 as i64 as u64)
    stxdw [r10-0x1a8], r3                   
    stxdw [r10-0x1b0], r5                   
    add64 r2, 72                                    r2 += 72   ///  r2 = r2.wrapping_add(72 as i32 as i64 as u64)
    stxdw [r10-0x1b8], r2                   
    stxdw [r10-0x1c0], r0                   
    ldxdw r2, [r10-0xa80]                   
    stxb [r10-0x18e], r2                    
    ldxdw r2, [r10-0xa90]                   
    stxb [r10-0x18f], r2                    
    ldxdw r2, [r10-0xa88]                   
    stxb [r10-0x190], r2                    
    stdw [r10-0x198], 0                     
    ldxb r2, [r4+0x0]                       
    jne r2, 255, lbb_17924                          if r2 != (255 as i32 as i64 as u64) { pc += 2055 }
    ldxb r2, [r4+0x1]                       
    mov64 r3, 1                                     r3 = 1 as i32 as i64 as u64
    mov64 r5, 1                                     r5 = 1 as i32 as i64 as u64
    jne r2, 0, lbb_16032                            if r2 != (0 as i32 as i64 as u64) { pc += 159 }
    mov64 r5, 0                                     r5 = 0 as i32 as i64 as u64
    stxdw [r10-0xa80], r5                   
    ldxb r2, [r4+0x2]                       
    mov64 r5, 1                                     r5 = 1 as i32 as i64 as u64
    jeq r2, 0, lbb_16036                            if r2 == (0 as i32 as i64 as u64) { pc += 158 }
lbb_15878:
    ldxb r2, [r4+0x3]                       
    jne r2, 0, lbb_15881                            if r2 != (0 as i32 as i64 as u64) { pc += 1 }
lbb_15880:
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
lbb_15881:
    ldxdw r2, [r4+0x50]                     
    mov64 r0, r4                                    r0 = r4
    add64 r0, 40                                    r0 += 40   ///  r0 = r0.wrapping_add(40 as i32 as i64 as u64)
    stxdw [r10-0x168], r0                   
    mov64 r0, r4                                    r0 = r4
    add64 r0, 88                                    r0 += 88   ///  r0 = r0.wrapping_add(88 as i32 as i64 as u64)
    stxdw [r10-0x170], r0                   
    stxdw [r10-0x178], r2                   
    add64 r4, 72                                    r4 += 72   ///  r4 = r4.wrapping_add(72 as i32 as i64 as u64)
    stxdw [r10-0x180], r4                   
    stxdw [r10-0x188], r6                   
    stxb [r10-0x156], r3                    
    stxb [r10-0x157], r5                    
    ldxdw r2, [r10-0xa80]                   
    stxb [r10-0x158], r2                    
    stdw [r10-0x160], 0                     
    ldxb r2, [r8+0x0]                       
    and64 r2, 136                                   r2 &= 136   ///  r2 = r2.and(136)
    jne r2, 136, lbb_17924                          if r2 != (136 as i32 as i64 as u64) { pc += 2024 }
    ldxb r2, [r8+0x1]                       
    mov64 r4, 1                                     r4 = 1 as i32 as i64 as u64
    mov64 r3, 1                                     r3 = 1 as i32 as i64 as u64
    jne r2, 0, lbb_16040                            if r2 != (0 as i32 as i64 as u64) { pc += 136 }
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
    ldxb r2, [r8+0x2]                       
    mov64 r5, 1                                     r5 = 1 as i32 as i64 as u64
    jeq r2, 0, lbb_16043                            if r2 == (0 as i32 as i64 as u64) { pc += 135 }
lbb_15908:
    ldxb r2, [r8+0x3]                       
    jne r2, 0, lbb_15911                            if r2 != (0 as i32 as i64 as u64) { pc += 1 }
lbb_15910:
    mov64 r4, 0                                     r4 = 0 as i32 as i64 as u64
lbb_15911:
    ldxdw r2, [r8+0x50]                     
    mov64 r0, r8                                    r0 = r8
    add64 r0, 40                                    r0 += 40   ///  r0 = r0.wrapping_add(40 as i32 as i64 as u64)
    stxdw [r10-0x130], r0                   
    mov64 r0, r8                                    r0 = r8
    add64 r0, 88                                    r0 += 88   ///  r0 = r0.wrapping_add(88 as i32 as i64 as u64)
    stxdw [r10-0x138], r0                   
    stxdw [r10-0x140], r2                   
    add64 r8, 72                                    r8 += 72   ///  r8 = r8.wrapping_add(72 as i32 as i64 as u64)
    stxdw [r10-0x148], r8                   
    stxdw [r10-0x150], r7                   
    stxb [r10-0x11e], r4                    
    stxb [r10-0x11f], r5                    
    stxb [r10-0x120], r3                    
    stdw [r10-0x128], 0                     
    ldxb r2, [r9+0x0]                       
    and64 r2, 136                                   r2 &= 136   ///  r2 = r2.and(136)
    jne r2, 136, lbb_17924                          if r2 != (136 as i32 as i64 as u64) { pc += 1995 }
    ldxb r2, [r9+0x1]                       
    mov64 r4, 1                                     r4 = 1 as i32 as i64 as u64
    mov64 r3, 1                                     r3 = 1 as i32 as i64 as u64
    jne r2, 0, lbb_16047                            if r2 != (0 as i32 as i64 as u64) { pc += 114 }
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
    ldxb r2, [r9+0x2]                       
    mov64 r5, 1                                     r5 = 1 as i32 as i64 as u64
    ldxdw r6, [r10-0xa98]                   
    jeq r2, 0, lbb_16051                            if r2 == (0 as i32 as i64 as u64) { pc += 113 }
lbb_15938:
    ldxb r2, [r9+0x3]                       
    jne r2, 0, lbb_15941                            if r2 != (0 as i32 as i64 as u64) { pc += 1 }
lbb_15940:
    mov64 r4, 0                                     r4 = 0 as i32 as i64 as u64
lbb_15941:
    mov64 r2, r9                                    r2 = r9
    add64 r2, 40                                    r2 += 40   ///  r2 = r2.wrapping_add(40 as i32 as i64 as u64)
    ldxdw r0, [r9+0x50]                     
    stxdw [r10-0xf8], r2                    
    mov64 r2, r9                                    r2 = r9
    add64 r2, 88                                    r2 += 88   ///  r2 = r2.wrapping_add(88 as i32 as i64 as u64)
    stxdw [r10-0x100], r2                   
    stxdw [r10-0x108], r0                   
    add64 r9, 72                                    r9 += 72   ///  r9 = r9.wrapping_add(72 as i32 as i64 as u64)
    stxdw [r10-0x110], r9                   
    ldxdw r2, [r10-0xaa0]                   
    stxdw [r10-0x118], r2                   
    stxb [r10-0xe6], r4                     
    stxb [r10-0xe7], r5                     
    stxb [r10-0xe8], r3                     
    stdw [r10-0xf0], 0                      
    ldxb r2, [r6+0x0]                       
    and64 r2, 136                                   r2 &= 136   ///  r2 = r2.and(136)
    jne r2, 136, lbb_17924                          if r2 != (136 as i32 as i64 as u64) { pc += 1964 }
    ldxb r4, [r6+0x1]                       
    mov64 r3, 1                                     r3 = 1 as i32 as i64 as u64
    mov64 r2, 1                                     r2 = 1 as i32 as i64 as u64
    jne r4, 0, lbb_16055                            if r4 != (0 as i32 as i64 as u64) { pc += 91 }
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
    ldxb r5, [r6+0x2]                       
    mov64 r4, 1                                     r4 = 1 as i32 as i64 as u64
    jeq r5, 0, lbb_16058                            if r5 == (0 as i32 as i64 as u64) { pc += 90 }
lbb_15968:
    ldxb r5, [r6+0x3]                       
    jne r5, 0, lbb_15971                            if r5 != (0 as i32 as i64 as u64) { pc += 1 }
lbb_15970:
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
lbb_15971:
    ldxdw r5, [r6+0x50]                     
    mov64 r0, r6                                    r0 = r6
    add64 r0, 40                                    r0 += 40   ///  r0 = r0.wrapping_add(40 as i32 as i64 as u64)
    stxdw [r10-0xc0], r0                    
    mov64 r0, r6                                    r0 = r6
    add64 r0, 88                                    r0 += 88   ///  r0 = r0.wrapping_add(88 as i32 as i64 as u64)
    stxdw [r10-0xc8], r0                    
    stxdw [r10-0xd0], r5                    
    add64 r6, 72                                    r6 += 72   ///  r6 = r6.wrapping_add(72 as i32 as i64 as u64)
    stxdw [r10-0xd8], r6                    
    ldxdw r5, [r10-0xaa8]                   
    stxdw [r10-0xe0], r5                    
    stxb [r10-0xae], r3                     
    stxb [r10-0xaf], r4                     
    stxb [r10-0xb0], r2                     
    stdw [r10-0xb8], 0                      
    ldxdw r2, [r10-0xa70]                   
    ldxb r2, [r2+0x0]                       
    and64 r2, 136                                   r2 &= 136   ///  r2 = r2.and(136)
    jne r2, 136, lbb_17924                          if r2 != (136 as i32 as i64 as u64) { pc += 1933 }
    ldxdw r6, [r10-0xa70]                   
    ldxb r2, [r6+0x1]                       
    ldxb r3, [r6+0x2]                       
    ldxb r0, [r6+0x3]                       
    ldxdw r4, [r6+0x50]                     
    mov64 r5, r6                                    r5 = r6
    add64 r5, 40                                    r5 += 40   ///  r5 = r5.wrapping_add(40 as i32 as i64 as u64)
    stxdw [r10-0x88], r5                    
    mov64 r5, r6                                    r5 = r6
    add64 r5, 88                                    r5 += 88   ///  r5 = r5.wrapping_add(88 as i32 as i64 as u64)
    stxdw [r10-0x90], r5                    
    stxdw [r10-0x98], r4                    
    add64 r6, 72                                    r6 += 72   ///  r6 = r6.wrapping_add(72 as i32 as i64 as u64)
    stxdw [r10-0xa0], r6                    
    ldxdw r4, [r10-0xac8]                   
    stxdw [r10-0xa8], r4                    
    mov64 r6, 0                                     r6 = 0 as i32 as i64 as u64
    mov64 r4, 1                                     r4 = 1 as i32 as i64 as u64
    mov64 r5, 1                                     r5 = 1 as i32 as i64 as u64
    jne r0, 0, lbb_16012                            if r0 != (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r5, 0                                     r5 = 0 as i32 as i64 as u64
lbb_16012:
    stxb [r10-0x76], r5                     
    mov64 r5, 1                                     r5 = 1 as i32 as i64 as u64
    ldxdw r9, [r10-0xad8]                   
    ldxdw r8, [r10-0xab0]                   
    jne r3, 0, lbb_16018                            if r3 != (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r5, 0                                     r5 = 0 as i32 as i64 as u64
lbb_16018:
    mov64 r7, r1                                    r7 = r1
    stxb [r10-0x77], r5                     
    jne r2, 0, lbb_15731                            if r2 != (0 as i32 as i64 as u64) { pc += -290 }
    mov64 r4, 0                                     r4 = 0 as i32 as i64 as u64
    ja lbb_15731                                    if true { pc += -292 }
lbb_16023:
    ldxb r0, [r2+0x2]                       
    mov64 r5, 1                                     r5 = 1 as i32 as i64 as u64
    jne r0, 0, lbb_15841                            if r0 != (0 as i32 as i64 as u64) { pc += -185 }
lbb_16026:
    mov64 r5, 0                                     r5 = 0 as i32 as i64 as u64
    stxdw [r10-0xa90], r5                   
    stxdw [r10-0xa88], r3                   
    ldxb r0, [r2+0x3]                       
    jeq r0, 0, lbb_15845                            if r0 == (0 as i32 as i64 as u64) { pc += -186 }
    ja lbb_15847                                    if true { pc += -185 }
lbb_16032:
    stxdw [r10-0xa80], r5                   
    ldxb r2, [r4+0x2]                       
    mov64 r5, 1                                     r5 = 1 as i32 as i64 as u64
    jne r2, 0, lbb_15878                            if r2 != (0 as i32 as i64 as u64) { pc += -158 }
lbb_16036:
    mov64 r5, 0                                     r5 = 0 as i32 as i64 as u64
    ldxb r2, [r4+0x3]                       
    jeq r2, 0, lbb_15880                            if r2 == (0 as i32 as i64 as u64) { pc += -159 }
    ja lbb_15881                                    if true { pc += -159 }
lbb_16040:
    ldxb r2, [r8+0x2]                       
    mov64 r5, 1                                     r5 = 1 as i32 as i64 as u64
    jne r2, 0, lbb_15908                            if r2 != (0 as i32 as i64 as u64) { pc += -135 }
lbb_16043:
    mov64 r5, 0                                     r5 = 0 as i32 as i64 as u64
    ldxb r2, [r8+0x3]                       
    jeq r2, 0, lbb_15910                            if r2 == (0 as i32 as i64 as u64) { pc += -136 }
    ja lbb_15911                                    if true { pc += -136 }
lbb_16047:
    ldxb r2, [r9+0x2]                       
    mov64 r5, 1                                     r5 = 1 as i32 as i64 as u64
    ldxdw r6, [r10-0xa98]                   
    jne r2, 0, lbb_15938                            if r2 != (0 as i32 as i64 as u64) { pc += -113 }
lbb_16051:
    mov64 r5, 0                                     r5 = 0 as i32 as i64 as u64
    ldxb r2, [r9+0x3]                       
    jeq r2, 0, lbb_15940                            if r2 == (0 as i32 as i64 as u64) { pc += -114 }
    ja lbb_15941                                    if true { pc += -114 }
lbb_16055:
    ldxb r5, [r6+0x2]                       
    mov64 r4, 1                                     r4 = 1 as i32 as i64 as u64
    jne r5, 0, lbb_15968                            if r5 != (0 as i32 as i64 as u64) { pc += -90 }
lbb_16058:
    mov64 r4, 0                                     r4 = 0 as i32 as i64 as u64
    ldxb r5, [r6+0x3]                       
    jeq r5, 0, lbb_15970                            if r5 == (0 as i32 as i64 as u64) { pc += -91 }
    ja lbb_15971                                    if true { pc += -91 }
lbb_16062:
    lddw r5, 0x4cfbdb8200836fd2                     r5 load str located at 5547268717437743058
    jne r4, r5, lbb_17643                           if r4 != r5 { pc += 1578 }
    ldxdw r4, [r1+0x18]                     
    lddw r5, 0x33559cb08794b05b                     r5 load str located at 3699034950957576283
    jne r4, r5, lbb_17643                           if r4 != r5 { pc += 1574 }
    ldxdw r4, [r1+0x20]                     
    lddw r5, 0xa2e8696d479bf0b2                     r5 load str located at -6707995726894600014
    jne r4, r5, lbb_17643                           if r4 != r5 { pc += 1570 }
    ldxdw r1, [r1+0x28]                     
    lddw r4, 0xb50d9a20d7d2fe4c                     r4 load str located at -5400490912296796596
    jne r1, r4, lbb_17643                           if r1 != r4 { pc += 1566 }
lbb_16077:
    jlt r3, 55, lbb_18150                           if r3 < (55 as i32 as i64 as u64) { pc += 2072 }
    add64 r2, -9                                    r2 += -9   ///  r2 = r2.wrapping_add(-9 as i32 as i64 as u64)
    ldxb r5, [r8+0x1a]                      
    jle r2, r5, lbb_18234                           if r2 <= r5 { pc += 2153 }
    stxdw [r10-0xa70], r2                   
    ldxdw r1, [r10-0xa38]                   
    ldxdw r3, [r1+0x50]                     
    jlt r3, 72, lbb_18174                           if r3 < (72 as i32 as i64 as u64) { pc += 2089 }
    ldxdw r3, [r10-0xa30]                   
    ldxdw r4, [r3+0x50]                     
    jlt r4, 72, lbb_18174                           if r4 < (72 as i32 as i64 as u64) { pc += 2086 }
    ldxdw r9, [r10-0xa28]                   
    ldxdw r4, [r9+0x50]                     
    jlt r4, 72, lbb_18174                           if r4 < (72 as i32 as i64 as u64) { pc += 2083 }
    stxdw [r10-0xac8], r5                   
    ldxb r0, [r8+0x1c]                      
    ldxdw r5, [r1+0x28]                     
    lddw r4, 0xde8f75eee1f6dd06                     r4 load str located at -2409577606766207738
    jne r5, r4, lbb_16110                           if r5 != r4 { pc += 13 }
    ldxdw r5, [r1+0x30]                     
    lddw r6, 0xdacd6ce4bc5d4218                     r6 load str located at -2680366473547005416
    jne r5, r6, lbb_16110                           if r5 != r6 { pc += 9 }
    ldxdw r5, [r1+0x38]                     
    lddw r6, 0x270db9834dfc1ab6                     r6 load str located at 2814109315776649910
    jne r5, r6, lbb_16110                           if r5 != r6 { pc += 5 }
    mov64 r5, 1                                     r5 = 1 as i32 as i64 as u64
    ldxdw r6, [r1+0x40]                     
    lddw r7, 0xfc8ba1d828f9bdfe                     r7 load str located at -248927404616466946
    jeq r6, r7, lbb_16127                           if r6 == r7 { pc += 17 }
lbb_16110:
    mov64 r5, 0                                     r5 = 0 as i32 as i64 as u64
    ldxdw r6, [r3+0x28]                     
    jne r6, r4, lbb_16127                           if r6 != r4 { pc += 14 }
    ldxdw r4, [r3+0x30]                     
    lddw r6, 0xdacd6ce4bc5d4218                     r6 load str located at -2680366473547005416
    jne r4, r6, lbb_16127                           if r4 != r6 { pc += 10 }
    ldxdw r4, [r3+0x38]                     
    lddw r6, 0x270db9834dfc1ab6                     r6 load str located at 2814109315776649910
    jne r4, r6, lbb_16127                           if r4 != r6 { pc += 6 }
    ldxdw r4, [r3+0x40]                     
    mov64 r5, 1                                     r5 = 1 as i32 as i64 as u64
    lddw r6, 0xfc8ba1d828f9bdfe                     r6 load str located at -248927404616466946
    jeq r4, r6, lbb_16127                           if r4 == r6 { pc += 1 }
    mov64 r5, 0                                     r5 = 0 as i32 as i64 as u64
lbb_16127:
    ldxb r2, [r8+0x19]                      
    stxdw [r10-0xa78], r2                   
    mov64 r2, r10                                   r2 = r10
    add64 r2, -2552                                 r2 += -2552   ///  r2 = r2.wrapping_add(-2552 as i32 as i64 as u64)
    stxdw [r10-0xab0], r2                   
    mov64 r2, r10                                   r2 = r10
    add64 r2, -2560                                 r2 += -2560   ///  r2 = r2.wrapping_add(-2560 as i32 as i64 as u64)
    stxdw [r10-0xab8], r2                   
    mov64 r2, r10                                   r2 = r10
    add64 r2, -2568                                 r2 += -2568   ///  r2 = r2.wrapping_add(-2568 as i32 as i64 as u64)
    stxdw [r10-0xa98], r2                   
    mov64 r2, r10                                   r2 = r10
    add64 r2, -2576                                 r2 += -2576   ///  r2 = r2.wrapping_add(-2576 as i32 as i64 as u64)
    stxdw [r10-0xa90], r2                   
    mov64 r2, r10                                   r2 = r10
    add64 r2, -2584                                 r2 += -2584   ///  r2 = r2.wrapping_add(-2584 as i32 as i64 as u64)
    stxdw [r10-0xa88], r2                   
    mov64 r2, r10                                   r2 = r10
    add64 r2, -2592                                 r2 += -2592   ///  r2 = r2.wrapping_add(-2592 as i32 as i64 as u64)
    stxdw [r10-0xa80], r2                   
    mov64 r2, r10                                   r2 = r10
    add64 r2, -2608                                 r2 += -2608   ///  r2 = r2.wrapping_add(-2608 as i32 as i64 as u64)
    stxdw [r10-0xaa0], r2                   
    mov64 r2, r10                                   r2 = r10
    add64 r2, -2616                                 r2 += -2616   ///  r2 = r2.wrapping_add(-2616 as i32 as i64 as u64)
    stxdw [r10-0xaa8], r2                   
    ldxh r2, [r8+0x25]                      
    ldxb r6, [r8+0x1b]                      
    ldxdw r4, [r8+0x1d]                     
    stxdw [r10-0xac0], r4                   
    ldxdw r4, [r8+0x9]                      
    mov64 r7, r0                                    r7 = r0
    mov64 r0, 1                                     r0 = 1 as i32 as i64 as u64
    jne r7, 0, lbb_16162                            if r7 != (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r0, 0                                     r0 = 0 as i32 as i64 as u64
lbb_16162:
    ldxh r7, [r8+0x3d]                      
    stxdw [r10-0xb08], r7                   
    ldxh r7, [r8+0x31]                      
    stxdw [r10-0xae0], r7                   
    ldxb r7, [r8+0x33]                      
    stxdw [r10-0xaf8], r7                   
    ldxb r7, [r8+0x27]                      
    stxdw [r10-0xad0], r7                   
    ldxdw r7, [r8+0x35]                     
    stxdw [r10-0xb00], r7                   
    ldxdw r7, [r8+0x29]                     
    stxdw [r10-0xad8], r7                   
    ldxdw r7, [r8+0x11]                     
    stxdw [r10-0xb20], r7                   
    ldxb r7, [r8+0x34]                      
    stxdw [r10-0xb10], r7                   
    ldxb r7, [r8+0x28]                      
    stxdw [r10-0xae8], r7                   
    ldxdw r7, [r9+0x98]                     
    stxdw [r10-0xb18], r7                   
    ldxdw r3, [r3+0x98]                     
    stxdw [r10-0xaf0], r3                   
    ldxdw r8, [r1+0x98]                     
    ldxdw r1, [r10-0xaa0]                   
    stxdw [r10-0x168], r1                   
    ldxdw r1, [r10-0xaa8]                   
    stxdw [r10-0x170], r1                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -2624                                 r1 += -2624   ///  r1 = r1.wrapping_add(-2624 as i32 as i64 as u64)
    stxdw [r10-0x178], r1                   
    ldxdw r1, [r10-0xa98]                   
    stxdw [r10-0x180], r1                   
    ldxdw r1, [r10-0xa90]                   
    stxdw [r10-0x188], r1                   
    ldxdw r1, [r10-0xa88]                   
    stxdw [r10-0x190], r1                   
    ldxdw r1, [r10-0xa80]                   
    stxdw [r10-0x198], r1                   
    ldxdw r1, [r10-0xab8]                   
    stxdw [r10-0x1a0], r1                   
    stxh [r10-0x160], r2                    
    stxdw [r10-0x1b0], r4                   
    ldxdw r1, [r10-0xa78]                   
    stxdw [r10-0x1b8], r1                   
    ldxdw r9, [r10-0xab0]                   
    stxdw [r10-0x1c0], r9                   
    ldxdw r1, [r10-0xac0]                   
    stxdw [r10-0x1a8], r1                   
    and64 r5, 1                                     r5 &= 1   ///  r5 = r5.and(1)
    stxb [r10-0x15c], r5                    
    stxb [r10-0x15e], r0                    
    stb [r10-0x15d], 1                      
    jge r6, 41, lbb_18234                           if r6 >= (41 as i32 as i64 as u64) { pc += 2019 }
    lsh64 r6, 3                                     r6 <<= 3   ///  r6 = r6.wrapping_shl(3)
    lddw r1, 0x1000280a8 --> b"\x00\x00\x00\x00`=\x00\x00\x00\x00\x00\x00(H\x00\x00\x00\x00\x00\x000S\x0…        r1 load str located at 4295131304
    add64 r1, r6                                    r1 += r6   ///  r1 = r1.wrapping_add(r6)
    ldxdw r3, [r1+0x0]                      
    mov64 r1, r10                                   r1 = r10
    add64 r1, -2632                                 r1 += -2632   ///  r1 = r1.wrapping_add(-2632 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -448                                  r2 += -448   ///  r2 = r2.wrapping_add(-448 as i32 as i64 as u64)
    callx r3                                
    ldxw r0, [r10-0xa48]                    
    ldxdw r7, [r10-0xac8]                   
    jne r0, 26, lbb_17648                           if r0 != (26 as i32 as i64 as u64) { pc += 1420 }
    ldxdw r5, [r10-0xa30]                   
    ldxdw r1, [r5+0x50]                     
    jlt r1, 72, lbb_18174                           if r1 < (72 as i32 as i64 as u64) { pc += 1943 }
    ldxdw r2, [r5+0x98]                     
    mov64 r3, r2                                    r3 = r2
    ldxdw r1, [r10-0xaf0]                   
    sub64 r3, r1                                    r3 -= r1   ///  r3 = r3.wrapping_sub(r1)
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    mov64 r4, 1                                     r4 = 1 as i32 as i64 as u64
    jgt r3, r2, lbb_16239                           if r3 > r2 { pc += 1 }
    mov64 r4, 0                                     r4 = 0 as i32 as i64 as u64
lbb_16239:
    ldxdw r2, [r10-0xa78]                   
    add64 r2, 1                                     r2 += 1   ///  r2 = r2.wrapping_add(1 as i32 as i64 as u64)
    jne r4, 0, lbb_16243                            if r4 != (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r1, r3                                    r1 = r3
lbb_16243:
    ldxdw r3, [r10-0xa78]                   
    lsh64 r3, 3                                     r3 <<= 3   ///  r3 = r3.wrapping_shl(3)
    stxdw [r10-0xa78], r3                   
    mov64 r4, r2                                    r4 = r2
    lsh64 r4, 3                                     r4 <<= 3   ///  r4 = r4.wrapping_shl(3)
    ldxdw r3, [r5+0x28]                     
    lddw r0, 0xde8f75eee1f6dd06                     r0 load str located at -2409577606766207738
    jne r3, r0, lbb_16265                           if r3 != r0 { pc += 13 }
    ldxdw r3, [r5+0x30]                     
    lddw r6, 0xdacd6ce4bc5d4218                     r6 load str located at -2680366473547005416
    jne r3, r6, lbb_16265                           if r3 != r6 { pc += 9 }
    ldxdw r3, [r5+0x38]                     
    lddw r6, 0x270db9834dfc1ab6                     r6 load str located at 2814109315776649910
    jne r3, r6, lbb_16265                           if r3 != r6 { pc += 5 }
    mov64 r3, 1                                     r3 = 1 as i32 as i64 as u64
    ldxdw r5, [r5+0x40]                     
    lddw r6, 0xfc8ba1d828f9bdfe                     r6 load str located at -248927404616466946
    jeq r5, r6, lbb_16283                           if r5 == r6 { pc += 18 }
lbb_16265:
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
    ldxdw r5, [r10-0xa28]                   
    ldxdw r6, [r5+0x28]                     
    jne r6, r0, lbb_16283                           if r6 != r0 { pc += 14 }
    ldxdw r0, [r5+0x30]                     
    lddw r6, 0xdacd6ce4bc5d4218                     r6 load str located at -2680366473547005416
    jne r0, r6, lbb_16283                           if r0 != r6 { pc += 10 }
    ldxdw r0, [r5+0x38]                     
    lddw r6, 0x270db9834dfc1ab6                     r6 load str located at 2814109315776649910
    jne r0, r6, lbb_16283                           if r0 != r6 { pc += 6 }
    ldxdw r5, [r5+0x40]                     
    mov64 r3, 1                                     r3 = 1 as i32 as i64 as u64
    lddw r0, 0xfc8ba1d828f9bdfe                     r0 load str located at -248927404616466946
    jeq r5, r0, lbb_16283                           if r5 == r0 { pc += 1 }
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
lbb_16283:
    mov64 r5, r10                                   r5 = r10
    add64 r5, -2600                                 r5 += -2600   ///  r5 = r5.wrapping_add(-2600 as i32 as i64 as u64)
    stxdw [r10-0xab8], r5                   
    mov64 r5, r7                                    r5 = r7
    sub64 r5, r2                                    r5 -= r2   ///  r5 = r5.wrapping_sub(r2)
    mov64 r6, r9                                    r6 = r9
    ldxdw r2, [r10-0xa78]                   
    add64 r6, r2                                    r6 += r2   ///  r6 = r6.wrapping_add(r2)
    mov64 r0, r9                                    r0 = r9
    add64 r0, r4                                    r0 += r4   ///  r0 = r0.wrapping_add(r4)
    ldxdw r2, [r10-0xae8]                   
    mov64 r4, r2                                    r4 = r2
    mov64 r2, 1                                     r2 = 1 as i32 as i64 as u64
    jne r4, 0, lbb_16298                            if r4 != (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
lbb_16298:
    ldxdw r4, [r10-0xab8]                   
    stxdw [r10-0x168], r4                   
    ldxdw r4, [r10-0xaa0]                   
    stxdw [r10-0x170], r4                   
    mov64 r4, r10                                   r4 = r10
    add64 r4, -2624                                 r4 += -2624   ///  r4 = r4.wrapping_add(-2624 as i32 as i64 as u64)
    stxdw [r10-0x178], r4                   
    ldxdw r4, [r10-0xa98]                   
    stxdw [r10-0x180], r4                   
    ldxdw r4, [r10-0xa90]                   
    stxdw [r10-0x188], r4                   
    ldxdw r4, [r10-0xa88]                   
    stxdw [r10-0x190], r4                   
    ldxdw r4, [r10-0xa80]                   
    stxdw [r10-0x198], r4                   
    stxdw [r10-0x1a0], r6                   
    ldxdw r4, [r10-0xae0]                   
    stxh [r10-0x160], r4                    
    stxdw [r10-0x1b0], r1                   
    stxdw [r10-0x1b8], r5                   
    stxdw [r10-0x1c0], r0                   
    ldxdw r1, [r10-0xad8]                   
    stxdw [r10-0x1a8], r1                   
    and64 r3, 1                                     r3 &= 1   ///  r3 = r3.and(1)
    stxb [r10-0x15c], r3                    
    stxb [r10-0x15e], r2                    
    stb [r10-0x15d], 0                      
    ldxdw r2, [r10-0xad0]                   
    jge r2, 41, lbb_18234                           if r2 >= (41 as i32 as i64 as u64) { pc += 1907 }
    lsh64 r2, 3                                     r2 <<= 3   ///  r2 = r2.wrapping_shl(3)
    lddw r1, 0x1000280a8 --> b"\x00\x00\x00\x00`=\x00\x00\x00\x00\x00\x00(H\x00\x00\x00\x00\x00\x000S\x0…        r1 load str located at 4295131304
    add64 r1, r2                                    r1 += r2   ///  r1 = r1.wrapping_add(r2)
    ldxdw r3, [r1+0x0]                      
    mov64 r1, r10                                   r1 = r10
    add64 r1, -2640                                 r1 += -2640   ///  r1 = r1.wrapping_add(-2640 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -448                                  r2 += -448   ///  r2 = r2.wrapping_add(-448 as i32 as i64 as u64)
    callx r3                                
    ldxw r0, [r10-0xa50]                    
    jne r0, 26, lbb_17905                           if r0 != (26 as i32 as i64 as u64) { pc += 1566 }
    ldxdw r5, [r10-0xa28]                   
    ldxdw r1, [r5+0x50]                     
    jlt r1, 72, lbb_18174                           if r1 < (72 as i32 as i64 as u64) { pc += 1832 }
    ldxdw r2, [r5+0x98]                     
    mov64 r3, r2                                    r3 = r2
    ldxdw r1, [r10-0xb18]                   
    sub64 r3, r1                                    r3 -= r1   ///  r3 = r3.wrapping_sub(r1)
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    mov64 r4, 1                                     r4 = 1 as i32 as i64 as u64
    jgt r3, r2, lbb_16350                           if r3 > r2 { pc += 1 }
    mov64 r4, 0                                     r4 = 0 as i32 as i64 as u64
lbb_16350:
    mov64 r2, r7                                    r2 = r7
    add64 r2, 1                                     r2 += 1   ///  r2 = r2.wrapping_add(1 as i32 as i64 as u64)
    jne r4, 0, lbb_16354                            if r4 != (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r1, r3                                    r1 = r3
lbb_16354:
    mov64 r4, r2                                    r4 = r2
    lsh64 r4, 3                                     r4 <<= 3   ///  r4 = r4.wrapping_shl(3)
    lsh64 r7, 3                                     r7 <<= 3   ///  r7 = r7.wrapping_shl(3)
    ldxdw r3, [r5+0x28]                     
    lddw r0, 0xde8f75eee1f6dd06                     r0 load str located at -2409577606766207738
    jne r3, r0, lbb_16374                           if r3 != r0 { pc += 13 }
    ldxdw r3, [r5+0x30]                     
    lddw r6, 0xdacd6ce4bc5d4218                     r6 load str located at -2680366473547005416
    jne r3, r6, lbb_16374                           if r3 != r6 { pc += 9 }
    ldxdw r3, [r5+0x38]                     
    lddw r6, 0x270db9834dfc1ab6                     r6 load str located at 2814109315776649910
    jne r3, r6, lbb_16374                           if r3 != r6 { pc += 5 }
    mov64 r3, 1                                     r3 = 1 as i32 as i64 as u64
    ldxdw r5, [r5+0x40]                     
    lddw r6, 0xfc8ba1d828f9bdfe                     r6 load str located at -248927404616466946
    jeq r5, r6, lbb_16392                           if r5 == r6 { pc += 18 }
lbb_16374:
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
    ldxdw r5, [r10-0xa38]                   
    ldxdw r6, [r5+0x28]                     
    jne r6, r0, lbb_16392                           if r6 != r0 { pc += 14 }
    ldxdw r0, [r5+0x30]                     
    lddw r6, 0xdacd6ce4bc5d4218                     r6 load str located at -2680366473547005416
    jne r0, r6, lbb_16392                           if r0 != r6 { pc += 10 }
    ldxdw r0, [r5+0x38]                     
    lddw r6, 0x270db9834dfc1ab6                     r6 load str located at 2814109315776649910
    jne r0, r6, lbb_16392                           if r0 != r6 { pc += 6 }
    ldxdw r5, [r5+0x40]                     
    mov64 r3, 1                                     r3 = 1 as i32 as i64 as u64
    lddw r0, 0xfc8ba1d828f9bdfe                     r0 load str located at -248927404616466946
    jeq r5, r0, lbb_16392                           if r5 == r0 { pc += 1 }
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
lbb_16392:
    ldxdw r0, [r10-0xa70]                   
    sub64 r0, r2                                    r0 -= r2   ///  r0 = r0.wrapping_sub(r2)
    mov64 r5, r9                                    r5 = r9
    add64 r5, r7                                    r5 += r7   ///  r5 = r5.wrapping_add(r7)
    add64 r9, r4                                    r9 += r4   ///  r9 = r9.wrapping_add(r4)
    ldxdw r2, [r10-0xb10]                   
    mov64 r4, r2                                    r4 = r2
    mov64 r2, 1                                     r2 = 1 as i32 as i64 as u64
    jne r4, 0, lbb_16402                            if r4 != (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
lbb_16402:
    ldxdw r4, [r10-0xaa8]                   
    stxdw [r10-0x168], r4                   
    ldxdw r4, [r10-0xab8]                   
    stxdw [r10-0x170], r4                   
    mov64 r4, r10                                   r4 = r10
    add64 r4, -2624                                 r4 += -2624   ///  r4 = r4.wrapping_add(-2624 as i32 as i64 as u64)
    stxdw [r10-0x178], r4                   
    ldxdw r4, [r10-0xa98]                   
    stxdw [r10-0x180], r4                   
    ldxdw r4, [r10-0xa90]                   
    stxdw [r10-0x188], r4                   
    ldxdw r4, [r10-0xa88]                   
    stxdw [r10-0x190], r4                   
    ldxdw r4, [r10-0xa80]                   
    stxdw [r10-0x198], r4                   
    stxdw [r10-0x1a0], r5                   
    ldxdw r4, [r10-0xb08]                   
    stxh [r10-0x160], r4                    
    stxdw [r10-0x1b0], r1                   
    stxdw [r10-0x1b8], r0                   
    stxdw [r10-0x1c0], r9                   
    ldxdw r1, [r10-0xb00]                   
    stxdw [r10-0x1a8], r1                   
    and64 r3, 1                                     r3 &= 1   ///  r3 = r3.and(1)
    stxb [r10-0x15c], r3                    
    stxb [r10-0x15e], r2                    
    stb [r10-0x15d], 0                      
    ldxdw r2, [r10-0xaf8]                   
    jge r2, 41, lbb_18234                           if r2 >= (41 as i32 as i64 as u64) { pc += 1803 }
    lsh64 r2, 3                                     r2 <<= 3   ///  r2 = r2.wrapping_shl(3)
    lddw r1, 0x1000280a8 --> b"\x00\x00\x00\x00`=\x00\x00\x00\x00\x00\x00(H\x00\x00\x00\x00\x00\x000S\x0…        r1 load str located at 4295131304
    add64 r1, r2                                    r1 += r2   ///  r1 = r1.wrapping_add(r2)
    ldxdw r3, [r1+0x0]                      
    mov64 r1, r10                                   r1 = r10
    add64 r1, -2648                                 r1 += -2648   ///  r1 = r1.wrapping_add(-2648 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -448                                  r2 += -448   ///  r2 = r2.wrapping_add(-448 as i32 as i64 as u64)
    callx r3                                
    ldxw r0, [r10-0xa58]                    
    jne r0, 26, lbb_17916                           if r0 != (26 as i32 as i64 as u64) { pc += 1473 }
    ldxdw r1, [r10-0xa38]                   
    ldxdw r2, [r1+0x50]                     
    jlt r2, 72, lbb_18174                           if r2 < (72 as i32 as i64 as u64) { pc += 1728 }
    mov64 r5, 1771                                  r5 = 1771 as i32 as i64 as u64
    ldxdw r1, [r1+0x98]                     
    jlt r1, r8, lbb_18200                           if r1 < r8 { pc += 1751 }
    sub64 r1, r8                                    r1 -= r8   ///  r1 = r1.wrapping_sub(r8)
    mov64 r6, 0                                     r6 = 0 as i32 as i64 as u64
    mov64 r5, 1772                                  r5 = 1772 as i32 as i64 as u64
    ldxdw r2, [r10-0xb20]                   
    jge r1, r2, lbb_18136                           if r1 >= r2 { pc += 1682 }
    ja lbb_18200                                    if true { pc += 1745 }
lbb_16455:
    lddw r4, 0x4cfbdb8200836fd2                     r4 load str located at 5547268717437743058
    jne r3, r4, lbb_17643                           if r3 != r4 { pc += 1185 }
    ldxdw r3, [r1+0x18]                     
    lddw r4, 0x33559cb08794b05b                     r4 load str located at 3699034950957576283
    jne r3, r4, lbb_17643                           if r3 != r4 { pc += 1181 }
    ldxdw r3, [r1+0x20]                     
    lddw r4, 0xa2e8696d479bf0b2                     r4 load str located at -6707995726894600014
    jne r3, r4, lbb_17643                           if r3 != r4 { pc += 1177 }
    ldxdw r3, [r1+0x28]                     
    lddw r4, 0xb50d9a20d7d2fe4c                     r4 load str located at -5400490912296796596
    jne r3, r4, lbb_17643                           if r3 != r4 { pc += 1173 }
lbb_16470:
    ldxb r5, [r8+0x9]                       
    mov64 r3, r5                                    r3 = r5
    lsh64 r3, 1                                     r3 <<= 1   ///  r3 = r3.wrapping_shl(1)
    add64 r3, 9                                     r3 += 9   ///  r3 = r3.wrapping_add(9 as i32 as i64 as u64)
    jne r3, r2, lbb_18134                           if r3 != r2 { pc += 1659 }
    stxdw [r10-0xa70], r2                   
    ldxdw r3, [r10-0xa28]                   
    ldxdw r4, [r3+0x50]                     
    jlt r4, 72, lbb_18174                           if r4 < (72 as i32 as i64 as u64) { pc += 1695 }
    mov64 r6, r1                                    r6 = r1
    ldxdw r7, [r10-0xa38]                   
    ldxb r1, [r7+0x0]                       
    mov64 r4, r1                                    r4 = r1
    and64 r4, 15                                    r4 &= 15   ///  r4 = r4.and(15)
    jne r4, 15, lbb_18183                           if r4 != (15 as i32 as i64 as u64) { pc += 1698 }
    stxdw [r10-0xa80], r5                   
    ldxb r9, [r8+0x12]                      
    ldxdw r2, [r8+0xa]                      
    stxdw [r10-0xab8], r2                   
    ldxdw r8, [r3+0x98]                     
    and64 r1, 247                                   r1 &= 247   ///  r1 = r1.and(247)
    stxb [r7+0x0], r1                       
    stdw [r10-0x1a8], 0                     
    stdw [r10-0x1b0], 0                     
    stdw [r10-0x1b8], 0                     
    stdw [r10-0x1c0], 0                     
    mov64 r1, r10                                   r1 = r10
    add64 r1, -448                                  r1 += -448   ///  r1 = r1.wrapping_add(-448 as i32 as i64 as u64)
    syscall [invalid]                       
    mov64 r2, r9                                    r2 = r9
    mov64 r1, 96                                    r1 = 96 as i32 as i64 as u64
    jeq r2, 0, lbb_16503                            if r2 == (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r1, 104                                   r1 = 104 as i32 as i64 as u64
lbb_16503:
    ldxdw r2, [r10-0x1c0]                   
    stxdw [r7+0x58], r2                     
    mov64 r2, r7                                    r2 = r7
    add64 r2, r1                                    r2 += r1   ///  r2 = r2.wrapping_add(r1)
    stxdw [r2+0x0], r8                      
    ldxb r1, [r7+0x0]                       
    or64 r1, 8                                      r1 |= 8   ///  r1 = r1.or(8)
    stxb [r7+0x0], r1                       
    mov64 r5, r6                                    r5 = r6
    ldxdw r2, [r10-0xa70]                   
    ldxdw r4, [r10-0xa80]                   
    jeq r4, 0, lbb_17907                            if r4 == (0 as i32 as i64 as u64) { pc += 1392 }
    mov64 r1, r10                                   r1 = r10
    add64 r1, -2568                                 r1 += -2568   ///  r1 = r1.wrapping_add(-2568 as i32 as i64 as u64)
    stxdw [r10-0xac0], r1                   
    mov64 r6, r10                                   r6 = r10
    add64 r6, -2576                                 r6 += -2576   ///  r6 = r6.wrapping_add(-2576 as i32 as i64 as u64)
    mov64 r1, r10                                   r1 = r10
    add64 r1, -2584                                 r1 += -2584   ///  r1 = r1.wrapping_add(-2584 as i32 as i64 as u64)
    stxdw [r10-0xa88], r1                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -2608                                 r1 += -2608   ///  r1 = r1.wrapping_add(-2608 as i32 as i64 as u64)
    stxdw [r10-0xa90], r1                   
    add64 r5, 16                                    r5 += 16   ///  r5 = r5.wrapping_add(16 as i32 as i64 as u64)
    mov64 r7, 0                                     r7 = 0 as i32 as i64 as u64
    mov64 r8, r10                                   r8 = r10
    add64 r8, -2544                                 r8 += -2544   ///  r8 = r8.wrapping_add(-2544 as i32 as i64 as u64)
    mov64 r1, r10                                   r1 = r10
    add64 r1, -112                                  r1 += -112   ///  r1 = r1.wrapping_add(-112 as i32 as i64 as u64)
    stxdw [r10-0xa98], r1                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -496                                  r1 += -496   ///  r1 = r1.wrapping_add(-496 as i32 as i64 as u64)
    stxdw [r10-0xaa0], r1                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -448                                  r1 += -448   ///  r1 = r1.wrapping_add(-448 as i32 as i64 as u64)
    stxdw [r10-0xaa8], r1                   
    add64 r2, -9                                    r2 += -9   ///  r2 = r2.wrapping_add(-9 as i32 as i64 as u64)
    mov64 r9, 0                                     r9 = 0 as i32 as i64 as u64
    stxdw [r10-0xa78], r5                   
    stxdw [r10-0xa70], r2                   
    stxdw [r10-0xab0], r6                   
    ja lbb_16631                                    if true { pc += 86 }
lbb_16545:
    ldxdw r6, [r10-0xa00]                   
    ldxdw r0, [r10-0xa18]                   
    add64 r0, 8                                     r0 += 8   ///  r0 = r0.wrapping_add(8 as i32 as i64 as u64)
    ldxdw r2, [r4+0x0]                      
    stxdw [r10-0x210], r0                   
    add64 r5, 8                                     r5 += 8   ///  r5 = r5.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x220], r5                   
    ldxdw r5, [r10-0xa30]                   
    add64 r5, 8                                     r5 += 8   ///  r5 = r5.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x230], r5                   
    add64 r3, 8                                     r3 += 8   ///  r3 = r3.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x240], r3                   
    ldxdw r3, [r10-0xa78]                   
    stxdw [r10-0x250], r3                   
    add64 r2, 8                                     r2 += 8   ///  r2 = r2.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x200], r2                   
    sth [r10-0x1f8], 0                      
    sth [r10-0x208], 0                      
    sth [r10-0x218], 0                      
    sth [r10-0x228], 0                      
    sth [r10-0x238], 1                      
    sth [r10-0x248], 257                    
    stxdw [r10-0x1c8], r4                   
    ldxdw r2, [r10-0xa88]                   
    stxdw [r10-0x1d0], r2                   
    stxdw [r10-0x1d8], r1                   
    ldxdw r1, [r10-0xa90]                   
    stxdw [r10-0x1e0], r1                   
    stxdw [r10-0x1e8], r8                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -2624                                 r1 += -2624   ///  r1 = r1.wrapping_add(-2624 as i32 as i64 as u64)
    stxdw [r10-0x1f0], r1                   
    ldxdw r1, [r10-0xa98]                   
    stxdw [r10-0x20], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -448                                  r1 += -448   ///  r1 = r1.wrapping_add(-448 as i32 as i64 as u64)
    stxdw [r10-0x28], r1                    
    ldxdw r1, [r10-0xaa0]                   
    stxdw [r10-0x48], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -592                                  r1 += -592   ///  r1 = r1.wrapping_add(-592 as i32 as i64 as u64)
    stxdw [r10-0x50], r1                    
    ldxdw r1, [r10-0xaa8]                   
    stxdw [r10-0x58], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -496                                  r1 += -496   ///  r1 = r1.wrapping_add(-496 as i32 as i64 as u64)
    stxdw [r10-0x60], r1                    
    stdw [r10-0x8], 6                       
    stdw [r10-0x10], 6                      
    stdw [r10-0x18], 0                      
    stdw [r10-0x30], 6                      
    stdw [r10-0x38], 6                      
    stdw [r10-0x40], 0                      
    mov64 r1, r10                                   r1 = r10
    add64 r1, -96                                   r1 += -96   ///  r1 = r1.wrapping_add(-96 as i32 as i64 as u64)
    call function_0                         
    mov64 r1, r0                                    r1 = r0
    lsh64 r1, 32                                    r1 <<= 32   ///  r1 = r1.wrapping_shl(32)
    rsh64 r1, 32                                    r1 >>= 32   ///  r1 = r1.wrapping_shr(32)
    jne r1, 26, lbb_17921                           if r1 != (26 as i32 as i64 as u64) { pc += 1316 }
    lddw r1, 0x1000259e1 --> b"\x01\x09attempt to divide with overflow but the index is"        r1 load str located at 4295121377
    stxdw [r10-0x48], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -592                                  r1 += -592   ///  r1 = r1.wrapping_add(-592 as i32 as i64 as u64)
    stxdw [r10-0x58], r1                    
    add64 r6, 8                                     r6 += 8   ///  r6 = r6.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x60], r6                    
    stdw [r10-0x40], 1                      
    stdw [r10-0x50], 6                      
    mov64 r1, r10                                   r1 = r10
    add64 r1, -96                                   r1 += -96   ///  r1 = r1.wrapping_add(-96 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -448                                  r2 += -448   ///  r2 = r2.wrapping_add(-448 as i32 as i64 as u64)
    mov64 r3, 6                                     r3 = 6 as i32 as i64 as u64
    mov64 r4, 8                                     r4 = 8 as i32 as i64 as u64
    mov64 r5, 0                                     r5 = 0 as i32 as i64 as u64
    syscall [invalid]                       
    ldxdw r5, [r10-0xa78]                   
    ldxdw r2, [r10-0xa70]                   
    ldxdw r4, [r10-0xa80]                   
    ldxdw r6, [r10-0xab0]                   
lbb_16627:
    add64 r9, 1                                     r9 += 1   ///  r9 = r9.wrapping_add(1 as i32 as i64 as u64)
    add64 r8, 16                                    r8 += 16   ///  r8 = r8.wrapping_add(16 as i32 as i64 as u64)
    add64 r7, 2                                     r7 += 2   ///  r7 = r7.wrapping_add(2 as i32 as i64 as u64)
    jge r9, r4, lbb_17907                           if r9 >= r4 { pc += 1276 }
lbb_16631:
    jge r7, r2, lbb_18331                           if r7 >= r2 { pc += 1699 }
    mov64 r1, r7                                    r1 = r7
    add64 r1, 1                                     r1 += 1   ///  r1 = r1.wrapping_add(1 as i32 as i64 as u64)
    jge r1, r2, lbb_18335                           if r1 >= r2 { pc += 1700 }
    ldxdw r3, [r8+0x0]                      
    ldxdw r1, [r3+0x50]                     
    jne r1, 0, lbb_16627                            if r1 != (0 as i32 as i64 as u64) { pc += -11 }
    mov64 r1, r8                                    r1 = r8
    add64 r1, -8                                    r1 += -8   ///  r1 = r1.wrapping_add(-8 as i32 as i64 as u64)
    ldxdw r5, [r1+0x0]                      
    ldxdw r0, [r5+0x28]                     
    mov64 r4, r6                                    r4 = r6
    lddw r2, 0xde8f75eee1f6dd06                     r2 load str located at -2409577606766207738
    jne r0, r2, lbb_16545                           if r0 != r2 { pc += -101 }
    ldxdw r0, [r5+0x30]                     
    mov64 r4, r6                                    r4 = r6
    lddw r2, 0xdacd6ce4bc5d4218                     r2 load str located at -2680366473547005416
    jne r0, r2, lbb_16545                           if r0 != r2 { pc += -106 }
    ldxdw r0, [r5+0x38]                     
    mov64 r4, r6                                    r4 = r6
    lddw r2, 0x270db9834dfc1ab6                     r2 load str located at 2814109315776649910
    jne r0, r2, lbb_16545                           if r0 != r2 { pc += -111 }
    ldxdw r0, [r5+0x40]                     
    mov64 r4, r6                                    r4 = r6
    lddw r2, 0xfc8ba1d828f9bdfe                     r2 load str located at -248927404616466946
    jne r0, r2, lbb_16545                           if r0 != r2 { pc += -116 }
    ldxdw r4, [r10-0xac0]                   
    ja lbb_16545                                    if true { pc += -118 }
lbb_16663:
    lddw r4, 0x4cfbdb8200836fd2                     r4 load str located at 5547268717437743058
    jne r3, r4, lbb_17643                           if r3 != r4 { pc += 977 }
    ldxdw r3, [r1+0x18]                     
    lddw r4, 0x33559cb08794b05b                     r4 load str located at 3699034950957576283
    jne r3, r4, lbb_17643                           if r3 != r4 { pc += 973 }
    ldxdw r3, [r1+0x20]                     
    lddw r4, 0xa2e8696d479bf0b2                     r4 load str located at -6707995726894600014
    jne r3, r4, lbb_17643                           if r3 != r4 { pc += 969 }
    ldxdw r1, [r1+0x28]                     
    lddw r3, 0xb50d9a20d7d2fe4c                     r3 load str located at -5400490912296796596
    jne r1, r3, lbb_17643                           if r1 != r3 { pc += 965 }
lbb_16678:
    ldxdw r1, [r10-0xa30]                   
    ldxdw r3, [r1+0x50]                     
    jlt r3, 72, lbb_18174                           if r3 < (72 as i32 as i64 as u64) { pc += 1493 }
    ldxdw r6, [r10-0xa38]                   
    ldxb r3, [r6+0x0]                       
    mov64 r4, r3                                    r4 = r3
    and64 r4, 15                                    r4 &= 15   ///  r4 = r4.and(15)
    jne r4, 15, lbb_18183                           if r4 != (15 as i32 as i64 as u64) { pc += 1497 }
    ldxb r8, [r8+0x12]                      
    ldxdw r7, [r1+0x98]                     
    and64 r3, 247                                   r3 &= 247   ///  r3 = r3.and(247)
    stxb [r6+0x0], r3                       
    stdw [r10-0x1a8], 0                     
    stdw [r10-0x1b0], 0                     
    stdw [r10-0x1b8], 0                     
    stdw [r10-0x1c0], 0                     
    mov64 r1, r10                                   r1 = r10
    add64 r1, -448                                  r1 += -448   ///  r1 = r1.wrapping_add(-448 as i32 as i64 as u64)
    syscall [invalid]                       
    mov64 r2, r8                                    r2 = r8
    mov64 r1, 96                                    r1 = 96 as i32 as i64 as u64
    jeq r2, 0, lbb_16701                            if r2 == (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r1, 104                                   r1 = 104 as i32 as i64 as u64
lbb_16701:
    ldxdw r2, [r10-0x1c0]                   
    stxdw [r6+0x58], r2                     
    mov64 r2, r6                                    r2 = r6
    add64 r2, r1                                    r2 += r1   ///  r2 = r2.wrapping_add(r1)
    stxdw [r2+0x0], r7                      
    ldxb r1, [r6+0x0]                       
    or64 r1, 8                                      r1 |= 8   ///  r1 = r1.or(8)
    stxb [r6+0x0], r1                       
    mov64 r6, 0                                     r6 = 0 as i32 as i64 as u64
    ja lbb_18136                                    if true { pc += 1425 }
lbb_16711:
    lddw r5, 0x4cfbdb8200836fd2                     r5 load str located at 5547268717437743058
    jne r4, r5, lbb_17643                           if r4 != r5 { pc += 929 }
    ldxdw r4, [r1+0x18]                     
    lddw r5, 0x33559cb08794b05b                     r5 load str located at 3699034950957576283
    jne r4, r5, lbb_17643                           if r4 != r5 { pc += 925 }
    ldxdw r4, [r1+0x20]                     
    lddw r5, 0xa2e8696d479bf0b2                     r5 load str located at -6707995726894600014
    jne r4, r5, lbb_17643                           if r4 != r5 { pc += 921 }
    ldxdw r1, [r1+0x28]                     
    lddw r4, 0xb50d9a20d7d2fe4c                     r4 load str located at -5400490912296796596
    jne r1, r4, lbb_17643                           if r1 != r4 { pc += 917 }
lbb_16726:
    jlt r3, 42, lbb_18150                           if r3 < (42 as i32 as i64 as u64) { pc += 1423 }
    add64 r2, -8                                    r2 += -8   ///  r2 = r2.wrapping_add(-8 as i32 as i64 as u64)
    ldxb r5, [r8+0x19]                      
    jle r2, r5, lbb_18234                           if r2 <= r5 { pc += 1504 }
    stxdw [r10-0xa70], r2                   
    ldxdw r1, [r10-0xa38]                   
    ldxdw r3, [r1+0x50]                     
    jlt r3, 72, lbb_18174                           if r3 < (72 as i32 as i64 as u64) { pc += 1440 }
    ldxdw r3, [r10-0xa30]                   
    ldxdw r4, [r3+0x50]                     
    jlt r4, 72, lbb_18174                           if r4 < (72 as i32 as i64 as u64) { pc += 1437 }
    stxdw [r10-0xab0], r5                   
    ldxb r5, [r8+0x1b]                      
    ldxdw r4, [r1+0x28]                     
    lddw r0, 0xde8f75eee1f6dd06                     r0 load str located at -2409577606766207738
    jne r4, r0, lbb_16756                           if r4 != r0 { pc += 13 }
    ldxdw r4, [r1+0x30]                     
    lddw r6, 0xdacd6ce4bc5d4218                     r6 load str located at -2680366473547005416
    jne r4, r6, lbb_16756                           if r4 != r6 { pc += 9 }
    ldxdw r4, [r1+0x38]                     
    lddw r6, 0x270db9834dfc1ab6                     r6 load str located at 2814109315776649910
    jne r4, r6, lbb_16756                           if r4 != r6 { pc += 5 }
    mov64 r4, 1                                     r4 = 1 as i32 as i64 as u64
    ldxdw r6, [r1+0x40]                     
    lddw r7, 0xfc8ba1d828f9bdfe                     r7 load str located at -248927404616466946
    jeq r6, r7, lbb_16773                           if r6 == r7 { pc += 17 }
lbb_16756:
    mov64 r4, 0                                     r4 = 0 as i32 as i64 as u64
    ldxdw r6, [r3+0x28]                     
    jne r6, r0, lbb_16773                           if r6 != r0 { pc += 14 }
    ldxdw r0, [r3+0x30]                     
    lddw r6, 0xdacd6ce4bc5d4218                     r6 load str located at -2680366473547005416
    jne r0, r6, lbb_16773                           if r0 != r6 { pc += 10 }
    ldxdw r0, [r3+0x38]                     
    lddw r6, 0x270db9834dfc1ab6                     r6 load str located at 2814109315776649910
    jne r0, r6, lbb_16773                           if r0 != r6 { pc += 6 }
    ldxdw r0, [r3+0x40]                     
    mov64 r4, 1                                     r4 = 1 as i32 as i64 as u64
    lddw r6, 0xfc8ba1d828f9bdfe                     r6 load str located at -248927404616466946
    jeq r0, r6, lbb_16773                           if r0 == r6 { pc += 1 }
    mov64 r4, 0                                     r4 = 0 as i32 as i64 as u64
lbb_16773:
    mov64 r2, r10                                   r2 = r10
    add64 r2, -2560                                 r2 += -2560   ///  r2 = r2.wrapping_add(-2560 as i32 as i64 as u64)
    stxdw [r10-0xa78], r2                   
    mov64 r2, r10                                   r2 = r10
    add64 r2, -2568                                 r2 += -2568   ///  r2 = r2.wrapping_add(-2568 as i32 as i64 as u64)
    stxdw [r10-0xab8], r2                   
    mov64 r2, r10                                   r2 = r10
    add64 r2, -2576                                 r2 += -2576   ///  r2 = r2.wrapping_add(-2576 as i32 as i64 as u64)
    stxdw [r10-0xa98], r2                   
    mov64 r2, r10                                   r2 = r10
    add64 r2, -2584                                 r2 += -2584   ///  r2 = r2.wrapping_add(-2584 as i32 as i64 as u64)
    stxdw [r10-0xa90], r2                   
    mov64 r2, r10                                   r2 = r10
    add64 r2, -2592                                 r2 += -2592   ///  r2 = r2.wrapping_add(-2592 as i32 as i64 as u64)
    stxdw [r10-0xa88], r2                   
    mov64 r2, r10                                   r2 = r10
    add64 r2, -2600                                 r2 += -2600   ///  r2 = r2.wrapping_add(-2600 as i32 as i64 as u64)
    stxdw [r10-0xa80], r2                   
    mov64 r2, r10                                   r2 = r10
    add64 r2, -2608                                 r2 += -2608   ///  r2 = r2.wrapping_add(-2608 as i32 as i64 as u64)
    stxdw [r10-0xaa0], r2                   
    mov64 r2, r10                                   r2 = r10
    add64 r2, -2616                                 r2 += -2616   ///  r2 = r2.wrapping_add(-2616 as i32 as i64 as u64)
    stxdw [r10-0xaa8], r2                   
    ldxb r0, [r8+0x1a]                      
    ldxh r7, [r8+0x24]                      
    ldxdw r2, [r8+0x1c]                     
    stxdw [r10-0xac0], r2                   
    ldxdw r6, [r8+0x9]                      
    mov64 r9, r5                                    r9 = r5
    mov64 r5, 1                                     r5 = 1 as i32 as i64 as u64
    jne r9, 0, lbb_16806                            if r9 != (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r5, 0                                     r5 = 0 as i32 as i64 as u64
lbb_16806:
    ldxh r2, [r8+0x30]                      
    stxdw [r10-0xad0], r2                   
    ldxb r9, [r8+0x26]                      
    ldxdw r2, [r8+0x28]                     
    stxdw [r10-0xac8], r2                   
    ldxdw r2, [r8+0x11]                     
    stxdw [r10-0xae8], r2                   
    ldxb r2, [r8+0x27]                      
    stxdw [r10-0xad8], r2                   
    ldxdw r2, [r3+0x98]                     
    stxdw [r10-0xae0], r2                   
    ldxdw r8, [r1+0x98]                     
    ldxdw r1, [r10-0xaa0]                   
    stxdw [r10-0x168], r1                   
    ldxdw r1, [r10-0xaa8]                   
    stxdw [r10-0x170], r1                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -2624                                 r1 += -2624   ///  r1 = r1.wrapping_add(-2624 as i32 as i64 as u64)
    stxdw [r10-0x178], r1                   
    ldxdw r1, [r10-0xa98]                   
    stxdw [r10-0x180], r1                   
    ldxdw r1, [r10-0xa90]                   
    stxdw [r10-0x188], r1                   
    ldxdw r1, [r10-0xa88]                   
    stxdw [r10-0x190], r1                   
    ldxdw r1, [r10-0xa80]                   
    stxdw [r10-0x198], r1                   
    ldxdw r1, [r10-0xab8]                   
    stxdw [r10-0x1a0], r1                   
    stxh [r10-0x160], r7                    
    stxdw [r10-0x1b0], r6                   
    ldxdw r7, [r10-0xab0]                   
    stxdw [r10-0x1b8], r7                   
    ldxdw r1, [r10-0xa78]                   
    stxdw [r10-0x1c0], r1                   
    ldxdw r1, [r10-0xac0]                   
    stxdw [r10-0x1a8], r1                   
    and64 r4, 1                                     r4 &= 1   ///  r4 = r4.and(1)
    stxb [r10-0x15c], r4                    
    stxb [r10-0x15e], r5                    
    stb [r10-0x15d], 1                      
    jge r0, 41, lbb_18234                           if r0 >= (41 as i32 as i64 as u64) { pc += 1386 }
    lsh64 r0, 3                                     r0 <<= 3   ///  r0 = r0.wrapping_shl(3)
    lddw r1, 0x1000280a8 --> b"\x00\x00\x00\x00`=\x00\x00\x00\x00\x00\x00(H\x00\x00\x00\x00\x00\x000S\x0…        r1 load str located at 4295131304
    add64 r1, r0                                    r1 += r0   ///  r1 = r1.wrapping_add(r0)
    ldxdw r3, [r1+0x0]                      
    mov64 r1, r10                                   r1 = r10
    add64 r1, -2656                                 r1 += -2656   ///  r1 = r1.wrapping_add(-2656 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -448                                  r2 += -448   ///  r2 = r2.wrapping_add(-448 as i32 as i64 as u64)
    callx r3                                
    ldxw r0, [r10-0xa60]                    
    jne r0, 26, lbb_17646                           if r0 != (26 as i32 as i64 as u64) { pc += 786 }
    ldxdw r5, [r10-0xa30]                   
    ldxdw r1, [r5+0x50]                     
    jlt r1, 72, lbb_18174                           if r1 < (72 as i32 as i64 as u64) { pc += 1311 }
    ldxdw r2, [r5+0x98]                     
    mov64 r3, r2                                    r3 = r2
    ldxdw r1, [r10-0xae0]                   
    sub64 r3, r1                                    r3 -= r1   ///  r3 = r3.wrapping_sub(r1)
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    mov64 r4, 1                                     r4 = 1 as i32 as i64 as u64
    jgt r3, r2, lbb_16871                           if r3 > r2 { pc += 1 }
    mov64 r4, 0                                     r4 = 0 as i32 as i64 as u64
lbb_16871:
    mov64 r2, r7                                    r2 = r7
    add64 r2, 1                                     r2 += 1   ///  r2 = r2.wrapping_add(1 as i32 as i64 as u64)
    jne r4, 0, lbb_16875                            if r4 != (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r1, r3                                    r1 = r3
lbb_16875:
    lsh64 r7, 3                                     r7 <<= 3   ///  r7 = r7.wrapping_shl(3)
    mov64 r4, r2                                    r4 = r2
    lsh64 r4, 3                                     r4 <<= 3   ///  r4 = r4.wrapping_shl(3)
    ldxdw r3, [r5+0x28]                     
    lddw r0, 0xde8f75eee1f6dd06                     r0 load str located at -2409577606766207738
    jne r3, r0, lbb_16895                           if r3 != r0 { pc += 13 }
    ldxdw r3, [r5+0x30]                     
    lddw r6, 0xdacd6ce4bc5d4218                     r6 load str located at -2680366473547005416
    jne r3, r6, lbb_16895                           if r3 != r6 { pc += 9 }
    ldxdw r3, [r5+0x38]                     
    lddw r6, 0x270db9834dfc1ab6                     r6 load str located at 2814109315776649910
    jne r3, r6, lbb_16895                           if r3 != r6 { pc += 5 }
    mov64 r3, 1                                     r3 = 1 as i32 as i64 as u64
    ldxdw r5, [r5+0x40]                     
    lddw r6, 0xfc8ba1d828f9bdfe                     r6 load str located at -248927404616466946
    jeq r5, r6, lbb_16913                           if r5 == r6 { pc += 18 }
lbb_16895:
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
    ldxdw r5, [r10-0xa38]                   
    ldxdw r6, [r5+0x28]                     
    jne r6, r0, lbb_16913                           if r6 != r0 { pc += 14 }
    ldxdw r0, [r5+0x30]                     
    lddw r6, 0xdacd6ce4bc5d4218                     r6 load str located at -2680366473547005416
    jne r0, r6, lbb_16913                           if r0 != r6 { pc += 10 }
    ldxdw r0, [r5+0x38]                     
    lddw r6, 0x270db9834dfc1ab6                     r6 load str located at 2814109315776649910
    jne r0, r6, lbb_16913                           if r0 != r6 { pc += 6 }
    ldxdw r5, [r5+0x40]                     
    mov64 r3, 1                                     r3 = 1 as i32 as i64 as u64
    lddw r0, 0xfc8ba1d828f9bdfe                     r0 load str located at -248927404616466946
    jeq r5, r0, lbb_16913                           if r5 == r0 { pc += 1 }
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
lbb_16913:
    ldxdw r0, [r10-0xa70]                   
    sub64 r0, r2                                    r0 -= r2   ///  r0 = r0.wrapping_sub(r2)
    ldxdw r6, [r10-0xa78]                   
    mov64 r5, r6                                    r5 = r6
    add64 r5, r7                                    r5 += r7   ///  r5 = r5.wrapping_add(r7)
    add64 r6, r4                                    r6 += r4   ///  r6 = r6.wrapping_add(r4)
    ldxdw r2, [r10-0xad8]                   
    mov64 r4, r2                                    r4 = r2
    mov64 r2, 1                                     r2 = 1 as i32 as i64 as u64
    jne r4, 0, lbb_16924                            if r4 != (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
lbb_16924:
    ldxdw r4, [r10-0xaa8]                   
    stxdw [r10-0x168], r4                   
    ldxdw r4, [r10-0xaa0]                   
    stxdw [r10-0x170], r4                   
    mov64 r4, r10                                   r4 = r10
    add64 r4, -2624                                 r4 += -2624   ///  r4 = r4.wrapping_add(-2624 as i32 as i64 as u64)
    stxdw [r10-0x178], r4                   
    ldxdw r4, [r10-0xa98]                   
    stxdw [r10-0x180], r4                   
    ldxdw r4, [r10-0xa90]                   
    stxdw [r10-0x188], r4                   
    ldxdw r4, [r10-0xa88]                   
    stxdw [r10-0x190], r4                   
    ldxdw r4, [r10-0xa80]                   
    stxdw [r10-0x198], r4                   
    stxdw [r10-0x1a0], r5                   
    ldxdw r4, [r10-0xad0]                   
    stxh [r10-0x160], r4                    
    stxdw [r10-0x1b0], r1                   
    stxdw [r10-0x1b8], r0                   
    stxdw [r10-0x1c0], r6                   
    ldxdw r1, [r10-0xac8]                   
    stxdw [r10-0x1a8], r1                   
    and64 r3, 1                                     r3 &= 1   ///  r3 = r3.and(1)
    stxb [r10-0x15c], r3                    
    stxb [r10-0x15e], r2                    
    stb [r10-0x15d], 0                      
    jge r9, 41, lbb_18234                           if r9 >= (41 as i32 as i64 as u64) { pc += 1282 }
    lsh64 r9, 3                                     r9 <<= 3   ///  r9 = r9.wrapping_shl(3)
    lddw r1, 0x1000280a8 --> b"\x00\x00\x00\x00`=\x00\x00\x00\x00\x00\x00(H\x00\x00\x00\x00\x00\x000S\x0…        r1 load str located at 4295131304
    add64 r1, r9                                    r1 += r9   ///  r1 = r1.wrapping_add(r9)
    ldxdw r3, [r1+0x0]                      
    mov64 r1, r10                                   r1 = r10
    add64 r1, -2664                                 r1 += -2664   ///  r1 = r1.wrapping_add(-2664 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -448                                  r2 += -448   ///  r2 = r2.wrapping_add(-448 as i32 as i64 as u64)
    callx r3                                
    ldxw r0, [r10-0xa68]                    
    jne r0, 26, lbb_17903                           if r0 != (26 as i32 as i64 as u64) { pc += 939 }
    ldxdw r1, [r10-0xa38]                   
    ldxdw r2, [r1+0x50]                     
    jlt r2, 72, lbb_18174                           if r2 < (72 as i32 as i64 as u64) { pc += 1207 }
    mov64 r5, 1771                                  r5 = 1771 as i32 as i64 as u64
    ldxdw r1, [r1+0x98]                     
    jlt r1, r8, lbb_18200                           if r1 < r8 { pc += 1230 }
    sub64 r1, r8                                    r1 -= r8   ///  r1 = r1.wrapping_sub(r8)
    mov64 r6, 0                                     r6 = 0 as i32 as i64 as u64
    mov64 r5, 1772                                  r5 = 1772 as i32 as i64 as u64
    ldxdw r2, [r10-0xae8]                   
    jge r1, r2, lbb_18136                           if r1 >= r2 { pc += 1161 }
    ja lbb_18200                                    if true { pc += 1224 }
lbb_16976:
    lddw r4, 0x4cfbdb8200836fd2                     r4 load str located at 5547268717437743058
    jne r3, r4, lbb_17643                           if r3 != r4 { pc += 664 }
    ldxdw r3, [r1+0x18]                     
    lddw r4, 0x33559cb08794b05b                     r4 load str located at 3699034950957576283
    jne r3, r4, lbb_17643                           if r3 != r4 { pc += 660 }
    ldxdw r3, [r1+0x20]                     
    lddw r4, 0xa2e8696d479bf0b2                     r4 load str located at -6707995726894600014
    jne r3, r4, lbb_17643                           if r3 != r4 { pc += 656 }
    ldxdw r1, [r1+0x28]                     
    lddw r3, 0xb50d9a20d7d2fe4c                     r3 load str located at -5400490912296796596
    jne r1, r3, lbb_17643                           if r1 != r3 { pc += 652 }
lbb_16991:
    ldxb r7, [r8+0x12]                      
    ldxdw r6, [r8+0xa]                      
    stdw [r10-0x1a8], 0                     
    stdw [r10-0x1b0], 0                     
    stdw [r10-0x1b8], 0                     
    stdw [r10-0x1c0], 0                     
    mov64 r1, r10                                   r1 = r10
    add64 r1, -448                                  r1 += -448   ///  r1 = r1.wrapping_add(-448 as i32 as i64 as u64)
    syscall [invalid]                       
    ldxdw r1, [r10-0xa38]                   
    ldxb r2, [r1+0x0]                       
    mov64 r3, r2                                    r3 = r2
    and64 r3, 8                                     r3 &= 8   ///  r3 = r3.and(8)
    jeq r3, 0, lbb_18183                            if r3 == (0 as i32 as i64 as u64) { pc += 1178 }
    mov64 r3, r2                                    r3 = r2
    and64 r3, 7                                     r3 &= 7   ///  r3 = r3.and(7)
    jeq r3, 0, lbb_18183                            if r3 == (0 as i32 as i64 as u64) { pc += 1175 }
    ldxdw r3, [r10-0x1c0]                   
    mov64 r4, r2                                    r4 = r2
    add64 r4, -1                                    r4 += -1   ///  r4 = r4.wrapping_add(-1 as i32 as i64 as u64)
    stxb [r1+0x0], r4                       
    ldxdw r4, [r1+0x58]                     
    jne r3, r4, lbb_17899                           if r3 != r4 { pc += 885 }
    ldxdw r3, [r10-0xa30]                   
    ldxdw r4, [r3+0x50]                     
    jle r4, 71, lbb_18328                           if r4 <= (71 as i32 as i64 as u64) { pc += 1311 }
    mov64 r5, r7                                    r5 = r7
    mov64 r4, 96                                    r4 = 96 as i32 as i64 as u64
    jeq r5, 0, lbb_17021                            if r5 == (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r4, 104                                   r4 = 104 as i32 as i64 as u64
lbb_17021:
    mov64 r5, r1                                    r5 = r1
    add64 r5, r4                                    r5 += r4   ///  r5 = r5.wrapping_add(r4)
    mov64 r0, 0                                     r0 = 0 as i32 as i64 as u64
    ldxdw r4, [r5+0x0]                      
    ldxdw r3, [r3+0x98]                     
    jge r3, r4, lbb_17911                           if r3 >= r4 { pc += 884 }
    mov64 r5, 1771                                  r5 = 1771 as i32 as i64 as u64
    stxb [r1+0x0], r2                       
    ja lbb_18124                                    if true { pc += 1094 }
lbb_17030:
    lddw r4, 0x4cfbdb8200836fd2                     r4 load str located at 5547268717437743058
    jne r3, r4, lbb_17643                           if r3 != r4 { pc += 610 }
    ldxdw r3, [r1+0x18]                     
    lddw r4, 0x33559cb08794b05b                     r4 load str located at 3699034950957576283
    jne r3, r4, lbb_17643                           if r3 != r4 { pc += 606 }
    ldxdw r3, [r1+0x20]                     
    lddw r4, 0xa2e8696d479bf0b2                     r4 load str located at -6707995726894600014
    jne r3, r4, lbb_17643                           if r3 != r4 { pc += 602 }
    ldxdw r3, [r1+0x28]                     
    lddw r4, 0xb50d9a20d7d2fe4c                     r4 load str located at -5400490912296796596
    jne r3, r4, lbb_17643                           if r3 != r4 { pc += 598 }
lbb_17045:
    ldxdw r9, [r10-0xa38]                   
    ldxdw r3, [r9+0x8]                      
    lddw r4, 0xca896837f7826fd2                     r4 load str located at -3852433416653738030
    jne r3, r4, lbb_17471                           if r3 != r4 { pc += 421 }
    ldxdw r3, [r9+0x10]                     
    lddw r4, 0x88adfc86574fea83                     r4 load str located at -8597938459659736445
    jne r3, r4, lbb_17486                           if r3 != r4 { pc += 432 }
    ldxdw r3, [r9+0x18]                     
    lddw r4, 0x384d82dd1cab4e18                     r4 load str located at 4057042725511056920
    jne r3, r4, lbb_17486                           if r3 != r4 { pc += 428 }
    ldxdw r3, [r9+0x20]                     
    lddw r4, 0x54a5fa76c74e4713                     r4 load str located at 6099556658400085779
    jeq r3, r4, lbb_17643                           if r3 == r4 { pc += 581 }
    ja lbb_17486                                    if true { pc += 423 }
lbb_17063:
    lddw r3, 0x4cfbdb8200836fd2                     r3 load str located at 5547268717437743058
    jne r2, r3, lbb_17643                           if r2 != r3 { pc += 577 }
    ldxdw r2, [r1+0x18]                     
    lddw r3, 0x33559cb08794b05b                     r3 load str located at 3699034950957576283
    jne r2, r3, lbb_17643                           if r2 != r3 { pc += 573 }
    ldxdw r2, [r1+0x20]                     
    lddw r3, 0xa2e8696d479bf0b2                     r3 load str located at -6707995726894600014
    jne r2, r3, lbb_17643                           if r2 != r3 { pc += 569 }
    ldxdw r1, [r1+0x28]                     
    lddw r2, 0xb50d9a20d7d2fe4c                     r2 load str located at -5400490912296796596
    jne r1, r2, lbb_17643                           if r1 != r2 { pc += 565 }
lbb_17078:
    ldxdw r7, [r10-0xa38]                   
    ldxdw r1, [r7+0x8]                      
    lddw r2, 0xca896837f7826fd2                     r2 load str located at -3852433416653738030
    jne r1, r2, lbb_17628                           if r1 != r2 { pc += 545 }
    ldxdw r1, [r7+0x10]                     
    lddw r2, 0x88adfc86574fea83                     r2 load str located at -8597938459659736445
    jne r1, r2, lbb_17650                           if r1 != r2 { pc += 563 }
    ldxdw r1, [r7+0x18]                     
    lddw r2, 0x384d82dd1cab4e18                     r2 load str located at 4057042725511056920
    jne r1, r2, lbb_17650                           if r1 != r2 { pc += 559 }
    ldxdw r1, [r7+0x20]                     
    lddw r2, 0x54a5fa76c74e4713                     r2 load str located at 6099556658400085779
    jeq r1, r2, lbb_17643                           if r1 == r2 { pc += 548 }
    ja lbb_17650                                    if true { pc += 554 }
lbb_17096:
    lddw r4, 0x4cfbdb8200836fd2                     r4 load str located at 5547268717437743058
    jne r3, r4, lbb_17643                           if r3 != r4 { pc += 544 }
    ldxdw r3, [r1+0x18]                     
    lddw r4, 0x33559cb08794b05b                     r4 load str located at 3699034950957576283
    jne r3, r4, lbb_17643                           if r3 != r4 { pc += 540 }
    ldxdw r3, [r1+0x20]                     
    lddw r4, 0xa2e8696d479bf0b2                     r4 load str located at -6707995726894600014
    jne r3, r4, lbb_17643                           if r3 != r4 { pc += 536 }
    ldxdw r3, [r1+0x28]                     
    lddw r4, 0xb50d9a20d7d2fe4c                     r4 load str located at -5400490912296796596
    jne r3, r4, lbb_17643                           if r3 != r4 { pc += 532 }
lbb_17111:
    ldxb r4, [r8+0x9]                       
    mov64 r3, r4                                    r3 = r4
    lsh64 r3, 1                                     r3 <<= 1   ///  r3 = r3.wrapping_shl(1)
    add64 r3, 9                                     r3 += 9   ///  r3 = r3.wrapping_add(9 as i32 as i64 as u64)
    jne r3, r2, lbb_18134                           if r3 != r2 { pc += 1018 }
    ldxdw r3, [r8+0xa]                      
    stxdw [r10-0xb00], r3                   
    jeq r4, 0, lbb_17806                            if r4 == (0 as i32 as i64 as u64) { pc += 687 }
    mov64 r3, r10                                   r3 = r10
    add64 r3, -2568                                 r3 += -2568   ///  r3 = r3.wrapping_add(-2568 as i32 as i64 as u64)
    stxdw [r10-0xb08], r3                   
    mov64 r5, r10                                   r5 = r10
    add64 r5, -2576                                 r5 += -2576   ///  r5 = r5.wrapping_add(-2576 as i32 as i64 as u64)
    mov64 r3, r1                                    r3 = r1
    add64 r3, 16                                    r3 += 16   ///  r3 = r3.wrapping_add(16 as i32 as i64 as u64)
    stxdw [r10-0xae8], r3                   
    mov64 r6, 0                                     r6 = 0 as i32 as i64 as u64
    mov64 r0, r10                                   r0 = r10
    add64 r0, -2544                                 r0 += -2544   ///  r0 = r0.wrapping_add(-2544 as i32 as i64 as u64)
    add64 r2, -9                                    r2 += -9   ///  r2 = r2.wrapping_add(-9 as i32 as i64 as u64)
    mov64 r9, 0                                     r9 = 0 as i32 as i64 as u64
    stxdw [r10-0xa70], r2                   
    stxdw [r10-0xaf0], r4                   
    stxdw [r10-0xaf8], r5                   
    mov64 r7, 1                                     r7 = 1 as i32 as i64 as u64
    ja lbb_17168                                    if true { pc += 31 }
lbb_17137:
    ldxdw r2, [r10-0xad0]                   
    add64 r2, 8                                     r2 += 8   ///  r2 = r2.wrapping_add(8 as i32 as i64 as u64)
    stxb [r10-0x78], r4                     
    stdw [r10-0x80], 0                      
    lddw r1, 0x1000259e1 --> b"\x01\x09attempt to divide with overflow but the index is"        r1 load str located at 4295121377
    stxdw [r10-0x238], r1                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -96                                   r1 += -96   ///  r1 = r1.wrapping_add(-96 as i32 as i64 as u64)
    stxdw [r10-0x248], r1                   
    stxdw [r10-0x250], r2                   
    stdw [r10-0x230], 1                     
    stdw [r10-0x240], 6                     
    mov64 r1, r10                                   r1 = r10
    add64 r1, -592                                  r1 += -592   ///  r1 = r1.wrapping_add(-592 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -448                                  r2 += -448   ///  r2 = r2.wrapping_add(-448 as i32 as i64 as u64)
    mov64 r3, 6                                     r3 = 6 as i32 as i64 as u64
    mov64 r4, 8                                     r4 = 8 as i32 as i64 as u64
    mov64 r5, 0                                     r5 = 0 as i32 as i64 as u64
    syscall [invalid]                       
    mov64 r1, r6                                    r1 = r6
    ldxdw r2, [r10-0xa70]                   
    ldxdw r4, [r10-0xaf0]                   
    ldxdw r5, [r10-0xaf8]                   
    ldxdw r0, [r10-0xac0]                   
    ldxdw r6, [r10-0xae0]                   
lbb_17164:
    add64 r9, 1                                     r9 += 1   ///  r9 = r9.wrapping_add(1 as i32 as i64 as u64)
    add64 r0, 16                                    r0 += 16   ///  r0 = r0.wrapping_add(16 as i32 as i64 as u64)
    add64 r6, 2                                     r6 += 2   ///  r6 = r6.wrapping_add(2 as i32 as i64 as u64)
    jge r9, r4, lbb_17806                           if r9 >= r4 { pc += 638 }
lbb_17168:
    jge r6, r2, lbb_18342                           if r6 >= r2 { pc += 1173 }
    mov64 r3, r6                                    r3 = r6
    add64 r3, 1                                     r3 += 1   ///  r3 = r3.wrapping_add(1 as i32 as i64 as u64)
    jge r3, r2, lbb_18338                           if r3 >= r2 { pc += 1166 }
    ldxdw r8, [r0+0x0]                      
    ldxdw r3, [r8+0x50]                     
    jne r3, 0, lbb_17164                            if r3 != (0 as i32 as i64 as u64) { pc += -11 }
    stxdw [r10-0xae0], r6                   
    stxdw [r10-0xac8], r9                   
    stxdw [r10-0xac0], r0                   
    ldxdw r0, [r0-0x8]                      
    ldxdw r3, [r0+0x28]                     
    mov64 r2, r5                                    r2 = r5
    lddw r4, 0xde8f75eee1f6dd06                     r4 load str located at -2409577606766207738
    jne r3, r4, lbb_17200                           if r3 != r4 { pc += 16 }
    ldxdw r3, [r0+0x30]                     
    mov64 r2, r5                                    r2 = r5
    lddw r4, 0xdacd6ce4bc5d4218                     r4 load str located at -2680366473547005416
    jne r3, r4, lbb_17200                           if r3 != r4 { pc += 11 }
    ldxdw r3, [r0+0x38]                     
    mov64 r2, r5                                    r2 = r5
    lddw r4, 0x270db9834dfc1ab6                     r4 load str located at 2814109315776649910
    jne r3, r4, lbb_17200                           if r3 != r4 { pc += 6 }
    ldxdw r3, [r0+0x40]                     
    mov64 r2, r5                                    r2 = r5
    lddw r4, 0xfc8ba1d828f9bdfe                     r4 load str located at -248927404616466946
    jne r3, r4, lbb_17200                           if r3 != r4 { pc += 1 }
    ldxdw r2, [r10-0xb08]                   
lbb_17200:
    mov64 r3, 1                                     r3 = 1 as i32 as i64 as u64
    stxdw [r10-0xa78], r3                   
    ldxdw r3, [r10-0xa00]                   
    stxdw [r10-0xad0], r3                   
    ldxdw r6, [r2+0x0]                      
    ldxdw r2, [r10-0xa18]                   
    stxdw [r10-0xaa0], r2                   
    add64 r2, 8                                     r2 += 8   ///  r2 = r2.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0xab0], r2                   
    stxdw [r10-0x20], r2                    
    stxdw [r10-0xa98], r0                   
    add64 r0, 8                                     r0 += 8   ///  r0 = r0.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0xaa8], r0                   
    stxdw [r10-0x30], r0                    
    ldxdw r3, [r10-0xa30]                   
    mov64 r9, r3                                    r9 = r3
    add64 r9, 8                                     r9 += 8   ///  r9 = r9.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x40], r9                    
    mov64 r5, r8                                    r5 = r8
    add64 r5, 8                                     r5 += 8   ///  r5 = r5.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x50], r5                    
    mov64 r2, r6                                    r2 = r6
    add64 r2, 8                                     r2 += 8   ///  r2 = r2.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0xad8], r2                   
    stxdw [r10-0x10], r2                    
    ldxdw r2, [r10-0xae8]                   
    stxdw [r10-0x60], r2                    
    sth [r10-0x8], 0                        
    sth [r10-0x18], 0                       
    sth [r10-0x28], 0                       
    sth [r10-0x38], 0                       
    sth [r10-0x48], 1                       
    sth [r10-0x58], 257                     
    ldxdw r4, [r10-0xa40]                   
    ldxdw r0, [r2+0x0]                      
    ldxdw r2, [r4+0x8]                      
    jne r2, r0, lbb_17924                           if r2 != r0 { pc += 687 }
    ldxdw r2, [r1+0x18]                     
    ldxdw r0, [r4+0x10]                     
    jne r0, r2, lbb_17924                           if r0 != r2 { pc += 684 }
    ldxdw r2, [r1+0x20]                     
    ldxdw r0, [r4+0x18]                     
    jne r0, r2, lbb_17924                           if r0 != r2 { pc += 681 }
    ldxdw r2, [r1+0x28]                     
    ldxdw r0, [r4+0x20]                     
    jne r0, r2, lbb_17924                           if r0 != r2 { pc += 678 }
    ldxb r2, [r4+0x0]                       
    jne r2, 255, lbb_17922                          if r2 != (255 as i32 as i64 as u64) { pc += 674 }
    ldxb r2, [r4+0x1]                       
    mov64 r0, 1                                     r0 = 1 as i32 as i64 as u64
    stxdw [r10-0xa80], r0                   
    jne r2, 0, lbb_17253                            if r2 != (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r0, 0                                     r0 = 0 as i32 as i64 as u64
lbb_17253:
    ldxb r2, [r4+0x2]                       
    stxdw [r10-0xa88], r7                   
    jne r2, 0, lbb_17258                            if r2 != (0 as i32 as i64 as u64) { pc += 2 }
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
    stxdw [r10-0xa88], r2                   
lbb_17258:
    stxdw [r10-0xa90], r0                   
    stxdw [r10-0xab8], r6                   
    mov64 r2, 11                                    r2 = 11 as i32 as i64 as u64
    stxdw [r10-0xa78], r2                   
    ldxb r2, [r4+0x3]                       
    jne r2, 0, lbb_17266                            if r2 != (0 as i32 as i64 as u64) { pc += 2 }
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
    stxdw [r10-0xa80], r2                   
lbb_17266:
    mov64 r2, r4                                    r2 = r4
    add64 r2, 8                                     r2 += 8   ///  r2 = r2.wrapping_add(8 as i32 as i64 as u64)
    ldxdw r0, [r4+0x50]                     
    mov64 r6, r4                                    r6 = r4
    add64 r6, 40                                    r6 += 40   ///  r6 = r6.wrapping_add(40 as i32 as i64 as u64)
    stxdw [r10-0x1a0], r6                   
    mov64 r6, r4                                    r6 = r4
    add64 r6, 88                                    r6 += 88   ///  r6 = r6.wrapping_add(88 as i32 as i64 as u64)
    stxdw [r10-0x1a8], r6                   
    stxdw [r10-0x1b0], r0                   
    add64 r4, 72                                    r4 += 72   ///  r4 = r4.wrapping_add(72 as i32 as i64 as u64)
    stxdw [r10-0x1b8], r4                   
    stxdw [r10-0x1c0], r2                   
    ldxdw r2, [r10-0xa80]                   
    stxb [r10-0x18e], r2                    
    ldxdw r2, [r10-0xa88]                   
    stxb [r10-0x18f], r2                    
    ldxdw r2, [r10-0xa90]                   
    stxb [r10-0x190], r2                    
    stdw [r10-0x198], 0                     
    ldxb r2, [r8+0x0]                       
    jne r2, 255, lbb_17924                          if r2 != (255 as i32 as i64 as u64) { pc += 636 }
    ldxb r2, [r8+0x1]                       
    mov64 r6, 1                                     r6 = 1 as i32 as i64 as u64
    mov64 r4, 1                                     r4 = 1 as i32 as i64 as u64
    jne r2, 0, lbb_17439                            if r2 != (0 as i32 as i64 as u64) { pc += 147 }
    mov64 r4, 0                                     r4 = 0 as i32 as i64 as u64
    ldxb r2, [r8+0x2]                       
    mov64 r0, 1                                     r0 = 1 as i32 as i64 as u64
    jeq r2, 0, lbb_17442                            if r2 == (0 as i32 as i64 as u64) { pc += 146 }
lbb_17296:
    stxdw [r10-0xa80], r4                   
    ldxb r2, [r8+0x3]                       
    jne r2, 0, lbb_17300                            if r2 != (0 as i32 as i64 as u64) { pc += 1 }
lbb_17299:
    mov64 r6, 0                                     r6 = 0 as i32 as i64 as u64
lbb_17300:
    ldxdw r2, [r8+0x50]                     
    mov64 r4, r8                                    r4 = r8
    add64 r4, 40                                    r4 += 40   ///  r4 = r4.wrapping_add(40 as i32 as i64 as u64)
    stxdw [r10-0x168], r4                   
    mov64 r4, r8                                    r4 = r8
    add64 r4, 88                                    r4 += 88   ///  r4 = r4.wrapping_add(88 as i32 as i64 as u64)
    stxdw [r10-0x170], r4                   
    stxdw [r10-0x178], r2                   
    add64 r8, 72                                    r8 += 72   ///  r8 = r8.wrapping_add(72 as i32 as i64 as u64)
    stxdw [r10-0x180], r8                   
    stxdw [r10-0x188], r5                   
    stxb [r10-0x156], r6                    
    stxb [r10-0x157], r0                    
    ldxdw r2, [r10-0xa80]                   
    stxb [r10-0x158], r2                    
    stdw [r10-0x160], 0                     
    ldxb r2, [r3+0x0]                       
    and64 r2, 136                                   r2 &= 136   ///  r2 = r2.and(136)
    jne r2, 136, lbb_17924                          if r2 != (136 as i32 as i64 as u64) { pc += 605 }
    ldxb r2, [r3+0x1]                       
    mov64 r6, 1                                     r6 = 1 as i32 as i64 as u64
    mov64 r5, 1                                     r5 = 1 as i32 as i64 as u64
    jne r2, 0, lbb_17447                            if r2 != (0 as i32 as i64 as u64) { pc += 124 }
    mov64 r5, 0                                     r5 = 0 as i32 as i64 as u64
    ldxb r2, [r3+0x2]                       
    mov64 r0, 1                                     r0 = 1 as i32 as i64 as u64
    jeq r2, 0, lbb_17450                            if r2 == (0 as i32 as i64 as u64) { pc += 123 }
lbb_17327:
    ldxb r2, [r3+0x3]                       
    jne r2, 0, lbb_17330                            if r2 != (0 as i32 as i64 as u64) { pc += 1 }
lbb_17329:
    mov64 r6, 0                                     r6 = 0 as i32 as i64 as u64
lbb_17330:
    ldxdw r2, [r3+0x50]                     
    mov64 r4, r3                                    r4 = r3
    add64 r4, 40                                    r4 += 40   ///  r4 = r4.wrapping_add(40 as i32 as i64 as u64)
    stxdw [r10-0x130], r4                   
    mov64 r4, r3                                    r4 = r3
    add64 r4, 88                                    r4 += 88   ///  r4 = r4.wrapping_add(88 as i32 as i64 as u64)
    stxdw [r10-0x138], r4                   
    stxdw [r10-0x140], r2                   
    add64 r3, 72                                    r3 += 72   ///  r3 = r3.wrapping_add(72 as i32 as i64 as u64)
    stxdw [r10-0x148], r3                   
    stxdw [r10-0x150], r9                   
    stxb [r10-0x11e], r6                    
    stxb [r10-0x11f], r0                    
    stxb [r10-0x120], r5                    
    stdw [r10-0x128], 0                     
    ldxdw r9, [r10-0xa98]                   
    ldxb r2, [r9+0x0]                       
    and64 r2, 136                                   r2 &= 136   ///  r2 = r2.and(136)
    jne r2, 136, lbb_17924                          if r2 != (136 as i32 as i64 as u64) { pc += 575 }
    ldxb r2, [r9+0x1]                       
    mov64 r5, 1                                     r5 = 1 as i32 as i64 as u64
    mov64 r3, 1                                     r3 = 1 as i32 as i64 as u64
    jne r2, 0, lbb_17354                            if r2 != (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
lbb_17354:
    ldxb r2, [r9+0x2]                       
    mov64 r0, 1                                     r0 = 1 as i32 as i64 as u64
    ldxdw r6, [r10-0xab8]                   
    ldxdw r8, [r10-0xaa0]                   
    jne r2, 0, lbb_17360                            if r2 != (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r0, 0                                     r0 = 0 as i32 as i64 as u64
lbb_17360:
    ldxb r2, [r9+0x3]                       
    jne r2, 0, lbb_17363                            if r2 != (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r5, 0                                     r5 = 0 as i32 as i64 as u64
lbb_17363:
    mov64 r2, r9                                    r2 = r9
    add64 r2, 40                                    r2 += 40   ///  r2 = r2.wrapping_add(40 as i32 as i64 as u64)
    ldxdw r4, [r9+0x50]                     
    stxdw [r10-0xf8], r2                    
    mov64 r2, r9                                    r2 = r9
    add64 r2, 88                                    r2 += 88   ///  r2 = r2.wrapping_add(88 as i32 as i64 as u64)
    stxdw [r10-0x100], r2                   
    stxdw [r10-0x108], r4                   
    add64 r9, 72                                    r9 += 72   ///  r9 = r9.wrapping_add(72 as i32 as i64 as u64)
    stxdw [r10-0x110], r9                   
    ldxdw r2, [r10-0xaa8]                   
    stxdw [r10-0x118], r2                   
    stxb [r10-0xe6], r5                     
    stxb [r10-0xe7], r0                     
    stxb [r10-0xe8], r3                     
    stdw [r10-0xf0], 0                      
    ldxb r2, [r8+0x0]                       
    and64 r2, 136                                   r2 &= 136   ///  r2 = r2.and(136)
    jne r2, 136, lbb_17924                          if r2 != (136 as i32 as i64 as u64) { pc += 542 }
    ldxb r4, [r8+0x1]                       
    mov64 r3, 1                                     r3 = 1 as i32 as i64 as u64
    mov64 r2, 1                                     r2 = 1 as i32 as i64 as u64
    jne r4, 0, lbb_17454                            if r4 != (0 as i32 as i64 as u64) { pc += 68 }
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
    ldxb r5, [r8+0x2]                       
    mov64 r4, 1                                     r4 = 1 as i32 as i64 as u64
    jeq r5, 0, lbb_17457                            if r5 == (0 as i32 as i64 as u64) { pc += 67 }
lbb_17390:
    ldxb r5, [r8+0x3]                       
    jne r5, 0, lbb_17393                            if r5 != (0 as i32 as i64 as u64) { pc += 1 }
lbb_17392:
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
lbb_17393:
    ldxdw r5, [r8+0x50]                     
    mov64 r0, r8                                    r0 = r8
    add64 r0, 40                                    r0 += 40   ///  r0 = r0.wrapping_add(40 as i32 as i64 as u64)
    stxdw [r10-0xc0], r0                    
    mov64 r0, r8                                    r0 = r8
    add64 r0, 88                                    r0 += 88   ///  r0 = r0.wrapping_add(88 as i32 as i64 as u64)
    stxdw [r10-0xc8], r0                    
    stxdw [r10-0xd0], r5                    
    add64 r8, 72                                    r8 += 72   ///  r8 = r8.wrapping_add(72 as i32 as i64 as u64)
    stxdw [r10-0xd8], r8                    
    ldxdw r5, [r10-0xab0]                   
    stxdw [r10-0xe0], r5                    
    stxb [r10-0xae], r3                     
    stxb [r10-0xaf], r4                     
    stxb [r10-0xb0], r2                     
    stdw [r10-0xb8], 0                      
    ldxb r2, [r6+0x0]                       
    and64 r2, 136                                   r2 &= 136   ///  r2 = r2.and(136)
    jne r2, 136, lbb_17924                          if r2 != (136 as i32 as i64 as u64) { pc += 512 }
    ldxb r2, [r6+0x1]                       
    ldxb r3, [r6+0x2]                       
    ldxb r0, [r6+0x3]                       
    ldxdw r4, [r6+0x50]                     
    mov64 r5, r6                                    r5 = r6
    add64 r5, 40                                    r5 += 40   ///  r5 = r5.wrapping_add(40 as i32 as i64 as u64)
    stxdw [r10-0x88], r5                    
    mov64 r5, r6                                    r5 = r6
    add64 r5, 88                                    r5 += 88   ///  r5 = r5.wrapping_add(88 as i32 as i64 as u64)
    stxdw [r10-0x90], r5                    
    stxdw [r10-0x98], r4                    
    add64 r6, 72                                    r6 += 72   ///  r6 = r6.wrapping_add(72 as i32 as i64 as u64)
    stxdw [r10-0xa0], r6                    
    ldxdw r4, [r10-0xad8]                   
    stxdw [r10-0xa8], r4                    
    mov64 r4, 1                                     r4 = 1 as i32 as i64 as u64
    mov64 r5, 1                                     r5 = 1 as i32 as i64 as u64
    jne r0, 0, lbb_17461                            if r0 != (0 as i32 as i64 as u64) { pc += 31 }
    mov64 r5, 0                                     r5 = 0 as i32 as i64 as u64
    stxb [r10-0x76], r5                     
    mov64 r5, 1                                     r5 = 1 as i32 as i64 as u64
    ldxdw r9, [r10-0xac8]                   
    jeq r3, 0, lbb_17465                            if r3 == (0 as i32 as i64 as u64) { pc += 30 }
lbb_17435:
    mov64 r6, r1                                    r6 = r1
    stxb [r10-0x77], r5                     
    jne r2, 0, lbb_17137                            if r2 != (0 as i32 as i64 as u64) { pc += -301 }
    ja lbb_17469                                    if true { pc += 30 }
lbb_17439:
    ldxb r2, [r8+0x2]                       
    mov64 r0, 1                                     r0 = 1 as i32 as i64 as u64
    jne r2, 0, lbb_17296                            if r2 != (0 as i32 as i64 as u64) { pc += -146 }
lbb_17442:
    mov64 r0, 0                                     r0 = 0 as i32 as i64 as u64
    stxdw [r10-0xa80], r4                   
    ldxb r2, [r8+0x3]                       
    jeq r2, 0, lbb_17299                            if r2 == (0 as i32 as i64 as u64) { pc += -147 }
    ja lbb_17300                                    if true { pc += -147 }
lbb_17447:
    ldxb r2, [r3+0x2]                       
    mov64 r0, 1                                     r0 = 1 as i32 as i64 as u64
    jne r2, 0, lbb_17327                            if r2 != (0 as i32 as i64 as u64) { pc += -123 }
lbb_17450:
    mov64 r0, 0                                     r0 = 0 as i32 as i64 as u64
    ldxb r2, [r3+0x3]                       
    jeq r2, 0, lbb_17329                            if r2 == (0 as i32 as i64 as u64) { pc += -124 }
    ja lbb_17330                                    if true { pc += -124 }
lbb_17454:
    ldxb r5, [r8+0x2]                       
    mov64 r4, 1                                     r4 = 1 as i32 as i64 as u64
    jne r5, 0, lbb_17390                            if r5 != (0 as i32 as i64 as u64) { pc += -67 }
lbb_17457:
    mov64 r4, 0                                     r4 = 0 as i32 as i64 as u64
    ldxb r5, [r8+0x3]                       
    jeq r5, 0, lbb_17392                            if r5 == (0 as i32 as i64 as u64) { pc += -68 }
    ja lbb_17393                                    if true { pc += -68 }
lbb_17461:
    stxb [r10-0x76], r5                     
    mov64 r5, 1                                     r5 = 1 as i32 as i64 as u64
    ldxdw r9, [r10-0xac8]                   
    jne r3, 0, lbb_17435                            if r3 != (0 as i32 as i64 as u64) { pc += -30 }
lbb_17465:
    mov64 r5, 0                                     r5 = 0 as i32 as i64 as u64
    mov64 r6, r1                                    r6 = r1
    stxb [r10-0x77], r5                     
    jne r2, 0, lbb_17137                            if r2 != (0 as i32 as i64 as u64) { pc += -332 }
lbb_17469:
    mov64 r4, 0                                     r4 = 0 as i32 as i64 as u64
    ja lbb_17137                                    if true { pc += -334 }
lbb_17471:
    lddw r4, 0x4cfbdb8200836fd2                     r4 load str located at 5547268717437743058
    jne r3, r4, lbb_17486                           if r3 != r4 { pc += 12 }
    ldxdw r3, [r9+0x10]                     
    lddw r4, 0x33559cb08794b05b                     r4 load str located at 3699034950957576283
    jne r3, r4, lbb_17486                           if r3 != r4 { pc += 8 }
    ldxdw r3, [r9+0x18]                     
    lddw r4, 0xa2e8696d479bf0b2                     r4 load str located at -6707995726894600014
    jne r3, r4, lbb_17486                           if r3 != r4 { pc += 4 }
    ldxdw r3, [r9+0x20]                     
    lddw r4, 0xb50d9a20d7d2fe4c                     r4 load str located at -5400490912296796596
    jeq r3, r4, lbb_17643                           if r3 == r4 { pc += 157 }
lbb_17486:
    mov64 r7, r2                                    r7 = r2
    stxdw [r10-0xa78], r1                   
    ldxb r1, [r8+0x12]                      
    stxdw [r10-0xa88], r1                   
    ldxdw r6, [r8+0xa]                      
    ldxb r1, [r8+0x9]                       
    stxdw [r10-0xa80], r1                   
    stdw [r10-0x1a8], 0                     
    stdw [r10-0x1b0], 0                     
    stdw [r10-0x1b8], 0                     
    stdw [r10-0x1c0], 0                     
    mov64 r1, r10                                   r1 = r10
    add64 r1, -448                                  r1 += -448   ///  r1 = r1.wrapping_add(-448 as i32 as i64 as u64)
    syscall [invalid]                       
    ldxdw r8, [r10-0xa30]                   
    ldxb r1, [r8+0x0]                       
    mov64 r2, r1                                    r2 = r1
    and64 r2, 8                                     r2 &= 8   ///  r2 = r2.and(8)
    jeq r2, 0, lbb_18183                            if r2 == (0 as i32 as i64 as u64) { pc += 678 }
    mov64 r2, r1                                    r2 = r1
    and64 r2, 7                                     r2 &= 7   ///  r2 = r2.and(7)
    jeq r2, 0, lbb_18183                            if r2 == (0 as i32 as i64 as u64) { pc += 675 }
    ldxdw r2, [r10-0x1c0]                   
    add64 r1, -1                                    r1 += -1   ///  r1 = r1.wrapping_add(-1 as i32 as i64 as u64)
    stxb [r8+0x0], r1                       
    ldxdw r1, [r8+0x58]                     
    jne r2, r1, lbb_17918                           if r2 != r1 { pc += 405 }
    mov64 r0, 3                                     r0 = 3 as i32 as i64 as u64
    mov64 r5, 0                                     r5 = 0 as i32 as i64 as u64
    ldxdw r1, [r10-0xa08]                   
    ldxdw r2, [r1+0x50]                     
    jle r2, 71, lbb_18121                           if r2 <= (71 as i32 as i64 as u64) { pc += 603 }
    ldxdw r2, [r10-0xa10]                   
    ldxdw r3, [r2+0x50]                     
    jlt r3, 32, lbb_18121                           if r3 < (32 as i32 as i64 as u64) { pc += 600 }
    ldxdw r3, [r2+0x58]                     
    ldxdw r4, [r1+0x58]                     
    jne r4, r3, lbb_18121                           if r4 != r3 { pc += 597 }
    ldxdw r3, [r2+0x60]                     
    ldxdw r4, [r1+0x60]                     
    jne r4, r3, lbb_18121                           if r4 != r3 { pc += 594 }
    ldxdw r3, [r2+0x68]                     
    ldxdw r4, [r1+0x68]                     
    jne r4, r3, lbb_18121                           if r4 != r3 { pc += 591 }
    ldxdw r3, [r2+0x70]                     
    ldxdw r4, [r1+0x70]                     
    jne r4, r3, lbb_18121                           if r4 != r3 { pc += 588 }
    stxdw [r10-0xac8], r6                   
    mov64 r3, r10                                   r3 = r10
    add64 r3, -2568                                 r3 += -2568   ///  r3 = r3.wrapping_add(-2568 as i32 as i64 as u64)
    mov64 r4, r10                                   r4 = r10
    add64 r4, -2576                                 r4 += -2576   ///  r4 = r4.wrapping_add(-2576 as i32 as i64 as u64)
    mov64 r6, r10                                   r6 = r10
    add64 r6, -2616                                 r6 += -2616   ///  r6 = r6.wrapping_add(-2616 as i32 as i64 as u64)
    ldxdw r5, [r1+0x98]                     
    ldxdw r0, [r10-0xa20]                   
    stxdw [r10-0xa70], r0                   
    ldxdw r0, [r10-0xa38]                   
    add64 r0, 8                                     r0 += 8   ///  r0 = r0.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x230], r0                   
    add64 r2, 8                                     r2 += 8   ///  r2 = r2.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x240], r2                   
    add64 r1, 8                                     r1 += 8   ///  r1 = r1.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x250], r1                   
    sth [r10-0x228], 257                    
    sth [r10-0x238], 1                      
    sth [r10-0x248], 1                      
    stxdw [r10-0x6b], r5                    
    stb [r10-0x6c], 3                       
    stxdw [r10-0xaa0], r6                   
    stxdw [r10-0x1e0], r6                   
    stxdw [r10-0x1e8], r4                   
    stxdw [r10-0x1f0], r3                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -280                                  r1 += -280   ///  r1 = r1.wrapping_add(-280 as i32 as i64 as u64)
    stxdw [r10-0xaa8], r1                   
    stxdw [r10-0x20], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -448                                  r1 += -448   ///  r1 = r1.wrapping_add(-448 as i32 as i64 as u64)
    stxdw [r10-0x28], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -544                                  r1 += -544   ///  r1 = r1.wrapping_add(-544 as i32 as i64 as u64)
    stxdw [r10-0xab0], r1                   
    stxdw [r10-0x48], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -592                                  r1 += -592   ///  r1 = r1.wrapping_add(-592 as i32 as i64 as u64)
    stxdw [r10-0x50], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -472                                  r1 += -472   ///  r1 = r1.wrapping_add(-472 as i32 as i64 as u64)
    stxdw [r10-0xab8], r1                   
    stxdw [r10-0x58], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -496                                  r1 += -496   ///  r1 = r1.wrapping_add(-496 as i32 as i64 as u64)
    stxdw [r10-0x60], r1                    
    stdw [r10-0x8], 3                       
    stdw [r10-0x10], 3                      
    stdw [r10-0x18], 0                      
    stdw [r10-0x30], 3                      
    stdw [r10-0x38], 3                      
    stdw [r10-0x40], 0                      
    mov64 r1, r10                                   r1 = r10
    add64 r1, -96                                   r1 += -96   ///  r1 = r1.wrapping_add(-96 as i32 as i64 as u64)
    call function_0                         
    mov64 r1, r0                                    r1 = r0
    lsh64 r1, 32                                    r1 <<= 32   ///  r1 = r1.wrapping_shl(32)
    rsh64 r1, 32                                    r1 >>= 32   ///  r1 = r1.wrapping_shr(32)
    jne r1, 26, lbb_18121                           if r1 != (26 as i32 as i64 as u64) { pc += 528 }
    mov64 r1, r10                                   r1 = r10
    add64 r1, -108                                  r1 += -108   ///  r1 = r1.wrapping_add(-108 as i32 as i64 as u64)
    stxdw [r10-0x48], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -592                                  r1 += -592   ///  r1 = r1.wrapping_add(-592 as i32 as i64 as u64)
    stxdw [r10-0x58], r1                    
    ldxdw r1, [r10-0xa70]                   
    add64 r1, 8                                     r1 += 8   ///  r1 = r1.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x60], r1                    
    stdw [r10-0x40], 9                      
    stdw [r10-0x50], 3                      
    mov64 r1, r10                                   r1 = r10
    add64 r1, -96                                   r1 += -96   ///  r1 = r1.wrapping_add(-96 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -448                                  r2 += -448   ///  r2 = r2.wrapping_add(-448 as i32 as i64 as u64)
    mov64 r6, 0                                     r6 = 0 as i32 as i64 as u64
    mov64 r3, 3                                     r3 = 3 as i32 as i64 as u64
    mov64 r4, 8                                     r4 = 8 as i32 as i64 as u64
    mov64 r5, 0                                     r5 = 0 as i32 as i64 as u64
    syscall [invalid]                       
    mov64 r2, r7                                    r2 = r7
    ldxdw r0, [r10-0xa80]                   
    jeq r0, 0, lbb_18037                            if r0 == (0 as i32 as i64 as u64) { pc += 421 }
    ldxdw r1, [r10-0xa78]                   
    add64 r1, 16                                    r1 += 16   ///  r1 = r1.wrapping_add(16 as i32 as i64 as u64)
    stxdw [r10-0xa78], r1                   
    mov64 r1, r9                                    r1 = r9
    add64 r1, 8                                     r1 += 8   ///  r1 = r1.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0xac0], r1                   
    mov64 r3, r10                                   r3 = r10
    add64 r3, -2552                                 r3 += -2552   ///  r3 = r3.wrapping_add(-2552 as i32 as i64 as u64)
    add64 r2, -8                                    r2 += -8   ///  r2 = r2.wrapping_add(-8 as i32 as i64 as u64)
    mov64 r7, 0                                     r7 = 0 as i32 as i64 as u64
    stxdw [r10-0xa70], r2                   
    ja lbb_17937                                    if true { pc += 309 }
lbb_17628:
    lddw r2, 0x4cfbdb8200836fd2                     r2 load str located at 5547268717437743058
    jne r1, r2, lbb_17650                           if r1 != r2 { pc += 19 }
    ldxdw r1, [r7+0x10]                     
    lddw r2, 0x33559cb08794b05b                     r2 load str located at 3699034950957576283
    jne r1, r2, lbb_17650                           if r1 != r2 { pc += 15 }
    ldxdw r1, [r7+0x18]                     
    lddw r2, 0xa2e8696d479bf0b2                     r2 load str located at -6707995726894600014
    jne r1, r2, lbb_17650                           if r1 != r2 { pc += 11 }
    ldxdw r1, [r7+0x20]                     
    lddw r2, 0xb50d9a20d7d2fe4c                     r2 load str located at -5400490912296796596
    jne r1, r2, lbb_17650                           if r1 != r2 { pc += 7 }
lbb_17643:
    lddw r6, 0x1a00000000                           r6 load str located at 111669149696
    ja lbb_18136                                    if true { pc += 490 }
lbb_17646:
    ldxw r5, [r10-0xa5c]                    
    ja lbb_18124                                    if true { pc += 476 }
lbb_17648:
    ldxw r5, [r10-0xa44]                    
    ja lbb_18124                                    if true { pc += 474 }
lbb_17650:
    ldxdw r1, [r10-0xa08]                   
    ldxdw r2, [r1+0x50]                     
    jlt r2, 72, lbb_18174                           if r2 < (72 as i32 as i64 as u64) { pc += 521 }
    ldxdw r2, [r10-0xa10]                   
    ldxdw r3, [r2+0x50]                     
    jlt r3, 32, lbb_18174                           if r3 < (32 as i32 as i64 as u64) { pc += 518 }
    ldxdw r3, [r2+0x58]                     
    ldxdw r4, [r1+0x58]                     
    jne r4, r3, lbb_18174                           if r4 != r3 { pc += 515 }
    ldxdw r3, [r2+0x60]                     
    ldxdw r4, [r1+0x60]                     
    jne r4, r3, lbb_18174                           if r4 != r3 { pc += 512 }
    ldxdw r3, [r2+0x68]                     
    ldxdw r4, [r1+0x68]                     
    jne r4, r3, lbb_18174                           if r4 != r3 { pc += 509 }
    ldxdw r3, [r2+0x70]                     
    ldxdw r4, [r1+0x70]                     
    jne r4, r3, lbb_18174                           if r4 != r3 { pc += 506 }
    mov64 r3, r10                                   r3 = r10
    add64 r3, -2568                                 r3 += -2568   ///  r3 = r3.wrapping_add(-2568 as i32 as i64 as u64)
    mov64 r4, r10                                   r4 = r10
    add64 r4, -2576                                 r4 += -2576   ///  r4 = r4.wrapping_add(-2576 as i32 as i64 as u64)
    mov64 r8, r10                                   r8 = r10
    add64 r8, -2616                                 r8 += -2616   ///  r8 = r8.wrapping_add(-2616 as i32 as i64 as u64)
    mov64 r5, r7                                    r5 = r7
    add64 r5, 8                                     r5 += 8   ///  r5 = r5.wrapping_add(8 as i32 as i64 as u64)
    ldxdw r0, [r1+0x98]                     
    ldxdw r6, [r10-0xa20]                   
    stxdw [r10-0x230], r5                   
    add64 r2, 8                                     r2 += 8   ///  r2 = r2.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x240], r2                   
    add64 r1, 8                                     r1 += 8   ///  r1 = r1.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x250], r1                   
    sth [r10-0x228], 257                    
    sth [r10-0x238], 1                      
    sth [r10-0x248], 1                      
    stxdw [r10-0x6b], r0                    
    stb [r10-0x6c], 3                       
    stxdw [r10-0x1e0], r8                   
    stxdw [r10-0x1e8], r4                   
    stxdw [r10-0x1f0], r3                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -280                                  r1 += -280   ///  r1 = r1.wrapping_add(-280 as i32 as i64 as u64)
    stxdw [r10-0x20], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -448                                  r1 += -448   ///  r1 = r1.wrapping_add(-448 as i32 as i64 as u64)
    stxdw [r10-0x28], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -544                                  r1 += -544   ///  r1 = r1.wrapping_add(-544 as i32 as i64 as u64)
    stxdw [r10-0x48], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -592                                  r1 += -592   ///  r1 = r1.wrapping_add(-592 as i32 as i64 as u64)
    stxdw [r10-0x50], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -472                                  r1 += -472   ///  r1 = r1.wrapping_add(-472 as i32 as i64 as u64)
    stxdw [r10-0x58], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -496                                  r1 += -496   ///  r1 = r1.wrapping_add(-496 as i32 as i64 as u64)
    stxdw [r10-0x60], r1                    
    stdw [r10-0x8], 3                       
    stdw [r10-0x10], 3                      
    stdw [r10-0x18], 0                      
    stdw [r10-0x30], 3                      
    stdw [r10-0x38], 3                      
    stdw [r10-0x40], 0                      
    mov64 r1, r10                                   r1 = r10
    add64 r1, -96                                   r1 += -96   ///  r1 = r1.wrapping_add(-96 as i32 as i64 as u64)
    call function_0                         
    mov64 r1, r0                                    r1 = r0
    lsh64 r1, 32                                    r1 <<= 32   ///  r1 = r1.wrapping_shl(32)
    rsh64 r1, 32                                    r1 >>= 32   ///  r1 = r1.wrapping_shr(32)
    jne r1, 26, lbb_17921                           if r1 != (26 as i32 as i64 as u64) { pc += 199 }
    mov64 r1, r10                                   r1 = r10
    add64 r1, -108                                  r1 += -108   ///  r1 = r1.wrapping_add(-108 as i32 as i64 as u64)
    stxdw [r10-0x48], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -592                                  r1 += -592   ///  r1 = r1.wrapping_add(-592 as i32 as i64 as u64)
    stxdw [r10-0x58], r1                    
    add64 r6, 8                                     r6 += 8   ///  r6 = r6.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x60], r6                    
    stdw [r10-0x40], 9                      
    stdw [r10-0x50], 3                      
    mov64 r1, r10                                   r1 = r10
    add64 r1, -96                                   r1 += -96   ///  r1 = r1.wrapping_add(-96 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -448                                  r2 += -448   ///  r2 = r2.wrapping_add(-448 as i32 as i64 as u64)
    mov64 r6, 0                                     r6 = 0 as i32 as i64 as u64
    mov64 r3, 3                                     r3 = 3 as i32 as i64 as u64
    mov64 r4, 8                                     r4 = 8 as i32 as i64 as u64
    mov64 r5, 0                                     r5 = 0 as i32 as i64 as u64
    syscall [invalid]                       
    ldxdw r1, [r7+0x48]                     
    ldxdw r2, [r10-0xa40]                   
    add64 r2, 8                                     r2 += 8   ///  r2 = r2.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x240], r2                   
    ldxdw r2, [r10-0xa38]                   
    add64 r2, 8                                     r2 += 8   ///  r2 = r2.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x250], r2                   
    sth [r10-0x238], 1                      
    sth [r10-0x248], 257                    
    stxdw [r10-0x68], r1                    
    stb [r10-0x69], 0                       
    sth [r10-0x6b], 0                       
    stb [r10-0x6c], 2                       
    mov64 r1, r10                                   r1 = r10
    add64 r1, -2624                                 r1 += -2624   ///  r1 = r1.wrapping_add(-2624 as i32 as i64 as u64)
    stxdw [r10-0x1e8], r1                   
    stxdw [r10-0x1f0], r8                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -336                                  r1 += -336   ///  r1 = r1.wrapping_add(-336 as i32 as i64 as u64)
    stxdw [r10-0x20], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -448                                  r1 += -448   ///  r1 = r1.wrapping_add(-448 as i32 as i64 as u64)
    stxdw [r10-0x28], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -560                                  r1 += -560   ///  r1 = r1.wrapping_add(-560 as i32 as i64 as u64)
    stxdw [r10-0x48], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -592                                  r1 += -592   ///  r1 = r1.wrapping_add(-592 as i32 as i64 as u64)
    stxdw [r10-0x50], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -480                                  r1 += -480   ///  r1 = r1.wrapping_add(-480 as i32 as i64 as u64)
    stxdw [r10-0x58], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -496                                  r1 += -496   ///  r1 = r1.wrapping_add(-496 as i32 as i64 as u64)
    stxdw [r10-0x60], r1                    
    stdw [r10-0x8], 2                       
    stdw [r10-0x10], 2                      
    stdw [r10-0x18], 0                      
    stdw [r10-0x30], 2                      
    stdw [r10-0x38], 2                      
    stdw [r10-0x40], 0                      
    mov64 r1, r10                                   r1 = r10
    add64 r1, -96                                   r1 += -96   ///  r1 = r1.wrapping_add(-96 as i32 as i64 as u64)
    call function_0                         
    mov64 r1, r0                                    r1 = r0
    lsh64 r1, 32                                    r1 <<= 32   ///  r1 = r1.wrapping_shl(32)
    rsh64 r1, 32                                    r1 >>= 32   ///  r1 = r1.wrapping_shr(32)
    jne r1, 26, lbb_17921                           if r1 != (26 as i32 as i64 as u64) { pc += 132 }
    mov64 r1, r10                                   r1 = r10
    add64 r1, -108                                  r1 += -108   ///  r1 = r1.wrapping_add(-108 as i32 as i64 as u64)
    stxdw [r10-0x48], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -592                                  r1 += -592   ///  r1 = r1.wrapping_add(-592 as i32 as i64 as u64)
    stxdw [r10-0x58], r1                    
    lddw r1, 0x100025958 --> b"\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\…        r1 load str located at 4295121240
    stxdw [r10-0x60], r1                    
    stdw [r10-0x40], 12                     
    stdw [r10-0x50], 2                      
    mov64 r1, r10                                   r1 = r10
    add64 r1, -96                                   r1 += -96   ///  r1 = r1.wrapping_add(-96 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -448                                  r2 += -448   ///  r2 = r2.wrapping_add(-448 as i32 as i64 as u64)
    mov64 r3, 2                                     r3 = 2 as i32 as i64 as u64
    ja lbb_17895                                    if true { pc += 89 }
lbb_17806:
    ldxdw r0, [r10-0xb00]                   
    jeq r0, 0, lbb_17909                            if r0 == (0 as i32 as i64 as u64) { pc += 101 }
lbb_17808:
    ldxdw r1, [r10-0xa28]                   
    ldxdw r2, [r1+0x50]                     
    jlt r2, 32, lbb_18174                           if r2 < (32 as i32 as i64 as u64) { pc += 363 }
    ldxdw r2, [r10-0xa20]                   
    ldxdw r3, [r2+0x50]                     
    jlt r3, 32, lbb_18174                           if r3 < (32 as i32 as i64 as u64) { pc += 360 }
    ldxdw r3, [r2+0x58]                     
    ldxdw r4, [r1+0x58]                     
    jne r4, r3, lbb_18174                           if r4 != r3 { pc += 357 }
    ldxdw r3, [r2+0x60]                     
    ldxdw r4, [r1+0x60]                     
    jne r4, r3, lbb_18174                           if r4 != r3 { pc += 354 }
    ldxdw r3, [r2+0x68]                     
    ldxdw r4, [r1+0x68]                     
    jne r4, r3, lbb_18174                           if r4 != r3 { pc += 351 }
    ldxdw r3, [r2+0x70]                     
    ldxdw r4, [r1+0x70]                     
    jne r4, r3, lbb_18174                           if r4 != r3 { pc += 348 }
    mov64 r3, r10                                   r3 = r10
    add64 r3, -2592                                 r3 += -2592   ///  r3 = r3.wrapping_add(-2592 as i32 as i64 as u64)
    mov64 r4, r10                                   r4 = r10
    add64 r4, -2600                                 r4 += -2600   ///  r4 = r4.wrapping_add(-2600 as i32 as i64 as u64)
    ldxdw r6, [r10-0xa10]                   
    ldxdw r5, [r10-0xa40]                   
    add64 r5, 8                                     r5 += 8   ///  r5 = r5.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x230], r5                   
    add64 r2, 8                                     r2 += 8   ///  r2 = r2.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x240], r2                   
    add64 r1, 8                                     r1 += 8   ///  r1 = r1.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x250], r1                   
    sth [r10-0x228], 257                    
    sth [r10-0x238], 1                      
    sth [r10-0x248], 1                      
    stxdw [r10-0x6b], r0                    
    stb [r10-0x6c], 3                       
    mov64 r1, r10                                   r1 = r10
    add64 r1, -2624                                 r1 += -2624   ///  r1 = r1.wrapping_add(-2624 as i32 as i64 as u64)
    stxdw [r10-0x1e0], r1                   
    stxdw [r10-0x1e8], r3                   
    stxdw [r10-0x1f0], r4                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -280                                  r1 += -280   ///  r1 = r1.wrapping_add(-280 as i32 as i64 as u64)
    stxdw [r10-0x20], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -448                                  r1 += -448   ///  r1 = r1.wrapping_add(-448 as i32 as i64 as u64)
    stxdw [r10-0x28], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -544                                  r1 += -544   ///  r1 = r1.wrapping_add(-544 as i32 as i64 as u64)
    stxdw [r10-0x48], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -592                                  r1 += -592   ///  r1 = r1.wrapping_add(-592 as i32 as i64 as u64)
    stxdw [r10-0x50], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -472                                  r1 += -472   ///  r1 = r1.wrapping_add(-472 as i32 as i64 as u64)
    stxdw [r10-0x58], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -496                                  r1 += -496   ///  r1 = r1.wrapping_add(-496 as i32 as i64 as u64)
    stxdw [r10-0x60], r1                    
    stdw [r10-0x8], 3                       
    stdw [r10-0x10], 3                      
    stdw [r10-0x18], 0                      
    stdw [r10-0x30], 3                      
    stdw [r10-0x38], 3                      
    stdw [r10-0x40], 0                      
    mov64 r1, r10                                   r1 = r10
    add64 r1, -96                                   r1 += -96   ///  r1 = r1.wrapping_add(-96 as i32 as i64 as u64)
    call function_0                         
    mov64 r1, r0                                    r1 = r0
    lsh64 r1, 32                                    r1 <<= 32   ///  r1 = r1.wrapping_shl(32)
    rsh64 r1, 32                                    r1 >>= 32   ///  r1 = r1.wrapping_shr(32)
    jne r1, 26, lbb_17921                           if r1 != (26 as i32 as i64 as u64) { pc += 42 }
    mov64 r1, r10                                   r1 = r10
    add64 r1, -108                                  r1 += -108   ///  r1 = r1.wrapping_add(-108 as i32 as i64 as u64)
    stxdw [r10-0x48], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -592                                  r1 += -592   ///  r1 = r1.wrapping_add(-592 as i32 as i64 as u64)
    stxdw [r10-0x58], r1                    
    add64 r6, 8                                     r6 += 8   ///  r6 = r6.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x60], r6                    
    stdw [r10-0x40], 9                      
    stdw [r10-0x50], 3                      
    mov64 r1, r10                                   r1 = r10
    add64 r1, -96                                   r1 += -96   ///  r1 = r1.wrapping_add(-96 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -448                                  r2 += -448   ///  r2 = r2.wrapping_add(-448 as i32 as i64 as u64)
    mov64 r6, 0                                     r6 = 0 as i32 as i64 as u64
    mov64 r3, 3                                     r3 = 3 as i32 as i64 as u64
lbb_17895:
    mov64 r4, 8                                     r4 = 8 as i32 as i64 as u64
    mov64 r5, 0                                     r5 = 0 as i32 as i64 as u64
    syscall [invalid]                       
    ja lbb_18136                                    if true { pc += 237 }
lbb_17899:
    mov64 r0, 0                                     r0 = 0 as i32 as i64 as u64
    mov64 r5, 1780                                  r5 = 1780 as i32 as i64 as u64
    stxb [r1+0x0], r2                       
    ja lbb_18124                                    if true { pc += 221 }
lbb_17903:
    ldxw r5, [r10-0xa64]                    
    ja lbb_18124                                    if true { pc += 219 }
lbb_17905:
    ldxw r5, [r10-0xa4c]                    
    ja lbb_18124                                    if true { pc += 217 }
lbb_17907:
    ldxdw r0, [r10-0xab8]                   
    jne r0, 0, lbb_17808                            if r0 != (0 as i32 as i64 as u64) { pc += -101 }
lbb_17909:
    mov64 r6, 0                                     r6 = 0 as i32 as i64 as u64
    ja lbb_18136                                    if true { pc += 225 }
lbb_17911:
    sub64 r3, r4                                    r3 -= r4   ///  r3 = r3.wrapping_sub(r4)
    mov64 r5, 1772                                  r5 = 1772 as i32 as i64 as u64
    jge r3, r6, lbb_17926                           if r3 >= r6 { pc += 12 }
lbb_17914:
    stxb [r1+0x0], r2                       
    ja lbb_18124                                    if true { pc += 208 }
lbb_17916:
    ldxw r5, [r10-0xa54]                    
    ja lbb_18124                                    if true { pc += 206 }
lbb_17918:
    mov64 r0, 0                                     r0 = 0 as i32 as i64 as u64
    mov64 r5, 1780                                  r5 = 1780 as i32 as i64 as u64
    ja lbb_18121                                    if true { pc += 200 }
lbb_17921:
    ja lbb_18124                                    if true { pc += 202 }
lbb_17922:
    mov64 r1, 11                                    r1 = 11 as i32 as i64 as u64
    stxdw [r10-0xa78], r1                   
lbb_17924:
    ldxdw r0, [r10-0xa78]                   
    ja lbb_18124                                    if true { pc += 198 }
lbb_17926:
    stxb [r1+0x0], r2                       
    mov64 r6, 0                                     r6 = 0 as i32 as i64 as u64
    ja lbb_18136                                    if true { pc += 207 }
lbb_17929:
    ldxdw r2, [r10-0xa70]                   
    ldxdw r0, [r10-0xa80]                   
    ldxdw r6, [r10-0xa98]                   
lbb_17932:
    add64 r7, 1                                     r7 += 1   ///  r7 = r7.wrapping_add(1 as i32 as i64 as u64)
    ldxdw r3, [r10-0xa90]                   
    add64 r3, 16                                    r3 += 16   ///  r3 = r3.wrapping_add(16 as i32 as i64 as u64)
    add64 r6, 2                                     r6 += 2   ///  r6 = r6.wrapping_add(2 as i32 as i64 as u64)
    jge r7, r0, lbb_18037                           if r7 >= r0 { pc += 100 }
lbb_17937:
    jge r6, r2, lbb_18354                           if r6 >= r2 { pc += 416 }
    mov64 r1, r6                                    r1 = r6
    add64 r1, 1                                     r1 += 1   ///  r1 = r1.wrapping_add(1 as i32 as i64 as u64)
    jge r1, r2, lbb_18358                           if r1 >= r2 { pc += 417 }
    stxdw [r10-0xa90], r3                   
    ldxdw r1, [r3+0x0]                      
    ldxdw r3, [r1+0x50]                     
    jlt r3, 72, lbb_17932                           if r3 < (72 as i32 as i64 as u64) { pc += -13 }
    ldxdw r3, [r1+0x98]                     
    jne r3, 0, lbb_17932                            if r3 != (0 as i32 as i64 as u64) { pc += -15 }
    ldxdw r3, [r10-0xa90]                   
    ldxdw r3, [r3-0x8]                      
    ldxdw r4, [r3+0x28]                     
    lddw r5, 0xde8f75eee1f6dd06                     r5 load str located at -2409577606766207738
    jne r4, r5, lbb_17965                           if r4 != r5 { pc += 12 }
    ldxdw r4, [r3+0x30]                     
    lddw r5, 0xdacd6ce4bc5d4218                     r5 load str located at -2680366473547005416
    jne r4, r5, lbb_17965                           if r4 != r5 { pc += 8 }
    ldxdw r4, [r3+0x38]                     
    lddw r5, 0x270db9834dfc1ab6                     r5 load str located at 2814109315776649910
    jne r4, r5, lbb_17965                           if r4 != r5 { pc += 4 }
    ldxdw r3, [r3+0x40]                     
    lddw r4, 0xfc8ba1d828f9bdfe                     r4 load str located at -248927404616466946
    jeq r3, r4, lbb_17932                           if r3 == r4 { pc += -33 }
lbb_17965:
    stxdw [r10-0xa98], r6                   
    ldxdw r6, [r10-0xa20]                   
    ldxdw r2, [r10-0xac0]                   
    stxdw [r10-0x230], r2                   
    ldxdw r2, [r10-0xa78]                   
    stxdw [r10-0x240], r2                   
    add64 r1, 8                                     r1 += 8   ///  r1 = r1.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x250], r1                   
    sth [r10-0x228], 257                    
    sth [r10-0x238], 1                      
    sth [r10-0x248], 1                      
    ldxdw r1, [r10-0xaa0]                   
    stxdw [r10-0x1e0], r1                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -2624                                 r1 += -2624   ///  r1 = r1.wrapping_add(-2624 as i32 as i64 as u64)
    stxdw [r10-0x1e8], r1                   
    ldxdw r1, [r10-0xa90]                   
    stxdw [r10-0x1f0], r1                   
    ldxdw r1, [r10-0xaa8]                   
    stxdw [r10-0x20], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -448                                  r1 += -448   ///  r1 = r1.wrapping_add(-448 as i32 as i64 as u64)
    stxdw [r10-0x28], r1                    
    ldxdw r1, [r10-0xab0]                   
    stxdw [r10-0x48], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -592                                  r1 += -592   ///  r1 = r1.wrapping_add(-592 as i32 as i64 as u64)
    stxdw [r10-0x50], r1                    
    ldxdw r1, [r10-0xab8]                   
    stxdw [r10-0x58], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -496                                  r1 += -496   ///  r1 = r1.wrapping_add(-496 as i32 as i64 as u64)
    stxdw [r10-0x60], r1                    
    stdw [r10-0x8], 3                       
    stdw [r10-0x10], 3                      
    stdw [r10-0x18], 0                      
    stdw [r10-0x30], 3                      
    stdw [r10-0x38], 3                      
    stdw [r10-0x40], 0                      
    mov64 r1, r10                                   r1 = r10
    add64 r1, -96                                   r1 += -96   ///  r1 = r1.wrapping_add(-96 as i32 as i64 as u64)
    call function_0                         
    lsh64 r0, 32                                    r0 <<= 32   ///  r0 = r0.wrapping_shl(32)
    rsh64 r0, 32                                    r0 >>= 32   ///  r0 = r0.wrapping_shr(32)
    jne r0, 26, lbb_17929                           if r0 != (26 as i32 as i64 as u64) { pc += -81 }
    lddw r1, 0x1000259e2 --> b"\x09attempt to divide with overflow but the index is "        r1 load str located at 4295121378
    stxdw [r10-0x48], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -592                                  r1 += -592   ///  r1 = r1.wrapping_add(-592 as i32 as i64 as u64)
    stxdw [r10-0x58], r1                    
    add64 r6, 8                                     r6 += 8   ///  r6 = r6.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x60], r6                    
    stdw [r10-0x40], 1                      
    stdw [r10-0x50], 3                      
    mov64 r1, r10                                   r1 = r10
    add64 r1, -96                                   r1 += -96   ///  r1 = r1.wrapping_add(-96 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -448                                  r2 += -448   ///  r2 = r2.wrapping_add(-448 as i32 as i64 as u64)
    mov64 r3, 3                                     r3 = 3 as i32 as i64 as u64
    mov64 r4, 8                                     r4 = 8 as i32 as i64 as u64
    mov64 r5, 0                                     r5 = 0 as i32 as i64 as u64
    syscall [invalid]                       
    ja lbb_17929                                    if true { pc += -100 }
lbb_18029:
    lsh64 r3, 3                                     r3 <<= 3   ///  r3 = r3.wrapping_shl(3)
    mov64 r4, r10                                   r4 = r10
    add64 r4, -2624                                 r4 += -2624   ///  r4 = r4.wrapping_add(-2624 as i32 as i64 as u64)
    add64 r4, r3                                    r4 += r3   ///  r4 = r4.wrapping_add(r3)
    ldxdw r3, [r4+0x0]                      
    stxdw [r10-0xa38], r3                   
lbb_18035:
    add64 r8, 8                                     r8 += 8   ///  r8 = r8.wrapping_add(8 as i32 as i64 as u64)
    ja lbb_15267                                    if true { pc += -2770 }
lbb_18037:
    ldxdw r1, [r9+0x48]                     
    ldxdw r2, [r10-0xa40]                   
    add64 r2, 8                                     r2 += 8   ///  r2 = r2.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x240], r2                   
    ldxdw r2, [r10-0xa38]                   
    add64 r2, 8                                     r2 += 8   ///  r2 = r2.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x250], r2                   
    sth [r10-0x238], 1                      
    sth [r10-0x248], 257                    
    stxdw [r10-0x68], r1                    
    stb [r10-0x69], 0                       
    sth [r10-0x6b], 0                       
    stb [r10-0x6c], 2                       
    mov64 r1, r10                                   r1 = r10
    add64 r1, -2624                                 r1 += -2624   ///  r1 = r1.wrapping_add(-2624 as i32 as i64 as u64)
    stxdw [r10-0x1e8], r1                   
    ldxdw r1, [r10-0xaa0]                   
    stxdw [r10-0x1f0], r1                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -336                                  r1 += -336   ///  r1 = r1.wrapping_add(-336 as i32 as i64 as u64)
    stxdw [r10-0x20], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -448                                  r1 += -448   ///  r1 = r1.wrapping_add(-448 as i32 as i64 as u64)
    stxdw [r10-0x28], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -560                                  r1 += -560   ///  r1 = r1.wrapping_add(-560 as i32 as i64 as u64)
    stxdw [r10-0x48], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -592                                  r1 += -592   ///  r1 = r1.wrapping_add(-592 as i32 as i64 as u64)
    stxdw [r10-0x50], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -480                                  r1 += -480   ///  r1 = r1.wrapping_add(-480 as i32 as i64 as u64)
    stxdw [r10-0x58], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -496                                  r1 += -496   ///  r1 = r1.wrapping_add(-496 as i32 as i64 as u64)
    stxdw [r10-0x60], r1                    
    stdw [r10-0x8], 2                       
    stdw [r10-0x10], 2                      
    stdw [r10-0x18], 0                      
    stdw [r10-0x30], 2                      
    stdw [r10-0x38], 2                      
    stdw [r10-0x40], 0                      
    mov64 r1, r10                                   r1 = r10
    add64 r1, -96                                   r1 += -96   ///  r1 = r1.wrapping_add(-96 as i32 as i64 as u64)
    call function_0                         
    mov64 r1, r0                                    r1 = r0
    lsh64 r1, 32                                    r1 <<= 32   ///  r1 = r1.wrapping_shl(32)
    rsh64 r1, 32                                    r1 >>= 32   ///  r1 = r1.wrapping_shr(32)
    jne r1, 26, lbb_18121                           if r1 != (26 as i32 as i64 as u64) { pc += 35 }
    mov64 r1, r10                                   r1 = r10
    add64 r1, -108                                  r1 += -108   ///  r1 = r1.wrapping_add(-108 as i32 as i64 as u64)
    stxdw [r10-0x48], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -592                                  r1 += -592   ///  r1 = r1.wrapping_add(-592 as i32 as i64 as u64)
    stxdw [r10-0x58], r1                    
    lddw r1, 0x100025958 --> b"\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\…        r1 load str located at 4295121240
    stxdw [r10-0x60], r1                    
    stdw [r10-0x40], 12                     
    stdw [r10-0x50], 2                      
    mov64 r1, r10                                   r1 = r10
    add64 r1, -96                                   r1 += -96   ///  r1 = r1.wrapping_add(-96 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -448                                  r2 += -448   ///  r2 = r2.wrapping_add(-448 as i32 as i64 as u64)
    mov64 r3, 2                                     r3 = 2 as i32 as i64 as u64
    mov64 r4, 8                                     r4 = 8 as i32 as i64 as u64
    mov64 r5, 0                                     r5 = 0 as i32 as i64 as u64
    syscall [invalid]                       
    ldxdw r1, [r10-0xa10]                   
    ldxdw r2, [r1+0x50]                     
    jlt r2, 72, lbb_18351                           if r2 < (72 as i32 as i64 as u64) { pc += 243 }
    ldxdw r2, [r10-0xa88]                   
    mov64 r3, r2                                    r3 = r2
    mov64 r2, 96                                    r2 = 96 as i32 as i64 as u64
    jeq r3, 0, lbb_18113                            if r3 == (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r2, 104                                   r2 = 104 as i32 as i64 as u64
lbb_18113:
    mov64 r3, r8                                    r3 = r8
    add64 r3, r2                                    r3 += r2   ///  r3 = r3.wrapping_add(r2)
    ldxdw r2, [r3+0x0]                      
    ldxdw r1, [r1+0x98]                     
    jge r1, r2, lbb_18236                           if r1 >= r2 { pc += 118 }
    mov64 r0, 0                                     r0 = 0 as i32 as i64 as u64
    mov64 r5, 1771                                  r5 = 1771 as i32 as i64 as u64
    ja lbb_18121                                    if true { pc += 0 }
lbb_18121:
    ldxb r1, [r8+0x0]                       
    add64 r1, 1                                     r1 += 1   ///  r1 = r1.wrapping_add(1 as i32 as i64 as u64)
    stxb [r8+0x0], r1                       
lbb_18124:
    lsh64 r0, 32                                    r0 <<= 32   ///  r0 = r0.wrapping_shl(32)
    rsh64 r0, 32                                    r0 >>= 32   ///  r0 = r0.wrapping_shr(32)
    jsgt r0, 12, lbb_18138                          if (r0 as i64) > (12 as i32 as i64) { pc += 11 }
    jsle r0, 5, lbb_18145                           if (r0 as i64) <= (5 as i32 as i64) { pc += 17 }
    jsle r0, 8, lbb_18159                           if (r0 as i64) <= (8 as i32 as i64) { pc += 30 }
    jsgt r0, 10, lbb_18182                          if (r0 as i64) > (10 as i32 as i64) { pc += 52 }
    jne r0, 9, lbb_18134                            if r0 != (9 as i32 as i64 as u64) { pc += 3 }
    lddw r6, 0xa00000000                            r6 load str located at 42949672960
    ja lbb_18136                                    if true { pc += 2 }
lbb_18134:
    lddw r6, 0xb00000000                            r6 load str located at 47244640256
lbb_18136:
    mov64 r0, r6                                    r0 = r6
    exit                                    
lbb_18138:
    jsle r0, 18, lbb_18153                          if (r0 as i64) <= (18 as i32 as i64) { pc += 14 }
    jsle r0, 21, lbb_18164                          if (r0 as i64) <= (21 as i32 as i64) { pc += 24 }
    jsgt r0, 23, lbb_18186                          if (r0 as i64) > (23 as i32 as i64) { pc += 45 }
    jne r0, 22, lbb_18216                           if r0 != (22 as i32 as i64 as u64) { pc += 74 }
    lddw r6, 0x1700000000                           r6 load str located at 98784247808
    ja lbb_18136                                    if true { pc += -9 }
lbb_18145:
    jsgt r0, 2, lbb_18169                           if (r0 as i64) > (2 as i32 as i64) { pc += 23 }
    jeq r0, 0, lbb_18196                            if r0 == (0 as i32 as i64 as u64) { pc += 49 }
    lddw r6, 0x200000000                            r6 load str located at 8589934592
    jeq r0, 1, lbb_18136                            if r0 == (1 as i32 as i64 as u64) { pc += -14 }
lbb_18150:
    lddw r6, 0x300000000                            r6 load str located at 12884901888
    ja lbb_18136                                    if true { pc += -17 }
lbb_18153:
    jsgt r0, 15, lbb_18177                          if (r0 as i64) > (15 as i32 as i64) { pc += 23 }
    jeq r0, 13, lbb_18204                           if r0 == (13 as i32 as i64 as u64) { pc += 49 }
    jne r0, 14, lbb_18222                           if r0 != (14 as i32 as i64 as u64) { pc += 66 }
    lddw r6, 0xf00000000                            r6 load str located at 64424509440
    ja lbb_18136                                    if true { pc += -23 }
lbb_18159:
    jeq r0, 6, lbb_18190                            if r0 == (6 as i32 as i64 as u64) { pc += 30 }
    jne r0, 7, lbb_18210                            if r0 != (7 as i32 as i64 as u64) { pc += 49 }
    lddw r6, 0x800000000                            r6 load str located at 34359738368
    ja lbb_18136                                    if true { pc += -28 }
lbb_18164:
    jeq r0, 19, lbb_18193                           if r0 == (19 as i32 as i64 as u64) { pc += 28 }
    jne r0, 20, lbb_18213                           if r0 != (20 as i32 as i64 as u64) { pc += 47 }
    lddw r6, 0x1500000000                           r6 load str located at 90194313216
    ja lbb_18136                                    if true { pc += -33 }
lbb_18169:
    jeq r0, 3, lbb_18174                            if r0 == (3 as i32 as i64 as u64) { pc += 4 }
    jne r0, 4, lbb_18225                            if r0 != (4 as i32 as i64 as u64) { pc += 54 }
    lddw r6, 0x500000000                            r6 load str located at 21474836480
    ja lbb_18136                                    if true { pc += -38 }
lbb_18174:
    lddw r6, 0x400000000                            r6 load str located at 17179869184
    ja lbb_18136                                    if true { pc += -41 }
lbb_18177:
    jeq r0, 16, lbb_18207                           if r0 == (16 as i32 as i64 as u64) { pc += 29 }
    jne r0, 17, lbb_18228                           if r0 != (17 as i32 as i64 as u64) { pc += 49 }
    lddw r6, 0x1200000000                           r6 load str located at 77309411328
    ja lbb_18136                                    if true { pc += -46 }
lbb_18182:
    jne r0, 11, lbb_18219                           if r0 != (11 as i32 as i64 as u64) { pc += 36 }
lbb_18183:
    lddw r6, 0xc00000000                            r6 load str located at 51539607552
    ja lbb_18136                                    if true { pc += -50 }
lbb_18186:
    jne r0, 24, lbb_17643                           if r0 != (24 as i32 as i64 as u64) { pc += -544 }
    lddw r6, 0x1900000000                           r6 load str located at 107374182400
    ja lbb_18136                                    if true { pc += -54 }
lbb_18190:
    lddw r6, 0x700000000                            r6 load str located at 30064771072
    ja lbb_18136                                    if true { pc += -57 }
lbb_18193:
    lddw r6, 0x1400000000                           r6 load str located at 85899345920
    ja lbb_18136                                    if true { pc += -60 }
lbb_18196:
    mov64 r1, r5                                    r1 = r5
    lsh64 r1, 32                                    r1 <<= 32   ///  r1 = r1.wrapping_shl(32)
    rsh64 r1, 32                                    r1 >>= 32   ///  r1 = r1.wrapping_shr(32)
    jeq r1, 0, lbb_18231                            if r1 == (0 as i32 as i64 as u64) { pc += 31 }
lbb_18200:
    lsh64 r5, 32                                    r5 <<= 32   ///  r5 = r5.wrapping_shl(32)
    rsh64 r5, 32                                    r5 >>= 32   ///  r5 = r5.wrapping_shr(32)
    mov64 r6, r5                                    r6 = r5
    ja lbb_18136                                    if true { pc += -68 }
lbb_18204:
    lddw r6, 0xe00000000                            r6 load str located at 60129542144
    ja lbb_18136                                    if true { pc += -71 }
lbb_18207:
    lddw r6, 0x1100000000                           r6 load str located at 73014444032
    ja lbb_18136                                    if true { pc += -74 }
lbb_18210:
    lddw r6, 0x900000000                            r6 load str located at 38654705664
    ja lbb_18136                                    if true { pc += -77 }
lbb_18213:
    lddw r6, 0x1600000000                           r6 load str located at 94489280512
    ja lbb_18136                                    if true { pc += -80 }
lbb_18216:
    lddw r6, 0x1800000000                           r6 load str located at 103079215104
    ja lbb_18136                                    if true { pc += -83 }
lbb_18219:
    lddw r6, 0xd00000000                            r6 load str located at 55834574848
    ja lbb_18136                                    if true { pc += -86 }
lbb_18222:
    lddw r6, 0x1000000000                           r6 load str located at 68719476736
    ja lbb_18136                                    if true { pc += -89 }
lbb_18225:
    lddw r6, 0x600000000                            r6 load str located at 25769803776
    ja lbb_18136                                    if true { pc += -92 }
lbb_18228:
    lddw r6, 0x1300000000                           r6 load str located at 81604378624
    ja lbb_18136                                    if true { pc += -95 }
lbb_18231:
    lddw r6, 0x100000000                            r6 load str located at 4294967296
    ja lbb_18136                                    if true { pc += -98 }
lbb_18234:
    mov64 r5, 1774                                  r5 = 1774 as i32 as i64 as u64
    ja lbb_18200                                    if true { pc += -36 }
lbb_18236:
    sub64 r1, r2                                    r1 -= r2   ///  r1 = r1.wrapping_sub(r2)
    mov64 r5, 1772                                  r5 = 1772 as i32 as i64 as u64
    mov64 r0, 0                                     r0 = 0 as i32 as i64 as u64
    ldxdw r2, [r10-0xac8]                   
    jlt r1, r2, lbb_18121                           if r1 < r2 { pc += -120 }
    ldxb r1, [r8+0x0]                       
    add64 r1, 1                                     r1 += 1   ///  r1 = r1.wrapping_add(1 as i32 as i64 as u64)
    stxb [r8+0x0], r1                       
    mov64 r6, 0                                     r6 = 0 as i32 as i64 as u64
    ja lbb_18136                                    if true { pc += -110 }
lbb_18246:
    lsh64 r4, 3                                     r4 <<= 3   ///  r4 = r4.wrapping_shl(3)
    mov64 r5, r10                                   r5 = r10
    add64 r5, -2624                                 r5 += -2624   ///  r5 = r5.wrapping_add(-2624 as i32 as i64 as u64)
    add64 r5, r4                                    r5 += r4   ///  r5 = r5.wrapping_add(r4)
    ldxdw r4, [r5+0x0]                      
    stxdw [r3+0x8], r4                      
    add64 r8, 8                                     r8 += 8   ///  r8 = r8.wrapping_add(8 as i32 as i64 as u64)
    ldxb r4, [r8+0x0]                       
    jeq r4, 255, lbb_15704                          if r4 == (255 as i32 as i64 as u64) { pc += -2551 }
lbb_18255:
    lsh64 r4, 3                                     r4 <<= 3   ///  r4 = r4.wrapping_shl(3)
    mov64 r5, r10                                   r5 = r10
    add64 r5, -2624                                 r5 += -2624   ///  r5 = r5.wrapping_add(-2624 as i32 as i64 as u64)
    add64 r5, r4                                    r5 += r4   ///  r5 = r5.wrapping_add(r4)
    ldxdw r4, [r5+0x0]                      
    stxdw [r3+0x10], r4                     
    ja lbb_18035                                    if true { pc += -227 }
lbb_18262:
    lsh64 r4, 3                                     r4 <<= 3   ///  r4 = r4.wrapping_shl(3)
    mov64 r5, r10                                   r5 = r10
    add64 r5, -2624                                 r5 += -2624   ///  r5 = r5.wrapping_add(-2624 as i32 as i64 as u64)
    add64 r5, r4                                    r5 += r4   ///  r5 = r5.wrapping_add(r4)
    ldxdw r4, [r5+0x0]                      
    stxdw [r3+0x8], r4                      
    add64 r8, 8                                     r8 += 8   ///  r8 = r8.wrapping_add(8 as i32 as i64 as u64)
    ldxb r4, [r8+0x0]                       
    jeq r4, 255, lbb_15458                          if r4 == (255 as i32 as i64 as u64) { pc += -2813 }
lbb_18271:
    lsh64 r4, 3                                     r4 <<= 3   ///  r4 = r4.wrapping_shl(3)
    mov64 r5, r10                                   r5 = r10
    add64 r5, -2624                                 r5 += -2624   ///  r5 = r5.wrapping_add(-2624 as i32 as i64 as u64)
    add64 r5, r4                                    r5 += r4   ///  r5 = r5.wrapping_add(r4)
    ldxdw r4, [r5+0x0]                      
    stxdw [r3+0x10], r4                     
    add64 r8, 8                                     r8 += 8   ///  r8 = r8.wrapping_add(8 as i32 as i64 as u64)
    ldxb r4, [r8+0x0]                       
    jeq r4, 255, lbb_15465                          if r4 == (255 as i32 as i64 as u64) { pc += -2815 }
lbb_18280:
    lsh64 r4, 3                                     r4 <<= 3   ///  r4 = r4.wrapping_shl(3)
    mov64 r5, r10                                   r5 = r10
    add64 r5, -2624                                 r5 += -2624   ///  r5 = r5.wrapping_add(-2624 as i32 as i64 as u64)
    add64 r5, r4                                    r5 += r4   ///  r5 = r5.wrapping_add(r4)
    ldxdw r4, [r5+0x0]                      
    stxdw [r3+0x18], r4                     
    ja lbb_18035                                    if true { pc += -252 }
lbb_18287:
    lsh64 r4, 3                                     r4 <<= 3   ///  r4 = r4.wrapping_shl(3)
    mov64 r5, r10                                   r5 = r10
    add64 r5, -2624                                 r5 += -2624   ///  r5 = r5.wrapping_add(-2624 as i32 as i64 as u64)
    add64 r5, r4                                    r5 += r4   ///  r5 = r5.wrapping_add(r4)
    ldxdw r4, [r5+0x0]                      
    stxdw [r3+0x8], r4                      
    add64 r8, 8                                     r8 += 8   ///  r8 = r8.wrapping_add(8 as i32 as i64 as u64)
    ldxb r4, [r8+0x0]                       
    jeq r4, 255, lbb_15715                          if r4 == (255 as i32 as i64 as u64) { pc += -2581 }
lbb_18296:
    lsh64 r4, 3                                     r4 <<= 3   ///  r4 = r4.wrapping_shl(3)
    mov64 r5, r10                                   r5 = r10
    add64 r5, -2624                                 r5 += -2624   ///  r5 = r5.wrapping_add(-2624 as i32 as i64 as u64)
    add64 r5, r4                                    r5 += r4   ///  r5 = r5.wrapping_add(r4)
    ldxdw r4, [r5+0x0]                      
    stxdw [r3+0x10], r4                     
    add64 r8, 8                                     r8 += 8   ///  r8 = r8.wrapping_add(8 as i32 as i64 as u64)
    ldxb r4, [r8+0x0]                       
    jeq r4, 255, lbb_15722                          if r4 == (255 as i32 as i64 as u64) { pc += -2583 }
lbb_18305:
    lsh64 r4, 3                                     r4 <<= 3   ///  r4 = r4.wrapping_shl(3)
    mov64 r5, r10                                   r5 = r10
    add64 r5, -2624                                 r5 += -2624   ///  r5 = r5.wrapping_add(-2624 as i32 as i64 as u64)
    add64 r5, r4                                    r5 += r4   ///  r5 = r5.wrapping_add(r4)
    ldxdw r4, [r5+0x0]                      
    stxdw [r3+0x18], r4                     
    add64 r8, 8                                     r8 += 8   ///  r8 = r8.wrapping_add(8 as i32 as i64 as u64)
    ldxb r4, [r8+0x0]                       
    jeq r4, 255, lbb_15729                          if r4 == (255 as i32 as i64 as u64) { pc += -2585 }
lbb_18314:
    lsh64 r4, 3                                     r4 <<= 3   ///  r4 = r4.wrapping_shl(3)
    mov64 r5, r10                                   r5 = r10
    add64 r5, -2624                                 r5 += -2624   ///  r5 = r5.wrapping_add(-2624 as i32 as i64 as u64)
    add64 r5, r4                                    r5 += r4   ///  r5 = r5.wrapping_add(r4)
    ldxdw r4, [r5+0x0]                      
    stxdw [r3+0x20], r4                     
    ja lbb_18035                                    if true { pc += -286 }
lbb_18321:
    lsh64 r4, 3                                     r4 <<= 3   ///  r4 = r4.wrapping_shl(3)
    mov64 r5, r10                                   r5 = r10
    add64 r5, -2624                                 r5 += -2624   ///  r5 = r5.wrapping_add(-2624 as i32 as i64 as u64)
    add64 r5, r4                                    r5 += r4   ///  r5 = r5.wrapping_add(r4)
    ldxdw r4, [r5+0x0]                      
    stxdw [r3+0x8], r4                      
    ja lbb_18035                                    if true { pc += -293 }
lbb_18328:
    mov64 r0, 3                                     r0 = 3 as i32 as i64 as u64
    mov64 r5, 0                                     r5 = 0 as i32 as i64 as u64
    ja lbb_17914                                    if true { pc += -417 }
lbb_18331:
    mov64 r1, r7                                    r1 = r7
    lddw r3, 0x100025cf0 --> b"\x00\x00\x00\x00\xb8Y\x02\x00\x10\x00\x00\x00\x00\x00\x00\x00.\x1e\x00\x0…        r3 load str located at 4295122160
    call function_18489                     
lbb_18335:
    lddw r3, 0x100025d08 --> b"\x00\x00\x00\x00\xb8Y\x02\x00\x10\x00\x00\x00\x00\x00\x00\x00/\x1e\x00\x0…        r3 load str located at 4295122184
    call function_18489                     
lbb_18338:
    mov64 r1, r3                                    r1 = r3
    lddw r3, 0x100025d68 --> b"\x00\x00\x00\x00\xb8Y\x02\x00\x10\x00\x00\x00\x00\x00\x00\x008\x1f\x00\x0…        r3 load str located at 4295122280
    call function_18489                     
lbb_18342:
    mov64 r1, r6                                    r1 = r6
    lddw r3, 0x100025d50 --> b"\x00\x00\x00\x00\xb8Y\x02\x00\x10\x00\x00\x00\x00\x00\x00\x007\x1f\x00\x0…        r3 load str located at 4295122256
    call function_18489                     
lbb_18346:
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
    lddw r3, 0x100025cd8 --> b"\x00\x00\x00\x00\xb8Y\x02\x00\x10\x00\x00\x00\x00\x00\x00\x00\xf6\x1c\x00…        r3 load str located at 4295122136
    call function_18489                     
lbb_18351:
    mov64 r0, 3                                     r0 = 3 as i32 as i64 as u64
    mov64 r5, 0                                     r5 = 0 as i32 as i64 as u64
    ja lbb_18121                                    if true { pc += -233 }
lbb_18354:
    mov64 r1, r6                                    r1 = r6
    lddw r3, 0x100025d20 --> b"\x00\x00\x00\x00\xb8Y\x02\x00\x10\x00\x00\x00\x00\x00\x00\x00\xa0\x1e\x00…        r3 load str located at 4295122208
    call function_18489                     
lbb_18358:
    lddw r3, 0x100025d38 --> b"\x00\x00\x00\x00\xb8Y\x02\x00\x10\x00\x00\x00\x00\x00\x00\x00\xa1\x1e\x00…        r3 load str located at 4295122232
    call function_18489                     

function_18361:
    ldxdw r1, [r1+0x8]                      
    ldxw r4, [r1+0x14]                      
    ldxw r3, [r1+0x10]                      
    ldxdw r2, [r1+0x8]                      
    ldxdw r1, [r1+0x0]                      
    syscall [invalid]                       

function_18367:
    stxdw [r10-0xe40], r1                   
    mov64 r6, 1                                     r6 = 1 as i32 as i64 as u64
    ldxdw r0, [r2+0x20]                     
    jgt r0, 64, lbb_18480                           if r0 > (64 as i32 as i64 as u64) { pc += 109 }
    mov64 r6, 10                                    r6 = 10 as i32 as i64 as u64
    jgt r0, r4, lbb_18480                           if r0 > r4 { pc += 107 }
    ldxdw r1, [r5-0xff8]                    
    stxdw [r10-0xe58], r1                   
    ldxdw r1, [r5-0x1000]                   
    stxdw [r10-0xe60], r1                   
    stxdw [r10-0xe50], r2                   
    ldxdw r1, [r2+0x18]                     
    stxdw [r10-0xe48], r1                   
    jeq r0, 0, lbb_18459                            if r0 == (0 as i32 as i64 as u64) { pc += 78 }
    mov64 r7, 0                                     r7 = 0 as i32 as i64 as u64
    mov64 r8, r10                                   r8 = r10
    add64 r8, -3574                                 r8 += -3574   ///  r8 = r8.wrapping_add(-3574 as i32 as i64 as u64)
    ldxdw r9, [r10-0xe48]                   
    add64 r9, 8                                     r9 += 8   ///  r9 = r9.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0xe38], r0                   
    ja lbb_18410                                    if true { pc += 22 }
lbb_18388:
    add64 r7, 1                                     r7 += 1   ///  r7 = r7.wrapping_add(1 as i32 as i64 as u64)
    ldxdw r1, [r0+0x50]                     
    mov64 r6, r0                                    r6 = r0
    add64 r6, 40                                    r6 += 40   ///  r6 = r6.wrapping_add(40 as i32 as i64 as u64)
    stxdw [r8-0x12], r6                     
    mov64 r6, r0                                    r6 = r0
    add64 r6, 88                                    r6 += 88   ///  r6 = r6.wrapping_add(88 as i32 as i64 as u64)
    stxdw [r8-0x1a], r6                     
    stxdw [r8-0x22], r1                     
    add64 r0, 72                                    r0 += 72   ///  r0 = r0.wrapping_add(72 as i32 as i64 as u64)
    stxdw [r8-0x2a], r0                     
    stxdw [r8-0x32], r2                     
    stxb [r8+0x0], r4                       
    stxb [r8-0x1], r5                       
    ldxdw r1, [r10-0xe30]                   
    stxb [r8-0x2], r1                       
    stdw [r8-0xa], 0                        
    add64 r8, 56                                    r8 += 56   ///  r8 = r8.wrapping_add(56 as i32 as i64 as u64)
    add64 r9, 16                                    r9 += 16   ///  r9 = r9.wrapping_add(16 as i32 as i64 as u64)
    add64 r3, 8                                     r3 += 8   ///  r3 = r3.wrapping_add(8 as i32 as i64 as u64)
    ldxdw r0, [r10-0xe38]                   
    jge r7, r0, lbb_18459                           if r7 >= r0 { pc += 49 }
lbb_18410:
    mov64 r6, 1                                     r6 = 1 as i32 as i64 as u64
    ldxdw r1, [r3+0x0]                      
    ldxdw r0, [r1+0x0]                      
    ldxdw r1, [r9-0x8]                      
    ldxdw r4, [r1+0x0]                      
    ldxdw r5, [r0+0x8]                      
    jne r5, r4, lbb_18480                           if r5 != r4 { pc += 63 }
    ldxdw r4, [r1+0x8]                      
    ldxdw r5, [r0+0x10]                     
    jne r5, r4, lbb_18480                           if r5 != r4 { pc += 60 }
    ldxdw r4, [r1+0x10]                     
    ldxdw r5, [r0+0x18]                     
    jne r5, r4, lbb_18480                           if r5 != r4 { pc += 57 }
    ldxdw r1, [r1+0x18]                     
    ldxdw r4, [r0+0x20]                     
    jne r4, r1, lbb_18480                           if r4 != r1 { pc += 54 }
    ldxb r4, [r9+0x0]                       
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    jne r4, 0, lbb_18430                            if r4 != (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r1, 119                                   r1 = 119 as i32 as i64 as u64
lbb_18430:
    ldxb r4, [r0+0x0]                       
    or64 r1, r4                                     r1 |= r4   ///  r1 = r1.or(r4)
    and64 r1, 255                                   r1 &= 255   ///  r1 = r1.and(255)
    jne r1, 255, lbb_18479                          if r1 != (255 as i32 as i64 as u64) { pc += 45 }
    ldxb r5, [r0+0x1]                       
    mov64 r4, 1                                     r4 = 1 as i32 as i64 as u64
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    jeq r5, 0, lbb_18447                            if r5 == (0 as i32 as i64 as u64) { pc += 9 }
    stxdw [r10-0xe30], r1                   
    ldxb r1, [r0+0x2]                       
    mov64 r5, 1                                     r5 = 1 as i32 as i64 as u64
    jeq r1, 0, lbb_18452                            if r1 == (0 as i32 as i64 as u64) { pc += 10 }
lbb_18442:
    mov64 r2, r0                                    r2 = r0
    add64 r2, 8                                     r2 += 8   ///  r2 = r2.wrapping_add(8 as i32 as i64 as u64)
    ldxb r1, [r0+0x3]                       
    jne r1, 0, lbb_18388                            if r1 != (0 as i32 as i64 as u64) { pc += -58 }
    ja lbb_18457                                    if true { pc += 10 }
lbb_18447:
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    stxdw [r10-0xe30], r1                   
    ldxb r1, [r0+0x2]                       
    mov64 r5, 1                                     r5 = 1 as i32 as i64 as u64
    jne r1, 0, lbb_18442                            if r1 != (0 as i32 as i64 as u64) { pc += -10 }
lbb_18452:
    mov64 r5, 0                                     r5 = 0 as i32 as i64 as u64
    mov64 r2, r0                                    r2 = r0
    add64 r2, 8                                     r2 += 8   ///  r2 = r2.wrapping_add(8 as i32 as i64 as u64)
    ldxb r1, [r0+0x3]                       
    jne r1, 0, lbb_18388                            if r1 != (0 as i32 as i64 as u64) { pc += -69 }
lbb_18457:
    mov64 r4, 0                                     r4 = 0 as i32 as i64 as u64
    ja lbb_18388                                    if true { pc += -71 }
lbb_18459:
    ldxdw r3, [r10-0xe50]                   
    ldxdw r1, [r3+0x0]                      
    ldxdw r2, [r3+0x8]                      
    ldxdw r3, [r3+0x10]                     
    stxdw [r10-0x8], r3                     
    stxdw [r10-0x10], r2                    
    ldxdw r2, [r10-0xe48]                   
    stxdw [r10-0x20], r2                    
    stxdw [r10-0x28], r1                    
    stxdw [r10-0x18], r0                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -40                                   r1 += -40   ///  r1 = r1.wrapping_add(-40 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -3624                                 r2 += -3624   ///  r2 = r2.wrapping_add(-3624 as i32 as i64 as u64)
    mov64 r3, r0                                    r3 = r0
    ldxdw r4, [r10-0xe60]                   
    ldxdw r5, [r10-0xe58]                   
    syscall [invalid]                       
    mov64 r6, 26                                    r6 = 26 as i32 as i64 as u64
    ja lbb_18480                                    if true { pc += 1 }
lbb_18479:
    mov64 r6, 11                                    r6 = 11 as i32 as i64 as u64
lbb_18480:
    ldxdw r1, [r10-0xe40]                   
    stxw [r1+0x0], r6                       
    exit                                    

function_18483:
    stxdw [r10-0x10], r2                    
    stxdw [r10-0x18], r1                    
    sth [r10-0x8], 1                        
    mov64 r1, r10                                   r1 = r10
    add64 r1, -24                                   r1 += -24   ///  r1 = r1.wrapping_add(-24 as i32 as i64 as u64)
    call function_18361                     

function_18489:
    stxdw [r10-0x58], r2                    
    stxdw [r10-0x60], r1                    
    lddw r1, 0x100028200 --> b"\x00\x00\x00\x008Y\x02\x00 \x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x…        r1 load str located at 4295131648
    stxdw [r10-0x50], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -32                                   r1 += -32   ///  r1 = r1.wrapping_add(-32 as i32 as i64 as u64)
    stxdw [r10-0x40], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -96                                   r1 += -96   ///  r1 = r1.wrapping_add(-96 as i32 as i64 as u64)
    stxdw [r10-0x10], r1                    
    lddw r1, 0x100025058 --> b"\xbf#\x00\x00\x00\x00\x00\x00y\x11\x00\x00\x00\x00\x00\x00\xb7\x02\x00\x0…        r1 load str located at 4295118936
    stxdw [r10-0x8], r1                     
    stxdw [r10-0x18], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -88                                   r1 += -88   ///  r1 = r1.wrapping_add(-88 as i32 as i64 as u64)
    stxdw [r10-0x20], r1                    
    stdw [r10-0x30], 0                      
    stdw [r10-0x48], 2                      
    stdw [r10-0x38], 2                      
    mov64 r1, r10                                   r1 = r10
    add64 r1, -80                                   r1 += -80   ///  r1 = r1.wrapping_add(-80 as i32 as i64 as u64)
    mov64 r2, r3                                    r2 = r3
    call function_18483                     

function_18514:
    mov64 r6, r1                                    r6 = r1
    ldxdw r9, [r5-0xff8]                    
    stxdw [r10-0x28], r9                    
    jeq r2, 0, lbb_18525                            if r2 == (0 as i32 as i64 as u64) { pc += 7 }
    mov64 r2, 1114112                               r2 = 1114112 as i32 as i64 as u64
    ldxw r7, [r6+0x34]                      
    mov64 r1, r7                                    r1 = r7
    and64 r1, 1                                     r1 &= 1   ///  r1 = r1.and(1)
    jeq r1, 0, lbb_18528                            if r1 == (0 as i32 as i64 as u64) { pc += 5 }
    mov64 r2, 43                                    r2 = 43 as i32 as i64 as u64
    ja lbb_18527                                    if true { pc += 2 }
lbb_18525:
    mov64 r2, 45                                    r2 = 45 as i32 as i64 as u64
    ldxw r7, [r6+0x34]                      
lbb_18527:
    add64 r9, 1                                     r9 += 1   ///  r9 = r9.wrapping_add(1 as i32 as i64 as u64)
lbb_18528:
    ldxdw r1, [r5-0x1000]                   
    stxdw [r10-0x30], r1                    
    mov64 r1, r7                                    r1 = r7
    and64 r1, 4                                     r1 &= 4   ///  r1 = r1.and(4)
    jne r1, 0, lbb_18536                            if r1 != (0 as i32 as i64 as u64) { pc += 3 }
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
    mov64 r8, r9                                    r8 = r9
    ja lbb_18563                                    if true { pc += 27 }
lbb_18536:
    stxdw [r10-0x38], r2                    
    jge r4, 32, lbb_18553                           if r4 >= (32 as i32 as i64 as u64) { pc += 15 }
    mov64 r8, 0                                     r8 = 0 as i32 as i64 as u64
    jeq r4, 0, lbb_18561                            if r4 == (0 as i32 as i64 as u64) { pc += 21 }
    mov64 r1, r3                                    r1 = r3
    mov64 r2, r4                                    r2 = r4
lbb_18542:
    ldxb r5, [r1+0x0]                       
    lsh64 r5, 56                                    r5 <<= 56   ///  r5 = r5.wrapping_shl(56)
    arsh64 r5, 56                                   r5 >>= 56 (signed)   ///  r5 = (r5 as i64).wrapping_shr(56)
    mov64 r0, 1                                     r0 = 1 as i32 as i64 as u64
    jsgt r5, -65, lbb_18548                         if (r5 as i64) > (-65 as i32 as i64) { pc += 1 }
    mov64 r0, 0                                     r0 = 0 as i32 as i64 as u64
lbb_18548:
    add64 r8, r0                                    r8 += r0   ///  r8 = r8.wrapping_add(r0)
    add64 r1, 1                                     r1 += 1   ///  r1 = r1.wrapping_add(1 as i32 as i64 as u64)
    add64 r2, -1                                    r2 += -1   ///  r2 = r2.wrapping_add(-1 as i32 as i64 as u64)
    jne r2, 0, lbb_18542                            if r2 != (0 as i32 as i64 as u64) { pc += -10 }
    ja lbb_18561                                    if true { pc += 8 }
lbb_18553:
    mov64 r1, r3                                    r1 = r3
    mov64 r2, r4                                    r2 = r4
    stxdw [r10-0x40], r4                    
    stxdw [r10-0x48], r3                    
    call function_18738                     
    mov64 r8, r0                                    r8 = r0
    ldxdw r3, [r10-0x48]                    
    ldxdw r4, [r10-0x40]                    
lbb_18561:
    add64 r8, r9                                    r8 += r9   ///  r8 = r8.wrapping_add(r9)
    ldxdw r2, [r10-0x38]                    
lbb_18563:
    ldxdw r1, [r6+0x0]                      
    jeq r1, 0, lbb_18609                            if r1 == (0 as i32 as i64 as u64) { pc += 44 }
    ldxdw r9, [r6+0x8]                      
    jle r9, r8, lbb_18609                           if r9 <= r8 { pc += 42 }
    and64 r7, 8                                     r7 &= 8   ///  r7 = r7.and(8)
    jne r7, 0, lbb_18623                            if r7 != (0 as i32 as i64 as u64) { pc += 54 }
    stxdw [r10-0x38], r2                    
    stxdw [r10-0x48], r3                    
    stxdw [r10-0x40], r4                    
    sub64 r9, r8                                    r9 -= r8   ///  r9 = r9.wrapping_sub(r8)
    mov64 r1, r10                                   r1 = r10
    add64 r1, -32                                   r1 += -32   ///  r1 = r1.wrapping_add(-32 as i32 as i64 as u64)
    mov64 r7, 1                                     r7 = 1 as i32 as i64 as u64
    mov64 r2, r6                                    r2 = r6
    mov64 r3, r9                                    r3 = r9
    mov64 r4, 1                                     r4 = 1 as i32 as i64 as u64
    call function_18701                     
    ldxw r8, [r10-0x18]                     
    jeq r8, 1114112, lbb_18620                      if r8 == (1114112 as i32 as i64 as u64) { pc += 38 }
    ldxdw r1, [r10-0x20]                    
    stxdw [r10-0x50], r1                    
    mov64 r1, r6                                    r1 = r6
    ldxdw r2, [r10-0x38]                    
    ldxdw r3, [r10-0x48]                    
    ldxdw r4, [r10-0x40]                    
    call function_18677                     
    jne r0, 0, lbb_18620                            if r0 != (0 as i32 as i64 as u64) { pc += 30 }
    ldxdw r1, [r6+0x20]                     
    ldxdw r6, [r6+0x28]                     
    ldxdw r4, [r6+0x18]                     
    stxdw [r10-0x38], r1                    
    ldxdw r2, [r10-0x30]                    
    ldxdw r3, [r10-0x28]                    
    callx r4                                
    jne r0, 0, lbb_18620                            if r0 != (0 as i32 as i64 as u64) { pc += 22 }
    mov64 r9, 0                                     r9 = 0 as i32 as i64 as u64
    ldxdw r7, [r10-0x50]                    
lbb_18600:
    jeq r7, r9, lbb_18671                           if r7 == r9 { pc += 70 }
    ldxdw r3, [r6+0x20]                     
    ldxdw r1, [r10-0x38]                    
    mov64 r2, r8                                    r2 = r8
    callx r3                                
    add64 r9, 1                                     r9 += 1   ///  r9 = r9.wrapping_add(1 as i32 as i64 as u64)
    jeq r0, 0, lbb_18600                            if r0 == (0 as i32 as i64 as u64) { pc += -7 }
    add64 r9, -1                                    r9 += -1   ///  r9 = r9.wrapping_add(-1 as i32 as i64 as u64)
    ja lbb_18672                                    if true { pc += 63 }
lbb_18609:
    mov64 r1, r6                                    r1 = r6
    call function_18677                     
    mov64 r7, 1                                     r7 = 1 as i32 as i64 as u64
    jne r0, 0, lbb_18620                            if r0 != (0 as i32 as i64 as u64) { pc += 7 }
    ldxdw r1, [r6+0x20]                     
    ldxdw r2, [r6+0x28]                     
    ldxdw r4, [r2+0x18]                     
    ldxdw r2, [r10-0x30]                    
    ldxdw r3, [r10-0x28]                    
    callx r4                                
    mov64 r7, r0                                    r7 = r0
lbb_18620:
    and64 r7, 1                                     r7 &= 1   ///  r7 = r7.and(1)
    mov64 r0, r7                                    r0 = r7
    exit                                    
lbb_18623:
    ldxw r1, [r6+0x30]                      
    stxdw [r10-0x50], r1                    
    stw [r6+0x30], 48                       
    ldxb r1, [r6+0x38]                      
    stxdw [r10-0x58], r1                    
    stb [r6+0x38], 1                        
    mov64 r1, r6                                    r1 = r6
    call function_18677                     
    mov64 r7, 1                                     r7 = 1 as i32 as i64 as u64
    jne r0, 0, lbb_18620                            if r0 != (0 as i32 as i64 as u64) { pc += -13 }
    sub64 r9, r8                                    r9 -= r8   ///  r9 = r9.wrapping_sub(r8)
    mov64 r1, r10                                   r1 = r10
    add64 r1, -16                                   r1 += -16   ///  r1 = r1.wrapping_add(-16 as i32 as i64 as u64)
    mov64 r2, r6                                    r2 = r6
    mov64 r3, r9                                    r3 = r9
    mov64 r4, 1                                     r4 = 1 as i32 as i64 as u64
    call function_18701                     
    ldxw r8, [r10-0x8]                      
    jeq r8, 1114112, lbb_18620                      if r8 == (1114112 as i32 as i64 as u64) { pc += -22 }
    ldxdw r1, [r10-0x10]                    
    stxdw [r10-0x38], r1                    
    ldxdw r1, [r6+0x20]                     
    ldxdw r2, [r6+0x28]                     
    stxdw [r10-0x48], r2                    
    ldxdw r4, [r2+0x18]                     
    stxdw [r10-0x40], r1                    
    ldxdw r2, [r10-0x30]                    
    ldxdw r3, [r10-0x28]                    
    callx r4                                
    jne r0, 0, lbb_18620                            if r0 != (0 as i32 as i64 as u64) { pc += -33 }
    mov64 r9, 0                                     r9 = 0 as i32 as i64 as u64
lbb_18654:
    ldxdw r1, [r10-0x38]                    
    jeq r1, r9, lbb_18666                           if r1 == r9 { pc += 10 }
    ldxdw r1, [r10-0x48]                    
    ldxdw r3, [r1+0x20]                     
    ldxdw r1, [r10-0x40]                    
    mov64 r2, r8                                    r2 = r8
    callx r3                                
    add64 r9, 1                                     r9 += 1   ///  r9 = r9.wrapping_add(1 as i32 as i64 as u64)
    jeq r0, 0, lbb_18654                            if r0 == (0 as i32 as i64 as u64) { pc += -9 }
    add64 r9, -1                                    r9 += -1   ///  r9 = r9.wrapping_add(-1 as i32 as i64 as u64)
    ldxdw r1, [r10-0x38]                    
    jlt r9, r1, lbb_18620                           if r9 < r1 { pc += -46 }
lbb_18666:
    ldxdw r1, [r10-0x58]                    
    stxb [r6+0x38], r1                      
    ldxdw r1, [r10-0x50]                    
    stxw [r6+0x30], r1                      
    ja lbb_18675                                    if true { pc += 4 }
lbb_18671:
    mov64 r9, r7                                    r9 = r7
lbb_18672:
    mov64 r1, r7                                    r1 = r7
    mov64 r7, 1                                     r7 = 1 as i32 as i64 as u64
    jlt r9, r1, lbb_18620                           if r9 < r1 { pc += -55 }
lbb_18675:
    mov64 r7, 0                                     r7 = 0 as i32 as i64 as u64
    ja lbb_18620                                    if true { pc += -57 }

function_18677:
    mov64 r6, r4                                    r6 = r4
    mov64 r7, r3                                    r7 = r3
    mov64 r8, r1                                    r8 = r1
    mov64 r1, r2                                    r1 = r2
    lsh64 r1, 32                                    r1 <<= 32   ///  r1 = r1.wrapping_shl(32)
    rsh64 r1, 32                                    r1 >>= 32   ///  r1 = r1.wrapping_shr(32)
    jeq r1, 1114112, lbb_18691                      if r1 == (1114112 as i32 as i64 as u64) { pc += 7 }
    ldxdw r1, [r8+0x20]                     
    ldxdw r3, [r8+0x28]                     
    ldxdw r3, [r3+0x20]                     
    callx r3                                
    mov64 r1, r0                                    r1 = r0
    mov64 r0, 1                                     r0 = 1 as i32 as i64 as u64
    jne r1, 0, lbb_18700                            if r1 != (0 as i32 as i64 as u64) { pc += 9 }
lbb_18691:
    jeq r7, 0, lbb_18699                            if r7 == (0 as i32 as i64 as u64) { pc += 7 }
    ldxdw r1, [r8+0x20]                     
    ldxdw r2, [r8+0x28]                     
    ldxdw r4, [r2+0x18]                     
    mov64 r2, r7                                    r2 = r7
    mov64 r3, r6                                    r3 = r6
    callx r4                                
    ja lbb_18700                                    if true { pc += 1 }
lbb_18699:
    mov64 r0, 0                                     r0 = 0 as i32 as i64 as u64
lbb_18700:
    exit                                    

function_18701:
    stxdw [r10-0x8], r1                     
    ldxb r9, [r2+0x38]                      
    jsgt r9, 1, lbb_18706                           if (r9 as i64) > (1 as i32 as i64) { pc += 2 }
    jne r9, 0, lbb_18714                            if r9 != (0 as i32 as i64 as u64) { pc += 9 }
    ja lbb_18719                                    if true { pc += 13 }
lbb_18706:
    jne r9, 2, lbb_18712                            if r9 != (2 as i32 as i64 as u64) { pc += 5 }
    mov64 r9, r3                                    r9 = r3
    rsh64 r9, 1                                     r9 >>= 1   ///  r9 = r9.wrapping_shr(1)
    add64 r3, 1                                     r3 += 1   ///  r3 = r3.wrapping_add(1 as i32 as i64 as u64)
    rsh64 r3, 1                                     r3 >>= 1   ///  r3 = r3.wrapping_shr(1)
    ja lbb_18719                                    if true { pc += 7 }
lbb_18712:
    and64 r4, 255                                   r4 &= 255   ///  r4 = r4.and(255)
    jeq r4, 0, lbb_18718                            if r4 == (0 as i32 as i64 as u64) { pc += 4 }
lbb_18714:
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    stxdw [r10-0x10], r1                    
    mov64 r9, r3                                    r9 = r3
    ja lbb_18720                                    if true { pc += 2 }
lbb_18718:
    mov64 r9, 0                                     r9 = 0 as i32 as i64 as u64
lbb_18719:
    stxdw [r10-0x10], r3                    
lbb_18720:
    add64 r9, 1                                     r9 += 1   ///  r9 = r9.wrapping_add(1 as i32 as i64 as u64)
    ldxw r7, [r2+0x30]                      
    ldxdw r6, [r2+0x28]                     
    ldxdw r8, [r2+0x20]                     
lbb_18724:
    add64 r9, -1                                    r9 += -1   ///  r9 = r9.wrapping_add(-1 as i32 as i64 as u64)
    jeq r9, 0, lbb_18732                            if r9 == (0 as i32 as i64 as u64) { pc += 6 }
    ldxdw r3, [r6+0x20]                     
    mov64 r1, r8                                    r1 = r8
    mov64 r2, r7                                    r2 = r7
    callx r3                                
    jeq r0, 0, lbb_18724                            if r0 == (0 as i32 as i64 as u64) { pc += -7 }
    mov64 r7, 1114112                               r7 = 1114112 as i32 as i64 as u64
lbb_18732:
    ldxdw r1, [r10-0x8]                     
    stxw [r1+0x8], r7                       
    ldxdw r2, [r10-0x10]                    
    stxdw [r1+0x0], r2                      
    exit                                    

function_18737:
    call function_19009                     

function_18738:
    mov64 r7, r1                                    r7 = r1
    add64 r7, 7                                     r7 += 7   ///  r7 = r7.wrapping_add(7 as i32 as i64 as u64)
    and64 r7, -8                                    r7 &= -8   ///  r7 = r7.and(-8)
    mov64 r3, r7                                    r3 = r7
    sub64 r3, r1                                    r3 -= r1   ///  r3 = r3.wrapping_sub(r1)
    jge r2, r3, lbb_18757                           if r2 >= r3 { pc += 13 }
lbb_18744:
    mov64 r0, 0                                     r0 = 0 as i32 as i64 as u64
    jeq r2, 0, lbb_18896                            if r2 == (0 as i32 as i64 as u64) { pc += 150 }
lbb_18746:
    ldxb r4, [r1+0x0]                       
    lsh64 r4, 56                                    r4 <<= 56   ///  r4 = r4.wrapping_shl(56)
    arsh64 r4, 56                                   r4 >>= 56 (signed)   ///  r4 = (r4 as i64).wrapping_shr(56)
    mov64 r3, 1                                     r3 = 1 as i32 as i64 as u64
    jsgt r4, -65, lbb_18752                         if (r4 as i64) > (-65 as i32 as i64) { pc += 1 }
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
lbb_18752:
    add64 r0, r3                                    r0 += r3   ///  r0 = r0.wrapping_add(r3)
    add64 r1, 1                                     r1 += 1   ///  r1 = r1.wrapping_add(1 as i32 as i64 as u64)
    add64 r2, -1                                    r2 += -1   ///  r2 = r2.wrapping_add(-1 as i32 as i64 as u64)
    jne r2, 0, lbb_18746                            if r2 != (0 as i32 as i64 as u64) { pc += -10 }
    ja lbb_18896                                    if true { pc += 139 }
lbb_18757:
    mov64 r8, r2                                    r8 = r2
    sub64 r8, r3                                    r8 -= r3   ///  r8 = r8.wrapping_sub(r3)
    jlt r8, 8, lbb_18744                            if r8 < (8 as i32 as i64 as u64) { pc += -16 }
    stxdw [r10-0x8], r3                     
    mov64 r2, r8                                    r2 = r8
    and64 r2, 7                                     r2 &= 7   ///  r2 = r2.and(7)
    mov64 r0, 0                                     r0 = 0 as i32 as i64 as u64
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
    jeq r7, r1, lbb_18782                           if r7 == r1 { pc += 16 }
    mov64 r6, r1                                    r6 = r1
    sub64 r6, r7                                    r6 -= r7   ///  r6 = r6.wrapping_sub(r7)
    mov64 r7, r1                                    r7 = r1
lbb_18769:
    ldxb r5, [r7+0x0]                       
    lsh64 r5, 56                                    r5 <<= 56   ///  r5 = r5.wrapping_shl(56)
    arsh64 r5, 56                                   r5 >>= 56 (signed)   ///  r5 = (r5 as i64).wrapping_shr(56)
    mov64 r4, 1                                     r4 = 1 as i32 as i64 as u64
    mov64 r9, 1                                     r9 = 1 as i32 as i64 as u64
    jsgt r5, -65, lbb_18776                         if (r5 as i64) > (-65 as i32 as i64) { pc += 1 }
    mov64 r9, 0                                     r9 = 0 as i32 as i64 as u64
lbb_18776:
    add64 r6, 1                                     r6 += 1   ///  r6 = r6.wrapping_add(1 as i32 as i64 as u64)
    jeq r6, 0, lbb_18779                            if r6 == (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r4, 0                                     r4 = 0 as i32 as i64 as u64
lbb_18779:
    add64 r3, r9                                    r3 += r9   ///  r3 = r3.wrapping_add(r9)
    add64 r7, 1                                     r7 += 1   ///  r7 = r7.wrapping_add(1 as i32 as i64 as u64)
    jne r4, 1, lbb_18769                            if r4 != (1 as i32 as i64 as u64) { pc += -13 }
lbb_18782:
    ldxdw r4, [r10-0x8]                     
    add64 r1, r4                                    r1 += r4   ///  r1 = r1.wrapping_add(r4)
    jeq r2, 0, lbb_18800                            if r2 == (0 as i32 as i64 as u64) { pc += 15 }
    mov64 r0, r8                                    r0 = r8
    and64 r0, -8                                    r0 &= -8   ///  r0 = r0.and(-8)
    mov64 r5, r1                                    r5 = r1
    add64 r5, r0                                    r5 += r0   ///  r5 = r5.wrapping_add(r0)
    mov64 r0, 0                                     r0 = 0 as i32 as i64 as u64
lbb_18790:
    ldxb r7, [r5+0x0]                       
    lsh64 r7, 56                                    r7 <<= 56   ///  r7 = r7.wrapping_shl(56)
    arsh64 r7, 56                                   r7 >>= 56 (signed)   ///  r7 = (r7 as i64).wrapping_shr(56)
    mov64 r6, 1                                     r6 = 1 as i32 as i64 as u64
    jsgt r7, -65, lbb_18796                         if (r7 as i64) > (-65 as i32 as i64) { pc += 1 }
    mov64 r6, 0                                     r6 = 0 as i32 as i64 as u64
lbb_18796:
    add64 r0, r6                                    r0 += r6   ///  r0 = r0.wrapping_add(r6)
    add64 r5, 1                                     r5 += 1   ///  r5 = r5.wrapping_add(1 as i32 as i64 as u64)
    add64 r2, -1                                    r2 += -1   ///  r2 = r2.wrapping_add(-1 as i32 as i64 as u64)
    jne r2, 0, lbb_18790                            if r2 != (0 as i32 as i64 as u64) { pc += -10 }
lbb_18800:
    rsh64 r8, 3                                     r8 >>= 3   ///  r8 = r8.wrapping_shr(3)
    add64 r0, r3                                    r0 += r3   ///  r0 = r0.wrapping_add(r3)
    lddw r9, 0x101010101010101                      r9 load str located at 72340172838076673
lbb_18804:
    mov64 r7, r8                                    r7 = r8
    mov64 r3, r1                                    r3 = r1
    jeq r7, 0, lbb_18896                            if r7 == (0 as i32 as i64 as u64) { pc += 89 }
    mov64 r1, r7                                    r1 = r7
    jlt r7, 192, lbb_18810                          if r7 < (192 as i32 as i64 as u64) { pc += 1 }
    mov64 r1, 192                                   r1 = 192 as i32 as i64 as u64
lbb_18810:
    stxdw [r10-0x10], r1                    
    lsh64 r1, 3                                     r1 <<= 3   ///  r1 = r1.wrapping_shl(3)
    stxdw [r10-0x8], r1                     
    mov64 r5, 0                                     r5 = 0 as i32 as i64 as u64
    jlt r7, 4, lbb_18837                            if r7 < (4 as i32 as i64 as u64) { pc += 22 }
    ldxdw r2, [r10-0x8]                     
    and64 r2, 2016                                  r2 &= 2016   ///  r2 = r2.and(2016)
    mov64 r1, r3                                    r1 = r3
    add64 r1, r2                                    r1 += r2   ///  r1 = r1.wrapping_add(r2)
    mov64 r2, r3                                    r2 = r3
lbb_18820:
    mov64 r8, r5                                    r8 = r5
    mov64 r6, 0                                     r6 = 0 as i32 as i64 as u64
lbb_18822:
    mov64 r5, r2                                    r5 = r2
    add64 r5, r6                                    r5 += r6   ///  r5 = r5.wrapping_add(r6)
    ldxdw r5, [r5+0x0]                      
    mov64 r4, r5                                    r4 = r5
    rsh64 r4, 6                                     r4 >>= 6   ///  r4 = r4.wrapping_shr(6)
    xor64 r5, -1                                    r5 ^= -1   ///  r5 = r5.xor(-1)
    rsh64 r5, 7                                     r5 >>= 7   ///  r5 = r5.wrapping_shr(7)
    or64 r5, r4                                     r5 |= r4   ///  r5 = r5.or(r4)
    and64 r5, r9                                    r5 &= r9   ///  r5 = r5.and(r9)
    add64 r5, r8                                    r5 += r8   ///  r5 = r5.wrapping_add(r8)
    add64 r6, 8                                     r6 += 8   ///  r6 = r6.wrapping_add(8 as i32 as i64 as u64)
    mov64 r8, r5                                    r8 = r5
    jne r6, 32, lbb_18822                           if r6 != (32 as i32 as i64 as u64) { pc += -13 }
    add64 r2, 32                                    r2 += 32   ///  r2 = r2.wrapping_add(32 as i32 as i64 as u64)
    jne r2, r1, lbb_18820                           if r2 != r1 { pc += -17 }
lbb_18837:
    mov64 r1, r3                                    r1 = r3
    ldxdw r2, [r10-0x8]                     
    add64 r1, r2                                    r1 += r2   ///  r1 = r1.wrapping_add(r2)
    ldxdw r2, [r10-0x10]                    
    mov64 r4, r2                                    r4 = r2
    and64 r4, 3                                     r4 &= 3   ///  r4 = r4.and(3)
    stxdw [r10-0x8], r3                     
    mov64 r3, r7                                    r3 = r7
    sub64 r3, r2                                    r3 -= r2   ///  r3 = r3.wrapping_sub(r2)
    mov64 r6, r5                                    r6 = r5
    lddw r8, 0xff00ff00ff00ff                       r8 load str located at 71777214294589695
    and64 r6, r8                                    r6 &= r8   ///  r6 = r6.and(r8)
    rsh64 r5, 8                                     r5 >>= 8   ///  r5 = r5.wrapping_shr(8)
    and64 r5, r8                                    r5 &= r8   ///  r5 = r5.and(r8)
    mov64 r8, r3                                    r8 = r3
    add64 r5, r6                                    r5 += r6   ///  r5 = r5.wrapping_add(r6)
    lddw r6, 0x1000100010001                        r6 load str located at 281479271743489
    mul64 r5, r6                                    r5 *= r6   ///  r5 = r5.wrapping_mul(r6)
    rsh64 r5, 48                                    r5 >>= 48   ///  r5 = r5.wrapping_shr(48)
    add64 r5, r0                                    r5 += r0   ///  r5 = r5.wrapping_add(r0)
    mov64 r0, r5                                    r0 = r5
    jeq r4, 0, lbb_18804                            if r4 == (0 as i32 as i64 as u64) { pc += -57 }
    ldxdw r3, [r10-0x8]                     
    and64 r2, 252                                   r2 &= 252   ///  r2 = r2.and(252)
    lsh64 r2, 3                                     r2 <<= 3   ///  r2 = r2.wrapping_shl(3)
    jlt r7, 192, lbb_18866                          if r7 < (192 as i32 as i64 as u64) { pc += 1 }
    mov64 r7, 192                                   r7 = 192 as i32 as i64 as u64
lbb_18866:
    add64 r3, r2                                    r3 += r2   ///  r3 = r3.wrapping_add(r2)
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
    and64 r7, 3                                     r7 &= 3   ///  r7 = r7.and(3)
    lsh64 r7, 3                                     r7 <<= 3   ///  r7 = r7.wrapping_shl(3)
    lddw r1, 0x101010101010101                      r1 load str located at 72340172838076673
lbb_18872:
    ldxdw r0, [r3+0x0]                      
    mov64 r4, r0                                    r4 = r0
    rsh64 r4, 6                                     r4 >>= 6   ///  r4 = r4.wrapping_shr(6)
    xor64 r0, -1                                    r0 ^= -1   ///  r0 = r0.xor(-1)
    rsh64 r0, 7                                     r0 >>= 7   ///  r0 = r0.wrapping_shr(7)
    or64 r0, r4                                     r0 |= r4   ///  r0 = r0.or(r4)
    and64 r0, r1                                    r0 &= r1   ///  r0 = r0.and(r1)
    add64 r0, r2                                    r0 += r2   ///  r0 = r0.wrapping_add(r2)
    add64 r3, 8                                     r3 += 8   ///  r3 = r3.wrapping_add(8 as i32 as i64 as u64)
    add64 r7, -8                                    r7 += -8   ///  r7 = r7.wrapping_add(-8 as i32 as i64 as u64)
    mov64 r2, r0                                    r2 = r0
    jne r7, 0, lbb_18872                            if r7 != (0 as i32 as i64 as u64) { pc += -12 }
    lddw r1, 0xff00ff00ff00ff                       r1 load str located at 71777214294589695
    mov64 r2, r0                                    r2 = r0
    and64 r2, r1                                    r2 &= r1   ///  r2 = r2.and(r1)
    rsh64 r0, 8                                     r0 >>= 8   ///  r0 = r0.wrapping_shr(8)
    and64 r0, r1                                    r0 &= r1   ///  r0 = r0.and(r1)
    add64 r0, r2                                    r0 += r2   ///  r0 = r0.wrapping_add(r2)
    lddw r1, 0x1000100010001                        r1 load str located at 281479271743489
    mul64 r0, r1                                    r0 *= r1   ///  r0 = r0.wrapping_mul(r1)
    rsh64 r0, 48                                    r0 >>= 48   ///  r0 = r0.wrapping_shr(48)
    add64 r0, r5                                    r0 += r5   ///  r0 = r0.wrapping_add(r5)
lbb_18896:
    exit                                    

function_18897:
    mov64 r2, r1                                    r2 = r1
    lddw r1, 0x1000281f0 --> b"\x00\x00\x00\x00\xe3Y\x02\x00\x1f\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00…        r1 load str located at 4295131632
    stxdw [r10-0x30], r1                    
    stdw [r10-0x10], 0                      
    stdw [r10-0x28], 1                      
    stdw [r10-0x18], 0                      
    stdw [r10-0x20], 8                      
    mov64 r1, r10                                   r1 = r10
    add64 r1, -48                                   r1 += -48   ///  r1 = r1.wrapping_add(-48 as i32 as i64 as u64)
    call function_18483                     

function_18908:
    mov64 r2, r1                                    r2 = r1
    lddw r1, 0x100028220 --> b"\x00\x00\x00\x00\xdcZ\x02\x00\x19\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00…        r1 load str located at 4295131680
    stxdw [r10-0x30], r1                    
    stdw [r10-0x10], 0                      
    stdw [r10-0x28], 1                      
    stdw [r10-0x18], 0                      
    stdw [r10-0x20], 8                      
    mov64 r1, r10                                   r1 = r10
    add64 r1, -48                                   r1 += -48   ///  r1 = r1.wrapping_add(-48 as i32 as i64 as u64)
    call function_18483                     
    mov64 r3, r2                                    r3 = r2
    ldxdw r1, [r1+0x0]                      
    mov64 r2, 1                                     r2 = 1 as i32 as i64 as u64
    call function_18924                     
    exit                                    

function_18924:
    mov64 r4, 20                                    r4 = 20 as i32 as i64 as u64
    jlt r1, 10000, lbb_18958                        if r1 < (10000 as i32 as i64 as u64) { pc += 32 }
    mov64 r4, 0                                     r4 = 0 as i32 as i64 as u64
lbb_18927:
    mov64 r5, r1                                    r5 = r1
    div64 r1, 10000                                 r1 /= 10000   ///  r1 = r1 / (10000 as u64)
    mov64 r6, r1                                    r6 = r1
    mul64 r6, 10000                                 r6 *= 10000   ///  r6 = r6.wrapping_mul(10000 as u64)
    mov64 r0, r5                                    r0 = r5
    sub64 r0, r6                                    r0 -= r6   ///  r0 = r0.wrapping_sub(r6)
    mov64 r6, r0                                    r6 = r0
    and64 r6, 65535                                 r6 &= 65535   ///  r6 = r6.and(65535)
    div64 r6, 100                                   r6 /= 100   ///  r6 = r6 / (100 as u64)
    mov64 r7, r6                                    r7 = r6
    mul64 r7, 100                                   r7 *= 100   ///  r7 = r7.wrapping_mul(100 as u64)
    sub64 r0, r7                                    r0 -= r7   ///  r0 = r0.wrapping_sub(r7)
    mov64 r7, r10                                   r7 = r10
    add64 r7, -20                                   r7 += -20   ///  r7 = r7.wrapping_add(-20 as i32 as i64 as u64)
    add64 r7, r4                                    r7 += r4   ///  r7 = r7.wrapping_add(r4)
    lsh64 r6, 1                                     r6 <<= 1   ///  r6 = r6.wrapping_shl(1)
    lddw r8, 0x100025a14 --> b"00010203040506070809101112131415161718192021222324"        r8 load str located at 4295121428
    add64 r8, r6                                    r8 += r6   ///  r8 = r8.wrapping_add(r6)
    ldxh r6, [r8+0x0]                       
    stxh [r7+0x10], r6                      
    lsh64 r0, 1                                     r0 <<= 1   ///  r0 = r0.wrapping_shl(1)
    and64 r0, 65534                                 r0 &= 65534   ///  r0 = r0.and(65534)
    lddw r6, 0x100025a14 --> b"00010203040506070809101112131415161718192021222324"        r6 load str located at 4295121428
    add64 r6, r0                                    r6 += r0   ///  r6 = r6.wrapping_add(r0)
    ldxh r0, [r6+0x0]                       
    stxh [r7+0x12], r0                      
    add64 r4, -4                                    r4 += -4   ///  r4 = r4.wrapping_add(-4 as i32 as i64 as u64)
    jgt r5, 99999999, lbb_18927                     if r5 > (99999999 as i32 as i64 as u64) { pc += -30 }
    add64 r4, 20                                    r4 += 20   ///  r4 = r4.wrapping_add(20 as i32 as i64 as u64)
lbb_18958:
    jle r1, 99, lbb_18988                           if r1 <= (99 as i32 as i64 as u64) { pc += 29 }
    mov64 r5, r1                                    r5 = r1
    and64 r5, 65535                                 r5 &= 65535   ///  r5 = r5.and(65535)
    div64 r5, 100                                   r5 /= 100   ///  r5 = r5 / (100 as u64)
    mov64 r0, r5                                    r0 = r5
    mul64 r0, 100                                   r0 *= 100   ///  r0 = r0.wrapping_mul(100 as u64)
    sub64 r1, r0                                    r1 -= r0   ///  r1 = r1.wrapping_sub(r0)
    lsh64 r1, 1                                     r1 <<= 1   ///  r1 = r1.wrapping_shl(1)
    and64 r1, 65534                                 r1 &= 65534   ///  r1 = r1.and(65534)
    lddw r0, 0x100025a14 --> b"00010203040506070809101112131415161718192021222324"        r0 load str located at 4295121428
    add64 r0, r1                                    r0 += r1   ///  r0 = r0.wrapping_add(r1)
    add64 r4, -2                                    r4 += -2   ///  r4 = r4.wrapping_add(-2 as i32 as i64 as u64)
    mov64 r1, r10                                   r1 = r10
    add64 r1, -20                                   r1 += -20   ///  r1 = r1.wrapping_add(-20 as i32 as i64 as u64)
    add64 r1, r4                                    r1 += r4   ///  r1 = r1.wrapping_add(r4)
    ldxh r0, [r0+0x0]                       
    stxh [r1+0x0], r0                       
    jlt r5, 10, lbb_18990                           if r5 < (10 as i32 as i64 as u64) { pc += 13 }
lbb_18977:
    lsh64 r5, 1                                     r5 <<= 1   ///  r5 = r5.wrapping_shl(1)
    lddw r1, 0x100025a14 --> b"00010203040506070809101112131415161718192021222324"        r1 load str located at 4295121428
    add64 r1, r5                                    r1 += r5   ///  r1 = r1.wrapping_add(r5)
    add64 r4, -2                                    r4 += -2   ///  r4 = r4.wrapping_add(-2 as i32 as i64 as u64)
    mov64 r5, r10                                   r5 = r10
    add64 r5, -20                                   r5 += -20   ///  r5 = r5.wrapping_add(-20 as i32 as i64 as u64)
    add64 r5, r4                                    r5 += r4   ///  r5 = r5.wrapping_add(r4)
    ldxh r1, [r1+0x0]                       
    stxh [r5+0x0], r1                       
    ja lbb_18996                                    if true { pc += 8 }
lbb_18988:
    mov64 r5, r1                                    r5 = r1
    jge r5, 10, lbb_18977                           if r5 >= (10 as i32 as i64 as u64) { pc += -13 }
lbb_18990:
    add64 r4, -1                                    r4 += -1   ///  r4 = r4.wrapping_add(-1 as i32 as i64 as u64)
    mov64 r1, r10                                   r1 = r10
    add64 r1, -20                                   r1 += -20   ///  r1 = r1.wrapping_add(-20 as i32 as i64 as u64)
    add64 r1, r4                                    r1 += r4   ///  r1 = r1.wrapping_add(r4)
    or64 r5, 48                                     r5 |= 48   ///  r5 = r5.or(48)
    stxb [r1+0x0], r5                       
lbb_18996:
    mov64 r1, 20                                    r1 = 20 as i32 as i64 as u64
    sub64 r1, r4                                    r1 -= r4   ///  r1 = r1.wrapping_sub(r4)
    stxdw [r10-0xff8], r1                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -20                                   r1 += -20   ///  r1 = r1.wrapping_add(-20 as i32 as i64 as u64)
    add64 r1, r4                                    r1 += r4   ///  r1 = r1.wrapping_add(r4)
    stxdw [r10-0x1000], r1                  
    mov64 r5, r10                                   r5 = r10
    mov64 r1, r3                                    r1 = r3
    mov64 r3, 1                                     r3 = 1 as i32 as i64 as u64
    mov64 r4, 0                                     r4 = 0 as i32 as i64 as u64
    call function_18514                     
    exit                                    

function_19009:
    stxdw [r10-0x58], r2                    
    stxdw [r10-0x60], r1                    
    lddw r1, 0x100028230 --> b"\x00\x00\x00\x00\xc8Y\x02\x00\x10\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00…        r1 load str located at 4295131696
    stxdw [r10-0x50], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -32                                   r1 += -32   ///  r1 = r1.wrapping_add(-32 as i32 as i64 as u64)
    stxdw [r10-0x40], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -88                                   r1 += -88   ///  r1 = r1.wrapping_add(-88 as i32 as i64 as u64)
    stxdw [r10-0x10], r1                    
    lddw r1, 0x100025058 --> b"\xbf#\x00\x00\x00\x00\x00\x00y\x11\x00\x00\x00\x00\x00\x00\xb7\x02\x00\x0…        r1 load str located at 4295118936
    stxdw [r10-0x8], r1                     
    stxdw [r10-0x18], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -96                                   r1 += -96   ///  r1 = r1.wrapping_add(-96 as i32 as i64 as u64)
    stxdw [r10-0x20], r1                    
    stdw [r10-0x30], 0                      
    stdw [r10-0x48], 2                      
    stdw [r10-0x38], 2                      
    mov64 r1, r10                                   r1 = r10
    add64 r1, -80                                   r1 += -80   ///  r1 = r1.wrapping_add(-80 as i32 as i64 as u64)
    mov64 r2, r3                                    r2 = r3
    call function_18483                     

function_19034:
    mov64 r5, 0                                     r5 = 0 as i32 as i64 as u64
    jge r2, r3, lbb_19038                           if r2 >= r3 { pc += 2 }
    mov64 r7, r2                                    r7 = r2
    ja lbb_19179                                    if true { pc += 141 }
lbb_19038:
    mov64 r4, r3                                    r4 = r3
    rsh64 r4, 1                                     r4 >>= 1   ///  r4 = r4.wrapping_shr(1)
    mov64 r6, r3                                    r6 = r3
    or64 r6, r4                                     r6 |= r4   ///  r6 = r6.or(r4)
    mov64 r4, r6                                    r4 = r6
    rsh64 r4, 2                                     r4 >>= 2   ///  r4 = r4.wrapping_shr(2)
    or64 r6, r4                                     r6 |= r4   ///  r6 = r6.or(r4)
    mov64 r4, r6                                    r4 = r6
    rsh64 r4, 4                                     r4 >>= 4   ///  r4 = r4.wrapping_shr(4)
    or64 r6, r4                                     r6 |= r4   ///  r6 = r6.or(r4)
    mov64 r4, r6                                    r4 = r6
    rsh64 r4, 8                                     r4 >>= 8   ///  r4 = r4.wrapping_shr(8)
    or64 r6, r4                                     r6 |= r4   ///  r6 = r6.or(r4)
    mov64 r4, r6                                    r4 = r6
    rsh64 r4, 16                                    r4 >>= 16   ///  r4 = r4.wrapping_shr(16)
    or64 r6, r4                                     r6 |= r4   ///  r6 = r6.or(r4)
    mov64 r4, r6                                    r4 = r6
    rsh64 r4, 32                                    r4 >>= 32   ///  r4 = r4.wrapping_shr(32)
    or64 r6, r4                                     r6 |= r4   ///  r6 = r6.or(r4)
    xor64 r6, -1                                    r6 ^= -1   ///  r6 = r6.xor(-1)
    lddw r0, 0x5555555555555555                     r0 load str located at 6148914691236517205
    mov64 r4, r6                                    r4 = r6
    rsh64 r4, 1                                     r4 >>= 1   ///  r4 = r4.wrapping_shr(1)
    and64 r4, r0                                    r4 &= r0   ///  r4 = r4.and(r0)
    sub64 r6, r4                                    r6 -= r4   ///  r6 = r6.wrapping_sub(r4)
    lddw r5, 0x3333333333333333                     r5 load str located at 3689348814741910323
    mov64 r4, r6                                    r4 = r6
    and64 r4, r5                                    r4 &= r5   ///  r4 = r4.and(r5)
    rsh64 r6, 2                                     r6 >>= 2   ///  r6 = r6.wrapping_shr(2)
    and64 r6, r5                                    r6 &= r5   ///  r6 = r6.and(r5)
    add64 r4, r6                                    r4 += r6   ///  r4 = r4.wrapping_add(r6)
    mov64 r6, r4                                    r6 = r4
    rsh64 r6, 4                                     r6 >>= 4   ///  r6 = r6.wrapping_shr(4)
    add64 r4, r6                                    r4 += r6   ///  r4 = r4.wrapping_add(r6)
    lddw r6, 0xf0f0f0f0f0f0f0f                      r6 load str located at 1085102592571150095
    and64 r4, r6                                    r4 &= r6   ///  r4 = r4.and(r6)
    lddw r7, 0x101010101010101                      r7 load str located at 72340172838076673
    mul64 r4, r7                                    r4 *= r7   ///  r4 = r4.wrapping_mul(r7)
    rsh64 r4, 56                                    r4 >>= 56   ///  r4 = r4.wrapping_shr(56)
    jeq r2, 0, lbb_19118                            if r2 == (0 as i32 as i64 as u64) { pc += 36 }
    mov64 r9, r2                                    r9 = r2
    rsh64 r9, 1                                     r9 >>= 1   ///  r9 = r9.wrapping_shr(1)
    mov64 r8, r2                                    r8 = r2
    or64 r8, r9                                     r8 |= r9   ///  r8 = r8.or(r9)
    mov64 r9, r8                                    r9 = r8
    rsh64 r9, 2                                     r9 >>= 2   ///  r9 = r9.wrapping_shr(2)
    or64 r8, r9                                     r8 |= r9   ///  r8 = r8.or(r9)
    mov64 r9, r8                                    r9 = r8
    rsh64 r9, 4                                     r9 >>= 4   ///  r9 = r9.wrapping_shr(4)
    or64 r8, r9                                     r8 |= r9   ///  r8 = r8.or(r9)
    mov64 r9, r8                                    r9 = r8
    rsh64 r9, 8                                     r9 >>= 8   ///  r9 = r9.wrapping_shr(8)
    or64 r8, r9                                     r8 |= r9   ///  r8 = r8.or(r9)
    mov64 r9, r8                                    r9 = r8
    rsh64 r9, 16                                    r9 >>= 16   ///  r9 = r9.wrapping_shr(16)
    or64 r8, r9                                     r8 |= r9   ///  r8 = r8.or(r9)
    mov64 r9, r8                                    r9 = r8
    rsh64 r9, 32                                    r9 >>= 32   ///  r9 = r9.wrapping_shr(32)
    or64 r8, r9                                     r8 |= r9   ///  r8 = r8.or(r9)
    xor64 r8, -1                                    r8 ^= -1   ///  r8 = r8.xor(-1)
    mov64 r9, r8                                    r9 = r8
    rsh64 r9, 1                                     r9 >>= 1   ///  r9 = r9.wrapping_shr(1)
    and64 r9, r0                                    r9 &= r0   ///  r9 = r9.and(r0)
    sub64 r8, r9                                    r8 -= r9   ///  r8 = r8.wrapping_sub(r9)
    mov64 r0, r8                                    r0 = r8
    and64 r0, r5                                    r0 &= r5   ///  r0 = r0.and(r5)
    rsh64 r8, 2                                     r8 >>= 2   ///  r8 = r8.wrapping_shr(2)
    and64 r8, r5                                    r8 &= r5   ///  r8 = r8.and(r5)
    add64 r0, r8                                    r0 += r8   ///  r0 = r0.wrapping_add(r8)
    mov64 r5, r0                                    r5 = r0
    rsh64 r5, 4                                     r5 >>= 4   ///  r5 = r5.wrapping_shr(4)
    add64 r0, r5                                    r0 += r5   ///  r0 = r0.wrapping_add(r5)
    and64 r0, r6                                    r0 &= r6   ///  r0 = r0.and(r6)
    mul64 r0, r7                                    r0 *= r7   ///  r0 = r0.wrapping_mul(r7)
    rsh64 r0, 56                                    r0 >>= 56   ///  r0 = r0.wrapping_shr(56)
    ja lbb_19119                                    if true { pc += 1 }
lbb_19118:
    mov64 r0, 64                                    r0 = 64 as i32 as i64 as u64
lbb_19119:
    sub64 r4, r0                                    r4 -= r0   ///  r4 = r4.wrapping_sub(r0)
    mov64 r5, r4                                    r5 = r4
    and64 r5, 63                                    r5 &= 63   ///  r5 = r5.and(63)
    mov64 r0, r3                                    r0 = r3
    lsh64 r0, r5                                    r0 <<= r5   ///  r0 = r0.wrapping_shl(r5 as u32)
    mov64 r8, 1                                     r8 = 1 as i32 as i64 as u64
    mov64 r5, 1                                     r5 = 1 as i32 as i64 as u64
    jgt r0, r2, lbb_19128                           if r0 > r2 { pc += 1 }
    mov64 r5, 0                                     r5 = 0 as i32 as i64 as u64
lbb_19128:
    lsh64 r4, 32                                    r4 <<= 32   ///  r4 = r4.wrapping_shl(32)
    rsh64 r4, 32                                    r4 >>= 32   ///  r4 = r4.wrapping_shr(32)
    sub64 r4, r5                                    r4 -= r5   ///  r4 = r4.wrapping_sub(r5)
    mov64 r5, r4                                    r5 = r4
    and64 r5, 63                                    r5 &= 63   ///  r5 = r5.and(63)
    lsh64 r8, r5                                    r8 <<= r5   ///  r8 = r8.wrapping_shl(r5 as u32)
    mov64 r0, r3                                    r0 = r3
    lsh64 r0, r5                                    r0 <<= r5   ///  r0 = r0.wrapping_shl(r5 as u32)
    sub64 r2, r0                                    r2 -= r0   ///  r2 = r2.wrapping_sub(r0)
    jge r2, r3, lbb_19141                           if r2 >= r3 { pc += 3 }
    mov64 r7, r2                                    r7 = r2
    mov64 r5, r8                                    r5 = r8
    ja lbb_19179                                    if true { pc += 38 }
lbb_19141:
    jsle r0, -1, lbb_19146                          if (r0 as i64) <= (-1 as i32 as i64) { pc += 4 }
    mov64 r6, r8                                    r6 = r8
    mov64 r5, r8                                    r5 = r8
    mov64 r7, r2                                    r7 = r2
    ja lbb_19161                                    if true { pc += 15 }
lbb_19146:
    add64 r4, -1                                    r4 += -1   ///  r4 = r4.wrapping_add(-1 as i32 as i64 as u64)
    mov64 r5, r4                                    r5 = r4
    and64 r5, 63                                    r5 &= 63   ///  r5 = r5.and(63)
    mov64 r6, 1                                     r6 = 1 as i32 as i64 as u64
    lsh64 r6, r5                                    r6 <<= r5   ///  r6 = r6.wrapping_shl(r5 as u32)
    rsh64 r0, 1                                     r0 >>= 1   ///  r0 = r0.wrapping_shr(1)
    mov64 r7, r2                                    r7 = r2
    sub64 r7, r0                                    r7 -= r0   ///  r7 = r7.wrapping_sub(r0)
    mov64 r5, r6                                    r5 = r6
    jsgt r7, -1, lbb_19157                          if (r7 as i64) > (-1 as i32 as i64) { pc += 1 }
    mov64 r5, 0                                     r5 = 0 as i32 as i64 as u64
lbb_19157:
    jsgt r7, -1, lbb_19159                          if (r7 as i64) > (-1 as i32 as i64) { pc += 1 }
    mov64 r7, r2                                    r7 = r2
lbb_19159:
    or64 r5, r8                                     r5 |= r8   ///  r5 = r5.or(r8)
    jlt r7, r3, lbb_19179                           if r7 < r3 { pc += 18 }
lbb_19161:
    add64 r6, -1                                    r6 += -1   ///  r6 = r6.wrapping_add(-1 as i32 as i64 as u64)
    mov64 r2, r7                                    r2 = r7
    jeq r4, 0, lbb_19173                            if r4 == (0 as i32 as i64 as u64) { pc += 9 }
    mov64 r3, r4                                    r3 = r4
lbb_19165:
    lsh64 r2, 1                                     r2 <<= 1   ///  r2 = r2.wrapping_shl(1)
    mov64 r7, r2                                    r7 = r2
    sub64 r7, r0                                    r7 -= r0   ///  r7 = r7.wrapping_sub(r0)
    add64 r7, 1                                     r7 += 1   ///  r7 = r7.wrapping_add(1 as i32 as i64 as u64)
    jslt r7, 0, lbb_19171                           if (r7 as i64) < (0 as i32 as i64) { pc += 1 }
    mov64 r2, r7                                    r2 = r7
lbb_19171:
    add64 r3, -1                                    r3 += -1   ///  r3 = r3.wrapping_add(-1 as i32 as i64 as u64)
    jne r3, 0, lbb_19165                            if r3 != (0 as i32 as i64 as u64) { pc += -8 }
lbb_19173:
    and64 r4, 63                                    r4 &= 63   ///  r4 = r4.and(63)
    mov64 r7, r2                                    r7 = r2
    rsh64 r7, r4                                    r7 >>= r4   ///  r7 = r7.wrapping_shr(r4 as u32)
    and64 r2, r6                                    r2 &= r6   ///  r2 = r2.and(r6)
    or64 r2, r5                                     r2 |= r5   ///  r2 = r2.or(r5)
    mov64 r5, r2                                    r5 = r2
lbb_19179:
    stxdw [r1+0x8], r7                      
    stxdw [r1+0x0], r5                      
    exit                                    

function_19182:
    mov64 r6, r2                                    r6 = r2
    mov64 r7, r1                                    r7 = r1
    arsh64 r1, 63                                   r1 >>= 63 (signed)   ///  r1 = (r1 as i64).wrapping_shr(63)
    mov64 r2, r7                                    r2 = r7
    xor64 r2, r1                                    r2 ^= r1   ///  r2 = r2.xor(r1)
    sub64 r2, r1                                    r2 -= r1   ///  r2 = r2.wrapping_sub(r1)
    mov64 r1, r6                                    r1 = r6
    arsh64 r1, 63                                   r1 >>= 63 (signed)   ///  r1 = (r1 as i64).wrapping_shr(63)
    mov64 r3, r6                                    r3 = r6
    xor64 r3, r1                                    r3 ^= r1   ///  r3 = r3.xor(r1)
    sub64 r3, r1                                    r3 -= r1   ///  r3 = r3.wrapping_sub(r1)
    mov64 r1, r10                                   r1 = r10
    add64 r1, -16                                   r1 += -16   ///  r1 = r1.wrapping_add(-16 as i32 as i64 as u64)
    call function_19034                     
    xor64 r6, r7                                    r6 ^= r7   ///  r6 = r6.xor(r7)
    ldxdw r1, [r10-0x10]                    
    mov64 r0, r1                                    r0 = r1
    neg64 r0                                        r0 = -r0   ///  r0 = (r0 as i64).wrapping_neg() as u64
    jslt r6, 0, lbb_19202                           if (r6 as i64) < (0 as i32 as i64) { pc += 1 }
    mov64 r0, r1                                    r0 = r1
lbb_19202:
    exit                                    
