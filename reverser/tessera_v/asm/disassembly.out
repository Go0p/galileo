function_0:
    mov64 r6, r1                                    r6 = r1
    mov64 r1, 165                                   r1 = 165 as i32 as i64 as u64
    jgt r1, r3, lbb_4                               if r1 > r3 { pc += 1 }
    jne r3, 355, lbb_10                             if r3 != (355 as i32 as i64 as u64) { pc += 6 }
lbb_4:
    mov64 r1, 2                                     r1 = 2 as i32 as i64 as u64
    stxw [r6+0x98], r1                      
lbb_6:
    lddw r1, 0x8000000000000003                     r1 load str located at -9223372036854775805
    stxdw [r6+0x0], r1                      
    ja lbb_65                                       if true { pc += 55 }
lbb_10:
    stxdw [r10-0x348], r3                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -176                                  r1 += -176   ///  r1 = r1.wrapping_add(-176 as i32 as i64 as u64)
    stxdw [r10-0x350], r2                   
    mov64 r3, 165                                   r3 = 165 as i32 as i64 as u64
    call function_16326                     
    mov64 r2, r10                                   r2 = r10
    add64 r2, -168                                  r2 += -168   ///  r2 = r2.wrapping_add(-168 as i32 as i64 as u64)
    ldxdw r8, [r10-0xb0]                    
    ldxw r1, [r10-0x28]                     
    jeq r1, 2, lbb_52                               if r1 == (2 as i32 as i64 as u64) { pc += 31 }
    stxdw [r10-0x360], r1                   
    mov64 r7, r10                                   r7 = r10
    add64 r7, -280                                  r7 += -280   ///  r7 = r7.wrapping_add(-280 as i32 as i64 as u64)
    mov64 r1, r7                                    r1 = r7
    mov64 r3, 100                                   r3 = 100 as i32 as i64 as u64
    call function_30349                     
    ldxdw r1, [r10-0x43]                    
    stxdw [r10-0x1a0], r1                   
    ldxdw r1, [r10-0x3b]                    
    stxdw [r10-0x198], r1                   
    ldxdw r1, [r10-0x33]                    
    stxdw [r10-0x190], r1                   
    ldxw r1, [r10-0x2c]                     
    stxw [r10-0x189], r1                    
    ldxb r9, [r10-0x44]                     
    mov64 r1, r10                                   r1 = r10
    add64 r1, -452                                  r1 += -452   ///  r1 = r1.wrapping_add(-452 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -36                                   r2 += -36   ///  r2 = r2.wrapping_add(-36 as i32 as i64 as u64)
    mov64 r3, 36                                    r3 = 36 as i32 as i64 as u64
    call function_30349                     
    mov64 r1, r10                                   r1 = r10
    add64 r1, -384                                  r1 += -384   ///  r1 = r1.wrapping_add(-384 as i32 as i64 as u64)
    mov64 r2, r7                                    r2 = r7
    mov64 r3, 100                                   r3 = 100 as i32 as i64 as u64
    call function_30349                     
    stxdw [r10-0x358], r9                   
    jne r9, 0, lbb_66                               if r9 != (0 as i32 as i64 as u64) { pc += 17 }
    lddw r8, 0x8000000000000009                     r8 load str located at -9223372036854775799
    ja lbb_56                                       if true { pc += 4 }
lbb_52:
    ldxdw r1, [r2+0x8]                      
    ldxdw r2, [r2+0x0]                      
    stxdw [r10-0x228], r2                   
    stxdw [r10-0x220], r1                   
lbb_56:
    ldxdw r1, [r10-0x220]                   
    stxdw [r10-0x288], r1                   
    ldxdw r2, [r10-0x228]                   
    stxdw [r10-0x290], r2                   
    stxdw [r6+0x10], r1                     
    stxdw [r6+0x8], r2                      
    mov64 r1, 2                                     r1 = 2 as i32 as i64 as u64
    stxw [r6+0x98], r1                      
    stxdw [r6+0x0], r8                      
lbb_65:
    exit                                    
lbb_66:
    stxdw [r10-0x368], r8                   
    mov64 r7, r10                                   r7 = r10
    add64 r7, -552                                  r7 += -552   ///  r7 = r7.wrapping_add(-552 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -384                                  r2 += -384   ///  r2 = r2.wrapping_add(-384 as i32 as i64 as u64)
    mov64 r1, r7                                    r1 = r7
    mov64 r3, 100                                   r3 = 100 as i32 as i64 as u64
    call function_30349                     
    ldxdw r1, [r10-0x1a0]                   
    stxdw [r10-0x318], r1                   
    ldxdw r1, [r10-0x198]                   
    stxdw [r10-0x310], r1                   
    ldxdw r1, [r10-0x190]                   
    stxdw [r10-0x308], r1                   
    ldxw r1, [r10-0x189]                    
    stxw [r10-0x301], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -828                                  r1 += -828   ///  r1 = r1.wrapping_add(-828 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -452                                  r2 += -452   ///  r2 = r2.wrapping_add(-452 as i32 as i64 as u64)
    mov64 r3, 36                                    r3 = 36 as i32 as i64 as u64
    call function_30349                     
    mov64 r8, r10                                   r8 = r10
    add64 r8, -656                                  r8 += -656   ///  r8 = r8.wrapping_add(-656 as i32 as i64 as u64)
    mov64 r1, r8                                    r1 = r8
    mov64 r2, r7                                    r2 = r7
    mov64 r3, 100                                   r3 = 100 as i32 as i64 as u64
    call function_30349                     
    mov64 r1, r10                                   r1 = r10
    add64 r1, -760                                  r1 += -760   ///  r1 = r1.wrapping_add(-760 as i32 as i64 as u64)
    mov64 r2, r8                                    r2 = r8
    mov64 r3, 100                                   r3 = 100 as i32 as i64 as u64
    call function_30349                     
    mov64 r8, 0                                     r8 = 0 as i32 as i64 as u64
    mov64 r7, 1                                     r7 = 1 as i32 as i64 as u64
    ldxdw r1, [r10-0x348]                   
    jeq r1, 165, lbb_110                            if r1 == (165 as i32 as i64 as u64) { pc += 7 }
    ldxdw r7, [r10-0x350]                   
    jeq r1, 166, lbb_139                            if r1 == (166 as i32 as i64 as u64) { pc += 34 }
    ldxb r2, [r7+0xa5]                      
    jne r2, 2, lbb_139                              if r2 != (2 as i32 as i64 as u64) { pc += 32 }
    add64 r7, 166                                   r7 += 166   ///  r7 = r7.wrapping_add(166 as i32 as i64 as u64)
    add64 r1, -166                                  r1 += -166   ///  r1 = r1.wrapping_add(-166 as i32 as i64 as u64)
    mov64 r8, r1                                    r8 = r1
lbb_110:
    mov64 r1, r6                                    r1 = r6
    add64 r1, 24                                    r1 += 24   ///  r1 = r1.wrapping_add(24 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -760                                  r2 += -760   ///  r2 = r2.wrapping_add(-760 as i32 as i64 as u64)
    mov64 r3, 100                                   r3 = 100 as i32 as i64 as u64
    call function_30349                     
    ldxdw r1, [r10-0x318]                   
    stxdw [r6+0x7d], r1                     
    ldxdw r1, [r10-0x310]                   
    stxdw [r6+0x85], r1                     
    ldxdw r1, [r10-0x308]                   
    stxdw [r6+0x8d], r1                     
    ldxw r1, [r10-0x301]                    
    stxw [r6+0x94], r1                      
    mov64 r1, r6                                    r1 = r6
    add64 r1, 156                                   r1 += 156   ///  r1 = r1.wrapping_add(156 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -828                                  r2 += -828   ///  r2 = r2.wrapping_add(-828 as i32 as i64 as u64)
    mov64 r3, 36                                    r3 = 36 as i32 as i64 as u64
    call function_30349                     
    ldxdw r1, [r10-0x360]                   
    stxw [r6+0x98], r1                      
    ldxdw r1, [r10-0x358]                   
    stxb [r6+0x7c], r1                      
    ldxdw r1, [r10-0x368]                   
    stxdw [r6+0x10], r1                     
    stxdw [r6+0x8], r8                      
    stxdw [r6+0x0], r7                      
    ja lbb_65                                       if true { pc += -74 }
lbb_139:
    mov64 r1, 2                                     r1 = 2 as i32 as i64 as u64
    stxw [r6+0x98], r1                      
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    stxdw [r6+0x10], r1                     
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    stxdw [r6+0x8], r1                      
    ja lbb_6                                        if true { pc += -140 }

function_146:
    mov64 r7, r3                                    r7 = r3
    mov64 r6, r1                                    r6 = r1
    mov64 r1, 82                                    r1 = 82 as i32 as i64 as u64
    jgt r1, r7, lbb_151                             if r1 > r7 { pc += 1 }
    jne r7, 355, lbb_157                            if r7 != (355 as i32 as i64 as u64) { pc += 6 }
lbb_151:
    mov64 r1, 2                                     r1 = 2 as i32 as i64 as u64
    stxw [r6+0x0], r1                       
    lddw r1, 0x8000000000000003                     r1 load str located at -9223372036854775805
    stxdw [r6+0x8], r1                      
    ja lbb_322                                      if true { pc += 165 }
lbb_157:
    mov64 r1, r10                                   r1 = r10
    add64 r1, -88                                   r1 += -88   ///  r1 = r1.wrapping_add(-88 as i32 as i64 as u64)
    stxdw [r10-0x140], r2                   
    mov64 r3, 82                                    r3 = 82 as i32 as i64 as u64
    call function_16236                     
    ldxw r1, [r10-0x58]                     
    jeq r1, 2, lbb_194                              if r1 == (2 as i32 as i64 as u64) { pc += 30 }
    stxdw [r10-0x158], r1                   
    ldxdw r1, [r10-0x48]                    
    stxdw [r10-0x68], r1                    
    ldxdw r1, [r10-0x40]                    
    stxdw [r10-0x60], r1                    
    ldxdw r1, [r10-0x38]                    
    stxdw [r10-0x90], r1                    
    ldxdw r1, [r10-0x30]                    
    stxdw [r10-0x88], r1                    
    ldxb r1, [r10-0x28]                     
    stxb [r10-0x80], r1                     
    ldxdw r1, [r10-0x50]                    
    stxdw [r10-0x148], r1                   
    ldxw r8, [r10-0x54]                     
    ldxb r9, [r10-0x27]                     
    mov64 r1, r10                                   r1 = r10
    add64 r1, -182                                  r1 += -182   ///  r1 = r1.wrapping_add(-182 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -38                                   r2 += -38   ///  r2 = r2.wrapping_add(-38 as i32 as i64 as u64)
    mov64 r3, 38                                    r3 = 38 as i32 as i64 as u64
    call function_30349                     
    ldxdw r1, [r10-0x68]                    
    stxdw [r10-0x78], r1                    
    ldxdw r1, [r10-0x60]                    
    stxdw [r10-0x70], r1                    
    stxdw [r10-0x150], r9                   
    jne r9, 0, lbb_206                              if r9 != (0 as i32 as i64 as u64) { pc += 15 }
    lddw r1, 0x8000000000000009                     r1 load str located at -9223372036854775799
    ja lbb_199                                      if true { pc += 5 }
lbb_194:
    ldxdw r1, [r10-0x48]                    
    stxdw [r10-0xd8], r1                    
    ldxdw r1, [r10-0x40]                    
    stxdw [r10-0xd0], r1                    
    ldxdw r1, [r10-0x50]                    
lbb_199:
    ldxdw r2, [r10-0xd0]                    
    stxdw [r10-0xe0], r2                    
    ldxdw r3, [r10-0xd8]                    
    stxdw [r10-0xe8], r3                    
    stxdw [r6+0x18], r2                     
    stxdw [r6+0x10], r3                     
    ja lbb_319                                      if true { pc += 113 }
lbb_206:
    stxdw [r10-0x160], r8                   
    mov64 r8, r7                                    r8 = r7
    add64 r8, -82                                   r8 += -82   ///  r8 = r8.wrapping_add(-82 as i32 as i64 as u64)
    ldxdw r1, [r10-0x70]                    
    stxdw [r10-0xd0], r1                    
    ldxdw r1, [r10-0x78]                    
    stxdw [r10-0xd8], r1                    
    ldxdw r1, [r10-0x90]                    
    stxdw [r10-0xc8], r1                    
    ldxdw r1, [r10-0x88]                    
    stxdw [r10-0xc0], r1                    
    ldxb r1, [r10-0x80]                     
    stxb [r10-0xb8], r1                     
    mov64 r1, r10                                   r1 = r10
    add64 r1, -310                                  r1 += -310   ///  r1 = r1.wrapping_add(-310 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -182                                  r2 += -182   ///  r2 = r2.wrapping_add(-182 as i32 as i64 as u64)
    mov64 r3, 38                                    r3 = 38 as i32 as i64 as u64
    call function_30349                     
    ldxdw r1, [r10-0xc8]                    
    stxdw [r10-0x110], r1                   
    ldxdw r1, [r10-0xc0]                    
    stxdw [r10-0x108], r1                   
    ldxb r1, [r10-0xb8]                     
    stxb [r10-0x100], r1                    
    ldxdw r1, [r10-0xd8]                    
    stxdw [r10-0xe8], r1                    
    stxdw [r10-0xf8], r1                    
    ldxdw r1, [r10-0xd0]                    
    stxdw [r10-0xf0], r1                    
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    mov64 r9, 1                                     r9 = 1 as i32 as i64 as u64
    jeq r8, 0, lbb_286                              if r8 == (0 as i32 as i64 as u64) { pc += 47 }
    mov64 r1, 85                                    r1 = 85 as i32 as i64 as u64
    jgt r1, r8, lbb_313                             if r1 > r8 { pc += 72 }
    lddw r1, 0x300000000                            r1 load str located at 12884901888
    ldxdw r1, [r1+0x0]                      
    mov64 r4, r1                                    r4 = r1
    add64 r4, -83                                   r4 += -83   ///  r4 = r4.wrapping_add(-83 as i32 as i64 as u64)
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
    mov64 r5, 1                                     r5 = 1 as i32 as i64 as u64
    jgt r4, r1, lbb_250                             if r4 > r1 { pc += 1 }
    mov64 r5, 0                                     r5 = 0 as i32 as i64 as u64
lbb_250:
    ldxdw r9, [r10-0x140]                   
    jne r5, 0, lbb_253                              if r5 != (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r2, r4                                    r2 = r4
lbb_253:
    lddw r8, 0x300007fad                            r8 load str located at 12884934573
    jeq r1, 0, lbb_257                              if r1 == (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r8, r2                                    r8 = r2
lbb_257:
    lddw r1, 0x300000007                            r1 load str located at 12884901895
    jgt r8, r1, lbb_263                             if r8 > r1 { pc += 3 }
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    mov64 r2, 83                                    r2 = 83 as i32 as i64 as u64
    call function_21549                     
lbb_263:
    add64 r9, 82                                    r9 += 82   ///  r9 = r9.wrapping_add(82 as i32 as i64 as u64)
    lddw r1, 0x300000000                            r1 load str located at 12884901888
    stxdw [r1+0x0], r8                      
    mov64 r1, r8                                    r1 = r8
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
    mov64 r3, 83                                    r3 = 83 as i32 as i64 as u64
    call function_30383                     
    mov64 r1, r9                                    r1 = r9
    mov64 r2, r8                                    r2 = r8
    mov64 r3, 83                                    r3 = 83 as i32 as i64 as u64
    call function_30418                     
    lsh64 r0, 32                                    r0 <<= 32   ///  r0 = r0.wrapping_shl(32)
    rsh64 r0, 32                                    r0 >>= 32   ///  r0 = r0.wrapping_shr(32)
    jne r0, 0, lbb_313                              if r0 != (0 as i32 as i64 as u64) { pc += 35 }
    ldxdw r1, [r10-0x140]                   
    ldxb r1, [r1+0xa5]                      
    jne r1, 1, lbb_313                              if r1 != (1 as i32 as i64 as u64) { pc += 32 }
    ldxdw r1, [r10-0x140]                   
    add64 r1, 166                                   r1 += 166   ///  r1 = r1.wrapping_add(166 as i32 as i64 as u64)
    add64 r7, -166                                  r7 += -166   ///  r7 = r7.wrapping_add(-166 as i32 as i64 as u64)
    mov64 r9, r1                                    r9 = r1
    mov64 r1, r7                                    r1 = r7
lbb_286:
    mov64 r7, r1                                    r7 = r1
    ldxdw r1, [r10-0xf0]                    
    stxdw [r6+0x18], r1                     
    ldxdw r1, [r10-0xf8]                    
    stxdw [r6+0x10], r1                     
    ldxdw r1, [r10-0x110]                   
    stxdw [r6+0x20], r1                     
    ldxdw r1, [r10-0x108]                   
    stxdw [r6+0x28], r1                     
    ldxb r1, [r10-0x100]                    
    stxb [r6+0x30], r1                      
    mov64 r1, r6                                    r1 = r6
    add64 r1, 50                                    r1 += 50   ///  r1 = r1.wrapping_add(50 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -310                                  r2 += -310   ///  r2 = r2.wrapping_add(-310 as i32 as i64 as u64)
    mov64 r3, 38                                    r3 = 38 as i32 as i64 as u64
    call function_30349                     
    stxdw [r6+0x60], r7                     
    stxdw [r6+0x58], r9                     
    ldxdw r1, [r10-0x150]                   
    stxb [r6+0x31], r1                      
    ldxdw r1, [r10-0x148]                   
    stxdw [r6+0x8], r1                      
    ldxdw r1, [r10-0x160]                   
    stxw [r6+0x4], r1                       
    ldxdw r1, [r10-0x158]                   
    ja lbb_321                                      if true { pc += 8 }
lbb_313:
    mov64 r1, 84                                    r1 = 84 as i32 as i64 as u64
    stxdw [r6+0x18], r1                     
    mov64 r1, 83                                    r1 = 83 as i32 as i64 as u64
    stxdw [r6+0x10], r1                     
    lddw r1, 0x8000000000000003                     r1 load str located at -9223372036854775805
lbb_319:
    stxdw [r6+0x8], r1                      
    mov64 r1, 2                                     r1 = 2 as i32 as i64 as u64
lbb_321:
    stxw [r6+0x0], r1                       
lbb_322:
    exit                                    

function_323:
    lddw r2, 0x300000000                            r2 load str located at 12884901888
    ldxdw r3, [r2+0x0]                      
    mov64 r2, r3                                    r2 = r3
    add64 r2, -24                                   r2 += -24   ///  r2 = r2.wrapping_add(-24 as i32 as i64 as u64)
    mov64 r4, 0                                     r4 = 0 as i32 as i64 as u64
    mov64 r5, 1                                     r5 = 1 as i32 as i64 as u64
    jgt r2, r3, lbb_332                             if r2 > r3 { pc += 1 }
    mov64 r5, 0                                     r5 = 0 as i32 as i64 as u64
lbb_332:
    jne r5, 0, lbb_334                              if r5 != (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r4, r2                                    r4 = r2
lbb_334:
    lddw r2, 0x300007fe8                            r2 load str located at 12884934632
    jeq r3, 0, lbb_339                              if r3 == (0 as i32 as i64 as u64) { pc += 2 }
    and64 r4, -8                                    r4 &= -8   ///  r4 = r4.and(-8)
    mov64 r2, r4                                    r2 = r4
lbb_339:
    lddw r3, 0x300000007                            r3 load str located at 12884901895
    jgt r2, r3, lbb_345                             if r2 > r3 { pc += 3 }
    mov64 r1, 8                                     r1 = 8 as i32 as i64 as u64
    mov64 r2, 24                                    r2 = 24 as i32 as i64 as u64
    call function_21552                     
lbb_345:
    lddw r3, 0x300000000                            r3 load str located at 12884901888
    stxdw [r3+0x0], r2                      
    ldxdw r3, [r1+0x10]                     
    stxdw [r2+0x10], r3                     
    ldxdw r3, [r1+0x8]                      
    stxdw [r2+0x8], r3                      
    ldxdw r1, [r1+0x0]                      
    stxdw [r2+0x0], r1                      
    mov64 r1, 21                                    r1 = 21 as i32 as i64 as u64
    lddw r3, 0x100040cb8 --> b"\x00\x00\x00\x00\xc0\x0f\x00\x00\x18\x00\x00\x00\x00\x00\x00\x00\x08\x00\…        r3 load str located at 4295232696
    call function_20895                     
    exit                                    

function_359:
    lddw r1, 0x300000000                            r1 load str located at 12884901888
    ldxdw r2, [r1+0x0]                      
    mov64 r1, r2                                    r1 = r2
    add64 r1, -18                                   r1 += -18   ///  r1 = r1.wrapping_add(-18 as i32 as i64 as u64)
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
    mov64 r4, 1                                     r4 = 1 as i32 as i64 as u64
    jgt r1, r2, lbb_368                             if r1 > r2 { pc += 1 }
    mov64 r4, 0                                     r4 = 0 as i32 as i64 as u64
lbb_368:
    jne r4, 0, lbb_370                              if r4 != (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r3, r1                                    r3 = r1
lbb_370:
    lddw r1, 0x300007fee                            r1 load str located at 12884934638
    jeq r2, 0, lbb_374                              if r2 == (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r1, r3                                    r1 = r3
lbb_374:
    lddw r2, 0x300000007                            r2 load str located at 12884901895
    jgt r1, r2, lbb_380                             if r1 > r2 { pc += 3 }
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    mov64 r2, 18                                    r2 = 18 as i32 as i64 as u64
    call function_21549                     
lbb_380:
    lddw r2, 0x300000000                            r2 load str located at 12884901888
    stxdw [r2+0x0], r1                      
    mov64 r3, 25697                                 r3 = 25697 as i32 as i64 as u64
    stxh [r1+0x10], r3                      
    lddw r3, 0x6572207365747962                     r3 load str located at 7309940825171196258
    stxdw [r1+0x8], r3                      
    lddw r3, 0x206c6c6120746f4e                     r3 load str located at 2336361471110573902
    stxdw [r1+0x0], r3                      
    ldxdw r3, [r2+0x0]                      
    mov64 r2, r3                                    r2 = r3
    add64 r2, -24                                   r2 += -24   ///  r2 = r2.wrapping_add(-24 as i32 as i64 as u64)
    mov64 r4, 0                                     r4 = 0 as i32 as i64 as u64
    mov64 r5, 1                                     r5 = 1 as i32 as i64 as u64
    jgt r2, r3, lbb_398                             if r2 > r3 { pc += 1 }
    mov64 r5, 0                                     r5 = 0 as i32 as i64 as u64
lbb_398:
    jne r5, 0, lbb_400                              if r5 != (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r4, r2                                    r4 = r2
lbb_400:
    lddw r2, 0x300007fe8                            r2 load str located at 12884934632
    jeq r3, 0, lbb_405                              if r3 == (0 as i32 as i64 as u64) { pc += 2 }
    and64 r4, -8                                    r4 &= -8   ///  r4 = r4.and(-8)
    mov64 r2, r4                                    r2 = r4
lbb_405:
    lddw r3, 0x300000007                            r3 load str located at 12884901895
    jgt r2, r3, lbb_411                             if r2 > r3 { pc += 3 }
    mov64 r1, 8                                     r1 = 8 as i32 as i64 as u64
    mov64 r2, 24                                    r2 = 24 as i32 as i64 as u64
    call function_21552                     
lbb_411:
    lddw r3, 0x300000000                            r3 load str located at 12884901888
    stxdw [r3+0x0], r2                      
    stxdw [r2+0x8], r1                      
    mov64 r1, 18                                    r1 = 18 as i32 as i64 as u64
    stxdw [r2+0x10], r1                     
    stxdw [r2+0x0], r1                      
    mov64 r1, 21                                    r1 = 21 as i32 as i64 as u64
    lddw r3, 0x100040cb8 --> b"\x00\x00\x00\x00\xc0\x0f\x00\x00\x18\x00\x00\x00\x00\x00\x00\x00\x08\x00\…        r3 load str located at 4295232696
    call function_20895                     
    exit                                    

function_423:
    mov64 r1, r2                                    r1 = r2
    lddw r2, 0x10003e460 --> b"an array of length 32"        r2 load str located at 4295222368
    mov64 r3, 21                                    r3 = 21 as i32 as i64 as u64
    call function_27691                     
    exit                                    

function_429:
    mov64 r1, r2                                    r1 = r2
    lddw r2, 0x10003e5d0 --> b"()"                  r2 load str located at 4295222736
    mov64 r3, 2                                     r3 = 2 as i32 as i64 as u64
    call function_27252                     
    exit                                    

function_435:
    ldxdw r1, [r1+0x0]                      
    call function_25700                     
    exit                                    

function_438:
    mov64 r3, r2                                    r3 = r2
    ldxdw r2, [r1+0x8]                      
    ldxdw r1, [r1+0x0]                      
    call function_20107                     
    exit                                    

function_443:
    ldxw r3, [r2+0x34]                      
    mov64 r4, r3                                    r4 = r3
    and64 r4, 16                                    r4 &= 16   ///  r4 = r4.and(16)
    jne r4, 0, lbb_452                              if r4 != (0 as i32 as i64 as u64) { pc += 5 }
    and64 r3, 32                                    r3 &= 32   ///  r3 = r3.and(32)
    jeq r3, 0, lbb_450                              if r3 == (0 as i32 as i64 as u64) { pc += 1 }
    ja lbb_454                                      if true { pc += 4 }
lbb_450:
    call function_30197                     
    ja lbb_455                                      if true { pc += 3 }
lbb_452:
    call function_29661                     
    ja lbb_455                                      if true { pc += 1 }
lbb_454:
    call function_29708                     
lbb_455:
    exit                                    

function_456:
    mov64 r3, r2                                    r3 = r2
    lddw r2, 0x100040db0 --> b"\x00\x00\x00\x00\xd8\x0f\x00\x00\x18\x00\x00\x00\x00\x00\x00\x00\x08\x00\…        r2 load str located at 4295232944
    call function_26898                     
    exit                                    

function_461:
    ldxdw r3, [r1+0x0]                      
    lddw r2, 0x800000000000001a                     r2 load str located at -9223372036854775782
    jeq r3, r2, lbb_465                             if r3 == r2 { pc += 0 }
lbb_465:
    ldxdw r1, [r1+0x18]                     
    jeq r1, r2, lbb_467                             if r1 == r2 { pc += 0 }
lbb_467:
    exit                                    

function_468:
    exit                                    

function_469:
    exit                                    

function_470:
    exit                                    

function_471:
    exit                                    

function_472:
    ldxdw r2, [r1+0x10]                     
    ldxdw r3, [r1+0x8]                      
    ldxdw r4, [r3+0x0]                      
    add64 r4, -1                                    r4 += -1   ///  r4 = r4.wrapping_add(-1 as i32 as i64 as u64)
    stxdw [r3+0x0], r4                      
    jne r4, 0, lbb_481                              if r4 != (0 as i32 as i64 as u64) { pc += 3 }
    ldxdw r4, [r3+0x8]                      
    add64 r4, -1                                    r4 += -1   ///  r4 = r4.wrapping_add(-1 as i32 as i64 as u64)
    stxdw [r3+0x8], r4                      
lbb_481:
    ldxdw r3, [r2+0x0]                      
    add64 r3, -1                                    r3 += -1   ///  r3 = r3.wrapping_add(-1 as i32 as i64 as u64)
    stxdw [r2+0x0], r3                      
    jne r3, 0, lbb_488                              if r3 != (0 as i32 as i64 as u64) { pc += 3 }
    ldxdw r3, [r2+0x8]                      
    add64 r3, -1                                    r3 += -1   ///  r3 = r3.wrapping_add(-1 as i32 as i64 as u64)
    stxdw [r2+0x8], r3                      
lbb_488:
    ldxdw r2, [r1+0x40]                     
    ldxdw r3, [r1+0x38]                     
    ldxdw r4, [r3+0x0]                      
    add64 r4, -1                                    r4 += -1   ///  r4 = r4.wrapping_add(-1 as i32 as i64 as u64)
    stxdw [r3+0x0], r4                      
    jne r4, 0, lbb_497                              if r4 != (0 as i32 as i64 as u64) { pc += 3 }
    ldxdw r4, [r3+0x8]                      
    add64 r4, -1                                    r4 += -1   ///  r4 = r4.wrapping_add(-1 as i32 as i64 as u64)
    stxdw [r3+0x8], r4                      
lbb_497:
    ldxdw r3, [r2+0x0]                      
    add64 r3, -1                                    r3 += -1   ///  r3 = r3.wrapping_add(-1 as i32 as i64 as u64)
    stxdw [r2+0x0], r3                      
    jne r3, 0, lbb_504                              if r3 != (0 as i32 as i64 as u64) { pc += 3 }
    ldxdw r3, [r2+0x8]                      
    add64 r3, -1                                    r3 += -1   ///  r3 = r3.wrapping_add(-1 as i32 as i64 as u64)
    stxdw [r2+0x8], r3                      
lbb_504:
    ldxdw r2, [r1+0x70]                     
    ldxdw r3, [r1+0x68]                     
    ldxdw r4, [r3+0x0]                      
    add64 r4, -1                                    r4 += -1   ///  r4 = r4.wrapping_add(-1 as i32 as i64 as u64)
    stxdw [r3+0x0], r4                      
    jne r4, 0, lbb_513                              if r4 != (0 as i32 as i64 as u64) { pc += 3 }
    ldxdw r4, [r3+0x8]                      
    add64 r4, -1                                    r4 += -1   ///  r4 = r4.wrapping_add(-1 as i32 as i64 as u64)
    stxdw [r3+0x8], r4                      
lbb_513:
    ldxdw r3, [r2+0x0]                      
    add64 r3, -1                                    r3 += -1   ///  r3 = r3.wrapping_add(-1 as i32 as i64 as u64)
    stxdw [r2+0x0], r3                      
    jne r3, 0, lbb_520                              if r3 != (0 as i32 as i64 as u64) { pc += 3 }
    ldxdw r3, [r2+0x8]                      
    add64 r3, -1                                    r3 += -1   ///  r3 = r3.wrapping_add(-1 as i32 as i64 as u64)
    stxdw [r2+0x8], r3                      
lbb_520:
    ldxdw r2, [r1+0xa0]                     
    ldxdw r1, [r1+0x98]                     
    ldxdw r3, [r1+0x0]                      
    add64 r3, -1                                    r3 += -1   ///  r3 = r3.wrapping_add(-1 as i32 as i64 as u64)
    stxdw [r1+0x0], r3                      
    jne r3, 0, lbb_529                              if r3 != (0 as i32 as i64 as u64) { pc += 3 }
    ldxdw r3, [r1+0x8]                      
    add64 r3, -1                                    r3 += -1   ///  r3 = r3.wrapping_add(-1 as i32 as i64 as u64)
    stxdw [r1+0x8], r3                      
lbb_529:
    ldxdw r1, [r2+0x0]                      
    add64 r1, -1                                    r1 += -1   ///  r1 = r1.wrapping_add(-1 as i32 as i64 as u64)
    stxdw [r2+0x0], r1                      
    jne r1, 0, lbb_536                              if r1 != (0 as i32 as i64 as u64) { pc += 3 }
    ldxdw r1, [r2+0x8]                      
    add64 r1, -1                                    r1 += -1   ///  r1 = r1.wrapping_add(-1 as i32 as i64 as u64)
    stxdw [r2+0x8], r1                      
lbb_536:
    exit                                    

function_537:
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
    stxdw [r1+0x10], r2                     
    stxdw [r1+0x8], r2                      
    stxdw [r1+0x0], r2                      
    stxdw [r1+0x18], r2                     
    stxdw [r1+0x20], r2                     
    stxdw [r1+0x28], r2                     
    stxdw [r1+0x30], r2                     
    stxdw [r1+0x38], r2                     
    stxdw [r1+0x40], r2                     
    stxdw [r1+0x48], r2                     
    stxdw [r1+0x50], r2                     
    stxdw [r1+0x58], r2                     
    stxdw [r1+0x60], r2                     
    stxdw [r1+0x68], r2                     
    stxdw [r1+0x70], r2                     
    stxdw [r1+0x88], r2                     
    stxdw [r1+0x80], r2                     
    stxdw [r1+0x78], r2                     
    stxdw [r1+0xa0], r2                     
    stxdw [r1+0x98], r2                     
    stxdw [r1+0x90], r2                     
    stxdw [r1+0xb8], r2                     
    stxdw [r1+0xb0], r2                     
    stxdw [r1+0xa8], r2                     
    stxdw [r1+0xd0], r2                     
    stxdw [r1+0xc8], r2                     
    stxdw [r1+0xc0], r2                     
    stxdw [r1+0xe8], r2                     
    stxdw [r1+0xe0], r2                     
    stxdw [r1+0xd8], r2                     
    stxdw [r1+0x100], r2                    
    stxdw [r1+0xf8], r2                     
    stxdw [r1+0xf0], r2                     
    stxdw [r1+0x108], r2                    
    stxdw [r1+0x110], r2                    
    stxdw [r1+0x118], r2                    
    stxdw [r1+0x130], r2                    
    stxdw [r1+0x128], r2                    
    stxdw [r1+0x120], r2                    
    stxdw [r1+0x148], r2                    
    stxdw [r1+0x140], r2                    
    stxdw [r1+0x138], r2                    
    stxdw [r1+0x160], r2                    
    stxdw [r1+0x158], r2                    
    stxdw [r1+0x150], r2                    
    stxdw [r1+0x178], r2                    
    stxdw [r1+0x170], r2                    
    stxdw [r1+0x168], r2                    
    stxdw [r1+0x190], r2                    
    stxdw [r1+0x188], r2                    
    stxdw [r1+0x180], r2                    
    stxdw [r1+0x1a8], r2                    
    stxdw [r1+0x1a0], r2                    
    stxdw [r1+0x198], r2                    
    stxdw [r1+0x1c0], r2                    
    stxdw [r1+0x1b8], r2                    
    stxdw [r1+0x1b0], r2                    
    stxdw [r1+0x1d8], r2                    
    stxdw [r1+0x1d0], r2                    
    stxdw [r1+0x1c8], r2                    
    exit                                    

function_599:
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
    stxdw [r1+0x0], r2                      
    exit                                    

function_602:
    exit                                    

function_603:
    lddw r2, 0x1c4088621fee484b                     r2 load str located at 2035776986595346507
    stxdw [r1+0x8], r2                      
    lddw r2, 0x2219183bd7fa6079                     r2 load str located at 2457021717012963449
    stxdw [r1+0x0], r2                      
    exit                                    

function_610:
    mov64 r1, r2                                    r1 = r2
    lddw r2, 0x10003e67a --> b"Error"               r2 load str located at 4295222906
    mov64 r3, 5                                     r3 = 5 as i32 as i64 as u64
    call function_27691                     
    exit                                    

function_616:
    mov64 r6, r1                                    r6 = r1
    mov64 r1, r2                                    r1 = r2
    lsh64 r1, 32                                    r1 <<= 32   ///  r1 = r1.wrapping_shl(32)
    rsh64 r1, 32                                    r1 >>= 32   ///  r1 = r1.wrapping_shr(32)
    mov64 r3, 128                                   r3 = 128 as i32 as i64 as u64
    jgt r3, r1, lbb_646                             if r3 > r1 { pc += 24 }
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
    stxw [r10-0x4], r3                      
    mov64 r3, 2048                                  r3 = 2048 as i32 as i64 as u64
    jgt r3, r1, lbb_659                             if r3 > r1 { pc += 33 }
    mov64 r1, r2                                    r1 = r2
    lsh64 r1, 32                                    r1 <<= 32   ///  r1 = r1.wrapping_shl(32)
    rsh64 r1, 32                                    r1 >>= 32   ///  r1 = r1.wrapping_shr(32)
    mov64 r3, 65536                                 r3 = 65536 as i32 as i64 as u64
    jgt r3, r1, lbb_632                             if r3 > r1 { pc += 1 }
    ja lbb_668                                      if true { pc += 36 }
lbb_632:
    mov64 r1, r2                                    r1 = r2
    and64 r1, 63                                    r1 &= 63   ///  r1 = r1.and(63)
    or64 r1, 128                                    r1 |= 128   ///  r1 = r1.or(128)
    stxb [r10-0x2], r1                      
    mov64 r1, r2                                    r1 = r2
    rsh64 r1, 12                                    r1 >>= 12   ///  r1 = r1.wrapping_shr(12)
    or64 r1, 224                                    r1 |= 224   ///  r1 = r1.or(224)
    stxb [r10-0x4], r1                      
    rsh64 r2, 6                                     r2 >>= 6   ///  r2 = r2.wrapping_shr(6)
    and64 r2, 63                                    r2 &= 63   ///  r2 = r2.and(63)
    or64 r2, 128                                    r2 |= 128   ///  r2 = r2.or(128)
    stxb [r10-0x3], r2                      
    mov64 r7, 3                                     r7 = 3 as i32 as i64 as u64
    ja lbb_687                                      if true { pc += 41 }
lbb_646:
    ldxdw r7, [r6+0x10]                     
    ldxdw r1, [r6+0x0]                      
    jne r7, r1, lbb_653                             if r7 != r1 { pc += 4 }
    mov64 r1, r6                                    r1 = r6
    mov64 r8, r2                                    r8 = r2
    call function_881                       
    mov64 r2, r8                                    r2 = r8
lbb_653:
    ldxdw r1, [r6+0x8]                      
    add64 r1, r7                                    r1 += r7   ///  r1 = r1.wrapping_add(r7)
    stxb [r1+0x0], r2                       
    add64 r7, 1                                     r7 += 1   ///  r7 = r7.wrapping_add(1 as i32 as i64 as u64)
    stxdw [r6+0x10], r7                     
    ja lbb_704                                      if true { pc += 45 }
lbb_659:
    mov64 r1, r2                                    r1 = r2
    and64 r1, 63                                    r1 &= 63   ///  r1 = r1.and(63)
    or64 r1, 128                                    r1 |= 128   ///  r1 = r1.or(128)
    stxb [r10-0x3], r1                      
    rsh64 r2, 6                                     r2 >>= 6   ///  r2 = r2.wrapping_shr(6)
    or64 r2, 192                                    r2 |= 192   ///  r2 = r2.or(192)
    stxb [r10-0x4], r2                      
    mov64 r7, 2                                     r7 = 2 as i32 as i64 as u64
    ja lbb_687                                      if true { pc += 19 }
lbb_668:
    mov64 r1, r2                                    r1 = r2
    and64 r1, 63                                    r1 &= 63   ///  r1 = r1.and(63)
    or64 r1, 128                                    r1 |= 128   ///  r1 = r1.or(128)
    stxb [r10-0x1], r1                      
    mov64 r1, r2                                    r1 = r2
    rsh64 r1, 6                                     r1 >>= 6   ///  r1 = r1.wrapping_shr(6)
    and64 r1, 63                                    r1 &= 63   ///  r1 = r1.and(63)
    or64 r1, 128                                    r1 |= 128   ///  r1 = r1.or(128)
    stxb [r10-0x2], r1                      
    mov64 r1, r2                                    r1 = r2
    rsh64 r1, 12                                    r1 >>= 12   ///  r1 = r1.wrapping_shr(12)
    and64 r1, 63                                    r1 &= 63   ///  r1 = r1.and(63)
    or64 r1, 128                                    r1 |= 128   ///  r1 = r1.or(128)
    stxb [r10-0x3], r1                      
    rsh64 r2, 18                                    r2 >>= 18   ///  r2 = r2.wrapping_shr(18)
    and64 r2, 7                                     r2 &= 7   ///  r2 = r2.and(7)
    or64 r2, 240                                    r2 |= 240   ///  r2 = r2.or(240)
    stxb [r10-0x4], r2                      
    mov64 r7, 4                                     r7 = 4 as i32 as i64 as u64
lbb_687:
    ldxdw r8, [r6+0x10]                     
    ldxdw r1, [r6+0x0]                      
    sub64 r1, r8                                    r1 -= r8   ///  r1 = r1.wrapping_sub(r8)
    jge r1, r7, lbb_696                             if r1 >= r7 { pc += 5 }
    mov64 r1, r6                                    r1 = r6
    mov64 r2, r8                                    r2 = r8
    mov64 r3, r7                                    r3 = r7
    call function_840                       
    ldxdw r8, [r6+0x10]                     
lbb_696:
    ldxdw r1, [r6+0x8]                      
    add64 r1, r8                                    r1 += r8   ///  r1 = r1.wrapping_add(r8)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -4                                    r2 += -4   ///  r2 = r2.wrapping_add(-4 as i32 as i64 as u64)
    mov64 r3, r7                                    r3 = r7
    call function_30349                     
    add64 r8, r7                                    r8 += r7   ///  r8 = r8.wrapping_add(r7)
    stxdw [r6+0x10], r8                     
lbb_704:
    mov64 r0, 0                                     r0 = 0 as i32 as i64 as u64
    exit                                    

function_706:
    mov64 r6, r3                                    r6 = r3
    mov64 r7, r1                                    r7 = r1
    ldxdw r8, [r7+0x10]                     
    ldxdw r1, [r7+0x0]                      
    sub64 r1, r8                                    r1 -= r8   ///  r1 = r1.wrapping_sub(r8)
    jge r1, r6, lbb_719                             if r1 >= r6 { pc += 7 }
    mov64 r1, r7                                    r1 = r7
    mov64 r9, r2                                    r9 = r2
    mov64 r2, r8                                    r2 = r8
    mov64 r3, r6                                    r3 = r6
    call function_840                       
    mov64 r2, r9                                    r2 = r9
    ldxdw r8, [r7+0x10]                     
lbb_719:
    ldxdw r1, [r7+0x8]                      
    add64 r1, r8                                    r1 += r8   ///  r1 = r1.wrapping_add(r8)
    mov64 r3, r6                                    r3 = r6
    call function_30349                     
    add64 r8, r6                                    r8 += r6   ///  r8 = r8.wrapping_add(r6)
    stxdw [r7+0x10], r8                     
    mov64 r0, 0                                     r0 = 0 as i32 as i64 as u64
    exit                                    

function_727:
    jeq r2, 0, lbb_735                              if r2 == (0 as i32 as i64 as u64) { pc += 7 }
    ldxdw r5, [r4+0x8]                      
    jeq r5, 0, lbb_774                              if r5 == (0 as i32 as i64 as u64) { pc += 44 }
    ldxdw r5, [r4+0x10]                     
    jne r5, 0, lbb_738                              if r5 != (0 as i32 as i64 as u64) { pc += 6 }
    jne r3, 0, lbb_798                              if r3 != (0 as i32 as i64 as u64) { pc += 65 }
lbb_733:
    mov64 r6, r2                                    r6 = r2
    ja lbb_822                                      if true { pc += 87 }
lbb_735:
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
    stxdw [r1+0x8], r2                      
    ja lbb_837                                      if true { pc += 99 }
lbb_738:
    lddw r0, 0x300000000                            r0 load str located at 12884901888
    ldxdw r0, [r0+0x0]                      
    lddw r7, 0x300008000                            r7 load str located at 12884934656
    jeq r0, 0, lbb_745                              if r0 == (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r7, r0                                    r7 = r0
lbb_745:
    mov64 r0, r7                                    r0 = r7
    sub64 r0, r3                                    r0 -= r3   ///  r0 = r0.wrapping_sub(r3)
    mov64 r6, 0                                     r6 = 0 as i32 as i64 as u64
    mov64 r8, 1                                     r8 = 1 as i32 as i64 as u64
    jgt r0, r7, lbb_751                             if r0 > r7 { pc += 1 }
    mov64 r8, 0                                     r8 = 0 as i32 as i64 as u64
lbb_751:
    jne r8, 0, lbb_753                              if r8 != (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r6, r0                                    r6 = r0
lbb_753:
    mov64 r0, r2                                    r0 = r2
    neg64 r0                                        r0 = -r0   ///  r0 = (r0 as i64).wrapping_neg() as u64
    and64 r6, r0                                    r6 &= r0   ///  r6 = r6.and(r0)
    lddw r0, 0x300000008                            r0 load str located at 12884901896
    jgt r0, r6, lbb_831                             if r0 > r6 { pc += 72 }
    ldxdw r4, [r4+0x0]                      
    lddw r0, 0x300000000                            r0 load str located at 12884901888
    stxdw [r0+0x0], r6                      
    mov64 r7, r1                                    r7 = r1
    mov64 r1, r6                                    r1 = r6
    mov64 r8, r2                                    r8 = r2
    mov64 r2, r4                                    r2 = r4
    mov64 r9, r3                                    r9 = r3
    mov64 r3, r5                                    r3 = r5
    call function_30349                     
    mov64 r2, r8                                    r2 = r8
    mov64 r3, r9                                    r3 = r9
    mov64 r1, r7                                    r1 = r7
    ja lbb_822                                      if true { pc += 48 }
lbb_774:
    jne r3, 0, lbb_776                              if r3 != (0 as i32 as i64 as u64) { pc += 1 }
    ja lbb_733                                      if true { pc += -43 }
lbb_776:
    lddw r4, 0x300000000                            r4 load str located at 12884901888
    ldxdw r4, [r4+0x0]                      
    lddw r5, 0x300008000                            r5 load str located at 12884934656
    jeq r4, 0, lbb_783                              if r4 == (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r5, r4                                    r5 = r4
lbb_783:
    mov64 r4, r5                                    r4 = r5
    sub64 r4, r3                                    r4 -= r3   ///  r4 = r4.wrapping_sub(r3)
    mov64 r6, 0                                     r6 = 0 as i32 as i64 as u64
    mov64 r0, 1                                     r0 = 1 as i32 as i64 as u64
    jgt r4, r5, lbb_789                             if r4 > r5 { pc += 1 }
    mov64 r0, 0                                     r0 = 0 as i32 as i64 as u64
lbb_789:
    jne r0, 0, lbb_791                              if r0 != (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r6, r4                                    r6 = r4
lbb_791:
    mov64 r4, r2                                    r4 = r2
    neg64 r4                                        r4 = -r4   ///  r4 = (r4 as i64).wrapping_neg() as u64
    and64 r6, r4                                    r6 &= r4   ///  r6 = r6.and(r4)
    lddw r4, 0x300000008                            r4 load str located at 12884901896
    jgt r4, r6, lbb_831                             if r4 > r6 { pc += 34 }
    ja lbb_819                                      if true { pc += 21 }
lbb_798:
    lddw r4, 0x300000000                            r4 load str located at 12884901888
    ldxdw r4, [r4+0x0]                      
    lddw r5, 0x300008000                            r5 load str located at 12884934656
    jeq r4, 0, lbb_805                              if r4 == (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r5, r4                                    r5 = r4
lbb_805:
    mov64 r4, r5                                    r4 = r5
    sub64 r4, r3                                    r4 -= r3   ///  r4 = r4.wrapping_sub(r3)
    mov64 r6, 0                                     r6 = 0 as i32 as i64 as u64
    mov64 r0, 1                                     r0 = 1 as i32 as i64 as u64
    jgt r4, r5, lbb_811                             if r4 > r5 { pc += 1 }
    mov64 r0, 0                                     r0 = 0 as i32 as i64 as u64
lbb_811:
    jne r0, 0, lbb_813                              if r0 != (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r6, r4                                    r6 = r4
lbb_813:
    mov64 r4, r2                                    r4 = r2
    neg64 r4                                        r4 = -r4   ///  r4 = (r4 as i64).wrapping_neg() as u64
    and64 r6, r4                                    r6 &= r4   ///  r6 = r6.and(r4)
    lddw r4, 0x300000008                            r4 load str located at 12884901896
    jgt r4, r6, lbb_831                             if r4 > r6 { pc += 12 }
lbb_819:
    lddw r4, 0x300000000                            r4 load str located at 12884901888
    stxdw [r4+0x0], r6                      
lbb_822:
    mov64 r4, r1                                    r4 = r1
    add64 r4, 16                                    r4 += 16   ///  r4 = r4.wrapping_add(16 as i32 as i64 as u64)
    mov64 r5, r1                                    r5 = r1
    add64 r5, 8                                     r5 += 8   ///  r5 = r5.wrapping_add(8 as i32 as i64 as u64)
    jeq r6, 0, lbb_835                              if r6 == (0 as i32 as i64 as u64) { pc += 8 }
    stxdw [r5+0x0], r6                      
    stxdw [r4+0x0], r3                      
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
    ja lbb_838                                      if true { pc += 7 }
lbb_831:
    mov64 r4, r1                                    r4 = r1
    add64 r4, 16                                    r4 += 16   ///  r4 = r4.wrapping_add(16 as i32 as i64 as u64)
    mov64 r5, r1                                    r5 = r1
    add64 r5, 8                                     r5 += 8   ///  r5 = r5.wrapping_add(8 as i32 as i64 as u64)
lbb_835:
    stxdw [r5+0x0], r2                      
    stxdw [r4+0x0], r3                      
lbb_837:
    mov64 r2, 1                                     r2 = 1 as i32 as i64 as u64
lbb_838:
    stxdw [r1+0x0], r2                      
    exit                                    

function_840:
    mov64 r6, r1                                    r6 = r1
    mov64 r4, r2                                    r4 = r2
    add64 r4, r3                                    r4 += r3   ///  r4 = r4.wrapping_add(r3)
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    mov64 r3, 1                                     r3 = 1 as i32 as i64 as u64
    jgt r2, r4, lbb_847                             if r2 > r4 { pc += 1 }
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
lbb_847:
    and64 r3, 1                                     r3 &= 1   ///  r3 = r3.and(1)
    jne r3, 0, lbb_876                              if r3 != (0 as i32 as i64 as u64) { pc += 27 }
    ldxdw r1, [r6+0x0]                      
    mov64 r7, r1                                    r7 = r1
    lsh64 r7, 1                                     r7 <<= 1   ///  r7 = r7.wrapping_shl(1)
    jgt r7, r4, lbb_854                             if r7 > r4 { pc += 1 }
    mov64 r7, r4                                    r7 = r4
lbb_854:
    jgt r7, 8, lbb_856                              if r7 > (8 as i32 as i64 as u64) { pc += 1 }
    mov64 r7, 8                                     r7 = 8 as i32 as i64 as u64
lbb_856:
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
    mov64 r2, r7                                    r2 = r7
    xor64 r2, -1                                    r2 ^= -1   ///  r2 = r2.xor(-1)
    rsh64 r2, 63                                    r2 >>= 63   ///  r2 = r2.wrapping_shr(63)
    jeq r1, 0, lbb_865                              if r1 == (0 as i32 as i64 as u64) { pc += 4 }
    ldxdw r3, [r6+0x8]                      
    stxdw [r10-0x8], r1                     
    stxdw [r10-0x18], r3                    
    mov64 r3, 1                                     r3 = 1 as i32 as i64 as u64
lbb_865:
    stxdw [r10-0x10], r3                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -48                                   r1 += -48   ///  r1 = r1.wrapping_add(-48 as i32 as i64 as u64)
    mov64 r4, r10                                   r4 = r10
    add64 r4, -24                                   r4 += -24   ///  r4 = r4.wrapping_add(-24 as i32 as i64 as u64)
    mov64 r3, r7                                    r3 = r7
    call function_727                       
    ldxdw r1, [r10-0x30]                    
    jeq r1, 0, lbb_877                              if r1 == (0 as i32 as i64 as u64) { pc += 3 }
    ldxdw r2, [r10-0x20]                    
    ldxdw r1, [r10-0x28]                    
lbb_876:
    call function_21549                     
lbb_877:
    ldxdw r1, [r10-0x28]                    
    stxdw [r6+0x0], r7                      
    stxdw [r6+0x8], r1                      
    exit                                    

function_881:
    mov64 r6, r1                                    r6 = r1
    ldxdw r3, [r6+0x0]                      
    mov64 r4, r3                                    r4 = r3
    add64 r4, 1                                     r4 += 1   ///  r4 = r4.wrapping_add(1 as i32 as i64 as u64)
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    mov64 r5, 1                                     r5 = 1 as i32 as i64 as u64
    jeq r4, 0, lbb_889                              if r4 == (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r5, 0                                     r5 = 0 as i32 as i64 as u64
lbb_889:
    and64 r5, 1                                     r5 &= 1   ///  r5 = r5.and(1)
    jne r5, 0, lbb_916                              if r5 != (0 as i32 as i64 as u64) { pc += 25 }
    mov64 r7, r3                                    r7 = r3
    lsh64 r7, 1                                     r7 <<= 1   ///  r7 = r7.wrapping_shl(1)
    jgt r7, r4, lbb_895                             if r7 > r4 { pc += 1 }
    mov64 r7, r4                                    r7 = r4
lbb_895:
    jgt r7, 8, lbb_897                              if r7 > (8 as i32 as i64 as u64) { pc += 1 }
    mov64 r7, 8                                     r7 = 8 as i32 as i64 as u64
lbb_897:
    mov64 r2, r7                                    r2 = r7
    xor64 r2, -1                                    r2 ^= -1   ///  r2 = r2.xor(-1)
    rsh64 r2, 63                                    r2 >>= 63   ///  r2 = r2.wrapping_shr(63)
    jeq r3, 0, lbb_905                              if r3 == (0 as i32 as i64 as u64) { pc += 4 }
    ldxdw r1, [r6+0x8]                      
    stxdw [r10-0x8], r3                     
    stxdw [r10-0x18], r1                    
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
lbb_905:
    stxdw [r10-0x10], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -48                                   r1 += -48   ///  r1 = r1.wrapping_add(-48 as i32 as i64 as u64)
    mov64 r4, r10                                   r4 = r10
    add64 r4, -24                                   r4 += -24   ///  r4 = r4.wrapping_add(-24 as i32 as i64 as u64)
    mov64 r3, r7                                    r3 = r7
    call function_727                       
    ldxdw r1, [r10-0x30]                    
    jeq r1, 0, lbb_917                              if r1 == (0 as i32 as i64 as u64) { pc += 3 }
    ldxdw r2, [r10-0x20]                    
    ldxdw r1, [r10-0x28]                    
lbb_916:
    call function_21549                     
lbb_917:
    ldxdw r1, [r10-0x28]                    
    stxdw [r6+0x0], r7                      
    stxdw [r6+0x8], r1                      
    exit                                    

function_921:
    mov64 r6, r1                                    r6 = r1
    ldxdw r4, [r6+0x0]                      
    mov64 r3, r4                                    r3 = r4
    add64 r3, 1                                     r3 += 1   ///  r3 = r3.wrapping_add(1 as i32 as i64 as u64)
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    mov64 r5, 1                                     r5 = 1 as i32 as i64 as u64
    jeq r3, 0, lbb_929                              if r3 == (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r5, 0                                     r5 = 0 as i32 as i64 as u64
lbb_929:
    and64 r5, 1                                     r5 &= 1   ///  r5 = r5.and(1)
    jne r5, 0, lbb_960                              if r5 != (0 as i32 as i64 as u64) { pc += 29 }
    mov64 r7, r4                                    r7 = r4
    lsh64 r7, 1                                     r7 <<= 1   ///  r7 = r7.wrapping_shl(1)
    jgt r7, r3, lbb_935                             if r7 > r3 { pc += 1 }
    mov64 r7, r3                                    r7 = r3
lbb_935:
    mov64 r2, 1                                     r2 = 1 as i32 as i64 as u64
    lddw r3, 0x400000000000000                      r3 load str located at 288230376151711744
    jgt r3, r7, lbb_940                             if r3 > r7 { pc += 1 }
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
lbb_940:
    jgt r7, 4, lbb_942                              if r7 > (4 as i32 as i64 as u64) { pc += 1 }
    mov64 r7, 4                                     r7 = 4 as i32 as i64 as u64
lbb_942:
    mov64 r3, r7                                    r3 = r7
    lsh64 r3, 5                                     r3 <<= 5   ///  r3 = r3.wrapping_shl(5)
    jeq r4, 0, lbb_950                              if r4 == (0 as i32 as i64 as u64) { pc += 5 }
    ldxdw r1, [r6+0x8]                      
    lsh64 r4, 5                                     r4 <<= 5   ///  r4 = r4.wrapping_shl(5)
    stxdw [r10-0x8], r4                     
    stxdw [r10-0x18], r1                    
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
lbb_950:
    stxdw [r10-0x10], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -48                                   r1 += -48   ///  r1 = r1.wrapping_add(-48 as i32 as i64 as u64)
    mov64 r4, r10                                   r4 = r10
    add64 r4, -24                                   r4 += -24   ///  r4 = r4.wrapping_add(-24 as i32 as i64 as u64)
    call function_727                       
    ldxdw r1, [r10-0x30]                    
    jeq r1, 0, lbb_961                              if r1 == (0 as i32 as i64 as u64) { pc += 3 }
    ldxdw r2, [r10-0x20]                    
    ldxdw r1, [r10-0x28]                    
lbb_960:
    call function_21549                     
lbb_961:
    ldxdw r1, [r10-0x28]                    
    stxdw [r6+0x0], r7                      
    stxdw [r6+0x8], r1                      
    exit                                    

function_965:
    mov64 r6, r1                                    r6 = r1
    ldxdw r4, [r6+0x0]                      
    mov64 r3, r4                                    r3 = r4
    add64 r3, 1                                     r3 += 1   ///  r3 = r3.wrapping_add(1 as i32 as i64 as u64)
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    mov64 r5, 1                                     r5 = 1 as i32 as i64 as u64
    jeq r3, 0, lbb_973                              if r3 == (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r5, 0                                     r5 = 0 as i32 as i64 as u64
lbb_973:
    and64 r5, 1                                     r5 &= 1   ///  r5 = r5.and(1)
    jne r5, 0, lbb_1004                             if r5 != (0 as i32 as i64 as u64) { pc += 29 }
    mov64 r7, r4                                    r7 = r4
    lsh64 r7, 1                                     r7 <<= 1   ///  r7 = r7.wrapping_shl(1)
    jgt r7, r3, lbb_979                             if r7 > r3 { pc += 1 }
    mov64 r7, r3                                    r7 = r3
lbb_979:
    mov64 r2, 1                                     r2 = 1 as i32 as i64 as u64
    lddw r3, 0xaaaaaaaaaaaaaab                      r3 load str located at 768614336404564651
    jgt r3, r7, lbb_984                             if r3 > r7 { pc += 1 }
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
lbb_984:
    jgt r7, 4, lbb_986                              if r7 > (4 as i32 as i64 as u64) { pc += 1 }
    mov64 r7, 4                                     r7 = 4 as i32 as i64 as u64
lbb_986:
    mov64 r3, r7                                    r3 = r7
    mul64 r3, 12                                    r3 *= 12   ///  r3 = r3.wrapping_mul(12 as u64)
    jeq r4, 0, lbb_994                              if r4 == (0 as i32 as i64 as u64) { pc += 5 }
    ldxdw r1, [r6+0x8]                      
    mul64 r4, 12                                    r4 *= 12   ///  r4 = r4.wrapping_mul(12 as u64)
    stxdw [r10-0x8], r4                     
    stxdw [r10-0x18], r1                    
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
lbb_994:
    stxdw [r10-0x10], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -48                                   r1 += -48   ///  r1 = r1.wrapping_add(-48 as i32 as i64 as u64)
    mov64 r4, r10                                   r4 = r10
    add64 r4, -24                                   r4 += -24   ///  r4 = r4.wrapping_add(-24 as i32 as i64 as u64)
    call function_727                       
    ldxdw r1, [r10-0x30]                    
    jeq r1, 0, lbb_1005                             if r1 == (0 as i32 as i64 as u64) { pc += 3 }
    ldxdw r2, [r10-0x20]                    
    ldxdw r1, [r10-0x28]                    
lbb_1004:
    call function_21549                     
lbb_1005:
    ldxdw r1, [r10-0x28]                    
    stxdw [r6+0x0], r7                      
    stxdw [r6+0x8], r1                      
    exit                                    

function_1009:
    mov64 r6, r1                                    r6 = r1
    ldxdw r4, [r6+0x0]                      
    mov64 r3, r4                                    r3 = r4
    add64 r3, 1                                     r3 += 1   ///  r3 = r3.wrapping_add(1 as i32 as i64 as u64)
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    mov64 r5, 1                                     r5 = 1 as i32 as i64 as u64
    jeq r3, 0, lbb_1017                             if r3 == (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r5, 0                                     r5 = 0 as i32 as i64 as u64
lbb_1017:
    and64 r5, 1                                     r5 &= 1   ///  r5 = r5.and(1)
    jne r5, 0, lbb_1049                             if r5 != (0 as i32 as i64 as u64) { pc += 30 }
    mov64 r7, r4                                    r7 = r4
    lsh64 r7, 1                                     r7 <<= 1   ///  r7 = r7.wrapping_shl(1)
    jgt r7, r3, lbb_1023                            if r7 > r3 { pc += 1 }
    mov64 r7, r3                                    r7 = r3
lbb_1023:
    mov64 r2, 1                                     r2 = 1 as i32 as i64 as u64
    lddw r3, 0x555555555555556                      r3 load str located at 384307168202282326
    jgt r3, r7, lbb_1028                            if r3 > r7 { pc += 1 }
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
lbb_1028:
    jgt r7, 4, lbb_1030                             if r7 > (4 as i32 as i64 as u64) { pc += 1 }
    mov64 r7, 4                                     r7 = 4 as i32 as i64 as u64
lbb_1030:
    lsh64 r2, 3                                     r2 <<= 3   ///  r2 = r2.wrapping_shl(3)
    mov64 r3, r7                                    r3 = r7
    mul64 r3, 24                                    r3 *= 24   ///  r3 = r3.wrapping_mul(24 as u64)
    jeq r4, 0, lbb_1039                             if r4 == (0 as i32 as i64 as u64) { pc += 5 }
    ldxdw r1, [r6+0x8]                      
    mul64 r4, 24                                    r4 *= 24   ///  r4 = r4.wrapping_mul(24 as u64)
    stxdw [r10-0x8], r4                     
    stxdw [r10-0x18], r1                    
    mov64 r1, 8                                     r1 = 8 as i32 as i64 as u64
lbb_1039:
    stxdw [r10-0x10], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -48                                   r1 += -48   ///  r1 = r1.wrapping_add(-48 as i32 as i64 as u64)
    mov64 r4, r10                                   r4 = r10
    add64 r4, -24                                   r4 += -24   ///  r4 = r4.wrapping_add(-24 as i32 as i64 as u64)
    call function_727                       
    ldxdw r1, [r10-0x30]                    
    jeq r1, 0, lbb_1050                             if r1 == (0 as i32 as i64 as u64) { pc += 3 }
    ldxdw r2, [r10-0x20]                    
    ldxdw r1, [r10-0x28]                    
lbb_1049:
    call function_21549                     
lbb_1050:
    ldxdw r1, [r10-0x28]                    
    stxdw [r6+0x0], r7                      
    stxdw [r6+0x8], r1                      
    exit                                    

function_1054:
    lddw r2, 0x100040d20 --> b"\x00\x00\x00\x00\xc8\x0f\x00\x00\x10\x00\x00\x00\x00\x00\x00\x00\x08\x00\…        r2 load str located at 4295232800
    stxdw [r10-0x58], r2                    
    lddw r2, 0x100040d10 --> b"\x00\x00\x00\x00u\xe4\x03\x00\x19\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00…        r2 load str located at 4295232784
    stxdw [r10-0x60], r2                    
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
    stxdw [r10-0x30], r2                    
    lddw r2, 0x100040e28 --> b"\x00\x00\x00\x00\x7f\xe6\x03\x00\x0f\x00\x00\x00\x00\x00\x00\x00\x00\x00\…        r2 load str located at 4295233064
    stxdw [r10-0x50], r2                    
    mov64 r2, 2                                     r2 = 2 as i32 as i64 as u64
    stxdw [r10-0x48], r2                    
    stxdw [r10-0x38], r2                    
    mov64 r2, r10                                   r2 = r10
    add64 r2, -32                                   r2 += -32   ///  r2 = r2.wrapping_add(-32 as i32 as i64 as u64)
    stxdw [r10-0x40], r2                    
    lddw r2, 0x100000ed0 --> b"\xbf#\x00\x00\x00\x00\x00\x00y\x12\x08\x00\x00\x00\x00\x00y\x11\x00\x00\x…        r2 load str located at 4294971088
    stxdw [r10-0x8], r2                     
    mov64 r2, r10                                   r2 = r10
    add64 r2, -96                                   r2 += -96   ///  r2 = r2.wrapping_add(-96 as i32 as i64 as u64)
    stxdw [r10-0x10], r2                    
    lddw r2, 0x100026ed0 --> b"q\x13\x00\x00\x00\x00\x00\x00e\x03\x14\x00\x08\x00\x00\x00e\x03\x1c\x00\x…        r2 load str located at 4295126736
    stxdw [r10-0x18], r2                    
    stxdw [r10-0x20], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -80                                   r1 += -80   ///  r1 = r1.wrapping_add(-80 as i32 as i64 as u64)
    call function_2034                      
    exit                                    

function_1085:
    stxdw [r10-0x58], r3                    
    stxdw [r10-0x60], r2                    
    stxdw [r10-0x68], r1                    
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    stxdw [r10-0x30], r1                    
    lddw r1, 0x100040e48 --> b"\x00\x00\x00\x00\x99\xe6\x03\x00\x0f\x00\x00\x00\x00\x00\x00\x00\x00\x00\…        r1 load str located at 4295233096
    stxdw [r10-0x50], r1                    
    mov64 r1, 2                                     r1 = 2 as i32 as i64 as u64
    stxdw [r10-0x48], r1                    
    stxdw [r10-0x38], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -32                                   r1 += -32   ///  r1 = r1.wrapping_add(-32 as i32 as i64 as u64)
    stxdw [r10-0x40], r1                    
    lddw r1, 0x100000ed0 --> b"\xbf#\x00\x00\x00\x00\x00\x00y\x12\x08\x00\x00\x00\x00\x00y\x11\x00\x00\x…        r1 load str located at 4294971088
    stxdw [r10-0x8], r1                     
    mov64 r1, r10                                   r1 = r10
    add64 r1, -96                                   r1 += -96   ///  r1 = r1.wrapping_add(-96 as i32 as i64 as u64)
    stxdw [r10-0x10], r1                    
    lddw r1, 0x10003b1e0 --> b"\xbf#\x00\x00\x00\x00\x00\x00y\x11\x00\x00\x00\x00\x00\x00\xb7\x02\x00\x0…        r1 load str located at 4295209440
    stxdw [r10-0x18], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -104                                  r1 += -104   ///  r1 = r1.wrapping_add(-104 as i32 as i64 as u64)
    stxdw [r10-0x20], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -80                                   r1 += -80   ///  r1 = r1.wrapping_add(-80 as i32 as i64 as u64)
    call function_2034                      
    exit                                    

function_1115:
    ldxdw r3, [r2+0x8]                      
    jne r3, 0, lbb_1121                             if r3 != (0 as i32 as i64 as u64) { pc += 4 }
    lddw r2, 0x8000000000000000                     r2 load str located at -9223372036854775808
    stxdw [r1+0x0], r2                      
    ja lbb_1261                                     if true { pc += 140 }
lbb_1121:
    add64 r3, -1                                    r3 += -1   ///  r3 = r3.wrapping_add(-1 as i32 as i64 as u64)
    stxdw [r2+0x8], r3                      
    ldxdw r6, [r2+0x0]                      
    ldxdw r7, [r6+0x28]                     
    jgt r7, 7, lbb_1148                             if r7 > (7 as i32 as i64 as u64) { pc += 22 }
    lddw r2, 0x300000000                            r2 load str located at 12884901888
    ldxdw r2, [r2+0x0]                      
    mov64 r4, r2                                    r4 = r2
    add64 r4, -24                                   r4 += -24   ///  r4 = r4.wrapping_add(-24 as i32 as i64 as u64)
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
    mov64 r5, 1                                     r5 = 1 as i32 as i64 as u64
    jgt r4, r2, lbb_1135                            if r4 > r2 { pc += 1 }
    mov64 r5, 0                                     r5 = 0 as i32 as i64 as u64
lbb_1135:
    jne r5, 0, lbb_1137                             if r5 != (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r3, r4                                    r3 = r4
lbb_1137:
    lddw r0, 0x300007fe8                            r0 load str located at 12884934632
    jeq r2, 0, lbb_1142                             if r2 == (0 as i32 as i64 as u64) { pc += 2 }
    and64 r3, -8                                    r3 &= -8   ///  r3 = r3.and(-8)
    mov64 r0, r3                                    r0 = r3
lbb_1142:
    lddw r2, 0x300000007                            r2 load str located at 12884901895
    jgt r0, r2, lbb_1188                            if r0 > r2 { pc += 43 }
lbb_1145:
    mov64 r1, 8                                     r1 = 8 as i32 as i64 as u64
    mov64 r2, 24                                    r2 = 24 as i32 as i64 as u64
    call function_21552                     
lbb_1148:
    mov64 r8, r1                                    r8 = r1
    add64 r7, -8                                    r7 += -8   ///  r7 = r7.wrapping_add(-8 as i32 as i64 as u64)
    stxdw [r6+0x28], r7                     
    ldxdw r9, [r6+0x20]                     
    mov64 r1, 8                                     r1 = 8 as i32 as i64 as u64
    jgt r1, r9, lbb_1253                            if r1 > r9 { pc += 99 }
    ldxdw r1, [r6+0x18]                     
    ldxdw r2, [r1+0x0]                      
    add64 r1, 8                                     r1 += 8   ///  r1 = r1.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r6+0x18], r1                     
    add64 r9, -8                                    r9 += -8   ///  r9 = r9.wrapping_add(-8 as i32 as i64 as u64)
    stxdw [r6+0x20], r9                     
    mov64 r1, r10                                   r1 = r10
    add64 r1, -40                                   r1 += -40   ///  r1 = r1.wrapping_add(-40 as i32 as i64 as u64)
    call function_19493                     
    ldxdw r0, [r10-0x20]                    
    ldxdw r2, [r10-0x28]                    
    mov64 r1, r8                                    r1 = r8
    jne r2, 0, lbb_1257                             if r2 != (0 as i32 as i64 as u64) { pc += 90 }
    jge r7, r0, lbb_1195                            if r7 >= r0 { pc += 27 }
    lddw r2, 0x300000000                            r2 load str located at 12884901888
    ldxdw r2, [r2+0x0]                      
    mov64 r4, r2                                    r4 = r2
    add64 r4, -24                                   r4 += -24   ///  r4 = r4.wrapping_add(-24 as i32 as i64 as u64)
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
    mov64 r5, 1                                     r5 = 1 as i32 as i64 as u64
    jgt r4, r2, lbb_1177                            if r4 > r2 { pc += 1 }
    mov64 r5, 0                                     r5 = 0 as i32 as i64 as u64
lbb_1177:
    jne r5, 0, lbb_1179                             if r5 != (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r3, r4                                    r3 = r4
lbb_1179:
    lddw r0, 0x300007fe8                            r0 load str located at 12884934632
    jeq r2, 0, lbb_1184                             if r2 == (0 as i32 as i64 as u64) { pc += 2 }
    and64 r3, -8                                    r3 &= -8   ///  r3 = r3.and(-8)
    mov64 r0, r3                                    r0 = r3
lbb_1184:
    lddw r2, 0x300000007                            r2 load str located at 12884901895
    jgt r0, r2, lbb_1188                            if r0 > r2 { pc += 1 }
    ja lbb_1145                                     if true { pc += -43 }
lbb_1188:
    lddw r2, 0x300000000                            r2 load str located at 12884901888
    stxdw [r2+0x0], r0                      
    lddw r2, 0x8000000000000006                     r2 load str located at -9223372036854775802
lbb_1193:
    stxdw [r0+0x0], r2                      
    ja lbb_1257                                     if true { pc += 62 }
lbb_1195:
    sub64 r7, r0                                    r7 -= r0   ///  r7 = r7.wrapping_sub(r0)
    stxdw [r6+0x28], r7                     
    ldxdw r7, [r6+0x10]                     
    jgt r0, r7, lbb_1202                            if r0 > r7 { pc += 3 }
    mov64 r7, r0                                    r7 = r0
    ldxdw r0, [r6+0x8]                      
    ja lbb_1237                                     if true { pc += 35 }
lbb_1202:
    sub64 r0, r7                                    r0 -= r7   ///  r0 = r0.wrapping_sub(r7)
    ldxdw r2, [r6+0x0]                      
    sub64 r2, r7                                    r2 -= r7   ///  r2 = r2.wrapping_sub(r7)
    jge r2, r0, lbb_1214                            if r2 >= r0 { pc += 8 }
    mov64 r1, r6                                    r1 = r6
    mov64 r2, r7                                    r2 = r7
    mov64 r3, r0                                    r3 = r0
    mov64 r7, r0                                    r7 = r0
    call function_840                       
    mov64 r0, r7                                    r0 = r7
    mov64 r1, r8                                    r1 = r8
    ldxdw r7, [r6+0x10]                     
lbb_1214:
    ldxdw r4, [r6+0x8]                      
    mov64 r2, r4                                    r2 = r4
    add64 r2, r7                                    r2 += r7   ///  r2 = r2.wrapping_add(r7)
    mov64 r3, 2                                     r3 = 2 as i32 as i64 as u64
    jgt r3, r0, lbb_1232                            if r3 > r0 { pc += 13 }
    add64 r0, -1                                    r0 += -1   ///  r0 = r0.wrapping_add(-1 as i32 as i64 as u64)
    stxdw [r10-0x30], r0                    
    mov64 r1, r2                                    r1 = r2
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
    mov64 r3, r0                                    r3 = r0
    mov64 r9, r4                                    r9 = r4
    call function_30383                     
    mov64 r4, r9                                    r4 = r9
    mov64 r1, r8                                    r1 = r8
    ldxdw r2, [r10-0x30]                    
    add64 r7, r2                                    r7 += r2   ///  r7 = r7.wrapping_add(r2)
    mov64 r2, r4                                    r2 = r4
    add64 r2, r7                                    r2 += r7   ///  r2 = r2.wrapping_add(r7)
lbb_1232:
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
    stxb [r2+0x0], r3                       
    add64 r7, 1                                     r7 += 1   ///  r7 = r7.wrapping_add(1 as i32 as i64 as u64)
    ldxdw r9, [r6+0x20]                     
    mov64 r0, r4                                    r0 = r4
lbb_1237:
    stxdw [r6+0x10], r7                     
    jgt r7, r9, lbb_1253                            if r7 > r9 { pc += 14 }
    sub64 r9, r7                                    r9 -= r7   ///  r9 = r9.wrapping_sub(r7)
    ldxdw r2, [r6+0x18]                     
    mov64 r3, r2                                    r3 = r2
    add64 r3, r7                                    r3 += r7   ///  r3 = r3.wrapping_add(r7)
    jeq r7, 1, lbb_1262                             if r7 == (1 as i32 as i64 as u64) { pc += 18 }
    mov64 r1, r0                                    r1 = r0
    stxdw [r10-0x38], r3                    
    mov64 r3, r7                                    r3 = r7
    stxdw [r10-0x30], r0                    
    call function_30349                     
    ldxdw r3, [r10-0x38]                    
    ldxdw r0, [r10-0x30]                    
    mov64 r1, r8                                    r1 = r8
    ja lbb_1264                                     if true { pc += 11 }
lbb_1253:
    lddw r1, 0x100040d80 --> b"\x00\x00\x00\x00\x99\xe5\x03\x00\x1b\x00\x00\x00\x00\x00\x00\x00%\x00\x00…        r1 load str located at 4295232896
    call function_19497                     
    mov64 r1, r8                                    r1 = r8
lbb_1257:
    lddw r2, 0x8000000000000001                     r2 load str located at -9223372036854775807
    stxdw [r1+0x0], r2                      
    stxdw [r1+0x8], r0                      
lbb_1261:
    exit                                    
lbb_1262:
    ldxb r2, [r2+0x0]                       
    stxb [r0+0x0], r2                       
lbb_1264:
    stxdw [r6+0x20], r9                     
    stxdw [r6+0x18], r3                     
    mov64 r2, 1                                     r2 = 1 as i32 as i64 as u64
    stxdw [r6+0x8], r2                      
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
    stxdw [r6+0x10], r2                     
    ldxdw r9, [r6+0x0]                      
    stxdw [r6+0x0], r2                      
    lddw r2, 0x8000000000000000                     r2 load str located at -9223372036854775808
    jeq r9, r2, lbb_1257                            if r9 == r2 { pc += -18 }
    mov64 r1, r10                                   r1 = r10
    add64 r1, -24                                   r1 += -24   ///  r1 = r1.wrapping_add(-24 as i32 as i64 as u64)
    mov64 r6, r0                                    r6 = r0
    mov64 r2, r0                                    r2 = r0
    mov64 r3, r7                                    r3 = r7
    call function_28437                     
    ldxdw r1, [r10-0x18]                    
    jeq r1, 0, lbb_1314                             if r1 == (0 as i32 as i64 as u64) { pc += 31 }
    lddw r1, 0x300000000                            r1 load str located at 12884901888
    ldxdw r2, [r1+0x0]                      
    mov64 r4, r2                                    r4 = r2
    add64 r4, -24                                   r4 += -24   ///  r4 = r4.wrapping_add(-24 as i32 as i64 as u64)
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
    mov64 r5, 1                                     r5 = 1 as i32 as i64 as u64
    mov64 r1, r8                                    r1 = r8
    jgt r4, r2, lbb_1293                            if r4 > r2 { pc += 1 }
    mov64 r5, 0                                     r5 = 0 as i32 as i64 as u64
lbb_1293:
    jne r5, 0, lbb_1295                             if r5 != (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r3, r4                                    r3 = r4
lbb_1295:
    lddw r0, 0x300007fe8                            r0 load str located at 12884934632
    jeq r2, 0, lbb_1300                             if r2 == (0 as i32 as i64 as u64) { pc += 2 }
    and64 r3, -8                                    r3 &= -8   ///  r3 = r3.and(-8)
    mov64 r0, r3                                    r0 = r3
lbb_1300:
    lddw r2, 0x300000007                            r2 load str located at 12884901895
    jgt r0, r2, lbb_1304                            if r0 > r2 { pc += 1 }
    ja lbb_1145                                     if true { pc += -159 }
lbb_1304:
    ldxdw r2, [r10-0x8]                     
    ldxdw r3, [r10-0x10]                    
    lddw r4, 0x300000000                            r4 load str located at 12884901888
    stxdw [r4+0x0], r0                      
    stxdw [r0+0x10], r2                     
    stxdw [r0+0x8], r3                      
    lddw r2, 0x8000000000000001                     r2 load str located at -9223372036854775807
    ja lbb_1193                                     if true { pc += -121 }
lbb_1314:
    stxdw [r8+0x10], r7                     
    stxdw [r8+0x8], r6                      
    stxdw [r8+0x0], r9                      
    ja lbb_1261                                     if true { pc += -57 }

function_1318:
    ldxdw r3, [r2+0x8]                      
    jne r3, 0, lbb_1323                             if r3 != (0 as i32 as i64 as u64) { pc += 3 }
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
    stxb [r1+0x1], r2                       
    ja lbb_1379                                     if true { pc += 56 }
lbb_1323:
    add64 r3, -1                                    r3 += -1   ///  r3 = r3.wrapping_add(-1 as i32 as i64 as u64)
    stxdw [r2+0x8], r3                      
    ldxdw r2, [r2+0x0]                      
    ldxdw r3, [r2+0x28]                     
    jne r3, 0, lbb_1350                             if r3 != (0 as i32 as i64 as u64) { pc += 22 }
    lddw r2, 0x300000000                            r2 load str located at 12884901888
    ldxdw r2, [r2+0x0]                      
    mov64 r4, r2                                    r4 = r2
    add64 r4, -24                                   r4 += -24   ///  r4 = r4.wrapping_add(-24 as i32 as i64 as u64)
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
    mov64 r5, 1                                     r5 = 1 as i32 as i64 as u64
    jgt r4, r2, lbb_1337                            if r4 > r2 { pc += 1 }
    mov64 r5, 0                                     r5 = 0 as i32 as i64 as u64
lbb_1337:
    jne r5, 0, lbb_1339                             if r5 != (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r3, r4                                    r3 = r4
lbb_1339:
    lddw r0, 0x300007fe8                            r0 load str located at 12884934632
    jeq r2, 0, lbb_1344                             if r2 == (0 as i32 as i64 as u64) { pc += 2 }
    and64 r3, -8                                    r3 &= -8   ///  r3 = r3.and(-8)
    mov64 r0, r3                                    r0 = r3
lbb_1344:
    lddw r2, 0x300000007                            r2 load str located at 12884901895
    jgt r0, r2, lbb_1365                            if r0 > r2 { pc += 18 }
    mov64 r1, 8                                     r1 = 8 as i32 as i64 as u64
    mov64 r2, 24                                    r2 = 24 as i32 as i64 as u64
    call function_21552                     
lbb_1350:
    add64 r3, -1                                    r3 += -1   ///  r3 = r3.wrapping_add(-1 as i32 as i64 as u64)
    stxdw [r2+0x28], r3                     
    ldxdw r3, [r2+0x20]                     
    jeq r3, 0, lbb_1372                             if r3 == (0 as i32 as i64 as u64) { pc += 18 }
    add64 r3, -1                                    r3 += -1   ///  r3 = r3.wrapping_add(-1 as i32 as i64 as u64)
    ldxdw r4, [r2+0x18]                     
    ldxb r5, [r4+0x0]                       
    stxdw [r2+0x20], r3                     
    add64 r4, 1                                     r4 += 1   ///  r4 = r4.wrapping_add(1 as i32 as i64 as u64)
    stxdw [r2+0x18], r4                     
    stxb [r1+0x2], r5                       
    mov64 r2, 1                                     r2 = 1 as i32 as i64 as u64
    stxb [r1+0x1], r2                       
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
    ja lbb_1379                                     if true { pc += 14 }
lbb_1365:
    lddw r2, 0x300000000                            r2 load str located at 12884901888
    stxdw [r2+0x0], r0                      
    lddw r2, 0x8000000000000006                     r2 load str located at -9223372036854775802
    stxdw [r0+0x0], r2                      
    ja lbb_1377                                     if true { pc += 5 }
lbb_1372:
    mov64 r6, r1                                    r6 = r1
    lddw r1, 0x100040d80 --> b"\x00\x00\x00\x00\x99\xe5\x03\x00\x1b\x00\x00\x00\x00\x00\x00\x00%\x00\x00…        r1 load str located at 4295232896
    call function_19497                     
    mov64 r1, r6                                    r1 = r6
lbb_1377:
    stxdw [r1+0x8], r0                      
    mov64 r2, 1                                     r2 = 1 as i32 as i64 as u64
lbb_1379:
    stxb [r1+0x0], r2                       
    exit                                    

function_1381:
    mov64 r7, r1                                    r7 = r1
    ldxdw r1, [r2+0x0]                      
    stxdw [r10-0x10], r2                    
    ldxdw r6, [r2+0x8]                      
    mov64 r2, 32                                    r2 = 32 as i32 as i64 as u64
    mov64 r9, r6                                    r9 = r6
    jgt r2, r6, lbb_1389                            if r2 > r6 { pc += 1 }
    mov64 r9, 32                                    r9 = 32 as i32 as i64 as u64
lbb_1389:
    stxdw [r10-0x8], r1                     
    ldxdw r1, [r10-0x8]                     
    mov64 r2, r7                                    r2 = r7
    mov64 r3, r9                                    r3 = r9
    call function_30349                     
    ldxdw r1, [r10-0x8]                     
    add64 r1, r9                                    r1 += r9   ///  r1 = r1.wrapping_add(r9)
    stxdw [r10-0x8], r1                     
    mov64 r8, r6                                    r8 = r6
    sub64 r8, r9                                    r8 -= r9   ///  r8 = r8.wrapping_sub(r9)
    ldxdw r1, [r10-0x10]                    
    stxdw [r1+0x8], r8                      
    ldxdw r2, [r10-0x8]                     
    stxdw [r1+0x0], r2                      
    lddw r0, 0x100040d98 --> b"\x00\x00\x00\x00\xb4\xe5\x03\x00\x1c\x00\x00\x00\x00\x00\x00\x00\x17\x00\…        r0 load str located at 4295232920
    mov64 r1, 32                                    r1 = 32 as i32 as i64 as u64
    jgt r1, r6, lbb_1591                            if r1 > r6 { pc += 184 }
    stxdw [r10-0x18], r7                    
    mov64 r2, r7                                    r2 = r7
    add64 r2, 32                                    r2 += 32   ///  r2 = r2.wrapping_add(32 as i32 as i64 as u64)
    mov64 r7, 32                                    r7 = 32 as i32 as i64 as u64
    mov64 r9, r8                                    r9 = r8
    jgt r7, r8, lbb_1414                            if r7 > r8 { pc += 1 }
    mov64 r9, 32                                    r9 = 32 as i32 as i64 as u64
lbb_1414:
    ldxdw r1, [r10-0x8]                     
    mov64 r3, r9                                    r3 = r9
    call function_30349                     
    ldxdw r1, [r10-0x8]                     
    add64 r1, r9                                    r1 += r9   ///  r1 = r1.wrapping_add(r9)
    stxdw [r10-0x8], r1                     
    mov64 r6, r8                                    r6 = r8
    sub64 r6, r9                                    r6 -= r9   ///  r6 = r6.wrapping_sub(r9)
    ldxdw r1, [r10-0x10]                    
    stxdw [r1+0x8], r6                      
    ldxdw r2, [r10-0x8]                     
    stxdw [r1+0x0], r2                      
    ldxdw r2, [r10-0x18]                    
    lddw r0, 0x100040d98 --> b"\x00\x00\x00\x00\xb4\xe5\x03\x00\x1c\x00\x00\x00\x00\x00\x00\x00\x17\x00\…        r0 load str located at 4295232920
    jgt r7, r8, lbb_1591                            if r7 > r8 { pc += 161 }
    add64 r2, 64                                    r2 += 64   ///  r2 = r2.wrapping_add(64 as i32 as i64 as u64)
    mov64 r9, r6                                    r9 = r6
    jgt r7, r6, lbb_1434                            if r7 > r6 { pc += 1 }
    mov64 r9, 32                                    r9 = 32 as i32 as i64 as u64
lbb_1434:
    ldxdw r1, [r10-0x8]                     
    mov64 r3, r9                                    r3 = r9
    call function_30349                     
    ldxdw r1, [r10-0x8]                     
    add64 r1, r9                                    r1 += r9   ///  r1 = r1.wrapping_add(r9)
    stxdw [r10-0x8], r1                     
    mov64 r8, r6                                    r8 = r6
    sub64 r8, r9                                    r8 -= r9   ///  r8 = r8.wrapping_sub(r9)
    ldxdw r1, [r10-0x10]                    
    stxdw [r1+0x8], r8                      
    ldxdw r2, [r10-0x8]                     
    stxdw [r1+0x0], r2                      
    ldxdw r2, [r10-0x18]                    
    lddw r0, 0x100040d98 --> b"\x00\x00\x00\x00\xb4\xe5\x03\x00\x1c\x00\x00\x00\x00\x00\x00\x00\x17\x00\…        r0 load str located at 4295232920
    jgt r7, r6, lbb_1591                            if r7 > r6 { pc += 141 }
    add64 r2, 96                                    r2 += 96   ///  r2 = r2.wrapping_add(96 as i32 as i64 as u64)
    mov64 r9, r8                                    r9 = r8
    jgt r7, r8, lbb_1454                            if r7 > r8 { pc += 1 }
    mov64 r9, 32                                    r9 = 32 as i32 as i64 as u64
lbb_1454:
    ldxdw r1, [r10-0x8]                     
    mov64 r3, r9                                    r3 = r9
    call function_30349                     
    ldxdw r1, [r10-0x8]                     
    add64 r1, r9                                    r1 += r9   ///  r1 = r1.wrapping_add(r9)
    stxdw [r10-0x8], r1                     
    mov64 r6, r8                                    r6 = r8
    sub64 r6, r9                                    r6 -= r9   ///  r6 = r6.wrapping_sub(r9)
    ldxdw r1, [r10-0x10]                    
    stxdw [r1+0x8], r6                      
    ldxdw r2, [r10-0x8]                     
    stxdw [r1+0x0], r2                      
    ldxdw r2, [r10-0x18]                    
    lddw r0, 0x100040d98 --> b"\x00\x00\x00\x00\xb4\xe5\x03\x00\x1c\x00\x00\x00\x00\x00\x00\x00\x17\x00\…        r0 load str located at 4295232920
    jgt r7, r8, lbb_1591                            if r7 > r8 { pc += 121 }
    add64 r2, 128                                   r2 += 128   ///  r2 = r2.wrapping_add(128 as i32 as i64 as u64)
    mov64 r9, r6                                    r9 = r6
    jgt r7, r6, lbb_1474                            if r7 > r6 { pc += 1 }
    mov64 r9, 32                                    r9 = 32 as i32 as i64 as u64
lbb_1474:
    ldxdw r1, [r10-0x8]                     
    mov64 r3, r9                                    r3 = r9
    call function_30349                     
    ldxdw r1, [r10-0x8]                     
    add64 r1, r9                                    r1 += r9   ///  r1 = r1.wrapping_add(r9)
    stxdw [r10-0x8], r1                     
    mov64 r8, r6                                    r8 = r6
    sub64 r8, r9                                    r8 -= r9   ///  r8 = r8.wrapping_sub(r9)
    ldxdw r1, [r10-0x10]                    
    stxdw [r1+0x8], r8                      
    ldxdw r2, [r10-0x8]                     
    stxdw [r1+0x0], r2                      
    ldxdw r2, [r10-0x18]                    
    lddw r0, 0x100040d98 --> b"\x00\x00\x00\x00\xb4\xe5\x03\x00\x1c\x00\x00\x00\x00\x00\x00\x00\x17\x00\…        r0 load str located at 4295232920
    jgt r7, r6, lbb_1591                            if r7 > r6 { pc += 101 }
    add64 r2, 160                                   r2 += 160   ///  r2 = r2.wrapping_add(160 as i32 as i64 as u64)
    mov64 r9, r8                                    r9 = r8
    jgt r7, r8, lbb_1494                            if r7 > r8 { pc += 1 }
    mov64 r9, 32                                    r9 = 32 as i32 as i64 as u64
lbb_1494:
    ldxdw r1, [r10-0x8]                     
    mov64 r3, r9                                    r3 = r9
    call function_30349                     
    ldxdw r1, [r10-0x8]                     
    add64 r1, r9                                    r1 += r9   ///  r1 = r1.wrapping_add(r9)
    stxdw [r10-0x8], r1                     
    mov64 r6, r8                                    r6 = r8
    sub64 r6, r9                                    r6 -= r9   ///  r6 = r6.wrapping_sub(r9)
    ldxdw r1, [r10-0x10]                    
    stxdw [r1+0x8], r6                      
    ldxdw r2, [r10-0x8]                     
    stxdw [r1+0x0], r2                      
    ldxdw r2, [r10-0x18]                    
    lddw r0, 0x100040d98 --> b"\x00\x00\x00\x00\xb4\xe5\x03\x00\x1c\x00\x00\x00\x00\x00\x00\x00\x17\x00\…        r0 load str located at 4295232920
    jgt r7, r8, lbb_1591                            if r7 > r8 { pc += 81 }
    add64 r2, 192                                   r2 += 192   ///  r2 = r2.wrapping_add(192 as i32 as i64 as u64)
    mov64 r9, r6                                    r9 = r6
    jgt r7, r6, lbb_1514                            if r7 > r6 { pc += 1 }
    mov64 r9, 32                                    r9 = 32 as i32 as i64 as u64
lbb_1514:
    ldxdw r1, [r10-0x8]                     
    mov64 r3, r9                                    r3 = r9
    call function_30349                     
    ldxdw r1, [r10-0x8]                     
    add64 r1, r9                                    r1 += r9   ///  r1 = r1.wrapping_add(r9)
    stxdw [r10-0x8], r1                     
    mov64 r8, r6                                    r8 = r6
    sub64 r8, r9                                    r8 -= r9   ///  r8 = r8.wrapping_sub(r9)
    ldxdw r1, [r10-0x10]                    
    stxdw [r1+0x8], r8                      
    ldxdw r2, [r10-0x8]                     
    stxdw [r1+0x0], r2                      
    ldxdw r2, [r10-0x18]                    
    lddw r0, 0x100040d98 --> b"\x00\x00\x00\x00\xb4\xe5\x03\x00\x1c\x00\x00\x00\x00\x00\x00\x00\x17\x00\…        r0 load str located at 4295232920
    jgt r7, r6, lbb_1591                            if r7 > r6 { pc += 61 }
    add64 r2, 224                                   r2 += 224   ///  r2 = r2.wrapping_add(224 as i32 as i64 as u64)
    mov64 r9, r8                                    r9 = r8
    jgt r7, r8, lbb_1534                            if r7 > r8 { pc += 1 }
    mov64 r9, 32                                    r9 = 32 as i32 as i64 as u64
lbb_1534:
    ldxdw r1, [r10-0x8]                     
    mov64 r3, r9                                    r3 = r9
    call function_30349                     
    ldxdw r1, [r10-0x8]                     
    add64 r1, r9                                    r1 += r9   ///  r1 = r1.wrapping_add(r9)
    stxdw [r10-0x8], r1                     
    mov64 r6, r8                                    r6 = r8
    sub64 r6, r9                                    r6 -= r9   ///  r6 = r6.wrapping_sub(r9)
    ldxdw r1, [r10-0x10]                    
    stxdw [r1+0x8], r6                      
    ldxdw r2, [r10-0x8]                     
    stxdw [r1+0x0], r2                      
    ldxdw r2, [r10-0x18]                    
    lddw r0, 0x100040d98 --> b"\x00\x00\x00\x00\xb4\xe5\x03\x00\x1c\x00\x00\x00\x00\x00\x00\x00\x17\x00\…        r0 load str located at 4295232920
    jgt r7, r8, lbb_1591                            if r7 > r8 { pc += 41 }
    add64 r2, 256                                   r2 += 256   ///  r2 = r2.wrapping_add(256 as i32 as i64 as u64)
    mov64 r1, 32                                    r1 = 32 as i32 as i64 as u64
    mov64 r9, r6                                    r9 = r6
    jgt r1, r6, lbb_1555                            if r1 > r6 { pc += 1 }
    mov64 r9, 32                                    r9 = 32 as i32 as i64 as u64
lbb_1555:
    ldxdw r1, [r10-0x8]                     
    mov64 r3, r9                                    r3 = r9
    call function_30349                     
    ldxdw r1, [r10-0x8]                     
    add64 r1, r9                                    r1 += r9   ///  r1 = r1.wrapping_add(r9)
    stxdw [r10-0x8], r1                     
    mov64 r8, r6                                    r8 = r6
    sub64 r8, r9                                    r8 -= r9   ///  r8 = r8.wrapping_sub(r9)
    ldxdw r1, [r10-0x10]                    
    stxdw [r1+0x8], r8                      
    ldxdw r2, [r10-0x8]                     
    stxdw [r1+0x0], r2                      
    ldxdw r7, [r10-0x8]                     
    ldxdw r2, [r10-0x18]                    
    lddw r0, 0x100040d98 --> b"\x00\x00\x00\x00\xb4\xe5\x03\x00\x1c\x00\x00\x00\x00\x00\x00\x00\x17\x00\…        r0 load str located at 4295232920
    mov64 r1, 32                                    r1 = 32 as i32 as i64 as u64
    jgt r1, r6, lbb_1591                            if r1 > r6 { pc += 18 }
    add64 r2, 288                                   r2 += 288   ///  r2 = r2.wrapping_add(288 as i32 as i64 as u64)
    mov64 r6, 32                                    r6 = 32 as i32 as i64 as u64
    mov64 r9, r8                                    r9 = r8
    jgt r6, r8, lbb_1578                            if r6 > r8 { pc += 1 }
    mov64 r9, 32                                    r9 = 32 as i32 as i64 as u64
lbb_1578:
    mov64 r1, r7                                    r1 = r7
    mov64 r3, r9                                    r3 = r9
    call function_30349                     
    mov64 r1, r8                                    r1 = r8
    sub64 r1, r9                                    r1 -= r9   ///  r1 = r1.wrapping_sub(r9)
    ldxdw r2, [r10-0x10]                    
    stxdw [r2+0x8], r1                      
    add64 r7, r9                                    r7 += r9   ///  r7 = r7.wrapping_add(r9)
    stxdw [r2+0x0], r7                      
    lddw r0, 0x100040d98 --> b"\x00\x00\x00\x00\xb4\xe5\x03\x00\x1c\x00\x00\x00\x00\x00\x00\x00\x17\x00\…        r0 load str located at 4295232920
    jgt r6, r8, lbb_1591                            if r6 > r8 { pc += 1 }
    mov64 r0, 0                                     r0 = 0 as i32 as i64 as u64
lbb_1591:
    exit                                    

function_1592:
    mov64 r6, r1                                    r6 = r1
    ldxdw r3, [r2+0x8]                      
    mov64 r5, 32                                    r5 = 32 as i32 as i64 as u64
    jgt r5, r3, lbb_1952                            if r5 > r3 { pc += 356 }
    ldxdw r1, [r2+0x0]                      
    mov64 r8, r3                                    r8 = r3
    add64 r8, -32                                   r8 += -32   ///  r8 = r8.wrapping_add(-32 as i32 as i64 as u64)
    stxdw [r2+0x8], r8                      
    mov64 r7, r1                                    r7 = r1
    add64 r7, 32                                    r7 += 32   ///  r7 = r7.wrapping_add(32 as i32 as i64 as u64)
    stxdw [r2+0x0], r7                      
    ldxdw r0, [r1+0x6]                      
    ldxb r4, [r1+0xe]                       
    stxb [r10-0x18], r4                     
    stxdw [r10-0x70], r0                    
    stxdw [r10-0x20], r0                    
    ldxdw r4, [r10-0x1f]                    
    stxdw [r10-0x78], r4                    
    ldxw r4, [r1+0x0]                       
    stxw [r10-0x28], r4                     
    ldxh r4, [r1+0x4]                       
    stxh [r10-0x24], r4                     
    ldxdw r4, [r1+0xf]                      
    stxdw [r10-0x40], r4                    
    ldxdw r4, [r1+0x17]                     
    stxdw [r10-0x38], r4                    
    ldxb r4, [r1+0x1f]                      
    stxb [r10-0x30], r4                     
    jgt r5, r8, lbb_1952                            if r5 > r8 { pc += 331 }
    mov64 r8, r3                                    r8 = r3
    add64 r8, -64                                   r8 += -64   ///  r8 = r8.wrapping_add(-64 as i32 as i64 as u64)
    stxdw [r2+0x8], r8                      
    mov64 r9, r1                                    r9 = r1
    add64 r9, 64                                    r9 += 64   ///  r9 = r9.wrapping_add(64 as i32 as i64 as u64)
    stxdw [r2+0x0], r9                      
    ldxdw r5, [r1+0x26]                     
    ldxb r4, [r1+0x2e]                      
    stxb [r10-0x18], r4                     
    stxdw [r10-0x20], r5                    
    ldxdw r4, [r10-0x1f]                    
    stxdw [r10-0x80], r4                    
    ldxw r4, [r7+0x0]                       
    stxw [r10-0x48], r4                     
    ldxh r4, [r7+0x4]                       
    stxh [r10-0x44], r4                     
    ldxdw r4, [r1+0x2f]                     
    stxdw [r10-0x60], r4                    
    ldxdw r4, [r1+0x37]                     
    stxdw [r10-0x58], r4                    
    ldxb r4, [r1+0x3f]                      
    stxb [r10-0x50], r4                     
    mov64 r4, 32                                    r4 = 32 as i32 as i64 as u64
    jgt r4, r8, lbb_1952                            if r4 > r8 { pc += 307 }
    mov64 r0, r3                                    r0 = r3
    add64 r0, -96                                   r0 += -96   ///  r0 = r0.wrapping_add(-96 as i32 as i64 as u64)
    stxdw [r2+0x8], r0                      
    mov64 r7, r1                                    r7 = r1
    add64 r7, 96                                    r7 += 96   ///  r7 = r7.wrapping_add(96 as i32 as i64 as u64)
    stxdw [r10-0x90], r7                    
    stxdw [r2+0x0], r7                      
    mov64 r7, r5                                    r7 = r5
    ldxdw r5, [r1+0x46]                     
    ldxb r8, [r1+0x4e]                      
    stxb [r10-0x18], r8                     
    stxdw [r10-0x88], r5                    
    stxdw [r10-0x20], r5                    
    mov64 r5, r7                                    r5 = r7
    ldxdw r7, [r10-0x1f]                    
    ldxw r8, [r9+0x0]                       
    stxw [r10-0x68], r8                     
    ldxh r8, [r9+0x4]                       
    stxh [r10-0x64], r8                     
    jgt r4, r0, lbb_1952                            if r4 > r0 { pc += 287 }
    mov64 r0, r3                                    r0 = r3
    add64 r0, -128                                  r0 += -128   ///  r0 = r0.wrapping_add(-128 as i32 as i64 as u64)
    stxdw [r2+0x8], r0                      
    mov64 r9, r1                                    r9 = r1
    add64 r9, 128                                   r9 += 128   ///  r9 = r9.wrapping_add(128 as i32 as i64 as u64)
    stxdw [r2+0x0], r9                      
    ldxdw r8, [r1+0x66]                     
    ldxb r4, [r1+0x6e]                      
    stxb [r10-0x18], r4                     
    stxdw [r10-0x98], r8                    
    stxdw [r10-0x20], r8                    
    mov64 r4, 32                                    r4 = 32 as i32 as i64 as u64
    jgt r4, r0, lbb_1952                            if r4 > r0 { pc += 274 }
    ldxdw r0, [r10-0x1f]                    
    stxdw [r10-0xa8], r0                    
    mov64 r0, r3                                    r0 = r3
    add64 r0, -160                                  r0 += -160   ///  r0 = r0.wrapping_add(-160 as i32 as i64 as u64)
    stxdw [r2+0x8], r0                      
    mov64 r8, r1                                    r8 = r1
    add64 r8, 160                                   r8 += 160   ///  r8 = r8.wrapping_add(160 as i32 as i64 as u64)
    stxdw [r10-0xa0], r8                    
    stxdw [r2+0x0], r8                      
    mov64 r4, r9                                    r4 = r9
    stxdw [r10-0xb8], r5                    
    mov64 r5, r7                                    r5 = r7
    ldxdw r7, [r1+0x86]                     
    ldxb r8, [r1+0x8e]                      
    stxb [r10-0x18], r8                     
    stxdw [r10-0xb0], r7                    
    stxdw [r10-0x20], r7                    
    mov64 r4, 32                                    r4 = 32 as i32 as i64 as u64
    jgt r4, r0, lbb_1952                            if r4 > r0 { pc += 255 }
    ldxdw r4, [r10-0x1f]                    
    stxdw [r10-0xc8], r4                    
    mov64 r0, r3                                    r0 = r3
    add64 r0, -192                                  r0 += -192   ///  r0 = r0.wrapping_add(-192 as i32 as i64 as u64)
    stxdw [r2+0x8], r0                      
    mov64 r4, r1                                    r4 = r1
    add64 r4, 192                                   r4 += 192   ///  r4 = r4.wrapping_add(192 as i32 as i64 as u64)
    stxdw [r10-0xc0], r4                    
    stxdw [r2+0x0], r4                      
    ldxdw r8, [r1+0xa6]                     
    ldxb r4, [r1+0xae]                      
    stxb [r10-0x18], r4                     
    stxdw [r10-0xd0], r8                    
    stxdw [r10-0x20], r8                    
    mov64 r4, 32                                    r4 = 32 as i32 as i64 as u64
    jgt r4, r0, lbb_1952                            if r4 > r0 { pc += 239 }
    ldxdw r0, [r10-0x1f]                    
    stxdw [r10-0xe0], r0                    
    mov64 r0, r3                                    r0 = r3
    add64 r0, -224                                  r0 += -224   ///  r0 = r0.wrapping_add(-224 as i32 as i64 as u64)
    stxdw [r2+0x8], r0                      
    mov64 r8, r1                                    r8 = r1
    add64 r8, 224                                   r8 += 224   ///  r8 = r8.wrapping_add(224 as i32 as i64 as u64)
    stxdw [r10-0xd8], r8                    
    stxdw [r2+0x0], r8                      
    stxdw [r10-0xf8], r5                    
    stxdw [r10-0xf0], r9                    
    ldxdw r9, [r1+0xc6]                     
    ldxb r8, [r1+0xce]                      
    stxb [r10-0x18], r8                     
    stxdw [r10-0xe8], r9                    
    stxdw [r10-0x20], r9                    
    jgt r4, r0, lbb_1952                            if r4 > r0 { pc += 222 }
    ldxdw r8, [r10-0x1f]                    
    mov64 r0, r3                                    r0 = r3
    add64 r0, -256                                  r0 += -256   ///  r0 = r0.wrapping_add(-256 as i32 as i64 as u64)
    stxdw [r2+0x8], r0                      
    mov64 r5, r1                                    r5 = r1
    add64 r5, 256                                   r5 += 256   ///  r5 = r5.wrapping_add(256 as i32 as i64 as u64)
    stxdw [r2+0x0], r5                      
    ldxdw r9, [r1+0xe6]                     
    ldxb r4, [r1+0xee]                      
    stxb [r10-0x18], r4                     
    stxdw [r10-0x20], r9                    
    mov64 r4, 32                                    r4 = 32 as i32 as i64 as u64
    jgt r4, r0, lbb_1952                            if r4 > r0 { pc += 209 }
    ldxdw r0, [r10-0x1f]                    
    stxdw [r10-0x100], r0                   
    mov64 r0, r3                                    r0 = r3
    add64 r0, -288                                  r0 += -288   ///  r0 = r0.wrapping_add(-288 as i32 as i64 as u64)
    stxdw [r2+0x8], r0                      
    mov64 r4, r1                                    r4 = r1
    add64 r4, 288                                   r4 += 288   ///  r4 = r4.wrapping_add(288 as i32 as i64 as u64)
    stxdw [r10-0x110], r4                   
    stxdw [r2+0x0], r4                      
    mov64 r4, r5                                    r4 = r5
    ldxdw r5, [r1+0x106]                    
    mov64 r7, r8                                    r7 = r8
    ldxb r8, [r1+0x10e]                     
    stxb [r10-0x18], r8                     
    mov64 r8, r7                                    r8 = r7
    mov64 r7, r9                                    r7 = r9
    stxdw [r10-0x108], r5                   
    stxdw [r10-0x20], r5                    
    mov64 r5, 32                                    r5 = 32 as i32 as i64 as u64
    jgt r5, r0, lbb_1952                            if r5 > r0 { pc += 189 }
    mov64 r5, r1                                    r5 = r1
    add64 r5, 79                                    r5 += 79   ///  r5 = r5.wrapping_add(79 as i32 as i64 as u64)
    mov64 r9, r1                                    r9 = r1
    add64 r9, 111                                   r9 += 111   ///  r9 = r9.wrapping_add(111 as i32 as i64 as u64)
    mov64 r0, r1                                    r0 = r1
    add64 r0, 143                                   r0 += 143   ///  r0 = r0.wrapping_add(143 as i32 as i64 as u64)
    stxdw [r10-0x138], r0                   
    stxdw [r10-0x128], r8                   
    mov64 r8, r1                                    r8 = r1
    add64 r8, 175                                   r8 += 175   ///  r8 = r8.wrapping_add(175 as i32 as i64 as u64)
    stxdw [r10-0x120], r7                   
    mov64 r7, r1                                    r7 = r1
    add64 r7, 207                                   r7 += 207   ///  r7 = r7.wrapping_add(207 as i32 as i64 as u64)
    stxdw [r10-0x130], r4                   
    mov64 r4, r1                                    r4 = r1
    add64 r4, 239                                   r4 += 239   ///  r4 = r4.wrapping_add(239 as i32 as i64 as u64)
    ldxdw r0, [r10-0x1f]                    
    stxdw [r10-0x118], r0                   
    add64 r3, -320                                  r3 += -320   ///  r3 = r3.wrapping_add(-320 as i32 as i64 as u64)
    stxdw [r2+0x8], r3                      
    mov64 r3, r1                                    r3 = r1
    add64 r3, 320                                   r3 += 320   ///  r3 = r3.wrapping_add(320 as i32 as i64 as u64)
    stxdw [r2+0x0], r3                      
    ldxdw r0, [r1+0x126]                    
    ldxb r3, [r1+0x12e]                     
    stxb [r10-0x18], r3                     
    stxdw [r10-0x20], r0                    
    ldxdw r2, [r10-0x1f]                    
    stxdw [r10-0x140], r2                   
    ldxdw r2, [r10-0x110]                   
    ldxh r3, [r2+0x4]                       
    stxh [r10-0x4], r3                      
    ldxw r3, [r2+0x0]                       
    stxw [r10-0x8], r3                      
    ldxb r3, [r1+0x13f]                     
    stxb [r10-0x10], r3                     
    ldxdw r3, [r1+0x137]                    
    stxdw [r10-0x18], r3                    
    ldxdw r3, [r1+0x12f]                    
    stxdw [r10-0x20], r3                    
    ldxb r3, [r10-0x30]                     
    stxb [r6+0x20], r3                      
    ldxdw r3, [r10-0x38]                    
    stxdw [r6+0x18], r3                     
    ldxdw r3, [r10-0x40]                    
    stxdw [r6+0x10], r3                     
    ldxb r3, [r10-0x50]                     
    stxb [r6+0x40], r3                      
    ldxdw r3, [r10-0x58]                    
    stxdw [r6+0x38], r3                     
    ldxdw r3, [r10-0x60]                    
    stxdw [r6+0x30], r3                     
    ldxb r3, [r5+0x10]                      
    stxb [r6+0x60], r3                      
    ldxdw r3, [r5+0x8]                      
    stxdw [r6+0x58], r3                     
    ldxdw r3, [r5+0x0]                      
    stxdw [r6+0x50], r3                     
    ldxb r3, [r9+0x10]                      
    stxb [r6+0x80], r3                      
    ldxdw r3, [r9+0x8]                      
    stxdw [r6+0x78], r3                     
    ldxdw r3, [r9+0x0]                      
    stxdw [r6+0x70], r3                     
    ldxdw r5, [r10-0x138]                   
    ldxb r3, [r5+0x10]                      
    stxb [r6+0xa0], r3                      
    ldxdw r3, [r5+0x8]                      
    stxdw [r6+0x98], r3                     
    ldxdw r3, [r5+0x0]                      
    stxdw [r6+0x90], r3                     
    ldxdw r3, [r8+0x0]                      
    stxdw [r6+0xb0], r3                     
    ldxdw r3, [r8+0x8]                      
    stxdw [r6+0xb8], r3                     
    ldxb r3, [r8+0x10]                      
    stxb [r6+0xc0], r3                      
    ldxdw r3, [r7+0x0]                      
    stxdw [r6+0xd0], r3                     
    ldxdw r3, [r7+0x8]                      
    stxdw [r6+0xd8], r3                     
    ldxb r3, [r7+0x10]                      
    stxb [r6+0xe0], r3                      
    ldxdw r3, [r4+0x0]                      
    stxdw [r6+0xf0], r3                     
    ldxdw r3, [r4+0x8]                      
    stxdw [r6+0xf8], r3                     
    ldxb r3, [r4+0x10]                      
    stxb [r6+0x100], r3                     
    ldxdw r3, [r1+0x10f]                    
    stxdw [r6+0x110], r3                    
    ldxdw r3, [r1+0x117]                    
    stxdw [r6+0x118], r3                    
    ldxb r1, [r1+0x11f]                     
    stxb [r6+0x120], r1                     
    ldxw r1, [r10-0x28]                     
    stxw [r6+0x1], r1                       
    ldxh r1, [r10-0x24]                     
    stxh [r6+0x5], r1                       
    ldxdw r1, [r10-0x78]                    
    stxdw [r6+0x8], r1                      
    ldxdw r1, [r10-0x70]                    
    stxb [r6+0x7], r1                       
    ldxw r1, [r10-0x48]                     
    stxw [r6+0x21], r1                      
    ldxh r1, [r10-0x44]                     
    stxh [r6+0x25], r1                      
    ldxdw r1, [r10-0xb8]                    
    stxb [r6+0x27], r1                      
    ldxdw r1, [r10-0x80]                    
    stxdw [r6+0x28], r1                     
    ldxh r1, [r10-0x64]                     
    stxh [r6+0x45], r1                      
    ldxw r1, [r10-0x68]                     
    stxw [r6+0x41], r1                      
    ldxdw r1, [r10-0xf8]                    
    stxdw [r6+0x48], r1                     
    ldxdw r1, [r10-0x88]                    
    stxb [r6+0x47], r1                      
    ldxdw r3, [r10-0x90]                    
    ldxh r1, [r3+0x4]                       
    stxh [r6+0x65], r1                      
    ldxw r1, [r3+0x0]                       
    stxw [r6+0x61], r1                      
    ldxdw r1, [r10-0xa8]                    
    stxdw [r6+0x68], r1                     
    ldxdw r1, [r10-0x98]                    
    stxb [r6+0x67], r1                      
    ldxdw r3, [r10-0xf0]                    
    ldxh r1, [r3+0x4]                       
    stxh [r6+0x85], r1                      
    ldxw r1, [r3+0x0]                       
    stxw [r6+0x81], r1                      
    ldxdw r1, [r10-0xc8]                    
    stxdw [r6+0x88], r1                     
    ldxdw r1, [r10-0xb0]                    
    stxb [r6+0x87], r1                      
    ldxdw r3, [r10-0xa0]                    
    ldxh r1, [r3+0x4]                       
    stxh [r6+0xa5], r1                      
    ldxw r1, [r3+0x0]                       
    stxw [r6+0xa1], r1                      
    ldxdw r1, [r10-0xe0]                    
    stxdw [r6+0xa8], r1                     
    ldxdw r1, [r10-0xd0]                    
    stxb [r6+0xa7], r1                      
    ldxdw r3, [r10-0xc0]                    
    ldxh r1, [r3+0x4]                       
    stxh [r6+0xc5], r1                      
    ldxw r1, [r3+0x0]                       
    stxw [r6+0xc1], r1                      
    ldxdw r1, [r10-0x128]                   
    stxdw [r6+0xc8], r1                     
    ldxdw r1, [r10-0xe8]                    
    stxb [r6+0xc7], r1                      
    ldxdw r3, [r10-0xd8]                    
    ldxh r1, [r3+0x4]                       
    stxh [r6+0xe5], r1                      
    ldxw r1, [r3+0x0]                       
    stxw [r6+0xe1], r1                      
    ldxdw r1, [r10-0x100]                   
    stxdw [r6+0xe8], r1                     
    ldxdw r1, [r10-0x120]                   
    stxb [r6+0xe7], r1                      
    ldxdw r3, [r10-0x130]                   
    ldxh r1, [r3+0x4]                       
    stxh [r6+0x105], r1                     
    ldxw r1, [r3+0x0]                       
    stxw [r6+0x101], r1                     
    ldxdw r1, [r10-0x118]                   
    stxdw [r6+0x108], r1                    
    ldxdw r1, [r10-0x108]                   
    stxb [r6+0x107], r1                     
    ldxh r1, [r10-0x4]                      
    stxh [r6+0x125], r1                     
    ldxw r1, [r10-0x8]                      
    stxw [r6+0x121], r1                     
    ldxdw r1, [r10-0x140]                   
    stxdw [r6+0x128], r1                    
    stxb [r6+0x127], r0                     
    ldxb r1, [r10-0x10]                     
    stxb [r6+0x140], r1                     
    ldxdw r1, [r10-0x18]                    
    stxdw [r6+0x138], r1                    
    ldxdw r1, [r10-0x20]                    
    stxdw [r6+0x130], r1                    
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    stxb [r6+0x0], r1                       
    ja lbb_1958                                     if true { pc += 6 }
lbb_1952:
    lddw r1, 0x100040d80 --> b"\x00\x00\x00\x00\x99\xe5\x03\x00\x1b\x00\x00\x00\x00\x00\x00\x00%\x00\x00…        r1 load str located at 4295232896
    call function_20446                     
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    stxb [r6+0x0], r1                       
    stxdw [r6+0x8], r0                      
lbb_1958:
    exit                                    

function_1959:
    mov64 r6, r1                                    r6 = r1
    ldxdw r1, [r2+0x8]                      
    mov64 r3, 64                                    r3 = 64 as i32 as i64 as u64
    jgt r3, r1, lbb_1983                            if r3 > r1 { pc += 20 }
    add64 r1, -64                                   r1 += -64   ///  r1 = r1.wrapping_add(-64 as i32 as i64 as u64)
    stxdw [r2+0x8], r1                      
    ldxdw r7, [r2+0x0]                      
    mov64 r1, r7                                    r1 = r7
    add64 r1, 64                                    r1 += 64   ///  r1 = r1.wrapping_add(64 as i32 as i64 as u64)
    stxdw [r2+0x0], r1                      
    ldxdw r8, [r7+0x6]                      
    mov64 r1, r6                                    r1 = r6
    add64 r1, 15                                    r1 += 15   ///  r1 = r1.wrapping_add(15 as i32 as i64 as u64)
    mov64 r2, r7                                    r2 = r7
    add64 r2, 14                                    r2 += 14   ///  r2 = r2.wrapping_add(14 as i32 as i64 as u64)
    mov64 r3, 50                                    r3 = 50 as i32 as i64 as u64
    call function_30349                     
    ldxh r1, [r7+0x4]                       
    ldxw r2, [r7+0x0]                       
    stxdw [r6+0x7], r8                      
    stxw [r6+0x1], r2                       
    stxh [r6+0x5], r1                       
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    ja lbb_1988                                     if true { pc += 5 }
lbb_1983:
    lddw r1, 0x100040d80 --> b"\x00\x00\x00\x00\x99\xe5\x03\x00\x1b\x00\x00\x00\x00\x00\x00\x00%\x00\x00…        r1 load str located at 4295232896
    call function_20446                     
    stxdw [r6+0x8], r0                      
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
lbb_1988:
    stxb [r6+0x0], r1                       
    exit                                    

function_1990:
    stxdw [r10-0x8], r1                     
    mov64 r4, r10                                   r4 = r10
    add64 r4, -8                                    r4 += -8   ///  r4 = r4.wrapping_add(-8 as i32 as i64 as u64)
    mov64 r1, r2                                    r1 = r2
    lddw r2, 0x10003e6a8 --> b"TryFromIntError"        r2 load str located at 4295222952
    mov64 r3, 15                                    r3 = 15 as i32 as i64 as u64
    lddw r5, 0x100040e68 --> b"\x00\x00\x00\x00\xc8\x0f\x00\x00\x08\x00\x00\x00\x00\x00\x00\x00\x08\x00\…        r5 load str located at 4295233128
    call function_27782                     
    exit                                    

function_2001:
    ldxdw r3, [r2+0x8]                      
    ldxdw r5, [r3+0x0]                      
    add64 r5, 1                                     r5 += 1   ///  r5 = r5.wrapping_add(1 as i32 as i64 as u64)
    mov64 r0, 1                                     r0 = 1 as i32 as i64 as u64
    jeq r5, 0, lbb_2007                             if r5 == (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r0, 0                                     r0 = 0 as i32 as i64 as u64
lbb_2007:
    ldxdw r4, [r2+0x0]                      
    stxdw [r3+0x0], r5                      
    jne r0, 1, lbb_2011                             if r0 != (1 as i32 as i64 as u64) { pc += 1 }
lbb_2010:
    syscall [invalid]                       
lbb_2011:
    ldxdw r5, [r2+0x10]                     
    ldxdw r0, [r5+0x0]                      
    add64 r0, 1                                     r0 += 1   ///  r0 = r0.wrapping_add(1 as i32 as i64 as u64)
    mov64 r6, 1                                     r6 = 1 as i32 as i64 as u64
    jeq r0, 0, lbb_2017                             if r0 == (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r6, 0                                     r6 = 0 as i32 as i64 as u64
lbb_2017:
    stxdw [r5+0x0], r0                      
    jne r6, 1, lbb_2020                             if r6 != (1 as i32 as i64 as u64) { pc += 1 }
    ja lbb_2010                                     if true { pc += -10 }
lbb_2020:
    ldxdw r0, [r2+0x18]                     
    ldxdw r6, [r2+0x20]                     
    ldxb r7, [r2+0x28]                      
    ldxb r8, [r2+0x29]                      
    ldxb r2, [r2+0x2a]                      
    stxb [r1+0x2a], r2                      
    stxb [r1+0x29], r8                      
    stxb [r1+0x28], r7                      
    stxdw [r1+0x20], r6                     
    stxdw [r1+0x18], r0                     
    stxdw [r1+0x10], r5                     
    stxdw [r1+0x8], r3                      
    stxdw [r1+0x0], r4                      
    exit                                    

function_2034:
    mov64 r3, r1                                    r3 = r1
    ldxdw r1, [r3+0x18]                     
    ldxdw r2, [r3+0x8]                      
    jeq r2, 1, lbb_2048                             if r2 == (1 as i32 as i64 as u64) { pc += 10 }
    jne r2, 0, lbb_2043                             if r2 != (0 as i32 as i64 as u64) { pc += 4 }
    mov64 r7, 0                                     r7 = 0 as i32 as i64 as u64
    mov64 r2, 1                                     r2 = 1 as i32 as i64 as u64
    mov64 r6, 1                                     r6 = 1 as i32 as i64 as u64
    jeq r1, 0, lbb_2081                             if r1 == (0 as i32 as i64 as u64) { pc += 38 }
lbb_2043:
    mov64 r1, r10                                   r1 = r10
    add64 r1, -24                                   r1 += -24   ///  r1 = r1.wrapping_add(-24 as i32 as i64 as u64)
    mov64 r2, r3                                    r2 = r3
    call function_21571                     
    ja lbb_2087                                     if true { pc += 39 }
lbb_2048:
    jeq r1, 0, lbb_2050                             if r1 == (0 as i32 as i64 as u64) { pc += 1 }
    ja lbb_2043                                     if true { pc += -7 }
lbb_2050:
    ldxdw r1, [r3+0x0]                      
    mov64 r6, 1                                     r6 = 1 as i32 as i64 as u64
    mov64 r7, 0                                     r7 = 0 as i32 as i64 as u64
    ldxdw r2, [r1+0x0]                      
    ldxdw r3, [r1+0x8]                      
    jeq r3, 0, lbb_2081                             if r3 == (0 as i32 as i64 as u64) { pc += 25 }
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    jsgt r1, r3, lbb_2119                           if (r1 as i64) > (r3 as i64) { pc += 61 }
    lddw r1, 0x300000000                            r1 load str located at 12884901888
    ldxdw r1, [r1+0x0]                      
    lddw r5, 0x300008000                            r5 load str located at 12884934656
    jeq r1, 0, lbb_2065                             if r1 == (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r5, r1                                    r5 = r1
lbb_2065:
    mov64 r4, r5                                    r4 = r5
    sub64 r4, r3                                    r4 -= r3   ///  r4 = r4.wrapping_sub(r3)
    mov64 r6, 0                                     r6 = 0 as i32 as i64 as u64
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    mov64 r0, 1                                     r0 = 1 as i32 as i64 as u64
    jgt r4, r5, lbb_2072                            if r4 > r5 { pc += 1 }
    mov64 r0, 0                                     r0 = 0 as i32 as i64 as u64
lbb_2072:
    jne r0, 0, lbb_2074                             if r0 != (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r6, r4                                    r6 = r4
lbb_2074:
    lddw r4, 0x300000008                            r4 load str located at 12884901896
    jgt r4, r6, lbb_2119                            if r4 > r6 { pc += 42 }
    lddw r1, 0x300000000                            r1 load str located at 12884901888
    stxdw [r1+0x0], r6                      
    mov64 r7, r3                                    r7 = r3
lbb_2081:
    mov64 r1, r6                                    r1 = r6
    mov64 r3, r7                                    r3 = r7
    call function_30349                     
    stxdw [r10-0x10], r6                    
    stxdw [r10-0x8], r7                     
    stxdw [r10-0x18], r7                    
lbb_2087:
    lddw r1, 0x300000000                            r1 load str located at 12884901888
    ldxdw r1, [r1+0x0]                      
    mov64 r3, r1                                    r3 = r1
    add64 r3, -24                                   r3 += -24   ///  r3 = r3.wrapping_add(-24 as i32 as i64 as u64)
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
    mov64 r4, 1                                     r4 = 1 as i32 as i64 as u64
    jgt r3, r1, lbb_2096                            if r3 > r1 { pc += 1 }
    mov64 r4, 0                                     r4 = 0 as i32 as i64 as u64
lbb_2096:
    jne r4, 0, lbb_2098                             if r4 != (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r2, r3                                    r2 = r3
lbb_2098:
    lddw r0, 0x300007fe8                            r0 load str located at 12884934632
    jeq r1, 0, lbb_2103                             if r1 == (0 as i32 as i64 as u64) { pc += 2 }
    and64 r2, -8                                    r2 &= -8   ///  r2 = r2.and(-8)
    mov64 r0, r2                                    r0 = r2
lbb_2103:
    lddw r1, 0x300000007                            r1 load str located at 12884901895
    jgt r0, r1, lbb_2109                            if r0 > r1 { pc += 3 }
    mov64 r1, 8                                     r1 = 8 as i32 as i64 as u64
    mov64 r2, 24                                    r2 = 24 as i32 as i64 as u64
    call function_21552                     
lbb_2109:
    lddw r1, 0x300000000                            r1 load str located at 12884901888
    stxdw [r1+0x0], r0                      
    ldxdw r1, [r10-0x8]                     
    stxdw [r0+0x10], r1                     
    ldxdw r1, [r10-0x10]                    
    stxdw [r0+0x8], r1                      
    ldxdw r1, [r10-0x18]                    
    stxdw [r0+0x0], r1                      
    exit                                    
lbb_2119:
    mov64 r2, r3                                    r2 = r3
    call function_21549                     

function_2121:
    mov64 r6, r1                                    r6 = r1
    stxdw [r10-0x1b8], r2                   
    ldxdw r1, [r2+0x28]                     
    jne r1, 0, lbb_2147                             if r1 != (0 as i32 as i64 as u64) { pc += 22 }
    lddw r1, 0x300000000                            r1 load str located at 12884901888
    ldxdw r1, [r1+0x0]                      
    mov64 r3, r1                                    r3 = r1
    add64 r3, -24                                   r3 += -24   ///  r3 = r3.wrapping_add(-24 as i32 as i64 as u64)
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
    mov64 r4, 1                                     r4 = 1 as i32 as i64 as u64
    jgt r3, r1, lbb_2134                            if r3 > r1 { pc += 1 }
    mov64 r4, 0                                     r4 = 0 as i32 as i64 as u64
lbb_2134:
    jne r4, 0, lbb_2136                             if r4 != (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r2, r3                                    r2 = r3
lbb_2136:
    lddw r0, 0x300007fe8                            r0 load str located at 12884934632
    jeq r1, 0, lbb_2141                             if r1 == (0 as i32 as i64 as u64) { pc += 2 }
    and64 r2, -8                                    r2 &= -8   ///  r2 = r2.and(-8)
    mov64 r0, r2                                    r0 = r2
lbb_2141:
    lddw r1, 0x300000007                            r1 load str located at 12884901895
    jgt r0, r1, lbb_2314                            if r0 > r1 { pc += 170 }
lbb_2144:
    mov64 r1, 8                                     r1 = 8 as i32 as i64 as u64
    mov64 r2, 24                                    r2 = 24 as i32 as i64 as u64
    call function_21552                     
lbb_2147:
    mov64 r5, r1                                    r5 = r1
    add64 r5, -1                                    r5 += -1   ///  r5 = r5.wrapping_add(-1 as i32 as i64 as u64)
    stxdw [r2+0x28], r5                     
    ldxdw r3, [r2+0x20]                     
    jeq r3, 0, lbb_2349                             if r3 == (0 as i32 as i64 as u64) { pc += 197 }
    ldxdw r4, [r2+0x18]                     
    ldxb r7, [r4+0x0]                       
    mov64 r0, r4                                    r0 = r4
    add64 r0, 1                                     r0 += 1   ///  r0 = r0.wrapping_add(1 as i32 as i64 as u64)
    stxdw [r2+0x18], r0                     
    mov64 r0, r3                                    r0 = r3
    add64 r0, -1                                    r0 += -1   ///  r0 = r0.wrapping_add(-1 as i32 as i64 as u64)
    stxdw [r2+0x20], r0                     
    jne r5, 0, lbb_2181                             if r5 != (0 as i32 as i64 as u64) { pc += 20 }
    lddw r1, 0x300000000                            r1 load str located at 12884901888
    ldxdw r1, [r1+0x0]                      
    mov64 r3, r1                                    r3 = r1
    add64 r3, -24                                   r3 += -24   ///  r3 = r3.wrapping_add(-24 as i32 as i64 as u64)
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
    mov64 r4, 1                                     r4 = 1 as i32 as i64 as u64
    jgt r3, r1, lbb_2170                            if r3 > r1 { pc += 1 }
    mov64 r4, 0                                     r4 = 0 as i32 as i64 as u64
lbb_2170:
    jne r4, 0, lbb_2172                             if r4 != (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r2, r3                                    r2 = r3
lbb_2172:
    lddw r0, 0x300007fe8                            r0 load str located at 12884934632
    jeq r1, 0, lbb_2177                             if r1 == (0 as i32 as i64 as u64) { pc += 2 }
    and64 r2, -8                                    r2 &= -8   ///  r2 = r2.and(-8)
    mov64 r0, r2                                    r0 = r2
lbb_2177:
    lddw r1, 0x300000007                            r1 load str located at 12884901895
    jgt r0, r1, lbb_2314                            if r0 > r1 { pc += 134 }
    ja lbb_2144                                     if true { pc += -37 }
lbb_2181:
    mov64 r5, r1                                    r5 = r1
    add64 r5, -2                                    r5 += -2   ///  r5 = r5.wrapping_add(-2 as i32 as i64 as u64)
    stxdw [r2+0x28], r5                     
    jeq r0, 0, lbb_2349                             if r0 == (0 as i32 as i64 as u64) { pc += 164 }
    ldxb r8, [r4+0x1]                       
    mov64 r0, r4                                    r0 = r4
    add64 r0, 2                                     r0 += 2   ///  r0 = r0.wrapping_add(2 as i32 as i64 as u64)
    stxdw [r2+0x18], r0                     
    mov64 r0, r3                                    r0 = r3
    add64 r0, -2                                    r0 += -2   ///  r0 = r0.wrapping_add(-2 as i32 as i64 as u64)
    stxdw [r2+0x20], r0                     
    jne r5, 0, lbb_2213                             if r5 != (0 as i32 as i64 as u64) { pc += 20 }
    lddw r1, 0x300000000                            r1 load str located at 12884901888
    ldxdw r1, [r1+0x0]                      
    mov64 r3, r1                                    r3 = r1
    add64 r3, -24                                   r3 += -24   ///  r3 = r3.wrapping_add(-24 as i32 as i64 as u64)
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
    mov64 r4, 1                                     r4 = 1 as i32 as i64 as u64
    jgt r3, r1, lbb_2202                            if r3 > r1 { pc += 1 }
    mov64 r4, 0                                     r4 = 0 as i32 as i64 as u64
lbb_2202:
    jne r4, 0, lbb_2204                             if r4 != (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r2, r3                                    r2 = r3
lbb_2204:
    lddw r0, 0x300007fe8                            r0 load str located at 12884934632
    jeq r1, 0, lbb_2209                             if r1 == (0 as i32 as i64 as u64) { pc += 2 }
    and64 r2, -8                                    r2 &= -8   ///  r2 = r2.and(-8)
    mov64 r0, r2                                    r0 = r2
lbb_2209:
    lddw r1, 0x300000007                            r1 load str located at 12884901895
    jgt r0, r1, lbb_2314                            if r0 > r1 { pc += 102 }
    ja lbb_2144                                     if true { pc += -69 }
lbb_2213:
    mov64 r5, r1                                    r5 = r1
    add64 r5, -3                                    r5 += -3   ///  r5 = r5.wrapping_add(-3 as i32 as i64 as u64)
    stxdw [r2+0x28], r5                     
    jeq r0, 0, lbb_2349                             if r0 == (0 as i32 as i64 as u64) { pc += 132 }
    ldxb r9, [r4+0x2]                       
    mov64 r0, r4                                    r0 = r4
    add64 r0, 3                                     r0 += 3   ///  r0 = r0.wrapping_add(3 as i32 as i64 as u64)
    stxdw [r2+0x18], r0                     
    mov64 r0, r3                                    r0 = r3
    add64 r0, -3                                    r0 += -3   ///  r0 = r0.wrapping_add(-3 as i32 as i64 as u64)
    stxdw [r2+0x20], r0                     
    jne r5, 0, lbb_2245                             if r5 != (0 as i32 as i64 as u64) { pc += 20 }
    lddw r1, 0x300000000                            r1 load str located at 12884901888
    ldxdw r1, [r1+0x0]                      
    mov64 r3, r1                                    r3 = r1
    add64 r3, -24                                   r3 += -24   ///  r3 = r3.wrapping_add(-24 as i32 as i64 as u64)
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
    mov64 r4, 1                                     r4 = 1 as i32 as i64 as u64
    jgt r3, r1, lbb_2234                            if r3 > r1 { pc += 1 }
    mov64 r4, 0                                     r4 = 0 as i32 as i64 as u64
lbb_2234:
    jne r4, 0, lbb_2236                             if r4 != (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r2, r3                                    r2 = r3
lbb_2236:
    lddw r0, 0x300007fe8                            r0 load str located at 12884934632
    jeq r1, 0, lbb_2241                             if r1 == (0 as i32 as i64 as u64) { pc += 2 }
    and64 r2, -8                                    r2 &= -8   ///  r2 = r2.and(-8)
    mov64 r0, r2                                    r0 = r2
lbb_2241:
    lddw r1, 0x300000007                            r1 load str located at 12884901895
    jgt r0, r1, lbb_2314                            if r0 > r1 { pc += 70 }
    ja lbb_2144                                     if true { pc += -101 }
lbb_2245:
    mov64 r5, r1                                    r5 = r1
    add64 r5, -4                                    r5 += -4   ///  r5 = r5.wrapping_add(-4 as i32 as i64 as u64)
    stxdw [r2+0x28], r5                     
    jeq r0, 0, lbb_2349                             if r0 == (0 as i32 as i64 as u64) { pc += 100 }
    ldxb r0, [r4+0x3]                       
    stxdw [r10-0x1c0], r0                   
    mov64 r0, r4                                    r0 = r4
    add64 r0, 4                                     r0 += 4   ///  r0 = r0.wrapping_add(4 as i32 as i64 as u64)
    stxdw [r2+0x18], r0                     
    mov64 r0, r3                                    r0 = r3
    add64 r0, -4                                    r0 += -4   ///  r0 = r0.wrapping_add(-4 as i32 as i64 as u64)
    stxdw [r2+0x20], r0                     
    jne r5, 0, lbb_2278                             if r5 != (0 as i32 as i64 as u64) { pc += 20 }
    lddw r1, 0x300000000                            r1 load str located at 12884901888
    ldxdw r1, [r1+0x0]                      
    mov64 r3, r1                                    r3 = r1
    add64 r3, -24                                   r3 += -24   ///  r3 = r3.wrapping_add(-24 as i32 as i64 as u64)
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
    mov64 r4, 1                                     r4 = 1 as i32 as i64 as u64
    jgt r3, r1, lbb_2267                            if r3 > r1 { pc += 1 }
    mov64 r4, 0                                     r4 = 0 as i32 as i64 as u64
lbb_2267:
    jne r4, 0, lbb_2269                             if r4 != (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r2, r3                                    r2 = r3
lbb_2269:
    lddw r0, 0x300007fe8                            r0 load str located at 12884934632
    jeq r1, 0, lbb_2274                             if r1 == (0 as i32 as i64 as u64) { pc += 2 }
    and64 r2, -8                                    r2 &= -8   ///  r2 = r2.and(-8)
    mov64 r0, r2                                    r0 = r2
lbb_2274:
    lddw r1, 0x300000007                            r1 load str located at 12884901895
    jgt r0, r1, lbb_2314                            if r0 > r1 { pc += 37 }
    ja lbb_2144                                     if true { pc += -134 }
lbb_2278:
    mov64 r5, r1                                    r5 = r1
    add64 r5, -5                                    r5 += -5   ///  r5 = r5.wrapping_add(-5 as i32 as i64 as u64)
    stxdw [r2+0x28], r5                     
    jeq r0, 0, lbb_2349                             if r0 == (0 as i32 as i64 as u64) { pc += 67 }
    stxdw [r10-0x1c8], r9                   
    ldxb r0, [r4+0x4]                       
    stxdw [r10-0x1d0], r0                   
    mov64 r0, r4                                    r0 = r4
    add64 r0, 5                                     r0 += 5   ///  r0 = r0.wrapping_add(5 as i32 as i64 as u64)
    stxdw [r2+0x18], r0                     
    mov64 r0, r3                                    r0 = r3
    add64 r0, -5                                    r0 += -5   ///  r0 = r0.wrapping_add(-5 as i32 as i64 as u64)
    stxdw [r2+0x20], r0                     
    mov64 r9, 26                                    r9 = 26 as i32 as i64 as u64
    stxdw [r10-0x1b0], r9                   
    jne r5, 0, lbb_2321                             if r5 != (0 as i32 as i64 as u64) { pc += 27 }
    lddw r1, 0x300000000                            r1 load str located at 12884901888
    ldxdw r1, [r1+0x0]                      
    mov64 r3, r1                                    r3 = r1
    add64 r3, -24                                   r3 += -24   ///  r3 = r3.wrapping_add(-24 as i32 as i64 as u64)
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
    mov64 r4, 1                                     r4 = 1 as i32 as i64 as u64
    jgt r3, r1, lbb_2303                            if r3 > r1 { pc += 1 }
    mov64 r4, 0                                     r4 = 0 as i32 as i64 as u64
lbb_2303:
    jne r4, 0, lbb_2305                             if r4 != (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r2, r3                                    r2 = r3
lbb_2305:
    lddw r0, 0x300007fe8                            r0 load str located at 12884934632
    jeq r1, 0, lbb_2310                             if r1 == (0 as i32 as i64 as u64) { pc += 2 }
    and64 r2, -8                                    r2 &= -8   ///  r2 = r2.and(-8)
    mov64 r0, r2                                    r0 = r2
lbb_2310:
    lddw r1, 0x300000007                            r1 load str located at 12884901895
    jgt r0, r1, lbb_2314                            if r0 > r1 { pc += 1 }
    ja lbb_2144                                     if true { pc += -170 }
lbb_2314:
    lddw r1, 0x300000000                            r1 load str located at 12884901888
    stxdw [r1+0x0], r0                      
    lddw r1, 0x8000000000000006                     r1 load str located at -9223372036854775802
    stxdw [r0+0x0], r1                      
    ja lbb_2352                                     if true { pc += 31 }
lbb_2321:
    add64 r1, -6                                    r1 += -6   ///  r1 = r1.wrapping_add(-6 as i32 as i64 as u64)
    stxdw [r2+0x28], r1                     
    jeq r0, 0, lbb_2349                             if r0 == (0 as i32 as i64 as u64) { pc += 25 }
    add64 r3, -6                                    r3 += -6   ///  r3 = r3.wrapping_add(-6 as i32 as i64 as u64)
    ldxb r9, [r4+0x5]                       
    stxdw [r2+0x20], r3                     
    add64 r4, 6                                     r4 += 6   ///  r4 = r4.wrapping_add(6 as i32 as i64 as u64)
    stxdw [r2+0x18], r4                     
    mov64 r1, r10                                   r1 = r10
    add64 r1, -424                                  r1 += -424   ///  r1 = r1.wrapping_add(-424 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -440                                  r2 += -440   ///  r2 = r2.wrapping_add(-440 as i32 as i64 as u64)
    call function_1318                      
    ldxb r1, [r10-0x1a8]                    
    jne r1, 0, lbb_2356                             if r1 != (0 as i32 as i64 as u64) { pc += 20 }
    stxdw [r10-0x1d8], r9                   
    ldxb r1, [r10-0x1a7]                    
    jeq r1, 0, lbb_2384                             if r1 == (0 as i32 as i64 as u64) { pc += 45 }
    ldxb r9, [r10-0x1a6]                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -408                                  r1 += -408   ///  r1 = r1.wrapping_add(-408 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -440                                  r2 += -440   ///  r2 = r2.wrapping_add(-440 as i32 as i64 as u64)
    call function_1318                      
    ldxb r1, [r10-0x198]                    
    jeq r1, 0, lbb_2358                             if r1 == (0 as i32 as i64 as u64) { pc += 11 }
    ldxdw r0, [r10-0x190]                   
    ja lbb_2352                                     if true { pc += 3 }
lbb_2349:
    lddw r1, 0x100040d80 --> b"\x00\x00\x00\x00\x99\xe5\x03\x00\x1b\x00\x00\x00\x00\x00\x00\x00%\x00\x00…        r1 load str located at 4295232896
    call function_19497                     
lbb_2352:
    stxdw [r6+0x8], r0                      
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
lbb_2354:
    stxb [r6+0x0], r1                       
    exit                                    
lbb_2356:
    ldxdw r0, [r10-0x1a0]                   
    ja lbb_2352                                     if true { pc += -6 }
lbb_2358:
    stxdw [r10-0x1e0], r9                   
    ldxb r1, [r10-0x197]                    
    jeq r1, 0, lbb_2401                             if r1 == (0 as i32 as i64 as u64) { pc += 40 }
    ldxb r9, [r10-0x196]                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -392                                  r1 += -392   ///  r1 = r1.wrapping_add(-392 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -440                                  r2 += -440   ///  r2 = r2.wrapping_add(-440 as i32 as i64 as u64)
    call function_1318                      
    ldxb r1, [r10-0x188]                    
    jeq r1, 0, lbb_2371                             if r1 == (0 as i32 as i64 as u64) { pc += 2 }
    ldxdw r0, [r10-0x180]                   
    ja lbb_2352                                     if true { pc += -19 }
lbb_2371:
    ldxb r1, [r10-0x187]                    
    jeq r1, 0, lbb_2418                             if r1 == (0 as i32 as i64 as u64) { pc += 45 }
    ldxb r1, [r10-0x186]                    
    stxdw [r10-0x1e8], r1                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -376                                  r1 += -376   ///  r1 = r1.wrapping_add(-376 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -440                                  r2 += -440   ///  r2 = r2.wrapping_add(-440 as i32 as i64 as u64)
    call function_1318                      
    ldxb r1, [r10-0x178]                    
    jeq r1, 0, lbb_2388                             if r1 == (0 as i32 as i64 as u64) { pc += 6 }
    ldxdw r0, [r10-0x170]                   
    ja lbb_2352                                     if true { pc += -32 }
lbb_2384:
    mov64 r2, r10                                   r2 = r10
    add64 r2, -1                                    r2 += -1   ///  r2 = r2.wrapping_add(-1 as i32 as i64 as u64)
    mov64 r1, 6                                     r1 = 6 as i32 as i64 as u64
    ja lbb_2845                                     if true { pc += 457 }
lbb_2388:
    ldxb r1, [r10-0x177]                    
    jeq r1, 0, lbb_2435                             if r1 == (0 as i32 as i64 as u64) { pc += 45 }
    ldxb r1, [r10-0x176]                    
    stxdw [r10-0x1f0], r1                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -360                                  r1 += -360   ///  r1 = r1.wrapping_add(-360 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -440                                  r2 += -440   ///  r2 = r2.wrapping_add(-440 as i32 as i64 as u64)
    call function_1318                      
    ldxb r1, [r10-0x168]                    
    jeq r1, 0, lbb_2405                             if r1 == (0 as i32 as i64 as u64) { pc += 6 }
    ldxdw r0, [r10-0x160]                   
    ja lbb_2352                                     if true { pc += -49 }
lbb_2401:
    mov64 r2, r10                                   r2 = r10
    add64 r2, -1                                    r2 += -1   ///  r2 = r2.wrapping_add(-1 as i32 as i64 as u64)
    mov64 r1, 7                                     r1 = 7 as i32 as i64 as u64
    ja lbb_2845                                     if true { pc += 440 }
lbb_2405:
    ldxb r1, [r10-0x167]                    
    jeq r1, 0, lbb_2452                             if r1 == (0 as i32 as i64 as u64) { pc += 45 }
    ldxb r1, [r10-0x166]                    
    stxdw [r10-0x1f8], r1                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -344                                  r1 += -344   ///  r1 = r1.wrapping_add(-344 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -440                                  r2 += -440   ///  r2 = r2.wrapping_add(-440 as i32 as i64 as u64)
    call function_1318                      
    ldxb r1, [r10-0x158]                    
    jeq r1, 0, lbb_2422                             if r1 == (0 as i32 as i64 as u64) { pc += 6 }
    ldxdw r0, [r10-0x150]                   
    ja lbb_2352                                     if true { pc += -66 }
lbb_2418:
    mov64 r2, r10                                   r2 = r10
    add64 r2, -1                                    r2 += -1   ///  r2 = r2.wrapping_add(-1 as i32 as i64 as u64)
    mov64 r1, 8                                     r1 = 8 as i32 as i64 as u64
    ja lbb_2845                                     if true { pc += 423 }
lbb_2422:
    ldxb r1, [r10-0x157]                    
    jeq r1, 0, lbb_2469                             if r1 == (0 as i32 as i64 as u64) { pc += 45 }
    ldxb r1, [r10-0x156]                    
    stxdw [r10-0x200], r1                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -328                                  r1 += -328   ///  r1 = r1.wrapping_add(-328 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -440                                  r2 += -440   ///  r2 = r2.wrapping_add(-440 as i32 as i64 as u64)
    call function_1318                      
    ldxb r1, [r10-0x148]                    
    jeq r1, 0, lbb_2439                             if r1 == (0 as i32 as i64 as u64) { pc += 6 }
    ldxdw r0, [r10-0x140]                   
    ja lbb_2352                                     if true { pc += -83 }
lbb_2435:
    mov64 r2, r10                                   r2 = r10
    add64 r2, -1                                    r2 += -1   ///  r2 = r2.wrapping_add(-1 as i32 as i64 as u64)
    mov64 r1, 9                                     r1 = 9 as i32 as i64 as u64
    ja lbb_2845                                     if true { pc += 406 }
lbb_2439:
    ldxb r1, [r10-0x147]                    
    jeq r1, 0, lbb_2486                             if r1 == (0 as i32 as i64 as u64) { pc += 45 }
    ldxb r1, [r10-0x146]                    
    stxdw [r10-0x208], r1                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -312                                  r1 += -312   ///  r1 = r1.wrapping_add(-312 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -440                                  r2 += -440   ///  r2 = r2.wrapping_add(-440 as i32 as i64 as u64)
    call function_1318                      
    ldxb r1, [r10-0x138]                    
    jeq r1, 0, lbb_2456                             if r1 == (0 as i32 as i64 as u64) { pc += 6 }
    ldxdw r0, [r10-0x130]                   
    ja lbb_2352                                     if true { pc += -100 }
lbb_2452:
    mov64 r2, r10                                   r2 = r10
    add64 r2, -1                                    r2 += -1   ///  r2 = r2.wrapping_add(-1 as i32 as i64 as u64)
    mov64 r1, 10                                    r1 = 10 as i32 as i64 as u64
    ja lbb_2845                                     if true { pc += 389 }
lbb_2456:
    ldxb r1, [r10-0x137]                    
    jeq r1, 0, lbb_2503                             if r1 == (0 as i32 as i64 as u64) { pc += 45 }
    ldxb r1, [r10-0x136]                    
    stxdw [r10-0x210], r1                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -296                                  r1 += -296   ///  r1 = r1.wrapping_add(-296 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -440                                  r2 += -440   ///  r2 = r2.wrapping_add(-440 as i32 as i64 as u64)
    call function_1318                      
    ldxb r1, [r10-0x128]                    
    jeq r1, 0, lbb_2473                             if r1 == (0 as i32 as i64 as u64) { pc += 6 }
    ldxdw r0, [r10-0x120]                   
    ja lbb_2352                                     if true { pc += -117 }
lbb_2469:
    mov64 r2, r10                                   r2 = r10
    add64 r2, -1                                    r2 += -1   ///  r2 = r2.wrapping_add(-1 as i32 as i64 as u64)
    mov64 r1, 11                                    r1 = 11 as i32 as i64 as u64
    ja lbb_2845                                     if true { pc += 372 }
lbb_2473:
    ldxb r1, [r10-0x127]                    
    jeq r1, 0, lbb_2520                             if r1 == (0 as i32 as i64 as u64) { pc += 45 }
    ldxb r1, [r10-0x126]                    
    stxdw [r10-0x218], r1                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -280                                  r1 += -280   ///  r1 = r1.wrapping_add(-280 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -440                                  r2 += -440   ///  r2 = r2.wrapping_add(-440 as i32 as i64 as u64)
    call function_1318                      
    ldxb r1, [r10-0x118]                    
    jeq r1, 0, lbb_2490                             if r1 == (0 as i32 as i64 as u64) { pc += 6 }
    ldxdw r0, [r10-0x110]                   
    ja lbb_2352                                     if true { pc += -134 }
lbb_2486:
    mov64 r2, r10                                   r2 = r10
    add64 r2, -1                                    r2 += -1   ///  r2 = r2.wrapping_add(-1 as i32 as i64 as u64)
    mov64 r1, 12                                    r1 = 12 as i32 as i64 as u64
    ja lbb_2845                                     if true { pc += 355 }
lbb_2490:
    ldxb r1, [r10-0x117]                    
    jeq r1, 0, lbb_2537                             if r1 == (0 as i32 as i64 as u64) { pc += 45 }
    ldxb r1, [r10-0x116]                    
    stxdw [r10-0x220], r1                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -264                                  r1 += -264   ///  r1 = r1.wrapping_add(-264 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -440                                  r2 += -440   ///  r2 = r2.wrapping_add(-440 as i32 as i64 as u64)
    call function_1318                      
    ldxb r1, [r10-0x108]                    
    jeq r1, 0, lbb_2507                             if r1 == (0 as i32 as i64 as u64) { pc += 6 }
    ldxdw r0, [r10-0x100]                   
    ja lbb_2352                                     if true { pc += -151 }
lbb_2503:
    mov64 r2, r10                                   r2 = r10
    add64 r2, -1                                    r2 += -1   ///  r2 = r2.wrapping_add(-1 as i32 as i64 as u64)
    mov64 r1, 13                                    r1 = 13 as i32 as i64 as u64
    ja lbb_2845                                     if true { pc += 338 }
lbb_2507:
    ldxb r1, [r10-0x107]                    
    jeq r1, 0, lbb_2554                             if r1 == (0 as i32 as i64 as u64) { pc += 45 }
    ldxb r1, [r10-0x106]                    
    stxdw [r10-0x228], r1                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -248                                  r1 += -248   ///  r1 = r1.wrapping_add(-248 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -440                                  r2 += -440   ///  r2 = r2.wrapping_add(-440 as i32 as i64 as u64)
    call function_1318                      
    ldxb r1, [r10-0xf8]                     
    jeq r1, 0, lbb_2524                             if r1 == (0 as i32 as i64 as u64) { pc += 6 }
    ldxdw r0, [r10-0xf0]                    
    ja lbb_2352                                     if true { pc += -168 }
lbb_2520:
    mov64 r2, r10                                   r2 = r10
    add64 r2, -1                                    r2 += -1   ///  r2 = r2.wrapping_add(-1 as i32 as i64 as u64)
    mov64 r1, 14                                    r1 = 14 as i32 as i64 as u64
    ja lbb_2845                                     if true { pc += 321 }
lbb_2524:
    ldxb r1, [r10-0xf7]                     
    jeq r1, 0, lbb_2571                             if r1 == (0 as i32 as i64 as u64) { pc += 45 }
    ldxb r1, [r10-0xf6]                     
    stxdw [r10-0x230], r1                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -232                                  r1 += -232   ///  r1 = r1.wrapping_add(-232 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -440                                  r2 += -440   ///  r2 = r2.wrapping_add(-440 as i32 as i64 as u64)
    call function_1318                      
    ldxb r1, [r10-0xe8]                     
    jeq r1, 0, lbb_2541                             if r1 == (0 as i32 as i64 as u64) { pc += 6 }
    ldxdw r0, [r10-0xe0]                    
    ja lbb_2352                                     if true { pc += -185 }
lbb_2537:
    mov64 r2, r10                                   r2 = r10
    add64 r2, -1                                    r2 += -1   ///  r2 = r2.wrapping_add(-1 as i32 as i64 as u64)
    mov64 r1, 15                                    r1 = 15 as i32 as i64 as u64
    ja lbb_2845                                     if true { pc += 304 }
lbb_2541:
    ldxb r1, [r10-0xe7]                     
    jeq r1, 0, lbb_2588                             if r1 == (0 as i32 as i64 as u64) { pc += 45 }
    ldxb r1, [r10-0xe6]                     
    stxdw [r10-0x238], r1                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -216                                  r1 += -216   ///  r1 = r1.wrapping_add(-216 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -440                                  r2 += -440   ///  r2 = r2.wrapping_add(-440 as i32 as i64 as u64)
    call function_1318                      
    ldxb r1, [r10-0xd8]                     
    jeq r1, 0, lbb_2558                             if r1 == (0 as i32 as i64 as u64) { pc += 6 }
    ldxdw r0, [r10-0xd0]                    
    ja lbb_2352                                     if true { pc += -202 }
lbb_2554:
    mov64 r2, r10                                   r2 = r10
    add64 r2, -1                                    r2 += -1   ///  r2 = r2.wrapping_add(-1 as i32 as i64 as u64)
    mov64 r1, 16                                    r1 = 16 as i32 as i64 as u64
    ja lbb_2845                                     if true { pc += 287 }
lbb_2558:
    ldxb r1, [r10-0xd7]                     
    jeq r1, 0, lbb_2605                             if r1 == (0 as i32 as i64 as u64) { pc += 45 }
    ldxb r1, [r10-0xd6]                     
    stxdw [r10-0x240], r1                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -200                                  r1 += -200   ///  r1 = r1.wrapping_add(-200 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -440                                  r2 += -440   ///  r2 = r2.wrapping_add(-440 as i32 as i64 as u64)
    call function_1318                      
    ldxb r1, [r10-0xc8]                     
    jeq r1, 0, lbb_2575                             if r1 == (0 as i32 as i64 as u64) { pc += 6 }
    ldxdw r0, [r10-0xc0]                    
    ja lbb_2352                                     if true { pc += -219 }
lbb_2571:
    mov64 r2, r10                                   r2 = r10
    add64 r2, -1                                    r2 += -1   ///  r2 = r2.wrapping_add(-1 as i32 as i64 as u64)
    mov64 r1, 17                                    r1 = 17 as i32 as i64 as u64
    ja lbb_2845                                     if true { pc += 270 }
lbb_2575:
    ldxb r1, [r10-0xc7]                     
    jeq r1, 0, lbb_2622                             if r1 == (0 as i32 as i64 as u64) { pc += 45 }
    ldxb r1, [r10-0xc6]                     
    stxdw [r10-0x248], r1                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -184                                  r1 += -184   ///  r1 = r1.wrapping_add(-184 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -440                                  r2 += -440   ///  r2 = r2.wrapping_add(-440 as i32 as i64 as u64)
    call function_1318                      
    ldxb r1, [r10-0xb8]                     
    jeq r1, 0, lbb_2592                             if r1 == (0 as i32 as i64 as u64) { pc += 6 }
    ldxdw r0, [r10-0xb0]                    
    ja lbb_2352                                     if true { pc += -236 }
lbb_2588:
    mov64 r2, r10                                   r2 = r10
    add64 r2, -1                                    r2 += -1   ///  r2 = r2.wrapping_add(-1 as i32 as i64 as u64)
    mov64 r1, 18                                    r1 = 18 as i32 as i64 as u64
    ja lbb_2845                                     if true { pc += 253 }
lbb_2592:
    ldxb r1, [r10-0xb7]                     
    jeq r1, 0, lbb_2639                             if r1 == (0 as i32 as i64 as u64) { pc += 45 }
    ldxb r1, [r10-0xb6]                     
    stxdw [r10-0x250], r1                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -168                                  r1 += -168   ///  r1 = r1.wrapping_add(-168 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -440                                  r2 += -440   ///  r2 = r2.wrapping_add(-440 as i32 as i64 as u64)
    call function_1318                      
    ldxb r1, [r10-0xa8]                     
    jeq r1, 0, lbb_2609                             if r1 == (0 as i32 as i64 as u64) { pc += 6 }
    ldxdw r0, [r10-0xa0]                    
    ja lbb_2352                                     if true { pc += -253 }
lbb_2605:
    mov64 r2, r10                                   r2 = r10
    add64 r2, -1                                    r2 += -1   ///  r2 = r2.wrapping_add(-1 as i32 as i64 as u64)
    mov64 r1, 19                                    r1 = 19 as i32 as i64 as u64
    ja lbb_2845                                     if true { pc += 236 }
lbb_2609:
    ldxb r1, [r10-0xa7]                     
    jeq r1, 0, lbb_2656                             if r1 == (0 as i32 as i64 as u64) { pc += 45 }
    ldxb r1, [r10-0xa6]                     
    stxdw [r10-0x258], r1                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -152                                  r1 += -152   ///  r1 = r1.wrapping_add(-152 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -440                                  r2 += -440   ///  r2 = r2.wrapping_add(-440 as i32 as i64 as u64)
    call function_1318                      
    ldxb r1, [r10-0x98]                     
    jeq r1, 0, lbb_2626                             if r1 == (0 as i32 as i64 as u64) { pc += 6 }
    ldxdw r0, [r10-0x90]                    
    ja lbb_2352                                     if true { pc += -270 }
lbb_2622:
    mov64 r2, r10                                   r2 = r10
    add64 r2, -1                                    r2 += -1   ///  r2 = r2.wrapping_add(-1 as i32 as i64 as u64)
    mov64 r1, 20                                    r1 = 20 as i32 as i64 as u64
    ja lbb_2845                                     if true { pc += 219 }
lbb_2626:
    ldxb r1, [r10-0x97]                     
    jeq r1, 0, lbb_2673                             if r1 == (0 as i32 as i64 as u64) { pc += 45 }
    ldxb r1, [r10-0x96]                     
    stxdw [r10-0x260], r1                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -136                                  r1 += -136   ///  r1 = r1.wrapping_add(-136 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -440                                  r2 += -440   ///  r2 = r2.wrapping_add(-440 as i32 as i64 as u64)
    call function_1318                      
    ldxb r1, [r10-0x88]                     
    jeq r1, 0, lbb_2643                             if r1 == (0 as i32 as i64 as u64) { pc += 6 }
    ldxdw r0, [r10-0x80]                    
    ja lbb_2352                                     if true { pc += -287 }
lbb_2639:
    mov64 r2, r10                                   r2 = r10
    add64 r2, -1                                    r2 += -1   ///  r2 = r2.wrapping_add(-1 as i32 as i64 as u64)
    mov64 r1, 21                                    r1 = 21 as i32 as i64 as u64
    ja lbb_2845                                     if true { pc += 202 }
lbb_2643:
    ldxb r1, [r10-0x87]                     
    jeq r1, 0, lbb_2690                             if r1 == (0 as i32 as i64 as u64) { pc += 45 }
    ldxb r1, [r10-0x86]                     
    stxdw [r10-0x268], r1                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -120                                  r1 += -120   ///  r1 = r1.wrapping_add(-120 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -440                                  r2 += -440   ///  r2 = r2.wrapping_add(-440 as i32 as i64 as u64)
    call function_1318                      
    ldxb r1, [r10-0x78]                     
    jeq r1, 0, lbb_2660                             if r1 == (0 as i32 as i64 as u64) { pc += 6 }
    ldxdw r0, [r10-0x70]                    
    ja lbb_2352                                     if true { pc += -304 }
lbb_2656:
    mov64 r2, r10                                   r2 = r10
    add64 r2, -1                                    r2 += -1   ///  r2 = r2.wrapping_add(-1 as i32 as i64 as u64)
    mov64 r1, 22                                    r1 = 22 as i32 as i64 as u64
    ja lbb_2845                                     if true { pc += 185 }
lbb_2660:
    ldxb r1, [r10-0x77]                     
    jeq r1, 0, lbb_2707                             if r1 == (0 as i32 as i64 as u64) { pc += 45 }
    ldxb r1, [r10-0x76]                     
    stxdw [r10-0x270], r1                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -104                                  r1 += -104   ///  r1 = r1.wrapping_add(-104 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -440                                  r2 += -440   ///  r2 = r2.wrapping_add(-440 as i32 as i64 as u64)
    call function_1318                      
    ldxb r1, [r10-0x68]                     
    jeq r1, 0, lbb_2677                             if r1 == (0 as i32 as i64 as u64) { pc += 6 }
    ldxdw r0, [r10-0x60]                    
    ja lbb_2352                                     if true { pc += -321 }
lbb_2673:
    mov64 r2, r10                                   r2 = r10
    add64 r2, -1                                    r2 += -1   ///  r2 = r2.wrapping_add(-1 as i32 as i64 as u64)
    mov64 r1, 23                                    r1 = 23 as i32 as i64 as u64
    ja lbb_2845                                     if true { pc += 168 }
lbb_2677:
    ldxb r1, [r10-0x67]                     
    jeq r1, 0, lbb_2724                             if r1 == (0 as i32 as i64 as u64) { pc += 45 }
    ldxb r1, [r10-0x66]                     
    stxdw [r10-0x278], r1                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -88                                   r1 += -88   ///  r1 = r1.wrapping_add(-88 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -440                                  r2 += -440   ///  r2 = r2.wrapping_add(-440 as i32 as i64 as u64)
    call function_1318                      
    ldxb r1, [r10-0x58]                     
    jeq r1, 0, lbb_2694                             if r1 == (0 as i32 as i64 as u64) { pc += 6 }
    ldxdw r0, [r10-0x50]                    
    ja lbb_2352                                     if true { pc += -338 }
lbb_2690:
    mov64 r2, r10                                   r2 = r10
    add64 r2, -1                                    r2 += -1   ///  r2 = r2.wrapping_add(-1 as i32 as i64 as u64)
    mov64 r1, 24                                    r1 = 24 as i32 as i64 as u64
    ja lbb_2845                                     if true { pc += 151 }
lbb_2694:
    ldxb r1, [r10-0x57]                     
    jeq r1, 0, lbb_2741                             if r1 == (0 as i32 as i64 as u64) { pc += 45 }
    ldxb r1, [r10-0x56]                     
    stxdw [r10-0x280], r1                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -72                                   r1 += -72   ///  r1 = r1.wrapping_add(-72 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -440                                  r2 += -440   ///  r2 = r2.wrapping_add(-440 as i32 as i64 as u64)
    call function_1318                      
    ldxb r1, [r10-0x48]                     
    jeq r1, 0, lbb_2711                             if r1 == (0 as i32 as i64 as u64) { pc += 6 }
    ldxdw r0, [r10-0x40]                    
    ja lbb_2352                                     if true { pc += -355 }
lbb_2707:
    mov64 r2, r10                                   r2 = r10
    add64 r2, -1                                    r2 += -1   ///  r2 = r2.wrapping_add(-1 as i32 as i64 as u64)
    mov64 r1, 25                                    r1 = 25 as i32 as i64 as u64
    ja lbb_2845                                     if true { pc += 134 }
lbb_2711:
    ldxb r1, [r10-0x47]                     
    jeq r1, 0, lbb_2758                             if r1 == (0 as i32 as i64 as u64) { pc += 45 }
    ldxb r1, [r10-0x46]                     
    stxdw [r10-0x288], r1                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -56                                   r1 += -56   ///  r1 = r1.wrapping_add(-56 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -440                                  r2 += -440   ///  r2 = r2.wrapping_add(-440 as i32 as i64 as u64)
    call function_1318                      
    ldxb r1, [r10-0x38]                     
    jeq r1, 0, lbb_2728                             if r1 == (0 as i32 as i64 as u64) { pc += 6 }
    ldxdw r0, [r10-0x30]                    
    ja lbb_2352                                     if true { pc += -372 }
lbb_2724:
    mov64 r2, r10                                   r2 = r10
    add64 r2, -1                                    r2 += -1   ///  r2 = r2.wrapping_add(-1 as i32 as i64 as u64)
    mov64 r1, 26                                    r1 = 26 as i32 as i64 as u64
    ja lbb_2845                                     if true { pc += 117 }
lbb_2728:
    ldxb r1, [r10-0x37]                     
    jeq r1, 0, lbb_2834                             if r1 == (0 as i32 as i64 as u64) { pc += 104 }
    ldxb r1, [r10-0x36]                     
    stxdw [r10-0x290], r1                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -40                                   r1 += -40   ///  r1 = r1.wrapping_add(-40 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -440                                  r2 += -440   ///  r2 = r2.wrapping_add(-440 as i32 as i64 as u64)
    call function_1318                      
    ldxb r1, [r10-0x28]                     
    jeq r1, 0, lbb_2745                             if r1 == (0 as i32 as i64 as u64) { pc += 6 }
    ldxdw r0, [r10-0x20]                    
    ja lbb_2352                                     if true { pc += -389 }
lbb_2741:
    mov64 r2, r10                                   r2 = r10
    add64 r2, -1                                    r2 += -1   ///  r2 = r2.wrapping_add(-1 as i32 as i64 as u64)
    mov64 r1, 27                                    r1 = 27 as i32 as i64 as u64
    ja lbb_2845                                     if true { pc += 100 }
lbb_2745:
    ldxb r1, [r10-0x27]                     
    jeq r1, 0, lbb_2838                             if r1 == (0 as i32 as i64 as u64) { pc += 91 }
    ldxb r1, [r10-0x26]                     
    stxdw [r10-0x298], r1                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -24                                   r1 += -24   ///  r1 = r1.wrapping_add(-24 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -440                                  r2 += -440   ///  r2 = r2.wrapping_add(-440 as i32 as i64 as u64)
    call function_1318                      
    ldxb r1, [r10-0x18]                     
    jeq r1, 0, lbb_2762                             if r1 == (0 as i32 as i64 as u64) { pc += 6 }
    ldxdw r0, [r10-0x10]                    
    ja lbb_2352                                     if true { pc += -406 }
lbb_2758:
    mov64 r2, r10                                   r2 = r10
    add64 r2, -1                                    r2 += -1   ///  r2 = r2.wrapping_add(-1 as i32 as i64 as u64)
    mov64 r1, 28                                    r1 = 28 as i32 as i64 as u64
    ja lbb_2845                                     if true { pc += 83 }
lbb_2762:
    ldxb r1, [r10-0x17]                     
    jeq r1, 0, lbb_2842                             if r1 == (0 as i32 as i64 as u64) { pc += 78 }
    ldxdw r2, [r10-0x1e8]                   
    lsh64 r2, 8                                     r2 <<= 8   ///  r2 = r2.wrapping_shl(8)
    or64 r2, r9                                     r2 |= r9   ///  r2 = r2.or(r9)
    ldxdw r1, [r10-0x1f0]                   
    lsh64 r1, 16                                    r1 <<= 16   ///  r1 = r1.wrapping_shl(16)
    or64 r2, r1                                     r2 |= r1   ///  r2 = r2.or(r1)
    ldxdw r1, [r10-0x1f8]                   
    lsh64 r1, 24                                    r1 <<= 24   ///  r1 = r1.wrapping_shl(24)
    or64 r2, r1                                     r2 |= r1   ///  r2 = r2.or(r1)
    ldxdw r1, [r10-0x200]                   
    lsh64 r1, 32                                    r1 <<= 32   ///  r1 = r1.wrapping_shl(32)
    or64 r2, r1                                     r2 |= r1   ///  r2 = r2.or(r1)
    ldxdw r1, [r10-0x208]                   
    lsh64 r1, 40                                    r1 <<= 40   ///  r1 = r1.wrapping_shl(40)
    or64 r2, r1                                     r2 |= r1   ///  r2 = r2.or(r1)
    ldxdw r1, [r10-0x210]                   
    lsh64 r1, 48                                    r1 <<= 48   ///  r1 = r1.wrapping_shl(48)
    or64 r2, r1                                     r2 |= r1   ///  r2 = r2.or(r1)
    ldxdw r1, [r10-0x218]                   
    lsh64 r1, 56                                    r1 <<= 56   ///  r1 = r1.wrapping_shl(56)
    or64 r2, r1                                     r2 |= r1   ///  r2 = r2.or(r1)
    ldxb r1, [r10-0x16]                     
    stxb [r6+0x20], r1                      
    ldxdw r1, [r10-0x298]                   
    stxb [r6+0x1f], r1                      
    ldxdw r1, [r10-0x290]                   
    stxb [r6+0x1e], r1                      
    ldxdw r1, [r10-0x288]                   
    stxb [r6+0x1d], r1                      
    ldxdw r1, [r10-0x280]                   
    stxb [r6+0x1c], r1                      
    ldxdw r1, [r10-0x278]                   
    stxb [r6+0x1b], r1                      
    ldxdw r1, [r10-0x270]                   
    stxb [r6+0x1a], r1                      
    ldxdw r1, [r10-0x268]                   
    stxb [r6+0x19], r1                      
    ldxdw r1, [r10-0x260]                   
    stxb [r6+0x18], r1                      
    ldxdw r1, [r10-0x258]                   
    stxb [r6+0x17], r1                      
    ldxdw r1, [r10-0x250]                   
    stxb [r6+0x16], r1                      
    ldxdw r1, [r10-0x248]                   
    stxb [r6+0x15], r1                      
    ldxdw r1, [r10-0x240]                   
    stxb [r6+0x14], r1                      
    ldxdw r1, [r10-0x238]                   
    stxb [r6+0x13], r1                      
    ldxdw r1, [r10-0x230]                   
    stxb [r6+0x12], r1                      
    ldxdw r1, [r10-0x228]                   
    stxb [r6+0x11], r1                      
    ldxdw r1, [r10-0x220]                   
    stxb [r6+0x10], r1                      
    stxdw [r6+0x8], r2                      
    ldxdw r1, [r10-0x1e0]                   
    stxb [r6+0x7], r1                       
    ldxdw r1, [r10-0x1d8]                   
    stxb [r6+0x6], r1                       
    ldxdw r1, [r10-0x1d0]                   
    stxb [r6+0x5], r1                       
    ldxdw r1, [r10-0x1c0]                   
    stxb [r6+0x4], r1                       
    ldxdw r1, [r10-0x1c8]                   
    stxb [r6+0x3], r1                       
    stxb [r6+0x2], r8                       
    stxb [r6+0x1], r7                       
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    ja lbb_2354                                     if true { pc += -480 }
lbb_2834:
    mov64 r2, r10                                   r2 = r10
    add64 r2, -1                                    r2 += -1   ///  r2 = r2.wrapping_add(-1 as i32 as i64 as u64)
    mov64 r1, 29                                    r1 = 29 as i32 as i64 as u64
    ja lbb_2845                                     if true { pc += 7 }
lbb_2838:
    mov64 r2, r10                                   r2 = r10
    add64 r2, -1                                    r2 += -1   ///  r2 = r2.wrapping_add(-1 as i32 as i64 as u64)
    mov64 r1, 30                                    r1 = 30 as i32 as i64 as u64
    ja lbb_2845                                     if true { pc += 3 }
lbb_2842:
    mov64 r2, r10                                   r2 = r10
    add64 r2, -1                                    r2 += -1   ///  r2 = r2.wrapping_add(-1 as i32 as i64 as u64)
    mov64 r1, 31                                    r1 = 31 as i32 as i64 as u64
lbb_2845:
    lddw r3, 0x100040c78 --> b"\x00\x00\x00\x00\xd0\x0f\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x01\x00\…        r3 load str located at 4295232632
    call function_1085                      
    ja lbb_2352                                     if true { pc += -497 }

function_2849:
    mov64 r9, r5                                    r9 = r5
    mov64 r7, r4                                    r7 = r4
    mov64 r8, r3                                    r8 = r3
    ldxb r4, [r9+0x0]                       
    jsgt r4, 7, lbb_2992                            if (r4 as i64) > (7 as i32 as i64) { pc += 138 }
    jsgt r4, 3, lbb_3142                            if (r4 as i64) > (3 as i32 as i64) { pc += 287 }
    jsgt r4, 1, lbb_2900                            if (r4 as i64) > (1 as i32 as i64) { pc += 44 }
    jeq r4, 0, lbb_2917                             if r4 == (0 as i32 as i64 as u64) { pc += 60 }
    jeq r7, 0, lbb_2935                             if r7 == (0 as i32 as i64 as u64) { pc += 77 }
    mov64 r6, r8                                    r6 = r8
    add64 r6, 48                                    r6 += 48   ///  r6 = r6.wrapping_add(48 as i32 as i64 as u64)
    jeq r7, 1, lbb_3773                             if r7 == (1 as i32 as i64 as u64) { pc += 912 }
    mov64 r0, r8                                    r0 = r8
    add64 r0, 96                                    r0 += 96   ///  r0 = r0.wrapping_add(96 as i32 as i64 as u64)
    jeq r7, 2, lbb_3626                             if r7 == (2 as i32 as i64 as u64) { pc += 762 }
    mov64 r3, r8                                    r3 = r8
    add64 r3, 144                                   r3 += 144   ///  r3 = r3.wrapping_add(144 as i32 as i64 as u64)
    jeq r7, 3, lbb_4528                             if r7 == (3 as i32 as i64 as u64) { pc += 1661 }
    mov64 r5, r8                                    r5 = r8
    add64 r5, 192                                   r5 += 192   ///  r5 = r5.wrapping_add(192 as i32 as i64 as u64)
    jeq r7, 4, lbb_3362                             if r7 == (4 as i32 as i64 as u64) { pc += 492 }
    mov64 r4, r8                                    r4 = r8
    add64 r4, 240                                   r4 += 240   ///  r4 = r4.wrapping_add(240 as i32 as i64 as u64)
    jeq r7, 5, lbb_4530                             if r7 == (5 as i32 as i64 as u64) { pc += 1657 }
    stxdw [r10-0xc18], r0                   
    stxdw [r10-0xc30], r5                   
    stxdw [r10-0xc38], r4                   
    stxdw [r10-0xc10], r2                   
    stxdw [r10-0xc08], r8                   
    stxdw [r10-0xc00], r1                   
    ldxb r8, [r9+0x2c]                      
    ldxh r7, [r9+0x2a]                      
    ldxh r1, [r9+0x28]                      
    stxdw [r10-0xc28], r1                   
    ldxw r1, [r9+0x24]                      
    stxdw [r10-0xc40], r1                   
    ldxw r1, [r9+0x20]                      
    stxdw [r10-0xc48], r1                   
    ldxw r1, [r9+0x1c]                      
    stxdw [r10-0xc60], r1                   
    ldxw r1, [r9+0x18]                      
    stxdw [r10-0xc58], r1                   
    ldxdw r1, [r9+0x10]                     
    stxdw [r10-0xc50], r1                   
    ldxdw r9, [r9+0x8]                      
    stxdw [r10-0xc20], r3                   
    mov64 r1, r3                                    r1 = r3
    call function_17730                     
    jne r0, 0, lbb_2956                             if r0 != (0 as i32 as i64 as u64) { pc += 58 }
    mov64 r1, 13                                    r1 = 13 as i32 as i64 as u64
    ja lbb_2954                                     if true { pc += 54 }
lbb_2900:
    jeq r4, 2, lbb_4420                             if r4 == (2 as i32 as i64 as u64) { pc += 1519 }
    stxdw [r10-0xc00], r1                   
    add64 r9, 1                                     r9 += 1   ///  r9 = r9.wrapping_add(1 as i32 as i64 as u64)
    mov64 r1, r10                                   r1 = r10
    add64 r1, -2858                                 r1 += -2858   ///  r1 = r1.wrapping_add(-2858 as i32 as i64 as u64)
    mov64 r2, r9                                    r2 = r9
    mov64 r3, 33                                    r3 = 33 as i32 as i64 as u64
    call function_30349                     
    jeq r7, 0, lbb_2937                             if r7 == (0 as i32 as i64 as u64) { pc += 28 }
    mov64 r2, r8                                    r2 = r8
    mov64 r9, r2                                    r9 = r2
    add64 r9, 48                                    r9 += 48   ///  r9 = r9.wrapping_add(48 as i32 as i64 as u64)
    ldxdw r1, [r10-0xc00]                   
    jeq r7, 1, lbb_2915                             if r7 == (1 as i32 as i64 as u64) { pc += 1 }
    ja lbb_4854                                     if true { pc += 1939 }
lbb_2915:
    stxdw [r1+0x8], r9                      
    ja lbb_3774                                     if true { pc += 857 }
lbb_2917:
    stxdw [r10-0xc10], r2                   
    stxdw [r10-0xc08], r8                   
    stxdw [r10-0xc00], r1                   
    add64 r9, 1                                     r9 += 1   ///  r9 = r9.wrapping_add(1 as i32 as i64 as u64)
    mov64 r1, r10                                   r1 = r10
    add64 r1, -2922                                 r1 += -2922   ///  r1 = r1.wrapping_add(-2922 as i32 as i64 as u64)
    mov64 r2, r9                                    r2 = r9
    mov64 r3, 64                                    r3 = 64 as i32 as i64 as u64
    call function_30349                     
    jeq r7, 0, lbb_2943                             if r7 == (0 as i32 as i64 as u64) { pc += 16 }
    ldxdw r8, [r10-0xc08]                   
    mov64 r6, r8                                    r6 = r8
    add64 r6, 48                                    r6 += 48   ///  r6 = r6.wrapping_add(48 as i32 as i64 as u64)
    ldxdw r1, [r10-0xc00]                   
    jeq r7, 1, lbb_3773                             if r7 == (1 as i32 as i64 as u64) { pc += 841 }
    add64 r8, 96                                    r8 += 96   ///  r8 = r8.wrapping_add(96 as i32 as i64 as u64)
    jeq r7, 2, lbb_2935                             if r7 == (2 as i32 as i64 as u64) { pc += 1 }
    ja lbb_2950                                     if true { pc += 15 }
lbb_2935:
    stxdw [r1+0x8], r8                      
    ja lbb_3774                                     if true { pc += 837 }
lbb_2937:
    ldxdw r6, [r10-0xc00]                   
    stxdw [r6+0x8], r8                      
    lddw r1, 0x800000000000000a                     r1 load str located at -9223372036854775798
    stxdw [r6+0x0], r1                      
    ja lbb_3730                                     if true { pc += 787 }
lbb_2943:
    ldxdw r2, [r10-0xc00]                   
    ldxdw r1, [r10-0xc08]                   
    stxdw [r2+0x8], r1                      
    lddw r1, 0x800000000000000a                     r1 load str located at -9223372036854775798
    stxdw [r2+0x0], r1                      
    ja lbb_3730                                     if true { pc += 780 }
lbb_2950:
    mov64 r1, r8                                    r1 = r8
    call function_17730                     
    jne r0, 0, lbb_3777                             if r0 != (0 as i32 as i64 as u64) { pc += 824 }
    mov64 r1, 12                                    r1 = 12 as i32 as i64 as u64
lbb_2954:
    ldxdw r2, [r10-0xc00]                   
    ja lbb_7119                                     if true { pc += 4163 }
lbb_2956:
    ldxdw r2, [r10-0xc08]                   
    ldxb r3, [r2+0x88]                      
    ldxdw r1, [r10-0xc00]                   
    jne r3, 0, lbb_2961                             if r3 != (0 as i32 as i64 as u64) { pc += 1 }
    ja lbb_3781                                     if true { pc += 820 }
lbb_2961:
    stxdw [r10-0xc78], r9                   
    stxdw [r10-0xc70], r8                   
    stxdw [r10-0xc68], r7                   
    ldxdw r8, [r2+0x40]                     
    ldxdw r1, [r8+0x10]                     
    lddw r2, 0x7ffffffffffffffe                     r2 load str located at 9223372036854775806
    jgt r1, r2, lbb_2989                            if r1 > r2 { pc += 20 }
    add64 r1, 1                                     r1 += 1   ///  r1 = r1.wrapping_add(1 as i32 as i64 as u64)
    stxdw [r8+0x10], r1                     
    ldxdw r1, [r8+0x18]                     
    ldxdw r2, [r8+0x20]                     
    stxdw [r10-0x150], r2                   
    stxdw [r10-0x158], r1                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -2792                                 r1 += -2792   ///  r1 = r1.wrapping_add(-2792 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -344                                  r2 += -344   ///  r2 = r2.wrapping_add(-344 as i32 as i64 as u64)
    call function_12619                     
    ldxdw r9, [r10-0xae0]                   
    ldxdw r7, [r10-0xae8]                   
    lddw r1, 0x8000000000000000                     r1 load str located at -9223372036854775808
    jeq r7, r1, lbb_2986                            if r7 == r1 { pc += 1 }
    ja lbb_3992                                     if true { pc += 1006 }
lbb_2986:
    ldxdw r1, [r10-0xc00]                   
    mov64 r2, r9                                    r2 = r9
    ja lbb_4849                                     if true { pc += 1860 }
lbb_2989:
    lddw r1, 0x100040f38 --> b"\x00\x00\x00\x000\xe7\x03\x00\x10\x00\x00\x00\x00\x00\x00\x00\xa3\x00\x00…        r1 load str located at 4295233336
    call function_25345                     
lbb_2992:
    jsgt r4, 11, lbb_3606                           if (r4 as i64) > (11 as i32 as i64) { pc += 613 }
    jsgt r4, 9, lbb_3216                            if (r4 as i64) > (9 as i32 as i64) { pc += 222 }
    jeq r4, 8, lbb_6537                             if r4 == (8 as i32 as i64 as u64) { pc += 3542 }
    jeq r7, 0, lbb_2935                             if r7 == (0 as i32 as i64 as u64) { pc += -61 }
    mov64 r9, r8                                    r9 = r8
    add64 r9, 48                                    r9 += 48   ///  r9 = r9.wrapping_add(48 as i32 as i64 as u64)
    jeq r7, 1, lbb_2915                             if r7 == (1 as i32 as i64 as u64) { pc += -84 }
    ldxb r2, [r8+0x58]                      
    jeq r2, 0, lbb_3781                             if r2 == (0 as i32 as i64 as u64) { pc += 780 }
    ldxdw r2, [r8+0x0]                      
    ldxdw r4, [r2+0x0]                      
    lddw r5, 0x9e9974ee626ad71                      r5 load str located at 714268381039471985
    jeq r4, r5, lbb_3008                            if r4 == r5 { pc += 2 }
lbb_3006:
    mov64 r4, 1                                     r4 = 1 as i32 as i64 as u64
    ja lbb_3021                                     if true { pc += 13 }
lbb_3008:
    ldxdw r4, [r2+0x8]                      
    lddw r5, 0xa5b18bf6febdfb8d                     r5 load str located at -6507266093621576819
    jne r4, r5, lbb_3006                            if r4 != r5 { pc += -6 }
    ldxdw r4, [r2+0x10]                     
    lddw r5, 0x3f762b2616a7d0c7                     r5 load str located at 4572889914230165703
    jne r4, r5, lbb_3006                            if r4 != r5 { pc += -10 }
    mov64 r4, 0                                     r4 = 0 as i32 as i64 as u64
    ldxdw r2, [r2+0x18]                     
    lddw r5, 0xe00b8186ff88305d                     r5 load str located at -2302604367657160611
    jne r2, r5, lbb_3006                            if r2 != r5 { pc += -15 }
lbb_3021:
    jne r4, 0, lbb_5436                             if r4 != (0 as i32 as i64 as u64) { pc += 2414 }
    stxdw [r10-0xc00], r1                   
    stxdw [r10-0xc08], r8                   
    ldxdw r8, [r8+0x10]                     
    ldxdw r1, [r8+0x10]                     
    lddw r2, 0x7fffffffffffffff                     r2 load str located at 9223372036854775807
    jgt r2, r1, lbb_3030                            if r2 > r1 { pc += 1 }
    ja lbb_3136                                     if true { pc += 106 }
lbb_3030:
    add64 r1, 1                                     r1 += 1   ///  r1 = r1.wrapping_add(1 as i32 as i64 as u64)
    stxdw [r8+0x10], r1                     
    ldxdw r1, [r8+0x18]                     
    ldxdw r2, [r8+0x20]                     
    stxdw [r10-0x150], r2                   
    stxdw [r10-0x158], r1                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -2792                                 r1 += -2792   ///  r1 = r1.wrapping_add(-2792 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -344                                  r2 += -344   ///  r2 = r2.wrapping_add(-344 as i32 as i64 as u64)
    call function_12619                     
    ldxdw r7, [r10-0xae0]                   
    ldxdw r6, [r10-0xae8]                   
    lddw r1, 0x8000000000000000                     r1 load str located at -9223372036854775808
    jeq r6, r1, lbb_7079                            if r6 == r1 { pc += 4033 }
    mov64 r1, r10                                   r1 = r10
    add64 r1, -1480                                 r1 += -1480   ///  r1 = r1.wrapping_add(-1480 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -2776                                 r2 += -2776   ///  r2 = r2.wrapping_add(-2776 as i32 as i64 as u64)
    mov64 r3, 528                                   r3 = 528 as i32 as i64 as u64
    call function_30349                     
    stxdw [r10-0x5d0], r7                   
    stxdw [r10-0x5d8], r6                   
    ldxdw r7, [r8+0x10]                     
    add64 r7, -1                                    r7 += -1   ///  r7 = r7.wrapping_add(-1 as i32 as i64 as u64)
    stxdw [r8+0x10], r7                     
    ldxdw r2, [r9+0x0]                      
    ldxdw r1, [r2+0x0]                      
    ldxdw r3, [r10-0x5a8]                   
    jeq r1, r3, lbb_3063                            if r1 == r3 { pc += 2 }
lbb_3061:
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    ja lbb_3073                                     if true { pc += 10 }
lbb_3063:
    ldxdw r1, [r2+0x8]                      
    ldxdw r3, [r10-0x5a0]                   
    jne r1, r3, lbb_3061                            if r1 != r3 { pc += -5 }
    ldxdw r1, [r2+0x10]                     
    ldxdw r3, [r10-0x598]                   
    jne r1, r3, lbb_3061                            if r1 != r3 { pc += -8 }
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    ldxdw r3, [r2+0x18]                     
    ldxdw r4, [r10-0x590]                   
    jne r3, r4, lbb_3061                            if r3 != r4 { pc += -12 }
lbb_3073:
    lddw r4, 0x800000000000001a                     r4 load str located at -9223372036854775782
    jeq r1, 0, lbb_3078                             if r1 == (0 as i32 as i64 as u64) { pc += 2 }
    lddw r4, 0x8000000000000000                     r4 load str located at -9223372036854775808
lbb_3078:
    ldxdw r5, [r2+0x0]                      
    ldxdw r0, [r10-0x588]                   
    ldxdw r3, [r10-0xc00]                   
    jeq r5, r0, lbb_3084                            if r5 == r0 { pc += 2 }
lbb_3082:
    mov64 r5, 1                                     r5 = 1 as i32 as i64 as u64
    ja lbb_3094                                     if true { pc += 10 }
lbb_3084:
    ldxdw r5, [r2+0x8]                      
    ldxdw r0, [r10-0x580]                   
    jne r5, r0, lbb_3082                            if r5 != r0 { pc += -5 }
    ldxdw r5, [r2+0x10]                     
    ldxdw r0, [r10-0x578]                   
    jne r5, r0, lbb_3082                            if r5 != r0 { pc += -8 }
    mov64 r5, 0                                     r5 = 0 as i32 as i64 as u64
    ldxdw r2, [r2+0x18]                     
    ldxdw r0, [r10-0x570]                   
    jne r2, r0, lbb_3082                            if r2 != r0 { pc += -12 }
lbb_3094:
    lddw r2, 0x800000000000001a                     r2 load str located at -9223372036854775782
    jeq r5, 0, lbb_3099                             if r5 == (0 as i32 as i64 as u64) { pc += 2 }
    lddw r2, 0x8000000000000000                     r2 load str located at -9223372036854775808
lbb_3099:
    mov64 r0, 3                                     r0 = 3 as i32 as i64 as u64
    stxw [r10-0xac8], r0                    
    stxw [r10-0xae0], r0                    
    stxdw [r10-0xae8], r4                   
    stxdw [r10-0xad0], r2                   
    jeq r1, 0, lbb_3107                             if r1 == (0 as i32 as i64 as u64) { pc += 2 }
    jeq r5, 0, lbb_3107                             if r5 == (0 as i32 as i64 as u64) { pc += 1 }
    ja lbb_6768                                     if true { pc += 3661 }
lbb_3107:
    mov64 r1, r10                                   r1 = r10
    add64 r1, -2792                                 r1 += -2792   ///  r1 = r1.wrapping_add(-2792 as i32 as i64 as u64)
    call function_461                       
    ldxdw r1, [r10-0xc08]                   
    ldxb r1, [r1+0x29]                      
    jeq r1, 0, lbb_3759                             if r1 == (0 as i32 as i64 as u64) { pc += 646 }
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    stxb [r10-0x3c4], r1                    
    jeq r7, 0, lbb_3117                             if r7 == (0 as i32 as i64 as u64) { pc += 1 }
    ja lbb_3139                                     if true { pc += 22 }
lbb_3117:
    mov64 r1, -1                                    r1 = -1 as i32 as i64 as u64
    stxdw [r8+0x10], r1                     
    ldxdw r1, [r8+0x18]                     
    ldxdw r2, [r8+0x20]                     
    stxdw [r10-0xae0], r2                   
    stxdw [r10-0xae8], r1                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -1496                                 r1 += -1496   ///  r1 = r1.wrapping_add(-1496 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -2792                                 r2 += -2792   ///  r2 = r2.wrapping_add(-2792 as i32 as i64 as u64)
    call function_13019                     
    jeq r0, 0, lbb_6800                             if r0 == (0 as i32 as i64 as u64) { pc += 3671 }
lbb_3129:
    ldxdw r1, [r10-0xc00]                   
    mov64 r2, r0                                    r2 = r0
    call function_18093                     
    ldxdw r1, [r8+0x10]                     
    add64 r1, 1                                     r1 += 1   ///  r1 = r1.wrapping_add(1 as i32 as i64 as u64)
    stxdw [r8+0x10], r1                     
    ja lbb_3730                                     if true { pc += 594 }
lbb_3136:
    lddw r1, 0x100041148 --> b"\x00\x00\x00\x000\xe7\x03\x00\x10\x00\x00\x00\x00\x00\x00\x00\xa8\x02\x00…        r1 load str located at 4295233864
    call function_25345                     
lbb_3139:
    lddw r1, 0x100041130 --> b"\x00\x00\x00\x000\xe7\x03\x00\x10\x00\x00\x00\x00\x00\x00\x00\xb4\x02\x00…        r1 load str located at 4295233840
    call function_25324                     
lbb_3142:
    jsgt r4, 5, lbb_3334                            if (r4 as i64) > (5 as i32 as i64) { pc += 191 }
    jeq r4, 4, lbb_5415                             if r4 == (4 as i32 as i64 as u64) { pc += 2271 }
    jeq r7, 0, lbb_2935                             if r7 == (0 as i32 as i64 as u64) { pc += -210 }
    mov64 r6, r8                                    r6 = r8
    add64 r6, 48                                    r6 += 48   ///  r6 = r6.wrapping_add(48 as i32 as i64 as u64)
    jeq r7, 1, lbb_3773                             if r7 == (1 as i32 as i64 as u64) { pc += 625 }
    mov64 r5, r8                                    r5 = r8
    add64 r5, 96                                    r5 += 96   ///  r5 = r5.wrapping_add(96 as i32 as i64 as u64)
    jeq r7, 2, lbb_3362                             if r7 == (2 as i32 as i64 as u64) { pc += 211 }
    mov64 r4, r8                                    r4 = r8
    add64 r4, 144                                   r4 += 144   ///  r4 = r4.wrapping_add(144 as i32 as i64 as u64)
    jeq r7, 3, lbb_4530                             if r7 == (3 as i32 as i64 as u64) { pc += 1376 }
    mov64 r3, r8                                    r3 = r8
    add64 r3, 192                                   r3 += 192   ///  r3 = r3.wrapping_add(192 as i32 as i64 as u64)
    jeq r7, 4, lbb_4528                             if r7 == (4 as i32 as i64 as u64) { pc += 1371 }
    stxdw [r10-0xc18], r5                   
    stxdw [r10-0xc20], r4                   
    ldxdw r4, [r8+0x0]                      
    ldxdw r5, [r4+0x0]                      
    lddw r0, 0x9e9974ee626ad71                      r0 load str located at 714268381039471985
    jeq r5, r0, lbb_3198                            if r5 == r0 { pc += 34 }
lbb_3164:
    mov64 r5, 1                                     r5 = 1 as i32 as i64 as u64
    jeq r5, 0, lbb_3167                             if r5 == (0 as i32 as i64 as u64) { pc += 1 }
    ja lbb_5436                                     if true { pc += 2269 }
lbb_3167:
    stxdw [r10-0xc28], r3                   
    stxdw [r10-0xc10], r2                   
    stxdw [r10-0xc00], r1                   
    stxdw [r10-0xc08], r8                   
    ldxdw r7, [r8+0x10]                     
    ldxdw r1, [r7+0x10]                     
    lddw r2, 0x7fffffffffffffff                     r2 load str located at 9223372036854775807
    jgt r2, r1, lbb_3177                            if r2 > r1 { pc += 1 }
    ja lbb_3213                                     if true { pc += 36 }
lbb_3177:
    ldxh r8, [r9+0x6]                       
    ldxw r9, [r9+0x2]                       
    add64 r1, 1                                     r1 += 1   ///  r1 = r1.wrapping_add(1 as i32 as i64 as u64)
    stxdw [r7+0x10], r1                     
    ldxdw r1, [r7+0x18]                     
    ldxdw r2, [r7+0x20]                     
    stxdw [r10-0x150], r2                   
    stxdw [r10-0x158], r1                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -2792                                 r1 += -2792   ///  r1 = r1.wrapping_add(-2792 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -344                                  r2 += -344   ///  r2 = r2.wrapping_add(-344 as i32 as i64 as u64)
    call function_12619                     
    lddw r1, 0x8000000000000000                     r1 load str located at -9223372036854775808
    ldxdw r2, [r10-0xae8]                   
    jeq r2, r1, lbb_3195                            if r2 == r1 { pc += 1 }
    ja lbb_5788                                     if true { pc += 2593 }
lbb_3195:
    ldxdw r2, [r10-0xae0]                   
    ldxdw r1, [r10-0xc00]                   
    ja lbb_4415                                     if true { pc += 1217 }
lbb_3198:
    ldxdw r5, [r4+0x8]                      
    lddw r0, 0xa5b18bf6febdfb8d                     r0 load str located at -6507266093621576819
    jne r5, r0, lbb_3164                            if r5 != r0 { pc += -38 }
    ldxdw r5, [r4+0x10]                     
    lddw r0, 0x3f762b2616a7d0c7                     r0 load str located at 4572889914230165703
    jne r5, r0, lbb_3164                            if r5 != r0 { pc += -42 }
    mov64 r5, 0                                     r5 = 0 as i32 as i64 as u64
    ldxdw r4, [r4+0x18]                     
    lddw r0, 0xe00b8186ff88305d                     r0 load str located at -2302604367657160611
    jne r4, r0, lbb_3164                            if r4 != r0 { pc += -47 }
    jeq r5, 0, lbb_3167                             if r5 == (0 as i32 as i64 as u64) { pc += -45 }
    ja lbb_5436                                     if true { pc += 2223 }
lbb_3213:
    lddw r1, 0x100041028 --> b"\x00\x00\x00\x000\xe7\x03\x00\x10\x00\x00\x00\x00\x00\x00\x00\xd2\x01\x00…        r1 load str located at 4295233576
    call function_25345                     
lbb_3216:
    jeq r4, 10, lbb_3499                            if r4 == (10 as i32 as i64 as u64) { pc += 282 }
    jeq r7, 0, lbb_2935                             if r7 == (0 as i32 as i64 as u64) { pc += -283 }
    mov64 r6, r8                                    r6 = r8
    add64 r6, 48                                    r6 += 48   ///  r6 = r6.wrapping_add(48 as i32 as i64 as u64)
    jeq r7, 1, lbb_3773                             if r7 == (1 as i32 as i64 as u64) { pc += 552 }
    ldxb r2, [r8+0x58]                      
    jeq r2, 0, lbb_3781                             if r2 == (0 as i32 as i64 as u64) { pc += 558 }
    ldxdw r2, [r8+0x0]                      
    ldxdw r4, [r2+0x0]                      
    lddw r5, 0x9e9974ee626ad71                      r5 load str located at 714268381039471985
    jeq r4, r5, lbb_3230                            if r4 == r5 { pc += 2 }
lbb_3228:
    mov64 r4, 1                                     r4 = 1 as i32 as i64 as u64
    ja lbb_3243                                     if true { pc += 13 }
lbb_3230:
    ldxdw r4, [r2+0x8]                      
    lddw r5, 0xa5b18bf6febdfb8d                     r5 load str located at -6507266093621576819
    jne r4, r5, lbb_3228                            if r4 != r5 { pc += -6 }
    ldxdw r4, [r2+0x10]                     
    lddw r5, 0x3f762b2616a7d0c7                     r5 load str located at 4572889914230165703
    jne r4, r5, lbb_3228                            if r4 != r5 { pc += -10 }
    mov64 r4, 0                                     r4 = 0 as i32 as i64 as u64
    ldxdw r2, [r2+0x18]                     
    lddw r5, 0xe00b8186ff88305d                     r5 load str located at -2302604367657160611
    jne r2, r5, lbb_3228                            if r2 != r5 { pc += -15 }
lbb_3243:
    jne r4, 0, lbb_5436                             if r4 != (0 as i32 as i64 as u64) { pc += 2192 }
    ldxb r2, [r8+0x29]                      
    jeq r2, 0, lbb_3426                             if r2 == (0 as i32 as i64 as u64) { pc += 180 }
    stxdw [r10-0xc00], r1                   
    ldxdw r8, [r8+0x10]                     
    ldxdw r1, [r8+0x10]                     
    lddw r2, 0x7fffffffffffffff                     r2 load str located at 9223372036854775807
    jgt r2, r1, lbb_3253                            if r2 > r1 { pc += 1 }
    ja lbb_3328                                     if true { pc += 75 }
lbb_3253:
    add64 r1, 1                                     r1 += 1   ///  r1 = r1.wrapping_add(1 as i32 as i64 as u64)
    stxdw [r8+0x10], r1                     
    ldxdw r1, [r8+0x18]                     
    ldxdw r2, [r8+0x20]                     
    stxdw [r10-0x150], r2                   
    stxdw [r10-0x158], r1                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -2792                                 r1 += -2792   ///  r1 = r1.wrapping_add(-2792 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -344                                  r2 += -344   ///  r2 = r2.wrapping_add(-344 as i32 as i64 as u64)
    call function_12619                     
    ldxdw r2, [r10-0xae0]                   
    ldxdw r7, [r10-0xae8]                   
    lddw r1, 0x8000000000000000                     r1 load str located at -9223372036854775808
    jeq r7, r1, lbb_3404                            if r7 == r1 { pc += 135 }
    mov64 r1, r10                                   r1 = r10
    add64 r1, -1480                                 r1 += -1480   ///  r1 = r1.wrapping_add(-1480 as i32 as i64 as u64)
    stxdw [r10-0xc08], r2                   
    mov64 r2, r10                                   r2 = r10
    add64 r2, -2776                                 r2 += -2776   ///  r2 = r2.wrapping_add(-2776 as i32 as i64 as u64)
    mov64 r3, 528                                   r3 = 528 as i32 as i64 as u64
    call function_30349                     
    ldxdw r1, [r10-0xc08]                   
    stxdw [r10-0x5d0], r1                   
    stxdw [r10-0x5d8], r7                   
    ldxdw r1, [r8+0x10]                     
    add64 r1, -1                                    r1 += -1   ///  r1 = r1.wrapping_add(-1 as i32 as i64 as u64)
    stxdw [r8+0x10], r1                     
    ldxdw r2, [r6+0x0]                      
    ldxdw r3, [r2+0x0]                      
    ldxdw r4, [r10-0x5a8]                   
    jeq r3, r4, lbb_3288                            if r3 == r4 { pc += 2 }
lbb_3286:
    mov64 r3, 1                                     r3 = 1 as i32 as i64 as u64
    ja lbb_3298                                     if true { pc += 10 }
lbb_3288:
    ldxdw r3, [r2+0x8]                      
    ldxdw r4, [r10-0x5a0]                   
    jne r3, r4, lbb_3286                            if r3 != r4 { pc += -5 }
    ldxdw r3, [r2+0x10]                     
    ldxdw r4, [r10-0x598]                   
    jne r3, r4, lbb_3286                            if r3 != r4 { pc += -8 }
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
    ldxdw r2, [r2+0x18]                     
    ldxdw r4, [r10-0x590]                   
    jne r2, r4, lbb_3286                            if r2 != r4 { pc += -12 }
lbb_3298:
    ldxdw r2, [r10-0xc00]                   
    jeq r3, 0, lbb_3301                             if r3 == (0 as i32 as i64 as u64) { pc += 1 }
    ja lbb_6621                                     if true { pc += 3320 }
lbb_3301:
    ldxb r3, [r10-0x3c4]                    
    jeq r3, 0, lbb_3304                             if r3 == (0 as i32 as i64 as u64) { pc += 1 }
    ja lbb_7126                                     if true { pc += 3822 }
lbb_3304:
    add64 r9, 1                                     r9 += 1   ///  r9 = r9.wrapping_add(1 as i32 as i64 as u64)
    ldxdw r2, [r9+0x18]                     
    stxdw [r10-0x550], r2                   
    ldxdw r2, [r9+0x10]                     
    stxdw [r10-0x558], r2                   
    ldxdw r2, [r9+0x8]                      
    stxdw [r10-0x560], r2                   
    ldxdw r2, [r9+0x0]                      
    stxdw [r10-0x568], r2                   
    jeq r1, 0, lbb_3315                             if r1 == (0 as i32 as i64 as u64) { pc += 1 }
    ja lbb_3331                                     if true { pc += 16 }
lbb_3315:
    mov64 r1, -1                                    r1 = -1 as i32 as i64 as u64
    stxdw [r8+0x10], r1                     
    ldxdw r1, [r8+0x18]                     
    ldxdw r2, [r8+0x20]                     
    stxdw [r10-0xae0], r2                   
    stxdw [r10-0xae8], r1                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -1496                                 r1 += -1496   ///  r1 = r1.wrapping_add(-1496 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -2792                                 r2 += -2792   ///  r2 = r2.wrapping_add(-2792 as i32 as i64 as u64)
    call function_13019                     
    jeq r0, 0, lbb_6800                             if r0 == (0 as i32 as i64 as u64) { pc += 3473 }
    ja lbb_3129                                     if true { pc += -199 }
lbb_3328:
    lddw r1, 0x100041118 --> b"\x00\x00\x00\x000\xe7\x03\x00\x10\x00\x00\x00\x00\x00\x00\x00\x91\x02\x00…        r1 load str located at 4295233816
    call function_25345                     
lbb_3331:
    lddw r1, 0x100041100 --> b"\x00\x00\x00\x000\xe7\x03\x00\x10\x00\x00\x00\x00\x00\x00\x00\x99\x02\x00…        r1 load str located at 4295233792
    call function_25324                     
lbb_3334:
    jeq r4, 6, lbb_3348                             if r4 == (6 as i32 as i64 as u64) { pc += 13 }
    jeq r7, 0, lbb_2935                             if r7 == (0 as i32 as i64 as u64) { pc += -401 }
    mov64 r6, r8                                    r6 = r8
    add64 r6, 48                                    r6 += 48   ///  r6 = r6.wrapping_add(48 as i32 as i64 as u64)
    jeq r7, 1, lbb_3773                             if r7 == (1 as i32 as i64 as u64) { pc += 434 }
    ldxb r2, [r8+0x58]                      
    jeq r2, 0, lbb_3781                             if r2 == (0 as i32 as i64 as u64) { pc += 440 }
    ldxdw r2, [r8+0x0]                      
    ldxdw r4, [r2+0x0]                      
    lddw r5, 0x9e9974ee626ad71                      r5 load str located at 714268381039471985
    jeq r4, r5, lbb_3364                            if r4 == r5 { pc += 18 }
lbb_3346:
    mov64 r4, 1                                     r4 = 1 as i32 as i64 as u64
    ja lbb_3377                                     if true { pc += 29 }
lbb_3348:
    jeq r7, 0, lbb_2935                             if r7 == (0 as i32 as i64 as u64) { pc += -414 }
    mov64 r6, r8                                    r6 = r8
    add64 r6, 48                                    r6 += 48   ///  r6 = r6.wrapping_add(48 as i32 as i64 as u64)
    jeq r7, 1, lbb_3773                             if r7 == (1 as i32 as i64 as u64) { pc += 421 }
    mov64 r3, r8                                    r3 = r8
    add64 r3, 96                                    r3 += 96   ///  r3 = r3.wrapping_add(96 as i32 as i64 as u64)
    jeq r7, 2, lbb_4528                             if r7 == (2 as i32 as i64 as u64) { pc += 1173 }
    mov64 r4, r8                                    r4 = r8
    add64 r4, 144                                   r4 += 144   ///  r4 = r4.wrapping_add(144 as i32 as i64 as u64)
    jeq r7, 3, lbb_4530                             if r7 == (3 as i32 as i64 as u64) { pc += 1172 }
    mov64 r5, r8                                    r5 = r8
    add64 r5, 192                                   r5 += 192   ///  r5 = r5.wrapping_add(192 as i32 as i64 as u64)
    jeq r7, 4, lbb_3362                             if r7 == (4 as i32 as i64 as u64) { pc += 1 }
    ja lbb_3406                                     if true { pc += 44 }
lbb_3362:
    stxdw [r1+0x8], r5                      
    ja lbb_3774                                     if true { pc += 410 }
lbb_3364:
    ldxdw r4, [r2+0x8]                      
    lddw r5, 0xa5b18bf6febdfb8d                     r5 load str located at -6507266093621576819
    jne r4, r5, lbb_3346                            if r4 != r5 { pc += -22 }
    ldxdw r4, [r2+0x10]                     
    lddw r5, 0x3f762b2616a7d0c7                     r5 load str located at 4572889914230165703
    jne r4, r5, lbb_3346                            if r4 != r5 { pc += -26 }
    mov64 r4, 0                                     r4 = 0 as i32 as i64 as u64
    ldxdw r2, [r2+0x18]                     
    lddw r5, 0xe00b8186ff88305d                     r5 load str located at -2302604367657160611
    jne r2, r5, lbb_3346                            if r2 != r5 { pc += -31 }
lbb_3377:
    jne r4, 0, lbb_5436                             if r4 != (0 as i32 as i64 as u64) { pc += 2058 }
    ldxb r2, [r8+0x29]                      
    jeq r2, 0, lbb_3426                             if r2 == (0 as i32 as i64 as u64) { pc += 46 }
    stxdw [r10-0xc00], r1                   
    ldxdw r8, [r8+0x10]                     
    ldxdw r1, [r8+0x10]                     
    lddw r2, 0x7fffffffffffffff                     r2 load str located at 9223372036854775807
    jgt r2, r1, lbb_3387                            if r2 > r1 { pc += 1 }
    ja lbb_3493                                     if true { pc += 106 }
lbb_3387:
    add64 r1, 1                                     r1 += 1   ///  r1 = r1.wrapping_add(1 as i32 as i64 as u64)
    stxdw [r8+0x10], r1                     
    ldxdw r1, [r8+0x18]                     
    ldxdw r2, [r8+0x20]                     
    stxdw [r10-0x150], r2                   
    stxdw [r10-0x158], r1                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -2792                                 r1 += -2792   ///  r1 = r1.wrapping_add(-2792 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -344                                  r2 += -344   ///  r2 = r2.wrapping_add(-344 as i32 as i64 as u64)
    call function_12619                     
    ldxdw r2, [r10-0xae0]                   
    ldxdw r7, [r10-0xae8]                   
    lddw r1, 0x8000000000000000                     r1 load str located at -9223372036854775808
    jeq r7, r1, lbb_3404                            if r7 == r1 { pc += 1 }
    ja lbb_6473                                     if true { pc += 3069 }
lbb_3404:
    ldxdw r1, [r10-0xc00]                   
    ja lbb_4849                                     if true { pc += 1443 }
lbb_3406:
    jeq r7, 5, lbb_3408                             if r7 == (5 as i32 as i64 as u64) { pc += 1 }
    ja lbb_3410                                     if true { pc += 2 }
lbb_3408:
    add64 r8, 240                                   r8 += 240   ///  r8 = r8.wrapping_add(240 as i32 as i64 as u64)
    ja lbb_2935                                     if true { pc += -475 }
lbb_3410:
    mov64 r0, r8                                    r0 = r8
    add64 r0, 288                                   r0 += 288   ///  r0 = r0.wrapping_add(288 as i32 as i64 as u64)
    jeq r7, 6, lbb_3626                             if r7 == (6 as i32 as i64 as u64) { pc += 213 }
    stxdw [r10-0xc28], r0                   
    stxdw [r10-0xc20], r5                   
    stxdw [r10-0xc18], r4                   
    ldxdw r4, [r8+0x0]                      
    ldxdw r5, [r4+0x0]                      
    lddw r0, 0x9e9974ee626ad71                      r0 load str located at 714268381039471985
    jeq r5, r0, lbb_3428                            if r5 == r0 { pc += 7 }
lbb_3421:
    mov64 r5, 1                                     r5 = 1 as i32 as i64 as u64
    jeq r5, 0, lbb_3424                             if r5 == (0 as i32 as i64 as u64) { pc += 1 }
    ja lbb_5436                                     if true { pc += 2012 }
lbb_3424:
    ldxb r4, [r8+0x29]                      
    jeq r4, 0, lbb_3443                             if r4 == (0 as i32 as i64 as u64) { pc += 17 }
lbb_3426:
    mov64 r2, 1                                     r2 = 1 as i32 as i64 as u64
    ja lbb_3782                                     if true { pc += 354 }
lbb_3428:
    ldxdw r5, [r4+0x8]                      
    lddw r0, 0xa5b18bf6febdfb8d                     r0 load str located at -6507266093621576819
    jne r5, r0, lbb_3421                            if r5 != r0 { pc += -11 }
    ldxdw r5, [r4+0x10]                     
    lddw r0, 0x3f762b2616a7d0c7                     r0 load str located at 4572889914230165703
    jne r5, r0, lbb_3421                            if r5 != r0 { pc += -15 }
    mov64 r5, 0                                     r5 = 0 as i32 as i64 as u64
    ldxdw r4, [r4+0x18]                     
    lddw r0, 0xe00b8186ff88305d                     r0 load str located at -2302604367657160611
    jne r4, r0, lbb_3421                            if r4 != r0 { pc += -20 }
    jeq r5, 0, lbb_3424                             if r5 == (0 as i32 as i64 as u64) { pc += -18 }
    ja lbb_5436                                     if true { pc += 1993 }
lbb_3443:
    stxdw [r10-0xc38], r3                   
    stxdw [r10-0xc10], r2                   
    stxdw [r10-0xc00], r1                   
    ldxh r1, [r9+0x14]                      
    stxdw [r10-0xc48], r1                   
    ldxh r1, [r9+0x12]                      
    stxdw [r10-0xc40], r1                   
    ldxh r1, [r9+0x10]                      
    stxdw [r10-0xc30], r1                   
    ldxdw r1, [r9+0x8]                      
    stxdw [r10-0xc50], r1                   
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    stxdw [r10-0x380], r1                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -152                                  r1 += -152   ///  r1 = r1.wrapping_add(-152 as i32 as i64 as u64)
    stxdw [r10-0x388], r1                   
    mov64 r1, 5                                     r1 = 5 as i32 as i64 as u64
    stxdw [r10-0x390], r1                   
    lddw r1, 0x10003e6f5 --> b"AC_01\x00\x00\x00\x00\x00\x00connection resetassertion `left ) when "        r1 load str located at 4295223029
    stxdw [r10-0x398], r1                   
    mov64 r1, 255                                   r1 = 255 as i32 as i64 as u64
    stxb [r10-0x98], r1                     
    stxdw [r10-0xc08], r8                   
    ldxdw r7, [r8+0x10]                     
    ldxdw r1, [r7+0x10]                     
    lddw r2, 0x7fffffffffffffff                     r2 load str located at 9223372036854775807
    jgt r2, r1, lbb_3473                            if r2 > r1 { pc += 1 }
    ja lbb_3496                                     if true { pc += 23 }
lbb_3473:
    add64 r1, 1                                     r1 += 1   ///  r1 = r1.wrapping_add(1 as i32 as i64 as u64)
    stxdw [r7+0x10], r1                     
    ldxdw r1, [r7+0x18]                     
    ldxdw r2, [r7+0x20]                     
    stxdw [r10-0x150], r2                   
    stxdw [r10-0x158], r1                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -2792                                 r1 += -2792   ///  r1 = r1.wrapping_add(-2792 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -344                                  r2 += -344   ///  r2 = r2.wrapping_add(-344 as i32 as i64 as u64)
    call function_12619                     
    ldxdw r8, [r10-0xae0]                   
    ldxdw r9, [r10-0xae8]                   
    lddw r1, 0x8000000000000000                     r1 load str located at -9223372036854775808
    jeq r9, r1, lbb_3490                            if r9 == r1 { pc += 1 }
    ja lbb_6092                                     if true { pc += 2602 }
lbb_3490:
    ldxdw r1, [r10-0xc00]                   
    mov64 r2, r8                                    r2 = r8
    ja lbb_4415                                     if true { pc += 922 }
lbb_3493:
    lddw r1, 0x1000410b8 --> b"\x00\x00\x00\x000\xe7\x03\x00\x10\x00\x00\x00\x00\x00\x00\x00`\x02\x00\x0…        r1 load str located at 4295233720
    call function_25345                     
lbb_3496:
    lddw r1, 0x100041088 --> b"\x00\x00\x00\x000\xe7\x03\x00\x10\x00\x00\x00\x00\x00\x00\x00\x12\x02\x00…        r1 load str located at 4295233672
    call function_25345                     
lbb_3499:
    jeq r7, 0, lbb_2935                             if r7 == (0 as i32 as i64 as u64) { pc += -565 }
    mov64 r9, r8                                    r9 = r8
    add64 r9, 48                                    r9 += 48   ///  r9 = r9.wrapping_add(48 as i32 as i64 as u64)
    jeq r7, 1, lbb_2915                             if r7 == (1 as i32 as i64 as u64) { pc += -588 }
    ldxb r2, [r8+0x58]                      
    jeq r2, 0, lbb_3781                             if r2 == (0 as i32 as i64 as u64) { pc += 276 }
    ldxdw r2, [r8+0x0]                      
    ldxdw r4, [r2+0x0]                      
    lddw r5, 0x9e9974ee626ad71                      r5 load str located at 714268381039471985
    jeq r4, r5, lbb_3512                            if r4 == r5 { pc += 2 }
lbb_3510:
    mov64 r4, 1                                     r4 = 1 as i32 as i64 as u64
    ja lbb_3525                                     if true { pc += 13 }
lbb_3512:
    ldxdw r4, [r2+0x8]                      
    lddw r5, 0xa5b18bf6febdfb8d                     r5 load str located at -6507266093621576819
    jne r4, r5, lbb_3510                            if r4 != r5 { pc += -6 }
    ldxdw r4, [r2+0x10]                     
    lddw r5, 0x3f762b2616a7d0c7                     r5 load str located at 4572889914230165703
    jne r4, r5, lbb_3510                            if r4 != r5 { pc += -10 }
    mov64 r4, 0                                     r4 = 0 as i32 as i64 as u64
    ldxdw r2, [r2+0x18]                     
    lddw r5, 0xe00b8186ff88305d                     r5 load str located at -2302604367657160611
    jne r2, r5, lbb_3510                            if r2 != r5 { pc += -15 }
lbb_3525:
    jne r4, 0, lbb_5436                             if r4 != (0 as i32 as i64 as u64) { pc += 1910 }
    stxdw [r10-0xc00], r1                   
    stxdw [r10-0xc08], r8                   
    ldxdw r8, [r8+0x10]                     
    ldxdw r1, [r8+0x10]                     
    lddw r2, 0x7fffffffffffffff                     r2 load str located at 9223372036854775807
    jgt r2, r1, lbb_3534                            if r2 > r1 { pc += 1 }
    ja lbb_3600                                     if true { pc += 66 }
lbb_3534:
    add64 r1, 1                                     r1 += 1   ///  r1 = r1.wrapping_add(1 as i32 as i64 as u64)
    stxdw [r8+0x10], r1                     
    ldxdw r1, [r8+0x18]                     
    ldxdw r2, [r8+0x20]                     
    stxdw [r10-0x150], r2                   
    stxdw [r10-0x158], r1                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -2792                                 r1 += -2792   ///  r1 = r1.wrapping_add(-2792 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -344                                  r2 += -344   ///  r2 = r2.wrapping_add(-344 as i32 as i64 as u64)
    call function_12619                     
    ldxdw r7, [r10-0xae0]                   
    ldxdw r6, [r10-0xae8]                   
    lddw r1, 0x8000000000000000                     r1 load str located at -9223372036854775808
    jeq r6, r1, lbb_7079                            if r6 == r1 { pc += 3529 }
    mov64 r1, r10                                   r1 = r10
    add64 r1, -1480                                 r1 += -1480   ///  r1 = r1.wrapping_add(-1480 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -2776                                 r2 += -2776   ///  r2 = r2.wrapping_add(-2776 as i32 as i64 as u64)
    mov64 r3, 528                                   r3 = 528 as i32 as i64 as u64
    call function_30349                     
    stxdw [r10-0x5d0], r7                   
    stxdw [r10-0x5d8], r6                   
    ldxdw r1, [r8+0x10]                     
    add64 r1, -1                                    r1 += -1   ///  r1 = r1.wrapping_add(-1 as i32 as i64 as u64)
    stxdw [r8+0x10], r1                     
    ldxdw r2, [r9+0x0]                      
    ldxdw r3, [r2+0x0]                      
    ldxdw r4, [r10-0x5a8]                   
    jeq r3, r4, lbb_3567                            if r3 == r4 { pc += 2 }
lbb_3565:
    mov64 r3, 1                                     r3 = 1 as i32 as i64 as u64
    ja lbb_3577                                     if true { pc += 10 }
lbb_3567:
    ldxdw r3, [r2+0x8]                      
    ldxdw r4, [r10-0x5a0]                   
    jne r3, r4, lbb_3565                            if r3 != r4 { pc += -5 }
    ldxdw r3, [r2+0x10]                     
    ldxdw r4, [r10-0x598]                   
    jne r3, r4, lbb_3565                            if r3 != r4 { pc += -8 }
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
    ldxdw r2, [r2+0x18]                     
    ldxdw r4, [r10-0x590]                   
    jne r2, r4, lbb_3565                            if r2 != r4 { pc += -12 }
lbb_3577:
    ldxdw r2, [r10-0xc00]                   
    ldxdw r4, [r10-0xc08]                   
    jeq r3, 0, lbb_3581                             if r3 == (0 as i32 as i64 as u64) { pc += 1 }
    ja lbb_6621                                     if true { pc += 3040 }
lbb_3581:
    ldxb r3, [r4+0x29]                      
    jeq r3, 0, lbb_7173                             if r3 == (0 as i32 as i64 as u64) { pc += 3590 }
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
    stxb [r10-0x3c4], r2                    
    jeq r1, 0, lbb_3587                             if r1 == (0 as i32 as i64 as u64) { pc += 1 }
    ja lbb_3603                                     if true { pc += 16 }
lbb_3587:
    mov64 r1, -1                                    r1 = -1 as i32 as i64 as u64
    stxdw [r8+0x10], r1                     
    ldxdw r1, [r8+0x18]                     
    ldxdw r2, [r8+0x20]                     
    stxdw [r10-0xae0], r2                   
    stxdw [r10-0xae8], r1                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -1496                                 r1 += -1496   ///  r1 = r1.wrapping_add(-1496 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -2792                                 r2 += -2792   ///  r2 = r2.wrapping_add(-2792 as i32 as i64 as u64)
    call function_13019                     
    jeq r0, 0, lbb_6800                             if r0 == (0 as i32 as i64 as u64) { pc += 3201 }
    ja lbb_3129                                     if true { pc += -471 }
lbb_3600:
    lddw r1, 0x100041178 --> b"\x00\x00\x00\x000\xe7\x03\x00\x10\x00\x00\x00\x00\x00\x00\x00\xc3\x02\x00…        r1 load str located at 4295233912
    call function_25345                     
lbb_3603:
    lddw r1, 0x100041160 --> b"\x00\x00\x00\x000\xe7\x03\x00\x10\x00\x00\x00\x00\x00\x00\x00\xc8\x02\x00…        r1 load str located at 4295233888
    call function_25324                     
lbb_3606:
    jsgt r4, 13, lbb_3610                           if (r4 as i64) > (13 as i32 as i64) { pc += 3 }
    jeq r4, 12, lbb_6655                            if r4 == (12 as i32 as i64 as u64) { pc += 3047 }
lbb_3608:
    mov64 r2, 3                                     r2 = 3 as i32 as i64 as u64
    ja lbb_3782                                     if true { pc += 172 }
lbb_3610:
    jeq r4, 14, lbb_3675                            if r4 == (14 as i32 as i64 as u64) { pc += 64 }
    jeq r4, 15, lbb_7023                            if r4 == (15 as i32 as i64 as u64) { pc += 3411 }
    jeq r7, 0, lbb_2935                             if r7 == (0 as i32 as i64 as u64) { pc += -678 }
    mov64 r6, r8                                    r6 = r8
    add64 r6, 48                                    r6 += 48   ///  r6 = r6.wrapping_add(48 as i32 as i64 as u64)
    jeq r7, 1, lbb_3773                             if r7 == (1 as i32 as i64 as u64) { pc += 157 }
    mov64 r3, r8                                    r3 = r8
    add64 r3, 96                                    r3 += 96   ///  r3 = r3.wrapping_add(96 as i32 as i64 as u64)
    jeq r7, 2, lbb_4528                             if r7 == (2 as i32 as i64 as u64) { pc += 909 }
    mov64 r4, r8                                    r4 = r8
    add64 r4, 144                                   r4 += 144   ///  r4 = r4.wrapping_add(144 as i32 as i64 as u64)
    jeq r7, 3, lbb_4530                             if r7 == (3 as i32 as i64 as u64) { pc += 908 }
    mov64 r0, r8                                    r0 = r8
    add64 r0, 192                                   r0 += 192   ///  r0 = r0.wrapping_add(192 as i32 as i64 as u64)
    jeq r7, 4, lbb_3626                             if r7 == (4 as i32 as i64 as u64) { pc += 1 }
    ja lbb_3628                                     if true { pc += 2 }
lbb_3626:
    stxdw [r1+0x8], r0                      
    ja lbb_3774                                     if true { pc += 146 }
lbb_3628:
    mov64 r5, r8                                    r5 = r8
    add64 r5, 240                                   r5 += 240   ///  r5 = r5.wrapping_add(240 as i32 as i64 as u64)
    jeq r7, 5, lbb_3362                             if r7 == (5 as i32 as i64 as u64) { pc += -269 }
    stxdw [r10-0xc18], r5                   
    mov64 r5, r8                                    r5 = r8
    add64 r5, 288                                   r5 += 288   ///  r5 = r5.wrapping_add(288 as i32 as i64 as u64)
    jeq r7, 6, lbb_3362                             if r7 == (6 as i32 as i64 as u64) { pc += -273 }
    stxdw [r10-0xc20], r3                   
    mov64 r3, r8                                    r3 = r8
    add64 r3, 336                                   r3 += 336   ///  r3 = r3.wrapping_add(336 as i32 as i64 as u64)
    jeq r7, 7, lbb_4528                             if r7 == (7 as i32 as i64 as u64) { pc += 889 }
    stxdw [r10-0xc30], r3                   
    stxdw [r10-0xc28], r0                   
    mov64 r0, r8                                    r0 = r8
    add64 r0, 384                                   r0 += 384   ///  r0 = r0.wrapping_add(384 as i32 as i64 as u64)
    jeq r7, 8, lbb_3626                             if r7 == (8 as i32 as i64 as u64) { pc += -18 }
    mov64 r3, r8                                    r3 = r8
    add64 r3, 432                                   r3 += 432   ///  r3 = r3.wrapping_add(432 as i32 as i64 as u64)
    stxdw [r10-0xc38], r3                   
    jeq r7, 9, lbb_3649                             if r7 == (9 as i32 as i64 as u64) { pc += 1 }
    ja lbb_3652                                     if true { pc += 3 }
lbb_3649:
    ldxdw r2, [r10-0xc38]                   
    stxdw [r1+0x8], r2                      
    ja lbb_3774                                     if true { pc += 122 }
lbb_3652:
    stxdw [r10-0xc58], r0                   
    stxdw [r10-0xc50], r5                   
    stxdw [r10-0xc48], r4                   
    stxdw [r10-0xc10], r2                   
    stxdw [r10-0xc00], r1                   
    stxdw [r10-0xc08], r8                   
    add64 r8, 480                                   r8 += 480   ///  r8 = r8.wrapping_add(480 as i32 as i64 as u64)
    stxdw [r10-0xc40], r8                   
    jeq r7, 10, lbb_3662                            if r7 == (10 as i32 as i64 as u64) { pc += 1 }
    ja lbb_3666                                     if true { pc += 4 }
lbb_3662:
    ldxdw r1, [r10-0xc00]                   
    ldxdw r2, [r10-0xc40]                   
    stxdw [r1+0x8], r2                      
    ja lbb_3774                                     if true { pc += 108 }
lbb_3666:
    ldxdw r1, [r10-0xc08]                   
    add64 r1, 528                                   r1 += 528   ///  r1 = r1.wrapping_add(528 as i32 as i64 as u64)
    stxdw [r10-0xc60], r1                   
    jeq r7, 11, lbb_3671                            if r7 == (11 as i32 as i64 as u64) { pc += 1 }
    ja lbb_3731                                     if true { pc += 60 }
lbb_3671:
    ldxdw r1, [r10-0xc00]                   
    ldxdw r2, [r10-0xc60]                   
    stxdw [r1+0x8], r2                      
    ja lbb_3774                                     if true { pc += 99 }
lbb_3675:
    jeq r7, 0, lbb_2935                             if r7 == (0 as i32 as i64 as u64) { pc += -741 }
    mov64 r6, r8                                    r6 = r8
    add64 r6, 48                                    r6 += 48   ///  r6 = r6.wrapping_add(48 as i32 as i64 as u64)
    jeq r7, 1, lbb_3773                             if r7 == (1 as i32 as i64 as u64) { pc += 94 }
    mov64 r3, r8                                    r3 = r8
    add64 r3, 96                                    r3 += 96   ///  r3 = r3.wrapping_add(96 as i32 as i64 as u64)
    jeq r7, 2, lbb_4528                             if r7 == (2 as i32 as i64 as u64) { pc += 846 }
    ldxb r4, [r8+0x58]                      
    jeq r4, 0, lbb_3781                             if r4 == (0 as i32 as i64 as u64) { pc += 97 }
    ldxdw r5, [r2+0x0]                      
    ldxdw r4, [r8+0x18]                     
    ldxdw r0, [r4+0x0]                      
    jeq r0, r5, lbb_3690                            if r0 == r5 { pc += 2 }
lbb_3688:
    mov64 r5, 1                                     r5 = 1 as i32 as i64 as u64
    ja lbb_3700                                     if true { pc += 10 }
lbb_3690:
    ldxdw r5, [r2+0x8]                      
    ldxdw r0, [r4+0x8]                      
    jne r0, r5, lbb_3688                            if r0 != r5 { pc += -5 }
    ldxdw r5, [r2+0x10]                     
    ldxdw r0, [r4+0x10]                     
    jne r0, r5, lbb_3688                            if r0 != r5 { pc += -8 }
    mov64 r5, 0                                     r5 = 0 as i32 as i64 as u64
    ldxdw r0, [r2+0x18]                     
    ldxdw r4, [r4+0x18]                     
    jne r4, r0, lbb_3688                            if r4 != r0 { pc += -12 }
lbb_3700:
    jne r5, 0, lbb_3728                             if r5 != (0 as i32 as i64 as u64) { pc += 27 }
    stxdw [r10-0xc00], r3                   
    stxdw [r10-0xc10], r2                   
    mov64 r7, r1                                    r7 = r1
    ldxb r1, [r9+0x28]                      
    stxdw [r10-0xc40], r1                   
    ldxw r1, [r9+0x24]                      
    stxdw [r10-0xc20], r1                   
    ldxw r1, [r9+0x20]                      
    stxdw [r10-0xc18], r1                   
    ldxw r1, [r9+0x1c]                      
    stxdw [r10-0xc38], r1                   
    ldxw r1, [r9+0x18]                      
    stxdw [r10-0xc30], r1                   
    ldxdw r1, [r9+0x10]                     
    stxdw [r10-0xc28], r1                   
    ldxdw r9, [r9+0x8]                      
    stxdw [r10-0xc08], r8                   
    mov64 r1, r8                                    r1 = r8
    call function_17730                     
    jne r0, 0, lbb_3722                             if r0 != (0 as i32 as i64 as u64) { pc += 1 }
    ja lbb_6810                                     if true { pc += 3088 }
lbb_3722:
    mov64 r1, 21                                    r1 = 21 as i32 as i64 as u64
lbb_3723:
    stxw [r7+0x8], r1                       
    lddw r1, 0x8000000000000000                     r1 load str located at -9223372036854775808
    stxdw [r7+0x0], r1                      
    ja lbb_3730                                     if true { pc += 2 }
lbb_3728:
    mov64 r2, 2                                     r2 = 2 as i32 as i64 as u64
    ja lbb_3782                                     if true { pc += 52 }
lbb_3730:
    exit                                    
lbb_3731:
    ldxdw r1, [r10-0xc08]                   
    ldxb r1, [r1+0x88]                      
    jeq r1, 0, lbb_6152                             if r1 == (0 as i32 as i64 as u64) { pc += 2418 }
    ldxdw r1, [r10-0xc10]                   
    ldxdw r2, [r1+0x0]                      
    ldxdw r1, [r10-0xc08]                   
    ldxdw r1, [r1+0x18]                     
    ldxdw r3, [r1+0x0]                      
    jeq r3, r2, lbb_3742                            if r3 == r2 { pc += 2 }
lbb_3740:
    mov64 r2, 1                                     r2 = 1 as i32 as i64 as u64
    ja lbb_3755                                     if true { pc += 13 }
lbb_3742:
    ldxdw r2, [r10-0xc10]                   
    ldxdw r2, [r2+0x8]                      
    ldxdw r3, [r1+0x8]                      
    jne r3, r2, lbb_3740                            if r3 != r2 { pc += -6 }
    ldxdw r2, [r10-0xc10]                   
    ldxdw r2, [r2+0x10]                     
    ldxdw r3, [r1+0x10]                     
    jne r3, r2, lbb_3740                            if r3 != r2 { pc += -10 }
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
    ldxdw r3, [r10-0xc10]                   
    ldxdw r3, [r3+0x18]                     
    ldxdw r1, [r1+0x18]                     
    jne r1, r3, lbb_3740                            if r1 != r3 { pc += -15 }
lbb_3755:
    jne r2, 0, lbb_4598                             if r2 != (0 as i32 as i64 as u64) { pc += 842 }
    ldxdw r1, [r10-0xc08]                   
    ldxb r1, [r1+0x29]                      
    jeq r1, 0, lbb_3761                             if r1 == (0 as i32 as i64 as u64) { pc += 2 }
lbb_3759:
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    ja lbb_2954                                     if true { pc += -807 }
lbb_3761:
    ldxb r8, [r9+0x18]                      
    ldxdw r1, [r9+0x10]                     
    stxdw [r10-0xc70], r1                   
    ldxdw r1, [r9+0x8]                      
    stxdw [r10-0xc68], r1                   
    ldxdw r1, [r10-0xc08]                   
    call function_17730                     
    jne r0, 0, lbb_3770                             if r0 != (0 as i32 as i64 as u64) { pc += 1 }
    ja lbb_7190                                     if true { pc += 3420 }
lbb_3770:
    mov64 r1, 21                                    r1 = 21 as i32 as i64 as u64
    ja lbb_2954                                     if true { pc += -818 }
lbb_3772:
    ldxdw r1, [r10-0xc00]                   
lbb_3773:
    stxdw [r1+0x8], r6                      
lbb_3774:
    lddw r2, 0x800000000000000a                     r2 load str located at -9223372036854775798
    ja lbb_3789                                     if true { pc += 12 }
lbb_3777:
    ldxdw r2, [r10-0xc08]                   
    ldxb r3, [r2+0x28]                      
    ldxdw r1, [r10-0xc00]                   
    jne r3, 0, lbb_3784                             if r3 != (0 as i32 as i64 as u64) { pc += 3 }
lbb_3781:
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
lbb_3782:
    stxw [r1+0x8], r2                       
    ja lbb_3787                                     if true { pc += 3 }
lbb_3784:
    ldxb r3, [r2+0x58]                      
    jne r3, 0, lbb_3791                             if r3 != (0 as i32 as i64 as u64) { pc += 5 }
    ja lbb_3781                                     if true { pc += -6 }
lbb_3787:
    lddw r2, 0x8000000000000000                     r2 load str located at -9223372036854775808
lbb_3789:
    stxdw [r1+0x0], r2                      
    ja lbb_3730                                     if true { pc += -61 }
lbb_3791:
    ldxdw r3, [r6+0x0]                      
    ldxdw r4, [r3+0x0]                      
    lddw r5, 0xfc3e34becfcb63d7                     r5 load str located at -270720933461007401
    jeq r4, r5, lbb_3798                            if r4 == r5 { pc += 2 }
lbb_3796:
    mov64 r4, 1                                     r4 = 1 as i32 as i64 as u64
    ja lbb_3811                                     if true { pc += 13 }
lbb_3798:
    ldxdw r4, [r3+0x8]                      
    lddw r5, 0xf495c87a5045cbbb                     r5 load str located at -822530929266930757
    jne r4, r5, lbb_3796                            if r4 != r5 { pc += -6 }
    ldxdw r4, [r3+0x10]                     
    lddw r5, 0xe7d24322df5eeb7c                     r5 load str located at -1742256288783471748
    jne r4, r5, lbb_3796                            if r4 != r5 { pc += -10 }
    mov64 r4, 0                                     r4 = 0 as i32 as i64 as u64
    ldxdw r3, [r3+0x18]                     
    lddw r5, 0xcf66dbb77498e62b                     r5 load str located at -3501870079252306389
    jne r3, r5, lbb_3796                            if r3 != r5 { pc += -15 }
lbb_3811:
    jne r4, 0, lbb_3608                             if r4 != (0 as i32 as i64 as u64) { pc += -204 }
    ldxdw r3, [r8+0x0]                      
    ldxdw r4, [r3+0x0]                      
    lddw r5, 0x9e9974ee626ad71                      r5 load str located at 714268381039471985
    jeq r4, r5, lbb_3865                            if r4 == r5 { pc += 48 }
lbb_3817:
    mov64 r4, 1                                     r4 = 1 as i32 as i64 as u64
    jeq r4, 0, lbb_3820                             if r4 == (0 as i32 as i64 as u64) { pc += 1 }
    ja lbb_5436                                     if true { pc += 1616 }
lbb_3820:
    ldxb r3, [r2+0x89]                      
    jeq r3, 0, lbb_3426                             if r3 == (0 as i32 as i64 as u64) { pc += -396 }
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    stxdw [r10-0xad0], r1                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -344                                  r1 += -344   ///  r1 = r1.wrapping_add(-344 as i32 as i64 as u64)
    stxdw [r10-0xad8], r1                   
    mov64 r1, 5                                     r1 = 5 as i32 as i64 as u64
    stxdw [r10-0xae0], r1                   
    lddw r1, 0x10003e6f5 --> b"AC_01\x00\x00\x00\x00\x00\x00connection resetassertion `left ) when "        r1 load str located at 4295223029
    stxdw [r10-0xae8], r1                   
    mov64 r1, 255                                   r1 = 255 as i32 as i64 as u64
    stxb [r10-0x158], r1                    
    mov64 r1, 2                                     r1 = 2 as i32 as i64 as u64
    stxdw [r10-0xff8], r1                   
    mov64 r1, 10240                                 r1 = 10240 as i32 as i64 as u64
    stxdw [r10-0xff0], r1                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -2792                                 r1 += -2792   ///  r1 = r1.wrapping_add(-2792 as i32 as i64 as u64)
    stxdw [r10-0x1000], r1                  
    mov64 r1, r10                                   r1 = r10
    add64 r1, -1496                                 r1 += -1496   ///  r1 = r1.wrapping_add(-1496 as i32 as i64 as u64)
    mov64 r5, r10                                   r5 = r10
    mov64 r3, r8                                    r3 = r8
    ldxdw r4, [r10-0xc10]                   
    call function_8492                      
    lddw r1, 0x800000000000001a                     r1 load str located at -9223372036854775782
    ldxdw r2, [r10-0x5d8]                   
    jeq r2, r1, lbb_3852                            if r2 == r1 { pc += 1 }
    ja lbb_3880                                     if true { pc += 28 }
lbb_3852:
    mov64 r1, r10                                   r1 = r10
    add64 r1, -1496                                 r1 += -1496   ///  r1 = r1.wrapping_add(-1496 as i32 as i64 as u64)
    call function_9272                      
    ldxdw r7, [r10-0x5c0]                   
    ldxdw r8, [r10-0x5c8]                   
    ldxdw r6, [r10-0x5d0]                   
    ldxdw r1, [r10-0x5d8]                   
    jeq r1, 0, lbb_3888                             if r1 == (0 as i32 as i64 as u64) { pc += 28 }
    ldxdw r1, [r10-0xc00]                   
    stxdw [r1+0x10], r7                     
    stxdw [r1+0x8], r8                      
    stxdw [r1+0x0], r6                      
    ja lbb_3730                                     if true { pc += -135 }
lbb_3865:
    ldxdw r4, [r3+0x8]                      
    lddw r5, 0xa5b18bf6febdfb8d                     r5 load str located at -6507266093621576819
    jne r4, r5, lbb_3817                            if r4 != r5 { pc += -52 }
    ldxdw r4, [r3+0x10]                     
    lddw r5, 0x3f762b2616a7d0c7                     r5 load str located at 4572889914230165703
    jne r4, r5, lbb_3817                            if r4 != r5 { pc += -56 }
    mov64 r4, 0                                     r4 = 0 as i32 as i64 as u64
    ldxdw r3, [r3+0x18]                     
    lddw r5, 0xe00b8186ff88305d                     r5 load str located at -2302604367657160611
    jne r3, r5, lbb_3817                            if r3 != r5 { pc += -61 }
    jeq r4, 0, lbb_3820                             if r4 == (0 as i32 as i64 as u64) { pc += -59 }
    ja lbb_5436                                     if true { pc += 1556 }
lbb_3880:
    ldxdw r1, [r10-0x5c8]                   
    ldxdw r2, [r10-0xc00]                   
    stxdw [r2+0x10], r1                     
    ldxdw r1, [r10-0x5d0]                   
    stxdw [r2+0x8], r1                      
    ldxdw r1, [r10-0x5d8]                   
    stxdw [r2+0x0], r1                      
    ja lbb_3730                                     if true { pc += -158 }
lbb_3888:
    mov64 r1, r10                                   r1 = r10
    add64 r1, -1496                                 r1 += -1496   ///  r1 = r1.wrapping_add(-1496 as i32 as i64 as u64)
    call function_9272                      
    ldxdw r1, [r10-0x5d0]                   
    stxdw [r10-0x158], r1                   
    ldxdw r1, [r10-0x5c8]                   
    stxdw [r10-0x150], r1                   
    ldxdw r1, [r10-0x5c0]                   
    stxdw [r10-0x148], r1                   
    ldxdw r1, [r10-0x5d8]                   
    jeq r1, 0, lbb_3907                             if r1 == (0 as i32 as i64 as u64) { pc += 8 }
    ldxdw r1, [r10-0x148]                   
    ldxdw r2, [r10-0xc00]                   
    stxdw [r2+0x10], r1                     
    ldxdw r1, [r10-0x150]                   
    stxdw [r2+0x8], r1                      
    ldxdw r1, [r10-0x158]                   
    stxdw [r2+0x0], r1                      
    ja lbb_3730                                     if true { pc += -177 }
lbb_3907:
    mov64 r1, r10                                   r1 = r10
    add64 r1, -2890                                 r1 += -2890   ///  r1 = r1.wrapping_add(-2890 as i32 as i64 as u64)
    ldxdw r2, [r10-0x148]                   
    stxdw [r10-0xad8], r2                   
    ldxdw r2, [r10-0x150]                   
    stxdw [r10-0xae0], r2                   
    ldxdw r2, [r10-0x158]                   
    stxdw [r10-0xae8], r2                   
    ldxdw r2, [r9+0x18]                     
    ldxdw r3, [r9+0x10]                     
    ldxdw r4, [r9+0x8]                      
    ldxdw r5, [r9+0x0]                      
    lddw r0, 0xfc3e34becfcb63d7                     r0 load str located at -270720933461007401
    stxdw [r10-0xa98], r0                   
    lddw r0, 0xf495c87a5045cbbb                     r0 load str located at -822530929266930757
    stxdw [r10-0xa90], r0                   
    lddw r0, 0xe7d24322df5eeb7c                     r0 load str located at -1742256288783471748
    stxdw [r10-0xa88], r0                   
    lddw r0, 0xcf66dbb77498e62b                     r0 load str located at -3501870079252306389
    stxdw [r10-0xa80], r0                   
    stxdw [r10-0xab8], r5                   
    stxdw [r10-0xab0], r4                   
    stxdw [r10-0xaa8], r3                   
    stxdw [r10-0xaa0], r2                   
    ldxdw r2, [r1+0x18]                     
    ldxdw r3, [r1+0x10]                     
    ldxdw r4, [r1+0x8]                      
    ldxdw r1, [r1+0x0]                      
    mov64 r5, 16843009                              r5 = 16843009 as i32 as i64 as u64
    stxb [r10-0x8ce], r5                    
    stxw [r10-0x8d2], r5                    
    stxdw [r10-0xa78], r1                   
    stxdw [r10-0xa70], r4                   
    stxdw [r10-0xa68], r3                   
    stxdw [r10-0xa60], r2                   
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    stxh [r10-0x8d4], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -2648                                 r1 += -2648   ///  r1 = r1.wrapping_add(-2648 as i32 as i64 as u64)
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
    mov64 r3, 388                                   r3 = 388 as i32 as i64 as u64
    call function_30383                     
    stxdw [r10-0xac0], r7                   
    stxdw [r10-0xac8], r8                   
    stxdw [r10-0xad0], r6                   
    ldxdw r1, [r10-0xc08]                   
    ldxdw r6, [r1+0x70]                     
    ldxdw r1, [r6+0x10]                     
    jeq r1, 0, lbb_3961                             if r1 == (0 as i32 as i64 as u64) { pc += 1 }
    ja lbb_3978                                     if true { pc += 17 }
lbb_3961:
    mov64 r1, -1                                    r1 = -1 as i32 as i64 as u64
    stxdw [r6+0x10], r1                     
    ldxdw r1, [r6+0x18]                     
    ldxdw r2, [r6+0x20]                     
    stxdw [r10-0x5d0], r2                   
    stxdw [r10-0x5d8], r1                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -2792                                 r1 += -2792   ///  r1 = r1.wrapping_add(-2792 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -1496                                 r2 += -1496   ///  r2 = r2.wrapping_add(-1496 as i32 as i64 as u64)
    call function_13019                     
    jeq r0, 0, lbb_3974                             if r0 == (0 as i32 as i64 as u64) { pc += 1 }
    ja lbb_3985                                     if true { pc += 11 }
lbb_3974:
    ldxdw r1, [r6+0x10]                     
    add64 r1, 1                                     r1 += 1   ///  r1 = r1.wrapping_add(1 as i32 as i64 as u64)
    stxdw [r6+0x10], r1                     
    ja lbb_3981                                     if true { pc += 3 }
lbb_3978:
    lddw r1, 0x100040ea8 --> b"\x00\x00\x00\x000\xe7\x03\x00\x10\x00\x00\x00\x00\x00\x00\x00\x8a\x00\x00…        r1 load str located at 4295233192
    call function_25324                     
lbb_3981:
    lddw r2, 0x800000000000001a                     r2 load str located at -9223372036854775782
    ldxdw r1, [r10-0xc00]                   
    ja lbb_3789                                     if true { pc += -196 }
lbb_3985:
    ldxdw r1, [r10-0xc00]                   
    mov64 r2, r0                                    r2 = r0
    call function_18093                     
lbb_3988:
    ldxdw r1, [r6+0x10]                     
    add64 r1, 1                                     r1 += 1   ///  r1 = r1.wrapping_add(1 as i32 as i64 as u64)
    stxdw [r6+0x10], r1                     
    ja lbb_3730                                     if true { pc += -262 }
lbb_3992:
    mov64 r1, r10                                   r1 = r10
    add64 r1, -1480                                 r1 += -1480   ///  r1 = r1.wrapping_add(-1480 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -2776                                 r2 += -2776   ///  r2 = r2.wrapping_add(-2776 as i32 as i64 as u64)
    mov64 r3, 528                                   r3 = 528 as i32 as i64 as u64
    call function_30349                     
    stxdw [r10-0x5d0], r9                   
    stxdw [r10-0x5d8], r7                   
    ldxdw r1, [r8+0x10]                     
    add64 r1, -1                                    r1 += -1   ///  r1 = r1.wrapping_add(-1 as i32 as i64 as u64)
    stxdw [r8+0x10], r1                     
    lddw r1, 0xfc3e34becfcb63d7                     r1 load str located at -270720933461007401
    ldxdw r2, [r10-0x588]                   
    jeq r2, r1, lbb_4010                            if r2 == r1 { pc += 3 }
lbb_4007:
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    jeq r1, 0, lbb_4025                             if r1 == (0 as i32 as i64 as u64) { pc += 16 }
lbb_4009:
    ja lbb_6109                                     if true { pc += 2099 }
lbb_4010:
    lddw r1, 0xf495c87a5045cbbb                     r1 load str located at -822530929266930757
    ldxdw r2, [r10-0x580]                   
    jne r2, r1, lbb_4007                            if r2 != r1 { pc += -7 }
    lddw r1, 0xe7d24322df5eeb7c                     r1 load str located at -1742256288783471748
    ldxdw r2, [r10-0x578]                   
    jne r2, r1, lbb_4007                            if r2 != r1 { pc += -11 }
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    lddw r2, 0xcf66dbb77498e62b                     r2 load str located at -3501870079252306389
    ldxdw r3, [r10-0x570]                   
    jne r3, r2, lbb_4007                            if r3 != r2 { pc += -16 }
    jeq r1, 0, lbb_4025                             if r1 == (0 as i32 as i64 as u64) { pc += 1 }
    ja lbb_4009                                     if true { pc += -16 }
lbb_4025:
    ldxdw r1, [r10-0xc18]                   
    ldxdw r1, [r1+0x0]                      
    ldxdw r2, [r1+0x0]                      
    ldxdw r3, [r10-0x588]                   
    jeq r2, r3, lbb_4033                            if r2 == r3 { pc += 3 }
lbb_4030:
    mov64 r2, 1                                     r2 = 1 as i32 as i64 as u64
    jeq r2, 0, lbb_4045                             if r2 == (0 as i32 as i64 as u64) { pc += 13 }
lbb_4032:
    ja lbb_5830                                     if true { pc += 1797 }
lbb_4033:
    ldxdw r2, [r1+0x8]                      
    ldxdw r3, [r10-0x580]                   
    jne r2, r3, lbb_4030                            if r2 != r3 { pc += -6 }
    ldxdw r2, [r1+0x10]                     
    ldxdw r3, [r10-0x578]                   
    jne r2, r3, lbb_4030                            if r2 != r3 { pc += -9 }
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
    ldxdw r1, [r1+0x18]                     
    ldxdw r3, [r10-0x570]                   
    jne r1, r3, lbb_4030                            if r1 != r3 { pc += -13 }
    jeq r2, 0, lbb_4045                             if r2 == (0 as i32 as i64 as u64) { pc += 1 }
    ja lbb_4032                                     if true { pc += -13 }
lbb_4045:
    ldxdw r1, [r6+0x0]                      
    ldxdw r2, [r1+0x0]                      
    lddw r3, 0x9e9974ee626ad71                      r3 load str located at 714268381039471985
    jeq r2, r3, lbb_4059                            if r2 == r3 { pc += 9 }
lbb_4050:
    mov64 r2, 1                                     r2 = 1 as i32 as i64 as u64
    jeq r2, 0, lbb_4074                             if r2 == (0 as i32 as i64 as u64) { pc += 22 }
lbb_4052:
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    ldxdw r2, [r10-0xc00]                   
    stxb [r2+0xb], r1                       
    stxh [r2+0x9], r1                       
    mov64 r1, 23                                    r1 = 23 as i32 as i64 as u64
    stxb [r2+0x8], r1                       
    ja lbb_7120                                     if true { pc += 3061 }
lbb_4059:
    ldxdw r2, [r1+0x8]                      
    lddw r3, 0xa5b18bf6febdfb8d                     r3 load str located at -6507266093621576819
    jne r2, r3, lbb_4050                            if r2 != r3 { pc += -13 }
    ldxdw r2, [r1+0x10]                     
    lddw r3, 0x3f762b2616a7d0c7                     r3 load str located at 4572889914230165703
    jne r2, r3, lbb_4050                            if r2 != r3 { pc += -17 }
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
    ldxdw r1, [r1+0x18]                     
    lddw r3, 0xe00b8186ff88305d                     r3 load str located at -2302604367657160611
    jne r1, r3, lbb_4050                            if r1 != r3 { pc += -22 }
    jeq r2, 0, lbb_4074                             if r2 == (0 as i32 as i64 as u64) { pc += 1 }
    ja lbb_4052                                     if true { pc += -22 }
lbb_4074:
    ldxdw r1, [r10-0xc08]                   
    ldxb r1, [r1+0x59]                      
    jeq r1, 0, lbb_3759                             if r1 == (0 as i32 as i64 as u64) { pc += -318 }
    ldxb r1, [r10-0x3c4]                    
    jeq r1, 0, lbb_4080                             if r1 == (0 as i32 as i64 as u64) { pc += 1 }
    ja lbb_6128                                     if true { pc += 2048 }
lbb_4080:
    ldxh r9, [r10-0x3c6]                    
    add64 r9, 1                                     r9 += 1   ///  r9 = r9.wrapping_add(1 as i32 as i64 as u64)
    stxh [r10-0x3c6], r9                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -2792                                 r1 += -2792   ///  r1 = r1.wrapping_add(-2792 as i32 as i64 as u64)
    ldxdw r2, [r10-0xc10]                   
    ldxdw r3, [r10-0xc20]                   
    mov64 r4, r9                                    r4 = r9
    call function_9195                      
    ldxb r1, [r10-0xae0]                    
    stxdw [r10-0xc18], r1                   
    ldxdw r1, [r10-0xae8]                   
    lddw r2, 0x800000000000001a                     r2 load str located at -9223372036854775782
    jeq r1, r2, lbb_4096                            if r1 == r2 { pc += 1 }
    ja lbb_4143                                     if true { pc += 47 }
lbb_4096:
    ldxdw r1, [r10-0xc08]                   
    ldxb r1, [r1+0xb9]                      
    jeq r1, 0, lbb_3759                             if r1 == (0 as i32 as i64 as u64) { pc += -340 }
    mov64 r1, r10                                   r1 = r10
    add64 r1, -2792                                 r1 += -2792   ///  r1 = r1.wrapping_add(-2792 as i32 as i64 as u64)
    ldxdw r2, [r10-0xc10]                   
    ldxdw r3, [r10-0xc30]                   
    ldxdw r4, [r10-0xc28]                   
    call function_9118                      
    ldxdw r1, [r10-0xae8]                   
    lddw r6, 0x800000000000001a                     r6 load str located at -9223372036854775782
    jeq r1, r6, lbb_4110                            if r1 == r6 { pc += 1 }
    ja lbb_6248                                     if true { pc += 2138 }
lbb_4110:
    mov64 r1, r10                                   r1 = r10
    add64 r1, -2792                                 r1 += -2792   ///  r1 = r1.wrapping_add(-2792 as i32 as i64 as u64)
    ldxdw r2, [r10-0xc10]                   
    ldxdw r3, [r10-0xc38]                   
    ldxdw r4, [r10-0xc68]                   
    call function_9118                      
    ldxdw r1, [r10-0xae8]                   
    jeq r1, r6, lbb_4119                            if r1 == r6 { pc += 1 }
    ja lbb_6248                                     if true { pc += 2129 }
lbb_4119:
    ldxdw r1, [r10-0xc08]                   
    ldxdw r7, [r1+0xd0]                     
    ldxdw r1, [r7+0x10]                     
    lddw r2, 0x7fffffffffffffff                     r2 load str located at 9223372036854775807
    jgt r2, r1, lbb_4126                            if r2 > r1 { pc += 1 }
    ja lbb_4194                                     if true { pc += 68 }
lbb_4126:
    add64 r1, 1                                     r1 += 1   ///  r1 = r1.wrapping_add(1 as i32 as i64 as u64)
    stxdw [r7+0x10], r1                     
    ldxdw r3, [r7+0x20]                     
    ldxdw r2, [r7+0x18]                     
    mov64 r1, r10                                   r1 = r10
    add64 r1, -2792                                 r1 += -2792   ///  r1 = r1.wrapping_add(-2792 as i32 as i64 as u64)
    call function_0                         
    ldxw r1, [r10-0xa50]                    
    jeq r1, 2, lbb_4136                             if r1 == (2 as i32 as i64 as u64) { pc += 1 }
    ja lbb_4152                                     if true { pc += 16 }
lbb_4136:
    ldxdw r1, [r10-0xad8]                   
    stxdw [r10-0x148], r1                   
    ldxdw r2, [r10-0xae0]                   
    stxdw [r10-0x150], r2                   
    ldxdw r3, [r10-0xae8]                   
    stxdw [r10-0x158], r3                   
    ja lbb_4200                                     if true { pc += 57 }
lbb_4143:
    ldxdw r2, [r10-0xad8]                   
    ldxdw r3, [r10-0xc00]                   
    stxdw [r3+0x10], r2                     
    ldxdw r2, [r10-0xadf]                   
    stxdw [r3+0x9], r2                      
    ldxdw r2, [r10-0xc18]                   
    stxb [r3+0x8], r2                       
    stxdw [r3+0x0], r1                      
    ja lbb_3730                                     if true { pc += -422 }
lbb_4152:
    mov64 r6, r10                                   r6 = r10
    add64 r6, -344                                  r6 += -344   ///  r6 = r6.wrapping_add(-344 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -2792                                 r2 += -2792   ///  r2 = r2.wrapping_add(-2792 as i32 as i64 as u64)
    mov64 r1, r6                                    r1 = r6
    mov64 r3, 152                                   r3 = 152 as i32 as i64 as u64
    call function_30349                     
    mov64 r1, r10                                   r1 = r10
    add64 r1, -536                                  r1 += -536   ///  r1 = r1.wrapping_add(-536 as i32 as i64 as u64)
    mov64 r2, r6                                    r2 = r6
    mov64 r3, 152                                   r3 = 152 as i32 as i64 as u64
    call function_30349                     
    ldxdw r1, [r10-0xc08]                   
    ldxdw r1, [r1+0x100]                    
    stxdw [r10-0xc30], r1                   
    ldxdw r1, [r1+0x10]                     
    lddw r2, 0x7fffffffffffffff                     r2 load str located at 9223372036854775807
    jgt r2, r1, lbb_4172                            if r2 > r1 { pc += 1 }
    ja lbb_4197                                     if true { pc += 25 }
lbb_4172:
    add64 r1, 1                                     r1 += 1   ///  r1 = r1.wrapping_add(1 as i32 as i64 as u64)
    ldxdw r2, [r10-0xc30]                   
    stxdw [r2+0x10], r1                     
    ldxdw r3, [r2+0x20]                     
    ldxdw r2, [r2+0x18]                     
    mov64 r1, r10                                   r1 = r10
    add64 r1, -2792                                 r1 += -2792   ///  r1 = r1.wrapping_add(-2792 as i32 as i64 as u64)
    call function_0                         
    ldxw r1, [r10-0xa50]                    
    jeq r1, 2, lbb_4183                             if r1 == (2 as i32 as i64 as u64) { pc += 1 }
    ja lbb_4205                                     if true { pc += 22 }
lbb_4183:
    ldxdw r1, [r10-0xad8]                   
    stxdw [r10-0x2c8], r1                   
    ldxdw r2, [r10-0xae0]                   
    stxdw [r10-0x2d0], r2                   
    ldxdw r3, [r10-0xae8]                   
    stxdw [r10-0x2d8], r3                   
    ldxdw r4, [r10-0xc00]                   
    stxdw [r4+0x10], r1                     
    stxdw [r4+0x8], r2                      
    stxdw [r4+0x0], r3                      
    ja lbb_4290                                     if true { pc += 96 }
lbb_4194:
    lddw r1, 0x100040f20 --> b"\x00\x00\x00\x000\xe7\x03\x00\x10\x00\x00\x00\x00\x00\x00\x00\xc0\x00\x00…        r1 load str located at 4295233312
    call function_25345                     
lbb_4197:
    lddw r1, 0x100040f08 --> b"\x00\x00\x00\x000\xe7\x03\x00\x10\x00\x00\x00\x00\x00\x00\x00\xc3\x00\x00…        r1 load str located at 4295233288
    call function_25345                     
lbb_4200:
    ldxdw r4, [r10-0xc00]                   
    stxdw [r4+0x10], r1                     
    stxdw [r4+0x8], r2                      
    stxdw [r4+0x0], r3                      
    ja lbb_4416                                     if true { pc += 211 }
lbb_4205:
    mov64 r6, r10                                   r6 = r10
    add64 r6, -728                                  r6 += -728   ///  r6 = r6.wrapping_add(-728 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -2792                                 r2 += -2792   ///  r2 = r2.wrapping_add(-2792 as i32 as i64 as u64)
    mov64 r1, r6                                    r1 = r6
    mov64 r3, 152                                   r3 = 152 as i32 as i64 as u64
    call function_30349                     
    mov64 r1, r10                                   r1 = r10
    add64 r1, -344                                  r1 += -344   ///  r1 = r1.wrapping_add(-344 as i32 as i64 as u64)
    mov64 r2, r6                                    r2 = r6
    mov64 r3, 152                                   r3 = 152 as i32 as i64 as u64
    call function_30349                     
    ldxdw r1, [r10-0x148]                   
    ldxdw r2, [r10-0x208]                   
    jeq r2, r1, lbb_4222                            if r2 == r1 { pc += 2 }
lbb_4220:
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    ja lbb_4232                                     if true { pc += 10 }
lbb_4222:
    ldxdw r1, [r10-0x140]                   
    ldxdw r2, [r10-0x200]                   
    jne r2, r1, lbb_4220                            if r2 != r1 { pc += -5 }
    ldxdw r1, [r10-0x138]                   
    ldxdw r2, [r10-0x1f8]                   
    jne r2, r1, lbb_4220                            if r2 != r1 { pc += -8 }
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    ldxdw r2, [r10-0x130]                   
    ldxdw r3, [r10-0x1f0]                   
    jne r3, r2, lbb_4220                            if r3 != r2 { pc += -12 }
lbb_4232:
    jeq r1, 0, lbb_4277                             if r1 == (0 as i32 as i64 as u64) { pc += 44 }
    mov64 r1, r9                                    r1 = r9
    be16 r1                                         r1 = match 16 { 16 => (r1 as u16).swap_bytes() as u64, 32 => (r1 as u32).swap_bytes() as u64, 64 => r1.swap_bytes(), _ => r1 }
    stxh [r10-0x398], r1                    
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    stxdw [r10-0xac0], r1                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -152                                  r1 += -152   ///  r1 = r1.wrapping_add(-152 as i32 as i64 as u64)
    stxdw [r10-0xac8], r1                   
    mov64 r1, 2                                     r1 = 2 as i32 as i64 as u64
    stxdw [r10-0xad0], r1                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -920                                  r1 += -920   ///  r1 = r1.wrapping_add(-920 as i32 as i64 as u64)
    stxdw [r10-0xad8], r1                   
    mov64 r1, 5                                     r1 = 5 as i32 as i64 as u64
    stxdw [r10-0xae0], r1                   
    lddw r1, 0x10003e800 --> b"AC_03AC_02called `Result::unwrap()` on an `Err` va"        r1 load str located at 4295223296
    stxdw [r10-0xae8], r1                   
    ldxdw r1, [r10-0xc18]                   
    stxb [r10-0x98], r1                     
    mov64 r1, 3                                     r1 = 3 as i32 as i64 as u64
    stxdw [r10-0xff8], r1                   
    mov64 r1, 1264                                  r1 = 1264 as i32 as i64 as u64
    stxdw [r10-0xff0], r1                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -2792                                 r1 += -2792   ///  r1 = r1.wrapping_add(-2792 as i32 as i64 as u64)
    stxdw [r10-0x1000], r1                  
    mov64 r1, r10                                   r1 = r10
    add64 r1, -728                                  r1 += -728   ///  r1 = r1.wrapping_add(-728 as i32 as i64 as u64)
    mov64 r5, r10                                   r5 = r10
    ldxdw r2, [r10-0xc08]                   
    ldxdw r3, [r10-0xc20]                   
    ldxdw r4, [r10-0xc10]                   
    call function_8492                      
    lddw r1, 0x800000000000001a                     r1 load str located at -9223372036854775782
    ldxdw r2, [r10-0x2d8]                   
    jeq r2, r1, lbb_4272                            if r2 == r1 { pc += 1 }
    ja lbb_4283                                     if true { pc += 11 }
lbb_4272:
    ldxdw r1, [r10-0xc40]                   
    jgt r1, 1000000, lbb_4275                       if r1 > (1000000 as i32 as i64 as u64) { pc += 1 }
    ja lbb_4295                                     if true { pc += 20 }
lbb_4275:
    mov64 r1, 10                                    r1 = 10 as i32 as i64 as u64
    ja lbb_4278                                     if true { pc += 1 }
lbb_4277:
    mov64 r1, 6                                     r1 = 6 as i32 as i64 as u64
lbb_4278:
    ldxdw r2, [r10-0xc00]                   
    stxw [r2+0x8], r1                       
    lddw r1, 0x8000000000000000                     r1 load str located at -9223372036854775808
    ja lbb_4289                                     if true { pc += 6 }
lbb_4283:
    ldxdw r1, [r10-0x2c8]                   
    ldxdw r2, [r10-0xc00]                   
    stxdw [r2+0x10], r1                     
    ldxdw r1, [r10-0x2d0]                   
    stxdw [r2+0x8], r1                      
    ldxdw r1, [r10-0x2d8]                   
lbb_4289:
    stxdw [r2+0x0], r1                      
lbb_4290:
    ldxdw r2, [r10-0xc30]                   
    ldxdw r1, [r2+0x10]                     
    add64 r1, -1                                    r1 += -1   ///  r1 = r1.wrapping_add(-1 as i32 as i64 as u64)
    stxdw [r2+0x10], r1                     
    ja lbb_4416                                     if true { pc += 121 }
lbb_4295:
    ldxdw r1, [r10-0xc48]                   
    jgt r1, 1000000, lbb_4298                       if r1 > (1000000 as i32 as i64 as u64) { pc += 1 }
    ja lbb_4300                                     if true { pc += 2 }
lbb_4298:
    mov64 r1, 11                                    r1 = 11 as i32 as i64 as u64
    ja lbb_4278                                     if true { pc += -22 }
lbb_4300:
    mov64 r1, r10                                   r1 = r10
    add64 r1, -520                                  r1 += -520   ///  r1 = r1.wrapping_add(-520 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -328                                  r2 += -328   ///  r2 = r2.wrapping_add(-328 as i32 as i64 as u64)
    ldxdw r3, [r1+0x18]                     
    stxdw [r10-0xab8], r3                   
    ldxdw r3, [r1+0x10]                     
    stxdw [r10-0xac0], r3                   
    ldxdw r3, [r1+0x8]                      
    stxdw [r10-0xac8], r3                   
    ldxdw r1, [r1+0x0]                      
    stxdw [r10-0xad0], r1                   
    ldxdw r1, [r2+0x0]                      
    stxdw [r10-0xab0], r1                   
    ldxdw r1, [r2+0x8]                      
    stxdw [r10-0xaa8], r1                   
    ldxdw r1, [r2+0x10]                     
    stxdw [r10-0xaa0], r1                   
    ldxdw r1, [r2+0x18]                     
    stxdw [r10-0xa98], r1                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -2632                                 r1 += -2632   ///  r1 = r1.wrapping_add(-2632 as i32 as i64 as u64)
    call function_537                       
    mov64 r1, r10                                   r1 = r10
    add64 r1, -2152                                 r1 += -2152   ///  r1 = r1.wrapping_add(-2152 as i32 as i64 as u64)
    call function_537                       
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    stxdw [r10-0xae0], r1                   
    stxdw [r10-0xae8], r1                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -1665                                 r1 += -1665   ///  r1 = r1.wrapping_add(-1665 as i32 as i64 as u64)
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
    mov64 r3, 137                                   r3 = 137 as i32 as i64 as u64
    call function_30383                     
    ldxdw r1, [r10-0xc60]                   
    stxw [r10-0xa7c], r1                    
    ldxdw r1, [r10-0xc58]                   
    stxw [r10-0xa80], r1                    
    ldxdw r1, [r10-0xc50]                   
    stxdw [r10-0xa88], r1                   
    ldxdw r1, [r10-0xc78]                   
    stxdw [r10-0xa90], r1                   
    ldxdw r1, [r10-0xc28]                   
    stxh [r10-0xad2], r1                    
    stxh [r10-0xad4], r9                    
    ldxdw r1, [r10-0xc40]                   
    stxw [r10-0xad8], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -2680                                 r1 += -2680   ///  r1 = r1.wrapping_add(-2680 as i32 as i64 as u64)
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
    mov64 r3, 48                                    r3 = 48 as i32 as i64 as u64
    call function_30383                     
    ldxdw r1, [r10-0xc70]                   
    stxb [r10-0x682], r1                    
    ldxdw r1, [r10-0xc68]                   
    stxh [r10-0x684], r1                    
    ldxdw r1, [r10-0xc48]                   
    stxw [r10-0x688], r1                    
    ldxdw r1, [r8+0x10]                     
    jeq r1, 0, lbb_4361                             if r1 == (0 as i32 as i64 as u64) { pc += 1 }
    ja lbb_4409                                     if true { pc += 48 }
lbb_4361:
    mov64 r1, -1                                    r1 = -1 as i32 as i64 as u64
    stxdw [r8+0x10], r1                     
    ldxdw r1, [r8+0x18]                     
    ldxdw r2, [r8+0x20]                     
    stxdw [r10-0x2d0], r2                   
    stxdw [r10-0x2d8], r1                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -1496                                 r1 += -1496   ///  r1 = r1.wrapping_add(-1496 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -728                                  r2 += -728   ///  r2 = r2.wrapping_add(-728 as i32 as i64 as u64)
    call function_13019                     
    jeq r0, 0, lbb_4380                             if r0 == (0 as i32 as i64 as u64) { pc += 7 }
    ldxdw r1, [r10-0xc00]                   
    mov64 r2, r0                                    r2 = r0
    call function_18093                     
    ldxdw r1, [r8+0x10]                     
    add64 r1, 1                                     r1 += 1   ///  r1 = r1.wrapping_add(1 as i32 as i64 as u64)
    stxdw [r8+0x10], r1                     
    ja lbb_4290                                     if true { pc += -90 }
lbb_4380:
    ldxdw r1, [r8+0x10]                     
    add64 r1, 1                                     r1 += 1   ///  r1 = r1.wrapping_add(1 as i32 as i64 as u64)
    stxdw [r8+0x10], r1                     
    ldxdw r1, [r10-0xc08]                   
    ldxdw r6, [r1+0xa0]                     
    ldxdw r1, [r6+0x10]                     
    jeq r1, 0, lbb_4388                             if r1 == (0 as i32 as i64 as u64) { pc += 1 }
    ja lbb_4412                                     if true { pc += 24 }
lbb_4388:
    mov64 r1, -1                                    r1 = -1 as i32 as i64 as u64
    stxdw [r6+0x10], r1                     
    ldxdw r1, [r6+0x20]                     
    jeq r1, 1264, lbb_4396                          if r1 == (1264 as i32 as i64 as u64) { pc += 4 }
    mov64 r2, 1264                                  r2 = 1264 as i32 as i64 as u64
    lddw r3, 0x100040ec0 --> b"\x00\x00\x00\x000\xe7\x03\x00\x10\x00\x00\x00\x00\x00\x00\x00\xfd\x00\x00…        r3 load str located at 4295233216
    call function_28409                     
lbb_4396:
    ldxdw r1, [r6+0x18]                     
    mov64 r2, r10                                   r2 = r10
    add64 r2, -2792                                 r2 += -2792   ///  r2 = r2.wrapping_add(-2792 as i32 as i64 as u64)
    mov64 r3, 1264                                  r3 = 1264 as i32 as i64 as u64
    call function_30349                     
    ldxdw r1, [r6+0x10]                     
    add64 r1, 1                                     r1 += 1   ///  r1 = r1.wrapping_add(1 as i32 as i64 as u64)
    stxdw [r6+0x10], r1                     
    lddw r2, 0x800000000000001a                     r2 load str located at -9223372036854775782
    ldxdw r1, [r10-0xc00]                   
    stxdw [r1+0x0], r2                      
    ja lbb_4290                                     if true { pc += -119 }
lbb_4409:
    lddw r1, 0x100040ef0 --> b"\x00\x00\x00\x000\xe7\x03\x00\x10\x00\x00\x00\x00\x00\x00\x00\xf9\x00\x00…        r1 load str located at 4295233264
    call function_25324                     
lbb_4412:
    lddw r1, 0x100040ed8 --> b"\x00\x00\x00\x000\xe7\x03\x00\x10\x00\x00\x00\x00\x00\x00\x00\xfc\x00\x00…        r1 load str located at 4295233240
    call function_25324                     
lbb_4415:
    call function_18093                     
lbb_4416:
    ldxdw r1, [r7+0x10]                     
    add64 r1, -1                                    r1 += -1   ///  r1 = r1.wrapping_add(-1 as i32 as i64 as u64)
lbb_4418:
    stxdw [r7+0x10], r1                     
    ja lbb_3730                                     if true { pc += -690 }
lbb_4420:
    jeq r7, 0, lbb_2935                             if r7 == (0 as i32 as i64 as u64) { pc += -1486 }
    mov64 r6, r8                                    r6 = r8
    add64 r6, 48                                    r6 += 48   ///  r6 = r6.wrapping_add(48 as i32 as i64 as u64)
    jeq r7, 1, lbb_3773                             if r7 == (1 as i32 as i64 as u64) { pc += -651 }
    mov64 r9, r8                                    r9 = r8
    add64 r9, 96                                    r9 += 96   ///  r9 = r9.wrapping_add(96 as i32 as i64 as u64)
    jeq r7, 2, lbb_2915                             if r7 == (2 as i32 as i64 as u64) { pc += -1512 }
    mov64 r4, r8                                    r4 = r8
    add64 r4, 144                                   r4 += 144   ///  r4 = r4.wrapping_add(144 as i32 as i64 as u64)
    jeq r7, 3, lbb_4530                             if r7 == (3 as i32 as i64 as u64) { pc += 100 }
    mov64 r5, r8                                    r5 = r8
    add64 r5, 192                                   r5 += 192   ///  r5 = r5.wrapping_add(192 as i32 as i64 as u64)
    jeq r7, 4, lbb_3362                             if r7 == (4 as i32 as i64 as u64) { pc += -1071 }
    mov64 r3, r8                                    r3 = r8
    add64 r3, 240                                   r3 += 240   ///  r3 = r3.wrapping_add(240 as i32 as i64 as u64)
    jeq r7, 5, lbb_4528                             if r7 == (5 as i32 as i64 as u64) { pc += 92 }
    mov64 r0, r8                                    r0 = r8
    add64 r0, 288                                   r0 += 288   ///  r0 = r0.wrapping_add(288 as i32 as i64 as u64)
    jeq r7, 6, lbb_3626                             if r7 == (6 as i32 as i64 as u64) { pc += -813 }
    stxdw [r10-0xc18], r0                   
    stxdw [r10-0xc28], r5                   
    stxdw [r10-0xc20], r4                   
    ldxdw r7, [r8+0x0]                      
    ldxdw r4, [r7+0x0]                      
    lddw r5, 0x9e9974ee626ad71                      r5 load str located at 714268381039471985
    jeq r4, r5, lbb_4532                            if r4 == r5 { pc += 85 }
lbb_4447:
    mov64 r4, 1                                     r4 = 1 as i32 as i64 as u64
    jeq r4, 0, lbb_4450                             if r4 == (0 as i32 as i64 as u64) { pc += 1 }
    ja lbb_5436                                     if true { pc += 986 }
lbb_4450:
    stxdw [r10-0xc38], r7                   
    stxdw [r10-0xc30], r3                   
    stxdw [r10-0xc10], r2                   
    stxdw [r10-0xc00], r1                   
    stxdw [r10-0xc08], r8                   
    ldxdw r8, [r8+0x10]                     
    ldxdw r1, [r8+0x10]                     
    lddw r2, 0x7fffffffffffffff                     r2 load str located at 9223372036854775807
    jgt r2, r1, lbb_4461                            if r2 > r1 { pc += 1 }
    ja lbb_4843                                     if true { pc += 382 }
lbb_4461:
    add64 r1, 1                                     r1 += 1   ///  r1 = r1.wrapping_add(1 as i32 as i64 as u64)
    stxdw [r8+0x10], r1                     
    ldxdw r1, [r8+0x18]                     
    ldxdw r2, [r8+0x20]                     
    stxdw [r10-0x150], r2                   
    stxdw [r10-0x158], r1                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -2792                                 r1 += -2792   ///  r1 = r1.wrapping_add(-2792 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -344                                  r2 += -344   ///  r2 = r2.wrapping_add(-344 as i32 as i64 as u64)
    call function_12619                     
    ldxdw r2, [r10-0xae0]                   
    ldxdw r7, [r10-0xae8]                   
    lddw r1, 0x8000000000000000                     r1 load str located at -9223372036854775808
    jeq r7, r1, lbb_3404                            if r7 == r1 { pc += -1073 }
    mov64 r1, r10                                   r1 = r10
    add64 r1, -1480                                 r1 += -1480   ///  r1 = r1.wrapping_add(-1480 as i32 as i64 as u64)
    stxdw [r10-0xc40], r2                   
    mov64 r2, r10                                   r2 = r10
    add64 r2, -2776                                 r2 += -2776   ///  r2 = r2.wrapping_add(-2776 as i32 as i64 as u64)
    mov64 r3, 528                                   r3 = 528 as i32 as i64 as u64
    call function_30349                     
    ldxdw r1, [r10-0xc40]                   
    stxdw [r10-0x5d0], r1                   
    stxdw [r10-0x5d8], r7                   
    ldxdw r1, [r8+0x10]                     
    add64 r1, -1                                    r1 += -1   ///  r1 = r1.wrapping_add(-1 as i32 as i64 as u64)
    mov64 r7, r8                                    r7 = r8
    stxdw [r8+0x10], r1                     
    lddw r1, 0xfc3e34becfcb63d7                     r1 load str located at -270720933461007401
    ldxdw r2, [r10-0x588]                   
    jeq r2, r1, lbb_4547                            if r2 == r1 { pc += 52 }
lbb_4495:
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    jeq r1, 0, lbb_4498                             if r1 == (0 as i32 as i64 as u64) { pc += 1 }
    ja lbb_6109                                     if true { pc += 1611 }
lbb_4498:
    ldxb r1, [r10-0x3c4]                    
    jeq r1, 0, lbb_4501                             if r1 == (0 as i32 as i64 as u64) { pc += 1 }
    ja lbb_5846                                     if true { pc += 1345 }
lbb_4501:
    ldxdw r1, [r10-0xc08]                   
    ldxb r1, [r1+0x29]                      
    jeq r1, 0, lbb_3759                             if r1 == (0 as i32 as i64 as u64) { pc += -745 }
    ldxdw r1, [r10-0xc08]                   
    ldxb r1, [r1+0x58]                      
    jeq r1, 0, lbb_6152                             if r1 == (0 as i32 as i64 as u64) { pc += 1645 }
    ldxdw r1, [r6+0x0]                      
    ldxdw r2, [r1+0x0]                      
    ldxdw r3, [r10-0x588]                   
    jeq r2, r3, lbb_4562                            if r2 == r3 { pc += 51 }
lbb_4511:
    mov64 r2, 1                                     r2 = 1 as i32 as i64 as u64
    jeq r2, 0, lbb_4514                             if r2 == (0 as i32 as i64 as u64) { pc += 1 }
    ja lbb_5830                                     if true { pc += 1316 }
lbb_4514:
    ldxdw r1, [r10-0xc08]                   
    ldxb r1, [r1+0x59]                      
    jeq r1, 0, lbb_3759                             if r1 == (0 as i32 as i64 as u64) { pc += -758 }
    ldxh r8, [r10-0x3c8]                    
    add64 r8, 1                                     r8 += 1   ///  r8 = r8.wrapping_add(1 as i32 as i64 as u64)
    stxh [r10-0x3c8], r8                    
    mov64 r1, r8                                    r1 = r8
    be16 r1                                         r1 = match 16 { 16 => (r1 as u16).swap_bytes() as u64, 32 => (r1 as u32).swap_bytes() as u64, 64 => r1.swap_bytes(), _ => r1 }
    stxh [r10-0x5f4], r1                    
    mov64 r1, r9                                    r1 = r9
    call function_17730                     
    jne r0, 0, lbb_4574                             if r0 != (0 as i32 as i64 as u64) { pc += 48 }
    mov64 r1, 14                                    r1 = 14 as i32 as i64 as u64
    ja lbb_2954                                     if true { pc += -1574 }
lbb_4528:
    stxdw [r1+0x8], r3                      
    ja lbb_3774                                     if true { pc += -756 }
lbb_4530:
    stxdw [r1+0x8], r4                      
    ja lbb_3774                                     if true { pc += -758 }
lbb_4532:
    ldxdw r4, [r7+0x8]                      
    lddw r5, 0xa5b18bf6febdfb8d                     r5 load str located at -6507266093621576819
    jne r4, r5, lbb_4447                            if r4 != r5 { pc += -89 }
    ldxdw r4, [r7+0x10]                     
    lddw r5, 0x3f762b2616a7d0c7                     r5 load str located at 4572889914230165703
    jne r4, r5, lbb_4447                            if r4 != r5 { pc += -93 }
    mov64 r4, 0                                     r4 = 0 as i32 as i64 as u64
    ldxdw r5, [r7+0x18]                     
    lddw r0, 0xe00b8186ff88305d                     r0 load str located at -2302604367657160611
    jne r5, r0, lbb_4447                            if r5 != r0 { pc += -98 }
    jeq r4, 0, lbb_4450                             if r4 == (0 as i32 as i64 as u64) { pc += -96 }
    ja lbb_5436                                     if true { pc += 889 }
lbb_4547:
    lddw r1, 0xf495c87a5045cbbb                     r1 load str located at -822530929266930757
    ldxdw r2, [r10-0x580]                   
    jne r2, r1, lbb_4495                            if r2 != r1 { pc += -56 }
    lddw r1, 0xe7d24322df5eeb7c                     r1 load str located at -1742256288783471748
    ldxdw r2, [r10-0x578]                   
    jne r2, r1, lbb_4495                            if r2 != r1 { pc += -60 }
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    lddw r2, 0xcf66dbb77498e62b                     r2 load str located at -3501870079252306389
    ldxdw r3, [r10-0x570]                   
    jne r3, r2, lbb_4495                            if r3 != r2 { pc += -65 }
    jeq r1, 0, lbb_4498                             if r1 == (0 as i32 as i64 as u64) { pc += -63 }
    ja lbb_6109                                     if true { pc += 1547 }
lbb_4562:
    ldxdw r2, [r1+0x8]                      
    ldxdw r3, [r10-0x580]                   
    jne r2, r3, lbb_4511                            if r2 != r3 { pc += -54 }
    ldxdw r2, [r1+0x10]                     
    ldxdw r3, [r10-0x578]                   
    jne r2, r3, lbb_4511                            if r2 != r3 { pc += -57 }
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
    ldxdw r1, [r1+0x18]                     
    ldxdw r3, [r10-0x570]                   
    jne r1, r3, lbb_4511                            if r1 != r3 { pc += -61 }
    jeq r2, 0, lbb_4514                             if r2 == (0 as i32 as i64 as u64) { pc += -59 }
    ja lbb_5830                                     if true { pc += 1256 }
lbb_4574:
    mov64 r1, r10                                   r1 = r10
    add64 r1, -2792                                 r1 += -2792   ///  r1 = r1.wrapping_add(-2792 as i32 as i64 as u64)
    ldxdw r2, [r10-0xc10]                   
    mov64 r3, r9                                    r3 = r9
    mov64 r4, r8                                    r4 = r8
    call function_9118                      
    ldxb r1, [r10-0xae0]                    
    ldxdw r2, [r10-0xae8]                   
    lddw r3, 0x800000000000001a                     r3 load str located at -9223372036854775782
    jeq r2, r3, lbb_4586                            if r2 == r3 { pc += 1 }
    ja lbb_4600                                     if true { pc += 14 }
lbb_4586:
    ldxdw r2, [r10-0xc08]                   
    ldxb r2, [r2+0x89]                      
    jeq r2, 0, lbb_3759                             if r2 == (0 as i32 as i64 as u64) { pc += -830 }
    ldxdw r2, [r10-0xc08]                   
    ldxdw r3, [r2+0xc0]                     
    mov64 r8, r3                                    r8 = r3
    ldxdw r3, [r3+0x0]                      
    ldxdw r2, [r2+0xa8]                     
    ldxdw r4, [r2+0x0]                      
    jeq r4, r3, lbb_4608                            if r4 == r3 { pc += 12 }
lbb_4596:
    mov64 r3, 1                                     r3 = 1 as i32 as i64 as u64
    jeq r3, 0, lbb_4620                             if r3 == (0 as i32 as i64 as u64) { pc += 22 }
lbb_4598:
    mov64 r1, 2                                     r1 = 2 as i32 as i64 as u64
    ja lbb_2954                                     if true { pc += -1646 }
lbb_4600:
    ldxdw r3, [r10-0xad8]                   
    ldxdw r4, [r10-0xc00]                   
    stxdw [r4+0x10], r3                     
    ldxdw r3, [r10-0xadf]                   
    stxdw [r4+0x9], r3                      
    stxb [r4+0x8], r1                       
    stxdw [r4+0x0], r2                      
    ja lbb_3730                                     if true { pc += -878 }
lbb_4608:
    ldxdw r3, [r8+0x8]                      
    ldxdw r4, [r2+0x8]                      
    jne r4, r3, lbb_4596                            if r4 != r3 { pc += -15 }
    ldxdw r3, [r8+0x10]                     
    ldxdw r4, [r2+0x10]                     
    jne r4, r3, lbb_4596                            if r4 != r3 { pc += -18 }
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
    ldxdw r4, [r8+0x18]                     
    ldxdw r2, [r2+0x18]                     
    jne r2, r4, lbb_4596                            if r2 != r4 { pc += -22 }
    jeq r3, 0, lbb_4620                             if r3 == (0 as i32 as i64 as u64) { pc += 1 }
    ja lbb_4598                                     if true { pc += -22 }
lbb_4620:
    ldxdw r2, [r10-0xc30]                   
    ldxdw r2, [r2+0x0]                      
    ldxdw r3, [r2+0x0]                      
    lddw r4, 0x515c2c1917d5a706                     r4 load str located at 5862609301215225606
    jeq r3, r4, lbb_4794                            if r3 == r4 { pc += 168 }
lbb_4626:
    mov64 r3, 1                                     r3 = 1 as i32 as i64 as u64
    jeq r3, 0, lbb_4629                             if r3 == (0 as i32 as i64 as u64) { pc += 1 }
    ja lbb_5830                                     if true { pc += 1201 }
lbb_4629:
    ldxdw r2, [r10-0xc18]                   
    ldxdw r2, [r2+0x0]                      
    ldxdw r3, [r2+0x0]                      
    jeq r3, 0, lbb_4809                             if r3 == (0 as i32 as i64 as u64) { pc += 176 }
lbb_4633:
    mov64 r3, 1                                     r3 = 1 as i32 as i64 as u64
    jeq r3, 0, lbb_4636                             if r3 == (0 as i32 as i64 as u64) { pc += 1 }
    ja lbb_5830                                     if true { pc += 1194 }
lbb_4636:
    mov64 r2, 1                                     r2 = 1 as i32 as i64 as u64
    stxdw [r10-0x70], r2                    
    mov64 r2, r10                                   r2 = r10
    add64 r2, -1521                                 r2 += -1521   ///  r2 = r2.wrapping_add(-1521 as i32 as i64 as u64)
    stxdw [r10-0x78], r2                    
    mov64 r2, 2                                     r2 = 2 as i32 as i64 as u64
    stxdw [r10-0x80], r2                    
    mov64 r2, r10                                   r2 = r10
    add64 r2, -1524                                 r2 += -1524   ///  r2 = r2.wrapping_add(-1524 as i32 as i64 as u64)
    stxdw [r10-0x88], r2                    
    mov64 r2, 5                                     r2 = 5 as i32 as i64 as u64
    stxdw [r10-0x90], r2                    
    lddw r2, 0x10003e805 --> b"AC_02called `Result::unwrap()` on an `Err` valueG\x99"        r2 load str located at 4295223301
    stxdw [r10-0x98], r2                    
    stxb [r10-0x5f1], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -2792                                 r1 += -2792   ///  r1 = r1.wrapping_add(-2792 as i32 as i64 as u64)
    ldxdw r2, [r10-0xc20]                   
    ldxdw r3, [r10-0xc28]                   
    call function_9829                      
    ldxdw r1, [r10-0xae0]                   
    ldxdw r2, [r10-0xae8]                   
    lddw r3, 0x800000000000001a                     r3 load str located at -9223372036854775782
    jeq r2, r3, lbb_4663                            if r2 == r3 { pc += 1 }
    ja lbb_4818                                     if true { pc += 155 }
lbb_4663:
    mov64 r2, 3                                     r2 = 3 as i32 as i64 as u64
    stxdw [r10-0xff8], r2                   
    stxdw [r10-0xff0], r1                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -152                                  r1 += -152   ///  r1 = r1.wrapping_add(-152 as i32 as i64 as u64)
    stxdw [r10-0x1000], r1                  
    mov64 r1, r10                                   r1 = r10
    add64 r1, -2792                                 r1 += -2792   ///  r1 = r1.wrapping_add(-2792 as i32 as i64 as u64)
    mov64 r5, r10                                   r5 = r10
    mov64 r2, r6                                    r2 = r6
    mov64 r3, r9                                    r3 = r9
    mov64 r4, r8                                    r4 = r8
    call function_8492                      
    ldxdw r1, [r10-0xae8]                   
    lddw r2, 0x800000000000001a                     r2 load str located at -9223372036854775782
    jeq r1, r2, lbb_4681                            if r1 == r2 { pc += 1 }
    ja lbb_6456                                     if true { pc += 1775 }
lbb_4681:
    ldxdw r1, [r10-0xc20]                   
    ldxdw r4, [r1+0x0]                      
    ldxdw r3, [r9+0x0]                      
    mov64 r1, r10                                   r1 = r10
    add64 r1, -2792                                 r1 += -2792   ///  r1 = r1.wrapping_add(-2792 as i32 as i64 as u64)
    mov64 r2, r8                                    r2 = r8
    ldxdw r5, [r10-0xc38]                   
    call function_15728                     
    ldxdw r1, [r10-0xae0]                   
    stxdw [r10-0x3b8], r1                   
    ldxdw r1, [r10-0xad8]                   
    stxdw [r10-0x3b0], r1                   
    ldxdw r1, [r10-0xad0]                   
    stxdw [r10-0x3a8], r1                   
    ldxdw r6, [r10-0xae8]                   
    lddw r1, 0x8000000000000000                     r1 load str located at -9223372036854775808
    jeq r6, r1, lbb_4824                            if r6 == r1 { pc += 125 }
    mov64 r1, r10                                   r1 = r10
    add64 r1, -312                                  r1 += -312   ///  r1 = r1.wrapping_add(-312 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -2760                                 r2 += -2760   ///  r2 = r2.wrapping_add(-2760 as i32 as i64 as u64)
    mov64 r3, 48                                    r3 = 48 as i32 as i64 as u64
    call function_30349                     
    stxdw [r10-0x158], r6                   
    ldxdw r1, [r10-0x3b8]                   
    stxdw [r10-0x150], r1                   
    ldxdw r1, [r10-0x3b0]                   
    stxdw [r10-0x148], r1                   
    ldxdw r1, [r10-0x3a8]                   
    stxdw [r10-0x140], r1                   
    mov64 r6, r10                                   r6 = r10
    add64 r6, -920                                  r6 += -920   ///  r6 = r6.wrapping_add(-920 as i32 as i64 as u64)
    mov64 r1, r6                                    r1 = r6
    mov64 r2, r9                                    r2 = r9
    call function_2001                      
    mov64 r9, r10                                   r9 = r10
    add64 r9, -728                                  r9 += -728   ///  r9 = r9.wrapping_add(-728 as i32 as i64 as u64)
    mov64 r1, r9                                    r1 = r9
    ldxdw r2, [r10-0xc20]                   
    call function_2001                      
    mov64 r8, r10                                   r8 = r10
    add64 r8, -536                                  r8 += -536   ///  r8 = r8.wrapping_add(-536 as i32 as i64 as u64)
    mov64 r1, r8                                    r1 = r8
    ldxdw r2, [r10-0xc08]                   
    call function_2001                      
    mov64 r1, r10                                   r1 = r10
    add64 r1, -2648                                 r1 += -2648   ///  r1 = r1.wrapping_add(-2648 as i32 as i64 as u64)
    ldxdw r2, [r10-0xc30]                   
    call function_2001                      
    mov64 r1, r10                                   r1 = r10
    add64 r1, -2792                                 r1 += -2792   ///  r1 = r1.wrapping_add(-2792 as i32 as i64 as u64)
    stxdw [r10-0xc08], r1                   
    mov64 r2, r6                                    r2 = r6
    mov64 r3, 48                                    r3 = 48 as i32 as i64 as u64
    call function_30349                     
    mov64 r1, r10                                   r1 = r10
    add64 r1, -2744                                 r1 += -2744   ///  r1 = r1.wrapping_add(-2744 as i32 as i64 as u64)
    mov64 r2, r9                                    r2 = r9
    mov64 r3, 48                                    r3 = 48 as i32 as i64 as u64
    call function_30349                     
    mov64 r1, r10                                   r1 = r10
    add64 r1, -2696                                 r1 += -2696   ///  r1 = r1.wrapping_add(-2696 as i32 as i64 as u64)
    mov64 r2, r8                                    r2 = r8
    mov64 r3, 48                                    r3 = 48 as i32 as i64 as u64
    call function_30349                     
    mov64 r1, 3                                     r1 = 3 as i32 as i64 as u64
    stxdw [r10-0x210], r1                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -152                                  r1 += -152   ///  r1 = r1.wrapping_add(-152 as i32 as i64 as u64)
    stxdw [r10-0x218], r1                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -536                                  r1 += -536   ///  r1 = r1.wrapping_add(-536 as i32 as i64 as u64)
    stxdw [r10-0x1000], r1                  
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    stxdw [r10-0xff8], r1                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -1520                                 r1 += -1520   ///  r1 = r1.wrapping_add(-1520 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -344                                  r2 += -344   ///  r2 = r2.wrapping_add(-344 as i32 as i64 as u64)
    mov64 r5, r10                                   r5 = r10
    ldxdw r3, [r10-0xc08]                   
    mov64 r4, 4                                     r4 = 4 as i32 as i64 as u64
    call function_16486                     
    lddw r1, 0x800000000000001a                     r1 load str located at -9223372036854775782
    ldxdw r2, [r10-0x5f0]                   
    jeq r2, r1, lbb_4770                            if r2 == r1 { pc += 1 }
    ja lbb_4832                                     if true { pc += 62 }
lbb_4770:
    mov64 r1, r10                                   r1 = r10
    add64 r1, -2792                                 r1 += -2792   ///  r1 = r1.wrapping_add(-2792 as i32 as i64 as u64)
    call function_472                       
    ldxdw r1, [r7+0x10]                     
    jeq r1, 0, lbb_4776                             if r1 == (0 as i32 as i64 as u64) { pc += 1 }
    ja lbb_4846                                     if true { pc += 70 }
lbb_4776:
    mov64 r1, -1                                    r1 = -1 as i32 as i64 as u64
    mov64 r2, r7                                    r2 = r7
    stxdw [r2+0x10], r1                     
    ldxdw r1, [r2+0x18]                     
    ldxdw r2, [r2+0x20]                     
    stxdw [r10-0xae0], r2                   
    stxdw [r10-0xae8], r1                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -1496                                 r1 += -1496   ///  r1 = r1.wrapping_add(-1496 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -2792                                 r2 += -2792   ///  r2 = r2.wrapping_add(-2792 as i32 as i64 as u64)
    call function_13019                     
    jeq r0, 0, lbb_4790                             if r0 == (0 as i32 as i64 as u64) { pc += 1 }
    ja lbb_5781                                     if true { pc += 991 }
lbb_4790:
    ldxdw r1, [r7+0x10]                     
    add64 r1, 1                                     r1 += 1   ///  r1 = r1.wrapping_add(1 as i32 as i64 as u64)
    stxdw [r7+0x10], r1                     
    ja lbb_3981                                     if true { pc += -813 }
lbb_4794:
    ldxdw r3, [r2+0x8]                      
    lddw r4, 0x7ff14a3d4cc98c21                     r4 load str located at 9219231539345853473
    jne r3, r4, lbb_4626                            if r3 != r4 { pc += -172 }
    ldxdw r3, [r2+0x10]                     
    lddw r4, 0x44fda19b08eeda58                     r4 load str located at 4971307250928769624
    jne r3, r4, lbb_4626                            if r3 != r4 { pc += -176 }
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
    ldxdw r2, [r2+0x18]                     
    lddw r4, 0x8ad9dbe3                             r4 load str located at 2329533411
    jne r2, r4, lbb_4626                            if r2 != r4 { pc += -181 }
    jeq r3, 0, lbb_4629                             if r3 == (0 as i32 as i64 as u64) { pc += -179 }
    ja lbb_5830                                     if true { pc += 1021 }
lbb_4809:
    ldxdw r3, [r2+0x8]                      
    jne r3, 0, lbb_4633                             if r3 != (0 as i32 as i64 as u64) { pc += -178 }
    ldxdw r3, [r2+0x10]                     
    jne r3, 0, lbb_4633                             if r3 != (0 as i32 as i64 as u64) { pc += -180 }
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
    ldxdw r2, [r2+0x18]                     
    jne r2, 0, lbb_4633                             if r2 != (0 as i32 as i64 as u64) { pc += -183 }
    jeq r3, 0, lbb_4636                             if r3 == (0 as i32 as i64 as u64) { pc += -181 }
    ja lbb_5830                                     if true { pc += 1012 }
lbb_4818:
    ldxdw r3, [r10-0xad8]                   
    ldxdw r4, [r10-0xc00]                   
    stxdw [r4+0x10], r3                     
    stxdw [r4+0x8], r1                      
    stxdw [r4+0x0], r2                      
    ja lbb_3730                                     if true { pc += -1094 }
lbb_4824:
    ldxdw r1, [r10-0x3a8]                   
    ldxdw r2, [r10-0xc00]                   
    stxdw [r2+0x10], r1                     
    ldxdw r1, [r10-0x3b0]                   
    stxdw [r2+0x8], r1                      
    ldxdw r1, [r10-0x3b8]                   
    stxdw [r2+0x0], r1                      
    ja lbb_3730                                     if true { pc += -1102 }
lbb_4832:
    ldxdw r1, [r10-0x5e0]                   
    ldxdw r2, [r10-0xc00]                   
    stxdw [r2+0x10], r1                     
    ldxdw r1, [r10-0x5e8]                   
    stxdw [r2+0x8], r1                      
    ldxdw r1, [r10-0x5f0]                   
    stxdw [r2+0x0], r1                      
    mov64 r1, r10                                   r1 = r10
    add64 r1, -2792                                 r1 += -2792   ///  r1 = r1.wrapping_add(-2792 as i32 as i64 as u64)
    call function_472                       
    ja lbb_3730                                     if true { pc += -1113 }
lbb_4843:
    lddw r1, 0x100040f68 --> b"\x00\x00\x00\x000\xe7\x03\x00\x10\x00\x00\x00\x00\x00\x00\x00\x0f\x01\x00…        r1 load str located at 4295233384
    call function_25345                     
lbb_4846:
    lddw r1, 0x100040f50 --> b"\x00\x00\x00\x000\xe7\x03\x00\x10\x00\x00\x00\x00\x00\x00\x00J\x01\x00\x0…        r1 load str located at 4295233360
    call function_25324                     
lbb_4849:
    call function_18093                     
    ldxdw r1, [r8+0x10]                     
    add64 r1, -1                                    r1 += -1   ///  r1 = r1.wrapping_add(-1 as i32 as i64 as u64)
    stxdw [r8+0x10], r1                     
    ja lbb_3730                                     if true { pc += -1124 }
lbb_4854:
    ldxdw r3, [r2+0x0]                      
    ldxdw r4, [r3+0x0]                      
    lddw r5, 0x9e9974ee626ad71                      r5 load str located at 714268381039471985
    jeq r4, r5, lbb_4892                            if r4 == r5 { pc += 33 }
lbb_4859:
    mov64 r4, 1                                     r4 = 1 as i32 as i64 as u64
    jeq r4, 0, lbb_4862                             if r4 == (0 as i32 as i64 as u64) { pc += 1 }
    ja lbb_5436                                     if true { pc += 574 }
lbb_4862:
    ldxdw r6, [r2+0x10]                     
    ldxdw r1, [r6+0x10]                     
    lddw r2, 0x7fffffffffffffff                     r2 load str located at 9223372036854775807
    jgt r2, r1, lbb_4868                            if r2 > r1 { pc += 1 }
    ja lbb_4907                                     if true { pc += 39 }
lbb_4868:
    add64 r1, 1                                     r1 += 1   ///  r1 = r1.wrapping_add(1 as i32 as i64 as u64)
    stxdw [r6+0x10], r1                     
    ldxdw r1, [r6+0x18]                     
    ldxdw r2, [r6+0x20]                     
    stxdw [r10-0x150], r2                   
    stxdw [r10-0x158], r1                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -2792                                 r1 += -2792   ///  r1 = r1.wrapping_add(-2792 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -344                                  r2 += -344   ///  r2 = r2.wrapping_add(-344 as i32 as i64 as u64)
    call function_12619                     
    ldxdw r4, [r10-0xae0]                   
    ldxdw r7, [r10-0xae8]                   
    lddw r1, 0x8000000000000000                     r1 load str located at -9223372036854775808
    jeq r7, r1, lbb_4885                            if r7 == r1 { pc += 1 }
    ja lbb_4910                                     if true { pc += 25 }
lbb_4885:
    ldxdw r1, [r10-0xc00]                   
    mov64 r2, r4                                    r2 = r4
    call function_18093                     
    ldxdw r1, [r6+0x10]                     
    add64 r1, -1                                    r1 += -1   ///  r1 = r1.wrapping_add(-1 as i32 as i64 as u64)
    stxdw [r6+0x10], r1                     
    ja lbb_3730                                     if true { pc += -1162 }
lbb_4892:
    ldxdw r4, [r3+0x8]                      
    lddw r5, 0xa5b18bf6febdfb8d                     r5 load str located at -6507266093621576819
    jne r4, r5, lbb_4859                            if r4 != r5 { pc += -37 }
    ldxdw r4, [r3+0x10]                     
    lddw r5, 0x3f762b2616a7d0c7                     r5 load str located at 4572889914230165703
    jne r4, r5, lbb_4859                            if r4 != r5 { pc += -41 }
    mov64 r4, 0                                     r4 = 0 as i32 as i64 as u64
    ldxdw r3, [r3+0x18]                     
    lddw r5, 0xe00b8186ff88305d                     r5 load str located at -2302604367657160611
    jne r3, r5, lbb_4859                            if r3 != r5 { pc += -46 }
    jeq r4, 0, lbb_4862                             if r4 == (0 as i32 as i64 as u64) { pc += -44 }
    ja lbb_5436                                     if true { pc += 529 }
lbb_4907:
    lddw r1, 0x100040f98 --> b"\x00\x00\x00\x000\xe7\x03\x00\x10\x00\x00\x00\x00\x00\x00\x00Z\x01\x00\x0…        r1 load str located at 4295233432
    call function_25345                     
lbb_4910:
    mov64 r1, r10                                   r1 = r10
    add64 r1, -1480                                 r1 += -1480   ///  r1 = r1.wrapping_add(-1480 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -2776                                 r2 += -2776   ///  r2 = r2.wrapping_add(-2776 as i32 as i64 as u64)
    stxdw [r10-0xc10], r1                   
    mov64 r3, 528                                   r3 = 528 as i32 as i64 as u64
    stxdw [r10-0xc08], r4                   
    call function_30349                     
    ldxdw r1, [r10-0xc08]                   
    stxdw [r10-0x5d0], r1                   
    stxdw [r10-0x5d8], r7                   
    ldxdw r1, [r6+0x10]                     
    add64 r1, -1                                    r1 += -1   ///  r1 = r1.wrapping_add(-1 as i32 as i64 as u64)
    stxdw [r6+0x10], r1                     
    lddw r2, 0xfc3e34becfcb63d7                     r2 load str located at -270720933461007401
    ldxdw r3, [r10-0x588]                   
    jeq r3, r2, lbb_4930                            if r3 == r2 { pc += 2 }
lbb_4928:
    mov64 r3, 1                                     r3 = 1 as i32 as i64 as u64
    ja lbb_4943                                     if true { pc += 13 }
lbb_4930:
    lddw r2, 0xf495c87a5045cbbb                     r2 load str located at -822530929266930757
    ldxdw r3, [r10-0x580]                   
    jne r3, r2, lbb_4928                            if r3 != r2 { pc += -6 }
    lddw r2, 0xe7d24322df5eeb7c                     r2 load str located at -1742256288783471748
    ldxdw r3, [r10-0x578]                   
    jne r3, r2, lbb_4928                            if r3 != r2 { pc += -10 }
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
    lddw r2, 0xcf66dbb77498e62b                     r2 load str located at -3501870079252306389
    ldxdw r4, [r10-0x570]                   
    jne r4, r2, lbb_4928                            if r4 != r2 { pc += -15 }
lbb_4943:
    ldxdw r2, [r10-0xc00]                   
    jeq r3, 0, lbb_4946                             if r3 == (0 as i32 as i64 as u64) { pc += 1 }
    ja lbb_7118                                     if true { pc += 2172 }
lbb_4946:
    ldxb r3, [r10-0x3c4]                    
    jeq r3, 0, lbb_4949                             if r3 == (0 as i32 as i64 as u64) { pc += 1 }
    ja lbb_5524                                     if true { pc += 575 }
lbb_4949:
    ldxb r3, [r8+0x29]                      
    jeq r3, 0, lbb_7173                             if r3 == (0 as i32 as i64 as u64) { pc += 2222 }
    ldxb r3, [r8+0x58]                      
    jeq r3, 0, lbb_5538                             if r3 == (0 as i32 as i64 as u64) { pc += 585 }
    ldxdw r3, [r9+0x0]                      
    ldxdw r4, [r3+0x0]                      
    ldxdw r5, [r10-0x588]                   
    jeq r4, r5, lbb_5006                            if r4 == r5 { pc += 49 }
lbb_4957:
    mov64 r4, 1                                     r4 = 1 as i32 as i64 as u64
    jeq r4, 0, lbb_4960                             if r4 == (0 as i32 as i64 as u64) { pc += 1 }
    ja lbb_5536                                     if true { pc += 576 }
lbb_4960:
    ldxb r2, [r10-0xb2a]                    
    jeq r2, 0, lbb_5018                             if r2 == (0 as i32 as i64 as u64) { pc += 56 }
    jeq r2, 1, lbb_4965                             if r2 == (1 as i32 as i64 as u64) { pc += 2 }
    ldxdw r1, [r10-0x5b8]                   
    stxdw [r10-0xc08], r1                   
lbb_4965:
    jeq r2, 1, lbb_4969                             if r2 == (1 as i32 as i64 as u64) { pc += 3 }
    mov64 r1, r10                                   r1 = r10
    add64 r1, -1456                                 r1 += -1456   ///  r1 = r1.wrapping_add(-1456 as i32 as i64 as u64)
    stxdw [r10-0xc10], r1                   
lbb_4969:
    ldxw r1, [r10-0xb0d]                    
    stxw [r10-0xae0], r1                    
    ldxw r1, [r10-0xb1b]                    
    stxw [r10-0xae4], r1                    
    ldxw r1, [r10-0xb29]                    
    stxw [r10-0xae8], r1                    
    ldxdw r1, [r10-0xc10]                   
    ldxdw r2, [r1+0x0]                      
    mov64 r3, r10                                   r3 = r10
    add64 r3, -2792                                 r3 += -2792   ///  r3 = r3.wrapping_add(-2792 as i32 as i64 as u64)
    ldxdw r1, [r10-0xc08]                   
    call function_9321                      
    ldxdw r1, [r6+0x10]                     
    jeq r1, 0, lbb_4984                             if r1 == (0 as i32 as i64 as u64) { pc += 1 }
    ja lbb_5412                                     if true { pc += 428 }
lbb_4984:
    mov64 r1, -1                                    r1 = -1 as i32 as i64 as u64
    mov64 r2, r6                                    r2 = r6
    stxdw [r2+0x10], r1                     
    ldxdw r1, [r2+0x18]                     
    ldxdw r2, [r2+0x20]                     
    stxdw [r10-0xae0], r2                   
    stxdw [r10-0xae8], r1                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -1496                                 r1 += -1496   ///  r1 = r1.wrapping_add(-1496 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -2792                                 r2 += -2792   ///  r2 = r2.wrapping_add(-2792 as i32 as i64 as u64)
    call function_13019                     
    jeq r0, 0, lbb_4998                             if r0 == (0 as i32 as i64 as u64) { pc += 1 }
    ja lbb_3985                                     if true { pc += -1013 }
lbb_4998:
    ldxdw r1, [r6+0x10]                     
    add64 r1, 1                                     r1 += 1   ///  r1 = r1.wrapping_add(1 as i32 as i64 as u64)
    stxdw [r6+0x10], r1                     
    lddw r1, 0x800000000000001a                     r1 load str located at -9223372036854775782
lbb_5003:
    ldxdw r2, [r10-0xc00]                   
    stxdw [r2+0x0], r1                      
    ja lbb_3730                                     if true { pc += -1276 }
lbb_5006:
    ldxdw r4, [r3+0x8]                      
    ldxdw r5, [r10-0x580]                   
    jne r4, r5, lbb_4957                            if r4 != r5 { pc += -52 }
    ldxdw r4, [r3+0x10]                     
    ldxdw r5, [r10-0x578]                   
    jne r4, r5, lbb_4957                            if r4 != r5 { pc += -55 }
    mov64 r4, 0                                     r4 = 0 as i32 as i64 as u64
    ldxdw r3, [r3+0x18]                     
    ldxdw r5, [r10-0x570]                   
    jne r3, r5, lbb_4957                            if r3 != r5 { pc += -59 }
    jeq r4, 0, lbb_4960                             if r4 == (0 as i32 as i64 as u64) { pc += -57 }
    ja lbb_5536                                     if true { pc += 518 }
lbb_5018:
    ldxdw r2, [r10-0x508]                   
    ldxdw r3, [r10-0xb29]                   
    jeq r3, r2, lbb_5028                            if r3 == r2 { pc += 7 }
lbb_5021:
    mov64 r2, 1                                     r2 = 1 as i32 as i64 as u64
    jeq r2, 0, lbb_5040                             if r2 == (0 as i32 as i64 as u64) { pc += 17 }
lbb_5023:
    ldxdw r2, [r10-0x4e8]                   
    ldxdw r3, [r10-0xb29]                   
    jeq r3, r2, lbb_5047                            if r3 == r2 { pc += 21 }
lbb_5026:
    mov64 r2, 1                                     r2 = 1 as i32 as i64 as u64
    ja lbb_5057                                     if true { pc += 29 }
lbb_5028:
    ldxdw r2, [r10-0x500]                   
    ldxdw r3, [r10-0xb21]                   
    jne r3, r2, lbb_5021                            if r3 != r2 { pc += -10 }
    ldxdw r2, [r10-0x4f8]                   
    ldxdw r3, [r10-0xb19]                   
    jne r3, r2, lbb_5021                            if r3 != r2 { pc += -13 }
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
    ldxdw r3, [r10-0x4f0]                   
    ldxdw r4, [r10-0xb11]                   
    jne r4, r3, lbb_5021                            if r4 != r3 { pc += -17 }
    jeq r2, 0, lbb_5040                             if r2 == (0 as i32 as i64 as u64) { pc += 1 }
    ja lbb_5023                                     if true { pc += -17 }
lbb_5040:
    mov64 r1, 16                                    r1 = 16 as i32 as i64 as u64
lbb_5041:
    ldxdw r6, [r10-0xc00]                   
    stxw [r6+0x8], r1                       
    lddw r1, 0x8000000000000000                     r1 load str located at -9223372036854775808
    stxdw [r6+0x0], r1                      
    ja lbb_3730                                     if true { pc += -1317 }
lbb_5047:
    ldxdw r2, [r10-0x4e0]                   
    ldxdw r3, [r10-0xb21]                   
    jne r3, r2, lbb_5026                            if r3 != r2 { pc += -24 }
    ldxdw r2, [r10-0x4d8]                   
    ldxdw r3, [r10-0xb19]                   
    jne r3, r2, lbb_5026                            if r3 != r2 { pc += -27 }
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
    ldxdw r3, [r10-0x4d0]                   
    ldxdw r4, [r10-0xb11]                   
    jne r4, r3, lbb_5026                            if r4 != r3 { pc += -31 }
lbb_5057:
    jeq r2, 0, lbb_5040                             if r2 == (0 as i32 as i64 as u64) { pc += -18 }
    ldxdw r2, [r10-0x4c8]                   
    ldxdw r3, [r10-0xb29]                   
    jeq r3, r2, lbb_5063                            if r3 == r2 { pc += 2 }
lbb_5061:
    mov64 r2, 1                                     r2 = 1 as i32 as i64 as u64
    ja lbb_5073                                     if true { pc += 10 }
lbb_5063:
    ldxdw r2, [r10-0x4c0]                   
    ldxdw r3, [r10-0xb21]                   
    jne r3, r2, lbb_5061                            if r3 != r2 { pc += -5 }
    ldxdw r2, [r10-0x4b8]                   
    ldxdw r3, [r10-0xb19]                   
    jne r3, r2, lbb_5061                            if r3 != r2 { pc += -8 }
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
    ldxdw r3, [r10-0x4b0]                   
    ldxdw r4, [r10-0xb11]                   
    jne r4, r3, lbb_5061                            if r4 != r3 { pc += -12 }
lbb_5073:
    jeq r2, 0, lbb_5040                             if r2 == (0 as i32 as i64 as u64) { pc += -34 }
    ldxdw r2, [r10-0x4a8]                   
    ldxdw r3, [r10-0xb29]                   
    jeq r3, r2, lbb_5079                            if r3 == r2 { pc += 2 }
lbb_5077:
    mov64 r2, 1                                     r2 = 1 as i32 as i64 as u64
    ja lbb_5089                                     if true { pc += 10 }
lbb_5079:
    ldxdw r2, [r10-0x4a0]                   
    ldxdw r3, [r10-0xb21]                   
    jne r3, r2, lbb_5077                            if r3 != r2 { pc += -5 }
    ldxdw r2, [r10-0x498]                   
    ldxdw r3, [r10-0xb19]                   
    jne r3, r2, lbb_5077                            if r3 != r2 { pc += -8 }
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
    ldxdw r3, [r10-0x490]                   
    ldxdw r4, [r10-0xb11]                   
    jne r4, r3, lbb_5077                            if r4 != r3 { pc += -12 }
lbb_5089:
    jeq r2, 0, lbb_5040                             if r2 == (0 as i32 as i64 as u64) { pc += -50 }
    ldxdw r2, [r10-0x488]                   
    ldxdw r3, [r10-0xb29]                   
    jeq r3, r2, lbb_5095                            if r3 == r2 { pc += 2 }
lbb_5093:
    mov64 r2, 1                                     r2 = 1 as i32 as i64 as u64
    ja lbb_5105                                     if true { pc += 10 }
lbb_5095:
    ldxdw r2, [r10-0x480]                   
    ldxdw r3, [r10-0xb21]                   
    jne r3, r2, lbb_5093                            if r3 != r2 { pc += -5 }
    ldxdw r2, [r10-0x478]                   
    ldxdw r3, [r10-0xb19]                   
    jne r3, r2, lbb_5093                            if r3 != r2 { pc += -8 }
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
    ldxdw r3, [r10-0x470]                   
    ldxdw r4, [r10-0xb11]                   
    jne r4, r3, lbb_5093                            if r4 != r3 { pc += -12 }
lbb_5105:
    jeq r2, 0, lbb_5040                             if r2 == (0 as i32 as i64 as u64) { pc += -66 }
    ldxdw r2, [r10-0x468]                   
    ldxdw r3, [r10-0xb29]                   
    jeq r3, r2, lbb_5111                            if r3 == r2 { pc += 2 }
lbb_5109:
    mov64 r2, 1                                     r2 = 1 as i32 as i64 as u64
    ja lbb_5121                                     if true { pc += 10 }
lbb_5111:
    ldxdw r2, [r10-0x460]                   
    ldxdw r3, [r10-0xb21]                   
    jne r3, r2, lbb_5109                            if r3 != r2 { pc += -5 }
    ldxdw r2, [r10-0x458]                   
    ldxdw r3, [r10-0xb19]                   
    jne r3, r2, lbb_5109                            if r3 != r2 { pc += -8 }
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
    ldxdw r3, [r10-0x450]                   
    ldxdw r4, [r10-0xb11]                   
    jne r4, r3, lbb_5109                            if r4 != r3 { pc += -12 }
lbb_5121:
    jeq r2, 0, lbb_5040                             if r2 == (0 as i32 as i64 as u64) { pc += -82 }
    ldxdw r2, [r10-0x448]                   
    ldxdw r3, [r10-0xb29]                   
    jeq r3, r2, lbb_5127                            if r3 == r2 { pc += 2 }
lbb_5125:
    mov64 r2, 1                                     r2 = 1 as i32 as i64 as u64
    ja lbb_5137                                     if true { pc += 10 }
lbb_5127:
    ldxdw r2, [r10-0x440]                   
    ldxdw r3, [r10-0xb21]                   
    jne r3, r2, lbb_5125                            if r3 != r2 { pc += -5 }
    ldxdw r2, [r10-0x438]                   
    ldxdw r3, [r10-0xb19]                   
    jne r3, r2, lbb_5125                            if r3 != r2 { pc += -8 }
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
    ldxdw r3, [r10-0x430]                   
    ldxdw r4, [r10-0xb11]                   
    jne r4, r3, lbb_5125                            if r4 != r3 { pc += -12 }
lbb_5137:
    jeq r2, 0, lbb_5040                             if r2 == (0 as i32 as i64 as u64) { pc += -98 }
    ldxdw r2, [r10-0x428]                   
    ldxdw r3, [r10-0xb29]                   
    jeq r3, r2, lbb_5143                            if r3 == r2 { pc += 2 }
lbb_5141:
    mov64 r2, 1                                     r2 = 1 as i32 as i64 as u64
    ja lbb_5153                                     if true { pc += 10 }
lbb_5143:
    ldxdw r2, [r10-0x420]                   
    ldxdw r3, [r10-0xb21]                   
    jne r3, r2, lbb_5141                            if r3 != r2 { pc += -5 }
    ldxdw r2, [r10-0x418]                   
    ldxdw r3, [r10-0xb19]                   
    jne r3, r2, lbb_5141                            if r3 != r2 { pc += -8 }
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
    ldxdw r3, [r10-0x410]                   
    ldxdw r4, [r10-0xb11]                   
    jne r4, r3, lbb_5141                            if r4 != r3 { pc += -12 }
lbb_5153:
    jeq r2, 0, lbb_5040                             if r2 == (0 as i32 as i64 as u64) { pc += -114 }
    ldxdw r2, [r10-0x408]                   
    ldxdw r3, [r10-0xb29]                   
    jeq r3, r2, lbb_5159                            if r3 == r2 { pc += 2 }
lbb_5157:
    mov64 r2, 1                                     r2 = 1 as i32 as i64 as u64
    ja lbb_5169                                     if true { pc += 10 }
lbb_5159:
    ldxdw r2, [r10-0x400]                   
    ldxdw r3, [r10-0xb21]                   
    jne r3, r2, lbb_5157                            if r3 != r2 { pc += -5 }
    ldxdw r2, [r10-0x3f8]                   
    ldxdw r3, [r10-0xb19]                   
    jne r3, r2, lbb_5157                            if r3 != r2 { pc += -8 }
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
    ldxdw r3, [r10-0x3f0]                   
    ldxdw r4, [r10-0xb11]                   
    jne r4, r3, lbb_5157                            if r4 != r3 { pc += -12 }
lbb_5169:
    jeq r2, 0, lbb_5040                             if r2 == (0 as i32 as i64 as u64) { pc += -130 }
    ldxdw r2, [r10-0x3e8]                   
    ldxdw r3, [r10-0xb29]                   
    jeq r3, r2, lbb_5175                            if r3 == r2 { pc += 2 }
lbb_5173:
    mov64 r2, 1                                     r2 = 1 as i32 as i64 as u64
    ja lbb_5185                                     if true { pc += 10 }
lbb_5175:
    ldxdw r2, [r10-0x3e0]                   
    ldxdw r3, [r10-0xb21]                   
    jne r3, r2, lbb_5173                            if r3 != r2 { pc += -5 }
    ldxdw r2, [r10-0x3d8]                   
    ldxdw r3, [r10-0xb19]                   
    jne r3, r2, lbb_5173                            if r3 != r2 { pc += -8 }
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
    ldxdw r3, [r10-0x3d0]                   
    ldxdw r4, [r10-0xb11]                   
    jne r4, r3, lbb_5173                            if r4 != r3 { pc += -12 }
lbb_5185:
    jeq r2, 0, lbb_5040                             if r2 == (0 as i32 as i64 as u64) { pc += -146 }
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
    stxdw [r10-0xad0], r2                   
    stxdw [r10-0xad8], r2                   
    stxdw [r10-0xae0], r2                   
    stxdw [r10-0xae8], r2                   
    ldxdw r2, [r10-0x508]                   
    jeq r2, 0, lbb_5195                             if r2 == (0 as i32 as i64 as u64) { pc += 2 }
lbb_5193:
    mov64 r3, 1                                     r3 = 1 as i32 as i64 as u64
    ja lbb_5205                                     if true { pc += 10 }
lbb_5195:
    ldxdw r2, [r10-0xae0]                   
    ldxdw r3, [r10-0x500]                   
    jne r3, r2, lbb_5193                            if r3 != r2 { pc += -5 }
    ldxdw r2, [r10-0xad8]                   
    ldxdw r3, [r10-0x4f8]                   
    jne r3, r2, lbb_5193                            if r3 != r2 { pc += -8 }
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
    ldxdw r2, [r10-0xad0]                   
    ldxdw r4, [r10-0x4f0]                   
    jne r4, r2, lbb_5193                            if r4 != r2 { pc += -12 }
lbb_5205:
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
    jeq r3, 0, lbb_5397                             if r3 == (0 as i32 as i64 as u64) { pc += 190 }
    stxdw [r10-0xad0], r2                   
    stxdw [r10-0xad8], r2                   
    stxdw [r10-0xae0], r2                   
    stxdw [r10-0xae8], r2                   
    ldxdw r2, [r10-0x4e8]                   
    jeq r2, 0, lbb_5215                             if r2 == (0 as i32 as i64 as u64) { pc += 2 }
lbb_5213:
    mov64 r3, 1                                     r3 = 1 as i32 as i64 as u64
    ja lbb_5225                                     if true { pc += 10 }
lbb_5215:
    ldxdw r2, [r10-0xae0]                   
    ldxdw r3, [r10-0x4e0]                   
    jne r3, r2, lbb_5213                            if r3 != r2 { pc += -5 }
    ldxdw r2, [r10-0xad8]                   
    ldxdw r3, [r10-0x4d8]                   
    jne r3, r2, lbb_5213                            if r3 != r2 { pc += -8 }
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
    ldxdw r2, [r10-0xad0]                   
    ldxdw r4, [r10-0x4d0]                   
    jne r4, r2, lbb_5213                            if r4 != r2 { pc += -12 }
lbb_5225:
    mov64 r2, 1                                     r2 = 1 as i32 as i64 as u64
    jeq r3, 0, lbb_5397                             if r3 == (0 as i32 as i64 as u64) { pc += 170 }
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
    stxdw [r10-0xad0], r2                   
    stxdw [r10-0xad8], r2                   
    stxdw [r10-0xae0], r2                   
    stxdw [r10-0xae8], r2                   
    ldxdw r2, [r10-0x4c8]                   
    jeq r2, 0, lbb_5236                             if r2 == (0 as i32 as i64 as u64) { pc += 2 }
lbb_5234:
    mov64 r3, 1                                     r3 = 1 as i32 as i64 as u64
    ja lbb_5246                                     if true { pc += 10 }
lbb_5236:
    ldxdw r2, [r10-0xae0]                   
    ldxdw r3, [r10-0x4c0]                   
    jne r3, r2, lbb_5234                            if r3 != r2 { pc += -5 }
    ldxdw r2, [r10-0xad8]                   
    ldxdw r3, [r10-0x4b8]                   
    jne r3, r2, lbb_5234                            if r3 != r2 { pc += -8 }
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
    ldxdw r2, [r10-0xad0]                   
    ldxdw r4, [r10-0x4b0]                   
    jne r4, r2, lbb_5234                            if r4 != r2 { pc += -12 }
lbb_5246:
    mov64 r2, 2                                     r2 = 2 as i32 as i64 as u64
    jeq r3, 0, lbb_5397                             if r3 == (0 as i32 as i64 as u64) { pc += 149 }
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
    stxdw [r10-0xad0], r2                   
    stxdw [r10-0xad8], r2                   
    stxdw [r10-0xae0], r2                   
    stxdw [r10-0xae8], r2                   
    ldxdw r2, [r10-0x4a8]                   
    jeq r2, 0, lbb_5257                             if r2 == (0 as i32 as i64 as u64) { pc += 2 }
lbb_5255:
    mov64 r3, 1                                     r3 = 1 as i32 as i64 as u64
    ja lbb_5267                                     if true { pc += 10 }
lbb_5257:
    ldxdw r2, [r10-0xae0]                   
    ldxdw r3, [r10-0x4a0]                   
    jne r3, r2, lbb_5255                            if r3 != r2 { pc += -5 }
    ldxdw r2, [r10-0xad8]                   
    ldxdw r3, [r10-0x498]                   
    jne r3, r2, lbb_5255                            if r3 != r2 { pc += -8 }
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
    ldxdw r2, [r10-0xad0]                   
    ldxdw r4, [r10-0x490]                   
    jne r4, r2, lbb_5255                            if r4 != r2 { pc += -12 }
lbb_5267:
    mov64 r2, 3                                     r2 = 3 as i32 as i64 as u64
    jeq r3, 0, lbb_5397                             if r3 == (0 as i32 as i64 as u64) { pc += 128 }
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
    stxdw [r10-0xad0], r2                   
    stxdw [r10-0xad8], r2                   
    stxdw [r10-0xae0], r2                   
    stxdw [r10-0xae8], r2                   
    ldxdw r2, [r10-0x488]                   
    jeq r2, 0, lbb_5278                             if r2 == (0 as i32 as i64 as u64) { pc += 2 }
lbb_5276:
    mov64 r3, 1                                     r3 = 1 as i32 as i64 as u64
    ja lbb_5288                                     if true { pc += 10 }
lbb_5278:
    ldxdw r2, [r10-0xae0]                   
    ldxdw r3, [r10-0x480]                   
    jne r3, r2, lbb_5276                            if r3 != r2 { pc += -5 }
    ldxdw r2, [r10-0xad8]                   
    ldxdw r3, [r10-0x478]                   
    jne r3, r2, lbb_5276                            if r3 != r2 { pc += -8 }
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
    ldxdw r2, [r10-0xad0]                   
    ldxdw r4, [r10-0x470]                   
    jne r4, r2, lbb_5276                            if r4 != r2 { pc += -12 }
lbb_5288:
    mov64 r2, 4                                     r2 = 4 as i32 as i64 as u64
    jeq r3, 0, lbb_5397                             if r3 == (0 as i32 as i64 as u64) { pc += 107 }
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
    stxdw [r10-0xad0], r2                   
    stxdw [r10-0xad8], r2                   
    stxdw [r10-0xae0], r2                   
    stxdw [r10-0xae8], r2                   
    ldxdw r2, [r10-0x468]                   
    jeq r2, 0, lbb_5299                             if r2 == (0 as i32 as i64 as u64) { pc += 2 }
lbb_5297:
    mov64 r3, 1                                     r3 = 1 as i32 as i64 as u64
    ja lbb_5309                                     if true { pc += 10 }
lbb_5299:
    ldxdw r2, [r10-0xae0]                   
    ldxdw r3, [r10-0x460]                   
    jne r3, r2, lbb_5297                            if r3 != r2 { pc += -5 }
    ldxdw r2, [r10-0xad8]                   
    ldxdw r3, [r10-0x458]                   
    jne r3, r2, lbb_5297                            if r3 != r2 { pc += -8 }
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
    ldxdw r2, [r10-0xad0]                   
    ldxdw r4, [r10-0x450]                   
    jne r4, r2, lbb_5297                            if r4 != r2 { pc += -12 }
lbb_5309:
    mov64 r2, 5                                     r2 = 5 as i32 as i64 as u64
    jeq r3, 0, lbb_5397                             if r3 == (0 as i32 as i64 as u64) { pc += 86 }
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
    stxdw [r10-0xad0], r2                   
    stxdw [r10-0xad8], r2                   
    stxdw [r10-0xae0], r2                   
    stxdw [r10-0xae8], r2                   
    ldxdw r2, [r10-0x448]                   
    jeq r2, 0, lbb_5320                             if r2 == (0 as i32 as i64 as u64) { pc += 2 }
lbb_5318:
    mov64 r3, 1                                     r3 = 1 as i32 as i64 as u64
    ja lbb_5330                                     if true { pc += 10 }
lbb_5320:
    ldxdw r2, [r10-0xae0]                   
    ldxdw r3, [r10-0x440]                   
    jne r3, r2, lbb_5318                            if r3 != r2 { pc += -5 }
    ldxdw r2, [r10-0xad8]                   
    ldxdw r3, [r10-0x438]                   
    jne r3, r2, lbb_5318                            if r3 != r2 { pc += -8 }
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
    ldxdw r2, [r10-0xad0]                   
    ldxdw r4, [r10-0x430]                   
    jne r4, r2, lbb_5318                            if r4 != r2 { pc += -12 }
lbb_5330:
    mov64 r2, 6                                     r2 = 6 as i32 as i64 as u64
    jeq r3, 0, lbb_5397                             if r3 == (0 as i32 as i64 as u64) { pc += 65 }
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
    stxdw [r10-0xad0], r2                   
    stxdw [r10-0xad8], r2                   
    stxdw [r10-0xae0], r2                   
    stxdw [r10-0xae8], r2                   
    ldxdw r2, [r10-0x428]                   
    jeq r2, 0, lbb_5341                             if r2 == (0 as i32 as i64 as u64) { pc += 2 }
lbb_5339:
    mov64 r3, 1                                     r3 = 1 as i32 as i64 as u64
    ja lbb_5351                                     if true { pc += 10 }
lbb_5341:
    ldxdw r2, [r10-0xae0]                   
    ldxdw r3, [r10-0x420]                   
    jne r3, r2, lbb_5339                            if r3 != r2 { pc += -5 }
    ldxdw r2, [r10-0xad8]                   
    ldxdw r3, [r10-0x418]                   
    jne r3, r2, lbb_5339                            if r3 != r2 { pc += -8 }
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
    ldxdw r2, [r10-0xad0]                   
    ldxdw r4, [r10-0x410]                   
    jne r4, r2, lbb_5339                            if r4 != r2 { pc += -12 }
lbb_5351:
    mov64 r2, 7                                     r2 = 7 as i32 as i64 as u64
    jeq r3, 0, lbb_5397                             if r3 == (0 as i32 as i64 as u64) { pc += 44 }
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
    stxdw [r10-0xad0], r2                   
    stxdw [r10-0xad8], r2                   
    stxdw [r10-0xae0], r2                   
    stxdw [r10-0xae8], r2                   
    ldxdw r2, [r10-0x408]                   
    jeq r2, 0, lbb_5362                             if r2 == (0 as i32 as i64 as u64) { pc += 2 }
lbb_5360:
    mov64 r3, 1                                     r3 = 1 as i32 as i64 as u64
    ja lbb_5372                                     if true { pc += 10 }
lbb_5362:
    ldxdw r2, [r10-0xae0]                   
    ldxdw r3, [r10-0x400]                   
    jne r3, r2, lbb_5360                            if r3 != r2 { pc += -5 }
    ldxdw r2, [r10-0xad8]                   
    ldxdw r3, [r10-0x3f8]                   
    jne r3, r2, lbb_5360                            if r3 != r2 { pc += -8 }
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
    ldxdw r2, [r10-0xad0]                   
    ldxdw r4, [r10-0x3f0]                   
    jne r4, r2, lbb_5360                            if r4 != r2 { pc += -12 }
lbb_5372:
    mov64 r2, 8                                     r2 = 8 as i32 as i64 as u64
    jeq r3, 0, lbb_5397                             if r3 == (0 as i32 as i64 as u64) { pc += 23 }
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
    stxdw [r10-0xad0], r2                   
    stxdw [r10-0xad8], r2                   
    stxdw [r10-0xae0], r2                   
    stxdw [r10-0xae8], r2                   
    ldxdw r2, [r10-0x3e8]                   
    jeq r2, 0, lbb_5383                             if r2 == (0 as i32 as i64 as u64) { pc += 2 }
lbb_5381:
    mov64 r3, 1                                     r3 = 1 as i32 as i64 as u64
    ja lbb_5393                                     if true { pc += 10 }
lbb_5383:
    ldxdw r2, [r10-0xae0]                   
    ldxdw r3, [r10-0x3e0]                   
    jne r3, r2, lbb_5381                            if r3 != r2 { pc += -5 }
    ldxdw r2, [r10-0xad8]                   
    ldxdw r3, [r10-0x3d8]                   
    jne r3, r2, lbb_5381                            if r3 != r2 { pc += -8 }
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
    ldxdw r2, [r10-0xad0]                   
    ldxdw r4, [r10-0x3d0]                   
    jne r4, r2, lbb_5381                            if r4 != r2 { pc += -12 }
lbb_5393:
    mov64 r2, 9                                     r2 = 9 as i32 as i64 as u64
    jeq r3, 0, lbb_5397                             if r3 == (0 as i32 as i64 as u64) { pc += 2 }
    mov64 r1, 17                                    r1 = 17 as i32 as i64 as u64
    ja lbb_5041                                     if true { pc += -356 }
lbb_5397:
    mov64 r3, r10                                   r3 = r10
    add64 r3, -2857                                 r3 += -2857   ///  r3 = r3.wrapping_add(-2857 as i32 as i64 as u64)
    mov64 r4, r10                                   r4 = r10
    add64 r4, -1288                                 r4 += -1288   ///  r4 = r4.wrapping_add(-1288 as i32 as i64 as u64)
    lsh64 r2, 5                                     r2 <<= 5   ///  r2 = r2.wrapping_shl(5)
    add64 r4, r2                                    r4 += r2   ///  r4 = r4.wrapping_add(r2)
    ldxdw r2, [r3+0x18]                     
    stxdw [r4+0x18], r2                     
    ldxdw r2, [r3+0x10]                     
    stxdw [r4+0x10], r2                     
    ldxdw r2, [r3+0x8]                      
    stxdw [r4+0x8], r2                      
    ldxdw r2, [r3+0x0]                      
    stxdw [r4+0x0], r2                      
    jeq r1, 0, lbb_4984                             if r1 == (0 as i32 as i64 as u64) { pc += -428 }
lbb_5412:
    lddw r1, 0x100040f80 --> b"\x00\x00\x00\x000\xe7\x03\x00\x10\x00\x00\x00\x00\x00\x00\x00\x89\x01\x00…        r1 load str located at 4295233408
    call function_25324                     
lbb_5415:
    mov64 r6, r8                                    r6 = r8
    stxdw [r10-0xc00], r1                   
    add64 r9, 1                                     r9 += 1   ///  r9 = r9.wrapping_add(1 as i32 as i64 as u64)
    mov64 r1, r10                                   r1 = r10
    add64 r1, -2825                                 r1 += -2825   ///  r1 = r1.wrapping_add(-2825 as i32 as i64 as u64)
    mov64 r2, r9                                    r2 = r9
    mov64 r3, 33                                    r3 = 33 as i32 as i64 as u64
    call function_30349                     
    jeq r7, 0, lbb_3772                             if r7 == (0 as i32 as i64 as u64) { pc += -1652 }
    mov64 r2, r6                                    r2 = r6
    mov64 r8, r2                                    r8 = r2
    add64 r8, 48                                    r8 += 48   ///  r8 = r8.wrapping_add(48 as i32 as i64 as u64)
    ldxdw r1, [r10-0xc00]                   
    jeq r7, 1, lbb_2935                             if r7 == (1 as i32 as i64 as u64) { pc += -2494 }
    ldxdw r3, [r2+0x0]                      
    ldxdw r4, [r3+0x0]                      
    lddw r5, 0x9e9974ee626ad71                      r5 load str located at 714268381039471985
    jeq r4, r5, lbb_5442                            if r4 == r5 { pc += 8 }
lbb_5434:
    mov64 r4, 1                                     r4 = 1 as i32 as i64 as u64
    jeq r4, 0, lbb_5457                             if r4 == (0 as i32 as i64 as u64) { pc += 21 }
lbb_5436:
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
    stxb [r1+0xb], r2                       
    stxh [r1+0x9], r2                       
    mov64 r2, 23                                    r2 = 23 as i32 as i64 as u64
    stxb [r1+0x8], r2                       
    ja lbb_3787                                     if true { pc += -1655 }
lbb_5442:
    ldxdw r4, [r3+0x8]                      
    lddw r5, 0xa5b18bf6febdfb8d                     r5 load str located at -6507266093621576819
    jne r4, r5, lbb_5434                            if r4 != r5 { pc += -12 }
    ldxdw r4, [r3+0x10]                     
    lddw r5, 0x3f762b2616a7d0c7                     r5 load str located at 4572889914230165703
    jne r4, r5, lbb_5434                            if r4 != r5 { pc += -16 }
    mov64 r4, 0                                     r4 = 0 as i32 as i64 as u64
    ldxdw r3, [r3+0x18]                     
    lddw r5, 0xe00b8186ff88305d                     r5 load str located at -2302604367657160611
    jne r3, r5, lbb_5434                            if r3 != r5 { pc += -21 }
    jeq r4, 0, lbb_5457                             if r4 == (0 as i32 as i64 as u64) { pc += 1 }
    ja lbb_5436                                     if true { pc += -21 }
lbb_5457:
    ldxdw r7, [r2+0x10]                     
    ldxdw r1, [r7+0x10]                     
    lddw r2, 0x7fffffffffffffff                     r2 load str located at 9223372036854775807
    jgt r2, r1, lbb_5463                            if r2 > r1 { pc += 1 }
    ja lbb_5483                                     if true { pc += 20 }
lbb_5463:
    add64 r1, 1                                     r1 += 1   ///  r1 = r1.wrapping_add(1 as i32 as i64 as u64)
    stxdw [r7+0x10], r1                     
    ldxdw r1, [r7+0x18]                     
    ldxdw r2, [r7+0x20]                     
    stxdw [r10-0x150], r2                   
    stxdw [r10-0x158], r1                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -2792                                 r1 += -2792   ///  r1 = r1.wrapping_add(-2792 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -344                                  r2 += -344   ///  r2 = r2.wrapping_add(-344 as i32 as i64 as u64)
    call function_12619                     
    ldxdw r4, [r10-0xae0]                   
    ldxdw r9, [r10-0xae8]                   
    lddw r1, 0x8000000000000000                     r1 load str located at -9223372036854775808
    jeq r9, r1, lbb_5480                            if r9 == r1 { pc += 1 }
    ja lbb_5486                                     if true { pc += 6 }
lbb_5480:
    ldxdw r1, [r10-0xc00]                   
    mov64 r2, r4                                    r2 = r4
    ja lbb_4415                                     if true { pc += -1068 }
lbb_5483:
    lddw r1, 0x100040fc8 --> b"\x00\x00\x00\x000\xe7\x03\x00\x10\x00\x00\x00\x00\x00\x00\x00\x98\x01\x00…        r1 load str located at 4295233480
    call function_25345                     
lbb_5486:
    mov64 r1, r10                                   r1 = r10
    add64 r1, -1480                                 r1 += -1480   ///  r1 = r1.wrapping_add(-1480 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -2776                                 r2 += -2776   ///  r2 = r2.wrapping_add(-2776 as i32 as i64 as u64)
    stxdw [r10-0xc10], r1                   
    mov64 r3, 528                                   r3 = 528 as i32 as i64 as u64
    stxdw [r10-0xc08], r4                   
    call function_30349                     
    ldxdw r1, [r10-0xc08]                   
    stxdw [r10-0x5d0], r1                   
    stxdw [r10-0x5d8], r9                   
    ldxdw r1, [r7+0x10]                     
    add64 r1, -1                                    r1 += -1   ///  r1 = r1.wrapping_add(-1 as i32 as i64 as u64)
    stxdw [r7+0x10], r1                     
    lddw r2, 0xfc3e34becfcb63d7                     r2 load str located at -270720933461007401
    ldxdw r3, [r10-0x588]                   
    jeq r3, r2, lbb_5506                            if r3 == r2 { pc += 2 }
lbb_5504:
    mov64 r3, 1                                     r3 = 1 as i32 as i64 as u64
    ja lbb_5519                                     if true { pc += 13 }
lbb_5506:
    lddw r2, 0xf495c87a5045cbbb                     r2 load str located at -822530929266930757
    ldxdw r3, [r10-0x580]                   
    jne r3, r2, lbb_5504                            if r3 != r2 { pc += -6 }
    lddw r2, 0xe7d24322df5eeb7c                     r2 load str located at -1742256288783471748
    ldxdw r3, [r10-0x578]                   
    jne r3, r2, lbb_5504                            if r3 != r2 { pc += -10 }
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
    lddw r2, 0xcf66dbb77498e62b                     r2 load str located at -3501870079252306389
    ldxdw r4, [r10-0x570]                   
    jne r4, r2, lbb_5504                            if r4 != r2 { pc += -15 }
lbb_5519:
    ldxdw r2, [r10-0xc00]                   
    jeq r3, 0, lbb_5522                             if r3 == (0 as i32 as i64 as u64) { pc += 1 }
    ja lbb_7118                                     if true { pc += 1596 }
lbb_5522:
    ldxb r3, [r10-0x3c4]                    
    jeq r3, 0, lbb_5526                             if r3 == (0 as i32 as i64 as u64) { pc += 2 }
lbb_5524:
    mov64 r1, 15                                    r1 = 15 as i32 as i64 as u64
    ja lbb_7119                                     if true { pc += 1593 }
lbb_5526:
    ldxb r3, [r6+0x29]                      
    jeq r3, 0, lbb_7173                             if r3 == (0 as i32 as i64 as u64) { pc += 1645 }
    ldxb r3, [r6+0x58]                      
    jeq r3, 0, lbb_5538                             if r3 == (0 as i32 as i64 as u64) { pc += 8 }
    ldxdw r3, [r8+0x0]                      
    ldxdw r4, [r3+0x0]                      
    ldxdw r5, [r10-0x588]                   
    jeq r4, r5, lbb_5540                            if r4 == r5 { pc += 6 }
lbb_5534:
    mov64 r4, 1                                     r4 = 1 as i32 as i64 as u64
    jeq r4, 0, lbb_5552                             if r4 == (0 as i32 as i64 as u64) { pc += 16 }
lbb_5536:
    mov64 r1, 3                                     r1 = 3 as i32 as i64 as u64
    ja lbb_7119                                     if true { pc += 1581 }
lbb_5538:
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    ja lbb_7119                                     if true { pc += 1579 }
lbb_5540:
    ldxdw r4, [r3+0x8]                      
    ldxdw r5, [r10-0x580]                   
    jne r4, r5, lbb_5534                            if r4 != r5 { pc += -9 }
    ldxdw r4, [r3+0x10]                     
    ldxdw r5, [r10-0x578]                   
    jne r4, r5, lbb_5534                            if r4 != r5 { pc += -12 }
    mov64 r4, 0                                     r4 = 0 as i32 as i64 as u64
    ldxdw r3, [r3+0x18]                     
    ldxdw r5, [r10-0x570]                   
    jne r3, r5, lbb_5534                            if r3 != r5 { pc += -16 }
    jeq r4, 0, lbb_5552                             if r4 == (0 as i32 as i64 as u64) { pc += 1 }
    ja lbb_5536                                     if true { pc += -16 }
lbb_5552:
    ldxb r2, [r10-0xb09]                    
    jeq r2, 0, lbb_5585                             if r2 == (0 as i32 as i64 as u64) { pc += 31 }
    jeq r2, 1, lbb_5557                             if r2 == (1 as i32 as i64 as u64) { pc += 2 }
    ldxdw r1, [r10-0x5b8]                   
    stxdw [r10-0xc08], r1                   
lbb_5557:
    jeq r2, 1, lbb_5561                             if r2 == (1 as i32 as i64 as u64) { pc += 3 }
    mov64 r1, r10                                   r1 = r10
    add64 r1, -1456                                 r1 += -1456   ///  r1 = r1.wrapping_add(-1456 as i32 as i64 as u64)
    stxdw [r10-0xc10], r1                   
lbb_5561:
    ldxw r1, [r10-0xaec]                    
    stxw [r10-0x150], r1                    
    ldxw r1, [r10-0xafa]                    
    stxw [r10-0x154], r1                    
    ldxw r1, [r10-0xb08]                    
    stxw [r10-0x158], r1                    
    ldxdw r1, [r10-0xc10]                   
    ldxdw r3, [r1+0x0]                      
    mov64 r1, r10                                   r1 = r10
    add64 r1, -2792                                 r1 += -2792   ///  r1 = r1.wrapping_add(-2792 as i32 as i64 as u64)
    mov64 r4, r10                                   r4 = r10
    add64 r4, -344                                  r4 += -344   ///  r4 = r4.wrapping_add(-344 as i32 as i64 as u64)
    ldxdw r2, [r10-0xc08]                   
    call function_9386                      
    lddw r1, 0x800000000000001a                     r1 load str located at -9223372036854775782
    ldxdw r2, [r10-0xae8]                   
    jeq r2, r1, lbb_5580                            if r2 == r1 { pc += 1 }
    ja lbb_6456                                     if true { pc += 876 }
lbb_5580:
    ldxdw r1, [r7+0x10]                     
    jeq r1, 0, lbb_5768                             if r1 == (0 as i32 as i64 as u64) { pc += 186 }
lbb_5582:
    lddw r1, 0x100040fb0 --> b"\x00\x00\x00\x000\xe7\x03\x00\x10\x00\x00\x00\x00\x00\x00\x00\xc0\x01\x00…        r1 load str located at 4295233456
    call function_25324                     
lbb_5585:
    ldxdw r2, [r10-0x508]                   
    ldxdw r3, [r10-0xb08]                   
    jeq r3, r2, lbb_5590                            if r3 == r2 { pc += 2 }
lbb_5588:
    mov64 r4, 1                                     r4 = 1 as i32 as i64 as u64
    ja lbb_5600                                     if true { pc += 10 }
lbb_5590:
    ldxdw r2, [r10-0x500]                   
    ldxdw r3, [r10-0xb00]                   
    jne r3, r2, lbb_5588                            if r3 != r2 { pc += -5 }
    ldxdw r2, [r10-0x4f8]                   
    ldxdw r3, [r10-0xaf8]                   
    jne r3, r2, lbb_5588                            if r3 != r2 { pc += -8 }
    mov64 r4, 0                                     r4 = 0 as i32 as i64 as u64
    ldxdw r2, [r10-0x4f0]                   
    ldxdw r3, [r10-0xaf0]                   
    jne r3, r2, lbb_5588                            if r3 != r2 { pc += -12 }
lbb_5600:
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
    jeq r4, 0, lbb_5758                             if r4 == (0 as i32 as i64 as u64) { pc += 155 }
    ldxdw r3, [r10-0x4e8]                   
    ldxdw r4, [r10-0xb08]                   
    jeq r4, r3, lbb_5608                            if r4 == r3 { pc += 2 }
lbb_5606:
    mov64 r4, 1                                     r4 = 1 as i32 as i64 as u64
    ja lbb_5618                                     if true { pc += 10 }
lbb_5608:
    ldxdw r3, [r10-0x4e0]                   
    ldxdw r4, [r10-0xb00]                   
    jne r4, r3, lbb_5606                            if r4 != r3 { pc += -5 }
    ldxdw r3, [r10-0x4d8]                   
    ldxdw r4, [r10-0xaf8]                   
    jne r4, r3, lbb_5606                            if r4 != r3 { pc += -8 }
    mov64 r4, 0                                     r4 = 0 as i32 as i64 as u64
    ldxdw r3, [r10-0x4d0]                   
    ldxdw r5, [r10-0xaf0]                   
    jne r5, r3, lbb_5606                            if r5 != r3 { pc += -12 }
lbb_5618:
    mov64 r3, 1                                     r3 = 1 as i32 as i64 as u64
    jeq r4, 0, lbb_5758                             if r4 == (0 as i32 as i64 as u64) { pc += 138 }
    ldxdw r3, [r10-0x4c8]                   
    ldxdw r4, [r10-0xb08]                   
    jeq r4, r3, lbb_5625                            if r4 == r3 { pc += 2 }
lbb_5623:
    mov64 r4, 1                                     r4 = 1 as i32 as i64 as u64
    ja lbb_5635                                     if true { pc += 10 }
lbb_5625:
    ldxdw r3, [r10-0x4c0]                   
    ldxdw r4, [r10-0xb00]                   
    jne r4, r3, lbb_5623                            if r4 != r3 { pc += -5 }
    ldxdw r3, [r10-0x4b8]                   
    ldxdw r4, [r10-0xaf8]                   
    jne r4, r3, lbb_5623                            if r4 != r3 { pc += -8 }
    mov64 r4, 0                                     r4 = 0 as i32 as i64 as u64
    ldxdw r3, [r10-0x4b0]                   
    ldxdw r5, [r10-0xaf0]                   
    jne r5, r3, lbb_5623                            if r5 != r3 { pc += -12 }
lbb_5635:
    mov64 r3, 2                                     r3 = 2 as i32 as i64 as u64
    jeq r4, 0, lbb_5758                             if r4 == (0 as i32 as i64 as u64) { pc += 121 }
    ldxdw r3, [r10-0x4a8]                   
    ldxdw r4, [r10-0xb08]                   
    jeq r4, r3, lbb_5642                            if r4 == r3 { pc += 2 }
lbb_5640:
    mov64 r4, 1                                     r4 = 1 as i32 as i64 as u64
    ja lbb_5652                                     if true { pc += 10 }
lbb_5642:
    ldxdw r3, [r10-0x4a0]                   
    ldxdw r4, [r10-0xb00]                   
    jne r4, r3, lbb_5640                            if r4 != r3 { pc += -5 }
    ldxdw r3, [r10-0x498]                   
    ldxdw r4, [r10-0xaf8]                   
    jne r4, r3, lbb_5640                            if r4 != r3 { pc += -8 }
    mov64 r4, 0                                     r4 = 0 as i32 as i64 as u64
    ldxdw r3, [r10-0x490]                   
    ldxdw r5, [r10-0xaf0]                   
    jne r5, r3, lbb_5640                            if r5 != r3 { pc += -12 }
lbb_5652:
    mov64 r3, 3                                     r3 = 3 as i32 as i64 as u64
    jeq r4, 0, lbb_5758                             if r4 == (0 as i32 as i64 as u64) { pc += 104 }
    ldxdw r3, [r10-0x488]                   
    ldxdw r4, [r10-0xb08]                   
    jeq r4, r3, lbb_5659                            if r4 == r3 { pc += 2 }
lbb_5657:
    mov64 r4, 1                                     r4 = 1 as i32 as i64 as u64
    ja lbb_5669                                     if true { pc += 10 }
lbb_5659:
    ldxdw r3, [r10-0x480]                   
    ldxdw r4, [r10-0xb00]                   
    jne r4, r3, lbb_5657                            if r4 != r3 { pc += -5 }
    ldxdw r3, [r10-0x478]                   
    ldxdw r4, [r10-0xaf8]                   
    jne r4, r3, lbb_5657                            if r4 != r3 { pc += -8 }
    mov64 r4, 0                                     r4 = 0 as i32 as i64 as u64
    ldxdw r3, [r10-0x470]                   
    ldxdw r5, [r10-0xaf0]                   
    jne r5, r3, lbb_5657                            if r5 != r3 { pc += -12 }
lbb_5669:
    mov64 r3, 4                                     r3 = 4 as i32 as i64 as u64
    jeq r4, 0, lbb_5758                             if r4 == (0 as i32 as i64 as u64) { pc += 87 }
    ldxdw r3, [r10-0x468]                   
    ldxdw r4, [r10-0xb08]                   
    jeq r4, r3, lbb_5676                            if r4 == r3 { pc += 2 }
lbb_5674:
    mov64 r4, 1                                     r4 = 1 as i32 as i64 as u64
    ja lbb_5686                                     if true { pc += 10 }
lbb_5676:
    ldxdw r3, [r10-0x460]                   
    ldxdw r4, [r10-0xb00]                   
    jne r4, r3, lbb_5674                            if r4 != r3 { pc += -5 }
    ldxdw r3, [r10-0x458]                   
    ldxdw r4, [r10-0xaf8]                   
    jne r4, r3, lbb_5674                            if r4 != r3 { pc += -8 }
    mov64 r4, 0                                     r4 = 0 as i32 as i64 as u64
    ldxdw r3, [r10-0x450]                   
    ldxdw r5, [r10-0xaf0]                   
    jne r5, r3, lbb_5674                            if r5 != r3 { pc += -12 }
lbb_5686:
    mov64 r3, 5                                     r3 = 5 as i32 as i64 as u64
    jeq r4, 0, lbb_5758                             if r4 == (0 as i32 as i64 as u64) { pc += 70 }
    ldxdw r3, [r10-0x448]                   
    ldxdw r4, [r10-0xb08]                   
    jeq r4, r3, lbb_5693                            if r4 == r3 { pc += 2 }
lbb_5691:
    mov64 r4, 1                                     r4 = 1 as i32 as i64 as u64
    ja lbb_5703                                     if true { pc += 10 }
lbb_5693:
    ldxdw r3, [r10-0x440]                   
    ldxdw r4, [r10-0xb00]                   
    jne r4, r3, lbb_5691                            if r4 != r3 { pc += -5 }
    ldxdw r3, [r10-0x438]                   
    ldxdw r4, [r10-0xaf8]                   
    jne r4, r3, lbb_5691                            if r4 != r3 { pc += -8 }
    mov64 r4, 0                                     r4 = 0 as i32 as i64 as u64
    ldxdw r3, [r10-0x430]                   
    ldxdw r5, [r10-0xaf0]                   
    jne r5, r3, lbb_5691                            if r5 != r3 { pc += -12 }
lbb_5703:
    mov64 r3, 6                                     r3 = 6 as i32 as i64 as u64
    jeq r4, 0, lbb_5758                             if r4 == (0 as i32 as i64 as u64) { pc += 53 }
    ldxdw r3, [r10-0x428]                   
    ldxdw r4, [r10-0xb08]                   
    jeq r4, r3, lbb_5710                            if r4 == r3 { pc += 2 }
lbb_5708:
    mov64 r4, 1                                     r4 = 1 as i32 as i64 as u64
    ja lbb_5720                                     if true { pc += 10 }
lbb_5710:
    ldxdw r3, [r10-0x420]                   
    ldxdw r4, [r10-0xb00]                   
    jne r4, r3, lbb_5708                            if r4 != r3 { pc += -5 }
    ldxdw r3, [r10-0x418]                   
    ldxdw r4, [r10-0xaf8]                   
    jne r4, r3, lbb_5708                            if r4 != r3 { pc += -8 }
    mov64 r4, 0                                     r4 = 0 as i32 as i64 as u64
    ldxdw r3, [r10-0x410]                   
    ldxdw r5, [r10-0xaf0]                   
    jne r5, r3, lbb_5708                            if r5 != r3 { pc += -12 }
lbb_5720:
    mov64 r3, 7                                     r3 = 7 as i32 as i64 as u64
    jeq r4, 0, lbb_5758                             if r4 == (0 as i32 as i64 as u64) { pc += 36 }
    ldxdw r3, [r10-0x408]                   
    ldxdw r4, [r10-0xb08]                   
    jeq r4, r3, lbb_5727                            if r4 == r3 { pc += 2 }
lbb_5725:
    mov64 r4, 1                                     r4 = 1 as i32 as i64 as u64
    ja lbb_5737                                     if true { pc += 10 }
lbb_5727:
    ldxdw r3, [r10-0x400]                   
    ldxdw r4, [r10-0xb00]                   
    jne r4, r3, lbb_5725                            if r4 != r3 { pc += -5 }
    ldxdw r3, [r10-0x3f8]                   
    ldxdw r4, [r10-0xaf8]                   
    jne r4, r3, lbb_5725                            if r4 != r3 { pc += -8 }
    mov64 r4, 0                                     r4 = 0 as i32 as i64 as u64
    ldxdw r3, [r10-0x3f0]                   
    ldxdw r5, [r10-0xaf0]                   
    jne r5, r3, lbb_5725                            if r5 != r3 { pc += -12 }
lbb_5737:
    mov64 r3, 8                                     r3 = 8 as i32 as i64 as u64
    jeq r4, 0, lbb_5758                             if r4 == (0 as i32 as i64 as u64) { pc += 19 }
    ldxdw r3, [r10-0x3e8]                   
    ldxdw r4, [r10-0xb08]                   
    jeq r4, r3, lbb_5744                            if r4 == r3 { pc += 2 }
lbb_5742:
    mov64 r4, 1                                     r4 = 1 as i32 as i64 as u64
    ja lbb_5754                                     if true { pc += 10 }
lbb_5744:
    ldxdw r3, [r10-0x3e0]                   
    ldxdw r4, [r10-0xb00]                   
    jne r4, r3, lbb_5742                            if r4 != r3 { pc += -5 }
    ldxdw r3, [r10-0x3d8]                   
    ldxdw r4, [r10-0xaf8]                   
    jne r4, r3, lbb_5742                            if r4 != r3 { pc += -8 }
    mov64 r4, 0                                     r4 = 0 as i32 as i64 as u64
    ldxdw r3, [r10-0x3d0]                   
    ldxdw r5, [r10-0xaf0]                   
    jne r5, r3, lbb_5742                            if r5 != r3 { pc += -12 }
lbb_5754:
    mov64 r3, 9                                     r3 = 9 as i32 as i64 as u64
    jeq r4, 0, lbb_5758                             if r4 == (0 as i32 as i64 as u64) { pc += 2 }
    mov64 r1, 18                                    r1 = 18 as i32 as i64 as u64
    ja lbb_2954                                     if true { pc += -2804 }
lbb_5758:
    mov64 r4, r10                                   r4 = r10
    add64 r4, -1288                                 r4 += -1288   ///  r4 = r4.wrapping_add(-1288 as i32 as i64 as u64)
    lsh64 r3, 5                                     r3 <<= 5   ///  r3 = r3.wrapping_shl(5)
    add64 r4, r3                                    r4 += r3   ///  r4 = r4.wrapping_add(r3)
    stxdw [r4+0x18], r2                     
    stxdw [r4+0x10], r2                     
    stxdw [r4+0x8], r2                      
    stxdw [r4+0x0], r2                      
    jeq r1, 0, lbb_5768                             if r1 == (0 as i32 as i64 as u64) { pc += 1 }
    ja lbb_5582                                     if true { pc += -186 }
lbb_5768:
    mov64 r1, -1                                    r1 = -1 as i32 as i64 as u64
    mov64 r2, r7                                    r2 = r7
    stxdw [r2+0x10], r1                     
    ldxdw r1, [r2+0x18]                     
    ldxdw r2, [r2+0x20]                     
    stxdw [r10-0xae0], r2                   
    stxdw [r10-0xae8], r1                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -1496                                 r1 += -1496   ///  r1 = r1.wrapping_add(-1496 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -2792                                 r2 += -2792   ///  r2 = r2.wrapping_add(-2792 as i32 as i64 as u64)
    call function_13019                     
    jeq r0, 0, lbb_4790                             if r0 == (0 as i32 as i64 as u64) { pc += -991 }
lbb_5781:
    ldxdw r1, [r10-0xc00]                   
    mov64 r2, r0                                    r2 = r0
    call function_18093                     
    ldxdw r1, [r7+0x10]                     
    add64 r1, 1                                     r1 += 1   ///  r1 = r1.wrapping_add(1 as i32 as i64 as u64)
    stxdw [r7+0x10], r1                     
    ja lbb_3730                                     if true { pc += -2058 }
lbb_5788:
    mov64 r1, r10                                   r1 = r10
    add64 r1, -1480                                 r1 += -1480   ///  r1 = r1.wrapping_add(-1480 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -2776                                 r2 += -2776   ///  r2 = r2.wrapping_add(-2776 as i32 as i64 as u64)
    mov64 r3, 528                                   r3 = 528 as i32 as i64 as u64
    call function_30349                     
    ldxdw r1, [r7+0x10]                     
    add64 r1, -1                                    r1 += -1   ///  r1 = r1.wrapping_add(-1 as i32 as i64 as u64)
    stxdw [r7+0x10], r1                     
    lddw r1, 0xfc3e34becfcb63d7                     r1 load str located at -270720933461007401
    ldxdw r2, [r10-0x588]                   
    jeq r2, r1, lbb_5803                            if r2 == r1 { pc += 2 }
lbb_5801:
    mov64 r2, 1                                     r2 = 1 as i32 as i64 as u64
    ja lbb_5816                                     if true { pc += 13 }
lbb_5803:
    lddw r1, 0xf495c87a5045cbbb                     r1 load str located at -822530929266930757
    ldxdw r2, [r10-0x580]                   
    jne r2, r1, lbb_5801                            if r2 != r1 { pc += -6 }
    lddw r1, 0xe7d24322df5eeb7c                     r1 load str located at -1742256288783471748
    ldxdw r2, [r10-0x578]                   
    jne r2, r1, lbb_5801                            if r2 != r1 { pc += -10 }
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
    lddw r1, 0xcf66dbb77498e62b                     r1 load str located at -3501870079252306389
    ldxdw r3, [r10-0x570]                   
    jne r3, r1, lbb_5801                            if r3 != r1 { pc += -15 }
lbb_5816:
    ldxdw r1, [r10-0xc00]                   
    ldxdw r3, [r10-0xc08]                   
    jeq r2, 0, lbb_5821                             if r2 == (0 as i32 as i64 as u64) { pc += 2 }
lbb_5819:
    mov64 r2, 28                                    r2 = 28 as i32 as i64 as u64
    ja lbb_3782                                     if true { pc += -2039 }
lbb_5821:
    ldxb r2, [r3+0x58]                      
    jeq r2, 0, lbb_3781                             if r2 == (0 as i32 as i64 as u64) { pc += -2042 }
    mov64 r7, r8                                    r7 = r8
    ldxdw r1, [r6+0x0]                      
    ldxdw r2, [r1+0x0]                      
    ldxdw r3, [r10-0x588]                   
    jeq r2, r3, lbb_5832                            if r2 == r3 { pc += 4 }
lbb_5828:
    mov64 r2, 1                                     r2 = 1 as i32 as i64 as u64
    jeq r2, 0, lbb_5844                             if r2 == (0 as i32 as i64 as u64) { pc += 14 }
lbb_5830:
    mov64 r1, 3                                     r1 = 3 as i32 as i64 as u64
    ja lbb_2954                                     if true { pc += -2878 }
lbb_5832:
    ldxdw r2, [r1+0x8]                      
    ldxdw r3, [r10-0x580]                   
    jne r2, r3, lbb_5828                            if r2 != r3 { pc += -7 }
    ldxdw r2, [r1+0x10]                     
    ldxdw r3, [r10-0x578]                   
    jne r2, r3, lbb_5828                            if r2 != r3 { pc += -10 }
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
    ldxdw r1, [r1+0x18]                     
    ldxdw r3, [r10-0x570]                   
    jne r1, r3, lbb_5828                            if r1 != r3 { pc += -14 }
    jeq r2, 0, lbb_5844                             if r2 == (0 as i32 as i64 as u64) { pc += 1 }
    ja lbb_5830                                     if true { pc += -14 }
lbb_5844:
    ldxb r1, [r10-0x3c4]                    
    jeq r1, 0, lbb_5848                             if r1 == (0 as i32 as i64 as u64) { pc += 2 }
lbb_5846:
    mov64 r1, 15                                    r1 = 15 as i32 as i64 as u64
    ja lbb_2954                                     if true { pc += -2894 }
lbb_5848:
    mov64 r1, r7                                    r1 = r7
    lsh64 r1, 32                                    r1 <<= 32   ///  r1 = r1.wrapping_shl(32)
    or64 r9, r1                                     r9 |= r1   ///  r9 = r9.or(r1)
    mov64 r1, r10                                   r1 = r10
    add64 r1, -2792                                 r1 += -2792   ///  r1 = r1.wrapping_add(-2792 as i32 as i64 as u64)
    ldxdw r2, [r10-0xc10]                   
    ldxdw r3, [r10-0xc18]                   
    mov64 r4, r9                                    r4 = r9
    call function_9195                      
    ldxdw r1, [r10-0xae8]                   
    lddw r2, 0x800000000000001a                     r2 load str located at -9223372036854775782
    jeq r1, r2, lbb_5862                            if r1 == r2 { pc += 1 }
    ja lbb_6248                                     if true { pc += 386 }
lbb_5862:
    ldxdw r1, [r10-0xc08]                   
    ldxb r1, [r1+0x89]                      
    jeq r1, 0, lbb_3759                             if r1 == (0 as i32 as i64 as u64) { pc += -2106 }
    ldxdw r1, [r10-0xc08]                   
    ldxdw r8, [r1+0x70]                     
    ldxdw r1, [r8+0x10]                     
    jeq r1, 0, lbb_5870                             if r1 == (0 as i32 as i64 as u64) { pc += 1 }
    ja lbb_5937                                     if true { pc += 67 }
lbb_5870:
    mov64 r1, -1                                    r1 = -1 as i32 as i64 as u64
    stxdw [r8+0x10], r1                     
    ldxdw r1, [r8+0x20]                     
    jne r1, 1264, lbb_5921                          if r1 != (1264 as i32 as i64 as u64) { pc += 47 }
    ldxdw r1, [r8+0x18]                     
    stxdw [r10-0xc18], r1                   
    and64 r1, 7                                     r1 &= 7   ///  r1 = r1.and(7)
    jeq r1, 0, lbb_5879                             if r1 == (0 as i32 as i64 as u64) { pc += 1 }
    ja lbb_5921                                     if true { pc += 42 }
lbb_5879:
    rsh64 r9, 16                                    r9 >>= 16   ///  r9 = r9.wrapping_shr(16)
    mov64 r1, r10                                   r1 = r10
    add64 r1, -2792                                 r1 += -2792   ///  r1 = r1.wrapping_add(-2792 as i32 as i64 as u64)
    ldxdw r2, [r10-0xc10]                   
    ldxdw r3, [r10-0xc20]                   
    mov64 r4, r9                                    r4 = r9
    call function_9118                      
    ldxdw r1, [r10-0xae8]                   
    lddw r2, 0x800000000000001a                     r2 load str located at -9223372036854775782
    jeq r1, r2, lbb_5891                            if r1 == r2 { pc += 1 }
    ja lbb_5928                                     if true { pc += 37 }
lbb_5891:
    ldxdw r1, [r10-0xc08]                   
    ldxdw r1, [r1+0xa0]                     
    stxdw [r10-0xc20], r1                   
    ldxdw r1, [r1+0x10]                     
    lddw r2, 0x7fffffffffffffff                     r2 load str located at 9223372036854775807
    jgt r2, r1, lbb_5899                            if r2 > r1 { pc += 1 }
    ja lbb_5940                                     if true { pc += 41 }
lbb_5899:
    add64 r1, 1                                     r1 += 1   ///  r1 = r1.wrapping_add(1 as i32 as i64 as u64)
    ldxdw r2, [r10-0xc20]                   
    stxdw [r2+0x10], r1                     
    ldxdw r3, [r2+0x20]                     
    ldxdw r2, [r2+0x18]                     
    mov64 r1, r10                                   r1 = r10
    add64 r1, -2792                                 r1 += -2792   ///  r1 = r1.wrapping_add(-2792 as i32 as i64 as u64)
    call function_0                         
    ldxw r1, [r10-0xa50]                    
    jeq r1, 2, lbb_5910                             if r1 == (2 as i32 as i64 as u64) { pc += 1 }
    ja lbb_5943                                     if true { pc += 33 }
lbb_5910:
    ldxdw r1, [r10-0xad8]                   
    stxdw [r10-0x148], r1                   
    ldxdw r2, [r10-0xae0]                   
    stxdw [r10-0x150], r2                   
    ldxdw r3, [r10-0xae8]                   
    stxdw [r10-0x158], r3                   
    ldxdw r4, [r10-0xc00]                   
    stxdw [r4+0x10], r1                     
    stxdw [r4+0x8], r2                      
    stxdw [r4+0x0], r3                      
    ja lbb_6084                                     if true { pc += 163 }
lbb_5921:
    mov64 r1, 65535                                 r1 = 65535 as i32 as i64 as u64
    ldxdw r2, [r10-0xc00]                   
    stxw [r2+0x8], r1                       
    lddw r1, 0x8000000000000000                     r1 load str located at -9223372036854775808
    stxdw [r2+0x0], r1                      
    ja lbb_6088                                     if true { pc += 160 }
lbb_5928:
    ldxb r2, [r10-0xae0]                    
    ldxdw r3, [r10-0xad8]                   
    ldxdw r4, [r10-0xc00]                   
    stxdw [r4+0x10], r3                     
    ldxdw r3, [r10-0xadf]                   
    stxdw [r4+0x9], r3                      
    stxb [r4+0x8], r2                       
    stxdw [r4+0x0], r1                      
    ja lbb_6088                                     if true { pc += 151 }
lbb_5937:
    lddw r1, 0x100041010 --> b"\x00\x00\x00\x000\xe7\x03\x00\x10\x00\x00\x00\x00\x00\x00\x00\xde\x01\x00…        r1 load str located at 4295233552
    call function_25324                     
lbb_5940:
    lddw r1, 0x100040ff8 --> b"\x00\x00\x00\x000\xe7\x03\x00\x10\x00\x00\x00\x00\x00\x00\x00\xea\x01\x00…        r1 load str located at 4295233528
    call function_25345                     
lbb_5943:
    mov64 r6, r10                                   r6 = r10
    add64 r6, -344                                  r6 += -344   ///  r6 = r6.wrapping_add(-344 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -2792                                 r2 += -2792   ///  r2 = r2.wrapping_add(-2792 as i32 as i64 as u64)
    mov64 r1, r6                                    r1 = r6
    mov64 r3, 152                                   r3 = 152 as i32 as i64 as u64
    call function_30349                     
    mov64 r1, r10                                   r1 = r10
    add64 r1, -536                                  r1 += -536   ///  r1 = r1.wrapping_add(-536 as i32 as i64 as u64)
    mov64 r2, r6                                    r2 = r6
    mov64 r3, 152                                   r3 = 152 as i32 as i64 as u64
    call function_30349                     
    ldxdw r1, [r10-0xc18]                   
    ldxdw r1, [r1+0x18]                     
    ldxdw r2, [r10-0x208]                   
    jeq r2, r1, lbb_5968                            if r2 == r1 { pc += 9 }
lbb_5959:
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    jeq r1, 0, lbb_5983                             if r1 == (0 as i32 as i64 as u64) { pc += 22 }
lbb_5961:
    mov64 r1, 5                                     r1 = 5 as i32 as i64 as u64
    ldxdw r2, [r10-0xc00]                   
    stxw [r2+0x8], r1                       
    lddw r1, 0x8000000000000000                     r1 load str located at -9223372036854775808
    stxdw [r2+0x0], r1                      
    ja lbb_6084                                     if true { pc += 116 }
lbb_5968:
    ldxdw r1, [r10-0xc18]                   
    ldxdw r1, [r1+0x20]                     
    ldxdw r2, [r10-0x200]                   
    jne r2, r1, lbb_5959                            if r2 != r1 { pc += -13 }
    ldxdw r1, [r10-0xc18]                   
    ldxdw r1, [r1+0x28]                     
    ldxdw r2, [r10-0x1f8]                   
    jne r2, r1, lbb_5959                            if r2 != r1 { pc += -17 }
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    ldxdw r2, [r10-0xc18]                   
    ldxdw r2, [r2+0x30]                     
    ldxdw r3, [r10-0x1f0]                   
    jne r3, r2, lbb_5959                            if r3 != r2 { pc += -22 }
    jeq r1, 0, lbb_5983                             if r1 == (0 as i32 as i64 as u64) { pc += 1 }
    ja lbb_5961                                     if true { pc += -22 }
lbb_5983:
    mov64 r1, r10                                   r1 = r10
    add64 r1, -2792                                 r1 += -2792   ///  r1 = r1.wrapping_add(-2792 as i32 as i64 as u64)
    ldxdw r2, [r10-0xc10]                   
    ldxdw r3, [r10-0xc28]                   
    mov64 r4, r7                                    r4 = r7
    call function_9118                      
    ldxdw r1, [r10-0xae8]                   
    lddw r2, 0x800000000000001a                     r2 load str located at -9223372036854775782
    jeq r1, r2, lbb_5994                            if r1 == r2 { pc += 1 }
    ja lbb_6022                                     if true { pc += 28 }
lbb_5994:
    ldxdw r1, [r10-0xc08]                   
    ldxdw r6, [r1+0xd0]                     
    ldxdw r1, [r6+0x10]                     
    lddw r2, 0x7fffffffffffffff                     r2 load str located at 9223372036854775807
    jgt r2, r1, lbb_6001                            if r2 > r1 { pc += 1 }
    ja lbb_6031                                     if true { pc += 30 }
lbb_6001:
    add64 r1, 1                                     r1 += 1   ///  r1 = r1.wrapping_add(1 as i32 as i64 as u64)
    stxdw [r6+0x10], r1                     
    ldxdw r3, [r6+0x20]                     
    ldxdw r2, [r6+0x18]                     
    mov64 r1, r10                                   r1 = r10
    add64 r1, -2792                                 r1 += -2792   ///  r1 = r1.wrapping_add(-2792 as i32 as i64 as u64)
    call function_0                         
    ldxw r1, [r10-0xa50]                    
    jeq r1, 2, lbb_6011                             if r1 == (2 as i32 as i64 as u64) { pc += 1 }
    ja lbb_6034                                     if true { pc += 23 }
lbb_6011:
    ldxdw r1, [r10-0xad8]                   
    stxdw [r10-0x2c8], r1                   
    ldxdw r2, [r10-0xae0]                   
    stxdw [r10-0x2d0], r2                   
    ldxdw r3, [r10-0xae8]                   
    stxdw [r10-0x2d8], r3                   
    ldxdw r4, [r10-0xc00]                   
    stxdw [r4+0x10], r1                     
    stxdw [r4+0x8], r2                      
    stxdw [r4+0x0], r3                      
    ja lbb_6081                                     if true { pc += 59 }
lbb_6022:
    ldxb r2, [r10-0xae0]                    
    ldxdw r3, [r10-0xad8]                   
    ldxdw r4, [r10-0xc00]                   
    stxdw [r4+0x10], r3                     
    ldxdw r3, [r10-0xadf]                   
    stxdw [r4+0x9], r3                      
    stxb [r4+0x8], r2                       
    stxdw [r4+0x0], r1                      
    ja lbb_6084                                     if true { pc += 53 }
lbb_6031:
    lddw r1, 0x100040fe0 --> b"\x00\x00\x00\x000\xe7\x03\x00\x10\x00\x00\x00\x00\x00\x00\x00\xf5\x01\x00…        r1 load str located at 4295233504
    call function_25345                     
lbb_6034:
    mov64 r1, r10                                   r1 = r10
    add64 r1, -728                                  r1 += -728   ///  r1 = r1.wrapping_add(-728 as i32 as i64 as u64)
    stxdw [r10-0xc08], r1                   
    mov64 r2, r10                                   r2 = r10
    add64 r2, -2792                                 r2 += -2792   ///  r2 = r2.wrapping_add(-2792 as i32 as i64 as u64)
    mov64 r3, 152                                   r3 = 152 as i32 as i64 as u64
    call function_30349                     
    mov64 r1, r10                                   r1 = r10
    add64 r1, -344                                  r1 += -344   ///  r1 = r1.wrapping_add(-344 as i32 as i64 as u64)
    ldxdw r2, [r10-0xc08]                   
    mov64 r3, 152                                   r3 = 152 as i32 as i64 as u64
    call function_30349                     
    ldxdw r1, [r10-0xc18]                   
    ldxdw r1, [r1+0x38]                     
    ldxdw r2, [r10-0x148]                   
    jeq r2, r1, lbb_6059                            if r2 == r1 { pc += 9 }
lbb_6050:
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    jeq r1, 0, lbb_6074                             if r1 == (0 as i32 as i64 as u64) { pc += 22 }
lbb_6052:
    mov64 r1, 5                                     r1 = 5 as i32 as i64 as u64
    ldxdw r2, [r10-0xc00]                   
    stxw [r2+0x8], r1                       
    lddw r1, 0x8000000000000000                     r1 load str located at -9223372036854775808
    stxdw [r2+0x0], r1                      
    ja lbb_6081                                     if true { pc += 22 }
lbb_6059:
    ldxdw r1, [r10-0xc18]                   
    ldxdw r1, [r1+0x40]                     
    ldxdw r2, [r10-0x140]                   
    jne r2, r1, lbb_6050                            if r2 != r1 { pc += -13 }
    ldxdw r1, [r10-0xc18]                   
    ldxdw r1, [r1+0x48]                     
    ldxdw r2, [r10-0x138]                   
    jne r2, r1, lbb_6050                            if r2 != r1 { pc += -17 }
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    ldxdw r2, [r10-0xc18]                   
    ldxdw r2, [r2+0x50]                     
    ldxdw r3, [r10-0x130]                   
    jne r3, r2, lbb_6050                            if r3 != r2 { pc += -22 }
    jeq r1, 0, lbb_6074                             if r1 == (0 as i32 as i64 as u64) { pc += 1 }
    ja lbb_6052                                     if true { pc += -22 }
lbb_6074:
    ldxdw r1, [r10-0xc18]                   
    stxh [r1+0x464], r7                     
    stxh [r1+0x16], r9                      
    lddw r2, 0x800000000000001a                     r2 load str located at -9223372036854775782
    ldxdw r1, [r10-0xc00]                   
    stxdw [r1+0x0], r2                      
lbb_6081:
    ldxdw r1, [r6+0x10]                     
    add64 r1, -1                                    r1 += -1   ///  r1 = r1.wrapping_add(-1 as i32 as i64 as u64)
    stxdw [r6+0x10], r1                     
lbb_6084:
    ldxdw r2, [r10-0xc20]                   
    ldxdw r1, [r2+0x10]                     
    add64 r1, -1                                    r1 += -1   ///  r1 = r1.wrapping_add(-1 as i32 as i64 as u64)
    stxdw [r2+0x10], r1                     
lbb_6088:
    ldxdw r1, [r8+0x10]                     
    add64 r1, 1                                     r1 += 1   ///  r1 = r1.wrapping_add(1 as i32 as i64 as u64)
    stxdw [r8+0x10], r1                     
    ja lbb_3730                                     if true { pc += -2362 }
lbb_6092:
    mov64 r1, r10                                   r1 = r10
    add64 r1, -1480                                 r1 += -1480   ///  r1 = r1.wrapping_add(-1480 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -2776                                 r2 += -2776   ///  r2 = r2.wrapping_add(-2776 as i32 as i64 as u64)
    mov64 r3, 528                                   r3 = 528 as i32 as i64 as u64
    call function_30349                     
    stxdw [r10-0x5d0], r8                   
    stxdw [r10-0x5d8], r9                   
    ldxdw r1, [r7+0x10]                     
    add64 r1, -1                                    r1 += -1   ///  r1 = r1.wrapping_add(-1 as i32 as i64 as u64)
    stxdw [r7+0x10], r1                     
    lddw r1, 0xfc3e34becfcb63d7                     r1 load str located at -270720933461007401
    ldxdw r2, [r10-0x588]                   
    jeq r2, r1, lbb_6111                            if r2 == r1 { pc += 4 }
lbb_6107:
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    jeq r1, 0, lbb_6126                             if r1 == (0 as i32 as i64 as u64) { pc += 17 }
lbb_6109:
    mov64 r1, 28                                    r1 = 28 as i32 as i64 as u64
    ja lbb_2954                                     if true { pc += -3157 }
lbb_6111:
    lddw r1, 0xf495c87a5045cbbb                     r1 load str located at -822530929266930757
    ldxdw r2, [r10-0x580]                   
    jne r2, r1, lbb_6107                            if r2 != r1 { pc += -8 }
    lddw r1, 0xe7d24322df5eeb7c                     r1 load str located at -1742256288783471748
    ldxdw r2, [r10-0x578]                   
    jne r2, r1, lbb_6107                            if r2 != r1 { pc += -12 }
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    lddw r2, 0xcf66dbb77498e62b                     r2 load str located at -3501870079252306389
    ldxdw r3, [r10-0x570]                   
    jne r3, r2, lbb_6107                            if r3 != r2 { pc += -17 }
    jeq r1, 0, lbb_6126                             if r1 == (0 as i32 as i64 as u64) { pc += 1 }
    ja lbb_6109                                     if true { pc += -17 }
lbb_6126:
    ldxb r1, [r10-0x3c4]                    
    jeq r1, 0, lbb_6129                             if r1 == (0 as i32 as i64 as u64) { pc += 1 }
lbb_6128:
    ja lbb_5846                                     if true { pc += -283 }
lbb_6129:
    ldxdw r1, [r10-0xc08]                   
    ldxb r1, [r1+0x58]                      
    jeq r1, 0, lbb_6152                             if r1 == (0 as i32 as i64 as u64) { pc += 20 }
    ldxdw r1, [r6+0x0]                      
    ldxdw r2, [r1+0x0]                      
    ldxdw r3, [r10-0x588]                   
    jeq r2, r3, lbb_6154                            if r2 == r3 { pc += 18 }
lbb_6136:
    mov64 r2, 1                                     r2 = 1 as i32 as i64 as u64
    jeq r2, 0, lbb_6139                             if r2 == (0 as i32 as i64 as u64) { pc += 1 }
    ja lbb_4032                                     if true { pc += -2107 }
lbb_6139:
    ldxdw r1, [r10-0xc08]                   
    ldxb r1, [r1+0x89]                      
    jeq r1, 0, lbb_6143                             if r1 == (0 as i32 as i64 as u64) { pc += 1 }
    ja lbb_3759                                     if true { pc += -2384 }
lbb_6143:
    ldxdw r1, [r10-0xc08]                   
    ldxdw r9, [r1+0xf0]                     
    ldxdw r2, [r9+0x0]                      
    ldxdw r1, [r1+0x78]                     
    ldxdw r3, [r1+0x0]                      
    jeq r3, r2, lbb_6166                            if r3 == r2 { pc += 17 }
lbb_6149:
    mov64 r2, 1                                     r2 = 1 as i32 as i64 as u64
    jeq r2, 0, lbb_6178                             if r2 == (0 as i32 as i64 as u64) { pc += 27 }
lbb_6151:
    ja lbb_4598                                     if true { pc += -1554 }
lbb_6152:
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    ja lbb_2954                                     if true { pc += -3200 }
lbb_6154:
    ldxdw r2, [r1+0x8]                      
    ldxdw r3, [r10-0x580]                   
    jne r2, r3, lbb_6136                            if r2 != r3 { pc += -21 }
    ldxdw r2, [r1+0x10]                     
    ldxdw r3, [r10-0x578]                   
    jne r2, r3, lbb_6136                            if r2 != r3 { pc += -24 }
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
    ldxdw r1, [r1+0x18]                     
    ldxdw r3, [r10-0x570]                   
    jne r1, r3, lbb_6136                            if r1 != r3 { pc += -28 }
    jeq r2, 0, lbb_6139                             if r2 == (0 as i32 as i64 as u64) { pc += -26 }
    ja lbb_4032                                     if true { pc += -2134 }
lbb_6166:
    ldxdw r2, [r9+0x8]                      
    ldxdw r3, [r1+0x8]                      
    jne r3, r2, lbb_6149                            if r3 != r2 { pc += -20 }
    ldxdw r2, [r9+0x10]                     
    ldxdw r3, [r1+0x10]                     
    jne r3, r2, lbb_6149                            if r3 != r2 { pc += -23 }
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
    ldxdw r3, [r9+0x18]                     
    ldxdw r1, [r1+0x18]                     
    jne r1, r3, lbb_6149                            if r1 != r3 { pc += -27 }
    jeq r2, 0, lbb_6178                             if r2 == (0 as i32 as i64 as u64) { pc += 1 }
    ja lbb_6151                                     if true { pc += -27 }
lbb_6178:
    ldxdw r1, [r10-0xc08]                   
    ldxdw r7, [r1+0x70]                     
    ldxdw r1, [r7+0x10]                     
    lddw r2, 0x7fffffffffffffff                     r2 load str located at 9223372036854775807
    jgt r2, r1, lbb_6185                            if r2 > r1 { pc += 1 }
    ja lbb_6309                                     if true { pc += 124 }
lbb_6185:
    add64 r1, 1                                     r1 += 1   ///  r1 = r1.wrapping_add(1 as i32 as i64 as u64)
    stxdw [r7+0x10], r1                     
    ldxdw r3, [r7+0x20]                     
    ldxdw r2, [r7+0x18]                     
    mov64 r1, r10                                   r1 = r10
    add64 r1, -2792                                 r1 += -2792   ///  r1 = r1.wrapping_add(-2792 as i32 as i64 as u64)
    call function_146                       
    ldxw r1, [r10-0xae8]                    
    jeq r1, 2, lbb_6195                             if r1 == (2 as i32 as i64 as u64) { pc += 1 }
    ja lbb_6202                                     if true { pc += 7 }
lbb_6195:
    ldxdw r1, [r10-0xad0]                   
    stxdw [r10-0x144], r1                   
    ldxdw r2, [r10-0xad8]                   
    stxdw [r10-0x14c], r2                   
    ldxdw r3, [r10-0xae0]                   
    stxdw [r10-0x154], r3                   
    ja lbb_4200                                     if true { pc += -2002 }
lbb_6202:
    ldxb r8, [r10-0xab8]                    
    ldxdw r1, [r7+0x10]                     
    add64 r1, -1                                    r1 += -1   ///  r1 = r1.wrapping_add(-1 as i32 as i64 as u64)
    stxdw [r7+0x10], r1                     
    mov64 r1, r10                                   r1 = r10
    add64 r1, -2792                                 r1 += -2792   ///  r1 = r1.wrapping_add(-2792 as i32 as i64 as u64)
    ldxdw r2, [r10-0xc10]                   
    ldxdw r3, [r10-0xc18]                   
    ldxdw r4, [r10-0xc30]                   
    call function_9118                      
    ldxdw r1, [r10-0xae8]                   
    lddw r2, 0x800000000000001a                     r2 load str located at -9223372036854775782
    jeq r1, r2, lbb_6217                            if r1 == r2 { pc += 1 }
    ja lbb_6248                                     if true { pc += 31 }
lbb_6217:
    ldxdw r1, [r10-0xc08]                   
    ldxb r1, [r1+0xb9]                      
    jeq r1, 0, lbb_3759                             if r1 == (0 as i32 as i64 as u64) { pc += -2461 }
    ldxdw r1, [r10-0xc08]                   
    ldxdw r6, [r1+0xa0]                     
    ldxdw r1, [r6+0x10]                     
    lddw r2, 0x7fffffffffffffff                     r2 load str located at 9223372036854775807
    jgt r2, r1, lbb_6227                            if r2 > r1 { pc += 1 }
    ja lbb_6312                                     if true { pc += 85 }
lbb_6227:
    add64 r1, 1                                     r1 += 1   ///  r1 = r1.wrapping_add(1 as i32 as i64 as u64)
    stxdw [r6+0x10], r1                     
    ldxdw r3, [r6+0x20]                     
    ldxdw r2, [r6+0x18]                     
    mov64 r1, r10                                   r1 = r10
    add64 r1, -2792                                 r1 += -2792   ///  r1 = r1.wrapping_add(-2792 as i32 as i64 as u64)
    call function_0                         
    ldxw r1, [r10-0xa50]                    
    jeq r1, 2, lbb_6237                             if r1 == (2 as i32 as i64 as u64) { pc += 1 }
    ja lbb_6257                                     if true { pc += 20 }
lbb_6237:
    ldxdw r1, [r10-0xad8]                   
    stxdw [r10-0x148], r1                   
    ldxdw r2, [r10-0xae0]                   
    stxdw [r10-0x150], r2                   
    ldxdw r3, [r10-0xae8]                   
    stxdw [r10-0x158], r3                   
    ldxdw r4, [r10-0xc00]                   
    stxdw [r4+0x10], r1                     
    stxdw [r4+0x8], r2                      
    stxdw [r4+0x0], r3                      
    ja lbb_6376                                     if true { pc += 128 }
lbb_6248:
    ldxb r2, [r10-0xae0]                    
    ldxdw r3, [r10-0xad8]                   
    ldxdw r4, [r10-0xc00]                   
    stxdw [r4+0x10], r3                     
    ldxdw r3, [r10-0xadf]                   
    stxdw [r4+0x9], r3                      
    stxb [r4+0x8], r2                       
    stxdw [r4+0x0], r1                      
    ja lbb_3730                                     if true { pc += -2527 }
lbb_6257:
    mov64 r7, r10                                   r7 = r10
    add64 r7, -344                                  r7 += -344   ///  r7 = r7.wrapping_add(-344 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -2792                                 r2 += -2792   ///  r2 = r2.wrapping_add(-2792 as i32 as i64 as u64)
    mov64 r1, r7                                    r1 = r7
    mov64 r3, 152                                   r3 = 152 as i32 as i64 as u64
    call function_30349                     
    mov64 r1, r10                                   r1 = r10
    add64 r1, -536                                  r1 += -536   ///  r1 = r1.wrapping_add(-536 as i32 as i64 as u64)
    mov64 r2, r7                                    r2 = r7
    mov64 r3, 152                                   r3 = 152 as i32 as i64 as u64
    call function_30349                     
    ldxdw r1, [r10-0xc08]                   
    ldxb r1, [r1+0xe9]                      
    jeq r1, 0, lbb_6302                             if r1 == (0 as i32 as i64 as u64) { pc += 30 }
    ldxdw r1, [r10-0xc08]                   
    ldxdw r1, [r1+0xd0]                     
    stxdw [r10-0xc30], r1                   
    ldxdw r1, [r1+0x10]                     
    lddw r2, 0x7fffffffffffffff                     r2 load str located at 9223372036854775807
    jgt r2, r1, lbb_6280                            if r2 > r1 { pc += 1 }
    ja lbb_6315                                     if true { pc += 35 }
lbb_6280:
    add64 r1, 1                                     r1 += 1   ///  r1 = r1.wrapping_add(1 as i32 as i64 as u64)
    ldxdw r2, [r10-0xc30]                   
    stxdw [r2+0x10], r1                     
    ldxdw r3, [r2+0x20]                     
    ldxdw r2, [r2+0x18]                     
    mov64 r1, r10                                   r1 = r10
    add64 r1, -2792                                 r1 += -2792   ///  r1 = r1.wrapping_add(-2792 as i32 as i64 as u64)
    call function_0                         
    ldxw r1, [r10-0xa50]                    
    jeq r1, 2, lbb_6291                             if r1 == (2 as i32 as i64 as u64) { pc += 1 }
    ja lbb_6318                                     if true { pc += 27 }
lbb_6291:
    ldxdw r1, [r10-0xad8]                   
    stxdw [r10-0x2c8], r1                   
    ldxdw r2, [r10-0xae0]                   
    stxdw [r10-0x2d0], r2                   
    ldxdw r3, [r10-0xae8]                   
    stxdw [r10-0x2d8], r3                   
    ldxdw r4, [r10-0xc00]                   
    stxdw [r4+0x10], r1                     
    stxdw [r4+0x8], r2                      
    stxdw [r4+0x0], r3                      
    ja lbb_6372                                     if true { pc += 70 }
lbb_6302:
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    ldxdw r2, [r10-0xc00]                   
    stxw [r2+0x8], r1                       
    lddw r1, 0x8000000000000000                     r1 load str located at -9223372036854775808
    stxdw [r2+0x0], r1                      
    ja lbb_6376                                     if true { pc += 67 }
lbb_6309:
    lddw r1, 0x100041070 --> b"\x00\x00\x00\x000\xe7\x03\x00\x10\x00\x00\x00\x00\x00\x00\x00\x1f\x02\x00…        r1 load str located at 4295233648
    call function_25345                     
lbb_6312:
    lddw r1, 0x100041058 --> b"\x00\x00\x00\x000\xe7\x03\x00\x10\x00\x00\x00\x00\x00\x00\x00-\x02\x00\x0…        r1 load str located at 4295233624
    call function_25345                     
lbb_6315:
    lddw r1, 0x100041040 --> b"\x00\x00\x00\x000\xe7\x03\x00\x10\x00\x00\x00\x00\x00\x00\x002\x02\x00\x0…        r1 load str located at 4295233600
    call function_25345                     
lbb_6318:
    mov64 r7, r10                                   r7 = r10
    add64 r7, -728                                  r7 += -728   ///  r7 = r7.wrapping_add(-728 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -2792                                 r2 += -2792   ///  r2 = r2.wrapping_add(-2792 as i32 as i64 as u64)
    mov64 r1, r7                                    r1 = r7
    mov64 r3, 152                                   r3 = 152 as i32 as i64 as u64
    call function_30349                     
    mov64 r1, r10                                   r1 = r10
    add64 r1, -344                                  r1 += -344   ///  r1 = r1.wrapping_add(-344 as i32 as i64 as u64)
    mov64 r2, r7                                    r2 = r7
    mov64 r3, 152                                   r3 = 152 as i32 as i64 as u64
    call function_30349                     
    ldxdw r1, [r10-0x208]                   
    ldxdw r2, [r10-0x148]                   
    jeq r2, r1, lbb_6343                            if r2 == r1 { pc += 10 }
lbb_6333:
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    jeq r1, 0, lbb_6336                             if r1 == (0 as i32 as i64 as u64) { pc += 1 }
    ja lbb_6366                                     if true { pc += 30 }
lbb_6336:
    ldxdw r1, [r10-0xc38]                   
    ldxdw r1, [r1+0x0]                      
    ldxdw r2, [r1+0x0]                      
    ldxdw r3, [r10-0x148]                   
    jeq r3, r2, lbb_6355                            if r3 == r2 { pc += 14 }
lbb_6341:
    mov64 r2, 1                                     r2 = 1 as i32 as i64 as u64
    ja lbb_6365                                     if true { pc += 22 }
lbb_6343:
    ldxdw r1, [r10-0x200]                   
    ldxdw r2, [r10-0x140]                   
    jne r2, r1, lbb_6333                            if r2 != r1 { pc += -13 }
    ldxdw r1, [r10-0x1f8]                   
    ldxdw r2, [r10-0x138]                   
    jne r2, r1, lbb_6333                            if r2 != r1 { pc += -16 }
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    ldxdw r2, [r10-0x1f0]                   
    ldxdw r3, [r10-0x130]                   
    jne r3, r2, lbb_6333                            if r3 != r2 { pc += -20 }
    jeq r1, 0, lbb_6336                             if r1 == (0 as i32 as i64 as u64) { pc += -18 }
    ja lbb_6366                                     if true { pc += 11 }
lbb_6355:
    ldxdw r2, [r1+0x8]                      
    ldxdw r3, [r10-0x140]                   
    jne r3, r2, lbb_6341                            if r3 != r2 { pc += -17 }
    ldxdw r2, [r1+0x10]                     
    ldxdw r3, [r10-0x138]                   
    jne r3, r2, lbb_6341                            if r3 != r2 { pc += -20 }
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
    ldxdw r1, [r1+0x18]                     
    ldxdw r3, [r10-0x130]                   
    jne r3, r1, lbb_6341                            if r3 != r1 { pc += -24 }
lbb_6365:
    jeq r2, 0, lbb_6380                             if r2 == (0 as i32 as i64 as u64) { pc += 14 }
lbb_6366:
    mov64 r1, 5                                     r1 = 5 as i32 as i64 as u64
lbb_6367:
    ldxdw r2, [r10-0xc00]                   
    stxw [r2+0x8], r1                       
    lddw r1, 0x8000000000000000                     r1 load str located at -9223372036854775808
    stxdw [r2+0x0], r1                      
lbb_6372:
    ldxdw r2, [r10-0xc30]                   
    ldxdw r1, [r2+0x10]                     
    add64 r1, -1                                    r1 += -1   ///  r1 = r1.wrapping_add(-1 as i32 as i64 as u64)
    stxdw [r2+0x10], r1                     
lbb_6376:
    ldxdw r1, [r6+0x10]                     
    add64 r1, -1                                    r1 += -1   ///  r1 = r1.wrapping_add(-1 as i32 as i64 as u64)
    stxdw [r6+0x10], r1                     
    ja lbb_3730                                     if true { pc += -2650 }
lbb_6380:
    ldxdw r1, [r10-0xc40]                   
    jeq r1, 0, lbb_6401                             if r1 == (0 as i32 as i64 as u64) { pc += 19 }
    mov64 r1, r10                                   r1 = r10
    add64 r1, -2792                                 r1 += -2792   ///  r1 = r1.wrapping_add(-2792 as i32 as i64 as u64)
    ldxdw r2, [r10-0xc10]                   
    ldxdw r3, [r10-0xc20]                   
    ldxdw r4, [r10-0xc48]                   
    call function_9118                      
    ldxdw r1, [r10-0xae8]                   
    lddw r2, 0x800000000000001a                     r2 load str located at -9223372036854775782
    jeq r1, r2, lbb_6420                            if r1 == r2 { pc += 28 }
    ldxb r2, [r10-0xae0]                    
    ldxdw r3, [r10-0xad8]                   
    ldxdw r4, [r10-0xc00]                   
    stxdw [r4+0x10], r3                     
    ldxdw r3, [r10-0xadf]                   
    stxdw [r4+0x9], r3                      
    stxb [r4+0x8], r2                       
    stxdw [r4+0x0], r1                      
    ja lbb_6372                                     if true { pc += -29 }
lbb_6401:
    ldxdw r1, [r10-0x568]                   
    ldxdw r2, [r10-0x128]                   
    jeq r2, r1, lbb_6408                            if r2 == r1 { pc += 4 }
lbb_6404:
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    jeq r1, 0, lbb_6420                             if r1 == (0 as i32 as i64 as u64) { pc += 14 }
lbb_6406:
    mov64 r1, 4                                     r1 = 4 as i32 as i64 as u64
    ja lbb_6367                                     if true { pc += -41 }
lbb_6408:
    ldxdw r1, [r10-0x560]                   
    ldxdw r2, [r10-0x120]                   
    jne r2, r1, lbb_6404                            if r2 != r1 { pc += -7 }
    ldxdw r1, [r10-0x558]                   
    ldxdw r2, [r10-0x118]                   
    jne r2, r1, lbb_6404                            if r2 != r1 { pc += -10 }
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    ldxdw r2, [r10-0x550]                   
    ldxdw r3, [r10-0x110]                   
    jne r3, r2, lbb_6404                            if r3 != r2 { pc += -14 }
    jeq r1, 0, lbb_6420                             if r1 == (0 as i32 as i64 as u64) { pc += 1 }
    ja lbb_6406                                     if true { pc += -14 }
lbb_6420:
    ldxdw r1, [r6+0x10]                     
    add64 r1, -1                                    r1 += -1   ///  r1 = r1.wrapping_add(-1 as i32 as i64 as u64)
    stxdw [r6+0x10], r1                     
    ldxdw r2, [r10-0xc30]                   
    ldxdw r1, [r2+0x10]                     
    add64 r1, -1                                    r1 += -1   ///  r1 = r1.wrapping_add(-1 as i32 as i64 as u64)
    stxdw [r2+0x10], r1                     
    ldxdw r1, [r10-0xc28]                   
    ldxdw r1, [r1+0x0]                      
    ldxdw r2, [r1+0x0]                      
    jeq r2, 0, lbb_6464                             if r2 == (0 as i32 as i64 as u64) { pc += 33 }
lbb_6431:
    mov64 r2, 1                                     r2 = 1 as i32 as i64 as u64
    jeq r2, 0, lbb_6434                             if r2 == (0 as i32 as i64 as u64) { pc += 1 }
    ja lbb_4032                                     if true { pc += -2402 }
lbb_6434:
    ldxdw r1, [r10-0xc50]                   
    stxdw [r10-0xfe0], r1                   
    stxdw [r10-0xfd8], r8                   
    stxdw [r10-0xfe8], r9                   
    ldxdw r1, [r10-0xc20]                   
    stxdw [r10-0xff0], r1                   
    ldxdw r1, [r10-0xc18]                   
    stxdw [r10-0xff8], r1                   
    mov64 r1, 2                                     r1 = 2 as i32 as i64 as u64
    stxdw [r10-0x1000], r1                  
    mov64 r1, r10                                   r1 = r10
    add64 r1, -2792                                 r1 += -2792   ///  r1 = r1.wrapping_add(-2792 as i32 as i64 as u64)
    mov64 r4, r10                                   r4 = r10
    add64 r4, -920                                  r4 += -920   ///  r4 = r4.wrapping_add(-920 as i32 as i64 as u64)
    mov64 r5, r10                                   r5 = r10
    ldxdw r2, [r10-0xc38]                   
    ldxdw r3, [r10-0xc08]                   
    call function_10085                     
    lddw r1, 0x800000000000001a                     r1 load str located at -9223372036854775782
    ldxdw r2, [r10-0xae8]                   
    jeq r2, r1, lbb_5003                            if r2 == r1 { pc += -1453 }
lbb_6456:
    ldxdw r1, [r10-0xad8]                   
    ldxdw r2, [r10-0xc00]                   
    stxdw [r2+0x10], r1                     
    ldxdw r1, [r10-0xae0]                   
    stxdw [r2+0x8], r1                      
    ldxdw r1, [r10-0xae8]                   
    stxdw [r2+0x0], r1                      
    ja lbb_3730                                     if true { pc += -2734 }
lbb_6464:
    ldxdw r2, [r1+0x8]                      
    jne r2, 0, lbb_6431                             if r2 != (0 as i32 as i64 as u64) { pc += -35 }
    ldxdw r2, [r1+0x10]                     
    jne r2, 0, lbb_6431                             if r2 != (0 as i32 as i64 as u64) { pc += -37 }
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
    ldxdw r1, [r1+0x18]                     
    jne r1, 0, lbb_6431                             if r1 != (0 as i32 as i64 as u64) { pc += -40 }
    jeq r2, 0, lbb_6434                             if r2 == (0 as i32 as i64 as u64) { pc += -38 }
    ja lbb_4032                                     if true { pc += -2441 }
lbb_6473:
    mov64 r1, r10                                   r1 = r10
    add64 r1, -1480                                 r1 += -1480   ///  r1 = r1.wrapping_add(-1480 as i32 as i64 as u64)
    stxdw [r10-0xc08], r2                   
    mov64 r2, r10                                   r2 = r10
    add64 r2, -2776                                 r2 += -2776   ///  r2 = r2.wrapping_add(-2776 as i32 as i64 as u64)
    mov64 r3, 528                                   r3 = 528 as i32 as i64 as u64
    call function_30349                     
    ldxdw r1, [r10-0xc08]                   
    stxdw [r10-0x5d0], r1                   
    stxdw [r10-0x5d8], r7                   
    ldxdw r1, [r8+0x10]                     
    add64 r1, -1                                    r1 += -1   ///  r1 = r1.wrapping_add(-1 as i32 as i64 as u64)
    stxdw [r8+0x10], r1                     
    ldxdw r2, [r6+0x0]                      
    ldxdw r3, [r2+0x0]                      
    ldxdw r4, [r10-0x5a8]                   
    jeq r3, r4, lbb_6492                            if r3 == r4 { pc += 2 }
lbb_6490:
    mov64 r3, 1                                     r3 = 1 as i32 as i64 as u64
    ja lbb_6502                                     if true { pc += 10 }
lbb_6492:
    ldxdw r3, [r2+0x8]                      
    ldxdw r4, [r10-0x5a0]                   
    jne r3, r4, lbb_6490                            if r3 != r4 { pc += -5 }
    ldxdw r3, [r2+0x10]                     
    ldxdw r4, [r10-0x598]                   
    jne r3, r4, lbb_6490                            if r3 != r4 { pc += -8 }
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
    ldxdw r2, [r2+0x18]                     
    ldxdw r4, [r10-0x590]                   
    jne r2, r4, lbb_6490                            if r2 != r4 { pc += -12 }
lbb_6502:
    ldxdw r2, [r10-0xc00]                   
    jeq r3, 0, lbb_6505                             if r3 == (0 as i32 as i64 as u64) { pc += 1 }
    ja lbb_6621                                     if true { pc += 116 }
lbb_6505:
    ldxb r3, [r10-0x3c4]                    
    jeq r3, 0, lbb_6508                             if r3 == (0 as i32 as i64 as u64) { pc += 1 }
    ja lbb_7126                                     if true { pc += 618 }
lbb_6508:
    add64 r9, 1                                     r9 += 1   ///  r9 = r9.wrapping_add(1 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -1448                                 r2 += -1448   ///  r2 = r2.wrapping_add(-1448 as i32 as i64 as u64)
    ldxdw r3, [r9+0x18]                     
    stxdw [r2+0x18], r3                     
    ldxdw r3, [r9+0x10]                     
    stxdw [r2+0x10], r3                     
    ldxdw r3, [r9+0x8]                      
    stxdw [r2+0x8], r3                      
    ldxdw r3, [r9+0x0]                      
    stxdw [r2+0x0], r3                      
    jeq r1, 0, lbb_6521                             if r1 == (0 as i32 as i64 as u64) { pc += 1 }
    ja lbb_6534                                     if true { pc += 13 }
lbb_6521:
    mov64 r1, -1                                    r1 = -1 as i32 as i64 as u64
    stxdw [r8+0x10], r1                     
    ldxdw r1, [r8+0x18]                     
    ldxdw r2, [r8+0x20]                     
    stxdw [r10-0xae0], r2                   
    stxdw [r10-0xae8], r1                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -1496                                 r1 += -1496   ///  r1 = r1.wrapping_add(-1496 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -2792                                 r2 += -2792   ///  r2 = r2.wrapping_add(-2792 as i32 as i64 as u64)
    call function_13019                     
    jeq r0, 0, lbb_6800                             if r0 == (0 as i32 as i64 as u64) { pc += 267 }
    ja lbb_3129                                     if true { pc += -3405 }
lbb_6534:
    lddw r1, 0x1000410a0 --> b"\x00\x00\x00\x000\xe7\x03\x00\x10\x00\x00\x00\x00\x00\x00\x00i\x02\x00\x0…        r1 load str located at 4295233696
    call function_25324                     
lbb_6537:
    jeq r7, 0, lbb_2935                             if r7 == (0 as i32 as i64 as u64) { pc += -3603 }
    mov64 r9, r8                                    r9 = r8
    add64 r9, 48                                    r9 += 48   ///  r9 = r9.wrapping_add(48 as i32 as i64 as u64)
    jeq r7, 1, lbb_2915                             if r7 == (1 as i32 as i64 as u64) { pc += -3626 }
    ldxb r2, [r8+0x58]                      
    jeq r2, 0, lbb_3781                             if r2 == (0 as i32 as i64 as u64) { pc += -2762 }
    ldxdw r2, [r8+0x0]                      
    ldxdw r4, [r2+0x0]                      
    lddw r5, 0x9e9974ee626ad71                      r5 load str located at 714268381039471985
    jeq r4, r5, lbb_6550                            if r4 == r5 { pc += 2 }
lbb_6548:
    mov64 r4, 1                                     r4 = 1 as i32 as i64 as u64
    ja lbb_6563                                     if true { pc += 13 }
lbb_6550:
    ldxdw r4, [r2+0x8]                      
    lddw r5, 0xa5b18bf6febdfb8d                     r5 load str located at -6507266093621576819
    jne r4, r5, lbb_6548                            if r4 != r5 { pc += -6 }
    ldxdw r4, [r2+0x10]                     
    lddw r5, 0x3f762b2616a7d0c7                     r5 load str located at 4572889914230165703
    jne r4, r5, lbb_6548                            if r4 != r5 { pc += -10 }
    mov64 r4, 0                                     r4 = 0 as i32 as i64 as u64
    ldxdw r2, [r2+0x18]                     
    lddw r5, 0xe00b8186ff88305d                     r5 load str located at -2302604367657160611
    jne r2, r5, lbb_6548                            if r2 != r5 { pc += -15 }
lbb_6563:
    jne r4, 0, lbb_5436                             if r4 != (0 as i32 as i64 as u64) { pc += -1128 }
    ldxb r2, [r8+0x29]                      
    jeq r2, 0, lbb_3426                             if r2 == (0 as i32 as i64 as u64) { pc += -3140 }
    stxdw [r10-0xc00], r1                   
    ldxdw r8, [r8+0x10]                     
    ldxdw r1, [r8+0x10]                     
    lddw r2, 0x7fffffffffffffff                     r2 load str located at 9223372036854775807
    jgt r2, r1, lbb_6573                            if r2 > r1 { pc += 1 }
    ja lbb_6606                                     if true { pc += 33 }
lbb_6573:
    add64 r1, 1                                     r1 += 1   ///  r1 = r1.wrapping_add(1 as i32 as i64 as u64)
    stxdw [r8+0x10], r1                     
    ldxdw r1, [r8+0x18]                     
    ldxdw r2, [r8+0x20]                     
    stxdw [r10-0x150], r2                   
    stxdw [r10-0x158], r1                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -2792                                 r1 += -2792   ///  r1 = r1.wrapping_add(-2792 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -344                                  r2 += -344   ///  r2 = r2.wrapping_add(-344 as i32 as i64 as u64)
    call function_12619                     
    ldxdw r7, [r10-0xae0]                   
    ldxdw r6, [r10-0xae8]                   
    lddw r1, 0x8000000000000000                     r1 load str located at -9223372036854775808
    jeq r6, r1, lbb_7079                            if r6 == r1 { pc += 490 }
    mov64 r1, r10                                   r1 = r10
    add64 r1, -1480                                 r1 += -1480   ///  r1 = r1.wrapping_add(-1480 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -2776                                 r2 += -2776   ///  r2 = r2.wrapping_add(-2776 as i32 as i64 as u64)
    mov64 r3, 528                                   r3 = 528 as i32 as i64 as u64
    call function_30349                     
    stxdw [r10-0x5d0], r7                   
    stxdw [r10-0x5d8], r6                   
    ldxdw r1, [r8+0x10]                     
    add64 r1, -1                                    r1 += -1   ///  r1 = r1.wrapping_add(-1 as i32 as i64 as u64)
    stxdw [r8+0x10], r1                     
    ldxdw r2, [r9+0x0]                      
    ldxdw r3, [r2+0x0]                      
    ldxdw r4, [r10-0x5a8]                   
    jeq r3, r4, lbb_6609                            if r3 == r4 { pc += 5 }
lbb_6604:
    mov64 r3, 1                                     r3 = 1 as i32 as i64 as u64
    ja lbb_6619                                     if true { pc += 13 }
lbb_6606:
    lddw r1, 0x1000410e8 --> b"\x00\x00\x00\x000\xe7\x03\x00\x10\x00\x00\x00\x00\x00\x00\x00y\x02\x00\x0…        r1 load str located at 4295233768
    call function_25345                     
lbb_6609:
    ldxdw r3, [r2+0x8]                      
    ldxdw r4, [r10-0x5a0]                   
    jne r3, r4, lbb_6604                            if r3 != r4 { pc += -8 }
    ldxdw r3, [r2+0x10]                     
    ldxdw r4, [r10-0x598]                   
    jne r3, r4, lbb_6604                            if r3 != r4 { pc += -11 }
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
    ldxdw r2, [r2+0x18]                     
    ldxdw r4, [r10-0x590]                   
    jne r2, r4, lbb_6604                            if r2 != r4 { pc += -15 }
lbb_6619:
    ldxdw r2, [r10-0xc00]                   
    jeq r3, 0, lbb_6622                             if r3 == (0 as i32 as i64 as u64) { pc += 1 }
lbb_6621:
    ja lbb_5536                                     if true { pc += -1086 }
lbb_6622:
    ldxb r3, [r10-0x3c4]                    
    jeq r3, 0, lbb_6625                             if r3 == (0 as i32 as i64 as u64) { pc += 1 }
    ja lbb_7126                                     if true { pc += 501 }
lbb_6625:
    lddw r2, 0xcf66dbb77498e62b                     r2 load str located at -3501870079252306389
    stxdw [r10-0x570], r2                   
    lddw r2, 0xe7d24322df5eeb7c                     r2 load str located at -1742256288783471748
    stxdw [r10-0x578], r2                   
    lddw r2, 0xf495c87a5045cbbb                     r2 load str located at -822530929266930757
    stxdw [r10-0x580], r2                   
    lddw r2, 0xfc3e34becfcb63d7                     r2 load str located at -270720933461007401
    stxdw [r10-0x588], r2                   
    jeq r1, 0, lbb_6639                             if r1 == (0 as i32 as i64 as u64) { pc += 1 }
    ja lbb_6652                                     if true { pc += 13 }
lbb_6639:
    mov64 r1, -1                                    r1 = -1 as i32 as i64 as u64
    stxdw [r8+0x10], r1                     
    ldxdw r1, [r8+0x18]                     
    ldxdw r2, [r8+0x20]                     
    stxdw [r10-0xae0], r2                   
    stxdw [r10-0xae8], r1                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -1496                                 r1 += -1496   ///  r1 = r1.wrapping_add(-1496 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -2792                                 r2 += -2792   ///  r2 = r2.wrapping_add(-2792 as i32 as i64 as u64)
    call function_13019                     
    jeq r0, 0, lbb_6800                             if r0 == (0 as i32 as i64 as u64) { pc += 149 }
    ja lbb_3129                                     if true { pc += -3523 }
lbb_6652:
    lddw r1, 0x1000410d0 --> b"\x00\x00\x00\x000\xe7\x03\x00\x10\x00\x00\x00\x00\x00\x00\x00\x81\x02\x00…        r1 load str located at 4295233744
    call function_25324                     
lbb_6655:
    jeq r7, 0, lbb_2935                             if r7 == (0 as i32 as i64 as u64) { pc += -3721 }
    mov64 r6, r8                                    r6 = r8
    add64 r6, 48                                    r6 += 48   ///  r6 = r6.wrapping_add(48 as i32 as i64 as u64)
    jeq r7, 1, lbb_3773                             if r7 == (1 as i32 as i64 as u64) { pc += -2886 }
    ldxb r2, [r8+0x58]                      
    jeq r2, 0, lbb_3781                             if r2 == (0 as i32 as i64 as u64) { pc += -2880 }
    ldxdw r2, [r8+0x0]                      
    ldxdw r4, [r2+0x0]                      
    lddw r5, 0x9e9974ee626ad71                      r5 load str located at 714268381039471985
    jeq r4, r5, lbb_6668                            if r4 == r5 { pc += 2 }
lbb_6666:
    mov64 r4, 1                                     r4 = 1 as i32 as i64 as u64
    ja lbb_6681                                     if true { pc += 13 }
lbb_6668:
    ldxdw r4, [r2+0x8]                      
    lddw r5, 0xa5b18bf6febdfb8d                     r5 load str located at -6507266093621576819
    jne r4, r5, lbb_6666                            if r4 != r5 { pc += -6 }
    ldxdw r4, [r2+0x10]                     
    lddw r5, 0x3f762b2616a7d0c7                     r5 load str located at 4572889914230165703
    jne r4, r5, lbb_6666                            if r4 != r5 { pc += -10 }
    mov64 r4, 0                                     r4 = 0 as i32 as i64 as u64
    ldxdw r2, [r2+0x18]                     
    lddw r5, 0xe00b8186ff88305d                     r5 load str located at -2302604367657160611
    jne r2, r5, lbb_6666                            if r2 != r5 { pc += -15 }
lbb_6681:
    jne r4, 0, lbb_5436                             if r4 != (0 as i32 as i64 as u64) { pc += -1246 }
    stxdw [r10-0xc00], r1                   
    stxdw [r10-0xc08], r8                   
    ldxdw r8, [r8+0x10]                     
    ldxdw r1, [r8+0x10]                     
    lddw r2, 0x7fffffffffffffff                     r2 load str located at 9223372036854775807
    jgt r2, r1, lbb_6690                            if r2 > r1 { pc += 1 }
    ja lbb_6804                                     if true { pc += 114 }
lbb_6690:
    ldxb r2, [r9+0x1]                       
    stxdw [r10-0xc10], r2                   
    add64 r1, 1                                     r1 += 1   ///  r1 = r1.wrapping_add(1 as i32 as i64 as u64)
    stxdw [r8+0x10], r1                     
    ldxdw r1, [r8+0x18]                     
    ldxdw r2, [r8+0x20]                     
    stxdw [r10-0x150], r2                   
    stxdw [r10-0x158], r1                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -2792                                 r1 += -2792   ///  r1 = r1.wrapping_add(-2792 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -344                                  r2 += -344   ///  r2 = r2.wrapping_add(-344 as i32 as i64 as u64)
    call function_12619                     
    ldxdw r7, [r10-0xae0]                   
    ldxdw r9, [r10-0xae8]                   
    lddw r1, 0x8000000000000000                     r1 load str located at -9223372036854775808
    jeq r9, r1, lbb_7079                            if r9 == r1 { pc += 371 }
    mov64 r1, r10                                   r1 = r10
    add64 r1, -1480                                 r1 += -1480   ///  r1 = r1.wrapping_add(-1480 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -2776                                 r2 += -2776   ///  r2 = r2.wrapping_add(-2776 as i32 as i64 as u64)
    mov64 r3, 528                                   r3 = 528 as i32 as i64 as u64
    call function_30349                     
    stxdw [r10-0x5d0], r7                   
    stxdw [r10-0x5d8], r9                   
    ldxdw r7, [r8+0x10]                     
    add64 r7, -1                                    r7 += -1   ///  r7 = r7.wrapping_add(-1 as i32 as i64 as u64)
    stxdw [r8+0x10], r7                     
    ldxdw r2, [r6+0x0]                      
    ldxdw r1, [r2+0x0]                      
    ldxdw r3, [r10-0x5a8]                   
    jeq r1, r3, lbb_6725                            if r1 == r3 { pc += 2 }
lbb_6723:
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    ja lbb_6735                                     if true { pc += 10 }
lbb_6725:
    ldxdw r1, [r2+0x8]                      
    ldxdw r3, [r10-0x5a0]                   
    jne r1, r3, lbb_6723                            if r1 != r3 { pc += -5 }
    ldxdw r1, [r2+0x10]                     
    ldxdw r3, [r10-0x598]                   
    jne r1, r3, lbb_6723                            if r1 != r3 { pc += -8 }
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    ldxdw r3, [r2+0x18]                     
    ldxdw r4, [r10-0x590]                   
    jne r3, r4, lbb_6723                            if r3 != r4 { pc += -12 }
lbb_6735:
    lddw r4, 0x800000000000001a                     r4 load str located at -9223372036854775782
    jeq r1, 0, lbb_6740                             if r1 == (0 as i32 as i64 as u64) { pc += 2 }
    lddw r4, 0x8000000000000000                     r4 load str located at -9223372036854775808
lbb_6740:
    ldxdw r5, [r2+0x0]                      
    ldxdw r0, [r10-0x588]                   
    ldxdw r3, [r10-0xc00]                   
    jeq r5, r0, lbb_6746                            if r5 == r0 { pc += 2 }
lbb_6744:
    mov64 r5, 1                                     r5 = 1 as i32 as i64 as u64
    ja lbb_6756                                     if true { pc += 10 }
lbb_6746:
    ldxdw r5, [r2+0x8]                      
    ldxdw r0, [r10-0x580]                   
    jne r5, r0, lbb_6744                            if r5 != r0 { pc += -5 }
    ldxdw r5, [r2+0x10]                     
    ldxdw r0, [r10-0x578]                   
    jne r5, r0, lbb_6744                            if r5 != r0 { pc += -8 }
    mov64 r5, 0                                     r5 = 0 as i32 as i64 as u64
    ldxdw r2, [r2+0x18]                     
    ldxdw r0, [r10-0x570]                   
    jne r2, r0, lbb_6744                            if r2 != r0 { pc += -12 }
lbb_6756:
    lddw r2, 0x800000000000001a                     r2 load str located at -9223372036854775782
    jeq r5, 0, lbb_6761                             if r5 == (0 as i32 as i64 as u64) { pc += 2 }
    lddw r2, 0x8000000000000000                     r2 load str located at -9223372036854775808
lbb_6761:
    mov64 r0, 3                                     r0 = 3 as i32 as i64 as u64
    stxw [r10-0xac8], r0                    
    stxw [r10-0xae0], r0                    
    stxdw [r10-0xae8], r4                   
    stxdw [r10-0xad0], r2                   
    jeq r1, 0, lbb_6777                             if r1 == (0 as i32 as i64 as u64) { pc += 10 }
    jeq r5, 0, lbb_6777                             if r5 == (0 as i32 as i64 as u64) { pc += 9 }
lbb_6768:
    mov64 r1, 19                                    r1 = 19 as i32 as i64 as u64
    stxw [r3+0x8], r1                       
    lddw r1, 0x8000000000000000                     r1 load str located at -9223372036854775808
    stxdw [r3+0x0], r1                      
    mov64 r1, r10                                   r1 = r10
    add64 r1, -2792                                 r1 += -2792   ///  r1 = r1.wrapping_add(-2792 as i32 as i64 as u64)
    call function_461                       
    ja lbb_3730                                     if true { pc += -3047 }
lbb_6777:
    mov64 r1, r10                                   r1 = r10
    add64 r1, -2792                                 r1 += -2792   ///  r1 = r1.wrapping_add(-2792 as i32 as i64 as u64)
    call function_461                       
    ldxdw r1, [r10-0xc08]                   
    ldxb r1, [r1+0x29]                      
    jeq r1, 0, lbb_3759                             if r1 == (0 as i32 as i64 as u64) { pc += -3024 }
    ldxdw r1, [r10-0xc10]                   
    stxb [r10-0x3c3], r1                    
    jeq r7, 0, lbb_6787                             if r7 == (0 as i32 as i64 as u64) { pc += 1 }
    ja lbb_6807                                     if true { pc += 20 }
lbb_6787:
    mov64 r1, -1                                    r1 = -1 as i32 as i64 as u64
    stxdw [r8+0x10], r1                     
    ldxdw r1, [r8+0x18]                     
    ldxdw r2, [r8+0x20]                     
    stxdw [r10-0xae0], r2                   
    stxdw [r10-0xae8], r1                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -1496                                 r1 += -1496   ///  r1 = r1.wrapping_add(-1496 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -2792                                 r2 += -2792   ///  r2 = r2.wrapping_add(-2792 as i32 as i64 as u64)
    call function_13019                     
    jeq r0, 0, lbb_6800                             if r0 == (0 as i32 as i64 as u64) { pc += 1 }
    ja lbb_3129                                     if true { pc += -3671 }
lbb_6800:
    ldxdw r1, [r8+0x10]                     
    add64 r1, 1                                     r1 += 1   ///  r1 = r1.wrapping_add(1 as i32 as i64 as u64)
    stxdw [r8+0x10], r1                     
    ja lbb_3981                                     if true { pc += -2823 }
lbb_6804:
    lddw r1, 0x1000411a8 --> b"\x00\x00\x00\x000\xe7\x03\x00\x10\x00\x00\x00\x00\x00\x00\x00\xda\x02\x00…        r1 load str located at 4295233960
    call function_25345                     
lbb_6807:
    lddw r1, 0x100041190 --> b"\x00\x00\x00\x000\xe7\x03\x00\x10\x00\x00\x00\x00\x00\x00\x00\xe6\x02\x00…        r1 load str located at 4295233936
    call function_25324                     
lbb_6810:
    ldxdw r2, [r10-0xc08]                   
    ldxdw r3, [r2+0x0]                      
    ldxdw r4, [r3+0x0]                      
    lddw r5, 0x9e9974ee626ad71                      r5 load str located at 714268381039471985
    mov64 r1, r7                                    r1 = r7
    jeq r4, r5, lbb_6850                            if r4 == r5 { pc += 33 }
lbb_6817:
    mov64 r4, 1                                     r4 = 1 as i32 as i64 as u64
    jeq r4, 0, lbb_6820                             if r4 == (0 as i32 as i64 as u64) { pc += 1 }
    ja lbb_5436                                     if true { pc += -1384 }
lbb_6820:
    mov64 r8, r9                                    r8 = r9
    ldxdw r9, [r2+0x10]                     
    ldxdw r1, [r9+0x10]                     
    lddw r2, 0x7fffffffffffffff                     r2 load str located at 9223372036854775807
    jgt r2, r1, lbb_6827                            if r2 > r1 { pc += 1 }
    ja lbb_6865                                     if true { pc += 38 }
lbb_6827:
    add64 r1, 1                                     r1 += 1   ///  r1 = r1.wrapping_add(1 as i32 as i64 as u64)
    stxdw [r9+0x10], r1                     
    ldxdw r1, [r9+0x18]                     
    ldxdw r2, [r9+0x20]                     
    stxdw [r10-0x150], r2                   
    stxdw [r10-0x158], r1                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -2792                                 r1 += -2792   ///  r1 = r1.wrapping_add(-2792 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -344                                  r2 += -344   ///  r2 = r2.wrapping_add(-344 as i32 as i64 as u64)
    call function_12619                     
    lddw r1, 0x8000000000000000                     r1 load str located at -9223372036854775808
    ldxdw r2, [r10-0xae8]                   
    jeq r2, r1, lbb_6843                            if r2 == r1 { pc += 1 }
    ja lbb_6868                                     if true { pc += 25 }
lbb_6843:
    ldxdw r2, [r10-0xae0]                   
    mov64 r1, r7                                    r1 = r7
    call function_18093                     
lbb_6846:
    ldxdw r1, [r9+0x10]                     
    add64 r1, -1                                    r1 += -1   ///  r1 = r1.wrapping_add(-1 as i32 as i64 as u64)
    stxdw [r9+0x10], r1                     
    ja lbb_3730                                     if true { pc += -3120 }
lbb_6850:
    ldxdw r4, [r3+0x8]                      
    lddw r5, 0xa5b18bf6febdfb8d                     r5 load str located at -6507266093621576819
    jne r4, r5, lbb_6817                            if r4 != r5 { pc += -37 }
    ldxdw r4, [r3+0x10]                     
    lddw r5, 0x3f762b2616a7d0c7                     r5 load str located at 4572889914230165703
    jne r4, r5, lbb_6817                            if r4 != r5 { pc += -41 }
    mov64 r4, 0                                     r4 = 0 as i32 as i64 as u64
    ldxdw r3, [r3+0x18]                     
    lddw r5, 0xe00b8186ff88305d                     r5 load str located at -2302604367657160611
    jne r3, r5, lbb_6817                            if r3 != r5 { pc += -46 }
    jeq r4, 0, lbb_6820                             if r4 == (0 as i32 as i64 as u64) { pc += -44 }
    ja lbb_5436                                     if true { pc += -1429 }
lbb_6865:
    lddw r1, 0x1000411d8 --> b"\x00\x00\x00\x000\xe7\x03\x00\x10\x00\x00\x00\x00\x00\x00\x00\x17\x03\x00…        r1 load str located at 4295234008
    call function_25345                     
lbb_6868:
    mov64 r1, r10                                   r1 = r10
    add64 r1, -1480                                 r1 += -1480   ///  r1 = r1.wrapping_add(-1480 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -2776                                 r2 += -2776   ///  r2 = r2.wrapping_add(-2776 as i32 as i64 as u64)
    mov64 r3, 528                                   r3 = 528 as i32 as i64 as u64
    call function_30349                     
    ldxdw r1, [r9+0x10]                     
    add64 r1, -1                                    r1 += -1   ///  r1 = r1.wrapping_add(-1 as i32 as i64 as u64)
    stxdw [r9+0x10], r1                     
    lddw r1, 0xfc3e34becfcb63d7                     r1 load str located at -270720933461007401
    ldxdw r2, [r10-0x588]                   
    jeq r2, r1, lbb_6883                            if r2 == r1 { pc += 2 }
lbb_6881:
    mov64 r2, 1                                     r2 = 1 as i32 as i64 as u64
    ja lbb_6896                                     if true { pc += 13 }
lbb_6883:
    lddw r1, 0xf495c87a5045cbbb                     r1 load str located at -822530929266930757
    ldxdw r2, [r10-0x580]                   
    jne r2, r1, lbb_6881                            if r2 != r1 { pc += -6 }
    lddw r1, 0xe7d24322df5eeb7c                     r1 load str located at -1742256288783471748
    ldxdw r2, [r10-0x578]                   
    jne r2, r1, lbb_6881                            if r2 != r1 { pc += -10 }
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
    lddw r1, 0xcf66dbb77498e62b                     r1 load str located at -3501870079252306389
    ldxdw r3, [r10-0x570]                   
    jne r3, r1, lbb_6881                            if r3 != r1 { pc += -15 }
lbb_6896:
    mov64 r1, r7                                    r1 = r7
    jeq r2, 0, lbb_6899                             if r2 == (0 as i32 as i64 as u64) { pc += 1 }
    ja lbb_5819                                     if true { pc += -1080 }
lbb_6899:
    ldxb r2, [r10-0x3c4]                    
    jeq r2, 0, lbb_6903                             if r2 == (0 as i32 as i64 as u64) { pc += 2 }
    mov64 r2, 15                                    r2 = 15 as i32 as i64 as u64
    ja lbb_3782                                     if true { pc += -3121 }
lbb_6903:
    ldxdw r1, [r6+0x0]                      
    ldxdw r2, [r1+0x0]                      
    ldxdw r3, [r10-0x588]                   
    jeq r2, r3, lbb_6911                            if r2 == r3 { pc += 4 }
lbb_6907:
    mov64 r2, 1                                     r2 = 1 as i32 as i64 as u64
    jeq r2, 0, lbb_6923                             if r2 == (0 as i32 as i64 as u64) { pc += 14 }
lbb_6909:
    mov64 r1, 3                                     r1 = 3 as i32 as i64 as u64
    ja lbb_3723                                     if true { pc += -3188 }
lbb_6911:
    ldxdw r2, [r1+0x8]                      
    ldxdw r3, [r10-0x580]                   
    jne r2, r3, lbb_6907                            if r2 != r3 { pc += -7 }
    ldxdw r2, [r1+0x10]                     
    ldxdw r3, [r10-0x578]                   
    jne r2, r3, lbb_6907                            if r2 != r3 { pc += -10 }
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
    ldxdw r1, [r1+0x18]                     
    ldxdw r3, [r10-0x570]                   
    jne r1, r3, lbb_6907                            if r1 != r3 { pc += -14 }
    jeq r2, 0, lbb_6923                             if r2 == (0 as i32 as i64 as u64) { pc += 1 }
    ja lbb_6909                                     if true { pc += -14 }
lbb_6923:
    ldxdw r1, [r10-0xc10]                   
    ldxdw r2, [r1+0x0]                      
    ldxdw r1, [r10-0xc08]                   
    ldxdw r1, [r1+0x78]                     
    ldxdw r3, [r1+0x0]                      
    jeq r3, r2, lbb_6933                            if r3 == r2 { pc += 4 }
lbb_6929:
    mov64 r2, 1                                     r2 = 1 as i32 as i64 as u64
    jeq r2, 0, lbb_6948                             if r2 == (0 as i32 as i64 as u64) { pc += 17 }
lbb_6931:
    mov64 r1, 2                                     r1 = 2 as i32 as i64 as u64
    ja lbb_3723                                     if true { pc += -3210 }
lbb_6933:
    ldxdw r2, [r10-0xc10]                   
    ldxdw r2, [r2+0x8]                      
    ldxdw r3, [r1+0x8]                      
    jne r3, r2, lbb_6929                            if r3 != r2 { pc += -8 }
    ldxdw r2, [r10-0xc10]                   
    ldxdw r2, [r2+0x10]                     
    ldxdw r3, [r1+0x10]                     
    jne r3, r2, lbb_6929                            if r3 != r2 { pc += -12 }
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
    ldxdw r3, [r10-0xc10]                   
    ldxdw r3, [r3+0x18]                     
    ldxdw r1, [r1+0x18]                     
    jne r1, r3, lbb_6929                            if r1 != r3 { pc += -17 }
    jeq r2, 0, lbb_6948                             if r2 == (0 as i32 as i64 as u64) { pc += 1 }
    ja lbb_6931                                     if true { pc += -17 }
lbb_6948:
    ldxdw r1, [r10-0xc00]                   
    call function_17730                     
    jne r0, 0, lbb_6952                             if r0 != (0 as i32 as i64 as u64) { pc += 1 }
    ja lbb_6954                                     if true { pc += 2 }
lbb_6952:
    mov64 r1, 22                                    r1 = 22 as i32 as i64 as u64
    ja lbb_3723                                     if true { pc += -3231 }
lbb_6954:
    ldxdw r1, [r10-0xc08]                   
    ldxdw r6, [r1+0x70]                     
    ldxdw r1, [r6+0x10]                     
    jeq r1, 0, lbb_6959                             if r1 == (0 as i32 as i64 as u64) { pc += 1 }
    ja lbb_7020                                     if true { pc += 61 }
lbb_6959:
    mov64 r1, -1                                    r1 = -1 as i32 as i64 as u64
    stxdw [r6+0x10], r1                     
    ldxdw r1, [r6+0x20]                     
    jne r1, 1264, lbb_6984                          if r1 != (1264 as i32 as i64 as u64) { pc += 21 }
    ldxdw r9, [r6+0x18]                     
    mov64 r1, r9                                    r1 = r9
    and64 r1, 7                                     r1 &= 7   ///  r1 = r1.and(7)
    jeq r1, 0, lbb_6968                             if r1 == (0 as i32 as i64 as u64) { pc += 1 }
    ja lbb_6984                                     if true { pc += 16 }
lbb_6968:
    ldxh r4, [r9+0x14]                      
    mov64 r1, r10                                   r1 = r10
    add64 r1, -2792                                 r1 += -2792   ///  r1 = r1.wrapping_add(-2792 as i32 as i64 as u64)
    ldxdw r2, [r10-0xc10]                   
    ldxdw r3, [r10-0xc00]                   
    call function_9195                      
    ldxdw r1, [r10-0xae8]                   
    lddw r2, 0x800000000000001a                     r2 load str located at -9223372036854775782
    jeq r1, r2, lbb_6979                            if r1 == r2 { pc += 1 }
    ja lbb_6990                                     if true { pc += 11 }
lbb_6979:
    ldxdw r1, [r10-0xc18]                   
    jgt r1, 1000000, lbb_6982                       if r1 > (1000000 as i32 as i64 as u64) { pc += 1 }
    ja lbb_6998                                     if true { pc += 16 }
lbb_6982:
    mov64 r1, 10                                    r1 = 10 as i32 as i64 as u64
    ja lbb_6985                                     if true { pc += 1 }
lbb_6984:
    mov64 r1, 65535                                 r1 = 65535 as i32 as i64 as u64
lbb_6985:
    stxw [r7+0x8], r1                       
    lddw r1, 0x8000000000000000                     r1 load str located at -9223372036854775808
    stxdw [r7+0x0], r1                      
    ja lbb_3988                                     if true { pc += -3002 }
lbb_6990:
    ldxb r2, [r10-0xae0]                    
    ldxdw r3, [r10-0xad8]                   
    stxdw [r7+0x10], r3                     
    ldxdw r3, [r10-0xadf]                   
    stxdw [r7+0x9], r3                      
    stxb [r7+0x8], r2                       
    stxdw [r7+0x0], r1                      
    ja lbb_3988                                     if true { pc += -3010 }
lbb_6998:
    ldxdw r1, [r10-0xc20]                   
    jgt r1, 1000000, lbb_7001                       if r1 > (1000000 as i32 as i64 as u64) { pc += 1 }
    ja lbb_7003                                     if true { pc += 2 }
lbb_7001:
    mov64 r1, 11                                    r1 = 11 as i32 as i64 as u64
    ja lbb_6985                                     if true { pc += -18 }
lbb_7003:
    ldxdw r1, [r10-0xc40]                   
    stxb [r9+0x466], r1                     
    ldxdw r1, [r10-0xc20]                   
    stxw [r9+0x460], r1                     
    ldxdw r1, [r10-0xc18]                   
    stxw [r9+0x10], r1                      
    ldxdw r1, [r10-0xc38]                   
    stxw [r9+0x6c], r1                      
    ldxdw r1, [r10-0xc30]                   
    stxw [r9+0x68], r1                      
    ldxdw r1, [r10-0xc28]                   
    stxdw [r9+0x60], r1                     
    stxdw [r9+0x58], r8                     
    lddw r1, 0x800000000000001a                     r1 load str located at -9223372036854775782
    stxdw [r7+0x0], r1                      
    ja lbb_3988                                     if true { pc += -3032 }
lbb_7020:
    lddw r1, 0x1000411c0 --> b"\x00\x00\x00\x000\xe7\x03\x00\x10\x00\x00\x00\x00\x00\x00\x00&\x03\x00\x0…        r1 load str located at 4295233984
    call function_25324                     
lbb_7023:
    jeq r7, 0, lbb_2935                             if r7 == (0 as i32 as i64 as u64) { pc += -4089 }
    mov64 r6, r8                                    r6 = r8
    add64 r6, 48                                    r6 += 48   ///  r6 = r6.wrapping_add(48 as i32 as i64 as u64)
    jeq r7, 1, lbb_3773                             if r7 == (1 as i32 as i64 as u64) { pc += -3254 }
    ldxb r2, [r8+0x58]                      
    jeq r2, 0, lbb_3781                             if r2 == (0 as i32 as i64 as u64) { pc += -3248 }
    ldxdw r2, [r8+0x0]                      
    ldxdw r4, [r2+0x0]                      
    lddw r5, 0x9e9974ee626ad71                      r5 load str located at 714268381039471985
    jeq r4, r5, lbb_7036                            if r4 == r5 { pc += 2 }
lbb_7034:
    mov64 r4, 1                                     r4 = 1 as i32 as i64 as u64
    ja lbb_7049                                     if true { pc += 13 }
lbb_7036:
    ldxdw r4, [r2+0x8]                      
    lddw r5, 0xa5b18bf6febdfb8d                     r5 load str located at -6507266093621576819
    jne r4, r5, lbb_7034                            if r4 != r5 { pc += -6 }
    ldxdw r4, [r2+0x10]                     
    lddw r5, 0x3f762b2616a7d0c7                     r5 load str located at 4572889914230165703
    jne r4, r5, lbb_7034                            if r4 != r5 { pc += -10 }
    mov64 r4, 0                                     r4 = 0 as i32 as i64 as u64
    ldxdw r2, [r2+0x18]                     
    lddw r5, 0xe00b8186ff88305d                     r5 load str located at -2302604367657160611
    jne r2, r5, lbb_7034                            if r2 != r5 { pc += -15 }
lbb_7049:
    jne r4, 0, lbb_5436                             if r4 != (0 as i32 as i64 as u64) { pc += -1614 }
    stxdw [r10-0xc00], r1                   
    stxdw [r10-0xc08], r8                   
    ldxdw r8, [r8+0x10]                     
    ldxdw r1, [r8+0x10]                     
    lddw r2, 0x7fffffffffffffff                     r2 load str located at 9223372036854775807
    jgt r2, r1, lbb_7058                            if r2 > r1 { pc += 1 }
    ja lbb_7082                                     if true { pc += 24 }
lbb_7058:
    ldxb r2, [r9+0x5]                       
    stxdw [r10-0xc18], r2                   
    ldxw r2, [r9+0x1]                       
    stxdw [r10-0xc10], r2                   
    add64 r1, 1                                     r1 += 1   ///  r1 = r1.wrapping_add(1 as i32 as i64 as u64)
    stxdw [r8+0x10], r1                     
    ldxdw r1, [r8+0x18]                     
    ldxdw r2, [r8+0x20]                     
    stxdw [r10-0x150], r2                   
    stxdw [r10-0x158], r1                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -2792                                 r1 += -2792   ///  r1 = r1.wrapping_add(-2792 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -344                                  r2 += -344   ///  r2 = r2.wrapping_add(-344 as i32 as i64 as u64)
    call function_12619                     
    ldxdw r7, [r10-0xae0]                   
    ldxdw r9, [r10-0xae8]                   
    lddw r1, 0x8000000000000000                     r1 load str located at -9223372036854775808
    jeq r9, r1, lbb_7079                            if r9 == r1 { pc += 1 }
    ja lbb_7085                                     if true { pc += 6 }
lbb_7079:
    ldxdw r1, [r10-0xc00]                   
    mov64 r2, r7                                    r2 = r7
    ja lbb_4849                                     if true { pc += -2233 }
lbb_7082:
    lddw r1, 0x100041208 --> b"\x00\x00\x00\x000\xe7\x03\x00\x10\x00\x00\x00\x00\x00\x00\x00M\x03\x00\x0…        r1 load str located at 4295234056
    call function_25345                     
lbb_7085:
    mov64 r1, r10                                   r1 = r10
    add64 r1, -1480                                 r1 += -1480   ///  r1 = r1.wrapping_add(-1480 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -2776                                 r2 += -2776   ///  r2 = r2.wrapping_add(-2776 as i32 as i64 as u64)
    mov64 r3, 528                                   r3 = 528 as i32 as i64 as u64
    call function_30349                     
    stxdw [r10-0x5d0], r7                   
    stxdw [r10-0x5d8], r9                   
    ldxdw r1, [r8+0x10]                     
    add64 r1, -1                                    r1 += -1   ///  r1 = r1.wrapping_add(-1 as i32 as i64 as u64)
    stxdw [r8+0x10], r1                     
    lddw r2, 0xfc3e34becfcb63d7                     r2 load str located at -270720933461007401
    ldxdw r3, [r10-0x588]                   
    jeq r3, r2, lbb_7102                            if r3 == r2 { pc += 2 }
lbb_7100:
    mov64 r3, 1                                     r3 = 1 as i32 as i64 as u64
    ja lbb_7115                                     if true { pc += 13 }
lbb_7102:
    lddw r2, 0xf495c87a5045cbbb                     r2 load str located at -822530929266930757
    ldxdw r3, [r10-0x580]                   
    jne r3, r2, lbb_7100                            if r3 != r2 { pc += -6 }
    lddw r2, 0xe7d24322df5eeb7c                     r2 load str located at -1742256288783471748
    ldxdw r3, [r10-0x578]                   
    jne r3, r2, lbb_7100                            if r3 != r2 { pc += -10 }
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
    lddw r2, 0xcf66dbb77498e62b                     r2 load str located at -3501870079252306389
    ldxdw r4, [r10-0x570]                   
    jne r4, r2, lbb_7100                            if r4 != r2 { pc += -15 }
lbb_7115:
    ldxdw r2, [r10-0xc00]                   
    ldxdw r4, [r10-0xc08]                   
    jeq r3, 0, lbb_7124                             if r3 == (0 as i32 as i64 as u64) { pc += 6 }
lbb_7118:
    mov64 r1, 28                                    r1 = 28 as i32 as i64 as u64
lbb_7119:
    stxw [r2+0x8], r1                       
lbb_7120:
    lddw r1, 0x8000000000000000                     r1 load str located at -9223372036854775808
    stxdw [r2+0x0], r1                      
    ja lbb_3730                                     if true { pc += -3394 }
lbb_7124:
    ldxb r3, [r10-0x3c4]                    
    jeq r3, 0, lbb_7127                             if r3 == (0 as i32 as i64 as u64) { pc += 1 }
lbb_7126:
    ja lbb_5524                                     if true { pc += -1603 }
lbb_7127:
    ldxb r3, [r4+0x29]                      
    jeq r3, 0, lbb_7173                             if r3 == (0 as i32 as i64 as u64) { pc += 44 }
    ldxdw r3, [r6+0x0]                      
    ldxdw r4, [r3+0x0]                      
    ldxdw r5, [r10-0x588]                   
    jeq r4, r5, lbb_7175                            if r4 == r5 { pc += 42 }
lbb_7133:
    mov64 r4, 1                                     r4 = 1 as i32 as i64 as u64
    jeq r4, 0, lbb_7136                             if r4 == (0 as i32 as i64 as u64) { pc += 1 }
    ja lbb_6621                                     if true { pc += -515 }
lbb_7136:
    ldxdw r2, [r10-0xc18]                   
    lsh64 r2, 32                                    r2 <<= 32   ///  r2 = r2.wrapping_shl(32)
    ldxdw r3, [r10-0xc10]                   
    or64 r3, r2                                     r3 |= r2   ///  r3 = r3.or(r2)
    mov64 r2, r3                                    r2 = r3
    and64 r2, 1                                     r2 &= 1   ///  r2 = r2.and(1)
    stxb [r10-0x3c2], r2                    
    mov64 r2, r3                                    r2 = r3
    rsh64 r2, 32                                    r2 >>= 32   ///  r2 = r2.wrapping_shr(32)
    and64 r2, 1                                     r2 &= 1   ///  r2 = r2.and(1)
    stxb [r10-0x3be], r2                    
    mov64 r2, r3                                    r2 = r3
    rsh64 r2, 24                                    r2 >>= 24   ///  r2 = r2.wrapping_shr(24)
    and64 r2, 1                                     r2 &= 1   ///  r2 = r2.and(1)
    stxb [r10-0x3bf], r2                    
    mov64 r2, r3                                    r2 = r3
    rsh64 r2, 16                                    r2 >>= 16   ///  r2 = r2.wrapping_shr(16)
    and64 r2, 1                                     r2 &= 1   ///  r2 = r2.and(1)
    stxb [r10-0x3c0], r2                    
    rsh64 r3, 8                                     r3 >>= 8   ///  r3 = r3.wrapping_shr(8)
    and64 r3, 1                                     r3 &= 1   ///  r3 = r3.and(1)
    stxb [r10-0x3c1], r3                    
    jeq r1, 0, lbb_7160                             if r1 == (0 as i32 as i64 as u64) { pc += 1 }
    ja lbb_7187                                     if true { pc += 27 }
lbb_7160:
    mov64 r1, -1                                    r1 = -1 as i32 as i64 as u64
    stxdw [r8+0x10], r1                     
    ldxdw r1, [r8+0x18]                     
    ldxdw r2, [r8+0x20]                     
    stxdw [r10-0xae0], r2                   
    stxdw [r10-0xae8], r1                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -1496                                 r1 += -1496   ///  r1 = r1.wrapping_add(-1496 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -2792                                 r2 += -2792   ///  r2 = r2.wrapping_add(-2792 as i32 as i64 as u64)
    call function_13019                     
    jeq r0, 0, lbb_6800                             if r0 == (0 as i32 as i64 as u64) { pc += -372 }
    ja lbb_3129                                     if true { pc += -4044 }
lbb_7173:
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    ja lbb_7119                                     if true { pc += -56 }
lbb_7175:
    ldxdw r4, [r3+0x8]                      
    ldxdw r5, [r10-0x580]                   
    jne r4, r5, lbb_7133                            if r4 != r5 { pc += -45 }
    ldxdw r4, [r3+0x10]                     
    ldxdw r5, [r10-0x578]                   
    jne r4, r5, lbb_7133                            if r4 != r5 { pc += -48 }
    mov64 r4, 0                                     r4 = 0 as i32 as i64 as u64
    ldxdw r3, [r3+0x18]                     
    ldxdw r5, [r10-0x570]                   
    jne r3, r5, lbb_7133                            if r3 != r5 { pc += -52 }
    jeq r4, 0, lbb_7136                             if r4 == (0 as i32 as i64 as u64) { pc += -50 }
    ja lbb_6621                                     if true { pc += -566 }
lbb_7187:
    lddw r1, 0x1000411f0 --> b"\x00\x00\x00\x000\xe7\x03\x00\x10\x00\x00\x00\x00\x00\x00\x00k\x03\x00\x0…        r1 load str located at 4295234032
    call function_25324                     
lbb_7190:
    ldxdw r1, [r10-0xc08]                   
    ldxdw r1, [r1+0x0]                      
    ldxdw r2, [r1+0x0]                      
    lddw r3, 0x9e9974ee626ad71                      r3 load str located at 714268381039471985
    jeq r2, r3, lbb_7236                            if r2 == r3 { pc += 40 }
lbb_7196:
    mov64 r2, 1                                     r2 = 1 as i32 as i64 as u64
    jeq r2, 0, lbb_7199                             if r2 == (0 as i32 as i64 as u64) { pc += 1 }
    ja lbb_4052                                     if true { pc += -3147 }
lbb_7199:
    ldxdw r1, [r10-0xc08]                   
    ldxdw r9, [r1+0x10]                     
    ldxdw r1, [r9+0x10]                     
    lddw r2, 0x7fffffffffffffff                     r2 load str located at 9223372036854775807
    jgt r2, r1, lbb_7206                            if r2 > r1 { pc += 1 }
    ja lbb_7251                                     if true { pc += 45 }
lbb_7206:
    add64 r1, 1                                     r1 += 1   ///  r1 = r1.wrapping_add(1 as i32 as i64 as u64)
    stxdw [r9+0x10], r1                     
    ldxdw r1, [r9+0x18]                     
    ldxdw r2, [r9+0x20]                     
    stxdw [r10-0x150], r2                   
    stxdw [r10-0x158], r1                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -2792                                 r1 += -2792   ///  r1 = r1.wrapping_add(-2792 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -344                                  r2 += -344   ///  r2 = r2.wrapping_add(-344 as i32 as i64 as u64)
    call function_12619                     
    ldxdw r1, [r10-0xae0]                   
    stxdw [r10-0xc78], r1                   
    ldxdw r7, [r10-0xae8]                   
    lddw r1, 0x8000000000000000                     r1 load str located at -9223372036854775808
    jeq r7, r1, lbb_7224                            if r7 == r1 { pc += 1 }
    ja lbb_7254                                     if true { pc += 30 }
lbb_7224:
    mov64 r1, r10                                   r1 = r10
    add64 r1, -2792                                 r1 += -2792   ///  r1 = r1.wrapping_add(-2792 as i32 as i64 as u64)
    ldxdw r2, [r10-0xc78]                   
    call function_18093                     
    ldxdw r1, [r10-0xad8]                   
    ldxdw r2, [r10-0xc00]                   
    stxdw [r2+0x10], r1                     
    ldxdw r1, [r10-0xae0]                   
    stxdw [r2+0x8], r1                      
    ldxdw r1, [r10-0xae8]                   
    stxdw [r2+0x0], r1                      
    ja lbb_6846                                     if true { pc += -390 }
lbb_7236:
    ldxdw r2, [r1+0x8]                      
    lddw r3, 0xa5b18bf6febdfb8d                     r3 load str located at -6507266093621576819
    jne r2, r3, lbb_7196                            if r2 != r3 { pc += -44 }
    ldxdw r2, [r1+0x10]                     
    lddw r3, 0x3f762b2616a7d0c7                     r3 load str located at 4572889914230165703
    jne r2, r3, lbb_7196                            if r2 != r3 { pc += -48 }
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
    ldxdw r1, [r1+0x18]                     
    lddw r3, 0xe00b8186ff88305d                     r3 load str located at -2302604367657160611
    jne r1, r3, lbb_7196                            if r1 != r3 { pc += -53 }
    jeq r2, 0, lbb_7199                             if r2 == (0 as i32 as i64 as u64) { pc += -51 }
    ja lbb_4052                                     if true { pc += -3199 }
lbb_7251:
    lddw r1, 0x100041318 --> b"\x00\x00\x00\x000\xe7\x03\x00\x10\x00\x00\x00\x00\x00\x00\x00\x8f\x03\x00…        r1 load str located at 4295234328
    call function_25345                     
lbb_7254:
    mov64 r1, r10                                   r1 = r10
    add64 r1, -1480                                 r1 += -1480   ///  r1 = r1.wrapping_add(-1480 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -2776                                 r2 += -2776   ///  r2 = r2.wrapping_add(-2776 as i32 as i64 as u64)
    mov64 r3, 528                                   r3 = 528 as i32 as i64 as u64
    call function_30349                     
    ldxdw r1, [r10-0xc78]                   
    stxdw [r10-0x5d0], r1                   
    stxdw [r10-0x5d8], r7                   
    ldxdw r1, [r9+0x10]                     
    add64 r1, -1                                    r1 += -1   ///  r1 = r1.wrapping_add(-1 as i32 as i64 as u64)
    stxdw [r9+0x10], r1                     
    lddw r1, 0xfc3e34becfcb63d7                     r1 load str located at -270720933461007401
    ldxdw r2, [r10-0x588]                   
    jeq r2, r1, lbb_7299                            if r2 == r1 { pc += 29 }
lbb_7270:
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    jeq r1, 0, lbb_7273                             if r1 == (0 as i32 as i64 as u64) { pc += 1 }
    ja lbb_4009                                     if true { pc += -3264 }
lbb_7273:
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    stxdw [r10-0x3a0], r1                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -1520                                 r1 += -1520   ///  r1 = r1.wrapping_add(-1520 as i32 as i64 as u64)
    stxdw [r10-0x3a8], r1                   
    mov64 r1, 5                                     r1 = 5 as i32 as i64 as u64
    stxdw [r10-0x3b0], r1                   
    lddw r1, 0x10003e6f5 --> b"AC_01\x00\x00\x00\x00\x00\x00connection resetassertion `left ) when "        r1 load str located at 4295223029
    stxdw [r10-0x3b8], r1                   
    mov64 r1, 255                                   r1 = 255 as i32 as i64 as u64
    stxb [r10-0x5f0], r1                    
    ldxb r1, [r10-0x3c4]                    
    ldxb r2, [r10-0x3c3]                    
    or64 r2, r1                                     r2 |= r1   ///  r2 = r2.or(r1)
    and64 r2, 255                                   r2 &= 255   ///  r2 = r2.and(255)
    jeq r2, 0, lbb_7291                             if r2 == (0 as i32 as i64 as u64) { pc += 1 }
    ja lbb_6128                                     if true { pc += -1163 }
lbb_7291:
    ldxdw r1, [r10-0xc10]                   
    ldxdw r2, [r1+0x0]                      
    ldxdw r1, [r10-0xc08]                   
    ldxdw r1, [r1+0x48]                     
    ldxdw r3, [r1+0x0]                      
    jeq r3, r2, lbb_7314                            if r3 == r2 { pc += 17 }
lbb_7297:
    mov64 r2, 1                                     r2 = 1 as i32 as i64 as u64
    ja lbb_7327                                     if true { pc += 28 }
lbb_7299:
    lddw r1, 0xf495c87a5045cbbb                     r1 load str located at -822530929266930757
    ldxdw r2, [r10-0x580]                   
    jne r2, r1, lbb_7270                            if r2 != r1 { pc += -33 }
    lddw r1, 0xe7d24322df5eeb7c                     r1 load str located at -1742256288783471748
    ldxdw r2, [r10-0x578]                   
    jne r2, r1, lbb_7270                            if r2 != r1 { pc += -37 }
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    lddw r2, 0xcf66dbb77498e62b                     r2 load str located at -3501870079252306389
    ldxdw r3, [r10-0x570]                   
    jne r3, r2, lbb_7270                            if r3 != r2 { pc += -42 }
    jeq r1, 0, lbb_7273                             if r1 == (0 as i32 as i64 as u64) { pc += -40 }
    ja lbb_4009                                     if true { pc += -3305 }
lbb_7314:
    ldxdw r2, [r10-0xc10]                   
    ldxdw r2, [r2+0x8]                      
    ldxdw r3, [r1+0x8]                      
    jne r3, r2, lbb_7297                            if r3 != r2 { pc += -21 }
    ldxdw r2, [r10-0xc10]                   
    ldxdw r2, [r2+0x10]                     
    ldxdw r3, [r1+0x10]                     
    jne r3, r2, lbb_7297                            if r3 != r2 { pc += -25 }
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
    ldxdw r3, [r10-0xc10]                   
    ldxdw r3, [r3+0x18]                     
    ldxdw r1, [r1+0x18]                     
    jne r1, r3, lbb_7297                            if r1 != r3 { pc += -30 }
lbb_7327:
    jne r2, 0, lbb_4598                             if r2 != (0 as i32 as i64 as u64) { pc += -2730 }
    mov64 r1, r6                                    r1 = r6
    call function_17730                     
    jne r0, 0, lbb_7332                             if r0 != (0 as i32 as i64 as u64) { pc += 1 }
    ja lbb_7334                                     if true { pc += 2 }
lbb_7332:
    mov64 r1, 22                                    r1 = 22 as i32 as i64 as u64
    ja lbb_2954                                     if true { pc += -4380 }
lbb_7334:
    ldxdw r1, [r10-0xc08]                   
    ldxdw r7, [r1+0x40]                     
    ldxdw r1, [r7+0x10]                     
    jeq r1, 0, lbb_7339                             if r1 == (0 as i32 as i64 as u64) { pc += 1 }
    ja lbb_8033                                     if true { pc += 694 }
lbb_7339:
    mov64 r1, -1                                    r1 = -1 as i32 as i64 as u64
    stxdw [r7+0x10], r1                     
    ldxdw r1, [r7+0x20]                     
    jne r1, 1264, lbb_7369                          if r1 != (1264 as i32 as i64 as u64) { pc += 26 }
    ldxdw r9, [r7+0x18]                     
    mov64 r1, r9                                    r1 = r9
    and64 r1, 7                                     r1 &= 7   ///  r1 = r1.and(7)
    jeq r1, 0, lbb_7348                             if r1 == (0 as i32 as i64 as u64) { pc += 1 }
    ja lbb_7369                                     if true { pc += 21 }
lbb_7348:
    ldxh r4, [r9+0x14]                      
    mov64 r1, r10                                   r1 = r10
    add64 r1, -2792                                 r1 += -2792   ///  r1 = r1.wrapping_add(-2792 as i32 as i64 as u64)
    ldxdw r2, [r10-0xc10]                   
    mov64 r3, r6                                    r3 = r6
    call function_9195                      
    ldxdw r1, [r10-0xae8]                   
    lddw r2, 0x800000000000001a                     r2 load str located at -9223372036854775782
    jeq r1, r2, lbb_7359                            if r1 == r2 { pc += 1 }
    ja lbb_7839                                     if true { pc += 480 }
lbb_7359:
    ldxdw r1, [r10-0xc60]                   
    ldxdw r1, [r1+0x0]                      
    ldxdw r2, [r1+0x0]                      
    lddw r3, 0x66d17b1817d5a706                     r3 load str located at 7408838205410486022
    jeq r2, r3, lbb_7376                            if r2 == r3 { pc += 11 }
lbb_7365:
    mov64 r2, 1                                     r2 = 1 as i32 as i64 as u64
    jeq r2, 0, lbb_7391                             if r2 == (0 as i32 as i64 as u64) { pc += 24 }
lbb_7367:
    mov64 r1, 3                                     r1 = 3 as i32 as i64 as u64
    ja lbb_7370                                     if true { pc += 1 }
lbb_7369:
    mov64 r1, 65535                                 r1 = 65535 as i32 as i64 as u64
lbb_7370:
    ldxdw r2, [r10-0xc00]                   
    stxw [r2+0x8], r1                       
    lddw r1, 0x8000000000000000                     r1 load str located at -9223372036854775808
    stxdw [r2+0x0], r1                      
    ja lbb_7847                                     if true { pc += 471 }
lbb_7376:
    ldxdw r2, [r1+0x8]                      
    lddw r3, 0xc0c2fd5504d4da35                     r3 load str located at -4556801331350414795
    jne r2, r3, lbb_7365                            if r2 != r3 { pc += -15 }
    ldxdw r2, [r1+0x10]                     
    lddw r3, 0xa57556218fc624c1                     r3 load str located at -6524213783030258495
    jne r2, r3, lbb_7365                            if r2 != r3 { pc += -19 }
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
    ldxdw r1, [r1+0x18]                     
    lddw r3, 0x85fcbbadb                            r3 load str located at 35966925531
    jne r1, r3, lbb_7365                            if r1 != r3 { pc += -24 }
    jeq r2, 0, lbb_7391                             if r2 == (0 as i32 as i64 as u64) { pc += 1 }
    ja lbb_7367                                     if true { pc += -24 }
lbb_7391:
    ldxb r1, [r9+0xb0]                      
    jeq r1, 0, lbb_7530                             if r1 == (0 as i32 as i64 as u64) { pc += 137 }
    ldxdw r3, [r9+0xa8]                     
    mov64 r1, 7                                     r1 = 7 as i32 as i64 as u64
    jgt r3, 999999, lbb_7370                        if r3 > (999999 as i32 as i64 as u64) { pc += -26 }
    ldxb r1, [r9+0xc8]                      
    jeq r1, 0, lbb_7530                             if r1 == (0 as i32 as i64 as u64) { pc += 132 }
    ldxdw r2, [r9+0xc0]                     
    mov64 r1, 7                                     r1 = 7 as i32 as i64 as u64
    jgt r2, 999999, lbb_7370                        if r2 > (999999 as i32 as i64 as u64) { pc += -31 }
    mov64 r1, 8                                     r1 = 8 as i32 as i64 as u64
    jge r2, r3, lbb_7370                            if r2 >= r3 { pc += -33 }
    ldxb r1, [r9+0xe0]                      
    jeq r1, 0, lbb_7530                             if r1 == (0 as i32 as i64 as u64) { pc += 125 }
    ldxdw r3, [r9+0xd8]                     
    mov64 r1, 7                                     r1 = 7 as i32 as i64 as u64
    jgt r3, 999999, lbb_7370                        if r3 > (999999 as i32 as i64 as u64) { pc += -38 }
    mov64 r1, 8                                     r1 = 8 as i32 as i64 as u64
    jge r3, r2, lbb_7370                            if r3 >= r2 { pc += -40 }
    ldxb r1, [r9+0xf8]                      
    jeq r1, 0, lbb_7530                             if r1 == (0 as i32 as i64 as u64) { pc += 118 }
    ldxdw r2, [r9+0xf0]                     
    mov64 r1, 7                                     r1 = 7 as i32 as i64 as u64
    jgt r2, 999999, lbb_7370                        if r2 > (999999 as i32 as i64 as u64) { pc += -45 }
    mov64 r1, 8                                     r1 = 8 as i32 as i64 as u64
    jge r2, r3, lbb_7370                            if r2 >= r3 { pc += -47 }
    ldxb r1, [r9+0x110]                     
    jeq r1, 0, lbb_7530                             if r1 == (0 as i32 as i64 as u64) { pc += 111 }
    ldxdw r3, [r9+0x108]                    
    mov64 r1, 7                                     r1 = 7 as i32 as i64 as u64
    jgt r3, 999999, lbb_7370                        if r3 > (999999 as i32 as i64 as u64) { pc += -52 }
    mov64 r1, 8                                     r1 = 8 as i32 as i64 as u64
    jge r3, r2, lbb_7370                            if r3 >= r2 { pc += -54 }
    ldxb r1, [r9+0x128]                     
    jeq r1, 0, lbb_7530                             if r1 == (0 as i32 as i64 as u64) { pc += 104 }
    ldxdw r2, [r9+0x120]                    
    mov64 r1, 7                                     r1 = 7 as i32 as i64 as u64
    jgt r2, 999999, lbb_7370                        if r2 > (999999 as i32 as i64 as u64) { pc += -59 }
    mov64 r1, 8                                     r1 = 8 as i32 as i64 as u64
    jge r2, r3, lbb_7370                            if r2 >= r3 { pc += -61 }
    ldxb r1, [r9+0x140]                     
    jeq r1, 0, lbb_7530                             if r1 == (0 as i32 as i64 as u64) { pc += 97 }
    ldxdw r3, [r9+0x138]                    
    mov64 r1, 7                                     r1 = 7 as i32 as i64 as u64
    jgt r3, 999999, lbb_7370                        if r3 > (999999 as i32 as i64 as u64) { pc += -66 }
    mov64 r1, 8                                     r1 = 8 as i32 as i64 as u64
    jge r3, r2, lbb_7370                            if r3 >= r2 { pc += -68 }
    ldxb r1, [r9+0x158]                     
    jeq r1, 0, lbb_7530                             if r1 == (0 as i32 as i64 as u64) { pc += 90 }
    ldxdw r2, [r9+0x150]                    
    mov64 r1, 7                                     r1 = 7 as i32 as i64 as u64
    jgt r2, 999999, lbb_7370                        if r2 > (999999 as i32 as i64 as u64) { pc += -73 }
    mov64 r1, 8                                     r1 = 8 as i32 as i64 as u64
    jge r2, r3, lbb_7370                            if r2 >= r3 { pc += -75 }
    ldxb r1, [r9+0x170]                     
    jeq r1, 0, lbb_7530                             if r1 == (0 as i32 as i64 as u64) { pc += 83 }
    ldxdw r3, [r9+0x168]                    
    mov64 r1, 7                                     r1 = 7 as i32 as i64 as u64
    jgt r3, 999999, lbb_7370                        if r3 > (999999 as i32 as i64 as u64) { pc += -80 }
    mov64 r1, 8                                     r1 = 8 as i32 as i64 as u64
    jge r3, r2, lbb_7370                            if r3 >= r2 { pc += -82 }
    ldxb r1, [r9+0x188]                     
    jeq r1, 0, lbb_7530                             if r1 == (0 as i32 as i64 as u64) { pc += 76 }
    ldxdw r2, [r9+0x180]                    
    mov64 r1, 7                                     r1 = 7 as i32 as i64 as u64
    jgt r2, 999999, lbb_7370                        if r2 > (999999 as i32 as i64 as u64) { pc += -87 }
    mov64 r1, 8                                     r1 = 8 as i32 as i64 as u64
    jge r2, r3, lbb_7370                            if r2 >= r3 { pc += -89 }
    ldxb r1, [r9+0x1a0]                     
    jeq r1, 0, lbb_7530                             if r1 == (0 as i32 as i64 as u64) { pc += 69 }
    ldxdw r3, [r9+0x198]                    
    mov64 r1, 7                                     r1 = 7 as i32 as i64 as u64
    jgt r3, 999999, lbb_7370                        if r3 > (999999 as i32 as i64 as u64) { pc += -94 }
    mov64 r1, 8                                     r1 = 8 as i32 as i64 as u64
    jge r3, r2, lbb_7370                            if r3 >= r2 { pc += -96 }
    ldxb r1, [r9+0x1b8]                     
    jeq r1, 0, lbb_7530                             if r1 == (0 as i32 as i64 as u64) { pc += 62 }
    ldxdw r2, [r9+0x1b0]                    
    mov64 r1, 7                                     r1 = 7 as i32 as i64 as u64
    jgt r2, 999999, lbb_7370                        if r2 > (999999 as i32 as i64 as u64) { pc += -101 }
    mov64 r1, 8                                     r1 = 8 as i32 as i64 as u64
    jge r2, r3, lbb_7370                            if r2 >= r3 { pc += -103 }
    ldxb r1, [r9+0x1d0]                     
    jeq r1, 0, lbb_7530                             if r1 == (0 as i32 as i64 as u64) { pc += 55 }
    ldxdw r3, [r9+0x1c8]                    
    mov64 r1, 7                                     r1 = 7 as i32 as i64 as u64
    jgt r3, 999999, lbb_7370                        if r3 > (999999 as i32 as i64 as u64) { pc += -108 }
    mov64 r1, 8                                     r1 = 8 as i32 as i64 as u64
    jge r3, r2, lbb_7370                            if r3 >= r2 { pc += -110 }
    ldxb r1, [r9+0x1e8]                     
    jeq r1, 0, lbb_7530                             if r1 == (0 as i32 as i64 as u64) { pc += 48 }
    ldxdw r2, [r9+0x1e0]                    
    mov64 r1, 7                                     r1 = 7 as i32 as i64 as u64
    jgt r2, 999999, lbb_7370                        if r2 > (999999 as i32 as i64 as u64) { pc += -115 }
    mov64 r1, 8                                     r1 = 8 as i32 as i64 as u64
    jge r2, r3, lbb_7370                            if r2 >= r3 { pc += -117 }
    ldxb r1, [r9+0x200]                     
    jeq r1, 0, lbb_7530                             if r1 == (0 as i32 as i64 as u64) { pc += 41 }
    ldxdw r3, [r9+0x1f8]                    
    mov64 r1, 7                                     r1 = 7 as i32 as i64 as u64
    jgt r3, 999999, lbb_7370                        if r3 > (999999 as i32 as i64 as u64) { pc += -122 }
    mov64 r1, 8                                     r1 = 8 as i32 as i64 as u64
    jge r3, r2, lbb_7370                            if r3 >= r2 { pc += -124 }
    ldxb r1, [r9+0x218]                     
    jeq r1, 0, lbb_7530                             if r1 == (0 as i32 as i64 as u64) { pc += 34 }
    ldxdw r2, [r9+0x210]                    
    mov64 r1, 7                                     r1 = 7 as i32 as i64 as u64
    jgt r2, 999999, lbb_7370                        if r2 > (999999 as i32 as i64 as u64) { pc += -129 }
    mov64 r1, 8                                     r1 = 8 as i32 as i64 as u64
    jge r2, r3, lbb_7370                            if r2 >= r3 { pc += -131 }
    ldxb r1, [r9+0x230]                     
    jeq r1, 0, lbb_7530                             if r1 == (0 as i32 as i64 as u64) { pc += 27 }
    ldxdw r3, [r9+0x228]                    
    mov64 r1, 7                                     r1 = 7 as i32 as i64 as u64
    jgt r3, 999999, lbb_7370                        if r3 > (999999 as i32 as i64 as u64) { pc += -136 }
    mov64 r1, 8                                     r1 = 8 as i32 as i64 as u64
    jge r3, r2, lbb_7370                            if r3 >= r2 { pc += -138 }
    ldxb r1, [r9+0x248]                     
    jeq r1, 0, lbb_7530                             if r1 == (0 as i32 as i64 as u64) { pc += 20 }
    ldxdw r2, [r9+0x240]                    
    mov64 r1, 7                                     r1 = 7 as i32 as i64 as u64
    jgt r2, 999999, lbb_7370                        if r2 > (999999 as i32 as i64 as u64) { pc += -143 }
    mov64 r1, 8                                     r1 = 8 as i32 as i64 as u64
    jge r2, r3, lbb_7370                            if r2 >= r3 { pc += -145 }
    ldxb r1, [r9+0x260]                     
    jeq r1, 0, lbb_7530                             if r1 == (0 as i32 as i64 as u64) { pc += 13 }
    ldxdw r3, [r9+0x258]                    
    mov64 r1, 7                                     r1 = 7 as i32 as i64 as u64
    jgt r3, 999999, lbb_7370                        if r3 > (999999 as i32 as i64 as u64) { pc += -150 }
    mov64 r1, 8                                     r1 = 8 as i32 as i64 as u64
    jge r3, r2, lbb_7370                            if r3 >= r2 { pc += -152 }
    ldxb r1, [r9+0x278]                     
    jeq r1, 0, lbb_7530                             if r1 == (0 as i32 as i64 as u64) { pc += 6 }
    ldxdw r2, [r9+0x270]                    
    mov64 r1, 7                                     r1 = 7 as i32 as i64 as u64
    jgt r2, 999999, lbb_7370                        if r2 > (999999 as i32 as i64 as u64) { pc += -157 }
    mov64 r1, 8                                     r1 = 8 as i32 as i64 as u64
    jgt r3, r2, lbb_7530                            if r3 > r2 { pc += 1 }
    ja lbb_7370                                     if true { pc += -160 }
lbb_7530:
    ldxb r1, [r9+0x290]                     
    jeq r1, 0, lbb_7669                             if r1 == (0 as i32 as i64 as u64) { pc += 137 }
    ldxdw r3, [r9+0x288]                    
    mov64 r1, 7                                     r1 = 7 as i32 as i64 as u64
    jgt r3, 999999, lbb_7370                        if r3 > (999999 as i32 as i64 as u64) { pc += -165 }
    ldxb r1, [r9+0x2a8]                     
    jeq r1, 0, lbb_7669                             if r1 == (0 as i32 as i64 as u64) { pc += 132 }
    ldxdw r2, [r9+0x2a0]                    
    mov64 r1, 7                                     r1 = 7 as i32 as i64 as u64
    jgt r2, 999999, lbb_7370                        if r2 > (999999 as i32 as i64 as u64) { pc += -170 }
    mov64 r1, 8                                     r1 = 8 as i32 as i64 as u64
    jge r2, r3, lbb_7370                            if r2 >= r3 { pc += -172 }
    ldxb r1, [r9+0x2c0]                     
    jeq r1, 0, lbb_7669                             if r1 == (0 as i32 as i64 as u64) { pc += 125 }
    ldxdw r3, [r9+0x2b8]                    
    mov64 r1, 7                                     r1 = 7 as i32 as i64 as u64
    jgt r3, 999999, lbb_7370                        if r3 > (999999 as i32 as i64 as u64) { pc += -177 }
    mov64 r1, 8                                     r1 = 8 as i32 as i64 as u64
    jge r3, r2, lbb_7370                            if r3 >= r2 { pc += -179 }
    ldxb r1, [r9+0x2d8]                     
    jeq r1, 0, lbb_7669                             if r1 == (0 as i32 as i64 as u64) { pc += 118 }
    ldxdw r2, [r9+0x2d0]                    
    mov64 r1, 7                                     r1 = 7 as i32 as i64 as u64
    jgt r2, 999999, lbb_7370                        if r2 > (999999 as i32 as i64 as u64) { pc += -184 }
    mov64 r1, 8                                     r1 = 8 as i32 as i64 as u64
    jge r2, r3, lbb_7370                            if r2 >= r3 { pc += -186 }
    ldxb r1, [r9+0x2f0]                     
    jeq r1, 0, lbb_7669                             if r1 == (0 as i32 as i64 as u64) { pc += 111 }
    ldxdw r3, [r9+0x2e8]                    
    mov64 r1, 7                                     r1 = 7 as i32 as i64 as u64
    jgt r3, 999999, lbb_7370                        if r3 > (999999 as i32 as i64 as u64) { pc += -191 }
    mov64 r1, 8                                     r1 = 8 as i32 as i64 as u64
    jge r3, r2, lbb_7370                            if r3 >= r2 { pc += -193 }
    ldxb r1, [r9+0x308]                     
    jeq r1, 0, lbb_7669                             if r1 == (0 as i32 as i64 as u64) { pc += 104 }
    ldxdw r2, [r9+0x300]                    
    mov64 r1, 7                                     r1 = 7 as i32 as i64 as u64
    jgt r2, 999999, lbb_7370                        if r2 > (999999 as i32 as i64 as u64) { pc += -198 }
    mov64 r1, 8                                     r1 = 8 as i32 as i64 as u64
    jge r2, r3, lbb_7370                            if r2 >= r3 { pc += -200 }
    ldxb r1, [r9+0x320]                     
    jeq r1, 0, lbb_7669                             if r1 == (0 as i32 as i64 as u64) { pc += 97 }
    ldxdw r3, [r9+0x318]                    
    mov64 r1, 7                                     r1 = 7 as i32 as i64 as u64
    jgt r3, 999999, lbb_7370                        if r3 > (999999 as i32 as i64 as u64) { pc += -205 }
    mov64 r1, 8                                     r1 = 8 as i32 as i64 as u64
    jge r3, r2, lbb_7370                            if r3 >= r2 { pc += -207 }
    ldxb r1, [r9+0x338]                     
    jeq r1, 0, lbb_7669                             if r1 == (0 as i32 as i64 as u64) { pc += 90 }
    ldxdw r2, [r9+0x330]                    
    mov64 r1, 7                                     r1 = 7 as i32 as i64 as u64
    jgt r2, 999999, lbb_7370                        if r2 > (999999 as i32 as i64 as u64) { pc += -212 }
    mov64 r1, 8                                     r1 = 8 as i32 as i64 as u64
    jge r2, r3, lbb_7370                            if r2 >= r3 { pc += -214 }
    ldxb r1, [r9+0x350]                     
    jeq r1, 0, lbb_7669                             if r1 == (0 as i32 as i64 as u64) { pc += 83 }
    ldxdw r3, [r9+0x348]                    
    mov64 r1, 7                                     r1 = 7 as i32 as i64 as u64
    jgt r3, 999999, lbb_7370                        if r3 > (999999 as i32 as i64 as u64) { pc += -219 }
    mov64 r1, 8                                     r1 = 8 as i32 as i64 as u64
    jge r3, r2, lbb_7370                            if r3 >= r2 { pc += -221 }
    ldxb r1, [r9+0x368]                     
    jeq r1, 0, lbb_7669                             if r1 == (0 as i32 as i64 as u64) { pc += 76 }
    ldxdw r2, [r9+0x360]                    
    mov64 r1, 7                                     r1 = 7 as i32 as i64 as u64
    jgt r2, 999999, lbb_7370                        if r2 > (999999 as i32 as i64 as u64) { pc += -226 }
    mov64 r1, 8                                     r1 = 8 as i32 as i64 as u64
    jge r2, r3, lbb_7370                            if r2 >= r3 { pc += -228 }
    ldxb r1, [r9+0x380]                     
    jeq r1, 0, lbb_7669                             if r1 == (0 as i32 as i64 as u64) { pc += 69 }
    ldxdw r3, [r9+0x378]                    
    mov64 r1, 7                                     r1 = 7 as i32 as i64 as u64
    jgt r3, 999999, lbb_7370                        if r3 > (999999 as i32 as i64 as u64) { pc += -233 }
    mov64 r1, 8                                     r1 = 8 as i32 as i64 as u64
    jge r3, r2, lbb_7370                            if r3 >= r2 { pc += -235 }
    ldxb r1, [r9+0x398]                     
    jeq r1, 0, lbb_7669                             if r1 == (0 as i32 as i64 as u64) { pc += 62 }
    ldxdw r2, [r9+0x390]                    
    mov64 r1, 7                                     r1 = 7 as i32 as i64 as u64
    jgt r2, 999999, lbb_7370                        if r2 > (999999 as i32 as i64 as u64) { pc += -240 }
    mov64 r1, 8                                     r1 = 8 as i32 as i64 as u64
    jge r2, r3, lbb_7370                            if r2 >= r3 { pc += -242 }
    ldxb r1, [r9+0x3b0]                     
    jeq r1, 0, lbb_7669                             if r1 == (0 as i32 as i64 as u64) { pc += 55 }
    ldxdw r3, [r9+0x3a8]                    
    mov64 r1, 7                                     r1 = 7 as i32 as i64 as u64
    jgt r3, 999999, lbb_7370                        if r3 > (999999 as i32 as i64 as u64) { pc += -247 }
    mov64 r1, 8                                     r1 = 8 as i32 as i64 as u64
    jge r3, r2, lbb_7370                            if r3 >= r2 { pc += -249 }
    ldxb r1, [r9+0x3c8]                     
    jeq r1, 0, lbb_7669                             if r1 == (0 as i32 as i64 as u64) { pc += 48 }
    ldxdw r2, [r9+0x3c0]                    
    mov64 r1, 7                                     r1 = 7 as i32 as i64 as u64
    jgt r2, 999999, lbb_7370                        if r2 > (999999 as i32 as i64 as u64) { pc += -254 }
    mov64 r1, 8                                     r1 = 8 as i32 as i64 as u64
    jge r2, r3, lbb_7370                            if r2 >= r3 { pc += -256 }
    ldxb r1, [r9+0x3e0]                     
    jeq r1, 0, lbb_7669                             if r1 == (0 as i32 as i64 as u64) { pc += 41 }
    ldxdw r3, [r9+0x3d8]                    
    mov64 r1, 7                                     r1 = 7 as i32 as i64 as u64
    jgt r3, 999999, lbb_7370                        if r3 > (999999 as i32 as i64 as u64) { pc += -261 }
    mov64 r1, 8                                     r1 = 8 as i32 as i64 as u64
    jge r3, r2, lbb_7370                            if r3 >= r2 { pc += -263 }
    ldxb r1, [r9+0x3f8]                     
    jeq r1, 0, lbb_7669                             if r1 == (0 as i32 as i64 as u64) { pc += 34 }
    ldxdw r2, [r9+0x3f0]                    
    mov64 r1, 7                                     r1 = 7 as i32 as i64 as u64
    jgt r2, 999999, lbb_7370                        if r2 > (999999 as i32 as i64 as u64) { pc += -268 }
    mov64 r1, 8                                     r1 = 8 as i32 as i64 as u64
    jge r2, r3, lbb_7370                            if r2 >= r3 { pc += -270 }
    ldxb r1, [r9+0x410]                     
    jeq r1, 0, lbb_7669                             if r1 == (0 as i32 as i64 as u64) { pc += 27 }
    ldxdw r3, [r9+0x408]                    
    mov64 r1, 7                                     r1 = 7 as i32 as i64 as u64
    jgt r3, 999999, lbb_7370                        if r3 > (999999 as i32 as i64 as u64) { pc += -275 }
    mov64 r1, 8                                     r1 = 8 as i32 as i64 as u64
    jge r3, r2, lbb_7370                            if r3 >= r2 { pc += -277 }
    ldxb r1, [r9+0x428]                     
    jeq r1, 0, lbb_7669                             if r1 == (0 as i32 as i64 as u64) { pc += 20 }
    ldxdw r2, [r9+0x420]                    
    mov64 r1, 7                                     r1 = 7 as i32 as i64 as u64
    jgt r2, 999999, lbb_7370                        if r2 > (999999 as i32 as i64 as u64) { pc += -282 }
    mov64 r1, 8                                     r1 = 8 as i32 as i64 as u64
    jge r2, r3, lbb_7370                            if r2 >= r3 { pc += -284 }
    ldxb r1, [r9+0x440]                     
    jeq r1, 0, lbb_7669                             if r1 == (0 as i32 as i64 as u64) { pc += 13 }
    ldxdw r3, [r9+0x438]                    
    mov64 r1, 7                                     r1 = 7 as i32 as i64 as u64
    jgt r3, 999999, lbb_7370                        if r3 > (999999 as i32 as i64 as u64) { pc += -289 }
    mov64 r1, 8                                     r1 = 8 as i32 as i64 as u64
    jge r3, r2, lbb_7370                            if r3 >= r2 { pc += -291 }
    ldxb r1, [r9+0x458]                     
    jeq r1, 0, lbb_7669                             if r1 == (0 as i32 as i64 as u64) { pc += 6 }
    ldxdw r2, [r9+0x450]                    
    mov64 r1, 7                                     r1 = 7 as i32 as i64 as u64
    jgt r2, 999999, lbb_7370                        if r2 > (999999 as i32 as i64 as u64) { pc += -296 }
    mov64 r1, 8                                     r1 = 8 as i32 as i64 as u64
    jgt r3, r2, lbb_7669                            if r3 > r2 { pc += 1 }
    ja lbb_7370                                     if true { pc += -299 }
lbb_7669:
    mov64 r1, r8                                    r1 = r8
    mov64 r2, 432                                   r2 = 432 as i32 as i64 as u64
    stxdw [r10-0xc78], r2                   
    jeq r1, 0, lbb_7675                             if r1 == (0 as i32 as i64 as u64) { pc += 2 }
    mov64 r2, 480                                   r2 = 480 as i32 as i64 as u64
    stxdw [r10-0xc78], r2                   
lbb_7675:
    jeq r1, 0, lbb_7678                             if r1 == (0 as i32 as i64 as u64) { pc += 2 }
    ldxdw r2, [r10-0xc38]                   
    stxdw [r10-0xc40], r2                   
lbb_7678:
    ldxdw r2, [r10-0xc30]                   
    stxdw [r10-0xc38], r2                   
    jeq r1, 0, lbb_7683                             if r1 == (0 as i32 as i64 as u64) { pc += 2 }
    ldxdw r2, [r10-0xc58]                   
    stxdw [r10-0xc38], r2                   
lbb_7683:
    jeq r1, 0, lbb_7686                             if r1 == (0 as i32 as i64 as u64) { pc += 2 }
    ldxdw r2, [r10-0xc30]                   
    stxdw [r10-0xc58], r2                   
lbb_7686:
    ldxdw r2, [r10-0xc18]                   
    stxdw [r10-0xc30], r2                   
    jeq r1, 0, lbb_7691                             if r1 == (0 as i32 as i64 as u64) { pc += 2 }
    ldxdw r2, [r10-0xc50]                   
    stxdw [r10-0xc30], r2                   
lbb_7691:
    jeq r1, 0, lbb_7694                             if r1 == (0 as i32 as i64 as u64) { pc += 2 }
    ldxdw r2, [r10-0xc18]                   
    stxdw [r10-0xc50], r2                   
lbb_7694:
    mov64 r3, 128                                   r3 = 128 as i32 as i64 as u64
    mov64 r2, 144                                   r2 = 144 as i32 as i64 as u64
    jeq r1, 0, lbb_7698                             if r1 == (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r2, 128                                   r2 = 128 as i32 as i64 as u64
lbb_7698:
    jeq r1, 0, lbb_7700                             if r1 == (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r3, 144                                   r3 = 144 as i32 as i64 as u64
lbb_7700:
    mov64 r4, 640                                   r4 = 640 as i32 as i64 as u64
    stxdw [r10-0xc80], r4                   
    jeq r1, 0, lbb_7705                             if r1 == (0 as i32 as i64 as u64) { pc += 2 }
    mov64 r4, 160                                   r4 = 160 as i32 as i64 as u64
    stxdw [r10-0xc80], r4                   
lbb_7705:
    mov64 r5, 1124                                  r5 = 1124 as i32 as i64 as u64
    mov64 r4, 22                                    r4 = 22 as i32 as i64 as u64
    jeq r1, 0, lbb_7709                             if r1 == (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r4, 1124                                  r4 = 1124 as i32 as i64 as u64
lbb_7709:
    jeq r1, 0, lbb_7711                             if r1 == (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r5, 22                                    r5 = 22 as i32 as i64 as u64
lbb_7711:
    mov64 r0, 1                                     r0 = 1 as i32 as i64 as u64
    mov64 r6, 1                                     r6 = 1 as i32 as i64 as u64
    jne r1, 0, lbb_7715                             if r1 != (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r6, 0                                     r6 = 0 as i32 as i64 as u64
lbb_7715:
    jeq r1, 0, lbb_7717                             if r1 == (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r0, 0                                     r0 = 0 as i32 as i64 as u64
lbb_7717:
    ldxdw r8, [r10-0xc28]                   
    stxdw [r10-0xc18], r8                   
    jeq r1, 0, lbb_7722                             if r1 == (0 as i32 as i64 as u64) { pc += 2 }
    ldxdw r8, [r10-0xc48]                   
    stxdw [r10-0xc18], r8                   
lbb_7722:
    jeq r1, 0, lbb_7725                             if r1 == (0 as i32 as i64 as u64) { pc += 2 }
    ldxdw r1, [r10-0xc28]                   
    stxdw [r10-0xc48], r1                   
lbb_7725:
    ldxdw r1, [r10-0xc48]                   
    ldxb r1, [r1+0x29]                      
    jeq r1, 0, lbb_7850                             if r1 == (0 as i32 as i64 as u64) { pc += 122 }
    ldxdw r1, [r10-0xc18]                   
    ldxb r1, [r1+0x29]                      
    jeq r1, 0, lbb_7850                             if r1 == (0 as i32 as i64 as u64) { pc += 119 }
    ldxdw r1, [r10-0xc50]                   
    ldxb r1, [r1+0x29]                      
    jeq r1, 0, lbb_7850                             if r1 == (0 as i32 as i64 as u64) { pc += 116 }
    ldxdw r1, [r10-0xc30]                   
    ldxb r1, [r1+0x29]                      
    jeq r1, 0, lbb_7850                             if r1 == (0 as i32 as i64 as u64) { pc += 113 }
    mov64 r1, r9                                    r1 = r9
    add64 r1, r5                                    r1 += r5   ///  r1 = r1.wrapping_add(r5)
    mov64 r5, r9                                    r5 = r9
    add64 r5, r3                                    r5 += r3   ///  r5 = r5.wrapping_add(r3)
    mov64 r3, r9                                    r3 = r9
    add64 r3, r2                                    r3 += r2   ///  r3 = r3.wrapping_add(r2)
    lsh64 r6, 3                                     r6 <<= 3   ///  r6 = r6.wrapping_shl(3)
    lsh64 r0, 3                                     r0 <<= 3   ///  r0 = r0.wrapping_shl(3)
    mov64 r2, r9                                    r2 = r9
    add64 r2, r0                                    r2 += r0   ///  r2 = r2.wrapping_add(r0)
    mov64 r0, r9                                    r0 = r9
    add64 r0, r4                                    r0 += r4   ///  r0 = r0.wrapping_add(r4)
    mov64 r8, r9                                    r8 = r9
    stxdw [r10-0xc88], r6                   
    add64 r8, r6                                    r8 += r6   ///  r8 = r8.wrapping_add(r6)
    ldxdw r4, [r3+0x8]                      
    stxdw [r10-0xc98], r4                   
    ldxdw r3, [r3+0x0]                      
    stxdw [r10-0xc90], r3                   
    ldxdw r3, [r5+0x8]                      
    stxdw [r10-0xca8], r3                   
    ldxdw r3, [r5+0x0]                      
    stxdw [r10-0xca0], r3                   
    ldxh r4, [r1+0x0]                       
    ldxh r6, [r0+0x0]                       
    ldxdw r1, [r8+0x0]                      
    stxdw [r10-0xc28], r1                   
    ldxdw r1, [r2+0x0]                      
    stxdw [r10-0xcb0], r1                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -2792                                 r1 += -2792   ///  r1 = r1.wrapping_add(-2792 as i32 as i64 as u64)
    ldxdw r2, [r10-0xc10]                   
    ldxdw r3, [r10-0xc18]                   
    call function_9118                      
    ldxdw r1, [r10-0xae8]                   
    lddw r2, 0x800000000000001a                     r2 load str located at -9223372036854775782
    lddw r8, 0x800000000000001a                     r8 load str located at -9223372036854775782
    jeq r1, r2, lbb_7778                            if r1 == r2 { pc += 1 }
    ja lbb_7839                                     if true { pc += 61 }
lbb_7778:
    mov64 r1, r10                                   r1 = r10
    add64 r1, -2792                                 r1 += -2792   ///  r1 = r1.wrapping_add(-2792 as i32 as i64 as u64)
    ldxdw r2, [r10-0xc10]                   
    ldxdw r3, [r10-0xc48]                   
    mov64 r4, r6                                    r4 = r6
    call function_9118                      
    ldxdw r1, [r10-0xae8]                   
    jeq r1, r8, lbb_7787                            if r1 == r8 { pc += 1 }
    ja lbb_7839                                     if true { pc += 52 }
lbb_7787:
    ldxdw r1, [r10-0xc58]                   
    ldxdw r6, [r1+0x10]                     
    ldxdw r1, [r6+0x10]                     
    lddw r2, 0x7fffffffffffffff                     r2 load str located at 9223372036854775807
    jgt r2, r1, lbb_7794                            if r2 > r1 { pc += 1 }
    ja lbb_8036                                     if true { pc += 242 }
lbb_7794:
    add64 r1, 1                                     r1 += 1   ///  r1 = r1.wrapping_add(1 as i32 as i64 as u64)
    stxdw [r6+0x10], r1                     
    ldxdw r3, [r6+0x20]                     
    ldxdw r2, [r6+0x18]                     
    mov64 r1, r10                                   r1 = r10
    add64 r1, -2792                                 r1 += -2792   ///  r1 = r1.wrapping_add(-2792 as i32 as i64 as u64)
    call function_146                       
    ldxw r1, [r10-0xae8]                    
    jeq r1, 2, lbb_7825                             if r1 == (2 as i32 as i64 as u64) { pc += 22 }
    ldxb r1, [r10-0xab8]                    
    stxdw [r10-0xcc0], r1                   
    ldxdw r1, [r6+0x10]                     
    add64 r1, -1                                    r1 += -1   ///  r1 = r1.wrapping_add(-1 as i32 as i64 as u64)
    stxdw [r6+0x10], r1                     
    ldxdw r1, [r10-0xc38]                   
    ldxdw r6, [r1+0x10]                     
    ldxdw r1, [r6+0x10]                     
    lddw r2, 0x7fffffffffffffff                     r2 load str located at 9223372036854775807
    jgt r2, r1, lbb_7815                            if r2 > r1 { pc += 1 }
    ja lbb_8039                                     if true { pc += 224 }
lbb_7815:
    add64 r1, 1                                     r1 += 1   ///  r1 = r1.wrapping_add(1 as i32 as i64 as u64)
    stxdw [r6+0x10], r1                     
    ldxdw r3, [r6+0x20]                     
    ldxdw r2, [r6+0x18]                     
    mov64 r1, r10                                   r1 = r10
    add64 r1, -2792                                 r1 += -2792   ///  r1 = r1.wrapping_add(-2792 as i32 as i64 as u64)
    call function_146                       
    ldxw r1, [r10-0xae8]                    
    jeq r1, 2, lbb_7825                             if r1 == (2 as i32 as i64 as u64) { pc += 1 }
    ja lbb_7852                                     if true { pc += 27 }
lbb_7825:
    ldxdw r1, [r10-0xad0]                   
    stxdw [r10-0x144], r1                   
    ldxdw r2, [r10-0xad8]                   
    stxdw [r10-0x14c], r2                   
    ldxdw r3, [r10-0xae0]                   
    stxdw [r10-0x154], r3                   
    ldxdw r4, [r10-0xc00]                   
    stxdw [r4+0x10], r1                     
    stxdw [r4+0x8], r2                      
    stxdw [r4+0x0], r3                      
    ldxdw r1, [r6+0x10]                     
    add64 r1, -1                                    r1 += -1   ///  r1 = r1.wrapping_add(-1 as i32 as i64 as u64)
    stxdw [r6+0x10], r1                     
    ja lbb_7847                                     if true { pc += 8 }
lbb_7839:
    ldxb r2, [r10-0xae0]                    
    ldxdw r3, [r10-0xad8]                   
    ldxdw r4, [r10-0xc00]                   
    stxdw [r4+0x10], r3                     
    ldxdw r3, [r10-0xadf]                   
    stxdw [r4+0x9], r3                      
    stxb [r4+0x8], r2                       
    stxdw [r4+0x0], r1                      
lbb_7847:
    ldxdw r1, [r7+0x10]                     
    add64 r1, 1                                     r1 += 1   ///  r1 = r1.wrapping_add(1 as i32 as i64 as u64)
    ja lbb_4418                                     if true { pc += -3432 }
lbb_7850:
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    ja lbb_7370                                     if true { pc += -482 }
lbb_7852:
    ldxb r1, [r10-0xab8]                    
    stxdw [r10-0xcd0], r1                   
    ldxdw r1, [r6+0x10]                     
    add64 r1, -1                                    r1 += -1   ///  r1 = r1.wrapping_add(-1 as i32 as i64 as u64)
    stxdw [r6+0x10], r1                     
    ldxdw r1, [r10-0xc18]                   
    ldxdw r1, [r1+0x10]                     
    stxdw [r10-0xcb8], r1                   
    ldxdw r1, [r1+0x10]                     
    lddw r2, 0x7fffffffffffffff                     r2 load str located at 9223372036854775807
    jgt r2, r1, lbb_7865                            if r2 > r1 { pc += 1 }
    ja lbb_8042                                     if true { pc += 177 }
lbb_7865:
    add64 r1, 1                                     r1 += 1   ///  r1 = r1.wrapping_add(1 as i32 as i64 as u64)
    ldxdw r2, [r10-0xcb8]                   
    stxdw [r2+0x10], r1                     
    ldxdw r3, [r2+0x20]                     
    ldxdw r2, [r2+0x18]                     
    mov64 r1, r10                                   r1 = r10
    add64 r1, -2792                                 r1 += -2792   ///  r1 = r1.wrapping_add(-2792 as i32 as i64 as u64)
    call function_0                         
    ldxw r6, [r10-0xa50]                    
    jeq r6, 2, lbb_7876                             if r6 == (2 as i32 as i64 as u64) { pc += 1 }
    ja lbb_7887                                     if true { pc += 11 }
lbb_7876:
    ldxdw r1, [r10-0xad8]                   
    stxdw [r10-0x148], r1                   
    ldxdw r2, [r10-0xae0]                   
    stxdw [r10-0x150], r2                   
    ldxdw r3, [r10-0xae8]                   
    stxdw [r10-0x158], r3                   
    ldxdw r4, [r10-0xc00]                   
    stxdw [r4+0x10], r1                     
    stxdw [r4+0x8], r2                      
    stxdw [r4+0x0], r3                      
    ja lbb_8192                                     if true { pc += 305 }
lbb_7887:
    mov64 r1, r10                                   r1 = r10
    add64 r1, -344                                  r1 += -344   ///  r1 = r1.wrapping_add(-344 as i32 as i64 as u64)
    stxdw [r10-0xcc8], r1                   
    mov64 r2, r10                                   r2 = r10
    add64 r2, -2792                                 r2 += -2792   ///  r2 = r2.wrapping_add(-2792 as i32 as i64 as u64)
    mov64 r3, 152                                   r3 = 152 as i32 as i64 as u64
    call function_30349                     
    mov64 r1, r10                                   r1 = r10
    add64 r1, -764                                  r1 += -764   ///  r1 = r1.wrapping_add(-764 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -2636                                 r2 += -2636   ///  r2 = r2.wrapping_add(-2636 as i32 as i64 as u64)
    mov64 r3, 36                                    r3 = 36 as i32 as i64 as u64
    call function_30349                     
    mov64 r1, r10                                   r1 = r10
    add64 r1, -920                                  r1 += -920   ///  r1 = r1.wrapping_add(-920 as i32 as i64 as u64)
    ldxdw r2, [r10-0xcc8]                   
    mov64 r3, 152                                   r3 = 152 as i32 as i64 as u64
    call function_30349                     
    stxw [r10-0x300], r6                    
    ldxdw r1, [r10-0xc48]                   
    ldxdw r1, [r1+0x10]                     
    stxdw [r10-0xcc8], r1                   
    ldxdw r1, [r1+0x10]                     
    lddw r2, 0x7fffffffffffffff                     r2 load str located at 9223372036854775807
    jgt r2, r1, lbb_7914                            if r2 > r1 { pc += 1 }
    ja lbb_8045                                     if true { pc += 131 }
lbb_7914:
    add64 r1, 1                                     r1 += 1   ///  r1 = r1.wrapping_add(1 as i32 as i64 as u64)
    ldxdw r2, [r10-0xcc8]                   
    stxdw [r2+0x10], r1                     
    ldxdw r3, [r2+0x20]                     
    ldxdw r2, [r2+0x18]                     
    mov64 r1, r10                                   r1 = r10
    add64 r1, -2792                                 r1 += -2792   ///  r1 = r1.wrapping_add(-2792 as i32 as i64 as u64)
    call function_0                         
    ldxw r6, [r10-0xa50]                    
    jeq r6, 2, lbb_7925                             if r6 == (2 as i32 as i64 as u64) { pc += 1 }
    ja lbb_7936                                     if true { pc += 11 }
lbb_7925:
    ldxdw r1, [r10-0xad8]                   
    stxdw [r10-0x148], r1                   
    ldxdw r2, [r10-0xae0]                   
    stxdw [r10-0x150], r2                   
    ldxdw r3, [r10-0xae8]                   
    stxdw [r10-0x158], r3                   
    ldxdw r4, [r10-0xc00]                   
    stxdw [r4+0x10], r1                     
    stxdw [r4+0x8], r2                      
    stxdw [r4+0x0], r3                      
    ja lbb_8188                                     if true { pc += 252 }
lbb_7936:
    mov64 r1, r10                                   r1 = r10
    add64 r1, -344                                  r1 += -344   ///  r1 = r1.wrapping_add(-344 as i32 as i64 as u64)
    stxdw [r10-0xcd8], r1                   
    mov64 r2, r10                                   r2 = r10
    add64 r2, -2792                                 r2 += -2792   ///  r2 = r2.wrapping_add(-2792 as i32 as i64 as u64)
    mov64 r3, 152                                   r3 = 152 as i32 as i64 as u64
    call function_30349                     
    mov64 r1, r10                                   r1 = r10
    add64 r1, -572                                  r1 += -572   ///  r1 = r1.wrapping_add(-572 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -2636                                 r2 += -2636   ///  r2 = r2.wrapping_add(-2636 as i32 as i64 as u64)
    mov64 r3, 36                                    r3 = 36 as i32 as i64 as u64
    call function_30349                     
    mov64 r1, r10                                   r1 = r10
    add64 r1, -728                                  r1 += -728   ///  r1 = r1.wrapping_add(-728 as i32 as i64 as u64)
    ldxdw r2, [r10-0xcd8]                   
    mov64 r3, 152                                   r3 = 152 as i32 as i64 as u64
    call function_30349                     
    stxw [r10-0x240], r6                    
    ldxdw r1, [r10-0xc50]                   
    ldxdw r1, [r1+0x10]                     
    stxdw [r10-0xcd8], r1                   
    ldxdw r1, [r1+0x10]                     
    lddw r2, 0x7fffffffffffffff                     r2 load str located at 9223372036854775807
    jgt r2, r1, lbb_7963                            if r2 > r1 { pc += 1 }
    ja lbb_8048                                     if true { pc += 85 }
lbb_7963:
    add64 r1, 1                                     r1 += 1   ///  r1 = r1.wrapping_add(1 as i32 as i64 as u64)
    ldxdw r2, [r10-0xcd8]                   
    stxdw [r2+0x10], r1                     
    ldxdw r3, [r2+0x20]                     
    ldxdw r2, [r2+0x18]                     
    mov64 r1, r10                                   r1 = r10
    add64 r1, -2792                                 r1 += -2792   ///  r1 = r1.wrapping_add(-2792 as i32 as i64 as u64)
    call function_0                         
    ldxw r1, [r10-0xa50]                    
    jeq r1, 2, lbb_7974                             if r1 == (2 as i32 as i64 as u64) { pc += 1 }
    ja lbb_7985                                     if true { pc += 11 }
lbb_7974:
    ldxdw r1, [r10-0xad8]                   
    stxdw [r10-0x148], r1                   
    ldxdw r2, [r10-0xae0]                   
    stxdw [r10-0x150], r2                   
    ldxdw r3, [r10-0xae8]                   
    stxdw [r10-0x158], r3                   
    ldxdw r4, [r10-0xc00]                   
    stxdw [r4+0x10], r1                     
    stxdw [r4+0x8], r2                      
    stxdw [r4+0x0], r3                      
    ja lbb_8184                                     if true { pc += 199 }
lbb_7985:
    mov64 r6, r10                                   r6 = r10
    add64 r6, -344                                  r6 += -344   ///  r6 = r6.wrapping_add(-344 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -2792                                 r2 += -2792   ///  r2 = r2.wrapping_add(-2792 as i32 as i64 as u64)
    mov64 r1, r6                                    r1 = r6
    mov64 r3, 152                                   r3 = 152 as i32 as i64 as u64
    call function_30349                     
    mov64 r1, r10                                   r1 = r10
    add64 r1, -380                                  r1 += -380   ///  r1 = r1.wrapping_add(-380 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -2636                                 r2 += -2636   ///  r2 = r2.wrapping_add(-2636 as i32 as i64 as u64)
    mov64 r3, 36                                    r3 = 36 as i32 as i64 as u64
    call function_30349                     
    mov64 r1, r10                                   r1 = r10
    add64 r1, -536                                  r1 += -536   ///  r1 = r1.wrapping_add(-536 as i32 as i64 as u64)
    mov64 r2, r6                                    r2 = r6
    mov64 r3, 152                                   r3 = 152 as i32 as i64 as u64
    call function_30349                     
    ldxdw r1, [r10-0xc30]                   
    ldxdw r1, [r1+0x10]                     
    stxdw [r10-0xce0], r1                   
    ldxdw r1, [r1+0x10]                     
    lddw r2, 0x7fffffffffffffff                     r2 load str located at 9223372036854775807
    jgt r2, r1, lbb_8011                            if r2 > r1 { pc += 1 }
    ja lbb_8051                                     if true { pc += 40 }
lbb_8011:
    add64 r1, 1                                     r1 += 1   ///  r1 = r1.wrapping_add(1 as i32 as i64 as u64)
    ldxdw r2, [r10-0xce0]                   
    stxdw [r2+0x10], r1                     
    ldxdw r3, [r2+0x20]                     
    ldxdw r2, [r2+0x18]                     
    mov64 r1, r10                                   r1 = r10
    add64 r1, -2792                                 r1 += -2792   ///  r1 = r1.wrapping_add(-2792 as i32 as i64 as u64)
    call function_0                         
    ldxw r1, [r10-0xa50]                    
    jeq r1, 2, lbb_8022                             if r1 == (2 as i32 as i64 as u64) { pc += 1 }
    ja lbb_8054                                     if true { pc += 32 }
lbb_8022:
    ldxdw r1, [r10-0xad8]                   
    stxdw [r10-0x88], r1                    
    ldxdw r2, [r10-0xae0]                   
    stxdw [r10-0x90], r2                    
    ldxdw r3, [r10-0xae8]                   
    stxdw [r10-0x98], r3                    
    ldxdw r4, [r10-0xc00]                   
    stxdw [r4+0x10], r1                     
    stxdw [r4+0x8], r2                      
    stxdw [r4+0x0], r3                      
    ja lbb_8180                                     if true { pc += 147 }
lbb_8033:
    lddw r1, 0x100041300 --> b"\x00\x00\x00\x000\xe7\x03\x00\x10\x00\x00\x00\x00\x00\x00\x00\x9c\x03\x00…        r1 load str located at 4295234304
    call function_25324                     
lbb_8036:
    lddw r1, 0x1000412e8 --> b"\x00\x00\x00\x000\xe7\x03\x00\x10\x00\x00\x00\x00\x00\x00\x00\xe7\x03\x00…        r1 load str located at 4295234280
    call function_25345                     
lbb_8039:
    lddw r1, 0x1000412d0 --> b"\x00\x00\x00\x000\xe7\x03\x00\x10\x00\x00\x00\x00\x00\x00\x00\xed\x03\x00…        r1 load str located at 4295234256
    call function_25345                     
lbb_8042:
    lddw r1, 0x1000412b8 --> b"\x00\x00\x00\x000\xe7\x03\x00\x10\x00\x00\x00\x00\x00\x00\x00\xf3\x03\x00…        r1 load str located at 4295234232
    call function_25345                     
lbb_8045:
    lddw r1, 0x1000412a0 --> b"\x00\x00\x00\x000\xe7\x03\x00\x10\x00\x00\x00\x00\x00\x00\x00\xf6\x03\x00…        r1 load str located at 4295234208
    call function_25345                     
lbb_8048:
    lddw r1, 0x100041288 --> b"\x00\x00\x00\x000\xe7\x03\x00\x10\x00\x00\x00\x00\x00\x00\x00\xfa\x03\x00…        r1 load str located at 4295234184
    call function_25345                     
lbb_8051:
    lddw r1, 0x100041270 --> b"\x00\x00\x00\x000\xe7\x03\x00\x10\x00\x00\x00\x00\x00\x00\x00\xfd\x03\x00…        r1 load str located at 4295234160
    call function_25345                     
lbb_8054:
    mov64 r6, r10                                   r6 = r10
    add64 r6, -152                                  r6 += -152   ///  r6 = r6.wrapping_add(-152 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -2792                                 r2 += -2792   ///  r2 = r2.wrapping_add(-2792 as i32 as i64 as u64)
    mov64 r1, r6                                    r1 = r6
    mov64 r3, 152                                   r3 = 152 as i32 as i64 as u64
    call function_30349                     
    mov64 r1, r10                                   r1 = r10
    add64 r1, -188                                  r1 += -188   ///  r1 = r1.wrapping_add(-188 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -2636                                 r2 += -2636   ///  r2 = r2.wrapping_add(-2636 as i32 as i64 as u64)
    mov64 r3, 36                                    r3 = 36 as i32 as i64 as u64
    call function_30349                     
    mov64 r1, r10                                   r1 = r10
    add64 r1, -344                                  r1 += -344   ///  r1 = r1.wrapping_add(-344 as i32 as i64 as u64)
    mov64 r2, r6                                    r2 = r6
    mov64 r3, 152                                   r3 = 152 as i32 as i64 as u64
    call function_30349                     
    ldxdw r1, [r10-0xc20]                   
    ldxdw r1, [r1+0x0]                      
    ldxdw r2, [r1+0x0]                      
    ldxdw r3, [r10-0x1e8]                   
    jeq r3, r2, lbb_8081                            if r3 == r2 { pc += 4 }
lbb_8077:
    mov64 r2, 1                                     r2 = 1 as i32 as i64 as u64
    jeq r2, 0, lbb_8093                             if r2 == (0 as i32 as i64 as u64) { pc += 14 }
lbb_8079:
    mov64 r1, 4                                     r1 = 4 as i32 as i64 as u64
    ja lbb_8175                                     if true { pc += 94 }
lbb_8081:
    ldxdw r2, [r1+0x8]                      
    ldxdw r3, [r10-0x1e0]                   
    jne r3, r2, lbb_8077                            if r3 != r2 { pc += -7 }
    ldxdw r2, [r1+0x10]                     
    ldxdw r3, [r10-0x1d8]                   
    jne r3, r2, lbb_8077                            if r3 != r2 { pc += -10 }
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
    ldxdw r1, [r1+0x18]                     
    ldxdw r3, [r10-0x1d0]                   
    jne r3, r1, lbb_8077                            if r3 != r1 { pc += -14 }
    jeq r2, 0, lbb_8093                             if r2 == (0 as i32 as i64 as u64) { pc += 1 }
    ja lbb_8079                                     if true { pc += -14 }
lbb_8093:
    ldxdw r1, [r10-0x388]                   
    ldxdw r2, [r10-0x208]                   
    jeq r2, r1, lbb_8127                            if r2 == r1 { pc += 31 }
lbb_8096:
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    jeq r1, 0, lbb_8099                             if r1 == (0 as i32 as i64 as u64) { pc += 1 }
    ja lbb_8174                                     if true { pc += 75 }
lbb_8099:
    ldxdw r1, [r10-0x2c8]                   
    ldxdw r2, [r10-0x148]                   
    jeq r2, r1, lbb_8139                            if r2 == r1 { pc += 37 }
lbb_8102:
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    jeq r1, 0, lbb_8105                             if r1 == (0 as i32 as i64 as u64) { pc += 1 }
    ja lbb_8174                                     if true { pc += 69 }
lbb_8105:
    ldxdw r1, [r10-0xc58]                   
    ldxdw r1, [r1+0x0]                      
    ldxdw r2, [r1+0x0]                      
    ldxdw r3, [r10-0x208]                   
    jeq r3, r2, lbb_8151                            if r3 == r2 { pc += 41 }
lbb_8110:
    mov64 r2, 1                                     r2 = 1 as i32 as i64 as u64
    jeq r2, 0, lbb_8113                             if r2 == (0 as i32 as i64 as u64) { pc += 1 }
    ja lbb_8174                                     if true { pc += 61 }
lbb_8113:
    ldxdw r1, [r10-0xc38]                   
    ldxdw r1, [r1+0x0]                      
    ldxdw r2, [r1+0x0]                      
    ldxdw r3, [r10-0x148]                   
    jeq r3, r2, lbb_8163                            if r3 == r2 { pc += 45 }
lbb_8118:
    mov64 r2, 1                                     r2 = 1 as i32 as i64 as u64
    jeq r2, 0, lbb_8121                             if r2 == (0 as i32 as i64 as u64) { pc += 1 }
    ja lbb_8174                                     if true { pc += 53 }
lbb_8121:
    ldxdw r1, [r10-0x1c8]                   
    ldxdw r2, [r10-0xc68]                   
    jgt r2, r1, lbb_8125                            if r2 > r1 { pc += 1 }
    ja lbb_8197                                     if true { pc += 72 }
lbb_8125:
    mov64 r1, 65535                                 r1 = 65535 as i32 as i64 as u64
    ja lbb_8175                                     if true { pc += 48 }
lbb_8127:
    ldxdw r1, [r10-0x380]                   
    ldxdw r2, [r10-0x200]                   
    jne r2, r1, lbb_8096                            if r2 != r1 { pc += -34 }
    ldxdw r1, [r10-0x378]                   
    ldxdw r2, [r10-0x1f8]                   
    jne r2, r1, lbb_8096                            if r2 != r1 { pc += -37 }
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    ldxdw r2, [r10-0x370]                   
    ldxdw r3, [r10-0x1f0]                   
    jne r3, r2, lbb_8096                            if r3 != r2 { pc += -41 }
    jeq r1, 0, lbb_8099                             if r1 == (0 as i32 as i64 as u64) { pc += -39 }
    ja lbb_8174                                     if true { pc += 35 }
lbb_8139:
    ldxdw r1, [r10-0x2c0]                   
    ldxdw r2, [r10-0x140]                   
    jne r2, r1, lbb_8102                            if r2 != r1 { pc += -40 }
    ldxdw r1, [r10-0x2b8]                   
    ldxdw r2, [r10-0x138]                   
    jne r2, r1, lbb_8102                            if r2 != r1 { pc += -43 }
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    ldxdw r2, [r10-0x2b0]                   
    ldxdw r3, [r10-0x130]                   
    jne r3, r2, lbb_8102                            if r3 != r2 { pc += -47 }
    jeq r1, 0, lbb_8105                             if r1 == (0 as i32 as i64 as u64) { pc += -45 }
    ja lbb_8174                                     if true { pc += 23 }
lbb_8151:
    ldxdw r2, [r1+0x8]                      
    ldxdw r3, [r10-0x200]                   
    jne r3, r2, lbb_8110                            if r3 != r2 { pc += -44 }
    ldxdw r2, [r1+0x10]                     
    ldxdw r3, [r10-0x1f8]                   
    jne r3, r2, lbb_8110                            if r3 != r2 { pc += -47 }
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
    ldxdw r1, [r1+0x18]                     
    ldxdw r3, [r10-0x1f0]                   
    jne r3, r1, lbb_8110                            if r3 != r1 { pc += -51 }
    jeq r2, 0, lbb_8113                             if r2 == (0 as i32 as i64 as u64) { pc += -49 }
    ja lbb_8174                                     if true { pc += 11 }
lbb_8163:
    ldxdw r2, [r1+0x8]                      
    ldxdw r3, [r10-0x140]                   
    jne r3, r2, lbb_8118                            if r3 != r2 { pc += -48 }
    ldxdw r2, [r1+0x10]                     
    ldxdw r3, [r10-0x138]                   
    jne r3, r2, lbb_8118                            if r3 != r2 { pc += -51 }
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
    ldxdw r1, [r1+0x18]                     
    ldxdw r3, [r10-0x130]                   
    jne r3, r1, lbb_8118                            if r3 != r1 { pc += -55 }
    jeq r2, 0, lbb_8121                             if r2 == (0 as i32 as i64 as u64) { pc += -53 }
lbb_8174:
    mov64 r1, 5                                     r1 = 5 as i32 as i64 as u64
lbb_8175:
    ldxdw r2, [r10-0xc00]                   
    stxw [r2+0x8], r1                       
lbb_8177:
    lddw r1, 0x8000000000000000                     r1 load str located at -9223372036854775808
    stxdw [r2+0x0], r1                      
lbb_8180:
    ldxdw r2, [r10-0xce0]                   
    ldxdw r1, [r2+0x10]                     
    add64 r1, -1                                    r1 += -1   ///  r1 = r1.wrapping_add(-1 as i32 as i64 as u64)
    stxdw [r2+0x10], r1                     
lbb_8184:
    ldxdw r2, [r10-0xcd8]                   
    ldxdw r1, [r2+0x10]                     
    add64 r1, -1                                    r1 += -1   ///  r1 = r1.wrapping_add(-1 as i32 as i64 as u64)
    stxdw [r2+0x10], r1                     
lbb_8188:
    ldxdw r2, [r10-0xcc8]                   
    ldxdw r1, [r2+0x10]                     
    add64 r1, -1                                    r1 += -1   ///  r1 = r1.wrapping_add(-1 as i32 as i64 as u64)
    stxdw [r2+0x10], r1                     
lbb_8192:
    ldxdw r2, [r10-0xcb8]                   
    ldxdw r1, [r2+0x10]                     
    add64 r1, -1                                    r1 += -1   ///  r1 = r1.wrapping_add(-1 as i32 as i64 as u64)
    stxdw [r2+0x10], r1                     
    ja lbb_7847                                     if true { pc += -350 }
lbb_8197:
    mov64 r1, r10                                   r1 = r10
    add64 r1, -2792                                 r1 += -2792   ///  r1 = r1.wrapping_add(-2792 as i32 as i64 as u64)
    mov64 r3, r10                                   r3 = r10
    add64 r3, -1496                                 r3 += -1496   ///  r3 = r3.wrapping_add(-1496 as i32 as i64 as u64)
    ldxdw r2, [r10-0xc10]                   
    ldxdw r4, [r10-0xc60]                   
    call function_10618                     
    ldxb r1, [r10-0xae0]                    
    ldxdw r2, [r10-0xae8]                   
    lddw r3, 0x800000000000001a                     r3 load str located at -9223372036854775782
    jeq r2, r3, lbb_8210                            if r2 == r3 { pc += 1 }
    ja lbb_8316                                     if true { pc += 106 }
lbb_8210:
    mov64 r6, 0                                     r6 = 0 as i32 as i64 as u64
    jeq r1, 0, lbb_8213                             if r1 == (0 as i32 as i64 as u64) { pc += 1 }
    ldxw r6, [r9+0x10]                      
lbb_8213:
    ldxb r1, [r10-0xadf]                    
    stxdw [r10-0xc10], r1                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -2792                                 r1 += -2792   ///  r1 = r1.wrapping_add(-2792 as i32 as i64 as u64)
    call function_17171                     
    ldxdw r4, [r10-0xae0]                   
    ldxdw r1, [r10-0xae8]                   
    jne r1, 0, lbb_8326                             if r1 != (0 as i32 as i64 as u64) { pc += 105 }
    ldxdw r3, [r9+0x78]                     
    mov64 r2, r9                                    r2 = r9
    add64 r2, 88                                    r2 += 88   ///  r2 = r2.wrapping_add(88 as i32 as i64 as u64)
    mov64 r1, r10                                   r1 = r10
    add64 r1, -2936                                 r1 += -2936   ///  r1 = r1.wrapping_add(-2936 as i32 as i64 as u64)
    call function_9783                      
    ldxw r1, [r10-0xb78]                    
    jeq r1, 0, lbb_8447                             if r1 == (0 as i32 as i64 as u64) { pc += 218 }
    ldxw r1, [r10-0xb74]                    
    mov64 r2, r6                                    r2 = r6
    lsh64 r2, 32                                    r2 <<= 32   ///  r2 = r2.wrapping_shl(32)
    rsh64 r2, 32                                    r2 >>= 32   ///  r2 = r2.wrapping_shr(32)
    add64 r2, r1                                    r2 += r1   ///  r2 = r2.wrapping_add(r1)
    mov64 r1, r2                                    r1 = r2
    lsh64 r1, 32                                    r1 <<= 32   ///  r1 = r1.wrapping_shl(32)
    rsh64 r1, 32                                    r1 >>= 32   ///  r1 = r1.wrapping_shr(32)
    stxdw [r10-0xc60], r2                   
    jne r1, r2, lbb_8447                            if r1 != r2 { pc += 208 }
    ldxb r1, [r9+0x466]                     
    jeq r1, 1, lbb_8242                             if r1 == (1 as i32 as i64 as u64) { pc += 1 }
    ja lbb_8292                                     if true { pc += 50 }
lbb_8242:
    mov64 r1, r10                                   r1 = r10
    add64 r1, -2968                                 r1 += -2968   ///  r1 = r1.wrapping_add(-2968 as i32 as i64 as u64)
    ldxdw r2, [r10-0xca8]                   
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
    ldxdw r6, [r10-0xcb0]                   
    mov64 r4, r6                                    r4 = r6
    mov64 r5, 0                                     r5 = 0 as i32 as i64 as u64
    call function_31300                     
    mov64 r1, r10                                   r1 = r10
    add64 r1, -2952                                 r1 += -2952   ///  r1 = r1.wrapping_add(-2952 as i32 as i64 as u64)
    mov64 r2, r6                                    r2 = r6
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
    ldxdw r4, [r10-0xca0]                   
    mov64 r5, 0                                     r5 = 0 as i32 as i64 as u64
    call function_31300                     
    mov64 r2, 1                                     r2 = 1 as i32 as i64 as u64
    ldxdw r3, [r10-0xb90]                   
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    jne r3, 0, lbb_8262                             if r3 != (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
lbb_8262:
    ldxdw r4, [r10-0xb80]                   
    ldxdw r5, [r10-0xb98]                   
    mov64 r3, r4                                    r3 = r4
    add64 r3, r5                                    r3 += r5   ///  r3 = r3.wrapping_add(r5)
    jgt r4, r3, lbb_8268                            if r4 > r3 { pc += 1 }
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
lbb_8268:
    or64 r1, r2                                     r1 |= r2   ///  r1 = r1.or(r2)
    and64 r1, 1                                     r1 &= 1   ///  r1 = r1.and(1)
    jne r1, 0, lbb_8447                             if r1 != (0 as i32 as i64 as u64) { pc += 176 }
    lddw r1, 0x38d7ea4c67fff                        r1 load str located at 999999999999999
    jgt r3, r1, lbb_8333                            if r3 > r1 { pc += 59 }
    ldxdw r2, [r10-0xb88]                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -2984                                 r1 += -2984   ///  r1 = r1.wrapping_add(-2984 as i32 as i64 as u64)
    mov64 r6, 0                                     r6 = 0 as i32 as i64 as u64
    lddw r4, 0x38d7ea4c68000                        r4 load str located at 1000000000000000
    mov64 r5, 0                                     r5 = 0 as i32 as i64 as u64
    call function_30496                     
    ldxdw r2, [r10-0xba8]                   
    ldxdw r8, [r10-0xc28]                   
    mov64 r1, r8                                    r1 = r8
    sub64 r1, r2                                    r1 -= r2   ///  r1 = r1.wrapping_sub(r2)
    mov64 r2, 1                                     r2 = 1 as i32 as i64 as u64
    jgt r1, r8, lbb_8289                            if r1 > r8 { pc += 1 }
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
lbb_8289:
    jne r2, 0, lbb_8291                             if r2 != (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r6, r1                                    r6 = r1
lbb_8291:
    stxdw [r10-0xc28], r6                   
lbb_8292:
    mov64 r1, r9                                    r1 = r9
    ldxdw r2, [r10-0xc80]                   
    add64 r1, r2                                    r1 += r2   ///  r1 = r1.wrapping_add(r2)
    ldxdw r2, [r10-0xc10]                   
    mov64 r3, r2                                    r3 = r2
    mov64 r2, 1                                     r2 = 1 as i32 as i64 as u64
    jne r3, 0, lbb_8300                             if r3 != (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
lbb_8300:
    mov64 r3, 15                                    r3 = 15 as i32 as i64 as u64
    stxdw [r10-0xff0], r3                   
    stxdw [r10-0xff8], r1                   
    ldxdw r1, [r10-0xc98]                   
    stxdw [r10-0x1000], r1                  
    stxdw [r10-0xfe8], r2                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -3000                                 r1 += -3000   ///  r1 = r1.wrapping_add(-3000 as i32 as i64 as u64)
    mov64 r5, r10                                   r5 = r10
    ldxdw r2, [r10-0xc28]                   
    ldxdw r3, [r10-0xc68]                   
    ldxdw r4, [r10-0xc90]                   
    call function_9466                      
    ldxdw r1, [r10-0xbb8]                   
    jne r1, 0, lbb_8343                             if r1 != (0 as i32 as i64 as u64) { pc += 28 }
    ja lbb_8447                                     if true { pc += 131 }
lbb_8316:
    ldxb r3, [r10-0xadf]                    
    ldxdw r4, [r10-0xad8]                   
    ldxdw r5, [r10-0xc00]                   
    stxdw [r5+0x10], r4                     
    ldxdw r4, [r10-0xade]                   
    stxdw [r5+0xa], r4                      
    stxb [r5+0x9], r3                       
    stxb [r5+0x8], r1                       
    stxdw [r5+0x0], r2                      
    ja lbb_8180                                     if true { pc += -146 }
lbb_8326:
    ldxdw r1, [r10-0xad8]                   
    ldxdw r2, [r10-0xad0]                   
    ldxdw r3, [r10-0xc00]                   
    stxdw [r3+0x10], r2                     
    stxdw [r3+0x8], r1                      
    stxdw [r3+0x0], r4                      
    ja lbb_8180                                     if true { pc += -153 }
lbb_8333:
    mov64 r3, r10                                   r3 = r10
    add64 r3, -2792                                 r3 += -2792   ///  r3 = r3.wrapping_add(-2792 as i32 as i64 as u64)
    lddw r1, 0x10003e80a --> b"called `Result::unwrap()` on an `Err` value"        r1 load str located at 4295223306
    mov64 r2, 43                                    r2 = 43 as i32 as i64 as u64
    lddw r4, 0x100041220 --> b"\x00\x00\x00\x00\xd0\x0f\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x01\x00\…        r4 load str located at 4295234080
    lddw r5, 0x100041240 --> b"\x00\x00\x00\x000\xe7\x03\x00\x10\x00\x00\x00\x00\x00\x00\x004\x04\x00\x0…        r5 load str located at 4295234112
    call function_25967                     
lbb_8343:
    ldxdw r4, [r10-0xbb0]                   
    ldxdw r1, [r10-0xc60]                   
    lsh64 r1, 32                                    r1 <<= 32   ///  r1 = r1.wrapping_shl(32)
    rsh64 r1, 32                                    r1 >>= 32   ///  r1 = r1.wrapping_shr(32)
    jne r1, 0, lbb_8445                             if r1 != (0 as i32 as i64 as u64) { pc += 97 }
lbb_8348:
    ldxdw r1, [r10-0x288]                   
    mov64 r6, r4                                    r6 = r4
    jgt r1, r4, lbb_8352                            if r1 > r4 { pc += 1 }
    mov64 r6, r1                                    r6 = r1
lbb_8352:
    ldxdw r2, [r10-0xc10]                   
    jeq r2, 0, lbb_8355                             if r2 == (0 as i32 as i64 as u64) { pc += 1 }
    jgt r4, r1, lbb_8125                            if r4 > r1 { pc += -230 }
lbb_8355:
    ldxdw r1, [r10-0xc70]                   
    jgt r1, r6, lbb_8125                            if r1 > r6 { pc += -232 }
    jeq r6, 0, lbb_8125                             if r6 == (0 as i32 as i64 as u64) { pc += -233 }
    ldxdw r2, [r10-0xcb8]                   
    ldxdw r1, [r2+0x10]                     
    add64 r1, -1                                    r1 += -1   ///  r1 = r1.wrapping_add(-1 as i32 as i64 as u64)
    stxdw [r2+0x10], r1                     
    ldxdw r2, [r10-0xcc8]                   
    ldxdw r1, [r2+0x10]                     
    add64 r1, -1                                    r1 += -1   ///  r1 = r1.wrapping_add(-1 as i32 as i64 as u64)
    stxdw [r2+0x10], r1                     
    ldxdw r2, [r10-0xcd8]                   
    ldxdw r1, [r2+0x10]                     
    add64 r1, -1                                    r1 += -1   ///  r1 = r1.wrapping_add(-1 as i32 as i64 as u64)
    stxdw [r2+0x10], r1                     
    ldxdw r2, [r10-0xce0]                   
    ldxdw r1, [r2+0x10]                     
    add64 r1, -1                                    r1 += -1   ///  r1 = r1.wrapping_add(-1 as i32 as i64 as u64)
    stxdw [r2+0x10], r1                     
    ldxdw r1, [r10-0xc40]                   
    ldxdw r1, [r1+0x0]                      
    ldxdw r2, [r10-0xc68]                   
    stxdw [r10-0xff0], r2                   
    ldxdw r2, [r10-0xcc0]                   
    stxdw [r10-0xfe8], r2                   
    stxdw [r10-0xff8], r1                   
    ldxdw r1, [r10-0xc18]                   
    stxdw [r10-0x1000], r1                  
    mov64 r1, r10                                   r1 = r10
    add64 r1, -2792                                 r1 += -2792   ///  r1 = r1.wrapping_add(-2792 as i32 as i64 as u64)
    mov64 r5, r10                                   r5 = r10
    ldxdw r2, [r10-0xc58]                   
    ldxdw r3, [r10-0xc50]                   
    ldxdw r4, [r10-0xc20]                   
    call function_10358                     
    lddw r8, 0x800000000000001a                     r8 load str located at -9223372036854775782
    ldxdw r1, [r10-0xae8]                   
    jne r1, r8, lbb_8451                            if r1 != r8 { pc += 57 }
    ldxdw r3, [r10-0xc08]                   
    mov64 r1, r3                                    r1 = r3
    ldxdw r2, [r10-0xc78]                   
    add64 r1, r2                                    r1 += r2   ///  r1 = r1.wrapping_add(r2)
    ldxdw r1, [r1+0x0]                      
    stxdw [r10-0xfe0], r6                   
    ldxdw r2, [r10-0xcd0]                   
    stxdw [r10-0xfd8], r2                   
    stxdw [r10-0xfe8], r1                   
    ldxdw r1, [r10-0xc30]                   
    stxdw [r10-0xff0], r1                   
    ldxdw r1, [r10-0xc48]                   
    stxdw [r10-0xff8], r1                   
    mov64 r1, 2                                     r1 = 2 as i32 as i64 as u64
    stxdw [r10-0x1000], r1                  
    mov64 r1, r10                                   r1 = r10
    add64 r1, -2792                                 r1 += -2792   ///  r1 = r1.wrapping_add(-2792 as i32 as i64 as u64)
    mov64 r4, r10                                   r4 = r10
    add64 r4, -952                                  r4 += -952   ///  r4 = r4.wrapping_add(-952 as i32 as i64 as u64)
    mov64 r5, r10                                   r5 = r10
    ldxdw r2, [r10-0xc38]                   
    call function_10085                     
    ldxdw r1, [r10-0xae8]                   
    jeq r1, r8, lbb_8419                            if r1 == r8 { pc += 1 }
    ja lbb_8451                                     if true { pc += 32 }
lbb_8419:
    ldxw r2, [r9+0x460]                     
    mov64 r1, r10                                   r1 = r10
    add64 r1, -3048                                 r1 += -3048   ///  r1 = r1.wrapping_add(-3048 as i32 as i64 as u64)
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
    ldxdw r4, [r10-0xc68]                   
    mov64 r5, 0                                     r5 = 0 as i32 as i64 as u64
    call function_31300                     
    ldxdw r3, [r10-0xbe0]                   
    jgt r3, 999999, lbb_8459                        if r3 > (999999 as i32 as i64 as u64) { pc += 31 }
    ldxdw r2, [r10-0xbe8]                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -3064                                 r1 += -3064   ///  r1 = r1.wrapping_add(-3064 as i32 as i64 as u64)
    mov64 r4, 1000000                               r4 = 1000000 as i32 as i64 as u64
    mov64 r5, 0                                     r5 = 0 as i32 as i64 as u64
    call function_30496                     
    ldxdw r1, [r10-0xc88]                   
    add64 r9, r1                                    r9 += r1   ///  r9 = r9.wrapping_add(r1)
    ldxdw r1, [r9+0x0]                      
    ldxdw r2, [r10-0xbf8]                   
    add64 r1, r2                                    r1 += r2   ///  r1 = r1.wrapping_add(r2)
    stxdw [r9+0x0], r1                      
    lddw r2, 0x800000000000001a                     r2 load str located at -9223372036854775782
    ldxdw r1, [r10-0xc00]                   
    stxdw [r1+0x0], r2                      
    ja lbb_7847                                     if true { pc += -598 }
lbb_8445:
    mov64 r2, 1000001                               r2 = 1000001 as i32 as i64 as u64
    jgt r2, r1, lbb_8469                            if r2 > r1 { pc += 22 }
lbb_8447:
    mov64 r1, 65535                                 r1 = 65535 as i32 as i64 as u64
    ldxdw r2, [r10-0xc00]                   
    stxdw [r2+0x8], r1                      
    ja lbb_8177                                     if true { pc += -274 }
lbb_8451:
    ldxdw r1, [r10-0xad8]                   
    ldxdw r2, [r10-0xc00]                   
    stxdw [r2+0x10], r1                     
    ldxdw r1, [r10-0xae0]                   
    stxdw [r2+0x8], r1                      
    ldxdw r1, [r10-0xae8]                   
    stxdw [r2+0x0], r1                      
    ja lbb_7847                                     if true { pc += -612 }
lbb_8459:
    mov64 r3, r10                                   r3 = r10
    add64 r3, -2792                                 r3 += -2792   ///  r3 = r3.wrapping_add(-2792 as i32 as i64 as u64)
    lddw r1, 0x10003e80a --> b"called `Result::unwrap()` on an `Err` value"        r1 load str located at 4295223306
    mov64 r2, 43                                    r2 = 43 as i32 as i64 as u64
    lddw r4, 0x100041220 --> b"\x00\x00\x00\x00\xd0\x0f\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x01\x00\…        r4 load str located at 4295234080
    lddw r5, 0x100041258 --> b"\x00\x00\x00\x000\xe7\x03\x00\x10\x00\x00\x00\x00\x00\x00\x00\x81\x04\x00…        r5 load str located at 4295234136
    call function_25967                     
lbb_8469:
    ldxdw r2, [r10-0xc60]                   
    lsh64 r2, 32                                    r2 <<= 32   ///  r2 = r2.wrapping_shl(32)
    rsh64 r2, 32                                    r2 >>= 32   ///  r2 = r2.wrapping_shr(32)
    mov64 r3, 1                                     r3 = 1 as i32 as i64 as u64
    mov64 r1, r2                                    r1 = r2
    jgt r2, 1000000, lbb_8476                       if r2 > (1000000 as i32 as i64 as u64) { pc += 1 }
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
lbb_8476:
    neg64 r3                                        r3 = -r3   ///  r3 = (r3 as i64).wrapping_neg() as u64
    mov64 r2, 1000000                               r2 = 1000000 as i32 as i64 as u64
    sub64 r2, r1                                    r2 -= r1   ///  r2 = r2.wrapping_sub(r1)
    mov64 r1, r10                                   r1 = r10
    add64 r1, -3016                                 r1 += -3016   ///  r1 = r1.wrapping_add(-3016 as i32 as i64 as u64)
    mov64 r5, 0                                     r5 = 0 as i32 as i64 as u64
    call function_31300                     
    mov64 r1, r10                                   r1 = r10
    add64 r1, -3032                                 r1 += -3032   ///  r1 = r1.wrapping_add(-3032 as i32 as i64 as u64)
    ldxdw r2, [r10-0xbc8]                   
    ldxdw r3, [r10-0xbc0]                   
    mov64 r4, 1000000                               r4 = 1000000 as i32 as i64 as u64
    mov64 r5, 0                                     r5 = 0 as i32 as i64 as u64
    call function_30496                     
    ldxdw r4, [r10-0xbd8]                   
    ja lbb_8348                                     if true { pc += -144 }

function_8492:
    mov64 r6, r5                                    r6 = r5
    stxdw [r10-0xe8], r4                    
    stxdw [r10-0xe0], r3                    
    mov64 r8, r2                                    r8 = r2
    mov64 r7, r1                                    r7 = r1
    mov64 r1, r10                                   r1 = r10
    add64 r1, -136                                  r1 += -136   ///  r1 = r1.wrapping_add(-136 as i32 as i64 as u64)
    call function_17194                     
    ldxdw r9, [r10-0x78]                    
    ldxdw r1, [r10-0x80]                    
    ldxdw r2, [r10-0x88]                    
    jne r2, 0, lbb_8558                             if r2 != (0 as i32 as i64 as u64) { pc += 54 }
    stxdw [r10-0xf8], r8                    
    ldxdw r2, [r10-0xe8]                    
    ldxdw r2, [r10-0xe0]                    
    stxdw [r10-0x110], r7                   
    ldxdw r8, [r6-0xff0]                    
    ldxdw r2, [r6-0xff8]                    
    stxdw [r10-0x108], r2                   
    ldxdw r2, [r6-0x1000]                   
    stxdw [r10-0x100], r2                   
    mov64 r2, r8                                    r2 = r8
    add64 r2, 128                                   r2 += 128   ///  r2 = r2.wrapping_add(128 as i32 as i64 as u64)
    mul64 r1, r2                                    r1 *= r2   ///  r1 = r1.wrapping_mul(r2)
    call function_31715                     
    mov64 r1, r9                                    r1 = r9
    mov64 r2, r0                                    r2 = r0
    call function_31778                     
    mov64 r9, r0                                    r9 = r0
    mov64 r7, 0                                     r7 = 0 as i32 as i64 as u64
    mov64 r1, r9                                    r1 = r9
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
    call function_31628                     
    mov64 r6, r0                                    r6 = r0
    mov64 r1, r9                                    r1 = r9
    call function_30472                     
    jsgt r7, r6, lbb_8530                           if (r7 as i64) > (r6 as i64) { pc += 1 }
    mov64 r7, r0                                    r7 = r0
lbb_8530:
    mov64 r1, r9                                    r1 = r9
    lddw r2, 0x43efffffffffffff                     r2 load str located at 4895412794951729151
    call function_31594                     
    mov64 r9, -1                                    r9 = -1 as i32 as i64 as u64
    jsgt r0, 0, lbb_8537                            if (r0 as i64) > (0 as i32 as i64) { pc += 1 }
    mov64 r9, r7                                    r9 = r7
lbb_8537:
    ldxdw r7, [r10-0xe0]                    
    mov64 r1, r7                                    r1 = r7
    call function_17715                     
    jeq r0, 0, lbb_8649                             if r0 == (0 as i32 as i64 as u64) { pc += 108 }
    ldxdw r1, [r7+0x0]                      
    stxdw [r10-0xf0], r1                    
    jgt r9, r0, lbb_8794                            if r9 > r0 { pc += 250 }
    ldxdw r6, [r7+0x8]                      
lbb_8545:
    mov64 r1, r10                                   r1 = r10
    add64 r1, -136                                  r1 += -136   ///  r1 = r1.wrapping_add(-136 as i32 as i64 as u64)
    ldxdw r2, [r10-0xf0]                    
    mov64 r3, r8                                    r3 = r8
    call function_19456                     
    ldxdw r2, [r6+0x0]                      
    add64 r2, 1                                     r2 += 1   ///  r2 = r2.wrapping_add(1 as i32 as i64 as u64)
    stxdw [r6+0x0], r2                      
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    jeq r2, 0, lbb_8556                             if r2 == (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
lbb_8556:
    jne r1, 1, lbb_8571                             if r1 != (1 as i32 as i64 as u64) { pc += 14 }
    ja lbb_8671                                     if true { pc += 113 }
lbb_8558:
    ldxw r2, [r10-0x6f]                     
    stxw [r10-0xd8], r2                     
    ldxw r2, [r10-0x6c]                     
    stxw [r10-0xd5], r2                     
    ldxb r2, [r10-0x70]                     
    ldxw r3, [r10-0xd5]                     
    stxw [r7+0x14], r3                      
    ldxw r3, [r10-0xd8]                     
    stxw [r7+0x11], r3                      
    stxb [r7+0x10], r2                      
    stxdw [r7+0x8], r9                      
    stxdw [r7+0x0], r1                      
lbb_8570:
    exit                                    
lbb_8571:
    ldxdw r8, [r7+0x10]                     
    ldxdw r1, [r8+0x0]                      
    add64 r1, 1                                     r1 += 1   ///  r1 = r1.wrapping_add(1 as i32 as i64 as u64)
    mov64 r2, 1                                     r2 = 1 as i32 as i64 as u64
    jeq r1, 0, lbb_8577                             if r1 == (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
lbb_8577:
    stxdw [r8+0x0], r1                      
    jne r2, 1, lbb_8580                             if r2 != (1 as i32 as i64 as u64) { pc += 1 }
    ja lbb_8671                                     if true { pc += 91 }
lbb_8580:
    ldxdw r2, [r7+0x18]                     
    ldxdw r3, [r7+0x20]                     
    ldxb r4, [r7+0x28]                      
    ldxb r9, [r7+0x29]                      
    ldxb r7, [r7+0x2a]                      
    stxdw [r10-0xc8], r8                    
    stxdw [r10-0xd0], r6                    
    ldxdw r1, [r10-0xf0]                    
    stxdw [r10-0xd8], r1                    
    stxb [r10-0xae], r7                     
    stxb [r10-0xaf], r9                     
    stxdw [r10-0x118], r4                   
    stxb [r10-0xb0], r4                     
    stxdw [r10-0xf8], r3                    
    stxdw [r10-0xb8], r3                    
    stxdw [r10-0xe0], r2                    
    stxdw [r10-0xc0], r2                    
    ldxdw r1, [r10-0x108]                   
    stxdw [r10-0x8], r1                     
    ldxdw r1, [r10-0x100]                   
    stxdw [r10-0x10], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -16                                   r1 += -16   ///  r1 = r1.wrapping_add(-16 as i32 as i64 as u64)
    stxdw [r10-0x1000], r1                  
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    stxdw [r10-0xff8], r1                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -40                                   r1 += -40   ///  r1 = r1.wrapping_add(-40 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -136                                  r2 += -136   ///  r2 = r2.wrapping_add(-136 as i32 as i64 as u64)
    mov64 r3, r10                                   r3 = r10
    add64 r3, -216                                  r3 += -216   ///  r3 = r3.wrapping_add(-216 as i32 as i64 as u64)
    mov64 r5, r10                                   r5 = r10
    mov64 r4, 1                                     r4 = 1 as i32 as i64 as u64
    call function_16486                     
    lddw r1, 0x800000000000001a                     r1 load str located at -9223372036854775782
    ldxdw r2, [r10-0x28]                    
    jeq r2, r1, lbb_8620                            if r2 == r1 { pc += 1 }
    ja lbb_8935                                     if true { pc += 315 }
lbb_8620:
    ldxdw r1, [r10-0xc8]                    
    ldxdw r2, [r10-0xd0]                    
    ldxdw r3, [r2+0x0]                      
    add64 r3, -1                                    r3 += -1   ///  r3 = r3.wrapping_add(-1 as i32 as i64 as u64)
    stxdw [r2+0x0], r3                      
    jne r3, 0, lbb_8629                             if r3 != (0 as i32 as i64 as u64) { pc += 3 }
    ldxdw r3, [r2+0x8]                      
    add64 r3, -1                                    r3 += -1   ///  r3 = r3.wrapping_add(-1 as i32 as i64 as u64)
    stxdw [r2+0x8], r3                      
lbb_8629:
    ldxdw r2, [r1+0x0]                      
    add64 r2, -1                                    r2 += -1   ///  r2 = r2.wrapping_add(-1 as i32 as i64 as u64)
    stxdw [r1+0x0], r2                      
    ldxdw r3, [r10-0xe8]                    
    jne r2, 0, lbb_8637                             if r2 != (0 as i32 as i64 as u64) { pc += 3 }
    ldxdw r2, [r1+0x8]                      
    add64 r2, -1                                    r2 += -1   ///  r2 = r2.wrapping_add(-1 as i32 as i64 as u64)
    stxdw [r1+0x8], r2                      
lbb_8637:
    mov64 r1, r10                                   r1 = r10
    add64 r1, -136                                  r1 += -136   ///  r1 = r1.wrapping_add(-136 as i32 as i64 as u64)
    ldxdw r2, [r10-0xf0]                    
    call function_19364                     
    ldxdw r2, [r6+0x0]                      
    add64 r2, 1                                     r2 += 1   ///  r2 = r2.wrapping_add(1 as i32 as i64 as u64)
    stxdw [r6+0x0], r2                      
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    jeq r2, 0, lbb_8647                             if r2 == (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
lbb_8647:
    jne r1, 1, lbb_8956                             if r1 != (1 as i32 as i64 as u64) { pc += 308 }
    ja lbb_8671                                     if true { pc += 22 }
lbb_8649:
    ldxdw r3, [r7+0x0]                      
    ldxdw r1, [r10-0xf8]                    
    ldxdw r2, [r1+0x0]                      
    stxdw [r10-0x1000], r8                  
    mov64 r8, r1                                    r8 = r1
    ldxdw r1, [r10-0xe8]                    
    stxdw [r10-0xff8], r1                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -216                                  r1 += -216   ///  r1 = r1.wrapping_add(-216 as i32 as i64 as u64)
    mov64 r5, r10                                   r5 = r10
    stxdw [r10-0x118], r2                   
    stxdw [r10-0x120], r3                   
    mov64 r4, r9                                    r4 = r9
    call function_19305                     
    ldxdw r9, [r8+0x8]                      
    ldxdw r1, [r9+0x0]                      
    add64 r1, 1                                     r1 += 1   ///  r1 = r1.wrapping_add(1 as i32 as i64 as u64)
    mov64 r2, 1                                     r2 = 1 as i32 as i64 as u64
    jeq r1, 0, lbb_8669                             if r1 == (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
lbb_8669:
    stxdw [r9+0x0], r1                      
    jne r2, 1, lbb_8672                             if r2 != (1 as i32 as i64 as u64) { pc += 1 }
lbb_8671:
    syscall [invalid]                       
lbb_8672:
    ldxdw r3, [r8+0x10]                     
    ldxdw r1, [r3+0x0]                      
    add64 r1, 1                                     r1 += 1   ///  r1 = r1.wrapping_add(1 as i32 as i64 as u64)
    mov64 r2, 1                                     r2 = 1 as i32 as i64 as u64
    jeq r1, 0, lbb_8678                             if r1 == (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
lbb_8678:
    stxdw [r3+0x0], r1                      
    jne r2, 1, lbb_8681                             if r2 != (1 as i32 as i64 as u64) { pc += 1 }
    ja lbb_8671                                     if true { pc += -10 }
lbb_8681:
    stxdw [r10-0xe8], r3                    
    ldxdw r2, [r7+0x8]                      
    ldxdw r0, [r2+0x0]                      
    add64 r0, 1                                     r0 += 1   ///  r0 = r0.wrapping_add(1 as i32 as i64 as u64)
    mov64 r7, 1                                     r7 = 1 as i32 as i64 as u64
    jeq r0, 0, lbb_8688                             if r0 == (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r7, 0                                     r7 = 0 as i32 as i64 as u64
lbb_8688:
    ldxb r1, [r8+0x2a]                      
    stxdw [r10-0x130], r1                   
    ldxb r1, [r8+0x29]                      
    stxdw [r10-0x128], r1                   
    ldxb r3, [r8+0x28]                      
    ldxdw r5, [r8+0x20]                     
    ldxdw r4, [r8+0x18]                     
    stxdw [r2+0x0], r0                      
    jne r7, 1, lbb_8698                             if r7 != (1 as i32 as i64 as u64) { pc += 1 }
    ja lbb_8671                                     if true { pc += -27 }
lbb_8698:
    ldxdw r1, [r10-0xe0]                    
    ldxdw r1, [r1+0x10]                     
    mov64 r6, r1                                    r6 = r1
    ldxdw r0, [r1+0x0]                      
    add64 r0, 1                                     r0 += 1   ///  r0 = r0.wrapping_add(1 as i32 as i64 as u64)
    mov64 r7, 1                                     r7 = 1 as i32 as i64 as u64
    jeq r0, 0, lbb_8706                             if r0 == (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r7, 0                                     r7 = 0 as i32 as i64 as u64
lbb_8706:
    mov64 r8, r3                                    r8 = r3
    stxdw [r10-0xf0], r2                    
    stxdw [r6+0x0], r0                      
    jne r7, 1, lbb_8711                             if r7 != (1 as i32 as i64 as u64) { pc += 1 }
    ja lbb_8671                                     if true { pc += -40 }
lbb_8711:
    ldxdw r3, [r10-0xe0]                    
    ldxdw r0, [r3+0x18]                     
    ldxdw r7, [r3+0x20]                     
    ldxb r1, [r3+0x28]                      
    ldxb r2, [r3+0x29]                      
    ldxb r3, [r3+0x2a]                      
    stxb [r10-0x2e], r3                     
    stxb [r10-0x2f], r2                     
    stxb [r10-0x30], r1                     
    stxdw [r10-0x38], r7                    
    stxdw [r10-0x40], r0                    
    stxdw [r10-0x48], r6                    
    ldxdw r1, [r10-0xf0]                    
    stxdw [r10-0x50], r1                    
    ldxdw r1, [r10-0x120]                   
    stxdw [r10-0x58], r1                    
    ldxdw r1, [r10-0x130]                   
    stxb [r10-0x5e], r1                     
    ldxdw r1, [r10-0x128]                   
    stxb [r10-0x5f], r1                     
    stxb [r10-0x60], r8                     
    stxdw [r10-0x68], r5                    
    stxdw [r10-0x70], r4                    
    ldxdw r1, [r10-0xe8]                    
    stxdw [r10-0x78], r1                    
    stxdw [r10-0x80], r9                    
    ldxdw r1, [r10-0x118]                   
    stxdw [r10-0x88], r1                    
    ldxdw r1, [r10-0x108]                   
    stxdw [r10-0x8], r1                     
    ldxdw r1, [r10-0x100]                   
    stxdw [r10-0x10], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -16                                   r1 += -16   ///  r1 = r1.wrapping_add(-16 as i32 as i64 as u64)
    stxdw [r10-0x1000], r1                  
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    stxdw [r10-0xff8], r1                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -40                                   r1 += -40   ///  r1 = r1.wrapping_add(-40 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -216                                  r2 += -216   ///  r2 = r2.wrapping_add(-216 as i32 as i64 as u64)
    mov64 r3, r10                                   r3 = r10
    add64 r3, -136                                  r3 += -136   ///  r3 = r3.wrapping_add(-136 as i32 as i64 as u64)
    mov64 r5, r10                                   r5 = r10
    mov64 r4, 2                                     r4 = 2 as i32 as i64 as u64
    call function_16486                     
    lddw r1, 0x800000000000001a                     r1 load str located at -9223372036854775782
    ldxdw r2, [r10-0x28]                    
    jeq r2, r1, lbb_8762                            if r2 == r1 { pc += 1 }
    ja lbb_9018                                     if true { pc += 256 }
lbb_8762:
    ldxdw r1, [r9+0x0]                      
    add64 r1, -1                                    r1 += -1   ///  r1 = r1.wrapping_add(-1 as i32 as i64 as u64)
    stxdw [r9+0x0], r1                      
    ldxdw r2, [r10-0x110]                   
    jne r1, 0, lbb_8770                             if r1 != (0 as i32 as i64 as u64) { pc += 3 }
    ldxdw r1, [r9+0x8]                      
    add64 r1, -1                                    r1 += -1   ///  r1 = r1.wrapping_add(-1 as i32 as i64 as u64)
    stxdw [r9+0x8], r1                      
lbb_8770:
    ldxdw r5, [r10-0xe8]                    
    ldxdw r1, [r5+0x0]                      
    add64 r1, -1                                    r1 += -1   ///  r1 = r1.wrapping_add(-1 as i32 as i64 as u64)
    stxdw [r5+0x0], r1                      
    ldxdw r3, [r10-0xf0]                    
    jne r1, 0, lbb_8779                             if r1 != (0 as i32 as i64 as u64) { pc += 3 }
    ldxdw r1, [r5+0x8]                      
    add64 r1, -1                                    r1 += -1   ///  r1 = r1.wrapping_add(-1 as i32 as i64 as u64)
    stxdw [r5+0x8], r1                      
lbb_8779:
    ldxdw r1, [r3+0x0]                      
    add64 r1, -1                                    r1 += -1   ///  r1 = r1.wrapping_add(-1 as i32 as i64 as u64)
    stxdw [r3+0x0], r1                      
    jne r1, 0, lbb_8786                             if r1 != (0 as i32 as i64 as u64) { pc += 3 }
    ldxdw r1, [r3+0x8]                      
    add64 r1, -1                                    r1 += -1   ///  r1 = r1.wrapping_add(-1 as i32 as i64 as u64)
    stxdw [r3+0x8], r1                      
lbb_8786:
    ldxdw r1, [r6+0x0]                      
    add64 r1, -1                                    r1 += -1   ///  r1 = r1.wrapping_add(-1 as i32 as i64 as u64)
    stxdw [r6+0x0], r1                      
    jne r1, 0, lbb_9014                             if r1 != (0 as i32 as i64 as u64) { pc += 224 }
    ldxdw r1, [r6+0x8]                      
    add64 r1, -1                                    r1 += -1   ///  r1 = r1.wrapping_add(-1 as i32 as i64 as u64)
    stxdw [r6+0x8], r1                      
    ja lbb_9014                                     if true { pc += 220 }
lbb_8794:
    mov64 r1, r9                                    r1 = r9
    sub64 r1, r0                                    r1 -= r0   ///  r1 = r1.wrapping_sub(r0)
    mov64 r6, 1                                     r6 = 1 as i32 as i64 as u64
    mov64 r2, 1                                     r2 = 1 as i32 as i64 as u64
    jgt r1, r9, lbb_8800                            if r1 > r9 { pc += 1 }
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
lbb_8800:
    mov64 r4, 0                                     r4 = 0 as i32 as i64 as u64
    jne r2, 0, lbb_8803                             if r2 != (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r4, r1                                    r4 = r1
lbb_8803:
    ldxdw r9, [r10-0xf8]                    
    ldxdw r2, [r9+0x0]                      
    mov64 r1, r10                                   r1 = r10
    add64 r1, -216                                  r1 += -216   ///  r1 = r1.wrapping_add(-216 as i32 as i64 as u64)
    stxdw [r10-0x118], r2                   
    ldxdw r3, [r10-0xf0]                    
    call function_19408                     
    ldxdw r5, [r9+0x8]                      
    ldxdw r2, [r5+0x0]                      
    add64 r2, 1                                     r2 += 1   ///  r2 = r2.wrapping_add(1 as i32 as i64 as u64)
    jeq r2, 0, lbb_8815                             if r2 == (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r6, 0                                     r6 = 0 as i32 as i64 as u64
lbb_8815:
    stxdw [r5+0x0], r2                      
    jne r6, 1, lbb_8818                             if r6 != (1 as i32 as i64 as u64) { pc += 1 }
    ja lbb_8671                                     if true { pc += -147 }
lbb_8818:
    ldxdw r2, [r10-0xf8]                    
    ldxdw r2, [r2+0x10]                     
    ldxdw r3, [r2+0x0]                      
    add64 r3, 1                                     r3 += 1   ///  r3 = r3.wrapping_add(1 as i32 as i64 as u64)
    mov64 r4, 1                                     r4 = 1 as i32 as i64 as u64
    jeq r3, 0, lbb_8825                             if r3 == (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r4, 0                                     r4 = 0 as i32 as i64 as u64
lbb_8825:
    stxdw [r2+0x0], r3                      
    jne r4, 1, lbb_8828                             if r4 != (1 as i32 as i64 as u64) { pc += 1 }
    ja lbb_8671                                     if true { pc += -157 }
lbb_8828:
    ldxdw r0, [r7+0x8]                      
    ldxdw r7, [r0+0x0]                      
    add64 r7, 1                                     r7 += 1   ///  r7 = r7.wrapping_add(1 as i32 as i64 as u64)
    mov64 r3, 1                                     r3 = 1 as i32 as i64 as u64
    jeq r7, 0, lbb_8834                             if r7 == (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
lbb_8834:
    ldxdw r4, [r10-0xf8]                    
    ldxb r1, [r4+0x2a]                      
    stxdw [r10-0x128], r1                   
    ldxb r1, [r4+0x29]                      
    stxdw [r10-0x120], r1                   
    ldxb r6, [r4+0x28]                      
    ldxdw r1, [r4+0x20]                     
    ldxdw r9, [r4+0x18]                     
    stxdw [r0+0x0], r7                      
    jne r3, 1, lbb_8845                             if r3 != (1 as i32 as i64 as u64) { pc += 1 }
    ja lbb_8671                                     if true { pc += -174 }
lbb_8845:
    stxdw [r10-0x130], r6                   
    stxdw [r10-0xf8], r0                    
    ldxdw r3, [r10-0xe0]                    
    ldxdw r7, [r3+0x10]                     
    ldxdw r3, [r7+0x0]                      
    add64 r3, 1                                     r3 += 1   ///  r3 = r3.wrapping_add(1 as i32 as i64 as u64)
    mov64 r4, 1                                     r4 = 1 as i32 as i64 as u64
    jeq r3, 0, lbb_8854                             if r3 == (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r4, 0                                     r4 = 0 as i32 as i64 as u64
lbb_8854:
    mov64 r6, r5                                    r6 = r5
    stxdw [r10-0x138], r8                   
    stxdw [r7+0x0], r3                      
    jne r4, 1, lbb_8859                             if r4 != (1 as i32 as i64 as u64) { pc += 1 }
    ja lbb_8671                                     if true { pc += -188 }
lbb_8859:
    ldxdw r8, [r10-0xe0]                    
    ldxdw r3, [r8+0x18]                     
    ldxdw r4, [r8+0x20]                     
    ldxb r5, [r8+0x28]                      
    ldxb r0, [r8+0x29]                      
    ldxb r8, [r8+0x2a]                      
    stxb [r10-0x2e], r8                     
    stxb [r10-0x2f], r0                     
    stxb [r10-0x30], r5                     
    stxdw [r10-0x38], r4                    
    stxdw [r10-0x40], r3                    
    stxdw [r10-0x48], r7                    
    ldxdw r3, [r10-0xf8]                    
    stxdw [r10-0x50], r3                    
    ldxdw r3, [r10-0xf0]                    
    stxdw [r10-0x58], r3                    
    ldxdw r3, [r10-0x128]                   
    stxb [r10-0x5e], r3                     
    ldxdw r3, [r10-0x120]                   
    stxb [r10-0x5f], r3                     
    ldxdw r3, [r10-0x130]                   
    stxb [r10-0x60], r3                     
    stxdw [r10-0x68], r1                    
    stxdw [r10-0x70], r9                    
    stxdw [r10-0x78], r2                    
    stxdw [r10-0x80], r6                    
    ldxdw r1, [r10-0x118]                   
    stxdw [r10-0x88], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -40                                   r1 += -40   ///  r1 = r1.wrapping_add(-40 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -216                                  r2 += -216   ///  r2 = r2.wrapping_add(-216 as i32 as i64 as u64)
    mov64 r3, r10                                   r3 = r10
    add64 r3, -136                                  r3 += -136   ///  r3 = r3.wrapping_add(-136 as i32 as i64 as u64)
    mov64 r4, 2                                     r4 = 2 as i32 as i64 as u64
    call function_16479                     
    lddw r1, 0x800000000000001a                     r1 load str located at -9223372036854775782
    ldxdw r2, [r10-0x28]                    
    jne r2, r1, lbb_9056                            if r2 != r1 { pc += 157 }
    ldxdw r1, [r10-0x78]                    
    ldxdw r2, [r10-0x80]                    
    ldxdw r3, [r2+0x0]                      
    add64 r3, -1                                    r3 += -1   ///  r3 = r3.wrapping_add(-1 as i32 as i64 as u64)
    stxdw [r2+0x0], r3                      
    jne r3, 0, lbb_8908                             if r3 != (0 as i32 as i64 as u64) { pc += 3 }
    ldxdw r3, [r2+0x8]                      
    add64 r3, -1                                    r3 += -1   ///  r3 = r3.wrapping_add(-1 as i32 as i64 as u64)
    stxdw [r2+0x8], r3                      
lbb_8908:
    ldxdw r2, [r1+0x0]                      
    add64 r2, -1                                    r2 += -1   ///  r2 = r2.wrapping_add(-1 as i32 as i64 as u64)
    stxdw [r1+0x0], r2                      
    ldxdw r7, [r10-0xe0]                    
    ldxdw r8, [r10-0x138]                   
    ldxdw r6, [r10-0xf8]                    
    jne r2, 0, lbb_8918                             if r2 != (0 as i32 as i64 as u64) { pc += 3 }
    ldxdw r2, [r1+0x8]                      
    add64 r2, -1                                    r2 += -1   ///  r2 = r2.wrapping_add(-1 as i32 as i64 as u64)
    stxdw [r1+0x8], r2                      
lbb_8918:
    ldxdw r1, [r10-0x48]                    
    ldxdw r2, [r10-0x50]                    
    ldxdw r3, [r2+0x0]                      
    add64 r3, -1                                    r3 += -1   ///  r3 = r3.wrapping_add(-1 as i32 as i64 as u64)
    stxdw [r2+0x0], r3                      
    jne r3, 0, lbb_8927                             if r3 != (0 as i32 as i64 as u64) { pc += 3 }
    ldxdw r3, [r2+0x8]                      
    add64 r3, -1                                    r3 += -1   ///  r3 = r3.wrapping_add(-1 as i32 as i64 as u64)
    stxdw [r2+0x8], r3                      
lbb_8927:
    ldxdw r2, [r1+0x0]                      
    add64 r2, -1                                    r2 += -1   ///  r2 = r2.wrapping_add(-1 as i32 as i64 as u64)
    stxdw [r1+0x0], r2                      
    jne r2, 0, lbb_8545                             if r2 != (0 as i32 as i64 as u64) { pc += -386 }
    ldxdw r2, [r1+0x8]                      
    add64 r2, -1                                    r2 += -1   ///  r2 = r2.wrapping_add(-1 as i32 as i64 as u64)
    stxdw [r1+0x8], r2                      
    ja lbb_8545                                     if true { pc += -390 }
lbb_8935:
    ldxdw r1, [r10-0x18]                    
    ldxdw r2, [r10-0x110]                   
    stxdw [r2+0x10], r1                     
    ldxdw r1, [r10-0x20]                    
    stxdw [r2+0x8], r1                      
    ldxdw r1, [r10-0x28]                    
    stxdw [r2+0x0], r1                      
    ldxdw r1, [r10-0xc8]                    
    ldxdw r2, [r10-0xd0]                    
    ldxdw r3, [r2+0x0]                      
    add64 r3, -1                                    r3 += -1   ///  r3 = r3.wrapping_add(-1 as i32 as i64 as u64)
    stxdw [r2+0x0], r3                      
    jne r3, 0, lbb_8951                             if r3 != (0 as i32 as i64 as u64) { pc += 3 }
    ldxdw r3, [r2+0x8]                      
    add64 r3, -1                                    r3 += -1   ///  r3 = r3.wrapping_add(-1 as i32 as i64 as u64)
    stxdw [r2+0x8], r3                      
lbb_8951:
    ldxdw r2, [r1+0x0]                      
    add64 r2, -1                                    r2 += -1   ///  r2 = r2.wrapping_add(-1 as i32 as i64 as u64)
    stxdw [r1+0x0], r2                      
    jne r2, 0, lbb_8570                             if r2 != (0 as i32 as i64 as u64) { pc += -385 }
    ja lbb_9092                                     if true { pc += 136 }
lbb_8956:
    ldxdw r2, [r8+0x0]                      
    add64 r2, 1                                     r2 += 1   ///  r2 = r2.wrapping_add(1 as i32 as i64 as u64)
    stxdw [r8+0x0], r2                      
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    jeq r2, 0, lbb_8962                             if r2 == (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
lbb_8962:
    jne r1, 1, lbb_8964                             if r1 != (1 as i32 as i64 as u64) { pc += 1 }
    ja lbb_8671                                     if true { pc += -293 }
lbb_8964:
    stxb [r10-0xae], r7                     
    stxb [r10-0xaf], r9                     
    ldxdw r1, [r10-0x118]                   
    stxb [r10-0xb0], r1                     
    ldxdw r1, [r10-0xf8]                    
    stxdw [r10-0xb8], r1                    
    ldxdw r1, [r10-0xe0]                    
    stxdw [r10-0xc0], r1                    
    stxdw [r10-0xc8], r8                    
    stxdw [r10-0xd0], r6                    
    ldxdw r1, [r10-0xf0]                    
    stxdw [r10-0xd8], r1                    
    ldxdw r1, [r10-0x108]                   
    stxdw [r10-0x8], r1                     
    ldxdw r1, [r10-0x100]                   
    stxdw [r10-0x10], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -16                                   r1 += -16   ///  r1 = r1.wrapping_add(-16 as i32 as i64 as u64)
    stxdw [r10-0x1000], r1                  
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    stxdw [r10-0xff8], r1                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -40                                   r1 += -40   ///  r1 = r1.wrapping_add(-40 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -136                                  r2 += -136   ///  r2 = r2.wrapping_add(-136 as i32 as i64 as u64)
    mov64 r3, r10                                   r3 = r10
    add64 r3, -216                                  r3 += -216   ///  r3 = r3.wrapping_add(-216 as i32 as i64 as u64)
    mov64 r5, r10                                   r5 = r10
    mov64 r4, 1                                     r4 = 1 as i32 as i64 as u64
    call function_16486                     
    lddw r1, 0x800000000000001a                     r1 load str located at -9223372036854775782
    ldxdw r2, [r10-0x28]                    
    jeq r2, r1, lbb_8999                            if r2 == r1 { pc += 1 }
    ja lbb_9096                                     if true { pc += 97 }
lbb_8999:
    ldxdw r1, [r6+0x0]                      
    add64 r1, -1                                    r1 += -1   ///  r1 = r1.wrapping_add(-1 as i32 as i64 as u64)
    stxdw [r6+0x0], r1                      
    ldxdw r2, [r10-0x110]                   
    jne r1, 0, lbb_9007                             if r1 != (0 as i32 as i64 as u64) { pc += 3 }
    ldxdw r1, [r6+0x8]                      
    add64 r1, -1                                    r1 += -1   ///  r1 = r1.wrapping_add(-1 as i32 as i64 as u64)
    stxdw [r6+0x8], r1                      
lbb_9007:
    ldxdw r1, [r8+0x0]                      
    add64 r1, -1                                    r1 += -1   ///  r1 = r1.wrapping_add(-1 as i32 as i64 as u64)
    stxdw [r8+0x0], r1                      
    jne r1, 0, lbb_9014                             if r1 != (0 as i32 as i64 as u64) { pc += 3 }
    ldxdw r1, [r8+0x8]                      
    add64 r1, -1                                    r1 += -1   ///  r1 = r1.wrapping_add(-1 as i32 as i64 as u64)
    stxdw [r8+0x8], r1                      
lbb_9014:
    lddw r1, 0x800000000000001a                     r1 load str located at -9223372036854775782
    stxdw [r2+0x0], r1                      
    ja lbb_8570                                     if true { pc += -448 }
lbb_9018:
    ldxdw r1, [r10-0x18]                    
    ldxdw r2, [r10-0x110]                   
    stxdw [r2+0x10], r1                     
    ldxdw r1, [r10-0x20]                    
    stxdw [r2+0x8], r1                      
    ldxdw r1, [r10-0x28]                    
    stxdw [r2+0x0], r1                      
    ldxdw r1, [r9+0x0]                      
    add64 r1, -1                                    r1 += -1   ///  r1 = r1.wrapping_add(-1 as i32 as i64 as u64)
    stxdw [r9+0x0], r1                      
    jne r1, 0, lbb_9032                             if r1 != (0 as i32 as i64 as u64) { pc += 3 }
    ldxdw r1, [r9+0x8]                      
    add64 r1, -1                                    r1 += -1   ///  r1 = r1.wrapping_add(-1 as i32 as i64 as u64)
    stxdw [r9+0x8], r1                      
lbb_9032:
    ldxdw r3, [r10-0xe8]                    
    ldxdw r1, [r3+0x0]                      
    add64 r1, -1                                    r1 += -1   ///  r1 = r1.wrapping_add(-1 as i32 as i64 as u64)
    stxdw [r3+0x0], r1                      
    ldxdw r2, [r10-0xf0]                    
    jne r1, 0, lbb_9041                             if r1 != (0 as i32 as i64 as u64) { pc += 3 }
    ldxdw r1, [r3+0x8]                      
    add64 r1, -1                                    r1 += -1   ///  r1 = r1.wrapping_add(-1 as i32 as i64 as u64)
    stxdw [r3+0x8], r1                      
lbb_9041:
    ldxdw r1, [r2+0x0]                      
    add64 r1, -1                                    r1 += -1   ///  r1 = r1.wrapping_add(-1 as i32 as i64 as u64)
    stxdw [r2+0x0], r1                      
    jne r1, 0, lbb_9048                             if r1 != (0 as i32 as i64 as u64) { pc += 3 }
    ldxdw r1, [r2+0x8]                      
    add64 r1, -1                                    r1 += -1   ///  r1 = r1.wrapping_add(-1 as i32 as i64 as u64)
    stxdw [r2+0x8], r1                      
lbb_9048:
    ldxdw r1, [r6+0x0]                      
    add64 r1, -1                                    r1 += -1   ///  r1 = r1.wrapping_add(-1 as i32 as i64 as u64)
    stxdw [r6+0x0], r1                      
    jne r1, 0, lbb_8570                             if r1 != (0 as i32 as i64 as u64) { pc += -482 }
    ldxdw r1, [r6+0x8]                      
    add64 r1, -1                                    r1 += -1   ///  r1 = r1.wrapping_add(-1 as i32 as i64 as u64)
    stxdw [r6+0x8], r1                      
    ja lbb_8570                                     if true { pc += -486 }
lbb_9056:
    ldxdw r1, [r10-0x18]                    
    ldxdw r2, [r10-0x110]                   
    stxdw [r2+0x10], r1                     
    ldxdw r1, [r10-0x20]                    
    stxdw [r2+0x8], r1                      
    ldxdw r1, [r10-0x28]                    
    stxdw [r2+0x0], r1                      
    ldxdw r1, [r10-0x78]                    
    ldxdw r2, [r10-0x80]                    
    ldxdw r3, [r2+0x0]                      
    add64 r3, -1                                    r3 += -1   ///  r3 = r3.wrapping_add(-1 as i32 as i64 as u64)
    stxdw [r2+0x0], r3                      
    jne r3, 0, lbb_9072                             if r3 != (0 as i32 as i64 as u64) { pc += 3 }
    ldxdw r3, [r2+0x8]                      
    add64 r3, -1                                    r3 += -1   ///  r3 = r3.wrapping_add(-1 as i32 as i64 as u64)
    stxdw [r2+0x8], r3                      
lbb_9072:
    ldxdw r2, [r1+0x0]                      
    add64 r2, -1                                    r2 += -1   ///  r2 = r2.wrapping_add(-1 as i32 as i64 as u64)
    stxdw [r1+0x0], r2                      
    jne r2, 0, lbb_9079                             if r2 != (0 as i32 as i64 as u64) { pc += 3 }
    ldxdw r2, [r1+0x8]                      
    add64 r2, -1                                    r2 += -1   ///  r2 = r2.wrapping_add(-1 as i32 as i64 as u64)
    stxdw [r1+0x8], r2                      
lbb_9079:
    ldxdw r1, [r10-0x48]                    
    ldxdw r2, [r10-0x50]                    
    ldxdw r3, [r2+0x0]                      
    add64 r3, -1                                    r3 += -1   ///  r3 = r3.wrapping_add(-1 as i32 as i64 as u64)
    stxdw [r2+0x0], r3                      
    jne r3, 0, lbb_9088                             if r3 != (0 as i32 as i64 as u64) { pc += 3 }
    ldxdw r3, [r2+0x8]                      
    add64 r3, -1                                    r3 += -1   ///  r3 = r3.wrapping_add(-1 as i32 as i64 as u64)
    stxdw [r2+0x8], r3                      
lbb_9088:
    ldxdw r2, [r1+0x0]                      
    add64 r2, -1                                    r2 += -1   ///  r2 = r2.wrapping_add(-1 as i32 as i64 as u64)
    stxdw [r1+0x0], r2                      
    jne r2, 0, lbb_8570                             if r2 != (0 as i32 as i64 as u64) { pc += -522 }
lbb_9092:
    ldxdw r2, [r1+0x8]                      
    add64 r2, -1                                    r2 += -1   ///  r2 = r2.wrapping_add(-1 as i32 as i64 as u64)
    stxdw [r1+0x8], r2                      
    ja lbb_8570                                     if true { pc += -526 }
lbb_9096:
    ldxdw r1, [r10-0x18]                    
    ldxdw r2, [r10-0x110]                   
    stxdw [r2+0x10], r1                     
    ldxdw r1, [r10-0x20]                    
    stxdw [r2+0x8], r1                      
    ldxdw r1, [r10-0x28]                    
    stxdw [r2+0x0], r1                      
    ldxdw r1, [r6+0x0]                      
    add64 r1, -1                                    r1 += -1   ///  r1 = r1.wrapping_add(-1 as i32 as i64 as u64)
    stxdw [r6+0x0], r1                      
    jne r1, 0, lbb_9110                             if r1 != (0 as i32 as i64 as u64) { pc += 3 }
    ldxdw r1, [r6+0x8]                      
    add64 r1, -1                                    r1 += -1   ///  r1 = r1.wrapping_add(-1 as i32 as i64 as u64)
    stxdw [r6+0x8], r1                      
lbb_9110:
    ldxdw r1, [r8+0x0]                      
    add64 r1, -1                                    r1 += -1   ///  r1 = r1.wrapping_add(-1 as i32 as i64 as u64)
    stxdw [r8+0x0], r1                      
    jne r1, 0, lbb_8570                             if r1 != (0 as i32 as i64 as u64) { pc += -544 }
    ldxdw r1, [r8+0x8]                      
    add64 r1, -1                                    r1 += -1   ///  r1 = r1.wrapping_add(-1 as i32 as i64 as u64)
    stxdw [r8+0x8], r1                      
    ja lbb_8570                                     if true { pc += -548 }

function_9118:
    mov64 r7, r3                                    r7 = r3
    mov64 r6, r1                                    r6 = r1
    mov64 r1, r4                                    r1 = r4
    and64 r1, 65535                                 r1 &= 65535   ///  r1 = r1.and(65535)
    jne r1, 0, lbb_9125                             if r1 != (0 as i32 as i64 as u64) { pc += 2 }
    mov64 r1, 27                                    r1 = 27 as i32 as i64 as u64
    ja lbb_9174                                     if true { pc += 49 }
lbb_9125:
    mov64 r3, 15                                    r3 = 15 as i32 as i64 as u64
    jgt r3, r1, lbb_9128                            if r3 > r1 { pc += 1 }
    ja lbb_9139                                     if true { pc += 11 }
lbb_9128:
    add64 r4, -1                                    r4 += -1   ///  r4 = r4.wrapping_add(-1 as i32 as i64 as u64)
    and64 r4, 65535                                 r4 &= 65535   ///  r4 = r4.and(65535)
    mul64 r4, 33                                    r4 *= 33   ///  r4 = r4.wrapping_mul(33 as u64)
    lddw r2, 0x10003e835 --> b"G\x99\x1d\xc8\xece\x969\xdci\xc6\xdc\x13\xceg\xc8\x97Qu\x16\xa8\xca~a\x1a…        r2 load str located at 4295223349
    add64 r2, r4                                    r2 += r4   ///  r2 = r2.wrapping_add(r4)
    mov64 r1, r10                                   r1 = r10
    add64 r1, -73                                   r1 += -73   ///  r1 = r1.wrapping_add(-73 as i32 as i64 as u64)
    mov64 r3, 33                                    r3 = 33 as i32 as i64 as u64
    call function_30349                     
    ja lbb_9159                                     if true { pc += 20 }
lbb_9139:
    mov64 r1, r10                                   r1 = r10
    add64 r1, -2                                    r1 += -2   ///  r1 = r1.wrapping_add(-2 as i32 as i64 as u64)
    stxdw [r10-0x18], r1                    
    mov64 r1, 5                                     r1 = 5 as i32 as i64 as u64
    stxdw [r10-0x20], r1                    
    lddw r1, 0x10003e805 --> b"AC_02called `Result::unwrap()` on an `Err` valueG\x99"        r1 load str located at 4295223301
    stxdw [r10-0x28], r1                    
    be16 r4                                         r4 = match 16 { 16 => (r4 as u16).swap_bytes() as u64, 32 => (r4 as u32).swap_bytes() as u64, 64 => r4.swap_bytes(), _ => r4 }
    stxh [r10-0x2], r4                      
    mov64 r1, 2                                     r1 = 2 as i32 as i64 as u64
    stxdw [r10-0x10], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -73                                   r1 += -73   ///  r1 = r1.wrapping_add(-73 as i32 as i64 as u64)
    mov64 r3, r10                                   r3 = r10
    add64 r3, -40                                   r3 += -40   ///  r3 = r3.wrapping_add(-40 as i32 as i64 as u64)
    mov64 r4, r2                                    r4 = r2
    mov64 r2, r3                                    r2 = r3
    mov64 r3, 2                                     r3 = 2 as i32 as i64 as u64
    call function_19618                     
lbb_9159:
    ldxdw r1, [r10-0x31]                    
    stxdw [r10-0x10], r1                    
    ldxdw r1, [r10-0x39]                    
    stxdw [r10-0x18], r1                    
    ldxdw r1, [r10-0x41]                    
    stxdw [r10-0x20], r1                    
    ldxb r1, [r10-0x29]                     
    ldxdw r3, [r10-0x49]                    
    stxdw [r10-0x28], r3                    
    ldxdw r2, [r7+0x0]                      
    ldxdw r4, [r2+0x0]                      
    jeq r4, r3, lbb_9178                            if r4 == r3 { pc += 7 }
lbb_9171:
    mov64 r3, 1                                     r3 = 1 as i32 as i64 as u64
    jeq r3, 0, lbb_9190                             if r3 == (0 as i32 as i64 as u64) { pc += 17 }
lbb_9173:
    mov64 r1, 24                                    r1 = 24 as i32 as i64 as u64
lbb_9174:
    stxw [r6+0x8], r1                       
    lddw r1, 0x8000000000000000                     r1 load str located at -9223372036854775808
    ja lbb_9193                                     if true { pc += 15 }
lbb_9178:
    ldxdw r3, [r2+0x8]                      
    ldxdw r4, [r10-0x20]                    
    jne r3, r4, lbb_9171                            if r3 != r4 { pc += -10 }
    ldxdw r3, [r2+0x10]                     
    ldxdw r4, [r10-0x18]                    
    jne r3, r4, lbb_9171                            if r3 != r4 { pc += -13 }
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
    ldxdw r2, [r2+0x18]                     
    ldxdw r4, [r10-0x10]                    
    jne r2, r4, lbb_9171                            if r2 != r4 { pc += -17 }
    jeq r3, 0, lbb_9190                             if r3 == (0 as i32 as i64 as u64) { pc += 1 }
    ja lbb_9173                                     if true { pc += -17 }
lbb_9190:
    stxb [r6+0x8], r1                       
    lddw r1, 0x800000000000001a                     r1 load str located at -9223372036854775782
lbb_9193:
    stxdw [r6+0x0], r1                      
    exit                                    

function_9195:
    mov64 r7, r3                                    r7 = r3
    mov64 r6, r1                                    r6 = r1
    mov64 r1, r4                                    r1 = r4
    and64 r1, 65535                                 r1 &= 65535   ///  r1 = r1.and(65535)
    jne r1, 0, lbb_9202                             if r1 != (0 as i32 as i64 as u64) { pc += 2 }
    mov64 r1, 26                                    r1 = 26 as i32 as i64 as u64
    ja lbb_9251                                     if true { pc += 49 }
lbb_9202:
    mov64 r3, 15                                    r3 = 15 as i32 as i64 as u64
    jgt r3, r1, lbb_9205                            if r3 > r1 { pc += 1 }
    ja lbb_9216                                     if true { pc += 11 }
lbb_9205:
    add64 r4, -1                                    r4 += -1   ///  r4 = r4.wrapping_add(-1 as i32 as i64 as u64)
    and64 r4, 65535                                 r4 &= 65535   ///  r4 = r4.and(65535)
    mul64 r4, 33                                    r4 *= 33   ///  r4 = r4.wrapping_mul(33 as u64)
    lddw r2, 0x10003ea03 --> b"\xd5\x0a\x12\x1b\xd7e|U)\xef\xcf\x84&\x85\x91v\x96e\x8e)"\xe6\xfcJ\xe9J\x…        r2 load str located at 4295223811
    add64 r2, r4                                    r2 += r4   ///  r2 = r2.wrapping_add(r4)
    mov64 r1, r10                                   r1 = r10
    add64 r1, -73                                   r1 += -73   ///  r1 = r1.wrapping_add(-73 as i32 as i64 as u64)
    mov64 r3, 33                                    r3 = 33 as i32 as i64 as u64
    call function_30349                     
    ja lbb_9236                                     if true { pc += 20 }
lbb_9216:
    mov64 r1, r10                                   r1 = r10
    add64 r1, -2                                    r1 += -2   ///  r1 = r1.wrapping_add(-2 as i32 as i64 as u64)
    stxdw [r10-0x18], r1                    
    mov64 r1, 5                                     r1 = 5 as i32 as i64 as u64
    stxdw [r10-0x20], r1                    
    lddw r1, 0x10003e800 --> b"AC_03AC_02called `Result::unwrap()` on an `Err` va"        r1 load str located at 4295223296
    stxdw [r10-0x28], r1                    
    be16 r4                                         r4 = match 16 { 16 => (r4 as u16).swap_bytes() as u64, 32 => (r4 as u32).swap_bytes() as u64, 64 => r4.swap_bytes(), _ => r4 }
    stxh [r10-0x2], r4                      
    mov64 r1, 2                                     r1 = 2 as i32 as i64 as u64
    stxdw [r10-0x10], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -73                                   r1 += -73   ///  r1 = r1.wrapping_add(-73 as i32 as i64 as u64)
    mov64 r3, r10                                   r3 = r10
    add64 r3, -40                                   r3 += -40   ///  r3 = r3.wrapping_add(-40 as i32 as i64 as u64)
    mov64 r4, r2                                    r4 = r2
    mov64 r2, r3                                    r2 = r3
    mov64 r3, 2                                     r3 = 2 as i32 as i64 as u64
    call function_19618                     
lbb_9236:
    ldxdw r1, [r10-0x31]                    
    stxdw [r10-0x10], r1                    
    ldxdw r1, [r10-0x39]                    
    stxdw [r10-0x18], r1                    
    ldxdw r1, [r10-0x41]                    
    stxdw [r10-0x20], r1                    
    ldxb r1, [r10-0x29]                     
    ldxdw r3, [r10-0x49]                    
    stxdw [r10-0x28], r3                    
    ldxdw r2, [r7+0x0]                      
    ldxdw r4, [r2+0x0]                      
    jeq r4, r3, lbb_9255                            if r4 == r3 { pc += 7 }
lbb_9248:
    mov64 r3, 1                                     r3 = 1 as i32 as i64 as u64
    jeq r3, 0, lbb_9267                             if r3 == (0 as i32 as i64 as u64) { pc += 17 }
lbb_9250:
    mov64 r1, 25                                    r1 = 25 as i32 as i64 as u64
lbb_9251:
    stxw [r6+0x8], r1                       
    lddw r1, 0x8000000000000000                     r1 load str located at -9223372036854775808
    ja lbb_9270                                     if true { pc += 15 }
lbb_9255:
    ldxdw r3, [r2+0x8]                      
    ldxdw r4, [r10-0x20]                    
    jne r3, r4, lbb_9248                            if r3 != r4 { pc += -10 }
    ldxdw r3, [r2+0x10]                     
    ldxdw r4, [r10-0x18]                    
    jne r3, r4, lbb_9248                            if r3 != r4 { pc += -13 }
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
    ldxdw r2, [r2+0x18]                     
    ldxdw r4, [r10-0x10]                    
    jne r2, r4, lbb_9248                            if r2 != r4 { pc += -17 }
    jeq r3, 0, lbb_9267                             if r3 == (0 as i32 as i64 as u64) { pc += 1 }
    ja lbb_9250                                     if true { pc += -17 }
lbb_9267:
    stxb [r6+0x8], r1                       
    lddw r1, 0x800000000000001a                     r1 load str located at -9223372036854775782
lbb_9270:
    stxdw [r6+0x0], r1                      
    exit                                    

function_9272:
    lddw r2, 0x300000000                            r2 load str located at 12884901888
    ldxdw r3, [r2+0x0]                      
    mov64 r2, r3                                    r2 = r3
    add64 r2, -6144                                 r2 += -6144   ///  r2 = r2.wrapping_add(-6144 as i32 as i64 as u64)
    mov64 r4, 0                                     r4 = 0 as i32 as i64 as u64
    mov64 r5, 1                                     r5 = 1 as i32 as i64 as u64
    jgt r2, r3, lbb_9281                            if r2 > r3 { pc += 1 }
    mov64 r5, 0                                     r5 = 0 as i32 as i64 as u64
lbb_9281:
    jne r5, 0, lbb_9283                             if r5 != (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r4, r2                                    r4 = r2
lbb_9283:
    lddw r2, 0x300006800                            r2 load str located at 12884928512
    jeq r3, 0, lbb_9288                             if r3 == (0 as i32 as i64 as u64) { pc += 2 }
    and64 r4, -8                                    r4 &= -8   ///  r4 = r4.and(-8)
    mov64 r2, r4                                    r2 = r4
lbb_9288:
    lddw r3, 0x300000008                            r3 load str located at 12884901896
    jgt r3, r2, lbb_9318                            if r3 > r2 { pc += 27 }
    lddw r3, 0x300000000                            r3 load str located at 12884901888
    stxdw [r3+0x0], r2                      
    mov64 r4, 0                                     r4 = 0 as i32 as i64 as u64
    mov64 r5, 1                                     r5 = 1 as i32 as i64 as u64
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
lbb_9297:
    mov64 r0, r2                                    r0 = r2
    add64 r0, r3                                    r0 += r3   ///  r0 = r0.wrapping_add(r3)
    stxdw [r0+0x8], r5                      
    stxdw [r0+0x10], r4                     
    stxdw [r0+0x0], r4                      
    add64 r3, 24                                    r3 += 24   ///  r3 = r3.wrapping_add(24 as i32 as i64 as u64)
    jeq r3, 6120, lbb_9305                          if r3 == (6120 as i32 as i64 as u64) { pc += 1 }
    ja lbb_9297                                     if true { pc += -8 }
lbb_9305:
    mov64 r4, r2                                    r4 = r2
    add64 r4, r3                                    r4 += r3   ///  r4 = r4.wrapping_add(r3)
    mov64 r3, 1                                     r3 = 1 as i32 as i64 as u64
    stxdw [r4+0x8], r3                      
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
    stxdw [r4+0x10], r3                     
    stxdw [r4+0x0], r3                      
    stxdw [r1+0x10], r2                     
    mov64 r2, 256                                   r2 = 256 as i32 as i64 as u64
    stxdw [r1+0x18], r2                     
    stxdw [r1+0x8], r2                      
    stxdw [r1+0x0], r3                      
    exit                                    
lbb_9318:
    mov64 r1, 8                                     r1 = 8 as i32 as i64 as u64
    mov64 r2, 6144                                  r2 = 6144 as i32 as i64 as u64
    call function_21549                     

function_9321:
    mov64 r7, r3                                    r7 = r3
    mov64 r8, r2                                    r8 = r2
    mov64 r6, r1                                    r6 = r1
    mov64 r1, r10                                   r1 = r10
    add64 r1, -32                                   r1 += -32   ///  r1 = r1.wrapping_add(-32 as i32 as i64 as u64)
    mov64 r2, r7                                    r2 = r7
    mov64 r3, 12                                    r3 = 12 as i32 as i64 as u64
    call function_19860                     
    jne r8, 0, lbb_9333                             if r8 != (0 as i32 as i64 as u64) { pc += 3 }
    lddw r1, 0x1000413a8 --> b"\x00\x00\x00\x00p\xe7\x03\x00\x10\x00\x00\x00\x00\x00\x00\x00@\x00\x00\x0…        r1 load str located at 4295234472
    call function_29633                     
lbb_9333:
    ldxdw r2, [r10-0x18]                    
    be64 r2                                         r2 = match 64 { 16 => (r2 as u16).swap_bytes() as u64, 32 => (r2 as u32).swap_bytes() as u64, 64 => r2.swap_bytes(), _ => r2 }
    ldxdw r3, [r10-0x20]                    
    be64 r3                                         r3 = match 64 { 16 => (r3 as u16).swap_bytes() as u64, 32 => (r3 as u32).swap_bytes() as u64, 64 => r3.swap_bytes(), _ => r3 }
    mov64 r1, r10                                   r1 = r10
    add64 r1, -48                                   r1 += -48   ///  r1 = r1.wrapping_add(-48 as i32 as i64 as u64)
    mov64 r9, 0                                     r9 = 0 as i32 as i64 as u64
    mov64 r4, r8                                    r4 = r8
    mov64 r5, 0                                     r5 = 0 as i32 as i64 as u64
    call function_31706                     
    ldxdw r1, [r10-0x30]                    
    jgt r8, r1, lbb_9349                            if r8 > r1 { pc += 4 }
    mov64 r2, r8                                    r2 = r8
    lddw r3, 0x100041330 --> b"\x00\x00\x00\x00p\xe7\x03\x00\x10\x00\x00\x00\x00\x00\x00\x00\x1c\x00\x00…        r3 load str located at 4295234352
    call function_25832                     
lbb_9349:
    mul64 r1, 24                                    r1 *= 24   ///  r1 = r1.wrapping_mul(24 as u64)
    add64 r6, r1                                    r6 += r1   ///  r6 = r6.wrapping_add(r1)
    ldxw r2, [r7+0x8]                       
    stxdw [r10-0x38], r7                    
    ldxdw r3, [r7+0x0]                      
    ldxdw r1, [r6+0x8]                      
    ldxdw r7, [r6+0x10]                     
    mov64 r8, r7                                    r8 = r7
    mul64 r8, 12                                    r8 *= 12   ///  r8 = r8.wrapping_mul(12 as u64)
    ja lbb_9371                                     if true { pc += 12 }
lbb_9359:
    mov64 r4, r1                                    r4 = r1
    add64 r4, r9                                    r4 += r9   ///  r4 = r4.wrapping_add(r9)
    ldxdw r5, [r4+0x0]                      
    xor64 r5, r3                                    r5 ^= r3   ///  r5 = r5.xor(r3)
    ldxw r4, [r4+0x8]                       
    xor64 r4, r2                                    r4 ^= r2   ///  r4 = r4.xor(r2)
    lsh64 r4, 32                                    r4 <<= 32   ///  r4 = r4.wrapping_shl(32)
    rsh64 r4, 32                                    r4 >>= 32   ///  r4 = r4.wrapping_shr(32)
    or64 r5, r4                                     r5 |= r4   ///  r5 = r5.or(r4)
    add64 r9, 12                                    r9 += 12   ///  r9 = r9.wrapping_add(12 as i32 as i64 as u64)
    jne r5, 0, lbb_9371                             if r5 != (0 as i32 as i64 as u64) { pc += 1 }
lbb_9370:
    exit                                    
lbb_9371:
    jne r8, r9, lbb_9359                            if r8 != r9 { pc += -13 }
    ldxdw r2, [r6+0x0]                      
    jne r7, r2, lbb_9377                            if r7 != r2 { pc += 3 }
    mov64 r1, r6                                    r1 = r6
    call function_965                       
    ldxdw r1, [r6+0x8]                      
lbb_9377:
    add64 r1, r8                                    r1 += r8   ///  r1 = r1.wrapping_add(r8)
    ldxdw r3, [r10-0x38]                    
    ldxw r2, [r3+0x8]                       
    stxw [r1+0x8], r2                       
    ldxdw r2, [r3+0x0]                      
    stxdw [r1+0x0], r2                      
    add64 r7, 1                                     r7 += 1   ///  r7 = r7.wrapping_add(1 as i32 as i64 as u64)
    stxdw [r6+0x10], r7                     
    ja lbb_9370                                     if true { pc += -16 }

function_9386:
    mov64 r8, r4                                    r8 = r4
    mov64 r9, r3                                    r9 = r3
    mov64 r7, r2                                    r7 = r2
    stxdw [r10-0x38], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -32                                   r1 += -32   ///  r1 = r1.wrapping_add(-32 as i32 as i64 as u64)
    mov64 r2, r8                                    r2 = r8
    mov64 r3, 12                                    r3 = 12 as i32 as i64 as u64
    call function_19860                     
    jne r9, 0, lbb_9399                             if r9 != (0 as i32 as i64 as u64) { pc += 3 }
    lddw r1, 0x1000413a8 --> b"\x00\x00\x00\x00p\xe7\x03\x00\x10\x00\x00\x00\x00\x00\x00\x00@\x00\x00\x0…        r1 load str located at 4295234472
    call function_29633                     
lbb_9399:
    ldxdw r2, [r10-0x18]                    
    be64 r2                                         r2 = match 64 { 16 => (r2 as u16).swap_bytes() as u64, 32 => (r2 as u32).swap_bytes() as u64, 64 => r2.swap_bytes(), _ => r2 }
    ldxdw r3, [r10-0x20]                    
    be64 r3                                         r3 = match 64 { 16 => (r3 as u16).swap_bytes() as u64, 32 => (r3 as u32).swap_bytes() as u64, 64 => r3.swap_bytes(), _ => r3 }
    mov64 r1, r10                                   r1 = r10
    add64 r1, -48                                   r1 += -48   ///  r1 = r1.wrapping_add(-48 as i32 as i64 as u64)
    mov64 r4, r9                                    r4 = r9
    mov64 r5, 0                                     r5 = 0 as i32 as i64 as u64
    call function_31706                     
    ldxdw r1, [r10-0x30]                    
    jgt r9, r1, lbb_9414                            if r9 > r1 { pc += 4 }
    mov64 r2, r9                                    r2 = r9
    lddw r3, 0x100041348 --> b"\x00\x00\x00\x00p\xe7\x03\x00\x10\x00\x00\x00\x00\x00\x00\x00(\x00\x00\x0…        r3 load str located at 4295234376
    call function_25832                     
lbb_9414:
    mul64 r1, 24                                    r1 *= 24   ///  r1 = r1.wrapping_mul(24 as u64)
    add64 r7, r1                                    r7 += r1   ///  r7 = r7.wrapping_add(r1)
    mov64 r1, -1                                    r1 = -1 as i32 as i64 as u64
    ldxw r5, [r8+0x8]                       
    ldxdw r0, [r8+0x0]                      
    ldxdw r3, [r7+0x8]                      
    ldxdw r2, [r7+0x10]                     
    mov64 r8, r2                                    r8 = r2
    mul64 r8, 12                                    r8 *= 12   ///  r8 = r8.wrapping_mul(12 as u64)
    mov64 r4, r3                                    r4 = r3
    ja lbb_9436                                     if true { pc += 11 }
lbb_9425:
    ldxdw r9, [r4+0x0]                      
    xor64 r9, r0                                    r9 ^= r0   ///  r9 = r9.xor(r0)
    ldxw r6, [r4+0x8]                       
    xor64 r6, r5                                    r6 ^= r5   ///  r6 = r6.xor(r5)
    lsh64 r6, 32                                    r6 <<= 32   ///  r6 = r6.wrapping_shl(32)
    rsh64 r6, 32                                    r6 >>= 32   ///  r6 = r6.wrapping_shr(32)
    or64 r9, r6                                     r9 |= r6   ///  r9 = r9.or(r6)
    add64 r8, -12                                   r8 += -12   ///  r8 = r8.wrapping_add(-12 as i32 as i64 as u64)
    add64 r1, 1                                     r1 += 1   ///  r1 = r1.wrapping_add(1 as i32 as i64 as u64)
    add64 r4, 12                                    r4 += 12   ///  r4 = r4.wrapping_add(12 as i32 as i64 as u64)
    jeq r9, 0, lbb_9443                             if r9 == (0 as i32 as i64 as u64) { pc += 7 }
lbb_9436:
    jne r8, 0, lbb_9425                             if r8 != (0 as i32 as i64 as u64) { pc += -12 }
    mov64 r1, 65535                                 r1 = 65535 as i32 as i64 as u64
    ldxdw r2, [r10-0x38]                    
    stxw [r2+0x8], r1                       
    lddw r1, 0x8000000000000000                     r1 load str located at -9223372036854775808
    ja lbb_9464                                     if true { pc += 21 }
lbb_9443:
    jne r2, 0, lbb_9447                             if r2 != (0 as i32 as i64 as u64) { pc += 3 }
    lddw r1, 0x100041360 --> b"\x00\x00\x00\x00p\xe7\x03\x00\x10\x00\x00\x00\x00\x00\x00\x00,\x00\x00\x0…        r1 load str located at 4295234400
    call function_25695                     
lbb_9447:
    jgt r2, r1, lbb_9451                            if r2 > r1 { pc += 3 }
    lddw r3, 0x100041378 --> b"\x00\x00\x00\x00p\xe7\x03\x00\x10\x00\x00\x00\x00\x00\x00\x00-\x00\x00\x0…        r3 load str located at 4295234424
    call function_25832                     
lbb_9451:
    mul64 r2, 12                                    r2 *= 12   ///  r2 = r2.wrapping_mul(12 as u64)
    add64 r2, r3                                    r2 += r3   ///  r2 = r2.wrapping_add(r3)
    ldxdw r1, [r2-0xc]                      
    ldxw r2, [r2-0x4]                       
    stxw [r4-0x4], r2                       
    stxdw [r4-0xc], r1                      
    ldxdw r1, [r7+0x10]                     
    jeq r1, 0, lbb_9461                             if r1 == (0 as i32 as i64 as u64) { pc += 2 }
    add64 r1, -1                                    r1 += -1   ///  r1 = r1.wrapping_add(-1 as i32 as i64 as u64)
    stxdw [r7+0x10], r1                     
lbb_9461:
    lddw r1, 0x800000000000001a                     r1 load str located at -9223372036854775782
    ldxdw r2, [r10-0x38]                    
lbb_9464:
    stxdw [r2+0x0], r1                      
    exit                                    

function_9466:
    ldxdw r0, [r5-0xfe8]                    
    stxdw [r10-0x100], r0                   
    ldxdw r0, [r5-0xff0]                    
    jeq r0, 0, lbb_9490                             if r0 == (0 as i32 as i64 as u64) { pc += 20 }
    ldxdw r6, [r5-0x1000]                   
    stxdw [r10-0x108], r6                   
    ldxdw r7, [r5-0xff8]                    
    mov64 r6, 0                                     r6 = 0 as i32 as i64 as u64
    mov64 r5, r0                                    r5 = r0
    mul64 r5, 24                                    r5 *= 24   ///  r5 = r5.wrapping_mul(24 as u64)
    stxdw [r10-0xf8], r5                    
    mov64 r5, 0                                     r5 = 0 as i32 as i64 as u64
lbb_9478:
    mov64 r8, r7                                    r8 = r7
    add64 r8, r6                                    r8 += r6   ///  r8 = r8.wrapping_add(r6)
    ldxdw r9, [r8+0x0]                      
    jgt r9, r2, lbb_9488                            if r9 > r2 { pc += 6 }
    sub64 r2, r9                                    r2 -= r9   ///  r2 = r2.wrapping_sub(r9)
    add64 r5, 1                                     r5 += 1   ///  r5 = r5.wrapping_add(1 as i32 as i64 as u64)
    add64 r6, 24                                    r6 += 24   ///  r6 = r6.wrapping_add(24 as i32 as i64 as u64)
    ldxdw r8, [r10-0xf8]                    
    jeq r8, r6, lbb_9490                            if r8 == r6 { pc += 3 }
    ja lbb_9478                                     if true { pc += -10 }
lbb_9488:
    jeq r0, r5, lbb_9490                            if r0 == r5 { pc += 1 }
    ja lbb_9500                                     if true { pc += 10 }
lbb_9490:
    mov64 r9, 0                                     r9 = 0 as i32 as i64 as u64
    mov64 r2, 1                                     r2 = 1 as i32 as i64 as u64
    jeq r3, 0, lbb_9494                             if r3 == (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
lbb_9494:
    ldxdw r3, [r10-0x100]                   
    xor64 r3, 1                                     r3 ^= 1   ///  r3 = r3.xor(1)
    or64 r2, r3                                     r2 |= r3   ///  r2 = r2.or(r3)
lbb_9497:
    stxdw [r1+0x8], r9                      
    stxdw [r1+0x0], r2                      
    exit                                    
lbb_9500:
    stxdw [r10-0x120], r4                   
    jge r0, r5, lbb_9507                            if r0 >= r5 { pc += 5 }
    mov64 r1, r5                                    r1 = r5
    mov64 r2, r0                                    r2 = r0
    lddw r3, 0x1000413c0 --> b"\x00\x00\x00\x00\xd1\xeb\x03\x00\x16\x00\x00\x00\x00\x00\x00\x00&\x00\x00…        r3 load str located at 4295234496
    call function_28325                     
lbb_9507:
    add64 r7, r6                                    r7 += r6   ///  r7 = r7.wrapping_add(r6)
    mov64 r9, 0                                     r9 = 0 as i32 as i64 as u64
    ldxb r4, [r7+0x10]                      
    jeq r4, 0, lbb_9740                             if r4 == (0 as i32 as i64 as u64) { pc += 229 }
    stxdw [r10-0x130], r2                   
    stxdw [r10-0x118], r3                   
    stxdw [r10-0x110], r1                   
    ldxdw r4, [r7+0x8]                      
    stxdw [r10-0x128], r4                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -32                                   r1 += -32   ///  r1 = r1.wrapping_add(-32 as i32 as i64 as u64)
    ldxdw r2, [r10-0x108]                   
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
    mov64 r5, 0                                     r5 = 0 as i32 as i64 as u64
    call function_31300                     
    mov64 r1, r10                                   r1 = r10
    add64 r1, -16                                   r1 += -16   ///  r1 = r1.wrapping_add(-16 as i32 as i64 as u64)
    ldxdw r2, [r10-0x120]                   
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
    ldxdw r4, [r10-0x128]                   
    mov64 r5, 0                                     r5 = 0 as i32 as i64 as u64
    call function_31300                     
    mov64 r2, 1                                     r2 = 1 as i32 as i64 as u64
    ldxdw r1, [r10-0x18]                    
    mov64 r4, 1                                     r4 = 1 as i32 as i64 as u64
    jne r1, 0, lbb_9534                             if r1 != (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r4, 0                                     r4 = 0 as i32 as i64 as u64
lbb_9534:
    ldxdw r1, [r10-0x20]                    
    ldxdw r5, [r10-0x8]                     
    mov64 r3, r5                                    r3 = r5
    add64 r3, r1                                    r3 += r1   ///  r3 = r3.wrapping_add(r1)
    ldxdw r1, [r10-0x110]                   
    jgt r5, r3, lbb_9541                            if r5 > r3 { pc += 1 }
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
lbb_9541:
    or64 r4, r2                                     r4 |= r2   ///  r4 = r4.or(r2)
    and64 r4, 1                                     r4 &= 1   ///  r4 = r4.and(1)
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
    jne r4, 0, lbb_9497                             if r4 != (0 as i32 as i64 as u64) { pc += -48 }
    ldxdw r2, [r10-0x10]                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -48                                   r1 += -48   ///  r1 = r1.wrapping_add(-48 as i32 as i64 as u64)
    mov64 r4, 1000000                               r4 = 1000000 as i32 as i64 as u64
    mov64 r5, 0                                     r5 = 0 as i32 as i64 as u64
    call function_30496                     
    ldxdw r7, [r7+0x0]                      
    ldxdw r1, [r10-0x130]                   
    sub64 r7, r1                                    r7 -= r1   ///  r7 = r7.wrapping_sub(r1)
    ldxdw r2, [r10-0x28]                    
    ldxdw r9, [r10-0x30]                    
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    stxdw [r10-0x128], r1                   
    ldxdw r1, [r10-0x118]                   
    jgt r7, r1, lbb_9673                            if r7 > r1 { pc += 113 }
    mov64 r1, r10                                   r1 = r10
    add64 r1, -80                                   r1 += -80   ///  r1 = r1.wrapping_add(-80 as i32 as i64 as u64)
    stxdw [r10-0x128], r9                   
    mov64 r9, 0                                     r9 = 0 as i32 as i64 as u64
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
    mov64 r4, r7                                    r4 = r7
    mov64 r5, 0                                     r5 = 0 as i32 as i64 as u64
    call function_31300                     
    mov64 r1, r10                                   r1 = r10
    add64 r1, -64                                   r1 += -64   ///  r1 = r1.wrapping_add(-64 as i32 as i64 as u64)
    mov64 r2, r7                                    r2 = r7
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
    ldxdw r4, [r10-0x128]                   
    mov64 r5, 0                                     r5 = 0 as i32 as i64 as u64
    call function_31300                     
    mov64 r2, 1                                     r2 = 1 as i32 as i64 as u64
    ldxdw r1, [r10-0x48]                    
    mov64 r4, 1                                     r4 = 1 as i32 as i64 as u64
    jne r1, 0, lbb_9580                             if r1 != (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r4, 0                                     r4 = 0 as i32 as i64 as u64
lbb_9580:
    ldxdw r5, [r10-0x38]                    
    ldxdw r1, [r10-0x50]                    
    mov64 r3, r5                                    r3 = r5
    add64 r3, r1                                    r3 += r1   ///  r3 = r3.wrapping_add(r1)
    ldxdw r1, [r10-0x110]                   
    jgt r5, r3, lbb_9587                            if r5 > r3 { pc += 1 }
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
lbb_9587:
    or64 r4, r2                                     r4 |= r2   ///  r4 = r4.or(r2)
    and64 r4, 1                                     r4 &= 1   ///  r4 = r4.and(1)
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
    jne r4, 0, lbb_9497                             if r4 != (0 as i32 as i64 as u64) { pc += -94 }
    mov64 r9, r7                                    r9 = r7
    ldxdw r7, [r10-0xf8]                    
    add64 r7, -24                                   r7 += -24   ///  r7 = r7.wrapping_add(-24 as i32 as i64 as u64)
    ldxdw r2, [r10-0x40]                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -96                                   r1 += -96   ///  r1 = r1.wrapping_add(-96 as i32 as i64 as u64)
    lddw r4, 0x38d7ea4c68000                        r4 load str located at 1000000000000000
    mov64 r5, 0                                     r5 = 0 as i32 as i64 as u64
    call function_30496                     
    ldxdw r1, [r10-0x110]                   
    ldxdw r3, [r10-0x118]                   
    sub64 r3, r9                                    r3 -= r9   ///  r3 = r3.wrapping_sub(r9)
    ldxdw r9, [r10-0x60]                    
    jeq r7, r6, lbb_9740                            if r7 == r6 { pc += 134 }
    ldxdw r2, [r10-0xf8]                    
    sub64 r2, r6                                    r2 -= r6   ///  r2 = r2.wrapping_sub(r6)
    add64 r2, -24                                   r2 += -24   ///  r2 = r2.wrapping_add(-24 as i32 as i64 as u64)
    stxdw [r10-0xf8], r2                    
    add64 r8, 40                                    r8 += 40   ///  r8 = r8.wrapping_add(40 as i32 as i64 as u64)
    ja lbb_9625                                     if true { pc += 13 }
lbb_9612:
    and64 r3, 1                                     r3 &= 1   ///  r3 = r3.and(1)
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
    ldxdw r1, [r10-0x110]                   
    jne r3, 0, lbb_9497                             if r3 != (0 as i32 as i64 as u64) { pc += -119 }
    ldxdw r3, [r10-0x118]                   
    ldxdw r2, [r10-0x130]                   
    sub64 r3, r2                                    r3 -= r2   ///  r3 = r3.wrapping_sub(r2)
    add64 r8, 24                                    r8 += 24   ///  r8 = r8.wrapping_add(24 as i32 as i64 as u64)
    ldxdw r2, [r10-0xf8]                    
    add64 r2, -24                                   r2 += -24   ///  r2 = r2.wrapping_add(-24 as i32 as i64 as u64)
    mov64 r9, r4                                    r9 = r4
    stxdw [r10-0xf8], r2                    
    jeq r2, 0, lbb_9740                             if r2 == (0 as i32 as i64 as u64) { pc += 115 }
lbb_9625:
    ldxb r2, [r8+0x0]                       
    jne r2, 0, lbb_9628                             if r2 != (0 as i32 as i64 as u64) { pc += 1 }
    ja lbb_9740                                     if true { pc += 112 }
lbb_9628:
    stxdw [r10-0x128], r9                   
    stxdw [r10-0x118], r3                   
    ldxdw r6, [r8-0x8]                      
    mov64 r1, r10                                   r1 = r10
    add64 r1, -128                                  r1 += -128   ///  r1 = r1.wrapping_add(-128 as i32 as i64 as u64)
    mov64 r9, 0                                     r9 = 0 as i32 as i64 as u64
    ldxdw r2, [r10-0x108]                   
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
    mov64 r4, r6                                    r4 = r6
    mov64 r5, 0                                     r5 = 0 as i32 as i64 as u64
    call function_31300                     
    mov64 r1, r10                                   r1 = r10
    add64 r1, -112                                  r1 += -112   ///  r1 = r1.wrapping_add(-112 as i32 as i64 as u64)
    ldxdw r2, [r10-0x120]                   
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
    mov64 r4, r6                                    r4 = r6
    mov64 r5, 0                                     r5 = 0 as i32 as i64 as u64
    call function_31300                     
    mov64 r2, 1                                     r2 = 1 as i32 as i64 as u64
    ldxdw r1, [r10-0x78]                    
    mov64 r4, 1                                     r4 = 1 as i32 as i64 as u64
    jne r1, 0, lbb_9651                             if r1 != (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r4, 0                                     r4 = 0 as i32 as i64 as u64
lbb_9651:
    ldxdw r1, [r10-0x80]                    
    ldxdw r5, [r10-0x68]                    
    mov64 r3, r5                                    r3 = r5
    add64 r3, r1                                    r3 += r1   ///  r3 = r3.wrapping_add(r1)
    ldxdw r1, [r10-0x110]                   
    jgt r5, r3, lbb_9658                            if r5 > r3 { pc += 1 }
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
lbb_9658:
    or64 r4, r2                                     r4 |= r2   ///  r4 = r4.or(r2)
    and64 r4, 1                                     r4 &= 1   ///  r4 = r4.and(1)
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
    jne r4, 0, lbb_9497                             if r4 != (0 as i32 as i64 as u64) { pc += -165 }
    ldxdw r2, [r10-0x70]                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -144                                  r1 += -144   ///  r1 = r1.wrapping_add(-144 as i32 as i64 as u64)
    mov64 r4, 1000000                               r4 = 1000000 as i32 as i64 as u64
    mov64 r5, 0                                     r5 = 0 as i32 as i64 as u64
    call function_30496                     
    ldxdw r2, [r10-0x88]                    
    ldxdw r9, [r10-0x90]                    
    ldxdw r7, [r8-0x10]                     
    ldxdw r1, [r10-0x118]                   
    jge r1, r7, lbb_9693                            if r1 >= r7 { pc += 20 }
lbb_9673:
    mov64 r1, r10                                   r1 = r10
    add64 r1, -224                                  r1 += -224   ///  r1 = r1.wrapping_add(-224 as i32 as i64 as u64)
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
    ldxdw r6, [r10-0x118]                   
    mov64 r4, r6                                    r4 = r6
    mov64 r5, 0                                     r5 = 0 as i32 as i64 as u64
    call function_31300                     
    mov64 r1, r10                                   r1 = r10
    add64 r1, -208                                  r1 += -208   ///  r1 = r1.wrapping_add(-208 as i32 as i64 as u64)
    mov64 r2, r6                                    r2 = r6
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
    mov64 r4, r9                                    r4 = r9
    mov64 r5, 0                                     r5 = 0 as i32 as i64 as u64
    call function_31300                     
    mov64 r2, 1                                     r2 = 1 as i32 as i64 as u64
    ldxdw r1, [r10-0xd8]                    
    mov64 r4, 1                                     r4 = 1 as i32 as i64 as u64
    jne r1, 0, lbb_9750                             if r1 != (0 as i32 as i64 as u64) { pc += 59 }
    mov64 r4, 0                                     r4 = 0 as i32 as i64 as u64
    ja lbb_9750                                     if true { pc += 57 }
lbb_9693:
    mov64 r1, r10                                   r1 = r10
    add64 r1, -176                                  r1 += -176   ///  r1 = r1.wrapping_add(-176 as i32 as i64 as u64)
    mov64 r6, r9                                    r6 = r9
    mov64 r9, 0                                     r9 = 0 as i32 as i64 as u64
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
    mov64 r4, r7                                    r4 = r7
    mov64 r5, 0                                     r5 = 0 as i32 as i64 as u64
    call function_31300                     
    mov64 r1, r10                                   r1 = r10
    add64 r1, -160                                  r1 += -160   ///  r1 = r1.wrapping_add(-160 as i32 as i64 as u64)
    stxdw [r10-0x130], r7                   
    mov64 r2, r7                                    r2 = r7
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
    mov64 r4, r6                                    r4 = r6
    mov64 r5, 0                                     r5 = 0 as i32 as i64 as u64
    call function_31300                     
    mov64 r2, 1                                     r2 = 1 as i32 as i64 as u64
    ldxdw r1, [r10-0xa8]                    
    mov64 r4, 1                                     r4 = 1 as i32 as i64 as u64
    jne r1, 0, lbb_9714                             if r1 != (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r4, 0                                     r4 = 0 as i32 as i64 as u64
lbb_9714:
    ldxdw r5, [r10-0x98]                    
    ldxdw r1, [r10-0xb0]                    
    mov64 r3, r5                                    r3 = r5
    add64 r3, r1                                    r3 += r1   ///  r3 = r3.wrapping_add(r1)
    ldxdw r1, [r10-0x110]                   
    jgt r5, r3, lbb_9721                            if r5 > r3 { pc += 1 }
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
lbb_9721:
    or64 r4, r2                                     r4 |= r2   ///  r4 = r4.or(r2)
    and64 r4, 1                                     r4 &= 1   ///  r4 = r4.and(1)
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
    jne r4, 0, lbb_9497                             if r4 != (0 as i32 as i64 as u64) { pc += -228 }
    ldxdw r2, [r10-0xa0]                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -192                                  r1 += -192   ///  r1 = r1.wrapping_add(-192 as i32 as i64 as u64)
    lddw r4, 0x38d7ea4c68000                        r4 load str located at 1000000000000000
    mov64 r5, 0                                     r5 = 0 as i32 as i64 as u64
    call function_30496                     
    ldxdw r1, [r10-0xc0]                    
    ldxdw r2, [r10-0x128]                   
    mov64 r4, r2                                    r4 = r2
    add64 r4, r1                                    r4 += r1   ///  r4 = r4.wrapping_add(r1)
    mov64 r3, 1                                     r3 = 1 as i32 as i64 as u64
    jgt r2, r4, lbb_9612                            if r2 > r4 { pc += -126 }
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
    ja lbb_9612                                     if true { pc += -128 }
lbb_9740:
    mov64 r2, 1                                     r2 = 1 as i32 as i64 as u64
    mov64 r4, r9                                    r4 = r9
    jeq r3, 0, lbb_9497                             if r3 == (0 as i32 as i64 as u64) { pc += -246 }
    mov64 r9, r4                                    r9 = r4
    ldxdw r3, [r10-0x100]                   
    jne r3, 0, lbb_9747                             if r3 != (0 as i32 as i64 as u64) { pc += 1 }
    ja lbb_9497                                     if true { pc += -250 }
lbb_9747:
    mov64 r9, 0                                     r9 = 0 as i32 as i64 as u64
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
    ja lbb_9497                                     if true { pc += -253 }
lbb_9750:
    ldxdw r5, [r10-0xc8]                    
    ldxdw r1, [r10-0xe0]                    
    mov64 r3, r5                                    r3 = r5
    add64 r3, r1                                    r3 += r1   ///  r3 = r3.wrapping_add(r1)
    ldxdw r1, [r10-0x110]                   
    jgt r5, r3, lbb_9757                            if r5 > r3 { pc += 1 }
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
lbb_9757:
    or64 r4, r2                                     r4 |= r2   ///  r4 = r4.or(r2)
    and64 r4, 1                                     r4 &= 1   ///  r4 = r4.and(1)
    mov64 r9, 0                                     r9 = 0 as i32 as i64 as u64
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
    jne r4, 0, lbb_9497                             if r4 != (0 as i32 as i64 as u64) { pc += -265 }
    ldxdw r2, [r10-0xd0]                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -240                                  r1 += -240   ///  r1 = r1.wrapping_add(-240 as i32 as i64 as u64)
    lddw r4, 0x38d7ea4c68000                        r4 load str located at 1000000000000000
    mov64 r5, 0                                     r5 = 0 as i32 as i64 as u64
    call function_30496                     
    ldxdw r1, [r10-0xf0]                    
    ldxdw r2, [r10-0x128]                   
    mov64 r3, r2                                    r3 = r2
    add64 r3, r1                                    r3 += r1   ///  r3 = r3.wrapping_add(r1)
    mov64 r4, 1                                     r4 = 1 as i32 as i64 as u64
    jgt r2, r3, lbb_9776                            if r2 > r3 { pc += 1 }
    mov64 r4, 0                                     r4 = 0 as i32 as i64 as u64
lbb_9776:
    and64 r4, 1                                     r4 &= 1   ///  r4 = r4.and(1)
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
    ldxdw r1, [r10-0x110]                   
    jne r4, 0, lbb_9497                             if r4 != (0 as i32 as i64 as u64) { pc += -283 }
    mov64 r2, 1                                     r2 = 1 as i32 as i64 as u64
    mov64 r9, r3                                    r9 = r3
    ja lbb_9497                                     if true { pc += -286 }

function_9783:
    mov64 r0, 0                                     r0 = 0 as i32 as i64 as u64
    jgt r3, r4, lbb_9788                            if r3 > r4 { pc += 3 }
    sub64 r4, r3                                    r4 -= r3   ///  r4 = r4.wrapping_sub(r3)
    ldxdw r3, [r2+0x0]                      
    jgt r3, r4, lbb_9791                            if r3 > r4 { pc += 3 }
lbb_9788:
    stxw [r1+0x4], r5                       
    stxw [r1+0x0], r0                       
    exit                                    
lbb_9791:
    mov64 r0, 1                                     r0 = 1 as i32 as i64 as u64
    mov64 r5, 0                                     r5 = 0 as i32 as i64 as u64
    ldxdw r3, [r2+0x8]                      
    jgt r3, r4, lbb_9788                            if r3 > r4 { pc += -7 }
    sub64 r4, r3                                    r4 -= r3   ///  r4 = r4.wrapping_sub(r3)
    mov64 r0, 0                                     r0 = 0 as i32 as i64 as u64
    lddw r3, 0xfffffffe                             r3 load str located at 4294967294
    jgt r4, r3, lbb_9788                            if r4 > r3 { pc += -12 }
    add64 r4, 1                                     r4 += 1   ///  r4 = r4.wrapping_add(1 as i32 as i64 as u64)
    ldxw r5, [r2+0x10]                      
    mov64 r3, r4                                    r3 = r4
    lsh64 r3, 32                                    r3 <<= 32   ///  r3 = r3.wrapping_shl(32)
    rsh64 r3, 32                                    r3 >>= 32   ///  r3 = r3.wrapping_shr(32)
    mul64 r5, r3                                    r5 *= r3   ///  r5 = r5.wrapping_mul(r3)
    mov64 r3, r5                                    r3 = r5
    rsh64 r3, 32                                    r3 >>= 32   ///  r3 = r3.wrapping_shr(32)
    jne r3, 0, lbb_9809                             if r3 != (0 as i32 as i64 as u64) { pc += 0 }
lbb_9809:
    jne r3, 0, lbb_9788                             if r3 != (0 as i32 as i64 as u64) { pc += -22 }
    lsh64 r4, 32                                    r4 <<= 32   ///  r4 = r4.wrapping_shl(32)
    rsh64 r4, 32                                    r4 >>= 32   ///  r4 = r4.wrapping_shr(32)
    lsh64 r5, 32                                    r5 <<= 32   ///  r5 = r5.wrapping_shl(32)
    rsh64 r5, 32                                    r5 >>= 32   ///  r5 = r5.wrapping_shr(32)
    mul64 r5, r4                                    r5 *= r4   ///  r5 = r5.wrapping_mul(r4)
    mov64 r3, r5                                    r3 = r5
    lsh64 r3, 32                                    r3 <<= 32   ///  r3 = r3.wrapping_shl(32)
    rsh64 r3, 32                                    r3 >>= 32   ///  r3 = r3.wrapping_shr(32)
    ldxw r2, [r2+0x14]                      
    jgt r3, r2, lbb_9821                            if r3 > r2 { pc += 1 }
    mov64 r2, r3                                    r2 = r3
lbb_9821:
    mov64 r3, r5                                    r3 = r5
    rsh64 r3, 32                                    r3 >>= 32   ///  r3 = r3.wrapping_shr(32)
    jne r3, 0, lbb_9825                             if r3 != (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r5, r2                                    r5 = r2
lbb_9825:
    mov64 r0, 1                                     r0 = 1 as i32 as i64 as u64
    jeq r3, 0, lbb_9788                             if r3 == (0 as i32 as i64 as u64) { pc += -39 }
    mov64 r0, 0                                     r0 = 0 as i32 as i64 as u64
    ja lbb_9788                                     if true { pc += -41 }

function_9829:
    mov64 r9, r3                                    r9 = r3
    mov64 r7, r2                                    r7 = r2
    mov64 r8, r1                                    r8 = r1
    ldxdw r3, [r7+0x0]                      
    ldxdw r2, [r9+0x0]                      
    mov64 r1, r10                                   r1 = r10
    add64 r1, -96                                   r1 += -96   ///  r1 = r1.wrapping_add(-96 as i32 as i64 as u64)
    stxdw [r10-0xe8], r2                    
    stxdw [r10-0xf0], r3                    
    mov64 r4, 2                                     r4 = 2 as i32 as i64 as u64
    mov64 r5, 0                                     r5 = 0 as i32 as i64 as u64
    call function_16110                     
    ldxdw r1, [r10-0x58]                    
    stxdw [r10-0x78], r1                    
    ldxdw r1, [r10-0x50]                    
    stxdw [r10-0x70], r1                    
    ldxdw r1, [r10-0x48]                    
    stxdw [r10-0x68], r1                    
    ldxdw r6, [r10-0x60]                    
    lddw r1, 0x8000000000000000                     r1 load str located at -9223372036854775808
    jeq r6, r1, lbb_9874                            if r6 == r1 { pc += 23 }
    stxdw [r10-0xf8], r8                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -168                                  r1 += -168   ///  r1 = r1.wrapping_add(-168 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -64                                   r2 += -64   ///  r2 = r2.wrapping_add(-64 as i32 as i64 as u64)
    mov64 r3, 48                                    r3 = 48 as i32 as i64 as u64
    call function_30349                     
    stxdw [r10-0xc8], r6                    
    ldxdw r1, [r10-0x78]                    
    stxdw [r10-0xc0], r1                    
    ldxdw r1, [r10-0x70]                    
    stxdw [r10-0xb8], r1                    
    ldxdw r1, [r10-0x68]                    
    stxdw [r10-0xb0], r1                    
    ldxdw r0, [r7+0x8]                      
    ldxdw r2, [r0+0x0]                      
    add64 r2, 1                                     r2 += 1   ///  r2 = r2.wrapping_add(1 as i32 as i64 as u64)
    mov64 r3, 1                                     r3 = 1 as i32 as i64 as u64
    jeq r2, 0, lbb_9871                             if r2 == (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
lbb_9871:
    stxdw [r0+0x0], r2                      
    jne r3, 1, lbb_9881                             if r3 != (1 as i32 as i64 as u64) { pc += 8 }
lbb_9873:
    syscall [invalid]                       
lbb_9874:
    ldxdw r1, [r10-0x68]                    
    stxdw [r8+0x10], r1                     
    ldxdw r1, [r10-0x70]                    
    stxdw [r8+0x8], r1                      
    ldxdw r1, [r10-0x78]                    
    stxdw [r8+0x0], r1                      
    ja lbb_10080                                    if true { pc += 199 }
lbb_9881:
    ldxdw r6, [r7+0x10]                     
    ldxdw r3, [r6+0x0]                      
    add64 r3, 1                                     r3 += 1   ///  r3 = r3.wrapping_add(1 as i32 as i64 as u64)
    mov64 r4, 1                                     r4 = 1 as i32 as i64 as u64
    jeq r3, 0, lbb_9887                             if r3 == (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r4, 0                                     r4 = 0 as i32 as i64 as u64
lbb_9887:
    stxdw [r6+0x0], r3                      
    jne r4, 1, lbb_9890                             if r4 != (1 as i32 as i64 as u64) { pc += 1 }
    ja lbb_9873                                     if true { pc += -17 }
lbb_9890:
    ldxdw r3, [r9+0x8]                      
    ldxdw r4, [r3+0x0]                      
    add64 r4, 1                                     r4 += 1   ///  r4 = r4.wrapping_add(1 as i32 as i64 as u64)
    mov64 r5, 1                                     r5 = 1 as i32 as i64 as u64
    jeq r4, 0, lbb_9896                             if r4 == (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r5, 0                                     r5 = 0 as i32 as i64 as u64
lbb_9896:
    ldxb r1, [r7+0x2a]                      
    stxdw [r10-0x108], r1                   
    ldxb r1, [r7+0x29]                      
    stxdw [r10-0x100], r1                   
    ldxb r2, [r7+0x28]                      
    ldxdw r8, [r7+0x20]                     
    ldxdw r1, [r7+0x18]                     
    stxdw [r3+0x0], r4                      
    jne r5, 1, lbb_9906                             if r5 != (1 as i32 as i64 as u64) { pc += 1 }
    ja lbb_9873                                     if true { pc += -33 }
lbb_9906:
    ldxdw r7, [r9+0x10]                     
    ldxdw r4, [r7+0x0]                      
    add64 r4, 1                                     r4 += 1   ///  r4 = r4.wrapping_add(1 as i32 as i64 as u64)
    mov64 r5, 1                                     r5 = 1 as i32 as i64 as u64
    jeq r4, 0, lbb_9912                             if r4 == (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r5, 0                                     r5 = 0 as i32 as i64 as u64
lbb_9912:
    stxdw [r10-0x118], r6                   
    stxdw [r10-0x110], r0                   
    stxdw [r7+0x0], r4                      
    jne r5, 1, lbb_9917                             if r5 != (1 as i32 as i64 as u64) { pc += 1 }
    ja lbb_9873                                     if true { pc += -44 }
lbb_9917:
    ldxdw r4, [r9+0x18]                     
    ldxdw r5, [r9+0x20]                     
    ldxb r0, [r9+0x28]                      
    ldxb r6, [r9+0x29]                      
    ldxb r9, [r9+0x2a]                      
    stxb [r10-0x6], r9                      
    stxb [r10-0x7], r6                      
    stxb [r10-0x8], r0                      
    stxdw [r10-0x10], r5                    
    stxdw [r10-0x18], r4                    
    stxdw [r10-0x20], r7                    
    stxdw [r10-0x28], r3                    
    ldxdw r6, [r10-0xe8]                    
    stxdw [r10-0x30], r6                    
    ldxdw r3, [r10-0x108]                   
    stxb [r10-0x36], r3                     
    ldxdw r3, [r10-0x100]                   
    stxb [r10-0x37], r3                     
    stxb [r10-0x38], r2                     
    stxdw [r10-0x40], r8                    
    stxdw [r10-0x48], r1                    
    ldxdw r1, [r10-0x118]                   
    stxdw [r10-0x50], r1                    
    ldxdw r1, [r10-0x110]                   
    stxdw [r10-0x58], r1                    
    ldxdw r1, [r10-0xf0]                    
    stxdw [r10-0x60], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -224                                  r1 += -224   ///  r1 = r1.wrapping_add(-224 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -200                                  r2 += -200   ///  r2 = r2.wrapping_add(-200 as i32 as i64 as u64)
    mov64 r3, r10                                   r3 = r10
    add64 r3, -96                                   r3 += -96   ///  r3 = r3.wrapping_add(-96 as i32 as i64 as u64)
    mov64 r4, 2                                     r4 = 2 as i32 as i64 as u64
    call function_16479                     
    lddw r1, 0x800000000000001a                     r1 load str located at -9223372036854775782
    ldxdw r2, [r10-0xe0]                    
    jeq r2, r1, lbb_9957                            if r2 == r1 { pc += 1 }
    ja lbb_10000                                    if true { pc += 43 }
lbb_9957:
    ldxdw r1, [r10-0x50]                    
    ldxdw r2, [r10-0x58]                    
    ldxdw r3, [r2+0x0]                      
    add64 r3, -1                                    r3 += -1   ///  r3 = r3.wrapping_add(-1 as i32 as i64 as u64)
    stxdw [r2+0x0], r3                      
    jne r3, 0, lbb_9966                             if r3 != (0 as i32 as i64 as u64) { pc += 3 }
    ldxdw r3, [r2+0x8]                      
    add64 r3, -1                                    r3 += -1   ///  r3 = r3.wrapping_add(-1 as i32 as i64 as u64)
    stxdw [r2+0x8], r3                      
lbb_9966:
    ldxdw r2, [r1+0x0]                      
    add64 r2, -1                                    r2 += -1   ///  r2 = r2.wrapping_add(-1 as i32 as i64 as u64)
    stxdw [r1+0x0], r2                      
    jne r2, 0, lbb_9973                             if r2 != (0 as i32 as i64 as u64) { pc += 3 }
    ldxdw r2, [r1+0x8]                      
    add64 r2, -1                                    r2 += -1   ///  r2 = r2.wrapping_add(-1 as i32 as i64 as u64)
    stxdw [r1+0x8], r2                      
lbb_9973:
    ldxdw r1, [r10-0x20]                    
    ldxdw r2, [r10-0x28]                    
    ldxdw r3, [r2+0x0]                      
    add64 r3, -1                                    r3 += -1   ///  r3 = r3.wrapping_add(-1 as i32 as i64 as u64)
    stxdw [r2+0x0], r3                      
    jne r3, 0, lbb_9982                             if r3 != (0 as i32 as i64 as u64) { pc += 3 }
    ldxdw r3, [r2+0x8]                      
    add64 r3, -1                                    r3 += -1   ///  r3 = r3.wrapping_add(-1 as i32 as i64 as u64)
    stxdw [r2+0x8], r3                      
lbb_9982:
    ldxdw r2, [r1+0x0]                      
    add64 r2, -1                                    r2 += -1   ///  r2 = r2.wrapping_add(-1 as i32 as i64 as u64)
    stxdw [r1+0x0], r2                      
    jne r2, 0, lbb_9989                             if r2 != (0 as i32 as i64 as u64) { pc += 3 }
    ldxdw r2, [r1+0x8]                      
    add64 r2, -1                                    r2 += -1   ///  r2 = r2.wrapping_add(-1 as i32 as i64 as u64)
    stxdw [r1+0x8], r2                      
lbb_9989:
    mov64 r1, r10                                   r1 = r10
    add64 r1, -200                                  r1 += -200   ///  r1 = r1.wrapping_add(-200 as i32 as i64 as u64)
    call function_16610                     
    lddw r1, 0x8000000000000000                     r1 load str located at -9223372036854775808
    ldxdw r2, [r10-0xa8]                    
    jeq r2, r1, lbb_9997                            if r2 == r1 { pc += 1 }
    ja lbb_10040                                    if true { pc += 43 }
lbb_9997:
    lddw r1, 0x8000000000000002                     r1 load str located at -9223372036854775806
    ja lbb_10078                                    if true { pc += 78 }
lbb_10000:
    ldxdw r1, [r10-0xd0]                    
    ldxdw r8, [r10-0xf8]                    
    stxdw [r8+0x10], r1                     
    ldxdw r1, [r10-0xd8]                    
    stxdw [r8+0x8], r1                      
    ldxdw r1, [r10-0xe0]                    
    stxdw [r8+0x0], r1                      
    ldxdw r1, [r10-0x50]                    
    ldxdw r2, [r10-0x58]                    
    ldxdw r3, [r2+0x0]                      
    add64 r3, -1                                    r3 += -1   ///  r3 = r3.wrapping_add(-1 as i32 as i64 as u64)
    stxdw [r2+0x0], r3                      
    jne r3, 0, lbb_10016                            if r3 != (0 as i32 as i64 as u64) { pc += 3 }
    ldxdw r3, [r2+0x8]                      
    add64 r3, -1                                    r3 += -1   ///  r3 = r3.wrapping_add(-1 as i32 as i64 as u64)
    stxdw [r2+0x8], r3                      
lbb_10016:
    ldxdw r2, [r1+0x0]                      
    add64 r2, -1                                    r2 += -1   ///  r2 = r2.wrapping_add(-1 as i32 as i64 as u64)
    stxdw [r1+0x0], r2                      
    jne r2, 0, lbb_10023                            if r2 != (0 as i32 as i64 as u64) { pc += 3 }
    ldxdw r2, [r1+0x8]                      
    add64 r2, -1                                    r2 += -1   ///  r2 = r2.wrapping_add(-1 as i32 as i64 as u64)
    stxdw [r1+0x8], r2                      
lbb_10023:
    ldxdw r1, [r10-0x20]                    
    ldxdw r2, [r10-0x28]                    
    ldxdw r3, [r2+0x0]                      
    add64 r3, -1                                    r3 += -1   ///  r3 = r3.wrapping_add(-1 as i32 as i64 as u64)
    stxdw [r2+0x0], r3                      
    jne r3, 0, lbb_10032                            if r3 != (0 as i32 as i64 as u64) { pc += 3 }
    ldxdw r3, [r2+0x8]                      
    add64 r3, -1                                    r3 += -1   ///  r3 = r3.wrapping_add(-1 as i32 as i64 as u64)
    stxdw [r2+0x8], r3                      
lbb_10032:
    ldxdw r2, [r1+0x0]                      
    add64 r2, -1                                    r2 += -1   ///  r2 = r2.wrapping_add(-1 as i32 as i64 as u64)
    stxdw [r1+0x0], r2                      
    jne r2, 0, lbb_10080                            if r2 != (0 as i32 as i64 as u64) { pc += 44 }
    ldxdw r2, [r1+0x8]                      
    add64 r2, -1                                    r2 += -1   ///  r2 = r2.wrapping_add(-1 as i32 as i64 as u64)
    stxdw [r1+0x8], r2                      
    ja lbb_10080                                    if true { pc += 40 }
lbb_10040:
    ldxdw r2, [r10-0xc8]                    
    ldxdw r1, [r10-0xc0]                    
    ldxdw r3, [r10-0xb8]                    
    ldxdw r4, [r10-0xb0]                    
    ldxdw r5, [r10-0x98]                    
    stxdw [r10-0x30], r5                    
    stxdw [r10-0x48], r4                    
    stxdw [r10-0x50], r3                    
    stxdw [r10-0x58], r1                    
    ldxdw r1, [r10-0xa0]                    
    stxdw [r10-0x38], r1                    
    stxdw [r10-0x60], r2                    
    ldxdw r3, [r6+0x0]                      
    jeq r2, r3, lbb_10056                           if r2 == r3 { pc += 2 }
lbb_10054:
    mov64 r2, 1                                     r2 = 1 as i32 as i64 as u64
    ja lbb_10066                                    if true { pc += 10 }
lbb_10056:
    ldxdw r2, [r6+0x8]                      
    ldxdw r3, [r10-0x58]                    
    jne r3, r2, lbb_10054                           if r3 != r2 { pc += -5 }
    ldxdw r2, [r6+0x10]                     
    ldxdw r3, [r10-0x50]                    
    jne r3, r2, lbb_10054                           if r3 != r2 { pc += -8 }
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
    ldxdw r3, [r6+0x18]                     
    ldxdw r4, [r10-0x48]                    
    jne r4, r3, lbb_10054                           if r4 != r3 { pc += -12 }
lbb_10066:
    jne r2, 0, lbb_10076                            if r2 != (0 as i32 as i64 as u64) { pc += 9 }
    ldxdw r2, [r10-0x30]                    
    ldxdw r8, [r10-0xf8]                    
    jne r2, 8, lbb_10081                            if r2 != (8 as i32 as i64 as u64) { pc += 11 }
    ldxdw r1, [r1+0x0]                      
    lddw r2, 0x800000000000001a                     r2 load str located at -9223372036854775782
    stxdw [r8+0x0], r2                      
    stxdw [r8+0x8], r1                      
    ja lbb_10080                                    if true { pc += 4 }
lbb_10076:
    lddw r1, 0x8000000000000006                     r1 load str located at -9223372036854775802
lbb_10078:
    ldxdw r2, [r10-0xf8]                    
    stxdw [r2+0x0], r1                      
lbb_10080:
    exit                                    
lbb_10081:
    lddw r1, 0x8000000000000002                     r1 load str located at -9223372036854775806
    stxdw [r8+0x0], r1                      
    ja lbb_10080                                    if true { pc += -5 }

function_10085:
    mov64 r9, r5                                    r9 = r5
    stxdw [r10-0x170], r4                   
    mov64 r8, r1                                    r8 = r1
    stxdw [r10-0x168], r2                   
    ldxdw r4, [r2+0x0]                      
    stxdw [r10-0x160], r3                   
    ldxdw r5, [r3+0x0]                      
    ldxdw r7, [r9-0xff8]                    
    ldxdw r3, [r7+0x0]                      
    ldxdw r1, [r9-0xff0]                    
    stxdw [r10-0x158], r1                   
    ldxdw r2, [r1+0x0]                      
    ldxdw r1, [r9-0xfe0]                    
    stxdw [r10-0xfe0], r1                   
    ldxdw r1, [r9-0xfd8]                    
    stxdw [r10-0xfd8], r1                   
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    stxdw [r10-0xfe8], r1                   
    mov64 r1, 8                                     r1 = 8 as i32 as i64 as u64
    stxdw [r10-0xff0], r1                   
    stxdw [r10-0x190], r5                   
    stxdw [r10-0xff8], r5                   
    stxdw [r10-0x188], r2                   
    stxdw [r10-0x1000], r2                  
    ldxdw r2, [r9-0xfe8]                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -208                                  r1 += -208   ///  r1 = r1.wrapping_add(-208 as i32 as i64 as u64)
    mov64 r5, r10                                   r5 = r10
    stxdw [r10-0x178], r3                   
    stxdw [r10-0x180], r4                   
    call function_15854                     
    ldxdw r1, [r10-0xc8]                    
    stxdw [r10-0xe8], r1                    
    ldxdw r1, [r10-0xc0]                    
    stxdw [r10-0xe0], r1                    
    ldxdw r1, [r10-0xb8]                    
    stxdw [r10-0xd8], r1                    
    ldxdw r6, [r10-0xd0]                    
    lddw r1, 0x8000000000000000                     r1 load str located at -9223372036854775808
    jeq r6, r1, lbb_10152                           if r6 == r1 { pc += 26 }
    stxdw [r10-0x198], r8                   
    ldxdw r9, [r9-0x1000]                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -280                                  r1 += -280   ///  r1 = r1.wrapping_add(-280 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -176                                  r2 += -176   ///  r2 = r2.wrapping_add(-176 as i32 as i64 as u64)
    mov64 r3, 48                                    r3 = 48 as i32 as i64 as u64
    call function_30349                     
    stxdw [r10-0x138], r6                   
    ldxdw r1, [r10-0xe8]                    
    stxdw [r10-0x130], r1                   
    ldxdw r1, [r10-0xe0]                    
    stxdw [r10-0x128], r1                   
    ldxdw r1, [r10-0xd8]                    
    stxdw [r10-0x120], r1                   
    ldxdw r6, [r7+0x8]                      
    ldxdw r1, [r6+0x0]                      
    add64 r1, 1                                     r1 += 1   ///  r1 = r1.wrapping_add(1 as i32 as i64 as u64)
    mov64 r2, 1                                     r2 = 1 as i32 as i64 as u64
    jeq r1, 0, lbb_10147                            if r1 == (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
lbb_10147:
    stxdw [r6+0x0], r1                      
    ldxdw r8, [r10-0x160]                   
    ldxdw r4, [r10-0x168]                   
    jne r2, 1, lbb_10159                            if r2 != (1 as i32 as i64 as u64) { pc += 8 }
lbb_10151:
    syscall [invalid]                       
lbb_10152:
    ldxdw r1, [r10-0xd8]                    
    stxdw [r8+0x10], r1                     
    ldxdw r1, [r10-0xe0]                    
    stxdw [r8+0x8], r1                      
    ldxdw r1, [r10-0xe8]                    
    stxdw [r8+0x0], r1                      
    ja lbb_10357                                    if true { pc += 198 }
lbb_10159:
    ldxdw r3, [r7+0x10]                     
    ldxdw r1, [r3+0x0]                      
    add64 r1, 1                                     r1 += 1   ///  r1 = r1.wrapping_add(1 as i32 as i64 as u64)
    mov64 r2, 1                                     r2 = 1 as i32 as i64 as u64
    jeq r1, 0, lbb_10165                            if r1 == (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
lbb_10165:
    stxdw [r3+0x0], r1                      
    jne r2, 1, lbb_10168                            if r2 != (1 as i32 as i64 as u64) { pc += 1 }
    ja lbb_10151                                    if true { pc += -17 }
lbb_10168:
    ldxdw r0, [r4+0x8]                      
    ldxdw r1, [r0+0x0]                      
    add64 r1, 1                                     r1 += 1   ///  r1 = r1.wrapping_add(1 as i32 as i64 as u64)
    mov64 r2, 1                                     r2 = 1 as i32 as i64 as u64
    jeq r1, 0, lbb_10174                            if r1 == (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
lbb_10174:
    ldxb r5, [r7+0x2a]                      
    stxdw [r10-0x1b8], r5                   
    ldxb r5, [r7+0x29]                      
    stxdw [r10-0x1b0], r5                   
    ldxb r5, [r7+0x28]                      
    stxdw [r10-0x1a8], r5                   
    ldxdw r5, [r7+0x20]                     
    stxdw [r10-0x1a0], r5                   
    ldxdw r5, [r7+0x18]                     
    stxdw [r0+0x0], r1                      
    jne r2, 1, lbb_10186                            if r2 != (1 as i32 as i64 as u64) { pc += 1 }
    ja lbb_10151                                    if true { pc += -35 }
lbb_10186:
    ldxdw r7, [r4+0x10]                     
    ldxdw r1, [r7+0x0]                      
    add64 r1, 1                                     r1 += 1   ///  r1 = r1.wrapping_add(1 as i32 as i64 as u64)
    mov64 r2, 1                                     r2 = 1 as i32 as i64 as u64
    jeq r1, 0, lbb_10192                            if r1 == (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
lbb_10192:
    stxdw [r10-0x1c0], r7                   
    stxdw [r7+0x0], r1                      
    jne r2, 1, lbb_10196                            if r2 != (1 as i32 as i64 as u64) { pc += 1 }
    ja lbb_10151                                    if true { pc += -45 }
lbb_10196:
    ldxdw r1, [r10-0x158]                   
    ldxdw r7, [r1+0x8]                      
    ldxdw r1, [r7+0x0]                      
    add64 r1, 1                                     r1 += 1   ///  r1 = r1.wrapping_add(1 as i32 as i64 as u64)
    mov64 r2, 1                                     r2 = 1 as i32 as i64 as u64
    jeq r1, 0, lbb_10203                            if r1 == (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
lbb_10203:
    stxdw [r10-0x1c8], r5                   
    ldxb r5, [r4+0x2a]                      
    stxdw [r10-0x1e8], r5                   
    ldxb r5, [r4+0x29]                      
    stxdw [r10-0x1e0], r5                   
    ldxb r5, [r4+0x28]                      
    stxdw [r10-0x1d8], r5                   
    ldxdw r5, [r4+0x20]                     
    stxdw [r10-0x1d0], r5                   
    ldxdw r4, [r4+0x18]                     
    stxdw [r7+0x0], r1                      
    jne r2, 1, lbb_10216                            if r2 != (1 as i32 as i64 as u64) { pc += 1 }
    ja lbb_10151                                    if true { pc += -65 }
lbb_10216:
    ldxdw r1, [r10-0x158]                   
    ldxdw r5, [r1+0x10]                     
    ldxdw r1, [r5+0x0]                      
    add64 r1, 1                                     r1 += 1   ///  r1 = r1.wrapping_add(1 as i32 as i64 as u64)
    mov64 r2, 1                                     r2 = 1 as i32 as i64 as u64
    jeq r1, 0, lbb_10223                            if r1 == (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
lbb_10223:
    stxdw [r10-0x1f8], r4                   
    stxdw [r10-0x1f0], r0                   
    stxdw [r10-0x168], r3                   
    stxdw [r5+0x0], r1                      
    jne r2, 1, lbb_10229                            if r2 != (1 as i32 as i64 as u64) { pc += 1 }
    ja lbb_10151                                    if true { pc += -78 }
lbb_10229:
    stxdw [r10-0x210], r5                   
    stxdw [r10-0x208], r7                   
    stxdw [r10-0x200], r9                   
    ldxdw r0, [r8+0x8]                      
    ldxdw r3, [r0+0x0]                      
    add64 r3, 1                                     r3 += 1   ///  r3 = r3.wrapping_add(1 as i32 as i64 as u64)
    mov64 r4, 1                                     r4 = 1 as i32 as i64 as u64
    jeq r3, 0, lbb_10238                            if r3 == (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r4, 0                                     r4 = 0 as i32 as i64 as u64
lbb_10238:
    ldxdw r1, [r10-0x158]                   
    ldxb r2, [r1+0x2a]                      
    stxdw [r10-0x218], r2                   
    ldxb r2, [r1+0x29]                      
    ldxb r5, [r1+0x28]                      
    ldxdw r7, [r1+0x20]                     
    ldxdw r9, [r1+0x18]                     
    stxdw [r0+0x0], r3                      
    jne r4, 1, lbb_10248                            if r4 != (1 as i32 as i64 as u64) { pc += 1 }
    ja lbb_10151                                    if true { pc += -97 }
lbb_10248:
    ldxdw r3, [r8+0x10]                     
    ldxdw r4, [r3+0x0]                      
    add64 r4, 1                                     r4 += 1   ///  r4 = r4.wrapping_add(1 as i32 as i64 as u64)
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    jeq r4, 0, lbb_10254                            if r4 == (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
lbb_10254:
    stxdw [r10-0x220], r2                   
    stxdw [r10-0x158], r6                   
    stxdw [r3+0x0], r4                      
    jne r1, 1, lbb_10259                            if r1 != (1 as i32 as i64 as u64) { pc += 1 }
    ja lbb_10151                                    if true { pc += -108 }
lbb_10259:
    ldxdw r1, [r8+0x18]                     
    ldxdw r4, [r8+0x20]                     
    ldxb r2, [r8+0x28]                      
    ldxb r6, [r8+0x29]                      
    ldxb r8, [r8+0x2a]                      
    stxb [r10-0x16], r8                     
    stxb [r10-0x17], r6                     
    stxb [r10-0x18], r2                     
    stxdw [r10-0x20], r4                    
    stxdw [r10-0x28], r1                    
    stxdw [r10-0x30], r3                    
    stxdw [r10-0x38], r0                    
    ldxdw r1, [r10-0x190]                   
    stxdw [r10-0x40], r1                    
    ldxdw r1, [r10-0x218]                   
    stxb [r10-0x46], r1                     
    ldxdw r1, [r10-0x220]                   
    stxb [r10-0x47], r1                     
    stxb [r10-0x48], r5                     
    stxdw [r10-0x50], r7                    
    stxdw [r10-0x58], r9                    
    ldxdw r1, [r10-0x210]                   
    stxdw [r10-0x60], r1                    
    ldxdw r1, [r10-0x208]                   
    stxdw [r10-0x68], r1                    
    ldxdw r1, [r10-0x188]                   
    stxdw [r10-0x70], r1                    
    ldxdw r1, [r10-0x1e8]                   
    stxb [r10-0x76], r1                     
    ldxdw r1, [r10-0x1e0]                   
    stxb [r10-0x77], r1                     
    ldxdw r1, [r10-0x1d8]                   
    stxb [r10-0x78], r1                     
    ldxdw r1, [r10-0x1d0]                   
    stxdw [r10-0x80], r1                    
    ldxdw r1, [r10-0x1f8]                   
    stxdw [r10-0x88], r1                    
    ldxdw r1, [r10-0x1c0]                   
    stxdw [r10-0x90], r1                    
    ldxdw r1, [r10-0x1f0]                   
    stxdw [r10-0x98], r1                    
    ldxdw r1, [r10-0x180]                   
    stxdw [r10-0xa0], r1                    
    ldxdw r1, [r10-0x1b8]                   
    stxb [r10-0xa6], r1                     
    ldxdw r1, [r10-0x1b0]                   
    stxb [r10-0xa7], r1                     
    ldxdw r1, [r10-0x1a8]                   
    stxb [r10-0xa8], r1                     
    ldxdw r1, [r10-0x1a0]                   
    stxdw [r10-0xb0], r1                    
    ldxdw r1, [r10-0x1c8]                   
    stxdw [r10-0xb8], r1                    
    ldxdw r1, [r10-0x168]                   
    stxdw [r10-0xc0], r1                    
    ldxdw r1, [r10-0x158]                   
    stxdw [r10-0xc8], r1                    
    ldxdw r1, [r10-0x178]                   
    stxdw [r10-0xd0], r1                    
    ldxdw r1, [r10-0x200]                   
    stxdw [r10-0x8], r1                     
    ldxdw r1, [r10-0x170]                   
    stxdw [r10-0x10], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -16                                   r1 += -16   ///  r1 = r1.wrapping_add(-16 as i32 as i64 as u64)
    stxdw [r10-0x1000], r1                  
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    stxdw [r10-0xff8], r1                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -336                                  r1 += -336   ///  r1 = r1.wrapping_add(-336 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -312                                  r2 += -312   ///  r2 = r2.wrapping_add(-312 as i32 as i64 as u64)
    mov64 r3, r10                                   r3 = r10
    add64 r3, -208                                  r3 += -208   ///  r3 = r3.wrapping_add(-208 as i32 as i64 as u64)
    mov64 r5, r10                                   r5 = r10
    mov64 r4, 4                                     r4 = 4 as i32 as i64 as u64
    call function_16486                     
    lddw r6, 0x800000000000001a                     r6 load str located at -9223372036854775782
    ldxdw r1, [r10-0x150]                   
    jeq r1, r6, lbb_10341                           if r1 == r6 { pc += 1 }
    ja lbb_10347                                    if true { pc += 6 }
lbb_10341:
    mov64 r1, r10                                   r1 = r10
    add64 r1, -208                                  r1 += -208   ///  r1 = r1.wrapping_add(-208 as i32 as i64 as u64)
    call function_472                       
    ldxdw r1, [r10-0x198]                   
    stxdw [r1+0x0], r6                      
    ja lbb_10357                                    if true { pc += 10 }
lbb_10347:
    ldxdw r1, [r10-0x140]                   
    ldxdw r2, [r10-0x198]                   
    stxdw [r2+0x10], r1                     
    ldxdw r1, [r10-0x148]                   
    stxdw [r2+0x8], r1                      
    ldxdw r1, [r10-0x150]                   
    stxdw [r2+0x0], r1                      
    mov64 r1, r10                                   r1 = r10
    add64 r1, -208                                  r1 += -208   ///  r1 = r1.wrapping_add(-208 as i32 as i64 as u64)
    call function_472                       
lbb_10357:
    exit                                    

function_10358:
    mov64 r0, r4                                    r0 = r4
    mov64 r8, r3                                    r8 = r3
    mov64 r7, r2                                    r7 = r2
    mov64 r6, r1                                    r6 = r1
    ldxdw r4, [r7+0x0]                      
    ldxdw r3, [r8+0x0]                      
    stxdw [r10-0x150], r0                   
    ldxdw r0, [r0+0x0]                      
    ldxdw r1, [r5-0x1000]                   
    stxdw [r10-0x148], r1                   
    ldxdw r2, [r1+0x0]                      
    ldxdw r1, [r5-0xff0]                    
    stxdw [r10-0xfe0], r1                   
    ldxdw r1, [r5-0xfe8]                    
    stxdw [r10-0xfd8], r1                   
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    stxdw [r10-0xfe8], r1                   
    mov64 r1, 8                                     r1 = 8 as i32 as i64 as u64
    stxdw [r10-0xff0], r1                   
    stxdw [r10-0x170], r0                   
    stxdw [r10-0xff8], r0                   
    stxdw [r10-0x168], r2                   
    stxdw [r10-0x1000], r2                  
    ldxdw r2, [r5-0xff8]                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -192                                  r1 += -192   ///  r1 = r1.wrapping_add(-192 as i32 as i64 as u64)
    mov64 r5, r10                                   r5 = r10
    stxdw [r10-0x158], r3                   
    stxdw [r10-0x160], r4                   
    call function_15854                     
    ldxdw r1, [r10-0xb8]                    
    stxdw [r10-0xd8], r1                    
    ldxdw r1, [r10-0xb0]                    
    stxdw [r10-0xd0], r1                    
    ldxdw r1, [r10-0xa8]                    
    stxdw [r10-0xc8], r1                    
    ldxdw r9, [r10-0xc0]                    
    lddw r1, 0x8000000000000000                     r1 load str located at -9223372036854775808
    jeq r9, r1, lbb_10422                           if r9 == r1 { pc += 24 }
    stxdw [r10-0x180], r6                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -264                                  r1 += -264   ///  r1 = r1.wrapping_add(-264 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -160                                  r2 += -160   ///  r2 = r2.wrapping_add(-160 as i32 as i64 as u64)
    mov64 r3, 48                                    r3 = 48 as i32 as i64 as u64
    call function_30349                     
    stxdw [r10-0x128], r9                   
    ldxdw r1, [r10-0xd8]                    
    stxdw [r10-0x120], r1                   
    ldxdw r1, [r10-0xd0]                    
    stxdw [r10-0x118], r1                   
    ldxdw r1, [r10-0xc8]                    
    stxdw [r10-0x110], r1                   
    ldxdw r3, [r8+0x8]                      
    ldxdw r1, [r3+0x0]                      
    add64 r1, 1                                     r1 += 1   ///  r1 = r1.wrapping_add(1 as i32 as i64 as u64)
    mov64 r2, 1                                     r2 = 1 as i32 as i64 as u64
    jeq r1, 0, lbb_10418                            if r1 == (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
lbb_10418:
    stxdw [r3+0x0], r1                      
    ldxdw r6, [r10-0x150]                   
    jne r2, 1, lbb_10429                            if r2 != (1 as i32 as i64 as u64) { pc += 8 }
lbb_10421:
    syscall [invalid]                       
lbb_10422:
    ldxdw r1, [r10-0xc8]                    
    stxdw [r6+0x10], r1                     
    ldxdw r1, [r10-0xd0]                    
    stxdw [r6+0x8], r1                      
    ldxdw r1, [r10-0xd8]                    
    stxdw [r6+0x0], r1                      
    ja lbb_10617                                    if true { pc += 188 }
lbb_10429:
    ldxdw r0, [r8+0x10]                     
    ldxdw r1, [r0+0x0]                      
    add64 r1, 1                                     r1 += 1   ///  r1 = r1.wrapping_add(1 as i32 as i64 as u64)
    mov64 r2, 1                                     r2 = 1 as i32 as i64 as u64
    jeq r1, 0, lbb_10435                            if r1 == (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
lbb_10435:
    stxdw [r0+0x0], r1                      
    jne r2, 1, lbb_10438                            if r2 != (1 as i32 as i64 as u64) { pc += 1 }
    ja lbb_10421                                    if true { pc += -17 }
lbb_10438:
    ldxdw r9, [r7+0x8]                      
    ldxdw r1, [r9+0x0]                      
    add64 r1, 1                                     r1 += 1   ///  r1 = r1.wrapping_add(1 as i32 as i64 as u64)
    mov64 r2, 1                                     r2 = 1 as i32 as i64 as u64
    jeq r1, 0, lbb_10444                            if r1 == (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
lbb_10444:
    ldxb r4, [r8+0x2a]                      
    stxdw [r10-0x190], r4                   
    ldxb r4, [r8+0x29]                      
    stxdw [r10-0x188], r4                   
    ldxb r4, [r8+0x28]                      
    ldxdw r5, [r8+0x20]                     
    ldxdw r8, [r8+0x18]                     
    stxdw [r9+0x0], r1                      
    jne r2, 1, lbb_10454                            if r2 != (1 as i32 as i64 as u64) { pc += 1 }
    ja lbb_10421                                    if true { pc += -33 }
lbb_10454:
    ldxdw r1, [r7+0x10]                     
    stxdw [r10-0x178], r1                   
    ldxdw r1, [r1+0x0]                      
    add64 r1, 1                                     r1 += 1   ///  r1 = r1.wrapping_add(1 as i32 as i64 as u64)
    mov64 r2, 1                                     r2 = 1 as i32 as i64 as u64
    jeq r1, 0, lbb_10461                            if r1 == (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
lbb_10461:
    stxdw [r10-0x198], r4                   
    ldxdw r4, [r10-0x178]                   
    stxdw [r4+0x0], r1                      
    jne r2, 1, lbb_10466                            if r2 != (1 as i32 as i64 as u64) { pc += 1 }
    ja lbb_10421                                    if true { pc += -45 }
lbb_10466:
    ldxdw r1, [r10-0x148]                   
    ldxdw r4, [r1+0x8]                      
    ldxdw r1, [r4+0x0]                      
    add64 r1, 1                                     r1 += 1   ///  r1 = r1.wrapping_add(1 as i32 as i64 as u64)
    mov64 r2, 1                                     r2 = 1 as i32 as i64 as u64
    jeq r1, 0, lbb_10473                            if r1 == (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
lbb_10473:
    stxdw [r10-0x1a0], r5                   
    ldxb r5, [r7+0x2a]                      
    stxdw [r10-0x1c0], r5                   
    ldxb r5, [r7+0x29]                      
    stxdw [r10-0x1b8], r5                   
    ldxb r5, [r7+0x28]                      
    stxdw [r10-0x1b0], r5                   
    ldxdw r5, [r7+0x20]                     
    stxdw [r10-0x1a8], r5                   
    ldxdw r7, [r7+0x18]                     
    stxdw [r4+0x0], r1                      
    jne r2, 1, lbb_10486                            if r2 != (1 as i32 as i64 as u64) { pc += 1 }
    ja lbb_10421                                    if true { pc += -65 }
lbb_10486:
    ldxdw r1, [r10-0x148]                   
    ldxdw r5, [r1+0x10]                     
    ldxdw r1, [r5+0x0]                      
    add64 r1, 1                                     r1 += 1   ///  r1 = r1.wrapping_add(1 as i32 as i64 as u64)
    mov64 r2, 1                                     r2 = 1 as i32 as i64 as u64
    jeq r1, 0, lbb_10493                            if r1 == (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
lbb_10493:
    stxdw [r10-0x1d8], r8                   
    stxdw [r10-0x1d0], r9                   
    stxdw [r10-0x1c8], r0                   
    stxdw [r5+0x0], r1                      
    jne r2, 1, lbb_10499                            if r2 != (1 as i32 as i64 as u64) { pc += 1 }
    ja lbb_10421                                    if true { pc += -78 }
lbb_10499:
    stxdw [r10-0x1f0], r5                   
    stxdw [r10-0x1e8], r4                   
    stxdw [r10-0x1e0], r7                   
    ldxdw r0, [r6+0x8]                      
    ldxdw r8, [r0+0x0]                      
    add64 r8, 1                                     r8 += 1   ///  r8 = r8.wrapping_add(1 as i32 as i64 as u64)
    mov64 r9, 1                                     r9 = 1 as i32 as i64 as u64
    jeq r8, 0, lbb_10508                            if r8 == (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r9, 0                                     r9 = 0 as i32 as i64 as u64
lbb_10508:
    ldxdw r1, [r10-0x148]                   
    ldxb r2, [r1+0x2a]                      
    stxdw [r10-0x1f8], r2                   
    ldxb r2, [r1+0x29]                      
    ldxb r5, [r1+0x28]                      
    ldxdw r4, [r1+0x20]                     
    ldxdw r7, [r1+0x18]                     
    stxdw [r0+0x0], r8                      
    jne r9, 1, lbb_10518                            if r9 != (1 as i32 as i64 as u64) { pc += 1 }
    ja lbb_10421                                    if true { pc += -97 }
lbb_10518:
    ldxdw r8, [r6+0x10]                     
    ldxdw r9, [r8+0x0]                      
    add64 r9, 1                                     r9 += 1   ///  r9 = r9.wrapping_add(1 as i32 as i64 as u64)
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    jeq r9, 0, lbb_10524                            if r9 == (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
lbb_10524:
    stxdw [r10-0x200], r2                   
    stxdw [r10-0x148], r3                   
    stxdw [r8+0x0], r9                      
    jne r1, 1, lbb_10529                            if r1 != (1 as i32 as i64 as u64) { pc += 1 }
    ja lbb_10421                                    if true { pc += -108 }
lbb_10529:
    ldxdw r1, [r6+0x18]                     
    ldxdw r9, [r6+0x20]                     
    ldxb r2, [r6+0x28]                      
    ldxb r3, [r6+0x29]                      
    ldxb r6, [r6+0x2a]                      
    stxb [r10-0x6], r6                      
    stxb [r10-0x7], r3                      
    stxb [r10-0x8], r2                      
    stxdw [r10-0x10], r9                    
    stxdw [r10-0x18], r1                    
    stxdw [r10-0x20], r8                    
    stxdw [r10-0x28], r0                    
    ldxdw r1, [r10-0x170]                   
    stxdw [r10-0x30], r1                    
    ldxdw r1, [r10-0x1f8]                   
    stxb [r10-0x36], r1                     
    ldxdw r1, [r10-0x200]                   
    stxb [r10-0x37], r1                     
    stxb [r10-0x38], r5                     
    stxdw [r10-0x40], r4                    
    stxdw [r10-0x48], r7                    
    ldxdw r1, [r10-0x1f0]                   
    stxdw [r10-0x50], r1                    
    ldxdw r1, [r10-0x1e8]                   
    stxdw [r10-0x58], r1                    
    ldxdw r1, [r10-0x168]                   
    stxdw [r10-0x60], r1                    
    ldxdw r1, [r10-0x1c0]                   
    stxb [r10-0x66], r1                     
    ldxdw r1, [r10-0x1b8]                   
    stxb [r10-0x67], r1                     
    ldxdw r1, [r10-0x1b0]                   
    stxb [r10-0x68], r1                     
    ldxdw r1, [r10-0x1a8]                   
    stxdw [r10-0x70], r1                    
    ldxdw r1, [r10-0x1e0]                   
    stxdw [r10-0x78], r1                    
    ldxdw r1, [r10-0x178]                   
    stxdw [r10-0x80], r1                    
    ldxdw r1, [r10-0x1d0]                   
    stxdw [r10-0x88], r1                    
    ldxdw r1, [r10-0x160]                   
    stxdw [r10-0x90], r1                    
    ldxdw r1, [r10-0x190]                   
    stxb [r10-0x96], r1                     
    ldxdw r1, [r10-0x188]                   
    stxb [r10-0x97], r1                     
    ldxdw r1, [r10-0x198]                   
    stxb [r10-0x98], r1                     
    ldxdw r1, [r10-0x1a0]                   
    stxdw [r10-0xa0], r1                    
    ldxdw r1, [r10-0x1d8]                   
    stxdw [r10-0xa8], r1                    
    ldxdw r1, [r10-0x1c8]                   
    stxdw [r10-0xb0], r1                    
    ldxdw r1, [r10-0x148]                   
    stxdw [r10-0xb8], r1                    
    ldxdw r1, [r10-0x158]                   
    stxdw [r10-0xc0], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -320                                  r1 += -320   ///  r1 = r1.wrapping_add(-320 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -296                                  r2 += -296   ///  r2 = r2.wrapping_add(-296 as i32 as i64 as u64)
    mov64 r3, r10                                   r3 = r10
    add64 r3, -192                                  r3 += -192   ///  r3 = r3.wrapping_add(-192 as i32 as i64 as u64)
    mov64 r4, 4                                     r4 = 4 as i32 as i64 as u64
    call function_16479                     
    lddw r6, 0x800000000000001a                     r6 load str located at -9223372036854775782
    ldxdw r1, [r10-0x140]                   
    jeq r1, r6, lbb_10601                           if r1 == r6 { pc += 1 }
    ja lbb_10607                                    if true { pc += 6 }
lbb_10601:
    mov64 r1, r10                                   r1 = r10
    add64 r1, -192                                  r1 += -192   ///  r1 = r1.wrapping_add(-192 as i32 as i64 as u64)
    call function_472                       
    ldxdw r1, [r10-0x180]                   
    stxdw [r1+0x0], r6                      
    ja lbb_10617                                    if true { pc += 10 }
lbb_10607:
    ldxdw r1, [r10-0x130]                   
    ldxdw r2, [r10-0x180]                   
    stxdw [r2+0x10], r1                     
    ldxdw r1, [r10-0x138]                   
    stxdw [r2+0x8], r1                      
    ldxdw r1, [r10-0x140]                   
    stxdw [r2+0x0], r1                      
    mov64 r1, r10                                   r1 = r10
    add64 r1, -192                                  r1 += -192   ///  r1 = r1.wrapping_add(-192 as i32 as i64 as u64)
    call function_472                       
lbb_10617:
    exit                                    

function_10618:
    mov64 r7, r4                                    r7 = r4
    stxdw [r10-0x208], r3                   
    stxdw [r10-0x1f0], r2                   
    mov64 r6, r1                                    r6 = r1
    mov64 r9, 1                                     r9 = 1 as i32 as i64 as u64
    stxdw [r10-0x178], r9                   
    stxdw [r10-0x160], r9                   
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
    stxdw [r10-0x170], r2                   
    stxdw [r10-0x180], r2                   
    stxdw [r10-0x168], r2                   
    stxdw [r10-0x158], r2                   
    stxdw [r10-0x150], r2                   
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    stxdw [r10-0x210], r1                   
    stxw [r10-0x146], r2                    
    mov64 r1, 2                                     r1 = 2 as i32 as i64 as u64
    stxb [r10-0x148], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -240                                  r1 += -240   ///  r1 = r1.wrapping_add(-240 as i32 as i64 as u64)
    mov64 r2, r7                                    r2 = r7
    call function_16700                     
    ldxh r8, [r10-0xe8]                     
    ldxdw r1, [r10-0xf0]                    
    lddw r2, 0x800000000000001a                     r2 load str located at -9223372036854775782
    jne r1, r2, lbb_10670                           if r1 != r2 { pc += 25 }
    stxdw [r10-0x230], r6                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -240                                  r1 += -240   ///  r1 = r1.wrapping_add(-240 as i32 as i64 as u64)
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
    mov64 r3, r7                                    r3 = r7
    call function_16995                     
    lddw r2, 0x8000000000000000                     r2 load str located at -9223372036854775808
    ldxdw r1, [r10-0xf0]                    
    mov64 r6, r7                                    r6 = r7
    jeq r1, r2, lbb_12177                           if r1 == r2 { pc += 1521 }
    mov64 r1, r10                                   r1 = r10
    add64 r1, -360                                  r1 += -360   ///  r1 = r1.wrapping_add(-360 as i32 as i64 as u64)
    stxdw [r10-0x240], r1                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -39                                   r1 += -39   ///  r1 = r1.wrapping_add(-39 as i32 as i64 as u64)
    stxdw [r10-0x248], r1                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -272                                  r1 += -272   ///  r1 = r1.wrapping_add(-272 as i32 as i64 as u64)
    stxdw [r10-0x228], r1                   
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    stxdw [r10-0x1e8], r1                   
    stxdw [r10-0x220], r6                   
    stxdw [r10-0x200], r8                   
    ja lbb_10688                                    if true { pc += 18 }
lbb_10670:
    ldxdw r2, [r10-0xe0]                    
    stxdw [r6+0x10], r2                     
    ldxdw r2, [r10-0xe6]                    
    stxdw [r6+0xa], r2                      
    stxh [r6+0x8], r8                       
    stxdw [r6+0x0], r1                      
    ja lbb_12614                                    if true { pc += 1937 }
lbb_10677:
    ldxdw r2, [r10-0x1e8]                   
    add64 r2, 1                                     r2 += 1   ///  r2 = r2.wrapping_add(1 as i32 as i64 as u64)
    mov64 r1, r10                                   r1 = r10
    add64 r1, -240                                  r1 += -240   ///  r1 = r1.wrapping_add(-240 as i32 as i64 as u64)
    stxdw [r10-0x1e8], r2                   
    mov64 r3, r6                                    r3 = r6
    call function_16995                     
    ldxdw r1, [r10-0xf0]                    
    lddw r2, 0x8000000000000000                     r2 load str located at -9223372036854775808
    jeq r1, r2, lbb_12177                           if r1 == r2 { pc += 1489 }
lbb_10688:
    mov64 r1, r10                                   r1 = r10
    add64 r1, -320                                  r1 += -320   ///  r1 = r1.wrapping_add(-320 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -240                                  r2 += -240   ///  r2 = r2.wrapping_add(-240 as i32 as i64 as u64)
    mov64 r3, 80                                    r3 = 80 as i32 as i64 as u64
    call function_30349                     
    ldxdw r1, [r10-0x130]                   
    mov64 r2, r1                                    r2 = r1
    mul64 r2, 34                                    r2 *= 34   ///  r2 = r2.wrapping_mul(34 as u64)
    stxdw [r10-0x1f8], r2                   
    ldxdw r7, [r10-0x138]                   
    stxdw [r10-0x218], r1                   
    jeq r1, 0, lbb_10776                            if r1 == (0 as i32 as i64 as u64) { pc += 75 }
    mov64 r9, r7                                    r9 = r7
    ldxdw r1, [r10-0x1f8]                   
    add64 r9, r1                                    r9 += r1   ///  r9 = r9.wrapping_add(r1)
    mov64 r6, r7                                    r6 = r7
    ja lbb_10708                                    if true { pc += 2 }
lbb_10706:
    add64 r6, 34                                    r6 += 34   ///  r6 = r6.wrapping_add(34 as i32 as i64 as u64)
    jeq r6, r9, lbb_10776                           if r6 == r9 { pc += 68 }
lbb_10708:
    ldxb r1, [r6+0x20]                      
    jeq r1, 0, lbb_10706                            if r1 == (0 as i32 as i64 as u64) { pc += -4 }
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
    ldxdw r1, [r10-0x178]                   
    ldxdw r8, [r10-0x170]                   
    mov64 r3, r8                                    r3 = r8
    lsh64 r3, 5                                     r3 <<= 5   ///  r3 = r3.wrapping_shl(5)
lbb_10715:
    jeq r3, r2, lbb_10736                           if r3 == r2 { pc += 20 }
    mov64 r4, r1                                    r4 = r1
    add64 r4, r2                                    r4 += r2   ///  r4 = r4.wrapping_add(r2)
    ldxdw r5, [r6+0x0]                      
    ldxdw r0, [r4+0x0]                      
    jeq r0, r5, lbb_10723                           if r0 == r5 { pc += 2 }
lbb_10721:
    mov64 r5, 1                                     r5 = 1 as i32 as i64 as u64
    ja lbb_10733                                    if true { pc += 10 }
lbb_10723:
    ldxdw r5, [r6+0x8]                      
    ldxdw r0, [r4+0x8]                      
    jne r0, r5, lbb_10721                           if r0 != r5 { pc += -5 }
    ldxdw r5, [r6+0x10]                     
    ldxdw r0, [r4+0x10]                     
    jne r0, r5, lbb_10721                           if r0 != r5 { pc += -8 }
    mov64 r5, 0                                     r5 = 0 as i32 as i64 as u64
    ldxdw r0, [r6+0x18]                     
    ldxdw r4, [r4+0x18]                     
    jne r4, r0, lbb_10721                           if r4 != r0 { pc += -12 }
lbb_10733:
    add64 r2, 32                                    r2 += 32   ///  r2 = r2.wrapping_add(32 as i32 as i64 as u64)
    jeq r5, 0, lbb_10706                            if r5 == (0 as i32 as i64 as u64) { pc += -29 }
    ja lbb_10715                                    if true { pc += -21 }
lbb_10736:
    ldxdw r2, [r6+0x18]                     
    stxdw [r10-0xd8], r2                    
    ldxdw r2, [r6+0x10]                     
    stxdw [r10-0xe0], r2                    
    ldxdw r2, [r6+0x8]                      
    stxdw [r10-0xe8], r2                    
    ldxdw r2, [r6+0x0]                      
    stxdw [r10-0xf0], r2                    
    ldxdw r2, [r10-0x180]                   
    jne r8, r2, lbb_10750                           if r8 != r2 { pc += 4 }
    mov64 r1, r10                                   r1 = r10
    add64 r1, -384                                  r1 += -384   ///  r1 = r1.wrapping_add(-384 as i32 as i64 as u64)
    call function_921                       
    ldxdw r1, [r10-0x178]                   
lbb_10750:
    mov64 r2, r8                                    r2 = r8
    lsh64 r2, 5                                     r2 <<= 5   ///  r2 = r2.wrapping_shl(5)
    add64 r1, r2                                    r1 += r2   ///  r1 = r1.wrapping_add(r2)
    ldxdw r2, [r10-0xd8]                    
    stxdw [r1+0x18], r2                     
    ldxdw r2, [r10-0xe0]                    
    stxdw [r1+0x10], r2                     
    ldxdw r2, [r10-0xe8]                    
    stxdw [r1+0x8], r2                      
    ldxdw r2, [r10-0xf0]                    
    stxdw [r1+0x0], r2                      
    add64 r8, 1                                     r8 += 1   ///  r8 = r8.wrapping_add(1 as i32 as i64 as u64)
    stxdw [r10-0x170], r8                   
    ja lbb_10706                                    if true { pc += -58 }
lbb_10764:
    ldxdw r1, [r10-0x118]                   
    mov64 r2, 8                                     r2 = 8 as i32 as i64 as u64
    jgt r2, r1, lbb_11225                           if r2 > r1 { pc += 458 }
    ldxdw r1, [r10-0x120]                   
    ldxdw r1, [r1+0x0]                      
    lddw r2, 0x76ae84f4647bf193                     r2 load str located at 8551918927615881619
    jeq r1, r2, lbb_10677                           if r1 == r2 { pc += -95 }
lbb_10772:
    ldxdw r1, [r10-0x150]                   
    add64 r1, 1                                     r1 += 1   ///  r1 = r1.wrapping_add(1 as i32 as i64 as u64)
    stxdw [r10-0x150], r1                   
    ja lbb_10677                                    if true { pc += -99 }
lbb_10776:
    ldxdw r1, [r10-0x1f0]                   
    ldxdw r1, [r1+0x0]                      
    ldxdw r2, [r10-0x110]                   
    jeq r2, r1, lbb_10782                           if r2 == r1 { pc += 2 }
lbb_10780:
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    ja lbb_10795                                    if true { pc += 13 }
lbb_10782:
    ldxdw r1, [r10-0x1f0]                   
    ldxdw r1, [r1+0x8]                      
    ldxdw r2, [r10-0x108]                   
    jne r2, r1, lbb_10780                           if r2 != r1 { pc += -6 }
    ldxdw r1, [r10-0x1f0]                   
    ldxdw r1, [r1+0x10]                     
    ldxdw r2, [r10-0x100]                   
    jne r2, r1, lbb_10780                           if r2 != r1 { pc += -10 }
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    ldxdw r2, [r10-0x1f0]                   
    ldxdw r2, [r2+0x18]                     
    ldxdw r3, [r10-0xf8]                    
    jne r3, r2, lbb_10780                           if r3 != r2 { pc += -15 }
lbb_10795:
    ldxdw r6, [r10-0x220]                   
    ldxdw r8, [r10-0x200]                   
    jeq r1, 0, lbb_11225                            if r1 == (0 as i32 as i64 as u64) { pc += 427 }
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    stxdw [r10-0xd8], r1                    
    stxdw [r10-0xe0], r1                    
    stxdw [r10-0xe8], r1                    
    stxdw [r10-0xf0], r1                    
    ldxdw r1, [r10-0x110]                   
    jeq r1, 0, lbb_10807                            if r1 == (0 as i32 as i64 as u64) { pc += 2 }
lbb_10805:
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    ja lbb_10817                                    if true { pc += 10 }
lbb_10807:
    ldxdw r1, [r10-0xe8]                    
    ldxdw r2, [r10-0x108]                   
    jne r2, r1, lbb_10805                           if r2 != r1 { pc += -5 }
    ldxdw r1, [r10-0xe0]                    
    ldxdw r2, [r10-0x100]                   
    jne r2, r1, lbb_10805                           if r2 != r1 { pc += -8 }
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    ldxdw r2, [r10-0xd8]                    
    ldxdw r3, [r10-0xf8]                    
    jne r3, r2, lbb_10805                           if r3 != r2 { pc += -12 }
lbb_10817:
    ldxdw r4, [r10-0x208]                   
    jeq r1, 0, lbb_10979                            if r1 == (0 as i32 as i64 as u64) { pc += 160 }
    ldxdw r1, [r4+0xd0]                     
    ldxdw r2, [r10-0x110]                   
    jeq r1, r2, lbb_10824                           if r1 == r2 { pc += 2 }
lbb_10822:
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    ja lbb_10834                                    if true { pc += 10 }
lbb_10824:
    ldxdw r1, [r4+0xd8]                     
    ldxdw r2, [r10-0x108]                   
    jne r1, r2, lbb_10822                           if r1 != r2 { pc += -5 }
    ldxdw r1, [r4+0xe0]                     
    ldxdw r2, [r10-0x100]                   
    jne r1, r2, lbb_10822                           if r1 != r2 { pc += -8 }
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    ldxdw r2, [r4+0xe8]                     
    ldxdw r3, [r10-0xf8]                    
    jne r2, r3, lbb_10822                           if r2 != r3 { pc += -12 }
lbb_10834:
    jeq r1, 0, lbb_11005                            if r1 == (0 as i32 as i64 as u64) { pc += 170 }
    ldxdw r1, [r4+0xf0]                     
    ldxdw r2, [r10-0x110]                   
    jeq r1, r2, lbb_10840                           if r1 == r2 { pc += 2 }
lbb_10838:
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    ja lbb_10850                                    if true { pc += 10 }
lbb_10840:
    ldxdw r1, [r4+0xf8]                     
    ldxdw r2, [r10-0x108]                   
    jne r1, r2, lbb_10838                           if r1 != r2 { pc += -5 }
    ldxdw r1, [r4+0x100]                    
    ldxdw r2, [r10-0x100]                   
    jne r1, r2, lbb_10838                           if r1 != r2 { pc += -8 }
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    ldxdw r2, [r4+0x108]                    
    ldxdw r3, [r10-0xf8]                    
    jne r2, r3, lbb_10838                           if r2 != r3 { pc += -12 }
lbb_10850:
    jeq r1, 0, lbb_11005                            if r1 == (0 as i32 as i64 as u64) { pc += 154 }
    ldxdw r1, [r4+0x110]                    
    ldxdw r2, [r10-0x110]                   
    jeq r1, r2, lbb_10856                           if r1 == r2 { pc += 2 }
lbb_10854:
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    ja lbb_10866                                    if true { pc += 10 }
lbb_10856:
    ldxdw r1, [r4+0x118]                    
    ldxdw r2, [r10-0x108]                   
    jne r1, r2, lbb_10854                           if r1 != r2 { pc += -5 }
    ldxdw r1, [r4+0x120]                    
    ldxdw r2, [r10-0x100]                   
    jne r1, r2, lbb_10854                           if r1 != r2 { pc += -8 }
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    ldxdw r2, [r4+0x128]                    
    ldxdw r3, [r10-0xf8]                    
    jne r2, r3, lbb_10854                           if r2 != r3 { pc += -12 }
lbb_10866:
    jeq r1, 0, lbb_11005                            if r1 == (0 as i32 as i64 as u64) { pc += 138 }
    ldxdw r1, [r4+0x130]                    
    ldxdw r2, [r10-0x110]                   
    jeq r1, r2, lbb_10872                           if r1 == r2 { pc += 2 }
lbb_10870:
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    ja lbb_10882                                    if true { pc += 10 }
lbb_10872:
    ldxdw r1, [r4+0x138]                    
    ldxdw r2, [r10-0x108]                   
    jne r1, r2, lbb_10870                           if r1 != r2 { pc += -5 }
    ldxdw r1, [r4+0x140]                    
    ldxdw r2, [r10-0x100]                   
    jne r1, r2, lbb_10870                           if r1 != r2 { pc += -8 }
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    ldxdw r2, [r4+0x148]                    
    ldxdw r3, [r10-0xf8]                    
    jne r2, r3, lbb_10870                           if r2 != r3 { pc += -12 }
lbb_10882:
    jeq r1, 0, lbb_11005                            if r1 == (0 as i32 as i64 as u64) { pc += 122 }
    ldxdw r1, [r4+0x150]                    
    ldxdw r2, [r10-0x110]                   
    jeq r1, r2, lbb_10888                           if r1 == r2 { pc += 2 }
lbb_10886:
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    ja lbb_10898                                    if true { pc += 10 }
lbb_10888:
    ldxdw r1, [r4+0x158]                    
    ldxdw r2, [r10-0x108]                   
    jne r1, r2, lbb_10886                           if r1 != r2 { pc += -5 }
    ldxdw r1, [r4+0x160]                    
    ldxdw r2, [r10-0x100]                   
    jne r1, r2, lbb_10886                           if r1 != r2 { pc += -8 }
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    ldxdw r2, [r4+0x168]                    
    ldxdw r3, [r10-0xf8]                    
    jne r2, r3, lbb_10886                           if r2 != r3 { pc += -12 }
lbb_10898:
    jeq r1, 0, lbb_11005                            if r1 == (0 as i32 as i64 as u64) { pc += 106 }
    ldxdw r1, [r4+0x170]                    
    ldxdw r2, [r10-0x110]                   
    jeq r1, r2, lbb_10904                           if r1 == r2 { pc += 2 }
lbb_10902:
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    ja lbb_10914                                    if true { pc += 10 }
lbb_10904:
    ldxdw r1, [r4+0x178]                    
    ldxdw r2, [r10-0x108]                   
    jne r1, r2, lbb_10902                           if r1 != r2 { pc += -5 }
    ldxdw r1, [r4+0x180]                    
    ldxdw r2, [r10-0x100]                   
    jne r1, r2, lbb_10902                           if r1 != r2 { pc += -8 }
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    ldxdw r2, [r4+0x188]                    
    ldxdw r3, [r10-0xf8]                    
    jne r2, r3, lbb_10902                           if r2 != r3 { pc += -12 }
lbb_10914:
    jeq r1, 0, lbb_11005                            if r1 == (0 as i32 as i64 as u64) { pc += 90 }
    ldxdw r1, [r4+0x190]                    
    ldxdw r2, [r10-0x110]                   
    jeq r1, r2, lbb_10920                           if r1 == r2 { pc += 2 }
lbb_10918:
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    ja lbb_10930                                    if true { pc += 10 }
lbb_10920:
    ldxdw r1, [r4+0x198]                    
    ldxdw r2, [r10-0x108]                   
    jne r1, r2, lbb_10918                           if r1 != r2 { pc += -5 }
    ldxdw r1, [r4+0x1a0]                    
    ldxdw r2, [r10-0x100]                   
    jne r1, r2, lbb_10918                           if r1 != r2 { pc += -8 }
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    ldxdw r2, [r4+0x1a8]                    
    ldxdw r3, [r10-0xf8]                    
    jne r2, r3, lbb_10918                           if r2 != r3 { pc += -12 }
lbb_10930:
    jeq r1, 0, lbb_11005                            if r1 == (0 as i32 as i64 as u64) { pc += 74 }
    ldxdw r1, [r4+0x1b0]                    
    ldxdw r2, [r10-0x110]                   
    jeq r1, r2, lbb_10936                           if r1 == r2 { pc += 2 }
lbb_10934:
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    ja lbb_10946                                    if true { pc += 10 }
lbb_10936:
    ldxdw r1, [r4+0x1b8]                    
    ldxdw r2, [r10-0x108]                   
    jne r1, r2, lbb_10934                           if r1 != r2 { pc += -5 }
    ldxdw r1, [r4+0x1c0]                    
    ldxdw r2, [r10-0x100]                   
    jne r1, r2, lbb_10934                           if r1 != r2 { pc += -8 }
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    ldxdw r2, [r4+0x1c8]                    
    ldxdw r3, [r10-0xf8]                    
    jne r2, r3, lbb_10934                           if r2 != r3 { pc += -12 }
lbb_10946:
    jeq r1, 0, lbb_11005                            if r1 == (0 as i32 as i64 as u64) { pc += 58 }
    ldxdw r1, [r4+0x1d0]                    
    ldxdw r2, [r10-0x110]                   
    jeq r1, r2, lbb_10952                           if r1 == r2 { pc += 2 }
lbb_10950:
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    ja lbb_10962                                    if true { pc += 10 }
lbb_10952:
    ldxdw r1, [r4+0x1d8]                    
    ldxdw r2, [r10-0x108]                   
    jne r1, r2, lbb_10950                           if r1 != r2 { pc += -5 }
    ldxdw r1, [r4+0x1e0]                    
    ldxdw r2, [r10-0x100]                   
    jne r1, r2, lbb_10950                           if r1 != r2 { pc += -8 }
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    ldxdw r2, [r4+0x1e8]                    
    ldxdw r3, [r10-0xf8]                    
    jne r2, r3, lbb_10950                           if r2 != r3 { pc += -12 }
lbb_10962:
    jeq r1, 0, lbb_11005                            if r1 == (0 as i32 as i64 as u64) { pc += 42 }
    ldxdw r1, [r4+0x1f0]                    
    ldxdw r2, [r10-0x110]                   
    jeq r1, r2, lbb_10968                           if r1 == r2 { pc += 2 }
lbb_10966:
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    ja lbb_10978                                    if true { pc += 10 }
lbb_10968:
    ldxdw r1, [r4+0x1f8]                    
    ldxdw r2, [r10-0x108]                   
    jne r1, r2, lbb_10966                           if r1 != r2 { pc += -5 }
    ldxdw r1, [r4+0x200]                    
    ldxdw r2, [r10-0x100]                   
    jne r1, r2, lbb_10966                           if r1 != r2 { pc += -8 }
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    ldxdw r2, [r4+0x208]                    
    ldxdw r3, [r10-0xf8]                    
    jne r2, r3, lbb_10966                           if r2 != r3 { pc += -12 }
lbb_10978:
    jeq r1, 0, lbb_11005                            if r1 == (0 as i32 as i64 as u64) { pc += 26 }
lbb_10979:
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    ldxdw r9, [r10-0x160]                   
    ldxdw r0, [r10-0x158]                   
    mov64 r2, r0                                    r2 = r0
    lsh64 r2, 5                                     r2 <<= 5   ///  r2 = r2.wrapping_shl(5)
lbb_10984:
    jeq r2, r1, lbb_11008                           if r2 == r1 { pc += 23 }
    mov64 r3, r9                                    r3 = r9
    add64 r3, r1                                    r3 += r1   ///  r3 = r3.wrapping_add(r1)
    ldxdw r4, [r3+0x0]                      
    ldxdw r5, [r10-0x110]                   
    jeq r4, r5, lbb_10992                           if r4 == r5 { pc += 2 }
lbb_10990:
    mov64 r4, 1                                     r4 = 1 as i32 as i64 as u64
    ja lbb_11002                                    if true { pc += 10 }
lbb_10992:
    ldxdw r4, [r3+0x8]                      
    ldxdw r5, [r10-0x108]                   
    jne r4, r5, lbb_10990                           if r4 != r5 { pc += -5 }
    ldxdw r4, [r3+0x10]                     
    ldxdw r5, [r10-0x100]                   
    jne r4, r5, lbb_10990                           if r4 != r5 { pc += -8 }
    mov64 r4, 0                                     r4 = 0 as i32 as i64 as u64
    ldxdw r3, [r3+0x18]                     
    ldxdw r5, [r10-0xf8]                    
    jne r3, r5, lbb_10990                           if r3 != r5 { pc += -12 }
lbb_11002:
    add64 r1, 32                                    r1 += 32   ///  r1 = r1.wrapping_add(32 as i32 as i64 as u64)
    jeq r4, 0, lbb_11036                            if r4 == (0 as i32 as i64 as u64) { pc += 32 }
    ja lbb_10984                                    if true { pc += -21 }
lbb_11005:
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    stxb [r10-0x146], r1                    
    ja lbb_10979                                    if true { pc += -29 }
lbb_11008:
    ldxdw r1, [r10-0x168]                   
    jne r0, r1, lbb_11021                           if r0 != r1 { pc += 11 }
    ldxdw r1, [r10-0x240]                   
    mov64 r9, r7                                    r9 = r7
    mov64 r7, r8                                    r7 = r8
    mov64 r8, r6                                    r8 = r6
    mov64 r6, r0                                    r6 = r0
    call function_921                       
    mov64 r0, r6                                    r0 = r6
    mov64 r6, r8                                    r6 = r8
    mov64 r8, r7                                    r8 = r7
    mov64 r7, r9                                    r7 = r9
    ldxdw r9, [r10-0x160]                   
lbb_11021:
    mov64 r1, r0                                    r1 = r0
    lsh64 r1, 5                                     r1 <<= 5   ///  r1 = r1.wrapping_shl(5)
    mov64 r2, r9                                    r2 = r9
    add64 r2, r1                                    r2 += r1   ///  r2 = r2.wrapping_add(r1)
    ldxdw r3, [r10-0x228]                   
    ldxdw r1, [r3+0x18]                     
    stxdw [r2+0x18], r1                     
    ldxdw r1, [r3+0x10]                     
    stxdw [r2+0x10], r1                     
    ldxdw r1, [r3+0x8]                      
    stxdw [r2+0x8], r1                      
    ldxdw r1, [r3+0x0]                      
    stxdw [r2+0x0], r1                      
    add64 r0, 1                                     r0 += 1   ///  r0 = r0.wrapping_add(1 as i32 as i64 as u64)
    stxdw [r10-0x158], r0                   
lbb_11036:
    ldxdw r1, [r10-0x1e8]                   
    jne r1, r8, lbb_11065                           if r1 != r8 { pc += 27 }
    ldxdw r1, [r10-0x110]                   
    lddw r2, 0x6ec031f25bd57904                     r2 load str located at 7980433456693082372
    jeq r1, r2, lbb_11050                           if r1 == r2 { pc += 8 }
lbb_11042:
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    jeq r1, 0, lbb_11201                            if r1 == (0 as i32 as i64 as u64) { pc += 157 }
lbb_11044:
    ldxdw r1, [r10-0x110]                   
    lddw r2, 0xc79dab767cd57904                     r2 load str located at -4062902763429463804
    jeq r1, r2, lbb_11127                           if r1 == r2 { pc += 79 }
lbb_11048:
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    ja lbb_11140                                    if true { pc += 90 }
lbb_11050:
    ldxdw r1, [r10-0x108]                   
    lddw r2, 0x71568ce6ec574ee                      r2 load str located at 510429368607405294
    jne r1, r2, lbb_11042                           if r1 != r2 { pc += -12 }
    ldxdw r1, [r10-0x100]                   
    lddw r2, 0x518ef4a3deb2b1fd                     r2 load str located at 5876903548418175485
    jne r1, r2, lbb_11042                           if r1 != r2 { pc += -16 }
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    ldxdw r2, [r10-0xf8]                    
    lddw r3, 0x8f13bc56a2cdb102                     r3 load str located at -8136953021443755774
    jne r2, r3, lbb_11042                           if r2 != r3 { pc += -21 }
    jeq r1, 0, lbb_11201                            if r1 == (0 as i32 as i64 as u64) { pc += 137 }
    ja lbb_11044                                    if true { pc += -21 }
lbb_11065:
    ldxdw r1, [r10-0x110]                   
    jeq r1, 0, lbb_11069                            if r1 == (0 as i32 as i64 as u64) { pc += 2 }
lbb_11067:
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    ja lbb_11076                                    if true { pc += 7 }
lbb_11069:
    ldxdw r1, [r10-0x108]                   
    jne r1, 0, lbb_11067                            if r1 != (0 as i32 as i64 as u64) { pc += -4 }
    ldxdw r1, [r10-0x100]                   
    jne r1, 0, lbb_11067                            if r1 != (0 as i32 as i64 as u64) { pc += -6 }
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    ldxdw r2, [r10-0xf8]                    
    jne r2, 0, lbb_11067                            if r2 != (0 as i32 as i64 as u64) { pc += -9 }
lbb_11076:
    stxdw [r10-0x210], r0                   
    jeq r1, 0, lbb_11469                            if r1 == (0 as i32 as i64 as u64) { pc += 391 }
    ldxdw r1, [r10-0x110]                   
    lddw r2, 0x6ec031f25bd57904                     r2 load str located at 7980433456693082372
    jeq r1, r2, lbb_11090                           if r1 == r2 { pc += 8 }
lbb_11082:
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    jeq r1, 0, lbb_11105                            if r1 == (0 as i32 as i64 as u64) { pc += 21 }
lbb_11084:
    ldxdw r1, [r10-0x110]                   
    lddw r2, 0xc79dab767cd57904                     r2 load str located at -4062902763429463804
    jeq r1, r2, lbb_11367                           if r1 == r2 { pc += 279 }
lbb_11088:
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    ja lbb_11380                                    if true { pc += 290 }
lbb_11090:
    ldxdw r1, [r10-0x108]                   
    lddw r2, 0x71568ce6ec574ee                      r2 load str located at 510429368607405294
    jne r1, r2, lbb_11082                           if r1 != r2 { pc += -12 }
    ldxdw r1, [r10-0x100]                   
    lddw r2, 0x518ef4a3deb2b1fd                     r2 load str located at 5876903548418175485
    jne r1, r2, lbb_11082                           if r1 != r2 { pc += -16 }
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    ldxdw r2, [r10-0xf8]                    
    lddw r3, 0x8f13bc56a2cdb102                     r3 load str located at -8136953021443755774
    jne r2, r3, lbb_11082                           if r2 != r3 { pc += -21 }
    jeq r1, 0, lbb_11105                            if r1 == (0 as i32 as i64 as u64) { pc += 1 }
    ja lbb_11084                                    if true { pc += -21 }
lbb_11105:
    ldxdw r1, [r10-0x110]                   
    lddw r2, 0x6ec031f25bd57904                     r2 load str located at 7980433456693082372
    jeq r1, r2, lbb_11112                           if r1 == r2 { pc += 3 }
lbb_11109:
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    jeq r1, 0, lbb_10764                            if r1 == (0 as i32 as i64 as u64) { pc += -347 }
    ja lbb_10772                                    if true { pc += -340 }
lbb_11112:
    ldxdw r1, [r10-0x108]                   
    lddw r2, 0x71568ce6ec574ee                      r2 load str located at 510429368607405294
    jne r1, r2, lbb_11109                           if r1 != r2 { pc += -7 }
    ldxdw r1, [r10-0x100]                   
    lddw r2, 0x518ef4a3deb2b1fd                     r2 load str located at 5876903548418175485
    jne r1, r2, lbb_11109                           if r1 != r2 { pc += -11 }
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    ldxdw r2, [r10-0xf8]                    
    lddw r3, 0x8f13bc56a2cdb102                     r3 load str located at -8136953021443755774
    jne r2, r3, lbb_11109                           if r2 != r3 { pc += -16 }
    jeq r1, 0, lbb_10764                            if r1 == (0 as i32 as i64 as u64) { pc += -362 }
    ja lbb_10772                                    if true { pc += -355 }
lbb_11127:
    ldxdw r1, [r10-0x108]                   
    lddw r2, 0x32dbcd2cc93ecb37                     r2 load str located at 3664748314034621239
    jne r1, r2, lbb_11048                           if r1 != r2 { pc += -83 }
    ldxdw r1, [r10-0x100]                   
    lddw r2, 0xdf7af1f51591e246                     r2 load str located at -2343294621161758138
    jne r1, r2, lbb_11048                           if r1 != r2 { pc += -87 }
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    ldxdw r2, [r10-0xf8]                    
    lddw r3, 0xd701f731b41ae7be                     r3 load str located at -2953808087731214402
    jne r2, r3, lbb_11048                           if r2 != r3 { pc += -92 }
lbb_11140:
    jeq r1, 0, lbb_11201                            if r1 == (0 as i32 as i64 as u64) { pc += 60 }
    ldxdw r1, [r10-0x110]                   
    lddw r2, 0x136d5ca2f1569155                     r2 load str located at 1399876914085531989
    jeq r1, r2, lbb_11147                           if r1 == r2 { pc += 2 }
lbb_11145:
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    ja lbb_11160                                    if true { pc += 13 }
lbb_11147:
    ldxdw r1, [r10-0x108]                   
    lddw r2, 0x340d9a0ae6f72a4f                     r2 load str located at 3750823436284799567
    jne r1, r2, lbb_11145                           if r1 != r2 { pc += -6 }
    ldxdw r1, [r10-0x100]                   
    lddw r2, 0xd56264635691c77e                     r2 load str located at -3070781618096322690
    jne r1, r2, lbb_11145                           if r1 != r2 { pc += -10 }
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    ldxdw r2, [r10-0xf8]                    
    lddw r3, 0x698f3435f126add1                     r3 load str located at 7606355701935812049
    jne r2, r3, lbb_11145                           if r2 != r3 { pc += -15 }
lbb_11160:
    jeq r1, 0, lbb_11201                            if r1 == (0 as i32 as i64 as u64) { pc += 40 }
    ldxdw r1, [r10-0x110]                   
    lddw r2, 0xbb0ee7126e9ca906                     r2 load str located at -4967779272591890170
    jeq r1, r2, lbb_11167                           if r1 == r2 { pc += 2 }
lbb_11165:
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    ja lbb_11180                                    if true { pc += 13 }
lbb_11167:
    ldxdw r1, [r10-0x108]                   
    lddw r2, 0x6e904b4c145c1835                     r2 load str located at 7966950530949584949
    jne r1, r2, lbb_11165                           if r1 != r2 { pc += -6 }
    ldxdw r1, [r10-0x100]                   
    lddw r2, 0x2a2f74470ab0ff18                     r2 load str located at 3039776121969245976
    jne r1, r2, lbb_11165                           if r1 != r2 { pc += -10 }
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    ldxdw r2, [r10-0xf8]                    
    lddw r3, 0xd4c988690b11045e                     r3 load str located at -3113807682611379106
    jne r2, r3, lbb_11165                           if r2 != r3 { pc += -15 }
lbb_11180:
    jeq r1, 0, lbb_11201                            if r1 == (0 as i32 as i64 as u64) { pc += 20 }
    ldxdw r1, [r10-0x110]                   
    lddw r2, 0x4873bce2144ae3b5                     r2 load str located at 5220724072241619893
    jeq r1, r2, lbb_11187                           if r1 == r2 { pc += 2 }
lbb_11185:
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    ja lbb_11200                                    if true { pc += 13 }
lbb_11187:
    ldxdw r1, [r10-0x108]                   
    lddw r2, 0xd6ee5daff5e10e69                     r2 load str located at -2959324894810010007
    jne r1, r2, lbb_11185                           if r1 != r2 { pc += -6 }
    ldxdw r1, [r10-0x100]                   
    lddw r2, 0x60b8aa6da3403855                     r2 load str located at 6969507811222894677
    jne r1, r2, lbb_11185                           if r1 != r2 { pc += -10 }
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    ldxdw r2, [r10-0xf8]                    
    lddw r3, 0x103cc0bd736050b0                     r3 load str located at 1170021923126530224
    jne r2, r3, lbb_11185                           if r2 != r3 { pc += -15 }
lbb_11200:
    jne r1, 0, lbb_11203                            if r1 != (0 as i32 as i64 as u64) { pc += 2 }
lbb_11201:
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    stxb [r10-0x145], r1                    
lbb_11203:
    ldxdw r1, [r10-0x110]                   
    lddw r2, 0x6ec031f25bd57904                     r2 load str located at 7980433456693082372
    jeq r1, r2, lbb_11209                           if r1 == r2 { pc += 2 }
lbb_11207:
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    ja lbb_11222                                    if true { pc += 13 }
lbb_11209:
    ldxdw r1, [r10-0x108]                   
    lddw r2, 0x71568ce6ec574ee                      r2 load str located at 510429368607405294
    jne r1, r2, lbb_11207                           if r1 != r2 { pc += -6 }
    ldxdw r1, [r10-0x100]                   
    lddw r2, 0x518ef4a3deb2b1fd                     r2 load str located at 5876903548418175485
    jne r1, r2, lbb_11207                           if r1 != r2 { pc += -10 }
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    ldxdw r2, [r10-0xf8]                    
    lddw r3, 0x8f13bc56a2cdb102                     r3 load str located at -8136953021443755774
    jne r2, r3, lbb_11207                           if r2 != r3 { pc += -15 }
lbb_11222:
    jne r1, 0, lbb_11065                            if r1 != (0 as i32 as i64 as u64) { pc += -158 }
    ldxdw r1, [r10-0x218]                   
    jne r1, 0, lbb_11229                            if r1 != (0 as i32 as i64 as u64) { pc += 4 }
lbb_11225:
    mov64 r1, 65535                                 r1 = 65535 as i32 as i64 as u64
    ldxdw r2, [r10-0x230]                   
    stxdw [r2+0x8], r1                      
    ja lbb_12196                                    if true { pc += 967 }
lbb_11229:
    stxdw [r10-0x238], r9                   
    mov64 r1, r7                                    r1 = r7
    mov64 r8, r6                                    r8 = r6
    mov64 r6, r0                                    r6 = r0
    ldxdw r2, [r10-0x1f8]                   
    add64 r2, r1                                    r2 += r1   ///  r2 = r2.wrapping_add(r1)
    ldxdw r1, [r2-0xa]                      
    stxdw [r10-0x60], r1                    
    ldxdw r1, [r2-0x12]                     
    stxdw [r10-0x68], r1                    
    ldxdw r1, [r2-0x1a]                     
    stxdw [r10-0x70], r1                    
    ldxdw r1, [r2-0x22]                     
    stxdw [r10-0x78], r1                    
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    stxdw [r10-0x20], r1                    
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
    stxdw [r10-0x18], r2                    
    stxdw [r10-0x28], r2                    
    mov64 r1, 3                                     r1 = 3 as i32 as i64 as u64
    stxb [r10-0xb8], r1                     
    mov64 r1, 32                                    r1 = 32 as i32 as i64 as u64
    stxdw [r10-0xc0], r1                    
    lddw r1, 0x100040db0 --> b"\x00\x00\x00\x00\xd8\x0f\x00\x00\x18\x00\x00\x00\x00\x00\x00\x00\x08\x00\…        r1 load str located at 4295232944
    stxdw [r10-0xc8], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -40                                   r1 += -40   ///  r1 = r1.wrapping_add(-40 as i32 as i64 as u64)
    stxdw [r10-0xd0], r1                    
    stxdw [r10-0xe0], r2                    
    stxdw [r10-0xf0], r2                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -120                                  r1 += -120   ///  r1 = r1.wrapping_add(-120 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -240                                  r2 += -240   ///  r2 = r2.wrapping_add(-240 as i32 as i64 as u64)
    call function_19855                     
    jeq r0, 0, lbb_11276                            if r0 == (0 as i32 as i64 as u64) { pc += 10 }
    mov64 r3, r10                                   r3 = r10
    add64 r3, -56                                   r3 += -56   ///  r3 = r3.wrapping_add(-56 as i32 as i64 as u64)
    lddw r1, 0x10003e5d2 --> b"a Display implementation returned an error unexpectedly"        r1 load str located at 4295222738
    mov64 r2, 55                                    r2 = 55 as i32 as i64 as u64
    lddw r4, 0x100040de0 --> b"\x00\x00\x00\x00\xd0\x0f\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x01\x00\…        r4 load str located at 4295232992
    lddw r5, 0x100040e00 --> b"\x00\x00\x00\x00\x09\xe6\x03\x00T\x00\x00\x00\x00\x00\x00\x00\xff\x09\x00…        r5 load str located at 4295233024
    call function_25967                     
lbb_11276:
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    ldxdw r2, [r10-0x18]                    
    mov64 r3, 13                                    r3 = 13 as i32 as i64 as u64
    mov64 r0, r6                                    r0 = r6
    mov64 r6, r8                                    r6 = r8
    ldxdw r9, [r10-0x238]                   
    jgt r3, r2, lbb_11298                           if r3 > r2 { pc += 15 }
    ldxdw r1, [r10-0x20]                    
    ldxdw r2, [r1+0x0]                      
    lddw r3, 0x746e6f646f74696a                     r3 load str located at 8389765632995125610
    jeq r2, r3, lbb_11290                           if r2 == r3 { pc += 2 }
lbb_11288:
    mov64 r2, 1                                     r2 = 1 as i32 as i64 as u64
    ja lbb_11295                                    if true { pc += 5 }
lbb_11290:
    ldxw r2, [r1+0x8]                       
    jne r2, 1852797542, lbb_11288                   if r2 != (1852797542 as i32 as i64 as u64) { pc += -4 }
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
    ldxb r1, [r1+0xc]                       
    jne r1, 116, lbb_11288                          if r1 != (116 as i32 as i64 as u64) { pc += -7 }
lbb_11295:
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    jeq r2, 0, lbb_11298                            if r2 == (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
lbb_11298:
    ldxdw r2, [r10-0x118]                   
    mov64 r3, 8                                     r3 = 8 as i32 as i64 as u64
    jgt r3, r2, lbb_11065                           if r3 > r2 { pc += -236 }
    ldxdw r3, [r10-0x120]                   
    ldxdw r2, [r3+0x0]                      
    lddw r4, 0x5ced2b7b97ef33d0                     r4 load str located at 6696056030799803344
    jeq r2, r4, lbb_11332                           if r2 == r4 { pc += 26 }
    ldxdw r2, [r3+0x0]                      
    lddw r4, 0x2aade37a97cb17e5                     r4 load str located at 3075364236236101605
    jeq r2, r4, lbb_11332                           if r2 == r4 { pc += 22 }
    ldxdw r2, [r3+0x0]                      
    lddw r4, 0x680e5da774475696                     r4 load str located at 7498033403410208406
    jeq r2, r4, lbb_11332                           if r2 == r4 { pc += 18 }
    ldxdw r2, [r3+0x0]                      
    lddw r4, 0x3e457d9aa869d1b0                     r4 load str located at 4487130706948510128
    jeq r2, r4, lbb_11338                           if r2 == r4 { pc += 20 }
    ldxdw r2, [r3+0x0]                      
    lddw r4, 0x819cd641339b20c1                     r4 load str located at -9107168770922962751
    jeq r2, r4, lbb_11338                           if r2 == r4 { pc += 16 }
    mov64 r2, 9                                     r2 = 9 as i32 as i64 as u64
    ldxdw r4, [r10-0x218]                   
    jgt r2, r4, lbb_11065                           if r2 > r4 { pc += -260 }
    mov64 r2, 8                                     r2 = 8 as i32 as i64 as u64
    mov64 r4, 7                                     r4 = 7 as i32 as i64 as u64
    ldxdw r3, [r3+0x0]                      
    lddw r5, 0xaa6a9f77508f79e6                     r5 load str located at -6166941404928968218
    jne r3, r5, lbb_11065                           if r3 != r5 { pc += -266 }
    ja lbb_11343                                    if true { pc += 11 }
lbb_11332:
    mov64 r2, 3                                     r2 = 3 as i32 as i64 as u64
    mov64 r4, 2                                     r4 = 2 as i32 as i64 as u64
    mov64 r3, 4                                     r3 = 4 as i32 as i64 as u64
    ldxdw r5, [r10-0x218]                   
    jgt r3, r5, lbb_11065                           if r3 > r5 { pc += -272 }
    ja lbb_11343                                    if true { pc += 5 }
lbb_11338:
    mov64 r2, 8                                     r2 = 8 as i32 as i64 as u64
    mov64 r4, 7                                     r4 = 7 as i32 as i64 as u64
    mov64 r3, 9                                     r3 = 9 as i32 as i64 as u64
    ldxdw r5, [r10-0x218]                   
    jgt r3, r5, lbb_11065                           if r3 > r5 { pc += -278 }
lbb_11343:
    mul64 r4, 34                                    r4 *= 34   ///  r4 = r4.wrapping_mul(34 as u64)
    mov64 r3, r7                                    r3 = r7
    add64 r3, r4                                    r3 += r4   ///  r3 = r3.wrapping_add(r4)
    mul64 r2, 34                                    r2 *= 34   ///  r2 = r2.wrapping_mul(34 as u64)
    add64 r7, r2                                    r7 += r2   ///  r7 = r7.wrapping_add(r2)
    ldxdw r2, [r7+0x0]                      
    ldxdw r4, [r3+0x0]                      
    jeq r4, r2, lbb_11353                           if r4 == r2 { pc += 2 }
lbb_11351:
    mov64 r2, 1                                     r2 = 1 as i32 as i64 as u64
    ja lbb_11363                                    if true { pc += 10 }
lbb_11353:
    ldxdw r2, [r7+0x8]                      
    ldxdw r4, [r3+0x8]                      
    jne r4, r2, lbb_11351                           if r4 != r2 { pc += -5 }
    ldxdw r2, [r7+0x10]                     
    ldxdw r4, [r3+0x10]                     
    jne r4, r2, lbb_11351                           if r4 != r2 { pc += -8 }
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
    ldxdw r4, [r7+0x18]                     
    ldxdw r3, [r3+0x18]                     
    jne r3, r4, lbb_11351                           if r3 != r4 { pc += -12 }
lbb_11363:
    stxb [r10-0x148], r2                    
    and64 r1, 1                                     r1 &= 1   ///  r1 = r1.and(1)
    stxb [r10-0x147], r1                    
    ja lbb_11065                                    if true { pc += -302 }
lbb_11367:
    ldxdw r1, [r10-0x108]                   
    lddw r2, 0x32dbcd2cc93ecb37                     r2 load str located at 3664748314034621239
    jne r1, r2, lbb_11088                           if r1 != r2 { pc += -283 }
    ldxdw r1, [r10-0x100]                   
    lddw r2, 0xdf7af1f51591e246                     r2 load str located at -2343294621161758138
    jne r1, r2, lbb_11088                           if r1 != r2 { pc += -287 }
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    ldxdw r2, [r10-0xf8]                    
    lddw r3, 0xd701f731b41ae7be                     r3 load str located at -2953808087731214402
    jne r2, r3, lbb_11088                           if r2 != r3 { pc += -292 }
lbb_11380:
    jeq r1, 0, lbb_11105                            if r1 == (0 as i32 as i64 as u64) { pc += -276 }
    ldxdw r1, [r10-0x110]                   
    lddw r2, 0x136d5ca2f1569155                     r2 load str located at 1399876914085531989
    jeq r1, r2, lbb_11387                           if r1 == r2 { pc += 2 }
lbb_11385:
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    ja lbb_11400                                    if true { pc += 13 }
lbb_11387:
    ldxdw r1, [r10-0x108]                   
    lddw r2, 0x340d9a0ae6f72a4f                     r2 load str located at 3750823436284799567
    jne r1, r2, lbb_11385                           if r1 != r2 { pc += -6 }
    ldxdw r1, [r10-0x100]                   
    lddw r2, 0xd56264635691c77e                     r2 load str located at -3070781618096322690
    jne r1, r2, lbb_11385                           if r1 != r2 { pc += -10 }
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    ldxdw r2, [r10-0xf8]                    
    lddw r3, 0x698f3435f126add1                     r3 load str located at 7606355701935812049
    jne r2, r3, lbb_11385                           if r2 != r3 { pc += -15 }
lbb_11400:
    jeq r1, 0, lbb_11105                            if r1 == (0 as i32 as i64 as u64) { pc += -296 }
    ldxdw r1, [r10-0x110]                   
    lddw r2, 0xbb0ee7126e9ca906                     r2 load str located at -4967779272591890170
    jeq r1, r2, lbb_11407                           if r1 == r2 { pc += 2 }
lbb_11405:
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    ja lbb_11420                                    if true { pc += 13 }
lbb_11407:
    ldxdw r1, [r10-0x108]                   
    lddw r2, 0x6e904b4c145c1835                     r2 load str located at 7966950530949584949
    jne r1, r2, lbb_11405                           if r1 != r2 { pc += -6 }
    ldxdw r1, [r10-0x100]                   
    lddw r2, 0x2a2f74470ab0ff18                     r2 load str located at 3039776121969245976
    jne r1, r2, lbb_11405                           if r1 != r2 { pc += -10 }
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    ldxdw r2, [r10-0xf8]                    
    lddw r3, 0xd4c988690b11045e                     r3 load str located at -3113807682611379106
    jne r2, r3, lbb_11405                           if r2 != r3 { pc += -15 }
lbb_11420:
    jeq r1, 0, lbb_11105                            if r1 == (0 as i32 as i64 as u64) { pc += -316 }
    ldxdw r1, [r10-0x110]                   
    lddw r2, 0x4873bce2144ae3b5                     r2 load str located at 5220724072241619893
    jeq r1, r2, lbb_11439                           if r1 == r2 { pc += 14 }
lbb_11425:
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    jeq r1, 0, lbb_11105                            if r1 == (0 as i32 as i64 as u64) { pc += -322 }
lbb_11427:
    ldxdw r1, [r10-0x110]                   
    lddw r2, 0x321721e56f460603                     r2 load str located at 3609390895658829315
    jeq r1, r2, lbb_11454                           if r1 == r2 { pc += 23 }
lbb_11431:
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    jeq r1, 0, lbb_10677                            if r1 == (0 as i32 as i64 as u64) { pc += -756 }
lbb_11433:
    ldxdw r1, [r10-0x110]                   
    lddw r2, 0xf189244e8f25978c                     r2 load str located at -1042261918931904628
    jeq r1, r2, lbb_12089                           if r1 == r2 { pc += 652 }
lbb_11437:
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    ja lbb_12102                                    if true { pc += 663 }
lbb_11439:
    ldxdw r1, [r10-0x108]                   
    lddw r2, 0xd6ee5daff5e10e69                     r2 load str located at -2959324894810010007
    jne r1, r2, lbb_11425                           if r1 != r2 { pc += -18 }
    ldxdw r1, [r10-0x100]                   
    lddw r2, 0x60b8aa6da3403855                     r2 load str located at 6969507811222894677
    jne r1, r2, lbb_11425                           if r1 != r2 { pc += -22 }
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    ldxdw r2, [r10-0xf8]                    
    lddw r3, 0x103cc0bd736050b0                     r3 load str located at 1170021923126530224
    jne r2, r3, lbb_11425                           if r2 != r3 { pc += -27 }
    jeq r1, 0, lbb_11105                            if r1 == (0 as i32 as i64 as u64) { pc += -348 }
    ja lbb_11427                                    if true { pc += -27 }
lbb_11454:
    ldxdw r1, [r10-0x108]                   
    lddw r2, 0xe79bc372baadecff                     r2 load str located at -1757596332032398081
    jne r1, r2, lbb_11431                           if r1 != r2 { pc += -27 }
    ldxdw r1, [r10-0x100]                   
    lddw r2, 0x6b12f7c5bbe58cbc                     r2 load str located at 7715501540272082108
    jne r1, r2, lbb_11431                           if r1 != r2 { pc += -31 }
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    ldxdw r2, [r10-0xf8]                    
    lddw r3, 0x403a9b432c                           r3 load str located at 275861160748
    jne r2, r3, lbb_11431                           if r2 != r3 { pc += -36 }
    jeq r1, 0, lbb_10677                            if r1 == (0 as i32 as i64 as u64) { pc += -791 }
    ja lbb_11433                                    if true { pc += -36 }
lbb_11469:
    ldxdw r1, [r10-0x120]                   
    ldxdw r4, [r10-0x118]                   
    mov64 r2, 228                                   r2 = 228 as i32 as i64 as u64
    stxdw [r10-0x50], r2                    
    mov64 r2, 1                                     r2 = 1 as i32 as i64 as u64
    stxdw [r10-0x70], r2                    
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
    stxdw [r10-0x68], r2                    
    stxdw [r10-0x78], r2                    
    jgt r4, 3, lbb_11518                            if r4 > (3 as i32 as i64 as u64) { pc += 39 }
lbb_11479:
    lddw r1, 0x100040d80 --> b"\x00\x00\x00\x00\x99\xe5\x03\x00\x1b\x00\x00\x00\x00\x00\x00\x00%\x00\x00…        r1 load str located at 4295232896
    call function_19497                     
lbb_11482:
    stxdw [r10-0x88], r0                    
lbb_11483:
    lddw r7, 0x800000000000000d                     r7 load str located at -9223372036854775795
lbb_11485:
    lddw r1, 0x800000000000000d                     r1 load str located at -9223372036854775795
    jne r7, r1, lbb_11497                           if r7 != r1 { pc += 9 }
    ldxdw r1, [r10-0x88]                    
    ldxdw r2, [r1+0x0]                      
    lddw r3, 0x8000000000000000                     r3 load str located at -9223372036854775808
    xor64 r2, r3                                    r2 ^= r3   ///  r2 = r2.xor(r3)
    mov64 r3, 8                                     r3 = 8 as i32 as i64 as u64
    jgt r3, r2, lbb_12480                           if r3 > r2 { pc += 985 }
    mov64 r2, 8                                     r2 = 8 as i32 as i64 as u64
    ja lbb_12480                                    if true { pc += 983 }
lbb_11497:
    mov64 r1, r7                                    r1 = r7
    lddw r2, 0x8000000000000000                     r2 load str located at -9223372036854775808
    xor64 r1, r2                                    r1 ^= r2   ///  r1 = r1.xor(r2)
    mov64 r2, 13                                    r2 = 13 as i32 as i64 as u64
    jgt r2, r1, lbb_11504                           if r2 > r1 { pc += 1 }
    mov64 r1, 3                                     r1 = 3 as i32 as i64 as u64
lbb_11504:
    stxh [r10-0xd2], r4                     
    ldxdw r2, [r10-0x80]                    
    stxdw [r10-0xe0], r2                    
    ldxdw r2, [r10-0x88]                    
    stxdw [r10-0xe8], r2                    
    stxdw [r10-0xf0], r7                    
    stxw [r10-0xd8], r8                     
    rsh64 r8, 32                                    r8 >>= 32   ///  r8 = r8.wrapping_shr(32)
    stxh [r10-0xd4], r8                     
    jsgt r1, 8, lbb_12163                           if (r1 as i64) > (8 as i32 as i64) { pc += 649 }
    ldxdw r8, [r10-0x200]                   
    jeq r1, 2, lbb_12168                            if r1 == (2 as i32 as i64 as u64) { pc += 652 }
    jeq r1, 3, lbb_12167                            if r1 == (3 as i32 as i64 as u64) { pc += 650 }
    ja lbb_12167                                    if true { pc += 649 }
lbb_11518:
    mov64 r2, r4                                    r2 = r4
    add64 r2, -4                                    r2 += -4   ///  r2 = r2.wrapping_add(-4 as i32 as i64 as u64)
    ldxw r3, [r1+0x0]                       
    stxdw [r10-0x58], r2                    
    mov64 r5, r1                                    r5 = r1
    add64 r5, 4                                     r5 += 4   ///  r5 = r5.wrapping_add(4 as i32 as i64 as u64)
    stxdw [r10-0x60], r5                    
    jsgt r3, 5, lbb_11538                           if (r3 as i64) > (5 as i32 as i64) { pc += 12 }
    mov64 r0, 8                                     r0 = 8 as i32 as i64 as u64
    jsgt r3, 2, lbb_11596                           if (r3 as i64) > (2 as i32 as i64) { pc += 68 }
    jeq r3, 0, lbb_11737                            if r3 == (0 as i32 as i64 as u64) { pc += 208 }
    jeq r3, 1, lbb_11837                            if r3 == (1 as i32 as i64 as u64) { pc += 307 }
    jeq r3, 2, lbb_11532                            if r3 == (2 as i32 as i64 as u64) { pc += 1 }
    ja lbb_11611                                    if true { pc += 79 }
lbb_11532:
    jgt r0, r2, lbb_11479                           if r0 > r2 { pc += -54 }
    ldxdw r1, [r5+0x0]                      
    stxdw [r10-0x88], r1                    
    lddw r7, 0x8000000000000002                     r7 load str located at -9223372036854775806
    ja lbb_11485                                    if true { pc += -53 }
lbb_11538:
    mov64 r0, 8                                     r0 = 8 as i32 as i64 as u64
    jsgt r3, 8, lbb_11550                           if (r3 as i64) > (8 as i32 as i64) { pc += 10 }
    jeq r3, 6, lbb_11716                            if r3 == (6 as i32 as i64 as u64) { pc += 175 }
    jeq r3, 7, lbb_11867                            if r3 == (7 as i32 as i64 as u64) { pc += 325 }
    jeq r3, 8, lbb_11544                            if r3 == (8 as i32 as i64 as u64) { pc += 1 }
    ja lbb_11611                                    if true { pc += 67 }
lbb_11544:
    jgt r0, r2, lbb_11479                           if r0 > r2 { pc += -66 }
    ldxdw r1, [r5+0x0]                      
    stxdw [r10-0x88], r1                    
    lddw r7, 0x8000000000000008                     r7 load str located at -9223372036854775800
    ja lbb_11485                                    if true { pc += -65 }
lbb_11550:
    jsgt r3, 10, lbb_11609                          if (r3 as i64) > (10 as i32 as i64) { pc += 58 }
    jeq r3, 9, lbb_11618                            if r3 == (9 as i32 as i64 as u64) { pc += 66 }
    jeq r3, 10, lbb_11554                           if r3 == (10 as i32 as i64 as u64) { pc += 1 }
    ja lbb_11611                                    if true { pc += 57 }
lbb_11554:
    mov64 r1, 2                                     r1 = 2 as i32 as i64 as u64
    stxdw [r10-0x30], r1                    
    mov64 r2, r10                                   r2 = r10
    add64 r2, -120                                  r2 += -120   ///  r2 = r2.wrapping_add(-120 as i32 as i64 as u64)
    stxdw [r10-0x38], r2                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -40                                   r1 += -40   ///  r1 = r1.wrapping_add(-40 as i32 as i64 as u64)
    call function_2121                      
    ldxb r1, [r10-0x28]                     
    jne r1, 0, lbb_11874                            if r1 != (0 as i32 as i64 as u64) { pc += 310 }
    ldxw r1, [r10-0x27]                     
    stxdw [r10-0x1f8], r1                   
    ldxh r6, [r10-0x23]                     
    mov64 r1, r10                                   r1 = r10
    add64 r1, -40                                   r1 += -40   ///  r1 = r1.wrapping_add(-40 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -56                                   r2 += -56   ///  r2 = r2.wrapping_add(-56 as i32 as i64 as u64)
    call function_1115                      
    ldxdw r0, [r10-0x20]                    
    ldxdw r7, [r10-0x28]                    
    lddw r1, 0x8000000000000001                     r1 load str located at -9223372036854775807
    jeq r7, r1, lbb_12059                           if r7 == r1 { pc += 482 }
    lddw r1, 0x8000000000000000                     r1 load str located at -9223372036854775808
    jeq r7, r1, lbb_12043                           if r7 == r1 { pc += 463 }
    ldxdw r1, [r10-0x30]                    
    jeq r1, 0, lbb_12053                            if r1 == (0 as i32 as i64 as u64) { pc += 471 }
    stxdw [r10-0x218], r0                   
    ldxh r1, [r10-0x14]                     
    stxdw [r10-0x250], r1                   
    ldxw r8, [r10-0x18]                     
    ldxh r1, [r10-0x12]                     
    stxdw [r10-0x238], r1                   
    ldxdw r2, [r10-0x38]                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -40                                   r1 += -40   ///  r1 = r1.wrapping_add(-40 as i32 as i64 as u64)
    call function_2121                      
    ldxb r1, [r10-0x28]                     
    jeq r1, 0, lbb_11944                            if r1 == (0 as i32 as i64 as u64) { pc += 350 }
lbb_11594:
    ldxdw r0, [r10-0x20]                    
    ja lbb_12059                                    if true { pc += 463 }
lbb_11596:
    jeq r3, 3, lbb_11778                            if r3 == (3 as i32 as i64 as u64) { pc += 181 }
    lddw r7, 0x8000000000000004                     r7 load str located at -9223372036854775804
    jeq r3, 4, lbb_11485                            if r3 == (4 as i32 as i64 as u64) { pc += -115 }
    mov64 r1, 8                                     r1 = 8 as i32 as i64 as u64
    jeq r3, 5, lbb_11603                            if r3 == (5 as i32 as i64 as u64) { pc += 1 }
    ja lbb_11611                                    if true { pc += 8 }
lbb_11603:
    jgt r1, r2, lbb_11479                           if r1 > r2 { pc += -125 }
    ldxdw r1, [r5+0x0]                      
    stxdw [r10-0x88], r1                    
    lddw r7, 0x8000000000000005                     r7 load str located at -9223372036854775803
    ja lbb_11485                                    if true { pc += -124 }
lbb_11609:
    jeq r3, 11, lbb_11670                           if r3 == (11 as i32 as i64 as u64) { pc += 60 }
    jeq r3, 12, lbb_11713                           if r3 == (12 as i32 as i64 as u64) { pc += 102 }
lbb_11611:
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    stxb [r10-0x28], r1                     
    stxdw [r10-0x20], r3                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -40                                   r1 += -40   ///  r1 = r1.wrapping_add(-40 as i32 as i64 as u64)
    call function_1054                      
    ja lbb_11482                                    if true { pc += -136 }
lbb_11618:
    mov64 r1, 3                                     r1 = 3 as i32 as i64 as u64
    stxdw [r10-0x30], r1                    
    mov64 r2, r10                                   r2 = r10
    add64 r2, -120                                  r2 += -120   ///  r2 = r2.wrapping_add(-120 as i32 as i64 as u64)
    stxdw [r10-0x38], r2                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -40                                   r1 += -40   ///  r1 = r1.wrapping_add(-40 as i32 as i64 as u64)
    call function_2121                      
    ldxb r1, [r10-0x28]                     
    jne r1, 0, lbb_11874                            if r1 != (0 as i32 as i64 as u64) { pc += 246 }
    ldxw r1, [r10-0x27]                     
    stxdw [r10-0x1f8], r1                   
    ldxh r6, [r10-0x23]                     
    mov64 r1, r10                                   r1 = r10
    add64 r1, -40                                   r1 += -40   ///  r1 = r1.wrapping_add(-40 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -56                                   r2 += -56   ///  r2 = r2.wrapping_add(-56 as i32 as i64 as u64)
    call function_1115                      
    ldxdw r0, [r10-0x20]                    
    ldxdw r7, [r10-0x28]                    
    lddw r1, 0x8000000000000001                     r1 load str located at -9223372036854775807
    jeq r7, r1, lbb_12059                           if r7 == r1 { pc += 418 }
    lddw r1, 0x8000000000000000                     r1 load str located at -9223372036854775808
    jeq r7, r1, lbb_12039                           if r7 == r1 { pc += 395 }
    ldxdw r1, [r10-0x30]                    
    jeq r1, 0, lbb_12049                            if r1 == (0 as i32 as i64 as u64) { pc += 403 }
    ldxdw r2, [r10-0x38]                    
    ldxdw r3, [r2+0x28]                     
    jgt r3, 7, lbb_11890                            if r3 > (7 as i32 as i64 as u64) { pc += 241 }
    lddw r1, 0x300000000                            r1 load str located at 12884901888
    ldxdw r1, [r1+0x0]                      
    mov64 r3, r1                                    r3 = r1
    add64 r3, -24                                   r3 += -24   ///  r3 = r3.wrapping_add(-24 as i32 as i64 as u64)
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
    mov64 r4, 1                                     r4 = 1 as i32 as i64 as u64
    jgt r3, r1, lbb_11658                           if r3 > r1 { pc += 1 }
    mov64 r4, 0                                     r4 = 0 as i32 as i64 as u64
lbb_11658:
    ldxdw r6, [r10-0x220]                   
    jne r4, 0, lbb_11661                            if r4 != (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r2, r3                                    r2 = r3
lbb_11661:
    lddw r0, 0x300007fe8                            r0 load str located at 12884934632
    jeq r1, 0, lbb_11666                            if r1 == (0 as i32 as i64 as u64) { pc += 2 }
    and64 r2, -8                                    r2 &= -8   ///  r2 = r2.and(-8)
    mov64 r0, r2                                    r0 = r2
lbb_11666:
    lddw r1, 0x300000007                            r1 load str located at 12884901895
    jgt r0, r1, lbb_11990                           if r0 > r1 { pc += 321 }
    ja lbb_11834                                    if true { pc += 164 }
lbb_11670:
    mov64 r3, 2                                     r3 = 2 as i32 as i64 as u64
    stxdw [r10-0x30], r3                    
    mov64 r3, r10                                   r3 = r10
    add64 r3, -120                                  r3 += -120   ///  r3 = r3.wrapping_add(-120 as i32 as i64 as u64)
    stxdw [r10-0x38], r3                    
    mov64 r3, 220                                   r3 = 220 as i32 as i64 as u64
    stxdw [r10-0x50], r3                    
    jgt r0, r2, lbb_11479                           if r0 > r2 { pc += -199 }
    add64 r4, -12                                   r4 += -12   ///  r4 = r4.wrapping_add(-12 as i32 as i64 as u64)
    ldxw r2, [r1+0x4]                       
    stxdw [r10-0x1f8], r2                   
    ldxh r6, [r1+0x8]                       
    stxdw [r10-0x58], r4                    
    add64 r1, 12                                    r1 += 12   ///  r1 = r1.wrapping_add(12 as i32 as i64 as u64)
    stxdw [r10-0x60], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -40                                   r1 += -40   ///  r1 = r1.wrapping_add(-40 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -56                                   r2 += -56   ///  r2 = r2.wrapping_add(-56 as i32 as i64 as u64)
    call function_1115                      
    ldxdw r0, [r10-0x20]                    
    ldxdw r7, [r10-0x28]                    
    lddw r1, 0x8000000000000001                     r1 load str located at -9223372036854775807
    jeq r7, r1, lbb_12059                           if r7 == r1 { pc += 364 }
    lddw r1, 0x8000000000000000                     r1 load str located at -9223372036854775808
    jeq r7, r1, lbb_12015                           if r7 == r1 { pc += 317 }
    ldxdw r1, [r10-0x30]                    
    jeq r1, 0, lbb_12035                            if r1 == (0 as i32 as i64 as u64) { pc += 335 }
    stxdw [r10-0x218], r0                   
    ldxh r1, [r10-0x14]                     
    stxdw [r10-0x250], r1                   
    ldxw r8, [r10-0x18]                     
    ldxh r1, [r10-0x12]                     
    stxdw [r10-0x238], r1                   
    ldxdw r2, [r10-0x38]                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -40                                   r1 += -40   ///  r1 = r1.wrapping_add(-40 as i32 as i64 as u64)
    call function_2121                      
    ldxb r1, [r10-0x28]                     
    jeq r1, 0, lbb_11913                            if r1 == (0 as i32 as i64 as u64) { pc += 201 }
    ja lbb_11594                                    if true { pc += -119 }
lbb_11713:
    lddw r7, 0x800000000000000c                     r7 load str located at -9223372036854775796
    ja lbb_11485                                    if true { pc += -231 }
lbb_11716:
    mov64 r1, r10                                   r1 = r10
    add64 r1, -40                                   r1 += -40   ///  r1 = r1.wrapping_add(-40 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -120                                  r2 += -120   ///  r2 = r2.wrapping_add(-120 as i32 as i64 as u64)
    call function_2121                      
    ldxb r1, [r10-0x28]                     
    jeq r1, 0, lbb_11724                            if r1 == (0 as i32 as i64 as u64) { pc += 1 }
    ja lbb_11874                                    if true { pc += 150 }
lbb_11724:
    ldxdw r2, [r10-0x248]                   
    ldxdw r1, [r2+0x8]                      
    stxdw [r10-0x80], r1                    
    ldxdw r1, [r2+0x0]                      
    stxdw [r10-0x88], r1                    
    ldxh r1, [r10-0x13]                     
    lsh64 r1, 32                                    r1 <<= 32   ///  r1 = r1.wrapping_shl(32)
    ldxw r8, [r10-0x17]                     
    or64 r8, r1                                     r8 |= r1   ///  r8 = r8.or(r1)
    lddw r7, 0x8000000000000006                     r7 load str located at -9223372036854775802
    ldxdw r4, [r10-0x11]                    
    ja lbb_11485                                    if true { pc += -252 }
lbb_11737:
    jgt r0, r2, lbb_11479                           if r0 > r2 { pc += -259 }
    mov64 r2, 212                                   r2 = 212 as i32 as i64 as u64
    stxdw [r10-0x50], r2                    
    mov64 r2, r4                                    r2 = r4
    add64 r2, -12                                   r2 += -12   ///  r2 = r2.wrapping_add(-12 as i32 as i64 as u64)
    jgt r0, r2, lbb_11479                           if r0 > r2 { pc += -264 }
    add64 r4, -20                                   r4 += -20   ///  r4 = r4.wrapping_add(-20 as i32 as i64 as u64)
    stxdw [r10-0x58], r4                    
    add64 r1, 20                                    r1 += 20   ///  r1 = r1.wrapping_add(20 as i32 as i64 as u64)
    stxdw [r10-0x60], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -40                                   r1 += -40   ///  r1 = r1.wrapping_add(-40 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -120                                  r2 += -120   ///  r2 = r2.wrapping_add(-120 as i32 as i64 as u64)
    call function_2121                      
    ldxb r1, [r10-0x28]                     
    jeq r1, 0, lbb_11755                            if r1 == (0 as i32 as i64 as u64) { pc += 1 }
    ja lbb_11874                                    if true { pc += 119 }
lbb_11755:
    ldxdw r2, [r10-0x248]                   
    ldxw r1, [r2+0x0]                       
    ldxh r2, [r2+0x4]                       
    ldxb r3, [r10-0x21]                     
    stxb [r10-0x38], r3                     
    stxh [r10-0x84], r2                     
    stxw [r10-0x88], r1                     
    ldxb r1, [r10-0x18]                     
    stxb [r10-0x79], r1                     
    ldxdw r1, [r10-0x20]                    
    stxdw [r10-0x37], r1                    
    rsh64 r1, 56                                    r1 >>= 56   ///  r1 = r1.wrapping_shr(56)
    stxb [r10-0x7a], r1                     
    ldxdw r1, [r10-0x38]                    
    stxdw [r10-0x82], r1                    
    ldxh r1, [r10-0x13]                     
    lsh64 r1, 32                                    r1 <<= 32   ///  r1 = r1.wrapping_shl(32)
    ldxw r8, [r10-0x17]                     
    or64 r8, r1                                     r8 |= r1   ///  r8 = r8.or(r1)
    lddw r7, 0x8000000000000000                     r7 load str located at -9223372036854775808
    ldxdw r4, [r10-0x11]                    
    ja lbb_11485                                    if true { pc += -293 }
lbb_11778:
    mov64 r1, 4                                     r1 = 4 as i32 as i64 as u64
    stxdw [r10-0x30], r1                    
    mov64 r2, r10                                   r2 = r10
    add64 r2, -120                                  r2 += -120   ///  r2 = r2.wrapping_add(-120 as i32 as i64 as u64)
    stxdw [r10-0x38], r2                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -40                                   r1 += -40   ///  r1 = r1.wrapping_add(-40 as i32 as i64 as u64)
    call function_2121                      
    ldxb r1, [r10-0x28]                     
    jne r1, 0, lbb_11874                            if r1 != (0 as i32 as i64 as u64) { pc += 86 }
    ldxb r1, [r10-0x21]                     
    stxb [r10-0x48], r1                     
    ldxdw r1, [r10-0x20]                    
    stxdw [r10-0x47], r1                    
    ldxw r8, [r10-0x27]                     
    ldxh r6, [r10-0x23]                     
    ldxdw r1, [r10-0x48]                    
    stxdw [r10-0x1f8], r1                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -40                                   r1 += -40   ///  r1 = r1.wrapping_add(-40 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -56                                   r2 += -56   ///  r2 = r2.wrapping_add(-56 as i32 as i64 as u64)
    call function_1115                      
    ldxdw r0, [r10-0x20]                    
    ldxdw r7, [r10-0x28]                    
    lddw r1, 0x8000000000000001                     r1 load str located at -9223372036854775807
    jeq r7, r1, lbb_12059                           if r7 == r1 { pc += 253 }
    lddw r1, 0x8000000000000000                     r1 load str located at -9223372036854775808
    jeq r7, r1, lbb_12045                           if r7 == r1 { pc += 236 }
    ldxdw r1, [r10-0x30]                    
    jeq r1, 0, lbb_12064                            if r1 == (0 as i32 as i64 as u64) { pc += 253 }
    ldxdw r2, [r10-0x38]                    
    ldxdw r3, [r2+0x28]                     
    jgt r3, 7, lbb_11929                            if r3 > (7 as i32 as i64 as u64) { pc += 115 }
    lddw r1, 0x300000000                            r1 load str located at 12884901888
    ldxdw r1, [r1+0x0]                      
    mov64 r3, r1                                    r3 = r1
    add64 r3, -24                                   r3 += -24   ///  r3 = r3.wrapping_add(-24 as i32 as i64 as u64)
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
    mov64 r4, 1                                     r4 = 1 as i32 as i64 as u64
    jgt r3, r1, lbb_11823                           if r3 > r1 { pc += 1 }
    mov64 r4, 0                                     r4 = 0 as i32 as i64 as u64
lbb_11823:
    ldxdw r6, [r10-0x220]                   
    jne r4, 0, lbb_11826                            if r4 != (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r2, r3                                    r2 = r3
lbb_11826:
    lddw r0, 0x300007fe8                            r0 load str located at 12884934632
    jeq r1, 0, lbb_11831                            if r1 == (0 as i32 as i64 as u64) { pc += 2 }
    and64 r2, -8                                    r2 &= -8   ///  r2 = r2.and(-8)
    mov64 r0, r2                                    r0 = r2
lbb_11831:
    lddw r1, 0x300000007                            r1 load str located at 12884901895
    jgt r0, r1, lbb_11990                           if r0 > r1 { pc += 156 }
lbb_11834:
    mov64 r1, 8                                     r1 = 8 as i32 as i64 as u64
    mov64 r2, 24                                    r2 = 24 as i32 as i64 as u64
    call function_21552                     
lbb_11837:
    mov64 r1, r10                                   r1 = r10
    add64 r1, -40                                   r1 += -40   ///  r1 = r1.wrapping_add(-40 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -120                                  r2 += -120   ///  r2 = r2.wrapping_add(-120 as i32 as i64 as u64)
    call function_2121                      
    ldxb r1, [r10-0x28]                     
    jne r1, 0, lbb_11874                            if r1 != (0 as i32 as i64 as u64) { pc += 30 }
    ldxdw r2, [r10-0x248]                   
    ldxw r1, [r2+0x0]                       
    ldxh r2, [r2+0x4]                       
    ldxb r3, [r10-0x21]                     
    stxb [r10-0x38], r3                     
    stxh [r10-0x84], r2                     
    stxw [r10-0x88], r1                     
    ldxb r1, [r10-0x18]                     
    stxb [r10-0x79], r1                     
    ldxdw r1, [r10-0x20]                    
    stxdw [r10-0x37], r1                    
    rsh64 r1, 56                                    r1 >>= 56   ///  r1 = r1.wrapping_shr(56)
    stxb [r10-0x7a], r1                     
    ldxdw r1, [r10-0x38]                    
    stxdw [r10-0x82], r1                    
    ldxh r1, [r10-0x13]                     
    lsh64 r1, 32                                    r1 <<= 32   ///  r1 = r1.wrapping_shl(32)
    ldxw r8, [r10-0x17]                     
    or64 r8, r1                                     r8 |= r1   ///  r8 = r8.or(r1)
    lddw r7, 0x8000000000000001                     r7 load str located at -9223372036854775807
    ldxdw r4, [r10-0x11]                    
    ja lbb_11485                                    if true { pc += -382 }
lbb_11867:
    mov64 r1, r10                                   r1 = r10
    add64 r1, -40                                   r1 += -40   ///  r1 = r1.wrapping_add(-40 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -120                                  r2 += -120   ///  r2 = r2.wrapping_add(-120 as i32 as i64 as u64)
    call function_2121                      
    ldxb r1, [r10-0x28]                     
    jeq r1, 0, lbb_11877                            if r1 == (0 as i32 as i64 as u64) { pc += 3 }
lbb_11874:
    ldxdw r1, [r10-0x20]                    
    stxdw [r10-0x88], r1                    
    ja lbb_11483                                    if true { pc += -394 }
lbb_11877:
    ldxdw r2, [r10-0x248]                   
    ldxdw r1, [r2+0x8]                      
    stxdw [r10-0x80], r1                    
    ldxdw r1, [r2+0x0]                      
    stxdw [r10-0x88], r1                    
    ldxh r1, [r10-0x13]                     
    lsh64 r1, 32                                    r1 <<= 32   ///  r1 = r1.wrapping_shl(32)
    ldxw r8, [r10-0x17]                     
    or64 r8, r1                                     r8 |= r1   ///  r8 = r8.or(r1)
    lddw r7, 0x8000000000000007                     r7 load str located at -9223372036854775801
    ldxdw r4, [r10-0x11]                    
    ja lbb_11485                                    if true { pc += -405 }
lbb_11890:
    ldxh r4, [r10-0x14]                     
    stxdw [r10-0x218], r4                   
    mov64 r4, 8                                     r4 = 8 as i32 as i64 as u64
    ldxw r8, [r10-0x18]                     
    ldxh r5, [r10-0x12]                     
    add64 r3, -8                                    r3 += -8   ///  r3 = r3.wrapping_add(-8 as i32 as i64 as u64)
    stxdw [r2+0x28], r3                     
    ldxdw r3, [r2+0x20]                     
    jgt r4, r3, lbb_11939                           if r4 > r3 { pc += 40 }
    stxdw [r10-0x250], r5                   
    stxdw [r10-0x238], r0                   
    add64 r3, -8                                    r3 += -8   ///  r3 = r3.wrapping_add(-8 as i32 as i64 as u64)
    stxdw [r2+0x20], r3                     
    ldxdw r3, [r2+0x18]                     
    add64 r3, 8                                     r3 += 8   ///  r3 = r3.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r2+0x18], r3                     
    jeq r1, 1, lbb_12081                            if r1 == (1 as i32 as i64 as u64) { pc += 174 }
    mov64 r1, r10                                   r1 = r10
    add64 r1, -40                                   r1 += -40   ///  r1 = r1.wrapping_add(-40 as i32 as i64 as u64)
    call function_2121                      
    ldxb r1, [r10-0x28]                     
    jeq r1, 0, lbb_12019                            if r1 == (0 as i32 as i64 as u64) { pc += 107 }
    ja lbb_12012                                    if true { pc += 99 }
lbb_11913:
    lsh64 r6, 32                                    r6 <<= 32   ///  r6 = r6.wrapping_shl(32)
    ldxdw r4, [r10-0x1f8]                   
    or64 r4, r6                                     r4 |= r6   ///  r4 = r4.or(r6)
    ldxdw r1, [r10-0x250]                   
    lsh64 r1, 32                                    r1 <<= 32   ///  r1 = r1.wrapping_shl(32)
    or64 r8, r1                                     r8 |= r1   ///  r8 = r8.or(r1)
    ldxdw r1, [r10-0x218]                   
    stxdw [r10-0x80], r1                    
    stxdw [r10-0x88], r7                    
    lsh64 r4, 16                                    r4 <<= 16   ///  r4 = r4.wrapping_shl(16)
    ldxdw r1, [r10-0x238]                   
    or64 r4, r1                                     r4 |= r1   ///  r4 = r4.or(r1)
    lddw r7, 0x800000000000000b                     r7 load str located at -9223372036854775797
    ldxdw r6, [r10-0x220]                   
    ja lbb_11485                                    if true { pc += -444 }
lbb_11929:
    stxdw [r10-0x218], r0                   
    ldxdw r4, [r10-0x18]                    
    stxdw [r10-0x238], r4                   
    mov64 r0, r3                                    r0 = r3
    add64 r0, -8                                    r0 += -8   ///  r0 = r0.wrapping_add(-8 as i32 as i64 as u64)
    stxdw [r2+0x28], r0                     
    ldxdw r5, [r2+0x20]                     
    mov64 r4, 8                                     r4 = 8 as i32 as i64 as u64
    jgt r4, r5, lbb_11939                           if r4 > r5 { pc += 1 }
    ja lbb_11960                                    if true { pc += 21 }
lbb_11939:
    lddw r1, 0x100040d80 --> b"\x00\x00\x00\x00\x99\xe5\x03\x00\x1b\x00\x00\x00\x00\x00\x00\x00%\x00\x00…        r1 load str located at 4295232896
    call function_19497                     
    ldxdw r6, [r10-0x220]                   
    ja lbb_11482                                    if true { pc += -462 }
lbb_11944:
    lsh64 r6, 32                                    r6 <<= 32   ///  r6 = r6.wrapping_shl(32)
    ldxdw r4, [r10-0x1f8]                   
    or64 r4, r6                                     r4 |= r6   ///  r4 = r4.or(r6)
    ldxdw r1, [r10-0x250]                   
    lsh64 r1, 32                                    r1 <<= 32   ///  r1 = r1.wrapping_shl(32)
    or64 r8, r1                                     r8 |= r1   ///  r8 = r8.or(r1)
    ldxdw r1, [r10-0x218]                   
    stxdw [r10-0x80], r1                    
    stxdw [r10-0x88], r7                    
    lsh64 r4, 16                                    r4 <<= 16   ///  r4 = r4.wrapping_shl(16)
    ldxdw r1, [r10-0x238]                   
    or64 r4, r1                                     r4 |= r1   ///  r4 = r4.or(r1)
    lddw r7, 0x800000000000000a                     r7 load str located at -9223372036854775798
    ldxdw r6, [r10-0x220]                   
    ja lbb_11485                                    if true { pc += -475 }
lbb_11960:
    ldxdw r4, [r2+0x18]                     
    stxdw [r10-0x250], r4                   
    add64 r4, 8                                     r4 += 8   ///  r4 = r4.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r2+0x18], r4                     
    mov64 r4, r5                                    r4 = r5
    add64 r4, -8                                    r4 += -8   ///  r4 = r4.wrapping_add(-8 as i32 as i64 as u64)
    stxdw [r2+0x20], r4                     
    jeq r1, 1, lbb_12085                            if r1 == (1 as i32 as i64 as u64) { pc += 117 }
    jgt r0, 7, lbb_11997                            if r0 > (7 as i32 as i64 as u64) { pc += 28 }
    lddw r1, 0x300000000                            r1 load str located at 12884901888
    ldxdw r1, [r1+0x0]                      
    mov64 r3, r1                                    r3 = r1
    add64 r3, -24                                   r3 += -24   ///  r3 = r3.wrapping_add(-24 as i32 as i64 as u64)
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
    mov64 r4, 1                                     r4 = 1 as i32 as i64 as u64
    jgt r3, r1, lbb_11978                           if r3 > r1 { pc += 1 }
    mov64 r4, 0                                     r4 = 0 as i32 as i64 as u64
lbb_11978:
    ldxdw r6, [r10-0x220]                   
    jne r4, 0, lbb_11981                            if r4 != (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r2, r3                                    r2 = r3
lbb_11981:
    lddw r0, 0x300007fe8                            r0 load str located at 12884934632
    jeq r1, 0, lbb_11986                            if r1 == (0 as i32 as i64 as u64) { pc += 2 }
    and64 r2, -8                                    r2 &= -8   ///  r2 = r2.and(-8)
    mov64 r0, r2                                    r0 = r2
lbb_11986:
    lddw r1, 0x300000007                            r1 load str located at 12884901895
    jgt r0, r1, lbb_11990                           if r0 > r1 { pc += 1 }
    ja lbb_11834                                    if true { pc += -156 }
lbb_11990:
    lddw r1, 0x300000000                            r1 load str located at 12884901888
    stxdw [r1+0x0], r0                      
    lddw r1, 0x8000000000000006                     r1 load str located at -9223372036854775802
    stxdw [r0+0x0], r1                      
    ja lbb_11482                                    if true { pc += -515 }
lbb_11997:
    add64 r3, -16                                   r3 += -16   ///  r3 = r3.wrapping_add(-16 as i32 as i64 as u64)
    stxdw [r2+0x28], r3                     
    mov64 r3, 8                                     r3 = 8 as i32 as i64 as u64
    jgt r3, r4, lbb_11939                           if r3 > r4 { pc += -62 }
    add64 r5, -16                                   r5 += -16   ///  r5 = r5.wrapping_add(-16 as i32 as i64 as u64)
    stxdw [r2+0x20], r5                     
    ldxdw r3, [r10-0x250]                   
    add64 r3, 16                                    r3 += 16   ///  r3 = r3.wrapping_add(16 as i32 as i64 as u64)
    stxdw [r2+0x18], r3                     
    jeq r1, 2, lbb_12087                            if r1 == (2 as i32 as i64 as u64) { pc += 80 }
    mov64 r1, r10                                   r1 = r10
    add64 r1, -40                                   r1 += -40   ///  r1 = r1.wrapping_add(-40 as i32 as i64 as u64)
    call function_2121                      
    ldxb r1, [r10-0x28]                     
    jeq r1, 0, lbb_12072                            if r1 == (0 as i32 as i64 as u64) { pc += 60 }
lbb_12012:
    ldxdw r0, [r10-0x20]                    
    ldxdw r6, [r10-0x220]                   
    ja lbb_11482                                    if true { pc += -533 }
lbb_12015:
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    lddw r2, 0x100040d60 --> b"\x00\x00\x00\x00\x17\xe5\x03\x00B\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00…        r2 load str located at 4295232864
    ja lbb_12056                                    if true { pc += 37 }
lbb_12019:
    lsh64 r6, 32                                    r6 <<= 32   ///  r6 = r6.wrapping_shl(32)
    ldxdw r4, [r10-0x1f8]                   
    or64 r4, r6                                     r4 |= r6   ///  r4 = r4.or(r6)
    ldxdw r1, [r10-0x218]                   
    lsh64 r1, 32                                    r1 <<= 32   ///  r1 = r1.wrapping_shl(32)
    or64 r8, r1                                     r8 |= r1   ///  r8 = r8.or(r1)
    ldxdw r1, [r10-0x238]                   
    stxdw [r10-0x80], r1                    
    stxdw [r10-0x88], r7                    
    lsh64 r4, 16                                    r4 <<= 16   ///  r4 = r4.wrapping_shl(16)
    ldxdw r1, [r10-0x250]                   
    or64 r4, r1                                     r4 |= r1   ///  r4 = r4.or(r1)
    lddw r7, 0x8000000000000009                     r7 load str located at -9223372036854775799
    ldxdw r6, [r10-0x220]                   
    ja lbb_11485                                    if true { pc += -550 }
lbb_12035:
    mov64 r1, 2                                     r1 = 2 as i32 as i64 as u64
    lddw r2, 0x100040d60 --> b"\x00\x00\x00\x00\x17\xe5\x03\x00B\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00…        r2 load str located at 4295232864
    ja lbb_12056                                    if true { pc += 17 }
lbb_12039:
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    lddw r2, 0x100040d50 --> b"\x00\x00\x00\x00\xd5\xe4\x03\x00B\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00…        r2 load str located at 4295232848
    ja lbb_12056                                    if true { pc += 13 }
lbb_12043:
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    ja lbb_12054                                    if true { pc += 9 }
lbb_12045:
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    lddw r2, 0x100040d40 --> b"\x00\x00\x00\x00\x8e\xe4\x03\x00G\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00…        r2 load str located at 4295232832
    ja lbb_12056                                    if true { pc += 7 }
lbb_12049:
    mov64 r1, 2                                     r1 = 2 as i32 as i64 as u64
    lddw r2, 0x100040d50 --> b"\x00\x00\x00\x00\xd5\xe4\x03\x00B\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00…        r2 load str located at 4295232848
    ja lbb_12067                                    if true { pc += 14 }
lbb_12053:
    mov64 r1, 2                                     r1 = 2 as i32 as i64 as u64
lbb_12054:
    lddw r2, 0x100040d70 --> b"\x00\x00\x00\x00Y\xe5\x03\x00@\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x0…        r2 load str located at 4295232880
lbb_12056:
    lddw r3, 0x100040d20 --> b"\x00\x00\x00\x00\xc8\x0f\x00\x00\x10\x00\x00\x00\x00\x00\x00\x00\x08\x00\…        r3 load str located at 4295232800
    call function_1085                      
lbb_12059:
    stxdw [r10-0x88], r0                    
    lddw r7, 0x800000000000000d                     r7 load str located at -9223372036854775795
    ldxdw r6, [r10-0x220]                   
    ja lbb_11485                                    if true { pc += -579 }
lbb_12064:
    mov64 r1, 2                                     r1 = 2 as i32 as i64 as u64
lbb_12065:
    lddw r2, 0x100040d40 --> b"\x00\x00\x00\x00\x8e\xe4\x03\x00G\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00…        r2 load str located at 4295232832
lbb_12067:
    lddw r3, 0x100040d20 --> b"\x00\x00\x00\x00\xc8\x0f\x00\x00\x10\x00\x00\x00\x00\x00\x00\x00\x08\x00\…        r3 load str located at 4295232800
    call function_1085                      
    ldxdw r6, [r10-0x220]                   
    ja lbb_11482                                    if true { pc += -590 }
lbb_12072:
    lsh64 r6, 32                                    r6 <<= 32   ///  r6 = r6.wrapping_shl(32)
    or64 r8, r6                                     r8 |= r6   ///  r8 = r8.or(r6)
    ldxdw r1, [r10-0x238]                   
    stxdw [r10-0x80], r1                    
    ldxdw r1, [r10-0x218]                   
    stxdw [r10-0x88], r1                    
    ldxdw r6, [r10-0x220]                   
    ldxdw r4, [r10-0x1f8]                   
    ja lbb_11485                                    if true { pc += -596 }
lbb_12081:
    mov64 r1, 3                                     r1 = 3 as i32 as i64 as u64
    lddw r2, 0x100040d50 --> b"\x00\x00\x00\x00\xd5\xe4\x03\x00B\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00…        r2 load str located at 4295232848
    ja lbb_12067                                    if true { pc += -18 }
lbb_12085:
    mov64 r1, 3                                     r1 = 3 as i32 as i64 as u64
    ja lbb_12065                                    if true { pc += -22 }
lbb_12087:
    mov64 r1, 4                                     r1 = 4 as i32 as i64 as u64
    ja lbb_12065                                    if true { pc += -24 }
lbb_12089:
    ldxdw r1, [r10-0x108]                   
    lddw r2, 0x830d8e1429103dbb                     r2 load str located at -9003383862804333125
    jne r1, r2, lbb_11437                           if r1 != r2 { pc += -656 }
    ldxdw r1, [r10-0x100]                   
    lddw r2, 0x8410ffda99135a0b                     r2 load str located at -8930356746739557877
    jne r1, r2, lbb_11437                           if r1 != r2 { pc += -660 }
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    ldxdw r2, [r10-0xf8]                    
    lddw r3, 0x59f8e9dbd87b8e04                     r3 load str located at 6483188794038914564
    jne r2, r3, lbb_11437                           if r2 != r3 { pc += -665 }
lbb_12102:
    jeq r1, 0, lbb_10677                            if r1 == (0 as i32 as i64 as u64) { pc += -1426 }
    ldxdw r1, [r10-0x110]                   
    lddw r2, 0x93a165d7e1f6dd06                     r2 load str located at -7808848301000303354
    jeq r1, r2, lbb_12109                           if r1 == r2 { pc += 2 }
lbb_12107:
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    ja lbb_12122                                    if true { pc += 13 }
lbb_12109:
    ldxdw r1, [r10-0x108]                   
    lddw r2, 0xac79ebce46e1cbd9                     r2 load str located at -6018520155818964007
    jne r1, r2, lbb_12107                           if r1 != r2 { pc += -6 }
    ldxdw r1, [r10-0x100]                   
    lddw r2, 0x91375b5fed85b41c                     r2 load str located at -7982811346925931492
    jne r1, r2, lbb_12107                           if r1 != r2 { pc += -10 }
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    ldxdw r2, [r10-0xf8]                    
    lddw r3, 0xa900ff7e85f58c3a                     r3 load str located at -6268729762421306310
    jne r2, r3, lbb_12107                           if r2 != r3 { pc += -15 }
lbb_12122:
    jeq r1, 0, lbb_12143                            if r1 == (0 as i32 as i64 as u64) { pc += 20 }
    ldxdw r1, [r10-0x110]                   
    lddw r2, 0xde8f75eee1f6dd06                     r2 load str located at -2409577606766207738
    jeq r1, r2, lbb_12129                           if r1 == r2 { pc += 2 }
lbb_12127:
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    ja lbb_12142                                    if true { pc += 13 }
lbb_12129:
    ldxdw r1, [r10-0x108]                   
    lddw r2, 0xdacd6ce4bc5d4218                     r2 load str located at -2680366473547005416
    jne r1, r2, lbb_12127                           if r1 != r2 { pc += -6 }
    ldxdw r1, [r10-0x100]                   
    lddw r2, 0x270db9834dfc1ab6                     r2 load str located at 2814109315776649910
    jne r1, r2, lbb_12127                           if r1 != r2 { pc += -10 }
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    ldxdw r2, [r10-0xf8]                    
    lddw r3, 0xfc8ba1d828f9bdfe                     r3 load str located at -248927404616466946
    jne r2, r3, lbb_12127                           if r2 != r3 { pc += -15 }
lbb_12142:
    jne r1, 0, lbb_12160                            if r1 != (0 as i32 as i64 as u64) { pc += 17 }
lbb_12143:
    ldxdw r2, [r10-0x120]                   
    ldxdw r3, [r10-0x118]                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -240                                  r1 += -240   ///  r1 = r1.wrapping_add(-240 as i32 as i64 as u64)
    call function_14648                     
    ldxw r1, [r10-0xf0]                     
    jeq r1, 45, lbb_11225                           if r1 == (45 as i32 as i64 as u64) { pc += -925 }
    jgt r1, 17, lbb_12155                           if r1 > (17 as i32 as i64 as u64) { pc += 4 }
    mov64 r2, 1                                     r2 = 1 as i32 as i64 as u64
    lsh64 r2, r1                                    r2 <<= r1   ///  r2 = r2.wrapping_shl(r1 as u32)
    and64 r2, 131586                                r2 &= 131586   ///  r2 = r2.and(131586)
    jne r2, 0, lbb_10677                            if r2 != (0 as i32 as i64 as u64) { pc += -1478 }
lbb_12155:
    mov64 r2, 1                                     r2 = 1 as i32 as i64 as u64
    stxb [r10-0x144], r2                    
    jeq r1, 29, lbb_10677                           if r1 == (29 as i32 as i64 as u64) { pc += -1481 }
    jne r1, 21, lbb_10677                           if r1 != (21 as i32 as i64 as u64) { pc += -1482 }
    ja lbb_10677                                    if true { pc += -1483 }
lbb_12160:
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    stxb [r10-0x144], r1                    
    ja lbb_10677                                    if true { pc += -1486 }
lbb_12163:
    ldxdw r8, [r10-0x200]                   
    jeq r1, 9, lbb_12167                            if r1 == (9 as i32 as i64 as u64) { pc += 2 }
    jeq r1, 10, lbb_12167                           if r1 == (10 as i32 as i64 as u64) { pc += 1 }
    jeq r1, 11, lbb_12168                           if r1 == (11 as i32 as i64 as u64) { pc += 1 }
lbb_12167:
    ja lbb_10677                                    if true { pc += -1491 }
lbb_12168:
    mov64 r2, 1                                     r2 = 1 as i32 as i64 as u64
    stxb [r10-0x143], r2                    
    jsgt r1, 9, lbb_12174                           if (r1 as i64) > (9 as i32 as i64) { pc += 3 }
    jeq r1, 3, lbb_12167                            if r1 == (3 as i32 as i64 as u64) { pc += -5 }
    jeq r1, 9, lbb_12167                            if r1 == (9 as i32 as i64 as u64) { pc += -6 }
    ja lbb_12167                                    if true { pc += -7 }
lbb_12174:
    jeq r1, 10, lbb_12167                           if r1 == (10 as i32 as i64 as u64) { pc += -8 }
    jeq r1, 11, lbb_12167                           if r1 == (11 as i32 as i64 as u64) { pc += -9 }
    ja lbb_12167                                    if true { pc += -10 }
lbb_12177:
    lddw r1, 0x8000000000000001                     r1 load str located at -9223372036854775807
    ldxdw r2, [r10-0xe8]                    
    jeq r2, r1, lbb_12182                           if r2 == r1 { pc += 1 }
    ja lbb_12193                                    if true { pc += 11 }
lbb_12182:
    ldxdw r1, [r10-0x170]                   
    ldxdw r5, [r10-0x230]                   
    jeq r1, 0, lbb_12306                            if r1 == (0 as i32 as i64 as u64) { pc += 121 }
    ldxdw r8, [r10-0x178]                   
    ldxdw r2, [r10-0x208]                   
    ldxdw r6, [r2+0x28]                     
    jne r6, 0, lbb_12200                            if r6 != (0 as i32 as i64 as u64) { pc += 11 }
    ldxw r1, [r8+0x0]                       
    ldxw r2, [r8+0xe]                       
    ldxw r3, [r8+0x1c]                      
    ja lbb_12314                                    if true { pc += 121 }
lbb_12193:
    mov64 r1, 65535                                 r1 = 65535 as i32 as i64 as u64
    ldxdw r2, [r10-0x230]                   
    stxw [r2+0x8], r1                       
lbb_12196:
    lddw r1, 0x8000000000000000                     r1 load str located at -9223372036854775808
    stxdw [r2+0x0], r1                      
    ja lbb_12614                                    if true { pc += 414 }
lbb_12200:
    ldxdw r7, [r2+0x20]                     
    ldxdw r3, [r2+0x10]                     
    stxdw [r10-0x1e8], r3                   
    jeq r3, 0, lbb_12499                            if r3 == (0 as i32 as i64 as u64) { pc += 295 }
    lsh64 r1, 5                                     r1 <<= 5   ///  r1 = r1.wrapping_shl(5)
    mov64 r3, r8                                    r3 = r8
    add64 r3, r1                                    r3 += r1   ///  r3 = r3.wrapping_add(r1)
    stxdw [r10-0x200], r3                   
    ldxdw r1, [r2+0x8]                      
    stxdw [r10-0x1f0], r1                   
    stxdw [r10-0x1f8], r7                   
lbb_12211:
    ldxw r1, [r8+0x0]                       
    ldxw r2, [r8+0xe]                       
    ldxw r3, [r8+0x1c]                      
    stxw [r10-0x138], r3                    
    stxw [r10-0x13c], r2                    
    stxw [r10-0x140], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -240                                  r1 += -240   ///  r1 = r1.wrapping_add(-240 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -320                                  r2 += -320   ///  r2 = r2.wrapping_add(-320 as i32 as i64 as u64)
    mov64 r3, 12                                    r3 = 12 as i32 as i64 as u64
    call function_19860                     
    ldxdw r2, [r10-0xe8]                    
    be64 r2                                         r2 = match 64 { 16 => (r2 as u16).swap_bytes() as u64, 32 => (r2 as u32).swap_bytes() as u64, 64 => r2.swap_bytes(), _ => r2 }
    ldxdw r3, [r10-0xf0]                    
    be64 r3                                         r3 = match 64 { 16 => (r3 as u16).swap_bytes() as u64, 32 => (r3 as u32).swap_bytes() as u64, 64 => r3.swap_bytes(), _ => r3 }
    mov64 r1, r10                                   r1 = r10
    add64 r1, -400                                  r1 += -400   ///  r1 = r1.wrapping_add(-400 as i32 as i64 as u64)
    mov64 r4, r6                                    r4 = r6
    mov64 r5, 0                                     r5 = 0 as i32 as i64 as u64
    call function_31706                     
    ldxdw r1, [r10-0x190]                   
    jgt r6, r1, lbb_12235                           if r6 > r1 { pc += 1 }
    ja lbb_12615                                    if true { pc += 380 }
lbb_12235:
    add64 r8, 32                                    r8 += 32   ///  r8 = r8.wrapping_add(32 as i32 as i64 as u64)
    mul64 r1, 24                                    r1 *= 24   ///  r1 = r1.wrapping_mul(24 as u64)
    mov64 r2, r7                                    r2 = r7
    add64 r2, r1                                    r2 += r1   ///  r2 = r2.wrapping_add(r1)
    ldxw r3, [r10-0x138]                    
    ldxdw r4, [r10-0x140]                   
    ldxdw r5, [r2+0x8]                      
    ldxdw r0, [r2+0x10]                     
    mul64 r0, 12                                    r0 *= 12   ///  r0 = r0.wrapping_mul(12 as u64)
lbb_12244:
    jeq r0, 0, lbb_12259                            if r0 == (0 as i32 as i64 as u64) { pc += 14 }
    ldxdw r7, [r5+0x0]                      
    xor64 r7, r4                                    r7 ^= r4   ///  r7 = r7.xor(r4)
    ldxw r1, [r5+0x8]                       
    xor64 r1, r3                                    r1 ^= r3   ///  r1 = r1.xor(r3)
    lsh64 r1, 32                                    r1 <<= 32   ///  r1 = r1.wrapping_shl(32)
    rsh64 r1, 32                                    r1 >>= 32   ///  r1 = r1.wrapping_shr(32)
    or64 r7, r1                                     r7 |= r1   ///  r7 = r7.or(r1)
    lddw r2, 0x8000000000000000                     r2 load str located at -9223372036854775808
    mov64 r1, 255                                   r1 = 255 as i32 as i64 as u64
    add64 r0, -12                                   r0 += -12   ///  r0 = r0.wrapping_add(-12 as i32 as i64 as u64)
    add64 r5, 12                                    r5 += 12   ///  r5 = r5.wrapping_add(12 as i32 as i64 as u64)
    jeq r7, 0, lbb_12589                            if r7 == (0 as i32 as i64 as u64) { pc += 331 }
    ja lbb_12244                                    if true { pc += -15 }
lbb_12259:
    mov64 r1, r10                                   r1 = r10
    add64 r1, -240                                  r1 += -240   ///  r1 = r1.wrapping_add(-240 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -320                                  r2 += -320   ///  r2 = r2.wrapping_add(-320 as i32 as i64 as u64)
    mov64 r3, 12                                    r3 = 12 as i32 as i64 as u64
    call function_19860                     
    ldxdw r2, [r10-0xe8]                    
    be64 r2                                         r2 = match 64 { 16 => (r2 as u16).swap_bytes() as u64, 32 => (r2 as u32).swap_bytes() as u64, 64 => r2.swap_bytes(), _ => r2 }
    ldxdw r3, [r10-0xf0]                    
    be64 r3                                         r3 = match 64 { 16 => (r3 as u16).swap_bytes() as u64, 32 => (r3 as u32).swap_bytes() as u64, 64 => r3.swap_bytes(), _ => r3 }
    mov64 r1, r10                                   r1 = r10
    add64 r1, -416                                  r1 += -416   ///  r1 = r1.wrapping_add(-416 as i32 as i64 as u64)
    ldxdw r7, [r10-0x1e8]                   
    mov64 r4, r7                                    r4 = r7
    mov64 r5, 0                                     r5 = 0 as i32 as i64 as u64
    call function_31706                     
    ldxdw r1, [r10-0x1a0]                   
    jgt r7, r1, lbb_12278                           if r7 > r1 { pc += 1 }
    ja lbb_12402                                    if true { pc += 124 }
lbb_12278:
    mul64 r1, 24                                    r1 *= 24   ///  r1 = r1.wrapping_mul(24 as u64)
    ldxdw r2, [r10-0x1f0]                   
    add64 r2, r1                                    r2 += r1   ///  r2 = r2.wrapping_add(r1)
    ldxw r3, [r10-0x138]                    
    ldxdw r4, [r10-0x140]                   
    ldxdw r5, [r2+0x8]                      
    ldxdw r0, [r2+0x10]                     
    mul64 r0, 12                                    r0 *= 12   ///  r0 = r0.wrapping_mul(12 as u64)
lbb_12286:
    jeq r0, 0, lbb_12301                            if r0 == (0 as i32 as i64 as u64) { pc += 14 }
    ldxdw r7, [r5+0x0]                      
    xor64 r7, r4                                    r7 ^= r4   ///  r7 = r7.xor(r4)
    ldxw r1, [r5+0x8]                       
    xor64 r1, r3                                    r1 ^= r3   ///  r1 = r1.xor(r3)
    lsh64 r1, 32                                    r1 <<= 32   ///  r1 = r1.wrapping_shl(32)
    rsh64 r1, 32                                    r1 >>= 32   ///  r1 = r1.wrapping_shr(32)
    or64 r7, r1                                     r7 |= r1   ///  r7 = r7.or(r1)
    lddw r2, 0x800000000000001a                     r2 load str located at -9223372036854775782
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    add64 r0, -12                                   r0 += -12   ///  r0 = r0.wrapping_add(-12 as i32 as i64 as u64)
    add64 r5, 12                                    r5 += 12   ///  r5 = r5.wrapping_add(12 as i32 as i64 as u64)
    jeq r7, 0, lbb_12589                            if r7 == (0 as i32 as i64 as u64) { pc += 289 }
    ja lbb_12286                                    if true { pc += -15 }
lbb_12301:
    ldxdw r5, [r10-0x230]                   
    ldxdw r7, [r10-0x1f8]                   
    ldxdw r1, [r10-0x200]                   
    jeq r8, r1, lbb_12306                           if r8 == r1 { pc += 1 }
    ja lbb_12211                                    if true { pc += -95 }
lbb_12306:
    ldxdw r2, [r10-0x210]                   
    jeq r2, 0, lbb_12433                            if r2 == (0 as i32 as i64 as u64) { pc += 125 }
    ldxdw r1, [r10-0x208]                   
    ldxdw r6, [r1+0x28]                     
    jne r6, 0, lbb_12326                            if r6 != (0 as i32 as i64 as u64) { pc += 15 }
    ldxw r1, [r9+0x0]                       
    ldxw r2, [r9+0xe]                       
    ldxw r3, [r9+0x1c]                      
lbb_12314:
    stxw [r10-0x138], r3                    
    stxw [r10-0x13c], r2                    
    stxw [r10-0x140], r1                    
lbb_12317:
    mov64 r1, r10                                   r1 = r10
    add64 r1, -240                                  r1 += -240   ///  r1 = r1.wrapping_add(-240 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -320                                  r2 += -320   ///  r2 = r2.wrapping_add(-320 as i32 as i64 as u64)
    mov64 r3, 12                                    r3 = 12 as i32 as i64 as u64
    call function_19860                     
    lddw r1, 0x1000413a8 --> b"\x00\x00\x00\x00p\xe7\x03\x00\x10\x00\x00\x00\x00\x00\x00\x00@\x00\x00\x0…        r1 load str located at 4295234472
    call function_29633                     
lbb_12326:
    ldxdw r7, [r1+0x20]                     
    ldxdw r3, [r1+0x10]                     
    stxdw [r10-0x1e8], r3                   
    jeq r3, 0, lbb_12544                            if r3 == (0 as i32 as i64 as u64) { pc += 214 }
    lsh64 r2, 5                                     r2 <<= 5   ///  r2 = r2.wrapping_shl(5)
    mov64 r8, r9                                    r8 = r9
    add64 r8, r2                                    r8 += r2   ///  r8 = r8.wrapping_add(r2)
    ldxdw r1, [r1+0x8]                      
    stxdw [r10-0x1f0], r1                   
    stxdw [r10-0x1f8], r7                   
lbb_12336:
    ldxw r1, [r9+0x0]                       
    ldxw r2, [r9+0xe]                       
    ldxw r3, [r9+0x1c]                      
    stxw [r10-0x138], r3                    
    stxw [r10-0x13c], r2                    
    stxw [r10-0x140], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -240                                  r1 += -240   ///  r1 = r1.wrapping_add(-240 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -320                                  r2 += -320   ///  r2 = r2.wrapping_add(-320 as i32 as i64 as u64)
    mov64 r3, 12                                    r3 = 12 as i32 as i64 as u64
    call function_19860                     
    ldxdw r2, [r10-0xe8]                    
    be64 r2                                         r2 = match 64 { 16 => (r2 as u16).swap_bytes() as u64, 32 => (r2 as u32).swap_bytes() as u64, 64 => r2.swap_bytes(), _ => r2 }
    ldxdw r3, [r10-0xf0]                    
    be64 r3                                         r3 = match 64 { 16 => (r3 as u16).swap_bytes() as u64, 32 => (r3 as u32).swap_bytes() as u64, 64 => r3.swap_bytes(), _ => r3 }
    mov64 r1, r10                                   r1 = r10
    add64 r1, -448                                  r1 += -448   ///  r1 = r1.wrapping_add(-448 as i32 as i64 as u64)
    mov64 r4, r6                                    r4 = r6
    mov64 r5, 0                                     r5 = 0 as i32 as i64 as u64
    call function_31706                     
    ldxdw r1, [r10-0x1c0]                   
    jgt r6, r1, lbb_12360                           if r6 > r1 { pc += 1 }
    ja lbb_12615                                    if true { pc += 255 }
lbb_12360:
    add64 r9, 32                                    r9 += 32   ///  r9 = r9.wrapping_add(32 as i32 as i64 as u64)
    mul64 r1, 24                                    r1 *= 24   ///  r1 = r1.wrapping_mul(24 as u64)
    mov64 r2, r7                                    r2 = r7
    add64 r2, r1                                    r2 += r1   ///  r2 = r2.wrapping_add(r1)
    ldxw r3, [r10-0x138]                    
    ldxdw r4, [r10-0x140]                   
    ldxdw r5, [r2+0x8]                      
    ldxdw r0, [r2+0x10]                     
    mul64 r0, 12                                    r0 *= 12   ///  r0 = r0.wrapping_mul(12 as u64)
lbb_12369:
    jeq r0, 0, lbb_12384                            if r0 == (0 as i32 as i64 as u64) { pc += 14 }
    ldxdw r7, [r5+0x0]                      
    xor64 r7, r4                                    r7 ^= r4   ///  r7 = r7.xor(r4)
    ldxw r1, [r5+0x8]                       
    xor64 r1, r3                                    r1 ^= r3   ///  r1 = r1.xor(r3)
    lsh64 r1, 32                                    r1 <<= 32   ///  r1 = r1.wrapping_shl(32)
    rsh64 r1, 32                                    r1 >>= 32   ///  r1 = r1.wrapping_shr(32)
    or64 r7, r1                                     r7 |= r1   ///  r7 = r7.or(r1)
    lddw r2, 0x8000000000000000                     r2 load str located at -9223372036854775808
    mov64 r1, 255                                   r1 = 255 as i32 as i64 as u64
    add64 r0, -12                                   r0 += -12   ///  r0 = r0.wrapping_add(-12 as i32 as i64 as u64)
    add64 r5, 12                                    r5 += 12   ///  r5 = r5.wrapping_add(12 as i32 as i64 as u64)
    jeq r7, 0, lbb_12589                            if r7 == (0 as i32 as i64 as u64) { pc += 206 }
    ja lbb_12369                                    if true { pc += -15 }
lbb_12384:
    mov64 r1, r10                                   r1 = r10
    add64 r1, -240                                  r1 += -240   ///  r1 = r1.wrapping_add(-240 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -320                                  r2 += -320   ///  r2 = r2.wrapping_add(-320 as i32 as i64 as u64)
    mov64 r3, 12                                    r3 = 12 as i32 as i64 as u64
    call function_19860                     
    ldxdw r2, [r10-0xe8]                    
    be64 r2                                         r2 = match 64 { 16 => (r2 as u16).swap_bytes() as u64, 32 => (r2 as u32).swap_bytes() as u64, 64 => r2.swap_bytes(), _ => r2 }
    ldxdw r3, [r10-0xf0]                    
    be64 r3                                         r3 = match 64 { 16 => (r3 as u16).swap_bytes() as u64, 32 => (r3 as u32).swap_bytes() as u64, 64 => r3.swap_bytes(), _ => r3 }
    mov64 r1, r10                                   r1 = r10
    add64 r1, -464                                  r1 += -464   ///  r1 = r1.wrapping_add(-464 as i32 as i64 as u64)
    ldxdw r7, [r10-0x1e8]                   
    mov64 r4, r7                                    r4 = r7
    mov64 r5, 0                                     r5 = 0 as i32 as i64 as u64
    call function_31706                     
    ldxdw r1, [r10-0x1d0]                   
    jgt r7, r1, lbb_12406                           if r7 > r1 { pc += 4 }
lbb_12402:
    ldxdw r2, [r10-0x1e8]                   
    lddw r3, 0x100041390 --> b"\x00\x00\x00\x00p\xe7\x03\x00\x10\x00\x00\x00\x00\x00\x00\x00:\x00\x00\x0…        r3 load str located at 4295234448
    call function_25832                     
lbb_12406:
    mul64 r1, 24                                    r1 *= 24   ///  r1 = r1.wrapping_mul(24 as u64)
    ldxdw r2, [r10-0x1f0]                   
    add64 r2, r1                                    r2 += r1   ///  r2 = r2.wrapping_add(r1)
    ldxw r3, [r10-0x138]                    
    ldxdw r4, [r10-0x140]                   
    ldxdw r5, [r2+0x8]                      
    ldxdw r0, [r2+0x10]                     
    mul64 r0, 12                                    r0 *= 12   ///  r0 = r0.wrapping_mul(12 as u64)
lbb_12414:
    jeq r0, 0, lbb_12429                            if r0 == (0 as i32 as i64 as u64) { pc += 14 }
    ldxdw r7, [r5+0x0]                      
    xor64 r7, r4                                    r7 ^= r4   ///  r7 = r7.xor(r4)
    ldxw r1, [r5+0x8]                       
    xor64 r1, r3                                    r1 ^= r3   ///  r1 = r1.xor(r3)
    lsh64 r1, 32                                    r1 <<= 32   ///  r1 = r1.wrapping_shl(32)
    rsh64 r1, 32                                    r1 >>= 32   ///  r1 = r1.wrapping_shr(32)
    or64 r7, r1                                     r7 |= r1   ///  r7 = r7.or(r1)
    lddw r2, 0x800000000000001a                     r2 load str located at -9223372036854775782
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    add64 r0, -12                                   r0 += -12   ///  r0 = r0.wrapping_add(-12 as i32 as i64 as u64)
    add64 r5, 12                                    r5 += 12   ///  r5 = r5.wrapping_add(12 as i32 as i64 as u64)
    jeq r7, 0, lbb_12589                            if r7 == (0 as i32 as i64 as u64) { pc += 161 }
    ja lbb_12414                                    if true { pc += -15 }
lbb_12429:
    ldxdw r5, [r10-0x230]                   
    ldxdw r7, [r10-0x1f8]                   
    jeq r9, r8, lbb_12433                           if r9 == r8 { pc += 1 }
    ja lbb_12336                                    if true { pc += -97 }
lbb_12433:
    ldxb r2, [r10-0x146]                    
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    jeq r2, 0, lbb_12437                            if r2 == (0 as i32 as i64 as u64) { pc += 1 }
    ja lbb_12593                                    if true { pc += 156 }
lbb_12437:
    ldxb r2, [r10-0x145]                    
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    jeq r2, 0, lbb_12593                            if r2 == (0 as i32 as i64 as u64) { pc += 153 }
    ldxdw r1, [r10-0x208]                   
    ldxb r1, [r1+0x218]                     
    jeq r1, 0, lbb_12446                            if r1 == (0 as i32 as i64 as u64) { pc += 3 }
    ldxdw r2, [r10-0x150]                   
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    jgt r2, 1, lbb_12593                            if r2 > (1 as i32 as i64 as u64) { pc += 147 }
lbb_12446:
    ldxb r1, [r10-0x148]                    
    jeq r1, 2, lbb_12462                            if r1 == (2 as i32 as i64 as u64) { pc += 14 }
    jne r1, 0, lbb_12454                            if r1 != (0 as i32 as i64 as u64) { pc += 5 }
    ldxdw r1, [r10-0x208]                   
    ldxb r1, [r1+0x219]                     
    mov64 r2, r1                                    r2 = r1
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    jne r2, 0, lbb_12593                            if r2 != (0 as i32 as i64 as u64) { pc += 139 }
lbb_12454:
    ldxb r2, [r10-0x147]                    
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    jne r2, 0, lbb_12593                            if r2 != (0 as i32 as i64 as u64) { pc += 136 }
    ldxdw r1, [r10-0x208]                   
    ldxb r2, [r1+0x21a]                     
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    jeq r2, 0, lbb_12462                            if r2 == (0 as i32 as i64 as u64) { pc += 1 }
    ja lbb_12593                                    if true { pc += 131 }
lbb_12462:
    ldxdw r1, [r10-0x208]                   
    ldxb r1, [r1+0x216]                     
    jeq r1, 0, lbb_12470                            if r1 == (0 as i32 as i64 as u64) { pc += 5 }
    ldxb r1, [r10-0x144]                    
    mov64 r2, r1                                    r2 = r1
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    jeq r2, 0, lbb_12470                            if r2 == (0 as i32 as i64 as u64) { pc += 1 }
    ja lbb_12593                                    if true { pc += 123 }
lbb_12470:
    ldxdw r1, [r10-0x208]                   
    ldxb r2, [r1+0x217]                     
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    jeq r2, 0, lbb_12593                            if r2 == (0 as i32 as i64 as u64) { pc += 119 }
    ldxb r1, [r10-0x143]                    
    mov64 r2, r1                                    r2 = r1
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    jeq r2, 0, lbb_12593                            if r2 == (0 as i32 as i64 as u64) { pc += 115 }
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    ja lbb_12593                                    if true { pc += 113 }
lbb_12480:
    mov64 r3, r2                                    r3 = r2
    add64 r3, -1                                    r3 += -1   ///  r3 = r3.wrapping_add(-1 as i32 as i64 as u64)
    mov64 r4, 7                                     r4 = 7 as i32 as i64 as u64
    jgt r4, r3, lbb_11225                           if r4 > r3 { pc += -1259 }
    jeq r2, 0, lbb_12486                            if r2 == (0 as i32 as i64 as u64) { pc += 1 }
    ja lbb_11225                                    if true { pc += -1261 }
lbb_12486:
    ldxdw r2, [r1+0x8]                      
    mov64 r1, r2                                    r1 = r2
    and64 r1, 3                                     r1 &= 3   ///  r1 = r1.and(3)
    mov64 r3, r1                                    r3 = r1
    add64 r3, -2                                    r3 += -2   ///  r3 = r3.wrapping_add(-2 as i32 as i64 as u64)
    mov64 r4, 2                                     r4 = 2 as i32 as i64 as u64
    jgt r4, r3, lbb_11225                           if r4 > r3 { pc += -1268 }
    jeq r1, 0, lbb_11225                            if r1 == (0 as i32 as i64 as u64) { pc += -1269 }
    ldxdw r1, [r2-0x1]                      
    ldxdw r2, [r2+0x7]                      
    ldxdw r2, [r2+0x0]                      
    callx r2                                
    ja lbb_11225                                    if true { pc += -1274 }
lbb_12499:
    ldxw r1, [r8+0x0]                       
    ldxw r2, [r8+0xe]                       
    ldxw r3, [r8+0x1c]                      
    stxw [r10-0x138], r3                    
    stxw [r10-0x13c], r2                    
    stxw [r10-0x140], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -240                                  r1 += -240   ///  r1 = r1.wrapping_add(-240 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -320                                  r2 += -320   ///  r2 = r2.wrapping_add(-320 as i32 as i64 as u64)
    mov64 r3, 12                                    r3 = 12 as i32 as i64 as u64
    call function_19860                     
    ldxdw r2, [r10-0xe8]                    
    be64 r2                                         r2 = match 64 { 16 => (r2 as u16).swap_bytes() as u64, 32 => (r2 as u32).swap_bytes() as u64, 64 => r2.swap_bytes(), _ => r2 }
    ldxdw r3, [r10-0xf0]                    
    be64 r3                                         r3 = match 64 { 16 => (r3 as u16).swap_bytes() as u64, 32 => (r3 as u32).swap_bytes() as u64, 64 => r3.swap_bytes(), _ => r3 }
    mov64 r1, r10                                   r1 = r10
    add64 r1, -432                                  r1 += -432   ///  r1 = r1.wrapping_add(-432 as i32 as i64 as u64)
    mov64 r4, r6                                    r4 = r6
    mov64 r5, 0                                     r5 = 0 as i32 as i64 as u64
    call function_31706                     
    ldxdw r1, [r10-0x1b0]                   
    jge r1, r6, lbb_12615                           if r1 >= r6 { pc += 93 }
    mul64 r1, 24                                    r1 *= 24   ///  r1 = r1.wrapping_mul(24 as u64)
    add64 r7, r1                                    r7 += r1   ///  r7 = r7.wrapping_add(r1)
    ldxw r3, [r10-0x138]                    
    ldxdw r4, [r10-0x140]                   
    ldxdw r5, [r7+0x8]                      
    ldxdw r0, [r7+0x10]                     
    mul64 r0, 12                                    r0 *= 12   ///  r0 = r0.wrapping_mul(12 as u64)
    lddw r2, 0x8000000000000000                     r2 load str located at -9223372036854775808
lbb_12531:
    jeq r0, 0, lbb_12317                            if r0 == (0 as i32 as i64 as u64) { pc += -215 }
    ldxdw r6, [r5+0x0]                      
    xor64 r6, r4                                    r6 ^= r4   ///  r6 = r6.xor(r4)
    ldxw r1, [r5+0x8]                       
    xor64 r1, r3                                    r1 ^= r3   ///  r1 = r1.xor(r3)
    lsh64 r1, 32                                    r1 <<= 32   ///  r1 = r1.wrapping_shl(32)
    rsh64 r1, 32                                    r1 >>= 32   ///  r1 = r1.wrapping_shr(32)
    or64 r6, r1                                     r6 |= r1   ///  r6 = r6.or(r1)
    mov64 r1, 255                                   r1 = 255 as i32 as i64 as u64
    add64 r0, -12                                   r0 += -12   ///  r0 = r0.wrapping_add(-12 as i32 as i64 as u64)
    add64 r5, 12                                    r5 += 12   ///  r5 = r5.wrapping_add(12 as i32 as i64 as u64)
    jeq r6, 0, lbb_12589                            if r6 == (0 as i32 as i64 as u64) { pc += 46 }
    ja lbb_12531                                    if true { pc += -13 }
lbb_12544:
    ldxw r1, [r9+0x0]                       
    ldxw r2, [r9+0xe]                       
    ldxw r3, [r9+0x1c]                      
    stxw [r10-0x138], r3                    
    stxw [r10-0x13c], r2                    
    stxw [r10-0x140], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -240                                  r1 += -240   ///  r1 = r1.wrapping_add(-240 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -320                                  r2 += -320   ///  r2 = r2.wrapping_add(-320 as i32 as i64 as u64)
    mov64 r3, 12                                    r3 = 12 as i32 as i64 as u64
    call function_19860                     
    ldxdw r2, [r10-0xe8]                    
    be64 r2                                         r2 = match 64 { 16 => (r2 as u16).swap_bytes() as u64, 32 => (r2 as u32).swap_bytes() as u64, 64 => r2.swap_bytes(), _ => r2 }
    ldxdw r3, [r10-0xf0]                    
    be64 r3                                         r3 = match 64 { 16 => (r3 as u16).swap_bytes() as u64, 32 => (r3 as u32).swap_bytes() as u64, 64 => r3.swap_bytes(), _ => r3 }
    mov64 r1, r10                                   r1 = r10
    add64 r1, -480                                  r1 += -480   ///  r1 = r1.wrapping_add(-480 as i32 as i64 as u64)
    mov64 r4, r6                                    r4 = r6
    mov64 r5, 0                                     r5 = 0 as i32 as i64 as u64
    call function_31706                     
    ldxdw r1, [r10-0x1e0]                   
    jge r1, r6, lbb_12615                           if r1 >= r6 { pc += 48 }
    mul64 r1, 24                                    r1 *= 24   ///  r1 = r1.wrapping_mul(24 as u64)
    add64 r7, r1                                    r7 += r1   ///  r7 = r7.wrapping_add(r1)
    ldxw r3, [r10-0x138]                    
    ldxdw r4, [r10-0x140]                   
    ldxdw r5, [r7+0x8]                      
    ldxdw r0, [r7+0x10]                     
    mul64 r0, 12                                    r0 *= 12   ///  r0 = r0.wrapping_mul(12 as u64)
    lddw r2, 0x8000000000000000                     r2 load str located at -9223372036854775808
lbb_12576:
    jeq r0, 0, lbb_12317                            if r0 == (0 as i32 as i64 as u64) { pc += -260 }
    ldxdw r6, [r5+0x0]                      
    xor64 r6, r4                                    r6 ^= r4   ///  r6 = r6.xor(r4)
    ldxw r1, [r5+0x8]                       
    xor64 r1, r3                                    r1 ^= r3   ///  r1 = r1.xor(r3)
    lsh64 r1, 32                                    r1 <<= 32   ///  r1 = r1.wrapping_shl(32)
    rsh64 r1, 32                                    r1 >>= 32   ///  r1 = r1.wrapping_shr(32)
    or64 r6, r1                                     r6 |= r1   ///  r6 = r6.or(r1)
    mov64 r1, 255                                   r1 = 255 as i32 as i64 as u64
    add64 r0, -12                                   r0 += -12   ///  r0 = r0.wrapping_add(-12 as i32 as i64 as u64)
    add64 r5, 12                                    r5 += 12   ///  r5 = r5.wrapping_add(12 as i32 as i64 as u64)
    jeq r6, 0, lbb_12589                            if r6 == (0 as i32 as i64 as u64) { pc += 1 }
    ja lbb_12576                                    if true { pc += -13 }
lbb_12589:
    lddw r3, 0x800000000000001a                     r3 load str located at -9223372036854775782
    ldxdw r5, [r10-0x230]                   
    jne r2, r3, lbb_12608                           if r2 != r3 { pc += 15 }
lbb_12593:
    mov64 r2, 1                                     r2 = 1 as i32 as i64 as u64
    ldxb r4, [r10-0x147]                    
    mov64 r3, 1                                     r3 = 1 as i32 as i64 as u64
    jne r4, 0, lbb_12598                            if r4 != (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
lbb_12598:
    ldxb r4, [r10-0x148]                    
    jne r4, 2, lbb_12601                            if r4 != (2 as i32 as i64 as u64) { pc += 1 }
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
lbb_12601:
    stxb [r5+0x8], r1                       
    lddw r1, 0x800000000000001a                     r1 load str located at -9223372036854775782
    stxdw [r5+0x0], r1                      
    and64 r2, r3                                    r2 &= r3   ///  r2 = r2.and(r3)
    stxb [r5+0x9], r2                       
    ja lbb_12614                                    if true { pc += 6 }
lbb_12608:
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
    stxb [r5+0xb], r3                       
    mov64 r3, 255                                   r3 = 255 as i32 as i64 as u64
    stxh [r5+0x9], r3                       
    stxb [r5+0x8], r1                       
    stxdw [r5+0x0], r2                      
lbb_12614:
    exit                                    
lbb_12615:
    mov64 r2, r6                                    r2 = r6
    lddw r3, 0x100041390 --> b"\x00\x00\x00\x00p\xe7\x03\x00\x10\x00\x00\x00\x00\x00\x00\x00:\x00\x00\x0…        r3 load str located at 4295234448
    call function_25832                     

function_12619:
    mov64 r6, r1                                    r6 = r1
    ldxdw r1, [r2+0x8]                      
    mov64 r4, 32                                    r4 = 32 as i32 as i64 as u64
    jgt r4, r1, lbb_12803                           if r4 > r1 { pc += 180 }
    mov64 r0, r1                                    r0 = r1
    add64 r0, -32                                   r0 += -32   ///  r0 = r0.wrapping_add(-32 as i32 as i64 as u64)
    stxdw [r2+0x8], r0                      
    ldxdw r3, [r2+0x0]                      
    mov64 r5, r3                                    r5 = r3
    add64 r5, 32                                    r5 += 32   ///  r5 = r5.wrapping_add(32 as i32 as i64 as u64)
    stxdw [r2+0x0], r5                      
    ldxdw r8, [r3+0x6]                      
    ldxb r7, [r3+0xe]                       
    stxb [r10-0x148], r7                    
    ldxw r7, [r3+0x0]                       
    stxw [r10-0x310], r7                    
    ldxh r7, [r3+0x4]                       
    stxh [r10-0x30c], r7                    
    stxdw [r10-0x150], r8                   
    ldxdw r9, [r10-0x14f]                   
    ldxdw r7, [r3+0xf]                      
    stxdw [r10-0x328], r7                   
    ldxdw r7, [r3+0x17]                     
    stxdw [r10-0x320], r7                   
    ldxb r7, [r3+0x1f]                      
    stxb [r10-0x318], r7                    
    jgt r4, r0, lbb_12803                           if r4 > r0 { pc += 157 }
    stxdw [r10-0x338], r9                   
    mov64 r0, r1                                    r0 = r1
    add64 r0, -64                                   r0 += -64   ///  r0 = r0.wrapping_add(-64 as i32 as i64 as u64)
    stxdw [r2+0x8], r0                      
    mov64 r4, r3                                    r4 = r3
    add64 r4, 64                                    r4 += 64   ///  r4 = r4.wrapping_add(64 as i32 as i64 as u64)
    stxdw [r2+0x0], r4                      
    ldxdw r7, [r3+0x26]                     
    ldxb r9, [r3+0x2e]                      
    stxb [r10-0x148], r9                    
    ldxw r9, [r5+0x0]                       
    stxw [r10-0x2f0], r9                    
    ldxh r5, [r5+0x4]                       
    stxh [r10-0x2ec], r5                    
    stxdw [r10-0x150], r7                   
    ldxdw r9, [r10-0x14f]                   
    ldxdw r5, [r3+0x2f]                     
    stxdw [r10-0x308], r5                   
    ldxdw r5, [r3+0x37]                     
    stxdw [r10-0x300], r5                   
    ldxb r5, [r3+0x3f]                      
    stxb [r10-0x2f8], r5                    
    mov64 r5, 32                                    r5 = 32 as i32 as i64 as u64
    jgt r5, r0, lbb_12803                           if r5 > r0 { pc += 133 }
    stxdw [r10-0x348], r9                   
    mov64 r5, r3                                    r5 = r3
    add64 r5, 96                                    r5 += 96   ///  r5 = r5.wrapping_add(96 as i32 as i64 as u64)
    stxdw [r2+0x0], r5                      
    mov64 r5, r1                                    r5 = r1
    add64 r5, -96                                   r5 += -96   ///  r5 = r5.wrapping_add(-96 as i32 as i64 as u64)
    stxdw [r2+0x8], r5                      
    ldxdw r9, [r3+0x46]                     
    ldxb r0, [r3+0x4e]                      
    stxb [r10-0x148], r0                    
    ldxw r0, [r4+0x0]                       
    stxw [r10-0x2d0], r0                    
    ldxh r4, [r4+0x4]                       
    stxh [r10-0x2cc], r4                    
    stxdw [r10-0x340], r9                   
    stxdw [r10-0x150], r9                   
    ldxdw r9, [r10-0x14f]                   
    ldxdw r4, [r3+0x4f]                     
    stxdw [r10-0x2e8], r4                   
    ldxdw r4, [r3+0x57]                     
    stxdw [r10-0x2e0], r4                   
    ldxb r4, [r3+0x5f]                      
    stxb [r10-0x2d8], r4                    
    jeq r5, 0, lbb_12803                            if r5 == (0 as i32 as i64 as u64) { pc += 109 }
    ldxb r0, [r3+0x60]                      
    mov64 r4, r3                                    r4 = r3
    add64 r4, 97                                    r4 += 97   ///  r4 = r4.wrapping_add(97 as i32 as i64 as u64)
    stxdw [r2+0x0], r4                      
    mov64 r4, r1                                    r4 = r1
    add64 r4, -97                                   r4 += -97   ///  r4 = r4.wrapping_add(-97 as i32 as i64 as u64)
    stxdw [r2+0x8], r4                      
    stxb [r10-0x1], r0                      
    mov64 r5, 2                                     r5 = 2 as i32 as i64 as u64
    jgt r5, r0, lbb_12730                           if r5 > r0 { pc += 26 }
lbb_12704:
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    stxdw [r10-0x130], r1                   
    lddw r1, 0x100040e18 --> b"\x00\x00\x00\x00]\xe6\x03\x00\x1d\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00…        r1 load str located at 4295233048
    stxdw [r10-0x150], r1                   
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    stxdw [r10-0x148], r1                   
    stxdw [r10-0x138], r1                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -712                                  r1 += -712   ///  r1 = r1.wrapping_add(-712 as i32 as i64 as u64)
    stxdw [r10-0x140], r1                   
    lddw r1, 0x10003b0c8 --> b"\xbf#\x00\x00\x00\x00\x00\x00q\x11\x00\x00\x00\x00\x00\x00\xb7\x02\x00\x0…        r1 load str located at 4295209160
    stxdw [r10-0x2c0], r1                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -1                                    r1 += -1   ///  r1 = r1.wrapping_add(-1 as i32 as i64 as u64)
    stxdw [r10-0x2c8], r1                   
    mov64 r7, r10                                   r7 = r10
    add64 r7, -648                                  r7 += -648   ///  r7 = r7.wrapping_add(-648 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -336                                  r2 += -336   ///  r2 = r2.wrapping_add(-336 as i32 as i64 as u64)
    mov64 r1, r7                                    r1 = r7
    call function_21571                     
    mov64 r1, r7                                    r1 = r7
    call function_323                       
    ja lbb_12806                                    if true { pc += 76 }
lbb_12730:
    jeq r4, 0, lbb_12803                            if r4 == (0 as i32 as i64 as u64) { pc += 72 }
    stxdw [r10-0x358], r9                   
    ldxb r9, [r3+0x61]                      
    mov64 r4, r3                                    r4 = r3
    add64 r4, 98                                    r4 += 98   ///  r4 = r4.wrapping_add(98 as i32 as i64 as u64)
    stxdw [r2+0x0], r4                      
    mov64 r4, r1                                    r4 = r1
    add64 r4, -98                                   r4 += -98   ///  r4 = r4.wrapping_add(-98 as i32 as i64 as u64)
    stxdw [r2+0x8], r4                      
    stxb [r10-0x1], r9                      
    stxdw [r10-0x350], r9                   
    jgt r5, r9, lbb_12743                           if r5 > r9 { pc += 1 }
    ja lbb_12704                                    if true { pc += -39 }
lbb_12743:
    jeq r4, 0, lbb_12803                            if r4 == (0 as i32 as i64 as u64) { pc += 59 }
    ldxb r9, [r3+0x62]                      
    mov64 r4, r3                                    r4 = r3
    add64 r4, 99                                    r4 += 99   ///  r4 = r4.wrapping_add(99 as i32 as i64 as u64)
    stxdw [r2+0x0], r4                      
    mov64 r4, r1                                    r4 = r1
    add64 r4, -99                                   r4 += -99   ///  r4 = r4.wrapping_add(-99 as i32 as i64 as u64)
    stxdw [r2+0x8], r4                      
    stxb [r10-0x1], r9                      
    jgt r5, r9, lbb_12754                           if r5 > r9 { pc += 1 }
    ja lbb_12704                                    if true { pc += -50 }
lbb_12754:
    jeq r4, 0, lbb_12803                            if r4 == (0 as i32 as i64 as u64) { pc += 48 }
    stxdw [r10-0x368], r9                   
    ldxb r9, [r3+0x63]                      
    mov64 r4, r3                                    r4 = r3
    add64 r4, 100                                   r4 += 100   ///  r4 = r4.wrapping_add(100 as i32 as i64 as u64)
    stxdw [r2+0x0], r4                      
    mov64 r4, r1                                    r4 = r1
    add64 r4, -100                                  r4 += -100   ///  r4 = r4.wrapping_add(-100 as i32 as i64 as u64)
    stxdw [r2+0x8], r4                      
    stxb [r10-0x1], r9                      
    stxdw [r10-0x360], r9                   
    jgt r5, r9, lbb_12767                           if r5 > r9 { pc += 1 }
    ja lbb_12704                                    if true { pc += -63 }
lbb_12767:
    jeq r4, 0, lbb_12803                            if r4 == (0 as i32 as i64 as u64) { pc += 35 }
    ldxb r9, [r3+0x64]                      
    mov64 r4, r3                                    r4 = r3
    add64 r4, 101                                   r4 += 101   ///  r4 = r4.wrapping_add(101 as i32 as i64 as u64)
    stxdw [r2+0x0], r4                      
    mov64 r4, r1                                    r4 = r1
    add64 r4, -101                                  r4 += -101   ///  r4 = r4.wrapping_add(-101 as i32 as i64 as u64)
    stxdw [r2+0x8], r4                      
    stxb [r10-0x1], r9                      
    jgt r5, r9, lbb_12778                           if r5 > r9 { pc += 1 }
    ja lbb_12704                                    if true { pc += -74 }
lbb_12778:
    jeq r4, 0, lbb_12803                            if r4 == (0 as i32 as i64 as u64) { pc += 24 }
    stxdw [r10-0x378], r9                   
    ldxb r9, [r3+0x65]                      
    mov64 r4, r3                                    r4 = r3
    add64 r4, 102                                   r4 += 102   ///  r4 = r4.wrapping_add(102 as i32 as i64 as u64)
    stxdw [r2+0x0], r4                      
    mov64 r4, r1                                    r4 = r1
    add64 r4, -102                                  r4 += -102   ///  r4 = r4.wrapping_add(-102 as i32 as i64 as u64)
    stxdw [r2+0x8], r4                      
    stxb [r10-0x1], r9                      
    stxdw [r10-0x370], r9                   
    jgt r5, r9, lbb_12791                           if r5 > r9 { pc += 1 }
    ja lbb_12704                                    if true { pc += -87 }
lbb_12791:
    stxdw [r10-0x388], r0                   
    jeq r4, 0, lbb_12803                            if r4 == (0 as i32 as i64 as u64) { pc += 10 }
    add64 r1, -103                                  r1 += -103   ///  r1 = r1.wrapping_add(-103 as i32 as i64 as u64)
    ldxb r9, [r3+0x66]                      
    stxdw [r2+0x8], r1                      
    add64 r3, 103                                   r3 += 103   ///  r3 = r3.wrapping_add(103 as i32 as i64 as u64)
    stxdw [r10-0x380], r2                   
    stxdw [r2+0x0], r3                      
    stxb [r10-0x1], r9                      
    mov64 r1, 2                                     r1 = 2 as i32 as i64 as u64
    jgt r1, r9, lbb_12811                           if r1 > r9 { pc += 9 }
    ja lbb_12704                                    if true { pc += -99 }
lbb_12803:
    lddw r1, 0x100040d80 --> b"\x00\x00\x00\x00\x99\xe5\x03\x00\x1b\x00\x00\x00\x00\x00\x00\x00%\x00\x00…        r1 load str located at 4295232896
    call function_20446                     
lbb_12806:
    lddw r1, 0x8000000000000000                     r1 load str located at -9223372036854775808
    stxdw [r6+0x0], r1                      
    stxdw [r6+0x8], r0                      
lbb_12810:
    exit                                    
lbb_12811:
    mov64 r1, r10                                   r1 = r10
    add64 r1, -336                                  r1 += -336   ///  r1 = r1.wrapping_add(-336 as i32 as i64 as u64)
    ldxdw r2, [r10-0x380]                   
    call function_1959                      
    ldxb r1, [r10-0x150]                    
    jeq r1, 0, lbb_12823                            if r1 == (0 as i32 as i64 as u64) { pc += 6 }
lbb_12817:
    ldxdw r1, [r10-0x148]                   
    lddw r2, 0x8000000000000000                     r2 load str located at -9223372036854775808
    stxdw [r6+0x0], r2                      
lbb_12821:
    stxdw [r6+0x8], r1                      
    ja lbb_12810                                    if true { pc += -13 }
lbb_12823:
    ldxw r1, [r10-0x14c]                    
    stxw [r10-0x28d], r1                    
    ldxw r1, [r10-0x14f]                    
    stxw [r10-0x290], r1                    
    ldxdw r1, [r10-0x148]                   
    stxdw [r10-0x390], r1                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -712                                  r1 += -712   ///  r1 = r1.wrapping_add(-712 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -320                                  r2 += -320   ///  r2 = r2.wrapping_add(-320 as i32 as i64 as u64)
    mov64 r3, 49                                    r3 = 49 as i32 as i64 as u64
    call function_30349                     
    ldxdw r1, [r10-0x380]                   
    ldxdw r1, [r1+0x8]                      
    mov64 r2, 2                                     r2 = 2 as i32 as i64 as u64
    jgt r2, r1, lbb_12892                           if r2 > r1 { pc += 53 }
    ldxdw r4, [r10-0x380]                   
    ldxdw r3, [r4+0x0]                      
    ldxh r5, [r3+0x0]                       
    stxdw [r10-0x398], r5                   
    mov64 r5, r3                                    r5 = r3
    add64 r5, 2                                     r5 += 2   ///  r5 = r5.wrapping_add(2 as i32 as i64 as u64)
    stxdw [r4+0x0], r5                      
    mov64 r5, r1                                    r5 = r1
    add64 r5, -2                                    r5 += -2   ///  r5 = r5.wrapping_add(-2 as i32 as i64 as u64)
    stxdw [r4+0x8], r5                      
    jgt r2, r5, lbb_12892                           if r2 > r5 { pc += 42 }
    add64 r1, -4                                    r1 += -4   ///  r1 = r1.wrapping_add(-4 as i32 as i64 as u64)
    ldxh r2, [r3+0x2]                       
    stxdw [r10-0x3a0], r2                   
    ldxdw r2, [r10-0x380]                   
    stxdw [r2+0x8], r1                      
    add64 r3, 4                                     r3 += 4   ///  r3 = r3.wrapping_add(4 as i32 as i64 as u64)
    stxdw [r2+0x0], r3                      
    mov64 r1, r10                                   r1 = r10
    add64 r1, -336                                  r1 += -336   ///  r1 = r1.wrapping_add(-336 as i32 as i64 as u64)
    call function_1592                      
    ldxb r1, [r10-0x150]                    
    jeq r1, 0, lbb_12863                            if r1 == (0 as i32 as i64 as u64) { pc += 1 }
    ja lbb_12817                                    if true { pc += -46 }
lbb_12863:
    ldxw r1, [r10-0x14c]                    
    stxw [r10-0x5], r1                      
    ldxw r1, [r10-0x14f]                    
    stxw [r10-0x8], r1                      
    ldxdw r1, [r10-0x148]                   
    stxdw [r10-0x3b0], r1                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -648                                  r1 += -648   ///  r1 = r1.wrapping_add(-648 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -320                                  r2 += -320   ///  r2 = r2.wrapping_add(-320 as i32 as i64 as u64)
    mov64 r3, 305                                   r3 = 305 as i32 as i64 as u64
    call function_30349                     
    mov64 r1, r10                                   r1 = r10
    add64 r1, -336                                  r1 += -336   ///  r1 = r1.wrapping_add(-336 as i32 as i64 as u64)
    ldxdw r2, [r10-0x380]                   
    call function_13316                     
    ldxdw r1, [r10-0x148]                   
    stxdw [r10-0x3a8], r1                   
    ldxdw r1, [r10-0x150]                   
    lddw r2, 0x8000000000000000                     r2 load str located at -9223372036854775808
    stxdw [r10-0x3b8], r1                   
    jeq r1, r2, lbb_12887                           if r1 == r2 { pc += 1 }
    ja lbb_12900                                    if true { pc += 13 }
lbb_12887:
    lddw r1, 0x8000000000000000                     r1 load str located at -9223372036854775808
    stxdw [r6+0x0], r1                      
    ldxdw r1, [r10-0x3a8]                   
    ja lbb_12821                                    if true { pc += -71 }
lbb_12892:
    lddw r1, 0x100040d80 --> b"\x00\x00\x00\x00\x99\xe5\x03\x00\x1b\x00\x00\x00\x00\x00\x00\x00%\x00\x00…        r1 load str located at 4295232896
    call function_20446                     
    stxdw [r6+0x8], r0                      
    lddw r1, 0x8000000000000000                     r1 load str located at -9223372036854775808
    stxdw [r6+0x0], r1                      
    ja lbb_12810                                    if true { pc += -90 }
lbb_12900:
    ldxdw r1, [r10-0x140]                   
    stxdw [r10-0x3c0], r1                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -336                                  r1 += -336   ///  r1 = r1.wrapping_add(-336 as i32 as i64 as u64)
    ldxdw r2, [r10-0x380]                   
    call function_13316                     
    ldxdw r1, [r10-0x148]                   
    stxdw [r10-0x380], r1                   
    ldxdw r1, [r10-0x150]                   
    stxdw [r10-0x3c8], r1                   
    lddw r2, 0x8000000000000000                     r2 load str located at -9223372036854775808
    jeq r1, r2, lbb_12914                           if r1 == r2 { pc += 1 }
    ja lbb_12919                                    if true { pc += 5 }
lbb_12914:
    lddw r1, 0x8000000000000000                     r1 load str located at -9223372036854775808
    stxdw [r6+0x0], r1                      
    ldxdw r1, [r10-0x380]                   
    ja lbb_12821                                    if true { pc += -98 }
lbb_12919:
    ldxdw r1, [r10-0x140]                   
    stxdw [r10-0x3d0], r1                   
    ldxh r1, [r10-0x30c]                    
    stxh [r6+0x34], r1                      
    ldxw r1, [r10-0x310]                    
    stxw [r6+0x30], r1                      
    ldxb r1, [r10-0x318]                    
    stxb [r6+0x4f], r1                      
    ldxdw r1, [r10-0x320]                   
    stxdw [r6+0x47], r1                     
    ldxdw r1, [r10-0x328]                   
    stxdw [r6+0x3f], r1                     
    ldxh r1, [r10-0x2ec]                    
    stxh [r6+0x54], r1                      
    ldxw r1, [r10-0x2f0]                    
    stxw [r6+0x50], r1                      
    ldxb r1, [r10-0x2f8]                    
    stxb [r6+0x6f], r1                      
    ldxdw r1, [r10-0x300]                   
    stxdw [r6+0x67], r1                     
    ldxdw r1, [r10-0x308]                   
    stxdw [r6+0x5f], r1                     
    ldxw r1, [r10-0x2d0]                    
    stxw [r6+0x70], r1                      
    ldxh r1, [r10-0x2cc]                    
    stxh [r6+0x74], r1                      
    ldxdw r1, [r10-0x2e8]                   
    stxdw [r6+0x7f], r1                     
    ldxdw r1, [r10-0x2e0]                   
    stxdw [r6+0x87], r1                     
    ldxb r1, [r10-0x2d8]                    
    stxb [r6+0x8f], r1                      
    ldxw r1, [r10-0x290]                    
    stxw [r6+0x90], r1                      
    ldxw r1, [r10-0x28d]                    
    stxw [r6+0x93], r1                      
    mov64 r1, r6                                    r1 = r6
    add64 r1, 159                                   r1 += 159   ///  r1 = r1.wrapping_add(159 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -712                                  r2 += -712   ///  r2 = r2.wrapping_add(-712 as i32 as i64 as u64)
    mov64 r3, 49                                    r3 = 49 as i32 as i64 as u64
    call function_30349                     
    ldxw r1, [r10-0x8]                      
    stxw [r6+0xd0], r1                      
    ldxw r1, [r10-0x5]                      
    stxw [r6+0xd3], r1                      
    mov64 r1, r6                                    r1 = r6
    add64 r1, 223                                   r1 += 223   ///  r1 = r1.wrapping_add(223 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -648                                  r2 += -648   ///  r2 = r2.wrapping_add(-648 as i32 as i64 as u64)
    mov64 r3, 305                                   r3 = 305 as i32 as i64 as u64
    call function_30349                     
    stxb [r6+0x21a], r9                     
    ldxdw r1, [r10-0x370]                   
    stxb [r6+0x219], r1                     
    ldxdw r1, [r10-0x378]                   
    stxb [r6+0x218], r1                     
    ldxdw r1, [r10-0x360]                   
    stxb [r6+0x217], r1                     
    ldxdw r1, [r10-0x368]                   
    stxb [r6+0x216], r1                     
    ldxdw r1, [r10-0x350]                   
    stxb [r6+0x215], r1                     
    ldxdw r1, [r10-0x388]                   
    stxb [r6+0x214], r1                     
    ldxdw r1, [r10-0x3a0]                   
    stxh [r6+0x212], r1                     
    ldxdw r1, [r10-0x398]                   
    stxh [r6+0x210], r1                     
    ldxdw r1, [r10-0x3b0]                   
    stxdw [r6+0xd7], r1                     
    ldxdw r1, [r10-0x390]                   
    stxdw [r6+0x97], r1                     
    ldxdw r1, [r10-0x358]                   
    stxdw [r6+0x77], r1                     
    ldxdw r1, [r10-0x340]                   
    stxb [r6+0x76], r1                      
    ldxdw r1, [r10-0x348]                   
    stxdw [r6+0x57], r1                     
    stxb [r6+0x56], r7                      
    ldxdw r1, [r10-0x338]                   
    stxdw [r6+0x37], r1                     
    stxb [r6+0x36], r8                      
    ldxdw r1, [r10-0x3d0]                   
    stxdw [r6+0x28], r1                     
    ldxdw r1, [r10-0x380]                   
    stxdw [r6+0x20], r1                     
    ldxdw r1, [r10-0x3c8]                   
    stxdw [r6+0x18], r1                     
    ldxdw r1, [r10-0x3c0]                   
    stxdw [r6+0x10], r1                     
    ldxdw r1, [r10-0x3a8]                   
    stxdw [r6+0x8], r1                      
    ldxdw r1, [r10-0x3b8]                   
    stxdw [r6+0x0], r1                      
    ldxb r1, [r10-0x329]                    
    stxb [r6+0x21f], r1                     
    ldxw r1, [r10-0x32d]                    
    stxw [r6+0x21b], r1                     
    ja lbb_12810                                    if true { pc += -209 }

function_13019:
    ldxdw r8, [r2+0x0]                      
    stxdw [r10-0x10], r2                    
    ldxdw r6, [r2+0x8]                      
    stxdw [r10-0x18], r1                    
    mov64 r2, r1                                    r2 = r1
    add64 r2, 48                                    r2 += 48   ///  r2 = r2.wrapping_add(48 as i32 as i64 as u64)
    mov64 r1, 32                                    r1 = 32 as i32 as i64 as u64
    mov64 r9, r6                                    r9 = r6
    jgt r1, r6, lbb_13029                           if r1 > r6 { pc += 1 }
    mov64 r9, 32                                    r9 = 32 as i32 as i64 as u64
lbb_13029:
    mov64 r1, r8                                    r1 = r8
    mov64 r3, r9                                    r3 = r9
    call function_30349                     
    add64 r8, r9                                    r8 += r9   ///  r8 = r8.wrapping_add(r9)
    mov64 r7, r6                                    r7 = r6
    sub64 r7, r9                                    r7 -= r9   ///  r7 = r7.wrapping_sub(r9)
    ldxdw r1, [r10-0x10]                    
    stxdw [r1+0x8], r7                      
    stxdw [r1+0x0], r8                      
    lddw r0, 0x100040d98 --> b"\x00\x00\x00\x00\xb4\xe5\x03\x00\x1c\x00\x00\x00\x00\x00\x00\x00\x17\x00\…        r0 load str located at 4295232920
    mov64 r1, 32                                    r1 = 32 as i32 as i64 as u64
    jgt r1, r6, lbb_13204                           if r1 > r6 { pc += 162 }
    ldxdw r2, [r10-0x18]                    
    add64 r2, 80                                    r2 += 80   ///  r2 = r2.wrapping_add(80 as i32 as i64 as u64)
    mov64 r9, r7                                    r9 = r7
    jgt r1, r7, lbb_13047                           if r1 > r7 { pc += 1 }
    mov64 r9, 32                                    r9 = 32 as i32 as i64 as u64
lbb_13047:
    mov64 r1, r8                                    r1 = r8
    mov64 r3, r9                                    r3 = r9
    call function_30349                     
    add64 r8, r9                                    r8 += r9   ///  r8 = r8.wrapping_add(r9)
    mov64 r6, r7                                    r6 = r7
    sub64 r6, r9                                    r6 -= r9   ///  r6 = r6.wrapping_sub(r9)
    ldxdw r1, [r10-0x10]                    
    stxdw [r1+0x8], r6                      
    stxdw [r1+0x0], r8                      
    lddw r0, 0x100040d98 --> b"\x00\x00\x00\x00\xb4\xe5\x03\x00\x1c\x00\x00\x00\x00\x00\x00\x00\x17\x00\…        r0 load str located at 4295232920
    mov64 r1, 32                                    r1 = 32 as i32 as i64 as u64
    jgt r1, r7, lbb_13204                           if r1 > r7 { pc += 144 }
    ldxdw r2, [r10-0x18]                    
    add64 r2, 112                                   r2 += 112   ///  r2 = r2.wrapping_add(112 as i32 as i64 as u64)
    mov64 r7, 32                                    r7 = 32 as i32 as i64 as u64
    mov64 r9, r6                                    r9 = r6
    jgt r7, r6, lbb_13066                           if r7 > r6 { pc += 1 }
    mov64 r9, 32                                    r9 = 32 as i32 as i64 as u64
lbb_13066:
    mov64 r1, r8                                    r1 = r8
    mov64 r3, r9                                    r3 = r9
    call function_30349                     
    add64 r8, r9                                    r8 += r9   ///  r8 = r8.wrapping_add(r9)
    mov64 r2, r6                                    r2 = r6
    sub64 r2, r9                                    r2 -= r9   ///  r2 = r2.wrapping_sub(r9)
    ldxdw r1, [r10-0x10]                    
    stxdw [r1+0x8], r2                      
    stxdw [r1+0x0], r8                      
    lddw r0, 0x100040d98 --> b"\x00\x00\x00\x00\xb4\xe5\x03\x00\x1c\x00\x00\x00\x00\x00\x00\x00\x17\x00\…        r0 load str located at 4295232920
    jgt r7, r6, lbb_13204                           if r7 > r6 { pc += 126 }
    stxdw [r10-0x20], r2                    
    ldxdw r1, [r10-0x18]                    
    ldxb r1, [r1+0x214]                     
    stxb [r10-0x6], r1                      
    mov64 r9, 1                                     r9 = 1 as i32 as i64 as u64
    jne r6, 32, lbb_13085                           if r6 != (32 as i32 as i64 as u64) { pc += 1 }
    mov64 r9, 0                                     r9 = 0 as i32 as i64 as u64
lbb_13085:
    mov64 r2, r10                                   r2 = r10
    add64 r2, -6                                    r2 += -6   ///  r2 = r2.wrapping_add(-6 as i32 as i64 as u64)
    mov64 r1, r8                                    r1 = r8
    mov64 r3, r9                                    r3 = r9
    call function_30349                     
    ldxdw r2, [r10-0x20]                    
    mov64 r7, r2                                    r7 = r2
    sub64 r7, r9                                    r7 -= r9   ///  r7 = r7.wrapping_sub(r9)
    ldxdw r1, [r10-0x10]                    
    stxdw [r1+0x8], r7                      
    add64 r8, r9                                    r8 += r9   ///  r8 = r8.wrapping_add(r9)
    stxdw [r1+0x0], r8                      
    lddw r0, 0x100040d98 --> b"\x00\x00\x00\x00\xb4\xe5\x03\x00\x1c\x00\x00\x00\x00\x00\x00\x00\x17\x00\…        r0 load str located at 4295232920
    jeq r6, 32, lbb_13204                           if r6 == (32 as i32 as i64 as u64) { pc += 104 }
    ldxdw r1, [r10-0x18]                    
    ldxb r1, [r1+0x215]                     
    stxb [r10-0x5], r1                      
    mov64 r6, 1                                     r6 = 1 as i32 as i64 as u64
    jne r2, r9, lbb_13106                           if r2 != r9 { pc += 1 }
    mov64 r6, 0                                     r6 = 0 as i32 as i64 as u64
lbb_13106:
    mov64 r2, r10                                   r2 = r10
    add64 r2, -5                                    r2 += -5   ///  r2 = r2.wrapping_add(-5 as i32 as i64 as u64)
    mov64 r1, r8                                    r1 = r8
    mov64 r3, r6                                    r3 = r6
    call function_30349                     
    sub64 r7, r6                                    r7 -= r6   ///  r7 = r7.wrapping_sub(r6)
    ldxdw r2, [r10-0x10]                    
    stxdw [r2+0x8], r7                      
    add64 r8, r6                                    r8 += r6   ///  r8 = r8.wrapping_add(r6)
    stxdw [r2+0x0], r8                      
    lddw r0, 0x100040d98 --> b"\x00\x00\x00\x00\xb4\xe5\x03\x00\x1c\x00\x00\x00\x00\x00\x00\x00\x17\x00\…        r0 load str located at 4295232920
    ldxdw r1, [r10-0x20]                    
    jeq r1, r9, lbb_13204                           if r1 == r9 { pc += 84 }
    ldxdw r1, [r10-0x18]                    
    add64 r1, 534                                   r1 += 534   ///  r1 = r1.wrapping_add(534 as i32 as i64 as u64)
    call function_13205                     
    ldxdw r1, [r10-0x10]                    
    jne r0, 0, lbb_13204                            if r0 != (0 as i32 as i64 as u64) { pc += 79 }
    ldxdw r8, [r1+0x0]                      
    ldxdw r7, [r1+0x8]                      
    ldxdw r2, [r10-0x18]                    
    add64 r2, 144                                   r2 += 144   ///  r2 = r2.wrapping_add(144 as i32 as i64 as u64)
    mov64 r1, 64                                    r1 = 64 as i32 as i64 as u64
    mov64 r9, r7                                    r9 = r7
    jgt r1, r7, lbb_13133                           if r1 > r7 { pc += 1 }
    mov64 r9, 64                                    r9 = 64 as i32 as i64 as u64
lbb_13133:
    mov64 r1, r8                                    r1 = r8
    mov64 r3, r9                                    r3 = r9
    call function_30349                     
    add64 r8, r9                                    r8 += r9   ///  r8 = r8.wrapping_add(r9)
    mov64 r6, r7                                    r6 = r7
    sub64 r6, r9                                    r6 -= r9   ///  r6 = r6.wrapping_sub(r9)
    ldxdw r1, [r10-0x10]                    
    stxdw [r1+0x8], r6                      
    stxdw [r1+0x0], r8                      
    lddw r0, 0x100040d98 --> b"\x00\x00\x00\x00\xb4\xe5\x03\x00\x1c\x00\x00\x00\x00\x00\x00\x00\x17\x00\…        r0 load str located at 4295232920
    mov64 r1, 64                                    r1 = 64 as i32 as i64 as u64
    jgt r1, r7, lbb_13204                           if r1 > r7 { pc += 58 }
    ldxdw r1, [r10-0x18]                    
    ldxh r1, [r1+0x210]                     
    stxh [r10-0x4], r1                      
    mov64 r1, 2                                     r1 = 2 as i32 as i64 as u64
    mov64 r9, r6                                    r9 = r6
    jgt r1, r6, lbb_13153                           if r1 > r6 { pc += 1 }
    mov64 r9, 2                                     r9 = 2 as i32 as i64 as u64
lbb_13153:
    mov64 r2, r10                                   r2 = r10
    add64 r2, -4                                    r2 += -4   ///  r2 = r2.wrapping_add(-4 as i32 as i64 as u64)
    mov64 r1, r8                                    r1 = r8
    mov64 r3, r9                                    r3 = r9
    call function_30349                     
    add64 r8, r9                                    r8 += r9   ///  r8 = r8.wrapping_add(r9)
    mov64 r7, r6                                    r7 = r6
    sub64 r7, r9                                    r7 -= r9   ///  r7 = r7.wrapping_sub(r9)
    ldxdw r1, [r10-0x10]                    
    stxdw [r1+0x8], r7                      
    stxdw [r1+0x0], r8                      
    lddw r0, 0x100040d98 --> b"\x00\x00"            r0 load str located at 4295232920
    mov64 r1, 2                                     r1 = 2 as i32 as i64 as u64
    jgt r1, r6, lbb_13204                           if r1 > r6 { pc += 36 }
    ldxdw r1, [r10-0x18]                    
    ldxh r1, [r1+0x212]                     
    stxh [r10-0x2], r1                      
    mov64 r6, 2                                     r6 = 2 as i32 as i64 as u64
    mov64 r9, r7                                    r9 = r7
    jgt r6, r7, lbb_13175                           if r6 > r7 { pc += 1 }
    mov64 r9, 2                                     r9 = 2 as i32 as i64 as u64
lbb_13175:
    mov64 r2, r10                                   r2 = r10
    add64 r2, -2                                    r2 += -2   ///  r2 = r2.wrapping_add(-2 as i32 as i64 as u64)
    mov64 r1, r8                                    r1 = r8
    mov64 r3, r9                                    r3 = r9
    call function_30349                     
    mov64 r1, r7                                    r1 = r7
    sub64 r1, r9                                    r1 -= r9   ///  r1 = r1.wrapping_sub(r9)
    ldxdw r2, [r10-0x10]                    
    stxdw [r2+0x8], r1                      
    add64 r8, r9                                    r8 += r9   ///  r8 = r8.wrapping_add(r9)
    stxdw [r2+0x0], r8                      
    lddw r0, 0x100040d98 --> b"\x00\x00\x00\x00\xb4\xe5\x03\x00\x1c\x00\x00\x00\x00\x00\x00\x00\x17\x00\…        r0 load str located at 4295232920
    jgt r6, r7, lbb_13204                           if r6 > r7 { pc += 15 }
    ldxdw r1, [r10-0x18]                    
    add64 r1, 208                                   r1 += 208   ///  r1 = r1.wrapping_add(208 as i32 as i64 as u64)
    call function_1381                      
    jne r0, 0, lbb_13204                            if r0 != (0 as i32 as i64 as u64) { pc += 11 }
    ldxdw r1, [r10-0x18]                    
    ldxdw r2, [r1+0x10]                     
    ldxdw r1, [r1+0x8]                      
    ldxdw r3, [r10-0x10]                    
    call function_13549                     
    ldxdw r3, [r10-0x10]                    
    jne r0, 0, lbb_13204                            if r0 != (0 as i32 as i64 as u64) { pc += 4 }
    ldxdw r1, [r10-0x18]                    
    ldxdw r2, [r1+0x28]                     
    ldxdw r1, [r1+0x20]                     
    call function_13549                     
lbb_13204:
    exit                                    

function_13205:
    stxdw [r10-0x18], r1                    
    ldxb r1, [r1+0x0]                       
    stxb [r10-0x5], r1                      
    stxdw [r10-0x10], r2                    
    ldxdw r9, [r2+0x8]                      
    mov64 r8, 1                                     r8 = 1 as i32 as i64 as u64
    jne r9, 0, lbb_13213                            if r9 != (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r8, 0                                     r8 = 0 as i32 as i64 as u64
lbb_13213:
    ldxdw r6, [r10-0x10]                    
    ldxdw r7, [r6+0x0]                      
    mov64 r2, r10                                   r2 = r10
    add64 r2, -5                                    r2 += -5   ///  r2 = r2.wrapping_add(-5 as i32 as i64 as u64)
    mov64 r1, r7                                    r1 = r7
    mov64 r3, r8                                    r3 = r8
    call function_30349                     
    add64 r7, r8                                    r7 += r8   ///  r7 = r7.wrapping_add(r8)
    mov64 r1, r9                                    r1 = r9
    sub64 r1, r8                                    r1 -= r8   ///  r1 = r1.wrapping_sub(r8)
    stxdw [r6+0x8], r1                      
    stxdw [r6+0x0], r7                      
    lddw r2, 0x100040d98 --> b"\x00\x00\x00\x00\xb4\xe5\x03\x00\x1c\x00\x00\x00\x00\x00\x00\x00\x17\x00\…        r2 load str located at 4295232920
    stxdw [r10-0x20], r2                    
    jeq r9, 0, lbb_13314                            if r9 == (0 as i32 as i64 as u64) { pc += 85 }
    mov64 r6, r1                                    r6 = r1
    ldxdw r1, [r10-0x18]                    
    ldxb r1, [r1+0x1]                       
    stxb [r10-0x4], r1                      
    mov64 r8, 1                                     r8 = 1 as i32 as i64 as u64
    jne r9, 1, lbb_13236                            if r9 != (1 as i32 as i64 as u64) { pc += 1 }
    mov64 r8, 0                                     r8 = 0 as i32 as i64 as u64
lbb_13236:
    mov64 r2, r10                                   r2 = r10
    add64 r2, -4                                    r2 += -4   ///  r2 = r2.wrapping_add(-4 as i32 as i64 as u64)
    mov64 r1, r7                                    r1 = r7
    mov64 r3, r8                                    r3 = r8
    call function_30349                     
    mov64 r3, r6                                    r3 = r6
    mov64 r2, r3                                    r2 = r3
    sub64 r2, r8                                    r2 -= r8   ///  r2 = r2.wrapping_sub(r8)
    ldxdw r1, [r10-0x10]                    
    stxdw [r1+0x8], r2                      
    add64 r7, r8                                    r7 += r8   ///  r7 = r7.wrapping_add(r8)
    stxdw [r1+0x0], r7                      
    jeq r9, 1, lbb_13314                            if r9 == (1 as i32 as i64 as u64) { pc += 65 }
    stxdw [r10-0x28], r2                    
    ldxdw r1, [r10-0x18]                    
    ldxb r1, [r1+0x2]                       
    stxb [r10-0x3], r1                      
    mov64 r9, 1                                     r9 = 1 as i32 as i64 as u64
    jne r3, r8, lbb_13256                           if r3 != r8 { pc += 1 }
    mov64 r9, 0                                     r9 = 0 as i32 as i64 as u64
lbb_13256:
    mov64 r2, r10                                   r2 = r10
    add64 r2, -3                                    r2 += -3   ///  r2 = r2.wrapping_add(-3 as i32 as i64 as u64)
    mov64 r1, r7                                    r1 = r7
    mov64 r3, r9                                    r3 = r9
    call function_30349                     
    ldxdw r2, [r10-0x28]                    
    mov64 r3, r2                                    r3 = r2
    sub64 r3, r9                                    r3 -= r9   ///  r3 = r3.wrapping_sub(r9)
    ldxdw r1, [r10-0x10]                    
    stxdw [r1+0x8], r3                      
    add64 r7, r9                                    r7 += r9   ///  r7 = r7.wrapping_add(r9)
    stxdw [r1+0x0], r7                      
    jeq r6, r8, lbb_13314                           if r6 == r8 { pc += 45 }
    stxdw [r10-0x30], r3                    
    ldxdw r1, [r10-0x18]                    
    ldxb r3, [r1+0x4]                       
    stxdw [r10-0x38], r3                    
    ldxb r1, [r1+0x3]                       
    stxb [r10-0x2], r1                      
    mov64 r8, 1                                     r8 = 1 as i32 as i64 as u64
    mov64 r6, r9                                    r6 = r9
    jne r2, r9, lbb_13279                           if r2 != r9 { pc += 1 }
    mov64 r8, 0                                     r8 = 0 as i32 as i64 as u64
lbb_13279:
    mov64 r2, r10                                   r2 = r10
    add64 r2, -2                                    r2 += -2   ///  r2 = r2.wrapping_add(-2 as i32 as i64 as u64)
    mov64 r1, r7                                    r1 = r7
    mov64 r3, r8                                    r3 = r8
    call function_30349                     
    add64 r7, r8                                    r7 += r8   ///  r7 = r7.wrapping_add(r8)
    ldxdw r2, [r10-0x30]                    
    mov64 r9, r2                                    r9 = r2
    sub64 r9, r8                                    r9 -= r8   ///  r9 = r9.wrapping_sub(r8)
    ldxdw r1, [r10-0x10]                    
    stxdw [r1+0x8], r9                      
    stxdw [r1+0x0], r7                      
    ldxdw r1, [r10-0x28]                    
    jeq r1, r6, lbb_13314                           if r1 == r6 { pc += 21 }
    ldxdw r1, [r10-0x38]                    
    stxb [r10-0x1], r1                      
    mov64 r8, 1                                     r8 = 1 as i32 as i64 as u64
    jne r2, 1, lbb_13298                            if r2 != (1 as i32 as i64 as u64) { pc += 1 }
    mov64 r8, 0                                     r8 = 0 as i32 as i64 as u64
lbb_13298:
    mov64 r2, r10                                   r2 = r10
    add64 r2, -1                                    r2 += -1   ///  r2 = r2.wrapping_add(-1 as i32 as i64 as u64)
    mov64 r1, r7                                    r1 = r7
    mov64 r3, r8                                    r3 = r8
    call function_30349                     
    sub64 r9, r8                                    r9 -= r8   ///  r9 = r9.wrapping_sub(r8)
    ldxdw r1, [r10-0x10]                    
    stxdw [r1+0x8], r9                      
    add64 r7, r8                                    r7 += r8   ///  r7 = r7.wrapping_add(r8)
    stxdw [r1+0x0], r7                      
    lddw r2, 0x100040d98 --> b"\x00\x00\x00\x00\xb4\xe5\x03\x00\x1c\x00\x00\x00\x00\x00\x00\x00\x17\x00\…        r2 load str located at 4295232920
    ldxdw r1, [r10-0x30]                    
    jeq r1, 1, lbb_13313                            if r1 == (1 as i32 as i64 as u64) { pc += 1 }
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
lbb_13313:
    stxdw [r10-0x20], r2                    
lbb_13314:
    ldxdw r0, [r10-0x20]                    
    exit                                    

function_13316:
    mov64 r8, r1                                    r8 = r1
    ldxdw r6, [r2+0x8]                      
    mov64 r1, 4                                     r1 = 4 as i32 as i64 as u64
    jgt r1, r6, lbb_13521                           if r1 > r6 { pc += 201 }
    ldxdw r1, [r2+0x0]                      
    ldxw r3, [r1+0x0]                       
    add64 r1, 4                                     r1 += 4   ///  r1 = r1.wrapping_add(4 as i32 as i64 as u64)
    add64 r6, -4                                    r6 += -4   ///  r6 = r6.wrapping_add(-4 as i32 as i64 as u64)
    stxdw [r2+0x8], r6                      
    stxdw [r10-0x40], r1                    
    stxdw [r2+0x0], r1                      
    mov64 r1, 8                                     r1 = 8 as i32 as i64 as u64
    mov64 r5, 0                                     r5 = 0 as i32 as i64 as u64
    mov64 r4, 0                                     r4 = 0 as i32 as i64 as u64
    stxdw [r10-0x70], r3                    
    jeq r3, 0, lbb_13541                            if r3 == (0 as i32 as i64 as u64) { pc += 209 }
    lddw r1, 0x300000000                            r1 load str located at 12884901888
    ldxdw r1, [r1+0x0]                      
    lddw r4, 0x300008000                            r4 load str located at 12884934656
    jeq r1, 0, lbb_13339                            if r1 == (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r4, r1                                    r4 = r1
lbb_13339:
    mov64 r9, r6                                    r9 = r6
    stxdw [r10-0x60], r2                    
    mov64 r2, 170                                   r2 = 170 as i32 as i64 as u64
    ldxdw r3, [r10-0x70]                    
    mov64 r1, r3                                    r1 = r3
    jgt r2, r3, lbb_13346                           if r2 > r3 { pc += 1 }
    mov64 r1, 170                                   r1 = 170 as i32 as i64 as u64
lbb_13346:
    mov64 r2, r1                                    r2 = r1
    mul64 r2, 24                                    r2 *= 24   ///  r2 = r2.wrapping_mul(24 as u64)
    mov64 r5, r4                                    r5 = r4
    sub64 r5, r2                                    r5 -= r2   ///  r5 = r5.wrapping_sub(r2)
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
    mov64 r0, 1                                     r0 = 1 as i32 as i64 as u64
    jgt r5, r4, lbb_13354                           if r5 > r4 { pc += 1 }
    mov64 r0, 0                                     r0 = 0 as i32 as i64 as u64
lbb_13354:
    jne r0, 0, lbb_13356                            if r0 != (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r3, r5                                    r3 = r5
lbb_13356:
    and64 r3, -8                                    r3 &= -8   ///  r3 = r3.and(-8)
    lddw r4, 0x300000008                            r4 load str located at 12884901896
    jgt r4, r3, lbb_13547                           if r4 > r3 { pc += 187 }
    lddw r2, 0x300000000                            r2 load str located at 12884901888
    stxdw [r2+0x0], r3                      
    stxdw [r10-0x30], r3                    
    stxdw [r10-0x38], r1                    
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    stxdw [r10-0x58], r1                    
    stxdw [r10-0x28], r2                    
    mov64 r0, 4                                     r0 = 4 as i32 as i64 as u64
    mov64 r7, 0                                     r7 = 0 as i32 as i64 as u64
    mov64 r4, r8                                    r4 = r8
    stxdw [r10-0x78], r8                    
    ldxdw r5, [r10-0x60]                    
    mov64 r8, r9                                    r8 = r9
lbb_13375:
    jgt r0, r8, lbb_13525                           if r0 > r8 { pc += 149 }
    add64 r8, -4                                    r8 += -4   ///  r8 = r8.wrapping_add(-4 as i32 as i64 as u64)
    ldxdw r1, [r10-0x40]                    
    ldxw r2, [r1+0x0]                       
    stxdw [r5+0x8], r8                      
    add64 r1, 4                                     r1 += 4   ///  r1 = r1.wrapping_add(4 as i32 as i64 as u64)
    stxdw [r5+0x0], r1                      
    stxdw [r10-0x48], r2                    
    stxdw [r10-0x68], r7                    
    jne r2, 0, lbb_13423                            if r2 != (0 as i32 as i64 as u64) { pc += 38 }
    stxdw [r10-0x50], r8                    
    mov64 r0, 1                                     r0 = 1 as i32 as i64 as u64
    mov64 r9, 0                                     r9 = 0 as i32 as i64 as u64
    stxdw [r10-0x40], r1                    
    mov64 r8, 0                                     r8 = 0 as i32 as i64 as u64
    ldxdw r6, [r10-0x58]                    
lbb_13391:
    ldxdw r1, [r10-0x38]                    
    ldxdw r7, [r10-0x68]                    
    jne r6, r1, lbb_13403                           if r6 != r1 { pc += 9 }
    mov64 r1, r10                                   r1 = r10
    add64 r1, -56                                   r1 += -56   ///  r1 = r1.wrapping_add(-56 as i32 as i64 as u64)
    stxdw [r10-0x58], r6                    
    mov64 r6, r0                                    r6 = r0
    call function_1009                      
    ldxdw r5, [r10-0x60]                    
    mov64 r0, r6                                    r0 = r6
    ldxdw r6, [r10-0x58]                    
    ldxdw r4, [r10-0x78]                    
lbb_13403:
    add64 r7, 1                                     r7 += 1   ///  r7 = r7.wrapping_add(1 as i32 as i64 as u64)
    mov64 r2, r6                                    r2 = r6
    mul64 r2, 24                                    r2 *= 24   ///  r2 = r2.wrapping_mul(24 as u64)
    ldxdw r1, [r10-0x30]                    
    mov64 r3, r1                                    r3 = r1
    add64 r3, r2                                    r3 += r2   ///  r3 = r3.wrapping_add(r2)
    stxdw [r3+0x10], r9                     
    stxdw [r3+0x8], r0                      
    stxdw [r3+0x0], r8                      
    add64 r6, 1                                     r6 += 1   ///  r6 = r6.wrapping_add(1 as i32 as i64 as u64)
    stxdw [r10-0x58], r6                    
    stxdw [r10-0x28], r6                    
    mov64 r2, r7                                    r2 = r7
    lsh64 r2, 32                                    r2 <<= 32   ///  r2 = r2.wrapping_shl(32)
    rsh64 r2, 32                                    r2 >>= 32   ///  r2 = r2.wrapping_shr(32)
    ldxdw r8, [r10-0x50]                    
    ldxdw r3, [r10-0x70]                    
    mov64 r0, 4                                     r0 = 4 as i32 as i64 as u64
    jgt r3, r2, lbb_13375                           if r3 > r2 { pc += -47 }
    ja lbb_13534                                    if true { pc += 111 }
lbb_13423:
    lddw r1, 0x300000000                            r1 load str located at 12884901888
    ldxdw r1, [r1+0x0]                      
    lddw r4, 0x300008000                            r4 load str located at 12884934656
    jeq r1, 0, lbb_13430                            if r1 == (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r4, r1                                    r4 = r1
lbb_13430:
    mov64 r6, r8                                    r6 = r8
    mov64 r1, 341                                   r1 = 341 as i32 as i64 as u64
    ldxdw r2, [r10-0x48]                    
    mov64 r3, r2                                    r3 = r2
    jgt r1, r2, lbb_13436                           if r1 > r2 { pc += 1 }
    mov64 r3, 341                                   r3 = 341 as i32 as i64 as u64
lbb_13436:
    mov64 r2, r3                                    r2 = r3
    mul64 r2, 12                                    r2 *= 12   ///  r2 = r2.wrapping_mul(12 as u64)
    mov64 r5, r4                                    r5 = r4
    sub64 r5, r2                                    r5 -= r2   ///  r5 = r5.wrapping_sub(r2)
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    mov64 r0, 1                                     r0 = 1 as i32 as i64 as u64
    jgt r5, r4, lbb_13444                           if r5 > r4 { pc += 1 }
    mov64 r0, 0                                     r0 = 0 as i32 as i64 as u64
lbb_13444:
    jne r0, 0, lbb_13446                            if r0 != (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r1, r5                                    r1 = r5
lbb_13446:
    lddw r4, 0x300000008                            r4 load str located at 12884901896
    jgt r4, r1, lbb_13545                           if r4 > r1 { pc += 96 }
    lddw r2, 0x300000000                            r2 load str located at 12884901888
    stxdw [r2+0x0], r1                      
    stxdw [r10-0x20], r3                    
    mov64 r7, 0                                     r7 = 0 as i32 as i64 as u64
    stxdw [r10-0x10], r7                    
    stxdw [r10-0x18], r1                    
    mov64 r9, 0                                     r9 = 0 as i32 as i64 as u64
    ldxdw r5, [r10-0x60]                    
    mov64 r0, r6                                    r0 = r6
    ja lbb_13491                                    if true { pc += 31 }
lbb_13460:
    add64 r9, 1                                     r9 += 1   ///  r9 = r9.wrapping_add(1 as i32 as i64 as u64)
    lsh64 r6, 32                                    r6 <<= 32   ///  r6 = r6.wrapping_shl(32)
    or64 r8, r6                                     r8 |= r6   ///  r8 = r8.or(r6)
    mov64 r2, r1                                    r2 = r1
    add64 r2, r7                                    r2 += r7   ///  r2 = r2.wrapping_add(r7)
    ldxh r3, [r10-0x4]                      
    stxh [r2+0x4], r3                       
    ldxw r3, [r10-0x8]                      
    stxw [r2+0x0], r3                       
    mov64 r3, r8                                    r3 = r8
    rsh64 r3, 32                                    r3 >>= 32   ///  r3 = r3.wrapping_shr(32)
    stxb [r2+0xb], r3                       
    stxw [r2+0x7], r8                       
    stxb [r2+0x6], r4                       
    stxdw [r10-0x10], r9                    
    add64 r7, 12                                    r7 += 12   ///  r7 = r7.wrapping_add(12 as i32 as i64 as u64)
    ldxdw r2, [r10-0x48]                    
    jgt r2, r9, lbb_13491                           if r2 > r9 { pc += 13 }
    stxdw [r10-0x50], r0                    
    ldxdw r0, [r10-0x18]                    
    ldxdw r8, [r10-0x20]                    
    lddw r1, 0x8000000000000000                     r1 load str located at -9223372036854775808
    jeq r8, r1, lbb_13528                           if r8 == r1 { pc += 44 }
    ldxdw r1, [r10-0x40]                    
    add64 r1, r7                                    r1 += r7   ///  r1 = r1.wrapping_add(r7)
    add64 r1, 4                                     r1 += 4   ///  r1 = r1.wrapping_add(4 as i32 as i64 as u64)
    stxdw [r10-0x40], r1                    
    ldxdw r6, [r10-0x28]                    
    ldxdw r4, [r10-0x78]                    
    ja lbb_13391                                    if true { pc += -100 }
lbb_13491:
    mov64 r2, 12                                    r2 = 12 as i32 as i64 as u64
    jgt r2, r0, lbb_13525                           if r2 > r0 { pc += 32 }
    ldxdw r2, [r10-0x40]                    
    add64 r2, r7                                    r2 += r7   ///  r2 = r2.wrapping_add(r7)
    mov64 r3, r2                                    r3 = r2
    add64 r3, 4                                     r3 += 4   ///  r3 = r3.wrapping_add(4 as i32 as i64 as u64)
    mov64 r4, r2                                    r4 = r2
    add64 r4, 16                                    r4 += 16   ///  r4 = r4.wrapping_add(16 as i32 as i64 as u64)
    stxdw [r5+0x0], r4                      
    add64 r0, -12                                   r0 += -12   ///  r0 = r0.wrapping_add(-12 as i32 as i64 as u64)
    stxdw [r5+0x8], r0                      
    ldxb r4, [r2+0xa]                       
    ldxw r8, [r2+0xb]                       
    ldxb r6, [r2+0xf]                       
    ldxw r2, [r3+0x0]                       
    stxw [r10-0x8], r2                      
    ldxh r2, [r3+0x4]                       
    stxh [r10-0x4], r2                      
    ldxdw r2, [r10-0x20]                    
    jne r9, r2, lbb_13460                           if r9 != r2 { pc += -51 }
    mov64 r1, r10                                   r1 = r10
    add64 r1, -32                                   r1 += -32   ///  r1 = r1.wrapping_add(-32 as i32 as i64 as u64)
    stxdw [r10-0x50], r0                    
    stxdw [r10-0x58], r4                    
    call function_965                       
    ldxdw r4, [r10-0x58]                    
    ldxdw r0, [r10-0x50]                    
    ldxdw r5, [r10-0x60]                    
    ldxdw r1, [r10-0x18]                    
    ja lbb_13460                                    if true { pc += -61 }
lbb_13521:
    lddw r1, 0x100040d80 --> b"\x00\x00\x00\x00\x99\xe5\x03\x00\x1b\x00\x00\x00\x00\x00\x00\x00%\x00\x00…        r1 load str located at 4295232896
    call function_20446                     
    ja lbb_13529                                    if true { pc += 4 }
lbb_13525:
    lddw r1, 0x100040d80 --> b"\x00\x00\x00\x00\x99\xe5\x03\x00\x1b\x00\x00\x00\x00\x00\x00\x00%\x00\x00…        r1 load str located at 4295232896
    call function_20446                     
lbb_13528:
    ldxdw r8, [r10-0x78]                    
lbb_13529:
    lddw r1, 0x8000000000000000                     r1 load str located at -9223372036854775808
    stxdw [r8+0x0], r1                      
    stxdw [r8+0x8], r0                      
lbb_13533:
    exit                                    
lbb_13534:
    ldxdw r5, [r10-0x38]                    
    lddw r3, 0x8000000000000000                     r3 load str located at -9223372036854775808
    mov64 r0, r1                                    r0 = r1
    mov64 r8, r4                                    r8 = r4
    ldxdw r4, [r10-0x58]                    
    jeq r5, r3, lbb_13529                           if r5 == r3 { pc += -12 }
lbb_13541:
    stxdw [r8+0x10], r4                     
    stxdw [r8+0x8], r1                      
    stxdw [r8+0x0], r5                      
    ja lbb_13533                                    if true { pc += -12 }
lbb_13545:
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    call function_21549                     
lbb_13547:
    mov64 r1, 8                                     r1 = 8 as i32 as i64 as u64
    call function_21549                     

function_13549:
    mov64 r9, r2                                    r9 = r2
    lddw r0, 0x1500000003                           r0 load str located at 90194313219
    lddw r2, 0xffffffff                             r2 load str located at 4294967295
    jgt r9, r2, lbb_13643                           if r9 > r2 { pc += 88 }
    stxdw [r10-0x18], r1                    
    stxw [r10-0x8], r9                      
    ldxdw r1, [r3+0x0]                      
    stxdw [r10-0x20], r3                    
    ldxdw r8, [r3+0x8]                      
    mov64 r2, 4                                     r2 = 4 as i32 as i64 as u64
    mov64 r7, r8                                    r7 = r8
    jgt r2, r8, lbb_13564                           if r2 > r8 { pc += 1 }
    mov64 r7, 4                                     r7 = 4 as i32 as i64 as u64
lbb_13564:
    mov64 r2, r10                                   r2 = r10
    add64 r2, -8                                    r2 += -8   ///  r2 = r2.wrapping_add(-8 as i32 as i64 as u64)
    mov64 r3, r7                                    r3 = r7
    mov64 r6, r1                                    r6 = r1
    call function_30349                     
    mov64 r1, r6                                    r1 = r6
    add64 r1, r7                                    r1 += r7   ///  r1 = r1.wrapping_add(r7)
    mov64 r6, r8                                    r6 = r8
    sub64 r6, r7                                    r6 -= r7   ///  r6 = r6.wrapping_sub(r7)
    ldxdw r2, [r10-0x20]                    
    stxdw [r2+0x8], r6                      
    stxdw [r2+0x0], r1                      
    lddw r0, 0x100040d98 --> b"\x00\x00\x00\x00\xb4\xe5\x03\x00\x1c\x00\x00\x00\x00\x00\x00\x00\x17\x00\…        r0 load str located at 4295232920
    ldxdw r2, [r10-0x18]                    
    mov64 r3, 4                                     r3 = 4 as i32 as i64 as u64
    jgt r3, r8, lbb_13643                           if r3 > r8 { pc += 62 }
    mov64 r0, 0                                     r0 = 0 as i32 as i64 as u64
    jeq r9, 0, lbb_13643                            if r9 == (0 as i32 as i64 as u64) { pc += 60 }
    mul64 r9, 24                                    r9 *= 24   ///  r9 = r9.wrapping_mul(24 as u64)
    mov64 r3, r2                                    r3 = r2
    add64 r3, r9                                    r3 += r9   ///  r3 = r3.wrapping_add(r9)
    stxdw [r10-0x28], r3                    
    ja lbb_13591                                    if true { pc += 3 }
lbb_13588:
    mov64 r0, 0                                     r0 = 0 as i32 as i64 as u64
    ldxdw r3, [r10-0x28]                    
    jeq r2, r3, lbb_13643                           if r2 == r3 { pc += 52 }
lbb_13591:
    lddw r0, 0x1500000003                           r0 load str located at 90194313219
    ldxdw r8, [r2+0x10]                     
    lddw r3, 0xffffffff                             r3 load str located at 4294967295
    jgt r8, r3, lbb_13643                           if r8 > r3 { pc += 46 }
    stxdw [r10-0x18], r2                    
    ldxdw r9, [r2+0x8]                      
    stxw [r10-0x4], r8                      
    mov64 r2, 4                                     r2 = 4 as i32 as i64 as u64
    mov64 r7, r6                                    r7 = r6
    jgt r2, r6, lbb_13604                           if r2 > r6 { pc += 1 }
    mov64 r7, 4                                     r7 = 4 as i32 as i64 as u64
lbb_13604:
    mov64 r2, r10                                   r2 = r10
    add64 r2, -4                                    r2 += -4   ///  r2 = r2.wrapping_add(-4 as i32 as i64 as u64)
    mov64 r3, r7                                    r3 = r7
    stxdw [r10-0x10], r1                    
    call function_30349                     
    ldxdw r1, [r10-0x10]                    
    add64 r1, r7                                    r1 += r7   ///  r1 = r1.wrapping_add(r7)
    mov64 r3, r6                                    r3 = r6
    sub64 r3, r7                                    r3 -= r7   ///  r3 = r3.wrapping_sub(r7)
    ldxdw r2, [r10-0x20]                    
    stxdw [r2+0x8], r3                      
    stxdw [r2+0x0], r1                      
    lddw r0, 0x100040d98 --> b"\x00\x00\x00\x00\xb4\xe5\x03\x00\x1c\x00\x00\x00\x00\x00\x00\x00\x17\x00\…        r0 load str located at 4295232920
    ldxdw r2, [r10-0x18]                    
    mov64 r4, 4                                     r4 = 4 as i32 as i64 as u64
    jgt r4, r6, lbb_13643                           if r4 > r6 { pc += 22 }
    add64 r2, 24                                    r2 += 24   ///  r2 = r2.wrapping_add(24 as i32 as i64 as u64)
    mul64 r8, 12                                    r8 *= 12   ///  r8 = r8.wrapping_mul(12 as u64)
    stxdw [r10-0x18], r2                    
    ja lbb_13644                                    if true { pc += 19 }
lbb_13625:
    mov64 r2, r9                                    r2 = r9
    mov64 r3, r7                                    r3 = r7
    mov64 r6, r1                                    r6 = r1
    call function_30349                     
    mov64 r1, r6                                    r1 = r6
    add64 r1, r7                                    r1 += r7   ///  r1 = r1.wrapping_add(r7)
    ldxdw r4, [r10-0x10]                    
    mov64 r3, r4                                    r3 = r4
    sub64 r3, r7                                    r3 -= r7   ///  r3 = r3.wrapping_sub(r7)
    ldxdw r2, [r10-0x20]                    
    stxdw [r2+0x8], r3                      
    stxdw [r2+0x0], r1                      
    lddw r0, 0x100040d98 --> b"\x00\x00\x00\x00\xb4\xe5\x03\x00\x1c\x00\x00\x00\x00\x00\x00\x00\x17\x00\…        r0 load str located at 4295232920
    add64 r8, -12                                   r8 += -12   ///  r8 = r8.wrapping_add(-12 as i32 as i64 as u64)
    add64 r9, 12                                    r9 += 12   ///  r9 = r9.wrapping_add(12 as i32 as i64 as u64)
    ldxdw r2, [r10-0x18]                    
    jgt r4, 11, lbb_13644                           if r4 > (11 as i32 as i64 as u64) { pc += 1 }
lbb_13643:
    exit                                    
lbb_13644:
    mov64 r6, r3                                    r6 = r3
    jeq r8, 0, lbb_13588                            if r8 == (0 as i32 as i64 as u64) { pc += -58 }
    mov64 r2, 12                                    r2 = 12 as i32 as i64 as u64
    mov64 r7, r6                                    r7 = r6
    stxdw [r10-0x10], r6                    
    jgt r2, r6, lbb_13625                           if r2 > r6 { pc += -25 }
    mov64 r7, 12                                    r7 = 12 as i32 as i64 as u64
    ja lbb_13625                                    if true { pc += -27 }

entrypoint:
    mov64 r6, r1                                    r6 = r1
    ldxdw r1, [r6+0x0]                      
    jne r1, 2, lbb_13695                            if r1 != (2 as i32 as i64 as u64) { pc += 40 }
    ldxdw r1, [r6+0x10]                     
    lddw r2, 0xfc3e34becfcb63d7                     r2 load str located at -270720933461007401
    jeq r1, r2, lbb_13661                           if r1 == r2 { pc += 2 }
lbb_13659:
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    ja lbb_13674                                    if true { pc += 13 }
lbb_13661:
    ldxdw r1, [r6+0x18]                     
    lddw r2, 0xf495c87a5045cbbb                     r2 load str located at -822530929266930757
    jne r1, r2, lbb_13659                           if r1 != r2 { pc += -6 }
    ldxdw r1, [r6+0x20]                     
    lddw r2, 0xe7d24322df5eeb7c                     r2 load str located at -1742256288783471748
    jne r1, r2, lbb_13659                           if r1 != r2 { pc += -10 }
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    ldxdw r2, [r6+0x28]                     
    lddw r3, 0xcf66dbb77498e62b                     r3 load str located at -3501870079252306389
    jne r2, r3, lbb_13659                           if r2 != r3 { pc += -15 }
lbb_13674:
    jne r1, 0, lbb_13695                            if r1 != (0 as i32 as i64 as u64) { pc += 20 }
    ldxb r1, [r6+0x9]                       
    jne r1, 0, lbb_13682                            if r1 != (0 as i32 as i64 as u64) { pc += 5 }
    lddw r1, 0x8000000000000000                     r1 load str located at -9223372036854775808
    stxdw [r10-0xf0], r1                    
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    ja lbb_13841                                    if true { pc += 159 }
lbb_13682:
    ldxdw r1, [r6+0x28b8]                   
    jne r1, 1264, lbb_13837                         if r1 != (1264 as i32 as i64 as u64) { pc += 153 }
    ldxdw r1, [r6+0x55b8]                   
    jeq r1, 776, lbb_13687                          if r1 == (776 as i32 as i64 as u64) { pc += 1 }
    ja lbb_13913                                    if true { pc += 226 }
lbb_13687:
    ldxb r1, [r6+0x55c0]                    
    jeq r1, 13, lbb_13690                           if r1 == (13 as i32 as i64 as u64) { pc += 1 }
    ja lbb_13695                                    if true { pc += 5 }
lbb_13690:
    ldxdw r1, [r6+0x2890]                   
    ldxdw r2, [r6+0x58c8]                   
    jeq r2, r1, lbb_14088                           if r2 == r1 { pc += 395 }
lbb_13693:
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    ja lbb_14098                                    if true { pc += 403 }
lbb_13695:
    mov64 r1, r10                                   r1 = r10
    add64 r1, -240                                  r1 += -240   ///  r1 = r1.wrapping_add(-240 as i32 as i64 as u64)
    mov64 r2, r6                                    r2 = r6
    call function_17306                     
    ldxdw r8, [r10-0xc8]                    
    jne r8, 0, lbb_13706                            if r8 != (0 as i32 as i64 as u64) { pc += 5 }
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
    lddw r3, 0x1000413d8 --> b"\x00\x00\x00\x00\xe7\xeb\x03\x00\x11\x00\x00\x00\x00\x00\x00\x00\x0f\x00\…        r3 load str located at 4295234520
    call function_28353                     
lbb_13706:
    ldxdw r4, [r10-0xd0]                    
    ldxdw r6, [r10-0xe0]                    
    ldxdw r7, [r10-0xe8]                    
    ldxb r5, [r4+0x0]                       
    jeq r5, 13, lbb_13757                           if r5 == (13 as i32 as i64 as u64) { pc += 46 }
    ldxdw r9, [r10-0xd8]                    
    stxb [r10-0xa1], r5                     
    mov64 r3, r8                                    r3 = r8
    add64 r3, -1                                    r3 += -1   ///  r3 = r3.wrapping_add(-1 as i32 as i64 as u64)
    jsgt r5, 7, lbb_13763                           if (r5 as i64) > (7 as i32 as i64) { pc += 47 }
    jsgt r5, 3, lbb_13805                           if (r5 as i64) > (3 as i32 as i64) { pc += 88 }
    jsgt r5, 1, lbb_13846                           if (r5 as i64) > (1 as i32 as i64) { pc += 128 }
    jeq r5, 0, lbb_13943                            if r5 == (0 as i32 as i64 as u64) { pc += 224 }
    jeq r5, 1, lbb_13721                            if r5 == (1 as i32 as i64 as u64) { pc += 1 }
    ja lbb_13917                                    if true { pc += 196 }
lbb_13721:
    mov64 r1, 3                                     r1 = 3 as i32 as i64 as u64
    jgt r1, r8, lbb_14308                           if r1 > r8 { pc += 585 }
    mov64 r1, r8                                    r1 = r8
    add64 r1, -3                                    r1 += -3   ///  r1 = r1.wrapping_add(-3 as i32 as i64 as u64)
    mov64 r2, 2                                     r2 = 2 as i32 as i64 as u64
    jgt r2, r1, lbb_14308                           if r2 > r1 { pc += 581 }
    mov64 r1, r8                                    r1 = r8
    add64 r1, -5                                    r1 += -5   ///  r1 = r1.wrapping_add(-5 as i32 as i64 as u64)
    mov64 r2, 4                                     r2 = 4 as i32 as i64 as u64
    jgt r2, r1, lbb_14308                           if r2 > r1 { pc += 577 }
    jeq r8, 9, lbb_14308                            if r8 == (9 as i32 as i64 as u64) { pc += 576 }
    ldxh r1, [r4+0x1]                       
    stxdw [r10-0x168], r1                   
    ldxh r0, [r4+0x3]                       
    ldxw r2, [r4+0x5]                       
    ldxb r3, [r4+0x9]                       
    stxb [r10-0x88], r3                     
    mov64 r1, 2                                     r1 = 2 as i32 as i64 as u64
    jgt r1, r3, lbb_14257                           if r1 > r3 { pc += 517 }
lbb_13740:
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    stxdw [r10-0x20], r1                    
    lddw r1, 0x100040e18 --> b"\x00\x00\x00\x00]\xe6\x03\x00\x1d\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00…        r1 load str located at 4295233048
    stxdw [r10-0x40], r1                    
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    stxdw [r10-0x38], r1                    
lbb_13747:
    stxdw [r10-0x28], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -16                                   r1 += -16   ///  r1 = r1.wrapping_add(-16 as i32 as i64 as u64)
    stxdw [r10-0x30], r1                    
    lddw r1, 0x10003b0c8 --> b"\xbf#\x00\x00\x00\x00\x00\x00q\x11\x00\x00\x00\x00\x00\x00\xb7\x02\x00\x0…        r1 load str located at 4295209160
lbb_13753:
    stxdw [r10-0x8], r1                     
    mov64 r1, r10                                   r1 = r10
    add64 r1, -136                                  r1 += -136   ///  r1 = r1.wrapping_add(-136 as i32 as i64 as u64)
    ja lbb_13871                                    if true { pc += 114 }
lbb_13757:
    mov64 r1, 3                                     r1 = 3 as i32 as i64 as u64
    stxw [r10-0x38], r1                     
    lddw r1, 0x8000000000000000                     r1 load str located at -9223372036854775808
    stxdw [r10-0x40], r1                    
    ja lbb_14320                                    if true { pc += 557 }
lbb_13763:
    jsgt r5, 11, lbb_13819                          if (r5 as i64) > (11 as i32 as i64) { pc += 55 }
    stxdw [r10-0x110], r9                   
    mov64 r1, r5                                    r1 = r5
    add64 r1, -8                                    r1 += -8   ///  r1 = r1.wrapping_add(-8 as i32 as i64 as u64)
    mov64 r0, 3                                     r0 = 3 as i32 as i64 as u64
    jgt r0, r1, lbb_14180                           if r0 > r1 { pc += 411 }
    jeq r5, 11, lbb_13771                           if r5 == (11 as i32 as i64 as u64) { pc += 1 }
    ja lbb_13917                                    if true { pc += 146 }
lbb_13771:
    mov64 r1, 33                                    r1 = 33 as i32 as i64 as u64
    jgt r1, r8, lbb_14308                           if r1 > r8 { pc += 535 }
lbb_13773:
    ldxdw r2, [r4+0x7]                      
    ldxb r1, [r4+0xf]                       
    stxb [r10-0x38], r1                     
    ldxw r1, [r4+0x2]                       
    stxdw [r10-0x128], r1                   
    ldxb r1, [r4+0x1]                       
    stxdw [r10-0x138], r1                   
    ldxb r1, [r4+0x6]                       
    stxdw [r10-0x40], r2                    
    lsh64 r2, 8                                     r2 <<= 8   ///  r2 = r2.wrapping_shl(8)
    or64 r2, r1                                     r2 |= r1   ///  r2 = r2.or(r1)
    stxdw [r10-0x130], r2                   
    ldxdw r1, [r10-0x3f]                    
    stxdw [r10-0x148], r1                   
    ldxb r1, [r4+0x1b]                      
    lsh64 r1, 16                                    r1 <<= 16   ///  r1 = r1.wrapping_shl(16)
    ldxh r9, [r4+0x19]                      
    or64 r9, r1                                     r9 |= r1   ///  r9 = r9.or(r1)
    add64 r8, -33                                   r8 += -33   ///  r8 = r8.wrapping_add(-33 as i32 as i64 as u64)
    ldxb r1, [r4+0x20]                      
    stxdw [r10-0x158], r1                   
    ldxw r1, [r4+0x1c]                      
    stxdw [r10-0x160], r1                   
    ldxb r1, [r4+0x18]                      
    stxdw [r10-0x150], r1                   
    ldxw r1, [r4+0x14]                      
    stxdw [r10-0x120], r1                   
    ldxh r1, [r4+0x12]                      
    stxdw [r10-0x118], r1                   
    ldxh r1, [r4+0x10]                      
    stxdw [r10-0x140], r1                   
    ja lbb_14179                                    if true { pc += 374 }
lbb_13805:
    jsgt r5, 5, lbb_13875                           if (r5 as i64) > (5 as i32 as i64) { pc += 69 }
    jeq r5, 4, lbb_14013                            if r5 == (4 as i32 as i64 as u64) { pc += 206 }
    jeq r5, 5, lbb_13809                            if r5 == (5 as i32 as i64 as u64) { pc += 1 }
    ja lbb_13917                                    if true { pc += 108 }
lbb_13809:
    mov64 r1, 7                                     r1 = 7 as i32 as i64 as u64
    jgt r1, r8, lbb_14308                           if r1 > r8 { pc += 497 }
    stxdw [r10-0x110], r9                   
    ldxw r1, [r4+0x1]                       
    stxdw [r10-0x128], r1                   
    ldxh r1, [r4+0x5]                       
    stxdw [r10-0x130], r1                   
    add64 r8, -7                                    r8 += -7   ///  r8 = r8.wrapping_add(-7 as i32 as i64 as u64)
lbb_13817:
    mov64 r3, r8                                    r3 = r8
    ja lbb_14081                                    if true { pc += 262 }
lbb_13819:
    jsgt r5, 14, lbb_13882                          if (r5 as i64) > (14 as i32 as i64) { pc += 62 }
    jeq r5, 12, lbb_14019                           if r5 == (12 as i32 as i64 as u64) { pc += 198 }
    jeq r5, 14, lbb_13823                           if r5 == (14 as i32 as i64 as u64) { pc += 1 }
    ja lbb_13917                                    if true { pc += 94 }
lbb_13823:
    mov64 r1, 5                                     r1 = 5 as i32 as i64 as u64
    jgt r1, r8, lbb_14308                           if r1 > r8 { pc += 483 }
    mov64 r1, r8                                    r1 = r8
    add64 r1, -5                                    r1 += -5   ///  r1 = r1.wrapping_add(-5 as i32 as i64 as u64)
    mov64 r2, 4                                     r2 = 4 as i32 as i64 as u64
    jgt r2, r1, lbb_14308                           if r2 > r1 { pc += 479 }
    jeq r8, 9, lbb_14308                            if r8 == (9 as i32 as i64 as u64) { pc += 478 }
    ldxw r2, [r4+0x1]                       
    ldxw r3, [r4+0x5]                       
    ldxb r0, [r4+0x9]                       
    stxb [r10-0x88], r0                     
    mov64 r1, 2                                     r1 = 2 as i32 as i64 as u64
    jgt r1, r0, lbb_14305                           if r1 > r0 { pc += 469 }
    ja lbb_13740                                    if true { pc += -97 }
lbb_13837:
    lddw r1, 0x8000000000000000                     r1 load str located at -9223372036854775808
    stxdw [r10-0xf0], r1                    
    mov64 r1, 25                                    r1 = 25 as i32 as i64 as u64
lbb_13841:
    stxw [r10-0xe8], r1                     
lbb_13842:
    mov64 r1, r10                                   r1 = r10
    add64 r1, -240                                  r1 += -240   ///  r1 = r1.wrapping_add(-240 as i32 as i64 as u64)
    call function_17811                     
lbb_13845:
    exit                                    
lbb_13846:
    stxdw [r10-0x110], r9                   
    jeq r5, 2, lbb_14180                            if r5 == (2 as i32 as i64 as u64) { pc += 332 }
    jeq r5, 3, lbb_13850                            if r5 == (3 as i32 as i64 as u64) { pc += 1 }
    ja lbb_13917                                    if true { pc += 67 }
lbb_13850:
    jeq r3, 0, lbb_14308                            if r3 == (0 as i32 as i64 as u64) { pc += 457 }
    ldxb r2, [r4+0x1]                       
    stxb [r10-0x59], r2                     
    mov64 r1, 3                                     r1 = 3 as i32 as i64 as u64
    jgt r1, r2, lbb_14073                           if r1 > r2 { pc += 218 }
lbb_13855:
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    stxdw [r10-0x20], r1                    
    lddw r1, 0x1000413f0 --> b"\x00\x00\x00\x00\xf8\xeb\x03\x00\x18\x00\x00\x00\x00\x00\x00\x00\x00\x00\…        r1 load str located at 4295234544
    stxdw [r10-0x40], r1                    
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    stxdw [r10-0x38], r1                    
    stxdw [r10-0x28], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -16                                   r1 += -16   ///  r1 = r1.wrapping_add(-16 as i32 as i64 as u64)
    stxdw [r10-0x30], r1                    
    lddw r1, 0x100000ef8 --> b"a#4\x00\x00\x00\x00\x00\xbf4\x00\x00\x00\x00\x00\x00W\x04\x00\x00\x10\x00…        r1 load str located at 4294971128
    stxdw [r10-0x8], r1                     
    mov64 r1, r10                                   r1 = r10
    add64 r1, -89                                   r1 += -89   ///  r1 = r1.wrapping_add(-89 as i32 as i64 as u64)
lbb_13871:
    stxdw [r10-0x10], r1                    
    mov64 r8, r10                                   r8 = r10
    add64 r8, -88                                   r8 += -88   ///  r8 = r8.wrapping_add(-88 as i32 as i64 as u64)
    ja lbb_13936                                    if true { pc += 61 }
lbb_13875:
    jeq r5, 6, lbb_14025                            if r5 == (6 as i32 as i64 as u64) { pc += 149 }
    jeq r5, 7, lbb_13878                            if r5 == (7 as i32 as i64 as u64) { pc += 1 }
    ja lbb_13917                                    if true { pc += 39 }
lbb_13878:
    mov64 r1, 33                                    r1 = 33 as i32 as i64 as u64
    jgt r1, r8, lbb_14308                           if r1 > r8 { pc += 428 }
    stxdw [r10-0x110], r9                   
    ja lbb_13773                                    if true { pc += -109 }
lbb_13882:
    jeq r5, 15, lbb_14067                           if r5 == (15 as i32 as i64 as u64) { pc += 184 }
    jeq r5, 16, lbb_13885                           if r5 == (16 as i32 as i64 as u64) { pc += 1 }
    ja lbb_13917                                    if true { pc += 32 }
lbb_13885:
    jeq r3, 0, lbb_14308                            if r3 == (0 as i32 as i64 as u64) { pc += 422 }
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
    ldxb r2, [r4+0x1]                       
    stxb [r10-0x88], r2                     
    jeq r2, 0, lbb_13892                            if r2 == (0 as i32 as i64 as u64) { pc += 2 }
    jne r2, 1, lbb_14129                            if r2 != (1 as i32 as i64 as u64) { pc += 238 }
    mov64 r3, 1                                     r3 = 1 as i32 as i64 as u64
lbb_13892:
    mov64 r1, 10                                    r1 = 10 as i32 as i64 as u64
    jgt r1, r8, lbb_14308                           if r1 > r8 { pc += 414 }
    mov64 r1, r8                                    r1 = r8
    add64 r1, -10                                   r1 += -10   ///  r1 = r1.wrapping_add(-10 as i32 as i64 as u64)
    mov64 r2, 8                                     r2 = 8 as i32 as i64 as u64
    jgt r2, r1, lbb_14308                           if r2 > r1 { pc += 410 }
    stxdw [r10-0x150], r3                   
    stxdw [r10-0x110], r9                   
    ldxdw r1, [r4+0x2]                      
    stxdw [r10-0x148], r1                   
    add64 r8, -18                                   r8 += -18   ///  r8 = r8.wrapping_add(-18 as i32 as i64 as u64)
    ldxdw r2, [r4+0xa]                      
    mov64 r1, r2                                    r1 = r2
    rsh64 r1, 32                                    r1 >>= 32   ///  r1 = r1.wrapping_shr(32)
    stxdw [r10-0x120], r1                   
    stxdw [r10-0x140], r2                   
    mov64 r1, r2                                    r1 = r2
    rsh64 r1, 16                                    r1 >>= 16   ///  r1 = r1.wrapping_shr(16)
    stxdw [r10-0x118], r1                   
    mov64 r3, r8                                    r3 = r8
    ja lbb_14081                                    if true { pc += 168 }
lbb_13913:
    lddw r1, 0x8000000000000002                     r1 load str located at -9223372036854775806
    stxdw [r10-0xf0], r1                    
    ja lbb_13842                                    if true { pc += -75 }
lbb_13917:
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    stxdw [r10-0x20], r1                    
    lddw r1, 0x1000413f0 --> b"\x00\x00\x00\x00\xf8\xeb\x03\x00\x18\x00\x00\x00\x00\x00\x00\x00\x00\x00\…        r1 load str located at 4295234544
    stxdw [r10-0x40], r1                    
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    stxdw [r10-0x38], r1                    
    stxdw [r10-0x28], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -88                                   r1 += -88   ///  r1 = r1.wrapping_add(-88 as i32 as i64 as u64)
    stxdw [r10-0x30], r1                    
    lddw r1, 0x100000ef8 --> b"a#4\x00\x00\x00\x00\x00\xbf4\x00\x00\x00\x00\x00\x00W\x04\x00\x00\x10\x00…        r1 load str located at 4294971128
    stxdw [r10-0x50], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -161                                  r1 += -161   ///  r1 = r1.wrapping_add(-161 as i32 as i64 as u64)
    stxdw [r10-0x58], r1                    
    mov64 r8, r10                                   r8 = r10
    add64 r8, -120                                  r8 += -120   ///  r8 = r8.wrapping_add(-120 as i32 as i64 as u64)
lbb_13936:
    mov64 r2, r10                                   r2 = r10
    add64 r2, -64                                   r2 += -64   ///  r2 = r2.wrapping_add(-64 as i32 as i64 as u64)
    mov64 r1, r8                                    r1 = r8
    call function_21571                     
    mov64 r1, r8                                    r1 = r8
    call function_323                       
    ja lbb_14311                                    if true { pc += 368 }
lbb_13943:
    mov64 r1, 33                                    r1 = 33 as i32 as i64 as u64
    jgt r1, r8, lbb_14308                           if r1 > r8 { pc += 363 }
    ldxdw r0, [r4+0x7]                      
    ldxb r1, [r4+0xf]                       
    stxb [r10-0x38], r1                     
    stxdw [r10-0x40], r0                    
    mov64 r1, r8                                    r1 = r8
    add64 r1, -33                                   r1 += -33   ///  r1 = r1.wrapping_add(-33 as i32 as i64 as u64)
    mov64 r2, 32                                    r2 = 32 as i32 as i64 as u64
    jgt r2, r1, lbb_14308                           if r2 > r1 { pc += 355 }
    stxdw [r10-0x110], r9                   
    ldxdw r1, [r10-0x3f]                    
    stxdw [r10-0x148], r1                   
    ldxdw r2, [r4+0x27]                     
    ldxb r1, [r4+0x2f]                      
    stxb [r10-0x38], r1                     
    ldxh r9, [r4+0x25]                      
    ldxw r1, [r4+0x21]                      
    stxdw [r10-0x40], r2                    
    ldxdw r3, [r10-0x3f]                    
    stxdw [r10-0x168], r3                   
    ldxb r3, [r4+0x40]                      
    stxb [r10-0x90], r3                     
    ldxdw r3, [r4+0x38]                     
    stxdw [r10-0x98], r3                    
    ldxdw r3, [r4+0x30]                     
    stxdw [r10-0xa0], r3                    
    lsh64 r1, 8                                     r1 <<= 8   ///  r1 = r1.wrapping_shl(8)
    lsh64 r9, 40                                    r9 <<= 40   ///  r9 = r9.wrapping_shl(40)
    or64 r9, r1                                     r9 |= r1   ///  r9 = r9.or(r1)
    ldxb r1, [r4+0x20]                      
    or64 r9, r1                                     r9 |= r1   ///  r9 = r9.or(r1)
    lsh64 r0, 8                                     r0 <<= 8   ///  r0 = r0.wrapping_shl(8)
    ldxb r1, [r4+0x6]                       
    or64 r0, r1                                     r0 |= r1   ///  r0 = r0.or(r1)
    stxdw [r10-0x130], r0                   
    lsh64 r2, 56                                    r2 <<= 56   ///  r2 = r2.wrapping_shl(56)
    or64 r9, r2                                     r9 |= r2   ///  r9 = r9.or(r2)
    stxdw [r10-0x158], r9                   
    ldxb r1, [r4+0x1b]                      
    lsh64 r1, 16                                    r1 <<= 16   ///  r1 = r1.wrapping_shl(16)
    ldxh r9, [r4+0x19]                      
    or64 r9, r1                                     r9 |= r1   ///  r9 = r9.or(r1)
    add64 r8, -65                                   r8 += -65   ///  r8 = r8.wrapping_add(-65 as i32 as i64 as u64)
    ldxdw r2, [r10-0x168]                   
    mov64 r1, r2                                    r1 = r2
    rsh64 r1, 40                                    r1 >>= 40   ///  r1 = r1.wrapping_shr(40)
    stxdw [r10-0x180], r1                   
    mov64 r1, r2                                    r1 = r2
    rsh64 r1, 32                                    r1 >>= 32   ///  r1 = r1.wrapping_shr(32)
    stxdw [r10-0x170], r1                   
    mov64 r1, r2                                    r1 = r2
    rsh64 r1, 8                                     r1 >>= 8   ///  r1 = r1.wrapping_shr(8)
    stxdw [r10-0x178], r1                   
    ldxw r1, [r4+0x1c]                      
    stxdw [r10-0x160], r1                   
    ldxb r1, [r4+0x18]                      
    stxdw [r10-0x150], r1                   
    ldxw r1, [r4+0x14]                      
    stxdw [r10-0x120], r1                   
    ldxh r1, [r4+0x12]                      
    stxdw [r10-0x118], r1                   
    ldxh r1, [r4+0x10]                      
    stxdw [r10-0x140], r1                   
    ldxw r1, [r4+0x2]                       
    stxdw [r10-0x128], r1                   
    ldxb r1, [r4+0x1]                       
    stxdw [r10-0x138], r1                   
    mov64 r3, r8                                    r3 = r8
    ja lbb_14180                                    if true { pc += 167 }
lbb_14013:
    jeq r3, 0, lbb_14308                            if r3 == (0 as i32 as i64 as u64) { pc += 294 }
    ldxb r2, [r4+0x1]                       
    stxb [r10-0x59], r2                     
    mov64 r1, 3                                     r1 = 3 as i32 as i64 as u64
    jgt r1, r2, lbb_14075                           if r1 > r2 { pc += 57 }
    ja lbb_13855                                    if true { pc += -164 }
lbb_14019:
    jeq r3, 0, lbb_14308                            if r3 == (0 as i32 as i64 as u64) { pc += 288 }
    ldxb r2, [r4+0x1]                       
    stxb [r10-0x88], r2                     
    mov64 r1, 2                                     r1 = 2 as i32 as i64 as u64
    jgt r1, r2, lbb_14077                           if r1 > r2 { pc += 53 }
    ja lbb_13740                                    if true { pc += -285 }
lbb_14025:
    mov64 r1, 3                                     r1 = 3 as i32 as i64 as u64
    jgt r1, r8, lbb_14308                           if r1 > r8 { pc += 281 }
    mov64 r2, r8                                    r2 = r8
    add64 r2, -3                                    r2 += -3   ///  r2 = r2.wrapping_add(-3 as i32 as i64 as u64)
    jeq r2, 0, lbb_14308                            if r2 == (0 as i32 as i64 as u64) { pc += 278 }
    ldxh r1, [r4+0x1]                       
    stxdw [r10-0x140], r1                   
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    stxdw [r10-0x118], r1                   
    mov64 r3, r8                                    r3 = r8
    add64 r3, -4                                    r3 += -4   ///  r3 = r3.wrapping_add(-4 as i32 as i64 as u64)
    mov64 r1, r4                                    r1 = r4
    add64 r1, 4                                     r1 += 4   ///  r1 = r1.wrapping_add(4 as i32 as i64 as u64)
    stxdw [r10-0x128], r1                   
    ldxb r0, [r4+0x3]                       
    stxb [r10-0x88], r0                     
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    stxdw [r10-0x120], r1                   
    jeq r0, 0, lbb_14055                            if r0 == (0 as i32 as i64 as u64) { pc += 11 }
    jne r0, 1, lbb_14239                            if r0 != (1 as i32 as i64 as u64) { pc += 194 }
    mov64 r1, 3                                     r1 = 3 as i32 as i64 as u64
    jgt r1, r2, lbb_14308                           if r1 > r2 { pc += 261 }
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    stxdw [r10-0x118], r1                   
    ldxh r1, [r4+0x4]                       
    stxdw [r10-0x120], r1                   
    add64 r8, -6                                    r8 += -6   ///  r8 = r8.wrapping_add(-6 as i32 as i64 as u64)
    add64 r4, 6                                     r4 += 6   ///  r4 = r4.wrapping_add(6 as i32 as i64 as u64)
    stxdw [r10-0x128], r4                   
    mov64 r3, r8                                    r3 = r8
lbb_14055:
    ldxdw r4, [r10-0x128]                   
    ldxdw r1, [r10-0x120]                   
    stxdw [r10-0x120], r1                   
    ldxdw r2, [r10-0x118]                   
    stxdw [r10-0x118], r2                   
    jgt r3, 7, lbb_14062                            if r3 > (7 as i32 as i64 as u64) { pc += 1 }
    ja lbb_14308                                    if true { pc += 246 }
lbb_14062:
    stxdw [r10-0x110], r9                   
    ldxdw r1, [r4+0x0]                      
    stxdw [r10-0x148], r1                   
    add64 r3, -8                                    r3 += -8   ///  r3 = r3.wrapping_add(-8 as i32 as i64 as u64)
    ja lbb_14081                                    if true { pc += 14 }
lbb_14067:
    jeq r3, 0, lbb_14308                            if r3 == (0 as i32 as i64 as u64) { pc += 240 }
    ldxb r2, [r4+0x1]                       
    stxb [r10-0x88], r2                     
    mov64 r1, 2                                     r1 = 2 as i32 as i64 as u64
    jgt r1, r2, lbb_14082                           if r1 > r2 { pc += 10 }
    ja lbb_13740                                    if true { pc += -333 }
lbb_14073:
    jgt r8, 33, lbb_14143                           if r8 > (33 as i32 as i64 as u64) { pc += 69 }
    ja lbb_14308                                    if true { pc += 233 }
lbb_14075:
    jgt r8, 33, lbb_14145                           if r8 > (33 as i32 as i64 as u64) { pc += 69 }
    ja lbb_14308                                    if true { pc += 231 }
lbb_14077:
    stxdw [r10-0x138], r2                   
    stxdw [r10-0x110], r9                   
    add64 r8, -2                                    r8 += -2   ///  r8 = r8.wrapping_add(-2 as i32 as i64 as u64)
    mov64 r3, r8                                    r3 = r8
lbb_14081:
    ja lbb_14180                                    if true { pc += 98 }
lbb_14082:
    jeq r8, 2, lbb_14308                            if r8 == (2 as i32 as i64 as u64) { pc += 225 }
    stxdw [r10-0x138], r2                   
    ldxb r2, [r4+0x2]                       
    stxb [r10-0x88], r2                     
    jgt r1, r2, lbb_14247                           if r1 > r2 { pc += 160 }
    ja lbb_13740                                    if true { pc += -348 }
lbb_14088:
    ldxdw r1, [r6+0x2898]                   
    ldxdw r2, [r6+0x58d0]                   
    jne r2, r1, lbb_13693                           if r2 != r1 { pc += -398 }
    ldxdw r1, [r6+0x28a0]                   
    ldxdw r2, [r6+0x58d8]                   
    jne r2, r1, lbb_13693                           if r2 != r1 { pc += -401 }
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    ldxdw r2, [r6+0x28a8]                   
    ldxdw r3, [r6+0x58e0]                   
    jne r3, r2, lbb_13693                           if r3 != r2 { pc += -405 }
lbb_14098:
    jne r1, 0, lbb_14125                            if r1 != (0 as i32 as i64 as u64) { pc += 26 }
    ldxh r1, [r6+0x28d4]                    
    ldxh r2, [r6+0x55c1]                    
    jne r2, r1, lbb_14234                           if r2 != r1 { pc += 132 }
    mov64 r1, r6                                    r1 = r6
    add64 r1, 10432                                 r1 += 10432   ///  r1 = r1.wrapping_add(10432 as i32 as i64 as u64)
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
    stxdw [r1+0x8], r2                      
    stxdw [r1+0x0], r2                      
    ldxdw r1, [r6+0x2930]                   
    ldxdw r2, [r6+0x55c8]                   
    jgt r2, r1, lbb_14111                           if r2 > r1 { pc += 1 }
    ja lbb_14252                                    if true { pc += 141 }
lbb_14111:
    mov64 r1, r6                                    r1 = r6
    add64 r1, 10544                                 r1 += 10544   ///  r1 = r1.wrapping_add(10544 as i32 as i64 as u64)
    mov64 r2, r6                                    r2 = r6
    add64 r2, 21960                                 r2 += 21960   ///  r2 = r2.wrapping_add(21960 as i32 as i64 as u64)
    mov64 r3, 408                                   r3 = 408 as i32 as i64 as u64
    call function_30349                     
    mov64 r1, r6                                    r1 = r6
    add64 r1, 11072                                 r1 += 11072   ///  r1 = r1.wrapping_add(11072 as i32 as i64 as u64)
    add64 r6, 22368                                 r6 += 22368   ///  r6 = r6.wrapping_add(22368 as i32 as i64 as u64)
    mov64 r2, r6                                    r2 = r6
    mov64 r3, 360                                   r3 = 360 as i32 as i64 as u64
    call function_30349                     
    mov64 r0, 0                                     r0 = 0 as i32 as i64 as u64
    ja lbb_13845                                    if true { pc += -280 }
lbb_14125:
    lddw r1, 0x8000000000000016                     r1 load str located at -9223372036854775786
    stxdw [r10-0xf0], r1                    
    ja lbb_13842                                    if true { pc += -287 }
lbb_14129:
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    stxdw [r10-0x20], r1                    
    lddw r1, 0x1000413f0 --> b"\x00\x00\x00\x00\xf8\xeb\x03\x00\x18\x00\x00\x00\x00\x00\x00\x00\x00\x00\…        r1 load str located at 4295234544
    stxdw [r10-0x40], r1                    
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    stxdw [r10-0x38], r1                    
    stxdw [r10-0x28], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -16                                   r1 += -16   ///  r1 = r1.wrapping_add(-16 as i32 as i64 as u64)
    stxdw [r10-0x30], r1                    
    lddw r1, 0x100000ef8 --> b"a#4\x00\x00\x00\x00\x00\xbf4\x00\x00\x00\x00\x00\x00W\x04\x00\x00\x10\x00…        r1 load str located at 4294971128
    ja lbb_13753                                    if true { pc += -390 }
lbb_14143:
    stxdw [r10-0x138], r2                   
    ja lbb_14147                                    if true { pc += 2 }
lbb_14145:
    stxdw [r10-0x138], r2                   
    stxdw [r10-0x110], r9                   
lbb_14147:
    ldxdw r1, [r4+0x8]                      
    ldxb r2, [r4+0x10]                      
    stxb [r10-0x38], r2                     
    ldxh r2, [r4+0x6]                       
    stxdw [r10-0x130], r2                   
    ldxw r2, [r4+0x2]                       
    stxdw [r10-0x128], r2                   
    stxdw [r10-0x40], r1                    
    ldxdw r2, [r10-0x3f]                    
    ldxb r3, [r4+0x11]                      
    stxb [r10-0x7f], r3                     
    ldxh r3, [r4+0x20]                      
    stxdw [r10-0x158], r3                   
    ldxw r3, [r4+0x1c]                      
    stxdw [r10-0x160], r3                   
    ldxb r3, [r4+0x18]                      
    stxdw [r10-0x150], r3                   
    ldxw r3, [r4+0x14]                      
    stxdw [r10-0x120], r3                   
    ldxh r3, [r4+0x12]                      
    stxdw [r10-0x118], r3                   
    ldxh r9, [r4+0x19]                      
    ldxb r3, [r4+0x1b]                      
    stxdw [r10-0x87], r2                    
    stxb [r10-0x88], r1                     
    lsh64 r3, 16                                    r3 <<= 16   ///  r3 = r3.wrapping_shl(16)
    or64 r9, r3                                     r9 |= r3   ///  r9 = r9.or(r3)
    add64 r8, -34                                   r8 += -34   ///  r8 = r8.wrapping_add(-34 as i32 as i64 as u64)
    ldxh r1, [r10-0x80]                     
    stxdw [r10-0x140], r1                   
    ldxdw r1, [r10-0x88]                    
    stxdw [r10-0x148], r1                   
lbb_14179:
    mov64 r3, r8                                    r3 = r8
lbb_14180:
    jeq r3, 0, lbb_14183                            if r3 == (0 as i32 as i64 as u64) { pc += 2 }
    call function_359                       
    ja lbb_14311                                    if true { pc += 128 }
lbb_14183:
    ldxdw r1, [r10-0x90]                    
    stxdw [r10-0xb0], r1                    
    ldxdw r1, [r10-0x98]                    
    stxdw [r10-0xb8], r1                    
    ldxdw r1, [r10-0xa0]                    
    stxdw [r10-0xc0], r1                    
    ldxdw r1, [r10-0x170]                   
    stxb [r10-0xc4], r1                     
    ldxdw r1, [r10-0x168]                   
    stxb [r10-0xc8], r1                     
    ldxdw r1, [r10-0x158]                   
    stxdw [r10-0xd0], r1                    
    ldxdw r1, [r10-0x160]                   
    stxw [r10-0xd4], r1                     
    ldxdw r1, [r10-0x150]                   
    stxb [r10-0xd8], r1                     
    ldxdw r1, [r10-0x120]                   
    stxw [r10-0xdc], r1                     
    ldxdw r1, [r10-0x118]                   
    stxh [r10-0xde], r1                     
    ldxdw r1, [r10-0x140]                   
    stxh [r10-0xe0], r1                     
    ldxdw r1, [r10-0x148]                   
    stxdw [r10-0xe8], r1                    
    ldxdw r1, [r10-0x130]                   
    stxh [r10-0xea], r1                     
    ldxdw r1, [r10-0x128]                   
    stxw [r10-0xee], r1                     
    ldxdw r1, [r10-0x138]                   
    stxb [r10-0xef], r1                     
    stxb [r10-0xf0], r5                     
    ldxdw r1, [r10-0x180]                   
    stxh [r10-0xc3], r1                     
    rsh64 r1, 16                                    r1 >>= 16   ///  r1 = r1.wrapping_shr(16)
    stxb [r10-0xc1], r1                     
    ldxdw r1, [r10-0x178]                   
    stxh [r10-0xc7], r1                     
    rsh64 r1, 16                                    r1 >>= 16   ///  r1 = r1.wrapping_shr(16)
    stxb [r10-0xc5], r1                     
    stxh [r10-0xd7], r9                     
    rsh64 r9, 16                                    r9 >>= 16   ///  r9 = r9.wrapping_shr(16)
    stxb [r10-0xd5], r9                     
    mov64 r1, r10                                   r1 = r10
    add64 r1, -64                                   r1 += -64   ///  r1 = r1.wrapping_add(-64 as i32 as i64 as u64)
    mov64 r5, r10                                   r5 = r10
    add64 r5, -240                                  r5 += -240   ///  r5 = r5.wrapping_add(-240 as i32 as i64 as u64)
    ldxdw r2, [r10-0x110]                   
    mov64 r3, r7                                    r3 = r7
    mov64 r4, r6                                    r4 = r6
    call function_2849                      
    ja lbb_14315                                    if true { pc += 81 }
lbb_14234:
    lddw r1, 0x8000000000000000                     r1 load str located at -9223372036854775808
    stxdw [r10-0xf0], r1                    
    mov64 r1, 26                                    r1 = 26 as i32 as i64 as u64
    ja lbb_13841                                    if true { pc += -398 }
lbb_14239:
    stxdw [r10-0x20], r1                    
    mov64 r1, 2                                     r1 = 2 as i32 as i64 as u64
    stxdw [r10-0x38], r1                    
    lddw r1, 0x100040e88 --> b"\x00\x00\x00\x00\xb7\xe6\x03\x00\x1f\x00\x00\x00\x00\x00\x00\x00\x00\x00\…        r1 load str located at 4295233160
    stxdw [r10-0x40], r1                    
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    ja lbb_13747                                    if true { pc += -500 }
lbb_14247:
    jeq r8, 3, lbb_14308                            if r8 == (3 as i32 as i64 as u64) { pc += 60 }
    ldxb r0, [r4+0x3]                       
    stxb [r10-0x88], r0                     
    jgt r1, r0, lbb_14294                           if r1 > r0 { pc += 43 }
    ja lbb_13740                                    if true { pc += -512 }
lbb_14252:
    lddw r1, 0x8000000000000000                     r1 load str located at -9223372036854775808
    stxdw [r10-0xf0], r1                    
    mov64 r1, 20                                    r1 = 20 as i32 as i64 as u64
    ja lbb_13841                                    if true { pc += -416 }
lbb_14257:
    stxdw [r10-0x170], r3                   
    mov64 r1, r8                                    r1 = r8
    add64 r1, -10                                   r1 += -10   ///  r1 = r1.wrapping_add(-10 as i32 as i64 as u64)
    mov64 r3, 4                                     r3 = 4 as i32 as i64 as u64
    jgt r3, r1, lbb_14308                           if r3 > r1 { pc += 46 }
    mov64 r1, r8                                    r1 = r8
    add64 r1, -14                                   r1 += -14   ///  r1 = r1.wrapping_add(-14 as i32 as i64 as u64)
    mov64 r3, 24                                    r3 = 24 as i32 as i64 as u64
    jgt r3, r1, lbb_14308                           if r3 > r1 { pc += 42 }
    stxdw [r10-0x110], r9                   
    lsh64 r0, 8                                     r0 <<= 8   ///  r0 = r0.wrapping_shl(8)
    ldxdw r1, [r10-0x168]                   
    and64 r1, 65280                                 r1 &= 65280   ///  r1 = r1.and(65280)
    rsh64 r1, 8                                     r1 >>= 8   ///  r1 = r1.wrapping_shr(8)
    or64 r0, r1                                     r0 |= r1   ///  r0 = r0.or(r1)
    stxdw [r10-0x178], r0                   
    ldxw r1, [r4+0xa]                       
    lsh64 r1, 32                                    r1 <<= 32   ///  r1 = r1.wrapping_shl(32)
    or64 r1, r2                                     r1 |= r2   ///  r1 = r1.or(r2)
    stxdw [r10-0x158], r1                   
    ldxdw r1, [r4+0xe]                      
    stxdw [r10-0x148], r1                   
    ldxw r1, [r4+0x22]                      
    stxdw [r10-0x160], r1                   
    add64 r8, -38                                   r8 += -38   ///  r8 = r8.wrapping_add(-38 as i32 as i64 as u64)
    ldxdw r2, [r4+0x16]                     
    mov64 r1, r2                                    r1 = r2
    rsh64 r1, 32                                    r1 >>= 32   ///  r1 = r1.wrapping_shr(32)
    stxdw [r10-0x120], r1                   
    stxdw [r10-0x140], r2                   
    mov64 r1, r2                                    r1 = r2
    rsh64 r1, 16                                    r1 >>= 16   ///  r1 = r1.wrapping_shr(16)
    stxdw [r10-0x118], r1                   
    ldxw r9, [r4+0x1e]                      
    stxdw [r10-0x150], r9                   
    rsh64 r9, 8                                     r9 >>= 8   ///  r9 = r9.wrapping_shr(8)
    ja lbb_14179                                    if true { pc += -115 }
lbb_14294:
    jeq r8, 4, lbb_14308                            if r8 == (4 as i32 as i64 as u64) { pc += 13 }
    ldxb r3, [r4+0x4]                       
    stxb [r10-0x88], r3                     
    jgt r1, r3, lbb_14299                           if r1 > r3 { pc += 1 }
    ja lbb_13740                                    if true { pc += -559 }
lbb_14299:
    stxdw [r10-0x110], r9                   
    jeq r8, 5, lbb_14308                            if r8 == (5 as i32 as i64 as u64) { pc += 7 }
    ldxb r4, [r4+0x5]                       
    stxb [r10-0x88], r4                     
    jgt r1, r4, lbb_14376                           if r1 > r4 { pc += 72 }
    ja lbb_13740                                    if true { pc += -565 }
lbb_14305:
    mov64 r1, r8                                    r1 = r8
    add64 r1, -10                                   r1 += -10   ///  r1 = r1.wrapping_add(-10 as i32 as i64 as u64)
    jgt r1, 23, lbb_14353                           if r1 > (23 as i32 as i64 as u64) { pc += 45 }
lbb_14308:
    lddw r1, 0x100040d80 --> b"\x00\x00\x00\x00\x99\xe5\x03\x00\x1b\x00\x00\x00\x00\x00\x00\x00%\x00\x00…        r1 load str located at 4295232896
    call function_20446                     
lbb_14311:
    mov64 r2, r0                                    r2 = r0
    mov64 r1, r10                                   r1 = r10
    add64 r1, -64                                   r1 += -64   ///  r1 = r1.wrapping_add(-64 as i32 as i64 as u64)
    call function_18093                     
lbb_14315:
    mov64 r0, 0                                     r0 = 0 as i32 as i64 as u64
    ldxdw r1, [r10-0x40]                    
    lddw r2, 0x800000000000001a                     r2 load str located at -9223372036854775782
    jeq r1, r2, lbb_14329                           if r1 == r2 { pc += 9 }
lbb_14320:
    ldxdw r1, [r10-0x30]                    
    stxdw [r10-0xf8], r1                    
    ldxdw r1, [r10-0x38]                    
    stxdw [r10-0x100], r1                   
    ldxdw r1, [r10-0x40]                    
    stxdw [r10-0x108], r1                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -264                                  r1 += -264   ///  r1 = r1.wrapping_add(-264 as i32 as i64 as u64)
    call function_17811                     
lbb_14329:
    jeq r6, 0, lbb_14335                            if r6 == (0 as i32 as i64 as u64) { pc += 5 }
    add64 r7, 16                                    r7 += 16   ///  r7 = r7.wrapping_add(16 as i32 as i64 as u64)
    ja lbb_14336                                    if true { pc += 4 }
lbb_14332:
    add64 r7, 48                                    r7 += 48   ///  r7 = r7.wrapping_add(48 as i32 as i64 as u64)
    add64 r6, -1                                    r6 += -1   ///  r6 = r6.wrapping_add(-1 as i32 as i64 as u64)
    jne r6, 0, lbb_14336                            if r6 != (0 as i32 as i64 as u64) { pc += 1 }
lbb_14335:
    ja lbb_13845                                    if true { pc += -491 }
lbb_14336:
    ldxdw r1, [r7+0x0]                      
    ldxdw r2, [r7-0x8]                      
    ldxdw r3, [r2+0x0]                      
    add64 r3, -1                                    r3 += -1   ///  r3 = r3.wrapping_add(-1 as i32 as i64 as u64)
    stxdw [r2+0x0], r3                      
    jne r3, 0, lbb_14345                            if r3 != (0 as i32 as i64 as u64) { pc += 3 }
    ldxdw r3, [r2+0x8]                      
    add64 r3, -1                                    r3 += -1   ///  r3 = r3.wrapping_add(-1 as i32 as i64 as u64)
    stxdw [r2+0x8], r3                      
lbb_14345:
    ldxdw r2, [r1+0x0]                      
    add64 r2, -1                                    r2 += -1   ///  r2 = r2.wrapping_add(-1 as i32 as i64 as u64)
    stxdw [r1+0x0], r2                      
    jne r2, 0, lbb_14332                            if r2 != (0 as i32 as i64 as u64) { pc += -17 }
    ldxdw r2, [r1+0x8]                      
    add64 r2, -1                                    r2 += -1   ///  r2 = r2.wrapping_add(-1 as i32 as i64 as u64)
    stxdw [r1+0x8], r2                      
    ja lbb_14332                                    if true { pc += -21 }
lbb_14353:
    stxdw [r10-0x168], r0                   
    stxdw [r10-0x110], r9                   
    lsh64 r3, 32                                    r3 <<= 32   ///  r3 = r3.wrapping_shl(32)
    or64 r3, r2                                     r3 |= r2   ///  r3 = r3.or(r2)
    stxdw [r10-0x158], r3                   
    ldxdw r1, [r4+0xa]                      
    stxdw [r10-0x148], r1                   
    ldxw r1, [r4+0x1e]                      
    stxdw [r10-0x160], r1                   
    add64 r8, -34                                   r8 += -34   ///  r8 = r8.wrapping_add(-34 as i32 as i64 as u64)
    ldxdw r2, [r4+0x12]                     
    mov64 r1, r2                                    r1 = r2
    rsh64 r1, 32                                    r1 >>= 32   ///  r1 = r1.wrapping_shr(32)
    stxdw [r10-0x120], r1                   
    stxdw [r10-0x140], r2                   
    mov64 r1, r2                                    r1 = r2
    rsh64 r1, 16                                    r1 >>= 16   ///  r1 = r1.wrapping_shr(16)
    stxdw [r10-0x118], r1                   
    ldxw r9, [r4+0x1a]                      
    stxdw [r10-0x150], r9                   
    rsh64 r9, 8                                     r9 >>= 8   ///  r9 = r9.wrapping_shr(8)
    mov64 r3, r8                                    r3 = r8
    ja lbb_14081                                    if true { pc += -295 }
lbb_14376:
    lsh64 r0, 8                                     r0 <<= 8   ///  r0 = r0.wrapping_shl(8)
    or64 r0, r2                                     r0 |= r2   ///  r0 = r0.or(r2)
    lsh64 r3, 16                                    r3 <<= 16   ///  r3 = r3.wrapping_shl(16)
    or64 r0, r3                                     r0 |= r3   ///  r0 = r0.or(r3)
    lsh64 r4, 24                                    r4 <<= 24   ///  r4 = r4.wrapping_shl(24)
    or64 r0, r4                                     r0 |= r4   ///  r0 = r0.or(r4)
    stxdw [r10-0x128], r0                   
    add64 r8, -6                                    r8 += -6   ///  r8 = r8.wrapping_add(-6 as i32 as i64 as u64)
    ja lbb_13817                                    if true { pc += -568 }

function_14385:
    lddw r3, 0x300000000                            r3 load str located at 12884901888
    ldxdw r3, [r3+0x0]                      
    lddw r4, 0x300008000                            r4 load str located at 12884934656
    jeq r3, 0, lbb_14392                            if r3 == (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r4, r3                                    r4 = r3
lbb_14392:
    mov64 r3, r4                                    r3 = r4
    sub64 r3, r1                                    r3 -= r1   ///  r3 = r3.wrapping_sub(r1)
    mov64 r0, 0                                     r0 = 0 as i32 as i64 as u64
    mov64 r5, 1                                     r5 = 1 as i32 as i64 as u64
    jgt r3, r4, lbb_14398                           if r3 > r4 { pc += 1 }
    mov64 r5, 0                                     r5 = 0 as i32 as i64 as u64
lbb_14398:
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    jne r5, 0, lbb_14401                            if r5 != (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r1, r3                                    r1 = r3
lbb_14401:
    neg64 r2                                        r2 = -r2   ///  r2 = (r2 as i64).wrapping_neg() as u64
    and64 r1, r2                                    r1 &= r2   ///  r1 = r1.and(r2)
    lddw r2, 0x300000008                            r2 load str located at 12884901896
    jgt r2, r1, lbb_14410                           if r2 > r1 { pc += 4 }
    lddw r2, 0x300000000                            r2 load str located at 12884901888
    stxdw [r2+0x0], r1                      
    mov64 r0, r1                                    r0 = r1
lbb_14410:
    exit                                    

function_14411:
    exit                                    

function_14412:
    mov64 r5, r2                                    r5 = r2
    mov64 r2, r1                                    r2 = r1
    lddw r1, 0x300000000                            r1 load str located at 12884901888
    ldxdw r1, [r1+0x0]                      
    lddw r6, 0x300008000                            r6 load str located at 12884934656
    jeq r1, 0, lbb_14421                            if r1 == (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r6, r1                                    r6 = r1
lbb_14421:
    mov64 r1, r6                                    r1 = r6
    sub64 r1, r4                                    r1 -= r4   ///  r1 = r1.wrapping_sub(r4)
    mov64 r0, 0                                     r0 = 0 as i32 as i64 as u64
    mov64 r7, 1                                     r7 = 1 as i32 as i64 as u64
    jgt r1, r6, lbb_14427                           if r1 > r6 { pc += 1 }
    mov64 r7, 0                                     r7 = 0 as i32 as i64 as u64
lbb_14427:
    mov64 r6, 0                                     r6 = 0 as i32 as i64 as u64
    jne r7, 0, lbb_14430                            if r7 != (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r6, r1                                    r6 = r1
lbb_14430:
    neg64 r3                                        r3 = -r3   ///  r3 = (r3 as i64).wrapping_neg() as u64
    and64 r6, r3                                    r6 &= r3   ///  r6 = r6.and(r3)
    lddw r1, 0x300000008                            r1 load str located at 12884901896
    jgt r1, r6, lbb_14444                           if r1 > r6 { pc += 9 }
    lddw r1, 0x300000000                            r1 load str located at 12884901888
    stxdw [r1+0x0], r6                      
    jgt r4, r5, lbb_14440                           if r4 > r5 { pc += 1 }
    mov64 r5, r4                                    r5 = r4
lbb_14440:
    mov64 r1, r6                                    r1 = r6
    mov64 r3, r5                                    r3 = r5
    call function_30349                     
    mov64 r0, r6                                    r0 = r6
lbb_14444:
    exit                                    

custom_panic:
    stxdw [r10-0x60], r1                    
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    stxdw [r10-0x20], r1                    
    lddw r1, 0x10003e790 --> b"\x01\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00Permissio…        r1 load str located at 4295223184
    stxdw [r10-0x40], r1                    
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    stxdw [r10-0x38], r1                    
    stxdw [r10-0x28], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -16                                   r1 += -16   ///  r1 = r1.wrapping_add(-16 as i32 as i64 as u64)
    stxdw [r10-0x30], r1                    
    lddw r1, 0x100000eb8 --> b"y\x11\x00\x00\x00\x00\x00\x00\x85\x10\x00\x00\xafb\x00\x00\x95\x00\x00\x0…        r1 load str located at 4294971064
    stxdw [r10-0x8], r1                     
    mov64 r1, r10                                   r1 = r10
    add64 r1, -96                                   r1 += -96   ///  r1 = r1.wrapping_add(-96 as i32 as i64 as u64)
    stxdw [r10-0x10], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -88                                   r1 += -88   ///  r1 = r1.wrapping_add(-88 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -64                                   r2 += -64   ///  r2 = r2.wrapping_add(-64 as i32 as i64 as u64)
    call function_21571                     
    ldxdw r1, [r10-0x50]                    
    ldxdw r2, [r10-0x48]                    
    syscall [invalid]                       
    exit                                    

function_14472:
    call function_21390                     
    exit                                    

function_14474:
    mov64 r7, r3                                    r7 = r3
    mov64 r8, r2                                    r8 = r2
    mov64 r6, r1                                    r6 = r1
    jeq r8, 0, lbb_14485                            if r8 == (0 as i32 as i64 as u64) { pc += 7 }
    ldxdw r1, [r4+0x8]                      
    jeq r1, 0, lbb_14502                            if r1 == (0 as i32 as i64 as u64) { pc += 22 }
    ldxdw r2, [r4+0x10]                     
    jne r2, 0, lbb_14488                            if r2 != (0 as i32 as i64 as u64) { pc += 6 }
    jne r7, 0, lbb_14504                            if r7 != (0 as i32 as i64 as u64) { pc += 21 }
lbb_14483:
    mov64 r0, r8                                    r0 = r8
    ja lbb_14507                                    if true { pc += 22 }
lbb_14485:
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    stxdw [r6+0x8], r1                      
    ja lbb_14500                                    if true { pc += 12 }
lbb_14488:
    ldxdw r1, [r4+0x0]                      
    mov64 r3, r8                                    r3 = r8
    mov64 r4, r7                                    r4 = r7
    call function_14412                     
    mov64 r1, r6                                    r1 = r6
    add64 r1, 16                                    r1 += 16   ///  r1 = r1.wrapping_add(16 as i32 as i64 as u64)
    mov64 r2, r6                                    r2 = r6
    add64 r2, 8                                     r2 += 8   ///  r2 = r2.wrapping_add(8 as i32 as i64 as u64)
    jeq r0, 0, lbb_14498                            if r0 == (0 as i32 as i64 as u64) { pc += 1 }
    ja lbb_14512                                    if true { pc += 14 }
lbb_14498:
    stxdw [r2+0x0], r8                      
    stxdw [r1+0x0], r7                      
lbb_14500:
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    ja lbb_14515                                    if true { pc += 13 }
lbb_14502:
    jne r7, 0, lbb_14504                            if r7 != (0 as i32 as i64 as u64) { pc += 1 }
    ja lbb_14483                                    if true { pc += -21 }
lbb_14504:
    mov64 r1, r7                                    r1 = r7
    mov64 r2, r8                                    r2 = r8
    call function_14385                     
lbb_14507:
    mov64 r1, r6                                    r1 = r6
    add64 r1, 16                                    r1 += 16   ///  r1 = r1.wrapping_add(16 as i32 as i64 as u64)
    mov64 r2, r6                                    r2 = r6
    add64 r2, 8                                     r2 += 8   ///  r2 = r2.wrapping_add(8 as i32 as i64 as u64)
    jeq r0, 0, lbb_14498                            if r0 == (0 as i32 as i64 as u64) { pc += -14 }
lbb_14512:
    stxdw [r2+0x0], r0                      
    stxdw [r1+0x0], r7                      
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
lbb_14515:
    stxdw [r6+0x0], r1                      
    exit                                    

function_14517:
    mov64 r6, r1                                    r6 = r1
    mov64 r4, r2                                    r4 = r2
    add64 r4, r3                                    r4 += r3   ///  r4 = r4.wrapping_add(r3)
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    mov64 r3, 1                                     r3 = 1 as i32 as i64 as u64
    jgt r2, r4, lbb_14524                           if r2 > r4 { pc += 1 }
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
lbb_14524:
    and64 r3, 1                                     r3 &= 1   ///  r3 = r3.and(1)
    jne r3, 0, lbb_14553                            if r3 != (0 as i32 as i64 as u64) { pc += 27 }
    ldxdw r1, [r6+0x0]                      
    mov64 r7, r1                                    r7 = r1
    lsh64 r7, 1                                     r7 <<= 1   ///  r7 = r7.wrapping_shl(1)
    jgt r7, r4, lbb_14531                           if r7 > r4 { pc += 1 }
    mov64 r7, r4                                    r7 = r4
lbb_14531:
    jgt r7, 8, lbb_14533                            if r7 > (8 as i32 as i64 as u64) { pc += 1 }
    mov64 r7, 8                                     r7 = 8 as i32 as i64 as u64
lbb_14533:
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
    mov64 r2, r7                                    r2 = r7
    xor64 r2, -1                                    r2 ^= -1   ///  r2 = r2.xor(-1)
    rsh64 r2, 63                                    r2 >>= 63   ///  r2 = r2.wrapping_shr(63)
    jeq r1, 0, lbb_14542                            if r1 == (0 as i32 as i64 as u64) { pc += 4 }
    ldxdw r3, [r6+0x8]                      
    stxdw [r10-0x8], r1                     
    stxdw [r10-0x18], r3                    
    mov64 r3, 1                                     r3 = 1 as i32 as i64 as u64
lbb_14542:
    stxdw [r10-0x10], r3                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -48                                   r1 += -48   ///  r1 = r1.wrapping_add(-48 as i32 as i64 as u64)
    mov64 r4, r10                                   r4 = r10
    add64 r4, -24                                   r4 += -24   ///  r4 = r4.wrapping_add(-24 as i32 as i64 as u64)
    mov64 r3, r7                                    r3 = r7
    call function_14474                     
    ldxdw r1, [r10-0x30]                    
    jeq r1, 0, lbb_14554                            if r1 == (0 as i32 as i64 as u64) { pc += 3 }
    ldxdw r2, [r10-0x20]                    
    ldxdw r1, [r10-0x28]                    
lbb_14553:
    call function_21549                     
lbb_14554:
    ldxdw r1, [r10-0x28]                    
    stxdw [r6+0x0], r7                      
    stxdw [r6+0x8], r1                      
    exit                                    

function_14558:
    mov64 r6, r1                                    r6 = r1
    ldxdw r4, [r6+0x0]                      
    mov64 r3, r4                                    r3 = r4
    add64 r3, 1                                     r3 += 1   ///  r3 = r3.wrapping_add(1 as i32 as i64 as u64)
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    mov64 r5, 1                                     r5 = 1 as i32 as i64 as u64
    jeq r3, 0, lbb_14566                            if r3 == (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r5, 0                                     r5 = 0 as i32 as i64 as u64
lbb_14566:
    and64 r5, 1                                     r5 &= 1   ///  r5 = r5.and(1)
    jne r5, 0, lbb_14599                            if r5 != (0 as i32 as i64 as u64) { pc += 31 }
    mov64 r1, r4                                    r1 = r4
    lsh64 r1, 1                                     r1 <<= 1   ///  r1 = r1.wrapping_shl(1)
    mov64 r7, r1                                    r7 = r1
    jgt r1, r3, lbb_14573                           if r1 > r3 { pc += 1 }
    mov64 r7, r3                                    r7 = r3
lbb_14573:
    mov64 r5, 0                                     r5 = 0 as i32 as i64 as u64
    mov64 r2, 1                                     r2 = 1 as i32 as i64 as u64
    lddw r3, 0x4000000000000000                     r3 load str located at 4611686018427387904
    jgt r3, r7, lbb_14579                           if r3 > r7 { pc += 1 }
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
lbb_14579:
    jgt r7, 4, lbb_14581                            if r7 > (4 as i32 as i64 as u64) { pc += 1 }
    mov64 r7, 4                                     r7 = 4 as i32 as i64 as u64
lbb_14581:
    lsh64 r2, 1                                     r2 <<= 1   ///  r2 = r2.wrapping_shl(1)
    mov64 r3, r7                                    r3 = r7
    lsh64 r3, 1                                     r3 <<= 1   ///  r3 = r3.wrapping_shl(1)
    jeq r4, 0, lbb_14589                            if r4 == (0 as i32 as i64 as u64) { pc += 4 }
    ldxdw r4, [r6+0x8]                      
    stxdw [r10-0x8], r1                     
    stxdw [r10-0x18], r4                    
    mov64 r5, 2                                     r5 = 2 as i32 as i64 as u64
lbb_14589:
    stxdw [r10-0x10], r5                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -48                                   r1 += -48   ///  r1 = r1.wrapping_add(-48 as i32 as i64 as u64)
    mov64 r4, r10                                   r4 = r10
    add64 r4, -24                                   r4 += -24   ///  r4 = r4.wrapping_add(-24 as i32 as i64 as u64)
    call function_14474                     
    ldxdw r1, [r10-0x30]                    
    jeq r1, 0, lbb_14600                            if r1 == (0 as i32 as i64 as u64) { pc += 3 }
    ldxdw r2, [r10-0x20]                    
    ldxdw r1, [r10-0x28]                    
lbb_14599:
    call function_21549                     
lbb_14600:
    ldxdw r1, [r10-0x28]                    
    stxdw [r6+0x0], r7                      
    stxdw [r6+0x8], r1                      
    exit                                    

function_14604:
    mov64 r6, r1                                    r6 = r1
    ldxdw r4, [r6+0x0]                      
    mov64 r3, r4                                    r3 = r4
    add64 r3, 1                                     r3 += 1   ///  r3 = r3.wrapping_add(1 as i32 as i64 as u64)
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    mov64 r5, 1                                     r5 = 1 as i32 as i64 as u64
    jeq r3, 0, lbb_14612                            if r3 == (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r5, 0                                     r5 = 0 as i32 as i64 as u64
lbb_14612:
    and64 r5, 1                                     r5 &= 1   ///  r5 = r5.and(1)
    jne r5, 0, lbb_14643                            if r5 != (0 as i32 as i64 as u64) { pc += 29 }
    mov64 r7, r4                                    r7 = r4
    lsh64 r7, 1                                     r7 <<= 1   ///  r7 = r7.wrapping_shl(1)
    jgt r7, r3, lbb_14618                           if r7 > r3 { pc += 1 }
    mov64 r7, r3                                    r7 = r3
lbb_14618:
    mov64 r2, 1                                     r2 = 1 as i32 as i64 as u64
    lddw r3, 0x3c3c3c3c3c3c3c4                      r3 load str located at 271275648142787524
    jgt r3, r7, lbb_14623                           if r3 > r7 { pc += 1 }
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
lbb_14623:
    jgt r7, 4, lbb_14625                            if r7 > (4 as i32 as i64 as u64) { pc += 1 }
    mov64 r7, 4                                     r7 = 4 as i32 as i64 as u64
lbb_14625:
    mov64 r3, r7                                    r3 = r7
    mul64 r3, 34                                    r3 *= 34   ///  r3 = r3.wrapping_mul(34 as u64)
    jeq r4, 0, lbb_14633                            if r4 == (0 as i32 as i64 as u64) { pc += 5 }
    ldxdw r1, [r6+0x8]                      
    mul64 r4, 34                                    r4 *= 34   ///  r4 = r4.wrapping_mul(34 as u64)
    stxdw [r10-0x8], r4                     
    stxdw [r10-0x18], r1                    
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
lbb_14633:
    stxdw [r10-0x10], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -48                                   r1 += -48   ///  r1 = r1.wrapping_add(-48 as i32 as i64 as u64)
    mov64 r4, r10                                   r4 = r10
    add64 r4, -24                                   r4 += -24   ///  r4 = r4.wrapping_add(-24 as i32 as i64 as u64)
    call function_14474                     
    ldxdw r1, [r10-0x30]                    
    jeq r1, 0, lbb_14644                            if r1 == (0 as i32 as i64 as u64) { pc += 3 }
    ldxdw r2, [r10-0x20]                    
    ldxdw r1, [r10-0x28]                    
lbb_14643:
    call function_21549                     
lbb_14644:
    ldxdw r1, [r10-0x28]                    
    stxdw [r6+0x0], r7                      
    stxdw [r6+0x8], r1                      
    exit                                    

function_14648:
    jne r3, 0, lbb_14657                            if r3 != (0 as i32 as i64 as u64) { pc += 8 }
lbb_14649:
    mov64 r2, 12                                    r2 = 12 as i32 as i64 as u64
    stxw [r1+0x10], r2                      
lbb_14651:
    lddw r2, 0x8000000000000000                     r2 load str located at -9223372036854775808
    stxdw [r1+0x8], r2                      
lbb_14654:
    mov64 r2, 45                                    r2 = 45 as i32 as i64 as u64
    stxw [r1+0x0], r2                       
    ja lbb_15099                                    if true { pc += 442 }
lbb_14657:
    mov64 r4, 0                                     r4 = 0 as i32 as i64 as u64
    mov64 r7, r3                                    r7 = r3
    add64 r7, -1                                    r7 += -1   ///  r7 = r7.wrapping_add(-1 as i32 as i64 as u64)
    mov64 r6, r2                                    r6 = r2
    add64 r6, 1                                     r6 += 1   ///  r6 = r6.wrapping_add(1 as i32 as i64 as u64)
    ldxb r0, [r2+0x0]                       
    jsgt r0, 21, lbb_14675                          if (r0 as i64) > (21 as i32 as i64) { pc += 11 }
    jsgt r0, 10, lbb_14711                          if (r0 as i64) > (10 as i32 as i64) { pc += 46 }
    jsgt r0, 4, lbb_14774                           if (r0 as i64) > (4 as i32 as i64) { pc += 108 }
    jsgt r0, 2, lbb_14826                           if (r0 as i64) > (2 as i32 as i64) { pc += 159 }
    jeq r0, 0, lbb_14947                            if r0 == (0 as i32 as i64 as u64) { pc += 279 }
    mov64 r3, 1                                     r3 = 1 as i32 as i64 as u64
    jeq r0, 1, lbb_15070                            if r0 == (1 as i32 as i64 as u64) { pc += 400 }
    jeq r0, 2, lbb_14672                            if r0 == (2 as i32 as i64 as u64) { pc += 1 }
    ja lbb_14912                                    if true { pc += 240 }
lbb_14672:
    jeq r7, 0, lbb_14649                            if r7 == (0 as i32 as i64 as u64) { pc += -24 }
    mov64 r3, 2                                     r3 = 2 as i32 as i64 as u64
    ja lbb_15019                                    if true { pc += 344 }
lbb_14675:
    jsgt r0, 32, lbb_14686                          if (r0 as i64) > (32 as i32 as i64) { pc += 10 }
    jsgt r0, 26, lbb_14727                          if (r0 as i64) > (26 as i32 as i64) { pc += 50 }
    jsgt r0, 23, lbb_14841                          if (r0 as i64) > (23 as i32 as i64) { pc += 163 }
    jeq r0, 22, lbb_15021                           if r0 == (22 as i32 as i64 as u64) { pc += 342 }
    jeq r0, 23, lbb_14681                           if r0 == (23 as i32 as i64 as u64) { pc += 1 }
    ja lbb_14912                                    if true { pc += 231 }
lbb_14681:
    mov64 r2, 9                                     r2 = 9 as i32 as i64 as u64
    jgt r2, r3, lbb_15014                           if r2 > r3 { pc += 331 }
    mov64 r3, 23                                    r3 = 23 as i32 as i64 as u64
    ldxdw r5, [r6+0x0]                      
    ja lbb_15162                                    if true { pc += 476 }
lbb_14686:
    jsgt r0, 38, lbb_14720                          if (r0 as i64) > (38 as i32 as i64) { pc += 33 }
    jsgt r0, 35, lbb_14835                          if (r0 as i64) > (35 as i32 as i64) { pc += 147 }
    jeq r0, 33, lbb_14921                           if r0 == (33 as i32 as i64 as u64) { pc += 232 }
    jeq r0, 34, lbb_15003                           if r0 == (34 as i32 as i64 as u64) { pc += 313 }
    jeq r0, 35, lbb_14692                           if r0 == (35 as i32 as i64 as u64) { pc += 1 }
    ja lbb_14912                                    if true { pc += 220 }
lbb_14692:
    mov64 r4, 33                                    r4 = 33 as i32 as i64 as u64
    jgt r4, r3, lbb_15014                           if r4 > r3 { pc += 320 }
    ldxh r3, [r2+0x6]                       
    lsh64 r3, 32                                    r3 <<= 32   ///  r3 = r3.wrapping_shl(32)
    ldxb r4, [r2+0x8]                       
    lsh64 r4, 48                                    r4 <<= 48   ///  r4 = r4.wrapping_shl(48)
    or64 r4, r3                                     r4 |= r3   ///  r4 = r4.or(r3)
    ldxh r3, [r2+0x1e]                      
    lsh64 r3, 32                                    r3 <<= 32   ///  r3 = r3.wrapping_shl(32)
    ldxb r5, [r2+0x20]                      
    lsh64 r5, 48                                    r5 <<= 48   ///  r5 = r5.wrapping_shl(48)
    or64 r5, r3                                     r5 |= r3   ///  r5 = r5.or(r3)
    ldxw r3, [r2+0x1a]                      
    or64 r3, r5                                     r3 |= r5   ///  r3 = r3.or(r5)
    stxdw [r10-0xa0], r3                    
    ldxw r9, [r2+0x2]                       
    or64 r9, r4                                     r9 |= r4   ///  r9 = r9.or(r4)
    mov64 r3, 35                                    r3 = 35 as i32 as i64 as u64
    ja lbb_15181                                    if true { pc += 470 }
lbb_14711:
    jsgt r0, 15, lbb_14793                          if (r0 as i64) > (15 as i32 as i64) { pc += 81 }
    jsgt r0, 12, lbb_14849                          if (r0 as i64) > (12 as i32 as i64) { pc += 136 }
    jeq r0, 11, lbb_15049                           if r0 == (11 as i32 as i64 as u64) { pc += 335 }
    jeq r0, 12, lbb_14716                           if r0 == (12 as i32 as i64 as u64) { pc += 1 }
    ja lbb_14912                                    if true { pc += 196 }
lbb_14716:
    mov64 r5, 10                                    r5 = 10 as i32 as i64 as u64
    jgt r5, r3, lbb_15054                           if r5 > r3 { pc += 336 }
    mov64 r3, 12                                    r3 = 12 as i32 as i64 as u64
    ja lbb_15218                                    if true { pc += 498 }
lbb_14720:
    jsgt r0, 41, lbb_14909                          if (r0 as i64) > (41 as i32 as i64) { pc += 188 }
    jeq r0, 39, lbb_14923                           if r0 == (39 as i32 as i64 as u64) { pc += 201 }
    jeq r0, 40, lbb_15005                           if r0 == (40 as i32 as i64 as u64) { pc += 282 }
    jeq r0, 41, lbb_14725                           if r0 == (41 as i32 as i64 as u64) { pc += 1 }
    ja lbb_14912                                    if true { pc += 187 }
lbb_14725:
    mov64 r3, 41                                    r3 = 41 as i32 as i64 as u64
    ja lbb_15070                                    if true { pc += 343 }
lbb_14727:
    jsgt r0, 29, lbb_14857                          if (r0 as i64) > (29 as i32 as i64) { pc += 129 }
    jeq r0, 27, lbb_14999                           if r0 == (27 as i32 as i64 as u64) { pc += 270 }
    jeq r0, 28, lbb_15061                           if r0 == (28 as i32 as i64 as u64) { pc += 331 }
    jeq r0, 29, lbb_14732                           if r0 == (29 as i32 as i64 as u64) { pc += 1 }
    ja lbb_14912                                    if true { pc += 180 }
lbb_14732:
    mov64 r8, 2                                     r8 = 2 as i32 as i64 as u64
    stxdw [r10-0x40], r8                    
    mov64 r0, 0                                     r0 = 0 as i32 as i64 as u64
    stxdw [r10-0x38], r0                    
    stxdw [r10-0x48], r0                    
    mov64 r5, 0                                     r5 = 0 as i32 as i64 as u64
    jeq r7, 0, lbb_15284                            if r7 == (0 as i32 as i64 as u64) { pc += 545 }
    mov64 r8, 0                                     r8 = 0 as i32 as i64 as u64
    mov64 r3, 2                                     r3 = 2 as i32 as i64 as u64
    stxdw [r10-0xb0], r1                    
    ja lbb_14753                                    if true { pc += 10 }
lbb_14743:
    add64 r6, r9                                    r6 += r9   ///  r6 = r6.wrapping_add(r9)
    sub64 r7, r9                                    r7 -= r9   ///  r7 = r7.wrapping_sub(r9)
    mov64 r2, r3                                    r2 = r3
    add64 r2, r8                                    r2 += r8   ///  r2 = r2.wrapping_add(r8)
    ldxdw r4, [r10-0x98]                    
    stxh [r2+0x0], r4                       
    add64 r8, 2                                     r8 += 2   ///  r8 = r8.wrapping_add(2 as i32 as i64 as u64)
    add64 r0, 1                                     r0 += 1   ///  r0 = r0.wrapping_add(1 as i32 as i64 as u64)
    stxdw [r10-0x38], r0                    
    jeq r7, 0, lbb_15282                            if r7 == (0 as i32 as i64 as u64) { pc += 529 }
lbb_14753:
    mov64 r9, r7                                    r9 = r7
    mov64 r5, 2                                     r5 = 2 as i32 as i64 as u64
    jgt r5, r7, lbb_14757                           if r5 > r7 { pc += 1 }
    mov64 r9, 2                                     r9 = 2 as i32 as i64 as u64
lbb_14757:
    jne r7, 1, lbb_14760                            if r7 != (1 as i32 as i64 as u64) { pc += 2 }
    ldxdw r2, [r10-0x48]                    
    ja lbb_15223                                    if true { pc += 463 }
lbb_14760:
    ldxdw r2, [r10-0x48]                    
    ldxh r5, [r6+0x0]                       
    stxdw [r10-0x98], r5                    
    jgt r5, 27, lbb_15223                           if r5 > (27 as i32 as i64 as u64) { pc += 459 }
    jne r0, r2, lbb_14743                           if r0 != r2 { pc += -22 }
    mov64 r2, r10                                   r2 = r10
    add64 r2, -72                                   r2 += -72   ///  r2 = r2.wrapping_add(-72 as i32 as i64 as u64)
    mov64 r1, r2                                    r1 = r2
    stxdw [r10-0x90], r0                    
    call function_14558                     
    ldxdw r0, [r10-0x90]                    
    ldxdw r1, [r10-0xb0]                    
    ldxdw r3, [r10-0x40]                    
    ja lbb_14743                                    if true { pc += -31 }
lbb_14774:
    jsgt r0, 6, lbb_14817                           if (r0 as i64) > (6 as i32 as i64) { pc += 42 }
    jeq r0, 5, lbb_15067                            if r0 == (5 as i32 as i64 as u64) { pc += 291 }
    jeq r0, 6, lbb_14778                            if r0 == (6 as i32 as i64 as u64) { pc += 1 }
    ja lbb_14912                                    if true { pc += 134 }
lbb_14778:
    jeq r7, 0, lbb_14783                            if r7 == (0 as i32 as i64 as u64) { pc += 4 }
    add64 r3, -2                                    r3 += -2   ///  r3 = r3.wrapping_add(-2 as i32 as i64 as u64)
    ldxb r7, [r6+0x0]                       
    mov64 r4, 17                                    r4 = 17 as i32 as i64 as u64
    jgt r4, r7, lbb_15252                           if r4 > r7 { pc += 469 }
lbb_14783:
    mov64 r2, 128                                   r2 = 128 as i32 as i64 as u64
    stxb [r1+0xf], r2                       
    stxdw [r1+0x18], r3                     
    mov64 r2, 12                                    r2 = 12 as i32 as i64 as u64
    stxdw [r1+0x10], r2                     
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
    stxh [r1+0xd], r2                       
    stxw [r1+0x9], r2                       
    stxb [r1+0x8], r2                       
    ja lbb_14654                                    if true { pc += -139 }
lbb_14793:
    jsgt r0, 18, lbb_14863                          if (r0 as i64) > (18 as i32 as i64) { pc += 69 }
    jeq r0, 16, lbb_15011                           if r0 == (16 as i32 as i64 as u64) { pc += 216 }
    jeq r0, 17, lbb_15069                           if r0 == (17 as i32 as i64 as u64) { pc += 273 }
    jeq r0, 18, lbb_14798                           if r0 == (18 as i32 as i64 as u64) { pc += 1 }
    ja lbb_14912                                    if true { pc += 114 }
lbb_14798:
    mov64 r4, 33                                    r4 = 33 as i32 as i64 as u64
    jgt r4, r3, lbb_15014                           if r4 > r3 { pc += 214 }
    ldxh r3, [r2+0x6]                       
    lsh64 r3, 32                                    r3 <<= 32   ///  r3 = r3.wrapping_shl(32)
    ldxb r4, [r2+0x8]                       
    lsh64 r4, 48                                    r4 <<= 48   ///  r4 = r4.wrapping_shl(48)
    or64 r4, r3                                     r4 |= r3   ///  r4 = r4.or(r3)
    ldxh r3, [r2+0x1e]                      
    lsh64 r3, 32                                    r3 <<= 32   ///  r3 = r3.wrapping_shl(32)
    ldxb r5, [r2+0x20]                      
    lsh64 r5, 48                                    r5 <<= 48   ///  r5 = r5.wrapping_shl(48)
    or64 r5, r3                                     r5 |= r3   ///  r5 = r5.or(r3)
    ldxw r3, [r2+0x1a]                      
    or64 r3, r5                                     r3 |= r5   ///  r3 = r3.or(r5)
    stxdw [r10-0xa0], r3                    
    ldxw r9, [r2+0x2]                       
    or64 r9, r4                                     r9 |= r4   ///  r9 = r9.or(r4)
    mov64 r3, 18                                    r3 = 18 as i32 as i64 as u64
    ja lbb_15181                                    if true { pc += 364 }
lbb_14817:
    mov64 r2, r0                                    r2 = r0
    add64 r2, -7                                    r2 += -7   ///  r2 = r2.wrapping_add(-7 as i32 as i64 as u64)
    mov64 r5, 2                                     r5 = 2 as i32 as i64 as u64
    jgt r5, r2, lbb_14826                           if r5 > r2 { pc += 5 }
    jeq r0, 9, lbb_15065                            if r0 == (9 as i32 as i64 as u64) { pc += 243 }
    jeq r0, 10, lbb_14824                           if r0 == (10 as i32 as i64 as u64) { pc += 1 }
    ja lbb_14912                                    if true { pc += 88 }
lbb_14824:
    mov64 r3, 10                                    r3 = 10 as i32 as i64 as u64
    ja lbb_15070                                    if true { pc += 244 }
lbb_14826:
    mov64 r2, 9                                     r2 = 9 as i32 as i64 as u64
    jgt r2, r3, lbb_14649                           if r2 > r3 { pc += -179 }
    ldxdw r5, [r6+0x0]                      
    jsgt r0, 6, lbb_14913                           if (r0 as i64) > (6 as i32 as i64) { pc += 83 }
    jeq r0, 3, lbb_15157                            if r0 == (3 as i32 as i64 as u64) { pc += 326 }
    jeq r0, 4, lbb_14833                            if r0 == (4 as i32 as i64 as u64) { pc += 1 }
    ja lbb_14915                                    if true { pc += 82 }
lbb_14833:
    mov64 r3, 4                                     r3 = 4 as i32 as i64 as u64
    ja lbb_15162                                    if true { pc += 327 }
lbb_14835:
    jeq r0, 36, lbb_14925                           if r0 == (36 as i32 as i64 as u64) { pc += 89 }
    jeq r0, 37, lbb_15007                           if r0 == (37 as i32 as i64 as u64) { pc += 170 }
    jeq r0, 38, lbb_14839                           if r0 == (38 as i32 as i64 as u64) { pc += 1 }
    ja lbb_14912                                    if true { pc += 73 }
lbb_14839:
    mov64 r3, 38                                    r3 = 38 as i32 as i64 as u64
    ja lbb_15070                                    if true { pc += 229 }
lbb_14841:
    stxdw [r10-0xb0], r1                    
    jeq r0, 24, lbb_14929                           if r0 == (24 as i32 as i64 as u64) { pc += 86 }
    jeq r0, 25, lbb_15023                           if r0 == (25 as i32 as i64 as u64) { pc += 179 }
    ldxdw r1, [r10-0xb0]                    
    jeq r0, 26, lbb_14847                           if r0 == (26 as i32 as i64 as u64) { pc += 1 }
    ja lbb_14912                                    if true { pc += 65 }
lbb_14847:
    mov64 r3, 26                                    r3 = 26 as i32 as i64 as u64
    ja lbb_15070                                    if true { pc += 221 }
lbb_14849:
    jeq r0, 13, lbb_14995                           if r0 == (13 as i32 as i64 as u64) { pc += 145 }
    jeq r0, 14, lbb_15051                           if r0 == (14 as i32 as i64 as u64) { pc += 200 }
    jeq r0, 15, lbb_14853                           if r0 == (15 as i32 as i64 as u64) { pc += 1 }
    ja lbb_14912                                    if true { pc += 59 }
lbb_14853:
    mov64 r5, 10                                    r5 = 10 as i32 as i64 as u64
    jgt r5, r3, lbb_15054                           if r5 > r3 { pc += 199 }
    mov64 r3, 15                                    r3 = 15 as i32 as i64 as u64
    ja lbb_15218                                    if true { pc += 361 }
lbb_14857:
    jeq r0, 30, lbb_15001                           if r0 == (30 as i32 as i64 as u64) { pc += 143 }
    jeq r0, 31, lbb_15063                           if r0 == (31 as i32 as i64 as u64) { pc += 204 }
    jeq r0, 32, lbb_14861                           if r0 == (32 as i32 as i64 as u64) { pc += 1 }
    ja lbb_14912                                    if true { pc += 51 }
lbb_14861:
    mov64 r3, 32                                    r3 = 32 as i32 as i64 as u64
    ja lbb_15070                                    if true { pc += 207 }
lbb_14863:
    jeq r0, 19, lbb_15017                           if r0 == (19 as i32 as i64 as u64) { pc += 153 }
    jeq r0, 20, lbb_15100                           if r0 == (20 as i32 as i64 as u64) { pc += 235 }
    jeq r0, 21, lbb_14867                           if r0 == (21 as i32 as i64 as u64) { pc += 1 }
    ja lbb_14912                                    if true { pc += 45 }
lbb_14867:
    mov64 r8, 2                                     r8 = 2 as i32 as i64 as u64
    stxdw [r10-0x40], r8                    
    mov64 r0, 0                                     r0 = 0 as i32 as i64 as u64
    stxdw [r10-0x38], r0                    
    stxdw [r10-0x48], r0                    
    mov64 r5, 0                                     r5 = 0 as i32 as i64 as u64
    jeq r7, 0, lbb_15289                            if r7 == (0 as i32 as i64 as u64) { pc += 415 }
    mov64 r8, 0                                     r8 = 0 as i32 as i64 as u64
    mov64 r3, 2                                     r3 = 2 as i32 as i64 as u64
    stxdw [r10-0xb0], r1                    
    ja lbb_14888                                    if true { pc += 10 }
lbb_14878:
    add64 r6, r9                                    r6 += r9   ///  r6 = r6.wrapping_add(r9)
    sub64 r7, r9                                    r7 -= r9   ///  r7 = r7.wrapping_sub(r9)
    mov64 r2, r3                                    r2 = r3
    add64 r2, r8                                    r2 += r8   ///  r2 = r2.wrapping_add(r8)
    ldxdw r4, [r10-0x98]                    
    stxh [r2+0x0], r4                       
    add64 r8, 2                                     r8 += 2   ///  r8 = r8.wrapping_add(2 as i32 as i64 as u64)
    add64 r0, 1                                     r0 += 1   ///  r0 = r0.wrapping_add(1 as i32 as i64 as u64)
    stxdw [r10-0x38], r0                    
    jeq r7, 0, lbb_15287                            if r7 == (0 as i32 as i64 as u64) { pc += 399 }
lbb_14888:
    mov64 r9, r7                                    r9 = r7
    mov64 r5, 2                                     r5 = 2 as i32 as i64 as u64
    jgt r5, r7, lbb_14892                           if r5 > r7 { pc += 1 }
    mov64 r9, 2                                     r9 = 2 as i32 as i64 as u64
lbb_14892:
    jne r7, 1, lbb_14895                            if r7 != (1 as i32 as i64 as u64) { pc += 2 }
    ldxdw r2, [r10-0x48]                    
    ja lbb_15231                                    if true { pc += 336 }
lbb_14895:
    ldxdw r2, [r10-0x48]                    
    ldxh r5, [r6+0x0]                       
    stxdw [r10-0x98], r5                    
    jgt r5, 27, lbb_15231                           if r5 > (27 as i32 as i64 as u64) { pc += 332 }
    jne r0, r2, lbb_14878                           if r0 != r2 { pc += -22 }
    mov64 r2, r10                                   r2 = r10
    add64 r2, -72                                   r2 += -72   ///  r2 = r2.wrapping_add(-72 as i32 as i64 as u64)
    mov64 r1, r2                                    r1 = r2
    stxdw [r10-0x90], r0                    
    call function_14558                     
    ldxdw r0, [r10-0x90]                    
    ldxdw r1, [r10-0xb0]                    
    ldxdw r3, [r10-0x40]                    
    ja lbb_14878                                    if true { pc += -31 }
lbb_14909:
    jeq r0, 42, lbb_14927                           if r0 == (42 as i32 as i64 as u64) { pc += 17 }
    jeq r0, 43, lbb_15009                           if r0 == (43 as i32 as i64 as u64) { pc += 98 }
    jeq r0, 44, lbb_14945                           if r0 == (44 as i32 as i64 as u64) { pc += 33 }
lbb_14912:
    ja lbb_14649                                    if true { pc += -264 }
lbb_14913:
    jeq r0, 7, lbb_15159                            if r0 == (7 as i32 as i64 as u64) { pc += 245 }
    jeq r0, 8, lbb_15161                            if r0 == (8 as i32 as i64 as u64) { pc += 246 }
lbb_14915:
    lddw r1, 0x10003ec10 --> b"internal error: entered unreachable code"        r1 load str located at 4295224336
    mov64 r2, 40                                    r2 = 40 as i32 as i64 as u64
    lddw r3, 0x100041400 --> b"\x00\x00\x00\x008\xec\x03\x00\x12\x00\x00\x00\x00\x00\x00\x00\x02\x03\x00…        r3 load str located at 4295234560
    call function_25816                     
lbb_14921:
    mov64 r3, 33                                    r3 = 33 as i32 as i64 as u64
    ja lbb_15070                                    if true { pc += 147 }
lbb_14923:
    mov64 r3, 39                                    r3 = 39 as i32 as i64 as u64
    ja lbb_15070                                    if true { pc += 145 }
lbb_14925:
    mov64 r3, 36                                    r3 = 36 as i32 as i64 as u64
    ja lbb_15070                                    if true { pc += 143 }
lbb_14927:
    mov64 r3, 42                                    r3 = 42 as i32 as i64 as u64
    ja lbb_15070                                    if true { pc += 141 }
lbb_14929:
    mov64 r1, r10                                   r1 = r10
    add64 r1, -72                                   r1 += -72   ///  r1 = r1.wrapping_add(-72 as i32 as i64 as u64)
    mov64 r2, r6                                    r2 = r6
    mov64 r3, r7                                    r3 = r7
    call function_28437                     
    ldxdw r1, [r10-0x48]                    
    jeq r1, 0, lbb_15243                            if r1 == (0 as i32 as i64 as u64) { pc += 307 }
    mov64 r1, 12                                    r1 = 12 as i32 as i64 as u64
    ldxdw r2, [r10-0xb0]                    
    stxw [r2+0x10], r1                      
    lddw r1, 0x8000000000000000                     r1 load str located at -9223372036854775808
    stxdw [r2+0x8], r1                      
    mov64 r1, 45                                    r1 = 45 as i32 as i64 as u64
    stxw [r2+0x0], r1                       
    ja lbb_15099                                    if true { pc += 154 }
lbb_14945:
    mov64 r3, 44                                    r3 = 44 as i32 as i64 as u64
    ja lbb_15070                                    if true { pc += 123 }
lbb_14947:
    jeq r7, 0, lbb_14649                            if r7 == (0 as i32 as i64 as u64) { pc += -299 }
    mov64 r4, r3                                    r4 = r3
    add64 r4, -2                                    r4 += -2   ///  r4 = r4.wrapping_add(-2 as i32 as i64 as u64)
    mov64 r5, 32                                    r5 = 32 as i32 as i64 as u64
    jgt r5, r4, lbb_15145                           if r5 > r4 { pc += 193 }
    stxdw [r10-0xb0], r1                    
    ldxb r1, [r6+0x0]                       
    stxdw [r10-0xb8], r1                    
    ldxb r1, [r2+0x2]                       
    ldxdw r4, [r2+0x9]                      
    stxdw [r10-0x41], r4                    
    ldxdw r4, [r2+0x3]                      
    stxdw [r10-0x47], r4                    
    ldxdw r4, [r2+0x11]                     
    stxdw [r10-0x90], r4                    
    ldxb r4, [r2+0x19]                      
    stxdw [r10-0x98], r4                    
    ldxdw r4, [r2+0x1a]                     
    stxdw [r10-0xa0], r4                    
    stxb [r10-0x48], r1                     
    ldxdw r8, [r10-0x41]                    
    ldxw r9, [r10-0x48]                     
    ldxb r6, [r10-0x42]                     
    ldxh r7, [r10-0x44]                     
    add64 r2, 34                                    r2 += 34   ///  r2 = r2.wrapping_add(34 as i32 as i64 as u64)
    add64 r3, -34                                   r3 += -34   ///  r3 = r3.wrapping_add(-34 as i32 as i64 as u64)
    mov64 r1, r10                                   r1 = r10
    add64 r1, -72                                   r1 += -72   ///  r1 = r1.wrapping_add(-72 as i32 as i64 as u64)
    call function_15690                     
    ldxw r2, [r10-0x48]                     
    jeq r2, 2, lbb_15132                            if r2 == (2 as i32 as i64 as u64) { pc += 154 }
    lsh64 r7, 32                                    r7 <<= 32   ///  r7 = r7.wrapping_shl(32)
    lsh64 r6, 48                                    r6 <<= 48   ///  r6 = r6.wrapping_shl(48)
    or64 r6, r7                                     r6 |= r7   ///  r6 = r6.or(r7)
    or64 r9, r6                                     r9 |= r6   ///  r9 = r9.or(r6)
    ldxdw r1, [r10-0x44]                    
    stxdw [r10-0x88], r1                    
    ldxdw r1, [r10-0x3c]                    
    stxdw [r10-0x60], r1                    
    stxdw [r10-0x80], r1                    
    ldxdw r1, [r10-0x34]                    
    stxdw [r10-0x58], r1                    
    stxdw [r10-0x78], r1                    
    ldxw r1, [r10-0x2c]                     
    stxw [r10-0x50], r1                     
    stxw [r10-0x70], r1                     
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
    ja lbb_15326                                    if true { pc += 331 }
lbb_14995:
    mov64 r5, 10                                    r5 = 10 as i32 as i64 as u64
    jgt r5, r3, lbb_15054                           if r5 > r3 { pc += 57 }
    mov64 r3, 13                                    r3 = 13 as i32 as i64 as u64
    ja lbb_15218                                    if true { pc += 219 }
lbb_14999:
    mov64 r3, 27                                    r3 = 27 as i32 as i64 as u64
    ja lbb_15070                                    if true { pc += 69 }
lbb_15001:
    mov64 r3, 30                                    r3 = 30 as i32 as i64 as u64
    ja lbb_15070                                    if true { pc += 67 }
lbb_15003:
    mov64 r3, 34                                    r3 = 34 as i32 as i64 as u64
    ja lbb_15070                                    if true { pc += 65 }
lbb_15005:
    mov64 r3, 40                                    r3 = 40 as i32 as i64 as u64
    ja lbb_15070                                    if true { pc += 63 }
lbb_15007:
    mov64 r3, 37                                    r3 = 37 as i32 as i64 as u64
    ja lbb_15070                                    if true { pc += 61 }
lbb_15009:
    mov64 r3, 43                                    r3 = 43 as i32 as i64 as u64
    ja lbb_15070                                    if true { pc += 59 }
lbb_15011:
    mov64 r4, 33                                    r4 = 33 as i32 as i64 as u64
    jgt r4, r3, lbb_15014                           if r4 > r3 { pc += 1 }
    ja lbb_15165                                    if true { pc += 151 }
lbb_15014:
    mov64 r2, 12                                    r2 = 12 as i32 as i64 as u64
    stxdw [r1+0x10], r2                     
    ja lbb_14651                                    if true { pc += -366 }
lbb_15017:
    jeq r7, 0, lbb_14649                            if r7 == (0 as i32 as i64 as u64) { pc += -369 }
    mov64 r3, 19                                    r3 = 19 as i32 as i64 as u64
lbb_15019:
    ldxb r5, [r6+0x0]                       
    ja lbb_15070                                    if true { pc += 49 }
lbb_15021:
    mov64 r3, 22                                    r3 = 22 as i32 as i64 as u64
    ja lbb_15070                                    if true { pc += 47 }
lbb_15023:
    mov64 r1, r10                                   r1 = r10
    add64 r1, -72                                   r1 += -72   ///  r1 = r1.wrapping_add(-72 as i32 as i64 as u64)
    mov64 r2, r6                                    r2 = r6
    mov64 r3, r7                                    r3 = r7
    call function_15690                     
    ldxw r5, [r10-0x48]                     
    jeq r5, 2, lbb_15031                            if r5 == (2 as i32 as i64 as u64) { pc += 1 }
    ja lbb_15190                                    if true { pc += 159 }
lbb_15031:
    ldxw r1, [r10-0x2f]                     
    stxw [r10-0x68], r1                     
    ldxw r1, [r10-0x2c]                     
    stxw [r10-0x65], r1                     
    ldxdw r1, [r10-0x40]                    
    ldxdw r2, [r10-0x38]                    
    ldxb r3, [r10-0x30]                     
    ldxw r4, [r10-0x65]                     
    ldxdw r5, [r10-0xb0]                    
    stxw [r5+0x1c], r4                      
    ldxw r4, [r10-0x68]                     
    stxw [r5+0x19], r4                      
    stxb [r5+0x18], r3                      
    stxdw [r5+0x10], r2                     
    stxdw [r5+0x8], r1                      
    mov64 r1, 45                                    r1 = 45 as i32 as i64 as u64
    stxw [r5+0x0], r1                       
    ja lbb_15099                                    if true { pc += 50 }
lbb_15049:
    mov64 r3, 11                                    r3 = 11 as i32 as i64 as u64
    ja lbb_15070                                    if true { pc += 19 }
lbb_15051:
    mov64 r5, 10                                    r5 = 10 as i32 as i64 as u64
    jgt r5, r3, lbb_15054                           if r5 > r3 { pc += 1 }
    ja lbb_15217                                    if true { pc += 163 }
lbb_15054:
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
    stxb [r1+0x17], r2                      
    stxh [r1+0x15], r2                      
    stxw [r1+0x11], r2                      
    mov64 r2, 12                                    r2 = 12 as i32 as i64 as u64
    stxb [r1+0x10], r2                      
    ja lbb_14651                                    if true { pc += -410 }
lbb_15061:
    mov64 r3, 28                                    r3 = 28 as i32 as i64 as u64
    ja lbb_15070                                    if true { pc += 7 }
lbb_15063:
    mov64 r3, 31                                    r3 = 31 as i32 as i64 as u64
    ja lbb_15070                                    if true { pc += 5 }
lbb_15065:
    mov64 r3, 9                                     r3 = 9 as i32 as i64 as u64
    ja lbb_15070                                    if true { pc += 3 }
lbb_15067:
    mov64 r3, 5                                     r3 = 5 as i32 as i64 as u64
    ja lbb_15070                                    if true { pc += 1 }
lbb_15069:
    mov64 r3, 17                                    r3 = 17 as i32 as i64 as u64
lbb_15070:
    and64 r8, 255                                   r8 &= 255   ///  r8 = r8.and(255)
    or64 r4, r8                                     r4 |= r8   ///  r4 = r4.or(r8)
    ldxdw r0, [r10-0xa0]                    
    stxdw [r1+0x21], r0                     
    ldxdw r0, [r10-0x98]                    
    stxb [r1+0x20], r0                      
    ldxdw r0, [r10-0x90]                    
    stxdw [r1+0x18], r0                     
    stxw [r1+0x0], r3                       
    stxdw [r1+0x10], r4                     
    and64 r5, 255                                   r5 &= 255   ///  r5 = r5.and(255)
    lsh64 r9, 8                                     r9 <<= 8   ///  r9 = r9.wrapping_shl(8)
    or64 r9, r5                                     r9 |= r5   ///  r9 = r9.or(r5)
    stxdw [r1+0x8], r9                      
    ldxh r3, [r10-0x6c]                     
    stxh [r1+0x29], r3                      
    ldxb r3, [r10-0x6a]                     
    stxb [r1+0x2b], r3                      
    stxw [r1+0x2c], r2                      
    ldxdw r2, [r10-0x88]                    
    stxdw [r1+0x30], r2                     
    ldxdw r2, [r10-0x80]                    
    stxdw [r1+0x38], r2                     
    ldxdw r2, [r10-0x78]                    
    stxdw [r1+0x40], r2                     
    ldxw r2, [r10-0x70]                     
    stxw [r1+0x48], r2                      
    ldxdw r2, [r10-0xa8]                    
    stxw [r1+0x4c], r2                      
lbb_15099:
    exit                                    
lbb_15100:
    jeq r7, 0, lbb_14649                            if r7 == (0 as i32 as i64 as u64) { pc += -452 }
    mov64 r4, r3                                    r4 = r3
    add64 r4, -2                                    r4 += -2   ///  r4 = r4.wrapping_add(-2 as i32 as i64 as u64)
    mov64 r5, 32                                    r5 = 32 as i32 as i64 as u64
    jgt r5, r4, lbb_15145                           if r5 > r4 { pc += 40 }
    stxdw [r10-0xb0], r1                    
    ldxb r1, [r6+0x0]                       
    stxdw [r10-0xb8], r1                    
    ldxb r1, [r2+0x2]                       
    ldxdw r4, [r2+0x9]                      
    stxdw [r10-0x41], r4                    
    ldxdw r4, [r2+0x3]                      
    stxdw [r10-0x47], r4                    
    ldxdw r4, [r2+0x11]                     
    stxdw [r10-0x90], r4                    
    ldxb r4, [r2+0x19]                      
    stxdw [r10-0x98], r4                    
    ldxdw r4, [r2+0x1a]                     
    stxdw [r10-0xa0], r4                    
    stxb [r10-0x48], r1                     
    ldxdw r8, [r10-0x41]                    
    ldxw r9, [r10-0x48]                     
    ldxb r6, [r10-0x42]                     
    ldxh r7, [r10-0x44]                     
    add64 r2, 34                                    r2 += 34   ///  r2 = r2.wrapping_add(34 as i32 as i64 as u64)
    add64 r3, -34                                   r3 += -34   ///  r3 = r3.wrapping_add(-34 as i32 as i64 as u64)
    mov64 r1, r10                                   r1 = r10
    add64 r1, -72                                   r1 += -72   ///  r1 = r1.wrapping_add(-72 as i32 as i64 as u64)
    call function_15690                     
    ldxw r2, [r10-0x48]                     
    jeq r2, 2, lbb_15132                            if r2 == (2 as i32 as i64 as u64) { pc += 1 }
    ja lbb_15310                                    if true { pc += 178 }
lbb_15132:
    ldxdw r1, [r10-0x30]                    
    stxdw [r10-0x54], r1                    
    ldxdw r2, [r10-0x38]                    
    stxdw [r10-0x5c], r2                    
    ldxdw r3, [r10-0x40]                    
    stxdw [r10-0x64], r3                    
    ldxdw r4, [r10-0xb0]                    
    stxdw [r4+0x18], r1                     
    stxdw [r4+0x10], r2                     
    stxdw [r4+0x8], r3                      
    mov64 r1, 45                                    r1 = 45 as i32 as i64 as u64
    stxw [r4+0x0], r1                       
    ja lbb_15099                                    if true { pc += -46 }
lbb_15145:
    mov64 r2, 12                                    r2 = 12 as i32 as i64 as u64
    stxw [r10-0x40], r2                     
    lddw r2, 0x8000000000000000                     r2 load str located at -9223372036854775808
    stxdw [r10-0x48], r2                    
    ldxdw r2, [r10-0x41]                    
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
    stxb [r1+0xe], r3                       
    stxh [r1+0xc], r3                       
    stxw [r1+0x8], r3                       
    stxdw [r1+0xf], r2                      
    ja lbb_14654                                    if true { pc += -503 }
lbb_15157:
    mov64 r3, 3                                     r3 = 3 as i32 as i64 as u64
    ja lbb_15162                                    if true { pc += 3 }
lbb_15159:
    mov64 r3, 7                                     r3 = 7 as i32 as i64 as u64
    ja lbb_15162                                    if true { pc += 1 }
lbb_15161:
    mov64 r3, 8                                     r3 = 8 as i32 as i64 as u64
lbb_15162:
    mov64 r9, r5                                    r9 = r5
    rsh64 r9, 8                                     r9 >>= 8   ///  r9 = r9.wrapping_shr(8)
    ja lbb_15070                                    if true { pc += -95 }
lbb_15165:
    ldxh r3, [r2+0x6]                       
    lsh64 r3, 32                                    r3 <<= 32   ///  r3 = r3.wrapping_shl(32)
    ldxb r4, [r2+0x8]                       
    lsh64 r4, 48                                    r4 <<= 48   ///  r4 = r4.wrapping_shl(48)
    or64 r4, r3                                     r4 |= r3   ///  r4 = r4.or(r3)
    ldxh r3, [r2+0x1e]                      
    lsh64 r3, 32                                    r3 <<= 32   ///  r3 = r3.wrapping_shl(32)
    ldxb r5, [r2+0x20]                      
    lsh64 r5, 48                                    r5 <<= 48   ///  r5 = r5.wrapping_shl(48)
    or64 r5, r3                                     r5 |= r3   ///  r5 = r5.or(r3)
    ldxw r3, [r2+0x1a]                      
    or64 r3, r5                                     r3 |= r5   ///  r3 = r3.or(r5)
    stxdw [r10-0xa0], r3                    
    ldxw r9, [r2+0x2]                       
    or64 r9, r4                                     r9 |= r4   ///  r9 = r9.or(r4)
    mov64 r3, 16                                    r3 = 16 as i32 as i64 as u64
lbb_15181:
    ldxb r4, [r2+0x19]                      
    stxdw [r10-0x98], r4                    
    ldxdw r4, [r2+0x11]                     
    stxdw [r10-0x90], r4                    
    ldxb r5, [r2+0x1]                       
    ldxdw r8, [r2+0x9]                      
    mov64 r4, r8                                    r4 = r8
    and64 r4, -256                                  r4 &= -256   ///  r4 = r4.and(-256)
    ja lbb_15070                                    if true { pc += -120 }
lbb_15190:
    ldxw r1, [r10-0x2c]                     
    stxw [r10-0x65], r1                     
    ldxw r1, [r10-0x2f]                     
    stxw [r10-0x68], r1                     
    ldxdw r1, [r10-0x28]                    
    stxw [r10-0x9], r1                      
    ldxw r1, [r10-0x65]                     
    stxw [r10-0xd], r1                      
    ldxw r1, [r10-0x68]                     
    stxw [r10-0x10], r1                     
    ldxb r1, [r10-0x30]                     
    stxdw [r10-0x98], r1                    
    ldxdw r1, [r10-0x38]                    
    stxdw [r10-0x90], r1                    
    ldxw r9, [r10-0x44]                     
    ldxdw r8, [r10-0x40]                    
    ldxdw r1, [r10-0x10]                    
    stxdw [r10-0xa0], r1                    
    ldxb r1, [r10-0x6]                      
    stxb [r10-0x6a], r1                     
    ldxh r1, [r10-0x8]                      
    stxh [r10-0x6c], r1                     
    mov64 r3, 25                                    r3 = 25 as i32 as i64 as u64
    mov64 r4, r8                                    r4 = r8
    and64 r4, -256                                  r4 &= -256   ///  r4 = r4.and(-256)
    lsh64 r9, 24                                    r9 <<= 24   ///  r9 = r9.wrapping_shl(24)
    ja lbb_15250                                    if true { pc += 33 }
lbb_15217:
    mov64 r3, 14                                    r3 = 14 as i32 as i64 as u64
lbb_15218:
    ldxb r8, [r2+0x9]                       
    ldxdw r5, [r2+0x1]                      
    mov64 r9, r5                                    r9 = r5
    rsh64 r9, 8                                     r9 >>= 8   ///  r9 = r9.wrapping_shr(8)
    ja lbb_15295                                    if true { pc += 72 }
lbb_15223:
    stxh [r1+0x10], r4                      
    lddw r3, 0x8000000000000003                     r3 load str located at -9223372036854775805
    stxdw [r1+0x8], r3                      
    mov64 r3, 45                                    r3 = 45 as i32 as i64 as u64
    stxw [r1+0x0], r3                       
    jeq r2, 0, lbb_15099                            if r2 == (0 as i32 as i64 as u64) { pc += -131 }
    ja lbb_15238                                    if true { pc += 7 }
lbb_15231:
    stxh [r1+0x10], r4                      
    lddw r3, 0x8000000000000003                     r3 load str located at -9223372036854775805
    stxdw [r1+0x8], r3                      
    mov64 r3, 45                                    r3 = 45 as i32 as i64 as u64
    stxw [r1+0x0], r3                       
    jeq r2, 0, lbb_15099                            if r2 == (0 as i32 as i64 as u64) { pc += -139 }
lbb_15238:
    lsh64 r2, 1                                     r2 <<= 1   ///  r2 = r2.wrapping_shl(1)
    ldxdw r1, [r10-0x40]                    
    mov64 r3, 2                                     r3 = 2 as i32 as i64 as u64
    call function_14411                     
    ja lbb_15099                                    if true { pc += -144 }
lbb_15243:
    mov64 r3, 24                                    r3 = 24 as i32 as i64 as u64
    ldxdw r8, [r10-0x38]                    
    mov64 r4, r8                                    r4 = r8
    and64 r4, -256                                  r4 &= -256   ///  r4 = r4.and(-256)
    ldxdw r5, [r10-0x40]                    
    mov64 r9, r5                                    r9 = r5
    rsh64 r9, 8                                     r9 >>= 8   ///  r9 = r9.wrapping_shr(8)
lbb_15250:
    ldxdw r1, [r10-0xb0]                    
    ja lbb_15070                                    if true { pc += -182 }
lbb_15252:
    mov64 r6, r1                                    r6 = r1
    add64 r2, 2                                     r2 += 2   ///  r2 = r2.wrapping_add(2 as i32 as i64 as u64)
    mov64 r1, r10                                   r1 = r10
    add64 r1, -72                                   r1 += -72   ///  r1 = r1.wrapping_add(-72 as i32 as i64 as u64)
    call function_15690                     
    mov64 r1, r10                                   r1 = r10
    add64 r1, -43                                   r1 += -43   ///  r1 = r1.wrapping_add(-43 as i32 as i64 as u64)
    ldxdw r5, [r10-0x33]                    
    ldxb r4, [r10-0x34]                     
    ldxdw r0, [r10-0x3c]                    
    ldxw r9, [r10-0x48]                     
    jeq r9, 2, lbb_15296                            if r9 == (2 as i32 as i64 as u64) { pc += 32 }
    ldxh r2, [r1+0x0]                       
    ldxb r1, [r1+0x2]                       
    stxb [r10-0x6a], r1                     
    stxh [r10-0x6c], r2                     
    mov64 r3, 6                                     r3 = 6 as i32 as i64 as u64
    ldxdw r2, [r10-0x28]                    
    ldxdw r8, [r10-0x44]                    
    stxdw [r10-0x98], r4                    
    mov64 r4, r8                                    r4 = r8
    and64 r4, -256                                  r4 &= -256   ///  r4 = r4.and(-256)
    lsh64 r9, 24                                    r9 <<= 24   ///  r9 = r9.wrapping_shl(24)
    lsh64 r9, 32                                    r9 <<= 32   ///  r9 = r9.wrapping_shl(32)
    rsh64 r9, 32                                    r9 >>= 32   ///  r9 = r9.wrapping_shr(32)
    mov64 r1, r6                                    r1 = r6
    stxdw [r10-0x90], r0                    
    stxdw [r10-0xa0], r5                    
    mov64 r5, r7                                    r5 = r7
    ja lbb_15070                                    if true { pc += -212 }
lbb_15282:
    ldxdw r8, [r10-0x40]                    
    ldxdw r5, [r10-0x48]                    
lbb_15284:
    stxdw [r10-0x90], r0                    
    mov64 r3, 29                                    r3 = 29 as i32 as i64 as u64
    ja lbb_15291                                    if true { pc += 4 }
lbb_15287:
    ldxdw r8, [r10-0x40]                    
    ldxdw r5, [r10-0x48]                    
lbb_15289:
    stxdw [r10-0x90], r0                    
    mov64 r3, 21                                    r3 = 21 as i32 as i64 as u64
lbb_15291:
    mov64 r4, r8                                    r4 = r8
    and64 r4, -256                                  r4 &= -256   ///  r4 = r4.and(-256)
    mov64 r9, r5                                    r9 = r5
    rsh64 r9, 8                                     r9 >>= 8   ///  r9 = r9.wrapping_shr(8)
lbb_15295:
    ja lbb_15070                                    if true { pc += -226 }
lbb_15296:
    ldxh r2, [r1+0x0]                       
    stxh [r10-0x68], r2                     
    ldxb r1, [r1+0x2]                       
    stxb [r10-0x66], r1                     
    ldxw r3, [r10-0x40]                     
    stxb [r6+0x1f], r1                      
    stxh [r6+0x1d], r2                      
    stxdw [r6+0x15], r5                     
    stxb [r6+0x14], r4                      
    stxdw [r6+0xc], r0                      
    stxw [r6+0x8], r3                       
    mov64 r1, 45                                    r1 = 45 as i32 as i64 as u64
    stxw [r6+0x0], r1                       
    ja lbb_15099                                    if true { pc += -211 }
lbb_15310:
    lsh64 r7, 32                                    r7 <<= 32   ///  r7 = r7.wrapping_shl(32)
    lsh64 r6, 48                                    r6 <<= 48   ///  r6 = r6.wrapping_shl(48)
    or64 r6, r7                                     r6 |= r7   ///  r6 = r6.or(r7)
    or64 r9, r6                                     r9 |= r6   ///  r9 = r9.or(r6)
    ldxdw r1, [r10-0x44]                    
    stxdw [r10-0x88], r1                    
    ldxdw r1, [r10-0x3c]                    
    stxdw [r10-0x60], r1                    
    stxdw [r10-0x80], r1                    
    ldxdw r1, [r10-0x34]                    
    stxdw [r10-0x58], r1                    
    stxdw [r10-0x78], r1                    
    ldxw r1, [r10-0x2c]                     
    stxw [r10-0x50], r1                     
    stxw [r10-0x70], r1                     
    mov64 r3, 20                                    r3 = 20 as i32 as i64 as u64
lbb_15326:
    ldxdw r1, [r10-0x28]                    
    stxdw [r10-0xa8], r1                    
    mov64 r4, r8                                    r4 = r8
    and64 r4, -256                                  r4 &= -256   ///  r4 = r4.and(-256)
    ldxdw r1, [r10-0xb0]                    
    ldxdw r5, [r10-0x90]                    
    ldxdw r5, [r10-0xb8]                    
    ldxdw r0, [r10-0x98]                    
    ldxdw r0, [r10-0xa0]                    
    ja lbb_15070                                    if true { pc += -266 }

function_15336:
    mov64 r7, r2                                    r7 = r2
    mov64 r6, r1                                    r6 = r1
    mov64 r8, 80                                    r8 = 80 as i32 as i64 as u64
    mov64 r1, 80                                    r1 = 80 as i32 as i64 as u64
    mov64 r2, 1                                     r2 = 1 as i32 as i64 as u64
    call function_14385                     
    jeq r0, 0, lbb_15687                            if r0 == (0 as i32 as i64 as u64) { pc += 344 }
    stxdw [r10-0x10], r0                    
    stxdw [r10-0x18], r8                    
    ldxw r1, [r7+0x0]                       
    jsgt r1, 21, lbb_15354                          if (r1 as i64) > (21 as i32 as i64) { pc += 7 }
    jsgt r1, 10, lbb_15368                          if (r1 as i64) > (10 as i32 as i64) { pc += 20 }
    jsgt r1, 4, lbb_15377                           if (r1 as i64) > (4 as i32 as i64) { pc += 28 }
    jsgt r1, 1, lbb_15424                           if (r1 as i64) > (1 as i32 as i64) { pc += 74 }
    jeq r1, 0, lbb_15595                            if r1 == (0 as i32 as i64 as u64) { pc += 244 }
    mov64 r8, 1                                     r8 = 1 as i32 as i64 as u64
    stxb [r0+0x0], r8                       
    ja lbb_15655                                    if true { pc += 301 }
lbb_15354:
    jsgt r1, 32, lbb_15362                          if (r1 as i64) > (32 as i32 as i64) { pc += 7 }
    jsgt r1, 26, lbb_15389                          if (r1 as i64) > (26 as i32 as i64) { pc += 33 }
    jsgt r1, 23, lbb_15471                          if (r1 as i64) > (23 as i32 as i64) { pc += 114 }
    jeq r1, 22, lbb_15640                           if r1 == (22 as i32 as i64 as u64) { pc += 282 }
    ldxdw r1, [r7+0x8]                      
    stxdw [r0+0x1], r1                      
    mov64 r1, 23                                    r1 = 23 as i32 as i64 as u64
    ja lbb_15548                                    if true { pc += 186 }
lbb_15362:
    jsgt r1, 38, lbb_15419                          if (r1 as i64) > (38 as i32 as i64) { pc += 56 }
    jsgt r1, 35, lbb_15479                          if (r1 as i64) > (35 as i32 as i64) { pc += 115 }
    jeq r1, 33, lbb_15624                           if r1 == (33 as i32 as i64 as u64) { pc += 259 }
    jeq r1, 34, lbb_15646                           if r1 == (34 as i32 as i64 as u64) { pc += 280 }
    mov64 r1, 35                                    r1 = 35 as i32 as i64 as u64
    ja lbb_15501                                    if true { pc += 133 }
lbb_15368:
    jsgt r1, 15, lbb_15384                          if (r1 as i64) > (15 as i32 as i64) { pc += 15 }
    jsgt r1, 12, lbb_15430                          if (r1 as i64) > (12 as i32 as i64) { pc += 60 }
    jeq r1, 11, lbb_15559                           if r1 == (11 as i32 as i64 as u64) { pc += 188 }
    ldxdw r1, [r7+0x8]                      
    ldxb r2, [r7+0x10]                      
    stxb [r0+0x9], r2                       
    stxdw [r0+0x1], r1                      
    mov64 r1, 12                                    r1 = 12 as i32 as i64 as u64
    ja lbb_15556                                    if true { pc += 179 }
lbb_15377:
    jsgt r1, 7, lbb_15438                           if (r1 as i64) > (7 as i32 as i64) { pc += 60 }
    jeq r1, 5, lbb_15498                            if r1 == (5 as i32 as i64 as u64) { pc += 119 }
    jeq r1, 6, lbb_15565                            if r1 == (6 as i32 as i64 as u64) { pc += 185 }
    ldxdw r1, [r7+0x8]                      
    stxdw [r0+0x1], r1                      
    mov64 r1, 7                                     r1 = 7 as i32 as i64 as u64
    ja lbb_15548                                    if true { pc += 164 }
lbb_15384:
    jsgt r1, 18, lbb_15442                          if (r1 as i64) > (18 as i32 as i64) { pc += 57 }
    jeq r1, 16, lbb_15500                           if r1 == (16 as i32 as i64 as u64) { pc += 114 }
    jeq r1, 17, lbb_15575                           if r1 == (17 as i32 as i64 as u64) { pc += 188 }
    mov64 r1, 18                                    r1 = 18 as i32 as i64 as u64
    ja lbb_15501                                    if true { pc += 112 }
lbb_15389:
    jsgt r1, 29, lbb_15475                          if (r1 as i64) > (29 as i32 as i64) { pc += 85 }
    jeq r1, 27, lbb_15561                           if r1 == (27 as i32 as i64 as u64) { pc += 170 }
    jeq r1, 28, lbb_15642                           if r1 == (28 as i32 as i64 as u64) { pc += 250 }
    mov64 r1, 29                                    r1 = 29 as i32 as i64 as u64
    stxb [r0+0x0], r1                       
    mov64 r2, 1                                     r2 = 1 as i32 as i64 as u64
    stxdw [r10-0x8], r2                     
    ldxdw r8, [r7+0x18]                     
    jeq r8, 0, lbb_15656                            if r8 == (0 as i32 as i64 as u64) { pc += 258 }
    ldxdw r7, [r7+0x10]                     
    lsh64 r8, 1                                     r8 <<= 1   ///  r8 = r8.wrapping_shl(1)
    ja lbb_15409                                    if true { pc += 8 }
lbb_15401:
    add64 r7, 2                                     r7 += 2   ///  r7 = r7.wrapping_add(2 as i32 as i64 as u64)
    ldxdw r1, [r10-0x10]                    
    add64 r1, r2                                    r1 += r2   ///  r1 = r1.wrapping_add(r2)
    stxh [r1+0x0], r9                       
    add64 r2, 2                                     r2 += 2   ///  r2 = r2.wrapping_add(2 as i32 as i64 as u64)
    stxdw [r10-0x8], r2                     
    add64 r8, -2                                    r8 += -2   ///  r8 = r8.wrapping_add(-2 as i32 as i64 as u64)
    jeq r8, 0, lbb_15656                            if r8 == (0 as i32 as i64 as u64) { pc += 247 }
lbb_15409:
    ldxdw r1, [r10-0x18]                    
    sub64 r1, r2                                    r1 -= r2   ///  r1 = r1.wrapping_sub(r2)
    ldxh r9, [r7+0x0]                       
    jgt r1, 1, lbb_15401                            if r1 > (1 as i32 as i64 as u64) { pc += -12 }
    mov64 r1, r10                                   r1 = r10
    add64 r1, -24                                   r1 += -24   ///  r1 = r1.wrapping_add(-24 as i32 as i64 as u64)
    mov64 r3, 2                                     r3 = 2 as i32 as i64 as u64
    call function_14517                     
    ldxdw r2, [r10-0x8]                     
    ja lbb_15401                                    if true { pc += -18 }
lbb_15419:
    jsgt r1, 41, lbb_15483                          if (r1 as i64) > (41 as i32 as i64) { pc += 63 }
    jeq r1, 39, lbb_15626                           if r1 == (39 as i32 as i64 as u64) { pc += 205 }
    jeq r1, 40, lbb_15648                           if r1 == (40 as i32 as i64 as u64) { pc += 226 }
    mov64 r1, 41                                    r1 = 41 as i32 as i64 as u64
    ja lbb_15653                                    if true { pc += 229 }
lbb_15424:
    jeq r1, 2, lbb_15487                            if r1 == (2 as i32 as i64 as u64) { pc += 62 }
    jeq r1, 3, lbb_15545                            if r1 == (3 as i32 as i64 as u64) { pc += 119 }
    ldxdw r1, [r7+0x8]                      
    stxdw [r0+0x1], r1                      
    mov64 r1, 4                                     r1 = 4 as i32 as i64 as u64
    ja lbb_15548                                    if true { pc += 118 }
lbb_15430:
    jeq r1, 13, lbb_15492                           if r1 == (13 as i32 as i64 as u64) { pc += 61 }
    jeq r1, 14, lbb_15551                           if r1 == (14 as i32 as i64 as u64) { pc += 119 }
    ldxdw r1, [r7+0x8]                      
    ldxb r2, [r7+0x10]                      
    stxb [r0+0x9], r2                       
    stxdw [r0+0x1], r1                      
    mov64 r1, 15                                    r1 = 15 as i32 as i64 as u64
    ja lbb_15556                                    if true { pc += 118 }
lbb_15438:
    jeq r1, 8, lbb_15512                            if r1 == (8 as i32 as i64 as u64) { pc += 73 }
    jeq r1, 9, lbb_15577                            if r1 == (9 as i32 as i64 as u64) { pc += 137 }
    mov64 r1, 10                                    r1 = 10 as i32 as i64 as u64
    ja lbb_15653                                    if true { pc += 211 }
lbb_15442:
    jeq r1, 19, lbb_15516                           if r1 == (19 as i32 as i64 as u64) { pc += 73 }
    jeq r1, 20, lbb_15579                           if r1 == (20 as i32 as i64 as u64) { pc += 135 }
    mov64 r1, 21                                    r1 = 21 as i32 as i64 as u64
    stxb [r0+0x0], r1                       
    mov64 r2, 1                                     r2 = 1 as i32 as i64 as u64
    stxdw [r10-0x8], r2                     
    ldxdw r8, [r7+0x18]                     
    jeq r8, 0, lbb_15656                            if r8 == (0 as i32 as i64 as u64) { pc += 206 }
    ldxdw r7, [r7+0x10]                     
    lsh64 r8, 1                                     r8 <<= 1   ///  r8 = r8.wrapping_shl(1)
    ja lbb_15461                                    if true { pc += 8 }
lbb_15453:
    add64 r7, 2                                     r7 += 2   ///  r7 = r7.wrapping_add(2 as i32 as i64 as u64)
    ldxdw r1, [r10-0x10]                    
    add64 r1, r2                                    r1 += r2   ///  r1 = r1.wrapping_add(r2)
    stxh [r1+0x0], r9                       
    add64 r2, 2                                     r2 += 2   ///  r2 = r2.wrapping_add(2 as i32 as i64 as u64)
    stxdw [r10-0x8], r2                     
    add64 r8, -2                                    r8 += -2   ///  r8 = r8.wrapping_add(-2 as i32 as i64 as u64)
    jeq r8, 0, lbb_15656                            if r8 == (0 as i32 as i64 as u64) { pc += 195 }
lbb_15461:
    ldxdw r1, [r10-0x18]                    
    sub64 r1, r2                                    r1 -= r2   ///  r1 = r1.wrapping_sub(r2)
    ldxh r9, [r7+0x0]                       
    jgt r1, 1, lbb_15453                            if r1 > (1 as i32 as i64 as u64) { pc += -12 }
    mov64 r1, r10                                   r1 = r10
    add64 r1, -24                                   r1 += -24   ///  r1 = r1.wrapping_add(-24 as i32 as i64 as u64)
    mov64 r3, 2                                     r3 = 2 as i32 as i64 as u64
    call function_14517                     
    ldxdw r2, [r10-0x8]                     
    ja lbb_15453                                    if true { pc += -18 }
lbb_15471:
    jeq r1, 24, lbb_15522                           if r1 == (24 as i32 as i64 as u64) { pc += 50 }
    jeq r1, 25, lbb_15632                           if r1 == (25 as i32 as i64 as u64) { pc += 159 }
    mov64 r1, 26                                    r1 = 26 as i32 as i64 as u64
    ja lbb_15653                                    if true { pc += 178 }
lbb_15475:
    jeq r1, 30, lbb_15563                           if r1 == (30 as i32 as i64 as u64) { pc += 87 }
    jeq r1, 31, lbb_15644                           if r1 == (31 as i32 as i64 as u64) { pc += 167 }
    mov64 r1, 32                                    r1 = 32 as i32 as i64 as u64
    ja lbb_15653                                    if true { pc += 174 }
lbb_15479:
    jeq r1, 36, lbb_15628                           if r1 == (36 as i32 as i64 as u64) { pc += 148 }
    jeq r1, 37, lbb_15650                           if r1 == (37 as i32 as i64 as u64) { pc += 169 }
    mov64 r1, 38                                    r1 = 38 as i32 as i64 as u64
    ja lbb_15653                                    if true { pc += 170 }
lbb_15483:
    jeq r1, 42, lbb_15630                           if r1 == (42 as i32 as i64 as u64) { pc += 146 }
    jeq r1, 43, lbb_15652                           if r1 == (43 as i32 as i64 as u64) { pc += 167 }
    mov64 r1, 44                                    r1 = 44 as i32 as i64 as u64
    ja lbb_15653                                    if true { pc += 166 }
lbb_15487:
    ldxb r1, [r7+0x8]                       
    stxb [r0+0x1], r1                       
    mov64 r8, 2                                     r8 = 2 as i32 as i64 as u64
    stxb [r0+0x0], r8                       
    ja lbb_15655                                    if true { pc += 163 }
lbb_15492:
    ldxdw r1, [r7+0x8]                      
    ldxb r2, [r7+0x10]                      
    stxb [r0+0x9], r2                       
    stxdw [r0+0x1], r1                      
    mov64 r1, 13                                    r1 = 13 as i32 as i64 as u64
    ja lbb_15556                                    if true { pc += 58 }
lbb_15498:
    mov64 r1, 5                                     r1 = 5 as i32 as i64 as u64
    ja lbb_15653                                    if true { pc += 153 }
lbb_15500:
    mov64 r1, 16                                    r1 = 16 as i32 as i64 as u64
lbb_15501:
    stxb [r0+0x0], r1                       
    ldxdw r1, [r7+0x8]                      
    stxdw [r0+0x1], r1                      
    ldxdw r1, [r7+0x10]                     
    stxdw [r0+0x9], r1                      
    ldxdw r1, [r7+0x18]                     
    stxdw [r0+0x11], r1                     
    ldxdw r1, [r7+0x20]                     
    stxdw [r0+0x19], r1                     
    mov64 r8, 33                                    r8 = 33 as i32 as i64 as u64
    ja lbb_15655                                    if true { pc += 143 }
lbb_15512:
    ldxdw r1, [r7+0x8]                      
    stxdw [r0+0x1], r1                      
    mov64 r1, 8                                     r1 = 8 as i32 as i64 as u64
    ja lbb_15548                                    if true { pc += 32 }
lbb_15516:
    ldxb r1, [r7+0x8]                       
    stxb [r0+0x1], r1                       
    mov64 r1, 19                                    r1 = 19 as i32 as i64 as u64
    stxb [r0+0x0], r1                       
    mov64 r8, 2                                     r8 = 2 as i32 as i64 as u64
    ja lbb_15655                                    if true { pc += 133 }
lbb_15522:
    mov64 r1, 24                                    r1 = 24 as i32 as i64 as u64
    stxb [r0+0x0], r1                       
    mov64 r8, 1                                     r8 = 1 as i32 as i64 as u64
    stxdw [r10-0x8], r8                     
    ldxdw r2, [r7+0x8]                      
    ldxdw r7, [r7+0x10]                     
    mov64 r1, 80                                    r1 = 80 as i32 as i64 as u64
    jgt r1, r7, lbb_15539                           if r1 > r7 { pc += 9 }
    mov64 r1, r10                                   r1 = r10
    add64 r1, -24                                   r1 += -24   ///  r1 = r1.wrapping_add(-24 as i32 as i64 as u64)
    mov64 r8, r2                                    r8 = r2
    mov64 r2, 1                                     r2 = 1 as i32 as i64 as u64
    mov64 r3, r7                                    r3 = r7
    call function_14517                     
    mov64 r2, r8                                    r2 = r8
    ldxdw r0, [r10-0x10]                    
    ldxdw r8, [r10-0x8]                     
lbb_15539:
    add64 r0, r8                                    r0 += r8   ///  r0 = r0.wrapping_add(r8)
    mov64 r1, r0                                    r1 = r0
    mov64 r3, r7                                    r3 = r7
    call function_30349                     
    add64 r8, r7                                    r8 += r7   ///  r8 = r8.wrapping_add(r7)
    ja lbb_15655                                    if true { pc += 110 }
lbb_15545:
    ldxdw r1, [r7+0x8]                      
    stxdw [r0+0x1], r1                      
    mov64 r1, 3                                     r1 = 3 as i32 as i64 as u64
lbb_15548:
    stxb [r0+0x0], r1                       
    mov64 r8, 9                                     r8 = 9 as i32 as i64 as u64
    ja lbb_15655                                    if true { pc += 104 }
lbb_15551:
    ldxdw r1, [r7+0x8]                      
    ldxb r2, [r7+0x10]                      
    stxb [r0+0x9], r2                       
    stxdw [r0+0x1], r1                      
    mov64 r1, 14                                    r1 = 14 as i32 as i64 as u64
lbb_15556:
    stxb [r0+0x0], r1                       
    mov64 r8, 10                                    r8 = 10 as i32 as i64 as u64
    ja lbb_15655                                    if true { pc += 96 }
lbb_15559:
    mov64 r1, 11                                    r1 = 11 as i32 as i64 as u64
    ja lbb_15653                                    if true { pc += 92 }
lbb_15561:
    mov64 r1, 27                                    r1 = 27 as i32 as i64 as u64
    ja lbb_15653                                    if true { pc += 90 }
lbb_15563:
    mov64 r1, 30                                    r1 = 30 as i32 as i64 as u64
    ja lbb_15653                                    if true { pc += 88 }
lbb_15565:
    mov64 r1, 6                                     r1 = 6 as i32 as i64 as u64
    stxb [r0+0x0], r1                       
    ldxb r1, [r7+0x8]                       
    stxb [r0+0x1], r1                       
    ldxw r1, [r7+0xc]                       
    jne r1, 0, lbb_15663                            if r1 != (0 as i32 as i64 as u64) { pc += 92 }
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    stxb [r0+0x2], r1                       
    mov64 r8, 3                                     r8 = 3 as i32 as i64 as u64
    ja lbb_15655                                    if true { pc += 80 }
lbb_15575:
    mov64 r1, 17                                    r1 = 17 as i32 as i64 as u64
    ja lbb_15653                                    if true { pc += 76 }
lbb_15577:
    mov64 r1, 9                                     r1 = 9 as i32 as i64 as u64
    ja lbb_15653                                    if true { pc += 74 }
lbb_15579:
    ldxb r1, [r7+0x8]                       
    stxb [r0+0x1], r1                       
    mov64 r1, 20                                    r1 = 20 as i32 as i64 as u64
    stxb [r0+0x0], r1                       
    ldxdw r1, [r7+0x21]                     
    stxdw [r0+0x1a], r1                     
    ldxdw r1, [r7+0x19]                     
    stxdw [r0+0x12], r1                     
    ldxdw r1, [r7+0x11]                     
    stxdw [r0+0xa], r1                      
    ldxdw r1, [r7+0x9]                      
    stxdw [r0+0x2], r1                      
    ldxw r1, [r7+0x2c]                      
    jne r1, 0, lbb_15612                            if r1 != (0 as i32 as i64 as u64) { pc += 19 }
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    ja lbb_15609                                    if true { pc += 14 }
lbb_15595:
    ldxb r1, [r7+0x8]                       
    stxb [r0+0x1], r1                       
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    stxb [r0+0x0], r1                       
    ldxdw r2, [r7+0x21]                     
    stxdw [r0+0x1a], r2                     
    ldxdw r2, [r7+0x19]                     
    stxdw [r0+0x12], r2                     
    ldxdw r2, [r7+0x11]                     
    stxdw [r0+0xa], r2                      
    ldxdw r2, [r7+0x9]                      
    stxdw [r0+0x2], r2                      
    ldxw r2, [r7+0x2c]                      
    jne r2, 0, lbb_15612                            if r2 != (0 as i32 as i64 as u64) { pc += 3 }
lbb_15609:
    stxb [r0+0x22], r1                      
    mov64 r8, 35                                    r8 = 35 as i32 as i64 as u64
    ja lbb_15655                                    if true { pc += 43 }
lbb_15612:
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    stxb [r0+0x22], r1                      
    ldxdw r1, [r7+0x30]                     
    stxdw [r0+0x23], r1                     
    ldxdw r1, [r7+0x38]                     
    stxdw [r0+0x2b], r1                     
    ldxdw r1, [r7+0x40]                     
    stxdw [r0+0x33], r1                     
    ldxdw r1, [r7+0x48]                     
    stxdw [r0+0x3b], r1                     
    mov64 r8, 67                                    r8 = 67 as i32 as i64 as u64
    ja lbb_15655                                    if true { pc += 31 }
lbb_15624:
    mov64 r1, 33                                    r1 = 33 as i32 as i64 as u64
    ja lbb_15653                                    if true { pc += 27 }
lbb_15626:
    mov64 r1, 39                                    r1 = 39 as i32 as i64 as u64
    ja lbb_15653                                    if true { pc += 25 }
lbb_15628:
    mov64 r1, 36                                    r1 = 36 as i32 as i64 as u64
    ja lbb_15653                                    if true { pc += 23 }
lbb_15630:
    mov64 r1, 42                                    r1 = 42 as i32 as i64 as u64
    ja lbb_15653                                    if true { pc += 21 }
lbb_15632:
    mov64 r1, 25                                    r1 = 25 as i32 as i64 as u64
    stxb [r0+0x0], r1                       
    ldxw r1, [r7+0x8]                       
    jne r1, 0, lbb_15675                            if r1 != (0 as i32 as i64 as u64) { pc += 39 }
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    stxb [r0+0x1], r1                       
    mov64 r8, 2                                     r8 = 2 as i32 as i64 as u64
    ja lbb_15655                                    if true { pc += 15 }
lbb_15640:
    mov64 r1, 22                                    r1 = 22 as i32 as i64 as u64
    ja lbb_15653                                    if true { pc += 11 }
lbb_15642:
    mov64 r1, 28                                    r1 = 28 as i32 as i64 as u64
    ja lbb_15653                                    if true { pc += 9 }
lbb_15644:
    mov64 r1, 31                                    r1 = 31 as i32 as i64 as u64
    ja lbb_15653                                    if true { pc += 7 }
lbb_15646:
    mov64 r1, 34                                    r1 = 34 as i32 as i64 as u64
    ja lbb_15653                                    if true { pc += 5 }
lbb_15648:
    mov64 r1, 40                                    r1 = 40 as i32 as i64 as u64
    ja lbb_15653                                    if true { pc += 3 }
lbb_15650:
    mov64 r1, 37                                    r1 = 37 as i32 as i64 as u64
    ja lbb_15653                                    if true { pc += 1 }
lbb_15652:
    mov64 r1, 43                                    r1 = 43 as i32 as i64 as u64
lbb_15653:
    stxb [r0+0x0], r1                       
    mov64 r8, 1                                     r8 = 1 as i32 as i64 as u64
lbb_15655:
    stxdw [r10-0x8], r8                     
lbb_15656:
    ldxdw r1, [r10-0x8]                     
    stxdw [r6+0x10], r1                     
    ldxdw r1, [r10-0x10]                    
    stxdw [r6+0x8], r1                      
    ldxdw r1, [r10-0x18]                    
    stxdw [r6+0x0], r1                      
    exit                                    
lbb_15663:
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    stxb [r0+0x2], r1                       
    ldxdw r1, [r7+0x10]                     
    stxdw [r0+0x3], r1                      
    ldxdw r1, [r7+0x18]                     
    stxdw [r0+0xb], r1                      
    ldxdw r1, [r7+0x20]                     
    stxdw [r0+0x13], r1                     
    ldxdw r1, [r7+0x28]                     
    stxdw [r0+0x1b], r1                     
    mov64 r8, 35                                    r8 = 35 as i32 as i64 as u64
    ja lbb_15655                                    if true { pc += -20 }
lbb_15675:
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    stxb [r0+0x1], r1                       
    ldxdw r1, [r7+0xc]                      
    stxdw [r0+0x2], r1                      
    ldxdw r1, [r7+0x14]                     
    stxdw [r0+0xa], r1                      
    ldxdw r1, [r7+0x1c]                     
    stxdw [r0+0x12], r1                     
    ldxdw r1, [r7+0x24]                     
    stxdw [r0+0x1a], r1                     
    mov64 r8, 34                                    r8 = 34 as i32 as i64 as u64
    ja lbb_15655                                    if true { pc += -32 }
lbb_15687:
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    mov64 r2, 80                                    r2 = 80 as i32 as i64 as u64
    call function_21549                     

function_15690:
    jeq r3, 0, lbb_15694                            if r3 == (0 as i32 as i64 as u64) { pc += 3 }
    ldxb r4, [r2+0x0]                       
    jeq r4, 0, lbb_15721                            if r4 == (0 as i32 as i64 as u64) { pc += 28 }
    jeq r4, 1, lbb_15702                            if r4 == (1 as i32 as i64 as u64) { pc += 8 }
lbb_15694:
    mov64 r2, 12                                    r2 = 12 as i32 as i64 as u64
    stxw [r1+0x10], r2                      
    lddw r2, 0x8000000000000000                     r2 load str located at -9223372036854775808
    stxdw [r1+0x8], r2                      
    mov64 r2, 2                                     r2 = 2 as i32 as i64 as u64
    stxw [r1+0x0], r2                       
    ja lbb_15727                                    if true { pc += 25 }
lbb_15702:
    mov64 r4, 33                                    r4 = 33 as i32 as i64 as u64
    jgt r4, r3, lbb_15694                           if r4 > r3 { pc += -10 }
    add64 r3, -33                                   r3 += -33   ///  r3 = r3.wrapping_add(-33 as i32 as i64 as u64)
    ldxdw r4, [r2+0x1]                      
    ldxdw r5, [r2+0xd]                      
    ldxdw r0, [r2+0x15]                     
    ldxw r6, [r2+0x1d]                      
    ldxw r7, [r2+0x9]                       
    stxdw [r1+0x30], r3                     
    add64 r2, 33                                    r2 += 33   ///  r2 = r2.wrapping_add(33 as i32 as i64 as u64)
    stxdw [r1+0x28], r2                     
    stxw [r1+0xc], r7                       
    mov64 r2, 1                                     r2 = 1 as i32 as i64 as u64
    stxw [r1+0x0], r2                       
    stxw [r1+0x20], r6                      
    stxdw [r1+0x18], r0                     
    stxdw [r1+0x10], r5                     
    stxdw [r1+0x4], r4                      
    ja lbb_15727                                    if true { pc += 6 }
lbb_15721:
    add64 r2, 1                                     r2 += 1   ///  r2 = r2.wrapping_add(1 as i32 as i64 as u64)
    stxdw [r1+0x28], r2                     
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
    stxw [r1+0x0], r2                       
    add64 r3, -1                                    r3 += -1   ///  r3 = r3.wrapping_add(-1 as i32 as i64 as u64)
    stxdw [r1+0x30], r3                     
lbb_15727:
    exit                                    

function_15728:
    mov64 r9, r4                                    r9 = r4
    mov64 r8, r3                                    r8 = r3
    mov64 r7, r2                                    r7 = r2
    mov64 r6, r1                                    r6 = r1
    ldxdw r1, [r7+0x0]                      
    lddw r2, 0xde8f75eee1f6dd06                     r2 load str located at -2409577606766207738
    jeq r1, r2, lbb_15738                           if r1 == r2 { pc += 2 }
lbb_15736:
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    ja lbb_15751                                    if true { pc += 13 }
lbb_15738:
    ldxdw r1, [r7+0x8]                      
    lddw r2, 0xdacd6ce4bc5d4218                     r2 load str located at -2680366473547005416
    jne r1, r2, lbb_15736                           if r1 != r2 { pc += -6 }
    ldxdw r1, [r7+0x10]                     
    lddw r2, 0x270db9834dfc1ab6                     r2 load str located at 2814109315776649910
    jne r1, r2, lbb_15736                           if r1 != r2 { pc += -10 }
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    ldxdw r2, [r7+0x18]                     
    lddw r3, 0xfc8ba1d828f9bdfe                     r3 load str located at -248927404616466946
    jne r2, r3, lbb_15736                           if r2 != r3 { pc += -15 }
lbb_15751:
    jeq r1, 0, lbb_15772                            if r1 == (0 as i32 as i64 as u64) { pc += 20 }
    ldxdw r1, [r7+0x0]                      
    lddw r2, 0x93a165d7e1f6dd06                     r2 load str located at -7808848301000303354
    jeq r1, r2, lbb_15758                           if r1 == r2 { pc += 2 }
lbb_15756:
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    ja lbb_15771                                    if true { pc += 13 }
lbb_15758:
    ldxdw r1, [r7+0x8]                      
    lddw r2, 0xac79ebce46e1cbd9                     r2 load str located at -6018520155818964007
    jne r1, r2, lbb_15756                           if r1 != r2 { pc += -6 }
    ldxdw r1, [r7+0x10]                     
    lddw r2, 0x91375b5fed85b41c                     r2 load str located at -7982811346925931492
    jne r1, r2, lbb_15756                           if r1 != r2 { pc += -10 }
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    ldxdw r2, [r7+0x18]                     
    lddw r3, 0xa900ff7e85f58c3a                     r3 load str located at -6268729762421306310
    jne r2, r3, lbb_15756                           if r2 != r3 { pc += -15 }
lbb_15771:
    jne r1, 0, lbb_15847                            if r1 != (0 as i32 as i64 as u64) { pc += 75 }
lbb_15772:
    stxdw [r10-0x20], r5                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -24                                   r1 += -24   ///  r1 = r1.wrapping_add(-24 as i32 as i64 as u64)
    lddw r2, 0x10003ec50 --> b"\x01\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\…        r2 load str located at 4295224400
    call function_15336                     
    mov64 r1, 136                                   r1 = 136 as i32 as i64 as u64
    mov64 r2, 1                                     r2 = 1 as i32 as i64 as u64
    call function_14385                     
    jne r0, 0, lbb_15785                            if r0 != (0 as i32 as i64 as u64) { pc += 3 }
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    mov64 r2, 136                                   r2 = 136 as i32 as i64 as u64
    call function_21552                     
lbb_15785:
    ldxdw r1, [r8+0x18]                     
    stxdw [r0+0x18], r1                     
    ldxdw r1, [r8+0x10]                     
    stxdw [r0+0x10], r1                     
    ldxdw r1, [r8+0x8]                      
    stxdw [r0+0x8], r1                      
    ldxdw r1, [r8+0x0]                      
    stxdw [r0+0x0], r1                      
    mov64 r1, 256                                   r1 = 256 as i32 as i64 as u64
    stxh [r0+0x20], r1                      
    ldxdw r1, [r9+0x0]                      
    stxdw [r0+0x22], r1                     
    ldxdw r1, [r9+0x8]                      
    stxdw [r0+0x2a], r1                     
    ldxdw r1, [r9+0x10]                     
    stxdw [r0+0x32], r1                     
    ldxdw r1, [r9+0x18]                     
    stxdw [r0+0x3a], r1                     
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    stxh [r0+0x42], r1                      
    ldxdw r3, [r10-0x20]                    
    ldxdw r2, [r3+0x0]                      
    stxdw [r0+0x44], r2                     
    ldxdw r2, [r3+0x8]                      
    stxdw [r0+0x4c], r2                     
    ldxdw r2, [r3+0x10]                     
    stxdw [r0+0x54], r2                     
    ldxdw r2, [r3+0x18]                     
    stxdw [r0+0x5c], r2                     
    lddw r2, 0x8ad9dbe3                             r2 load str located at 2329533411
    stxdw [r0+0x7e], r2                     
    lddw r2, 0x44fda19b08eeda58                     r2 load str located at 4971307250928769624
    stxdw [r0+0x76], r2                     
    lddw r2, 0x7ff14a3d4cc98c21                     r2 load str located at 9219231539345853473
    stxdw [r0+0x6e], r2                     
    lddw r2, 0x515c2c1917d5a706                     r2 load str located at 5862609301215225606
    stxdw [r0+0x66], r2                     
    stxh [r0+0x64], r1                      
    stxh [r0+0x86], r1                      
    ldxdw r1, [r7+0x18]                     
    stxdw [r6+0x48], r1                     
    ldxdw r1, [r7+0x10]                     
    stxdw [r6+0x40], r1                     
    ldxdw r1, [r7+0x8]                      
    stxdw [r6+0x38], r1                     
    ldxdw r1, [r7+0x0]                      
    stxdw [r6+0x30], r1                     
    ldxdw r1, [r10-0x18]                    
    stxdw [r6+0x18], r1                     
    ldxdw r1, [r10-0x10]                    
    stxdw [r6+0x20], r1                     
    ldxdw r1, [r10-0x8]                     
    stxdw [r6+0x28], r1                     
    stxdw [r6+0x8], r0                      
    mov64 r1, 4                                     r1 = 4 as i32 as i64 as u64
    stxdw [r6+0x10], r1                     
    stxdw [r6+0x0], r1                      
    ja lbb_15853                                    if true { pc += 6 }
lbb_15847:
    lddw r1, 0x8000000000000000                     r1 load str located at -9223372036854775808
    stxdw [r6+0x0], r1                      
    lddw r1, 0x8000000000000006                     r1 load str located at -9223372036854775802
    stxdw [r6+0x8], r1                      
lbb_15853:
    exit                                    

function_15854:
    mov64 r9, r4                                    r9 = r4
    stxdw [r10-0x98], r3                    
    ldxdw r3, [r2+0x0]                      
    lddw r4, 0xde8f75eee1f6dd06                     r4 load str located at -2409577606766207738
    jeq r3, r4, lbb_15862                           if r3 == r4 { pc += 2 }
lbb_15860:
    mov64 r3, 1                                     r3 = 1 as i32 as i64 as u64
    ja lbb_15875                                    if true { pc += 13 }
lbb_15862:
    ldxdw r3, [r2+0x8]                      
    lddw r4, 0xdacd6ce4bc5d4218                     r4 load str located at -2680366473547005416
    jne r3, r4, lbb_15860                           if r3 != r4 { pc += -6 }
    ldxdw r3, [r2+0x10]                     
    lddw r4, 0x270db9834dfc1ab6                     r4 load str located at 2814109315776649910
    jne r3, r4, lbb_15860                           if r3 != r4 { pc += -10 }
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
    ldxdw r4, [r2+0x18]                     
    lddw r0, 0xfc8ba1d828f9bdfe                     r0 load str located at -248927404616466946
    jne r4, r0, lbb_15860                           if r4 != r0 { pc += -15 }
lbb_15875:
    ldxdw r6, [r5-0xfd8]                    
    ldxdw r0, [r5-0xfe0]                    
    ldxdw r8, [r5-0xfe8]                    
    ldxdw r7, [r5-0xff0]                    
    ldxdw r4, [r5-0xff8]                    
    stxdw [r10-0x88], r4                    
    ldxdw r4, [r5-0x1000]                   
    stxdw [r10-0x90], r4                    
    jeq r3, 0, lbb_15904                            if r3 == (0 as i32 as i64 as u64) { pc += 20 }
    ldxdw r3, [r2+0x0]                      
    lddw r4, 0x93a165d7e1f6dd06                     r4 load str located at -7808848301000303354
    jeq r3, r4, lbb_15890                           if r3 == r4 { pc += 2 }
lbb_15888:
    mov64 r3, 1                                     r3 = 1 as i32 as i64 as u64
    ja lbb_15903                                    if true { pc += 13 }
lbb_15890:
    ldxdw r3, [r2+0x8]                      
    lddw r4, 0xac79ebce46e1cbd9                     r4 load str located at -6018520155818964007
    jne r3, r4, lbb_15888                           if r3 != r4 { pc += -6 }
    ldxdw r3, [r2+0x10]                     
    lddw r4, 0x91375b5fed85b41c                     r4 load str located at -7982811346925931492
    jne r3, r4, lbb_15888                           if r3 != r4 { pc += -10 }
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
    ldxdw r4, [r2+0x18]                     
    lddw r5, 0xa900ff7e85f58c3a                     r5 load str located at -6268729762421306310
    jne r4, r5, lbb_15888                           if r4 != r5 { pc += -15 }
lbb_15903:
    jne r3, 0, lbb_15945                            if r3 != (0 as i32 as i64 as u64) { pc += 41 }
lbb_15904:
    stxdw [r10-0xa8], r2                    
    stxdw [r10-0xa0], r1                    
    stxb [r10-0x40], r6                     
    stxdw [r10-0x48], r0                    
    mov64 r1, 12                                    r1 = 12 as i32 as i64 as u64
    stxw [r10-0x50], r1                     
    mov64 r1, r10                                   r1 = r10
    add64 r1, -128                                  r1 += -128   ///  r1 = r1.wrapping_add(-128 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -80                                   r2 += -80   ///  r2 = r2.wrapping_add(-80 as i32 as i64 as u64)
    call function_15336                     
    mov64 r6, r8                                    r6 = r8
    add64 r6, 4                                     r6 += 4   ///  r6 = r6.wrapping_add(4 as i32 as i64 as u64)
    jeq r6, 0, lbb_15952                            if r6 == (0 as i32 as i64 as u64) { pc += 34 }
    stxdw [r10-0xb8], r9                    
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    stxdw [r10-0xb0], r1                    
    mov64 r9, r6                                    r9 = r6
    mul64 r9, 34                                    r9 *= 34   ///  r9 = r9.wrapping_mul(34 as u64)
    lddw r1, 0x3c3c3c3c3c3c3c3                      r1 load str located at 271275648142787523
    jgt r6, r1, lbb_16107                           if r6 > r1 { pc += 181 }
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    stxdw [r10-0xb0], r1                    
    mov64 r1, r9                                    r1 = r9
    mov64 r2, 1                                     r2 = 1 as i32 as i64 as u64
    call function_14385                     
    jeq r0, 0, lbb_16107                            if r0 == (0 as i32 as i64 as u64) { pc += 175 }
    stxdw [r10-0x60], r0                    
    stxdw [r10-0x68], r6                    
    ldxdw r2, [r10-0x98]                    
    ldxdw r1, [r2+0x18]                     
    stxdw [r10-0x38], r1                    
    ldxdw r1, [r2+0x10]                     
    stxdw [r10-0x40], r1                    
    ldxdw r1, [r2+0x8]                      
    stxdw [r10-0x48], r1                    
    ldxdw r1, [r2+0x0]                      
    stxdw [r10-0x50], r1                    
    ldxdw r9, [r10-0xb8]                    
    ja lbb_15971                                    if true { pc += 26 }
lbb_15945:
    lddw r2, 0x8000000000000000                     r2 load str located at -9223372036854775808
    stxdw [r1+0x0], r2                      
    lddw r2, 0x8000000000000006                     r2 load str located at -9223372036854775802
    stxdw [r1+0x8], r2                      
    ja lbb_16106                                    if true { pc += 154 }
lbb_15952:
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    stxdw [r10-0x60], r1                    
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    stxdw [r10-0x58], r1                    
    stxdw [r10-0x68], r1                    
    ldxdw r2, [r10-0x98]                    
    ldxdw r1, [r2+0x18]                     
    stxdw [r10-0x38], r1                    
    ldxdw r1, [r2+0x10]                     
    stxdw [r10-0x40], r1                    
    ldxdw r1, [r2+0x8]                      
    stxdw [r10-0x48], r1                    
    ldxdw r1, [r2+0x0]                      
    stxdw [r10-0x50], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -104                                  r1 += -104   ///  r1 = r1.wrapping_add(-104 as i32 as i64 as u64)
    call function_14604                     
    ldxdw r6, [r10-0x68]                    
    ldxdw r0, [r10-0x60]                    
lbb_15971:
    ldxdw r1, [r10-0x38]                    
    stxdw [r0+0x18], r1                     
    ldxdw r1, [r10-0x40]                    
    stxdw [r0+0x10], r1                     
    ldxdw r1, [r10-0x48]                    
    stxdw [r0+0x8], r1                      
    ldxdw r1, [r10-0x50]                    
    stxdw [r0+0x0], r1                      
    mov64 r1, 256                                   r1 = 256 as i32 as i64 as u64
    stxh [r0+0x20], r1                      
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    stxdw [r10-0x58], r1                    
    jne r6, 1, lbb_15989                            if r6 != (1 as i32 as i64 as u64) { pc += 5 }
    mov64 r1, r10                                   r1 = r10
    add64 r1, -104                                  r1 += -104   ///  r1 = r1.wrapping_add(-104 as i32 as i64 as u64)
    call function_14604                     
    ldxdw r6, [r10-0x68]                    
    ldxdw r0, [r10-0x60]                    
lbb_15989:
    ldxdw r1, [r9+0x18]                     
    stxdw [r0+0x3a], r1                     
    ldxdw r1, [r9+0x10]                     
    stxdw [r0+0x32], r1                     
    ldxdw r1, [r9+0x8]                      
    stxdw [r0+0x2a], r1                     
    ldxdw r1, [r9+0x0]                      
    stxdw [r0+0x22], r1                     
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    stxh [r0+0x42], r1                      
    mov64 r1, 2                                     r1 = 2 as i32 as i64 as u64
    stxdw [r10-0x58], r1                    
    jne r6, 2, lbb_16007                            if r6 != (2 as i32 as i64 as u64) { pc += 5 }
    mov64 r1, r10                                   r1 = r10
    add64 r1, -104                                  r1 += -104   ///  r1 = r1.wrapping_add(-104 as i32 as i64 as u64)
    call function_14604                     
    ldxdw r6, [r10-0x68]                    
    ldxdw r0, [r10-0x60]                    
lbb_16007:
    ldxdw r2, [r10-0x90]                    
    ldxdw r1, [r2+0x18]                     
    stxdw [r0+0x5c], r1                     
    ldxdw r1, [r2+0x10]                     
    stxdw [r0+0x54], r1                     
    ldxdw r1, [r2+0x8]                      
    stxdw [r0+0x4c], r1                     
    ldxdw r1, [r2+0x0]                      
    stxdw [r0+0x44], r1                     
    mov64 r1, 256                                   r1 = 256 as i32 as i64 as u64
    stxh [r0+0x64], r1                      
    mov64 r9, 1                                     r9 = 1 as i32 as i64 as u64
    jeq r8, 0, lbb_16021                            if r8 == (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r9, 0                                     r9 = 0 as i32 as i64 as u64
lbb_16021:
    mov64 r1, 3                                     r1 = 3 as i32 as i64 as u64
    stxdw [r10-0x58], r1                    
    jne r6, 3, lbb_16028                            if r6 != (3 as i32 as i64 as u64) { pc += 4 }
    mov64 r1, r10                                   r1 = r10
    add64 r1, -104                                  r1 += -104   ///  r1 = r1.wrapping_add(-104 as i32 as i64 as u64)
    call function_14604                     
    ldxdw r0, [r10-0x60]                    
lbb_16028:
    ldxdw r2, [r10-0x88]                    
    ldxdw r1, [r2+0x18]                     
    stxdw [r0+0x7e], r1                     
    ldxdw r1, [r2+0x10]                     
    stxdw [r0+0x76], r1                     
    ldxdw r1, [r2+0x8]                      
    stxdw [r0+0x6e], r1                     
    ldxdw r1, [r2+0x0]                      
    stxdw [r0+0x66], r1                     
    mov64 r6, 0                                     r6 = 0 as i32 as i64 as u64
    stxb [r0+0x87], r6                      
    stxb [r0+0x86], r9                      
    mov64 r9, 4                                     r9 = 4 as i32 as i64 as u64
    stxdw [r10-0x58], r9                    
    jeq r8, 0, lbb_16080                            if r8 == (0 as i32 as i64 as u64) { pc += 37 }
    lsh64 r8, 3                                     r8 <<= 3   ///  r8 = r8.wrapping_shl(3)
    mov64 r3, 1                                     r3 = 1 as i32 as i64 as u64
    ja lbb_16063                                    if true { pc += 17 }
lbb_16046:
    add64 r7, 8                                     r7 += 8   ///  r7 = r7.wrapping_add(8 as i32 as i64 as u64)
    mov64 r1, r0                                    r1 = r0
    add64 r1, r6                                    r1 += r6   ///  r1 = r1.wrapping_add(r6)
    ldxdw r2, [r10-0x38]                    
    stxdw [r1+0xa0], r2                     
    ldxdw r2, [r10-0x40]                    
    stxdw [r1+0x98], r2                     
    ldxdw r2, [r10-0x48]                    
    stxdw [r1+0x90], r2                     
    ldxdw r2, [r10-0x50]                    
    stxdw [r1+0x88], r2                     
    stxh [r1+0xa8], r3                      
    add64 r6, 34                                    r6 += 34   ///  r6 = r6.wrapping_add(34 as i32 as i64 as u64)
    add64 r9, 1                                     r9 += 1   ///  r9 = r9.wrapping_add(1 as i32 as i64 as u64)
    stxdw [r10-0x58], r9                    
    add64 r8, -8                                    r8 += -8   ///  r8 = r8.wrapping_add(-8 as i32 as i64 as u64)
    jeq r8, 0, lbb_16080                            if r8 == (0 as i32 as i64 as u64) { pc += 17 }
lbb_16063:
    ldxdw r1, [r7+0x0]                      
    ldxdw r2, [r1+0x18]                     
    stxdw [r10-0x38], r2                    
    ldxdw r2, [r1+0x10]                     
    stxdw [r10-0x40], r2                    
    ldxdw r2, [r1+0x8]                      
    stxdw [r10-0x48], r2                    
    ldxdw r1, [r1+0x0]                      
    stxdw [r10-0x50], r1                    
    ldxdw r1, [r10-0x68]                    
    jne r9, r1, lbb_16046                           if r9 != r1 { pc += -28 }
    mov64 r1, r10                                   r1 = r10
    add64 r1, -104                                  r1 += -104   ///  r1 = r1.wrapping_add(-104 as i32 as i64 as u64)
    call function_14604                     
    mov64 r3, 1                                     r3 = 1 as i32 as i64 as u64
    ldxdw r0, [r10-0x60]                    
    ja lbb_16046                                    if true { pc += -34 }
lbb_16080:
    ldxdw r2, [r10-0xa8]                    
    ldxdw r1, [r2+0x18]                     
    stxdw [r10-0x8], r1                     
    ldxdw r1, [r2+0x10]                     
    stxdw [r10-0x10], r1                    
    ldxdw r1, [r2+0x8]                      
    stxdw [r10-0x18], r1                    
    ldxdw r1, [r2+0x0]                      
    stxdw [r10-0x20], r1                    
    ldxdw r1, [r10-0x68]                    
    stxdw [r10-0x50], r1                    
    ldxdw r1, [r10-0x60]                    
    stxdw [r10-0x48], r1                    
    ldxdw r1, [r10-0x58]                    
    stxdw [r10-0x40], r1                    
    ldxdw r1, [r10-0x80]                    
    stxdw [r10-0x38], r1                    
    ldxdw r1, [r10-0x78]                    
    stxdw [r10-0x30], r1                    
    ldxdw r1, [r10-0x70]                    
    stxdw [r10-0x28], r1                    
    mov64 r2, r10                                   r2 = r10
    add64 r2, -80                                   r2 += -80   ///  r2 = r2.wrapping_add(-80 as i32 as i64 as u64)
    ldxdw r1, [r10-0xa0]                    
    mov64 r3, 80                                    r3 = 80 as i32 as i64 as u64
    call function_30349                     
lbb_16106:
    exit                                    
lbb_16107:
    ldxdw r1, [r10-0xb0]                    
    mov64 r2, r9                                    r2 = r9
    call function_21549                     

function_16110:
    mov64 r9, r3                                    r9 = r3
    mov64 r8, r2                                    r8 = r2
    mov64 r0, r1                                    r0 = r1
    ldxdw r1, [r8+0x0]                      
    lddw r2, 0xde8f75eee1f6dd06                     r2 load str located at -2409577606766207738
    jeq r1, r2, lbb_16119                           if r1 == r2 { pc += 2 }
lbb_16117:
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    ja lbb_16132                                    if true { pc += 13 }
lbb_16119:
    ldxdw r1, [r8+0x8]                      
    lddw r2, 0xdacd6ce4bc5d4218                     r2 load str located at -2680366473547005416
    jne r1, r2, lbb_16117                           if r1 != r2 { pc += -6 }
    ldxdw r1, [r8+0x10]                     
    lddw r2, 0x270db9834dfc1ab6                     r2 load str located at 2814109315776649910
    jne r1, r2, lbb_16117                           if r1 != r2 { pc += -10 }
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    ldxdw r2, [r8+0x18]                     
    lddw r3, 0xfc8ba1d828f9bdfe                     r3 load str located at -248927404616466946
    jne r2, r3, lbb_16117                           if r2 != r3 { pc += -15 }
lbb_16132:
    jeq r1, 0, lbb_16153                            if r1 == (0 as i32 as i64 as u64) { pc += 20 }
    ldxdw r1, [r8+0x0]                      
    lddw r2, 0x93a165d7e1f6dd06                     r2 load str located at -7808848301000303354
    jeq r1, r2, lbb_16139                           if r1 == r2 { pc += 2 }
lbb_16137:
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    ja lbb_16152                                    if true { pc += 13 }
lbb_16139:
    ldxdw r1, [r8+0x8]                      
    lddw r2, 0xac79ebce46e1cbd9                     r2 load str located at -6018520155818964007
    jne r1, r2, lbb_16137                           if r1 != r2 { pc += -6 }
    ldxdw r1, [r8+0x10]                     
    lddw r2, 0x91375b5fed85b41c                     r2 load str located at -7982811346925931492
    jne r1, r2, lbb_16137                           if r1 != r2 { pc += -10 }
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    ldxdw r2, [r8+0x18]                     
    lddw r3, 0xa900ff7e85f58c3a                     r3 load str located at -6268729762421306310
    jne r2, r3, lbb_16137                           if r2 != r3 { pc += -15 }
lbb_16152:
    jne r1, 0, lbb_16223                            if r1 != (0 as i32 as i64 as u64) { pc += 70 }
lbb_16153:
    stxdw [r10-0x60], r4                    
    stxdw [r10-0x58], r0                    
    mov64 r7, r5                                    r7 = r5
    mov64 r1, 34                                    r1 = 34 as i32 as i64 as u64
    mov64 r2, 1                                     r2 = 1 as i32 as i64 as u64
    call function_14385                     
    mov64 r6, r0                                    r6 = r0
    jne r6, 0, lbb_16164                            if r6 != (0 as i32 as i64 as u64) { pc += 3 }
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    mov64 r2, 34                                    r2 = 34 as i32 as i64 as u64
    call function_21552                     
lbb_16164:
    stxdw [r10-0x68], r8                    
    ldxdw r1, [r9+0x18]                     
    stxdw [r6+0x18], r1                     
    ldxdw r1, [r9+0x10]                     
    stxdw [r6+0x10], r1                     
    ldxdw r1, [r9+0x8]                      
    stxdw [r6+0x8], r1                      
    ldxdw r1, [r9+0x0]                      
    stxdw [r6+0x0], r1                      
    mov64 r9, 0                                     r9 = 0 as i32 as i64 as u64
    stxh [r6+0x20], r9                      
    mov64 r0, 2                                     r0 = 2 as i32 as i64 as u64
    jeq r7, 0, lbb_16191                            if r7 == (0 as i32 as i64 as u64) { pc += 14 }
    mov64 r8, 0                                     r8 = 0 as i32 as i64 as u64
    mov64 r9, r7                                    r9 = r7
    lsh64 r9, 1                                     r9 <<= 1   ///  r9 = r9.wrapping_shl(1)
    lddw r1, 0x3fffffffffffffff                     r1 load str located at 4611686018427387903
    jgt r7, r1, lbb_16188                           if r7 > r1 { pc += 5 }
    mov64 r8, 2                                     r8 = 2 as i32 as i64 as u64
    mov64 r1, r9                                    r1 = r9
    mov64 r2, 2                                     r2 = 2 as i32 as i64 as u64
    call function_14385                     
    jne r0, 0, lbb_16191                            if r0 != (0 as i32 as i64 as u64) { pc += 3 }
lbb_16188:
    mov64 r1, r8                                    r1 = r8
    mov64 r2, r9                                    r2 = r9
    call function_21549                     
lbb_16191:
    mov64 r8, r0                                    r8 = r0
    mov64 r1, r8                                    r1 = r8
    ldxdw r2, [r10-0x60]                    
    mov64 r3, r9                                    r3 = r9
    call function_30349                     
    stxdw [r10-0x60], r8                    
    stxdw [r10-0x40], r8                    
    mov64 r1, 21                                    r1 = 21 as i32 as i64 as u64
    stxw [r10-0x50], r1                     
    stxdw [r10-0x38], r7                    
    stxdw [r10-0x48], r7                    
    ldxdw r9, [r10-0x58]                    
    mov64 r1, r9                                    r1 = r9
    add64 r1, 24                                    r1 += 24   ///  r1 = r1.wrapping_add(24 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -80                                   r2 += -80   ///  r2 = r2.wrapping_add(-80 as i32 as i64 as u64)
    call function_15336                     
    ldxdw r2, [r10-0x68]                    
    ldxdw r1, [r2+0x18]                     
    stxdw [r9+0x48], r1                     
    ldxdw r1, [r2+0x10]                     
    stxdw [r9+0x40], r1                     
    ldxdw r1, [r2+0x8]                      
    stxdw [r9+0x38], r1                     
    ldxdw r1, [r2+0x0]                      
    stxdw [r9+0x30], r1                     
    stxdw [r9+0x8], r6                      
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    stxdw [r9+0x10], r1                     
    stxdw [r9+0x0], r1                      
    jne r7, 0, lbb_16230                            if r7 != (0 as i32 as i64 as u64) { pc += 8 }
    ja lbb_16235                                    if true { pc += 12 }
lbb_16223:
    lddw r1, 0x8000000000000000                     r1 load str located at -9223372036854775808
    stxdw [r0+0x0], r1                      
    lddw r1, 0x8000000000000006                     r1 load str located at -9223372036854775802
    stxdw [r0+0x8], r1                      
    ja lbb_16235                                    if true { pc += 5 }
lbb_16230:
    lsh64 r7, 1                                     r7 <<= 1   ///  r7 = r7.wrapping_shl(1)
    ldxdw r1, [r10-0x60]                    
    mov64 r2, r7                                    r2 = r7
    mov64 r3, 2                                     r3 = 2 as i32 as i64 as u64
    call function_14411                     
lbb_16235:
    exit                                    

function_16236:
    jgt r3, 81, lbb_16242                           if r3 > (81 as i32 as i64 as u64) { pc += 5 }
    mov64 r1, 82                                    r1 = 82 as i32 as i64 as u64
    mov64 r2, r3                                    r2 = r3
    lddw r3, 0x100041418 --> b"\x00\x00\x00\x00\xa0\xec\x03\x00\x0c\x00\x00\x00\x00\x00\x00\x004\x00\x00…        r3 load str located at 4295234584
    call function_28353                     
lbb_16242:
    ldxb r3, [r2+0x0]                       
    jeq r3, 1, lbb_16254                            if r3 == (1 as i32 as i64 as u64) { pc += 10 }
    jne r3, 0, lbb_16274                            if r3 != (0 as i32 as i64 as u64) { pc += 29 }
    ldxb r3, [r2+0x1]                       
    jne r3, 0, lbb_16274                            if r3 != (0 as i32 as i64 as u64) { pc += 27 }
    ldxb r3, [r2+0x2]                       
    jne r3, 0, lbb_16274                            if r3 != (0 as i32 as i64 as u64) { pc += 25 }
    mov64 r4, 0                                     r4 = 0 as i32 as i64 as u64
    ldxb r3, [r2+0x3]                       
    mov64 r5, r3                                    r5 = r3
    jeq r5, 0, lbb_16268                            if r5 == (0 as i32 as i64 as u64) { pc += 15 }
    ja lbb_16274                                    if true { pc += 20 }
lbb_16254:
    ldxb r3, [r2+0x1]                       
    jne r3, 0, lbb_16274                            if r3 != (0 as i32 as i64 as u64) { pc += 18 }
    ldxb r3, [r2+0x2]                       
    jne r3, 0, lbb_16274                            if r3 != (0 as i32 as i64 as u64) { pc += 16 }
    ldxb r3, [r2+0x3]                       
    jne r3, 0, lbb_16274                            if r3 != (0 as i32 as i64 as u64) { pc += 14 }
    ldxdw r3, [r2+0x4]                      
    ldxdw r4, [r2+0x1c]                     
    stxdw [r10-0x20], r4                    
    ldxdw r4, [r2+0x14]                     
    stxdw [r10-0x28], r4                    
    ldxdw r4, [r2+0xc]                      
    stxdw [r10-0x30], r4                    
    mov64 r4, 1                                     r4 = 1 as i32 as i64 as u64
lbb_16268:
    mov64 r6, 0                                     r6 = 0 as i32 as i64 as u64
    ldxb r0, [r2+0x2c]                      
    ldxdw r5, [r2+0x24]                     
    ldxb r7, [r2+0x2d]                      
    jeq r7, 0, lbb_16281                            if r7 == (0 as i32 as i64 as u64) { pc += 8 }
    jeq r7, 1, lbb_16280                            if r7 == (1 as i32 as i64 as u64) { pc += 6 }
lbb_16274:
    mov64 r2, 2                                     r2 = 2 as i32 as i64 as u64
    stxw [r1+0x0], r2                       
    lddw r2, 0x8000000000000003                     r2 load str located at -9223372036854775805
    stxdw [r1+0x8], r2                      
lbb_16279:
    exit                                    
lbb_16280:
    mov64 r6, 1                                     r6 = 1 as i32 as i64 as u64
lbb_16281:
    ldxb r7, [r2+0x2e]                      
    jeq r7, 1, lbb_16292                            if r7 == (1 as i32 as i64 as u64) { pc += 9 }
    jne r7, 0, lbb_16274                            if r7 != (0 as i32 as i64 as u64) { pc += -10 }
    ldxb r7, [r2+0x2f]                      
    jne r7, 0, lbb_16274                            if r7 != (0 as i32 as i64 as u64) { pc += -12 }
    ldxb r7, [r2+0x30]                      
    jne r7, 0, lbb_16274                            if r7 != (0 as i32 as i64 as u64) { pc += -14 }
    mov64 r8, 0                                     r8 = 0 as i32 as i64 as u64
    ldxb r2, [r2+0x31]                      
    jeq r2, 0, lbb_16306                            if r2 == (0 as i32 as i64 as u64) { pc += 15 }
    ja lbb_16274                                    if true { pc += -18 }
lbb_16292:
    ldxb r7, [r2+0x2f]                      
    jne r7, 0, lbb_16274                            if r7 != (0 as i32 as i64 as u64) { pc += -20 }
    ldxb r7, [r2+0x30]                      
    jne r7, 0, lbb_16274                            if r7 != (0 as i32 as i64 as u64) { pc += -22 }
    ldxb r7, [r2+0x31]                      
    jne r7, 0, lbb_16274                            if r7 != (0 as i32 as i64 as u64) { pc += -24 }
    ldxdw r7, [r2+0x32]                     
    ldxdw r8, [r2+0x4a]                     
    stxdw [r10-0x8], r8                     
    ldxdw r8, [r2+0x42]                     
    stxdw [r10-0x10], r8                    
    ldxdw r2, [r2+0x3a]                     
    stxdw [r10-0x18], r2                    
    mov64 r8, 1                                     r8 = 1 as i32 as i64 as u64
lbb_16306:
    ldxdw r2, [r10-0x20]                    
    stxdw [r1+0x1c], r2                     
    ldxdw r2, [r10-0x28]                    
    stxdw [r1+0x14], r2                     
    ldxdw r2, [r10-0x30]                    
    stxdw [r1+0xc], r2                      
    stxdw [r1+0x38], r7                     
    stxw [r1+0x34], r8                      
    stxb [r1+0x31], r6                      
    stxb [r1+0x30], r0                      
    stxdw [r1+0x28], r5                     
    stxdw [r1+0x4], r3                      
    stxw [r1+0x0], r4                       
    ldxdw r2, [r10-0x18]                    
    stxdw [r1+0x40], r2                     
    ldxdw r2, [r10-0x10]                    
    stxdw [r1+0x48], r2                     
    ldxdw r2, [r10-0x8]                     
    stxdw [r1+0x50], r2                     
    ja lbb_16279                                    if true { pc += -47 }

function_16326:
    jgt r3, 164, lbb_16332                          if r3 > (164 as i32 as i64 as u64) { pc += 5 }
    mov64 r1, 165                                   r1 = 165 as i32 as i64 as u64
    mov64 r2, r3                                    r2 = r3
    lddw r3, 0x100041430 --> b"\x00\x00\x00\x00\xa0\xec\x03\x00\x0c\x00\x00\x00\x00\x00\x00\x00\x95\x00\…        r3 load str located at 4295234608
    call function_28353                     
lbb_16332:
    ldxdw r7, [r2+0x40]                     
    ldxb r3, [r2+0x48]                      
    jeq r3, 1, lbb_16360                            if r3 == (1 as i32 as i64 as u64) { pc += 25 }
    jne r3, 0, lbb_16381                            if r3 != (0 as i32 as i64 as u64) { pc += 45 }
    ldxb r3, [r2+0x49]                      
    jne r3, 0, lbb_16381                            if r3 != (0 as i32 as i64 as u64) { pc += 43 }
    ldxb r3, [r2+0x4a]                      
    jne r3, 0, lbb_16381                            if r3 != (0 as i32 as i64 as u64) { pc += 41 }
    mov64 r9, 0                                     r9 = 0 as i32 as i64 as u64
    ldxb r3, [r2+0x4b]                      
    jeq r3, 0, lbb_16344                            if r3 == (0 as i32 as i64 as u64) { pc += 1 }
    ja lbb_16381                                    if true { pc += 37 }
lbb_16344:
    ldxb r8, [r2+0x6c]                      
    mov64 r3, 3                                     r3 = 3 as i32 as i64 as u64
    jgt r3, r8, lbb_16348                           if r3 > r8 { pc += 1 }
    ja lbb_16377                                    if true { pc += 29 }
lbb_16348:
    ldxb r3, [r2+0x6d]                      
    jeq r3, 1, lbb_16387                            if r3 == (1 as i32 as i64 as u64) { pc += 37 }
    jne r3, 0, lbb_16381                            if r3 != (0 as i32 as i64 as u64) { pc += 30 }
    ldxb r3, [r2+0x6e]                      
    jne r3, 0, lbb_16381                            if r3 != (0 as i32 as i64 as u64) { pc += 28 }
    ldxb r3, [r2+0x6f]                      
    jne r3, 0, lbb_16381                            if r3 != (0 as i32 as i64 as u64) { pc += 26 }
    mov64 r5, 0                                     r5 = 0 as i32 as i64 as u64
    ldxb r3, [r2+0x70]                      
    mov64 r0, 0                                     r0 = 0 as i32 as i64 as u64
    jeq r3, 0, lbb_16395                            if r3 == (0 as i32 as i64 as u64) { pc += 36 }
    ja lbb_16381                                    if true { pc += 21 }
lbb_16360:
    ldxb r3, [r2+0x49]                      
    jne r3, 0, lbb_16381                            if r3 != (0 as i32 as i64 as u64) { pc += 19 }
    ldxb r3, [r2+0x4a]                      
    jne r3, 0, lbb_16381                            if r3 != (0 as i32 as i64 as u64) { pc += 17 }
    ldxb r3, [r2+0x4b]                      
    jne r3, 0, lbb_16381                            if r3 != (0 as i32 as i64 as u64) { pc += 15 }
    ldxdw r4, [r2+0x4c]                     
    ldxdw r3, [r2+0x64]                     
    stxdw [r10-0x20], r3                    
    ldxdw r3, [r2+0x5c]                     
    stxdw [r10-0x28], r3                    
    ldxdw r3, [r2+0x54]                     
    stxdw [r10-0x30], r3                    
    mov64 r9, 1                                     r9 = 1 as i32 as i64 as u64
    ldxb r8, [r2+0x6c]                      
    mov64 r3, 3                                     r3 = 3 as i32 as i64 as u64
    jgt r3, r8, lbb_16348                           if r3 > r8 { pc += -29 }
lbb_16377:
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
    stxb [r1+0xf], r2                       
    stxh [r1+0xd], r2                       
    stxw [r1+0x9], r2                       
lbb_16381:
    mov64 r2, 2                                     r2 = 2 as i32 as i64 as u64
    stxw [r1+0x88], r2                      
    lddw r2, 0x8000000000000003                     r2 load str located at -9223372036854775805
    stxdw [r1+0x0], r2                      
lbb_16386:
    exit                                    
lbb_16387:
    ldxb r3, [r2+0x6e]                      
    jne r3, 0, lbb_16381                            if r3 != (0 as i32 as i64 as u64) { pc += -8 }
    ldxb r3, [r2+0x6f]                      
    jne r3, 0, lbb_16381                            if r3 != (0 as i32 as i64 as u64) { pc += -10 }
    ldxb r3, [r2+0x70]                      
    jne r3, 0, lbb_16381                            if r3 != (0 as i32 as i64 as u64) { pc += -12 }
    mov64 r5, 1                                     r5 = 1 as i32 as i64 as u64
    ldxdw r0, [r2+0x71]                     
lbb_16395:
    ldxdw r3, [r2+0x79]                     
    stxdw [r10-0x78], r3                    
    ldxb r3, [r2+0x81]                      
    jeq r3, 1, lbb_16409                            if r3 == (1 as i32 as i64 as u64) { pc += 10 }
    jne r3, 0, lbb_16381                            if r3 != (0 as i32 as i64 as u64) { pc += -19 }
    ldxb r3, [r2+0x82]                      
    jne r3, 0, lbb_16381                            if r3 != (0 as i32 as i64 as u64) { pc += -21 }
    ldxb r3, [r2+0x83]                      
    jne r3, 0, lbb_16381                            if r3 != (0 as i32 as i64 as u64) { pc += -23 }
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
    stxdw [r10-0x80], r3                    
    ldxb r3, [r2+0x84]                      
    jeq r3, 0, lbb_16425                            if r3 == (0 as i32 as i64 as u64) { pc += 17 }
    ja lbb_16381                                    if true { pc += -28 }
lbb_16409:
    ldxb r3, [r2+0x82]                      
    jne r3, 0, lbb_16381                            if r3 != (0 as i32 as i64 as u64) { pc += -30 }
    ldxb r3, [r2+0x83]                      
    jne r3, 0, lbb_16381                            if r3 != (0 as i32 as i64 as u64) { pc += -32 }
    ldxb r3, [r2+0x84]                      
    jne r3, 0, lbb_16381                            if r3 != (0 as i32 as i64 as u64) { pc += -34 }
    ldxdw r3, [r2+0x85]                     
    stxdw [r10-0xa0], r3                    
    ldxdw r3, [r2+0x9d]                     
    stxdw [r10-0x8], r3                     
    ldxdw r3, [r2+0x95]                     
    stxdw [r10-0x10], r3                    
    ldxdw r3, [r2+0x8d]                     
    stxdw [r10-0x18], r3                    
    mov64 r3, 1                                     r3 = 1 as i32 as i64 as u64
    stxdw [r10-0x80], r3                    
lbb_16425:
    mov64 r3, r2                                    r3 = r2
    add64 r3, 32                                    r3 += 32   ///  r3 = r3.wrapping_add(32 as i32 as i64 as u64)
    stxdw [r10-0x88], r4                    
    ldxdw r4, [r2+0x18]                     
    stxdw [r10-0x58], r4                    
    ldxdw r4, [r2+0x10]                     
    stxdw [r10-0x60], r4                    
    ldxdw r4, [r2+0x8]                      
    stxdw [r10-0x68], r4                    
    ldxdw r2, [r2+0x0]                      
    stxdw [r10-0x70], r2                    
    ldxdw r2, [r3+0x0]                      
    stxdw [r10-0x50], r2                    
    ldxdw r2, [r3+0x8]                      
    stxdw [r10-0x48], r2                    
    ldxdw r2, [r3+0x10]                     
    stxdw [r10-0x40], r2                    
    ldxdw r2, [r3+0x18]                     
    stxdw [r10-0x38], r2                    
    ldxdw r2, [r10-0x20]                    
    stxdw [r1+0x64], r2                     
    ldxdw r2, [r10-0x28]                    
    stxdw [r1+0x5c], r2                     
    ldxdw r2, [r10-0x30]                    
    stxdw [r1+0x54], r2                     
    mov64 r2, r10                                   r2 = r10
    add64 r2, -112                                  r2 += -112   ///  r2 = r2.wrapping_add(-112 as i32 as i64 as u64)
    mov64 r6, r1                                    r6 = r1
    mov64 r3, 64                                    r3 = 64 as i32 as i64 as u64
    stxdw [r10-0x90], r5                    
    stxdw [r10-0x98], r0                    
    call function_30349                     
    ldxdw r1, [r10-0xa0]                    
    stxdw [r6+0x8c], r1                     
    ldxdw r1, [r10-0x80]                    
    stxw [r6+0x88], r1                      
    ldxdw r1, [r10-0x78]                    
    stxdw [r6+0x80], r1                     
    ldxdw r1, [r10-0x98]                    
    stxdw [r6+0x78], r1                     
    ldxdw r1, [r10-0x90]                    
    stxw [r6+0x70], r1                      
    stxb [r6+0x6c], r8                      
    ldxdw r1, [r10-0x88]                    
    stxdw [r6+0x4c], r1                     
    stxw [r6+0x48], r9                      
    stxdw [r6+0x40], r7                     
    ldxdw r1, [r10-0x18]                    
    stxdw [r6+0x94], r1                     
    ldxdw r1, [r10-0x10]                    
    stxdw [r6+0x9c], r1                     
    ldxdw r1, [r10-0x8]                     
    stxdw [r6+0xa4], r1                     
    ja lbb_16386                                    if true { pc += -93 }

function_16479:
    mov64 r5, 8                                     r5 = 8 as i32 as i64 as u64
    stxdw [r10-0x1000], r5                  
    mov64 r5, 0                                     r5 = 0 as i32 as i64 as u64
    stxdw [r10-0xff8], r5                   
    mov64 r5, r10                                   r5 = r10
    call function_16486                     
    exit                                    

function_16486:
    stxdw [r10-0x28], r4                    
    stxdw [r10-0x30], r3                    
    stxdw [r10-0x40], r1                    
    stxdw [r10-0x38], r2                    
    ldxdw r1, [r2+0x10]                     
    ldxdw r2, [r5-0xff8]                    
    stxdw [r10-0x48], r2                    
    ldxdw r2, [r5-0x1000]                   
    stxdw [r10-0x50], r2                    
    jeq r1, 0, lbb_16593                            if r1 == (0 as i32 as i64 as u64) { pc += 97 }
    ldxdw r2, [r10-0x38]                    
    ldxdw r8, [r2+0x8]                      
    mul64 r1, 34                                    r1 *= 34   ///  r1 = r1.wrapping_mul(34 as u64)
    mov64 r9, r8                                    r9 = r8
    add64 r9, r1                                    r9 += r1   ///  r9 = r9.wrapping_add(r1)
    ldxdw r0, [r10-0x28]                    
    mul64 r0, 48                                    r0 *= 48   ///  r0 = r0.wrapping_mul(48 as u64)
    ldxdw r6, [r10-0x30]                    
    add64 r6, -48                                   r6 += -48   ///  r6 = r6.wrapping_add(-48 as i32 as i64 as u64)
    stxdw [r10-0x20], r6                    
    ja lbb_16513                                    if true { pc += 6 }
lbb_16507:
    ldxdw r3, [r1+0x0]                      
    add64 r3, r2                                    r3 += r2   ///  r3 = r3.wrapping_add(r2)
    stxdw [r1+0x0], r3                      
    mov64 r0, r6                                    r0 = r6
    ldxdw r6, [r10-0x20]                    
lbb_16512:
    jeq r8, r9, lbb_16593                           if r8 == r9 { pc += 80 }
lbb_16513:
    mov64 r1, r8                                    r1 = r8
    add64 r8, 34                                    r8 += 34   ///  r8 = r8.wrapping_add(34 as i32 as i64 as u64)
    mov64 r2, r0                                    r2 = r0
    mov64 r7, r6                                    r7 = r6
lbb_16517:
    jeq r2, 0, lbb_16512                            if r2 == (0 as i32 as i64 as u64) { pc += -6 }
    ldxdw r3, [r1+0x0]                      
    ldxdw r4, [r7+0x30]                     
    ldxdw r5, [r4+0x0]                      
    jeq r3, r5, lbb_16524                           if r3 == r5 { pc += 2 }
lbb_16522:
    mov64 r3, 1                                     r3 = 1 as i32 as i64 as u64
    ja lbb_16534                                    if true { pc += 10 }
lbb_16524:
    ldxdw r3, [r4+0x8]                      
    ldxdw r5, [r1+0x8]                      
    jne r5, r3, lbb_16522                           if r5 != r3 { pc += -5 }
    ldxdw r3, [r4+0x10]                     
    ldxdw r5, [r1+0x10]                     
    jne r5, r3, lbb_16522                           if r5 != r3 { pc += -8 }
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
    ldxdw r4, [r4+0x18]                     
    ldxdw r5, [r1+0x18]                     
    jne r5, r4, lbb_16522                           if r5 != r4 { pc += -12 }
lbb_16534:
    add64 r2, -48                                   r2 += -48   ///  r2 = r2.wrapping_add(-48 as i32 as i64 as u64)
    add64 r7, 48                                    r7 += 48   ///  r7 = r7.wrapping_add(48 as i32 as i64 as u64)
    jne r3, 0, lbb_16517                            if r3 != (0 as i32 as i64 as u64) { pc += -20 }
    mov64 r6, r0                                    r6 = r0
    ldxb r1, [r1+0x21]                      
    jne r1, 0, lbb_16569                            if r1 != (0 as i32 as i64 as u64) { pc += 29 }
    mov64 r1, r10                                   r1 = r10
    add64 r1, -24                                   r1 += -24   ///  r1 = r1.wrapping_add(-24 as i32 as i64 as u64)
    mov64 r2, r7                                    r2 = r7
    call function_17743                     
    ldxdw r1, [r10-0x8]                     
    ldxdw r2, [r10-0x18]                    
    lddw r3, 0x800000000000001a                     r3 load str located at -9223372036854775782
    jeq r2, r3, lbb_16550                           if r2 == r3 { pc += 1 }
    ja lbb_16604                                    if true { pc += 54 }
lbb_16550:
    ldxdw r2, [r1+0x0]                      
    add64 r2, -1                                    r2 += -1   ///  r2 = r2.wrapping_add(-1 as i32 as i64 as u64)
    stxdw [r1+0x0], r2                      
    mov64 r1, r10                                   r1 = r10
    add64 r1, -24                                   r1 += -24   ///  r1 = r1.wrapping_add(-24 as i32 as i64 as u64)
    mov64 r2, r7                                    r2 = r7
    call function_17777                     
    lddw r4, 0x800000000000001a                     r4 load str located at -9223372036854775782
    mov64 r2, -1                                    r2 = -1 as i32 as i64 as u64
    ldxdw r1, [r10-0x8]                     
    ldxdw r3, [r10-0x18]                    
    jeq r3, r4, lbb_16507                           if r3 == r4 { pc += -56 }
lbb_16563:
    ldxdw r2, [r10-0x10]                    
    ldxdw r4, [r10-0x40]                    
    stxdw [r4+0x10], r1                     
    stxdw [r4+0x8], r2                      
    stxdw [r4+0x0], r3                      
    ja lbb_16603                                    if true { pc += 34 }
lbb_16569:
    mov64 r1, r10                                   r1 = r10
    add64 r1, -24                                   r1 += -24   ///  r1 = r1.wrapping_add(-24 as i32 as i64 as u64)
    mov64 r2, r7                                    r2 = r7
    call function_17761                     
    ldxdw r1, [r10-0x8]                     
    ldxdw r2, [r10-0x18]                    
    lddw r3, 0x800000000000001a                     r3 load str located at -9223372036854775782
    jeq r2, r3, lbb_16579                           if r2 == r3 { pc += 1 }
    ja lbb_16604                                    if true { pc += 25 }
lbb_16579:
    ldxdw r2, [r1+0x0]                      
    add64 r2, 1                                     r2 += 1   ///  r2 = r2.wrapping_add(1 as i32 as i64 as u64)
    stxdw [r1+0x0], r2                      
    mov64 r1, r10                                   r1 = r10
    add64 r1, -24                                   r1 += -24   ///  r1 = r1.wrapping_add(-24 as i32 as i64 as u64)
    mov64 r2, r7                                    r2 = r7
    call function_17795                     
    lddw r4, 0x800000000000001a                     r4 load str located at -9223372036854775782
    mov64 r2, 1                                     r2 = 1 as i32 as i64 as u64
    ldxdw r1, [r10-0x8]                     
    ldxdw r3, [r10-0x18]                    
    jeq r3, r4, lbb_16507                           if r3 == r4 { pc += -85 }
    ja lbb_16563                                    if true { pc += -30 }
lbb_16593:
    ldxdw r1, [r10-0x50]                    
    stxdw [r10-0x1000], r1                  
    ldxdw r1, [r10-0x48]                    
    stxdw [r10-0xff8], r1                   
    mov64 r5, r10                                   r5 = r10
    ldxdw r1, [r10-0x40]                    
    ldxdw r2, [r10-0x38]                    
    ldxdw r3, [r10-0x30]                    
    ldxdw r4, [r10-0x28]                    
    call function_17531                     
lbb_16603:
    exit                                    
lbb_16604:
    ldxdw r3, [r10-0x10]                    
    ldxdw r4, [r10-0x40]                    
    stxdw [r4+0x10], r1                     
    stxdw [r4+0x8], r3                      
    stxdw [r4+0x0], r2                      
    ja lbb_16603                                    if true { pc += -7 }

function_16610:
    call function_17654                     
    exit                                    

function_16612:
    mov64 r7, r3                                    r7 = r3
    mov64 r6, r1                                    r6 = r1
    jeq r2, 0, lbb_16628                            if r2 == (0 as i32 as i64 as u64) { pc += 13 }
    ldxdw r1, [r4+0x8]                      
    jeq r1, 0, lbb_16643                            if r1 == (0 as i32 as i64 as u64) { pc += 26 }
    ldxdw r2, [r4+0x10]                     
    jne r2, 0, lbb_16632                            if r2 != (0 as i32 as i64 as u64) { pc += 13 }
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    mov64 r0, 1                                     r0 = 1 as i32 as i64 as u64
    jeq r7, 0, lbb_16651                            if r7 == (0 as i32 as i64 as u64) { pc += 29 }
    mov64 r1, r7                                    r1 = r7
    mov64 r2, 1                                     r2 = 1 as i32 as i64 as u64
    call function_14385                     
    mov64 r1, r7                                    r1 = r7
    jeq r0, 0, lbb_16639                            if r0 == (0 as i32 as i64 as u64) { pc += 12 }
    ja lbb_16651                                    if true { pc += 23 }
lbb_16628:
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    stxdw [r6+0x8], r1                      
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    ja lbb_16654                                    if true { pc += 22 }
lbb_16632:
    ldxdw r1, [r4+0x0]                      
    mov64 r3, 1                                     r3 = 1 as i32 as i64 as u64
    mov64 r4, r7                                    r4 = r7
    call function_14412                     
    mov64 r1, r7                                    r1 = r7
    jeq r0, 0, lbb_16639                            if r0 == (0 as i32 as i64 as u64) { pc += 1 }
    ja lbb_16651                                    if true { pc += 12 }
lbb_16639:
    stxdw [r6+0x10], r7                     
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    stxdw [r6+0x8], r1                      
    ja lbb_16654                                    if true { pc += 11 }
lbb_16643:
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    mov64 r0, 1                                     r0 = 1 as i32 as i64 as u64
    jeq r7, 0, lbb_16651                            if r7 == (0 as i32 as i64 as u64) { pc += 5 }
    mov64 r1, r7                                    r1 = r7
    mov64 r2, 1                                     r2 = 1 as i32 as i64 as u64
    call function_14385                     
    mov64 r1, r7                                    r1 = r7
    jeq r0, 0, lbb_16639                            if r0 == (0 as i32 as i64 as u64) { pc += -12 }
lbb_16651:
    stxdw [r6+0x10], r1                     
    stxdw [r6+0x8], r0                      
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
lbb_16654:
    stxdw [r6+0x0], r1                      
    exit                                    

function_16656:
    mov64 r6, r1                                    r6 = r1
    ldxdw r4, [r6+0x0]                      
    mov64 r3, r4                                    r3 = r4
    add64 r3, 1                                     r3 += 1   ///  r3 = r3.wrapping_add(1 as i32 as i64 as u64)
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    mov64 r5, 1                                     r5 = 1 as i32 as i64 as u64
    jeq r3, 0, lbb_16664                            if r3 == (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r5, 0                                     r5 = 0 as i32 as i64 as u64
lbb_16664:
    and64 r5, 1                                     r5 &= 1   ///  r5 = r5.and(1)
    jne r5, 0, lbb_16695                            if r5 != (0 as i32 as i64 as u64) { pc += 29 }
    mov64 r7, r4                                    r7 = r4
    lsh64 r7, 1                                     r7 <<= 1   ///  r7 = r7.wrapping_shl(1)
    jgt r7, r3, lbb_16670                           if r7 > r3 { pc += 1 }
    mov64 r7, r3                                    r7 = r3
lbb_16670:
    mov64 r2, 1                                     r2 = 1 as i32 as i64 as u64
    lddw r3, 0x3c3c3c3c3c3c3c4                      r3 load str located at 271275648142787524
    jgt r3, r7, lbb_16675                           if r3 > r7 { pc += 1 }
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
lbb_16675:
    jgt r7, 4, lbb_16677                            if r7 > (4 as i32 as i64 as u64) { pc += 1 }
    mov64 r7, 4                                     r7 = 4 as i32 as i64 as u64
lbb_16677:
    mov64 r3, r7                                    r3 = r7
    mul64 r3, 34                                    r3 *= 34   ///  r3 = r3.wrapping_mul(34 as u64)
    jeq r4, 0, lbb_16685                            if r4 == (0 as i32 as i64 as u64) { pc += 5 }
    ldxdw r1, [r6+0x8]                      
    mul64 r4, 34                                    r4 *= 34   ///  r4 = r4.wrapping_mul(34 as u64)
    stxdw [r10-0x8], r4                     
    stxdw [r10-0x18], r1                    
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
lbb_16685:
    stxdw [r10-0x10], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -48                                   r1 += -48   ///  r1 = r1.wrapping_add(-48 as i32 as i64 as u64)
    mov64 r4, r10                                   r4 = r10
    add64 r4, -24                                   r4 += -24   ///  r4 = r4.wrapping_add(-24 as i32 as i64 as u64)
    call function_16612                     
    ldxdw r1, [r10-0x30]                    
    jeq r1, 0, lbb_16696                            if r1 == (0 as i32 as i64 as u64) { pc += 3 }
    ldxdw r2, [r10-0x20]                    
    ldxdw r1, [r10-0x28]                    
lbb_16695:
    call function_21549                     
lbb_16696:
    ldxdw r1, [r10-0x28]                    
    stxdw [r6+0x0], r7                      
    stxdw [r6+0x8], r1                      
    exit                                    

function_16700:
    mov64 r7, r2                                    r7 = r2
    mov64 r6, r1                                    r6 = r1
    ldxdw r1, [r7+0x0]                      
    call function_19510                     
    jne r0, 0, lbb_16708                            if r0 != (0 as i32 as i64 as u64) { pc += 3 }
    lddw r1, 0x8000000000000010                     r1 load str located at -9223372036854775792
    ja lbb_16728                                    if true { pc += 20 }
lbb_16708:
    mov64 r1, r10                                   r1 = r10
    add64 r1, -24                                   r1 += -24   ///  r1 = r1.wrapping_add(-24 as i32 as i64 as u64)
    mov64 r2, r7                                    r2 = r7
    call function_17777                     
    ldxdw r3, [r10-0x8]                     
    ldxdw r4, [r10-0x10]                    
    ldxdw r1, [r10-0x18]                    
    lddw r2, 0x800000000000001a                     r2 load str located at -9223372036854775782
    jeq r1, r2, lbb_16719                           if r1 == r2 { pc += 1 }
    ja lbb_16726                                    if true { pc += 7 }
lbb_16719:
    ldxdw r2, [r4+0x8]                      
    mov64 r1, r2                                    r1 = r2
    add64 r1, -2                                    r1 += -2   ///  r1 = r1.wrapping_add(-2 as i32 as i64 as u64)
    jgt r2, 1, lbb_16730                            if r2 > (1 as i32 as i64 as u64) { pc += 7 }
    lddw r3, 0x100041448 --> b"\x00\x00\x00\x00\xac\xec\x03\x00\x0a\x00\x00\x00\x00\x00\x00\x00\x8d\x00\…        r3 load str located at 4295234632
    call function_28381                     
lbb_16726:
    stxdw [r6+0x10], r3                     
    stxdw [r6+0x8], r4                      
lbb_16728:
    stxdw [r6+0x0], r1                      
    ja lbb_16740                                    if true { pc += 10 }
lbb_16730:
    ldxdw r2, [r4+0x0]                      
    add64 r2, r1                                    r2 += r1   ///  r2 = r2.wrapping_add(r1)
    ldxh r1, [r2+0x0]                       
    lddw r2, 0x800000000000001a                     r2 load str located at -9223372036854775782
    stxdw [r6+0x0], r2                      
    stxh [r6+0x8], r1                       
    ldxdw r1, [r3+0x0]                      
    add64 r1, -1                                    r1 += -1   ///  r1 = r1.wrapping_add(-1 as i32 as i64 as u64)
    stxdw [r3+0x0], r1                      
lbb_16740:
    exit                                    

function_16741:
    mov64 r8, r4                                    r8 = r4
    mov64 r6, r3                                    r6 = r3
    mov64 r9, r2                                    r9 = r2
    mov64 r7, r1                                    r7 = r1
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    stxdw [r10-0x68], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -104                                  r1 += -104   ///  r1 = r1.wrapping_add(-104 as i32 as i64 as u64)
    mov64 r2, r6                                    r2 = r6
    mov64 r3, r8                                    r3 = r8
    call function_17106                     
    mov64 r1, r0                                    r1 = r0
    and64 r1, 1                                     r1 &= 1   ///  r1 = r1.and(1)
    jne r1, 0, lbb_16817                            if r1 != (0 as i32 as i64 as u64) { pc += 62 }
    lddw r1, 0xffff0000                             r1 load str located at 4294901760
    and64 r0, r1                                    r0 &= r1   ///  r0 = r0.and(r1)
    rsh64 r0, 16                                    r0 >>= 16   ///  r0 = r0.wrapping_shr(16)
    jgt r0, r9, lbb_16761                           if r0 > r9 { pc += 1 }
    ja lbb_16894                                    if true { pc += 133 }
lbb_16761:
    lsh64 r9, 1                                     r9 <<= 1   ///  r9 = r9.wrapping_shl(1)
    ldxdw r1, [r10-0x68]                    
    add64 r1, r9                                    r1 += r9   ///  r1 = r1.wrapping_add(r9)
    stxdw [r10-0x68], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -104                                  r1 += -104   ///  r1 = r1.wrapping_add(-104 as i32 as i64 as u64)
    mov64 r2, r6                                    r2 = r6
    mov64 r3, r8                                    r3 = r8
    call function_17106                     
    mov64 r1, r0                                    r1 = r0
    and64 r1, 1                                     r1 &= 1   ///  r1 = r1.and(1)
    jeq r1, 0, lbb_16774                            if r1 == (0 as i32 as i64 as u64) { pc += 1 }
    ja lbb_16817                                    if true { pc += 43 }
lbb_16774:
    mov64 r2, r6                                    r2 = r6
    lddw r6, 0xffff0000                             r6 load str located at 4294901760
    and64 r0, r6                                    r0 &= r6   ///  r0 = r0.and(r6)
    rsh64 r0, 16                                    r0 >>= 16   ///  r0 = r0.wrapping_shr(16)
    stxdw [r10-0x68], r0                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -104                                  r1 += -104   ///  r1 = r1.wrapping_add(-104 as i32 as i64 as u64)
    stxdw [r10-0x88], r2                    
    mov64 r3, r8                                    r3 = r8
    call function_17106                     
    mov64 r1, r0                                    r1 = r0
    and64 r1, 1                                     r1 &= 1   ///  r1 = r1.and(1)
    jeq r1, 0, lbb_16789                            if r1 == (0 as i32 as i64 as u64) { pc += 1 }
    ja lbb_16817                                    if true { pc += 28 }
lbb_16789:
    mov64 r9, r0                                    r9 = r0
    and64 r9, r6                                    r9 &= r6   ///  r9 = r9.and(r6)
    rsh64 r9, 16                                    r9 >>= 16   ///  r9 = r9.wrapping_shr(16)
    mov64 r4, 1                                     r4 = 1 as i32 as i64 as u64
    lsh64 r0, 32                                    r0 <<= 32   ///  r0 = r0.wrapping_shl(32)
    rsh64 r0, 32                                    r0 >>= 32   ///  r0 = r0.wrapping_shr(32)
    mov64 r1, 65536                                 r1 = 65536 as i32 as i64 as u64
    jgt r1, r0, lbb_16804                           if r1 > r0 { pc += 7 }
    mov64 r6, r9                                    r6 = r9
    mul64 r6, 34                                    r6 *= 34   ///  r6 = r6.wrapping_mul(34 as u64)
    mov64 r1, r6                                    r1 = r6
    mov64 r2, 1                                     r2 = 1 as i32 as i64 as u64
    call function_14385                     
    mov64 r4, r0                                    r4 = r0
    jeq r4, 0, lbb_16992                            if r4 == (0 as i32 as i64 as u64) { pc += 188 }
lbb_16804:
    stxdw [r10-0x90], r8                    
    stxdw [r10-0xa8], r7                    
    mov64 r5, 0                                     r5 = 0 as i32 as i64 as u64
    stxdw [r10-0x50], r5                    
    stxdw [r10-0x58], r4                    
    stxdw [r10-0x60], r9                    
    jeq r9, 0, lbb_16900                            if r9 == (0 as i32 as i64 as u64) { pc += 89 }
    mov64 r3, 1                                     r3 = 1 as i32 as i64 as u64
    mov64 r1, r10                                   r1 = r10
    add64 r1, -70                                   r1 += -70   ///  r1 = r1.wrapping_add(-70 as i32 as i64 as u64)
    stxdw [r10-0xa0], r1                    
    stxdw [r10-0x98], r9                    
    ja lbb_16850                                    if true { pc += 33 }
lbb_16817:
    lddw r1, 0x8000000000000000                     r1 load str located at -9223372036854775808
    stxdw [r7+0x0], r1                      
    rsh64 r0, 8                                     r0 >>= 8   ///  r0 = r0.wrapping_shr(8)
    stxb [r7+0x8], r0                       
    ja lbb_16899                                    if true { pc += 76 }
lbb_16823:
    mov64 r1, r9                                    r1 = r9
    and64 r1, 1                                     r1 &= 1   ///  r1 = r1.and(1)
    rsh64 r9, 1                                     r9 >>= 1   ///  r9 = r9.wrapping_shr(1)
    and64 r9, 1                                     r9 &= 1   ///  r9 = r9.and(1)
    mov64 r2, r4                                    r2 = r4
    ldxdw r5, [r10-0x78]                    
    add64 r2, r5                                    r2 += r5   ///  r2 = r2.wrapping_add(r5)
    stxb [r2+0x0], r7                       
    ldxdw r3, [r10-0x20]                    
    stxdw [r2+0x1], r3                      
    ldxdw r3, [r10-0x18]                    
    stxdw [r2+0x9], r3                      
    ldxdw r3, [r10-0x10]                    
    stxdw [r2+0x11], r3                     
    ldxdw r3, [r10-0x9]                     
    stxdw [r2+0x18], r3                     
    stxb [r2+0x21], r9                      
    stxb [r2+0x20], r1                      
    add64 r5, 34                                    r5 += 34   ///  r5 = r5.wrapping_add(34 as i32 as i64 as u64)
    mov64 r1, r8                                    r1 = r8
    add64 r1, 1                                     r1 += 1   ///  r1 = r1.wrapping_add(1 as i32 as i64 as u64)
    stxdw [r10-0x50], r8                    
    and64 r8, 65535                                 r8 &= 65535   ///  r8 = r8.and(65535)
    mov64 r3, r1                                    r3 = r1
    ldxdw r9, [r10-0x98]                    
    jgt r9, r8, lbb_16850                           if r9 > r8 { pc += 1 }
    ja lbb_16900                                    if true { pc += 50 }
lbb_16850:
    stxdw [r10-0x80], r4                    
    mov64 r8, r3                                    r8 = r3
    stxdw [r10-0x78], r5                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -112                                  r1 += -112   ///  r1 = r1.wrapping_add(-112 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -104                                  r2 += -104   ///  r2 = r2.wrapping_add(-104 as i32 as i64 as u64)
    ldxdw r6, [r10-0x88]                    
    mov64 r3, r6                                    r3 = r6
    ldxdw r7, [r10-0x90]                    
    mov64 r4, r7                                    r4 = r7
    call function_17057                     
    ldxb r9, [r10-0x6f]                     
    ldxb r1, [r10-0x70]                     
    jne r1, 0, lbb_16957                            if r1 != (0 as i32 as i64 as u64) { pc += 92 }
    mov64 r1, r10                                   r1 = r10
    add64 r1, -72                                   r1 += -72   ///  r1 = r1.wrapping_add(-72 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -104                                  r2 += -104   ///  r2 = r2.wrapping_add(-104 as i32 as i64 as u64)
    mov64 r3, r6                                    r3 = r6
    mov64 r4, r7                                    r4 = r7
    call function_17078                     
    ldxb r1, [r10-0x48]                     
    jne r1, 0, lbb_16950                            if r1 != (0 as i32 as i64 as u64) { pc += 76 }
    mov64 r1, r8                                    r1 = r8
    add64 r1, -1                                    r1 += -1   ///  r1 = r1.wrapping_add(-1 as i32 as i64 as u64)
    ldxb r7, [r10-0x47]                     
    ldxdw r3, [r10-0xa0]                    
    ldxdw r2, [r3+0x17]                     
    stxdw [r10-0x9], r2                     
    ldxdw r2, [r3+0x10]                     
    stxdw [r10-0x10], r2                    
    ldxdw r2, [r3+0x8]                      
    stxdw [r10-0x18], r2                    
    ldxdw r2, [r3+0x0]                      
    stxdw [r10-0x20], r2                    
    ldxdw r2, [r10-0x60]                    
    ldxdw r4, [r10-0x80]                    
    jne r1, r2, lbb_16823                           if r1 != r2 { pc += -66 }
    mov64 r1, r10                                   r1 = r10
    add64 r1, -96                                   r1 += -96   ///  r1 = r1.wrapping_add(-96 as i32 as i64 as u64)
    call function_16656                     
    ldxdw r4, [r10-0x58]                    
    ja lbb_16823                                    if true { pc += -71 }
lbb_16894:
    lddw r1, 0x8000000000000000                     r1 load str located at -9223372036854775808
    stxdw [r7+0x0], r1                      
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    stxb [r7+0x8], r1                       
lbb_16899:
    exit                                    
lbb_16900:
    mov64 r1, r10                                   r1 = r10
    add64 r1, -72                                   r1 += -72   ///  r1 = r1.wrapping_add(-72 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -104                                  r2 += -104   ///  r2 = r2.wrapping_add(-104 as i32 as i64 as u64)
    ldxdw r7, [r10-0x88]                    
    mov64 r3, r7                                    r3 = r7
    ldxdw r6, [r10-0x90]                    
    mov64 r4, r6                                    r4 = r6
    call function_17078                     
    ldxb r9, [r10-0x47]                     
    ldxb r1, [r10-0x48]                     
    jeq r1, 0, lbb_16913                            if r1 == (0 as i32 as i64 as u64) { pc += 1 }
    ja lbb_16957                                    if true { pc += 44 }
lbb_16913:
    ldxdw r1, [r10-0x2f]                    
    stxdw [r10-0x9], r1                     
    ldxdw r1, [r10-0x36]                    
    stxdw [r10-0x10], r1                    
    ldxdw r1, [r10-0x3e]                    
    stxdw [r10-0x18], r1                    
    ldxdw r1, [r10-0x46]                    
    stxdw [r10-0x20], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -104                                  r1 += -104   ///  r1 = r1.wrapping_add(-104 as i32 as i64 as u64)
    mov64 r2, r7                                    r2 = r7
    mov64 r3, r6                                    r3 = r6
    call function_17106                     
    mov64 r1, r0                                    r1 = r0
    and64 r1, 1                                     r1 &= 1   ///  r1 = r1.and(1)
    jeq r1, 0, lbb_16930                            if r1 == (0 as i32 as i64 as u64) { pc += 1 }
    ja lbb_16952                                    if true { pc += 22 }
lbb_16930:
    lddw r1, 0xffff0000                             r1 load str located at 4294901760
    and64 r0, r1                                    r0 &= r1   ///  r0 = r0.and(r1)
    rsh64 r0, 16                                    r0 >>= 16   ///  r0 = r0.wrapping_shr(16)
    mov64 r1, r10                                   r1 = r10
    add64 r1, -72                                   r1 += -72   ///  r1 = r1.wrapping_add(-72 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -104                                  r2 += -104   ///  r2 = r2.wrapping_add(-104 as i32 as i64 as u64)
    mov64 r3, r7                                    r3 = r7
    mov64 r4, r6                                    r4 = r6
    mov64 r5, r0                                    r5 = r0
    call function_17123                     
    ldxb r1, [r10-0x40]                     
    ldxdw r2, [r10-0x48]                    
    lddw r3, 0x8000000000000000                     r3 load str located at -9223372036854775808
    jeq r2, r3, lbb_16948                           if r2 == r3 { pc += 1 }
    ja lbb_16969                                    if true { pc += 21 }
lbb_16948:
    mov64 r9, r1                                    r9 = r1
    ja lbb_16957                                    if true { pc += 7 }
lbb_16950:
    ldxb r9, [r10-0x47]                     
    ja lbb_16957                                    if true { pc += 5 }
lbb_16952:
    lddw r1, 0xffffff00                             r1 load str located at 4294967040
    and64 r0, r1                                    r0 &= r1   ///  r0 = r0.and(r1)
    rsh64 r0, 8                                     r0 >>= 8   ///  r0 = r0.wrapping_shr(8)
    mov64 r9, r0                                    r9 = r0
lbb_16957:
    lddw r1, 0x8000000000000000                     r1 load str located at -9223372036854775808
    ldxdw r2, [r10-0xa8]                    
    stxdw [r2+0x0], r1                      
    stxb [r2+0x8], r9                       
    ldxdw r2, [r10-0x60]                    
    jeq r2, 0, lbb_16899                            if r2 == (0 as i32 as i64 as u64) { pc += -65 }
    mul64 r2, 34                                    r2 *= 34   ///  r2 = r2.wrapping_mul(34 as u64)
    ldxdw r1, [r10-0x58]                    
    mov64 r3, 1                                     r3 = 1 as i32 as i64 as u64
    call function_14411                     
    ja lbb_16899                                    if true { pc += -70 }
lbb_16969:
    ldxdw r3, [r10-0x38]                    
    ldxdw r4, [r10-0xa8]                    
    stxdw [r4+0x28], r3                     
    ldxdw r3, [r10-0x3f]                    
    stxdw [r4+0x21], r3                     
    ldxdw r3, [r10-0x50]                    
    stxdw [r4+0x10], r3                     
    ldxdw r3, [r10-0x58]                    
    stxdw [r4+0x8], r3                      
    ldxdw r3, [r10-0x60]                    
    stxdw [r4+0x0], r3                      
    ldxdw r3, [r10-0x18]                    
    stxdw [r4+0x39], r3                     
    ldxdw r3, [r10-0x10]                    
    stxdw [r4+0x41], r3                     
    ldxdw r3, [r10-0x9]                     
    stxdw [r4+0x48], r3                     
    ldxdw r3, [r10-0x20]                    
    stxb [r4+0x20], r1                      
    stxb [r4+0x30], r9                      
    stxdw [r4+0x18], r2                     
    stxdw [r4+0x31], r3                     
    ja lbb_16899                                    if true { pc += -93 }
lbb_16992:
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    mov64 r2, r6                                    r2 = r6
    call function_21549                     

function_16995:
    mov64 r8, r3                                    r8 = r3
    mov64 r7, r2                                    r7 = r2
    mov64 r6, r1                                    r6 = r1
    ldxdw r1, [r8+0x0]                      
    call function_19510                     
    jne r0, 0, lbb_17008                            if r0 != (0 as i32 as i64 as u64) { pc += 7 }
    lddw r1, 0x8000000000000000                     r1 load str located at -9223372036854775808
    stxdw [r6+0x0], r1                      
    lddw r1, 0x8000000000000010                     r1 load str located at -9223372036854775792
    stxdw [r6+0x8], r1                      
    ja lbb_17056                                    if true { pc += 48 }
lbb_17008:
    mov64 r1, r10                                   r1 = r10
    add64 r1, -80                                   r1 += -80   ///  r1 = r1.wrapping_add(-80 as i32 as i64 as u64)
    mov64 r2, r8                                    r2 = r8
    call function_17777                     
    ldxdw r8, [r10-0x40]                    
    ldxdw r1, [r10-0x48]                    
    ldxdw r2, [r10-0x50]                    
    lddw r3, 0x800000000000001a                     r3 load str located at -9223372036854775782
    jeq r2, r3, lbb_17019                           if r2 == r3 { pc += 1 }
    ja lbb_17041                                    if true { pc += 22 }
lbb_17019:
    ldxdw r4, [r1+0x8]                      
    ldxdw r3, [r1+0x0]                      
    mov64 r1, r10                                   r1 = r10
    add64 r1, -80                                   r1 += -80   ///  r1 = r1.wrapping_add(-80 as i32 as i64 as u64)
    mov64 r2, r7                                    r2 = r7
    call function_16741                     
    lddw r1, 0x8000000000000000                     r1 load str located at -9223372036854775808
    ldxdw r2, [r10-0x50]                    
    jeq r2, r1, lbb_17030                           if r2 == r1 { pc += 1 }
    ja lbb_17048                                    if true { pc += 18 }
lbb_17030:
    lddw r1, 0x8000000000000001                     r1 load str located at -9223372036854775807
    ldxb r2, [r10-0x48]                     
    jeq r2, 0, lbb_17036                            if r2 == (0 as i32 as i64 as u64) { pc += 2 }
    lddw r1, 0x8000000000000002                     r1 load str located at -9223372036854775806
lbb_17036:
    lddw r2, 0x8000000000000000                     r2 load str located at -9223372036854775808
    stxdw [r6+0x0], r2                      
    stxdw [r6+0x8], r1                      
    ja lbb_17053                                    if true { pc += 12 }
lbb_17041:
    stxdw [r6+0x18], r8                     
    stxdw [r6+0x10], r1                     
    stxdw [r6+0x8], r2                      
    lddw r1, 0x8000000000000000                     r1 load str located at -9223372036854775808
    stxdw [r6+0x0], r1                      
    ja lbb_17056                                    if true { pc += 8 }
lbb_17048:
    mov64 r2, r10                                   r2 = r10
    add64 r2, -80                                   r2 += -80   ///  r2 = r2.wrapping_add(-80 as i32 as i64 as u64)
    mov64 r1, r6                                    r1 = r6
    mov64 r3, 80                                    r3 = 80 as i32 as i64 as u64
    call function_30349                     
lbb_17053:
    ldxdw r1, [r8+0x0]                      
    add64 r1, -1                                    r1 += -1   ///  r1 = r1.wrapping_add(-1 as i32 as i64 as u64)
    stxdw [r8+0x0], r1                      
lbb_17056:
    exit                                    

function_17057:
    ldxdw r5, [r2+0x0]                      
    mov64 r0, r5                                    r0 = r5
    add64 r0, 1                                     r0 += 1   ///  r0 = r0.wrapping_add(1 as i32 as i64 as u64)
    mov64 r6, 0                                     r6 = 0 as i32 as i64 as u64
    jgt r0, r4, lbb_17066                           if r0 > r4 { pc += 4 }
    jge r5, r4, lbb_17073                           if r5 >= r4 { pc += 10 }
    add64 r3, r5                                    r3 += r5   ///  r3 = r3.wrapping_add(r5)
    ldxb r6, [r3+0x0]                       
    stxdw [r2+0x0], r0                      
lbb_17066:
    mov64 r2, 1                                     r2 = 1 as i32 as i64 as u64
    jgt r0, r4, lbb_17069                           if r0 > r4 { pc += 1 }
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
lbb_17069:
    stxb [r1+0x1], r6                       
    and64 r2, 1                                     r2 &= 1   ///  r2 = r2.and(1)
    stxb [r1+0x0], r2                       
    exit                                    
lbb_17073:
    mov64 r1, r5                                    r1 = r5
    mov64 r2, r4                                    r2 = r4
    lddw r3, 0x100041460 --> b"\x00\x00\x00\x00\xb6\xec\x03\x00\x0a\x00\x00\x00\x00\x00\x00\x00 \x00\x00…        r3 load str located at 4295234656
    call function_25832                     

function_17078:
    mov64 r7, 1                                     r7 = 1 as i32 as i64 as u64
    mov64 r6, 0                                     r6 = 0 as i32 as i64 as u64
    ldxdw r5, [r2+0x0]                      
    mov64 r0, r5                                    r0 = r5
    add64 r0, 32                                    r0 += 32   ///  r0 = r0.wrapping_add(32 as i32 as i64 as u64)
    jgt r0, r4, lbb_17103                           if r0 > r4 { pc += 19 }
    mov64 r4, -32                                   r4 = -32 as i32 as i64 as u64
    jgt r4, r5, lbb_17091                           if r4 > r5 { pc += 5 }
    mov64 r1, r5                                    r1 = r5
    mov64 r2, r0                                    r2 = r0
    lddw r3, 0x100041478 --> b"\x00\x00\x00\x00\xb6\xec\x03\x00\x0a\x00\x00\x00\x00\x00\x00\x00*\x00\x00…        r3 load str located at 4295234680
    call function_28381                     
lbb_17091:
    add64 r3, r5                                    r3 += r5   ///  r3 = r3.wrapping_add(r5)
    ldxb r6, [r3+0x0]                       
    ldxdw r4, [r3+0x18]                     
    stxdw [r1+0x19], r4                     
    ldxdw r4, [r3+0x11]                     
    stxdw [r1+0x12], r4                     
    ldxdw r4, [r3+0x9]                      
    stxdw [r1+0xa], r4                      
    ldxdw r3, [r3+0x1]                      
    stxdw [r1+0x2], r3                      
    stxdw [r2+0x0], r0                      
    mov64 r7, 0                                     r7 = 0 as i32 as i64 as u64
lbb_17103:
    stxb [r1+0x0], r7                       
    stxb [r1+0x1], r6                       
    exit                                    

function_17106:
    mov64 r5, r2                                    r5 = r2
    mov64 r0, 1                                     r0 = 1 as i32 as i64 as u64
    ldxdw r4, [r1+0x0]                      
    mov64 r2, r4                                    r2 = r4
    add64 r2, 2                                     r2 += 2   ///  r2 = r2.wrapping_add(2 as i32 as i64 as u64)
    jgt r2, r3, lbb_17122                           if r2 > r3 { pc += 10 }
    mov64 r3, -2                                    r3 = -2 as i32 as i64 as u64
    jgt r3, r4, lbb_17118                           if r3 > r4 { pc += 4 }
    mov64 r1, r4                                    r1 = r4
    lddw r3, 0x100041490 --> b"\x00\x00\x00\x00\xb6\xec\x03\x00\x0a\x00\x00\x00\x00\x00\x00\x005\x00\x00…        r3 load str located at 4295234704
    call function_28381                     
lbb_17118:
    add64 r5, r4                                    r5 += r4   ///  r5 = r5.wrapping_add(r4)
    ldxh r0, [r5+0x0]                       
    stxdw [r1+0x0], r2                      
    lsh64 r0, 16                                    r0 <<= 16   ///  r0 = r0.wrapping_shl(16)
lbb_17122:
    exit                                    

function_17123:
    mov64 r6, r5                                    r6 = r5
    mov64 r7, r1                                    r7 = r1
    ldxdw r9, [r2+0x0]                      
    mov64 r8, r9                                    r8 = r9
    add64 r8, r6                                    r8 += r6   ///  r8 = r8.wrapping_add(r6)
    jgt r8, r4, lbb_17135                           if r8 > r4 { pc += 6 }
    jge r8, r9, lbb_17141                           if r8 >= r9 { pc += 11 }
    mov64 r1, r9                                    r1 = r9
    mov64 r2, r8                                    r2 = r8
    lddw r3, 0x1000414a8 --> b"\x00\x00\x00\x00\xb6\xec\x03\x00\x0a\x00\x00\x00\x00\x00\x00\x00C\x00\x00…        r3 load str located at 4295234728
    call function_28381                     
lbb_17135:
    lddw r1, 0x8000000000000000                     r1 load str located at -9223372036854775808
    stxdw [r7+0x0], r1                      
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    stxb [r7+0x8], r1                       
    ja lbb_17167                                    if true { pc += 26 }
lbb_17141:
    stxdw [r10-0x8], r2                     
    mov64 r0, 1                                     r0 = 1 as i32 as i64 as u64
    jeq r6, 0, lbb_17156                            if r6 == (0 as i32 as i64 as u64) { pc += 12 }
    stxdw [r10-0x18], r3                    
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    stxdw [r10-0x10], r1                    
    jsgt r2, r6, lbb_17168                          if (r2 as i64) > (r6 as i64) { pc += 19 }
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    stxdw [r10-0x10], r1                    
    mov64 r1, r6                                    r1 = r6
    mov64 r2, 1                                     r2 = 1 as i32 as i64 as u64
    call function_14385                     
    jeq r0, 0, lbb_17168                            if r0 == (0 as i32 as i64 as u64) { pc += 13 }
    ldxdw r3, [r10-0x18]                    
lbb_17156:
    add64 r3, r9                                    r3 += r9   ///  r3 = r3.wrapping_add(r9)
    mov64 r9, r0                                    r9 = r0
    mov64 r1, r9                                    r1 = r9
    mov64 r2, r3                                    r2 = r3
    mov64 r3, r6                                    r3 = r6
    call function_30349                     
    ldxdw r1, [r10-0x8]                     
    stxdw [r1+0x0], r8                      
    stxdw [r7+0x8], r9                      
    stxdw [r7+0x0], r6                      
    stxdw [r7+0x10], r6                     
lbb_17167:
    exit                                    
lbb_17168:
    ldxdw r1, [r10-0x10]                    
    mov64 r2, r6                                    r2 = r6
    call function_21549                     

function_17171:
    mov64 r6, r1                                    r6 = r1
    mov64 r7, r10                                   r7 = r10
    add64 r7, -40                                   r7 += -40   ///  r7 = r7.wrapping_add(-40 as i32 as i64 as u64)
    mov64 r8, 0                                     r8 = 0 as i32 as i64 as u64
    mov64 r1, r7                                    r1 = r7
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
    mov64 r3, 40                                    r3 = 40 as i32 as i64 as u64
    call function_30383                     
    mov64 r1, r7                                    r1 = r7
    syscall [invalid]                       
    mov64 r1, r6                                    r1 = r6
    add64 r1, 8                                     r1 += 8   ///  r1 = r1.wrapping_add(8 as i32 as i64 as u64)
    jne r0, 0, lbb_17189                            if r0 != (0 as i32 as i64 as u64) { pc += 5 }
    mov64 r2, r10                                   r2 = r10
    add64 r2, -40                                   r2 += -40   ///  r2 = r2.wrapping_add(-40 as i32 as i64 as u64)
    mov64 r3, 40                                    r3 = 40 as i32 as i64 as u64
    call function_30349                     
    ja lbb_17192                                    if true { pc += 3 }
lbb_17189:
    mov64 r2, r0                                    r2 = r0
    call function_17940                     
    mov64 r8, 1                                     r8 = 1 as i32 as i64 as u64
lbb_17192:
    stxdw [r6+0x0], r8                      
    exit                                    

function_17194:
    mov64 r6, r1                                    r6 = r1
    mov64 r1, 50                                    r1 = 50 as i32 as i64 as u64
    stxb [r10-0x8], r1                      
    lddw r1, 0x4000000000000000                     r1 load str located at 4611686018427387904
    stxdw [r10-0x10], r1                    
    mov64 r1, 3480                                  r1 = 3480 as i32 as i64 as u64
    stxdw [r10-0x18], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -24                                   r1 += -24   ///  r1 = r1.wrapping_add(-24 as i32 as i64 as u64)
    syscall [invalid]                       
    mov64 r1, r6                                    r1 = r6
    add64 r1, 8                                     r1 += 8   ///  r1 = r1.wrapping_add(8 as i32 as i64 as u64)
    jne r0, 0, lbb_17216                            if r0 != (0 as i32 as i64 as u64) { pc += 8 }
    ldxdw r2, [r10-0x8]                     
    stxdw [r1+0x10], r2                     
    ldxdw r2, [r10-0x10]                    
    stxdw [r1+0x8], r2                      
    ldxdw r2, [r10-0x18]                    
    stxdw [r1+0x0], r2                      
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    ja lbb_17219                                    if true { pc += 3 }
lbb_17216:
    mov64 r2, r0                                    r2 = r0
    call function_17940                     
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
lbb_17219:
    stxdw [r6+0x0], r1                      
    exit                                    

function_17221:
    mov64 r7, r3                                    r7 = r3
    mov64 r8, r2                                    r8 = r2
    mov64 r6, r1                                    r6 = r1
    jeq r8, 0, lbb_17235                            if r8 == (0 as i32 as i64 as u64) { pc += 10 }
    ldxdw r1, [r4+0x8]                      
    jeq r1, 0, lbb_17245                            if r1 == (0 as i32 as i64 as u64) { pc += 18 }
    ldxdw r2, [r4+0x10]                     
    jne r2, 0, lbb_17239                            if r2 != (0 as i32 as i64 as u64) { pc += 10 }
    jeq r7, 0, lbb_17254                            if r7 == (0 as i32 as i64 as u64) { pc += 24 }
    mov64 r1, r7                                    r1 = r7
    mov64 r2, r8                                    r2 = r8
    call function_14385                     
    jeq r0, 0, lbb_17250                            if r0 == (0 as i32 as i64 as u64) { pc += 16 }
    ja lbb_17256                                    if true { pc += 21 }
lbb_17235:
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    stxdw [r6+0x8], r1                      
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    ja lbb_17259                                    if true { pc += 20 }
lbb_17239:
    ldxdw r1, [r4+0x0]                      
    mov64 r3, r8                                    r3 = r8
    mov64 r4, r7                                    r4 = r7
    call function_14412                     
    jeq r0, 0, lbb_17250                            if r0 == (0 as i32 as i64 as u64) { pc += 6 }
    ja lbb_17256                                    if true { pc += 11 }
lbb_17245:
    jeq r7, 0, lbb_17254                            if r7 == (0 as i32 as i64 as u64) { pc += 8 }
    mov64 r1, r7                                    r1 = r7
    mov64 r2, r8                                    r2 = r8
    call function_14385                     
    jne r0, 0, lbb_17256                            if r0 != (0 as i32 as i64 as u64) { pc += 6 }
lbb_17250:
    stxdw [r6+0x10], r7                     
    stxdw [r6+0x8], r8                      
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    ja lbb_17259                                    if true { pc += 5 }
lbb_17254:
    mov64 r7, 0                                     r7 = 0 as i32 as i64 as u64
    mov64 r0, r8                                    r0 = r8
lbb_17256:
    stxdw [r6+0x10], r7                     
    stxdw [r6+0x8], r0                      
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
lbb_17259:
    stxdw [r6+0x0], r1                      
    exit                                    

function_17261:
    mov64 r6, r1                                    r6 = r1
    ldxdw r4, [r6+0x0]                      
    mov64 r3, r4                                    r3 = r4
    add64 r3, 1                                     r3 += 1   ///  r3 = r3.wrapping_add(1 as i32 as i64 as u64)
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    mov64 r5, 1                                     r5 = 1 as i32 as i64 as u64
    jeq r3, 0, lbb_17269                            if r3 == (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r5, 0                                     r5 = 0 as i32 as i64 as u64
lbb_17269:
    and64 r5, 1                                     r5 &= 1   ///  r5 = r5.and(1)
    jne r5, 0, lbb_17301                            if r5 != (0 as i32 as i64 as u64) { pc += 30 }
    mov64 r7, r4                                    r7 = r4
    lsh64 r7, 1                                     r7 <<= 1   ///  r7 = r7.wrapping_shl(1)
    jgt r7, r3, lbb_17275                           if r7 > r3 { pc += 1 }
    mov64 r7, r3                                    r7 = r3
lbb_17275:
    mov64 r2, 1                                     r2 = 1 as i32 as i64 as u64
    lddw r3, 0x2aaaaaaaaaaaaab                      r3 load str located at 192153584101141163
    jgt r3, r7, lbb_17280                           if r3 > r7 { pc += 1 }
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
lbb_17280:
    jgt r7, 4, lbb_17282                            if r7 > (4 as i32 as i64 as u64) { pc += 1 }
    mov64 r7, 4                                     r7 = 4 as i32 as i64 as u64
lbb_17282:
    lsh64 r2, 3                                     r2 <<= 3   ///  r2 = r2.wrapping_shl(3)
    mov64 r3, r7                                    r3 = r7
    mul64 r3, 48                                    r3 *= 48   ///  r3 = r3.wrapping_mul(48 as u64)
    jeq r4, 0, lbb_17291                            if r4 == (0 as i32 as i64 as u64) { pc += 5 }
    ldxdw r1, [r6+0x8]                      
    mul64 r4, 48                                    r4 *= 48   ///  r4 = r4.wrapping_mul(48 as u64)
    stxdw [r10-0x8], r4                     
    stxdw [r10-0x18], r1                    
    mov64 r1, 8                                     r1 = 8 as i32 as i64 as u64
lbb_17291:
    stxdw [r10-0x10], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -48                                   r1 += -48   ///  r1 = r1.wrapping_add(-48 as i32 as i64 as u64)
    mov64 r4, r10                                   r4 = r10
    add64 r4, -24                                   r4 += -24   ///  r4 = r4.wrapping_add(-24 as i32 as i64 as u64)
    call function_17221                     
    ldxdw r1, [r10-0x30]                    
    jeq r1, 0, lbb_17302                            if r1 == (0 as i32 as i64 as u64) { pc += 3 }
    ldxdw r2, [r10-0x20]                    
    ldxdw r1, [r10-0x28]                    
lbb_17301:
    call function_21549                     
lbb_17302:
    ldxdw r1, [r10-0x28]                    
    stxdw [r6+0x0], r7                      
    stxdw [r6+0x8], r1                      
    exit                                    

function_17306:
    stxdw [r10-0x70], r1                    
    stxdw [r10-0x38], r2                    
    ldxdw r2, [r2+0x0]                      
    jne r2, 0, lbb_17331                            if r2 != (0 as i32 as i64 as u64) { pc += 21 }
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    stxdw [r10-0x10], r1                    
    stxdw [r10-0x20], r2                    
    mov64 r6, 8                                     r6 = 8 as i32 as i64 as u64
    stxdw [r10-0x18], r6                    
lbb_17315:
    ldxdw r3, [r10-0x38]                    
    add64 r3, r6                                    r3 += r6   ///  r3 = r3.wrapping_add(r6)
    ldxdw r1, [r3+0x0]                      
    ldxdw r2, [r10-0x10]                    
    ldxdw r4, [r10-0x70]                    
    stxdw [r4+0x10], r2                     
    ldxdw r2, [r10-0x18]                    
    stxdw [r4+0x8], r2                      
    ldxdw r2, [r10-0x20]                    
    stxdw [r4+0x0], r2                      
    stxdw [r4+0x28], r1                     
    add64 r3, 8                                     r3 += 8   ///  r3 = r3.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r4+0x20], r3                     
    add64 r3, r1                                    r3 += r1   ///  r3 = r3.wrapping_add(r1)
    stxdw [r4+0x18], r3                     
    exit                                    
lbb_17331:
    mov64 r8, 0                                     r8 = 0 as i32 as i64 as u64
    mov64 r7, r2                                    r7 = r2
    mul64 r7, 48                                    r7 *= 48   ///  r7 = r7.wrapping_mul(48 as u64)
    lddw r1, 0x2aaaaaaaaaaaaaa                      r1 load str located at 192153584101141162
    stxdw [r10-0x60], r2                    
    jgt r2, r1, lbb_17528                           if r2 > r1 { pc += 190 }
    mov64 r8, 8                                     r8 = 8 as i32 as i64 as u64
    mov64 r1, r7                                    r1 = r7
    mov64 r2, 8                                     r2 = 8 as i32 as i64 as u64
    call function_14385                     
    jeq r0, 0, lbb_17528                            if r0 == (0 as i32 as i64 as u64) { pc += 185 }
    stxdw [r10-0x18], r0                    
    ldxdw r4, [r10-0x60]                    
    stxdw [r10-0x20], r4                    
    mov64 r6, 8                                     r6 = 8 as i32 as i64 as u64
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    stxdw [r10-0x10], r1                    
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
    ja lbb_17379                                    if true { pc += 27 }
lbb_17352:
    mov64 r1, r2                                    r1 = r2
    mul64 r1, 48                                    r1 *= 48   ///  r1 = r1.wrapping_mul(48 as u64)
    mov64 r3, r0                                    r3 = r0
    add64 r3, r1                                    r3 += r1   ///  r3 = r3.wrapping_add(r1)
    ldxdw r1, [r10-0x58]                    
    stxb [r3+0x2a], r1                      
    ldxdw r1, [r10-0x50]                    
    stxb [r3+0x29], r1                      
    ldxdw r1, [r10-0x48]                    
    stxb [r3+0x28], r1                      
    ldxdw r1, [r10-0x40]                    
    stxdw [r3+0x20], r1                     
    stxdw [r3+0x18], r5                     
    stxdw [r3+0x10], r9                     
    stxdw [r3+0x8], r7                      
    stxdw [r3+0x0], r8                      
    ldxw r1, [r10-0x5]                      
    stxw [r3+0x2b], r1                      
    ldxb r1, [r10-0x1]                      
    stxb [r3+0x2f], r1                      
lbb_17372:
    add64 r2, 1                                     r2 += 1   ///  r2 = r2.wrapping_add(1 as i32 as i64 as u64)
    stxdw [r10-0x10], r2                    
    ldxdw r3, [r10-0x28]                    
    add64 r3, 1                                     r3 += 1   ///  r3 = r3.wrapping_add(1 as i32 as i64 as u64)
    add64 r6, 8                                     r6 += 8   ///  r6 = r6.wrapping_add(8 as i32 as i64 as u64)
    jgt r4, r3, lbb_17379                           if r4 > r3 { pc += 1 }
    ja lbb_17315                                    if true { pc += -64 }
lbb_17379:
    ldxdw r8, [r10-0x38]                    
    add64 r8, r6                                    r8 += r6   ///  r8 = r8.wrapping_add(r6)
    ldxb r1, [r8+0x0]                       
    stxdw [r10-0x28], r3                    
    jeq r1, 255, lbb_17431                          if r1 == (255 as i32 as i64 as u64) { pc += 47 }
    jgt r2, r1, lbb_17388                           if r2 > r1 { pc += 3 }
    lddw r3, 0x1000414c0 --> b"\x00\x00\x00\x00\xc0\xec\x03\x00\x0a\x00\x00\x00\x00\x00\x00\x00\xad\x01\…        r3 load str located at 4295234752
    call function_25832                     
lbb_17388:
    mul64 r1, 48                                    r1 *= 48   ///  r1 = r1.wrapping_mul(48 as u64)
    mov64 r5, r0                                    r5 = r0
    add64 r5, r1                                    r5 += r1   ///  r5 = r5.wrapping_add(r1)
    ldxdw r7, [r5+0x8]                      
    ldxdw r1, [r7+0x0]                      
    add64 r1, 1                                     r1 += 1   ///  r1 = r1.wrapping_add(1 as i32 as i64 as u64)
    mov64 r3, 1                                     r3 = 1 as i32 as i64 as u64
    jeq r1, 0, lbb_17397                            if r1 == (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
lbb_17397:
    ldxdw r8, [r5+0x0]                      
    stxdw [r7+0x0], r1                      
    jne r3, 1, lbb_17401                            if r3 != (1 as i32 as i64 as u64) { pc += 1 }
lbb_17400:
    syscall [invalid]                       
lbb_17401:
    ldxdw r9, [r5+0x10]                     
    ldxdw r1, [r9+0x0]                      
    add64 r1, 1                                     r1 += 1   ///  r1 = r1.wrapping_add(1 as i32 as i64 as u64)
    mov64 r3, 1                                     r3 = 1 as i32 as i64 as u64
    jeq r1, 0, lbb_17407                            if r1 == (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
lbb_17407:
    stxdw [r9+0x0], r1                      
    jne r3, 1, lbb_17410                            if r3 != (1 as i32 as i64 as u64) { pc += 1 }
    ja lbb_17400                                    if true { pc += -10 }
lbb_17410:
    ldxb r1, [r5+0x2a]                      
    stxdw [r10-0x58], r1                    
    ldxb r1, [r5+0x29]                      
    stxdw [r10-0x50], r1                    
    ldxb r1, [r5+0x28]                      
    stxdw [r10-0x48], r1                    
    ldxdw r1, [r5+0x20]                     
    stxdw [r10-0x40], r1                    
    ldxdw r5, [r5+0x18]                     
    ldxdw r1, [r10-0x20]                    
    jne r2, r1, lbb_17352                           if r2 != r1 { pc += -69 }
    mov64 r1, r10                                   r1 = r10
    add64 r1, -32                                   r1 += -32   ///  r1 = r1.wrapping_add(-32 as i32 as i64 as u64)
    stxdw [r10-0x30], r2                    
    stxdw [r10-0x68], r5                    
    call function_17261                     
    ldxdw r5, [r10-0x68]                    
    ldxdw r2, [r10-0x30]                    
    ldxdw r4, [r10-0x60]                    
    ldxdw r0, [r10-0x18]                    
    ja lbb_17352                                    if true { pc += -79 }
lbb_17431:
    stxdw [r10-0x30], r2                    
    ldxb r1, [r8+0x3]                       
    stxdw [r10-0x50], r1                    
    ldxb r1, [r8+0x2]                       
    stxdw [r10-0x40], r1                    
    ldxb r1, [r8+0x1]                       
    stxdw [r10-0x48], r1                    
    mov64 r1, 32                                    r1 = 32 as i32 as i64 as u64
    mov64 r2, 8                                     r2 = 8 as i32 as i64 as u64
    call function_14385                     
    jne r0, 0, lbb_17445                            if r0 != (0 as i32 as i64 as u64) { pc += 3 }
    mov64 r1, 8                                     r1 = 8 as i32 as i64 as u64
    mov64 r2, 32                                    r2 = 32 as i32 as i64 as u64
    call function_21552                     
lbb_17445:
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    stxdw [r0+0x10], r1                     
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    stxdw [r0+0x8], r1                      
    stxdw [r0+0x0], r1                      
    mov64 r1, r8                                    r1 = r8
    add64 r1, 72                                    r1 += 72   ///  r1 = r1.wrapping_add(72 as i32 as i64 as u64)
    stxdw [r10-0x58], r0                    
    stxdw [r0+0x18], r1                     
    ldxdw r9, [r8+0x50]                     
    stxw [r8+0x4], r9                       
    mov64 r1, 40                                    r1 = 40 as i32 as i64 as u64
    mov64 r2, 8                                     r2 = 8 as i32 as i64 as u64
    call function_14385                     
    mov64 r7, r0                                    r7 = r0
    jne r7, 0, lbb_17464                            if r7 != (0 as i32 as i64 as u64) { pc += 3 }
    mov64 r1, 8                                     r1 = 8 as i32 as i64 as u64
    mov64 r2, 40                                    r2 = 40 as i32 as i64 as u64
    call function_21552                     
lbb_17464:
    ldxdw r1, [r10-0x50]                    
    mov64 r3, r1                                    r3 = r1
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    mov64 r0, 1                                     r0 = 1 as i32 as i64 as u64
    ldxdw r4, [r10-0x60]                    
    ldxdw r2, [r10-0x30]                    
    jne r3, 0, lbb_17472                            if r3 != (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r0, 0                                     r0 = 0 as i32 as i64 as u64
lbb_17472:
    ldxdw r3, [r10-0x40]                    
    mov64 r5, 1                                     r5 = 1 as i32 as i64 as u64
    stxdw [r10-0x40], r5                    
    jne r3, 0, lbb_17478                            if r3 != (0 as i32 as i64 as u64) { pc += 2 }
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
    stxdw [r10-0x40], r3                    
lbb_17478:
    ldxdw r3, [r10-0x48]                    
    mov64 r5, 0                                     r5 = 0 as i32 as i64 as u64
    stxdw [r7+0x10], r5                     
    mov64 r5, 1                                     r5 = 1 as i32 as i64 as u64
    jne r3, 0, lbb_17484                            if r3 != (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r5, 0                                     r5 = 0 as i32 as i64 as u64
lbb_17484:
    stxdw [r10-0x48], r0                    
    stxdw [r7+0x8], r1                      
    stxdw [r7+0x0], r1                      
    mov64 r1, r8                                    r1 = r8
    add64 r1, 88                                    r1 += 88   ///  r1 = r1.wrapping_add(88 as i32 as i64 as u64)
    stxdw [r7+0x18], r1                     
    stxdw [r7+0x20], r9                     
    add64 r6, r9                                    r6 += r9   ///  r6 = r6.wrapping_add(r9)
    mov64 r9, r8                                    r9 = r8
    add64 r9, 8                                     r9 += 8   ///  r9 = r9.wrapping_add(8 as i32 as i64 as u64)
    add64 r8, 40                                    r8 += 40   ///  r8 = r8.wrapping_add(40 as i32 as i64 as u64)
    add64 r6, 10335                                 r6 += 10335   ///  r6 = r6.wrapping_add(10335 as i32 as i64 as u64)
    and64 r6, -8                                    r6 &= -8   ///  r6 = r6.and(-8)
    ldxdw r1, [r10-0x38]                    
    add64 r1, r6                                    r1 += r6   ///  r1 = r1.wrapping_add(r6)
    ldxdw r1, [r1+0x0]                      
    stxdw [r10-0x50], r1                    
    ldxdw r1, [r10-0x20]                    
    jne r2, r1, lbb_17510                           if r2 != r1 { pc += 7 }
    mov64 r1, r10                                   r1 = r10
    add64 r1, -32                                   r1 += -32   ///  r1 = r1.wrapping_add(-32 as i32 as i64 as u64)
    stxdw [r10-0x68], r5                    
    call function_17261                     
    ldxdw r5, [r10-0x68]                    
    ldxdw r2, [r10-0x30]                    
    ldxdw r4, [r10-0x60]                    
lbb_17510:
    mov64 r1, r2                                    r1 = r2
    mul64 r1, 48                                    r1 *= 48   ///  r1 = r1.wrapping_mul(48 as u64)
    ldxdw r0, [r10-0x18]                    
    mov64 r3, r0                                    r3 = r0
    add64 r3, r1                                    r3 += r1   ///  r3 = r3.wrapping_add(r1)
    ldxdw r1, [r10-0x48]                    
    stxb [r3+0x2a], r1                      
    ldxdw r1, [r10-0x40]                    
    stxb [r3+0x29], r1                      
    stxb [r3+0x28], r5                      
    ldxdw r1, [r10-0x50]                    
    stxdw [r3+0x20], r1                     
    stxdw [r3+0x18], r8                     
    stxdw [r3+0x10], r7                     
    ldxdw r1, [r10-0x58]                    
    stxdw [r3+0x8], r1                      
    stxdw [r3+0x0], r9                      
    ja lbb_17372                                    if true { pc += -156 }
lbb_17528:
    mov64 r1, r8                                    r1 = r8
    mov64 r2, r7                                    r2 = r7
    call function_21549                     

function_17531:
    mov64 r9, r4                                    r9 = r4
    stxdw [r10-0x78], r3                    
    mov64 r3, r1                                    r3 = r1
    mov64 r0, 1                                     r0 = 1 as i32 as i64 as u64
    ldxdw r1, [r5-0xff8]                    
    stxdw [r10-0x80], r1                    
    ldxdw r1, [r5-0x1000]                   
    stxdw [r10-0x88], r1                    
    stxdw [r10-0x58], r2                    
    ldxdw r1, [r2+0x10]                     
    mov64 r2, 1                                     r2 = 1 as i32 as i64 as u64
    stxdw [r10-0x70], r2                    
    stxdw [r10-0x60], r1                    
    stxdw [r10-0x68], r3                    
    jeq r1, 0, lbb_17586                            if r1 == (0 as i32 as i64 as u64) { pc += 40 }
    stxdw [r10-0x90], r9                    
    mov64 r7, 0                                     r7 = 0 as i32 as i64 as u64
    ldxdw r2, [r10-0x60]                    
    mov64 r6, r2                                    r6 = r2
    mul64 r6, 34                                    r6 *= 34   ///  r6 = r6.wrapping_mul(34 as u64)
    lddw r1, 0x3c3c3c3c3c3c3c3                      r1 load str located at 271275648142787523
    jgt r2, r1, lbb_17648                           if r2 > r1 { pc += 94 }
    ldxdw r1, [r10-0x58]                    
    ldxdw r8, [r1+0x8]                      
    mov64 r7, 1                                     r7 = 1 as i32 as i64 as u64
    mov64 r1, r6                                    r1 = r6
    mov64 r2, 1                                     r2 = 1 as i32 as i64 as u64
    call function_14385                     
    jeq r0, 0, lbb_17648                            if r0 == (0 as i32 as i64 as u64) { pc += 87 }
    stxdw [r10-0x70], r0                    
    mov64 r1, r0                                    r1 = r0
    add64 r1, 33                                    r1 += 33   ///  r1 = r1.wrapping_add(33 as i32 as i64 as u64)
    ldxdw r2, [r10-0x60]                    
lbb_17565:
    jeq r6, 0, lbb_17583                            if r6 == (0 as i32 as i64 as u64) { pc += 17 }
    ldxdw r3, [r8+0x0]                      
    ldxdw r4, [r8+0x8]                      
    ldxdw r5, [r8+0x10]                     
    ldxdw r0, [r8+0x18]                     
    ldxb r9, [r8+0x21]                      
    ldxb r7, [r8+0x20]                      
    stxb [r1-0x1], r7                       
    stxb [r1+0x0], r9                       
    stxdw [r1-0x9], r0                      
    stxdw [r1-0x11], r5                     
    stxdw [r1-0x19], r4                     
    stxdw [r1-0x21], r3                     
    add64 r1, 34                                    r1 += 34   ///  r1 = r1.wrapping_add(34 as i32 as i64 as u64)
    add64 r6, -34                                   r6 += -34   ///  r6 = r6.wrapping_add(-34 as i32 as i64 as u64)
    add64 r8, 34                                    r8 += 34   ///  r8 = r8.wrapping_add(34 as i32 as i64 as u64)
    add64 r2, -1                                    r2 += -1   ///  r2 = r2.wrapping_add(-1 as i32 as i64 as u64)
    jne r2, 0, lbb_17565                            if r2 != (0 as i32 as i64 as u64) { pc += -18 }
lbb_17583:
    ldxdw r3, [r10-0x68]                    
    ldxdw r9, [r10-0x90]                    
    mov64 r0, 1                                     r0 = 1 as i32 as i64 as u64
lbb_17586:
    ldxdw r1, [r10-0x58]                    
    ldxdw r7, [r1+0x20]                     
    ldxdw r6, [r1+0x28]                     
    jeq r6, 0, lbb_17597                            if r6 == (0 as i32 as i64 as u64) { pc += 7 }
    mov64 r8, 0                                     r8 = 0 as i32 as i64 as u64
    jsgt r8, r6, lbb_17651                          if (r8 as i64) > (r6 as i64) { pc += 59 }
    mov64 r8, 1                                     r8 = 1 as i32 as i64 as u64
    mov64 r1, r6                                    r1 = r6
    mov64 r2, 1                                     r2 = 1 as i32 as i64 as u64
    call function_14385                     
    jeq r0, 0, lbb_17651                            if r0 == (0 as i32 as i64 as u64) { pc += 54 }
lbb_17597:
    ldxdw r8, [r10-0x58]                    
    add64 r8, 48                                    r8 += 48   ///  r8 = r8.wrapping_add(48 as i32 as i64 as u64)
    mov64 r1, r0                                    r1 = r0
    mov64 r2, r7                                    r2 = r7
    mov64 r3, r6                                    r3 = r6
    mov64 r7, r0                                    r7 = r0
    call function_30349                     
    stxdw [r10-0x28], r6                    
    stxdw [r10-0x30], r6                    
    stxdw [r10-0x38], r7                    
    ldxdw r1, [r10-0x60]                    
    stxdw [r10-0x40], r1                    
    stxdw [r10-0x48], r1                    
    ldxdw r1, [r10-0x70]                    
    stxdw [r10-0x50], r1                    
    ldxdw r1, [r8+0x0]                      
    stxdw [r10-0x20], r1                    
    ldxdw r1, [r8+0x8]                      
    stxdw [r10-0x18], r1                    
    ldxdw r1, [r8+0x10]                     
    stxdw [r10-0x10], r1                    
    ldxdw r1, [r8+0x18]                     
    stxdw [r10-0x8], r1                     
    mov64 r1, r10                                   r1 = r10
    add64 r1, -80                                   r1 += -80   ///  r1 = r1.wrapping_add(-80 as i32 as i64 as u64)
    ldxdw r2, [r10-0x78]                    
    mov64 r3, r9                                    r3 = r9
    ldxdw r4, [r10-0x88]                    
    ldxdw r5, [r10-0x80]                    
    syscall [invalid]                       
    jne r0, 0, lbb_17633                            if r0 != (0 as i32 as i64 as u64) { pc += 5 }
    lddw r1, 0x800000000000001a                     r1 load str located at -9223372036854775782
    ldxdw r2, [r10-0x68]                    
    stxdw [r2+0x0], r1                      
    ja lbb_17636                                    if true { pc += 3 }
lbb_17633:
    ldxdw r1, [r10-0x68]                    
    mov64 r2, r0                                    r2 = r0
    call function_17940                     
lbb_17636:
    ldxdw r2, [r10-0x48]                    
    jeq r2, 0, lbb_17642                            if r2 == (0 as i32 as i64 as u64) { pc += 4 }
    ldxdw r1, [r10-0x50]                    
    mul64 r2, 34                                    r2 *= 34   ///  r2 = r2.wrapping_mul(34 as u64)
    mov64 r3, 1                                     r3 = 1 as i32 as i64 as u64
    call function_14411                     
lbb_17642:
    ldxdw r2, [r10-0x30]                    
    jeq r2, 0, lbb_17647                            if r2 == (0 as i32 as i64 as u64) { pc += 3 }
    ldxdw r1, [r10-0x38]                    
    mov64 r3, 1                                     r3 = 1 as i32 as i64 as u64
    call function_14411                     
lbb_17647:
    exit                                    
lbb_17648:
    mov64 r1, r7                                    r1 = r7
    mov64 r2, r6                                    r2 = r6
    call function_21549                     
lbb_17651:
    mov64 r1, r8                                    r1 = r8
    mov64 r2, r6                                    r2 = r6
    call function_21549                     

function_17654:
    mov64 r6, r1                                    r6 = r1
    mov64 r7, r10                                   r7 = r10
    add64 r7, -1088                                 r7 += -1088   ///  r7 = r7.wrapping_add(-1088 as i32 as i64 as u64)
    mov64 r9, 0                                     r9 = 0 as i32 as i64 as u64
    mov64 r8, 1024                                  r8 = 1024 as i32 as i64 as u64
    mov64 r1, r7                                    r1 = r7
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
    mov64 r3, 1024                                  r3 = 1024 as i32 as i64 as u64
    call function_30383                     
    stxdw [r10-0x28], r9                    
    stxdw [r10-0x30], r9                    
    stxdw [r10-0x38], r9                    
    stxdw [r10-0x40], r9                    
    mov64 r3, r10                                   r3 = r10
    add64 r3, -64                                   r3 += -64   ///  r3 = r3.wrapping_add(-64 as i32 as i64 as u64)
    mov64 r1, r7                                    r1 = r7
    mov64 r2, 1024                                  r2 = 1024 as i32 as i64 as u64
    syscall [invalid]                       
    mov64 r7, r0                                    r7 = r0
    lddw r2, 0x8000000000000000                     r2 load str located at -9223372036854775808
    mov64 r1, 32                                    r1 = 32 as i32 as i64 as u64
    jeq r7, 0, lbb_17712                            if r7 == (0 as i32 as i64 as u64) { pc += 35 }
    ldxdw r1, [r10-0x28]                    
    stxdw [r10-0x8], r1                     
    ldxdw r1, [r10-0x30]                    
    stxdw [r10-0x10], r1                    
    ldxdw r1, [r10-0x38]                    
    stxdw [r10-0x18], r1                    
    ldxdw r1, [r10-0x40]                    
    stxdw [r10-0x20], r1                    
    jgt r8, r7, lbb_17687                           if r8 > r7 { pc += 1 }
    mov64 r7, 1024                                  r7 = 1024 as i32 as i64 as u64
lbb_17687:
    mov64 r1, r7                                    r1 = r7
    mov64 r2, 1                                     r2 = 1 as i32 as i64 as u64
    call function_14385                     
    mov64 r8, r0                                    r8 = r0
    jne r8, 0, lbb_17695                            if r8 != (0 as i32 as i64 as u64) { pc += 3 }
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    mov64 r2, r7                                    r2 = r7
    call function_21549                     
lbb_17695:
    mov64 r2, r10                                   r2 = r10
    add64 r2, -1088                                 r2 += -1088   ///  r2 = r2.wrapping_add(-1088 as i32 as i64 as u64)
    mov64 r1, r8                                    r1 = r8
    mov64 r3, r7                                    r3 = r7
    call function_30349                     
    ldxdw r1, [r10-0x20]                    
    stxdw [r6+0x0], r1                      
    ldxdw r1, [r10-0x18]                    
    stxdw [r6+0x8], r1                      
    ldxdw r1, [r10-0x10]                    
    stxdw [r6+0x10], r1                     
    ldxdw r1, [r10-0x8]                     
    stxdw [r6+0x18], r1                     
    stxdw [r6+0x28], r8                     
    stxdw [r6+0x20], r7                     
    mov64 r1, 48                                    r1 = 48 as i32 as i64 as u64
    mov64 r2, r7                                    r2 = r7
lbb_17712:
    add64 r6, r1                                    r6 += r1   ///  r6 = r6.wrapping_add(r1)
    stxdw [r6+0x0], r2                      
    exit                                    

function_17715:
    ldxdw r1, [r1+0x8]                      
    ldxdw r2, [r1+0x10]                     
    lddw r3, 0x7ffffffffffffffe                     r3 load str located at 9223372036854775806
    jgt r2, r3, lbb_17727                           if r2 > r3 { pc += 7 }
    mov64 r3, r2                                    r3 = r2
    add64 r3, 1                                     r3 += 1   ///  r3 = r3.wrapping_add(1 as i32 as i64 as u64)
    stxdw [r1+0x10], r3                     
    ldxdw r3, [r1+0x18]                     
    ldxdw r0, [r3+0x0]                      
    stxdw [r1+0x10], r2                     
    exit                                    
lbb_17727:
    lddw r1, 0x1000414d8 --> b"\x00\x00\x00\x00\xca\xec\x03\x00\x0a\x00\x00\x00\x00\x00\x00\x00I\x00\x00…        r1 load str located at 4295234776
    call function_25345                     

function_17730:
    ldxdw r1, [r1+0x10]                     
    ldxdw r2, [r1+0x10]                     
    lddw r3, 0x7ffffffffffffffe                     r3 load str located at 9223372036854775806
    jgt r2, r3, lbb_17740                           if r2 > r3 { pc += 5 }
    ldxdw r1, [r1+0x20]                     
    mov64 r0, 1                                     r0 = 1 as i32 as i64 as u64
    jeq r1, 0, lbb_17739                            if r1 == (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r0, 0                                     r0 = 0 as i32 as i64 as u64
lbb_17739:
    exit                                    
lbb_17740:
    lddw r1, 0x1000414f0 --> b"\x00\x00\x00\x00\xca\xec\x03\x00\x0a\x00\x00\x00\x00\x00\x00\x00f\x00\x00…        r1 load str located at 4295234800
    call function_25345                     

function_17743:
    lddw r3, 0x800000000000000b                     r3 load str located at -9223372036854775797
    ldxdw r2, [r2+0x8]                      
    ldxdw r4, [r2+0x10]                     
    lddw r5, 0x7ffffffffffffffe                     r5 load str located at 9223372036854775806
    jgt r4, r5, lbb_17759                           if r4 > r5 { pc += 9 }
    mov64 r3, r2                                    r3 = r2
    add64 r3, 16                                    r3 += 16   ///  r3 = r3.wrapping_add(16 as i32 as i64 as u64)
    add64 r4, 1                                     r4 += 1   ///  r4 = r4.wrapping_add(1 as i32 as i64 as u64)
    stxdw [r2+0x10], r4                     
    stxdw [r1+0x10], r3                     
    add64 r2, 24                                    r2 += 24   ///  r2 = r2.wrapping_add(24 as i32 as i64 as u64)
    stxdw [r1+0x8], r2                      
    lddw r3, 0x800000000000001a                     r3 load str located at -9223372036854775782
lbb_17759:
    stxdw [r1+0x0], r3                      
    exit                                    

function_17761:
    lddw r3, 0x800000000000000b                     r3 load str located at -9223372036854775797
    ldxdw r2, [r2+0x8]                      
    ldxdw r4, [r2+0x10]                     
    jne r4, 0, lbb_17775                            if r4 != (0 as i32 as i64 as u64) { pc += 9 }
    mov64 r3, r2                                    r3 = r2
    add64 r3, 16                                    r3 += 16   ///  r3 = r3.wrapping_add(16 as i32 as i64 as u64)
    mov64 r4, -1                                    r4 = -1 as i32 as i64 as u64
    stxdw [r2+0x10], r4                     
    stxdw [r1+0x10], r3                     
    add64 r2, 24                                    r2 += 24   ///  r2 = r2.wrapping_add(24 as i32 as i64 as u64)
    stxdw [r1+0x8], r2                      
    lddw r3, 0x800000000000001a                     r3 load str located at -9223372036854775782
lbb_17775:
    stxdw [r1+0x0], r3                      
    exit                                    

function_17777:
    lddw r3, 0x800000000000000b                     r3 load str located at -9223372036854775797
    ldxdw r2, [r2+0x10]                     
    ldxdw r4, [r2+0x10]                     
    lddw r5, 0x7ffffffffffffffe                     r5 load str located at 9223372036854775806
    jgt r4, r5, lbb_17793                           if r4 > r5 { pc += 9 }
    mov64 r3, r2                                    r3 = r2
    add64 r3, 16                                    r3 += 16   ///  r3 = r3.wrapping_add(16 as i32 as i64 as u64)
    add64 r4, 1                                     r4 += 1   ///  r4 = r4.wrapping_add(1 as i32 as i64 as u64)
    stxdw [r2+0x10], r4                     
    stxdw [r1+0x10], r3                     
    add64 r2, 24                                    r2 += 24   ///  r2 = r2.wrapping_add(24 as i32 as i64 as u64)
    stxdw [r1+0x8], r2                      
    lddw r3, 0x800000000000001a                     r3 load str located at -9223372036854775782
lbb_17793:
    stxdw [r1+0x0], r3                      
    exit                                    

function_17795:
    lddw r3, 0x800000000000000b                     r3 load str located at -9223372036854775797
    ldxdw r2, [r2+0x10]                     
    ldxdw r4, [r2+0x10]                     
    jne r4, 0, lbb_17809                            if r4 != (0 as i32 as i64 as u64) { pc += 9 }
    mov64 r3, r2                                    r3 = r2
    add64 r3, 16                                    r3 += 16   ///  r3 = r3.wrapping_add(16 as i32 as i64 as u64)
    mov64 r4, -1                                    r4 = -1 as i32 as i64 as u64
    stxdw [r2+0x10], r4                     
    stxdw [r1+0x10], r3                     
    add64 r2, 24                                    r2 += 24   ///  r2 = r2.wrapping_add(24 as i32 as i64 as u64)
    stxdw [r1+0x8], r2                      
    lddw r3, 0x800000000000001a                     r3 load str located at -9223372036854775782
lbb_17809:
    stxdw [r1+0x0], r3                      
    exit                                    

function_17811:
    ldxdw r2, [r1+0x0]                      
    lddw r4, 0x8000000000000000                     r4 load str located at -9223372036854775808
    mov64 r3, r2                                    r3 = r2
    xor64 r3, r4                                    r3 ^= r4   ///  r3 = r3.xor(r4)
    mov64 r5, 26                                    r5 = 26 as i32 as i64 as u64
    mov64 r4, r3                                    r4 = r3
    jgt r5, r3, lbb_17820                           if r5 > r3 { pc += 1 }
    mov64 r4, 14                                    r4 = 14 as i32 as i64 as u64
lbb_17820:
    jsgt r4, 12, lbb_17830                          if (r4 as i64) > (12 as i32 as i64) { pc += 9 }
    jsgt r4, 5, lbb_17837                           if (r4 as i64) > (5 as i32 as i64) { pc += 15 }
    jsgt r4, 2, lbb_17859                           if (r4 as i64) > (2 as i32 as i64) { pc += 36 }
    jeq r4, 0, lbb_17883                            if r4 == (0 as i32 as i64 as u64) { pc += 59 }
    lddw r6, 0x200000000                            r6 load str located at 8589934592
    jeq r4, 1, lbb_17924                            if r4 == (1 as i32 as i64 as u64) { pc += 97 }
    lddw r6, 0x300000000                            r6 load str located at 12884901888
    ja lbb_17924                                    if true { pc += 94 }
lbb_17830:
    jsgt r4, 18, lbb_17843                          if (r4 as i64) > (18 as i32 as i64) { pc += 12 }
    jsgt r4, 15, lbb_17864                          if (r4 as i64) > (15 as i32 as i64) { pc += 32 }
    jeq r4, 13, lbb_17889                           if r4 == (13 as i32 as i64 as u64) { pc += 56 }
    jeq r4, 14, lbb_17916                           if r4 == (14 as i32 as i64 as u64) { pc += 82 }
    lddw r6, 0x1000000000                           r6 load str located at 68719476736
    ja lbb_17924                                    if true { pc += 87 }
lbb_17837:
    jsgt r4, 8, lbb_17849                           if (r4 as i64) > (8 as i32 as i64) { pc += 11 }
    jeq r4, 6, lbb_17877                            if r4 == (6 as i32 as i64 as u64) { pc += 38 }
    jeq r4, 7, lbb_17898                            if r4 == (7 as i32 as i64 as u64) { pc += 58 }
    lddw r6, 0x900000000                            r6 load str located at 38654705664
    ja lbb_17924                                    if true { pc += 81 }
lbb_17843:
    jsgt r4, 21, lbb_17854                          if (r4 as i64) > (21 as i32 as i64) { pc += 10 }
    jeq r4, 19, lbb_17880                           if r4 == (19 as i32 as i64 as u64) { pc += 35 }
    jeq r4, 20, lbb_17901                           if r4 == (20 as i32 as i64 as u64) { pc += 55 }
    lddw r6, 0x1600000000                           r6 load str located at 94489280512
    ja lbb_17924                                    if true { pc += 75 }
lbb_17849:
    jsgt r4, 10, lbb_17869                          if (r4 as i64) > (10 as i32 as i64) { pc += 19 }
    jeq r4, 9, lbb_17904                            if r4 == (9 as i32 as i64 as u64) { pc += 53 }
    lddw r6, 0xb00000000                            r6 load str located at 47244640256
    ja lbb_17924                                    if true { pc += 70 }
lbb_17854:
    jsgt r4, 23, lbb_17873                          if (r4 as i64) > (23 as i32 as i64) { pc += 18 }
    jeq r4, 22, lbb_17907                           if r4 == (22 as i32 as i64 as u64) { pc += 51 }
    lddw r6, 0x1800000000                           r6 load str located at 103079215104
    ja lbb_17924                                    if true { pc += 65 }
lbb_17859:
    jeq r4, 3, lbb_17892                            if r4 == (3 as i32 as i64 as u64) { pc += 32 }
    jeq r4, 4, lbb_17919                            if r4 == (4 as i32 as i64 as u64) { pc += 58 }
    lddw r6, 0x600000000                            r6 load str located at 25769803776
    ja lbb_17924                                    if true { pc += 60 }
lbb_17864:
    jeq r4, 16, lbb_17895                           if r4 == (16 as i32 as i64 as u64) { pc += 30 }
    jeq r4, 17, lbb_17922                           if r4 == (17 as i32 as i64 as u64) { pc += 56 }
    lddw r6, 0x1300000000                           r6 load str located at 81604378624
    ja lbb_17924                                    if true { pc += 55 }
lbb_17869:
    jeq r4, 11, lbb_17910                           if r4 == (11 as i32 as i64 as u64) { pc += 40 }
    lddw r6, 0xd00000000                            r6 load str located at 55834574848
    ja lbb_17924                                    if true { pc += 51 }
lbb_17873:
    jeq r4, 24, lbb_17913                           if r4 == (24 as i32 as i64 as u64) { pc += 39 }
    lddw r6, 0x1a00000000                           r6 load str located at 111669149696
    ja lbb_17924                                    if true { pc += 47 }
lbb_17877:
    lddw r6, 0x700000000                            r6 load str located at 30064771072
    ja lbb_17924                                    if true { pc += 44 }
lbb_17880:
    lddw r6, 0x1400000000                           r6 load str located at 85899345920
    ja lbb_17924                                    if true { pc += 41 }
lbb_17883:
    lddw r6, 0x100000000                            r6 load str located at 4294967296
    ldxw r4, [r1+0x8]                       
    jeq r4, 0, lbb_17924                            if r4 == (0 as i32 as i64 as u64) { pc += 37 }
    mov64 r6, r4                                    r6 = r4
    ja lbb_17924                                    if true { pc += 35 }
lbb_17889:
    lddw r6, 0xe00000000                            r6 load str located at 60129542144
    ja lbb_17924                                    if true { pc += 32 }
lbb_17892:
    lddw r6, 0x400000000                            r6 load str located at 17179869184
    ja lbb_17924                                    if true { pc += 29 }
lbb_17895:
    lddw r6, 0x1100000000                           r6 load str located at 73014444032
    ja lbb_17924                                    if true { pc += 26 }
lbb_17898:
    lddw r6, 0x800000000                            r6 load str located at 34359738368
    ja lbb_17924                                    if true { pc += 23 }
lbb_17901:
    lddw r6, 0x1500000000                           r6 load str located at 90194313216
    ja lbb_17924                                    if true { pc += 20 }
lbb_17904:
    lddw r6, 0xa00000000                            r6 load str located at 42949672960
    ja lbb_17924                                    if true { pc += 17 }
lbb_17907:
    lddw r6, 0x1700000000                           r6 load str located at 98784247808
    ja lbb_17924                                    if true { pc += 14 }
lbb_17910:
    lddw r6, 0xc00000000                            r6 load str located at 51539607552
    ja lbb_17924                                    if true { pc += 11 }
lbb_17913:
    lddw r6, 0x1900000000                           r6 load str located at 107374182400
    ja lbb_17924                                    if true { pc += 8 }
lbb_17916:
    lddw r6, 0xf00000000                            r6 load str located at 64424509440
    ja lbb_17924                                    if true { pc += 5 }
lbb_17919:
    lddw r6, 0x500000000                            r6 load str located at 21474836480
    ja lbb_17924                                    if true { pc += 2 }
lbb_17922:
    lddw r6, 0x1200000000                           r6 load str located at 77309411328
lbb_17924:
    mov64 r5, 1                                     r5 = 1 as i32 as i64 as u64
    mov64 r0, 26                                    r0 = 26 as i32 as i64 as u64
    mov64 r4, 1                                     r4 = 1 as i32 as i64 as u64
    jgt r0, r3, lbb_17929                           if r0 > r3 { pc += 1 }
    mov64 r4, 0                                     r4 = 0 as i32 as i64 as u64
lbb_17929:
    jne r3, 14, lbb_17931                           if r3 != (14 as i32 as i64 as u64) { pc += 1 }
    mov64 r5, 0                                     r5 = 0 as i32 as i64 as u64
lbb_17931:
    jeq r2, 0, lbb_17938                            if r2 == (0 as i32 as i64 as u64) { pc += 6 }
    and64 r4, r5                                    r4 &= r5   ///  r4 = r4.and(r5)
    and64 r4, 1                                     r4 &= 1   ///  r4 = r4.and(1)
    jne r4, 0, lbb_17938                            if r4 != (0 as i32 as i64 as u64) { pc += 3 }
    ldxdw r1, [r1+0x8]                      
    mov64 r3, 1                                     r3 = 1 as i32 as i64 as u64
    call function_14411                     
lbb_17938:
    mov64 r0, r6                                    r0 = r6
    exit                                    

function_17940:
    lddw r4, 0xffffffff00000000                     r4 load str located at -4294967296
    mov64 r3, r2                                    r3 = r2
    add64 r3, r4                                    r3 += r4   ///  r3 = r3.wrapping_add(r4)
    mov64 r4, r3                                    r4 = r3
    rsh64 r4, 32                                    r4 >>= 32   ///  r4 = r4.wrapping_shr(32)
    lsh64 r3, 32                                    r3 <<= 32   ///  r3 = r3.wrapping_shl(32)
    or64 r3, r4                                     r3 |= r4   ///  r3 = r3.or(r4)
    jsgt r3, 12, lbb_17958                          if (r3 as i64) > (12 as i32 as i64) { pc += 9 }
    jsgt r3, 5, lbb_17967                           if (r3 as i64) > (5 as i32 as i64) { pc += 17 }
    jsgt r3, 2, lbb_17997                           if (r3 as i64) > (2 as i32 as i64) { pc += 46 }
    jeq r3, 0, lbb_18045                            if r3 == (0 as i32 as i64 as u64) { pc += 93 }
    jeq r3, 1, lbb_18066                            if r3 == (1 as i32 as i64 as u64) { pc += 113 }
    jeq r3, 2, lbb_17955                            if r3 == (2 as i32 as i64 as u64) { pc += 1 }
    ja lbb_18019                                    if true { pc += 64 }
lbb_17955:
    lddw r2, 0x8000000000000002                     r2 load str located at -9223372036854775806
    ja lbb_18083                                    if true { pc += 125 }
lbb_17958:
    jsgt r3, 18, lbb_17975                          if (r3 as i64) > (18 as i32 as i64) { pc += 16 }
    jsgt r3, 15, lbb_18004                          if (r3 as i64) > (15 as i32 as i64) { pc += 44 }
    jeq r3, 13, lbb_18051                           if r3 == (13 as i32 as i64 as u64) { pc += 90 }
    jeq r3, 14, lbb_18069                           if r3 == (14 as i32 as i64 as u64) { pc += 107 }
    jeq r3, 15, lbb_17964                           if r3 == (15 as i32 as i64 as u64) { pc += 1 }
    ja lbb_18019                                    if true { pc += 55 }
lbb_17964:
    lddw r2, 0x800000000000000f                     r2 load str located at -9223372036854775793
    ja lbb_18083                                    if true { pc += 116 }
lbb_17967:
    jsgt r3, 8, lbb_17983                           if (r3 as i64) > (8 as i32 as i64) { pc += 15 }
    jeq r3, 6, lbb_18039                            if r3 == (6 as i32 as i64 as u64) { pc += 70 }
    jeq r3, 7, lbb_18060                            if r3 == (7 as i32 as i64 as u64) { pc += 90 }
    jeq r3, 8, lbb_17972                            if r3 == (8 as i32 as i64 as u64) { pc += 1 }
    ja lbb_18019                                    if true { pc += 47 }
lbb_17972:
    lddw r2, 0x8000000000000008                     r2 load str located at -9223372036854775800
    ja lbb_18083                                    if true { pc += 108 }
lbb_17975:
    jsgt r3, 21, lbb_17990                          if (r3 as i64) > (21 as i32 as i64) { pc += 14 }
    jeq r3, 19, lbb_18042                           if r3 == (19 as i32 as i64 as u64) { pc += 65 }
    jeq r3, 20, lbb_18063                           if r3 == (20 as i32 as i64 as u64) { pc += 85 }
    jeq r3, 21, lbb_17980                           if r3 == (21 as i32 as i64 as u64) { pc += 1 }
    ja lbb_18019                                    if true { pc += 39 }
lbb_17980:
    lddw r2, 0x8000000000000015                     r2 load str located at -9223372036854775787
    ja lbb_18083                                    if true { pc += 100 }
lbb_17983:
    jsgt r3, 10, lbb_18011                          if (r3 as i64) > (10 as i32 as i64) { pc += 27 }
    jeq r3, 9, lbb_18024                            if r3 == (9 as i32 as i64 as u64) { pc += 39 }
    jeq r3, 10, lbb_17987                           if r3 == (10 as i32 as i64 as u64) { pc += 1 }
    ja lbb_18019                                    if true { pc += 32 }
lbb_17987:
    lddw r2, 0x800000000000000a                     r2 load str located at -9223372036854775798
    ja lbb_18083                                    if true { pc += 93 }
lbb_17990:
    jsgt r3, 23, lbb_18017                          if (r3 as i64) > (23 as i32 as i64) { pc += 26 }
    jeq r3, 22, lbb_18027                           if r3 == (22 as i32 as i64 as u64) { pc += 35 }
    jeq r3, 23, lbb_17994                           if r3 == (23 as i32 as i64 as u64) { pc += 1 }
    ja lbb_18019                                    if true { pc += 25 }
lbb_17994:
    lddw r2, 0x8000000000000017                     r2 load str located at -9223372036854775785
    ja lbb_18083                                    if true { pc += 86 }
lbb_17997:
    jeq r3, 3, lbb_18054                            if r3 == (3 as i32 as i64 as u64) { pc += 56 }
    jeq r3, 4, lbb_18078                            if r3 == (4 as i32 as i64 as u64) { pc += 79 }
    jeq r3, 5, lbb_18001                            if r3 == (5 as i32 as i64 as u64) { pc += 1 }
    ja lbb_18019                                    if true { pc += 18 }
lbb_18001:
    lddw r2, 0x8000000000000005                     r2 load str located at -9223372036854775803
    ja lbb_18083                                    if true { pc += 79 }
lbb_18004:
    jeq r3, 16, lbb_18057                           if r3 == (16 as i32 as i64 as u64) { pc += 52 }
    jeq r3, 17, lbb_18081                           if r3 == (17 as i32 as i64 as u64) { pc += 75 }
    jeq r3, 18, lbb_18008                           if r3 == (18 as i32 as i64 as u64) { pc += 1 }
    ja lbb_18019                                    if true { pc += 11 }
lbb_18008:
    lddw r2, 0x8000000000000012                     r2 load str located at -9223372036854775790
    ja lbb_18083                                    if true { pc += 72 }
lbb_18011:
    jeq r3, 11, lbb_18030                           if r3 == (11 as i32 as i64 as u64) { pc += 18 }
    jeq r3, 12, lbb_18014                           if r3 == (12 as i32 as i64 as u64) { pc += 1 }
    ja lbb_18019                                    if true { pc += 5 }
lbb_18014:
    lddw r2, 0x800000000000000c                     r2 load str located at -9223372036854775796
    ja lbb_18083                                    if true { pc += 66 }
lbb_18017:
    jeq r3, 24, lbb_18033                           if r3 == (24 as i32 as i64 as u64) { pc += 15 }
    jeq r3, 25, lbb_18036                           if r3 == (25 as i32 as i64 as u64) { pc += 17 }
lbb_18019:
    lddw r3, 0x8000000000000000                     r3 load str located at -9223372036854775808
    stxdw [r1+0x0], r3                      
    stxw [r1+0x8], r2                       
    ja lbb_18084                                    if true { pc += 60 }
lbb_18024:
    lddw r2, 0x8000000000000009                     r2 load str located at -9223372036854775799
    ja lbb_18083                                    if true { pc += 56 }
lbb_18027:
    lddw r2, 0x8000000000000016                     r2 load str located at -9223372036854775786
    ja lbb_18083                                    if true { pc += 53 }
lbb_18030:
    lddw r2, 0x800000000000000b                     r2 load str located at -9223372036854775797
    ja lbb_18083                                    if true { pc += 50 }
lbb_18033:
    lddw r2, 0x8000000000000018                     r2 load str located at -9223372036854775784
    ja lbb_18083                                    if true { pc += 47 }
lbb_18036:
    lddw r2, 0x8000000000000019                     r2 load str located at -9223372036854775783
    ja lbb_18083                                    if true { pc += 44 }
lbb_18039:
    lddw r2, 0x8000000000000006                     r2 load str located at -9223372036854775802
    ja lbb_18083                                    if true { pc += 41 }
lbb_18042:
    lddw r2, 0x8000000000000013                     r2 load str located at -9223372036854775789
    ja lbb_18083                                    if true { pc += 38 }
lbb_18045:
    lddw r2, 0x8000000000000000                     r2 load str located at -9223372036854775808
    stxdw [r1+0x0], r2                      
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
    stxw [r1+0x8], r2                       
    ja lbb_18084                                    if true { pc += 33 }
lbb_18051:
    lddw r2, 0x800000000000000d                     r2 load str located at -9223372036854775795
    ja lbb_18083                                    if true { pc += 29 }
lbb_18054:
    lddw r2, 0x8000000000000003                     r2 load str located at -9223372036854775805
    ja lbb_18083                                    if true { pc += 26 }
lbb_18057:
    lddw r2, 0x8000000000000010                     r2 load str located at -9223372036854775792
    ja lbb_18083                                    if true { pc += 23 }
lbb_18060:
    lddw r2, 0x8000000000000007                     r2 load str located at -9223372036854775801
    ja lbb_18083                                    if true { pc += 20 }
lbb_18063:
    lddw r2, 0x8000000000000014                     r2 load str located at -9223372036854775788
    ja lbb_18083                                    if true { pc += 17 }
lbb_18066:
    lddw r2, 0x8000000000000001                     r2 load str located at -9223372036854775807
    ja lbb_18083                                    if true { pc += 14 }
lbb_18069:
    mov64 r7, r1                                    r7 = r1
    mov64 r6, 7                                     r6 = 7 as i32 as i64 as u64
    mov64 r1, 7                                     r1 = 7 as i32 as i64 as u64
    mov64 r2, 1                                     r2 = 1 as i32 as i64 as u64
    call function_14385                     
    jne r0, 0, lbb_18085                            if r0 != (0 as i32 as i64 as u64) { pc += 10 }
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    mov64 r2, 7                                     r2 = 7 as i32 as i64 as u64
    call function_21549                     
lbb_18078:
    lddw r2, 0x8000000000000004                     r2 load str located at -9223372036854775804
    ja lbb_18083                                    if true { pc += 2 }
lbb_18081:
    lddw r2, 0x8000000000000011                     r2 load str located at -9223372036854775791
lbb_18083:
    stxdw [r1+0x0], r2                      
lbb_18084:
    exit                                    
lbb_18085:
    mov64 r1, 1853321070                            r1 = 1853321070 as i32 as i64 as u64
    stxw [r0+0x3], r1                       
    mov64 r1, 1852534357                            r1 = 1852534357 as i32 as i64 as u64
    stxw [r0+0x0], r1                       
    stxdw [r7+0x8], r0                      
    stxdw [r7+0x10], r6                     
    stxdw [r7+0x0], r6                      
    ja lbb_18084                                    if true { pc += -9 }

function_18093:
    stxdw [r10-0x48], r2                    
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
    stxdw [r10-0x20], r2                    
    lddw r2, 0x10003e790 --> b"\x01\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00Permissio…        r2 load str located at 4295223184
    stxdw [r10-0x40], r2                    
    mov64 r2, 1                                     r2 = 1 as i32 as i64 as u64
    stxdw [r10-0x38], r2                    
    stxdw [r10-0x28], r2                    
    mov64 r2, r10                                   r2 = r10
    add64 r2, -16                                   r2 += -16   ///  r2 = r2.wrapping_add(-16 as i32 as i64 as u64)
    stxdw [r10-0x30], r2                    
    lddw r2, 0x100029358 --> b"\xbf&\x00\x00\x00\x00\x00\x00y\x11\x00\x00\x00\x00\x00\x00\xbf\x12\x00\x0…        r2 load str located at 4295136088
    stxdw [r10-0x8], r2                     
    mov64 r2, r10                                   r2 = r10
    add64 r2, -72                                   r2 += -72   ///  r2 = r2.wrapping_add(-72 as i32 as i64 as u64)
    stxdw [r10-0x10], r2                    
    mov64 r2, r10                                   r2 = r10
    add64 r2, -64                                   r2 += -64   ///  r2 = r2.wrapping_add(-64 as i32 as i64 as u64)
    call function_21571                     
    ldxdw r6, [r10-0x48]                    
    mov64 r1, r6                                    r1 = r6
    and64 r1, 3                                     r1 &= 3   ///  r1 = r1.and(3)
    mov64 r2, r1                                    r2 = r1
    add64 r2, -2                                    r2 += -2   ///  r2 = r2.wrapping_add(-2 as i32 as i64 as u64)
    mov64 r3, 2                                     r3 = 2 as i32 as i64 as u64
    jgt r3, r2, lbb_18137                           if r3 > r2 { pc += 16 }
    jeq r1, 0, lbb_18137                            if r1 == (0 as i32 as i64 as u64) { pc += 15 }
    ldxdw r7, [r6-0x1]                      
    ldxdw r8, [r6+0x7]                      
    ldxdw r2, [r8+0x0]                      
    mov64 r1, r7                                    r1 = r7
    callx r2                                
    add64 r6, -1                                    r6 += -1   ///  r6 = r6.wrapping_add(-1 as i32 as i64 as u64)
    ldxdw r2, [r8+0x8]                      
    jeq r2, 0, lbb_18133                            if r2 == (0 as i32 as i64 as u64) { pc += 3 }
    ldxdw r3, [r8+0x10]                     
    mov64 r1, r7                                    r1 = r7
    call function_14411                     
lbb_18133:
    mov64 r1, r6                                    r1 = r6
    mov64 r2, 24                                    r2 = 24 as i32 as i64 as u64
    mov64 r3, 8                                     r3 = 8 as i32 as i64 as u64
    call function_14411                     
lbb_18137:
    exit                                    

function_18138:
    mov64 r9, r1                                    r9 = r1
    ldxdw r6, [r3+0x0]                      
    lddw r1, 0x8000000000000000                     r1 load str located at -9223372036854775808
    xor64 r6, r1                                    r6 ^= r1   ///  r6 = r6.xor(r1)
    mov64 r1, 13                                    r1 = 13 as i32 as i64 as u64
    jgt r1, r6, lbb_18146                           if r1 > r6 { pc += 1 }
    mov64 r6, 3                                     r6 = 3 as i32 as i64 as u64
lbb_18146:
    stxdw [r10-0x20], r3                    
    stxdw [r10-0x28], r4                    
    stxdw [r10-0x30], r2                    
    jsgt r6, 5, lbb_18156                           if (r6 as i64) > (5 as i32 as i64) { pc += 6 }
    jsgt r6, 2, lbb_18166                           if (r6 as i64) > (2 as i32 as i64) { pc += 15 }
    mov64 r7, 52                                    r7 = 52 as i32 as i64 as u64
    jeq r6, 0, lbb_18186                            if r6 == (0 as i32 as i64 as u64) { pc += 33 }
    jeq r6, 1, lbb_18164                            if r6 == (1 as i32 as i64 as u64) { pc += 10 }
lbb_18154:
    mov64 r7, 12                                    r7 = 12 as i32 as i64 as u64
    ja lbb_18186                                    if true { pc += 30 }
lbb_18156:
    jsgt r6, 8, lbb_18160                           if (r6 as i64) > (8 as i32 as i64) { pc += 3 }
    jeq r6, 6, lbb_18164                            if r6 == (6 as i32 as i64 as u64) { pc += 6 }
    jeq r6, 7, lbb_18164                            if r6 == (7 as i32 as i64 as u64) { pc += 5 }
    ja lbb_18154                                    if true { pc += -6 }
lbb_18160:
    jsgt r6, 10, lbb_18171                          if (r6 as i64) > (10 as i32 as i64) { pc += 10 }
    jeq r6, 9, lbb_18174                            if r6 == (9 as i32 as i64 as u64) { pc += 12 }
    mov64 r1, 76                                    r1 = 76 as i32 as i64 as u64
    ja lbb_18177                                    if true { pc += 13 }
lbb_18164:
    mov64 r7, 36                                    r7 = 36 as i32 as i64 as u64
    ja lbb_18186                                    if true { pc += 20 }
lbb_18166:
    mov64 r1, 92                                    r1 = 92 as i32 as i64 as u64
    mov64 r5, 16                                    r5 = 16 as i32 as i64 as u64
    jeq r6, 3, lbb_18178                            if r6 == (3 as i32 as i64 as u64) { pc += 9 }
    jeq r6, 4, lbb_18172                            if r6 == (4 as i32 as i64 as u64) { pc += 2 }
    ja lbb_18154                                    if true { pc += -17 }
lbb_18171:
    jeq r6, 11, lbb_18176                           if r6 == (11 as i32 as i64 as u64) { pc += 4 }
lbb_18172:
    mov64 r7, 4                                     r7 = 4 as i32 as i64 as u64
    ja lbb_18186                                    if true { pc += 12 }
lbb_18174:
    mov64 r1, 84                                    r1 = 84 as i32 as i64 as u64
    ja lbb_18177                                    if true { pc += 1 }
lbb_18176:
    mov64 r1, 52                                    r1 = 52 as i32 as i64 as u64
lbb_18177:
    mov64 r5, 24                                    r5 = 24 as i32 as i64 as u64
lbb_18178:
    add64 r3, r5                                    r3 += r5   ///  r3 = r3.wrapping_add(r5)
    ldxdw r7, [r3+0x0]                      
    add64 r7, r1                                    r7 += r1   ///  r7 = r7.wrapping_add(r1)
    mov64 r0, 1                                     r0 = 1 as i32 as i64 as u64
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    jeq r7, 0, lbb_18192                            if r7 == (0 as i32 as i64 as u64) { pc += 8 }
    mov64 r8, 0                                     r8 = 0 as i32 as i64 as u64
    jsgt r8, r7, lbb_18962                          if (r8 as i64) > (r7 as i64) { pc += 776 }
lbb_18186:
    mov64 r8, 1                                     r8 = 1 as i32 as i64 as u64
    mov64 r1, r7                                    r1 = r7
    mov64 r2, 1                                     r2 = 1 as i32 as i64 as u64
    call function_14385                     
    jeq r0, 0, lbb_18962                            if r0 == (0 as i32 as i64 as u64) { pc += 771 }
    mov64 r1, r7                                    r1 = r7
lbb_18192:
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
    stxdw [r10-0x8], r2                     
    stxdw [r10-0x10], r0                    
    stxdw [r10-0x18], r1                    
    jsgt r6, 5, lbb_18229                           if (r6 as i64) > (5 as i32 as i64) { pc += 32 }
    jsgt r6, 2, lbb_18301                           if (r6 as i64) > (2 as i32 as i64) { pc += 103 }
    jeq r6, 0, lbb_18368                            if r6 == (0 as i32 as i64 as u64) { pc += 169 }
    jeq r6, 1, lbb_18854                            if r6 == (1 as i32 as i64 as u64) { pc += 654 }
    mov64 r7, 0                                     r7 = 0 as i32 as i64 as u64
    jgt r1, 3, lbb_18208                            if r1 > (3 as i32 as i64 as u64) { pc += 6 }
    mov64 r1, r10                                   r1 = r10
    add64 r1, -24                                   r1 += -24   ///  r1 = r1.wrapping_add(-24 as i32 as i64 as u64)
    mov64 r3, 4                                     r3 = 4 as i32 as i64 as u64
    call function_19168                     
    ldxdw r0, [r10-0x10]                    
    ldxdw r7, [r10-0x8]                     
lbb_18208:
    add64 r0, r7                                    r0 += r7   ///  r0 = r0.wrapping_add(r7)
    mov64 r1, 2                                     r1 = 2 as i32 as i64 as u64
    stxw [r0+0x0], r1                       
    add64 r7, 4                                     r7 += 4   ///  r7 = r7.wrapping_add(4 as i32 as i64 as u64)
    stxdw [r10-0x8], r7                     
    ldxdw r1, [r10-0x18]                    
    sub64 r1, r7                                    r1 -= r7   ///  r1 = r1.wrapping_sub(r7)
    ldxdw r2, [r10-0x20]                    
    ldxdw r6, [r2+0x8]                      
    jgt r1, 7, lbb_18224                            if r1 > (7 as i32 as i64 as u64) { pc += 6 }
lbb_18218:
    mov64 r1, r10                                   r1 = r10
    add64 r1, -24                                   r1 += -24   ///  r1 = r1.wrapping_add(-24 as i32 as i64 as u64)
    mov64 r2, r7                                    r2 = r7
    mov64 r3, 8                                     r3 = 8 as i32 as i64 as u64
    call function_19168                     
    ldxdw r7, [r10-0x8]                     
lbb_18224:
    ldxdw r1, [r10-0x10]                    
    add64 r1, r7                                    r1 += r7   ///  r1 = r1.wrapping_add(r7)
    stxdw [r1+0x0], r6                      
    add64 r7, 8                                     r7 += 8   ///  r7 = r7.wrapping_add(8 as i32 as i64 as u64)
    ja lbb_18904                                    if true { pc += 675 }
lbb_18229:
    jsgt r6, 8, lbb_18251                           if (r6 as i64) > (8 as i32 as i64) { pc += 21 }
    jeq r6, 6, lbb_18330                            if r6 == (6 as i32 as i64 as u64) { pc += 99 }
    jeq r6, 7, lbb_18574                            if r6 == (7 as i32 as i64 as u64) { pc += 342 }
    mov64 r7, 0                                     r7 = 0 as i32 as i64 as u64
    jgt r1, 3, lbb_18240                            if r1 > (3 as i32 as i64 as u64) { pc += 6 }
    mov64 r1, r10                                   r1 = r10
    add64 r1, -24                                   r1 += -24   ///  r1 = r1.wrapping_add(-24 as i32 as i64 as u64)
    mov64 r3, 4                                     r3 = 4 as i32 as i64 as u64
    call function_19168                     
    ldxdw r0, [r10-0x10]                    
    ldxdw r7, [r10-0x8]                     
lbb_18240:
    add64 r0, r7                                    r0 += r7   ///  r0 = r0.wrapping_add(r7)
    mov64 r1, 8                                     r1 = 8 as i32 as i64 as u64
    stxw [r0+0x0], r1                       
    add64 r7, 4                                     r7 += 4   ///  r7 = r7.wrapping_add(4 as i32 as i64 as u64)
    stxdw [r10-0x8], r7                     
    ldxdw r1, [r10-0x18]                    
    sub64 r1, r7                                    r1 -= r7   ///  r1 = r1.wrapping_sub(r7)
    ldxdw r2, [r10-0x20]                    
    ldxdw r6, [r2+0x8]                      
    jgt r1, 7, lbb_18224                            if r1 > (7 as i32 as i64 as u64) { pc += -26 }
    ja lbb_18218                                    if true { pc += -33 }
lbb_18251:
    jsgt r6, 10, lbb_18323                          if (r6 as i64) > (10 as i32 as i64) { pc += 71 }
    stxdw [r10-0x38], r9                    
    jeq r6, 9, lbb_18612                            if r6 == (9 as i32 as i64 as u64) { pc += 358 }
    mov64 r6, 0                                     r6 = 0 as i32 as i64 as u64
    mov64 r7, 0                                     r7 = 0 as i32 as i64 as u64
    jgt r1, 3, lbb_18258                            if r1 > (3 as i32 as i64 as u64) { pc += 1 }
    ja lbb_18929                                    if true { pc += 671 }
lbb_18258:
    add64 r0, r7                                    r0 += r7   ///  r0 = r0.wrapping_add(r7)
    mov64 r1, 10                                    r1 = 10 as i32 as i64 as u64
    stxw [r0+0x0], r1                       
    ldxdw r2, [r10-0x20]                    
    mov64 r8, r2                                    r8 = r2
    add64 r8, 32                                    r8 += 32   ///  r8 = r8.wrapping_add(32 as i32 as i64 as u64)
    add64 r7, 4                                     r7 += 4   ///  r7 = r7.wrapping_add(4 as i32 as i64 as u64)
    stxdw [r10-0x8], r7                     
    ja lbb_18288                                    if true { pc += 21 }
lbb_18267:
    add64 r6, 1                                     r6 += 1   ///  r6 = r6.wrapping_add(1 as i32 as i64 as u64)
    ldxdw r1, [r10-0x10]                    
    add64 r1, r7                                    r1 += r7   ///  r1 = r1.wrapping_add(r7)
    stxb [r1+0x0], r9                       
    add64 r7, 1                                     r7 += 1   ///  r7 = r7.wrapping_add(1 as i32 as i64 as u64)
    stxdw [r10-0x8], r7                     
    jne r6, 32, lbb_18288                           if r6 != (32 as i32 as i64 as u64) { pc += 14 }
    ldxdw r1, [r10-0x18]                    
    sub64 r1, r7                                    r1 -= r7   ///  r1 = r1.wrapping_sub(r7)
    ldxdw r8, [r2+0x18]                     
    ldxdw r2, [r2+0x10]                     
    jgt r1, 7, lbb_18664                            if r1 > (7 as i32 as i64 as u64) { pc += 385 }
    mov64 r1, r10                                   r1 = r10
    add64 r1, -24                                   r1 += -24   ///  r1 = r1.wrapping_add(-24 as i32 as i64 as u64)
    mov64 r6, r2                                    r6 = r2
    mov64 r2, r7                                    r2 = r7
    mov64 r3, 8                                     r3 = 8 as i32 as i64 as u64
    call function_19168                     
    mov64 r2, r6                                    r2 = r6
    ldxdw r7, [r10-0x8]                     
    ja lbb_18664                                    if true { pc += 376 }
lbb_18288:
    mov64 r1, r8                                    r1 = r8
    add64 r1, r6                                    r1 += r6   ///  r1 = r1.wrapping_add(r6)
    ldxb r9, [r1+0x0]                       
    ldxdw r1, [r10-0x18]                    
    jne r1, r7, lbb_18267                           if r1 != r7 { pc += -26 }
    mov64 r1, r10                                   r1 = r10
    add64 r1, -24                                   r1 += -24   ///  r1 = r1.wrapping_add(-24 as i32 as i64 as u64)
    mov64 r2, r7                                    r2 = r7
    mov64 r3, 1                                     r3 = 1 as i32 as i64 as u64
    call function_19168                     
    ldxdw r2, [r10-0x20]                    
    ldxdw r7, [r10-0x8]                     
    ja lbb_18267                                    if true { pc += -34 }
lbb_18301:
    jeq r6, 3, lbb_18438                            if r6 == (3 as i32 as i64 as u64) { pc += 136 }
    jeq r6, 4, lbb_18892                            if r6 == (4 as i32 as i64 as u64) { pc += 589 }
    mov64 r7, 0                                     r7 = 0 as i32 as i64 as u64
    ldxdw r2, [r10-0x20]                    
    ldxdw r6, [r2+0x8]                      
    jgt r1, 3, lbb_18314                            if r1 > (3 as i32 as i64 as u64) { pc += 7 }
    mov64 r1, r10                                   r1 = r10
    add64 r1, -24                                   r1 += -24   ///  r1 = r1.wrapping_add(-24 as i32 as i64 as u64)
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
    mov64 r3, 4                                     r3 = 4 as i32 as i64 as u64
    call function_19168                     
    ldxdw r0, [r10-0x10]                    
    ldxdw r7, [r10-0x8]                     
lbb_18314:
    add64 r0, r7                                    r0 += r7   ///  r0 = r0.wrapping_add(r7)
    mov64 r1, 5                                     r1 = 5 as i32 as i64 as u64
    stxw [r0+0x0], r1                       
    add64 r7, 4                                     r7 += 4   ///  r7 = r7.wrapping_add(4 as i32 as i64 as u64)
    stxdw [r10-0x8], r7                     
    ldxdw r1, [r10-0x18]                    
    sub64 r1, r7                                    r1 -= r7   ///  r1 = r1.wrapping_sub(r7)
    jgt r1, 7, lbb_18224                            if r1 > (7 as i32 as i64 as u64) { pc += -98 }
    ja lbb_18218                                    if true { pc += -105 }
lbb_18323:
    jeq r6, 11, lbb_18705                           if r6 == (11 as i32 as i64 as u64) { pc += 381 }
    mov64 r7, 0                                     r7 = 0 as i32 as i64 as u64
    jgt r1, 3, lbb_18327                            if r1 > (3 as i32 as i64 as u64) { pc += 1 }
    ja lbb_18936                                    if true { pc += 609 }
lbb_18327:
    add64 r0, r7                                    r0 += r7   ///  r0 = r0.wrapping_add(r7)
    mov64 r1, 12                                    r1 = 12 as i32 as i64 as u64
    ja lbb_18902                                    if true { pc += 572 }
lbb_18330:
    mov64 r6, 0                                     r6 = 0 as i32 as i64 as u64
    mov64 r7, 0                                     r7 = 0 as i32 as i64 as u64
    jgt r1, 3, lbb_18339                            if r1 > (3 as i32 as i64 as u64) { pc += 6 }
    mov64 r1, r10                                   r1 = r10
    add64 r1, -24                                   r1 += -24   ///  r1 = r1.wrapping_add(-24 as i32 as i64 as u64)
    mov64 r3, 4                                     r3 = 4 as i32 as i64 as u64
    call function_19168                     
    ldxdw r0, [r10-0x10]                    
    ldxdw r7, [r10-0x8]                     
lbb_18339:
    ldxdw r4, [r10-0x20]                    
    add64 r4, 8                                     r4 += 8   ///  r4 = r4.wrapping_add(8 as i32 as i64 as u64)
    add64 r0, r7                                    r0 += r7   ///  r0 = r0.wrapping_add(r7)
    mov64 r1, 6                                     r1 = 6 as i32 as i64 as u64
    stxw [r0+0x0], r1                       
    add64 r7, 4                                     r7 += 4   ///  r7 = r7.wrapping_add(4 as i32 as i64 as u64)
    stxdw [r10-0x8], r7                     
    ja lbb_18354                                    if true { pc += 7 }
lbb_18347:
    add64 r6, 1                                     r6 += 1   ///  r6 = r6.wrapping_add(1 as i32 as i64 as u64)
    ldxdw r1, [r10-0x10]                    
    add64 r1, r7                                    r1 += r7   ///  r1 = r1.wrapping_add(r7)
    stxb [r1+0x0], r8                       
    add64 r7, 1                                     r7 += 1   ///  r7 = r7.wrapping_add(1 as i32 as i64 as u64)
    stxdw [r10-0x8], r7                     
    jeq r6, 32, lbb_18904                           if r6 == (32 as i32 as i64 as u64) { pc += 550 }
lbb_18354:
    mov64 r1, r4                                    r1 = r4
    add64 r1, r6                                    r1 += r6   ///  r1 = r1.wrapping_add(r6)
    ldxb r8, [r1+0x0]                       
    ldxdw r1, [r10-0x18]                    
    jne r1, r7, lbb_18347                           if r1 != r7 { pc += -12 }
    mov64 r1, r10                                   r1 = r10
    add64 r1, -24                                   r1 += -24   ///  r1 = r1.wrapping_add(-24 as i32 as i64 as u64)
    mov64 r2, r7                                    r2 = r7
    mov64 r3, 1                                     r3 = 1 as i32 as i64 as u64
    mov64 r7, r4                                    r7 = r4
    call function_19168                     
    mov64 r4, r7                                    r4 = r7
    ldxdw r7, [r10-0x8]                     
    ja lbb_18347                                    if true { pc += -21 }
lbb_18368:
    mov64 r6, 0                                     r6 = 0 as i32 as i64 as u64
    mov64 r7, 0                                     r7 = 0 as i32 as i64 as u64
    jgt r1, 3, lbb_18377                            if r1 > (3 as i32 as i64 as u64) { pc += 6 }
    mov64 r1, r10                                   r1 = r10
    add64 r1, -24                                   r1 += -24   ///  r1 = r1.wrapping_add(-24 as i32 as i64 as u64)
    mov64 r3, 4                                     r3 = 4 as i32 as i64 as u64
    call function_19168                     
    ldxdw r0, [r10-0x10]                    
    ldxdw r7, [r10-0x8]                     
lbb_18377:
    add64 r0, r7                                    r0 += r7   ///  r0 = r0.wrapping_add(r7)
    stxw [r0+0x0], r6                       
    add64 r7, 4                                     r7 += 4   ///  r7 = r7.wrapping_add(4 as i32 as i64 as u64)
    stxdw [r10-0x8], r7                     
    ldxdw r1, [r10-0x18]                    
    sub64 r1, r7                                    r1 -= r7   ///  r1 = r1.wrapping_sub(r7)
    ldxdw r4, [r10-0x20]                    
    ldxdw r6, [r4+0x28]                     
    jgt r1, 7, lbb_18393                            if r1 > (7 as i32 as i64 as u64) { pc += 7 }
    mov64 r1, r10                                   r1 = r10
    add64 r1, -24                                   r1 += -24   ///  r1 = r1.wrapping_add(-24 as i32 as i64 as u64)
    mov64 r2, r7                                    r2 = r7
    mov64 r3, 8                                     r3 = 8 as i32 as i64 as u64
    call function_19168                     
    ldxdw r4, [r10-0x20]                    
    ldxdw r7, [r10-0x8]                     
lbb_18393:
    ldxdw r1, [r10-0x10]                    
    add64 r1, r7                                    r1 += r7   ///  r1 = r1.wrapping_add(r7)
    stxdw [r1+0x0], r6                      
    add64 r7, 8                                     r7 += 8   ///  r7 = r7.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x8], r7                     
    ldxdw r1, [r10-0x18]                    
    sub64 r1, r7                                    r1 -= r7   ///  r1 = r1.wrapping_sub(r7)
    ldxdw r6, [r4+0x30]                     
    jgt r1, 7, lbb_18409                            if r1 > (7 as i32 as i64 as u64) { pc += 7 }
    mov64 r1, r10                                   r1 = r10
    add64 r1, -24                                   r1 += -24   ///  r1 = r1.wrapping_add(-24 as i32 as i64 as u64)
    mov64 r2, r7                                    r2 = r7
    mov64 r3, 8                                     r3 = 8 as i32 as i64 as u64
    call function_19168                     
    ldxdw r4, [r10-0x20]                    
    ldxdw r7, [r10-0x8]                     
lbb_18409:
    ldxdw r1, [r10-0x10]                    
    add64 r1, r7                                    r1 += r7   ///  r1 = r1.wrapping_add(r7)
    stxdw [r1+0x0], r6                      
    mov64 r6, 0                                     r6 = 0 as i32 as i64 as u64
    add64 r4, 8                                     r4 += 8   ///  r4 = r4.wrapping_add(8 as i32 as i64 as u64)
    add64 r7, 8                                     r7 += 8   ///  r7 = r7.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x8], r7                     
    ja lbb_18424                                    if true { pc += 7 }
lbb_18417:
    add64 r6, 1                                     r6 += 1   ///  r6 = r6.wrapping_add(1 as i32 as i64 as u64)
    ldxdw r1, [r10-0x10]                    
    add64 r1, r7                                    r1 += r7   ///  r1 = r1.wrapping_add(r7)
    stxb [r1+0x0], r8                       
    add64 r7, 1                                     r7 += 1   ///  r7 = r7.wrapping_add(1 as i32 as i64 as u64)
    stxdw [r10-0x8], r7                     
    jeq r6, 32, lbb_18904                           if r6 == (32 as i32 as i64 as u64) { pc += 480 }
lbb_18424:
    mov64 r1, r4                                    r1 = r4
    add64 r1, r6                                    r1 += r6   ///  r1 = r1.wrapping_add(r6)
    ldxb r8, [r1+0x0]                       
    ldxdw r1, [r10-0x18]                    
    jne r1, r7, lbb_18417                           if r1 != r7 { pc += -12 }
    mov64 r1, r10                                   r1 = r10
    add64 r1, -24                                   r1 += -24   ///  r1 = r1.wrapping_add(-24 as i32 as i64 as u64)
    mov64 r2, r7                                    r2 = r7
    mov64 r3, 1                                     r3 = 1 as i32 as i64 as u64
    mov64 r7, r4                                    r7 = r4
    call function_19168                     
    mov64 r4, r7                                    r4 = r7
    ldxdw r7, [r10-0x8]                     
    ja lbb_18417                                    if true { pc += -21 }
lbb_18438:
    stxdw [r10-0x38], r9                    
    mov64 r6, 0                                     r6 = 0 as i32 as i64 as u64
    mov64 r7, 0                                     r7 = 0 as i32 as i64 as u64
    jgt r1, 3, lbb_18448                            if r1 > (3 as i32 as i64 as u64) { pc += 6 }
    mov64 r1, r10                                   r1 = r10
    add64 r1, -24                                   r1 += -24   ///  r1 = r1.wrapping_add(-24 as i32 as i64 as u64)
    mov64 r3, 4                                     r3 = 4 as i32 as i64 as u64
    call function_19168                     
    ldxdw r0, [r10-0x10]                    
    ldxdw r7, [r10-0x8]                     
lbb_18448:
    add64 r0, r7                                    r0 += r7   ///  r0 = r0.wrapping_add(r7)
    mov64 r1, 3                                     r1 = 3 as i32 as i64 as u64
    stxw [r0+0x0], r1                       
    ldxdw r2, [r10-0x20]                    
    mov64 r8, r2                                    r8 = r2
    add64 r8, 24                                    r8 += 24   ///  r8 = r8.wrapping_add(24 as i32 as i64 as u64)
    add64 r7, 4                                     r7 += 4   ///  r7 = r7.wrapping_add(4 as i32 as i64 as u64)
    stxdw [r10-0x8], r7                     
    ja lbb_18478                                    if true { pc += 21 }
lbb_18457:
    add64 r6, 1                                     r6 += 1   ///  r6 = r6.wrapping_add(1 as i32 as i64 as u64)
    ldxdw r1, [r10-0x10]                    
    add64 r1, r7                                    r1 += r7   ///  r1 = r1.wrapping_add(r7)
    stxb [r1+0x0], r9                       
    add64 r7, 1                                     r7 += 1   ///  r7 = r7.wrapping_add(1 as i32 as i64 as u64)
    stxdw [r10-0x8], r7                     
    jne r6, 32, lbb_18478                           if r6 != (32 as i32 as i64 as u64) { pc += 14 }
    ldxdw r1, [r10-0x18]                    
    sub64 r1, r7                                    r1 -= r7   ///  r1 = r1.wrapping_sub(r7)
    ldxdw r6, [r2+0x10]                     
    ldxdw r2, [r2+0x8]                      
    jgt r1, 7, lbb_18491                            if r1 > (7 as i32 as i64 as u64) { pc += 22 }
    mov64 r1, r10                                   r1 = r10
    add64 r1, -24                                   r1 += -24   ///  r1 = r1.wrapping_add(-24 as i32 as i64 as u64)
    mov64 r8, r2                                    r8 = r2
    mov64 r2, r7                                    r2 = r7
    mov64 r3, 8                                     r3 = 8 as i32 as i64 as u64
    call function_19168                     
    mov64 r2, r8                                    r2 = r8
    ldxdw r7, [r10-0x8]                     
    ja lbb_18491                                    if true { pc += 13 }
lbb_18478:
    mov64 r1, r8                                    r1 = r8
    add64 r1, r6                                    r1 += r6   ///  r1 = r1.wrapping_add(r6)
    ldxb r9, [r1+0x0]                       
    ldxdw r1, [r10-0x18]                    
    jne r1, r7, lbb_18457                           if r1 != r7 { pc += -26 }
    mov64 r1, r10                                   r1 = r10
    add64 r1, -24                                   r1 += -24   ///  r1 = r1.wrapping_add(-24 as i32 as i64 as u64)
    mov64 r2, r7                                    r2 = r7
    mov64 r3, 1                                     r3 = 1 as i32 as i64 as u64
    call function_19168                     
    ldxdw r2, [r10-0x20]                    
    ldxdw r7, [r10-0x8]                     
    ja lbb_18457                                    if true { pc += -34 }
lbb_18491:
    ldxdw r1, [r10-0x10]                    
    add64 r1, r7                                    r1 += r7   ///  r1 = r1.wrapping_add(r7)
    stxdw [r1+0x0], r6                      
    add64 r7, 8                                     r7 += 8   ///  r7 = r7.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x8], r7                     
    ldxdw r8, [r10-0x18]                    
    mov64 r1, r8                                    r1 = r8
    sub64 r1, r7                                    r1 -= r7   ///  r1 = r1.wrapping_sub(r7)
    ldxdw r9, [r10-0x38]                    
    jge r1, r6, lbb_18510                           if r1 >= r6 { pc += 9 }
    mov64 r1, r10                                   r1 = r10
    add64 r1, -24                                   r1 += -24   ///  r1 = r1.wrapping_add(-24 as i32 as i64 as u64)
    mov64 r8, r2                                    r8 = r2
    mov64 r2, r7                                    r2 = r7
    mov64 r3, r6                                    r3 = r6
    call function_19168                     
    mov64 r2, r8                                    r2 = r8
    ldxdw r8, [r10-0x18]                    
    ldxdw r7, [r10-0x8]                     
lbb_18510:
    ldxdw r1, [r10-0x10]                    
    stxdw [r10-0x40], r1                    
    add64 r1, r7                                    r1 += r7   ///  r1 = r1.wrapping_add(r7)
    mov64 r3, r6                                    r3 = r6
    call function_30349                     
    ldxdw r1, [r10-0x40]                    
    add64 r7, r6                                    r7 += r6   ///  r7 = r7.wrapping_add(r6)
    stxdw [r10-0x8], r7                     
    sub64 r8, r7                                    r8 -= r7   ///  r8 = r8.wrapping_sub(r7)
    ldxdw r4, [r10-0x20]                    
    ldxdw r6, [r4+0x38]                     
    jgt r8, 7, lbb_18530                            if r8 > (7 as i32 as i64 as u64) { pc += 8 }
    mov64 r1, r10                                   r1 = r10
    add64 r1, -24                                   r1 += -24   ///  r1 = r1.wrapping_add(-24 as i32 as i64 as u64)
    mov64 r2, r7                                    r2 = r7
    mov64 r3, 8                                     r3 = 8 as i32 as i64 as u64
    call function_19168                     
    ldxdw r4, [r10-0x20]                    
    ldxdw r1, [r10-0x10]                    
    ldxdw r7, [r10-0x8]                     
lbb_18530:
    add64 r1, r7                                    r1 += r7   ///  r1 = r1.wrapping_add(r7)
    stxdw [r1+0x0], r6                      
    add64 r7, 8                                     r7 += 8   ///  r7 = r7.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x8], r7                     
    ldxdw r1, [r10-0x18]                    
    sub64 r1, r7                                    r1 -= r7   ///  r1 = r1.wrapping_sub(r7)
    ldxdw r6, [r4+0x40]                     
    jgt r1, 7, lbb_18545                            if r1 > (7 as i32 as i64 as u64) { pc += 7 }
    mov64 r1, r10                                   r1 = r10
    add64 r1, -24                                   r1 += -24   ///  r1 = r1.wrapping_add(-24 as i32 as i64 as u64)
    mov64 r2, r7                                    r2 = r7
    mov64 r3, 8                                     r3 = 8 as i32 as i64 as u64
    call function_19168                     
    ldxdw r4, [r10-0x20]                    
    ldxdw r7, [r10-0x8]                     
lbb_18545:
    ldxdw r1, [r10-0x10]                    
    add64 r1, r7                                    r1 += r7   ///  r1 = r1.wrapping_add(r7)
    stxdw [r1+0x0], r6                      
    mov64 r6, 0                                     r6 = 0 as i32 as i64 as u64
    add64 r4, 72                                    r4 += 72   ///  r4 = r4.wrapping_add(72 as i32 as i64 as u64)
    add64 r7, 8                                     r7 += 8   ///  r7 = r7.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x8], r7                     
    ja lbb_18560                                    if true { pc += 7 }
lbb_18553:
    add64 r6, 1                                     r6 += 1   ///  r6 = r6.wrapping_add(1 as i32 as i64 as u64)
    ldxdw r1, [r10-0x10]                    
    add64 r1, r7                                    r1 += r7   ///  r1 = r1.wrapping_add(r7)
    stxb [r1+0x0], r8                       
    add64 r7, 1                                     r7 += 1   ///  r7 = r7.wrapping_add(1 as i32 as i64 as u64)
    stxdw [r10-0x8], r7                     
    jeq r6, 32, lbb_18904                           if r6 == (32 as i32 as i64 as u64) { pc += 344 }
lbb_18560:
    mov64 r1, r4                                    r1 = r4
    add64 r1, r6                                    r1 += r6   ///  r1 = r1.wrapping_add(r6)
    ldxb r8, [r1+0x0]                       
    ldxdw r1, [r10-0x18]                    
    jne r1, r7, lbb_18553                           if r1 != r7 { pc += -12 }
    mov64 r1, r10                                   r1 = r10
    add64 r1, -24                                   r1 += -24   ///  r1 = r1.wrapping_add(-24 as i32 as i64 as u64)
    mov64 r2, r7                                    r2 = r7
    mov64 r3, 1                                     r3 = 1 as i32 as i64 as u64
    mov64 r7, r4                                    r7 = r4
    call function_19168                     
    mov64 r4, r7                                    r4 = r7
    ldxdw r7, [r10-0x8]                     
    ja lbb_18553                                    if true { pc += -21 }
lbb_18574:
    mov64 r6, 0                                     r6 = 0 as i32 as i64 as u64
    mov64 r7, 0                                     r7 = 0 as i32 as i64 as u64
    jgt r1, 3, lbb_18583                            if r1 > (3 as i32 as i64 as u64) { pc += 6 }
    mov64 r1, r10                                   r1 = r10
    add64 r1, -24                                   r1 += -24   ///  r1 = r1.wrapping_add(-24 as i32 as i64 as u64)
    mov64 r3, 4                                     r3 = 4 as i32 as i64 as u64
    call function_19168                     
    ldxdw r0, [r10-0x10]                    
    ldxdw r7, [r10-0x8]                     
lbb_18583:
    ldxdw r4, [r10-0x20]                    
    add64 r4, 8                                     r4 += 8   ///  r4 = r4.wrapping_add(8 as i32 as i64 as u64)
    add64 r0, r7                                    r0 += r7   ///  r0 = r0.wrapping_add(r7)
    mov64 r1, 7                                     r1 = 7 as i32 as i64 as u64
    stxw [r0+0x0], r1                       
    add64 r7, 4                                     r7 += 4   ///  r7 = r7.wrapping_add(4 as i32 as i64 as u64)
    stxdw [r10-0x8], r7                     
    ja lbb_18598                                    if true { pc += 7 }
lbb_18591:
    add64 r6, 1                                     r6 += 1   ///  r6 = r6.wrapping_add(1 as i32 as i64 as u64)
    ldxdw r1, [r10-0x10]                    
    add64 r1, r7                                    r1 += r7   ///  r1 = r1.wrapping_add(r7)
    stxb [r1+0x0], r8                       
    add64 r7, 1                                     r7 += 1   ///  r7 = r7.wrapping_add(1 as i32 as i64 as u64)
    stxdw [r10-0x8], r7                     
    jeq r6, 32, lbb_18904                           if r6 == (32 as i32 as i64 as u64) { pc += 306 }
lbb_18598:
    mov64 r1, r4                                    r1 = r4
    add64 r1, r6                                    r1 += r6   ///  r1 = r1.wrapping_add(r6)
    ldxb r8, [r1+0x0]                       
    ldxdw r1, [r10-0x18]                    
    jne r1, r7, lbb_18591                           if r1 != r7 { pc += -12 }
    mov64 r1, r10                                   r1 = r10
    add64 r1, -24                                   r1 += -24   ///  r1 = r1.wrapping_add(-24 as i32 as i64 as u64)
    mov64 r2, r7                                    r2 = r7
    mov64 r3, 1                                     r3 = 1 as i32 as i64 as u64
    mov64 r7, r4                                    r7 = r4
    call function_19168                     
    mov64 r4, r7                                    r4 = r7
    ldxdw r7, [r10-0x8]                     
    ja lbb_18591                                    if true { pc += -21 }
lbb_18612:
    mov64 r6, 0                                     r6 = 0 as i32 as i64 as u64
    mov64 r7, 0                                     r7 = 0 as i32 as i64 as u64
    jgt r1, 3, lbb_18621                            if r1 > (3 as i32 as i64 as u64) { pc += 6 }
    mov64 r1, r10                                   r1 = r10
    add64 r1, -24                                   r1 += -24   ///  r1 = r1.wrapping_add(-24 as i32 as i64 as u64)
    mov64 r3, 4                                     r3 = 4 as i32 as i64 as u64
    call function_19168                     
    ldxdw r0, [r10-0x10]                    
    ldxdw r7, [r10-0x8]                     
lbb_18621:
    add64 r0, r7                                    r0 += r7   ///  r0 = r0.wrapping_add(r7)
    mov64 r1, 9                                     r1 = 9 as i32 as i64 as u64
    stxw [r0+0x0], r1                       
    ldxdw r2, [r10-0x20]                    
    mov64 r8, r2                                    r8 = r2
    add64 r8, 32                                    r8 += 32   ///  r8 = r8.wrapping_add(32 as i32 as i64 as u64)
    add64 r7, 4                                     r7 += 4   ///  r7 = r7.wrapping_add(4 as i32 as i64 as u64)
    stxdw [r10-0x8], r7                     
    ja lbb_18651                                    if true { pc += 21 }
lbb_18630:
    add64 r6, 1                                     r6 += 1   ///  r6 = r6.wrapping_add(1 as i32 as i64 as u64)
    ldxdw r1, [r10-0x10]                    
    add64 r1, r7                                    r1 += r7   ///  r1 = r1.wrapping_add(r7)
    stxb [r1+0x0], r9                       
    add64 r7, 1                                     r7 += 1   ///  r7 = r7.wrapping_add(1 as i32 as i64 as u64)
    stxdw [r10-0x8], r7                     
    jne r6, 32, lbb_18651                           if r6 != (32 as i32 as i64 as u64) { pc += 14 }
    ldxdw r1, [r10-0x18]                    
    sub64 r1, r7                                    r1 -= r7   ///  r1 = r1.wrapping_sub(r7)
    ldxdw r6, [r2+0x18]                     
    ldxdw r2, [r2+0x10]                     
    jgt r1, 7, lbb_18795                            if r1 > (7 as i32 as i64 as u64) { pc += 153 }
    mov64 r1, r10                                   r1 = r10
    add64 r1, -24                                   r1 += -24   ///  r1 = r1.wrapping_add(-24 as i32 as i64 as u64)
    mov64 r8, r2                                    r8 = r2
    mov64 r2, r7                                    r2 = r7
    mov64 r3, 8                                     r3 = 8 as i32 as i64 as u64
    call function_19168                     
    mov64 r2, r8                                    r2 = r8
    ldxdw r7, [r10-0x8]                     
    ja lbb_18795                                    if true { pc += 144 }
lbb_18651:
    mov64 r1, r8                                    r1 = r8
    add64 r1, r6                                    r1 += r6   ///  r1 = r1.wrapping_add(r6)
    ldxb r9, [r1+0x0]                       
    ldxdw r1, [r10-0x18]                    
    jne r1, r7, lbb_18630                           if r1 != r7 { pc += -26 }
    mov64 r1, r10                                   r1 = r10
    add64 r1, -24                                   r1 += -24   ///  r1 = r1.wrapping_add(-24 as i32 as i64 as u64)
    mov64 r2, r7                                    r2 = r7
    mov64 r3, 1                                     r3 = 1 as i32 as i64 as u64
    call function_19168                     
    ldxdw r2, [r10-0x20]                    
    ldxdw r7, [r10-0x8]                     
    ja lbb_18630                                    if true { pc += -34 }
lbb_18664:
    ldxdw r1, [r10-0x10]                    
    add64 r1, r7                                    r1 += r7   ///  r1 = r1.wrapping_add(r7)
    stxdw [r1+0x0], r8                      
    add64 r7, 8                                     r7 += 8   ///  r7 = r7.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x8], r7                     
    ldxdw r1, [r10-0x18]                    
    sub64 r1, r7                                    r1 -= r7   ///  r1 = r1.wrapping_sub(r7)
    ldxdw r9, [r10-0x38]                    
    jge r1, r8, lbb_18674                           if r1 >= r8 { pc += 1 }
    ja lbb_18943                                    if true { pc += 269 }
lbb_18674:
    ldxdw r1, [r10-0x10]                    
    add64 r1, r7                                    r1 += r7   ///  r1 = r1.wrapping_add(r7)
    mov64 r3, r8                                    r3 = r8
    call function_30349                     
    add64 r7, r8                                    r7 += r8   ///  r7 = r7.wrapping_add(r8)
    mov64 r6, 0                                     r6 = 0 as i32 as i64 as u64
    ldxdw r4, [r10-0x20]                    
    add64 r4, 64                                    r4 += 64   ///  r4 = r4.wrapping_add(64 as i32 as i64 as u64)
    stxdw [r10-0x8], r7                     
    ja lbb_18691                                    if true { pc += 7 }
lbb_18684:
    add64 r6, 1                                     r6 += 1   ///  r6 = r6.wrapping_add(1 as i32 as i64 as u64)
    ldxdw r1, [r10-0x10]                    
    add64 r1, r7                                    r1 += r7   ///  r1 = r1.wrapping_add(r7)
    stxb [r1+0x0], r8                       
    add64 r7, 1                                     r7 += 1   ///  r7 = r7.wrapping_add(1 as i32 as i64 as u64)
    stxdw [r10-0x8], r7                     
    jeq r6, 32, lbb_18904                           if r6 == (32 as i32 as i64 as u64) { pc += 213 }
lbb_18691:
    mov64 r1, r4                                    r1 = r4
    add64 r1, r6                                    r1 += r6   ///  r1 = r1.wrapping_add(r6)
    ldxb r8, [r1+0x0]                       
    ldxdw r1, [r10-0x18]                    
    jne r1, r7, lbb_18684                           if r1 != r7 { pc += -12 }
    mov64 r1, r10                                   r1 = r10
    add64 r1, -24                                   r1 += -24   ///  r1 = r1.wrapping_add(-24 as i32 as i64 as u64)
    mov64 r2, r7                                    r2 = r7
    mov64 r3, 1                                     r3 = 1 as i32 as i64 as u64
    mov64 r7, r4                                    r7 = r4
    call function_19168                     
    mov64 r4, r7                                    r4 = r7
    ldxdw r7, [r10-0x8]                     
    ja lbb_18684                                    if true { pc += -21 }
lbb_18705:
    mov64 r7, 0                                     r7 = 0 as i32 as i64 as u64
    jgt r1, 3, lbb_18713                            if r1 > (3 as i32 as i64 as u64) { pc += 6 }
    mov64 r1, r10                                   r1 = r10
    add64 r1, -24                                   r1 += -24   ///  r1 = r1.wrapping_add(-24 as i32 as i64 as u64)
    mov64 r3, 4                                     r3 = 4 as i32 as i64 as u64
    call function_19168                     
    ldxdw r0, [r10-0x10]                    
    ldxdw r7, [r10-0x8]                     
lbb_18713:
    add64 r0, r7                                    r0 += r7   ///  r0 = r0.wrapping_add(r7)
    mov64 r1, 11                                    r1 = 11 as i32 as i64 as u64
    stxw [r0+0x0], r1                       
    add64 r7, 4                                     r7 += 4   ///  r7 = r7.wrapping_add(4 as i32 as i64 as u64)
    stxdw [r10-0x8], r7                     
    ldxdw r1, [r10-0x18]                    
    sub64 r1, r7                                    r1 -= r7   ///  r1 = r1.wrapping_sub(r7)
    ldxdw r2, [r10-0x20]                    
    ldxdw r6, [r2+0x20]                     
    jgt r1, 7, lbb_18730                            if r1 > (7 as i32 as i64 as u64) { pc += 7 }
    mov64 r1, r10                                   r1 = r10
    add64 r1, -24                                   r1 += -24   ///  r1 = r1.wrapping_add(-24 as i32 as i64 as u64)
    mov64 r2, r7                                    r2 = r7
    mov64 r3, 8                                     r3 = 8 as i32 as i64 as u64
    call function_19168                     
    ldxdw r2, [r10-0x20]                    
    ldxdw r7, [r10-0x8]                     
lbb_18730:
    ldxdw r1, [r10-0x10]                    
    add64 r1, r7                                    r1 += r7   ///  r1 = r1.wrapping_add(r7)
    stxdw [r1+0x0], r6                      
    add64 r7, 8                                     r7 += 8   ///  r7 = r7.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x8], r7                     
    ldxdw r1, [r10-0x18]                    
    sub64 r1, r7                                    r1 -= r7   ///  r1 = r1.wrapping_sub(r7)
    ldxdw r8, [r2+0x18]                     
    ldxdw r2, [r2+0x10]                     
    jgt r1, 7, lbb_18748                            if r1 > (7 as i32 as i64 as u64) { pc += 8 }
    mov64 r1, r10                                   r1 = r10
    add64 r1, -24                                   r1 += -24   ///  r1 = r1.wrapping_add(-24 as i32 as i64 as u64)
    mov64 r6, r2                                    r6 = r2
    mov64 r2, r7                                    r2 = r7
    mov64 r3, 8                                     r3 = 8 as i32 as i64 as u64
    call function_19168                     
    mov64 r2, r6                                    r2 = r6
    ldxdw r7, [r10-0x8]                     
lbb_18748:
    ldxdw r1, [r10-0x10]                    
    add64 r1, r7                                    r1 += r7   ///  r1 = r1.wrapping_add(r7)
    stxdw [r1+0x0], r8                      
    add64 r7, 8                                     r7 += 8   ///  r7 = r7.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x8], r7                     
    ldxdw r1, [r10-0x18]                    
    sub64 r1, r7                                    r1 -= r7   ///  r1 = r1.wrapping_sub(r7)
    jge r1, r8, lbb_18764                           if r1 >= r8 { pc += 8 }
    mov64 r1, r10                                   r1 = r10
    add64 r1, -24                                   r1 += -24   ///  r1 = r1.wrapping_add(-24 as i32 as i64 as u64)
    mov64 r6, r2                                    r6 = r2
    mov64 r2, r7                                    r2 = r7
    mov64 r3, r8                                    r3 = r8
    call function_19168                     
    mov64 r2, r6                                    r2 = r6
    ldxdw r7, [r10-0x8]                     
lbb_18764:
    ldxdw r1, [r10-0x10]                    
    add64 r1, r7                                    r1 += r7   ///  r1 = r1.wrapping_add(r7)
    mov64 r3, r8                                    r3 = r8
    call function_30349                     
    add64 r7, r8                                    r7 += r8   ///  r7 = r7.wrapping_add(r8)
    mov64 r6, 0                                     r6 = 0 as i32 as i64 as u64
    ldxdw r4, [r10-0x20]                    
    add64 r4, 40                                    r4 += 40   ///  r4 = r4.wrapping_add(40 as i32 as i64 as u64)
    stxdw [r10-0x8], r7                     
    ja lbb_18781                                    if true { pc += 7 }
lbb_18774:
    add64 r6, 1                                     r6 += 1   ///  r6 = r6.wrapping_add(1 as i32 as i64 as u64)
    ldxdw r1, [r10-0x10]                    
    add64 r1, r7                                    r1 += r7   ///  r1 = r1.wrapping_add(r7)
    stxb [r1+0x0], r8                       
    add64 r7, 1                                     r7 += 1   ///  r7 = r7.wrapping_add(1 as i32 as i64 as u64)
    stxdw [r10-0x8], r7                     
    jeq r6, 32, lbb_18904                           if r6 == (32 as i32 as i64 as u64) { pc += 123 }
lbb_18781:
    mov64 r1, r4                                    r1 = r4
    add64 r1, r6                                    r1 += r6   ///  r1 = r1.wrapping_add(r6)
    ldxb r8, [r1+0x0]                       
    ldxdw r1, [r10-0x18]                    
    jne r1, r7, lbb_18774                           if r1 != r7 { pc += -12 }
    mov64 r1, r10                                   r1 = r10
    add64 r1, -24                                   r1 += -24   ///  r1 = r1.wrapping_add(-24 as i32 as i64 as u64)
    mov64 r2, r7                                    r2 = r7
    mov64 r3, 1                                     r3 = 1 as i32 as i64 as u64
    mov64 r7, r4                                    r7 = r4
    call function_19168                     
    mov64 r4, r7                                    r4 = r7
    ldxdw r7, [r10-0x8]                     
    ja lbb_18774                                    if true { pc += -21 }
lbb_18795:
    ldxdw r1, [r10-0x10]                    
    add64 r1, r7                                    r1 += r7   ///  r1 = r1.wrapping_add(r7)
    stxdw [r1+0x0], r6                      
    add64 r7, 8                                     r7 += 8   ///  r7 = r7.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x8], r7                     
    ldxdw r8, [r10-0x18]                    
    mov64 r1, r8                                    r1 = r8
    sub64 r1, r7                                    r1 -= r7   ///  r1 = r1.wrapping_sub(r7)
    ldxdw r9, [r10-0x38]                    
    jge r1, r6, lbb_18806                           if r1 >= r6 { pc += 1 }
    ja lbb_18952                                    if true { pc += 146 }
lbb_18806:
    ldxdw r1, [r10-0x10]                    
    stxdw [r10-0x40], r1                    
    add64 r1, r7                                    r1 += r7   ///  r1 = r1.wrapping_add(r7)
    mov64 r3, r6                                    r3 = r6
    call function_30349                     
    ldxdw r1, [r10-0x40]                    
    add64 r7, r6                                    r7 += r6   ///  r7 = r7.wrapping_add(r6)
    stxdw [r10-0x8], r7                     
    sub64 r8, r7                                    r8 -= r7   ///  r8 = r8.wrapping_sub(r7)
    ldxdw r4, [r10-0x20]                    
    ldxdw r6, [r4+0x40]                     
    jgt r8, 7, lbb_18826                            if r8 > (7 as i32 as i64 as u64) { pc += 8 }
    mov64 r1, r10                                   r1 = r10
    add64 r1, -24                                   r1 += -24   ///  r1 = r1.wrapping_add(-24 as i32 as i64 as u64)
    mov64 r2, r7                                    r2 = r7
    mov64 r3, 8                                     r3 = 8 as i32 as i64 as u64
    call function_19168                     
    ldxdw r4, [r10-0x20]                    
    ldxdw r1, [r10-0x10]                    
    ldxdw r7, [r10-0x8]                     
lbb_18826:
    add64 r1, r7                                    r1 += r7   ///  r1 = r1.wrapping_add(r7)
    stxdw [r1+0x0], r6                      
    mov64 r6, 0                                     r6 = 0 as i32 as i64 as u64
    add64 r4, 72                                    r4 += 72   ///  r4 = r4.wrapping_add(72 as i32 as i64 as u64)
    add64 r7, 8                                     r7 += 8   ///  r7 = r7.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x8], r7                     
    ja lbb_18840                                    if true { pc += 7 }
lbb_18833:
    add64 r6, 1                                     r6 += 1   ///  r6 = r6.wrapping_add(1 as i32 as i64 as u64)
    ldxdw r1, [r10-0x10]                    
    add64 r1, r7                                    r1 += r7   ///  r1 = r1.wrapping_add(r7)
    stxb [r1+0x0], r8                       
    add64 r7, 1                                     r7 += 1   ///  r7 = r7.wrapping_add(1 as i32 as i64 as u64)
    stxdw [r10-0x8], r7                     
    jeq r6, 32, lbb_18904                           if r6 == (32 as i32 as i64 as u64) { pc += 64 }
lbb_18840:
    mov64 r1, r4                                    r1 = r4
    add64 r1, r6                                    r1 += r6   ///  r1 = r1.wrapping_add(r6)
    ldxb r8, [r1+0x0]                       
    ldxdw r1, [r10-0x18]                    
    jne r1, r7, lbb_18833                           if r1 != r7 { pc += -12 }
    mov64 r1, r10                                   r1 = r10
    add64 r1, -24                                   r1 += -24   ///  r1 = r1.wrapping_add(-24 as i32 as i64 as u64)
    mov64 r2, r7                                    r2 = r7
    mov64 r3, 1                                     r3 = 1 as i32 as i64 as u64
    mov64 r7, r4                                    r7 = r4
    call function_19168                     
    mov64 r4, r7                                    r4 = r7
    ldxdw r7, [r10-0x8]                     
    ja lbb_18833                                    if true { pc += -21 }
lbb_18854:
    mov64 r6, 0                                     r6 = 0 as i32 as i64 as u64
    mov64 r7, 0                                     r7 = 0 as i32 as i64 as u64
    jgt r1, 3, lbb_18863                            if r1 > (3 as i32 as i64 as u64) { pc += 6 }
    mov64 r1, r10                                   r1 = r10
    add64 r1, -24                                   r1 += -24   ///  r1 = r1.wrapping_add(-24 as i32 as i64 as u64)
    mov64 r3, 4                                     r3 = 4 as i32 as i64 as u64
    call function_19168                     
    ldxdw r0, [r10-0x10]                    
    ldxdw r7, [r10-0x8]                     
lbb_18863:
    add64 r0, r7                                    r0 += r7   ///  r0 = r0.wrapping_add(r7)
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    stxw [r0+0x0], r1                       
    ldxdw r4, [r10-0x20]                    
    add64 r4, 8                                     r4 += 8   ///  r4 = r4.wrapping_add(8 as i32 as i64 as u64)
    add64 r7, 4                                     r7 += 4   ///  r7 = r7.wrapping_add(4 as i32 as i64 as u64)
    stxdw [r10-0x8], r7                     
    ja lbb_18878                                    if true { pc += 7 }
lbb_18871:
    add64 r6, 1                                     r6 += 1   ///  r6 = r6.wrapping_add(1 as i32 as i64 as u64)
    ldxdw r1, [r10-0x10]                    
    add64 r1, r7                                    r1 += r7   ///  r1 = r1.wrapping_add(r7)
    stxb [r1+0x0], r8                       
    add64 r7, 1                                     r7 += 1   ///  r7 = r7.wrapping_add(1 as i32 as i64 as u64)
    stxdw [r10-0x8], r7                     
    jeq r6, 32, lbb_18904                           if r6 == (32 as i32 as i64 as u64) { pc += 26 }
lbb_18878:
    mov64 r1, r4                                    r1 = r4
    add64 r1, r6                                    r1 += r6   ///  r1 = r1.wrapping_add(r6)
    ldxb r8, [r1+0x0]                       
    ldxdw r1, [r10-0x18]                    
    jne r1, r7, lbb_18871                           if r1 != r7 { pc += -12 }
    mov64 r1, r10                                   r1 = r10
    add64 r1, -24                                   r1 += -24   ///  r1 = r1.wrapping_add(-24 as i32 as i64 as u64)
    mov64 r2, r7                                    r2 = r7
    mov64 r3, 1                                     r3 = 1 as i32 as i64 as u64
    mov64 r7, r4                                    r7 = r4
    call function_19168                     
    mov64 r4, r7                                    r4 = r7
    ldxdw r7, [r10-0x8]                     
    ja lbb_18871                                    if true { pc += -21 }
lbb_18892:
    mov64 r7, 0                                     r7 = 0 as i32 as i64 as u64
    jgt r1, 3, lbb_18900                            if r1 > (3 as i32 as i64 as u64) { pc += 6 }
    mov64 r1, r10                                   r1 = r10
    add64 r1, -24                                   r1 += -24   ///  r1 = r1.wrapping_add(-24 as i32 as i64 as u64)
    mov64 r3, 4                                     r3 = 4 as i32 as i64 as u64
    call function_19168                     
    ldxdw r0, [r10-0x10]                    
    ldxdw r7, [r10-0x8]                     
lbb_18900:
    add64 r0, r7                                    r0 += r7   ///  r0 = r0.wrapping_add(r7)
    mov64 r1, 4                                     r1 = 4 as i32 as i64 as u64
lbb_18902:
    stxw [r0+0x0], r1                       
    add64 r7, 4                                     r7 += 4   ///  r7 = r7.wrapping_add(4 as i32 as i64 as u64)
lbb_18904:
    ldxdw r1, [r10-0x10]                    
    ldxdw r2, [r10-0x18]                    
    lddw r3, 0x8000000000000000                     r3 load str located at -9223372036854775808
    jeq r2, r3, lbb_18965                           if r2 == r3 { pc += 56 }
    ldxdw r4, [r10-0x30]                    
    ldxdw r3, [r4+0x18]                     
    stxdw [r9+0x48], r3                     
    ldxdw r3, [r4+0x10]                     
    stxdw [r9+0x40], r3                     
    ldxdw r3, [r4+0x8]                      
    stxdw [r9+0x38], r3                     
    ldxdw r3, [r4+0x0]                      
    stxdw [r9+0x30], r3                     
    ldxdw r4, [r10-0x28]                    
    ldxdw r3, [r4+0x0]                      
    stxdw [r9+0x0], r3                      
    ldxdw r3, [r4+0x8]                      
    stxdw [r9+0x8], r3                      
    ldxdw r3, [r4+0x10]                     
    stxdw [r9+0x10], r3                     
    stxdw [r9+0x28], r7                     
    stxdw [r9+0x20], r1                     
    stxdw [r9+0x18], r2                     
    exit                                    
lbb_18929:
    mov64 r1, r10                                   r1 = r10
    add64 r1, -24                                   r1 += -24   ///  r1 = r1.wrapping_add(-24 as i32 as i64 as u64)
    mov64 r3, 4                                     r3 = 4 as i32 as i64 as u64
    call function_19168                     
    ldxdw r0, [r10-0x10]                    
    ldxdw r7, [r10-0x8]                     
    ja lbb_18258                                    if true { pc += -678 }
lbb_18936:
    mov64 r1, r10                                   r1 = r10
    add64 r1, -24                                   r1 += -24   ///  r1 = r1.wrapping_add(-24 as i32 as i64 as u64)
    mov64 r3, 4                                     r3 = 4 as i32 as i64 as u64
    call function_19168                     
    ldxdw r0, [r10-0x10]                    
    ldxdw r7, [r10-0x8]                     
    ja lbb_18327                                    if true { pc += -616 }
lbb_18943:
    mov64 r1, r10                                   r1 = r10
    add64 r1, -24                                   r1 += -24   ///  r1 = r1.wrapping_add(-24 as i32 as i64 as u64)
    mov64 r6, r2                                    r6 = r2
    mov64 r2, r7                                    r2 = r7
    mov64 r3, r8                                    r3 = r8
    call function_19168                     
    mov64 r2, r6                                    r2 = r6
    ldxdw r7, [r10-0x8]                     
    ja lbb_18674                                    if true { pc += -278 }
lbb_18952:
    mov64 r1, r10                                   r1 = r10
    add64 r1, -24                                   r1 += -24   ///  r1 = r1.wrapping_add(-24 as i32 as i64 as u64)
    mov64 r8, r2                                    r8 = r2
    mov64 r2, r7                                    r2 = r7
    mov64 r3, r6                                    r3 = r6
    call function_19168                     
    mov64 r2, r8                                    r2 = r8
    ldxdw r8, [r10-0x18]                    
    ldxdw r7, [r10-0x8]                     
    ja lbb_18806                                    if true { pc += -156 }
lbb_18962:
    mov64 r1, r8                                    r1 = r8
    mov64 r2, r7                                    r2 = r7
    call function_21549                     
lbb_18965:
    stxdw [r10-0x18], r1                    
    mov64 r3, r10                                   r3 = r10
    add64 r3, -24                                   r3 += -24   ///  r3 = r3.wrapping_add(-24 as i32 as i64 as u64)
    lddw r1, 0x10003ecd4 --> b"called `Result::unwrap()` on an `Err` value"        r1 load str located at 4295224532
    mov64 r2, 43                                    r2 = 43 as i32 as i64 as u64
    lddw r4, 0x100041508 --> b"\x00\x00\x00\x00PU\x02\x00\x08\x00\x00\x00\x00\x00\x00\x00\x08\x00\x00\x0…        r4 load str located at 4295234824
    lddw r5, 0x100041528 --> b"\x00\x00\x00\x00\xff\xec\x03\x00\x0a\x00\x00\x00\x00\x00\x00\x00\xe5\x00\…        r5 load str located at 4295234856
    call function_25967                     
    ldxdw r1, [r1+0x0]                      
    ldxw r3, [r2+0x34]                      
    mov64 r4, r3                                    r4 = r3
    and64 r4, 16                                    r4 &= 16   ///  r4 = r4.and(16)
    jne r4, 0, lbb_18986                            if r4 != (0 as i32 as i64 as u64) { pc += 5 }
    and64 r3, 32                                    r3 &= 32   ///  r3 = r3.and(32)
    jeq r3, 0, lbb_18984                            if r3 == (0 as i32 as i64 as u64) { pc += 1 }
    ja lbb_18988                                    if true { pc += 4 }
lbb_18984:
    call function_30197                     
    ja lbb_18989                                    if true { pc += 3 }
lbb_18986:
    call function_29661                     
    ja lbb_18989                                    if true { pc += 1 }
lbb_18988:
    call function_29708                     
lbb_18989:
    exit                                    

function_18990:
    ldxdw r1, [r1+0x0]                      
    ldxw r3, [r2+0x34]                      
    mov64 r4, r3                                    r4 = r3
    and64 r4, 16                                    r4 &= 16   ///  r4 = r4.and(16)
    jne r4, 0, lbb_19000                            if r4 != (0 as i32 as i64 as u64) { pc += 5 }
    and64 r3, 32                                    r3 &= 32   ///  r3 = r3.and(32)
    jeq r3, 0, lbb_18998                            if r3 == (0 as i32 as i64 as u64) { pc += 1 }
    ja lbb_19002                                    if true { pc += 4 }
lbb_18998:
    call function_30232                     
    ja lbb_19003                                    if true { pc += 3 }
lbb_19000:
    call function_29851                     
    ja lbb_19003                                    if true { pc += 1 }
lbb_19002:
    call function_29897                     
lbb_19003:
    exit                                    

function_19004:
    mov64 r3, r2                                    r3 = r2
    ldxdw r1, [r1+0x0]                      
    ldxdw r2, [r1+0x10]                     
    ldxdw r1, [r1+0x8]                      
    call function_27859                     
    exit                                    

function_19010:
    ldxdw r1, [r1+0x0]                      
    mov64 r3, r1                                    r3 = r1
    add64 r3, 8                                     r3 += 8   ///  r3 = r3.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x8], r3                     
    mov64 r3, r10                                   r3 = r10
    add64 r3, -8                                    r3 += -8   ///  r3 = r3.wrapping_add(-8 as i32 as i64 as u64)
    stxdw [r10-0xfd8], r3                   
    lddw r3, 0x100041600 --> b"\x00\x00\x00\x00HU\x02\x00\x08\x00\x00\x00\x00\x00\x00\x00\x08\x00\x00\x0…        r3 load str located at 4295235072
    stxdw [r10-0xfd0], r3                   
    lddw r3, 0x10003eda9 --> b"error_lencodeKindkindSome <= trueenumNone    \x00\x00ind"        r3 load str located at 4295224745
    stxdw [r10-0xfe8], r3                   
    lddw r3, 0x1000415e0 --> b"\x00\x00\x00\x00HU\x02\x00\x08\x00\x00\x00\x00\x00\x00\x00\x08\x00\x00\x0…        r3 load str located at 4295235040
    stxdw [r10-0xff0], r3                   
    stxdw [r10-0xff8], r1                   
    mov64 r1, 11                                    r1 = 11 as i32 as i64 as u64
    stxdw [r10-0x1000], r1                  
    mov64 r1, 9                                     r1 = 9 as i32 as i64 as u64
    stxdw [r10-0xfe0], r1                   
    mov64 r5, r10                                   r5 = r10
    mov64 r1, r2                                    r1 = r2
    lddw r2, 0x10003ed95 --> b"Utf8Error"           r2 load str located at 4295224725
    mov64 r3, 9                                     r3 = 9 as i32 as i64 as u64
    lddw r4, 0x10003ed9e --> b"valid_up_toerror_lencodeKindkindSome <= trueenumNo"        r4 load str located at 4295224734
    call function_27710                     
    exit                                    

function_19040:
    ldxdw r1, [r1+0x0]                      
    ldxb r3, [r1+0x0]                       
    jne r3, 0, lbb_19049                            if r3 != (0 as i32 as i64 as u64) { pc += 6 }
    mov64 r1, r2                                    r1 = r2
    lddw r2, 0x10003edce --> b"None"                r2 load str located at 4295224782
    mov64 r3, 4                                     r3 = 4 as i32 as i64 as u64
    call function_27691                     
    ja lbb_19060                                    if true { pc += 11 }
lbb_19049:
    add64 r1, 1                                     r1 += 1   ///  r1 = r1.wrapping_add(1 as i32 as i64 as u64)
    stxdw [r10-0x8], r1                     
    mov64 r4, r10                                   r4 = r10
    add64 r4, -8                                    r4 += -8   ///  r4 = r4.wrapping_add(-8 as i32 as i64 as u64)
    mov64 r1, r2                                    r1 = r2
    lddw r2, 0x10003edbe --> b"Some"                r2 load str located at 4295224766
    mov64 r3, 4                                     r3 = 4 as i32 as i64 as u64
    lddw r5, 0x100041580 --> b"\x00\x00\x00\x00HU\x02\x00\x08\x00\x00\x00\x00\x00\x00\x00\x08\x00\x00\x0…        r5 load str located at 4295234944
    call function_27782                     
lbb_19060:
    exit                                    

function_19061:
    ldxdw r1, [r1+0x0]                      
    call function_20693                     
    exit                                    

function_19064:
    ldxw r3, [r2+0x34]                      
    mov64 r4, r3                                    r4 = r3
    and64 r4, 16                                    r4 &= 16   ///  r4 = r4.and(16)
    jne r4, 0, lbb_19073                            if r4 != (0 as i32 as i64 as u64) { pc += 5 }
    and64 r3, 32                                    r3 &= 32   ///  r3 = r3.and(32)
    jeq r3, 0, lbb_19071                            if r3 == (0 as i32 as i64 as u64) { pc += 1 }
    ja lbb_19075                                    if true { pc += 4 }
lbb_19071:
    call function_30232                     
    ja lbb_19076                                    if true { pc += 3 }
lbb_19073:
    call function_29851                     
    ja lbb_19076                                    if true { pc += 1 }
lbb_19075:
    call function_29897                     
lbb_19076:
    exit                                    

function_19077:
    exit                                    

function_19078:
    ldxdw r1, [r1+0x0]                      
    ldxdw r2, [r1+0x0]                      
    lddw r4, 0x8000000000000000                     r4 load str located at -9223372036854775808
    mov64 r3, r2                                    r3 = r2
    xor64 r3, r4                                    r3 ^= r4   ///  r3 = r3.xor(r4)
    mov64 r4, 8                                     r4 = 8 as i32 as i64 as u64
    jgt r4, r3, lbb_19087                           if r4 > r3 { pc += 1 }
    mov64 r3, 8                                     r3 = 8 as i32 as i64 as u64
lbb_19087:
    mov64 r4, r3                                    r4 = r3
    add64 r4, -1                                    r4 += -1   ///  r4 = r4.wrapping_add(-1 as i32 as i64 as u64)
    mov64 r5, 7                                     r5 = 7 as i32 as i64 as u64
    jgt r5, r4, lbb_19124                           if r5 > r4 { pc += 33 }
    ldxdw r6, [r1+0x8]                      
    jeq r3, 0, lbb_19100                            if r3 == (0 as i32 as i64 as u64) { pc += 7 }
    jeq r2, 0, lbb_19124                            if r2 == (0 as i32 as i64 as u64) { pc += 30 }
    mov64 r7, r1                                    r7 = r1
    mov64 r1, r6                                    r1 = r6
    mov64 r3, 1                                     r3 = 1 as i32 as i64 as u64
    call function_14411                     
    mov64 r1, r7                                    r1 = r7
    ja lbb_19124                                    if true { pc += 24 }
lbb_19100:
    mov64 r2, r6                                    r2 = r6
    and64 r2, 3                                     r2 &= 3   ///  r2 = r2.and(3)
    mov64 r3, r2                                    r3 = r2
    add64 r3, -2                                    r3 += -2   ///  r3 = r3.wrapping_add(-2 as i32 as i64 as u64)
    mov64 r4, 2                                     r4 = 2 as i32 as i64 as u64
    jgt r4, r3, lbb_19124                           if r4 > r3 { pc += 18 }
    jeq r2, 0, lbb_19124                            if r2 == (0 as i32 as i64 as u64) { pc += 17 }
    mov64 r8, r1                                    r8 = r1
    ldxdw r7, [r6-0x1]                      
    ldxdw r9, [r6+0x7]                      
    ldxdw r2, [r9+0x0]                      
    mov64 r1, r7                                    r1 = r7
    callx r2                                
    add64 r6, -1                                    r6 += -1   ///  r6 = r6.wrapping_add(-1 as i32 as i64 as u64)
    ldxdw r2, [r9+0x8]                      
    jeq r2, 0, lbb_19119                            if r2 == (0 as i32 as i64 as u64) { pc += 3 }
    ldxdw r3, [r9+0x10]                     
    mov64 r1, r7                                    r1 = r7
    call function_14411                     
lbb_19119:
    mov64 r1, r6                                    r1 = r6
    mov64 r2, 24                                    r2 = 24 as i32 as i64 as u64
    mov64 r3, 8                                     r3 = 8 as i32 as i64 as u64
    call function_14411                     
    mov64 r1, r8                                    r1 = r8
lbb_19124:
    mov64 r2, 24                                    r2 = 24 as i32 as i64 as u64
    mov64 r3, 8                                     r3 = 8 as i32 as i64 as u64
    call function_14411                     
    exit                                    

function_19128:
    mov64 r7, r3                                    r7 = r3
    mov64 r8, r2                                    r8 = r2
    mov64 r6, r1                                    r6 = r1
    jeq r8, 0, lbb_19142                            if r8 == (0 as i32 as i64 as u64) { pc += 10 }
    ldxdw r1, [r4+0x8]                      
    jeq r1, 0, lbb_19152                            if r1 == (0 as i32 as i64 as u64) { pc += 18 }
    ldxdw r2, [r4+0x10]                     
    jne r2, 0, lbb_19146                            if r2 != (0 as i32 as i64 as u64) { pc += 10 }
    jeq r7, 0, lbb_19161                            if r7 == (0 as i32 as i64 as u64) { pc += 24 }
    mov64 r1, r7                                    r1 = r7
    mov64 r2, r8                                    r2 = r8
    call function_14385                     
    jeq r0, 0, lbb_19157                            if r0 == (0 as i32 as i64 as u64) { pc += 16 }
    ja lbb_19163                                    if true { pc += 21 }
lbb_19142:
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    stxdw [r6+0x8], r1                      
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    ja lbb_19166                                    if true { pc += 20 }
lbb_19146:
    ldxdw r1, [r4+0x0]                      
    mov64 r3, r8                                    r3 = r8
    mov64 r4, r7                                    r4 = r7
    call function_14412                     
    jeq r0, 0, lbb_19157                            if r0 == (0 as i32 as i64 as u64) { pc += 6 }
    ja lbb_19163                                    if true { pc += 11 }
lbb_19152:
    jeq r7, 0, lbb_19161                            if r7 == (0 as i32 as i64 as u64) { pc += 8 }
    mov64 r1, r7                                    r1 = r7
    mov64 r2, r8                                    r2 = r8
    call function_14385                     
    jne r0, 0, lbb_19163                            if r0 != (0 as i32 as i64 as u64) { pc += 6 }
lbb_19157:
    stxdw [r6+0x10], r7                     
    stxdw [r6+0x8], r8                      
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    ja lbb_19166                                    if true { pc += 5 }
lbb_19161:
    mov64 r7, 0                                     r7 = 0 as i32 as i64 as u64
    mov64 r0, r8                                    r0 = r8
lbb_19163:
    stxdw [r6+0x10], r7                     
    stxdw [r6+0x8], r0                      
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
lbb_19166:
    stxdw [r6+0x0], r1                      
    exit                                    

function_19168:
    mov64 r6, r1                                    r6 = r1
    mov64 r4, r2                                    r4 = r2
    add64 r4, r3                                    r4 += r3   ///  r4 = r4.wrapping_add(r3)
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    mov64 r3, 1                                     r3 = 1 as i32 as i64 as u64
    jgt r2, r4, lbb_19175                           if r2 > r4 { pc += 1 }
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
lbb_19175:
    and64 r3, 1                                     r3 &= 1   ///  r3 = r3.and(1)
    jne r3, 0, lbb_19204                            if r3 != (0 as i32 as i64 as u64) { pc += 27 }
    ldxdw r1, [r6+0x0]                      
    mov64 r7, r1                                    r7 = r1
    lsh64 r7, 1                                     r7 <<= 1   ///  r7 = r7.wrapping_shl(1)
    jgt r7, r4, lbb_19182                           if r7 > r4 { pc += 1 }
    mov64 r7, r4                                    r7 = r4
lbb_19182:
    jgt r7, 8, lbb_19184                            if r7 > (8 as i32 as i64 as u64) { pc += 1 }
    mov64 r7, 8                                     r7 = 8 as i32 as i64 as u64
lbb_19184:
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
    mov64 r2, r7                                    r2 = r7
    xor64 r2, -1                                    r2 ^= -1   ///  r2 = r2.xor(-1)
    rsh64 r2, 63                                    r2 >>= 63   ///  r2 = r2.wrapping_shr(63)
    jeq r1, 0, lbb_19193                            if r1 == (0 as i32 as i64 as u64) { pc += 4 }
    ldxdw r3, [r6+0x8]                      
    stxdw [r10-0x8], r1                     
    stxdw [r10-0x18], r3                    
    mov64 r3, 1                                     r3 = 1 as i32 as i64 as u64
lbb_19193:
    stxdw [r10-0x10], r3                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -48                                   r1 += -48   ///  r1 = r1.wrapping_add(-48 as i32 as i64 as u64)
    mov64 r4, r10                                   r4 = r10
    add64 r4, -24                                   r4 += -24   ///  r4 = r4.wrapping_add(-24 as i32 as i64 as u64)
    mov64 r3, r7                                    r3 = r7
    call function_19128                     
    ldxdw r1, [r10-0x30]                    
    jeq r1, 0, lbb_19205                            if r1 == (0 as i32 as i64 as u64) { pc += 3 }
    ldxdw r2, [r10-0x20]                    
    ldxdw r1, [r10-0x28]                    
lbb_19204:
    call function_21549                     
lbb_19205:
    ldxdw r1, [r10-0x28]                    
    stxdw [r6+0x0], r7                      
    stxdw [r6+0x8], r1                      
    exit                                    

function_19209:
    ldxdw r1, [r1+0x0]                      
    ldxdw r3, [r1+0x0]                      
    lddw r4, 0x8000000000000000                     r4 load str located at -9223372036854775808
    xor64 r3, r4                                    r3 ^= r4   ///  r3 = r3.xor(r4)
    mov64 r4, 8                                     r4 = 8 as i32 as i64 as u64
    jgt r4, r3, lbb_19217                           if r4 > r3 { pc += 1 }
    mov64 r3, 8                                     r3 = 8 as i32 as i64 as u64
lbb_19217:
    jsgt r3, 3, lbb_19232                           if (r3 as i64) > (3 as i32 as i64) { pc += 14 }
    jsgt r3, 1, lbb_19252                           if (r3 as i64) > (1 as i32 as i64) { pc += 33 }
    jeq r3, 0, lbb_19263                            if r3 == (0 as i32 as i64 as u64) { pc += 43 }
    add64 r1, 8                                     r1 += 8   ///  r1 = r1.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x8], r1                     
    mov64 r4, r10                                   r4 = r10
    add64 r4, -8                                    r4 += -8   ///  r4 = r4.wrapping_add(-8 as i32 as i64 as u64)
    mov64 r1, r2                                    r1 = r2
    lddw r2, 0x10003ed0b --> b"InvalidUtf8Encoding"        r2 load str located at 4295224587
    mov64 r3, 19                                    r3 = 19 as i32 as i64 as u64
    lddw r5, 0x100041560 --> b"\x00\x00\x00\x00HU\x02\x00\x08\x00\x00\x00\x00\x00\x00\x00\x08\x00\x00\x0…        r5 load str located at 4295234912
    call function_27782                     
    ja lbb_19292                                    if true { pc += 60 }
lbb_19232:
    jsgt r3, 5, lbb_19239                           if (r3 as i64) > (5 as i32 as i64) { pc += 6 }
    jeq r3, 4, lbb_19293                            if r3 == (4 as i32 as i64 as u64) { pc += 59 }
    mov64 r1, r2                                    r1 = r2
    lddw r2, 0x10003ed56 --> b"DeserializeAnyNotSupported"        r2 load str located at 4295224662
    mov64 r3, 26                                    r3 = 26 as i32 as i64 as u64
    ja lbb_19291                                    if true { pc += 52 }
lbb_19239:
    jeq r3, 6, lbb_19258                            if r3 == (6 as i32 as i64 as u64) { pc += 18 }
    jeq r3, 7, lbb_19287                            if r3 == (7 as i32 as i64 as u64) { pc += 46 }
    stxdw [r10-0x8], r1                     
    mov64 r4, r10                                   r4 = r10
    add64 r4, -8                                    r4 += -8   ///  r4 = r4.wrapping_add(-8 as i32 as i64 as u64)
    mov64 r1, r2                                    r1 = r2
    lddw r2, 0x10003ed8f --> b"Custom"              r2 load str located at 4295224719
    mov64 r3, 6                                     r3 = 6 as i32 as i64 as u64
    lddw r5, 0x1000415c0 --> b"\x00\x00\x00\x00HU\x02\x00\x08\x00\x00\x00\x00\x00\x00\x00\x08\x00\x00\x0…        r5 load str located at 4295235008
    call function_27782                     
    ja lbb_19292                                    if true { pc += 40 }
lbb_19252:
    jeq r3, 2, lbb_19275                            if r3 == (2 as i32 as i64 as u64) { pc += 22 }
    mov64 r1, r2                                    r1 = r2
    lddw r2, 0x10003ed31 --> b"InvalidCharEncoding"        r2 load str located at 4295224625
    mov64 r3, 19                                    r3 = 19 as i32 as i64 as u64
    ja lbb_19291                                    if true { pc += 33 }
lbb_19258:
    mov64 r1, r2                                    r1 = r2
    lddw r2, 0x10003ed70 --> b"SizeLimit"           r2 load str located at 4295224688
    mov64 r3, 9                                     r3 = 9 as i32 as i64 as u64
    ja lbb_19291                                    if true { pc += 28 }
lbb_19263:
    add64 r1, 8                                     r1 += 8   ///  r1 = r1.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x8], r1                     
    mov64 r4, r10                                   r4 = r10
    add64 r4, -8                                    r4 += -8   ///  r4 = r4.wrapping_add(-8 as i32 as i64 as u64)
    mov64 r1, r2                                    r1 = r2
    lddw r2, 0x10003ed09 --> b"Io"                  r2 load str located at 4295224585
    mov64 r3, 2                                     r3 = 2 as i32 as i64 as u64
    lddw r5, 0x100041540 --> b"\x00\x00\x00\x00HU\x02\x00\x08\x00\x00\x00\x00\x00\x00\x00\x08\x00\x00\x0…        r5 load str located at 4295234880
    call function_27782                     
    ja lbb_19292                                    if true { pc += 17 }
lbb_19275:
    add64 r1, 8                                     r1 += 8   ///  r1 = r1.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x8], r1                     
    mov64 r4, r10                                   r4 = r10
    add64 r4, -8                                    r4 += -8   ///  r4 = r4.wrapping_add(-8 as i32 as i64 as u64)
    mov64 r1, r2                                    r1 = r2
    lddw r2, 0x10003ed1e --> b"InvalidBoolEncoding"        r2 load str located at 4295224606
    mov64 r3, 19                                    r3 = 19 as i32 as i64 as u64
    lddw r5, 0x100041580 --> b"\x00\x00\x00\x00HU\x02\x00\x08\x00\x00\x00\x00\x00\x00\x00\x08\x00\x00\x0…        r5 load str located at 4295234944
    call function_27782                     
    ja lbb_19292                                    if true { pc += 5 }
lbb_19287:
    mov64 r1, r2                                    r1 = r2
    lddw r2, 0x10003ed79 --> b"SequenceMustHaveLength"        r2 load str located at 4295224697
    mov64 r3, 22                                    r3 = 22 as i32 as i64 as u64
lbb_19291:
    call function_27691                     
lbb_19292:
    exit                                    
lbb_19293:
    add64 r1, 8                                     r1 += 8   ///  r1 = r1.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x8], r1                     
    mov64 r4, r10                                   r4 = r10
    add64 r4, -8                                    r4 += -8   ///  r4 = r4.wrapping_add(-8 as i32 as i64 as u64)
    mov64 r1, r2                                    r1 = r2
    lddw r2, 0x10003ed44 --> b"InvalidTagEncoding"        r2 load str located at 4295224644
    mov64 r3, 18                                    r3 = 18 as i32 as i64 as u64
    lddw r5, 0x1000415a0 --> b"\x00\x00\x00\x00HU\x02\x00\x08\x00\x00\x00\x00\x00\x00\x00\x08\x00\x00\x0…        r5 load str located at 4295234976
    call function_27782                     
    ja lbb_19292                                    if true { pc += -13 }

function_19305:
    mov64 r6, r5                                    r6 = r5
    mov64 r7, r4                                    r7 = r4
    mov64 r8, r3                                    r8 = r3
    mov64 r9, r2                                    r9 = r2
    stxdw [r10-0x88], r1                    
    mov64 r1, 68                                    r1 = 68 as i32 as i64 as u64
    mov64 r2, 1                                     r2 = 1 as i32 as i64 as u64
    call function_14385                     
    jne r0, 0, lbb_19317                            if r0 != (0 as i32 as i64 as u64) { pc += 3 }
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    mov64 r2, 68                                    r2 = 68 as i32 as i64 as u64
    call function_21552                     
lbb_19317:
    ldxdw r1, [r6-0xff8]                    
    ldxdw r2, [r6-0x1000]                   
    ldxdw r3, [r9+0x18]                     
    stxdw [r0+0x18], r3                     
    ldxdw r3, [r9+0x10]                     
    stxdw [r0+0x10], r3                     
    ldxdw r3, [r9+0x8]                      
    stxdw [r0+0x8], r3                      
    ldxdw r3, [r9+0x0]                      
    stxdw [r0+0x0], r3                      
    mov64 r3, 257                                   r3 = 257 as i32 as i64 as u64
    stxh [r0+0x20], r3                      
    ldxdw r4, [r8+0x0]                      
    stxdw [r0+0x22], r4                     
    ldxdw r4, [r8+0x8]                      
    stxdw [r0+0x2a], r4                     
    ldxdw r4, [r8+0x10]                     
    stxdw [r0+0x32], r4                     
    ldxdw r4, [r8+0x18]                     
    stxdw [r0+0x3a], r4                     
    stxh [r0+0x42], r3                      
    stxdw [r10-0x78], r0                    
    mov64 r3, 2                                     r3 = 2 as i32 as i64 as u64
    stxdw [r10-0x70], r3                    
    stxdw [r10-0x80], r3                    
    stxdw [r10-0x38], r2                    
    stxdw [r10-0x40], r7                    
    ldxdw r2, [r1+0x0]                      
    stxdw [r10-0x60], r2                    
    ldxdw r2, [r1+0x8]                      
    stxdw [r10-0x58], r2                    
    ldxdw r2, [r1+0x10]                     
    stxdw [r10-0x50], r2                    
    ldxdw r1, [r1+0x18]                     
    stxdw [r10-0x48], r1                    
    lddw r1, 0x8000000000000000                     r1 load str located at -9223372036854775808
    stxdw [r10-0x68], r1                    
    mov64 r3, r10                                   r3 = r10
    add64 r3, -104                                  r3 += -104   ///  r3 = r3.wrapping_add(-104 as i32 as i64 as u64)
    mov64 r4, r10                                   r4 = r10
    add64 r4, -128                                  r4 += -128   ///  r4 = r4.wrapping_add(-128 as i32 as i64 as u64)
    ldxdw r1, [r10-0x88]                    
    lddw r2, 0x10003edf8 --> b"\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\…        r2 load str located at 4295224824
    call function_18138                     
    exit                                    

function_19364:
    mov64 r7, r3                                    r7 = r3
    mov64 r8, r2                                    r8 = r2
    mov64 r6, r1                                    r6 = r1
    mov64 r9, 1                                     r9 = 1 as i32 as i64 as u64
    mov64 r1, 34                                    r1 = 34 as i32 as i64 as u64
    mov64 r2, 1                                     r2 = 1 as i32 as i64 as u64
    call function_14385                     
    jne r0, 0, lbb_19375                            if r0 != (0 as i32 as i64 as u64) { pc += 3 }
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    mov64 r2, 34                                    r2 = 34 as i32 as i64 as u64
    call function_21552                     
lbb_19375:
    ldxdw r1, [r8+0x18]                     
    stxdw [r0+0x18], r1                     
    ldxdw r1, [r8+0x10]                     
    stxdw [r0+0x10], r1                     
    ldxdw r1, [r8+0x8]                      
    stxdw [r0+0x8], r1                      
    ldxdw r1, [r8+0x0]                      
    stxdw [r0+0x0], r1                      
    mov64 r1, 257                                   r1 = 257 as i32 as i64 as u64
    stxh [r0+0x20], r1                      
    stxdw [r10-0x78], r0                    
    stxdw [r10-0x70], r9                    
    stxdw [r10-0x80], r9                    
    ldxdw r1, [r7+0x18]                     
    stxdw [r10-0x48], r1                    
    ldxdw r1, [r7+0x10]                     
    stxdw [r10-0x50], r1                    
    ldxdw r1, [r7+0x8]                      
    stxdw [r10-0x58], r1                    
    ldxdw r1, [r7+0x0]                      
    stxdw [r10-0x60], r1                    
    lddw r1, 0x8000000000000001                     r1 load str located at -9223372036854775807
    stxdw [r10-0x68], r1                    
    mov64 r3, r10                                   r3 = r10
    add64 r3, -104                                  r3 += -104   ///  r3 = r3.wrapping_add(-104 as i32 as i64 as u64)
    mov64 r4, r10                                   r4 = r10
    add64 r4, -128                                  r4 += -128   ///  r4 = r4.wrapping_add(-128 as i32 as i64 as u64)
    mov64 r1, r6                                    r1 = r6
    lddw r2, 0x10003edf8 --> b"\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\…        r2 load str located at 4295224824
    call function_18138                     
    exit                                    

function_19408:
    mov64 r7, r4                                    r7 = r4
    mov64 r8, r3                                    r8 = r3
    mov64 r9, r2                                    r9 = r2
    mov64 r6, r1                                    r6 = r1
    mov64 r1, 68                                    r1 = 68 as i32 as i64 as u64
    mov64 r2, 1                                     r2 = 1 as i32 as i64 as u64
    call function_14385                     
    jne r0, 0, lbb_19419                            if r0 != (0 as i32 as i64 as u64) { pc += 3 }
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    mov64 r2, 68                                    r2 = 68 as i32 as i64 as u64
    call function_21552                     
lbb_19419:
    ldxdw r1, [r9+0x18]                     
    stxdw [r0+0x18], r1                     
    ldxdw r1, [r9+0x10]                     
    stxdw [r0+0x10], r1                     
    ldxdw r1, [r9+0x8]                      
    stxdw [r0+0x8], r1                      
    ldxdw r1, [r9+0x0]                      
    stxdw [r0+0x0], r1                      
    mov64 r1, 257                                   r1 = 257 as i32 as i64 as u64
    stxh [r0+0x20], r1                      
    ldxdw r1, [r8+0x0]                      
    stxdw [r0+0x22], r1                     
    ldxdw r1, [r8+0x8]                      
    stxdw [r0+0x2a], r1                     
    ldxdw r1, [r8+0x10]                     
    stxdw [r0+0x32], r1                     
    ldxdw r1, [r8+0x18]                     
    stxdw [r0+0x3a], r1                     
    mov64 r1, 256                                   r1 = 256 as i32 as i64 as u64
    stxh [r0+0x42], r1                      
    stxdw [r10-0x78], r0                    
    mov64 r1, 2                                     r1 = 2 as i32 as i64 as u64
    stxdw [r10-0x70], r1                    
    stxdw [r10-0x80], r1                    
    lddw r1, 0x8000000000000002                     r1 load str located at -9223372036854775806
    stxdw [r10-0x68], r1                    
    stxdw [r10-0x60], r7                    
    mov64 r3, r10                                   r3 = r10
    add64 r3, -104                                  r3 += -104   ///  r3 = r3.wrapping_add(-104 as i32 as i64 as u64)
    mov64 r4, r10                                   r4 = r10
    add64 r4, -128                                  r4 += -128   ///  r4 = r4.wrapping_add(-128 as i32 as i64 as u64)
    mov64 r1, r6                                    r1 = r6
    lddw r2, 0x10003edf8 --> b"\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\…        r2 load str located at 4295224824
    call function_18138                     
    exit                                    

function_19456:
    mov64 r7, r3                                    r7 = r3
    mov64 r8, r2                                    r8 = r2
    mov64 r6, r1                                    r6 = r1
    mov64 r9, 1                                     r9 = 1 as i32 as i64 as u64
    mov64 r1, 34                                    r1 = 34 as i32 as i64 as u64
    mov64 r2, 1                                     r2 = 1 as i32 as i64 as u64
    call function_14385                     
    jne r0, 0, lbb_19467                            if r0 != (0 as i32 as i64 as u64) { pc += 3 }
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    mov64 r2, 34                                    r2 = 34 as i32 as i64 as u64
    call function_21552                     
lbb_19467:
    ldxdw r1, [r8+0x18]                     
    stxdw [r0+0x18], r1                     
    ldxdw r1, [r8+0x10]                     
    stxdw [r0+0x10], r1                     
    ldxdw r1, [r8+0x8]                      
    stxdw [r0+0x8], r1                      
    ldxdw r1, [r8+0x0]                      
    stxdw [r0+0x0], r1                      
    mov64 r1, 257                                   r1 = 257 as i32 as i64 as u64
    stxh [r0+0x20], r1                      
    stxdw [r10-0x78], r0                    
    stxdw [r10-0x70], r9                    
    stxdw [r10-0x80], r9                    
    lddw r1, 0x8000000000000008                     r1 load str located at -9223372036854775800
    stxdw [r10-0x68], r1                    
    stxdw [r10-0x60], r7                    
    mov64 r3, r10                                   r3 = r10
    add64 r3, -104                                  r3 += -104   ///  r3 = r3.wrapping_add(-104 as i32 as i64 as u64)
    mov64 r4, r10                                   r4 = r10
    add64 r4, -128                                  r4 += -128   ///  r4 = r4.wrapping_add(-128 as i32 as i64 as u64)
    mov64 r1, r6                                    r1 = r6
    lddw r2, 0x10003edf8 --> b"\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\…        r2 load str located at 4295224824
    call function_18138                     
    exit                                    

function_19493:
    stxdw [r1+0x8], r2                      
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
    stxdw [r1+0x0], r2                      
    exit                                    

function_19497:
    mov64 r6, r1                                    r6 = r1
    mov64 r1, 24                                    r1 = 24 as i32 as i64 as u64
    mov64 r2, 8                                     r2 = 8 as i32 as i64 as u64
    call function_14385                     
    jne r0, 0, lbb_19505                            if r0 != (0 as i32 as i64 as u64) { pc += 3 }
    mov64 r1, 8                                     r1 = 8 as i32 as i64 as u64
    mov64 r2, 24                                    r2 = 24 as i32 as i64 as u64
    call function_21552                     
lbb_19505:
    stxdw [r0+0x8], r6                      
    lddw r1, 0x8000000000000000                     r1 load str located at -9223372036854775808
    stxdw [r0+0x0], r1                      
    exit                                    

function_19510:
    ldxdw r2, [r1+0x0]                      
    lddw r3, 0x66d17b1817d5a706                     r3 load str located at 7408838205410486022
    jne r2, r3, lbb_19531                           if r2 != r3 { pc += 17 }
    ldxdw r2, [r1+0x8]                      
    lddw r3, 0xc0c2fd5504d4da35                     r3 load str located at -4556801331350414795
    jne r2, r3, lbb_19531                           if r2 != r3 { pc += 13 }
    ldxdw r2, [r1+0x10]                     
    lddw r3, 0xa57556218fc624c1                     r3 load str located at -6524213783030258495
    jne r2, r3, lbb_19531                           if r2 != r3 { pc += 9 }
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
    ldxdw r1, [r1+0x18]                     
    lddw r3, 0x85fcbbadb                            r3 load str located at 35966925531
    jne r1, r3, lbb_19531                           if r1 != r3 { pc += 4 }
lbb_19527:
    mov64 r0, 1                                     r0 = 1 as i32 as i64 as u64
    jeq r2, 0, lbb_19530                            if r2 == (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r0, 0                                     r0 = 0 as i32 as i64 as u64
lbb_19530:
    exit                                    
lbb_19531:
    mov64 r2, 1                                     r2 = 1 as i32 as i64 as u64
    ja lbb_19527                                    if true { pc += -6 }

function_19533:
    ldxdw r1, [r1+0x0]                      
    ldxw r3, [r2+0x34]                      
    mov64 r4, r3                                    r4 = r3
    and64 r4, 16                                    r4 &= 16   ///  r4 = r4.and(16)
    jne r4, 0, lbb_19543                            if r4 != (0 as i32 as i64 as u64) { pc += 5 }
    and64 r3, 32                                    r3 &= 32   ///  r3 = r3.and(32)
    jeq r3, 0, lbb_19541                            if r3 == (0 as i32 as i64 as u64) { pc += 1 }
    ja lbb_19545                                    if true { pc += 4 }
lbb_19541:
    call function_30197                     
    ja lbb_19546                                    if true { pc += 3 }
lbb_19543:
    call function_29661                     
    ja lbb_19546                                    if true { pc += 1 }
lbb_19545:
    call function_29708                     
lbb_19546:
    exit                                    

function_19547:
    ldxdw r1, [r1+0x0]                      
    ldxb r3, [r1+0x0]                       
    jne r3, 0, lbb_19556                            if r3 != (0 as i32 as i64 as u64) { pc += 6 }
    mov64 r1, r2                                    r1 = r2
    lddw r2, 0x10003edce --> b"None"                r2 load str located at 4295224782
    mov64 r3, 4                                     r3 = 4 as i32 as i64 as u64
    call function_27691                     
    ja lbb_19567                                    if true { pc += 11 }
lbb_19556:
    add64 r1, 1                                     r1 += 1   ///  r1 = r1.wrapping_add(1 as i32 as i64 as u64)
    stxdw [r10-0x8], r1                     
    mov64 r4, r10                                   r4 = r10
    add64 r4, -8                                    r4 += -8   ///  r4 = r4.wrapping_add(-8 as i32 as i64 as u64)
    mov64 r1, r2                                    r1 = r2
    lddw r2, 0x10003edbe --> b"Some"                r2 load str located at 4295224766
    mov64 r3, 4                                     r3 = 4 as i32 as i64 as u64
    lddw r5, 0x1000416c0 --> b"\x00\x00\x00\x00\x08e\x02\x00\x08\x00\x00\x00\x00\x00\x00\x00\x08\x00\x00…        r5 load str located at 4295235264
    call function_27782                     
lbb_19567:
    exit                                    

function_19568:
    ldxw r3, [r2+0x34]                      
    mov64 r4, r3                                    r4 = r3
    and64 r4, 16                                    r4 &= 16   ///  r4 = r4.and(16)
    jne r4, 0, lbb_19577                            if r4 != (0 as i32 as i64 as u64) { pc += 5 }
    and64 r3, 32                                    r3 &= 32   ///  r3 = r3.and(32)
    jeq r3, 0, lbb_19575                            if r3 == (0 as i32 as i64 as u64) { pc += 1 }
    ja lbb_19579                                    if true { pc += 4 }
lbb_19575:
    call function_30232                     
    ja lbb_19580                                    if true { pc += 3 }
lbb_19577:
    call function_29851                     
    ja lbb_19580                                    if true { pc += 1 }
lbb_19579:
    call function_29897                     
lbb_19580:
    exit                                    

function_19581:
    exit                                    

function_19582:
    exit                                    

function_19583:
    mov64 r1, r2                                    r1 = r2
    lddw r2, 0x10003ee25 --> b"BufferTooSmall"        r2 load str located at 4295224869
    mov64 r3, 14                                    r3 = 14 as i32 as i64 as u64
    call function_27691                     
    exit                                    

function_19589:
    mov64 r3, r1                                    r3 = r1
    add64 r3, 8                                     r3 += 8   ///  r3 = r3.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x8], r3                     
    mov64 r3, r10                                   r3 = r10
    add64 r3, -8                                    r3 += -8   ///  r3 = r3.wrapping_add(-8 as i32 as i64 as u64)
    stxdw [r10-0xfd8], r3                   
    lddw r3, 0x1000416a0 --> b"\x00\x00\x00\x00\x08e\x02\x00\x08\x00\x00\x00\x00\x00\x00\x00\x08\x00\x00…        r3 load str located at 4295235232
    stxdw [r10-0xfd0], r3                   
    lddw r3, 0x10003ee47 --> b"error_lensrc/lib.rs\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x…        r3 load str located at 4295224903
    stxdw [r10-0xfe8], r3                   
    lddw r3, 0x100041680 --> b"\x00\x00\x00\x00\x08e\x02\x00\x08\x00\x00\x00\x00\x00\x00\x00\x08\x00\x00…        r3 load str located at 4295235200
    stxdw [r10-0xff0], r3                   
    stxdw [r10-0xff8], r1                   
    mov64 r1, 11                                    r1 = 11 as i32 as i64 as u64
    stxdw [r10-0x1000], r1                  
    mov64 r1, 9                                     r1 = 9 as i32 as i64 as u64
    stxdw [r10-0xfe0], r1                   
    mov64 r5, r10                                   r5 = r10
    mov64 r1, r2                                    r1 = r2
    lddw r2, 0x10003ee33 --> b"Utf8Error"           r2 load str located at 4295224883
    mov64 r3, 9                                     r3 = 9 as i32 as i64 as u64
    lddw r4, 0x10003ee3c --> b"valid_up_toerror_lensrc/lib.rs\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xf…        r4 load str located at 4295224892
    call function_27710                     
    exit                                    

function_19618:
    mov64 r0, r4                                    r0 = r4
    mov64 r6, r1                                    r6 = r1
    mov64 r7, 0                                     r7 = 0 as i32 as i64 as u64
    stxdw [r10-0x20], r7                    
    stxdw [r10-0x28], r7                    
    stxdw [r10-0x30], r7                    
    stxdw [r10-0x38], r7                    
    mov64 r1, 255                                   r1 = 255 as i32 as i64 as u64
    stxb [r10-0x1], r1                      
    mov64 r4, r10                                   r4 = r10
    add64 r4, -56                                   r4 += -56   ///  r4 = r4.wrapping_add(-56 as i32 as i64 as u64)
    mov64 r5, r10                                   r5 = r10
    add64 r5, -1                                    r5 += -1   ///  r5 = r5.wrapping_add(-1 as i32 as i64 as u64)
    mov64 r1, r2                                    r1 = r2
    mov64 r2, r3                                    r2 = r3
    mov64 r3, r0                                    r3 = r0
    syscall [invalid]                       
    jeq r0, 0, lbb_19650                            if r0 == (0 as i32 as i64 as u64) { pc += 14 }
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    stxdw [r10-0x30], r1                    
    lddw r1, 0x1000416e0 --> b"\x00\x00\x00\x00\x14\xef\x03\x001\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00…        r1 load str located at 4295235296
    stxdw [r10-0x38], r1                    
    stxdw [r10-0x18], r7                    
    stxdw [r10-0x20], r7                    
    mov64 r1, 8                                     r1 = 8 as i32 as i64 as u64
    stxdw [r10-0x28], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -56                                   r1 += -56   ///  r1 = r1.wrapping_add(-56 as i32 as i64 as u64)
    lddw r2, 0x1000416f0 --> b"\x00\x00\x00\x00P\xee\x03\x00\x0a\x00\x00\x00\x00\x00\x00\x00d\x02\x00\x0…        r2 load str located at 4295235312
    call function_25805                     
lbb_19650:
    ldxdw r1, [r10-0x20]                    
    stxdw [r6+0x18], r1                     
    ldxdw r1, [r10-0x28]                    
    stxdw [r6+0x10], r1                     
    ldxdw r1, [r10-0x30]                    
    stxdw [r6+0x8], r1                      
    ldxdw r1, [r10-0x38]                    
    stxdw [r6+0x0], r1                      
    ldxb r1, [r10-0x1]                      
    stxb [r6+0x20], r1                      
    exit                                    

function_19661:
    mov64 r8, r2                                    r8 = r2
    mov64 r6, r1                                    r6 = r1
    mov64 r1, r10                                   r1 = r10
    add64 r1, -108                                  r1 += -108   ///  r1 = r1.wrapping_add(-108 as i32 as i64 as u64)
    mov64 r7, 0                                     r7 = 0 as i32 as i64 as u64
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
    mov64 r3, 44                                    r3 = 44 as i32 as i64 as u64
    call function_30383                     
    ldxdw r1, [r8+0x18]                     
    stxdw [r10-0x20], r1                    
    ldxdw r1, [r8+0x10]                     
    stxdw [r10-0x28], r1                    
    ldxdw r1, [r8+0x8]                      
    stxdw [r10-0x30], r1                    
    ldxdw r1, [r8+0x0]                      
    stxdw [r10-0x38], r1                    
    lddw r1, 0x10003ee5a --> b"\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\…        r1 load str located at 4295224922
    stxdw [r10-0x40], r1                    
    mov64 r1, 8                                     r1 = 8 as i32 as i64 as u64
    mov64 r2, r10                                   r2 = r10
    add64 r2, -64                                   r2 += -64   ///  r2 = r2.wrapping_add(-64 as i32 as i64 as u64)
    mov64 r2, 45                                    r2 = 45 as i32 as i64 as u64
    mov64 r3, 58                                    r3 = 58 as i32 as i64 as u64
    ja lbb_19696                                    if true { pc += 10 }
lbb_19686:
    add64 r1, 1                                     r1 += 1   ///  r1 = r1.wrapping_add(1 as i32 as i64 as u64)
    jne r1, 40, lbb_19696                           if r1 != (40 as i32 as i64 as u64) { pc += 8 }
    mov64 r2, r10                                   r2 = r10
    add64 r2, -108                                  r2 += -108   ///  r2 = r2.wrapping_add(-108 as i32 as i64 as u64)
    add64 r2, r7                                    r2 += r7   ///  r2 = r2.wrapping_add(r7)
    mov64 r4, 0                                     r4 = 0 as i32 as i64 as u64
    mov64 r5, r10                                   r5 = r10
    add64 r5, -56                                   r5 += -56   ///  r5 = r5.wrapping_add(-56 as i32 as i64 as u64)
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
    ja lbb_19741                                    if true { pc += 45 }
lbb_19696:
    jgt r2, r7, lbb_19698                           if r2 > r7 { pc += 1 }
    ja lbb_19836                                    if true { pc += 138 }
lbb_19698:
    mov64 r4, r10                                   r4 = r10
    add64 r4, -64                                   r4 += -64   ///  r4 = r4.wrapping_add(-64 as i32 as i64 as u64)
    add64 r4, r1                                    r4 += r1   ///  r4 = r4.wrapping_add(r1)
    ldxb r4, [r4+0x0]                       
    jeq r7, 0, lbb_19719                            if r7 == (0 as i32 as i64 as u64) { pc += 16 }
    mov64 r5, r10                                   r5 = r10
    add64 r5, -108                                  r5 += -108   ///  r5 = r5.wrapping_add(-108 as i32 as i64 as u64)
    mov64 r0, r7                                    r0 = r7
lbb_19706:
    ldxb r8, [r5+0x0]                       
    lsh64 r8, 8                                     r8 <<= 8   ///  r8 = r8.wrapping_shl(8)
    add64 r8, r4                                    r8 += r4   ///  r8 = r8.wrapping_add(r4)
    mov64 r4, r8                                    r4 = r8
    div64 r4, 58                                    r4 /= 58   ///  r4 = r4 / (58 as u64)
    mov64 r9, r4                                    r9 = r4
    mul64 r9, 58                                    r9 *= 58   ///  r9 = r9.wrapping_mul(58 as u64)
    sub64 r8, r9                                    r8 -= r9   ///  r8 = r8.wrapping_sub(r9)
    stxb [r5+0x0], r8                       
    add64 r5, 1                                     r5 += 1   ///  r5 = r5.wrapping_add(1 as i32 as i64 as u64)
    add64 r0, -1                                    r0 += -1   ///  r0 = r0.wrapping_add(-1 as i32 as i64 as u64)
    jeq r0, 0, lbb_19719                            if r0 == (0 as i32 as i64 as u64) { pc += 1 }
    ja lbb_19706                                    if true { pc += -13 }
lbb_19719:
    jeq r4, 0, lbb_19686                            if r4 == (0 as i32 as i64 as u64) { pc += -34 }
lbb_19720:
    mov64 r5, r4                                    r5 = r4
    jeq r7, 44, lbb_19752                           if r7 == (44 as i32 as i64 as u64) { pc += 30 }
    mov64 r4, r5                                    r4 = r5
    div64 r4, 58                                    r4 /= 58   ///  r4 = r4 / (58 as u64)
    mov64 r0, r4                                    r0 = r4
    mul64 r0, 58                                    r0 *= 58   ///  r0 = r0.wrapping_mul(58 as u64)
    mov64 r8, r5                                    r8 = r5
    sub64 r8, r0                                    r8 -= r0   ///  r8 = r8.wrapping_sub(r0)
    mov64 r0, r10                                   r0 = r10
    add64 r0, -108                                  r0 += -108   ///  r0 = r0.wrapping_add(-108 as i32 as i64 as u64)
    add64 r0, r7                                    r0 += r7   ///  r0 = r0.wrapping_add(r7)
    stxb [r0+0x0], r8                       
    add64 r7, 1                                     r7 += 1   ///  r7 = r7.wrapping_add(1 as i32 as i64 as u64)
    jgt r3, r5, lbb_19686                           if r3 > r5 { pc += -48 }
    ja lbb_19720                                    if true { pc += -15 }
lbb_19735:
    jgt r1, 43, lbb_19830                           if r1 > (43 as i32 as i64 as u64) { pc += 94 }
    mov64 r1, r2                                    r1 = r2
    add64 r1, r3                                    r1 += r3   ///  r1 = r1.wrapping_add(r3)
    stxb [r1+0x0], r4                       
    add64 r3, 1                                     r3 += 1   ///  r3 = r3.wrapping_add(1 as i32 as i64 as u64)
    jeq r3, 32, lbb_19784                           if r3 == (32 as i32 as i64 as u64) { pc += 43 }
lbb_19741:
    mov64 r0, r5                                    r0 = r5
    add64 r0, r3                                    r0 += r3   ///  r0 = r0.wrapping_add(r3)
    mov64 r1, r7                                    r1 = r7
    add64 r1, r3                                    r1 += r3   ///  r1 = r1.wrapping_add(r3)
    ldxb r0, [r0+0x0]                       
    jeq r0, 0, lbb_19748                            if r0 == (0 as i32 as i64 as u64) { pc += 1 }
    ja lbb_19762                                    if true { pc += 14 }
lbb_19748:
    mov64 r0, r1                                    r0 = r1
    add64 r0, -44                                   r0 += -44   ///  r0 = r0.wrapping_add(-44 as i32 as i64 as u64)
    jeq r0, 0, lbb_19752                            if r0 == (0 as i32 as i64 as u64) { pc += 1 }
    ja lbb_19735                                    if true { pc += -17 }
lbb_19752:
    mov64 r3, r10                                   r3 = r10
    add64 r3, -1                                    r3 += -1   ///  r3 = r3.wrapping_add(-1 as i32 as i64 as u64)
    lddw r1, 0x10003ef45 --> b"called `Result::unwrap()` on an `Err` value"        r1 load str located at 4295225157
    mov64 r2, 43                                    r2 = 43 as i32 as i64 as u64
    lddw r4, 0x100041758 --> b"\x00\x00\x00\x00\x10e\x02\x00\x00\x00\x00\x00\x00\x00\x00\x00\x01\x00\x00…        r4 load str located at 4295235416
    lddw r5, 0x100041778 --> b"\x00\x00\x00\x00P\xee\x03\x00\x0a\x00\x00\x00\x00\x00\x00\x001\x03\x00\x0…        r5 load str located at 4295235448
    call function_25967                     
lbb_19762:
    mov64 r2, 45                                    r2 = 45 as i32 as i64 as u64
    jgt r2, r1, lbb_19768                           if r2 > r1 { pc += 4 }
    mov64 r2, 44                                    r2 = 44 as i32 as i64 as u64
    lddw r3, 0x100041620 --> b"\x00\x00\x00\x00\x18\xee\x03\x00\x0d\x00\x00\x00\x00\x00\x00\x00\xd0\x01\…        r3 load str located at 4295235104
    call function_28353                     
lbb_19768:
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
    jeq r1, 0, lbb_19771                            if r1 == (0 as i32 as i64 as u64) { pc += 1 }
    ja lbb_19786                                    if true { pc += 15 }
lbb_19771:
    mov64 r1, r10                                   r1 = r10
    add64 r1, -64                                   r1 += -64   ///  r1 = r1.wrapping_add(-64 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -108                                  r2 += -108   ///  r2 = r2.wrapping_add(-108 as i32 as i64 as u64)
    call function_28437                     
    ldxdw r1, [r10-0x40]                    
    jeq r1, 0, lbb_19779                            if r1 == (0 as i32 as i64 as u64) { pc += 1 }
    ja lbb_19841                                    if true { pc += 62 }
lbb_19779:
    ldxdw r3, [r10-0x30]                    
    ldxdw r2, [r10-0x38]                    
    mov64 r1, r6                                    r1 = r6
    call function_27691                     
    exit                                    
lbb_19784:
    add64 r7, r3                                    r7 += r3   ///  r7 = r7.wrapping_add(r3)
    mov64 r1, r7                                    r1 = r7
lbb_19786:
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
lbb_19787:
    mov64 r4, r10                                   r4 = r10
    add64 r4, -108                                  r4 += -108   ///  r4 = r4.wrapping_add(-108 as i32 as i64 as u64)
    add64 r4, r3                                    r4 += r3   ///  r4 = r4.wrapping_add(r3)
    ldxb r2, [r4+0x0]                       
    jgt r2, 57, lbb_19825                           if r2 > (57 as i32 as i64 as u64) { pc += 33 }
    lddw r5, 0x10003ee5a --> b"\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\…        r5 load str located at 4295224922
    add64 r5, r2                                    r5 += r2   ///  r5 = r5.wrapping_add(r2)
    ldxb r2, [r5+0x80]                      
    stxb [r4+0x0], r2                       
    add64 r3, 1                                     r3 += 1   ///  r3 = r3.wrapping_add(1 as i32 as i64 as u64)
    jeq r1, r3, lbb_19800                           if r1 == r3 { pc += 1 }
    ja lbb_19787                                    if true { pc += -13 }
lbb_19800:
    mov64 r3, 1                                     r3 = 1 as i32 as i64 as u64
    jeq r1, 1, lbb_19771                            if r1 == (1 as i32 as i64 as u64) { pc += -31 }
    mov64 r2, r1                                    r2 = r1
    rsh64 r2, 1                                     r2 >>= 1   ///  r2 = r2.wrapping_shr(1)
    mov64 r3, r10                                   r3 = r10
    add64 r3, -108                                  r3 += -108   ///  r3 = r3.wrapping_add(-108 as i32 as i64 as u64)
    mov64 r4, r1                                    r4 = r1
    add64 r4, r3                                    r4 += r3   ///  r4 = r4.wrapping_add(r3)
    add64 r4, -1                                    r4 += -1   ///  r4 = r4.wrapping_add(-1 as i32 as i64 as u64)
lbb_19809:
    ldxb r5, [r3+0x0]                       
    ldxb r0, [r4+0x0]                       
    stxb [r3+0x0], r0                       
    stxb [r4+0x0], r5                       
    add64 r4, -1                                    r4 += -1   ///  r4 = r4.wrapping_add(-1 as i32 as i64 as u64)
    add64 r3, 1                                     r3 += 1   ///  r3 = r3.wrapping_add(1 as i32 as i64 as u64)
    add64 r2, -1                                    r2 += -1   ///  r2 = r2.wrapping_add(-1 as i32 as i64 as u64)
    jeq r2, 0, lbb_19818                            if r2 == (0 as i32 as i64 as u64) { pc += 1 }
    ja lbb_19809                                    if true { pc += -9 }
lbb_19818:
    mov64 r2, 45                                    r2 = 45 as i32 as i64 as u64
    mov64 r3, r1                                    r3 = r1
    jgt r2, r1, lbb_19771                           if r2 > r1 { pc += -50 }
    mov64 r2, 44                                    r2 = 44 as i32 as i64 as u64
    lddw r3, 0x100041708 --> b"\x00\x00\x00\x00P\xee\x03\x00\x0a\x00\x00\x00\x00\x00\x00\x002\x03\x00\x0…        r3 load str located at 4295235336
    call function_28353                     
lbb_19825:
    mov64 r1, r2                                    r1 = r2
    mov64 r2, 58                                    r2 = 58 as i32 as i64 as u64
    lddw r3, 0x100041638 --> b"\x00\x00\x00\x00\x18\xee\x03\x00\x0d\x00\x00\x00\x00\x00\x00\x00\xd1\x01\…        r3 load str located at 4295235128
    call function_25832                     
lbb_19830:
    add64 r7, r3                                    r7 += r3   ///  r7 = r7.wrapping_add(r3)
    mov64 r1, r7                                    r1 = r7
    mov64 r2, 44                                    r2 = 44 as i32 as i64 as u64
    lddw r3, 0x100041650 --> b"\x00\x00\x00\x00\x18\xee\x03\x00\x0d\x00\x00\x00\x00\x00\x00\x00\xcc\x01\…        r3 load str located at 4295235152
    call function_25832                     
lbb_19836:
    mov64 r1, r7                                    r1 = r7
    mov64 r2, 44                                    r2 = 44 as i32 as i64 as u64
    lddw r3, 0x100041668 --> b"\x00\x00\x00\x00\x18\xee\x03\x00\x0d\x00\x00\x00\x00\x00\x00\x00\xb9\x01\…        r3 load str located at 4295235176
    call function_28353                     
lbb_19841:
    ldxdw r1, [r10-0x30]                    
    stxdw [r10-0x10], r1                    
    ldxdw r1, [r10-0x38]                    
    stxdw [r10-0x18], r1                    
    mov64 r3, r10                                   r3 = r10
    add64 r3, -24                                   r3 += -24   ///  r3 = r3.wrapping_add(-24 as i32 as i64 as u64)
    lddw r1, 0x10003ef45 --> b"called `Result::unwrap()` on an `Err` value"        r1 load str located at 4295225157
    mov64 r2, 43                                    r2 = 43 as i32 as i64 as u64
    lddw r4, 0x100041720 --> b"\x00\x00\x00\x00\x08e\x02\x00\x10\x00\x00\x00\x00\x00\x00\x00\x08\x00\x00…        r4 load str located at 4295235360
    lddw r5, 0x100041740 --> b"\x00\x00\x00\x00P\xee\x03\x00\x0a\x00\x00\x00\x00\x00\x00\x002\x03\x00\x0…        r5 load str located at 4295235392
    call function_25967                     

function_19855:
    mov64 r3, r1                                    r3 = r1
    mov64 r1, r2                                    r1 = r2
    mov64 r2, r3                                    r2 = r3
    call function_19661                     
    exit                                    

function_19860:
    mov64 r6, r1                                    r6 = r1
    stxdw [r10-0x28], r3                    
    stxdw [r10-0x30], r2                    
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    stxdw [r10-0x8], r1                     
    stxdw [r10-0x10], r1                    
    stxdw [r10-0x18], r1                    
    stxdw [r10-0x20], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -48                                   r1 += -48   ///  r1 = r1.wrapping_add(-48 as i32 as i64 as u64)
    mov64 r3, r10                                   r3 = r10
    add64 r3, -32                                   r3 += -32   ///  r3 = r3.wrapping_add(-32 as i32 as i64 as u64)
    mov64 r2, 1                                     r2 = 1 as i32 as i64 as u64
    syscall [invalid]                       
    ldxdw r1, [r10-0x20]                    
    stxdw [r6+0x0], r1                      
    ldxdw r1, [r10-0x18]                    
    stxdw [r6+0x8], r1                      
    ldxdw r1, [r10-0x10]                    
    stxdw [r6+0x10], r1                     
    ldxdw r1, [r10-0x8]                     
    stxdw [r6+0x18], r1                     
    exit                                    

function_19883:
    mov64 r3, r2                                    r3 = r2
    ldxdw r2, [r1+0x8]                      
    ldxdw r1, [r1+0x0]                      
    call function_27859                     
    exit                                    

function_19888:
    mov64 r3, r2                                    r3 = r2
    lddw r2, 0x100041790 --> b"\x00\x00\x00\x00\xc8n\x02\x00\x10\x00\x00\x00\x00\x00\x00\x00\x08\x00\x00…        r2 load str located at 4295235472
    call function_26898                     
    exit                                    

function_19893:
    exit                                    

function_19894:
    ldxb r3, [r1+0x0]                       
    jsgt r3, 8, lbb_19916                           if (r3 as i64) > (8 as i32 as i64) { pc += 20 }
    jsgt r3, 3, lbb_19925                           if (r3 as i64) > (3 as i32 as i64) { pc += 28 }
    jsgt r3, 1, lbb_19969                           if (r3 as i64) > (1 as i32 as i64) { pc += 71 }
    jeq r3, 0, lbb_20010                            if r3 == (0 as i32 as i64 as u64) { pc += 111 }
    ldxdw r1, [r1+0x8]                      
    stxdw [r10-0x50], r1                    
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    stxdw [r10-0x20], r1                    
    mov64 r1, 2                                     r1 = 2 as i32 as i64 as u64
    stxdw [r10-0x38], r1                    
    lddw r1, 0x1000417e0 --> b"\x00\x00\x00\x00\xb4\xef\x03\x00\x09\x00\x00\x00\x00\x00\x00\x00\x00\x00\…        r1 load str located at 4295235552
    stxdw [r10-0x40], r1                    
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    stxdw [r10-0x28], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -16                                   r1 += -16   ///  r1 = r1.wrapping_add(-16 as i32 as i64 as u64)
    stxdw [r10-0x30], r1                    
    lddw r1, 0x10003b1e0 --> b"\xbf#\x00\x00\x00\x00\x00\x00y\x11\x00\x00\x00\x00\x00\x00\xb7\x02\x00\x0…        r1 load str located at 4295209440
    ja lbb_20084                                    if true { pc += 168 }
lbb_19916:
    jsgt r3, 12, lbb_19945                          if (r3 as i64) > (12 as i32 as i64) { pc += 28 }
    jsgt r3, 10, lbb_19991                          if (r3 as i64) > (10 as i32 as i64) { pc += 73 }
    jeq r3, 9, lbb_20027                            if r3 == (9 as i32 as i64 as u64) { pc += 108 }
    mov64 r1, r2                                    r1 = r2
    lddw r2, 0x10003ef70 --> b"sequence"            r2 load str located at 4295225200
    mov64 r3, 8                                     r3 = 8 as i32 as i64 as u64
    call function_27691                     
    ja lbb_20094                                    if true { pc += 169 }
lbb_19925:
    jsgt r3, 5, lbb_19953                           if (r3 as i64) > (5 as i32 as i64) { pc += 27 }
    jeq r3, 4, lbb_20068                            if r3 == (4 as i32 as i64 as u64) { pc += 141 }
    ldxdw r3, [r1+0x8]                      
    ldxdw r1, [r1+0x10]                     
    stxdw [r10-0x48], r1                    
    stxdw [r10-0x50], r3                    
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    stxdw [r10-0x20], r1                    
    lddw r1, 0x100041840 --> b"\x00\x00\x00\x00\xc8\xef\x03\x00\x07\x00\x00\x00\x00\x00\x00\x00\x00\x00\…        r1 load str located at 4295235648
    stxdw [r10-0x40], r1                    
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    stxdw [r10-0x38], r1                    
    stxdw [r10-0x28], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -16                                   r1 += -16   ///  r1 = r1.wrapping_add(-16 as i32 as i64 as u64)
    stxdw [r10-0x30], r1                    
    lddw r1, 0x100026e78 --> b"\xbf#\x00\x00\x00\x00\x00\x00y\x12\x08\x00\x00\x00\x00\x00y\x11\x00\x00\x…        r1 load str located at 4295126648
    ja lbb_20084                                    if true { pc += 139 }
lbb_19945:
    jsgt r3, 14, lbb_19961                          if (r3 as i64) > (14 as i32 as i64) { pc += 15 }
    jeq r3, 13, lbb_20095                           if r3 == (13 as i32 as i64 as u64) { pc += 148 }
    mov64 r1, r2                                    r1 = r2
    lddw r2, 0x10003f002 --> b"newtype variant"        r2 load str located at 4295225346
    mov64 r3, 15                                    r3 = 15 as i32 as i64 as u64
    call function_27691                     
    ja lbb_20094                                    if true { pc += 141 }
lbb_19953:
    jeq r3, 6, lbb_19998                            if r3 == (6 as i32 as i64 as u64) { pc += 44 }
    jeq r3, 7, lbb_20056                            if r3 == (7 as i32 as i64 as u64) { pc += 101 }
    mov64 r1, r2                                    r1 = r2
    lddw r2, 0x10003efd9 --> b"Option value"        r2 load str located at 4295225305
    mov64 r3, 12                                    r3 = 12 as i32 as i64 as u64
    call function_27691                     
    ja lbb_20094                                    if true { pc += 133 }
lbb_19961:
    jeq r3, 15, lbb_20004                           if r3 == (15 as i32 as i64 as u64) { pc += 42 }
    jeq r3, 16, lbb_20062                           if r3 == (16 as i32 as i64 as u64) { pc += 99 }
    ldxdw r3, [r1+0x10]                     
    ldxdw r4, [r1+0x8]                      
    mov64 r1, r2                                    r1 = r2
    mov64 r2, r4                                    r2 = r4
    call function_27691                     
    ja lbb_20094                                    if true { pc += 125 }
lbb_19969:
    jeq r3, 2, lbb_20033                            if r3 == (2 as i32 as i64 as u64) { pc += 63 }
    ldxdw r1, [r1+0x8]                      
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
    stxdw [r10-0x20], r3                    
    mov64 r3, 2                                     r3 = 2 as i32 as i64 as u64
    stxdw [r10-0x38], r3                    
    lddw r3, 0x100041800 --> b"\x00\x00\x00\x00\xe0\xe7\x03\x00\x10\x00\x00\x00\x00\x00\x00\x00\x00\x00\…        r3 load str located at 4295235584
    stxdw [r10-0x40], r3                    
    mov64 r3, 1                                     r3 = 1 as i32 as i64 as u64
    stxdw [r10-0x28], r3                    
    mov64 r3, r10                                   r3 = r10
    add64 r3, -16                                   r3 += -16   ///  r3 = r3.wrapping_add(-16 as i32 as i64 as u64)
    stxdw [r10-0x30], r3                    
    lddw r3, 0x100027598 --> b"\xbf&\x00\x00\x00\x00\x00\x00\xbf\x17\x00\x00\x00\x00\x00\x00yq\x00\x00\x…        r3 load str located at 4295128472
    stxdw [r10-0x8], r3                     
    mov64 r3, r10                                   r3 = r10
    add64 r3, -80                                   r3 += -80   ///  r3 = r3.wrapping_add(-80 as i32 as i64 as u64)
    stxdw [r10-0x10], r3                    
    stxdw [r10-0x50], r1                    
    ja lbb_20088                                    if true { pc += 97 }
lbb_19991:
    jeq r3, 11, lbb_20050                           if r3 == (11 as i32 as i64 as u64) { pc += 58 }
    mov64 r1, r2                                    r1 = r2
    lddw r2, 0x10003edca --> b"enum"                r2 load str located at 4295224778
    mov64 r3, 4                                     r3 = 4 as i32 as i64 as u64
    call function_27691                     
    ja lbb_20094                                    if true { pc += 96 }
lbb_19998:
    mov64 r1, r2                                    r1 = r2
    lddw r2, 0x10003efa0 --> b"byte array"          r2 load str located at 4295225248
    mov64 r3, 10                                    r3 = 10 as i32 as i64 as u64
    call function_27691                     
    ja lbb_20094                                    if true { pc += 90 }
lbb_20004:
    mov64 r1, r2                                    r1 = r2
    lddw r2, 0x10003f011 --> b"tuple variant"        r2 load str located at 4295225361
    mov64 r3, 13                                    r3 = 13 as i32 as i64 as u64
    call function_27691                     
    ja lbb_20094                                    if true { pc += 84 }
lbb_20010:
    ldxb r1, [r1+0x1]                       
    stxb [r10-0x50], r1                     
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    stxdw [r10-0x20], r1                    
    mov64 r1, 2                                     r1 = 2 as i32 as i64 as u64
    stxdw [r10-0x38], r1                    
    lddw r1, 0x1000417c0 --> b"\x00\x00\x00\x00\xaa\xef\x03\x00\x09\x00\x00\x00\x00\x00\x00\x00\x00\x00\…        r1 load str located at 4295235520
    stxdw [r10-0x40], r1                    
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    stxdw [r10-0x28], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -16                                   r1 += -16   ///  r1 = r1.wrapping_add(-16 as i32 as i64 as u64)
    stxdw [r10-0x30], r1                    
    lddw r1, 0x100036750 --> b"q\x11\x00\x00\x00\x00\x00\x00U\x01\x05\x00\x00\x00\x00\x00\xbf!\x00\x00\x…        r1 load str located at 4295190352
    ja lbb_20084                                    if true { pc += 57 }
lbb_20027:
    mov64 r1, r2                                    r1 = r2
    lddw r2, 0x10003efe5 --> b"newtype struct"        r2 load str located at 4295225317
    mov64 r3, 14                                    r3 = 14 as i32 as i64 as u64
    call function_27691                     
    ja lbb_20094                                    if true { pc += 61 }
lbb_20033:
    ldxdw r1, [r1+0x8]                      
    stxdw [r10-0x50], r1                    
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    stxdw [r10-0x20], r1                    
    mov64 r1, 2                                     r1 = 2 as i32 as i64 as u64
    stxdw [r10-0x38], r1                    
    lddw r1, 0x1000417e0 --> b"\x00\x00\x00\x00\xb4\xef\x03\x00\x09\x00\x00\x00\x00\x00\x00\x00\x00\x00\…        r1 load str located at 4295235552
    stxdw [r10-0x40], r1                    
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    stxdw [r10-0x28], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -16                                   r1 += -16   ///  r1 = r1.wrapping_add(-16 as i32 as i64 as u64)
    stxdw [r10-0x30], r1                    
    lddw r1, 0x10003b188 --> b"\xbf#\x00\x00\x00\x00\x00\x00y\x12\x00\x00\x00\x00\x00\x00\xbf$\x00\x00\x…        r1 load str located at 4295209352
    ja lbb_20084                                    if true { pc += 34 }
lbb_20050:
    mov64 r1, r2                                    r1 = r2
    lddw r2, 0x10003eff3 --> b"map"                 r2 load str located at 4295225331
    mov64 r3, 3                                     r3 = 3 as i32 as i64 as u64
    call function_27691                     
    ja lbb_20094                                    if true { pc += 38 }
lbb_20056:
    mov64 r1, r2                                    r1 = r2
    lddw r2, 0x10003efcf --> b"unit value"          r2 load str located at 4295225295
    mov64 r3, 10                                    r3 = 10 as i32 as i64 as u64
    call function_27691                     
    ja lbb_20094                                    if true { pc += 32 }
lbb_20062:
    mov64 r1, r2                                    r1 = r2
    lddw r2, 0x10003f01e --> b"struct variant"        r2 load str located at 4295225374
    mov64 r3, 14                                    r3 = 14 as i32 as i64 as u64
    call function_27691                     
    ja lbb_20094                                    if true { pc += 26 }
lbb_20068:
    ldxw r1, [r1+0x4]                       
    stxw [r10-0x50], r1                     
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    stxdw [r10-0x20], r1                    
    mov64 r1, 2                                     r1 = 2 as i32 as i64 as u64
    stxdw [r10-0x38], r1                    
    lddw r1, 0x100041820 --> b"\x00\x00\x00\x00\xbd\xef\x03\x00\x0b\x00\x00\x00\x00\x00\x00\x00\x00\x00\…        r1 load str located at 4295235616
    stxdw [r10-0x40], r1                    
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    stxdw [r10-0x28], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -16                                   r1 += -16   ///  r1 = r1.wrapping_add(-16 as i32 as i64 as u64)
    stxdw [r10-0x30], r1                    
    lddw r1, 0x1000371b0 --> b"y#\x10\x00\x00\x00\x00\x00y$\x00\x00\x00\x00\x00\x00O4\x00\x00\x00\x00\x0…        r1 load str located at 4295193008
lbb_20084:
    stxdw [r10-0x8], r1                     
    mov64 r1, r10                                   r1 = r10
    add64 r1, -80                                   r1 += -80   ///  r1 = r1.wrapping_add(-80 as i32 as i64 as u64)
    stxdw [r10-0x10], r1                    
lbb_20088:
    ldxdw r4, [r2+0x28]                     
    ldxdw r1, [r2+0x20]                     
    mov64 r3, r10                                   r3 = r10
    add64 r3, -64                                   r3 += -64   ///  r3 = r3.wrapping_add(-64 as i32 as i64 as u64)
    mov64 r2, r4                                    r2 = r4
    call function_26898                     
lbb_20094:
    exit                                    
lbb_20095:
    mov64 r1, r2                                    r1 = r2
    lddw r2, 0x10003eff6 --> b"unit variant"        r2 load str located at 4295225334
    mov64 r3, 12                                    r3 = 12 as i32 as i64 as u64
    call function_27691                     
    ja lbb_20094                                    if true { pc += -7 }

function_20101:
    mov64 r4, r2                                    r4 = r2
    ldxdw r3, [r1+0x8]                      
    ldxdw r2, [r1+0x0]                      
    mov64 r1, r4                                    r1 = r4
    call function_27691                     
    exit                                    

function_20107:
    ldxdw r4, [r2+0x18]                     
    mov64 r2, r3                                    r2 = r3
    callx r4                                
    exit                                    

function_20111:
    mov64 r6, r2                                    r6 = r2
    mov64 r7, r1                                    r7 = r1
    ldxdw r1, [r7+0x0]                      
    lddw r2, 0x7fffffffffffffff                     r2 load str located at 9223372036854775807
    and64 r1, r2                                    r1 &= r2   ///  r1 = r1.and(r2)
    lddw r2, 0x7ff0000000000000                     r2 load str located at 9218868437227405312
    call function_31794                     
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    jsgt r1, r0, lbb_20142                          if (r1 as i64) > (r0 as i64) { pc += 20 }
    stxdw [r10-0x20], r1                    
    lddw r1, 0x10003e790 --> b"\x01\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00Permissio…        r1 load str located at 4295223184
    stxdw [r10-0x40], r1                    
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    stxdw [r10-0x38], r1                    
    stxdw [r10-0x28], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -16                                   r1 += -16   ///  r1 = r1.wrapping_add(-16 as i32 as i64 as u64)
    stxdw [r10-0x30], r1                    
    lddw r1, 0x100039f98 --> b"\xbf%\x00\x00\x00\x00\x00\x00y\x12\x00\x00\x00\x00\x00\x00aS4\x00\x00\x00…        r1 load str located at 4295204760
    stxdw [r10-0x8], r1                     
    stxdw [r10-0x10], r7                    
    ldxdw r2, [r6+0x28]                     
    ldxdw r1, [r6+0x20]                     
    mov64 r3, r10                                   r3 = r10
    add64 r3, -64                                   r3 += -64   ///  r3 = r3.wrapping_add(-64 as i32 as i64 as u64)
    call function_26898                     
    ja lbb_20177                                    if true { pc += 35 }
lbb_20142:
    stxdw [r10-0x50], r6                    
    stxb [r10-0x48], r1                     
    stxdw [r10-0x20], r1                    
    lddw r1, 0x10003e790 --> b"\x01\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00Permissio…        r1 load str located at 4295223184
    stxdw [r10-0x40], r1                    
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    stxdw [r10-0x38], r1                    
    stxdw [r10-0x28], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -16                                   r1 += -16   ///  r1 = r1.wrapping_add(-16 as i32 as i64 as u64)
    stxdw [r10-0x30], r1                    
    lddw r1, 0x100039f98 --> b"\xbf%\x00\x00\x00\x00\x00\x00y\x12\x00\x00\x00\x00\x00\x00aS4\x00\x00\x00…        r1 load str located at 4295204760
    stxdw [r10-0x8], r1                     
    stxdw [r10-0x10], r7                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -80                                   r1 += -80   ///  r1 = r1.wrapping_add(-80 as i32 as i64 as u64)
    mov64 r3, r10                                   r3 = r10
    add64 r3, -64                                   r3 += -64   ///  r3 = r3.wrapping_add(-64 as i32 as i64 as u64)
    lddw r2, 0x100041790 --> b"\x00\x00\x00\x00\xc8n\x02\x00\x10\x00\x00\x00\x00\x00\x00\x00\x08\x00\x00…        r2 load str located at 4295235472
    call function_26898                     
    jne r0, 0, lbb_20176                            if r0 != (0 as i32 as i64 as u64) { pc += 10 }
    ldxb r1, [r10-0x48]                     
    jne r1, 0, lbb_20174                            if r1 != (0 as i32 as i64 as u64) { pc += 6 }
    mov64 r1, r6                                    r1 = r6
    lddw r2, 0x10003f02c --> b".0"                  r2 load str located at 4295225388
    mov64 r3, 2                                     r3 = 2 as i32 as i64 as u64
    call function_27691                     
    jne r0, 0, lbb_20176                            if r0 != (0 as i32 as i64 as u64) { pc += 2 }
lbb_20174:
    mov64 r0, 0                                     r0 = 0 as i32 as i64 as u64
    ja lbb_20177                                    if true { pc += 1 }
lbb_20176:
    mov64 r0, 1                                     r0 = 1 as i32 as i64 as u64
lbb_20177:
    exit                                    

function_20178:
    mov64 r6, r3                                    r6 = r3
    mov64 r7, r2                                    r7 = r2
    mov64 r8, r1                                    r8 = r1
    mov64 r1, 16                                    r1 = 16 as i32 as i64 as u64
    jgt r1, r6, lbb_20194                           if r1 > r6 { pc += 11 }
    mov64 r1, r10                                   r1 = r10
    add64 r1, -16                                   r1 += -16   ///  r1 = r1.wrapping_add(-16 as i32 as i64 as u64)
    mov64 r2, 46                                    r2 = 46 as i32 as i64 as u64
    mov64 r3, r7                                    r3 = r7
    mov64 r4, r6                                    r4 = r6
    call function_28250                     
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    ldxdw r2, [r10-0x10]                    
    jeq r2, 1, lbb_20201                            if r2 == (1 as i32 as i64 as u64) { pc += 9 }
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    ja lbb_20201                                    if true { pc += 7 }
lbb_20194:
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    jeq r6, 0, lbb_20201                            if r6 == (0 as i32 as i64 as u64) { pc += 5 }
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
    ja lbb_20206                                    if true { pc += 8 }
lbb_20198:
    jeq r3, 46, lbb_20201                           if r3 == (46 as i32 as i64 as u64) { pc += 2 }
    add64 r2, 1                                     r2 += 1   ///  r2 = r2.wrapping_add(1 as i32 as i64 as u64)
    jgt r6, r2, lbb_20206                           if r6 > r2 { pc += 5 }
lbb_20201:
    ldxb r3, [r8+0x8]                       
    mov64 r2, 1                                     r2 = 1 as i32 as i64 as u64
    jne r3, 0, lbb_20213                            if r3 != (0 as i32 as i64 as u64) { pc += 9 }
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
    ja lbb_20213                                    if true { pc += 7 }
lbb_20206:
    mov64 r1, r7                                    r1 = r7
    add64 r1, r2                                    r1 += r2   ///  r1 = r1.wrapping_add(r2)
    ldxb r3, [r1+0x0]                       
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    jeq r3, 46, lbb_20198                           if r3 == (46 as i32 as i64 as u64) { pc += -13 }
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    ja lbb_20198                                    if true { pc += -15 }
lbb_20213:
    or64 r1, r2                                     r1 |= r2   ///  r1 = r1.or(r2)
    and64 r1, 1                                     r1 &= 1   ///  r1 = r1.and(1)
    stxb [r8+0x8], r1                       
    ldxdw r1, [r8+0x0]                      
    mov64 r2, r7                                    r2 = r7
    mov64 r3, r6                                    r3 = r6
    call function_27691                     
    exit                                    

function_20221:
    ldxb r5, [r1+0x8]                       
    mov64 r3, 1                                     r3 = 1 as i32 as i64 as u64
    mov64 r4, 1                                     r4 = 1 as i32 as i64 as u64
    jne r5, 0, lbb_20226                            if r5 != (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r4, 0                                     r4 = 0 as i32 as i64 as u64
lbb_20226:
    mov64 r5, r2                                    r5 = r2
    lsh64 r5, 32                                    r5 <<= 32   ///  r5 = r5.wrapping_shl(32)
    rsh64 r5, 32                                    r5 >>= 32   ///  r5 = r5.wrapping_shr(32)
    jeq r5, 46, lbb_20231                           if r5 == (46 as i32 as i64 as u64) { pc += 1 }
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
lbb_20231:
    or64 r3, r4                                     r3 |= r4   ///  r3 = r3.or(r4)
    stxb [r1+0x8], r3                       
    ldxdw r1, [r1+0x0]                      
    call function_27840                     
    exit                                    

function_20236:
    lsh64 r1, 32                                    r1 <<= 32   ///  r1 = r1.wrapping_shl(32)
    rsh64 r1, 32                                    r1 >>= 32   ///  r1 = r1.wrapping_shr(32)
    jsgt r1, 19, lbb_20248                          if (r1 as i64) > (19 as i32 as i64) { pc += 9 }
    jsgt r1, 9, lbb_20263                           if (r1 as i64) > (9 as i32 as i64) { pc += 23 }
    jsgt r1, 4, lbb_20283                           if (r1 as i64) > (4 as i32 as i64) { pc += 42 }
    jsgt r1, 1, lbb_20319                           if (r1 as i64) > (1 as i32 as i64) { pc += 77 }
    mov64 r0, 0                                     r0 = 0 as i32 as i64 as u64
    jeq r1, 0, lbb_20392                            if r1 == (0 as i32 as i64 as u64) { pc += 148 }
    jeq r1, 1, lbb_20246                            if r1 == (1 as i32 as i64 as u64) { pc += 1 }
    ja lbb_20391                                    if true { pc += 145 }
lbb_20246:
    mov64 r0, 1                                     r0 = 1 as i32 as i64 as u64
    ja lbb_20392                                    if true { pc += 144 }
lbb_20248:
    jsgt r1, 29, lbb_20256                          if (r1 as i64) > (29 as i32 as i64) { pc += 7 }
    jsgt r1, 24, lbb_20277                          if (r1 as i64) > (24 as i32 as i64) { pc += 27 }
    jsgt r1, 21, lbb_20295                          if (r1 as i64) > (21 as i32 as i64) { pc += 44 }
    jeq r1, 20, lbb_20343                           if r1 == (20 as i32 as i64 as u64) { pc += 91 }
    jeq r1, 21, lbb_20254                           if r1 == (21 as i32 as i64 as u64) { pc += 1 }
    ja lbb_20391                                    if true { pc += 137 }
lbb_20254:
    mov64 r0, 21                                    r0 = 21 as i32 as i64 as u64
    ja lbb_20392                                    if true { pc += 136 }
lbb_20256:
    jsgt r1, 34, lbb_20270                          if (r1 as i64) > (34 as i32 as i64) { pc += 13 }
    jsgt r1, 31, lbb_20313                          if (r1 as i64) > (31 as i32 as i64) { pc += 55 }
    jeq r1, 30, lbb_20355                           if r1 == (30 as i32 as i64 as u64) { pc += 96 }
    jeq r1, 31, lbb_20261                           if r1 == (31 as i32 as i64 as u64) { pc += 1 }
    ja lbb_20391                                    if true { pc += 130 }
lbb_20261:
    mov64 r0, 31                                    r0 = 31 as i32 as i64 as u64
    ja lbb_20392                                    if true { pc += 129 }
lbb_20263:
    jsgt r1, 14, lbb_20289                          if (r1 as i64) > (14 as i32 as i64) { pc += 25 }
    jsgt r1, 11, lbb_20325                          if (r1 as i64) > (11 as i32 as i64) { pc += 60 }
    jeq r1, 10, lbb_20367                           if r1 == (10 as i32 as i64 as u64) { pc += 101 }
    jeq r1, 11, lbb_20268                           if r1 == (11 as i32 as i64 as u64) { pc += 1 }
    ja lbb_20391                                    if true { pc += 123 }
lbb_20268:
    mov64 r0, 11                                    r0 = 11 as i32 as i64 as u64
    ja lbb_20392                                    if true { pc += 122 }
lbb_20270:
    jsgt r1, 37, lbb_20307                          if (r1 as i64) > (37 as i32 as i64) { pc += 36 }
    jeq r1, 35, lbb_20363                           if r1 == (35 as i32 as i64 as u64) { pc += 91 }
    jeq r1, 36, lbb_20351                           if r1 == (36 as i32 as i64 as u64) { pc += 78 }
    jeq r1, 37, lbb_20275                           if r1 == (37 as i32 as i64 as u64) { pc += 1 }
    ja lbb_20391                                    if true { pc += 116 }
lbb_20275:
    mov64 r0, 37                                    r0 = 37 as i32 as i64 as u64
    ja lbb_20392                                    if true { pc += 115 }
lbb_20277:
    jsgt r1, 26, lbb_20301                          if (r1 as i64) > (26 as i32 as i64) { pc += 23 }
    jeq r1, 25, lbb_20345                           if r1 == (25 as i32 as i64 as u64) { pc += 66 }
    jeq r1, 26, lbb_20281                           if r1 == (26 as i32 as i64 as u64) { pc += 1 }
    ja lbb_20391                                    if true { pc += 110 }
lbb_20281:
    mov64 r0, 26                                    r0 = 26 as i32 as i64 as u64
    ja lbb_20392                                    if true { pc += 109 }
lbb_20283:
    jsgt r1, 6, lbb_20331                           if (r1 as i64) > (6 as i32 as i64) { pc += 47 }
    jeq r1, 5, lbb_20369                            if r1 == (5 as i32 as i64 as u64) { pc += 84 }
    jeq r1, 6, lbb_20287                            if r1 == (6 as i32 as i64 as u64) { pc += 1 }
    ja lbb_20391                                    if true { pc += 104 }
lbb_20287:
    mov64 r0, 6                                     r0 = 6 as i32 as i64 as u64
    ja lbb_20392                                    if true { pc += 103 }
lbb_20289:
    jsgt r1, 16, lbb_20337                          if (r1 as i64) > (16 as i32 as i64) { pc += 47 }
    jeq r1, 15, lbb_20371                           if r1 == (15 as i32 as i64 as u64) { pc += 80 }
    jeq r1, 16, lbb_20293                           if r1 == (16 as i32 as i64 as u64) { pc += 1 }
    ja lbb_20391                                    if true { pc += 98 }
lbb_20293:
    mov64 r0, 16                                    r0 = 16 as i32 as i64 as u64
    ja lbb_20392                                    if true { pc += 97 }
lbb_20295:
    jeq r1, 22, lbb_20357                           if r1 == (22 as i32 as i64 as u64) { pc += 61 }
    jeq r1, 23, lbb_20347                           if r1 == (23 as i32 as i64 as u64) { pc += 50 }
    jeq r1, 24, lbb_20299                           if r1 == (24 as i32 as i64 as u64) { pc += 1 }
    ja lbb_20391                                    if true { pc += 92 }
lbb_20299:
    mov64 r0, 24                                    r0 = 24 as i32 as i64 as u64
    ja lbb_20392                                    if true { pc += 91 }
lbb_20301:
    jeq r1, 27, lbb_20359                           if r1 == (27 as i32 as i64 as u64) { pc += 57 }
    jeq r1, 28, lbb_20349                           if r1 == (28 as i32 as i64 as u64) { pc += 46 }
    jeq r1, 29, lbb_20305                           if r1 == (29 as i32 as i64 as u64) { pc += 1 }
    ja lbb_20391                                    if true { pc += 86 }
lbb_20305:
    mov64 r0, 29                                    r0 = 29 as i32 as i64 as u64
    ja lbb_20392                                    if true { pc += 85 }
lbb_20307:
    jeq r1, 38, lbb_20365                           if r1 == (38 as i32 as i64 as u64) { pc += 57 }
    jeq r1, 39, lbb_20353                           if r1 == (39 as i32 as i64 as u64) { pc += 44 }
    jeq r1, 40, lbb_20311                           if r1 == (40 as i32 as i64 as u64) { pc += 1 }
    ja lbb_20391                                    if true { pc += 80 }
lbb_20311:
    mov64 r0, 40                                    r0 = 40 as i32 as i64 as u64
    ja lbb_20392                                    if true { pc += 79 }
lbb_20313:
    jeq r1, 32, lbb_20381                           if r1 == (32 as i32 as i64 as u64) { pc += 67 }
    jeq r1, 33, lbb_20361                           if r1 == (33 as i32 as i64 as u64) { pc += 46 }
    jeq r1, 34, lbb_20317                           if r1 == (34 as i32 as i64 as u64) { pc += 1 }
    ja lbb_20391                                    if true { pc += 74 }
lbb_20317:
    mov64 r0, 34                                    r0 = 34 as i32 as i64 as u64
    ja lbb_20392                                    if true { pc += 73 }
lbb_20319:
    jeq r1, 2, lbb_20383                            if r1 == (2 as i32 as i64 as u64) { pc += 63 }
    jeq r1, 3, lbb_20373                            if r1 == (3 as i32 as i64 as u64) { pc += 52 }
    jeq r1, 4, lbb_20323                            if r1 == (4 as i32 as i64 as u64) { pc += 1 }
    ja lbb_20391                                    if true { pc += 68 }
lbb_20323:
    mov64 r0, 4                                     r0 = 4 as i32 as i64 as u64
    ja lbb_20392                                    if true { pc += 67 }
lbb_20325:
    jeq r1, 12, lbb_20385                           if r1 == (12 as i32 as i64 as u64) { pc += 59 }
    jeq r1, 13, lbb_20375                           if r1 == (13 as i32 as i64 as u64) { pc += 48 }
    jeq r1, 14, lbb_20329                           if r1 == (14 as i32 as i64 as u64) { pc += 1 }
    ja lbb_20391                                    if true { pc += 62 }
lbb_20329:
    mov64 r0, 14                                    r0 = 14 as i32 as i64 as u64
    ja lbb_20392                                    if true { pc += 61 }
lbb_20331:
    jeq r1, 7, lbb_20387                            if r1 == (7 as i32 as i64 as u64) { pc += 55 }
    jeq r1, 8, lbb_20377                            if r1 == (8 as i32 as i64 as u64) { pc += 44 }
    jeq r1, 9, lbb_20335                            if r1 == (9 as i32 as i64 as u64) { pc += 1 }
    ja lbb_20391                                    if true { pc += 56 }
lbb_20335:
    mov64 r0, 9                                     r0 = 9 as i32 as i64 as u64
    ja lbb_20392                                    if true { pc += 55 }
lbb_20337:
    jeq r1, 17, lbb_20389                           if r1 == (17 as i32 as i64 as u64) { pc += 51 }
    jeq r1, 18, lbb_20379                           if r1 == (18 as i32 as i64 as u64) { pc += 40 }
    jeq r1, 19, lbb_20341                           if r1 == (19 as i32 as i64 as u64) { pc += 1 }
    ja lbb_20391                                    if true { pc += 50 }
lbb_20341:
    mov64 r0, 19                                    r0 = 19 as i32 as i64 as u64
    ja lbb_20392                                    if true { pc += 49 }
lbb_20343:
    mov64 r0, 20                                    r0 = 20 as i32 as i64 as u64
    ja lbb_20392                                    if true { pc += 47 }
lbb_20345:
    mov64 r0, 25                                    r0 = 25 as i32 as i64 as u64
    ja lbb_20392                                    if true { pc += 45 }
lbb_20347:
    mov64 r0, 23                                    r0 = 23 as i32 as i64 as u64
    ja lbb_20392                                    if true { pc += 43 }
lbb_20349:
    mov64 r0, 28                                    r0 = 28 as i32 as i64 as u64
    ja lbb_20392                                    if true { pc += 41 }
lbb_20351:
    mov64 r0, 36                                    r0 = 36 as i32 as i64 as u64
    ja lbb_20392                                    if true { pc += 39 }
lbb_20353:
    mov64 r0, 39                                    r0 = 39 as i32 as i64 as u64
    ja lbb_20392                                    if true { pc += 37 }
lbb_20355:
    mov64 r0, 30                                    r0 = 30 as i32 as i64 as u64
    ja lbb_20392                                    if true { pc += 35 }
lbb_20357:
    mov64 r0, 22                                    r0 = 22 as i32 as i64 as u64
    ja lbb_20392                                    if true { pc += 33 }
lbb_20359:
    mov64 r0, 27                                    r0 = 27 as i32 as i64 as u64
    ja lbb_20392                                    if true { pc += 31 }
lbb_20361:
    mov64 r0, 33                                    r0 = 33 as i32 as i64 as u64
    ja lbb_20392                                    if true { pc += 29 }
lbb_20363:
    mov64 r0, 35                                    r0 = 35 as i32 as i64 as u64
    ja lbb_20392                                    if true { pc += 27 }
lbb_20365:
    mov64 r0, 38                                    r0 = 38 as i32 as i64 as u64
    ja lbb_20392                                    if true { pc += 25 }
lbb_20367:
    mov64 r0, 10                                    r0 = 10 as i32 as i64 as u64
    ja lbb_20392                                    if true { pc += 23 }
lbb_20369:
    mov64 r0, 5                                     r0 = 5 as i32 as i64 as u64
    ja lbb_20392                                    if true { pc += 21 }
lbb_20371:
    mov64 r0, 15                                    r0 = 15 as i32 as i64 as u64
    ja lbb_20392                                    if true { pc += 19 }
lbb_20373:
    mov64 r0, 3                                     r0 = 3 as i32 as i64 as u64
    ja lbb_20392                                    if true { pc += 17 }
lbb_20375:
    mov64 r0, 13                                    r0 = 13 as i32 as i64 as u64
    ja lbb_20392                                    if true { pc += 15 }
lbb_20377:
    mov64 r0, 8                                     r0 = 8 as i32 as i64 as u64
    ja lbb_20392                                    if true { pc += 13 }
lbb_20379:
    mov64 r0, 18                                    r0 = 18 as i32 as i64 as u64
    ja lbb_20392                                    if true { pc += 11 }
lbb_20381:
    mov64 r0, 32                                    r0 = 32 as i32 as i64 as u64
    ja lbb_20392                                    if true { pc += 9 }
lbb_20383:
    mov64 r0, 2                                     r0 = 2 as i32 as i64 as u64
    ja lbb_20392                                    if true { pc += 7 }
lbb_20385:
    mov64 r0, 12                                    r0 = 12 as i32 as i64 as u64
    ja lbb_20392                                    if true { pc += 5 }
lbb_20387:
    mov64 r0, 7                                     r0 = 7 as i32 as i64 as u64
    ja lbb_20392                                    if true { pc += 3 }
lbb_20389:
    mov64 r0, 17                                    r0 = 17 as i32 as i64 as u64
    ja lbb_20392                                    if true { pc += 1 }
lbb_20391:
    mov64 r0, 41                                    r0 = 41 as i32 as i64 as u64
lbb_20392:
    exit                                    

function_20393:
    mov64 r1, 26                                    r1 = 26 as i32 as i64 as u64
    mov64 r2, 1                                     r2 = 1 as i32 as i64 as u64
    call function_14385                     
    mov64 r6, r0                                    r6 = r0
    jne r6, 0, lbb_20401                            if r6 != (0 as i32 as i64 as u64) { pc += 3 }
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    mov64 r2, 26                                    r2 = 26 as i32 as i64 as u64
    call function_21549                     
lbb_20401:
    mov64 r1, 29813                                 r1 = 29813 as i32 as i64 as u64
    stxh [r6+0x18], r1                      
    lddw r1, 0x706e6920666f2068                     r1 load str located at 8101528367564529768
    stxdw [r6+0x10], r1                     
    lddw r1, 0x74676e656c206465                     r1 load str located at 8387794212885652581
    stxdw [r6+0x8], r1                      
    lddw r1, 0x7463657078656e55                     r1 load str located at 8386658464824651349
    stxdw [r6+0x0], r1                      
    mov64 r1, 24                                    r1 = 24 as i32 as i64 as u64
    mov64 r2, 8                                     r2 = 8 as i32 as i64 as u64
    call function_14385                     
    jne r0, 0, lbb_20419                            if r0 != (0 as i32 as i64 as u64) { pc += 3 }
    mov64 r1, 8                                     r1 = 8 as i32 as i64 as u64
    mov64 r2, 24                                    r2 = 24 as i32 as i64 as u64
    call function_21552                     
lbb_20419:
    stxdw [r0+0x8], r6                      
    mov64 r1, 26                                    r1 = 26 as i32 as i64 as u64
    stxdw [r0+0x10], r1                     
    stxdw [r0+0x0], r1                      
    mov64 r1, 21                                    r1 = 21 as i32 as i64 as u64
    mov64 r2, r0                                    r2 = r0
    lddw r3, 0x100041870 --> b"\x00\x00\x00\x00\x88\x7f\x02\x00\x18\x00\x00\x00\x00\x00\x00\x00\x08\x00\…        r3 load str located at 4295235696
    call function_20895                     
    exit                                    

function_20429:
    ldxdw r2, [r1+0x0]                      
    jeq r2, 0, lbb_20434                            if r2 == (0 as i32 as i64 as u64) { pc += 3 }
    ldxdw r1, [r1+0x8]                      
    mov64 r3, 1                                     r3 = 1 as i32 as i64 as u64
    call function_14411                     
lbb_20434:
    exit                                    

function_20435:
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
    stxdw [r1+0x0], r2                      
    exit                                    

function_20438:
    exit                                    

function_20439:
    lddw r2, 0x1c4088621fee484b                     r2 load str located at 2035776986595346507
    stxdw [r1+0x8], r2                      
    lddw r2, 0x2219183bd7fa6079                     r2 load str located at 2457021717012963449
    stxdw [r1+0x0], r2                      
    exit                                    

function_20446:
    mov64 r6, r1                                    r6 = r1
    mov64 r7, r6                                    r7 = r6
    and64 r7, 3                                     r7 &= 3   ///  r7 = r7.and(3)
    jsgt r7, 1, lbb_20453                           if (r7 as i64) > (1 as i32 as i64) { pc += 3 }
    jeq r7, 0, lbb_20460                            if r7 == (0 as i32 as i64 as u64) { pc += 9 }
    ldxb r1, [r6+0xf]                       
    ja lbb_20461                                    if true { pc += 8 }
lbb_20453:
    mov64 r0, r6                                    r0 = r6
    jeq r7, 2, lbb_20487                            if r7 == (2 as i32 as i64 as u64) { pc += 32 }
    mov64 r1, r6                                    r1 = r6
    rsh64 r1, 32                                    r1 >>= 32   ///  r1 = r1.wrapping_shr(32)
    call function_20236                     
    mov64 r1, r0                                    r1 = r0
    ja lbb_20461                                    if true { pc += 1 }
lbb_20460:
    ldxb r1, [r6+0x10]                      
lbb_20461:
    and64 r1, 255                                   r1 &= 255   ///  r1 = r1.and(255)
    mov64 r0, r6                                    r0 = r6
    jne r1, 37, lbb_20487                           if r1 != (37 as i32 as i64 as u64) { pc += 23 }
    call function_20393                     
    mov64 r1, r7                                    r1 = r7
    add64 r1, -2                                    r1 += -2   ///  r1 = r1.wrapping_add(-2 as i32 as i64 as u64)
    mov64 r2, 2                                     r2 = 2 as i32 as i64 as u64
    jgt r2, r1, lbb_20487                           if r2 > r1 { pc += 18 }
    jeq r7, 0, lbb_20487                            if r7 == (0 as i32 as i64 as u64) { pc += 17 }
    mov64 r8, r0                                    r8 = r0
    ldxdw r7, [r6-0x1]                      
    ldxdw r9, [r6+0x7]                      
    ldxdw r2, [r9+0x0]                      
    mov64 r1, r7                                    r1 = r7
    callx r2                                
    add64 r6, -1                                    r6 += -1   ///  r6 = r6.wrapping_add(-1 as i32 as i64 as u64)
    ldxdw r2, [r9+0x8]                      
    jeq r2, 0, lbb_20482                            if r2 == (0 as i32 as i64 as u64) { pc += 3 }
    ldxdw r3, [r9+0x10]                     
    mov64 r1, r7                                    r1 = r7
    call function_14411                     
lbb_20482:
    mov64 r1, r6                                    r1 = r6
    mov64 r2, 24                                    r2 = 24 as i32 as i64 as u64
    mov64 r3, 8                                     r3 = 8 as i32 as i64 as u64
    call function_14411                     
    mov64 r0, r8                                    r0 = r8
lbb_20487:
    exit                                    

function_20488:
    ldxdw r3, [r1+0x0]                      
    ldxdw r1, [r3+0x0]                      
    ldxdw r3, [r3+0x8]                      
    ldxdw r3, [r3+0x18]                     
    callx r3                                
    exit                                    

function_20494:
    mov64 r3, r2                                    r3 = r2
    ldxdw r2, [r1+0x8]                      
    ldxdw r1, [r1+0x0]                      
    call function_27859                     
    exit                                    

function_20499:
    mov64 r3, r2                                    r3 = r2
    ldxdw r2, [r1+0x8]                      
    ldxdw r1, [r1+0x0]                      
    call function_28099                     
    exit                                    

function_20504:
    ldxw r3, [r2+0x34]                      
    mov64 r4, r3                                    r4 = r3
    and64 r4, 16                                    r4 &= 16   ///  r4 = r4.and(16)
    jne r4, 0, lbb_20513                            if r4 != (0 as i32 as i64 as u64) { pc += 5 }
    and64 r3, 32                                    r3 &= 32   ///  r3 = r3.and(32)
    jeq r3, 0, lbb_20511                            if r3 == (0 as i32 as i64 as u64) { pc += 1 }
    ja lbb_20515                                    if true { pc += 4 }
lbb_20511:
    call function_30202                     
    ja lbb_20516                                    if true { pc += 3 }
lbb_20513:
    call function_29755                     
    ja lbb_20516                                    if true { pc += 1 }
lbb_20515:
    call function_29803                     
lbb_20516:
    exit                                    

function_20517:
    exit                                    

function_20518:
    exit                                    

function_20519:
    exit                                    

function_20520:
    ldxdw r2, [r1+0x0]                      
    jeq r2, 0, lbb_20525                            if r2 == (0 as i32 as i64 as u64) { pc += 3 }
    ldxdw r1, [r1+0x8]                      
    mov64 r3, 1                                     r3 = 1 as i32 as i64 as u64
    call function_14411                     
lbb_20525:
    exit                                    

function_20526:
    mov64 r3, r2                                    r3 = r2
    ldxdw r2, [r1+0x10]                     
    ldxdw r1, [r1+0x8]                      
    call function_27859                     
    exit                                    

function_20531:
    mov64 r3, r2                                    r3 = r2
    ldxdw r2, [r1+0x10]                     
    ldxdw r1, [r1+0x8]                      
    call function_28099                     
    exit                                    

function_20536:
    lsh64 r1, 32                                    r1 <<= 32   ///  r1 = r1.wrapping_shl(32)
    rsh64 r1, 32                                    r1 >>= 32   ///  r1 = r1.wrapping_shr(32)
    jsgt r1, 19, lbb_20548                          if (r1 as i64) > (19 as i32 as i64) { pc += 9 }
    jsgt r1, 9, lbb_20563                           if (r1 as i64) > (9 as i32 as i64) { pc += 23 }
    jsgt r1, 4, lbb_20583                           if (r1 as i64) > (4 as i32 as i64) { pc += 42 }
    jsgt r1, 1, lbb_20619                           if (r1 as i64) > (1 as i32 as i64) { pc += 77 }
    mov64 r0, 0                                     r0 = 0 as i32 as i64 as u64
    jeq r1, 0, lbb_20692                            if r1 == (0 as i32 as i64 as u64) { pc += 148 }
    jeq r1, 1, lbb_20546                            if r1 == (1 as i32 as i64 as u64) { pc += 1 }
    ja lbb_20691                                    if true { pc += 145 }
lbb_20546:
    mov64 r0, 1                                     r0 = 1 as i32 as i64 as u64
    ja lbb_20692                                    if true { pc += 144 }
lbb_20548:
    jsgt r1, 29, lbb_20556                          if (r1 as i64) > (29 as i32 as i64) { pc += 7 }
    jsgt r1, 24, lbb_20577                          if (r1 as i64) > (24 as i32 as i64) { pc += 27 }
    jsgt r1, 21, lbb_20595                          if (r1 as i64) > (21 as i32 as i64) { pc += 44 }
    jeq r1, 20, lbb_20643                           if r1 == (20 as i32 as i64 as u64) { pc += 91 }
    jeq r1, 21, lbb_20554                           if r1 == (21 as i32 as i64 as u64) { pc += 1 }
    ja lbb_20691                                    if true { pc += 137 }
lbb_20554:
    mov64 r0, 21                                    r0 = 21 as i32 as i64 as u64
    ja lbb_20692                                    if true { pc += 136 }
lbb_20556:
    jsgt r1, 34, lbb_20570                          if (r1 as i64) > (34 as i32 as i64) { pc += 13 }
    jsgt r1, 31, lbb_20613                          if (r1 as i64) > (31 as i32 as i64) { pc += 55 }
    jeq r1, 30, lbb_20655                           if r1 == (30 as i32 as i64 as u64) { pc += 96 }
    jeq r1, 31, lbb_20561                           if r1 == (31 as i32 as i64 as u64) { pc += 1 }
    ja lbb_20691                                    if true { pc += 130 }
lbb_20561:
    mov64 r0, 31                                    r0 = 31 as i32 as i64 as u64
    ja lbb_20692                                    if true { pc += 129 }
lbb_20563:
    jsgt r1, 14, lbb_20589                          if (r1 as i64) > (14 as i32 as i64) { pc += 25 }
    jsgt r1, 11, lbb_20625                          if (r1 as i64) > (11 as i32 as i64) { pc += 60 }
    jeq r1, 10, lbb_20667                           if r1 == (10 as i32 as i64 as u64) { pc += 101 }
    jeq r1, 11, lbb_20568                           if r1 == (11 as i32 as i64 as u64) { pc += 1 }
    ja lbb_20691                                    if true { pc += 123 }
lbb_20568:
    mov64 r0, 11                                    r0 = 11 as i32 as i64 as u64
    ja lbb_20692                                    if true { pc += 122 }
lbb_20570:
    jsgt r1, 37, lbb_20607                          if (r1 as i64) > (37 as i32 as i64) { pc += 36 }
    jeq r1, 35, lbb_20663                           if r1 == (35 as i32 as i64 as u64) { pc += 91 }
    jeq r1, 36, lbb_20651                           if r1 == (36 as i32 as i64 as u64) { pc += 78 }
    jeq r1, 37, lbb_20575                           if r1 == (37 as i32 as i64 as u64) { pc += 1 }
    ja lbb_20691                                    if true { pc += 116 }
lbb_20575:
    mov64 r0, 37                                    r0 = 37 as i32 as i64 as u64
    ja lbb_20692                                    if true { pc += 115 }
lbb_20577:
    jsgt r1, 26, lbb_20601                          if (r1 as i64) > (26 as i32 as i64) { pc += 23 }
    jeq r1, 25, lbb_20645                           if r1 == (25 as i32 as i64 as u64) { pc += 66 }
    jeq r1, 26, lbb_20581                           if r1 == (26 as i32 as i64 as u64) { pc += 1 }
    ja lbb_20691                                    if true { pc += 110 }
lbb_20581:
    mov64 r0, 26                                    r0 = 26 as i32 as i64 as u64
    ja lbb_20692                                    if true { pc += 109 }
lbb_20583:
    jsgt r1, 6, lbb_20631                           if (r1 as i64) > (6 as i32 as i64) { pc += 47 }
    jeq r1, 5, lbb_20669                            if r1 == (5 as i32 as i64 as u64) { pc += 84 }
    jeq r1, 6, lbb_20587                            if r1 == (6 as i32 as i64 as u64) { pc += 1 }
    ja lbb_20691                                    if true { pc += 104 }
lbb_20587:
    mov64 r0, 6                                     r0 = 6 as i32 as i64 as u64
    ja lbb_20692                                    if true { pc += 103 }
lbb_20589:
    jsgt r1, 16, lbb_20637                          if (r1 as i64) > (16 as i32 as i64) { pc += 47 }
    jeq r1, 15, lbb_20671                           if r1 == (15 as i32 as i64 as u64) { pc += 80 }
    jeq r1, 16, lbb_20593                           if r1 == (16 as i32 as i64 as u64) { pc += 1 }
    ja lbb_20691                                    if true { pc += 98 }
lbb_20593:
    mov64 r0, 16                                    r0 = 16 as i32 as i64 as u64
    ja lbb_20692                                    if true { pc += 97 }
lbb_20595:
    jeq r1, 22, lbb_20657                           if r1 == (22 as i32 as i64 as u64) { pc += 61 }
    jeq r1, 23, lbb_20647                           if r1 == (23 as i32 as i64 as u64) { pc += 50 }
    jeq r1, 24, lbb_20599                           if r1 == (24 as i32 as i64 as u64) { pc += 1 }
    ja lbb_20691                                    if true { pc += 92 }
lbb_20599:
    mov64 r0, 24                                    r0 = 24 as i32 as i64 as u64
    ja lbb_20692                                    if true { pc += 91 }
lbb_20601:
    jeq r1, 27, lbb_20659                           if r1 == (27 as i32 as i64 as u64) { pc += 57 }
    jeq r1, 28, lbb_20649                           if r1 == (28 as i32 as i64 as u64) { pc += 46 }
    jeq r1, 29, lbb_20605                           if r1 == (29 as i32 as i64 as u64) { pc += 1 }
    ja lbb_20691                                    if true { pc += 86 }
lbb_20605:
    mov64 r0, 29                                    r0 = 29 as i32 as i64 as u64
    ja lbb_20692                                    if true { pc += 85 }
lbb_20607:
    jeq r1, 38, lbb_20665                           if r1 == (38 as i32 as i64 as u64) { pc += 57 }
    jeq r1, 39, lbb_20653                           if r1 == (39 as i32 as i64 as u64) { pc += 44 }
    jeq r1, 40, lbb_20611                           if r1 == (40 as i32 as i64 as u64) { pc += 1 }
    ja lbb_20691                                    if true { pc += 80 }
lbb_20611:
    mov64 r0, 40                                    r0 = 40 as i32 as i64 as u64
    ja lbb_20692                                    if true { pc += 79 }
lbb_20613:
    jeq r1, 32, lbb_20681                           if r1 == (32 as i32 as i64 as u64) { pc += 67 }
    jeq r1, 33, lbb_20661                           if r1 == (33 as i32 as i64 as u64) { pc += 46 }
    jeq r1, 34, lbb_20617                           if r1 == (34 as i32 as i64 as u64) { pc += 1 }
    ja lbb_20691                                    if true { pc += 74 }
lbb_20617:
    mov64 r0, 34                                    r0 = 34 as i32 as i64 as u64
    ja lbb_20692                                    if true { pc += 73 }
lbb_20619:
    jeq r1, 2, lbb_20683                            if r1 == (2 as i32 as i64 as u64) { pc += 63 }
    jeq r1, 3, lbb_20673                            if r1 == (3 as i32 as i64 as u64) { pc += 52 }
    jeq r1, 4, lbb_20623                            if r1 == (4 as i32 as i64 as u64) { pc += 1 }
    ja lbb_20691                                    if true { pc += 68 }
lbb_20623:
    mov64 r0, 4                                     r0 = 4 as i32 as i64 as u64
    ja lbb_20692                                    if true { pc += 67 }
lbb_20625:
    jeq r1, 12, lbb_20685                           if r1 == (12 as i32 as i64 as u64) { pc += 59 }
    jeq r1, 13, lbb_20675                           if r1 == (13 as i32 as i64 as u64) { pc += 48 }
    jeq r1, 14, lbb_20629                           if r1 == (14 as i32 as i64 as u64) { pc += 1 }
    ja lbb_20691                                    if true { pc += 62 }
lbb_20629:
    mov64 r0, 14                                    r0 = 14 as i32 as i64 as u64
    ja lbb_20692                                    if true { pc += 61 }
lbb_20631:
    jeq r1, 7, lbb_20687                            if r1 == (7 as i32 as i64 as u64) { pc += 55 }
    jeq r1, 8, lbb_20677                            if r1 == (8 as i32 as i64 as u64) { pc += 44 }
    jeq r1, 9, lbb_20635                            if r1 == (9 as i32 as i64 as u64) { pc += 1 }
    ja lbb_20691                                    if true { pc += 56 }
lbb_20635:
    mov64 r0, 9                                     r0 = 9 as i32 as i64 as u64
    ja lbb_20692                                    if true { pc += 55 }
lbb_20637:
    jeq r1, 17, lbb_20689                           if r1 == (17 as i32 as i64 as u64) { pc += 51 }
    jeq r1, 18, lbb_20679                           if r1 == (18 as i32 as i64 as u64) { pc += 40 }
    jeq r1, 19, lbb_20641                           if r1 == (19 as i32 as i64 as u64) { pc += 1 }
    ja lbb_20691                                    if true { pc += 50 }
lbb_20641:
    mov64 r0, 19                                    r0 = 19 as i32 as i64 as u64
    ja lbb_20692                                    if true { pc += 49 }
lbb_20643:
    mov64 r0, 20                                    r0 = 20 as i32 as i64 as u64
    ja lbb_20692                                    if true { pc += 47 }
lbb_20645:
    mov64 r0, 25                                    r0 = 25 as i32 as i64 as u64
    ja lbb_20692                                    if true { pc += 45 }
lbb_20647:
    mov64 r0, 23                                    r0 = 23 as i32 as i64 as u64
    ja lbb_20692                                    if true { pc += 43 }
lbb_20649:
    mov64 r0, 28                                    r0 = 28 as i32 as i64 as u64
    ja lbb_20692                                    if true { pc += 41 }
lbb_20651:
    mov64 r0, 36                                    r0 = 36 as i32 as i64 as u64
    ja lbb_20692                                    if true { pc += 39 }
lbb_20653:
    mov64 r0, 39                                    r0 = 39 as i32 as i64 as u64
    ja lbb_20692                                    if true { pc += 37 }
lbb_20655:
    mov64 r0, 30                                    r0 = 30 as i32 as i64 as u64
    ja lbb_20692                                    if true { pc += 35 }
lbb_20657:
    mov64 r0, 22                                    r0 = 22 as i32 as i64 as u64
    ja lbb_20692                                    if true { pc += 33 }
lbb_20659:
    mov64 r0, 27                                    r0 = 27 as i32 as i64 as u64
    ja lbb_20692                                    if true { pc += 31 }
lbb_20661:
    mov64 r0, 33                                    r0 = 33 as i32 as i64 as u64
    ja lbb_20692                                    if true { pc += 29 }
lbb_20663:
    mov64 r0, 35                                    r0 = 35 as i32 as i64 as u64
    ja lbb_20692                                    if true { pc += 27 }
lbb_20665:
    mov64 r0, 38                                    r0 = 38 as i32 as i64 as u64
    ja lbb_20692                                    if true { pc += 25 }
lbb_20667:
    mov64 r0, 10                                    r0 = 10 as i32 as i64 as u64
    ja lbb_20692                                    if true { pc += 23 }
lbb_20669:
    mov64 r0, 5                                     r0 = 5 as i32 as i64 as u64
    ja lbb_20692                                    if true { pc += 21 }
lbb_20671:
    mov64 r0, 15                                    r0 = 15 as i32 as i64 as u64
    ja lbb_20692                                    if true { pc += 19 }
lbb_20673:
    mov64 r0, 3                                     r0 = 3 as i32 as i64 as u64
    ja lbb_20692                                    if true { pc += 17 }
lbb_20675:
    mov64 r0, 13                                    r0 = 13 as i32 as i64 as u64
    ja lbb_20692                                    if true { pc += 15 }
lbb_20677:
    mov64 r0, 8                                     r0 = 8 as i32 as i64 as u64
    ja lbb_20692                                    if true { pc += 13 }
lbb_20679:
    mov64 r0, 18                                    r0 = 18 as i32 as i64 as u64
    ja lbb_20692                                    if true { pc += 11 }
lbb_20681:
    mov64 r0, 32                                    r0 = 32 as i32 as i64 as u64
    ja lbb_20692                                    if true { pc += 9 }
lbb_20683:
    mov64 r0, 2                                     r0 = 2 as i32 as i64 as u64
    ja lbb_20692                                    if true { pc += 7 }
lbb_20685:
    mov64 r0, 12                                    r0 = 12 as i32 as i64 as u64
    ja lbb_20692                                    if true { pc += 5 }
lbb_20687:
    mov64 r0, 7                                     r0 = 7 as i32 as i64 as u64
    ja lbb_20692                                    if true { pc += 3 }
lbb_20689:
    mov64 r0, 17                                    r0 = 17 as i32 as i64 as u64
    ja lbb_20692                                    if true { pc += 1 }
lbb_20691:
    mov64 r0, 41                                    r0 = 41 as i32 as i64 as u64
lbb_20692:
    exit                                    

function_20693:
    call function_20910                     
    exit                                    

function_20695:
    mov64 r3, 16                                    r3 = 16 as i32 as i64 as u64
    and64 r2, 255                                   r2 &= 255   ///  r2 = r2.and(255)
    jsgt r2, 19, lbb_20708                          if (r2 as i64) > (19 as i32 as i64) { pc += 10 }
    jsgt r2, 9, lbb_20723                           if (r2 as i64) > (9 as i32 as i64) { pc += 24 }
    jsgt r2, 4, lbb_20742                           if (r2 as i64) > (4 as i32 as i64) { pc += 42 }
    jsgt r2, 1, lbb_20771                           if (r2 as i64) > (1 as i32 as i64) { pc += 70 }
    lddw r4, 0x10003e740 --> b"entity not foundhost unreachableinvalid filenamesr"        r4 load str located at 4295223104
    jeq r2, 0, lbb_20892                            if r2 == (0 as i32 as i64 as u64) { pc += 188 }
    lddw r4, 0x10003f02e --> b"permission denied"        r4 load str located at 4295225390
    mov64 r3, 17                                    r3 = 17 as i32 as i64 as u64
    ja lbb_20892                                    if true { pc += 184 }
lbb_20708:
    jsgt r2, 29, lbb_20716                          if (r2 as i64) > (29 as i32 as i64) { pc += 7 }
    jsgt r2, 24, lbb_20736                          if (r2 as i64) > (24 as i32 as i64) { pc += 26 }
    jsgt r2, 21, lbb_20760                          if (r2 as i64) > (21 as i32 as i64) { pc += 49 }
    jeq r2, 20, lbb_20866                           if r2 == (20 as i32 as i64 as u64) { pc += 154 }
    lddw r4, 0x10003f1a5 --> b"invalid data"        r4 load str located at 4295225765
    mov64 r3, 12                                    r3 = 12 as i32 as i64 as u64
    ja lbb_20892                                    if true { pc += 176 }
lbb_20716:
    jsgt r2, 34, lbb_20729                          if (r2 as i64) > (34 as i32 as i64) { pc += 12 }
    jsgt r2, 31, lbb_20754                          if (r2 as i64) > (31 as i32 as i64) { pc += 36 }
    jeq r2, 30, lbb_20862                           if r2 == (30 as i32 as i64 as u64) { pc += 143 }
    lddw r4, 0x10003f223 --> b"cross-device link or rename"        r4 load str located at 4295225891
    mov64 r3, 27                                    r3 = 27 as i32 as i64 as u64
    ja lbb_20892                                    if true { pc += 169 }
lbb_20723:
    jsgt r2, 14, lbb_20748                          if (r2 as i64) > (14 as i32 as i64) { pc += 24 }
    jsgt r2, 11, lbb_20776                          if (r2 as i64) > (11 as i32 as i64) { pc += 51 }
    jeq r2, 10, lbb_20874                           if r2 == (10 as i32 as i64 as u64) { pc += 148 }
    lddw r4, 0x10003f0b2 --> b"broken pipeentity already existsoperation would bl"        r4 load str located at 4295225522
    ja lbb_20891                                    if true { pc += 162 }
lbb_20729:
    jsgt r2, 37, lbb_20794                          if (r2 as i64) > (37 as i32 as i64) { pc += 64 }
    jeq r2, 35, lbb_20828                           if r2 == (35 as i32 as i64 as u64) { pc += 97 }
    jeq r2, 36, lbb_20886                           if r2 == (36 as i32 as i64 as u64) { pc += 154 }
    lddw r4, 0x10003f282 --> b"unexpected end of file"        r4 load str located at 4295225986
    mov64 r3, 22                                    r3 = 22 as i32 as i64 as u64
    ja lbb_20892                                    if true { pc += 156 }
lbb_20736:
    jsgt r2, 26, lbb_20765                          if (r2 as i64) > (26 as i32 as i64) { pc += 28 }
    jeq r2, 25, lbb_20870                           if r2 == (25 as i32 as i64 as u64) { pc += 132 }
    lddw r4, 0x10003f1db --> b"filesystem quota exceeded"        r4 load str located at 4295225819
    mov64 r3, 25                                    r3 = 25 as i32 as i64 as u64
    ja lbb_20892                                    if true { pc += 150 }
lbb_20742:
    jsgt r2, 6, lbb_20782                           if (r2 as i64) > (6 as i32 as i64) { pc += 39 }
    jeq r2, 5, lbb_20878                            if r2 == (5 as i32 as i64 as u64) { pc += 134 }
    lddw r4, 0x10003f064 --> b"connection aborted"        r4 load str located at 4295225444
    mov64 r3, 18                                    r3 = 18 as i32 as i64 as u64
    ja lbb_20892                                    if true { pc += 144 }
lbb_20748:
    jsgt r2, 16, lbb_20788                          if (r2 as i64) > (16 as i32 as i64) { pc += 39 }
    jeq r2, 15, lbb_20882                           if r2 == (15 as i32 as i64 as u64) { pc += 132 }
    lddw r4, 0x10003f104 --> b"directory not empty"        r4 load str located at 4295225604
    mov64 r3, 19                                    r3 = 19 as i32 as i64 as u64
    ja lbb_20892                                    if true { pc += 138 }
lbb_20754:
    jeq r2, 32, lbb_20800                           if r2 == (32 as i32 as i64 as u64) { pc += 45 }
    jeq r2, 33, lbb_20836                           if r2 == (33 as i32 as i64 as u64) { pc += 80 }
    lddw r4, 0x10003f24c --> b"argument list too long"        r4 load str located at 4295225932
    mov64 r3, 22                                    r3 = 22 as i32 as i64 as u64
    ja lbb_20892                                    if true { pc += 132 }
lbb_20760:
    jeq r2, 22, lbb_20804                           if r2 == (22 as i32 as i64 as u64) { pc += 43 }
    jeq r2, 23, lbb_20839                           if r2 == (23 as i32 as i64 as u64) { pc += 77 }
    lddw r4, 0x10003e7b0 --> b"no storage spaceAddrNotAvailable right` failed: fl"        r4 load str located at 4295223216
    ja lbb_20892                                    if true { pc += 127 }
lbb_20765:
    jeq r2, 27, lbb_20808                           if r2 == (27 as i32 as i64 as u64) { pc += 42 }
    jeq r2, 28, lbb_20843                           if r2 == (28 as i32 as i64 as u64) { pc += 76 }
    lddw r4, 0x10003f20f --> b"executable file busy"        r4 load str located at 4295225871
    mov64 r3, 20                                    r3 = 20 as i32 as i64 as u64
    ja lbb_20892                                    if true { pc += 121 }
lbb_20771:
    jeq r2, 2, lbb_20812                            if r2 == (2 as i32 as i64 as u64) { pc += 40 }
    jeq r2, 3, lbb_20847                            if r2 == (3 as i32 as i64 as u64) { pc += 74 }
    lddw r4, 0x10003e750 --> b"host unreachableinvalid filenamesrc/utils/set.rsra"        r4 load str located at 4295223120
    ja lbb_20892                                    if true { pc += 116 }
lbb_20776:
    jeq r2, 12, lbb_20816                           if r2 == (12 as i32 as i64 as u64) { pc += 39 }
    jeq r2, 13, lbb_20850                           if r2 == (13 as i32 as i64 as u64) { pc += 72 }
    lddw r4, 0x10003f0e7 --> b"not a directory"        r4 load str located at 4295225575
    mov64 r3, 15                                    r3 = 15 as i32 as i64 as u64
    ja lbb_20892                                    if true { pc += 110 }
lbb_20782:
    jeq r2, 7, lbb_20820                            if r2 == (7 as i32 as i64 as u64) { pc += 37 }
    jeq r2, 8, lbb_20854                            if r2 == (8 as i32 as i64 as u64) { pc += 70 }
    lddw r4, 0x10003f091 --> b"address not available"        r4 load str located at 4295225489
    mov64 r3, 21                                    r3 = 21 as i32 as i64 as u64
    ja lbb_20892                                    if true { pc += 104 }
lbb_20788:
    jeq r2, 17, lbb_20824                           if r2 == (17 as i32 as i64 as u64) { pc += 35 }
    jeq r2, 18, lbb_20858                           if r2 == (18 as i32 as i64 as u64) { pc += 68 }
    lddw r4, 0x10003f175 --> b"stale network file handle"        r4 load str located at 4295225717
    mov64 r3, 25                                    r3 = 25 as i32 as i64 as u64
    ja lbb_20892                                    if true { pc += 98 }
lbb_20794:
    jeq r2, 38, lbb_20832                           if r2 == (38 as i32 as i64 as u64) { pc += 37 }
    jeq r2, 39, lbb_20889                           if r2 == (39 as i32 as i64 as u64) { pc += 93 }
    lddw r4, 0x10003f2b0 --> b"uncategorized error"        r4 load str located at 4295226032
    mov64 r3, 19                                    r3 = 19 as i32 as i64 as u64
    ja lbb_20892                                    if true { pc += 92 }
lbb_20800:
    lddw r4, 0x10003f23e --> b"too many links"        r4 load str located at 4295225918
    mov64 r3, 14                                    r3 = 14 as i32 as i64 as u64
    ja lbb_20892                                    if true { pc += 88 }
lbb_20804:
    lddw r4, 0x10003f1b1 --> b"timed out"           r4 load str located at 4295225777
    mov64 r3, 9                                     r3 = 9 as i32 as i64 as u64
    ja lbb_20892                                    if true { pc += 84 }
lbb_20808:
    lddw r4, 0x10003f1f4 --> b"file too large"        r4 load str located at 4295225844
    mov64 r3, 14                                    r3 = 14 as i32 as i64 as u64
    ja lbb_20892                                    if true { pc += 80 }
lbb_20812:
    lddw r4, 0x10003f03f --> b"connection refused"        r4 load str located at 4295225407
    mov64 r3, 18                                    r3 = 18 as i32 as i64 as u64
    ja lbb_20892                                    if true { pc += 76 }
lbb_20816:
    lddw r4, 0x10003f0bd --> b"entity already exists"        r4 load str located at 4295225533
    mov64 r3, 21                                    r3 = 21 as i32 as i64 as u64
    ja lbb_20892                                    if true { pc += 72 }
lbb_20820:
    lddw r4, 0x10003f076 --> b"not connected"        r4 load str located at 4295225462
    mov64 r3, 13                                    r3 = 13 as i32 as i64 as u64
    ja lbb_20892                                    if true { pc += 68 }
lbb_20824:
    lddw r4, 0x10003f117 --> b"read-only filesystem or storage medium"        r4 load str located at 4295225623
    mov64 r3, 38                                    r3 = 38 as i32 as i64 as u64
    ja lbb_20892                                    if true { pc += 64 }
lbb_20828:
    lddw r4, 0x10003f262 --> b"operation interrupted"        r4 load str located at 4295225954
    mov64 r3, 21                                    r3 = 21 as i32 as i64 as u64
    ja lbb_20892                                    if true { pc += 60 }
lbb_20832:
    lddw r4, 0x10003f298 --> b"out of memory"        r4 load str located at 4295226008
    mov64 r3, 13                                    r3 = 13 as i32 as i64 as u64
    ja lbb_20892                                    if true { pc += 56 }
lbb_20836:
    lddw r4, 0x10003e760 --> b"invalid filenamesrc/utils/set.rsrange end index \x01\x00"        r4 load str located at 4295223136
    ja lbb_20892                                    if true { pc += 53 }
lbb_20839:
    lddw r4, 0x10003f1ba --> b"write zero"          r4 load str located at 4295225786
    mov64 r3, 10                                    r3 = 10 as i32 as i64 as u64
    ja lbb_20892                                    if true { pc += 49 }
lbb_20843:
    lddw r4, 0x10003f202 --> b"resource busy"        r4 load str located at 4295225858
    mov64 r3, 13                                    r3 = 13 as i32 as i64 as u64
    ja lbb_20892                                    if true { pc += 45 }
lbb_20847:
    lddw r4, 0x10003e700 --> b"connection resetassertion `left ) when slicing `sr"        r4 load str located at 4295223040
    ja lbb_20892                                    if true { pc += 42 }
lbb_20850:
    lddw r4, 0x10003f0d2 --> b"operation would block"        r4 load str located at 4295225554
    mov64 r3, 21                                    r3 = 21 as i32 as i64 as u64
    ja lbb_20892                                    if true { pc += 38 }
lbb_20854:
    lddw r4, 0x10003f083 --> b"address in use"        r4 load str located at 4295225475
    mov64 r3, 14                                    r3 = 14 as i32 as i64 as u64
    ja lbb_20892                                    if true { pc += 34 }
lbb_20858:
    lddw r4, 0x10003f13d --> b"filesystem loop or indirection limit (e.g. symlink loop)"        r4 load str located at 4295225661
    mov64 r3, 56                                    r3 = 56 as i32 as i64 as u64
    ja lbb_20892                                    if true { pc += 30 }
lbb_20862:
    lddw r4, 0x10003ef98 --> b"deadlock"            r4 load str located at 4295225240
    mov64 r3, 8                                     r3 = 8 as i32 as i64 as u64
    ja lbb_20892                                    if true { pc += 26 }
lbb_20866:
    lddw r4, 0x10003f18e --> b"invalid input parameter"        r4 load str located at 4295225742
    mov64 r3, 23                                    r3 = 23 as i32 as i64 as u64
    ja lbb_20892                                    if true { pc += 22 }
lbb_20870:
    lddw r4, 0x10003f1c4 --> b"seek on unseekable file"        r4 load str located at 4295225796
    mov64 r3, 23                                    r3 = 23 as i32 as i64 as u64
    ja lbb_20892                                    if true { pc += 18 }
lbb_20874:
    lddw r4, 0x10003f0a6 --> b"network down"        r4 load str located at 4295225510
    mov64 r3, 12                                    r3 = 12 as i32 as i64 as u64
    ja lbb_20892                                    if true { pc += 14 }
lbb_20878:
    lddw r4, 0x10003f051 --> b"network unreachable"        r4 load str located at 4295225425
    mov64 r3, 19                                    r3 = 19 as i32 as i64 as u64
    ja lbb_20892                                    if true { pc += 10 }
lbb_20882:
    lddw r4, 0x10003f0f6 --> b"is a directory"        r4 load str located at 4295225590
    mov64 r3, 14                                    r3 = 14 as i32 as i64 as u64
    ja lbb_20892                                    if true { pc += 6 }
lbb_20886:
    lddw r4, 0x10003f277 --> b"unsupportedunexpected end of fileout of memoryothe"        r4 load str located at 4295225975
    ja lbb_20891                                    if true { pc += 2 }
lbb_20889:
    lddw r4, 0x10003f2a5 --> b"other error"         r4 load str located at 4295226021
lbb_20891:
    mov64 r3, 11                                    r3 = 11 as i32 as i64 as u64
lbb_20892:
    stxdw [r1+0x8], r3                      
    stxdw [r1+0x0], r4                      
    exit                                    

function_20895:
    mov64 r7, r3                                    r7 = r3
    mov64 r6, r2                                    r6 = r2
    mov64 r8, r1                                    r8 = r1
    mov64 r1, 24                                    r1 = 24 as i32 as i64 as u64
    mov64 r2, 8                                     r2 = 8 as i32 as i64 as u64
    call function_14385                     
    jne r0, 0, lbb_20905                            if r0 != (0 as i32 as i64 as u64) { pc += 3 }
    mov64 r1, 8                                     r1 = 8 as i32 as i64 as u64
    mov64 r2, 24                                    r2 = 24 as i32 as i64 as u64
    call function_21552                     
lbb_20905:
    stxb [r0+0x10], r8                      
    stxdw [r0+0x8], r7                      
    stxdw [r0+0x0], r6                      
    add64 r0, 1                                     r0 += 1   ///  r0 = r0.wrapping_add(1 as i32 as i64 as u64)
    exit                                    

function_20910:
    ldxdw r6, [r1+0x0]                      
    mov64 r1, r6                                    r1 = r6
    and64 r1, 3                                     r1 &= 3   ///  r1 = r1.and(3)
    jsgt r1, 1, lbb_20945                           if (r1 as i64) > (1 as i32 as i64) { pc += 31 }
    jeq r1, 0, lbb_20968                            if r1 == (0 as i32 as i64 as u64) { pc += 53 }
    mov64 r1, r6                                    r1 = r6
    add64 r1, -1                                    r1 += -1   ///  r1 = r1.wrapping_add(-1 as i32 as i64 as u64)
    stxdw [r10-0x18], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -24                                   r1 += -24   ///  r1 = r1.wrapping_add(-24 as i32 as i64 as u64)
    stxdw [r10-0xfd8], r1                   
    lddw r1, 0x100041948 --> b"\x00\x00\x00\x00H\x82\x02\x00\x08\x00\x00\x00\x00\x00\x00\x00\x08\x00\x00…        r1 load str located at 4295235912
    stxdw [r10-0xfd0], r1                   
    mov64 r1, 5                                     r1 = 5 as i32 as i64 as u64
    stxdw [r10-0xfe0], r1                   
    lddw r1, 0x10003f2d7 --> b"error (os error )ConnectionRefusedConnectionResetH"        r1 load str located at 4295226071
    stxdw [r10-0xfe8], r1                   
    lddw r1, 0x1000418e8 --> b"\x00\x00\x00\x00X\x82\x02\x00\x01\x00\x00\x00\x00\x00\x00\x00\x01\x00\x00…        r1 load str located at 4295235816
    stxdw [r10-0xff0], r1                   
    add64 r6, 15                                    r6 += 15   ///  r6 = r6.wrapping_add(15 as i32 as i64 as u64)
    stxdw [r10-0xff8], r6                   
    mov64 r1, 4                                     r1 = 4 as i32 as i64 as u64
    stxdw [r10-0x1000], r1                  
    mov64 r5, r10                                   r5 = r10
    mov64 r1, r2                                    r1 = r2
    lddw r2, 0x10003f2d1 --> b"Custom"              r2 load str located at 4295226065
    mov64 r3, 6                                     r3 = 6 as i32 as i64 as u64
    lddw r4, 0x10003edba --> b"kindSome <= trueenumNone    \x00\x00index out of bounds:"        r4 load str located at 4295224762
    call function_27710                     
    ja lbb_21062                                    if true { pc += 117 }
lbb_20945:
    jeq r1, 2, lbb_20995                            if r1 == (2 as i32 as i64 as u64) { pc += 49 }
    mov64 r7, r2                                    r7 = r2
    rsh64 r6, 32                                    r6 >>= 32   ///  r6 = r6.wrapping_shr(32)
    mov64 r1, r6                                    r1 = r6
    call function_20536                     
    stxb [r10-0x30], r0                     
    mov64 r6, r10                                   r6 = r10
    add64 r6, -24                                   r6 += -24   ///  r6 = r6.wrapping_add(-24 as i32 as i64 as u64)
    mov64 r1, r6                                    r1 = r6
    mov64 r2, r7                                    r2 = r7
    lddw r3, 0x10003edb6 --> b"Kind"                r3 load str located at 4295224758
    mov64 r4, 4                                     r4 = 4 as i32 as i64 as u64
    call function_27764                     
    mov64 r2, r10                                   r2 = r10
    add64 r2, -48                                   r2 += -48   ///  r2 = r2.wrapping_add(-48 as i32 as i64 as u64)
    mov64 r1, r6                                    r1 = r6
    lddw r3, 0x1000418e8 --> b"\x00\x00\x00\x00X\x82\x02\x00\x01\x00\x00\x00\x00\x00\x00\x00\x01\x00\x00…        r3 load str located at 4295235816
    call function_26346                     
    mov64 r1, r0                                    r1 = r0
    call function_26444                     
    ja lbb_21062                                    if true { pc += 94 }
lbb_20968:
    mov64 r7, r10                                   r7 = r10
    add64 r7, -24                                   r7 += -24   ///  r7 = r7.wrapping_add(-24 as i32 as i64 as u64)
    mov64 r1, r7                                    r1 = r7
    lddw r3, 0x10003f2cc --> b"Error"               r3 load str located at 4295226060
    mov64 r4, 5                                     r4 = 5 as i32 as i64 as u64
    call function_27697                     
    mov64 r4, r6                                    r4 = r6
    add64 r4, 16                                    r4 += 16   ///  r4 = r4.wrapping_add(16 as i32 as i64 as u64)
    mov64 r1, r7                                    r1 = r7
    lddw r2, 0x10003edba --> b"kind"                r2 load str located at 4295224762
    mov64 r3, 4                                     r3 = 4 as i32 as i64 as u64
    lddw r5, 0x1000418e8 --> b"\x00\x00\x00\x00X\x82\x02\x00\x01\x00\x00\x00\x00\x00\x00\x00\x01\x00\x00…        r5 load str located at 4295235816
    call function_26188                     
    mov64 r1, r0                                    r1 = r0
    lddw r2, 0x10003f2c5 --> b"message"             r2 load str located at 4295226053
    mov64 r3, 7                                     r3 = 7 as i32 as i64 as u64
    mov64 r4, r6                                    r4 = r6
    lddw r5, 0x100041928 --> b"\x00\x00\x00\x00H\x82\x02\x00\x10\x00\x00\x00\x00\x00\x00\x00\x08\x00\x00…        r5 load str located at 4295235880
    call function_26188                     
    mov64 r1, r0                                    r1 = r0
    call function_26313                     
    ja lbb_21062                                    if true { pc += 67 }
lbb_20995:
    rsh64 r6, 32                                    r6 >>= 32   ///  r6 = r6.wrapping_shr(32)
    stxw [r10-0x34], r6                     
    mov64 r6, r10                                   r6 = r10
    add64 r6, -48                                   r6 += -48   ///  r6 = r6.wrapping_add(-48 as i32 as i64 as u64)
    mov64 r1, r6                                    r1 = r6
    lddw r3, 0x10003f2c3 --> b"Os"                  r3 load str located at 4295226051
    mov64 r4, 2                                     r4 = 2 as i32 as i64 as u64
    call function_27697                     
    mov64 r4, r10                                   r4 = r10
    add64 r4, -52                                   r4 += -52   ///  r4 = r4.wrapping_add(-52 as i32 as i64 as u64)
    mov64 r1, r6                                    r1 = r6
    lddw r2, 0x10003edb2 --> b"code"                r2 load str located at 4295224754
    mov64 r3, 4                                     r3 = 4 as i32 as i64 as u64
    lddw r5, 0x1000418c8 --> b"\x00\x00\x00\x00P\x82\x02\x00\x04\x00\x00\x00\x00\x00\x00\x00\x04\x00\x00…        r5 load str located at 4295235784
    call function_26188                     
    mov64 r1, 39                                    r1 = 39 as i32 as i64 as u64
    stxb [r10-0x19], r1                     
    mov64 r4, r10                                   r4 = r10
    add64 r4, -25                                   r4 += -25   ///  r4 = r4.wrapping_add(-25 as i32 as i64 as u64)
    mov64 r1, r0                                    r1 = r0
    lddw r2, 0x10003edba --> b"kind"                r2 load str located at 4295224762
    mov64 r3, 4                                     r3 = 4 as i32 as i64 as u64
    lddw r5, 0x1000418e8 --> b"\x00\x00\x00\x00X\x82\x02\x00\x01\x00\x00\x00\x00\x00\x00\x00\x01\x00\x00…        r5 load str located at 4295235816
    call function_26188                     
    mov64 r6, r0                                    r6 = r0
    mov64 r7, 20                                    r7 = 20 as i32 as i64 as u64
    mov64 r1, 20                                    r1 = 20 as i32 as i64 as u64
    mov64 r2, 1                                     r2 = 1 as i32 as i64 as u64
    call function_14385                     
    jne r0, 0, lbb_21033                            if r0 != (0 as i32 as i64 as u64) { pc += 3 }
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    mov64 r2, 20                                    r2 = 20 as i32 as i64 as u64
    call function_21549                     
lbb_21033:
    mov64 r1, 1819633267                            r1 = 1819633267 as i32 as i64 as u64
    stxw [r0+0x10], r1                      
    lddw r1, 0x736563637573206e                     r1 load str located at 8315161565832880238
    stxdw [r0+0x8], r1                      
    lddw r1, 0x6f6974617265706f                     r1 load str located at 8028075772644520047
    stxdw [r0+0x0], r1                      
    stxdw [r10-0x10], r0                    
    stxdw [r10-0x8], r7                     
    stxdw [r10-0x18], r7                    
    mov64 r4, r10                                   r4 = r10
    add64 r4, -24                                   r4 += -24   ///  r4 = r4.wrapping_add(-24 as i32 as i64 as u64)
    mov64 r1, r6                                    r1 = r6
    lddw r2, 0x10003f2c5 --> b"message"             r2 load str located at 4295226053
    mov64 r3, 7                                     r3 = 7 as i32 as i64 as u64
    lddw r5, 0x100041908 --> b"\x00\x00\x00\x00`\x82\x02\x00\x18\x00\x00\x00\x00\x00\x00\x00\x08\x00\x00…        r5 load str located at 4295235848
    call function_26188                     
    mov64 r1, r0                                    r1 = r0
    call function_26313                     
    ldxdw r2, [r10-0x18]                    
    jeq r2, 0, lbb_21062                            if r2 == (0 as i32 as i64 as u64) { pc += 5 }
    ldxdw r1, [r10-0x10]                    
    mov64 r3, 1                                     r3 = 1 as i32 as i64 as u64
    mov64 r6, r0                                    r6 = r0
    call function_14411                     
    mov64 r0, r6                                    r0 = r6
lbb_21062:
    exit                                    

function_21063:
    mov64 r6, r2                                    r6 = r2
    ldxdw r1, [r1+0x0]                      
    mov64 r2, r1                                    r2 = r1
    and64 r2, 3                                     r2 &= 3   ///  r2 = r2.and(3)
    jsgt r2, 1, lbb_21076                           if (r2 as i64) > (1 as i32 as i64) { pc += 8 }
    jeq r2, 0, lbb_21110                            if r2 == (0 as i32 as i64 as u64) { pc += 41 }
    ldxdw r2, [r1-0x1]                      
    ldxdw r1, [r1+0x7]                      
    ldxdw r3, [r1+0x20]                     
    mov64 r1, r2                                    r1 = r2
    mov64 r2, r6                                    r2 = r6
    callx r3                                
    ja lbb_21172                                    if true { pc += 96 }
lbb_21076:
    jeq r2, 2, lbb_21115                            if r2 == (2 as i32 as i64 as u64) { pc += 38 }
    rsh64 r1, 32                                    r1 >>= 32   ///  r1 = r1.wrapping_shr(32)
    call function_20536                     
    mov64 r1, r10                                   r1 = r10
    add64 r1, -128                                  r1 += -128   ///  r1 = r1.wrapping_add(-128 as i32 as i64 as u64)
    mov64 r2, r0                                    r2 = r0
    call function_20695                     
    lddw r1, 0x1000281b8 --> b"\xbf#\x00\x00\x00\x00\x00\x00y\x12\x08\x00\x00\x00\x00\x00y\x11\x00\x00\x…        r1 load str located at 4295131576
    stxdw [r10-0x60], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -80                                   r1 += -80   ///  r1 = r1.wrapping_add(-80 as i32 as i64 as u64)
    stxdw [r10-0x68], r1                    
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    stxdw [r10-0x10], r1                    
    lddw r1, 0x10003e790 --> b"\x01\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00Permissio…        r1 load str located at 4295223184
    stxdw [r10-0x30], r1                    
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    stxdw [r10-0x28], r1                    
    stxdw [r10-0x18], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -104                                  r1 += -104   ///  r1 = r1.wrapping_add(-104 as i32 as i64 as u64)
    stxdw [r10-0x20], r1                    
    ldxdw r1, [r10-0x78]                    
    stxdw [r10-0x48], r1                    
    ldxdw r1, [r10-0x80]                    
    stxdw [r10-0x50], r1                    
    ldxdw r2, [r6+0x28]                     
    ldxdw r1, [r6+0x20]                     
    mov64 r3, r10                                   r3 = r10
    add64 r3, -48                                   r3 += -48   ///  r3 = r3.wrapping_add(-48 as i32 as i64 as u64)
    call function_26898                     
    ja lbb_21172                                    if true { pc += 62 }
lbb_21110:
    ldxdw r2, [r1+0x8]                      
    ldxdw r1, [r1+0x0]                      
    mov64 r3, r6                                    r3 = r6
    call function_28099                     
    ja lbb_21172                                    if true { pc += 57 }
lbb_21115:
    rsh64 r1, 32                                    r1 >>= 32   ///  r1 = r1.wrapping_shr(32)
    stxw [r10-0x6c], r1                     
    mov64 r7, 20                                    r7 = 20 as i32 as i64 as u64
    mov64 r1, 20                                    r1 = 20 as i32 as i64 as u64
    mov64 r2, 1                                     r2 = 1 as i32 as i64 as u64
    call function_14385                     
    jne r0, 0, lbb_21125                            if r0 != (0 as i32 as i64 as u64) { pc += 3 }
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    mov64 r2, 20                                    r2 = 20 as i32 as i64 as u64
    call function_21549                     
lbb_21125:
    mov64 r1, 1819633267                            r1 = 1819633267 as i32 as i64 as u64
    stxw [r0+0x10], r1                      
    lddw r1, 0x736563637573206e                     r1 load str located at 8315161565832880238
    stxdw [r0+0x8], r1                      
    lddw r1, 0x6f6974617265706f                     r1 load str located at 8028075772644520047
    stxdw [r0+0x0], r1                      
    stxdw [r10-0x60], r0                    
    stxdw [r10-0x58], r7                    
    stxdw [r10-0x68], r7                    
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    stxdw [r10-0x10], r1                    
    mov64 r1, 3                                     r1 = 3 as i32 as i64 as u64
    stxdw [r10-0x28], r1                    
    lddw r1, 0x100041968 --> b"\x01\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\…        r1 load str located at 4295235944
    stxdw [r10-0x30], r1                    
    mov64 r1, 2                                     r1 = 2 as i32 as i64 as u64
    stxdw [r10-0x18], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -80                                   r1 += -80   ///  r1 = r1.wrapping_add(-80 as i32 as i64 as u64)
    stxdw [r10-0x20], r1                    
    lddw r1, 0x10003b0f0 --> b"\xbf#\x00\x00\x00\x00\x00\x00a\x14\x00\x00\x00\x00\x00\x00g\x04\x00\x00 \…        r1 load str located at 4295209200
    stxdw [r10-0x38], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -108                                  r1 += -108   ///  r1 = r1.wrapping_add(-108 as i32 as i64 as u64)
    stxdw [r10-0x40], r1                    
    lddw r1, 0x1000282b8 --> b"\xbf#\x00\x00\x00\x00\x00\x00y\x12\x10\x00\x00\x00\x00\x00y\x11\x08\x00\x…        r1 load str located at 4295131832
    stxdw [r10-0x48], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -104                                  r1 += -104   ///  r1 = r1.wrapping_add(-104 as i32 as i64 as u64)
    stxdw [r10-0x50], r1                    
    ldxdw r2, [r6+0x28]                     
    ldxdw r1, [r6+0x20]                     
    mov64 r3, r10                                   r3 = r10
    add64 r3, -48                                   r3 += -48   ///  r3 = r3.wrapping_add(-48 as i32 as i64 as u64)
    call function_26898                     
    ldxdw r2, [r10-0x68]                    
    jeq r2, 0, lbb_21172                            if r2 == (0 as i32 as i64 as u64) { pc += 5 }
    ldxdw r1, [r10-0x60]                    
    mov64 r3, 1                                     r3 = 1 as i32 as i64 as u64
    mov64 r6, r0                                    r6 = r0
    call function_14411                     
    mov64 r0, r6                                    r0 = r6
lbb_21172:
    exit                                    

function_21173:
    call function_21384                     

function_21174:
    call function_21382                     
    mov64 r4, r2                                    r4 = r2
    mov64 r3, 8                                     r3 = 8 as i32 as i64 as u64
    ldxb r1, [r1+0x0]                       
    jsgt r1, 19, lbb_21189                          if (r1 as i64) > (19 as i32 as i64) { pc += 10 }
    jsgt r1, 9, lbb_21204                           if (r1 as i64) > (9 as i32 as i64) { pc += 24 }
    jsgt r1, 4, lbb_21224                           if (r1 as i64) > (4 as i32 as i64) { pc += 43 }
    jsgt r1, 1, lbb_21254                           if (r1 as i64) > (1 as i32 as i64) { pc += 72 }
    lddw r2, 0x10003ef78 --> b"NotFoundTimedOut (bytes Deadlockdeadlockbyte array"        r2 load str located at 4295225208
    jeq r1, 0, lbb_21377                            if r1 == (0 as i32 as i64 as u64) { pc += 192 }
    lddw r2, 0x10003e7a0 --> b"PermissionDenied"        r2 load str located at 4295223200
    mov64 r3, 16                                    r3 = 16 as i32 as i64 as u64
    ja lbb_21377                                    if true { pc += 188 }
lbb_21189:
    jsgt r1, 29, lbb_21197                          if (r1 as i64) > (29 as i32 as i64) { pc += 7 }
    jsgt r1, 24, lbb_21218                          if (r1 as i64) > (24 as i32 as i64) { pc += 27 }
    jsgt r1, 21, lbb_21242                          if (r1 as i64) > (21 as i32 as i64) { pc += 50 }
    jeq r1, 20, lbb_21350                           if r1 == (20 as i32 as i64 as u64) { pc += 157 }
    lddw r2, 0x10003f3e7 --> b"InvalidData"         r2 load str located at 4295226343
    mov64 r3, 11                                    r3 = 11 as i32 as i64 as u64
    ja lbb_21377                                    if true { pc += 180 }
lbb_21197:
    jsgt r1, 34, lbb_21211                          if (r1 as i64) > (34 as i32 as i64) { pc += 13 }
    jsgt r1, 31, lbb_21236                          if (r1 as i64) > (31 as i32 as i64) { pc += 37 }
    jeq r1, 30, lbb_21347                           if r1 == (30 as i32 as i64 as u64) { pc += 147 }
    lddw r2, 0x10003f452 --> b"CrossesDevices"        r2 load str located at 4295226450
    mov64 r3, 14                                    r3 = 14 as i32 as i64 as u64
    ja lbb_21377                                    if true { pc += 173 }
lbb_21204:
    jsgt r1, 14, lbb_21230                          if (r1 as i64) > (14 as i32 as i64) { pc += 25 }
    jsgt r1, 11, lbb_21260                          if (r1 as i64) > (11 as i32 as i64) { pc += 54 }
    jeq r1, 10, lbb_21358                           if r1 == (10 as i32 as i64 as u64) { pc += 151 }
    lddw r2, 0x10003f35a --> b"BrokenPipe"          r2 load str located at 4295226202
    mov64 r3, 10                                    r3 = 10 as i32 as i64 as u64
    ja lbb_21377                                    if true { pc += 166 }
lbb_21211:
    jsgt r1, 37, lbb_21278                          if (r1 as i64) > (37 as i32 as i64) { pc += 66 }
    jeq r1, 35, lbb_21311                           if r1 == (35 as i32 as i64 as u64) { pc += 98 }
    jeq r1, 36, lbb_21370                           if r1 == (36 as i32 as i64 as u64) { pc += 156 }
    lddw r2, 0x10003f4a4 --> b"UnexpectedEof"        r2 load str located at 4295226532
    mov64 r3, 13                                    r3 = 13 as i32 as i64 as u64
    ja lbb_21377                                    if true { pc += 159 }
lbb_21218:
    jsgt r1, 26, lbb_21248                          if (r1 as i64) > (26 as i32 as i64) { pc += 29 }
    jeq r1, 25, lbb_21354                           if r1 == (25 as i32 as i64 as u64) { pc += 134 }
    lddw r2, 0x10003f411 --> b"FilesystemQuotaExceeded"        r2 load str located at 4295226385
    mov64 r3, 23                                    r3 = 23 as i32 as i64 as u64
    ja lbb_21377                                    if true { pc += 153 }
lbb_21224:
    jsgt r1, 6, lbb_21266                           if (r1 as i64) > (6 as i32 as i64) { pc += 41 }
    jeq r1, 5, lbb_21362                            if r1 == (5 as i32 as i64 as u64) { pc += 136 }
    lddw r2, 0x10003f329 --> b"ConnectionAborted"        r2 load str located at 4295226153
    mov64 r3, 17                                    r3 = 17 as i32 as i64 as u64
    ja lbb_21377                                    if true { pc += 147 }
lbb_21230:
    jsgt r1, 16, lbb_21272                          if (r1 as i64) > (16 as i32 as i64) { pc += 41 }
    jeq r1, 15, lbb_21366                           if r1 == (15 as i32 as i64 as u64) { pc += 134 }
    lddw r2, 0x10003f394 --> b"DirectoryNotEmpty"        r2 load str located at 4295226260
    mov64 r3, 17                                    r3 = 17 as i32 as i64 as u64
    ja lbb_21377                                    if true { pc += 141 }
lbb_21236:
    jeq r1, 32, lbb_21284                           if r1 == (32 as i32 as i64 as u64) { pc += 47 }
    jeq r1, 33, lbb_21319                           if r1 == (33 as i32 as i64 as u64) { pc += 81 }
    lddw r2, 0x10003f47b --> b"ArgumentListTooLong"        r2 load str located at 4295226491
    mov64 r3, 19                                    r3 = 19 as i32 as i64 as u64
    ja lbb_21377                                    if true { pc += 135 }
lbb_21242:
    jeq r1, 22, lbb_21288                           if r1 == (22 as i32 as i64 as u64) { pc += 45 }
    jeq r1, 23, lbb_21323                           if r1 == (23 as i32 as i64 as u64) { pc += 79 }
    lddw r2, 0x10003f3fb --> b"StorageFull"         r2 load str located at 4295226363
    mov64 r3, 11                                    r3 = 11 as i32 as i64 as u64
    ja lbb_21377                                    if true { pc += 129 }
lbb_21248:
    jeq r1, 27, lbb_21291                           if r1 == (27 as i32 as i64 as u64) { pc += 42 }
    jeq r1, 28, lbb_21327                           if r1 == (28 as i32 as i64 as u64) { pc += 77 }
    lddw r2, 0x10003f440 --> b"ExecutableFileBusy"        r2 load str located at 4295226432
    mov64 r3, 18                                    r3 = 18 as i32 as i64 as u64
    ja lbb_21377                                    if true { pc += 123 }
lbb_21254:
    jeq r1, 2, lbb_21295                            if r1 == (2 as i32 as i64 as u64) { pc += 40 }
    jeq r1, 3, lbb_21331                            if r1 == (3 as i32 as i64 as u64) { pc += 75 }
    lddw r2, 0x10003f308 --> b"HostUnreachable"        r2 load str located at 4295226120
    mov64 r3, 15                                    r3 = 15 as i32 as i64 as u64
    ja lbb_21377                                    if true { pc += 117 }
lbb_21260:
    jeq r1, 12, lbb_21299                           if r1 == (12 as i32 as i64 as u64) { pc += 38 }
    jeq r1, 13, lbb_21335                           if r1 == (13 as i32 as i64 as u64) { pc += 73 }
    lddw r2, 0x10003f37b --> b"NotADirectory"        r2 load str located at 4295226235
    mov64 r3, 13                                    r3 = 13 as i32 as i64 as u64
    ja lbb_21377                                    if true { pc += 111 }
lbb_21266:
    jeq r1, 7, lbb_21303                            if r1 == (7 as i32 as i64 as u64) { pc += 36 }
    jeq r1, 8, lbb_21339                            if r1 == (8 as i32 as i64 as u64) { pc += 71 }
    lddw r2, 0x10003e7c0 --> b"AddrNotAvailable"        r2 load str located at 4295223232
    mov64 r3, 16                                    r3 = 16 as i32 as i64 as u64
    ja lbb_21377                                    if true { pc += 105 }
lbb_21272:
    jeq r1, 17, lbb_21307                           if r1 == (17 as i32 as i64 as u64) { pc += 34 }
    jeq r1, 18, lbb_21343                           if r1 == (18 as i32 as i64 as u64) { pc += 69 }
    lddw r2, 0x10003f3c5 --> b"StaleNetworkFileHandle"        r2 load str located at 4295226309
    mov64 r3, 22                                    r3 = 22 as i32 as i64 as u64
    ja lbb_21377                                    if true { pc += 99 }
lbb_21278:
    jeq r1, 38, lbb_21315                           if r1 == (38 as i32 as i64 as u64) { pc += 36 }
    jeq r1, 39, lbb_21374                           if r1 == (39 as i32 as i64 as u64) { pc += 94 }
    lddw r2, 0x10003f4c1 --> b"Uncategorized"        r2 load str located at 4295226561
    mov64 r3, 13                                    r3 = 13 as i32 as i64 as u64
    ja lbb_21377                                    if true { pc += 93 }
lbb_21284:
    lddw r2, 0x10003f460 --> b"TooManyLinks"        r2 load str located at 4295226464
    mov64 r3, 12                                    r3 = 12 as i32 as i64 as u64
    ja lbb_21377                                    if true { pc += 89 }
lbb_21288:
    lddw r2, 0x10003ef80 --> b"TimedOut (bytes Deadlockdeadlockbyte arrayboolean "        r2 load str located at 4295225216
    ja lbb_21377                                    if true { pc += 86 }
lbb_21291:
    lddw r2, 0x10003f428 --> b"FileTooLarge"        r2 load str located at 4295226408
    mov64 r3, 12                                    r3 = 12 as i32 as i64 as u64
    ja lbb_21377                                    if true { pc += 82 }
lbb_21295:
    lddw r2, 0x10003f2e8 --> b"ConnectionRefused"        r2 load str located at 4295226088
    mov64 r3, 17                                    r3 = 17 as i32 as i64 as u64
    ja lbb_21377                                    if true { pc += 78 }
lbb_21299:
    lddw r2, 0x10003f364 --> b"AlreadyExists"        r2 load str located at 4295226212
    mov64 r3, 13                                    r3 = 13 as i32 as i64 as u64
    ja lbb_21377                                    if true { pc += 74 }
lbb_21303:
    lddw r2, 0x10003f33a --> b"NotConnected"        r2 load str located at 4295226170
    mov64 r3, 12                                    r3 = 12 as i32 as i64 as u64
    ja lbb_21377                                    if true { pc += 70 }
lbb_21307:
    lddw r2, 0x10003f3a5 --> b"ReadOnlyFilesystem"        r2 load str located at 4295226277
    mov64 r3, 18                                    r3 = 18 as i32 as i64 as u64
    ja lbb_21377                                    if true { pc += 66 }
lbb_21311:
    lddw r2, 0x10003f48e --> b"Interrupted"         r2 load str located at 4295226510
    mov64 r3, 11                                    r3 = 11 as i32 as i64 as u64
    ja lbb_21377                                    if true { pc += 62 }
lbb_21315:
    lddw r2, 0x10003f4b1 --> b"OutOfMemory"         r2 load str located at 4295226545
    mov64 r3, 11                                    r3 = 11 as i32 as i64 as u64
    ja lbb_21377                                    if true { pc += 58 }
lbb_21319:
    lddw r2, 0x10003f46c --> b"InvalidFilename"        r2 load str located at 4295226476
    mov64 r3, 15                                    r3 = 15 as i32 as i64 as u64
    ja lbb_21377                                    if true { pc += 54 }
lbb_21323:
    lddw r2, 0x10003f3f2 --> b"WriteZero"           r2 load str located at 4295226354
    mov64 r3, 9                                     r3 = 9 as i32 as i64 as u64
    ja lbb_21377                                    if true { pc += 50 }
lbb_21327:
    lddw r2, 0x10003f434 --> b"ResourceBusy"        r2 load str located at 4295226420
    mov64 r3, 12                                    r3 = 12 as i32 as i64 as u64
    ja lbb_21377                                    if true { pc += 46 }
lbb_21331:
    lddw r2, 0x10003f2f9 --> b"ConnectionReset"        r2 load str located at 4295226105
    mov64 r3, 15                                    r3 = 15 as i32 as i64 as u64
    ja lbb_21377                                    if true { pc += 42 }
lbb_21335:
    lddw r2, 0x10003f371 --> b"WouldBlock"          r2 load str located at 4295226225
    mov64 r3, 10                                    r3 = 10 as i32 as i64 as u64
    ja lbb_21377                                    if true { pc += 38 }
lbb_21339:
    lddw r2, 0x10003f346 --> b"AddrInUse"           r2 load str located at 4295226182
    mov64 r3, 9                                     r3 = 9 as i32 as i64 as u64
    ja lbb_21377                                    if true { pc += 34 }
lbb_21343:
    lddw r2, 0x10003f3b7 --> b"FilesystemLoop"        r2 load str located at 4295226295
    mov64 r3, 14                                    r3 = 14 as i32 as i64 as u64
    ja lbb_21377                                    if true { pc += 30 }
lbb_21347:
    lddw r2, 0x10003ef90 --> b"Deadlockdeadlockbyte arrayboolean ``integer `chara"        r2 load str located at 4295225232
    ja lbb_21377                                    if true { pc += 27 }
lbb_21350:
    lddw r2, 0x10003f3db --> b"InvalidInput"        r2 load str located at 4295226331
    mov64 r3, 12                                    r3 = 12 as i32 as i64 as u64
    ja lbb_21377                                    if true { pc += 23 }
lbb_21354:
    lddw r2, 0x10003f406 --> b"NotSeekable"         r2 load str located at 4295226374
    mov64 r3, 11                                    r3 = 11 as i32 as i64 as u64
    ja lbb_21377                                    if true { pc += 19 }
lbb_21358:
    lddw r2, 0x10003f34f --> b"NetworkDown"         r2 load str located at 4295226191
    mov64 r3, 11                                    r3 = 11 as i32 as i64 as u64
    ja lbb_21377                                    if true { pc += 15 }
lbb_21362:
    lddw r2, 0x10003f317 --> b"NetworkUnreachable"        r2 load str located at 4295226135
    mov64 r3, 18                                    r3 = 18 as i32 as i64 as u64
    ja lbb_21377                                    if true { pc += 11 }
lbb_21366:
    lddw r2, 0x10003f388 --> b"IsADirectory"        r2 load str located at 4295226248
    mov64 r3, 12                                    r3 = 12 as i32 as i64 as u64
    ja lbb_21377                                    if true { pc += 7 }
lbb_21370:
    lddw r2, 0x10003f499 --> b"Unsupported"         r2 load str located at 4295226521
    mov64 r3, 11                                    r3 = 11 as i32 as i64 as u64
    ja lbb_21377                                    if true { pc += 3 }
lbb_21374:
    lddw r2, 0x10003f4bc --> b"Other"               r2 load str located at 4295226556
    mov64 r3, 5                                     r3 = 5 as i32 as i64 as u64
lbb_21377:
    mov64 r1, r4                                    r1 = r4
    call function_27691                     
    exit                                    

function_21380:
    syscall [invalid]                       
    exit                                    

function_21382:
    call custom_panic                       
    syscall [invalid]                       

function_21384:
    syscall [invalid]                       

function_21385:
    lddw r1, 0x10003f4ce --> b"Error: memory allocation failed, out of memory"        r1 load str located at 4295226574
    mov64 r2, 46                                    r2 = 46 as i32 as i64 as u64
    call function_21380                     
    call function_21173                     

function_21390:
    call function_21385                     
    mov64 r3, r2                                    r3 = r2
    lddw r2, 0x100041998 --> b"\x00\x00\x00\x00\xc8\x9d\x02\x00\x18\x00\x00\x00\x00\x00\x00\x00\x08\x00\…        r2 load str located at 4295235992
    call function_26898                     
    exit                                    

function_21396:
    exit                                    

function_21397:
    ldxdw r2, [r1+0x0]                      
    jeq r2, 0, lbb_21402                            if r2 == (0 as i32 as i64 as u64) { pc += 3 }
    ldxdw r1, [r1+0x8]                      
    mov64 r3, 1                                     r3 = 1 as i32 as i64 as u64
    call function_14411                     
lbb_21402:
    exit                                    

function_21403:
    mov64 r1, r2                                    r1 = r2
    lddw r2, 0x10003f4fc --> b"Error"               r2 load str located at 4295226620
    mov64 r3, 5                                     r3 = 5 as i32 as i64 as u64
    call function_27691                     
    exit                                    

function_21409:
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    stxdw [r10-0x28], r1                    
    lddw r1, 0x1000419c8 --> b"\x00\x00\x00\x00\x01\xf5\x03\x00\x11\x00\x00\x00\x00\x00\x00\x00\x00\x00\…        r1 load str located at 4295236040
    stxdw [r10-0x30], r1                    
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    stxdw [r10-0x10], r1                    
    stxdw [r10-0x18], r1                    
    mov64 r1, 8                                     r1 = 8 as i32 as i64 as u64
    stxdw [r10-0x20], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -48                                   r1 += -48   ///  r1 = r1.wrapping_add(-48 as i32 as i64 as u64)
    lddw r2, 0x1000419d8 --> b"\x00\x00\x00\x00\x12\xf5\x03\x00\x1c\x00\x00\x00\x00\x00\x00\x00\x19\x00\…        r2 load str located at 4295236056
    call function_25805                     

function_21424:
    mov64 r6, r1                                    r6 = r1
    mov64 r4, r2                                    r4 = r2
    add64 r4, r3                                    r4 += r3   ///  r4 = r4.wrapping_add(r3)
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    mov64 r3, 1                                     r3 = 1 as i32 as i64 as u64
    jgt r2, r4, lbb_21431                           if r2 > r4 { pc += 1 }
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
lbb_21431:
    and64 r3, 1                                     r3 &= 1   ///  r3 = r3.and(1)
    jne r3, 0, lbb_21460                            if r3 != (0 as i32 as i64 as u64) { pc += 27 }
    ldxdw r1, [r6+0x0]                      
    mov64 r7, r1                                    r7 = r1
    lsh64 r7, 1                                     r7 <<= 1   ///  r7 = r7.wrapping_shl(1)
    jgt r7, r4, lbb_21438                           if r7 > r4 { pc += 1 }
    mov64 r7, r4                                    r7 = r4
lbb_21438:
    jgt r7, 8, lbb_21440                            if r7 > (8 as i32 as i64 as u64) { pc += 1 }
    mov64 r7, 8                                     r7 = 8 as i32 as i64 as u64
lbb_21440:
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
    mov64 r2, r7                                    r2 = r7
    xor64 r2, -1                                    r2 ^= -1   ///  r2 = r2.xor(-1)
    rsh64 r2, 63                                    r2 >>= 63   ///  r2 = r2.wrapping_shr(63)
    jeq r1, 0, lbb_21449                            if r1 == (0 as i32 as i64 as u64) { pc += 4 }
    ldxdw r3, [r6+0x8]                      
    stxdw [r10-0x8], r1                     
    stxdw [r10-0x18], r3                    
    mov64 r3, 1                                     r3 = 1 as i32 as i64 as u64
lbb_21449:
    stxdw [r10-0x10], r3                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -48                                   r1 += -48   ///  r1 = r1.wrapping_add(-48 as i32 as i64 as u64)
    mov64 r4, r10                                   r4 = r10
    add64 r4, -24                                   r4 += -24   ///  r4 = r4.wrapping_add(-24 as i32 as i64 as u64)
    mov64 r3, r7                                    r3 = r7
    call function_21505                     
    ldxdw r1, [r10-0x30]                    
    jeq r1, 0, lbb_21461                            if r1 == (0 as i32 as i64 as u64) { pc += 3 }
    ldxdw r2, [r10-0x20]                    
    ldxdw r1, [r10-0x28]                    
lbb_21460:
    call function_21549                     
lbb_21461:
    ldxdw r1, [r10-0x28]                    
    stxdw [r6+0x0], r7                      
    stxdw [r6+0x8], r1                      
    exit                                    

function_21465:
    mov64 r6, r1                                    r6 = r1
    ldxdw r3, [r6+0x0]                      
    mov64 r4, r3                                    r4 = r3
    add64 r4, 1                                     r4 += 1   ///  r4 = r4.wrapping_add(1 as i32 as i64 as u64)
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    mov64 r5, 1                                     r5 = 1 as i32 as i64 as u64
    jeq r4, 0, lbb_21473                            if r4 == (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r5, 0                                     r5 = 0 as i32 as i64 as u64
lbb_21473:
    and64 r5, 1                                     r5 &= 1   ///  r5 = r5.and(1)
    jne r5, 0, lbb_21500                            if r5 != (0 as i32 as i64 as u64) { pc += 25 }
    mov64 r7, r3                                    r7 = r3
    lsh64 r7, 1                                     r7 <<= 1   ///  r7 = r7.wrapping_shl(1)
    jgt r7, r4, lbb_21479                           if r7 > r4 { pc += 1 }
    mov64 r7, r4                                    r7 = r4
lbb_21479:
    jgt r7, 8, lbb_21481                            if r7 > (8 as i32 as i64 as u64) { pc += 1 }
    mov64 r7, 8                                     r7 = 8 as i32 as i64 as u64
lbb_21481:
    mov64 r2, r7                                    r2 = r7
    xor64 r2, -1                                    r2 ^= -1   ///  r2 = r2.xor(-1)
    rsh64 r2, 63                                    r2 >>= 63   ///  r2 = r2.wrapping_shr(63)
    jeq r3, 0, lbb_21489                            if r3 == (0 as i32 as i64 as u64) { pc += 4 }
    ldxdw r1, [r6+0x8]                      
    stxdw [r10-0x8], r3                     
    stxdw [r10-0x18], r1                    
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
lbb_21489:
    stxdw [r10-0x10], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -48                                   r1 += -48   ///  r1 = r1.wrapping_add(-48 as i32 as i64 as u64)
    mov64 r4, r10                                   r4 = r10
    add64 r4, -24                                   r4 += -24   ///  r4 = r4.wrapping_add(-24 as i32 as i64 as u64)
    mov64 r3, r7                                    r3 = r7
    call function_21505                     
    ldxdw r1, [r10-0x30]                    
    jeq r1, 0, lbb_21501                            if r1 == (0 as i32 as i64 as u64) { pc += 3 }
    ldxdw r2, [r10-0x20]                    
    ldxdw r1, [r10-0x28]                    
lbb_21500:
    call function_21549                     
lbb_21501:
    ldxdw r1, [r10-0x28]                    
    stxdw [r6+0x0], r7                      
    stxdw [r6+0x8], r1                      
    exit                                    

function_21505:
    mov64 r7, r3                                    r7 = r3
    mov64 r6, r1                                    r6 = r1
    jeq r2, 0, lbb_21521                            if r2 == (0 as i32 as i64 as u64) { pc += 13 }
    ldxdw r1, [r4+0x8]                      
    jeq r1, 0, lbb_21536                            if r1 == (0 as i32 as i64 as u64) { pc += 26 }
    ldxdw r2, [r4+0x10]                     
    jne r2, 0, lbb_21525                            if r2 != (0 as i32 as i64 as u64) { pc += 13 }
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    mov64 r0, 1                                     r0 = 1 as i32 as i64 as u64
    jeq r7, 0, lbb_21544                            if r7 == (0 as i32 as i64 as u64) { pc += 29 }
    mov64 r1, r7                                    r1 = r7
    mov64 r2, 1                                     r2 = 1 as i32 as i64 as u64
    call function_14385                     
    mov64 r1, r7                                    r1 = r7
    jeq r0, 0, lbb_21532                            if r0 == (0 as i32 as i64 as u64) { pc += 12 }
    ja lbb_21544                                    if true { pc += 23 }
lbb_21521:
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    stxdw [r6+0x8], r1                      
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    ja lbb_21547                                    if true { pc += 22 }
lbb_21525:
    ldxdw r1, [r4+0x0]                      
    mov64 r3, 1                                     r3 = 1 as i32 as i64 as u64
    mov64 r4, r7                                    r4 = r7
    call function_14412                     
    mov64 r1, r7                                    r1 = r7
    jeq r0, 0, lbb_21532                            if r0 == (0 as i32 as i64 as u64) { pc += 1 }
    ja lbb_21544                                    if true { pc += 12 }
lbb_21532:
    stxdw [r6+0x10], r7                     
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    stxdw [r6+0x8], r1                      
    ja lbb_21547                                    if true { pc += 11 }
lbb_21536:
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    mov64 r0, 1                                     r0 = 1 as i32 as i64 as u64
    jeq r7, 0, lbb_21544                            if r7 == (0 as i32 as i64 as u64) { pc += 5 }
    mov64 r1, r7                                    r1 = r7
    mov64 r2, 1                                     r2 = 1 as i32 as i64 as u64
    call function_14385                     
    mov64 r1, r7                                    r1 = r7
    jeq r0, 0, lbb_21532                            if r0 == (0 as i32 as i64 as u64) { pc += -12 }
lbb_21544:
    stxdw [r6+0x10], r1                     
    stxdw [r6+0x8], r0                      
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
lbb_21547:
    stxdw [r6+0x0], r1                      
    exit                                    

function_21549:
    jne r1, 0, lbb_21551                            if r1 != (0 as i32 as i64 as u64) { pc += 1 }
    call function_21409                     
lbb_21551:
    call function_21552                     

function_21552:
    mov64 r3, r1                                    r3 = r1
    mov64 r1, r2                                    r1 = r2
    mov64 r2, r3                                    r2 = r3
    call function_14472                     
    ldxdw r3, [r2+0x10]                     
    stxdw [r1+0x8], r3                      
    ldxdw r2, [r2+0x8]                      
    stxdw [r1+0x0], r2                      
    exit                                    

function_21561:
    mov64 r3, r2                                    r3 = r2
    ldxdw r2, [r1+0x10]                     
    ldxdw r1, [r1+0x8]                      
    call function_28099                     
    exit                                    

function_21566:
    mov64 r3, r2                                    r3 = r2
    ldxdw r2, [r1+0x10]                     
    ldxdw r1, [r1+0x8]                      
    call function_27859                     
    exit                                    

function_21571:
    mov64 r7, r2                                    r7 = r2
    mov64 r6, r1                                    r6 = r1
    ldxdw r2, [r7+0x8]                      
    jeq r2, 0, lbb_21601                            if r2 == (0 as i32 as i64 as u64) { pc += 26 }
    ldxdw r1, [r7+0x0]                      
    mov64 r4, 0                                     r4 = 0 as i32 as i64 as u64
    mov64 r3, r1                                    r3 = r1
    add64 r3, 8                                     r3 += 8   ///  r3 = r3.wrapping_add(8 as i32 as i64 as u64)
lbb_21579:
    ldxdw r8, [r3+0x0]                      
    add64 r8, r4                                    r8 += r4   ///  r8 = r8.wrapping_add(r4)
    add64 r3, 16                                    r3 += 16   ///  r3 = r3.wrapping_add(16 as i32 as i64 as u64)
    add64 r2, -1                                    r2 += -1   ///  r2 = r2.wrapping_add(-1 as i32 as i64 as u64)
    mov64 r4, r8                                    r4 = r8
    jne r2, 0, lbb_21579                            if r2 != (0 as i32 as i64 as u64) { pc += -6 }
    ldxdw r2, [r7+0x18]                     
    jeq r2, 0, lbb_21604                            if r2 == (0 as i32 as i64 as u64) { pc += 17 }
    mov64 r4, 0                                     r4 = 0 as i32 as i64 as u64
    mov64 r3, 1                                     r3 = 1 as i32 as i64 as u64
    mov64 r5, 16                                    r5 = 16 as i32 as i64 as u64
    mov64 r2, 1                                     r2 = 1 as i32 as i64 as u64
    jgt r5, r8, lbb_21593                           if r5 > r8 { pc += 1 }
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
lbb_21593:
    ldxdw r1, [r1+0x8]                      
    jeq r1, 0, lbb_21596                            if r1 == (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
lbb_21596:
    jsgt r4, r8, lbb_21601                          if (r4 as i64) > (r8 as i64) { pc += 4 }
    and64 r2, r3                                    r2 &= r3   ///  r2 = r2.and(r3)
    lsh64 r8, 1                                     r8 <<= 1   ///  r8 = r8.wrapping_shl(1)
    and64 r2, 1                                     r2 &= 1   ///  r2 = r2.and(1)
    jeq r2, 0, lbb_21604                            if r2 == (0 as i32 as i64 as u64) { pc += 3 }
lbb_21601:
    mov64 r0, 1                                     r0 = 1 as i32 as i64 as u64
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    ja lbb_21615                                    if true { pc += 11 }
lbb_21604:
    mov64 r0, 1                                     r0 = 1 as i32 as i64 as u64
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    jeq r8, 0, lbb_21615                            if r8 == (0 as i32 as i64 as u64) { pc += 8 }
    mov64 r9, 0                                     r9 = 0 as i32 as i64 as u64
    jsgt r9, r8, lbb_21643                          if (r9 as i64) > (r8 as i64) { pc += 34 }
    mov64 r9, 1                                     r9 = 1 as i32 as i64 as u64
    mov64 r1, r8                                    r1 = r8
    mov64 r2, 1                                     r2 = 1 as i32 as i64 as u64
    call function_14385                     
    jeq r0, 0, lbb_21643                            if r0 == (0 as i32 as i64 as u64) { pc += 29 }
    mov64 r1, r8                                    r1 = r8
lbb_21615:
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
    stxdw [r10-0x10], r2                    
    stxdw [r10-0x18], r0                    
    stxdw [r10-0x20], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -32                                   r1 += -32   ///  r1 = r1.wrapping_add(-32 as i32 as i64 as u64)
    lddw r2, 0x100041998 --> b"\x00\x00\x00\x00\xc8\x9d\x02\x00\x18\x00\x00\x00\x00\x00\x00\x00\x08\x00\…        r2 load str located at 4295235992
    mov64 r3, r7                                    r3 = r7
    call function_26898                     
    jne r0, 0, lbb_21633                            if r0 != (0 as i32 as i64 as u64) { pc += 7 }
    ldxdw r1, [r10-0x10]                    
    stxdw [r6+0x10], r1                     
    ldxdw r1, [r10-0x18]                    
    stxdw [r6+0x8], r1                      
    ldxdw r1, [r10-0x20]                    
    stxdw [r6+0x0], r1                      
    exit                                    
lbb_21633:
    mov64 r3, r10                                   r3 = r10
    add64 r3, -1                                    r3 += -1   ///  r3 = r3.wrapping_add(-1 as i32 as i64 as u64)
    lddw r1, 0x10003f52e --> b"a formatting trait implementation returned an error"        r1 load str located at 4295226670
    mov64 r2, 51                                    r2 = 51 as i32 as i64 as u64
    lddw r4, 0x1000419f0 --> b"\x00\x00\x00\x00\xc0\x9d\x02\x00\x00\x00\x00\x00\x00\x00\x00\x00\x01\x00\…        r4 load str located at 4295236080
    lddw r5, 0x100041a10 --> b"\x00\x00\x00\x00a\xf5\x03\x00\x18\x00\x00\x00\x00\x00\x00\x00y\x02\x00\x0…        r5 load str located at 4295236112
    call function_25967                     
lbb_21643:
    mov64 r1, r9                                    r1 = r9
    mov64 r2, r8                                    r2 = r8
    call function_21549                     

function_21646:
    mov64 r6, r1                                    r6 = r1
    mov64 r1, r2                                    r1 = r2
    lsh64 r1, 32                                    r1 <<= 32   ///  r1 = r1.wrapping_shl(32)
    rsh64 r1, 32                                    r1 >>= 32   ///  r1 = r1.wrapping_shr(32)
    mov64 r3, 128                                   r3 = 128 as i32 as i64 as u64
    jgt r3, r1, lbb_21676                           if r3 > r1 { pc += 24 }
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
    stxw [r10-0x4], r3                      
    mov64 r3, 2048                                  r3 = 2048 as i32 as i64 as u64
    jgt r3, r1, lbb_21689                           if r3 > r1 { pc += 33 }
    mov64 r1, r2                                    r1 = r2
    lsh64 r1, 32                                    r1 <<= 32   ///  r1 = r1.wrapping_shl(32)
    rsh64 r1, 32                                    r1 >>= 32   ///  r1 = r1.wrapping_shr(32)
    mov64 r3, 65536                                 r3 = 65536 as i32 as i64 as u64
    jgt r3, r1, lbb_21662                           if r3 > r1 { pc += 1 }
    ja lbb_21698                                    if true { pc += 36 }
lbb_21662:
    mov64 r1, r2                                    r1 = r2
    and64 r1, 63                                    r1 &= 63   ///  r1 = r1.and(63)
    or64 r1, 128                                    r1 |= 128   ///  r1 = r1.or(128)
    stxb [r10-0x2], r1                      
    mov64 r1, r2                                    r1 = r2
    rsh64 r1, 12                                    r1 >>= 12   ///  r1 = r1.wrapping_shr(12)
    or64 r1, 224                                    r1 |= 224   ///  r1 = r1.or(224)
    stxb [r10-0x4], r1                      
    rsh64 r2, 6                                     r2 >>= 6   ///  r2 = r2.wrapping_shr(6)
    and64 r2, 63                                    r2 &= 63   ///  r2 = r2.and(63)
    or64 r2, 128                                    r2 |= 128   ///  r2 = r2.or(128)
    stxb [r10-0x3], r2                      
    mov64 r7, 3                                     r7 = 3 as i32 as i64 as u64
    ja lbb_21717                                    if true { pc += 41 }
lbb_21676:
    ldxdw r7, [r6+0x10]                     
    ldxdw r1, [r6+0x0]                      
    jne r7, r1, lbb_21683                           if r7 != r1 { pc += 4 }
    mov64 r1, r6                                    r1 = r6
    mov64 r8, r2                                    r8 = r2
    call function_21465                     
    mov64 r2, r8                                    r2 = r8
lbb_21683:
    ldxdw r1, [r6+0x8]                      
    add64 r1, r7                                    r1 += r7   ///  r1 = r1.wrapping_add(r7)
    stxb [r1+0x0], r2                       
    add64 r7, 1                                     r7 += 1   ///  r7 = r7.wrapping_add(1 as i32 as i64 as u64)
    stxdw [r6+0x10], r7                     
    ja lbb_21734                                    if true { pc += 45 }
lbb_21689:
    mov64 r1, r2                                    r1 = r2
    and64 r1, 63                                    r1 &= 63   ///  r1 = r1.and(63)
    or64 r1, 128                                    r1 |= 128   ///  r1 = r1.or(128)
    stxb [r10-0x3], r1                      
    rsh64 r2, 6                                     r2 >>= 6   ///  r2 = r2.wrapping_shr(6)
    or64 r2, 192                                    r2 |= 192   ///  r2 = r2.or(192)
    stxb [r10-0x4], r2                      
    mov64 r7, 2                                     r7 = 2 as i32 as i64 as u64
    ja lbb_21717                                    if true { pc += 19 }
lbb_21698:
    mov64 r1, r2                                    r1 = r2
    and64 r1, 63                                    r1 &= 63   ///  r1 = r1.and(63)
    or64 r1, 128                                    r1 |= 128   ///  r1 = r1.or(128)
    stxb [r10-0x1], r1                      
    mov64 r1, r2                                    r1 = r2
    rsh64 r1, 6                                     r1 >>= 6   ///  r1 = r1.wrapping_shr(6)
    and64 r1, 63                                    r1 &= 63   ///  r1 = r1.and(63)
    or64 r1, 128                                    r1 |= 128   ///  r1 = r1.or(128)
    stxb [r10-0x2], r1                      
    mov64 r1, r2                                    r1 = r2
    rsh64 r1, 12                                    r1 >>= 12   ///  r1 = r1.wrapping_shr(12)
    and64 r1, 63                                    r1 &= 63   ///  r1 = r1.and(63)
    or64 r1, 128                                    r1 |= 128   ///  r1 = r1.or(128)
    stxb [r10-0x3], r1                      
    rsh64 r2, 18                                    r2 >>= 18   ///  r2 = r2.wrapping_shr(18)
    and64 r2, 7                                     r2 &= 7   ///  r2 = r2.and(7)
    or64 r2, 240                                    r2 |= 240   ///  r2 = r2.or(240)
    stxb [r10-0x4], r2                      
    mov64 r7, 4                                     r7 = 4 as i32 as i64 as u64
lbb_21717:
    ldxdw r8, [r6+0x10]                     
    ldxdw r1, [r6+0x0]                      
    sub64 r1, r8                                    r1 -= r8   ///  r1 = r1.wrapping_sub(r8)
    jge r1, r7, lbb_21726                           if r1 >= r7 { pc += 5 }
    mov64 r1, r6                                    r1 = r6
    mov64 r2, r8                                    r2 = r8
    mov64 r3, r7                                    r3 = r7
    call function_21424                     
    ldxdw r8, [r6+0x10]                     
lbb_21726:
    ldxdw r1, [r6+0x8]                      
    add64 r1, r8                                    r1 += r8   ///  r1 = r1.wrapping_add(r8)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -4                                    r2 += -4   ///  r2 = r2.wrapping_add(-4 as i32 as i64 as u64)
    mov64 r3, r7                                    r3 = r7
    call function_30349                     
    add64 r8, r7                                    r8 += r7   ///  r8 = r8.wrapping_add(r7)
    stxdw [r6+0x10], r8                     
lbb_21734:
    exit                                    

function_21735:
    mov64 r6, r3                                    r6 = r3
    mov64 r7, r1                                    r7 = r1
    ldxdw r8, [r7+0x10]                     
    ldxdw r1, [r7+0x0]                      
    sub64 r1, r8                                    r1 -= r8   ///  r1 = r1.wrapping_sub(r8)
    jge r1, r6, lbb_21748                           if r1 >= r6 { pc += 7 }
    mov64 r1, r7                                    r1 = r7
    mov64 r9, r2                                    r9 = r2
    mov64 r2, r8                                    r2 = r8
    mov64 r3, r6                                    r3 = r6
    call function_21424                     
    mov64 r2, r9                                    r2 = r9
    ldxdw r8, [r7+0x10]                     
lbb_21748:
    ldxdw r1, [r7+0x8]                      
    add64 r1, r8                                    r1 += r8   ///  r1 = r1.wrapping_add(r8)
    mov64 r3, r6                                    r3 = r6
    call function_30349                     
    add64 r8, r6                                    r8 += r6   ///  r8 = r8.wrapping_add(r6)
    stxdw [r7+0x10], r8                     
    mov64 r0, 0                                     r0 = 0 as i32 as i64 as u64
    exit                                    

function_21756:
    call function_21646                     
    mov64 r0, 0                                     r0 = 0 as i32 as i64 as u64
    exit                                    

function_21759:
    exit                                    

function_21760:
    exit                                    

function_21761:
    mov64 r7, r2                                    r7 = r2
    mov64 r6, r1                                    r6 = r1
    and64 r2, 7                                     r2 &= 7   ///  r2 = r2.and(7)
    jne r2, 0, lbb_21772                            if r2 != (0 as i32 as i64 as u64) { pc += 7 }
lbb_21765:
    mov64 r1, r7                                    r1 = r7
    and64 r1, 8                                     r1 &= 8   ///  r1 = r1.and(8)
    jeq r1, 0, lbb_21835                            if r1 == (0 as i32 as i64 as u64) { pc += 67 }
    ldxdw r1, [r6+0xa0]                     
    mov64 r2, 41                                    r2 = 41 as i32 as i64 as u64
    jgt r2, r1, lbb_21810                           if r2 > r1 { pc += 39 }
    ja lbb_21775                                    if true { pc += 3 }
lbb_21772:
    ldxdw r1, [r6+0xa0]                     
    mov64 r3, 41                                    r3 = 41 as i32 as i64 as u64
    jgt r3, r1, lbb_21779                           if r3 > r1 { pc += 4 }
lbb_21775:
    mov64 r2, 40                                    r2 = 40 as i32 as i64 as u64
    lddw r3, 0x100042210 --> b"\x00\x00\x00\x00Y\x08\x04\x00\x1e\x00\x00\x00\x00\x00\x00\x00\xac\x01\x00…        r3 load str located at 4295238160
    call function_28353                     
lbb_21779:
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
    jeq r1, 0, lbb_21808                            if r1 == (0 as i32 as i64 as u64) { pc += 27 }
    lsh64 r2, 2                                     r2 <<= 2   ///  r2 = r2.wrapping_shl(2)
    lddw r3, 0x10003fd88 --> b"\x01\x00\x00\x00\x0a\x00\x00\x00d\x00\x00\x00\xe8\x03\x00\x00\x10'\x00\x0…        r3 load str located at 4295228808
    add64 r3, r2                                    r3 += r2   ///  r3 = r3.wrapping_add(r2)
    ldxw r3, [r3+0x0]                       
    mov64 r4, r1                                    r4 = r1
    lsh64 r4, 2                                     r4 <<= 2   ///  r4 = r4.wrapping_shl(2)
    mov64 r2, r6                                    r2 = r6
    add64 r2, r4                                    r2 += r4   ///  r2 = r2.wrapping_add(r4)
    mov64 r8, 0                                     r8 = 0 as i32 as i64 as u64
    mov64 r0, r6                                    r0 = r6
lbb_21792:
    ldxw r5, [r0+0x0]                       
    mul64 r5, r3                                    r5 *= r3   ///  r5 = r5.wrapping_mul(r3)
    add64 r5, r8                                    r5 += r8   ///  r5 = r5.wrapping_add(r8)
    stxw [r0+0x0], r5                       
    add64 r0, 4                                     r0 += 4   ///  r0 = r0.wrapping_add(4 as i32 as i64 as u64)
    rsh64 r5, 32                                    r5 >>= 32   ///  r5 = r5.wrapping_shr(32)
    add64 r4, -4                                    r4 += -4   ///  r4 = r4.wrapping_add(-4 as i32 as i64 as u64)
    mov64 r8, r5                                    r8 = r5
    jeq r4, 0, lbb_21802                            if r4 == (0 as i32 as i64 as u64) { pc += 1 }
    ja lbb_21792                                    if true { pc += -10 }
lbb_21802:
    mov64 r3, r1                                    r3 = r1
    jeq r5, 0, lbb_21808                            if r5 == (0 as i32 as i64 as u64) { pc += 4 }
    jeq r1, 40, lbb_21876                           if r1 == (40 as i32 as i64 as u64) { pc += 71 }
    stxw [r2+0x0], r5                       
    add64 r1, 1                                     r1 += 1   ///  r1 = r1.wrapping_add(1 as i32 as i64 as u64)
    mov64 r3, r1                                    r3 = r1
lbb_21808:
    stxdw [r6+0xa0], r3                     
    ja lbb_21765                                    if true { pc += -45 }
lbb_21810:
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
    jeq r1, 0, lbb_21834                            if r1 == (0 as i32 as i64 as u64) { pc += 22 }
    mov64 r3, r1                                    r3 = r1
    lsh64 r3, 2                                     r3 <<= 2   ///  r3 = r3.wrapping_shl(2)
    mov64 r2, r6                                    r2 = r6
    add64 r2, r3                                    r2 += r3   ///  r2 = r2.wrapping_add(r3)
    mov64 r0, 0                                     r0 = 0 as i32 as i64 as u64
    mov64 r5, r6                                    r5 = r6
lbb_21818:
    ldxw r4, [r5+0x0]                       
    mul64 r4, 100000000                             r4 *= 100000000   ///  r4 = r4.wrapping_mul(100000000 as u64)
    add64 r4, r0                                    r4 += r0   ///  r4 = r4.wrapping_add(r0)
    stxw [r5+0x0], r4                       
    add64 r5, 4                                     r5 += 4   ///  r5 = r5.wrapping_add(4 as i32 as i64 as u64)
    rsh64 r4, 32                                    r4 >>= 32   ///  r4 = r4.wrapping_shr(32)
    add64 r3, -4                                    r3 += -4   ///  r3 = r3.wrapping_add(-4 as i32 as i64 as u64)
    mov64 r0, r4                                    r0 = r4
    jeq r3, 0, lbb_21828                            if r3 == (0 as i32 as i64 as u64) { pc += 1 }
    ja lbb_21818                                    if true { pc += -10 }
lbb_21828:
    mov64 r3, r1                                    r3 = r1
    jeq r4, 0, lbb_21834                            if r4 == (0 as i32 as i64 as u64) { pc += 4 }
    jeq r1, 40, lbb_21876                           if r1 == (40 as i32 as i64 as u64) { pc += 45 }
    stxw [r2+0x0], r4                       
    add64 r1, 1                                     r1 += 1   ///  r1 = r1.wrapping_add(1 as i32 as i64 as u64)
    mov64 r3, r1                                    r3 = r1
lbb_21834:
    stxdw [r6+0xa0], r3                     
lbb_21835:
    mov64 r1, r7                                    r1 = r7
    and64 r1, 16                                    r1 &= 16   ///  r1 = r1.and(16)
    jeq r1, 0, lbb_21843                            if r1 == (0 as i32 as i64 as u64) { pc += 5 }
    mov64 r1, r6                                    r1 = r6
    lddw r2, 0x10003f5e0 --> b"\x00\x00"            r2 load str located at 4295226848
    mov64 r3, 2                                     r3 = 2 as i32 as i64 as u64
    call function_29423                     
lbb_21843:
    mov64 r1, r7                                    r1 = r7
    and64 r1, 32                                    r1 &= 32   ///  r1 = r1.and(32)
    jeq r1, 0, lbb_21851                            if r1 == (0 as i32 as i64 as u64) { pc += 5 }
    mov64 r1, r6                                    r1 = r6
    lddw r2, 0x10003f5e8 --> b"\x00\x00\x00\x00"        r2 load str located at 4295226856
    mov64 r3, 4                                     r3 = 4 as i32 as i64 as u64
    call function_29423                     
lbb_21851:
    mov64 r1, r7                                    r1 = r7
    and64 r1, 64                                    r1 &= 64   ///  r1 = r1.and(64)
    jeq r1, 0, lbb_21859                            if r1 == (0 as i32 as i64 as u64) { pc += 5 }
    mov64 r1, r6                                    r1 = r6
    lddw r2, 0x10003f5f8 --> b"\x00\x00\x00\x00\x00\x00\x00"        r2 load str located at 4295226872
    mov64 r3, 7                                     r3 = 7 as i32 as i64 as u64
    call function_29423                     
lbb_21859:
    mov64 r1, r7                                    r1 = r7
    and64 r1, 128                                   r1 &= 128   ///  r1 = r1.and(128)
    jeq r1, 0, lbb_21867                            if r1 == (0 as i32 as i64 as u64) { pc += 5 }
    mov64 r1, r6                                    r1 = r6
    lddw r2, 0x10003f614 --> b"\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00"        r2 load str located at 4295226900
    mov64 r3, 14                                    r3 = 14 as i32 as i64 as u64
    call function_29423                     
lbb_21867:
    and64 r7, 256                                   r7 &= 256   ///  r7 = r7.and(256)
    jeq r7, 0, lbb_21874                            if r7 == (0 as i32 as i64 as u64) { pc += 5 }
    mov64 r1, r6                                    r1 = r6
    lddw r2, 0x10003f64c --> b"\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\…        r2 load str located at 4295226956
    mov64 r3, 27                                    r3 = 27 as i32 as i64 as u64
    call function_29423                     
lbb_21874:
    mov64 r0, r6                                    r0 = r6
    exit                                    
lbb_21876:
    mov64 r1, 40                                    r1 = 40 as i32 as i64 as u64
    mov64 r2, 40                                    r2 = 40 as i32 as i64 as u64
    lddw r3, 0x100042210 --> b"\x00\x00\x00\x00Y\x08\x04\x00\x1e\x00\x00\x00\x00\x00\x00\x00\xac\x01\x00…        r3 load str located at 4295238160
    call function_25832                     

function_21881:
    ldxdw r0, [r2+0x0]                      
    jne r0, 0, lbb_21889                            if r0 != (0 as i32 as i64 as u64) { pc += 6 }
    lddw r1, 0x10003f6e7 --> b"assertion failed: d.mant > 0"        r1 load str located at 4295227111
    mov64 r2, 28                                    r2 = 28 as i32 as i64 as u64
    lddw r3, 0x100041a58 --> b"\x00\x00\x00\x00\xb8\xf6\x03\x00/\x00\x00\x00\x00\x00\x00\x00u\x00\x00\x0…        r3 load str located at 4295236184
    call function_25816                     
lbb_21889:
    ldxdw r7, [r2+0x8]                      
    jne r7, 0, lbb_21897                            if r7 != (0 as i32 as i64 as u64) { pc += 6 }
    lddw r1, 0x10003f703 --> b"assertion failed: d.minus > 0"        r1 load str located at 4295227139
    mov64 r2, 29                                    r2 = 29 as i32 as i64 as u64
    lddw r3, 0x100041a70 --> b"\x00\x00\x00\x00\xb8\xf6\x03\x00/\x00\x00\x00\x00\x00\x00\x00v\x00\x00\x0…        r3 load str located at 4295236208
    call function_25816                     
lbb_21897:
    stxdw [r10-0x598], r3                   
    ldxdw r6, [r2+0x10]                     
    jne r6, 0, lbb_21906                            if r6 != (0 as i32 as i64 as u64) { pc += 6 }
    lddw r1, 0x10003f720 --> b"assertion failed: d.plus > 0"        r1 load str located at 4295227168
    mov64 r2, 28                                    r2 = 28 as i32 as i64 as u64
    lddw r3, 0x100041a88 --> b"\x00\x00\x00\x00\xb8\xf6\x03\x00/\x00\x00\x00\x00\x00\x00\x00w\x00\x00\x0…        r3 load str located at 4295236232
    call function_25816                     
lbb_21906:
    mov64 r5, r0                                    r5 = r0
    add64 r5, r6                                    r5 += r6   ///  r5 = r5.wrapping_add(r6)
    mov64 r3, 1                                     r3 = 1 as i32 as i64 as u64
    jgt r0, r5, lbb_21911                           if r0 > r5 { pc += 1 }
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
lbb_21911:
    and64 r3, 1                                     r3 &= 1   ///  r3 = r3.and(1)
    jne r3, 0, lbb_22180                            if r3 != (0 as i32 as i64 as u64) { pc += 267 }
    jgt r7, r0, lbb_22186                           if r7 > r0 { pc += 272 }
    stxdw [r10-0x580], r4                   
    jgt r4, 16, lbb_21917                           if r4 > (16 as i32 as i64 as u64) { pc += 1 }
    ja lbb_22192                                    if true { pc += 275 }
lbb_21917:
    mov64 r3, r0                                    r3 = r0
    add64 r3, r6                                    r3 += r6   ///  r3 = r3.wrapping_add(r6)
    mov64 r9, 64                                    r9 = 64 as i32 as i64 as u64
    add64 r3, -1                                    r3 += -1   ///  r3 = r3.wrapping_add(-1 as i32 as i64 as u64)
    jeq r3, 0, lbb_21964                            if r3 == (0 as i32 as i64 as u64) { pc += 42 }
    mov64 r4, r3                                    r4 = r3
    rsh64 r4, 1                                     r4 >>= 1   ///  r4 = r4.wrapping_shr(1)
    or64 r3, r4                                     r3 |= r4   ///  r3 = r3.or(r4)
    mov64 r4, r3                                    r4 = r3
    rsh64 r4, 2                                     r4 >>= 2   ///  r4 = r4.wrapping_shr(2)
    or64 r3, r4                                     r3 |= r4   ///  r3 = r3.or(r4)
    mov64 r4, r3                                    r4 = r3
    rsh64 r4, 4                                     r4 >>= 4   ///  r4 = r4.wrapping_shr(4)
    or64 r3, r4                                     r3 |= r4   ///  r3 = r3.or(r4)
    mov64 r4, r3                                    r4 = r3
    rsh64 r4, 8                                     r4 >>= 8   ///  r4 = r4.wrapping_shr(8)
    or64 r3, r4                                     r3 |= r4   ///  r3 = r3.or(r4)
    mov64 r4, r3                                    r4 = r3
    rsh64 r4, 16                                    r4 >>= 16   ///  r4 = r4.wrapping_shr(16)
    or64 r3, r4                                     r3 |= r4   ///  r3 = r3.or(r4)
    mov64 r4, r3                                    r4 = r3
    rsh64 r4, 32                                    r4 >>= 32   ///  r4 = r4.wrapping_shr(32)
    or64 r3, r4                                     r3 |= r4   ///  r3 = r3.or(r4)
    xor64 r3, -1                                    r3 ^= -1   ///  r3 = r3.xor(-1)
    lddw r4, 0x5555555555555555                     r4 load str located at 6148914691236517205
    mov64 r5, r3                                    r5 = r3
    rsh64 r5, 1                                     r5 >>= 1   ///  r5 = r5.wrapping_shr(1)
    and64 r5, r4                                    r5 &= r4   ///  r5 = r5.and(r4)
    sub64 r3, r5                                    r3 -= r5   ///  r3 = r3.wrapping_sub(r5)
    lddw r4, 0x3333333333333333                     r4 load str located at 3689348814741910323
    mov64 r9, r3                                    r9 = r3
    and64 r9, r4                                    r9 &= r4   ///  r9 = r9.and(r4)
    rsh64 r3, 2                                     r3 >>= 2   ///  r3 = r3.wrapping_shr(2)
    and64 r3, r4                                    r3 &= r4   ///  r3 = r3.and(r4)
    add64 r9, r3                                    r9 += r3   ///  r9 = r9.wrapping_add(r3)
    mov64 r3, r9                                    r3 = r9
    rsh64 r3, 4                                     r3 >>= 4   ///  r3 = r3.wrapping_shr(4)
    add64 r9, r3                                    r9 += r3   ///  r9 = r9.wrapping_add(r3)
    lddw r3, 0xf0f0f0f0f0f0f0f                      r3 load str located at 1085102592571150095
    and64 r9, r3                                    r9 &= r3   ///  r9 = r9.and(r3)
    lddw r3, 0x101010101010101                      r3 load str located at 72340172838076673
    mul64 r9, r3                                    r9 *= r3   ///  r9 = r9.wrapping_mul(r3)
    rsh64 r9, 56                                    r9 >>= 56   ///  r9 = r9.wrapping_shr(56)
lbb_21964:
    stxdw [r10-0x5b0], r1                   
    lddw r4, 0x100000000                            r4 load str located at 4294967296
    mov64 r3, 1                                     r3 = 1 as i32 as i64 as u64
    jgt r4, r0, lbb_21970                           if r4 > r0 { pc += 1 }
    mov64 r3, 2                                     r3 = 2 as i32 as i64 as u64
lbb_21970:
    ldxh r8, [r2+0x18]                      
    ldxb r1, [r2+0x1a]                      
    stxdw [r10-0x568], r1                   
    stxdw [r10-0x4a0], r3                   
    stxw [r10-0x540], r0                    
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
    jgt r4, r0, lbb_21979                           if r4 > r0 { pc += 2 }
    rsh64 r0, 32                                    r0 >>= 32   ///  r0 = r0.wrapping_shr(32)
    mov64 r2, r0                                    r2 = r0
lbb_21979:
    stxw [r10-0x53c], r2                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -1336                                 r1 += -1336   ///  r1 = r1.wrapping_add(-1336 as i32 as i64 as u64)
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
    mov64 r3, 152                                   r3 = 152 as i32 as i64 as u64
    call function_30383                     
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    lddw r2, 0x100000000                            r2 load str located at 4294967296
    jgt r2, r7, lbb_21991                           if r2 > r7 { pc += 2 }
    mov64 r1, r7                                    r1 = r7
    rsh64 r1, 32                                    r1 >>= 32   ///  r1 = r1.wrapping_shr(32)
lbb_21991:
    stxw [r10-0x494], r1                    
    stxw [r10-0x498], r7                    
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    jgt r2, r7, lbb_21996                           if r2 > r7 { pc += 1 }
    mov64 r1, 2                                     r1 = 2 as i32 as i64 as u64
lbb_21996:
    lsh64 r8, 48                                    r8 <<= 48   ///  r8 = r8.wrapping_shl(48)
    stxdw [r10-0x3f8], r1                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -1168                                 r1 += -1168   ///  r1 = r1.wrapping_add(-1168 as i32 as i64 as u64)
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
    mov64 r3, 152                                   r3 = 152 as i32 as i64 as u64
    call function_30383                     
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    lddw r3, 0x100000000                            r3 load str located at 4294967296
    jgt r3, r6, lbb_22008                           if r3 > r6 { pc += 1 }
    mov64 r1, 2                                     r1 = 2 as i32 as i64 as u64
lbb_22008:
    arsh64 r8, 48                                   r8 >>= 48 (signed)   ///  r8 = (r8 as i64).wrapping_shr(48)
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
    jgt r3, r6, lbb_22013                           if r3 > r6 { pc += 2 }
    mov64 r2, r6                                    r2 = r6
    rsh64 r2, 32                                    r2 >>= 32   ///  r2 = r2.wrapping_shr(32)
lbb_22013:
    stxw [r10-0x3ec], r2                    
    stxw [r10-0x3f0], r6                    
    stxdw [r10-0x350], r1                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -1000                                 r1 += -1000   ///  r1 = r1.wrapping_add(-1000 as i32 as i64 as u64)
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
    mov64 r3, 152                                   r3 = 152 as i32 as i64 as u64
    call function_30383                     
    mov64 r1, r10                                   r1 = r10
    add64 r1, -836                                  r1 += -836   ///  r1 = r1.wrapping_add(-836 as i32 as i64 as u64)
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
    mov64 r3, 156                                   r3 = 156 as i32 as i64 as u64
    call function_30383                     
    mov64 r1, r8                                    r1 = r8
    sub64 r1, r9                                    r1 -= r9   ///  r1 = r1.wrapping_sub(r9)
    mov64 r9, r1                                    r9 = r1
    mul64 r9, 1292913986                            r9 *= 1292913986   ///  r9 = r9.wrapping_mul(1292913986 as u64)
    lddw r1, 0x1344135080                           r1 load str located at 82746495104
    add64 r9, r1                                    r9 += r1   ///  r9 = r9.wrapping_add(r1)
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    stxdw [r10-0x2a8], r1                   
    stxw [r10-0x348], r1                    
    rsh64 r9, 32                                    r9 >>= 32   ///  r9 = r9.wrapping_shr(32)
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    jsgt r1, r8, lbb_22050                          if (r1 as i64) > (r8 as i64) { pc += 11 }
    mov64 r1, r10                                   r1 = r10
    add64 r1, -1344                                 r1 += -1344   ///  r1 = r1.wrapping_add(-1344 as i32 as i64 as u64)
    mov64 r2, r8                                    r2 = r8
    call function_29303                     
    mov64 r1, r10                                   r1 = r10
    add64 r1, -1176                                 r1 += -1176   ///  r1 = r1.wrapping_add(-1176 as i32 as i64 as u64)
    mov64 r2, r8                                    r2 = r8
    call function_29303                     
    mov64 r1, r10                                   r1 = r10
    add64 r1, -1008                                 r1 += -1008   ///  r1 = r1.wrapping_add(-1008 as i32 as i64 as u64)
    ja lbb_22055                                    if true { pc += 5 }
lbb_22050:
    neg64 r8                                        r8 = -r8   ///  r8 = (r8 as i64).wrapping_neg() as u64
    lsh64 r8, 48                                    r8 <<= 48   ///  r8 = r8.wrapping_shl(48)
    arsh64 r8, 48                                   r8 >>= 48 (signed)   ///  r8 = (r8 as i64).wrapping_shr(48)
    mov64 r1, r10                                   r1 = r10
    add64 r1, -840                                  r1 += -840   ///  r1 = r1.wrapping_add(-840 as i32 as i64 as u64)
lbb_22055:
    mov64 r2, r8                                    r2 = r8
    call function_29303                     
    mov64 r1, r9                                    r1 = r9
    lsh64 r1, 48                                    r1 <<= 48   ///  r1 = r1.wrapping_shl(48)
    arsh64 r1, 48                                   r1 >>= 48 (signed)   ///  r1 = (r1 as i64).wrapping_shr(48)
    jsgt r1, -1, lbb_22076                          if (r1 as i64) > (-1 as i32 as i64) { pc += 15 }
    mov64 r8, r9                                    r8 = r9
    neg64 r8                                        r8 = -r8   ///  r8 = (r8 as i64).wrapping_neg() as u64
    and64 r8, 65535                                 r8 &= 65535   ///  r8 = r8.and(65535)
    mov64 r1, r10                                   r1 = r10
    add64 r1, -1344                                 r1 += -1344   ///  r1 = r1.wrapping_add(-1344 as i32 as i64 as u64)
    mov64 r2, r8                                    r2 = r8
    call function_21761                     
    mov64 r1, r10                                   r1 = r10
    add64 r1, -1176                                 r1 += -1176   ///  r1 = r1.wrapping_add(-1176 as i32 as i64 as u64)
    mov64 r2, r8                                    r2 = r8
    call function_21761                     
    mov64 r1, r10                                   r1 = r10
    add64 r1, -1008                                 r1 += -1008   ///  r1 = r1.wrapping_add(-1008 as i32 as i64 as u64)
    mov64 r2, r8                                    r2 = r8
    ja lbb_22080                                    if true { pc += 4 }
lbb_22076:
    mov64 r2, r9                                    r2 = r9
    and64 r2, 65535                                 r2 &= 65535   ///  r2 = r2.and(65535)
    mov64 r1, r10                                   r1 = r10
    add64 r1, -840                                  r1 += -840   ///  r1 = r1.wrapping_add(-840 as i32 as i64 as u64)
lbb_22080:
    call function_21761                     
    ldxdw r7, [r10-0x4a0]                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -168                                  r1 += -168   ///  r1 = r1.wrapping_add(-168 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -1344                                 r2 += -1344   ///  r2 = r2.wrapping_add(-1344 as i32 as i64 as u64)
    mov64 r3, 160                                   r3 = 160 as i32 as i64 as u64
    call function_30349                     
    stxdw [r10-0x8], r7                     
    ldxdw r2, [r10-0x350]                   
    mov64 r1, r7                                    r1 = r7
    jgt r7, r2, lbb_22093                           if r7 > r2 { pc += 1 }
    mov64 r1, r2                                    r1 = r2
lbb_22093:
    stxdw [r10-0x548], r2                   
    jgt r1, 40, lbb_22866                           if r1 > (40 as i32 as i64 as u64) { pc += 771 }
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
    stxdw [r10-0x5a8], r9                   
    jeq r1, 0, lbb_22146                            if r1 == (0 as i32 as i64 as u64) { pc += 48 }
    mov64 r6, 0                                     r6 = 0 as i32 as i64 as u64
    mov64 r3, r10                                   r3 = r10
    add64 r3, -1008                                 r3 += -1008   ///  r3 = r3.wrapping_add(-1008 as i32 as i64 as u64)
    mov64 r4, r10                                   r4 = r10
    add64 r4, -168                                  r4 += -168   ///  r4 = r4.wrapping_add(-168 as i32 as i64 as u64)
    mov64 r5, 0                                     r5 = 0 as i32 as i64 as u64
    ja lbb_22113                                    if true { pc += 8 }
lbb_22105:
    stxw [r4+0x0], r8                       
    or64 r0, r9                                     r0 |= r9   ///  r0 = r0.or(r9)
    add64 r4, 4                                     r4 += 4   ///  r4 = r4.wrapping_add(4 as i32 as i64 as u64)
    add64 r3, 4                                     r3 += 4   ///  r3 = r3.wrapping_add(4 as i32 as i64 as u64)
    add64 r5, 1                                     r5 += 1   ///  r5 = r5.wrapping_add(1 as i32 as i64 as u64)
    mov64 r6, r0                                    r6 = r0
    jgt r1, r5, lbb_22113                           if r1 > r5 { pc += 1 }
    ja lbb_22131                                    if true { pc += 18 }
lbb_22113:
    ldxw r0, [r3+0x0]                       
    ldxw r2, [r4+0x0]                       
    add64 r2, r0                                    r2 += r0   ///  r2 = r2.wrapping_add(r0)
    mov64 r8, r2                                    r8 = r2
    lsh64 r8, 32                                    r8 <<= 32   ///  r8 = r8.wrapping_shl(32)
    rsh64 r8, 32                                    r8 >>= 32   ///  r8 = r8.wrapping_shr(32)
    mov64 r9, 1                                     r9 = 1 as i32 as i64 as u64
    mov64 r0, 1                                     r0 = 1 as i32 as i64 as u64
    jne r8, r2, lbb_22123                           if r8 != r2 { pc += 1 }
    mov64 r0, 0                                     r0 = 0 as i32 as i64 as u64
lbb_22123:
    and64 r6, 1                                     r6 &= 1   ///  r6 = r6.and(1)
    add64 r8, r6                                    r8 += r6   ///  r8 = r8.wrapping_add(r6)
    mov64 r2, r8                                    r2 = r8
    lsh64 r2, 32                                    r2 <<= 32   ///  r2 = r2.wrapping_shl(32)
    rsh64 r2, 32                                    r2 >>= 32   ///  r2 = r2.wrapping_shr(32)
    jne r2, r8, lbb_22105                           if r2 != r8 { pc += -24 }
    mov64 r9, 0                                     r9 = 0 as i32 as i64 as u64
    ja lbb_22105                                    if true { pc += -26 }
lbb_22131:
    and64 r0, 1                                     r0 &= 1   ///  r0 = r0.and(1)
    mov64 r3, r1                                    r3 = r1
    ldxdw r9, [r10-0x5a8]                   
    jne r0, 0, lbb_22136                            if r0 != (0 as i32 as i64 as u64) { pc += 1 }
    ja lbb_22146                                    if true { pc += 10 }
lbb_22136:
    jeq r1, 40, lbb_22954                           if r1 == (40 as i32 as i64 as u64) { pc += 817 }
    mov64 r2, r1                                    r2 = r1
    lsh64 r2, 2                                     r2 <<= 2   ///  r2 = r2.wrapping_shl(2)
    mov64 r3, r10                                   r3 = r10
    add64 r3, -168                                  r3 += -168   ///  r3 = r3.wrapping_add(-168 as i32 as i64 as u64)
    add64 r3, r2                                    r3 += r2   ///  r3 = r3.wrapping_add(r2)
    mov64 r2, 1                                     r2 = 1 as i32 as i64 as u64
    stxw [r3+0x0], r2                       
    add64 r1, 1                                     r1 += 1   ///  r1 = r1.wrapping_add(1 as i32 as i64 as u64)
    mov64 r3, r1                                    r3 = r1
lbb_22146:
    stxdw [r10-0x8], r3                     
    ldxdw r6, [r10-0x2a8]                   
    mov64 r1, r6                                    r1 = r6
    jgt r6, r3, lbb_22151                           if r6 > r3 { pc += 1 }
    mov64 r1, r3                                    r1 = r3
lbb_22151:
    mov64 r2, 41                                    r2 = 41 as i32 as i64 as u64
    ldxdw r4, [r10-0x568]                   
    jgt r2, r1, lbb_22155                           if r2 > r1 { pc += 1 }
    ja lbb_22866                                    if true { pc += 711 }
lbb_22155:
    lsh64 r4, 56                                    r4 <<= 56   ///  r4 = r4.wrapping_shl(56)
    arsh64 r4, 56                                   r4 >>= 56 (signed)   ///  r4 = (r4 as i64).wrapping_shr(56)
    lsh64 r1, 2                                     r1 <<= 2   ///  r1 = r1.wrapping_shl(2)
    stxdw [r10-0x568], r4                   
    ja lbb_22164                                    if true { pc += 4 }
lbb_22160:
    add64 r1, -4                                    r1 += -4   ///  r1 = r1.wrapping_add(-4 as i32 as i64 as u64)
    ldxdw r4, [r10-0x568]                   
    jeq r3, 0, lbb_22164                            if r3 == (0 as i32 as i64 as u64) { pc += 1 }
    ja lbb_22203                                    if true { pc += 39 }
lbb_22164:
    jeq r1, 0, lbb_22198                            if r1 == (0 as i32 as i64 as u64) { pc += 33 }
    mov64 r2, r10                                   r2 = r10
    add64 r2, -840                                  r2 += -840   ///  r2 = r2.wrapping_add(-840 as i32 as i64 as u64)
    add64 r2, r1                                    r2 += r1   ///  r2 = r2.wrapping_add(r1)
    ldxw r4, [r2-0x4]                       
    mov64 r2, r10                                   r2 = r10
    add64 r2, -168                                  r2 += -168   ///  r2 = r2.wrapping_add(-168 as i32 as i64 as u64)
    add64 r2, r1                                    r2 += r1   ///  r2 = r2.wrapping_add(r1)
    ldxw r5, [r2-0x4]                       
    mov64 r0, 1                                     r0 = 1 as i32 as i64 as u64
    jne r5, r4, lbb_22176                           if r5 != r4 { pc += 1 }
    mov64 r0, 0                                     r0 = 0 as i32 as i64 as u64
lbb_22176:
    mov64 r3, -1                                    r3 = -1 as i32 as i64 as u64
    jgt r5, r4, lbb_22160                           if r5 > r4 { pc += -18 }
    mov64 r3, r0                                    r3 = r0
    ja lbb_22160                                    if true { pc += -20 }
lbb_22180:
    lddw r1, 0x10003f7a0 --> b"assertion failed: d.mant.checked_add(d.plus).is_some()"        r1 load str located at 4295227296
    mov64 r2, 54                                    r2 = 54 as i32 as i64 as u64
    lddw r3, 0x100041b18 --> b"\x00\x00\x00\x00\xb8\xf6\x03\x00/\x00\x00\x00\x00\x00\x00\x00x\x00\x00\x0…        r3 load str located at 4295236376
    call function_25816                     
lbb_22186:
    lddw r1, 0x10003f769 --> b"assertion failed: d.mant.checked_sub(d.minus).is_some()"        r1 load str located at 4295227241
    mov64 r2, 55                                    r2 = 55 as i32 as i64 as u64
    lddw r3, 0x100041b00 --> b"\x00\x00\x00\x00\xb8\xf6\x03\x00/\x00\x00\x00\x00\x00\x00\x00y\x00\x00\x0…        r3 load str located at 4295236352
    call function_25816                     
lbb_22192:
    lddw r1, 0x10003f73c --> b"assertion failed: buf.len() >= MAX_SIG_DIGITS"        r1 load str located at 4295227196
    mov64 r2, 45                                    r2 = 45 as i32 as i64 as u64
    lddw r3, 0x100041aa0 --> b"\x00\x00\x00\x00\xb8\xf6\x03\x00/\x00\x00\x00\x00\x00\x00\x00z\x00\x00\x0…        r3 load str located at 4295236256
    call function_25816                     
lbb_22198:
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
    jeq r1, 0, lbb_22203                            if r1 == (0 as i32 as i64 as u64) { pc += 3 }
lbb_22200:
    add64 r9, 1                                     r9 += 1   ///  r9 = r9.wrapping_add(1 as i32 as i64 as u64)
    stxdw [r10-0x5a8], r9                   
    ja lbb_22292                                    if true { pc += 89 }
lbb_22203:
    lsh64 r3, 56                                    r3 <<= 56   ///  r3 = r3.wrapping_shl(56)
    arsh64 r3, 56                                   r3 >>= 56 (signed)   ///  r3 = (r3 as i64).wrapping_shr(56)
    jsgt r4, r3, lbb_22200                          if (r4 as i64) > (r3 as i64) { pc += -6 }
    mov64 r1, r10                                   r1 = r10
    add64 r1, -1344                                 r1 += -1344   ///  r1 = r1.wrapping_add(-1344 as i32 as i64 as u64)
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
    jeq r7, 0, lbb_22232                            if r7 == (0 as i32 as i64 as u64) { pc += 22 }
    mov64 r3, r7                                    r3 = r7
    lsh64 r3, 2                                     r3 <<= 2   ///  r3 = r3.wrapping_shl(2)
    add64 r1, r3                                    r1 += r3   ///  r1 = r1.wrapping_add(r3)
    mov64 r4, r10                                   r4 = r10
    add64 r4, -1344                                 r4 += -1344   ///  r4 = r4.wrapping_add(-1344 as i32 as i64 as u64)
    mov64 r0, 0                                     r0 = 0 as i32 as i64 as u64
lbb_22216:
    ldxw r5, [r4+0x0]                       
    mul64 r5, 10                                    r5 *= 10   ///  r5 = r5.wrapping_mul(10 as u64)
    add64 r5, r0                                    r5 += r0   ///  r5 = r5.wrapping_add(r0)
    stxw [r4+0x0], r5                       
    add64 r4, 4                                     r4 += 4   ///  r4 = r4.wrapping_add(4 as i32 as i64 as u64)
    rsh64 r5, 32                                    r5 >>= 32   ///  r5 = r5.wrapping_shr(32)
    add64 r3, -4                                    r3 += -4   ///  r3 = r3.wrapping_add(-4 as i32 as i64 as u64)
    mov64 r0, r5                                    r0 = r5
    jeq r3, 0, lbb_22226                            if r3 == (0 as i32 as i64 as u64) { pc += 1 }
    ja lbb_22216                                    if true { pc += -10 }
lbb_22226:
    mov64 r3, r7                                    r3 = r7
    jeq r5, 0, lbb_22232                            if r5 == (0 as i32 as i64 as u64) { pc += 4 }
    jeq r7, 40, lbb_22954                           if r7 == (40 as i32 as i64 as u64) { pc += 725 }
    stxw [r1+0x0], r5                       
    add64 r7, 1                                     r7 += 1   ///  r7 = r7.wrapping_add(1 as i32 as i64 as u64)
    mov64 r3, r7                                    r3 = r7
lbb_22232:
    stxdw [r10-0x4a0], r3                   
    ldxdw r1, [r10-0x3f8]                   
    mov64 r2, 41                                    r2 = 41 as i32 as i64 as u64
    jgt r2, r1, lbb_22237                           if r2 > r1 { pc += 1 }
    ja lbb_22866                                    if true { pc += 629 }
lbb_22237:
    mov64 r4, r10                                   r4 = r10
    add64 r4, -1176                                 r4 += -1176   ///  r4 = r4.wrapping_add(-1176 as i32 as i64 as u64)
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
    mov64 r5, 0                                     r5 = 0 as i32 as i64 as u64
    ldxdw r2, [r10-0x548]                   
    jeq r1, 0, lbb_22265                            if r1 == (0 as i32 as i64 as u64) { pc += 22 }
    mov64 r5, r1                                    r5 = r1
    lsh64 r5, 2                                     r5 <<= 2   ///  r5 = r5.wrapping_shl(2)
    add64 r4, r5                                    r4 += r5   ///  r4 = r4.wrapping_add(r5)
    mov64 r0, r10                                   r0 = r10
    add64 r0, -1176                                 r0 += -1176   ///  r0 = r0.wrapping_add(-1176 as i32 as i64 as u64)
    mov64 r8, 0                                     r8 = 0 as i32 as i64 as u64
lbb_22249:
    ldxw r7, [r0+0x0]                       
    mul64 r7, 10                                    r7 *= 10   ///  r7 = r7.wrapping_mul(10 as u64)
    add64 r7, r8                                    r7 += r8   ///  r7 = r7.wrapping_add(r8)
    stxw [r0+0x0], r7                       
    add64 r0, 4                                     r0 += 4   ///  r0 = r0.wrapping_add(4 as i32 as i64 as u64)
    rsh64 r7, 32                                    r7 >>= 32   ///  r7 = r7.wrapping_shr(32)
    add64 r5, -4                                    r5 += -4   ///  r5 = r5.wrapping_add(-4 as i32 as i64 as u64)
    mov64 r8, r7                                    r8 = r7
    jeq r5, 0, lbb_22259                            if r5 == (0 as i32 as i64 as u64) { pc += 1 }
    ja lbb_22249                                    if true { pc += -10 }
lbb_22259:
    mov64 r5, r1                                    r5 = r1
    jeq r7, 0, lbb_22265                            if r7 == (0 as i32 as i64 as u64) { pc += 4 }
    jeq r1, 40, lbb_22954                           if r1 == (40 as i32 as i64 as u64) { pc += 692 }
    stxw [r4+0x0], r7                       
    add64 r1, 1                                     r1 += 1   ///  r1 = r1.wrapping_add(1 as i32 as i64 as u64)
    mov64 r5, r1                                    r5 = r1
lbb_22265:
    stxdw [r10-0x3f8], r5                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -1008                                 r1 += -1008   ///  r1 = r1.wrapping_add(-1008 as i32 as i64 as u64)
    jeq r2, 0, lbb_22291                            if r2 == (0 as i32 as i64 as u64) { pc += 22 }
    mov64 r3, r2                                    r3 = r2
    lsh64 r3, 2                                     r3 <<= 2   ///  r3 = r3.wrapping_shl(2)
    add64 r1, r3                                    r1 += r3   ///  r1 = r1.wrapping_add(r3)
    mov64 r4, r10                                   r4 = r10
    add64 r4, -1008                                 r4 += -1008   ///  r4 = r4.wrapping_add(-1008 as i32 as i64 as u64)
    mov64 r0, 0                                     r0 = 0 as i32 as i64 as u64
lbb_22275:
    ldxw r5, [r4+0x0]                       
    mul64 r5, 10                                    r5 *= 10   ///  r5 = r5.wrapping_mul(10 as u64)
    add64 r5, r0                                    r5 += r0   ///  r5 = r5.wrapping_add(r0)
    stxw [r4+0x0], r5                       
    add64 r4, 4                                     r4 += 4   ///  r4 = r4.wrapping_add(4 as i32 as i64 as u64)
    rsh64 r5, 32                                    r5 >>= 32   ///  r5 = r5.wrapping_shr(32)
    add64 r3, -4                                    r3 += -4   ///  r3 = r3.wrapping_add(-4 as i32 as i64 as u64)
    mov64 r0, r5                                    r0 = r5
    jeq r3, 0, lbb_22285                            if r3 == (0 as i32 as i64 as u64) { pc += 1 }
    ja lbb_22275                                    if true { pc += -10 }
lbb_22285:
    mov64 r3, r2                                    r3 = r2
    jeq r5, 0, lbb_22291                            if r5 == (0 as i32 as i64 as u64) { pc += 4 }
    jeq r2, 40, lbb_22954                           if r2 == (40 as i32 as i64 as u64) { pc += 666 }
    stxw [r1+0x0], r5                       
    add64 r2, 1                                     r2 += 1   ///  r2 = r2.wrapping_add(1 as i32 as i64 as u64)
    mov64 r3, r2                                    r3 = r2
lbb_22291:
    stxdw [r10-0x350], r3                   
lbb_22292:
    mov64 r9, r10                                   r9 = r10
    add64 r9, -672                                  r9 += -672   ///  r9 = r9.wrapping_add(-672 as i32 as i64 as u64)
    mov64 r8, r10                                   r8 = r10
    add64 r8, -840                                  r8 += -840   ///  r8 = r8.wrapping_add(-840 as i32 as i64 as u64)
    mov64 r1, r9                                    r1 = r9
    mov64 r2, r8                                    r2 = r8
    mov64 r3, 160                                   r3 = 160 as i32 as i64 as u64
    call function_30349                     
    stxdw [r10-0x200], r6                   
    mov64 r1, r9                                    r1 = r9
    mov64 r2, 1                                     r2 = 1 as i32 as i64 as u64
    call function_29303                     
    ldxdw r6, [r10-0x2a8]                   
    mov64 r9, r10                                   r9 = r10
    add64 r9, -504                                  r9 += -504   ///  r9 = r9.wrapping_add(-504 as i32 as i64 as u64)
    mov64 r1, r9                                    r1 = r9
    mov64 r2, r8                                    r2 = r8
    mov64 r3, 160                                   r3 = 160 as i32 as i64 as u64
    call function_30349                     
    stxdw [r10-0x158], r6                   
    mov64 r1, r9                                    r1 = r9
    mov64 r2, 2                                     r2 = 2 as i32 as i64 as u64
    call function_29303                     
    ldxdw r6, [r10-0x2a8]                   
    mov64 r9, r10                                   r9 = r10
    add64 r9, -336                                  r9 += -336   ///  r9 = r9.wrapping_add(-336 as i32 as i64 as u64)
    mov64 r1, r9                                    r1 = r9
    mov64 r2, r8                                    r2 = r8
    mov64 r3, 160                                   r3 = 160 as i32 as i64 as u64
    call function_30349                     
    stxdw [r10-0xb0], r6                    
    mov64 r1, r9                                    r1 = r9
    mov64 r2, 3                                     r2 = 3 as i32 as i64 as u64
    call function_29303                     
    ldxdw r3, [r10-0x4a0]                   
    ldxdw r2, [r10-0xb0]                    
    mov64 r1, r3                                    r1 = r3
    stxdw [r10-0x588], r2                   
    jgt r3, r2, lbb_22332                           if r3 > r2 { pc += 1 }
    ldxdw r1, [r10-0x588]                   
lbb_22332:
    ldxdw r9, [r10-0x580]                   
    jgt r1, 40, lbb_22866                           if r1 > (40 as i32 as i64 as u64) { pc += 532 }
    mov64 r6, 0                                     r6 = 0 as i32 as i64 as u64
    ldxdw r2, [r10-0x2a8]                   
    stxdw [r10-0x550], r2                   
    ldxdw r2, [r10-0x200]                   
    stxdw [r10-0x578], r2                   
    ldxdw r2, [r10-0x158]                   
    stxdw [r10-0x570], r2                   
    mov64 r7, 41                                    r7 = 41 as i32 as i64 as u64
    ja lbb_22344                                    if true { pc += 1 }
lbb_22343:
    jgt r1, 40, lbb_22866                           if r1 > (40 as i32 as i64 as u64) { pc += 522 }
lbb_22344:
    mov64 r8, r6                                    r8 = r6
    mov64 r4, r1                                    r4 = r1
    lsh64 r4, 2                                     r4 <<= 2   ///  r4 = r4.wrapping_shl(2)
lbb_22347:
    jeq r4, 0, lbb_22396                            if r4 == (0 as i32 as i64 as u64) { pc += 48 }
    mov64 r2, r10                                   r2 = r10
    add64 r2, -1344                                 r2 += -1344   ///  r2 = r2.wrapping_add(-1344 as i32 as i64 as u64)
    add64 r2, r4                                    r2 += r4   ///  r2 = r2.wrapping_add(r4)
    mov64 r5, r10                                   r5 = r10
    add64 r5, -336                                  r5 += -336   ///  r5 = r5.wrapping_add(-336 as i32 as i64 as u64)
    add64 r5, r4                                    r5 += r4   ///  r5 = r5.wrapping_add(r4)
    add64 r4, -4                                    r4 += -4   ///  r4 = r4.wrapping_add(-4 as i32 as i64 as u64)
    ldxw r5, [r5-0x4]                       
    ldxw r0, [r2-0x4]                       
    jeq r5, r0, lbb_22347                           if r5 == r0 { pc += -11 }
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
    jge r5, r0, lbb_22406                           if r5 >= r0 { pc += 46 }
lbb_22360:
    jeq r1, 0, lbb_22403                            if r1 == (0 as i32 as i64 as u64) { pc += 42 }
    mov64 r5, 1                                     r5 = 1 as i32 as i64 as u64
    mov64 r3, r10                                   r3 = r10
    add64 r3, -336                                  r3 += -336   ///  r3 = r3.wrapping_add(-336 as i32 as i64 as u64)
    mov64 r4, r10                                   r4 = r10
    add64 r4, -1344                                 r4 += -1344   ///  r4 = r4.wrapping_add(-1344 as i32 as i64 as u64)
    ja lbb_22375                                    if true { pc += 8 }
lbb_22367:
    stxw [r4+0x0], r6                       
    or64 r0, r5                                     r0 |= r5   ///  r0 = r0.or(r5)
    add64 r4, 4                                     r4 += 4   ///  r4 = r4.wrapping_add(4 as i32 as i64 as u64)
    add64 r3, 4                                     r3 += 4   ///  r3 = r3.wrapping_add(4 as i32 as i64 as u64)
    add64 r2, 1                                     r2 += 1   ///  r2 = r2.wrapping_add(1 as i32 as i64 as u64)
    mov64 r5, r0                                    r5 = r0
    jgt r1, r2, lbb_22375                           if r1 > r2 { pc += 1 }
    ja lbb_22399                                    if true { pc += 24 }
lbb_22375:
    ldxw r0, [r3+0x0]                       
    xor64 r0, -1                                    r0 ^= -1   ///  r0 = r0.xor(-1)
    lsh64 r0, 32                                    r0 <<= 32   ///  r0 = r0.wrapping_shl(32)
    rsh64 r0, 32                                    r0 >>= 32   ///  r0 = r0.wrapping_shr(32)
    ldxw r7, [r4+0x0]                       
    add64 r7, r0                                    r7 += r0   ///  r7 = r7.wrapping_add(r0)
    mov64 r6, r7                                    r6 = r7
    lsh64 r6, 32                                    r6 <<= 32   ///  r6 = r6.wrapping_shl(32)
    rsh64 r6, 32                                    r6 >>= 32   ///  r6 = r6.wrapping_shr(32)
    mov64 r0, 1                                     r0 = 1 as i32 as i64 as u64
    jne r6, r7, lbb_22387                           if r6 != r7 { pc += 1 }
    mov64 r0, 0                                     r0 = 0 as i32 as i64 as u64
lbb_22387:
    and64 r5, 1                                     r5 &= 1   ///  r5 = r5.and(1)
    add64 r6, r5                                    r6 += r5   ///  r6 = r6.wrapping_add(r5)
    mov64 r7, r6                                    r7 = r6
    lsh64 r7, 32                                    r7 <<= 32   ///  r7 = r7.wrapping_shl(32)
    rsh64 r7, 32                                    r7 >>= 32   ///  r7 = r7.wrapping_shr(32)
    mov64 r5, 1                                     r5 = 1 as i32 as i64 as u64
    jne r7, r6, lbb_22367                           if r7 != r6 { pc += -27 }
    mov64 r5, 0                                     r5 = 0 as i32 as i64 as u64
    ja lbb_22367                                    if true { pc += -29 }
lbb_22396:
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
    jeq r4, 0, lbb_22360                            if r4 == (0 as i32 as i64 as u64) { pc += -38 }
    ja lbb_22406                                    if true { pc += 7 }
lbb_22399:
    and64 r0, 1                                     r0 &= 1   ///  r0 = r0.and(1)
    mov64 r7, 41                                    r7 = 41 as i32 as i64 as u64
    jne r0, 0, lbb_22403                            if r0 != (0 as i32 as i64 as u64) { pc += 1 }
    ja lbb_22968                                    if true { pc += 565 }
lbb_22403:
    stxdw [r10-0x4a0], r1                   
    mov64 r2, 8                                     r2 = 8 as i32 as i64 as u64
    mov64 r3, r1                                    r3 = r1
lbb_22406:
    mov64 r1, r3                                    r1 = r3
    ldxdw r4, [r10-0x570]                   
    jgt r3, r4, lbb_22410                           if r3 > r4 { pc += 1 }
    ldxdw r1, [r10-0x570]                   
lbb_22410:
    jgt r7, r1, lbb_22412                           if r7 > r1 { pc += 1 }
    ja lbb_22866                                    if true { pc += 454 }
lbb_22412:
    mov64 r4, r1                                    r4 = r1
    lsh64 r4, 2                                     r4 <<= 2   ///  r4 = r4.wrapping_shl(2)
lbb_22414:
    jeq r4, 0, lbb_22464                            if r4 == (0 as i32 as i64 as u64) { pc += 49 }
    mov64 r0, r10                                   r0 = r10
    add64 r0, -1344                                 r0 += -1344   ///  r0 = r0.wrapping_add(-1344 as i32 as i64 as u64)
    add64 r0, r4                                    r0 += r4   ///  r0 = r0.wrapping_add(r4)
    mov64 r5, r10                                   r5 = r10
    add64 r5, -504                                  r5 += -504   ///  r5 = r5.wrapping_add(-504 as i32 as i64 as u64)
    add64 r5, r4                                    r5 += r4   ///  r5 = r5.wrapping_add(r4)
    add64 r4, -4                                    r4 += -4   ///  r4 = r4.wrapping_add(-4 as i32 as i64 as u64)
    ldxw r5, [r5-0x4]                       
    ldxw r0, [r0-0x4]                       
    jeq r5, r0, lbb_22414                           if r5 == r0 { pc += -11 }
    jge r5, r0, lbb_22475                           if r5 >= r0 { pc += 49 }
lbb_22426:
    jeq r1, 0, lbb_22472                            if r1 == (0 as i32 as i64 as u64) { pc += 45 }
    mov64 r9, r8                                    r9 = r8
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
    mov64 r0, 1                                     r0 = 1 as i32 as i64 as u64
    mov64 r4, r10                                   r4 = r10
    add64 r4, -504                                  r4 += -504   ///  r4 = r4.wrapping_add(-504 as i32 as i64 as u64)
    mov64 r5, r10                                   r5 = r10
    add64 r5, -1344                                 r5 += -1344   ///  r5 = r5.wrapping_add(-1344 as i32 as i64 as u64)
    ja lbb_22443                                    if true { pc += 8 }
lbb_22435:
    stxw [r5+0x0], r7                       
    or64 r6, r0                                     r6 |= r0   ///  r6 = r6.or(r0)
    add64 r5, 4                                     r5 += 4   ///  r5 = r5.wrapping_add(4 as i32 as i64 as u64)
    add64 r4, 4                                     r4 += 4   ///  r4 = r4.wrapping_add(4 as i32 as i64 as u64)
    add64 r3, 1                                     r3 += 1   ///  r3 = r3.wrapping_add(1 as i32 as i64 as u64)
    mov64 r0, r6                                    r0 = r6
    jgt r1, r3, lbb_22443                           if r1 > r3 { pc += 1 }
    ja lbb_22466                                    if true { pc += 23 }
lbb_22443:
    ldxw r6, [r4+0x0]                       
    xor64 r6, -1                                    r6 ^= -1   ///  r6 = r6.xor(-1)
    lsh64 r6, 32                                    r6 <<= 32   ///  r6 = r6.wrapping_shl(32)
    rsh64 r6, 32                                    r6 >>= 32   ///  r6 = r6.wrapping_shr(32)
    ldxw r8, [r5+0x0]                       
    add64 r8, r6                                    r8 += r6   ///  r8 = r8.wrapping_add(r6)
    mov64 r7, r8                                    r7 = r8
    lsh64 r7, 32                                    r7 <<= 32   ///  r7 = r7.wrapping_shl(32)
    rsh64 r7, 32                                    r7 >>= 32   ///  r7 = r7.wrapping_shr(32)
    mov64 r6, 1                                     r6 = 1 as i32 as i64 as u64
    jne r7, r8, lbb_22455                           if r7 != r8 { pc += 1 }
    mov64 r6, 0                                     r6 = 0 as i32 as i64 as u64
lbb_22455:
    and64 r0, 1                                     r0 &= 1   ///  r0 = r0.and(1)
    add64 r7, r0                                    r7 += r0   ///  r7 = r7.wrapping_add(r0)
    mov64 r8, r7                                    r8 = r7
    lsh64 r8, 32                                    r8 <<= 32   ///  r8 = r8.wrapping_shl(32)
    rsh64 r8, 32                                    r8 >>= 32   ///  r8 = r8.wrapping_shr(32)
    mov64 r0, 1                                     r0 = 1 as i32 as i64 as u64
    jne r8, r7, lbb_22435                           if r8 != r7 { pc += -27 }
    mov64 r0, 0                                     r0 = 0 as i32 as i64 as u64
    ja lbb_22435                                    if true { pc += -29 }
lbb_22464:
    jeq r4, 0, lbb_22426                            if r4 == (0 as i32 as i64 as u64) { pc += -39 }
    ja lbb_22475                                    if true { pc += 9 }
lbb_22466:
    and64 r6, 1                                     r6 &= 1   ///  r6 = r6.and(1)
    mov64 r7, 41                                    r7 = 41 as i32 as i64 as u64
    mov64 r8, r9                                    r8 = r9
    ldxdw r9, [r10-0x580]                   
    jne r6, 0, lbb_22472                            if r6 != (0 as i32 as i64 as u64) { pc += 1 }
    ja lbb_22968                                    if true { pc += 496 }
lbb_22472:
    stxdw [r10-0x4a0], r1                   
    or64 r2, 4                                      r2 |= 4   ///  r2 = r2.or(4)
    mov64 r3, r1                                    r3 = r1
lbb_22475:
    mov64 r1, r3                                    r1 = r3
    ldxdw r4, [r10-0x578]                   
    jgt r3, r4, lbb_22479                           if r3 > r4 { pc += 1 }
    ldxdw r1, [r10-0x578]                   
lbb_22479:
    jgt r7, r1, lbb_22481                           if r7 > r1 { pc += 1 }
    ja lbb_22866                                    if true { pc += 385 }
lbb_22481:
    mov64 r4, r1                                    r4 = r1
    lsh64 r4, 2                                     r4 <<= 2   ///  r4 = r4.wrapping_shl(2)
lbb_22483:
    jeq r4, 0, lbb_22533                            if r4 == (0 as i32 as i64 as u64) { pc += 49 }
    mov64 r0, r10                                   r0 = r10
    add64 r0, -1344                                 r0 += -1344   ///  r0 = r0.wrapping_add(-1344 as i32 as i64 as u64)
    add64 r0, r4                                    r0 += r4   ///  r0 = r0.wrapping_add(r4)
    mov64 r5, r10                                   r5 = r10
    add64 r5, -672                                  r5 += -672   ///  r5 = r5.wrapping_add(-672 as i32 as i64 as u64)
    add64 r5, r4                                    r5 += r4   ///  r5 = r5.wrapping_add(r4)
    add64 r4, -4                                    r4 += -4   ///  r4 = r4.wrapping_add(-4 as i32 as i64 as u64)
    ldxw r5, [r5-0x4]                       
    ldxw r0, [r0-0x4]                       
    jeq r5, r0, lbb_22483                           if r5 == r0 { pc += -11 }
    jge r5, r0, lbb_22544                           if r5 >= r0 { pc += 49 }
lbb_22495:
    jeq r1, 0, lbb_22541                            if r1 == (0 as i32 as i64 as u64) { pc += 45 }
    mov64 r9, r8                                    r9 = r8
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
    mov64 r0, 1                                     r0 = 1 as i32 as i64 as u64
    mov64 r4, r10                                   r4 = r10
    add64 r4, -672                                  r4 += -672   ///  r4 = r4.wrapping_add(-672 as i32 as i64 as u64)
    mov64 r5, r10                                   r5 = r10
    add64 r5, -1344                                 r5 += -1344   ///  r5 = r5.wrapping_add(-1344 as i32 as i64 as u64)
    ja lbb_22512                                    if true { pc += 8 }
lbb_22504:
    stxw [r5+0x0], r7                       
    or64 r6, r0                                     r6 |= r0   ///  r6 = r6.or(r0)
    add64 r5, 4                                     r5 += 4   ///  r5 = r5.wrapping_add(4 as i32 as i64 as u64)
    add64 r4, 4                                     r4 += 4   ///  r4 = r4.wrapping_add(4 as i32 as i64 as u64)
    add64 r3, 1                                     r3 += 1   ///  r3 = r3.wrapping_add(1 as i32 as i64 as u64)
    mov64 r0, r6                                    r0 = r6
    jgt r1, r3, lbb_22512                           if r1 > r3 { pc += 1 }
    ja lbb_22535                                    if true { pc += 23 }
lbb_22512:
    ldxw r6, [r4+0x0]                       
    xor64 r6, -1                                    r6 ^= -1   ///  r6 = r6.xor(-1)
    lsh64 r6, 32                                    r6 <<= 32   ///  r6 = r6.wrapping_shl(32)
    rsh64 r6, 32                                    r6 >>= 32   ///  r6 = r6.wrapping_shr(32)
    ldxw r8, [r5+0x0]                       
    add64 r8, r6                                    r8 += r6   ///  r8 = r8.wrapping_add(r6)
    mov64 r7, r8                                    r7 = r8
    lsh64 r7, 32                                    r7 <<= 32   ///  r7 = r7.wrapping_shl(32)
    rsh64 r7, 32                                    r7 >>= 32   ///  r7 = r7.wrapping_shr(32)
    mov64 r6, 1                                     r6 = 1 as i32 as i64 as u64
    jne r7, r8, lbb_22524                           if r7 != r8 { pc += 1 }
    mov64 r6, 0                                     r6 = 0 as i32 as i64 as u64
lbb_22524:
    and64 r0, 1                                     r0 &= 1   ///  r0 = r0.and(1)
    add64 r7, r0                                    r7 += r0   ///  r7 = r7.wrapping_add(r0)
    mov64 r8, r7                                    r8 = r7
    lsh64 r8, 32                                    r8 <<= 32   ///  r8 = r8.wrapping_shl(32)
    rsh64 r8, 32                                    r8 >>= 32   ///  r8 = r8.wrapping_shr(32)
    mov64 r0, 1                                     r0 = 1 as i32 as i64 as u64
    jne r8, r7, lbb_22504                           if r8 != r7 { pc += -27 }
    mov64 r0, 0                                     r0 = 0 as i32 as i64 as u64
    ja lbb_22504                                    if true { pc += -29 }
lbb_22533:
    jeq r4, 0, lbb_22495                            if r4 == (0 as i32 as i64 as u64) { pc += -39 }
    ja lbb_22544                                    if true { pc += 9 }
lbb_22535:
    and64 r6, 1                                     r6 &= 1   ///  r6 = r6.and(1)
    mov64 r7, 41                                    r7 = 41 as i32 as i64 as u64
    mov64 r8, r9                                    r8 = r9
    ldxdw r9, [r10-0x580]                   
    jne r6, 0, lbb_22541                            if r6 != (0 as i32 as i64 as u64) { pc += 1 }
    ja lbb_22968                                    if true { pc += 427 }
lbb_22541:
    stxdw [r10-0x4a0], r1                   
    add64 r2, 2                                     r2 += 2   ///  r2 = r2.wrapping_add(2 as i32 as i64 as u64)
    mov64 r3, r1                                    r3 = r1
lbb_22544:
    mov64 r1, r3                                    r1 = r3
    ldxdw r4, [r10-0x550]                   
    jgt r3, r4, lbb_22548                           if r3 > r4 { pc += 1 }
    ldxdw r1, [r10-0x550]                   
lbb_22548:
    jgt r7, r1, lbb_22550                           if r7 > r1 { pc += 1 }
    ja lbb_22866                                    if true { pc += 316 }
lbb_22550:
    mov64 r4, r1                                    r4 = r1
    lsh64 r4, 2                                     r4 <<= 2   ///  r4 = r4.wrapping_shl(2)
lbb_22552:
    jeq r4, 0, lbb_22602                            if r4 == (0 as i32 as i64 as u64) { pc += 49 }
    mov64 r0, r10                                   r0 = r10
    add64 r0, -1344                                 r0 += -1344   ///  r0 = r0.wrapping_add(-1344 as i32 as i64 as u64)
    add64 r0, r4                                    r0 += r4   ///  r0 = r0.wrapping_add(r4)
    mov64 r5, r10                                   r5 = r10
    add64 r5, -840                                  r5 += -840   ///  r5 = r5.wrapping_add(-840 as i32 as i64 as u64)
    add64 r5, r4                                    r5 += r4   ///  r5 = r5.wrapping_add(r4)
    add64 r4, -4                                    r4 += -4   ///  r4 = r4.wrapping_add(-4 as i32 as i64 as u64)
    ldxw r5, [r5-0x4]                       
    ldxw r0, [r0-0x4]                       
    jeq r5, r0, lbb_22552                           if r5 == r0 { pc += -11 }
    jge r5, r0, lbb_22613                           if r5 >= r0 { pc += 49 }
lbb_22564:
    jeq r1, 0, lbb_22610                            if r1 == (0 as i32 as i64 as u64) { pc += 45 }
    mov64 r9, r8                                    r9 = r8
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
    mov64 r0, 1                                     r0 = 1 as i32 as i64 as u64
    mov64 r4, r10                                   r4 = r10
    add64 r4, -840                                  r4 += -840   ///  r4 = r4.wrapping_add(-840 as i32 as i64 as u64)
    mov64 r5, r10                                   r5 = r10
    add64 r5, -1344                                 r5 += -1344   ///  r5 = r5.wrapping_add(-1344 as i32 as i64 as u64)
    ja lbb_22581                                    if true { pc += 8 }
lbb_22573:
    stxw [r5+0x0], r7                       
    or64 r6, r0                                     r6 |= r0   ///  r6 = r6.or(r0)
    add64 r5, 4                                     r5 += 4   ///  r5 = r5.wrapping_add(4 as i32 as i64 as u64)
    add64 r4, 4                                     r4 += 4   ///  r4 = r4.wrapping_add(4 as i32 as i64 as u64)
    add64 r3, 1                                     r3 += 1   ///  r3 = r3.wrapping_add(1 as i32 as i64 as u64)
    mov64 r0, r6                                    r0 = r6
    jgt r1, r3, lbb_22581                           if r1 > r3 { pc += 1 }
    ja lbb_22604                                    if true { pc += 23 }
lbb_22581:
    ldxw r6, [r4+0x0]                       
    xor64 r6, -1                                    r6 ^= -1   ///  r6 = r6.xor(-1)
    lsh64 r6, 32                                    r6 <<= 32   ///  r6 = r6.wrapping_shl(32)
    rsh64 r6, 32                                    r6 >>= 32   ///  r6 = r6.wrapping_shr(32)
    ldxw r8, [r5+0x0]                       
    add64 r8, r6                                    r8 += r6   ///  r8 = r8.wrapping_add(r6)
    mov64 r7, r8                                    r7 = r8
    lsh64 r7, 32                                    r7 <<= 32   ///  r7 = r7.wrapping_shl(32)
    rsh64 r7, 32                                    r7 >>= 32   ///  r7 = r7.wrapping_shr(32)
    mov64 r6, 1                                     r6 = 1 as i32 as i64 as u64
    jne r7, r8, lbb_22593                           if r7 != r8 { pc += 1 }
    mov64 r6, 0                                     r6 = 0 as i32 as i64 as u64
lbb_22593:
    and64 r0, 1                                     r0 &= 1   ///  r0 = r0.and(1)
    add64 r7, r0                                    r7 += r0   ///  r7 = r7.wrapping_add(r0)
    mov64 r8, r7                                    r8 = r7
    lsh64 r8, 32                                    r8 <<= 32   ///  r8 = r8.wrapping_shl(32)
    rsh64 r8, 32                                    r8 >>= 32   ///  r8 = r8.wrapping_shr(32)
    mov64 r0, 1                                     r0 = 1 as i32 as i64 as u64
    jne r8, r7, lbb_22573                           if r8 != r7 { pc += -27 }
    mov64 r0, 0                                     r0 = 0 as i32 as i64 as u64
    ja lbb_22573                                    if true { pc += -29 }
lbb_22602:
    jeq r4, 0, lbb_22564                            if r4 == (0 as i32 as i64 as u64) { pc += -39 }
    ja lbb_22613                                    if true { pc += 9 }
lbb_22604:
    and64 r6, 1                                     r6 &= 1   ///  r6 = r6.and(1)
    mov64 r7, 41                                    r7 = 41 as i32 as i64 as u64
    mov64 r8, r9                                    r8 = r9
    ldxdw r9, [r10-0x580]                   
    jne r6, 0, lbb_22610                            if r6 != (0 as i32 as i64 as u64) { pc += 1 }
    ja lbb_22968                                    if true { pc += 358 }
lbb_22610:
    stxdw [r10-0x4a0], r1                   
    add64 r2, 1                                     r2 += 1   ///  r2 = r2.wrapping_add(1 as i32 as i64 as u64)
    mov64 r3, r1                                    r3 = r1
lbb_22613:
    jeq r8, r9, lbb_22959                           if r8 == r9 { pc += 345 }
    ldxdw r1, [r10-0x598]                   
    add64 r1, r8                                    r1 += r8   ///  r1 = r1.wrapping_add(r8)
    add64 r2, 48                                    r2 += 48   ///  r2 = r2.wrapping_add(48 as i32 as i64 as u64)
    stxb [r1+0x0], r2                       
    ldxdw r2, [r10-0x3f8]                   
    mov64 r1, r3                                    r1 = r3
    stxdw [r10-0x558], r2                   
    jgt r3, r2, lbb_22623                           if r3 > r2 { pc += 1 }
    ldxdw r1, [r10-0x558]                   
lbb_22623:
    jgt r7, r1, lbb_22625                           if r7 > r1 { pc += 1 }
    ja lbb_22866                                    if true { pc += 241 }
lbb_22625:
    stxdw [r10-0x548], r3                   
    stxdw [r10-0x5a0], r8                   
    mov64 r6, r8                                    r6 = r8
    add64 r6, 1                                     r6 += 1   ///  r6 = r6.wrapping_add(1 as i32 as i64 as u64)
    lsh64 r1, 2                                     r1 <<= 2   ///  r1 = r1.wrapping_shl(2)
    ja lbb_22634                                    if true { pc += 3 }
lbb_22631:
    add64 r1, -4                                    r1 += -4   ///  r1 = r1.wrapping_add(-4 as i32 as i64 as u64)
    jeq r8, 0, lbb_22634                            if r8 == (0 as i32 as i64 as u64) { pc += 1 }
    ja lbb_22653                                    if true { pc += 19 }
lbb_22634:
    jeq r1, 0, lbb_22650                            if r1 == (0 as i32 as i64 as u64) { pc += 15 }
    mov64 r2, r10                                   r2 = r10
    add64 r2, -1344                                 r2 += -1344   ///  r2 = r2.wrapping_add(-1344 as i32 as i64 as u64)
    add64 r2, r1                                    r2 += r1   ///  r2 = r2.wrapping_add(r1)
    ldxw r2, [r2-0x4]                       
    mov64 r3, r10                                   r3 = r10
    add64 r3, -1176                                 r3 += -1176   ///  r3 = r3.wrapping_add(-1176 as i32 as i64 as u64)
    add64 r3, r1                                    r3 += r1   ///  r3 = r3.wrapping_add(r1)
    ldxw r3, [r3-0x4]                       
    mov64 r4, 1                                     r4 = 1 as i32 as i64 as u64
    jne r3, r2, lbb_22646                           if r3 != r2 { pc += 1 }
    mov64 r4, 0                                     r4 = 0 as i32 as i64 as u64
lbb_22646:
    mov64 r8, -1                                    r8 = -1 as i32 as i64 as u64
    jgt r3, r2, lbb_22631                           if r3 > r2 { pc += -17 }
    mov64 r8, r4                                    r8 = r4
    ja lbb_22631                                    if true { pc += -19 }
lbb_22650:
    mov64 r8, 0                                     r8 = 0 as i32 as i64 as u64
    jeq r1, 0, lbb_22653                            if r1 == (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r8, 255                                   r8 = 255 as i32 as i64 as u64
lbb_22653:
    mov64 r1, r10                                   r1 = r10
    add64 r1, -168                                  r1 += -168   ///  r1 = r1.wrapping_add(-168 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -1344                                 r2 += -1344   ///  r2 = r2.wrapping_add(-1344 as i32 as i64 as u64)
    mov64 r3, 160                                   r3 = 160 as i32 as i64 as u64
    call function_30349                     
    ldxdw r3, [r10-0x548]                   
    stxdw [r10-0x8], r3                     
    ldxdw r2, [r10-0x350]                   
    mov64 r1, r3                                    r1 = r3
    stxdw [r10-0x560], r2                   
    jgt r3, r2, lbb_22666                           if r3 > r2 { pc += 1 }
    ldxdw r1, [r10-0x560]                   
lbb_22666:
    jgt r1, 40, lbb_22866                           if r1 > (40 as i32 as i64 as u64) { pc += 199 }
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
    jeq r1, 0, lbb_22720                            if r1 == (0 as i32 as i64 as u64) { pc += 51 }
    stxdw [r10-0x590], r6                   
    mov64 r9, 0                                     r9 = 0 as i32 as i64 as u64
    mov64 r3, r10                                   r3 = r10
    add64 r3, -1008                                 r3 += -1008   ///  r3 = r3.wrapping_add(-1008 as i32 as i64 as u64)
    mov64 r4, r10                                   r4 = r10
    add64 r4, -168                                  r4 += -168   ///  r4 = r4.wrapping_add(-168 as i32 as i64 as u64)
    mov64 r5, 0                                     r5 = 0 as i32 as i64 as u64
    ja lbb_22685                                    if true { pc += 8 }
lbb_22677:
    stxw [r4+0x0], r7                       
    or64 r0, r2                                     r0 |= r2   ///  r0 = r0.or(r2)
    add64 r4, 4                                     r4 += 4   ///  r4 = r4.wrapping_add(4 as i32 as i64 as u64)
    add64 r3, 4                                     r3 += 4   ///  r3 = r3.wrapping_add(4 as i32 as i64 as u64)
    add64 r5, 1                                     r5 += 1   ///  r5 = r5.wrapping_add(1 as i32 as i64 as u64)
    mov64 r9, r0                                    r9 = r0
    jgt r1, r5, lbb_22685                           if r1 > r5 { pc += 1 }
    ja lbb_22703                                    if true { pc += 18 }
lbb_22685:
    ldxw r2, [r3+0x0]                       
    ldxw r6, [r4+0x0]                       
    add64 r6, r2                                    r6 += r2   ///  r6 = r6.wrapping_add(r2)
    mov64 r7, r6                                    r7 = r6
    lsh64 r7, 32                                    r7 <<= 32   ///  r7 = r7.wrapping_shl(32)
    rsh64 r7, 32                                    r7 >>= 32   ///  r7 = r7.wrapping_shr(32)
    mov64 r2, 1                                     r2 = 1 as i32 as i64 as u64
    mov64 r0, 1                                     r0 = 1 as i32 as i64 as u64
    jne r7, r6, lbb_22695                           if r7 != r6 { pc += 1 }
    mov64 r0, 0                                     r0 = 0 as i32 as i64 as u64
lbb_22695:
    and64 r9, 1                                     r9 &= 1   ///  r9 = r9.and(1)
    add64 r7, r9                                    r7 += r9   ///  r7 = r7.wrapping_add(r9)
    mov64 r6, r7                                    r6 = r7
    lsh64 r6, 32                                    r6 <<= 32   ///  r6 = r6.wrapping_shl(32)
    rsh64 r6, 32                                    r6 >>= 32   ///  r6 = r6.wrapping_shr(32)
    jne r6, r7, lbb_22677                           if r6 != r7 { pc += -24 }
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
    ja lbb_22677                                    if true { pc += -26 }
lbb_22703:
    and64 r0, 1                                     r0 &= 1   ///  r0 = r0.and(1)
    mov64 r2, r1                                    r2 = r1
    ldxdw r9, [r10-0x580]                   
    mov64 r7, 41                                    r7 = 41 as i32 as i64 as u64
    ldxdw r6, [r10-0x590]                   
    jne r0, 0, lbb_22710                            if r0 != (0 as i32 as i64 as u64) { pc += 1 }
    ja lbb_22720                                    if true { pc += 10 }
lbb_22710:
    jeq r1, 40, lbb_22954                           if r1 == (40 as i32 as i64 as u64) { pc += 243 }
    mov64 r2, r1                                    r2 = r1
    lsh64 r2, 2                                     r2 <<= 2   ///  r2 = r2.wrapping_shl(2)
    mov64 r3, r10                                   r3 = r10
    add64 r3, -168                                  r3 += -168   ///  r3 = r3.wrapping_add(-168 as i32 as i64 as u64)
    add64 r3, r2                                    r3 += r2   ///  r3 = r3.wrapping_add(r2)
    mov64 r2, 1                                     r2 = 1 as i32 as i64 as u64
    stxw [r3+0x0], r2                       
    add64 r1, 1                                     r1 += 1   ///  r1 = r1.wrapping_add(1 as i32 as i64 as u64)
    mov64 r2, r1                                    r2 = r1
lbb_22720:
    stxdw [r10-0x8], r2                     
    ldxdw r3, [r10-0x550]                   
    mov64 r1, r3                                    r1 = r3
    jgt r3, r2, lbb_22725                           if r3 > r2 { pc += 1 }
    mov64 r1, r2                                    r1 = r2
lbb_22725:
    ldxdw r0, [r10-0x568]                   
    jgt r7, r1, lbb_22728                           if r7 > r1 { pc += 1 }
    ja lbb_22866                                    if true { pc += 138 }
lbb_22728:
    lsh64 r1, 2                                     r1 <<= 2   ///  r1 = r1.wrapping_shl(2)
    ja lbb_22733                                    if true { pc += 3 }
lbb_22730:
    add64 r1, -4                                    r1 += -4   ///  r1 = r1.wrapping_add(-4 as i32 as i64 as u64)
    jeq r3, 0, lbb_22733                            if r3 == (0 as i32 as i64 as u64) { pc += 1 }
    ja lbb_22755                                    if true { pc += 22 }
lbb_22733:
    jeq r1, 0, lbb_22749                            if r1 == (0 as i32 as i64 as u64) { pc += 15 }
    mov64 r2, r10                                   r2 = r10
    add64 r2, -840                                  r2 += -840   ///  r2 = r2.wrapping_add(-840 as i32 as i64 as u64)
    add64 r2, r1                                    r2 += r1   ///  r2 = r2.wrapping_add(r1)
    ldxw r2, [r2-0x4]                       
    mov64 r3, r10                                   r3 = r10
    add64 r3, -168                                  r3 += -168   ///  r3 = r3.wrapping_add(-168 as i32 as i64 as u64)
    add64 r3, r1                                    r3 += r1   ///  r3 = r3.wrapping_add(r1)
    ldxw r4, [r3-0x4]                       
    mov64 r5, 1                                     r5 = 1 as i32 as i64 as u64
    jne r4, r2, lbb_22745                           if r4 != r2 { pc += 1 }
    mov64 r5, 0                                     r5 = 0 as i32 as i64 as u64
lbb_22745:
    mov64 r3, -1                                    r3 = -1 as i32 as i64 as u64
    jgt r4, r2, lbb_22730                           if r4 > r2 { pc += -17 }
    mov64 r3, r5                                    r3 = r5
    ja lbb_22730                                    if true { pc += -19 }
lbb_22749:
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
    jeq r1, 0, lbb_22755                            if r1 == (0 as i32 as i64 as u64) { pc += 4 }
lbb_22751:
    lsh64 r8, 56                                    r8 <<= 56   ///  r8 = r8.wrapping_shl(56)
    arsh64 r8, 56                                   r8 >>= 56 (signed)   ///  r8 = (r8 as i64).wrapping_shr(56)
    jsgt r0, r8, lbb_22856                          if (r0 as i64) > (r8 as i64) { pc += 102 }
    ja lbb_22888                                    if true { pc += 133 }
lbb_22755:
    mov64 r1, r8                                    r1 = r8
    lsh64 r1, 56                                    r1 <<= 56   ///  r1 = r1.wrapping_shl(56)
    arsh64 r1, 56                                   r1 >>= 56 (signed)   ///  r1 = (r1 as i64).wrapping_shr(56)
    jsgt r0, r1, lbb_22852                          if (r0 as i64) > (r1 as i64) { pc += 93 }
    mov64 r1, r3                                    r1 = r3
    lsh64 r1, 56                                    r1 <<= 56   ///  r1 = r1.wrapping_shl(56)
    arsh64 r1, 56                                   r1 >>= 56 (signed)   ///  r1 = (r1 as i64).wrapping_shr(56)
    jsgt r0, r1, lbb_22852                          if (r0 as i64) > (r1 as i64) { pc += 89 }
    mov64 r4, r10                                   r4 = r10
    add64 r4, -1344                                 r4 += -1344   ///  r4 = r4.wrapping_add(-1344 as i32 as i64 as u64)
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
    ldxdw r8, [r10-0x558]                   
    ldxdw r2, [r10-0x548]                   
    jeq r2, 0, lbb_22793                            if r2 == (0 as i32 as i64 as u64) { pc += 23 }
    mov64 r3, r2                                    r3 = r2
    lsh64 r3, 2                                     r3 <<= 2   ///  r3 = r3.wrapping_shl(2)
    add64 r4, r3                                    r4 += r3   ///  r4 = r4.wrapping_add(r3)
    mov64 r5, r10                                   r5 = r10
    add64 r5, -1344                                 r5 += -1344   ///  r5 = r5.wrapping_add(-1344 as i32 as i64 as u64)
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
lbb_22776:
    ldxw r0, [r5+0x0]                       
    mul64 r0, 10                                    r0 *= 10   ///  r0 = r0.wrapping_mul(10 as u64)
    add64 r0, r2                                    r0 += r2   ///  r0 = r0.wrapping_add(r2)
    stxw [r5+0x0], r0                       
    add64 r5, 4                                     r5 += 4   ///  r5 = r5.wrapping_add(4 as i32 as i64 as u64)
    rsh64 r0, 32                                    r0 >>= 32   ///  r0 = r0.wrapping_shr(32)
    add64 r3, -4                                    r3 += -4   ///  r3 = r3.wrapping_add(-4 as i32 as i64 as u64)
    mov64 r2, r0                                    r2 = r0
    jeq r3, 0, lbb_22786                            if r3 == (0 as i32 as i64 as u64) { pc += 1 }
    ja lbb_22776                                    if true { pc += -10 }
lbb_22786:
    ldxdw r2, [r10-0x548]                   
    mov64 r3, r2                                    r3 = r2
    jeq r0, 0, lbb_22793                            if r0 == (0 as i32 as i64 as u64) { pc += 4 }
    jeq r2, 40, lbb_22954                           if r2 == (40 as i32 as i64 as u64) { pc += 164 }
    stxw [r4+0x0], r0                       
    add64 r2, 1                                     r2 += 1   ///  r2 = r2.wrapping_add(1 as i32 as i64 as u64)
    mov64 r3, r2                                    r3 = r2
lbb_22793:
    stxdw [r10-0x4a0], r3                   
    mov64 r4, r10                                   r4 = r10
    add64 r4, -1176                                 r4 += -1176   ///  r4 = r4.wrapping_add(-1176 as i32 as i64 as u64)
    jeq r8, 0, lbb_22819                            if r8 == (0 as i32 as i64 as u64) { pc += 22 }
    mov64 r1, r8                                    r1 = r8
    lsh64 r1, 2                                     r1 <<= 2   ///  r1 = r1.wrapping_shl(2)
    add64 r4, r1                                    r4 += r1   ///  r4 = r4.wrapping_add(r1)
    mov64 r5, r10                                   r5 = r10
    add64 r5, -1176                                 r5 += -1176   ///  r5 = r5.wrapping_add(-1176 as i32 as i64 as u64)
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
lbb_22803:
    ldxw r0, [r5+0x0]                       
    mul64 r0, 10                                    r0 *= 10   ///  r0 = r0.wrapping_mul(10 as u64)
    add64 r0, r2                                    r0 += r2   ///  r0 = r0.wrapping_add(r2)
    stxw [r5+0x0], r0                       
    add64 r5, 4                                     r5 += 4   ///  r5 = r5.wrapping_add(4 as i32 as i64 as u64)
    rsh64 r0, 32                                    r0 >>= 32   ///  r0 = r0.wrapping_shr(32)
    add64 r1, -4                                    r1 += -4   ///  r1 = r1.wrapping_add(-4 as i32 as i64 as u64)
    mov64 r2, r0                                    r2 = r0
    jeq r1, 0, lbb_22813                            if r1 == (0 as i32 as i64 as u64) { pc += 1 }
    ja lbb_22803                                    if true { pc += -10 }
lbb_22813:
    mov64 r1, r8                                    r1 = r8
    jeq r0, 0, lbb_22819                            if r0 == (0 as i32 as i64 as u64) { pc += 4 }
    jeq r8, 40, lbb_22954                           if r8 == (40 as i32 as i64 as u64) { pc += 138 }
    stxw [r4+0x0], r0                       
    add64 r8, 1                                     r8 += 1   ///  r8 = r8.wrapping_add(1 as i32 as i64 as u64)
    mov64 r1, r8                                    r1 = r8
lbb_22819:
    stxdw [r10-0x3f8], r1                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -1008                                 r1 += -1008   ///  r1 = r1.wrapping_add(-1008 as i32 as i64 as u64)
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
    ldxdw r8, [r10-0x560]                   
    jeq r8, 0, lbb_22846                            if r8 == (0 as i32 as i64 as u64) { pc += 21 }
    mov64 r4, r8                                    r4 = r8
    lsh64 r4, 2                                     r4 <<= 2   ///  r4 = r4.wrapping_shl(2)
    add64 r1, r4                                    r1 += r4   ///  r1 = r1.wrapping_add(r4)
    mov64 r5, r10                                   r5 = r10
    add64 r5, -1008                                 r5 += -1008   ///  r5 = r5.wrapping_add(-1008 as i32 as i64 as u64)
lbb_22830:
    ldxw r0, [r5+0x0]                       
    mul64 r0, 10                                    r0 *= 10   ///  r0 = r0.wrapping_mul(10 as u64)
    add64 r0, r2                                    r0 += r2   ///  r0 = r0.wrapping_add(r2)
    stxw [r5+0x0], r0                       
    add64 r5, 4                                     r5 += 4   ///  r5 = r5.wrapping_add(4 as i32 as i64 as u64)
    rsh64 r0, 32                                    r0 >>= 32   ///  r0 = r0.wrapping_shr(32)
    add64 r4, -4                                    r4 += -4   ///  r4 = r4.wrapping_add(-4 as i32 as i64 as u64)
    mov64 r2, r0                                    r2 = r0
    jeq r4, 0, lbb_22840                            if r4 == (0 as i32 as i64 as u64) { pc += 1 }
    ja lbb_22830                                    if true { pc += -10 }
lbb_22840:
    mov64 r2, r8                                    r2 = r8
    jeq r0, 0, lbb_22846                            if r0 == (0 as i32 as i64 as u64) { pc += 4 }
    jeq r8, 40, lbb_22954                           if r8 == (40 as i32 as i64 as u64) { pc += 111 }
    stxw [r1+0x0], r0                       
    add64 r8, 1                                     r8 += 1   ///  r8 = r8.wrapping_add(1 as i32 as i64 as u64)
    mov64 r2, r8                                    r2 = r8
lbb_22846:
    stxdw [r10-0x350], r2                   
    mov64 r1, r3                                    r1 = r3
    ldxdw r2, [r10-0x588]                   
    jgt r3, r2, lbb_22343                           if r3 > r2 { pc += -507 }
    ldxdw r1, [r10-0x588]                   
    ja lbb_22343                                    if true { pc += -509 }
lbb_22852:
    lsh64 r3, 56                                    r3 <<= 56   ///  r3 = r3.wrapping_shl(56)
    arsh64 r3, 56                                   r3 >>= 56 (signed)   ///  r3 = (r3 as i64).wrapping_shr(56)
    jsgt r0, r3, lbb_22751                          if (r0 as i64) > (r3 as i64) { pc += -104 }
    ja lbb_22941                                    if true { pc += 85 }
lbb_22856:
    mov64 r1, r10                                   r1 = r10
    add64 r1, -1344                                 r1 += -1344   ///  r1 = r1.wrapping_add(-1344 as i32 as i64 as u64)
    mov64 r2, 1                                     r2 = 1 as i32 as i64 as u64
    call function_29303                     
    ldxdw r2, [r10-0x2a8]                   
    ldxdw r1, [r10-0x4a0]                   
    jgt r1, r2, lbb_22864                           if r1 > r2 { pc += 1 }
    mov64 r1, r2                                    r1 = r2
lbb_22864:
    mov64 r2, 41                                    r2 = 41 as i32 as i64 as u64
    jgt r2, r1, lbb_22870                           if r2 > r1 { pc += 4 }
lbb_22866:
    mov64 r2, 40                                    r2 = 40 as i32 as i64 as u64
    lddw r3, 0x100042210 --> b"\x00\x00\x00\x00Y\x08\x04\x00\x1e\x00\x00\x00\x00\x00\x00\x00\xac\x01\x00…        r3 load str located at 4295238160
    call function_28353                     
lbb_22870:
    mov64 r2, r10                                   r2 = r10
    add64 r2, -1348                                 r2 += -1348   ///  r2 = r2.wrapping_add(-1348 as i32 as i64 as u64)
    mov64 r3, r10                                   r3 = r10
    add64 r3, -844                                  r3 += -844   ///  r3 = r3.wrapping_add(-844 as i32 as i64 as u64)
    lsh64 r1, 2                                     r1 <<= 2   ///  r1 = r1.wrapping_shl(2)
lbb_22875:
    jeq r1, 0, lbb_22886                            if r1 == (0 as i32 as i64 as u64) { pc += 10 }
    mov64 r5, r2                                    r5 = r2
    add64 r5, r1                                    r5 += r1   ///  r5 = r5.wrapping_add(r1)
    mov64 r4, r3                                    r4 = r3
    add64 r4, r1                                    r4 += r1   ///  r4 = r4.wrapping_add(r1)
    add64 r1, -4                                    r1 += -4   ///  r1 = r1.wrapping_add(-4 as i32 as i64 as u64)
    ldxw r4, [r4+0x0]                       
    ldxw r5, [r5+0x0]                       
    jeq r4, r5, lbb_22875                           if r4 == r5 { pc += -9 }
    jgt r5, r4, lbb_22888                           if r5 > r4 { pc += 3 }
    ja lbb_22941                                    if true { pc += 55 }
lbb_22886:
    jeq r1, 0, lbb_22888                            if r1 == (0 as i32 as i64 as u64) { pc += 1 }
    ja lbb_22941                                    if true { pc += 53 }
lbb_22888:
    ldxdw r4, [r10-0x598]                   
    mov64 r1, r4                                    r1 = r4
    ldxdw r7, [r10-0x5a0]                   
    add64 r1, r7                                    r1 += r7   ///  r1 = r1.wrapping_add(r7)
    mov64 r2, r6                                    r2 = r6
    mov64 r6, r4                                    r6 = r4
    mov64 r8, r2                                    r8 = r2
    add64 r6, r2                                    r6 += r2   ///  r6 = r6.wrapping_add(r2)
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
lbb_22897:
    mov64 r2, r7                                    r2 = r7
    add64 r2, r3                                    r2 += r3   ///  r2 = r2.wrapping_add(r3)
    jeq r2, -1, lbb_22924                           if r2 == (-1 as i32 as i64 as u64) { pc += 24 }
    mov64 r2, r1                                    r2 = r1
    add64 r2, r3                                    r2 += r3   ///  r2 = r2.wrapping_add(r3)
    add64 r3, -1                                    r3 += -1   ///  r3 = r3.wrapping_add(-1 as i32 as i64 as u64)
    ldxb r2, [r2+0x0]                       
    jeq r2, 57, lbb_22897                           if r2 == (57 as i32 as i64 as u64) { pc += -8 }
    mov64 r1, r7                                    r1 = r7
    add64 r1, r3                                    r1 += r3   ///  r1 = r1.wrapping_add(r3)
    mov64 r2, r1                                    r2 = r1
    add64 r2, r4                                    r2 += r4   ///  r2 = r2.wrapping_add(r4)
    ldxb r4, [r2+0x1]                       
    add64 r4, 1                                     r4 += 1   ///  r4 = r4.wrapping_add(1 as i32 as i64 as u64)
    stxb [r2+0x1], r4                       
    add64 r1, 2                                     r1 += 2   ///  r1 = r1.wrapping_add(2 as i32 as i64 as u64)
    mov64 r6, r8                                    r6 = r8
    jgt r1, r7, lbb_22941                           if r1 > r7 { pc += 26 }
    ldxdw r1, [r10-0x598]                   
    ldxdw r2, [r10-0x5a0]                   
    add64 r1, r2                                    r1 += r2   ///  r1 = r1.wrapping_add(r2)
    add64 r1, r3                                    r1 += r3   ///  r1 = r1.wrapping_add(r3)
    xor64 r3, -1                                    r3 ^= -1   ///  r3 = r3.xor(-1)
    add64 r1, 2                                     r1 += 2   ///  r1 = r1.wrapping_add(2 as i32 as i64 as u64)
    mov64 r2, 48                                    r2 = 48 as i32 as i64 as u64
    call function_30383                     
    ja lbb_22941                                    if true { pc += 17 }
lbb_22924:
    mov64 r1, 49                                    r1 = 49 as i32 as i64 as u64
    stxb [r4+0x0], r1                       
    jeq r7, 0, lbb_22932                            if r7 == (0 as i32 as i64 as u64) { pc += 5 }
    mov64 r1, r4                                    r1 = r4
    add64 r1, 1                                     r1 += 1   ///  r1 = r1.wrapping_add(1 as i32 as i64 as u64)
    mov64 r2, 48                                    r2 = 48 as i32 as i64 as u64
    mov64 r3, r7                                    r3 = r7
    call function_30383                     
lbb_22932:
    mov64 r1, r8                                    r1 = r8
    jge r1, r9, lbb_22964                           if r1 >= r9 { pc += 30 }
    mov64 r1, 48                                    r1 = 48 as i32 as i64 as u64
    stxb [r6+0x0], r1                       
    ldxdw r1, [r10-0x5a8]                   
    add64 r1, 1                                     r1 += 1   ///  r1 = r1.wrapping_add(1 as i32 as i64 as u64)
    stxdw [r10-0x5a8], r1                   
    add64 r7, 2                                     r7 += 2   ///  r7 = r7.wrapping_add(2 as i32 as i64 as u64)
    mov64 r6, r7                                    r6 = r7
lbb_22941:
    jge r9, r6, lbb_22947                           if r9 >= r6 { pc += 5 }
    mov64 r1, r6                                    r1 = r6
    mov64 r2, r9                                    r2 = r9
    lddw r3, 0x100041ae8 --> b"\x00\x00\x00\x00\xb8\xf6\x03\x00/\x00\x00\x00\x00\x00\x00\x00\x01\x01\x00…        r3 load str located at 4295236328
    call function_28353                     
lbb_22947:
    ldxdw r2, [r10-0x5b0]                   
    ldxdw r1, [r10-0x5a8]                   
    stxh [r2+0x10], r1                      
    stxdw [r2+0x8], r6                      
    ldxdw r1, [r10-0x598]                   
    stxdw [r2+0x0], r1                      
    exit                                    
lbb_22954:
    mov64 r1, 40                                    r1 = 40 as i32 as i64 as u64
    mov64 r2, 40                                    r2 = 40 as i32 as i64 as u64
    lddw r3, 0x100042210 --> b"\x00\x00\x00\x00Y\x08\x04\x00\x1e\x00\x00\x00\x00\x00\x00\x00\xac\x01\x00…        r3 load str located at 4295238160
    call function_25832                     
lbb_22959:
    mov64 r1, r9                                    r1 = r9
    mov64 r2, r9                                    r2 = r9
    lddw r3, 0x100041ab8 --> b"\x00\x00\x00\x00\xb8\xf6\x03\x00/\x00\x00\x00\x00\x00\x00\x00\xc1\x00\x00…        r3 load str located at 4295236280
    call function_25832                     
lbb_22964:
    mov64 r2, r9                                    r2 = r9
    lddw r3, 0x100041ad0 --> b"\x00\x00\x00\x00\xb8\xf6\x03\x00/\x00\x00\x00\x00\x00\x00\x00\xfa\x00\x00…        r3 load str located at 4295236304
    call function_25832                     
lbb_22968:
    lddw r1, 0x100040877 --> b"assertion failed: noborrow"        r1 load str located at 4295231607
    mov64 r2, 26                                    r2 = 26 as i32 as i64 as u64
    lddw r3, 0x100042210 --> b"\x00\x00\x00\x00Y\x08\x04\x00\x1e\x00\x00\x00\x00\x00\x00\x00\xac\x01\x00…        r3 load str located at 4295238160
    call function_25816                     

function_22974:
    stxdw [r10-0x360], r5                   
    stxdw [r10-0x358], r3                   
    ldxdw r8, [r2+0x0]                      
    jne r8, 0, lbb_22984                            if r8 != (0 as i32 as i64 as u64) { pc += 6 }
    lddw r1, 0x10003f6e7 --> b"assertion failed: d.mant > 0"        r1 load str located at 4295227111
    mov64 r2, 28                                    r2 = 28 as i32 as i64 as u64
    lddw r3, 0x100041b30 --> b"\x00\x00\x00\x00\xb8\xf6\x03\x00/\x00\x00\x00\x00\x00\x00\x00\x0a\x01\x00…        r3 load str located at 4295236400
    call function_25816                     
lbb_22984:
    ldxdw r3, [r2+0x8]                      
    jne r3, 0, lbb_22992                            if r3 != (0 as i32 as i64 as u64) { pc += 6 }
    lddw r1, 0x10003f703 --> b"assertion failed: d.minus > 0"        r1 load str located at 4295227139
    mov64 r2, 29                                    r2 = 29 as i32 as i64 as u64
    lddw r3, 0x100041b48 --> b"\x00\x00\x00\x00\xb8\xf6\x03\x00/\x00\x00\x00\x00\x00\x00\x00\x0b\x01\x00…        r3 load str located at 4295236424
    call function_25816                     
lbb_22992:
    ldxdw r0, [r2+0x10]                     
    jne r0, 0, lbb_23000                            if r0 != (0 as i32 as i64 as u64) { pc += 6 }
    lddw r1, 0x10003f720 --> b"assertion failed: d.plus > 0"        r1 load str located at 4295227168
    mov64 r2, 28                                    r2 = 28 as i32 as i64 as u64
    lddw r3, 0x100041b60 --> b"\x00\x00\x00\x00\xb8\xf6\x03\x00/\x00\x00\x00\x00\x00\x00\x00\x0c\x01\x00…        r3 load str located at 4295236448
    call function_25816                     
lbb_23000:
    mov64 r5, r8                                    r5 = r8
    add64 r5, r0                                    r5 += r0   ///  r5 = r5.wrapping_add(r0)
    mov64 r0, 1                                     r0 = 1 as i32 as i64 as u64
    jgt r8, r5, lbb_23005                           if r8 > r5 { pc += 1 }
    mov64 r0, 0                                     r0 = 0 as i32 as i64 as u64
lbb_23005:
    and64 r0, 1                                     r0 &= 1   ///  r0 = r0.and(1)
    jne r0, 0, lbb_23139                            if r0 != (0 as i32 as i64 as u64) { pc += 132 }
    jgt r3, r8, lbb_23145                           if r3 > r8 { pc += 137 }
    mov64 r7, 64                                    r7 = 64 as i32 as i64 as u64
    ldxh r6, [r2+0x18]                      
    mov64 r2, r8                                    r2 = r8
    add64 r2, -1                                    r2 += -1   ///  r2 = r2.wrapping_add(-1 as i32 as i64 as u64)
    jeq r2, 0, lbb_23055                            if r2 == (0 as i32 as i64 as u64) { pc += 42 }
    mov64 r3, r2                                    r3 = r2
    rsh64 r3, 1                                     r3 >>= 1   ///  r3 = r3.wrapping_shr(1)
    or64 r2, r3                                     r2 |= r3   ///  r2 = r2.or(r3)
    mov64 r3, r2                                    r3 = r2
    rsh64 r3, 2                                     r3 >>= 2   ///  r3 = r3.wrapping_shr(2)
    or64 r2, r3                                     r2 |= r3   ///  r2 = r2.or(r3)
    mov64 r3, r2                                    r3 = r2
    rsh64 r3, 4                                     r3 >>= 4   ///  r3 = r3.wrapping_shr(4)
    or64 r2, r3                                     r2 |= r3   ///  r2 = r2.or(r3)
    mov64 r3, r2                                    r3 = r2
    rsh64 r3, 8                                     r3 >>= 8   ///  r3 = r3.wrapping_shr(8)
    or64 r2, r3                                     r2 |= r3   ///  r2 = r2.or(r3)
    mov64 r3, r2                                    r3 = r2
    rsh64 r3, 16                                    r3 >>= 16   ///  r3 = r3.wrapping_shr(16)
    or64 r2, r3                                     r2 |= r3   ///  r2 = r2.or(r3)
    mov64 r3, r2                                    r3 = r2
    rsh64 r3, 32                                    r3 >>= 32   ///  r3 = r3.wrapping_shr(32)
    or64 r2, r3                                     r2 |= r3   ///  r2 = r2.or(r3)
    xor64 r2, -1                                    r2 ^= -1   ///  r2 = r2.xor(-1)
    lddw r3, 0x5555555555555555                     r3 load str located at 6148914691236517205
    mov64 r5, r2                                    r5 = r2
    rsh64 r5, 1                                     r5 >>= 1   ///  r5 = r5.wrapping_shr(1)
    and64 r5, r3                                    r5 &= r3   ///  r5 = r5.and(r3)
    sub64 r2, r5                                    r2 -= r5   ///  r2 = r2.wrapping_sub(r5)
    lddw r3, 0x3333333333333333                     r3 load str located at 3689348814741910323
    mov64 r7, r2                                    r7 = r2
    and64 r7, r3                                    r7 &= r3   ///  r7 = r7.and(r3)
    rsh64 r2, 2                                     r2 >>= 2   ///  r2 = r2.wrapping_shr(2)
    and64 r2, r3                                    r2 &= r3   ///  r2 = r2.and(r3)
    add64 r7, r2                                    r7 += r2   ///  r7 = r7.wrapping_add(r2)
    mov64 r2, r7                                    r2 = r7
    rsh64 r2, 4                                     r2 >>= 4   ///  r2 = r2.wrapping_shr(4)
    add64 r7, r2                                    r7 += r2   ///  r7 = r7.wrapping_add(r2)
    lddw r2, 0xf0f0f0f0f0f0f0f                      r2 load str located at 1085102592571150095
    and64 r7, r2                                    r7 &= r2   ///  r7 = r7.and(r2)
    lddw r2, 0x101010101010101                      r2 load str located at 72340172838076673
    mul64 r7, r2                                    r7 *= r2   ///  r7 = r7.wrapping_mul(r2)
    rsh64 r7, 56                                    r7 >>= 56   ///  r7 = r7.wrapping_shr(56)
lbb_23055:
    stxdw [r10-0x378], r1                   
    stxdw [r10-0x368], r4                   
    lsh64 r6, 48                                    r6 <<= 48   ///  r6 = r6.wrapping_shl(48)
    lddw r3, 0x100000000                            r3 load str located at 4294967296
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
    jgt r3, r8, lbb_23064                           if r3 > r8 { pc += 2 }
    mov64 r2, r8                                    r2 = r8
    rsh64 r2, 32                                    r2 >>= 32   ///  r2 = r2.wrapping_shr(32)
lbb_23064:
    arsh64 r6, 48                                   r6 >>= 48 (signed)   ///  r6 = (r6 as i64).wrapping_shr(48)
    mov64 r9, 1                                     r9 = 1 as i32 as i64 as u64
    mov64 r4, 1                                     r4 = 1 as i32 as i64 as u64
    jgt r3, r8, lbb_23069                           if r3 > r8 { pc += 1 }
    mov64 r4, 2                                     r4 = 2 as i32 as i64 as u64
lbb_23069:
    stxw [r10-0x348], r8                    
    stxdw [r10-0x2a8], r4                   
    stxw [r10-0x344], r2                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -832                                  r1 += -832   ///  r1 = r1.wrapping_add(-832 as i32 as i64 as u64)
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
    mov64 r3, 152                                   r3 = 152 as i32 as i64 as u64
    call function_30383                     
    mov64 r1, r10                                   r1 = r10
    add64 r1, -668                                  r1 += -668   ///  r1 = r1.wrapping_add(-668 as i32 as i64 as u64)
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
    mov64 r3, 156                                   r3 = 156 as i32 as i64 as u64
    call function_30383                     
    stxdw [r10-0x200], r9                   
    stxw [r10-0x2a0], r9                    
    mov64 r8, r6                                    r8 = r6
    sub64 r8, r7                                    r8 -= r7   ///  r8 = r8.wrapping_sub(r7)
    mul64 r8, 1292913986                            r8 *= 1292913986   ///  r8 = r8.wrapping_mul(1292913986 as u64)
    lddw r1, 0x1344135080                           r1 load str located at 82746495104
    add64 r8, r1                                    r8 += r1   ///  r8 = r8.wrapping_add(r1)
    mov64 r1, r10                                   r1 = r10
    add64 r1, -840                                  r1 += -840   ///  r1 = r1.wrapping_add(-840 as i32 as i64 as u64)
    rsh64 r8, 32                                    r8 >>= 32   ///  r8 = r8.wrapping_shr(32)
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
    jsgt r2, r6, lbb_23096                          if (r2 as i64) > (r6 as i64) { pc += 1 }
    ja lbb_23099                                    if true { pc += 3 }
lbb_23096:
    mov64 r1, r10                                   r1 = r10
    add64 r1, -672                                  r1 += -672   ///  r1 = r1.wrapping_add(-672 as i32 as i64 as u64)
    neg64 r6                                        r6 = -r6   ///  r6 = (r6 as i64).wrapping_neg() as u64
lbb_23099:
    lsh64 r6, 48                                    r6 <<= 48   ///  r6 = r6.wrapping_shl(48)
    arsh64 r6, 48                                   r6 >>= 48 (signed)   ///  r6 = (r6 as i64).wrapping_shr(48)
    mov64 r2, r6                                    r2 = r6
    call function_29303                     
    mov64 r3, r8                                    r3 = r8
    lsh64 r3, 48                                    r3 <<= 48   ///  r3 = r3.wrapping_shl(48)
    arsh64 r3, 48                                   r3 >>= 48 (signed)   ///  r3 = (r3 as i64).wrapping_shr(48)
    mov64 r2, r8                                    r2 = r8
    ldxdw r9, [r10-0x368]                   
    jsgt r3, -1, lbb_23111                          if (r3 as i64) > (-1 as i32 as i64) { pc += 2 }
    mov64 r2, r8                                    r2 = r8
    neg64 r2                                        r2 = -r2   ///  r2 = (r2 as i64).wrapping_neg() as u64
lbb_23111:
    mov64 r4, r10                                   r4 = r10
    add64 r4, -840                                  r4 += -840   ///  r4 = r4.wrapping_add(-840 as i32 as i64 as u64)
    mov64 r7, r10                                   r7 = r10
    add64 r7, -672                                  r7 += -672   ///  r7 = r7.wrapping_add(-672 as i32 as i64 as u64)
    mov64 r1, r7                                    r1 = r7
    jsgt r3, -1, lbb_23118                          if (r3 as i64) > (-1 as i32 as i64) { pc += 1 }
    mov64 r1, r4                                    r1 = r4
lbb_23118:
    and64 r2, 65535                                 r2 &= 65535   ///  r2 = r2.and(65535)
    call function_21761                     
    ldxdw r3, [r10-0x200]                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -168                                  r1 += -168   ///  r1 = r1.wrapping_add(-168 as i32 as i64 as u64)
    mov64 r2, r7                                    r2 = r7
    mov64 r7, r3                                    r7 = r3
    mov64 r3, 160                                   r3 = 160 as i32 as i64 as u64
    call function_30349                     
    stxdw [r10-0x8], r7                     
    mov64 r1, 10                                    r1 = 10 as i32 as i64 as u64
    mov64 r3, r10                                   r3 = r10
    add64 r3, -172                                  r3 += -172   ///  r3 = r3.wrapping_add(-172 as i32 as i64 as u64)
    mov64 r2, r9                                    r2 = r9
    jgt r1, r9, lbb_23165                           if r1 > r9 { pc += 32 }
    mov64 r1, r7                                    r1 = r7
    jgt r7, 40, lbb_23179                           if r7 > (40 as i32 as i64 as u64) { pc += 44 }
    mov64 r4, 41                                    r4 = 41 as i32 as i64 as u64
    mov64 r2, r9                                    r2 = r9
    mov64 r1, r7                                    r1 = r7
    ja lbb_23183                                    if true { pc += 44 }
lbb_23139:
    lddw r1, 0x10003f7a0 --> b"assertion failed: d.mant.checked_add(d.plus).is_some()"        r1 load str located at 4295227296
    mov64 r2, 54                                    r2 = 54 as i32 as i64 as u64
    lddw r3, 0x100041c08 --> b"\x00\x00\x00\x00\xb8\xf6\x03\x00/\x00\x00\x00\x00\x00\x00\x00\x0d\x01\x00…        r3 load str located at 4295236616
    call function_25816                     
lbb_23145:
    lddw r1, 0x10003f769 --> b"assertion failed: d.mant.checked_sub(d.minus).is_some()"        r1 load str located at 4295227241
    mov64 r2, 55                                    r2 = 55 as i32 as i64 as u64
    lddw r3, 0x100041bf0 --> b"\x00\x00\x00\x00\xb8\xf6\x03\x00/\x00\x00\x00\x00\x00\x00\x00\x0e\x01\x00…        r3 load str located at 4295236592
    call function_25816                     
lbb_23151:
    mov64 r0, r3                                    r0 = r3
    add64 r0, r1                                    r0 += r1   ///  r0 = r0.wrapping_add(r1)
    lsh64 r5, 32                                    r5 <<= 32   ///  r5 = r5.wrapping_shl(32)
    ldxw r6, [r0+0x0]                       
    or64 r5, r6                                     r5 |= r6   ///  r5 = r5.or(r6)
    mov64 r6, r5                                    r6 = r5
    div64 r6, 1000000000                            r6 /= 1000000000   ///  r6 = r6 / (1000000000 as u64)
    stxw [r0+0x0], r6                       
    mul64 r6, 1000000000                            r6 *= 1000000000   ///  r6 = r6.wrapping_mul(1000000000 as u64)
    sub64 r5, r6                                    r5 -= r6   ///  r5 = r5.wrapping_sub(r6)
    add64 r1, -4                                    r1 += -4   ///  r1 = r1.wrapping_add(-4 as i32 as i64 as u64)
    jne r1, 0, lbb_23151                            if r1 != (0 as i32 as i64 as u64) { pc += -12 }
lbb_23163:
    add64 r2, -9                                    r2 += -9   ///  r2 = r2.wrapping_add(-9 as i32 as i64 as u64)
    jgt r2, 9, lbb_23177                            if r2 > (9 as i32 as i64 as u64) { pc += 12 }
lbb_23165:
    lsh64 r2, 2                                     r2 <<= 2   ///  r2 = r2.wrapping_shl(2)
    lddw r1, 0x10003f5b8 --> b"\x02\x00\x00\x00\x14\x00\x00\x00\xc8\x00\x00\x00\xd0\x07\x00\x00 N\x00\x0…        r1 load str located at 4295226808
    add64 r1, r2                                    r1 += r2   ///  r1 = r1.wrapping_add(r2)
    ldxw r4, [r1+0x0]                       
    jne r4, 0, lbb_23187                            if r4 != (0 as i32 as i64 as u64) { pc += 16 }
    lddw r1, 0x1000408ae --> b"assertion failed: other > 0"        r1 load str located at 4295231662
    mov64 r2, 27                                    r2 = 27 as i32 as i64 as u64
    lddw r3, 0x100042210 --> b"\x00\x00\x00\x00Y\x08\x04\x00\x1e\x00\x00\x00\x00\x00\x00\x00\xac\x01\x00…        r3 load str located at 4295238160
    call function_25816                     
lbb_23177:
    ldxdw r1, [r10-0x8]                     
    jgt r4, r1, lbb_23183                           if r4 > r1 { pc += 4 }
lbb_23179:
    mov64 r2, 40                                    r2 = 40 as i32 as i64 as u64
    lddw r3, 0x100042210 --> b"\x00\x00\x00\x00Y\x08\x04\x00\x1e\x00\x00\x00\x00\x00\x00\x00\xac\x01\x00…        r3 load str located at 4295238160
    call function_28353                     
lbb_23183:
    jeq r1, 0, lbb_23163                            if r1 == (0 as i32 as i64 as u64) { pc += -21 }
    mov64 r5, 0                                     r5 = 0 as i32 as i64 as u64
    lsh64 r1, 2                                     r1 <<= 2   ///  r1 = r1.wrapping_shl(2)
    ja lbb_23151                                    if true { pc += -36 }
lbb_23187:
    ldxdw r2, [r10-0x8]                     
    mov64 r1, 41                                    r1 = 41 as i32 as i64 as u64
    jgt r1, r2, lbb_23192                           if r1 > r2 { pc += 2 }
lbb_23190:
    mov64 r1, r2                                    r1 = r2
    ja lbb_23179                                    if true { pc += -13 }
lbb_23192:
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    jeq r2, 0, lbb_23208                            if r2 == (0 as i32 as i64 as u64) { pc += 14 }
    lsh64 r2, 2                                     r2 <<= 2   ///  r2 = r2.wrapping_shl(2)
lbb_23195:
    mov64 r5, r3                                    r5 = r3
    add64 r5, r2                                    r5 += r2   ///  r5 = r5.wrapping_add(r2)
    lsh64 r1, 32                                    r1 <<= 32   ///  r1 = r1.wrapping_shl(32)
    ldxw r0, [r5+0x0]                       
    or64 r1, r0                                     r1 |= r0   ///  r1 = r1.or(r0)
    mov64 r0, r1                                    r0 = r1
    div64 r0, r4                                    r0 /= r4   ///  r0 = r0 / r4
    stxw [r5+0x0], r0                       
    mul64 r0, r4                                    r0 *= r4   ///  r0 = r0.wrapping_mul(r4)
    sub64 r1, r0                                    r1 -= r0   ///  r1 = r1.wrapping_sub(r0)
    add64 r2, -4                                    r2 += -4   ///  r2 = r2.wrapping_add(-4 as i32 as i64 as u64)
    jne r2, 0, lbb_23195                            if r2 != (0 as i32 as i64 as u64) { pc += -12 }
    ldxdw r1, [r10-0x8]                     
lbb_23208:
    ldxdw r3, [r10-0x2a8]                   
    jgt r1, r3, lbb_23211                           if r1 > r3 { pc += 1 }
    mov64 r1, r3                                    r1 = r3
lbb_23211:
    jgt r1, 40, lbb_23179                           if r1 > (40 as i32 as i64 as u64) { pc += -33 }
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
    stxdw [r10-0x350], r7                   
    jeq r1, 0, lbb_23265                            if r1 == (0 as i32 as i64 as u64) { pc += 50 }
    stxdw [r10-0x370], r8                   
    mov64 r7, 0                                     r7 = 0 as i32 as i64 as u64
    mov64 r2, r10                                   r2 = r10
    add64 r2, -840                                  r2 += -840   ///  r2 = r2.wrapping_add(-840 as i32 as i64 as u64)
    mov64 r4, r10                                   r4 = r10
    add64 r4, -168                                  r4 += -168   ///  r4 = r4.wrapping_add(-168 as i32 as i64 as u64)
    mov64 r5, 0                                     r5 = 0 as i32 as i64 as u64
    ja lbb_23237                                    if true { pc += 14 }
lbb_23223:
    stxw [r4+0x0], r8                       
    or64 r0, r6                                     r0 |= r6   ///  r0 = r0.or(r6)
    add64 r4, 4                                     r4 += 4   ///  r4 = r4.wrapping_add(4 as i32 as i64 as u64)
    add64 r2, 4                                     r2 += 4   ///  r2 = r2.wrapping_add(4 as i32 as i64 as u64)
    add64 r5, 1                                     r5 += 1   ///  r5 = r5.wrapping_add(1 as i32 as i64 as u64)
    mov64 r7, r0                                    r7 = r0
    jgt r1, r5, lbb_23237                           if r1 > r5 { pc += 7 }
    and64 r0, 1                                     r0 &= 1   ///  r0 = r0.and(1)
    mov64 r2, r1                                    r2 = r1
    ldxdw r9, [r10-0x368]                   
    ldxdw r8, [r10-0x370]                   
    ldxdw r7, [r10-0x350]                   
    jne r0, 0, lbb_23255                            if r0 != (0 as i32 as i64 as u64) { pc += 19 }
    ja lbb_23265                                    if true { pc += 28 }
lbb_23237:
    ldxw r0, [r2+0x0]                       
    ldxw r9, [r4+0x0]                       
    add64 r9, r0                                    r9 += r0   ///  r9 = r9.wrapping_add(r0)
    mov64 r8, r9                                    r8 = r9
    lsh64 r8, 32                                    r8 <<= 32   ///  r8 = r8.wrapping_shl(32)
    rsh64 r8, 32                                    r8 >>= 32   ///  r8 = r8.wrapping_shr(32)
    mov64 r6, 1                                     r6 = 1 as i32 as i64 as u64
    mov64 r0, 1                                     r0 = 1 as i32 as i64 as u64
    jne r8, r9, lbb_23247                           if r8 != r9 { pc += 1 }
    mov64 r0, 0                                     r0 = 0 as i32 as i64 as u64
lbb_23247:
    and64 r7, 1                                     r7 &= 1   ///  r7 = r7.and(1)
    add64 r8, r7                                    r8 += r7   ///  r8 = r8.wrapping_add(r7)
    mov64 r7, r8                                    r7 = r8
    lsh64 r7, 32                                    r7 <<= 32   ///  r7 = r7.wrapping_shl(32)
    rsh64 r7, 32                                    r7 >>= 32   ///  r7 = r7.wrapping_shr(32)
    jne r7, r8, lbb_23223                           if r7 != r8 { pc += -30 }
    mov64 r6, 0                                     r6 = 0 as i32 as i64 as u64
    ja lbb_23223                                    if true { pc += -32 }
lbb_23255:
    jeq r1, 40, lbb_23897                           if r1 == (40 as i32 as i64 as u64) { pc += 641 }
    mov64 r2, r1                                    r2 = r1
    lsh64 r2, 2                                     r2 <<= 2   ///  r2 = r2.wrapping_shl(2)
    mov64 r4, r10                                   r4 = r10
    add64 r4, -168                                  r4 += -168   ///  r4 = r4.wrapping_add(-168 as i32 as i64 as u64)
    add64 r4, r2                                    r4 += r2   ///  r4 = r4.wrapping_add(r2)
    mov64 r2, 1                                     r2 = 1 as i32 as i64 as u64
    stxw [r4+0x0], r2                       
    add64 r1, 1                                     r1 += 1   ///  r1 = r1.wrapping_add(1 as i32 as i64 as u64)
    mov64 r2, r1                                    r2 = r1
lbb_23265:
    stxdw [r10-0x8], r2                     
    jgt r2, r7, lbb_23268                           if r2 > r7 { pc += 1 }
    mov64 r2, r7                                    r2 = r7
lbb_23268:
    mov64 r1, 41                                    r1 = 41 as i32 as i64 as u64
    jgt r1, r2, lbb_23271                           if r1 > r2 { pc += 1 }
    ja lbb_23190                                    if true { pc += -81 }
lbb_23271:
    lsh64 r2, 2                                     r2 <<= 2   ///  r2 = r2.wrapping_shl(2)
lbb_23272:
    jeq r2, 0, lbb_23312                            if r2 == (0 as i32 as i64 as u64) { pc += 39 }
    mov64 r4, r10                                   r4 = r10
    add64 r4, -168                                  r4 += -168   ///  r4 = r4.wrapping_add(-168 as i32 as i64 as u64)
    add64 r4, r2                                    r4 += r2   ///  r4 = r4.wrapping_add(r2)
    mov64 r1, r10                                   r1 = r10
    add64 r1, -672                                  r1 += -672   ///  r1 = r1.wrapping_add(-672 as i32 as i64 as u64)
    add64 r1, r2                                    r1 += r2   ///  r1 = r1.wrapping_add(r2)
    add64 r2, -4                                    r2 += -4   ///  r2 = r2.wrapping_add(-4 as i32 as i64 as u64)
    ldxw r1, [r1-0x4]                       
    ldxw r4, [r4-0x4]                       
    jeq r1, r4, lbb_23272                           if r1 == r4 { pc += -11 }
    jgt r4, r1, lbb_23314                           if r4 > r1 { pc += 30 }
lbb_23284:
    mov64 r2, r10                                   r2 = r10
    add64 r2, -840                                  r2 += -840   ///  r2 = r2.wrapping_add(-840 as i32 as i64 as u64)
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    jeq r3, 0, lbb_23310                            if r3 == (0 as i32 as i64 as u64) { pc += 22 }
    mov64 r1, r3                                    r1 = r3
    lsh64 r1, 2                                     r1 <<= 2   ///  r1 = r1.wrapping_shl(2)
    add64 r2, r1                                    r2 += r1   ///  r2 = r2.wrapping_add(r1)
    mov64 r4, r10                                   r4 = r10
    add64 r4, -840                                  r4 += -840   ///  r4 = r4.wrapping_add(-840 as i32 as i64 as u64)
    mov64 r0, 0                                     r0 = 0 as i32 as i64 as u64
lbb_23294:
    ldxw r5, [r4+0x0]                       
    mul64 r5, 10                                    r5 *= 10   ///  r5 = r5.wrapping_mul(10 as u64)
    add64 r5, r0                                    r5 += r0   ///  r5 = r5.wrapping_add(r0)
    stxw [r4+0x0], r5                       
    add64 r4, 4                                     r4 += 4   ///  r4 = r4.wrapping_add(4 as i32 as i64 as u64)
    rsh64 r5, 32                                    r5 >>= 32   ///  r5 = r5.wrapping_shr(32)
    add64 r1, -4                                    r1 += -4   ///  r1 = r1.wrapping_add(-4 as i32 as i64 as u64)
    mov64 r0, r5                                    r0 = r5
    jeq r1, 0, lbb_23304                            if r1 == (0 as i32 as i64 as u64) { pc += 1 }
    ja lbb_23294                                    if true { pc += -10 }
lbb_23304:
    mov64 r1, r3                                    r1 = r3
    jeq r5, 0, lbb_23310                            if r5 == (0 as i32 as i64 as u64) { pc += 4 }
    jeq r3, 40, lbb_23897                           if r3 == (40 as i32 as i64 as u64) { pc += 590 }
    stxw [r2+0x0], r5                       
    add64 r3, 1                                     r3 += 1   ///  r3 = r3.wrapping_add(1 as i32 as i64 as u64)
    mov64 r1, r3                                    r1 = r3
lbb_23310:
    stxdw [r10-0x2a8], r1                   
    ja lbb_23316                                    if true { pc += 4 }
lbb_23312:
    jeq r2, 0, lbb_23314                            if r2 == (0 as i32 as i64 as u64) { pc += 1 }
    ja lbb_23284                                    if true { pc += -30 }
lbb_23314:
    add64 r8, 1                                     r8 += 1   ///  r8 = r8.wrapping_add(1 as i32 as i64 as u64)
    mov64 r1, r3                                    r1 = r3
lbb_23316:
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
    mov64 r3, r8                                    r3 = r8
    lsh64 r3, 48                                    r3 <<= 48   ///  r3 = r3.wrapping_shl(48)
    arsh64 r3, 48                                   r3 >>= 48 (signed)   ///  r3 = (r3 as i64).wrapping_shr(48)
    ldxdw r4, [r10-0x360]                   
    lsh64 r4, 48                                    r4 <<= 48   ///  r4 = r4.wrapping_shl(48)
    arsh64 r4, 48                                   r4 >>= 48 (signed)   ///  r4 = (r4 as i64).wrapping_shr(48)
    mov64 r7, 0                                     r7 = 0 as i32 as i64 as u64
    jsgt r4, r3, lbb_23731                          if (r4 as i64) > (r3 as i64) { pc += 406 }
    sub64 r3, r4                                    r3 -= r4   ///  r3 = r3.wrapping_sub(r4)
    mov64 r4, r8                                    r4 = r8
    ldxdw r2, [r10-0x360]                   
    sub64 r4, r2                                    r4 -= r2   ///  r4 = r4.wrapping_sub(r2)
    lsh64 r4, 48                                    r4 <<= 48   ///  r4 = r4.wrapping_shl(48)
    arsh64 r4, 48                                   r4 >>= 48 (signed)   ///  r4 = (r4 as i64).wrapping_shr(48)
    jgt r9, r3, lbb_23333                           if r9 > r3 { pc += 1 }
    mov64 r4, r9                                    r4 = r9
lbb_23333:
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
    jeq r4, 0, lbb_23731                            if r4 == (0 as i32 as i64 as u64) { pc += 396 }
    stxdw [r10-0x380], r4                   
    stxdw [r10-0x370], r8                   
    mov64 r8, r10                                   r8 = r10
    add64 r8, -504                                  r8 += -504   ///  r8 = r8.wrapping_add(-504 as i32 as i64 as u64)
    mov64 r7, r10                                   r7 = r10
    add64 r7, -672                                  r7 += -672   ///  r7 = r7.wrapping_add(-672 as i32 as i64 as u64)
    mov64 r1, r8                                    r1 = r8
    mov64 r2, r7                                    r2 = r7
    mov64 r3, 160                                   r3 = 160 as i32 as i64 as u64
    call function_30349                     
    ldxdw r1, [r10-0x350]                   
    stxdw [r10-0x158], r1                   
    mov64 r1, r8                                    r1 = r8
    mov64 r2, 1                                     r2 = 1 as i32 as i64 as u64
    call function_29303                     
    ldxdw r8, [r10-0x200]                   
    mov64 r6, r10                                   r6 = r10
    add64 r6, -336                                  r6 += -336   ///  r6 = r6.wrapping_add(-336 as i32 as i64 as u64)
    mov64 r1, r6                                    r1 = r6
    mov64 r2, r7                                    r2 = r7
    mov64 r3, 160                                   r3 = 160 as i32 as i64 as u64
    call function_30349                     
    stxdw [r10-0xb0], r8                    
    mov64 r1, r6                                    r1 = r6
    mov64 r2, 2                                     r2 = 2 as i32 as i64 as u64
    call function_29303                     
    ldxdw r8, [r10-0x200]                   
    mov64 r6, r10                                   r6 = r10
    add64 r6, -168                                  r6 += -168   ///  r6 = r6.wrapping_add(-168 as i32 as i64 as u64)
    mov64 r1, r6                                    r1 = r6
    mov64 r2, r7                                    r2 = r7
    mov64 r3, 160                                   r3 = 160 as i32 as i64 as u64
    call function_30349                     
    stxdw [r10-0x8], r8                     
    mov64 r1, r6                                    r1 = r6
    mov64 r2, 3                                     r2 = 3 as i32 as i64 as u64
    call function_29303                     
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
    mov64 r8, r10                                   r8 = r10
    add64 r8, -844                                  r8 += -844   ///  r8 = r8.wrapping_add(-844 as i32 as i64 as u64)
    mov64 r5, r10                                   r5 = r10
    add64 r5, -676                                  r5 += -676   ///  r5 = r5.wrapping_add(-676 as i32 as i64 as u64)
    ldxdw r1, [r10-0x2a8]                   
    ldxdw r7, [r10-0x200]                   
    ldxdw r2, [r10-0x158]                   
    stxdw [r10-0x3a0], r2                   
    ldxdw r2, [r10-0xb0]                    
    stxdw [r10-0x398], r2                   
    ldxdw r2, [r10-0x8]                     
    stxdw [r10-0x390], r2                   
    mov64 r6, 41                                    r6 = 41 as i32 as i64 as u64
    stxdw [r10-0x350], r7                   
lbb_23387:
    mov64 r0, r3                                    r0 = r3
    jgt r6, r1, lbb_23390                           if r6 > r1 { pc += 1 }
    ja lbb_23179                                    if true { pc += -211 }
lbb_23390:
    mov64 r2, r0                                    r2 = r0
    add64 r2, 1                                     r2 += 1   ///  r2 = r2.wrapping_add(1 as i32 as i64 as u64)
    stxdw [r10-0x388], r2                   
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
    mov64 r3, r1                                    r3 = r1
    lsh64 r3, 2                                     r3 <<= 2   ///  r3 = r3.wrapping_shl(2)
    ldxdw r6, [r10-0x370]                   
lbb_23397:
    mov64 r4, r10                                   r4 = r10
    add64 r4, -840                                  r4 += -840   ///  r4 = r4.wrapping_add(-840 as i32 as i64 as u64)
    jeq r3, r2, lbb_23792                           if r3 == r2 { pc += 392 }
    add64 r4, r2                                    r4 += r2   ///  r4 = r4.wrapping_add(r2)
    add64 r2, 4                                     r2 += 4   ///  r2 = r2.wrapping_add(4 as i32 as i64 as u64)
    ldxw r4, [r4+0x0]                       
    jeq r4, 0, lbb_23397                            if r4 == (0 as i32 as i64 as u64) { pc += -7 }
    mov64 r2, r1                                    r2 = r1
    ldxdw r3, [r10-0x390]                   
    jgt r1, r3, lbb_23408                           if r1 > r3 { pc += 1 }
    ldxdw r2, [r10-0x390]                   
lbb_23408:
    stxdw [r10-0x3b0], r0                   
    mov64 r6, 41                                    r6 = 41 as i32 as i64 as u64
    jgt r6, r2, lbb_23412                           if r6 > r2 { pc += 1 }
    ja lbb_23190                                    if true { pc += -222 }
lbb_23412:
    mov64 r3, r2                                    r3 = r2
    lsh64 r3, 2                                     r3 <<= 2   ///  r3 = r3.wrapping_shl(2)
    stxdw [r10-0x3a8], r8                   
lbb_23415:
    jeq r3, 0, lbb_23430                            if r3 == (0 as i32 as i64 as u64) { pc += 14 }
    mov64 r0, r10                                   r0 = r10
    add64 r0, -840                                  r0 += -840   ///  r0 = r0.wrapping_add(-840 as i32 as i64 as u64)
    add64 r0, r3                                    r0 += r3   ///  r0 = r0.wrapping_add(r3)
    mov64 r4, r10                                   r4 = r10
    add64 r4, -168                                  r4 += -168   ///  r4 = r4.wrapping_add(-168 as i32 as i64 as u64)
    add64 r4, r3                                    r4 += r3   ///  r4 = r4.wrapping_add(r3)
    add64 r3, -4                                    r3 += -4   ///  r3 = r3.wrapping_add(-4 as i32 as i64 as u64)
    ldxw r4, [r4-0x4]                       
    ldxw r0, [r0-0x4]                       
    jeq r4, r0, lbb_23415                           if r4 == r0 { pc += -11 }
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
    stxdw [r10-0x368], r3                   
    jgt r0, r4, lbb_23434                           if r0 > r4 { pc += 5 }
    ja lbb_23479                                    if true { pc += 49 }
lbb_23430:
    mov64 r4, 0                                     r4 = 0 as i32 as i64 as u64
    stxdw [r10-0x368], r4                   
    jeq r3, 0, lbb_23434                            if r3 == (0 as i32 as i64 as u64) { pc += 1 }
    ja lbb_23479                                    if true { pc += 45 }
lbb_23434:
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    mov64 r7, 1                                     r7 = 1 as i32 as i64 as u64
    mov64 r3, r10                                   r3 = r10
    add64 r3, -168                                  r3 += -168   ///  r3 = r3.wrapping_add(-168 as i32 as i64 as u64)
    mov64 r8, r10                                   r8 = r10
    add64 r8, -840                                  r8 += -840   ///  r8 = r8.wrapping_add(-840 as i32 as i64 as u64)
    ja lbb_23451                                    if true { pc += 10 }
lbb_23441:
    stxw [r8+0x0], r4                       
    or64 r0, r6                                     r0 |= r6   ///  r0 = r0.or(r6)
    add64 r8, 4                                     r8 += 4   ///  r8 = r8.wrapping_add(4 as i32 as i64 as u64)
    add64 r3, 4                                     r3 += 4   ///  r3 = r3.wrapping_add(4 as i32 as i64 as u64)
    add64 r1, 1                                     r1 += 1   ///  r1 = r1.wrapping_add(1 as i32 as i64 as u64)
    mov64 r7, r0                                    r7 = r0
    jgt r2, r1, lbb_23451                           if r2 > r1 { pc += 3 }
    and64 r0, 1                                     r0 &= 1   ///  r0 = r0.and(1)
    jne r0, 0, lbb_23472                            if r0 != (0 as i32 as i64 as u64) { pc += 22 }
    ja lbb_23911                                    if true { pc += 460 }
lbb_23451:
    ldxw r4, [r3+0x0]                       
    xor64 r4, -1                                    r4 ^= -1   ///  r4 = r4.xor(-1)
    lsh64 r4, 32                                    r4 <<= 32   ///  r4 = r4.wrapping_shl(32)
    rsh64 r4, 32                                    r4 >>= 32   ///  r4 = r4.wrapping_shr(32)
    ldxw r6, [r8+0x0]                       
    add64 r6, r4                                    r6 += r4   ///  r6 = r6.wrapping_add(r4)
    mov64 r4, r6                                    r4 = r6
    lsh64 r4, 32                                    r4 <<= 32   ///  r4 = r4.wrapping_shl(32)
    rsh64 r4, 32                                    r4 >>= 32   ///  r4 = r4.wrapping_shr(32)
    mov64 r0, 1                                     r0 = 1 as i32 as i64 as u64
    jne r4, r6, lbb_23463                           if r4 != r6 { pc += 1 }
    mov64 r0, 0                                     r0 = 0 as i32 as i64 as u64
lbb_23463:
    and64 r7, 1                                     r7 &= 1   ///  r7 = r7.and(1)
    add64 r4, r7                                    r4 += r7   ///  r4 = r4.wrapping_add(r7)
    mov64 r7, r4                                    r7 = r4
    lsh64 r7, 32                                    r7 <<= 32   ///  r7 = r7.wrapping_shl(32)
    rsh64 r7, 32                                    r7 >>= 32   ///  r7 = r7.wrapping_shr(32)
    mov64 r6, 1                                     r6 = 1 as i32 as i64 as u64
    jne r7, r4, lbb_23441                           if r7 != r4 { pc += -29 }
    mov64 r6, 0                                     r6 = 0 as i32 as i64 as u64
    ja lbb_23441                                    if true { pc += -31 }
lbb_23472:
    stxdw [r10-0x2a8], r2                   
    mov64 r1, 8                                     r1 = 8 as i32 as i64 as u64
    stxdw [r10-0x368], r1                   
    mov64 r1, r2                                    r1 = r2
    ldxdw r7, [r10-0x350]                   
    ldxdw r8, [r10-0x3a8]                   
    mov64 r6, 41                                    r6 = 41 as i32 as i64 as u64
lbb_23479:
    mov64 r2, r1                                    r2 = r1
    ldxdw r3, [r10-0x398]                   
    jgt r1, r3, lbb_23483                           if r1 > r3 { pc += 1 }
    ldxdw r2, [r10-0x398]                   
lbb_23483:
    jgt r6, r2, lbb_23485                           if r6 > r2 { pc += 1 }
    ja lbb_23190                                    if true { pc += -295 }
lbb_23485:
    mov64 r3, r2                                    r3 = r2
    lsh64 r3, 2                                     r3 <<= 2   ///  r3 = r3.wrapping_shl(2)
lbb_23487:
    jeq r3, 0, lbb_23536                            if r3 == (0 as i32 as i64 as u64) { pc += 48 }
    mov64 r0, r10                                   r0 = r10
    add64 r0, -840                                  r0 += -840   ///  r0 = r0.wrapping_add(-840 as i32 as i64 as u64)
    add64 r0, r3                                    r0 += r3   ///  r0 = r0.wrapping_add(r3)
    mov64 r4, r10                                   r4 = r10
    add64 r4, -336                                  r4 += -336   ///  r4 = r4.wrapping_add(-336 as i32 as i64 as u64)
    add64 r4, r3                                    r4 += r3   ///  r4 = r4.wrapping_add(r3)
    add64 r3, -4                                    r3 += -4   ///  r3 = r3.wrapping_add(-4 as i32 as i64 as u64)
    ldxw r4, [r4-0x4]                       
    ldxw r0, [r0-0x4]                       
    jeq r4, r0, lbb_23487                           if r4 == r0 { pc += -11 }
    jge r4, r0, lbb_23549                           if r4 >= r0 { pc += 50 }
lbb_23499:
    jeq r2, 0, lbb_23543                            if r2 == (0 as i32 as i64 as u64) { pc += 43 }
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    mov64 r8, 1                                     r8 = 1 as i32 as i64 as u64
    mov64 r3, r10                                   r3 = r10
    add64 r3, -336                                  r3 += -336   ///  r3 = r3.wrapping_add(-336 as i32 as i64 as u64)
    mov64 r0, r10                                   r0 = r10
    add64 r0, -840                                  r0 += -840   ///  r0 = r0.wrapping_add(-840 as i32 as i64 as u64)
    ja lbb_23515                                    if true { pc += 8 }
lbb_23507:
    stxw [r0+0x0], r4                       
    or64 r7, r6                                     r7 |= r6   ///  r7 = r7.or(r6)
    add64 r0, 4                                     r0 += 4   ///  r0 = r0.wrapping_add(4 as i32 as i64 as u64)
    add64 r3, 4                                     r3 += 4   ///  r3 = r3.wrapping_add(4 as i32 as i64 as u64)
    add64 r1, 1                                     r1 += 1   ///  r1 = r1.wrapping_add(1 as i32 as i64 as u64)
    mov64 r8, r7                                    r8 = r7
    jgt r2, r1, lbb_23515                           if r2 > r1 { pc += 1 }
    ja lbb_23538                                    if true { pc += 23 }
lbb_23515:
    ldxw r4, [r3+0x0]                       
    xor64 r4, -1                                    r4 ^= -1   ///  r4 = r4.xor(-1)
    lsh64 r4, 32                                    r4 <<= 32   ///  r4 = r4.wrapping_shl(32)
    rsh64 r4, 32                                    r4 >>= 32   ///  r4 = r4.wrapping_shr(32)
    ldxw r6, [r0+0x0]                       
    add64 r6, r4                                    r6 += r4   ///  r6 = r6.wrapping_add(r4)
    mov64 r4, r6                                    r4 = r6
    lsh64 r4, 32                                    r4 <<= 32   ///  r4 = r4.wrapping_shl(32)
    rsh64 r4, 32                                    r4 >>= 32   ///  r4 = r4.wrapping_shr(32)
    mov64 r7, 1                                     r7 = 1 as i32 as i64 as u64
    jne r4, r6, lbb_23527                           if r4 != r6 { pc += 1 }
    mov64 r7, 0                                     r7 = 0 as i32 as i64 as u64
lbb_23527:
    and64 r8, 1                                     r8 &= 1   ///  r8 = r8.and(1)
    add64 r4, r8                                    r4 += r8   ///  r4 = r4.wrapping_add(r8)
    mov64 r8, r4                                    r8 = r4
    lsh64 r8, 32                                    r8 <<= 32   ///  r8 = r8.wrapping_shl(32)
    rsh64 r8, 32                                    r8 >>= 32   ///  r8 = r8.wrapping_shr(32)
    mov64 r6, 1                                     r6 = 1 as i32 as i64 as u64
    jne r8, r4, lbb_23507                           if r8 != r4 { pc += -27 }
    mov64 r6, 0                                     r6 = 0 as i32 as i64 as u64
    ja lbb_23507                                    if true { pc += -29 }
lbb_23536:
    jeq r3, 0, lbb_23499                            if r3 == (0 as i32 as i64 as u64) { pc += -38 }
    ja lbb_23549                                    if true { pc += 11 }
lbb_23538:
    and64 r7, 1                                     r7 &= 1   ///  r7 = r7.and(1)
    ldxdw r8, [r10-0x3a8]                   
    mov64 r6, 41                                    r6 = 41 as i32 as i64 as u64
    jne r7, 0, lbb_23543                            if r7 != (0 as i32 as i64 as u64) { pc += 1 }
    ja lbb_23911                                    if true { pc += 368 }
lbb_23543:
    stxdw [r10-0x2a8], r2                   
    ldxdw r1, [r10-0x368]                   
    or64 r1, 4                                      r1 |= 4   ///  r1 = r1.or(4)
    stxdw [r10-0x368], r1                   
    mov64 r1, r2                                    r1 = r2
    ldxdw r7, [r10-0x350]                   
lbb_23549:
    mov64 r2, r1                                    r2 = r1
    ldxdw r3, [r10-0x3a0]                   
    jgt r1, r3, lbb_23553                           if r1 > r3 { pc += 1 }
    ldxdw r2, [r10-0x3a0]                   
lbb_23553:
    jgt r6, r2, lbb_23555                           if r6 > r2 { pc += 1 }
    ja lbb_23190                                    if true { pc += -365 }
lbb_23555:
    mov64 r3, r2                                    r3 = r2
    lsh64 r3, 2                                     r3 <<= 2   ///  r3 = r3.wrapping_shl(2)
lbb_23557:
    jeq r3, 0, lbb_23606                            if r3 == (0 as i32 as i64 as u64) { pc += 48 }
    mov64 r0, r10                                   r0 = r10
    add64 r0, -840                                  r0 += -840   ///  r0 = r0.wrapping_add(-840 as i32 as i64 as u64)
    add64 r0, r3                                    r0 += r3   ///  r0 = r0.wrapping_add(r3)
    mov64 r4, r10                                   r4 = r10
    add64 r4, -504                                  r4 += -504   ///  r4 = r4.wrapping_add(-504 as i32 as i64 as u64)
    add64 r4, r3                                    r4 += r3   ///  r4 = r4.wrapping_add(r3)
    add64 r3, -4                                    r3 += -4   ///  r3 = r3.wrapping_add(-4 as i32 as i64 as u64)
    ldxw r4, [r4-0x4]                       
    ldxw r0, [r0-0x4]                       
    jeq r4, r0, lbb_23557                           if r4 == r0 { pc += -11 }
    jge r4, r0, lbb_23619                           if r4 >= r0 { pc += 50 }
lbb_23569:
    jeq r2, 0, lbb_23613                            if r2 == (0 as i32 as i64 as u64) { pc += 43 }
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    mov64 r8, 1                                     r8 = 1 as i32 as i64 as u64
    mov64 r3, r10                                   r3 = r10
    add64 r3, -504                                  r3 += -504   ///  r3 = r3.wrapping_add(-504 as i32 as i64 as u64)
    mov64 r0, r10                                   r0 = r10
    add64 r0, -840                                  r0 += -840   ///  r0 = r0.wrapping_add(-840 as i32 as i64 as u64)
    ja lbb_23585                                    if true { pc += 8 }
lbb_23577:
    stxw [r0+0x0], r4                       
    or64 r7, r6                                     r7 |= r6   ///  r7 = r7.or(r6)
    add64 r0, 4                                     r0 += 4   ///  r0 = r0.wrapping_add(4 as i32 as i64 as u64)
    add64 r3, 4                                     r3 += 4   ///  r3 = r3.wrapping_add(4 as i32 as i64 as u64)
    add64 r1, 1                                     r1 += 1   ///  r1 = r1.wrapping_add(1 as i32 as i64 as u64)
    mov64 r8, r7                                    r8 = r7
    jgt r2, r1, lbb_23585                           if r2 > r1 { pc += 1 }
    ja lbb_23608                                    if true { pc += 23 }
lbb_23585:
    ldxw r4, [r3+0x0]                       
    xor64 r4, -1                                    r4 ^= -1   ///  r4 = r4.xor(-1)
    lsh64 r4, 32                                    r4 <<= 32   ///  r4 = r4.wrapping_shl(32)
    rsh64 r4, 32                                    r4 >>= 32   ///  r4 = r4.wrapping_shr(32)
    ldxw r6, [r0+0x0]                       
    add64 r6, r4                                    r6 += r4   ///  r6 = r6.wrapping_add(r4)
    mov64 r4, r6                                    r4 = r6
    lsh64 r4, 32                                    r4 <<= 32   ///  r4 = r4.wrapping_shl(32)
    rsh64 r4, 32                                    r4 >>= 32   ///  r4 = r4.wrapping_shr(32)
    mov64 r7, 1                                     r7 = 1 as i32 as i64 as u64
    jne r4, r6, lbb_23597                           if r4 != r6 { pc += 1 }
    mov64 r7, 0                                     r7 = 0 as i32 as i64 as u64
lbb_23597:
    and64 r8, 1                                     r8 &= 1   ///  r8 = r8.and(1)
    add64 r4, r8                                    r4 += r8   ///  r4 = r4.wrapping_add(r8)
    mov64 r8, r4                                    r8 = r4
    lsh64 r8, 32                                    r8 <<= 32   ///  r8 = r8.wrapping_shl(32)
    rsh64 r8, 32                                    r8 >>= 32   ///  r8 = r8.wrapping_shr(32)
    mov64 r6, 1                                     r6 = 1 as i32 as i64 as u64
    jne r8, r4, lbb_23577                           if r8 != r4 { pc += -27 }
    mov64 r6, 0                                     r6 = 0 as i32 as i64 as u64
    ja lbb_23577                                    if true { pc += -29 }
lbb_23606:
    jeq r3, 0, lbb_23569                            if r3 == (0 as i32 as i64 as u64) { pc += -38 }
    ja lbb_23619                                    if true { pc += 11 }
lbb_23608:
    and64 r7, 1                                     r7 &= 1   ///  r7 = r7.and(1)
    ldxdw r8, [r10-0x3a8]                   
    mov64 r6, 41                                    r6 = 41 as i32 as i64 as u64
    jne r7, 0, lbb_23613                            if r7 != (0 as i32 as i64 as u64) { pc += 1 }
    ja lbb_23911                                    if true { pc += 298 }
lbb_23613:
    stxdw [r10-0x2a8], r2                   
    ldxdw r1, [r10-0x368]                   
    add64 r1, 2                                     r1 += 2   ///  r1 = r1.wrapping_add(2 as i32 as i64 as u64)
    stxdw [r10-0x368], r1                   
    mov64 r1, r2                                    r1 = r2
    ldxdw r7, [r10-0x350]                   
lbb_23619:
    mov64 r2, r1                                    r2 = r1
    jgt r1, r7, lbb_23622                           if r1 > r7 { pc += 1 }
    mov64 r2, r7                                    r2 = r7
lbb_23622:
    jgt r6, r2, lbb_23624                           if r6 > r2 { pc += 1 }
    ja lbb_23190                                    if true { pc += -434 }
lbb_23624:
    mov64 r4, r2                                    r4 = r2
    lsh64 r4, 2                                     r4 <<= 2   ///  r4 = r4.wrapping_shl(2)
lbb_23626:
    jeq r4, 0, lbb_23674                            if r4 == (0 as i32 as i64 as u64) { pc += 47 }
    mov64 r3, r8                                    r3 = r8
    add64 r3, r4                                    r3 += r4   ///  r3 = r3.wrapping_add(r4)
    mov64 r0, r5                                    r0 = r5
    add64 r0, r4                                    r0 += r4   ///  r0 = r0.wrapping_add(r4)
    add64 r4, -4                                    r4 += -4   ///  r4 = r4.wrapping_add(-4 as i32 as i64 as u64)
    ldxw r0, [r0+0x0]                       
    ldxw r6, [r3+0x0]                       
    jeq r0, r6, lbb_23626                           if r0 == r6 { pc += -9 }
    mov64 r3, r1                                    r3 = r1
    jge r0, r6, lbb_23686                           if r0 >= r6 { pc += 49 }
lbb_23637:
    jeq r2, 0, lbb_23681                            if r2 == (0 as i32 as i64 as u64) { pc += 43 }
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    mov64 r8, 1                                     r8 = 1 as i32 as i64 as u64
    mov64 r3, r10                                   r3 = r10
    add64 r3, -672                                  r3 += -672   ///  r3 = r3.wrapping_add(-672 as i32 as i64 as u64)
    mov64 r0, r10                                   r0 = r10
    add64 r0, -840                                  r0 += -840   ///  r0 = r0.wrapping_add(-840 as i32 as i64 as u64)
    ja lbb_23653                                    if true { pc += 8 }
lbb_23645:
    stxw [r0+0x0], r4                       
    or64 r7, r6                                     r7 |= r6   ///  r7 = r7.or(r6)
    add64 r0, 4                                     r0 += 4   ///  r0 = r0.wrapping_add(4 as i32 as i64 as u64)
    add64 r3, 4                                     r3 += 4   ///  r3 = r3.wrapping_add(4 as i32 as i64 as u64)
    add64 r1, 1                                     r1 += 1   ///  r1 = r1.wrapping_add(1 as i32 as i64 as u64)
    mov64 r8, r7                                    r8 = r7
    jgt r2, r1, lbb_23653                           if r2 > r1 { pc += 1 }
    ja lbb_23677                                    if true { pc += 24 }
lbb_23653:
    ldxw r4, [r3+0x0]                       
    xor64 r4, -1                                    r4 ^= -1   ///  r4 = r4.xor(-1)
    lsh64 r4, 32                                    r4 <<= 32   ///  r4 = r4.wrapping_shl(32)
    rsh64 r4, 32                                    r4 >>= 32   ///  r4 = r4.wrapping_shr(32)
    ldxw r6, [r0+0x0]                       
    add64 r6, r4                                    r6 += r4   ///  r6 = r6.wrapping_add(r4)
    mov64 r4, r6                                    r4 = r6
    lsh64 r4, 32                                    r4 <<= 32   ///  r4 = r4.wrapping_shl(32)
    rsh64 r4, 32                                    r4 >>= 32   ///  r4 = r4.wrapping_shr(32)
    mov64 r7, 1                                     r7 = 1 as i32 as i64 as u64
    jne r4, r6, lbb_23665                           if r4 != r6 { pc += 1 }
    mov64 r7, 0                                     r7 = 0 as i32 as i64 as u64
lbb_23665:
    and64 r8, 1                                     r8 &= 1   ///  r8 = r8.and(1)
    add64 r4, r8                                    r4 += r8   ///  r4 = r4.wrapping_add(r8)
    mov64 r8, r4                                    r8 = r4
    lsh64 r8, 32                                    r8 <<= 32   ///  r8 = r8.wrapping_shl(32)
    rsh64 r8, 32                                    r8 >>= 32   ///  r8 = r8.wrapping_shr(32)
    mov64 r6, 1                                     r6 = 1 as i32 as i64 as u64
    jne r8, r4, lbb_23645                           if r8 != r4 { pc += -27 }
    mov64 r6, 0                                     r6 = 0 as i32 as i64 as u64
    ja lbb_23645                                    if true { pc += -29 }
lbb_23674:
    mov64 r3, r1                                    r3 = r1
    jeq r4, 0, lbb_23637                            if r4 == (0 as i32 as i64 as u64) { pc += -39 }
    ja lbb_23686                                    if true { pc += 9 }
lbb_23677:
    and64 r7, 1                                     r7 &= 1   ///  r7 = r7.and(1)
    ldxdw r8, [r10-0x3a8]                   
    jne r7, 0, lbb_23681                            if r7 != (0 as i32 as i64 as u64) { pc += 1 }
    ja lbb_23911                                    if true { pc += 230 }
lbb_23681:
    stxdw [r10-0x2a8], r2                   
    ldxdw r1, [r10-0x368]                   
    add64 r1, 1                                     r1 += 1   ///  r1 = r1.wrapping_add(1 as i32 as i64 as u64)
    stxdw [r10-0x368], r1                   
    mov64 r3, r2                                    r3 = r2
lbb_23686:
    ldxdw r2, [r10-0x3b0]                   
    jeq r2, r9, lbb_23902                           if r2 == r9 { pc += 214 }
    ldxdw r1, [r10-0x358]                   
    add64 r1, r2                                    r1 += r2   ///  r1 = r1.wrapping_add(r2)
    ldxdw r2, [r10-0x368]                   
    add64 r2, 48                                    r2 += 48   ///  r2 = r2.wrapping_add(48 as i32 as i64 as u64)
    stxb [r1+0x0], r2                       
    mov64 r6, 41                                    r6 = 41 as i32 as i64 as u64
    jgt r6, r3, lbb_23697                           if r6 > r3 { pc += 2 }
    mov64 r1, r3                                    r1 = r3
    ja lbb_23179                                    if true { pc += -518 }
lbb_23697:
    mov64 r2, r10                                   r2 = r10
    add64 r2, -840                                  r2 += -840   ///  r2 = r2.wrapping_add(-840 as i32 as i64 as u64)
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    jeq r3, 0, lbb_23723                            if r3 == (0 as i32 as i64 as u64) { pc += 22 }
    mov64 r1, r3                                    r1 = r3
    lsh64 r1, 2                                     r1 <<= 2   ///  r1 = r1.wrapping_shl(2)
    add64 r2, r1                                    r2 += r1   ///  r2 = r2.wrapping_add(r1)
    mov64 r0, r10                                   r0 = r10
    add64 r0, -840                                  r0 += -840   ///  r0 = r0.wrapping_add(-840 as i32 as i64 as u64)
    mov64 r4, 0                                     r4 = 0 as i32 as i64 as u64
lbb_23707:
    ldxw r7, [r0+0x0]                       
    mul64 r7, 10                                    r7 *= 10   ///  r7 = r7.wrapping_mul(10 as u64)
    add64 r7, r4                                    r7 += r4   ///  r7 = r7.wrapping_add(r4)
    stxw [r0+0x0], r7                       
    add64 r0, 4                                     r0 += 4   ///  r0 = r0.wrapping_add(4 as i32 as i64 as u64)
    rsh64 r7, 32                                    r7 >>= 32   ///  r7 = r7.wrapping_shr(32)
    add64 r1, -4                                    r1 += -4   ///  r1 = r1.wrapping_add(-4 as i32 as i64 as u64)
    mov64 r4, r7                                    r4 = r7
    jeq r1, 0, lbb_23717                            if r1 == (0 as i32 as i64 as u64) { pc += 1 }
    ja lbb_23707                                    if true { pc += -10 }
lbb_23717:
    mov64 r1, r3                                    r1 = r3
    jeq r7, 0, lbb_23723                            if r7 == (0 as i32 as i64 as u64) { pc += 4 }
    jeq r3, 40, lbb_23897                           if r3 == (40 as i32 as i64 as u64) { pc += 177 }
    stxw [r2+0x0], r7                       
    add64 r3, 1                                     r3 += 1   ///  r3 = r3.wrapping_add(1 as i32 as i64 as u64)
    mov64 r1, r3                                    r1 = r3
lbb_23723:
    stxdw [r10-0x2a8], r1                   
    ldxdw r7, [r10-0x350]                   
    ldxdw r2, [r10-0x380]                   
    ldxdw r3, [r10-0x388]                   
    jgt r2, r3, lbb_23387                           if r2 > r3 { pc += -341 }
    mov64 r2, 1                                     r2 = 1 as i32 as i64 as u64
    ldxdw r7, [r10-0x380]                   
    ldxdw r8, [r10-0x370]                   
lbb_23731:
    mov64 r3, 41                                    r3 = 41 as i32 as i64 as u64
    ldxdw r5, [r10-0x350]                   
    jgt r3, r5, lbb_23736                           if r3 > r5 { pc += 2 }
    mov64 r1, r5                                    r1 = r5
    ja lbb_23179                                    if true { pc += -557 }
lbb_23736:
    mov64 r3, r10                                   r3 = r10
    add64 r3, -672                                  r3 += -672   ///  r3 = r3.wrapping_add(-672 as i32 as i64 as u64)
    mov64 r4, 0                                     r4 = 0 as i32 as i64 as u64
    jeq r5, 0, lbb_23763                            if r5 == (0 as i32 as i64 as u64) { pc += 23 }
    mov64 r4, r5                                    r4 = r5
    lsh64 r4, 2                                     r4 <<= 2   ///  r4 = r4.wrapping_shl(2)
    add64 r3, r4                                    r3 += r4   ///  r3 = r3.wrapping_add(r4)
    mov64 r5, r10                                   r5 = r10
    add64 r5, -672                                  r5 += -672   ///  r5 = r5.wrapping_add(-672 as i32 as i64 as u64)
    mov64 r6, 0                                     r6 = 0 as i32 as i64 as u64
lbb_23746:
    ldxw r0, [r5+0x0]                       
    mul64 r0, 5                                     r0 *= 5   ///  r0 = r0.wrapping_mul(5 as u64)
    add64 r0, r6                                    r0 += r6   ///  r0 = r0.wrapping_add(r6)
    stxw [r5+0x0], r0                       
    add64 r5, 4                                     r5 += 4   ///  r5 = r5.wrapping_add(4 as i32 as i64 as u64)
    rsh64 r0, 32                                    r0 >>= 32   ///  r0 = r0.wrapping_shr(32)
    add64 r4, -4                                    r4 += -4   ///  r4 = r4.wrapping_add(-4 as i32 as i64 as u64)
    mov64 r6, r0                                    r6 = r0
    jeq r4, 0, lbb_23756                            if r4 == (0 as i32 as i64 as u64) { pc += 1 }
    ja lbb_23746                                    if true { pc += -10 }
lbb_23756:
    ldxdw r5, [r10-0x350]                   
    mov64 r4, r5                                    r4 = r5
    jeq r0, 0, lbb_23763                            if r0 == (0 as i32 as i64 as u64) { pc += 4 }
    jeq r5, 40, lbb_23897                           if r5 == (40 as i32 as i64 as u64) { pc += 137 }
    stxw [r3+0x0], r0                       
    add64 r5, 1                                     r5 += 1   ///  r5 = r5.wrapping_add(1 as i32 as i64 as u64)
    mov64 r4, r5                                    r4 = r5
lbb_23763:
    stxdw [r10-0x200], r4                   
    jgt r1, r4, lbb_23766                           if r1 > r4 { pc += 1 }
    mov64 r1, r4                                    r1 = r4
lbb_23766:
    mov64 r3, 41                                    r3 = 41 as i32 as i64 as u64
    jgt r3, r1, lbb_23769                           if r3 > r1 { pc += 1 }
    ja lbb_23179                                    if true { pc += -590 }
lbb_23769:
    lsh64 r1, 2                                     r1 <<= 2   ///  r1 = r1.wrapping_shl(2)
    ja lbb_23776                                    if true { pc += 5 }
lbb_23771:
    add64 r1, -4                                    r1 += -4   ///  r1 = r1.wrapping_add(-4 as i32 as i64 as u64)
    jeq r4, 0, lbb_23776                            if r4 == (0 as i32 as i64 as u64) { pc += 3 }
    and64 r4, 255                                   r4 &= 255   ///  r4 = r4.and(255)
    jeq r4, 1, lbb_23827                            if r4 == (1 as i32 as i64 as u64) { pc += 52 }
    ja lbb_23857                                    if true { pc += 81 }
lbb_23776:
    jeq r1, 0, lbb_23810                            if r1 == (0 as i32 as i64 as u64) { pc += 33 }
    mov64 r3, r10                                   r3 = r10
    add64 r3, -840                                  r3 += -840   ///  r3 = r3.wrapping_add(-840 as i32 as i64 as u64)
    add64 r3, r1                                    r3 += r1   ///  r3 = r3.wrapping_add(r1)
    ldxw r3, [r3-0x4]                       
    mov64 r4, r10                                   r4 = r10
    add64 r4, -672                                  r4 += -672   ///  r4 = r4.wrapping_add(-672 as i32 as i64 as u64)
    add64 r4, r1                                    r4 += r1   ///  r4 = r4.wrapping_add(r1)
    ldxw r5, [r4-0x4]                       
    mov64 r0, 1                                     r0 = 1 as i32 as i64 as u64
    jne r5, r3, lbb_23788                           if r5 != r3 { pc += 1 }
    mov64 r0, 0                                     r0 = 0 as i32 as i64 as u64
lbb_23788:
    mov64 r4, -1                                    r4 = -1 as i32 as i64 as u64
    jgt r5, r3, lbb_23771                           if r5 > r3 { pc += -19 }
    mov64 r4, r0                                    r4 = r0
    ja lbb_23771                                    if true { pc += -21 }
lbb_23792:
    ldxdw r3, [r10-0x380]                   
    jge r9, r3, lbb_23799                           if r9 >= r3 { pc += 5 }
    mov64 r1, r3                                    r1 = r3
    mov64 r2, r9                                    r2 = r9
    lddw r3, 0x100041bd8 --> b"\x00\x00\x00\x00\xb8\xf6\x03\x00/\x00\x00\x00\x00\x00\x00\x00K\x01\x00\x0…        r3 load str located at 4295236568
    call function_28353                     
lbb_23799:
    jeq r3, r0, lbb_23806                           if r3 == r0 { pc += 6 }
    ldxdw r1, [r10-0x358]                   
    add64 r1, r0                                    r1 += r0   ///  r1 = r1.wrapping_add(r0)
    sub64 r3, r0                                    r3 -= r0   ///  r3 = r3.wrapping_sub(r0)
    mov64 r2, 48                                    r2 = 48 as i32 as i64 as u64
    call function_30383                     
    ldxdw r3, [r10-0x380]                   
lbb_23806:
    ldxdw r2, [r10-0x378]                   
    stxh [r2+0x10], r6                      
    stxdw [r2+0x8], r3                      
    ja lbb_23863                                    if true { pc += 53 }
lbb_23810:
    mov64 r3, 1                                     r3 = 1 as i32 as i64 as u64
    jeq r1, 0, lbb_23813                            if r1 == (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
lbb_23813:
    and64 r2, r3                                    r2 &= r3   ///  r2 = r2.and(r3)
    mov64 r4, r8                                    r4 = r8
    jne r2, 0, lbb_23817                            if r2 != (0 as i32 as i64 as u64) { pc += 1 }
    ja lbb_23858                                    if true { pc += 41 }
lbb_23817:
    mov64 r1, r7                                    r1 = r7
    add64 r1, -1                                    r1 += -1   ///  r1 = r1.wrapping_add(-1 as i32 as i64 as u64)
    jgt r9, r1, lbb_23821                           if r9 > r1 { pc += 1 }
    ja lbb_23907                                    if true { pc += 86 }
lbb_23821:
    ldxdw r2, [r10-0x358]                   
    add64 r2, r1                                    r2 += r1   ///  r2 = r2.wrapping_add(r1)
    ldxb r1, [r2+0x0]                       
    and64 r1, 1                                     r1 &= 1   ///  r1 = r1.and(1)
    mov64 r4, r8                                    r4 = r8
    jeq r1, 0, lbb_23858                            if r1 == (0 as i32 as i64 as u64) { pc += 31 }
lbb_23827:
    mov64 r2, r9                                    r2 = r9
    jge r2, r7, lbb_23833                           if r2 >= r7 { pc += 4 }
    mov64 r1, r7                                    r1 = r7
    lddw r3, 0x100041b90 --> b"\x00\x00\x00\x00\xb8\xf6\x03\x00/\x00\x00\x00\x00\x00\x00\x00v\x01\x00\x0…        r3 load str located at 4295236496
    call function_28353                     
lbb_23833:
    ldxdw r1, [r10-0x358]                   
    mov64 r6, r1                                    r6 = r1
    add64 r6, r7                                    r6 += r7   ///  r6 = r6.wrapping_add(r7)
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
lbb_23837:
    jeq r7, r3, lbb_23866                           if r7 == r3 { pc += 28 }
    mov64 r2, r1                                    r2 = r1
    add64 r2, r7                                    r2 += r7   ///  r2 = r2.wrapping_add(r7)
    add64 r1, -1                                    r1 += -1   ///  r1 = r1.wrapping_add(-1 as i32 as i64 as u64)
    add64 r3, 1                                     r3 += 1   ///  r3 = r3.wrapping_add(1 as i32 as i64 as u64)
    ldxb r2, [r2-0x1]                       
    jeq r2, 57, lbb_23837                           if r2 == (57 as i32 as i64 as u64) { pc += -7 }
    add64 r1, r7                                    r1 += r7   ///  r1 = r1.wrapping_add(r7)
    ldxb r2, [r1+0x0]                       
    add64 r2, 1                                     r2 += 1   ///  r2 = r2.wrapping_add(1 as i32 as i64 as u64)
    stxb [r1+0x0], r2                       
    mov64 r2, r7                                    r2 = r7
    sub64 r2, r3                                    r2 -= r3   ///  r2 = r2.wrapping_sub(r3)
    add64 r2, 1                                     r2 += 1   ///  r2 = r2.wrapping_add(1 as i32 as i64 as u64)
    mov64 r4, r8                                    r4 = r8
    jge r2, r7, lbb_23858                           if r2 >= r7 { pc += 5 }
    add64 r3, -1                                    r3 += -1   ///  r3 = r3.wrapping_add(-1 as i32 as i64 as u64)
    add64 r1, 1                                     r1 += 1   ///  r1 = r1.wrapping_add(1 as i32 as i64 as u64)
    mov64 r2, 48                                    r2 = 48 as i32 as i64 as u64
    call function_30383                     
lbb_23857:
    mov64 r4, r8                                    r4 = r8
lbb_23858:
    jge r9, r7, lbb_23860                           if r9 >= r7 { pc += 1 }
    ja lbb_23892                                    if true { pc += 32 }
lbb_23860:
    ldxdw r2, [r10-0x378]                   
    stxh [r2+0x10], r4                      
    stxdw [r2+0x8], r7                      
lbb_23863:
    ldxdw r1, [r10-0x358]                   
    stxdw [r2+0x0], r1                      
    exit                                    
lbb_23866:
    mov64 r3, 49                                    r3 = 49 as i32 as i64 as u64
    jeq r7, 0, lbb_23880                            if r7 == (0 as i32 as i64 as u64) { pc += 12 }
    mov64 r1, 49                                    r1 = 49 as i32 as i64 as u64
    ldxdw r2, [r10-0x358]                   
    stxb [r2+0x0], r1                       
    mov64 r3, 48                                    r3 = 48 as i32 as i64 as u64
    jeq r7, 1, lbb_23880                            if r7 == (1 as i32 as i64 as u64) { pc += 7 }
    ldxdw r1, [r10-0x358]                   
    add64 r1, 1                                     r1 += 1   ///  r1 = r1.wrapping_add(1 as i32 as i64 as u64)
    mov64 r3, r7                                    r3 = r7
    add64 r3, -1                                    r3 += -1   ///  r3 = r3.wrapping_add(-1 as i32 as i64 as u64)
    mov64 r2, 48                                    r2 = 48 as i32 as i64 as u64
    call function_30383                     
    mov64 r3, 48                                    r3 = 48 as i32 as i64 as u64
lbb_23880:
    mov64 r4, r8                                    r4 = r8
    add64 r4, 1                                     r4 += 1   ///  r4 = r4.wrapping_add(1 as i32 as i64 as u64)
    lsh64 r8, 48                                    r8 <<= 48   ///  r8 = r8.wrapping_shl(48)
    arsh64 r8, 48                                   r8 >>= 48 (signed)   ///  r8 = (r8 as i64).wrapping_shr(48)
    ldxdw r1, [r10-0x360]                   
    lsh64 r1, 48                                    r1 <<= 48   ///  r1 = r1.wrapping_shl(48)
    arsh64 r1, 48                                   r1 >>= 48 (signed)   ///  r1 = (r1 as i64).wrapping_shr(48)
    jsgt r1, r8, lbb_23858                          if (r1 as i64) > (r8 as i64) { pc += -30 }
    jge r7, r9, lbb_23858                           if r7 >= r9 { pc += -31 }
    stxb [r6+0x0], r3                       
    add64 r7, 1                                     r7 += 1   ///  r7 = r7.wrapping_add(1 as i32 as i64 as u64)
    jge r9, r7, lbb_23860                           if r9 >= r7 { pc += -32 }
lbb_23892:
    mov64 r1, r7                                    r1 = r7
    mov64 r2, r9                                    r2 = r9
    lddw r3, 0x100041ba8 --> b"\x00\x00\x00\x00\xb8\xf6\x03\x00/\x00\x00\x00\x00\x00\x00\x00\x83\x01\x00…        r3 load str located at 4295236520
    call function_28353                     
lbb_23897:
    mov64 r1, 40                                    r1 = 40 as i32 as i64 as u64
    mov64 r2, 40                                    r2 = 40 as i32 as i64 as u64
    lddw r3, 0x100042210 --> b"\x00\x00\x00\x00Y\x08\x04\x00\x1e\x00\x00\x00\x00\x00\x00\x00\xac\x01\x00…        r3 load str located at 4295238160
    call function_25832                     
lbb_23902:
    mov64 r1, r9                                    r1 = r9
    mov64 r2, r9                                    r2 = r9
    lddw r3, 0x100041bc0 --> b"\x00\x00\x00\x00\xb8\xf6\x03\x00/\x00\x00\x00\x00\x00\x00\x00e\x01\x00\x0…        r3 load str located at 4295236544
    call function_25832                     
lbb_23907:
    mov64 r2, r9                                    r2 = r9
    lddw r3, 0x100041b78 --> b"\x00\x00\x00\x00\xb8\xf6\x03\x00/\x00\x00\x00\x00\x00\x00\x00q\x01\x00\x0…        r3 load str located at 4295236472
    call function_25832                     
lbb_23911:
    lddw r1, 0x100040877 --> b"assertion failed: noborrow"        r1 load str located at 4295231607
    mov64 r2, 26                                    r2 = 26 as i32 as i64 as u64
    lddw r3, 0x100042210 --> b"\x00\x00\x00\x00Y\x08\x04\x00\x1e\x00\x00\x00\x00\x00\x00\x00\xac\x01\x00…        r3 load str located at 4295238160
    call function_25816                     

function_23917:
    stxdw [r10-0x50], r4                    
    stxdw [r10-0x58], r3                    
    ldxdw r8, [r2+0x0]                      
    jne r8, 0, lbb_23927                            if r8 != (0 as i32 as i64 as u64) { pc += 6 }
    lddw r1, 0x10003f6e7 --> b"assertion failed: d.mant > 0"        r1 load str located at 4295227111
    mov64 r2, 28                                    r2 = 28 as i32 as i64 as u64
    lddw r3, 0x100041c38 --> b"\x00\x00\x00\x00\xe8\xfc\x03\x00.\x00\x00\x00\x00\x00\x00\x00\xa9\x00\x00…        r3 load str located at 4295236664
    call function_25816                     
lbb_23927:
    ldxdw r3, [r2+0x8]                      
    jne r3, 0, lbb_23935                            if r3 != (0 as i32 as i64 as u64) { pc += 6 }
    lddw r1, 0x10003f703 --> b"assertion failed: d.minus > 0"        r1 load str located at 4295227139
    mov64 r2, 29                                    r2 = 29 as i32 as i64 as u64
    lddw r3, 0x100041c50 --> b"\x00\x00\x00\x00\xe8\xfc\x03\x00.\x00\x00\x00\x00\x00\x00\x00\xaa\x00\x00…        r3 load str located at 4295236688
    call function_25816                     
lbb_23935:
    ldxdw r4, [r2+0x10]                     
    jne r4, 0, lbb_23943                            if r4 != (0 as i32 as i64 as u64) { pc += 6 }
    lddw r1, 0x10003f720 --> b"assertion failed: d.plus > 0"        r1 load str located at 4295227168
    mov64 r2, 28                                    r2 = 28 as i32 as i64 as u64
    lddw r3, 0x100041c68 --> b"\x00\x00\x00\x00\xe8\xfc\x03\x00.\x00\x00\x00\x00\x00\x00\x00\xab\x00\x00…        r3 load str located at 4295236712
    call function_25816                     
lbb_23943:
    mov64 r0, r8                                    r0 = r8
    add64 r0, r4                                    r0 += r4   ///  r0 = r0.wrapping_add(r4)
    mov64 r5, 1                                     r5 = 1 as i32 as i64 as u64
    jgt r8, r0, lbb_23948                           if r8 > r0 { pc += 1 }
    mov64 r5, 0                                     r5 = 0 as i32 as i64 as u64
lbb_23948:
    and64 r5, 1                                     r5 &= 1   ///  r5 = r5.and(1)
    jne r5, 0, lbb_24034                            if r5 != (0 as i32 as i64 as u64) { pc += 84 }
    jgt r3, r8, lbb_24040                           if r3 > r8 { pc += 89 }
    ldxdw r5, [r10-0x50]                    
    jgt r5, 16, lbb_23954                           if r5 > (16 as i32 as i64 as u64) { pc += 1 }
    ja lbb_24046                                    if true { pc += 92 }
lbb_23954:
    add64 r4, r8                                    r4 += r8   ///  r4 = r4.wrapping_add(r8)
    lddw r5, 0x2000000000000000                     r5 load str located at 2305843009213693952
    jgt r5, r4, lbb_23964                           if r5 > r4 { pc += 6 }
    lddw r1, 0x10003fd16 --> b"assertion failed: d.mant + d.plus < (1 << 61)"        r1 load str located at 4295228694
    mov64 r2, 45                                    r2 = 45 as i32 as i64 as u64
    lddw r3, 0x100041c98 --> b"\x00\x00\x00\x00\xe8\xfc\x03\x00.\x00\x00\x00\x00\x00\x00\x00\xaf\x00\x00…        r3 load str located at 4295236760
    call function_25816                     
lbb_23964:
    ldxh r2, [r2+0x18]                      
    mov64 r5, r2                                    r5 = r2
    add64 r5, -32                                   r5 += -32   ///  r5 = r5.wrapping_add(-32 as i32 as i64 as u64)
    lddw r6, 0x100000000                            r6 load str located at 4294967296
    jgt r6, r4, lbb_23971                           if r6 > r4 { pc += 1 }
    mov64 r5, r2                                    r5 = r2
lbb_23971:
    mov64 r0, r4                                    r0 = r4
    lsh64 r0, 32                                    r0 <<= 32   ///  r0 = r0.wrapping_shl(32)
    jgt r6, r4, lbb_23975                           if r6 > r4 { pc += 1 }
    mov64 r0, r4                                    r0 = r4
lbb_23975:
    mov64 r4, r5                                    r4 = r5
    add64 r4, -16                                   r4 += -16   ///  r4 = r4.wrapping_add(-16 as i32 as i64 as u64)
    lddw r7, 0x1000000000000                        r7 load str located at 281474976710656
    jgt r7, r0, lbb_23981                           if r7 > r0 { pc += 1 }
    mov64 r4, r5                                    r4 = r5
lbb_23981:
    mov64 r6, r0                                    r6 = r0
    lsh64 r6, 16                                    r6 <<= 16   ///  r6 = r6.wrapping_shl(16)
    jgt r7, r0, lbb_23985                           if r7 > r0 { pc += 1 }
    mov64 r6, r0                                    r6 = r0
lbb_23985:
    mov64 r5, r4                                    r5 = r4
    add64 r5, -8                                    r5 += -8   ///  r5 = r5.wrapping_add(-8 as i32 as i64 as u64)
    lddw r0, 0x100000000000000                      r0 load str located at 72057594037927936
    jgt r0, r6, lbb_23991                           if r0 > r6 { pc += 1 }
    mov64 r5, r4                                    r5 = r4
lbb_23991:
    mov64 r4, r6                                    r4 = r6
    lsh64 r4, 8                                     r4 <<= 8   ///  r4 = r4.wrapping_shl(8)
    jgt r0, r6, lbb_23995                           if r0 > r6 { pc += 1 }
    mov64 r4, r6                                    r4 = r6
lbb_23995:
    lddw r6, 0x1000000000000000                     r6 load str located at 1152921504606846976
    mov64 r0, r5                                    r0 = r5
    add64 r0, -4                                    r0 += -4   ///  r0 = r0.wrapping_add(-4 as i32 as i64 as u64)
    jgt r6, r4, lbb_24001                           if r6 > r4 { pc += 1 }
    mov64 r0, r5                                    r0 = r5
lbb_24001:
    mov64 r5, r4                                    r5 = r4
    lsh64 r5, 4                                     r5 <<= 4   ///  r5 = r5.wrapping_shl(4)
    jgt r6, r4, lbb_24005                           if r6 > r4 { pc += 1 }
    mov64 r5, r4                                    r5 = r4
lbb_24005:
    lddw r4, 0x4000000000000000                     r4 load str located at 4611686018427387904
    mov64 r6, r0                                    r6 = r0
    add64 r6, -2                                    r6 += -2   ///  r6 = r6.wrapping_add(-2 as i32 as i64 as u64)
    jgt r4, r5, lbb_24011                           if r4 > r5 { pc += 1 }
    mov64 r6, r0                                    r6 = r0
lbb_24011:
    mov64 r0, r5                                    r0 = r5
    lsh64 r0, 2                                     r0 <<= 2   ///  r0 = r0.wrapping_shl(2)
    jgt r4, r5, lbb_24015                           if r4 > r5 { pc += 1 }
    mov64 r0, r5                                    r0 = r5
lbb_24015:
    mov64 r4, r8                                    r4 = r8
    sub64 r4, r3                                    r4 -= r3   ///  r4 = r4.wrapping_sub(r3)
    mov64 r7, 1                                     r7 = 1 as i32 as i64 as u64
    jsgt r0, -1, lbb_24020                          if (r0 as i64) > (-1 as i32 as i64) { pc += 1 }
    mov64 r7, 0                                     r7 = 0 as i32 as i64 as u64
lbb_24020:
    sub64 r6, r7                                    r6 -= r7   ///  r6 = r6.wrapping_sub(r7)
    stxdw [r10-0x48], r4                    
    stxh [r10-0x40], r2                     
    mov64 r3, r2                                    r3 = r2
    sub64 r3, r6                                    r3 -= r6   ///  r3 = r3.wrapping_sub(r6)
    lsh64 r3, 48                                    r3 <<= 48   ///  r3 = r3.wrapping_shl(48)
    arsh64 r3, 48                                   r3 >>= 48 (signed)   ///  r3 = (r3 as i64).wrapping_shr(48)
    jsgt r3, -1, lbb_24052                          if (r3 as i64) > (-1 as i32 as i64) { pc += 24 }
    lddw r1, 0x10003f579 --> b"assertion failed: edelta >= 0"        r1 load str located at 4295226745
    mov64 r2, 29                                    r2 = 29 as i32 as i64 as u64
    lddw r3, 0x100041a28 --> b"\x00\x00\x00\x00\x96\xf5\x03\x00!\x00\x00\x00\x00\x00\x00\x00L\x00\x00\x0…        r3 load str located at 4295236136
    call function_25816                     
lbb_24034:
    lddw r1, 0x10003f7a0 --> b"assertion failed: d.mant.checked_add(d.plus).is_some()"        r1 load str located at 4295227296
    mov64 r2, 54                                    r2 = 54 as i32 as i64 as u64
    lddw r3, 0x100041d10 --> b"\x00\x00\x00\x00\xe8\xfc\x03\x00.\x00\x00\x00\x00\x00\x00\x00\xac\x00\x00…        r3 load str located at 4295236880
    call function_25816                     
lbb_24040:
    lddw r1, 0x10003f769 --> b"assertion failed: d.mant.checked_sub(d.minus).is_some()"        r1 load str located at 4295227241
    mov64 r2, 55                                    r2 = 55 as i32 as i64 as u64
    lddw r3, 0x100041cf8 --> b"\x00\x00\x00\x00\xe8\xfc\x03\x00.\x00\x00\x00\x00\x00\x00\x00\xad\x00\x00…        r3 load str located at 4295236856
    call function_25816                     
lbb_24046:
    lddw r1, 0x10003f73c --> b"assertion failed: buf.len() >= MAX_SIG_DIGITS"        r1 load str located at 4295227196
    mov64 r2, 45                                    r2 = 45 as i32 as i64 as u64
    lddw r3, 0x100041c80 --> b"\x00\x00\x00\x00\xe8\xfc\x03\x00.\x00\x00\x00\x00\x00\x00\x00\xae\x00\x00…        r3 load str located at 4295236736
    call function_25816                     
lbb_24052:
    stxdw [r10-0xa0], r1                    
    and64 r3, 63                                    r3 &= 63   ///  r3 = r3.and(63)
    mov64 r9, r4                                    r9 = r4
    lsh64 r9, r3                                    r9 <<= r3   ///  r9 = r9.wrapping_shl(r3 as u32)
    mov64 r5, r9                                    r5 = r9
    rsh64 r5, r3                                    r5 >>= r3   ///  r5 = r5.wrapping_shr(r3 as u32)
    stxdw [r10-0x38], r5                    
    jeq r5, r4, lbb_24069                           if r5 == r4 { pc += 9 }
lbb_24060:
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    stxdw [r10-0x30], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -56                                   r1 += -56   ///  r1 = r1.wrapping_add(-56 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -72                                   r2 += -72   ///  r2 = r2.wrapping_add(-72 as i32 as i64 as u64)
    mov64 r3, r10                                   r3 = r10
    add64 r3, -48                                   r3 += -48   ///  r3 = r3.wrapping_add(-48 as i32 as i64 as u64)
    call function_25859                     
lbb_24069:
    stxdw [r10-0x78], r0                    
    stxh [r10-0x40], r2                     
    mov64 r2, r8                                    r2 = r8
    lsh64 r2, r3                                    r2 <<= r3   ///  r2 = r2.wrapping_shl(r3 as u32)
    stxdw [r10-0x80], r2                    
    rsh64 r2, r3                                    r2 >>= r3   ///  r2 = r2.wrapping_shr(r3 as u32)
    stxdw [r10-0x48], r8                    
    stxdw [r10-0x38], r2                    
    jeq r2, r8, lbb_24079                           if r2 == r8 { pc += 1 }
    ja lbb_24060                                    if true { pc += -19 }
lbb_24079:
    mov64 r1, -96                                   r1 = -96 as i32 as i64 as u64
    sub64 r1, r6                                    r1 -= r6   ///  r1 = r1.wrapping_sub(r6)
    lsh64 r1, 48                                    r1 <<= 48   ///  r1 = r1.wrapping_shl(48)
    arsh64 r1, 48                                   r1 >>= 48 (signed)   ///  r1 = (r1 as i64).wrapping_shr(48)
    mul64 r1, 80                                    r1 *= 80   ///  r1 = r1.wrapping_mul(80 as u64)
    add64 r1, 86960                                 r1 += 86960   ///  r1 = r1.wrapping_add(86960 as i32 as i64 as u64)
    mov64 r2, 2126                                  r2 = 2126 as i32 as i64 as u64
    call function_31662                     
    lsh64 r0, 32                                    r0 <<= 32   ///  r0 = r0.wrapping_shl(32)
    mov64 r1, r0                                    r1 = r0
    arsh64 r1, 32                                   r1 >>= 32 (signed)   ///  r1 = (r1 as i64).wrapping_shr(32)
    rsh64 r0, 32                                    r0 >>= 32   ///  r0 = r0.wrapping_shr(32)
    mov64 r2, 81                                    r2 = 81 as i32 as i64 as u64
    jgt r2, r0, lbb_24096                           if r2 > r0 { pc += 3 }
    lddw r3, 0x100041c20 --> b"\x00\x00\x00\x00\xe8\xfc\x03\x00.\x00\x00\x00\x00\x00\x00\x00}\x00\x00\x0…        r3 load str located at 4295236640
    call function_25832                     
lbb_24096:
    ldxdw r2, [r10-0x78]                    
    lsh64 r2, r7                                    r2 <<= r7   ///  r2 = r2.wrapping_shl(r7 as u32)
    stxdw [r10-0x78], r2                    
    lsh64 r1, 4                                     r1 <<= 4   ///  r1 = r1.wrapping_shl(4)
    lddw r2, 0x10003f7d8 --> b"\xdfE\x1a=\x03\xcf\x1a\xe6\xc1\xfb\xcc\xfe\x00\x00\x00\x00\xca\xc6\x9a\xc…        r2 load str located at 4295227352
    add64 r2, r1                                    r2 += r1   ///  r2 = r2.wrapping_add(r1)
    ldxdw r3, [r2+0x0]                      
    mov64 r0, r2                                    r0 = r2
    stxdw [r10-0x70], r0                    
    mov64 r5, r3                                    r5 = r3
    lsh64 r5, 32                                    r5 <<= 32   ///  r5 = r5.wrapping_shl(32)
    rsh64 r5, 32                                    r5 >>= 32   ///  r5 = r5.wrapping_shr(32)
    mov64 r1, r9                                    r1 = r9
    lsh64 r1, 32                                    r1 <<= 32   ///  r1 = r1.wrapping_shl(32)
    rsh64 r1, 32                                    r1 >>= 32   ///  r1 = r1.wrapping_shr(32)
    mov64 r2, r5                                    r2 = r5
    mul64 r2, r1                                    r2 *= r1   ///  r2 = r2.wrapping_mul(r1)
    rsh64 r2, 32                                    r2 >>= 32   ///  r2 = r2.wrapping_shr(32)
    rsh64 r9, 32                                    r9 >>= 32   ///  r9 = r9.wrapping_shr(32)
    stxdw [r10-0x60], r9                    
    mov64 r4, r5                                    r4 = r5
    mul64 r4, r9                                    r4 *= r9   ///  r4 = r4.wrapping_mul(r9)
    stxdw [r10-0x90], r4                    
    stxdw [r10-0x68], r6                    
    mov64 r9, r4                                    r9 = r4
    lsh64 r9, 32                                    r9 <<= 32   ///  r9 = r9.wrapping_shl(32)
    rsh64 r9, 32                                    r9 >>= 32   ///  r9 = r9.wrapping_shr(32)
    add64 r9, r2                                    r9 += r2   ///  r9 = r9.wrapping_add(r2)
    ldxdw r6, [r10-0x80]                    
    mov64 r2, r6                                    r2 = r6
    lsh64 r2, 32                                    r2 <<= 32   ///  r2 = r2.wrapping_shl(32)
    rsh64 r2, 32                                    r2 >>= 32   ///  r2 = r2.wrapping_shr(32)
    mov64 r4, r5                                    r4 = r5
    mul64 r4, r2                                    r4 *= r2   ///  r4 = r4.wrapping_mul(r2)
    rsh64 r4, 32                                    r4 >>= 32   ///  r4 = r4.wrapping_shr(32)
    rsh64 r6, 32                                    r6 >>= 32   ///  r6 = r6.wrapping_shr(32)
    stxdw [r10-0x80], r6                    
    mov64 r8, r5                                    r8 = r5
    mul64 r8, r6                                    r8 *= r6   ///  r8 = r8.wrapping_mul(r6)
    mov64 r7, r8                                    r7 = r8
    lsh64 r7, 32                                    r7 <<= 32   ///  r7 = r7.wrapping_shl(32)
    rsh64 r7, 32                                    r7 >>= 32   ///  r7 = r7.wrapping_shr(32)
    add64 r7, r4                                    r7 += r4   ///  r7 = r7.wrapping_add(r4)
    rsh64 r3, 32                                    r3 >>= 32   ///  r3 = r3.wrapping_shr(32)
    mov64 r6, r3                                    r6 = r3
    mul64 r6, r2                                    r6 *= r2   ///  r6 = r6.wrapping_mul(r2)
    mov64 r2, r6                                    r2 = r6
    lsh64 r2, 32                                    r2 <<= 32   ///  r2 = r2.wrapping_shl(32)
    rsh64 r2, 32                                    r2 >>= 32   ///  r2 = r2.wrapping_shr(32)
    add64 r7, r2                                    r7 += r2   ///  r7 = r7.wrapping_add(r2)
    mov64 r2, r3                                    r2 = r3
    mul64 r2, r1                                    r2 *= r1   ///  r2 = r2.wrapping_mul(r1)
    stxdw [r10-0x98], r2                    
    mov64 r1, r2                                    r1 = r2
    lsh64 r1, 32                                    r1 <<= 32   ///  r1 = r1.wrapping_shl(32)
    rsh64 r1, 32                                    r1 >>= 32   ///  r1 = r1.wrapping_shr(32)
    add64 r9, r1                                    r9 += r1   ///  r9 = r9.wrapping_add(r1)
    ldxh r1, [r0+0x8]                       
    ldxdw r2, [r10-0x68]                    
    add64 r2, r1                                    r2 += r1   ///  r2 = r2.wrapping_add(r1)
    stxdw [r10-0x68], r2                    
    ldxdw r1, [r10-0x78]                    
    lsh64 r1, 32                                    r1 <<= 32   ///  r1 = r1.wrapping_shl(32)
    rsh64 r1, 32                                    r1 >>= 32   ///  r1 = r1.wrapping_shr(32)
    mov64 r0, r3                                    r0 = r3
    mul64 r0, r1                                    r0 *= r1   ///  r0 = r0.wrapping_mul(r1)
    mov64 r4, r0                                    r4 = r0
    lsh64 r4, 32                                    r4 <<= 32   ///  r4 = r4.wrapping_shl(32)
    rsh64 r4, 32                                    r4 >>= 32   ///  r4 = r4.wrapping_shr(32)
    mov64 r2, r5                                    r2 = r5
    mul64 r2, r1                                    r2 *= r1   ///  r2 = r2.wrapping_mul(r1)
    rsh64 r2, 32                                    r2 >>= 32   ///  r2 = r2.wrapping_shr(32)
    ldxdw r1, [r10-0x78]                    
    rsh64 r1, 32                                    r1 >>= 32   ///  r1 = r1.wrapping_shr(32)
    stxdw [r10-0x78], r1                    
    mul64 r5, r1                                    r5 *= r1   ///  r5 = r5.wrapping_mul(r1)
    mov64 r1, r5                                    r1 = r5
    lsh64 r1, 32                                    r1 <<= 32   ///  r1 = r1.wrapping_shl(32)
    rsh64 r1, 32                                    r1 >>= 32   ///  r1 = r1.wrapping_shr(32)
    stxdw [r10-0xf8], r1                    
    stxdw [r10-0xd8], r2                    
    add64 r1, r2                                    r1 += r2   ///  r1 = r1.wrapping_add(r2)
    stxdw [r10-0xe0], r4                    
    add64 r1, r4                                    r1 += r4   ///  r1 = r1.wrapping_add(r4)
    lddw r2, 0x80000000                             r2 load str located at 2147483648
    add64 r1, r2                                    r1 += r2   ///  r1 = r1.wrapping_add(r2)
    add64 r9, r2                                    r9 += r2   ///  r9 = r9.wrapping_add(r2)
    add64 r7, r2                                    r7 += r2   ///  r7 = r7.wrapping_add(r2)
    rsh64 r0, 32                                    r0 >>= 32   ///  r0 = r0.wrapping_shr(32)
    rsh64 r5, 32                                    r5 >>= 32   ///  r5 = r5.wrapping_shr(32)
    mov64 r2, r3                                    r2 = r3
    ldxdw r4, [r10-0x78]                    
    mul64 r2, r4                                    r2 *= r4   ///  r2 = r2.wrapping_mul(r4)
    stxdw [r10-0xf0], r2                    
    stxdw [r10-0xd0], r5                    
    add64 r2, r5                                    r2 += r5   ///  r2 = r2.wrapping_add(r5)
    stxdw [r10-0xe8], r0                    
    add64 r2, r0                                    r2 += r0   ///  r2 = r2.wrapping_add(r0)
    rsh64 r1, 32                                    r1 >>= 32   ///  r1 = r1.wrapping_shr(32)
    add64 r2, r1                                    r2 += r1   ///  r2 = r2.wrapping_add(r1)
    ldxdw r1, [r10-0x70]                    
    ldxh r5, [r1+0xa]                       
    mov64 r1, r3                                    r1 = r3
    ldxdw r4, [r10-0x60]                    
    mul64 r1, r4                                    r1 *= r4   ///  r1 = r1.wrapping_mul(r4)
    stxdw [r10-0xb8], r1                    
    stxdw [r10-0x100], r3                   
    mov64 r1, r3                                    r1 = r3
    ldxdw r3, [r10-0x80]                    
    mul64 r1, r3                                    r1 *= r3   ///  r1 = r1.wrapping_mul(r3)
    rsh64 r8, 32                                    r8 >>= 32   ///  r8 = r8.wrapping_shr(32)
    stxdw [r10-0x88], r8                    
    mov64 r3, r8                                    r3 = r8
    stxdw [r10-0x110], r1                   
    add64 r3, r1                                    r3 += r1   ///  r3 = r3.wrapping_add(r1)
    rsh64 r6, 32                                    r6 >>= 32   ///  r6 = r6.wrapping_shr(32)
    stxdw [r10-0x108], r6                   
    add64 r3, r6                                    r3 += r6   ///  r3 = r3.wrapping_add(r6)
    ldxdw r1, [r10-0x98]                    
    rsh64 r1, 32                                    r1 >>= 32   ///  r1 = r1.wrapping_shr(32)
    stxdw [r10-0x98], r1                    
    ldxdw r1, [r10-0x90]                    
    rsh64 r1, 32                                    r1 >>= 32   ///  r1 = r1.wrapping_shr(32)
    stxdw [r10-0x90], r1                    
    rsh64 r7, 32                                    r7 >>= 32   ///  r7 = r7.wrapping_shr(32)
    stxdw [r10-0xb0], r7                    
    rsh64 r9, 32                                    r9 >>= 32   ///  r9 = r9.wrapping_shr(32)
    stxdw [r10-0xa8], r9                    
    ldxdw r0, [r10-0x68]                    
    neg64 r0                                        r0 = -r0   ///  r0 = (r0 as i64).wrapping_neg() as u64
    and64 r0, 63                                    r0 &= 63   ///  r0 = r0.and(63)
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    lsh64 r1, r0                                    r1 <<= r0   ///  r1 = r1.wrapping_shl(r0 as u32)
    stxdw [r10-0x60], r1                    
    add64 r2, 1                                     r2 += 1   ///  r2 = r2.wrapping_add(1 as i32 as i64 as u64)
    mov64 r8, r1                                    r8 = r1
    add64 r8, -1                                    r8 += -1   ///  r8 = r8.wrapping_add(-1 as i32 as i64 as u64)
    stxdw [r10-0x70], r2                    
    mov64 r6, r2                                    r6 = r2
    rsh64 r6, r0                                    r6 >>= r0   ///  r6 = r6.wrapping_shr(r0 as u32)
    mov64 r1, r6                                    r1 = r6
    lsh64 r1, 32                                    r1 <<= 32   ///  r1 = r1.wrapping_shl(32)
    rsh64 r1, 32                                    r1 >>= 32   ///  r1 = r1.wrapping_shr(32)
    mov64 r2, 10000                                 r2 = 10000 as i32 as i64 as u64
    stxdw [r10-0x68], r0                    
    stxdw [r10-0xc8], r5                    
    jgt r2, r1, lbb_24261                           if r2 > r1 { pc += 16 }
    mov64 r2, 1000000                               r2 = 1000000 as i32 as i64 as u64
    ldxdw r4, [r10-0xa0]                    
    jgt r2, r1, lbb_24249                           if r2 > r1 { pc += 1 }
    ja lbb_24276                                    if true { pc += 27 }
lbb_24249:
    mov64 r1, r6                                    r1 = r6
    lsh64 r1, 32                                    r1 <<= 32   ///  r1 = r1.wrapping_shl(32)
    rsh64 r1, 32                                    r1 >>= 32   ///  r1 = r1.wrapping_shr(32)
    mov64 r5, 4                                     r5 = 4 as i32 as i64 as u64
    mov64 r2, 100000                                r2 = 100000 as i32 as i64 as u64
    jgt r2, r1, lbb_24256                           if r2 > r1 { pc += 1 }
    mov64 r5, 5                                     r5 = 5 as i32 as i64 as u64
lbb_24256:
    ldxdw r7, [r10-0x78]                    
    mov64 r7, 10000                                 r7 = 10000 as i32 as i64 as u64
    jgt r2, r1, lbb_24311                           if r2 > r1 { pc += 52 }
    mov64 r7, 100000                                r7 = 100000 as i32 as i64 as u64
    ja lbb_24311                                    if true { pc += 50 }
lbb_24261:
    mov64 r2, 100                                   r2 = 100 as i32 as i64 as u64
    ldxdw r4, [r10-0xa0]                    
    jgt r2, r1, lbb_24265                           if r2 > r1 { pc += 1 }
    ja lbb_24291                                    if true { pc += 26 }
lbb_24265:
    mov64 r1, r6                                    r1 = r6
    lsh64 r1, 32                                    r1 <<= 32   ///  r1 = r1.wrapping_shl(32)
    rsh64 r1, 32                                    r1 >>= 32   ///  r1 = r1.wrapping_shr(32)
    mov64 r5, 1                                     r5 = 1 as i32 as i64 as u64
    jgt r1, 9, lbb_24271                            if r1 > (9 as i32 as i64 as u64) { pc += 1 }
    mov64 r5, 0                                     r5 = 0 as i32 as i64 as u64
lbb_24271:
    ldxdw r2, [r10-0x78]                    
    mov64 r7, 10                                    r7 = 10 as i32 as i64 as u64
    jgt r1, 9, lbb_24311                            if r1 > (9 as i32 as i64 as u64) { pc += 37 }
    mov64 r7, 1                                     r7 = 1 as i32 as i64 as u64
    ja lbb_24311                                    if true { pc += 35 }
lbb_24276:
    mov64 r1, r6                                    r1 = r6
    lsh64 r1, 32                                    r1 <<= 32   ///  r1 = r1.wrapping_shl(32)
    rsh64 r1, 32                                    r1 >>= 32   ///  r1 = r1.wrapping_shr(32)
    mov64 r2, 100000000                             r2 = 100000000 as i32 as i64 as u64
    jgt r2, r1, lbb_24282                           if r2 > r1 { pc += 1 }
    ja lbb_24303                                    if true { pc += 21 }
lbb_24282:
    mov64 r5, 6                                     r5 = 6 as i32 as i64 as u64
    mov64 r2, 10000000                              r2 = 10000000 as i32 as i64 as u64
    jgt r2, r1, lbb_24286                           if r2 > r1 { pc += 1 }
    mov64 r5, 7                                     r5 = 7 as i32 as i64 as u64
lbb_24286:
    ldxdw r7, [r10-0x78]                    
    mov64 r7, 1000000                               r7 = 1000000 as i32 as i64 as u64
    jgt r2, r1, lbb_24311                           if r2 > r1 { pc += 22 }
    mov64 r7, 10000000                              r7 = 10000000 as i32 as i64 as u64
    ja lbb_24311                                    if true { pc += 20 }
lbb_24291:
    mov64 r1, r6                                    r1 = r6
    lsh64 r1, 32                                    r1 <<= 32   ///  r1 = r1.wrapping_shl(32)
    rsh64 r1, 32                                    r1 >>= 32   ///  r1 = r1.wrapping_shr(32)
    mov64 r5, 2                                     r5 = 2 as i32 as i64 as u64
    mov64 r2, 1000                                  r2 = 1000 as i32 as i64 as u64
    jgt r2, r1, lbb_24298                           if r2 > r1 { pc += 1 }
    mov64 r5, 3                                     r5 = 3 as i32 as i64 as u64
lbb_24298:
    ldxdw r7, [r10-0x78]                    
    mov64 r7, 100                                   r7 = 100 as i32 as i64 as u64
    jgt r2, r1, lbb_24311                           if r2 > r1 { pc += 10 }
    mov64 r7, 1000                                  r7 = 1000 as i32 as i64 as u64
    ja lbb_24311                                    if true { pc += 8 }
lbb_24303:
    mov64 r5, 8                                     r5 = 8 as i32 as i64 as u64
    mov64 r2, 1000000000                            r2 = 1000000000 as i32 as i64 as u64
    jgt r2, r1, lbb_24307                           if r2 > r1 { pc += 1 }
    mov64 r5, 9                                     r5 = 9 as i32 as i64 as u64
lbb_24307:
    ldxdw r7, [r10-0x78]                    
    mov64 r7, 100000000                             r7 = 100000000 as i32 as i64 as u64
    jgt r2, r1, lbb_24311                           if r2 > r1 { pc += 1 }
    mov64 r7, 1000000000                            r7 = 1000000000 as i32 as i64 as u64
lbb_24311:
    ldxdw r1, [r10-0xb0]                    
    add64 r3, r1                                    r3 += r1   ///  r3 = r3.wrapping_add(r1)
    stxdw [r10-0xc0], r3                    
    ldxdw r9, [r10-0x70]                    
    mov64 r4, r9                                    r4 = r9
    and64 r4, r8                                    r4 &= r8   ///  r4 = r4.and(r8)
    ldxdw r1, [r10-0xb8]                    
    ldxdw r3, [r10-0x90]                    
    add64 r1, r3                                    r1 += r3   ///  r1 = r1.wrapping_add(r3)
    ldxdw r3, [r10-0x98]                    
    add64 r1, r3                                    r1 += r3   ///  r1 = r1.wrapping_add(r3)
    ldxdw r3, [r10-0xa8]                    
    add64 r1, r3                                    r1 += r3   ///  r1 = r1.wrapping_add(r3)
    sub64 r9, r1                                    r9 -= r1   ///  r9 = r9.wrapping_sub(r1)
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    and64 r5, 255                                   r5 &= 255   ///  r5 = r5.and(255)
    mov64 r0, r5                                    r0 = r5
    ldxdw r3, [r10-0xc8]                    
    sub64 r5, r3                                    r5 -= r3   ///  r5 = r5.wrapping_sub(r3)
    add64 r5, 1                                     r5 += 1   ///  r5 = r5.wrapping_add(1 as i32 as i64 as u64)
    stxdw [r10-0x120], r5                   
    stxdw [r10-0x118], r9                   
    add64 r9, 1                                     r9 += 1   ///  r9 = r9.wrapping_add(1 as i32 as i64 as u64)
    mov64 r3, r9                                    r3 = r9
    stxdw [r10-0xc8], r8                    
    and64 r3, r8                                    r3 &= r8   ///  r3 = r3.and(r8)
    ja lbb_24346                                    if true { pc += 8 }
lbb_24338:
    add64 r1, 1                                     r1 += 1   ///  r1 = r1.wrapping_add(1 as i32 as i64 as u64)
    lsh64 r7, 32                                    r7 <<= 32   ///  r7 = r7.wrapping_shl(32)
    mov64 r2, r7                                    r2 = r7
    rsh64 r2, 32                                    r2 >>= 32   ///  r2 = r2.wrapping_shr(32)
    mov64 r7, r2                                    r7 = r2
    div64 r7, 10                                    r7 /= 10   ///  r7 = r7 / (10 as u64)
    mov64 r5, 10                                    r5 = 10 as i32 as i64 as u64
    jgt r5, r2, lbb_24666                           if r5 > r2 { pc += 320 }
lbb_24346:
    ldxdw r2, [r10-0x50]                    
    jeq r2, r1, lbb_24657                           if r2 == r1 { pc += 309 }
    mov64 r2, r7                                    r2 = r7
    lsh64 r2, 32                                    r2 <<= 32   ///  r2 = r2.wrapping_shl(32)
    rsh64 r2, 32                                    r2 >>= 32   ///  r2 = r2.wrapping_shr(32)
    mov64 r5, r6                                    r5 = r6
    lsh64 r5, 32                                    r5 <<= 32   ///  r5 = r5.wrapping_shl(32)
    rsh64 r5, 32                                    r5 >>= 32   ///  r5 = r5.wrapping_shr(32)
    div64 r5, r2                                    r5 /= r2   ///  r5 = r5 / r2
    mov64 r2, r5                                    r2 = r5
    mul64 r2, r7                                    r2 *= r7   ///  r2 = r2.wrapping_mul(r7)
    sub64 r6, r2                                    r6 -= r2   ///  r6 = r6.wrapping_sub(r2)
    ldxdw r2, [r10-0x58]                    
    add64 r2, r1                                    r2 += r1   ///  r2 = r2.wrapping_add(r1)
    add64 r5, 48                                    r5 += 48   ///  r5 = r5.wrapping_add(48 as i32 as i64 as u64)
    stxb [r2+0x0], r5                       
    mov64 r8, r6                                    r8 = r6
    lsh64 r8, 32                                    r8 <<= 32   ///  r8 = r8.wrapping_shl(32)
    rsh64 r8, 32                                    r8 >>= 32   ///  r8 = r8.wrapping_shr(32)
    ldxdw r2, [r10-0x68]                    
    lsh64 r8, r2                                    r8 <<= r2   ///  r8 = r8.wrapping_shl(r2 as u32)
    mov64 r2, r8                                    r2 = r8
    add64 r2, r4                                    r2 += r4   ///  r2 = r2.wrapping_add(r4)
    jgt r9, r2, lbb_24482                           if r9 > r2 { pc += 112 }
    jne r0, r1, lbb_24338                           if r0 != r1 { pc += -33 }
    mov64 r2, 1                                     r2 = 1 as i32 as i64 as u64
    add64 r1, 1                                     r1 += 1   ///  r1 = r1.wrapping_add(1 as i32 as i64 as u64)
    ldxdw r0, [r10-0x68]                    
    ldxdw r5, [r10-0x60]                    
    ldxdw r7, [r10-0xc8]                    
lbb_24376:
    mov64 r9, r2                                    r9 = r2
    mov64 r8, r3                                    r8 = r3
    ldxdw r2, [r10-0x50]                    
    jge r1, r2, lbb_24662                           if r1 >= r2 { pc += 282 }
    ldxdw r2, [r10-0x58]                    
    add64 r2, r1                                    r2 += r1   ///  r2 = r2.wrapping_add(r1)
    mul64 r4, 10                                    r4 *= 10   ///  r4 = r4.wrapping_mul(10 as u64)
    mov64 r6, r4                                    r6 = r4
    rsh64 r6, r0                                    r6 >>= r0   ///  r6 = r6.wrapping_shr(r0 as u32)
    add64 r6, 48                                    r6 += 48   ///  r6 = r6.wrapping_add(48 as i32 as i64 as u64)
    stxb [r2+0x0], r6                       
    and64 r4, r7                                    r4 &= r7   ///  r4 = r4.and(r7)
    add64 r1, 1                                     r1 += 1   ///  r1 = r1.wrapping_add(1 as i32 as i64 as u64)
    mov64 r2, r9                                    r2 = r9
    mul64 r2, 10                                    r2 *= 10   ///  r2 = r2.wrapping_mul(10 as u64)
    mov64 r3, r8                                    r3 = r8
    mul64 r3, 10                                    r3 *= 10   ///  r3 = r3.wrapping_mul(10 as u64)
    jgt r3, r4, lbb_24395                           if r3 > r4 { pc += 1 }
    ja lbb_24376                                    if true { pc += -19 }
lbb_24395:
    stxdw [r10-0x80], r9                    
    mov64 r0, r3                                    r0 = r3
    sub64 r0, r4                                    r0 -= r4   ///  r0 = r0.wrapping_sub(r4)
    mov64 r5, 1                                     r5 = 1 as i32 as i64 as u64
    ldxdw r7, [r10-0x60]                    
    jgt r7, r0, lbb_24402                           if r7 > r0 { pc += 1 }
    mov64 r5, 0                                     r5 = 0 as i32 as i64 as u64
lbb_24402:
    ldxdw r7, [r10-0x70]                    
    ldxdw r9, [r10-0xc0]                    
    sub64 r7, r9                                    r7 -= r9   ///  r7 = r7.wrapping_sub(r9)
    mov64 r9, r2                                    r9 = r2
    mul64 r9, r7                                    r9 *= r7   ///  r9 = r9.wrapping_mul(r7)
    stxdw [r10-0x50], r9                    
    mov64 r7, r9                                    r7 = r9
    add64 r7, r2                                    r7 += r2   ///  r7 = r7.wrapping_add(r2)
    stxdw [r10-0x88], r7                    
    ldxdw r7, [r10-0x60]                    
    jgt r7, r0, lbb_24590                           if r7 > r0 { pc += 177 }
    ldxdw r0, [r10-0x50]                    
    sub64 r0, r2                                    r0 -= r2   ///  r0 = r0.wrapping_sub(r2)
    stxdw [r10-0x50], r0                    
    jge r4, r0, lbb_24590                           if r4 >= r0 { pc += 173 }
    ldxdw r2, [r10-0x58]                    
    add64 r2, r1                                    r2 += r1   ///  r2 = r2.wrapping_add(r1)
    stxdw [r10-0x68], r2                    
    ldxdw r0, [r10-0xd0]                    
    ldxdw r2, [r10-0xe8]                    
    add64 r0, r2                                    r0 += r2   ///  r0 = r0.wrapping_add(r2)
    ldxdw r7, [r10-0xd8]                    
    ldxdw r2, [r10-0xf8]                    
    add64 r7, r2                                    r7 += r2   ///  r7 = r7.wrapping_add(r2)
    ldxdw r2, [r10-0xe0]                    
    add64 r7, r2                                    r7 += r2   ///  r7 = r7.wrapping_add(r2)
    lddw r2, 0x80000000                             r2 load str located at 2147483648
    add64 r7, r2                                    r7 += r2   ///  r7 = r7.wrapping_add(r2)
    rsh64 r7, 32                                    r7 >>= 32   ///  r7 = r7.wrapping_shr(32)
    add64 r0, r7                                    r0 += r7   ///  r0 = r0.wrapping_add(r7)
    ldxdw r2, [r10-0xf0]                    
    add64 r0, r2                                    r0 += r2   ///  r0 = r0.wrapping_add(r2)
    mul64 r0, 10                                    r0 *= 10   ///  r0 = r0.wrapping_mul(10 as u64)
    ldxdw r7, [r10-0xc0]                    
    mul64 r7, 10                                    r7 *= 10   ///  r7 = r7.wrapping_mul(10 as u64)
    sub64 r7, r0                                    r7 -= r0   ///  r7 = r7.wrapping_sub(r0)
    ldxdw r2, [r10-0x50]                    
    sub64 r2, r4                                    r2 -= r4   ///  r2 = r2.wrapping_sub(r4)
    stxdw [r10-0x70], r2                    
    ldxdw r5, [r10-0x60]                    
    mov64 r2, r5                                    r2 = r5
    add64 r2, r4                                    r2 += r4   ///  r2 = r2.wrapping_add(r4)
    mul64 r8, 10                                    r8 *= 10   ///  r8 = r8.wrapping_mul(10 as u64)
    sub64 r8, r2                                    r8 -= r2   ///  r8 = r8.wrapping_sub(r2)
    ldxdw r2, [r10-0x80]                    
    mul64 r7, r2                                    r7 *= r2   ///  r7 = r7.wrapping_mul(r2)
    add64 r5, r7                                    r5 += r7   ///  r5 = r5.wrapping_add(r7)
    stxdw [r10-0x78], r5                    
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
    mov64 r9, r4                                    r9 = r4
    ja lbb_24462                                    if true { pc += 8 }
lbb_24454:
    mov64 r4, r9                                    r4 = r9
    ldxdw r7, [r10-0x60]                    
    ldxdw r7, [r10-0x50]                    
    jge r9, r7, lbb_24590                           if r9 >= r7 { pc += 132 }
    ldxdw r7, [r10-0x60]                    
    sub64 r2, r7                                    r2 -= r7   ///  r2 = r2.wrapping_sub(r7)
    mov64 r4, r9                                    r4 = r9
    jgt r7, r0, lbb_24590                           if r7 > r0 { pc += 128 }
lbb_24462:
    ldxdw r5, [r10-0x60]                    
    add64 r9, r5                                    r9 += r5   ///  r9 = r9.wrapping_add(r5)
    ldxdw r0, [r10-0x50]                    
    jgt r0, r9, lbb_24472                           if r0 > r9 { pc += 6 }
    ldxdw r0, [r10-0x70]                    
    add64 r0, r2                                    r0 += r2   ///  r0 = r0.wrapping_add(r2)
    ldxdw r7, [r10-0x78]                    
    add64 r7, r4                                    r7 += r4   ///  r7 = r7.wrapping_add(r4)
    mov64 r5, 0                                     r5 = 0 as i32 as i64 as u64
    jgt r7, r0, lbb_24590                           if r7 > r0 { pc += 118 }
lbb_24472:
    add64 r6, -1                                    r6 += -1   ///  r6 = r6.wrapping_add(-1 as i32 as i64 as u64)
    ldxdw r4, [r10-0x68]                    
    stxb [r4-0x1], r6                       
    mov64 r0, r8                                    r0 = r8
    add64 r0, r2                                    r0 += r2   ///  r0 = r0.wrapping_add(r2)
    mov64 r5, 1                                     r5 = 1 as i32 as i64 as u64
    ldxdw r4, [r10-0x60]                    
    jgt r4, r0, lbb_24454                           if r4 > r0 { pc += -26 }
    mov64 r5, 0                                     r5 = 0 as i32 as i64 as u64
    ja lbb_24454                                    if true { pc += -28 }
lbb_24482:
    lsh64 r7, 32                                    r7 <<= 32   ///  r7 = r7.wrapping_shl(32)
    rsh64 r7, 32                                    r7 >>= 32   ///  r7 = r7.wrapping_shr(32)
    ldxdw r3, [r10-0x68]                    
    lsh64 r7, r3                                    r7 <<= r3   ///  r7 = r7.wrapping_shl(r3 as u32)
    sub64 r9, r2                                    r9 -= r2   ///  r9 = r9.wrapping_sub(r2)
    mov64 r6, 1                                     r6 = 1 as i32 as i64 as u64
    jgt r7, r9, lbb_24490                           if r7 > r9 { pc += 1 }
    mov64 r6, 0                                     r6 = 0 as i32 as i64 as u64
lbb_24490:
    ldxdw r3, [r10-0x70]                    
    ldxdw r0, [r10-0xc0]                    
    sub64 r3, r0                                    r3 -= r0   ///  r3 = r3.wrapping_sub(r0)
    mov64 r0, r3                                    r0 = r3
    add64 r0, 1                                     r0 += 1   ///  r0 = r0.wrapping_add(1 as i32 as i64 as u64)
    add64 r3, -1                                    r3 += -1   ///  r3 = r3.wrapping_add(-1 as i32 as i64 as u64)
    stxdw [r10-0x70], r3                    
    jge r2, r3, lbb_24622                           if r2 >= r3 { pc += 124 }
    jgt r7, r9, lbb_24622                           if r7 > r9 { pc += 123 }
    stxdw [r10-0xc0], r0                    
    ldxdw r2, [r10-0x58]                    
    add64 r2, r1                                    r2 += r1   ///  r2 = r2.wrapping_add(r1)
    stxdw [r10-0x68], r2                    
    ldxdw r2, [r10-0x78]                    
    ldxdw r3, [r10-0x80]                    
    sub64 r3, r2                                    r3 -= r2   ///  r3 = r3.wrapping_sub(r2)
    ldxdw r0, [r10-0x90]                    
    ldxdw r2, [r10-0x98]                    
    add64 r0, r2                                    r0 += r2   ///  r0 = r0.wrapping_add(r2)
    ldxdw r2, [r10-0xa8]                    
    add64 r0, r2                                    r0 += r2   ///  r0 = r0.wrapping_add(r2)
    ldxdw r2, [r10-0x100]                   
    mul64 r2, r3                                    r2 *= r3   ///  r2 = r2.wrapping_mul(r3)
    ldxdw r3, [r10-0x88]                    
    ldxdw r6, [r10-0x108]                   
    add64 r3, r6                                    r3 += r6   ///  r3 = r3.wrapping_add(r6)
    ldxdw r6, [r10-0xb0]                    
    add64 r3, r6                                    r3 += r6   ///  r3 = r3.wrapping_add(r6)
    stxdw [r10-0x88], r3                    
    mov64 r6, r4                                    r6 = r4
    add64 r6, r7                                    r6 += r7   ///  r6 = r6.wrapping_add(r7)
    add64 r3, r6                                    r3 += r6   ///  r3 = r3.wrapping_add(r6)
    add64 r3, r2                                    r3 += r2   ///  r3 = r3.wrapping_add(r2)
    ldxdw r2, [r10-0xb8]                    
    add64 r0, r2                                    r0 += r2   ///  r0 = r0.wrapping_add(r2)
    mov64 r2, r6                                    r2 = r6
    add64 r2, r8                                    r2 += r8   ///  r2 = r2.wrapping_add(r8)
    add64 r0, r2                                    r0 += r2   ///  r0 = r0.wrapping_add(r2)
    mov64 r2, 2                                     r2 = 2 as i32 as i64 as u64
    sub64 r2, r0                                    r2 -= r0   ///  r2 = r2.wrapping_sub(r0)
    stxdw [r10-0x78], r2                    
    ldxdw r9, [r10-0xd0]                    
    sub64 r3, r9                                    r3 -= r9   ///  r3 = r3.wrapping_sub(r9)
    ldxdw r2, [r10-0xe8]                    
    sub64 r3, r2                                    r3 -= r2   ///  r3 = r3.wrapping_sub(r2)
    add64 r9, r2                                    r9 += r2   ///  r9 = r9.wrapping_add(r2)
    ldxdw r0, [r10-0xd8]                    
    ldxdw r2, [r10-0xf8]                    
    add64 r0, r2                                    r0 += r2   ///  r0 = r0.wrapping_add(r2)
    ldxdw r2, [r10-0xe0]                    
    add64 r0, r2                                    r0 += r2   ///  r0 = r0.wrapping_add(r2)
    lddw r2, 0x80000000                             r2 load str located at 2147483648
    add64 r0, r2                                    r0 += r2   ///  r0 = r0.wrapping_add(r2)
    rsh64 r0, 32                                    r0 >>= 32   ///  r0 = r0.wrapping_shr(32)
    add64 r9, r0                                    r9 += r0   ///  r9 = r9.wrapping_add(r0)
    ldxdw r2, [r10-0xf0]                    
    add64 r9, r2                                    r9 += r2   ///  r9 = r9.wrapping_add(r2)
    sub64 r3, r0                                    r3 -= r0   ///  r3 = r3.wrapping_sub(r0)
    stxdw [r10-0x50], r3                    
    mov64 r2, r4                                    r2 = r4
    add64 r2, r8                                    r2 += r8   ///  r2 = r2.wrapping_add(r8)
    ldxdw r0, [r10-0x110]                   
    ldxdw r3, [r10-0x88]                    
    add64 r3, r0                                    r3 += r0   ///  r3 = r3.wrapping_add(r0)
    add64 r3, r2                                    r3 += r2   ///  r3 = r3.wrapping_add(r2)
    neg64 r3                                        r3 = -r3   ///  r3 = (r3 as i64).wrapping_neg() as u64
    stxdw [r10-0x88], r3                    
    ja lbb_24570                                    if true { pc += 11 }
lbb_24559:
    stxdw [r10-0x80], r0                    
    add64 r4, r7                                    r4 += r7   ///  r4 = r4.wrapping_add(r7)
    ldxdw r0, [r10-0x70]                    
    ldxdw r6, [r10-0x60]                    
    jge r2, r0, lbb_24613                           if r2 >= r0 { pc += 49 }
    ldxdw r2, [r10-0x50]                    
    add64 r2, r7                                    r2 += r7   ///  r2 = r2.wrapping_add(r7)
    stxdw [r10-0x50], r2                    
    add64 r6, r7                                    r6 += r7   ///  r6 = r6.wrapping_add(r7)
    sub64 r9, r7                                    r9 -= r7   ///  r9 = r9.wrapping_sub(r7)
    jgt r7, r3, lbb_24613                           if r7 > r3 { pc += 43 }
lbb_24570:
    mov64 r2, r8                                    r2 = r8
    stxdw [r10-0x60], r6                    
    add64 r2, r6                                    r2 += r6   ///  r2 = r2.wrapping_add(r6)
    ldxdw r3, [r10-0x70]                    
    jgt r3, r2, lbb_24581                           if r3 > r2 { pc += 6 }
    ldxdw r3, [r10-0x88]                    
    add64 r3, r9                                    r3 += r9   ///  r3 = r3.wrapping_add(r9)
    mov64 r0, r8                                    r0 = r8
    ldxdw r6, [r10-0x50]                    
    add64 r0, r6                                    r0 += r6   ///  r0 = r0.wrapping_add(r6)
    jgt r0, r3, lbb_24618                           if r0 > r3 { pc += 37 }
lbb_24581:
    add64 r5, -1                                    r5 += -1   ///  r5 = r5.wrapping_add(-1 as i32 as i64 as u64)
    ldxdw r3, [r10-0x68]                    
    stxb [r3+0x0], r5                       
    ldxdw r3, [r10-0x78]                    
    add64 r3, r9                                    r3 += r9   ///  r3 = r3.wrapping_add(r9)
    mov64 r0, 1                                     r0 = 1 as i32 as i64 as u64
    jgt r7, r3, lbb_24559                           if r7 > r3 { pc += -29 }
    mov64 r0, 0                                     r0 = 0 as i32 as i64 as u64
    ja lbb_24559                                    if true { pc += -31 }
lbb_24590:
    ldxdw r0, [r10-0x88]                    
    jge r4, r0, lbb_24602                           if r4 >= r0 { pc += 10 }
    and64 r5, 1                                     r5 &= 1   ///  r5 = r5.and(1)
    jne r5, 0, lbb_24602                            if r5 != (0 as i32 as i64 as u64) { pc += 8 }
    mov64 r2, r4                                    r2 = r4
    ldxdw r5, [r10-0x60]                    
    add64 r2, r5                                    r2 += r5   ///  r2 = r2.wrapping_add(r5)
    jgt r0, r2, lbb_24644                           if r0 > r2 { pc += 46 }
    sub64 r2, r0                                    r2 -= r0   ///  r2 = r2.wrapping_sub(r0)
    sub64 r0, r4                                    r0 -= r4   ///  r0 = r0.wrapping_sub(r4)
    jgt r2, r0, lbb_24602                           if r2 > r0 { pc += 1 }
    ja lbb_24644                                    if true { pc += 42 }
lbb_24602:
    ldxdw r5, [r10-0x80]                    
    mov64 r2, r5                                    r2 = r5
    mul64 r2, 20                                    r2 *= 20   ///  r2 = r2.wrapping_mul(20 as u64)
    ldxdw r0, [r10-0xa0]                    
    jgt r2, r4, lbb_24610                           if r2 > r4 { pc += 3 }
    mul64 r5, -40                                   r5 *= -40   ///  r5 = r5.wrapping_mul(-40 as u64)
    add64 r5, r3                                    r5 += r3   ///  r5 = r5.wrapping_add(r3)
    jge r5, r4, lbb_24651                           if r5 >= r4 { pc += 41 }
lbb_24610:
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    stxdw [r0+0x0], r1                      
    ja lbb_24650                                    if true { pc += 37 }
lbb_24613:
    add64 r8, r4                                    r8 += r4   ///  r8 = r8.wrapping_add(r4)
    mov64 r2, r8                                    r2 = r8
    ldxdw r0, [r10-0xc0]                    
    ldxdw r6, [r10-0x80]                    
    ja lbb_24622                                    if true { pc += 4 }
lbb_24618:
    add64 r8, r4                                    r8 += r4   ///  r8 = r8.wrapping_add(r4)
    mov64 r6, 0                                     r6 = 0 as i32 as i64 as u64
    mov64 r2, r8                                    r2 = r8
    ldxdw r0, [r10-0xc0]                    
lbb_24622:
    jge r2, r0, lbb_24632                           if r2 >= r0 { pc += 9 }
    and64 r6, 1                                     r6 &= 1   ///  r6 = r6.and(1)
    jne r6, 0, lbb_24632                            if r6 != (0 as i32 as i64 as u64) { pc += 7 }
    mov64 r3, r2                                    r3 = r2
    add64 r3, r7                                    r3 += r7   ///  r3 = r3.wrapping_add(r7)
    jgt r0, r3, lbb_24644                           if r0 > r3 { pc += 16 }
    sub64 r3, r0                                    r3 -= r0   ///  r3 = r3.wrapping_sub(r0)
    sub64 r0, r2                                    r0 -= r2   ///  r0 = r0.wrapping_sub(r2)
    jgt r3, r0, lbb_24632                           if r3 > r0 { pc += 1 }
    ja lbb_24644                                    if true { pc += 12 }
lbb_24632:
    mov64 r3, 2                                     r3 = 2 as i32 as i64 as u64
    ldxdw r4, [r10-0xa0]                    
    jgt r3, r2, lbb_24648                           if r3 > r2 { pc += 13 }
    ldxdw r3, [r10-0x118]                   
    add64 r3, -3                                    r3 += -3   ///  r3 = r3.wrapping_add(-3 as i32 as i64 as u64)
    jgt r2, r3, lbb_24648                           if r2 > r3 { pc += 10 }
    add64 r1, 1                                     r1 += 1   ///  r1 = r1.wrapping_add(1 as i32 as i64 as u64)
    ldxdw r2, [r10-0x120]                   
    stxh [r4+0x10], r2                      
    stxdw [r4+0x8], r1                      
    ldxdw r1, [r10-0x58]                    
    ja lbb_24649                                    if true { pc += 5 }
lbb_24644:
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    ldxdw r2, [r10-0xa0]                    
    stxdw [r2+0x0], r1                      
    ja lbb_24650                                    if true { pc += 2 }
lbb_24648:
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
lbb_24649:
    stxdw [r4+0x0], r1                      
lbb_24650:
    exit                                    
lbb_24651:
    ldxdw r2, [r10-0x120]                   
    stxh [r0+0x10], r2                      
    stxdw [r0+0x8], r1                      
    ldxdw r1, [r10-0x58]                    
    stxdw [r0+0x0], r1                      
    ja lbb_24650                                    if true { pc += -7 }
lbb_24657:
    ldxdw r1, [r10-0x50]                    
    mov64 r2, r1                                    r2 = r1
    lddw r3, 0x100041cc8 --> b"\x00\x00\x00\x00\xe8\xfc\x03\x00.\x00\x00\x00\x00\x00\x00\x00\x0d\x01\x00…        r3 load str located at 4295236808
    call function_25832                     
lbb_24662:
    ldxdw r2, [r10-0x50]                    
    lddw r3, 0x100041ce0 --> b"\x00\x00\x00\x00\xe8\xfc\x03\x00.\x00\x00\x00\x00\x00\x00\x00@\x01\x00\x0…        r3 load str located at 4295236832
    call function_25832                     
lbb_24666:
    lddw r1, 0x100041cb0 --> b"\x00\x00\x00\x00\xe8\xfc\x03\x00.\x00\x00\x00\x00\x00\x00\x00\x0a\x01\x00…        r1 load str located at 4295236784
    call function_29619                     

function_24669:
    stxdw [r10-0x28], r5                    
    mov64 r9, r4                                    r9 = r4
    stxdw [r10-0x8], r3                     
    mov64 r8, r1                                    r8 = r1
    ldxdw r1, [r2+0x0]                      
    jne r1, 0, lbb_24681                            if r1 != (0 as i32 as i64 as u64) { pc += 6 }
    lddw r1, 0x10003f6e7 --> b"assertion failed: d.mant > 0"        r1 load str located at 4295227111
    mov64 r2, 28                                    r2 = 28 as i32 as i64 as u64
    lddw r3, 0x100041d28 --> b"\x00\x00\x00\x00\xe8\xfc\x03\x00.\x00\x00\x00\x00\x00\x00\x00\xdc\x01\x00…        r3 load str located at 4295236904
    call function_25816                     
lbb_24681:
    lddw r3, 0x2000000000000000                     r3 load str located at 2305843009213693952
    jgt r3, r1, lbb_24690                           if r3 > r1 { pc += 6 }
    lddw r1, 0x10003fd64 --> b"assertion failed: d.mant < (1 << 61)"        r1 load str located at 4295228772
    mov64 r2, 36                                    r2 = 36 as i32 as i64 as u64
    lddw r3, 0x100041d40 --> b"\x00\x00\x00\x00\xe8\xfc\x03\x00.\x00\x00\x00\x00\x00\x00\x00\xdd\x01\x00…        r3 load str located at 4295236928
    call function_25816                     
lbb_24690:
    jne r9, 0, lbb_24697                            if r9 != (0 as i32 as i64 as u64) { pc += 6 }
    lddw r1, 0x10003fd43 --> b"assertion failed: !buf.is_empty()"        r1 load str located at 4295228739
    mov64 r2, 33                                    r2 = 33 as i32 as i64 as u64
    lddw r3, 0x100041d58 --> b"\x00\x00\x00\x00\xe8\xfc\x03\x00.\x00\x00\x00\x00\x00\x00\x00\xde\x01\x00…        r3 load str located at 4295236952
    call function_25816                     
lbb_24697:
    ldxh r3, [r2+0x18]                      
    mov64 r2, r3                                    r2 = r3
    add64 r2, -32                                   r2 += -32   ///  r2 = r2.wrapping_add(-32 as i32 as i64 as u64)
    lddw r4, 0x100000000                            r4 load str located at 4294967296
    jgt r4, r1, lbb_24704                           if r4 > r1 { pc += 1 }
    mov64 r2, r3                                    r2 = r3
lbb_24704:
    mov64 r3, r1                                    r3 = r1
    lsh64 r3, 32                                    r3 <<= 32   ///  r3 = r3.wrapping_shl(32)
    jgt r4, r1, lbb_24708                           if r4 > r1 { pc += 1 }
    mov64 r3, r1                                    r3 = r1
lbb_24708:
    mov64 r1, r2                                    r1 = r2
    add64 r1, -16                                   r1 += -16   ///  r1 = r1.wrapping_add(-16 as i32 as i64 as u64)
    lddw r5, 0x1000000000000                        r5 load str located at 281474976710656
    jgt r5, r3, lbb_24714                           if r5 > r3 { pc += 1 }
    mov64 r1, r2                                    r1 = r2
lbb_24714:
    mov64 r4, r3                                    r4 = r3
    lsh64 r4, 16                                    r4 <<= 16   ///  r4 = r4.wrapping_shl(16)
    jgt r5, r3, lbb_24718                           if r5 > r3 { pc += 1 }
    mov64 r4, r3                                    r4 = r3
lbb_24718:
    mov64 r2, r1                                    r2 = r1
    add64 r2, -8                                    r2 += -8   ///  r2 = r2.wrapping_add(-8 as i32 as i64 as u64)
    lddw r3, 0x100000000000000                      r3 load str located at 72057594037927936
    jgt r3, r4, lbb_24724                           if r3 > r4 { pc += 1 }
    mov64 r2, r1                                    r2 = r1
lbb_24724:
    mov64 r1, r4                                    r1 = r4
    lsh64 r1, 8                                     r1 <<= 8   ///  r1 = r1.wrapping_shl(8)
    jgt r3, r4, lbb_24728                           if r3 > r4 { pc += 1 }
    mov64 r1, r4                                    r1 = r4
lbb_24728:
    lddw r4, 0x1000000000000000                     r4 load str located at 1152921504606846976
    mov64 r3, r2                                    r3 = r2
    add64 r3, -4                                    r3 += -4   ///  r3 = r3.wrapping_add(-4 as i32 as i64 as u64)
    jgt r4, r1, lbb_24734                           if r4 > r1 { pc += 1 }
    mov64 r3, r2                                    r3 = r2
lbb_24734:
    mov64 r2, r1                                    r2 = r1
    lsh64 r2, 4                                     r2 <<= 4   ///  r2 = r2.wrapping_shl(4)
    jgt r4, r1, lbb_24738                           if r4 > r1 { pc += 1 }
    mov64 r2, r1                                    r2 = r1
lbb_24738:
    lddw r1, 0x4000000000000000                     r1 load str located at 4611686018427387904
    mov64 r6, r3                                    r6 = r3
    add64 r6, -2                                    r6 += -2   ///  r6 = r6.wrapping_add(-2 as i32 as i64 as u64)
    jgt r1, r2, lbb_24744                           if r1 > r2 { pc += 1 }
    mov64 r6, r3                                    r6 = r3
lbb_24744:
    mov64 r7, r2                                    r7 = r2
    lsh64 r7, 2                                     r7 <<= 2   ///  r7 = r7.wrapping_shl(2)
    jgt r1, r2, lbb_24748                           if r1 > r2 { pc += 1 }
    mov64 r7, r2                                    r7 = r2
lbb_24748:
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    jsgt r7, -1, lbb_24751                          if (r7 as i64) > (-1 as i32 as i64) { pc += 1 }
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
lbb_24751:
    sub64 r6, r1                                    r6 -= r1   ///  r6 = r6.wrapping_sub(r1)
    mov64 r1, -96                                   r1 = -96 as i32 as i64 as u64
    sub64 r1, r6                                    r1 -= r6   ///  r1 = r1.wrapping_sub(r6)
    lsh64 r1, 48                                    r1 <<= 48   ///  r1 = r1.wrapping_shl(48)
    arsh64 r1, 48                                   r1 >>= 48 (signed)   ///  r1 = (r1 as i64).wrapping_shr(48)
    mul64 r1, 80                                    r1 *= 80   ///  r1 = r1.wrapping_mul(80 as u64)
    add64 r1, 86960                                 r1 += 86960   ///  r1 = r1.wrapping_add(86960 as i32 as i64 as u64)
    mov64 r2, 2126                                  r2 = 2126 as i32 as i64 as u64
    call function_31662                     
    lsh64 r0, 32                                    r0 <<= 32   ///  r0 = r0.wrapping_shl(32)
    mov64 r1, r0                                    r1 = r0
    arsh64 r1, 32                                   r1 >>= 32 (signed)   ///  r1 = (r1 as i64).wrapping_shr(32)
    rsh64 r0, 32                                    r0 >>= 32   ///  r0 = r0.wrapping_shr(32)
    mov64 r2, 81                                    r2 = 81 as i32 as i64 as u64
    jgt r2, r0, lbb_24769                           if r2 > r0 { pc += 3 }
    lddw r3, 0x100041c20 --> b"\x00\x00\x00\x00\xe8\xfc\x03\x00.\x00\x00\x00\x00\x00\x00\x00}\x00\x00\x0…        r3 load str located at 4295236640
    call function_25832                     
lbb_24769:
    stxdw [r10-0x20], r8                    
    lsh64 r1, 4                                     r1 <<= 4   ///  r1 = r1.wrapping_shl(4)
    lddw r2, 0x10003f7d8 --> b"\xdfE\x1a=\x03\xcf\x1a\xe6\xc1\xfb\xcc\xfe\x00\x00\x00\x00\xca\xc6\x9a\xc…        r2 load str located at 4295227352
    add64 r2, r1                                    r2 += r1   ///  r2 = r2.wrapping_add(r1)
    mov64 r1, r7                                    r1 = r7
    xor64 r1, -1                                    r1 ^= -1   ///  r1 = r1.xor(-1)
    rsh64 r1, 63                                    r1 >>= 63   ///  r1 = r1.wrapping_shr(63)
    lsh64 r7, r1                                    r7 <<= r1   ///  r7 = r7.wrapping_shl(r1 as u32)
    mov64 r5, r7                                    r5 = r7
    lsh64 r5, 32                                    r5 <<= 32   ///  r5 = r5.wrapping_shl(32)
    rsh64 r5, 32                                    r5 >>= 32   ///  r5 = r5.wrapping_shr(32)
    ldxdw r4, [r2+0x0]                      
    mov64 r1, r4                                    r1 = r4
    lsh64 r1, 32                                    r1 <<= 32   ///  r1 = r1.wrapping_shl(32)
    rsh64 r1, 32                                    r1 >>= 32   ///  r1 = r1.wrapping_shr(32)
    mov64 r0, r1                                    r0 = r1
    mul64 r0, r5                                    r0 *= r5   ///  r0 = r0.wrapping_mul(r5)
    rsh64 r0, 32                                    r0 >>= 32   ///  r0 = r0.wrapping_shr(32)
    rsh64 r7, 32                                    r7 >>= 32   ///  r7 = r7.wrapping_shr(32)
    mul64 r1, r7                                    r1 *= r7   ///  r1 = r1.wrapping_mul(r7)
    mov64 r3, r1                                    r3 = r1
    lsh64 r3, 32                                    r3 <<= 32   ///  r3 = r3.wrapping_shl(32)
    rsh64 r3, 32                                    r3 >>= 32   ///  r3 = r3.wrapping_shr(32)
    add64 r3, r0                                    r3 += r0   ///  r3 = r3.wrapping_add(r0)
    rsh64 r4, 32                                    r4 >>= 32   ///  r4 = r4.wrapping_shr(32)
    mov64 r0, r4                                    r0 = r4
    mul64 r0, r7                                    r0 *= r7   ///  r0 = r0.wrapping_mul(r7)
    rsh64 r1, 32                                    r1 >>= 32   ///  r1 = r1.wrapping_shr(32)
    add64 r1, r0                                    r1 += r0   ///  r1 = r1.wrapping_add(r0)
    mul64 r4, r5                                    r4 *= r5   ///  r4 = r4.wrapping_mul(r5)
    mov64 r5, r4                                    r5 = r4
    rsh64 r5, 32                                    r5 >>= 32   ///  r5 = r5.wrapping_shr(32)
    add64 r1, r5                                    r1 += r5   ///  r1 = r1.wrapping_add(r5)
    lsh64 r4, 32                                    r4 <<= 32   ///  r4 = r4.wrapping_shl(32)
    rsh64 r4, 32                                    r4 >>= 32   ///  r4 = r4.wrapping_shr(32)
    add64 r3, r4                                    r3 += r4   ///  r3 = r3.wrapping_add(r4)
    ldxh r4, [r2+0x8]                       
    add64 r6, r4                                    r6 += r4   ///  r6 = r6.wrapping_add(r4)
    lddw r4, 0x80000000                             r4 load str located at 2147483648
    add64 r3, r4                                    r3 += r4   ///  r3 = r3.wrapping_add(r4)
    mov64 r7, -64                                   r7 = -64 as i32 as i64 as u64
    sub64 r7, r6                                    r7 -= r6   ///  r7 = r7.wrapping_sub(r6)
    rsh64 r3, 32                                    r3 >>= 32   ///  r3 = r3.wrapping_shr(32)
    add64 r1, r3                                    r1 += r3   ///  r1 = r1.wrapping_add(r3)
    ldxh r4, [r2+0xa]                       
    mov64 r3, r7                                    r3 = r7
    and64 r3, 63                                    r3 &= 63   ///  r3 = r3.and(63)
    mov64 r2, 1                                     r2 = 1 as i32 as i64 as u64
    lsh64 r2, r3                                    r2 <<= r3   ///  r2 = r2.wrapping_shl(r3 as u32)
    mov64 r6, r1                                    r6 = r1
    rsh64 r6, r3                                    r6 >>= r3   ///  r6 = r6.wrapping_shr(r3 as u32)
    stxdw [r10-0x30], r2                    
    add64 r2, -1                                    r2 += -1   ///  r2 = r2.wrapping_add(-1 as i32 as i64 as u64)
    mov64 r8, r1                                    r8 = r1
    stxdw [r10-0x40], r2                    
    and64 r8, r2                                    r8 &= r2   ///  r8 = r8.and(r2)
    jne r8, 0, lbb_24839                            if r8 != (0 as i32 as i64 as u64) { pc += 11 }
    jgt r9, 10, lbb_25029                           if r9 > (10 as i32 as i64 as u64) { pc += 200 }
    mov64 r2, r9                                    r2 = r9
    lsh64 r2, 2                                     r2 <<= 2   ///  r2 = r2.wrapping_shl(2)
    lddw r0, 0x10003fd88 --> b"\x01\x00\x00\x00\x0a\x00\x00\x00d\x00\x00\x00\xe8\x03\x00\x00\x10'\x00\x0…        r0 load str located at 4295228808
    add64 r2, r0                                    r2 += r0   ///  r2 = r2.wrapping_add(r0)
    ldxw r2, [r2-0x4]                       
    mov64 r0, r6                                    r0 = r6
    lsh64 r0, 32                                    r0 <<= 32   ///  r0 = r0.wrapping_shl(32)
    rsh64 r0, 32                                    r0 >>= 32   ///  r0 = r0.wrapping_shr(32)
    jgt r2, r0, lbb_25029                           if r2 > r0 { pc += 190 }
lbb_24839:
    mov64 r2, r6                                    r2 = r6
    lsh64 r2, 32                                    r2 <<= 32   ///  r2 = r2.wrapping_shl(32)
    rsh64 r2, 32                                    r2 >>= 32   ///  r2 = r2.wrapping_shr(32)
    mov64 r0, 10000                                 r0 = 10000 as i32 as i64 as u64
    stxdw [r10-0x38], r3                    
    jgt r0, r2, lbb_24862                           if r0 > r2 { pc += 17 }
    mov64 r0, 1000000                               r0 = 1000000 as i32 as i64 as u64
    jgt r0, r2, lbb_24848                           if r0 > r2 { pc += 1 }
    ja lbb_24877                                    if true { pc += 29 }
lbb_24848:
    mov64 r0, r7                                    r0 = r7
    mov64 r2, r6                                    r2 = r6
    lsh64 r2, 32                                    r2 <<= 32   ///  r2 = r2.wrapping_shl(32)
    rsh64 r2, 32                                    r2 >>= 32   ///  r2 = r2.wrapping_shr(32)
    mov64 r5, 4                                     r5 = 4 as i32 as i64 as u64
    stxdw [r10-0x10], r5                    
    mov64 r7, 100000                                r7 = 100000 as i32 as i64 as u64
    jgt r7, r2, lbb_24858                           if r7 > r2 { pc += 2 }
    mov64 r5, 5                                     r5 = 5 as i32 as i64 as u64
    stxdw [r10-0x10], r5                    
lbb_24858:
    mov64 r5, 10000                                 r5 = 10000 as i32 as i64 as u64
    jgt r7, r2, lbb_24906                           if r7 > r2 { pc += 46 }
    mov64 r5, 100000                                r5 = 100000 as i32 as i64 as u64
    ja lbb_24906                                    if true { pc += 44 }
lbb_24862:
    mov64 r0, 100                                   r0 = 100 as i32 as i64 as u64
    jgt r0, r2, lbb_24865                           if r0 > r2 { pc += 1 }
    ja lbb_24893                                    if true { pc += 28 }
lbb_24865:
    mov64 r2, r6                                    r2 = r6
    lsh64 r2, 32                                    r2 <<= 32   ///  r2 = r2.wrapping_shl(32)
    rsh64 r2, 32                                    r2 >>= 32   ///  r2 = r2.wrapping_shr(32)
    mov64 r5, 1                                     r5 = 1 as i32 as i64 as u64
    stxdw [r10-0x10], r5                    
    jgt r2, 9, lbb_24873                            if r2 > (9 as i32 as i64 as u64) { pc += 2 }
    mov64 r5, 0                                     r5 = 0 as i32 as i64 as u64
    stxdw [r10-0x10], r5                    
lbb_24873:
    mov64 r5, 10                                    r5 = 10 as i32 as i64 as u64
    jgt r2, 9, lbb_24907                            if r2 > (9 as i32 as i64 as u64) { pc += 32 }
    mov64 r5, 1                                     r5 = 1 as i32 as i64 as u64
    ja lbb_24907                                    if true { pc += 30 }
lbb_24877:
    mov64 r2, r6                                    r2 = r6
    lsh64 r2, 32                                    r2 <<= 32   ///  r2 = r2.wrapping_shl(32)
    rsh64 r2, 32                                    r2 >>= 32   ///  r2 = r2.wrapping_shr(32)
    mov64 r0, 100000000                             r0 = 100000000 as i32 as i64 as u64
    jgt r0, r2, lbb_24883                           if r0 > r2 { pc += 1 }
    ja lbb_25033                                    if true { pc += 150 }
lbb_24883:
    mov64 r5, 6                                     r5 = 6 as i32 as i64 as u64
    stxdw [r10-0x10], r5                    
    mov64 r0, 10000000                              r0 = 10000000 as i32 as i64 as u64
    jgt r0, r2, lbb_24889                           if r0 > r2 { pc += 2 }
    mov64 r5, 7                                     r5 = 7 as i32 as i64 as u64
    stxdw [r10-0x10], r5                    
lbb_24889:
    mov64 r5, 1000000                               r5 = 1000000 as i32 as i64 as u64
    jgt r0, r2, lbb_24907                           if r0 > r2 { pc += 16 }
    mov64 r5, 10000000                              r5 = 10000000 as i32 as i64 as u64
    ja lbb_24907                                    if true { pc += 14 }
lbb_24893:
    mov64 r0, r7                                    r0 = r7
    mov64 r2, r6                                    r2 = r6
    lsh64 r2, 32                                    r2 <<= 32   ///  r2 = r2.wrapping_shl(32)
    rsh64 r2, 32                                    r2 >>= 32   ///  r2 = r2.wrapping_shr(32)
    mov64 r5, 2                                     r5 = 2 as i32 as i64 as u64
    stxdw [r10-0x10], r5                    
    mov64 r7, 1000                                  r7 = 1000 as i32 as i64 as u64
    jgt r7, r2, lbb_24903                           if r7 > r2 { pc += 2 }
    mov64 r5, 3                                     r5 = 3 as i32 as i64 as u64
    stxdw [r10-0x10], r5                    
lbb_24903:
    mov64 r5, 100                                   r5 = 100 as i32 as i64 as u64
    jgt r7, r2, lbb_24906                           if r7 > r2 { pc += 1 }
    mov64 r5, 1000                                  r5 = 1000 as i32 as i64 as u64
lbb_24906:
    mov64 r7, r0                                    r7 = r0
lbb_24907:
    ldxdw r0, [r10-0x10]                    
    and64 r0, 255                                   r0 &= 255   ///  r0 = r0.and(255)
    sub64 r0, r4                                    r0 -= r4   ///  r0 = r0.wrapping_sub(r4)
    lsh64 r0, 48                                    r0 <<= 48   ///  r0 = r0.wrapping_shl(48)
    lddw r2, 0x1000000000000                        r2 load str located at 281474976710656
    add64 r0, r2                                    r0 += r2   ///  r0 = r0.wrapping_add(r2)
    arsh64 r0, 48                                   r0 >>= 48 (signed)   ///  r0 = (r0 as i64).wrapping_shr(48)
    ldxdw r3, [r10-0x28]                    
    mov64 r2, r3                                    r2 = r3
    lsh64 r2, 48                                    r2 <<= 48   ///  r2 = r2.wrapping_shl(48)
    arsh64 r2, 48                                   r2 >>= 48 (signed)   ///  r2 = (r2 as i64).wrapping_shr(48)
    jsgt r0, r2, lbb_24921                          if (r0 as i64) > (r2 as i64) { pc += 1 }
    ja lbb_24969                                    if true { pc += 48 }
lbb_24921:
    mov64 r1, r0                                    r1 = r0
    sub64 r1, r2                                    r1 -= r2   ///  r1 = r1.wrapping_sub(r2)
    mov64 r4, r0                                    r4 = r0
    sub64 r4, r3                                    r4 -= r3   ///  r4 = r4.wrapping_sub(r3)
    lsh64 r4, 48                                    r4 <<= 48   ///  r4 = r4.wrapping_shl(48)
    arsh64 r4, 48                                   r4 >>= 48 (signed)   ///  r4 = (r4 as i64).wrapping_shr(48)
    jgt r9, r1, lbb_24929                           if r9 > r1 { pc += 1 }
    mov64 r4, r9                                    r4 = r9
lbb_24929:
    and64 r7, 65535                                 r7 &= 65535   ///  r7 = r7.and(65535)
    stxdw [r10-0x48], r7                    
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    ldxdw r2, [r10-0x10]                    
    and64 r2, 255                                   r2 &= 255   ///  r2 = r2.and(255)
    stxdw [r10-0x10], r2                    
    stxdw [r10-0x18], r4                    
    add64 r4, -1                                    r4 += -1   ///  r4 = r4.wrapping_add(-1 as i32 as i64 as u64)
    mov64 r2, 10                                    r2 = 10 as i32 as i64 as u64
lbb_24938:
    jeq r9, r1, lbb_25057                           if r9 == r1 { pc += 118 }
    mov64 r3, r9                                    r3 = r9
    mov64 r7, r5                                    r7 = r5
    lsh64 r7, 32                                    r7 <<= 32   ///  r7 = r7.wrapping_shl(32)
    rsh64 r7, 32                                    r7 >>= 32   ///  r7 = r7.wrapping_shr(32)
    mov64 r9, r6                                    r9 = r6
    lsh64 r9, 32                                    r9 <<= 32   ///  r9 = r9.wrapping_shl(32)
    rsh64 r9, 32                                    r9 >>= 32   ///  r9 = r9.wrapping_shr(32)
    div64 r9, r7                                    r9 /= r7   ///  r9 = r9 / r7
    mov64 r7, r9                                    r7 = r9
    mul64 r7, r5                                    r7 *= r5   ///  r7 = r7.wrapping_mul(r5)
    sub64 r6, r7                                    r6 -= r7   ///  r6 = r6.wrapping_sub(r7)
    ldxdw r7, [r10-0x8]                     
    add64 r7, r1                                    r7 += r1   ///  r7 = r7.wrapping_add(r1)
    add64 r9, 48                                    r9 += 48   ///  r9 = r9.wrapping_add(48 as i32 as i64 as u64)
    stxb [r7+0x0], r9                       
    jeq r4, r1, lbb_24986                           if r4 == r1 { pc += 31 }
    mov64 r9, r3                                    r9 = r3
    ldxdw r3, [r10-0x10]                    
    jeq r3, r1, lbb_25005                           if r3 == r1 { pc += 47 }
    add64 r1, 1                                     r1 += 1   ///  r1 = r1.wrapping_add(1 as i32 as i64 as u64)
    lsh64 r5, 32                                    r5 <<= 32   ///  r5 = r5.wrapping_shl(32)
    mov64 r7, r5                                    r7 = r5
    rsh64 r7, 32                                    r7 >>= 32   ///  r7 = r7.wrapping_shr(32)
    mov64 r5, r7                                    r5 = r7
    div64 r5, 10                                    r5 /= 10   ///  r5 = r5 / (10 as u64)
    jgt r2, r7, lbb_24966                           if r2 > r7 { pc += 1 }
    ja lbb_24938                                    if true { pc += -28 }
lbb_24966:
    lddw r1, 0x100041d70 --> b"\x00\x00\x00\x00\xe8\xfc\x03\x00.\x00\x00\x00\x00\x00\x00\x003\x02\x00\x0…        r1 load str located at 4295236976
    call function_29619                     
lbb_24969:
    ldxdw r2, [r10-0x30]                    
    stxdw [r10-0xfe0], r2                   
    stxdw [r10-0xff8], r3                   
    stxdw [r10-0x1000], r0                  
    div64 r1, 10                                    r1 /= 10   ///  r1 = r1 / (10 as u64)
    stxdw [r10-0xff0], r1                   
    lsh64 r5, 32                                    r5 <<= 32   ///  r5 = r5.wrapping_shl(32)
    rsh64 r5, 32                                    r5 >>= 32   ///  r5 = r5.wrapping_shr(32)
    ldxdw r1, [r10-0x38]                    
    lsh64 r5, r1                                    r5 <<= r1   ///  r5 = r5.wrapping_shl(r1 as u32)
    stxdw [r10-0xfe8], r5                   
    mov64 r5, r10                                   r5 = r10
    ldxdw r1, [r10-0x20]                    
    ldxdw r2, [r10-0x8]                     
    mov64 r3, r9                                    r3 = r9
    mov64 r4, 0                                     r4 = 0 as i32 as i64 as u64
    ja lbb_25055                                    if true { pc += 69 }
lbb_24986:
    ldxdw r1, [r10-0x30]                    
    stxdw [r10-0xfe0], r1                   
    ldxdw r1, [r10-0x28]                    
    stxdw [r10-0xff8], r1                   
    stxdw [r10-0x1000], r0                  
    lsh64 r5, 32                                    r5 <<= 32   ///  r5 = r5.wrapping_shl(32)
    rsh64 r5, 32                                    r5 >>= 32   ///  r5 = r5.wrapping_shr(32)
    ldxdw r1, [r10-0x38]                    
    lsh64 r5, r1                                    r5 <<= r1   ///  r5 = r5.wrapping_shl(r1 as u32)
    stxdw [r10-0xfe8], r5                   
    lsh64 r6, 32                                    r6 <<= 32   ///  r6 = r6.wrapping_shl(32)
    rsh64 r6, 32                                    r6 >>= 32   ///  r6 = r6.wrapping_shr(32)
    lsh64 r6, r1                                    r6 <<= r1   ///  r6 = r6.wrapping_shl(r1 as u32)
    add64 r6, r8                                    r6 += r8   ///  r6 = r6.wrapping_add(r8)
    stxdw [r10-0xff0], r6                   
    mov64 r5, r10                                   r5 = r10
    ldxdw r1, [r10-0x20]                    
    ldxdw r2, [r10-0x8]                     
    ja lbb_25054                                    if true { pc += 49 }
lbb_25005:
    mov64 r2, 1                                     r2 = 1 as i32 as i64 as u64
    add64 r1, 1                                     r1 += 1   ///  r1 = r1.wrapping_add(1 as i32 as i64 as u64)
    ldxdw r6, [r10-0x48]                    
    add64 r6, -1                                    r6 += -1   ///  r6 = r6.wrapping_add(-1 as i32 as i64 as u64)
    and64 r6, 63                                    r6 &= 63   ///  r6 = r6.and(63)
    ldxdw r3, [r10-0x38]                    
    ldxdw r7, [r10-0x40]                    
    ja lbb_25026                                    if true { pc += 13 }
lbb_25013:
    jge r1, r9, lbb_25062                           if r1 >= r9 { pc += 48 }
    ldxdw r4, [r10-0x8]                     
    add64 r4, r1                                    r4 += r1   ///  r4 = r4.wrapping_add(r1)
    mul64 r8, 10                                    r8 *= 10   ///  r8 = r8.wrapping_mul(10 as u64)
    mov64 r5, r8                                    r5 = r8
    rsh64 r5, r3                                    r5 >>= r3   ///  r5 = r5.wrapping_shr(r3 as u32)
    add64 r5, 48                                    r5 += 48   ///  r5 = r5.wrapping_add(48 as i32 as i64 as u64)
    stxb [r4+0x0], r5                       
    and64 r8, r7                                    r8 &= r7   ///  r8 = r8.and(r7)
    mul64 r2, 10                                    r2 *= 10   ///  r2 = r2.wrapping_mul(10 as u64)
    add64 r1, 1                                     r1 += 1   ///  r1 = r1.wrapping_add(1 as i32 as i64 as u64)
    ldxdw r4, [r10-0x18]                    
    jeq r4, r1, lbb_25043                           if r4 == r1 { pc += 17 }
lbb_25026:
    mov64 r4, r2                                    r4 = r2
    rsh64 r4, r6                                    r4 >>= r6   ///  r4 = r4.wrapping_shr(r6 as u32)
    jeq r4, 0, lbb_25013                            if r4 == (0 as i32 as i64 as u64) { pc += -16 }
lbb_25029:
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    ldxdw r2, [r10-0x20]                    
    stxdw [r2+0x0], r1                      
    ja lbb_25056                                    if true { pc += 23 }
lbb_25033:
    mov64 r5, 8                                     r5 = 8 as i32 as i64 as u64
    stxdw [r10-0x10], r5                    
    mov64 r0, 1000000000                            r0 = 1000000000 as i32 as i64 as u64
    jgt r0, r2, lbb_25039                           if r0 > r2 { pc += 2 }
    mov64 r5, 9                                     r5 = 9 as i32 as i64 as u64
    stxdw [r10-0x10], r5                    
lbb_25039:
    mov64 r5, 100000000                             r5 = 100000000 as i32 as i64 as u64
    jgt r0, r2, lbb_24907                           if r0 > r2 { pc += -134 }
    mov64 r5, 1000000000                            r5 = 1000000000 as i32 as i64 as u64
    ja lbb_24907                                    if true { pc += -136 }
lbb_25043:
    ldxdw r1, [r10-0x30]                    
    stxdw [r10-0xfe8], r1                   
    stxdw [r10-0xfe0], r2                   
    stxdw [r10-0xff0], r8                   
    ldxdw r1, [r10-0x28]                    
    stxdw [r10-0xff8], r1                   
    stxdw [r10-0x1000], r0                  
    mov64 r5, r10                                   r5 = r10
    ldxdw r1, [r10-0x20]                    
    ldxdw r2, [r10-0x8]                     
    mov64 r3, r9                                    r3 = r9
lbb_25054:
    ldxdw r4, [r10-0x18]                    
lbb_25055:
    call function_25066                     
lbb_25056:
    exit                                    
lbb_25057:
    mov64 r1, r9                                    r1 = r9
    mov64 r2, r9                                    r2 = r9
    lddw r3, 0x100041d88 --> b"\x00\x00\x00\x00\xe8\xfc\x03\x00.\x00\x00\x00\x00\x00\x00\x006\x02\x00\x0…        r3 load str located at 4295237000
    call function_25832                     
lbb_25062:
    mov64 r2, r9                                    r2 = r9
    lddw r3, 0x100041da0 --> b"\x00\x00\x00\x00\xe8\xfc\x03\x00.\x00\x00\x00\x00\x00\x00\x00l\x02\x00\x0…        r3 load str located at 4295237024
    call function_25832                     

function_25066:
    ldxdw r8, [r5-0xfe0]                    
    ldxdw r0, [r5-0xfe8]                    
    jge r8, r0, lbb_25099                           if r8 >= r0 { pc += 30 }
    mov64 r6, r0                                    r6 = r0
    sub64 r6, r8                                    r6 -= r8   ///  r6 = r6.wrapping_sub(r8)
    jgt r6, r8, lbb_25073                           if r6 > r8 { pc += 1 }
    ja lbb_25099                                    if true { pc += 26 }
lbb_25073:
    ldxdw r9, [r5-0xff0]                    
    ldxdw r6, [r5-0xff8]                    
    stxdw [r10-0x8], r6                     
    ldxdw r6, [r5-0x1000]                   
    mov64 r5, r0                                    r5 = r0
    sub64 r5, r9                                    r5 -= r9   ///  r5 = r5.wrapping_sub(r9)
    jgt r5, r9, lbb_25081                           if r5 > r9 { pc += 1 }
    ja lbb_25088                                    if true { pc += 7 }
lbb_25081:
    mov64 r5, r9                                    r5 = r9
    lsh64 r5, 1                                     r5 <<= 1   ///  r5 = r5.wrapping_shl(1)
    mov64 r7, r0                                    r7 = r0
    sub64 r7, r5                                    r7 -= r5   ///  r7 = r7.wrapping_sub(r5)
    mov64 r5, r8                                    r5 = r8
    lsh64 r5, 1                                     r5 <<= 1   ///  r5 = r5.wrapping_shl(1)
    jge r7, r5, lbb_25102                           if r7 >= r5 { pc += 14 }
lbb_25088:
    jgt r9, r8, lbb_25090                           if r9 > r8 { pc += 1 }
    ja lbb_25099                                    if true { pc += 9 }
lbb_25090:
    sub64 r9, r8                                    r9 -= r8   ///  r9 = r9.wrapping_sub(r8)
    sub64 r0, r9                                    r0 -= r9   ///  r0 = r0.wrapping_sub(r9)
    jgt r0, r9, lbb_25099                           if r0 > r9 { pc += 6 }
    jge r3, r4, lbb_25108                           if r3 >= r4 { pc += 14 }
    mov64 r1, r4                                    r1 = r4
    mov64 r2, r3                                    r2 = r3
    lddw r3, 0x100041db8 --> b"\x00\x00\x00\x00\xe8\xfc\x03\x00.\x00\x00\x00\x00\x00\x00\x00\xe3\x02\x00…        r3 load str located at 4295237048
    call function_28353                     
lbb_25099:
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
lbb_25100:
    stxdw [r1+0x0], r2                      
    exit                                    
lbb_25102:
    jge r3, r4, lbb_25180                           if r3 >= r4 { pc += 77 }
    mov64 r1, r4                                    r1 = r4
    mov64 r2, r3                                    r2 = r3
    lddw r3, 0x100041de8 --> b"\x00\x00\x00\x00\xe8\xfc\x03\x00.\x00\x00\x00\x00\x00\x00\x00\xcc\x02\x00…        r3 load str located at 4295237096
    call function_28353                     
lbb_25108:
    mov64 r8, r2                                    r8 = r2
    add64 r8, r4                                    r8 += r4   ///  r8 = r8.wrapping_add(r4)
    mov64 r5, 0                                     r5 = 0 as i32 as i64 as u64
    mov64 r0, r2                                    r0 = r2
lbb_25112:
    jeq r4, r5, lbb_25142                           if r4 == r5 { pc += 29 }
    mov64 r7, r0                                    r7 = r0
    add64 r7, r4                                    r7 += r4   ///  r7 = r7.wrapping_add(r4)
    add64 r0, -1                                    r0 += -1   ///  r0 = r0.wrapping_add(-1 as i32 as i64 as u64)
    add64 r5, 1                                     r5 += 1   ///  r5 = r5.wrapping_add(1 as i32 as i64 as u64)
    ldxb r7, [r7-0x1]                       
    jeq r7, 57, lbb_25112                           if r7 == (57 as i32 as i64 as u64) { pc += -7 }
    add64 r0, r4                                    r0 += r4   ///  r0 = r0.wrapping_add(r4)
    ldxb r7, [r0+0x0]                       
    add64 r7, 1                                     r7 += 1   ///  r7 = r7.wrapping_add(1 as i32 as i64 as u64)
    stxb [r0+0x0], r7                       
    mov64 r7, r4                                    r7 = r4
    sub64 r7, r5                                    r7 -= r5   ///  r7 = r7.wrapping_sub(r5)
    add64 r7, 1                                     r7 += 1   ///  r7 = r7.wrapping_add(1 as i32 as i64 as u64)
    jge r7, r4, lbb_25174                           if r7 >= r4 { pc += 47 }
    add64 r5, -1                                    r5 += -1   ///  r5 = r5.wrapping_add(-1 as i32 as i64 as u64)
    add64 r0, 1                                     r0 += 1   ///  r0 = r0.wrapping_add(1 as i32 as i64 as u64)
    stxdw [r10-0x10], r1                    
    mov64 r1, r0                                    r1 = r0
    mov64 r8, r2                                    r8 = r2
    mov64 r2, 48                                    r2 = 48 as i32 as i64 as u64
    mov64 r9, r3                                    r9 = r3
    mov64 r3, r5                                    r3 = r5
    mov64 r7, r4                                    r7 = r4
    call function_30383                     
    mov64 r2, r8                                    r2 = r8
    ldxdw r1, [r10-0x10]                    
    mov64 r3, r9                                    r3 = r9
    mov64 r4, r7                                    r4 = r7
    ja lbb_25174                                    if true { pc += 32 }
lbb_25142:
    mov64 r9, 49                                    r9 = 49 as i32 as i64 as u64
    jeq r4, 0, lbb_25164                            if r4 == (0 as i32 as i64 as u64) { pc += 20 }
    mov64 r5, 49                                    r5 = 49 as i32 as i64 as u64
    stxb [r2+0x0], r5                       
    mov64 r9, 48                                    r9 = 48 as i32 as i64 as u64
    jeq r4, 1, lbb_25164                            if r4 == (1 as i32 as i64 as u64) { pc += 16 }
    mov64 r5, r2                                    r5 = r2
    add64 r5, 1                                     r5 += 1   ///  r5 = r5.wrapping_add(1 as i32 as i64 as u64)
    mov64 r0, r4                                    r0 = r4
    add64 r0, -1                                    r0 += -1   ///  r0 = r0.wrapping_add(-1 as i32 as i64 as u64)
    stxdw [r10-0x10], r1                    
    mov64 r1, r5                                    r1 = r5
    stxdw [r10-0x18], r2                    
    mov64 r2, 48                                    r2 = 48 as i32 as i64 as u64
    stxdw [r10-0x20], r3                    
    mov64 r3, r0                                    r3 = r0
    stxdw [r10-0x28], r4                    
    call function_30383                     
    ldxdw r2, [r10-0x18]                    
    ldxdw r1, [r10-0x10]                    
    ldxdw r3, [r10-0x20]                    
    ldxdw r4, [r10-0x28]                    
lbb_25164:
    lsh64 r6, 48                                    r6 <<= 48   ///  r6 = r6.wrapping_shl(48)
    lddw r5, 0x1000000000000                        r5 load str located at 281474976710656
    add64 r6, r5                                    r6 += r5   ///  r6 = r6.wrapping_add(r5)
    arsh64 r6, 48                                   r6 >>= 48 (signed)   ///  r6 = (r6 as i64).wrapping_shr(48)
    jge r4, r3, lbb_25174                           if r4 >= r3 { pc += 4 }
    ldxdw r5, [r10-0x8]                     
    lsh64 r5, 48                                    r5 <<= 48   ///  r5 = r5.wrapping_shl(48)
    arsh64 r5, 48                                   r5 >>= 48 (signed)   ///  r5 = (r5 as i64).wrapping_shr(48)
    jsgt r6, r5, lbb_25183                          if (r6 as i64) > (r5 as i64) { pc += 9 }
lbb_25174:
    jge r3, r4, lbb_25180                           if r3 >= r4 { pc += 5 }
    mov64 r1, r4                                    r1 = r4
    mov64 r2, r3                                    r2 = r3
    lddw r3, 0x100041dd0 --> b"\x00\x00\x00\x00\xe8\xfc\x03\x00.\x00\x00\x00\x00\x00\x00\x00\xef\x02\x00…        r3 load str located at 4295237072
    call function_28353                     
lbb_25180:
    stxh [r1+0x10], r6                      
    stxdw [r1+0x8], r4                      
    ja lbb_25100                                    if true { pc += -83 }
lbb_25183:
    stxb [r8+0x0], r9                       
    add64 r4, 1                                     r4 += 1   ///  r4 = r4.wrapping_add(1 as i32 as i64 as u64)
    ja lbb_25174                                    if true { pc += -12 }

function_25186:
    jne r3, 0, lbb_25193                            if r3 != (0 as i32 as i64 as u64) { pc += 6 }
    lddw r1, 0x10003fd43 --> b"assertion failed: !buf.is_empty()"        r1 load str located at 4295228739
    mov64 r2, 33                                    r2 = 33 as i32 as i64 as u64
    lddw r3, 0x100041e00 --> b"\x00\x00\x00\x00\xb0\xfd\x03\x00#\x00\x00\x00\x00\x00\x00\x00\xbc\x00\x00…        r3 load str located at 4295237120
    call function_25816                     
lbb_25193:
    ldxb r0, [r2+0x0]                       
    jgt r0, 48, lbb_25201                           if r0 > (48 as i32 as i64 as u64) { pc += 6 }
    lddw r1, 0x10003fdd3 --> b"assertion failed: buf[0] > b'0'"        r1 load str located at 4295228883
    mov64 r2, 31                                    r2 = 31 as i32 as i64 as u64
    lddw r3, 0x100041e18 --> b"\x00\x00\x00\x00\xb0\xfd\x03\x00#\x00\x00\x00\x00\x00\x00\x00\xbd\x00\x00…        r3 load str located at 4295237144
    call function_25816                     
lbb_25201:
    ldxdw r0, [r5-0xff0]                    
    jgt r0, 3, lbb_25209                            if r0 > (3 as i32 as i64 as u64) { pc += 6 }
    lddw r1, 0x10003fdf2 --> b"assertion failed: parts.len() >= 4"        r1 load str located at 4295228914
    mov64 r2, 34                                    r2 = 34 as i32 as i64 as u64
    lddw r3, 0x100041e30 --> b"\x00\x00\x00\x00\xb0\xfd\x03\x00#\x00\x00\x00\x00\x00\x00\x00\xbe\x00\x00…        r3 load str located at 4295237168
    call function_25816                     
lbb_25209:
    ldxdw r0, [r5-0xff8]                    
    ldxdw r5, [r5-0x1000]                   
    mov64 r7, r4                                    r7 = r4
    lsh64 r7, 48                                    r7 <<= 48   ///  r7 = r7.wrapping_shl(48)
    arsh64 r7, 48                                   r7 >>= 48 (signed)   ///  r7 = (r7 as i64).wrapping_shr(48)
    mov64 r6, 1                                     r6 = 1 as i32 as i64 as u64
    jsgt r6, r7, lbb_25240                          if (r6 as i64) > (r7 as i64) { pc += 24 }
    stxdw [r0+0x8], r2                      
    mov64 r6, 2                                     r6 = 2 as i32 as i64 as u64
    stxh [r0+0x0], r6                       
    and64 r4, 65535                                 r4 &= 65535   ///  r4 = r4.and(65535)
    jgt r3, r4, lbb_25222                           if r3 > r4 { pc += 1 }
    ja lbb_25261                                    if true { pc += 39 }
lbb_25222:
    mov64 r6, 1                                     r6 = 1 as i32 as i64 as u64
    stxdw [r0+0x28], r6                     
    lddw r6, 0x10003fe14 --> b".0.-+NaNinf0assertion failed: buf.len() >= maxlenl"        r6 load str located at 4295228948
    stxdw [r0+0x20], r6                     
    mov64 r6, 2                                     r6 = 2 as i32 as i64 as u64
    stxh [r0+0x30], r6                      
    stxh [r0+0x18], r6                      
    add64 r2, r4                                    r2 += r4   ///  r2 = r2.wrapping_add(r4)
    stxdw [r0+0x38], r2                     
    stxdw [r0+0x10], r4                     
    sub64 r3, r4                                    r3 -= r4   ///  r3 = r3.wrapping_sub(r4)
    stxdw [r0+0x40], r3                     
    mov64 r6, 3                                     r6 = 3 as i32 as i64 as u64
    jgt r5, r3, lbb_25238                           if r5 > r3 { pc += 1 }
    ja lbb_25278                                    if true { pc += 40 }
lbb_25238:
    sub64 r5, r3                                    r5 -= r3   ///  r5 = r5.wrapping_sub(r3)
    ja lbb_25274                                    if true { pc += 34 }
lbb_25240:
    stxdw [r0+0x38], r2                     
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
    stxh [r0+0x18], r2                      
    lddw r2, 0x10003fe15 --> b"0.-+NaNinf0assertion failed: buf.len() >= maxlenli"        r2 load str located at 4295228949
    stxdw [r0+0x8], r2                      
    mov64 r2, 2                                     r2 = 2 as i32 as i64 as u64
    stxh [r0+0x30], r2                      
    stxdw [r0+0x10], r2                     
    stxh [r0+0x0], r2                       
    stxdw [r0+0x40], r3                     
    mov64 r2, r7                                    r2 = r7
    neg64 r2                                        r2 = -r2   ///  r2 = (r2 as i64).wrapping_neg() as u64
    stxdw [r0+0x20], r2                     
    mov64 r6, 3                                     r6 = 3 as i32 as i64 as u64
    jgt r5, r3, lbb_25257                           if r5 > r3 { pc += 1 }
    ja lbb_25278                                    if true { pc += 21 }
lbb_25257:
    sub64 r5, r3                                    r5 -= r3   ///  r5 = r5.wrapping_sub(r3)
    jge r2, r5, lbb_25278                           if r2 >= r5 { pc += 19 }
    add64 r5, r7                                    r5 += r7   ///  r5 = r5.wrapping_add(r7)
    ja lbb_25274                                    if true { pc += 13 }
lbb_25261:
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
    stxh [r0+0x18], r2                      
    stxdw [r0+0x10], r3                     
    sub64 r4, r3                                    r4 -= r3   ///  r4 = r4.wrapping_sub(r3)
    stxdw [r0+0x20], r4                     
    jeq r5, 0, lbb_25278                            if r5 == (0 as i32 as i64 as u64) { pc += 11 }
    mov64 r2, 1                                     r2 = 1 as i32 as i64 as u64
    stxdw [r0+0x40], r2                     
    lddw r2, 0x10003fe14 --> b".0.-+NaNinf0assertion failed: buf.len() >= maxlenl"        r2 load str located at 4295228948
    stxdw [r0+0x38], r2                     
    mov64 r2, 2                                     r2 = 2 as i32 as i64 as u64
    stxh [r0+0x30], r2                      
lbb_25274:
    stxdw [r0+0x50], r5                     
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
    stxh [r0+0x48], r2                      
    mov64 r6, 4                                     r6 = 4 as i32 as i64 as u64
lbb_25278:
    stxdw [r1+0x8], r6                      
    stxdw [r1+0x0], r0                      
    exit                                    

function_25281:
    mov64 r6, r2                                    r6 = r2
    mov64 r7, r1                                    r7 = r1
    call function_30025                     
    mov64 r8, 1                                     r8 = 1 as i32 as i64 as u64
    jne r0, 0, lbb_25299                            if r0 != (0 as i32 as i64 as u64) { pc += 13 }
    ldxdw r1, [r6+0x20]                     
    ldxdw r2, [r6+0x28]                     
    ldxdw r4, [r2+0x18]                     
    lddw r2, 0x10003fe61 --> b".."                  r2 load str located at 4295229025
    mov64 r3, 2                                     r3 = 2 as i32 as i64 as u64
    callx r4                                
    jne r0, 0, lbb_25299                            if r0 != (0 as i32 as i64 as u64) { pc += 5 }
    add64 r7, 8                                     r7 += 8   ///  r7 = r7.wrapping_add(8 as i32 as i64 as u64)
    mov64 r1, r7                                    r1 = r7
    mov64 r2, r6                                    r2 = r6
    call function_30025                     
    mov64 r8, r0                                    r8 = r0
lbb_25299:
    mov64 r0, r8                                    r0 = r8
    exit                                    

function_25301:
    lddw r2, 0xfa7019cea288c066                     r2 load str located at -400791991555145626
    stxdw [r1+0x8], r2                      
    lddw r2, 0xda447f87a8571939                     r2 load str located at -2718908054403344071
    stxdw [r1+0x0], r2                      
    exit                                    

function_25308:
    ldxdw r1, [r2+0x20]                     
    ldxdw r2, [r2+0x28]                     
    ldxdw r4, [r2+0x18]                     
    lddw r2, 0x10003fe63 --> b"BorrowError"         r2 load str located at 4295229027
    mov64 r3, 11                                    r3 = 11 as i32 as i64 as u64
    callx r4                                
    exit                                    

function_25316:
    ldxdw r1, [r2+0x20]                     
    ldxdw r2, [r2+0x28]                     
    ldxdw r4, [r2+0x18]                     
    lddw r2, 0x10003fe6e --> b"BorrowMutError"        r2 load str located at 4295229038
    mov64 r3, 14                                    r3 = 14 as i32 as i64 as u64
    callx r4                                
    exit                                    

function_25324:
    mov64 r2, r1                                    r2 = r1
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    stxdw [r10-0x28], r1                    
    lddw r1, 0x100041e60 --> b"\x00\x00\x00\x00|\xfe\x03\x00\x12\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00…        r1 load str located at 4295237216
    stxdw [r10-0x48], r1                    
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    stxdw [r10-0x40], r1                    
    stxdw [r10-0x30], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -24                                   r1 += -24   ///  r1 = r1.wrapping_add(-24 as i32 as i64 as u64)
    stxdw [r10-0x38], r1                    
    lddw r1, 0x100031840 --> b"y! \x00\x00\x00\x00\x00y"(\x00\x00\x00\x00\x00y$\x18\x00\x00\x00\x00\x00\…        r1 load str located at 4295170112
    stxdw [r10-0x10], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -1                                    r1 += -1   ///  r1 = r1.wrapping_add(-1 as i32 as i64 as u64)
    stxdw [r10-0x18], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -72                                   r1 += -72   ///  r1 = r1.wrapping_add(-72 as i32 as i64 as u64)
    call function_25805                     

function_25345:
    mov64 r2, r1                                    r2 = r1
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    stxdw [r10-0x28], r1                    
    lddw r1, 0x100041e70 --> b"\x00\x00\x00\x00\x8e\xfe\x03\x00\x1a\x00\x00\x00\x00\x00\x00\x00\x01\x00\…        r1 load str located at 4295237232
    stxdw [r10-0x48], r1                    
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    stxdw [r10-0x40], r1                    
    stxdw [r10-0x30], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -24                                   r1 += -24   ///  r1 = r1.wrapping_add(-24 as i32 as i64 as u64)
    stxdw [r10-0x38], r1                    
    lddw r1, 0x100031800 --> b"y! \x00\x00\x00\x00\x00y"(\x00\x00\x00\x00\x00y$\x18\x00\x00\x00\x00\x00\…        r1 load str located at 4295170048
    stxdw [r10-0x10], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -1                                    r1 += -1   ///  r1 = r1.wrapping_add(-1 as i32 as i64 as u64)
    stxdw [r10-0x18], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -72                                   r1 += -72   ///  r1 = r1.wrapping_add(-72 as i32 as i64 as u64)
    call function_25805                     

function_25366:
    mov64 r4, r2                                    r4 = r2
    lsh64 r4, 32                                    r4 <<= 32   ///  r4 = r4.wrapping_shl(32)
    rsh64 r4, 32                                    r4 >>= 32   ///  r4 = r4.wrapping_shr(32)
    jsgt r4, 12, lbb_25380                          if (r4 as i64) > (12 as i32 as i64) { pc += 10 }
    jeq r4, 0, lbb_25514                            if r4 == (0 as i32 as i64 as u64) { pc += 143 }
    jeq r4, 9, lbb_25545                            if r4 == (9 as i32 as i64 as u64) { pc += 173 }
    jeq r4, 10, lbb_25374                           if r4 == (10 as i32 as i64 as u64) { pc += 1 }
    ja lbb_25394                                    if true { pc += 20 }
lbb_25374:
    mov64 r2, 512                                   r2 = 512 as i32 as i64 as u64
    stxh [r1+0xa], r2                       
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
    stxdw [r1+0x2], r2                      
    mov64 r2, 28252                                 r2 = 28252 as i32 as i64 as u64
    ja lbb_25678                                    if true { pc += 298 }
lbb_25380:
    jsgt r4, 38, lbb_25392                          if (r4 as i64) > (38 as i32 as i64) { pc += 11 }
    jeq r4, 13, lbb_25520                           if r4 == (13 as i32 as i64 as u64) { pc += 138 }
    jeq r4, 34, lbb_25384                           if r4 == (34 as i32 as i64 as u64) { pc += 1 }
    ja lbb_25394                                    if true { pc += 10 }
lbb_25384:
    and64 r3, 65536                                 r3 &= 65536   ///  r3 = r3.and(65536)
    jeq r3, 0, lbb_25529                            if r3 == (0 as i32 as i64 as u64) { pc += 143 }
    mov64 r2, 512                                   r2 = 512 as i32 as i64 as u64
    stxh [r1+0xa], r2                       
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
    stxdw [r1+0x2], r2                      
    mov64 r2, 8796                                  r2 = 8796 as i32 as i64 as u64
    ja lbb_25678                                    if true { pc += 286 }
lbb_25392:
    jeq r4, 39, lbb_25526                           if r4 == (39 as i32 as i64 as u64) { pc += 133 }
    jeq r4, 92, lbb_25539                           if r4 == (92 as i32 as i64 as u64) { pc += 145 }
lbb_25394:
    mov64 r4, r2                                    r4 = r2
    lsh64 r4, 32                                    r4 <<= 32   ///  r4 = r4.wrapping_shl(32)
    rsh64 r4, 32                                    r4 >>= 32   ///  r4 = r4.wrapping_shr(32)
    mov64 r5, 768                                   r5 = 768 as i32 as i64 as u64
    jgt r5, r4, lbb_25529                           if r5 > r4 { pc += 130 }
    and64 r3, 1                                     r3 &= 1   ///  r3 = r3.and(1)
    jne r3, 0, lbb_25402                            if r3 != (0 as i32 as i64 as u64) { pc += 1 }
    ja lbb_25529                                    if true { pc += 127 }
lbb_25402:
    mov64 r6, r1                                    r6 = r1
    mov64 r1, r2                                    r1 = r2
    mov64 r7, r2                                    r7 = r2
    call function_30253                     
    mov64 r2, r7                                    r2 = r7
    mov64 r1, r6                                    r1 = r6
    jeq r0, 0, lbb_25529                            if r0 == (0 as i32 as i64 as u64) { pc += 120 }
    lddw r3, 0xfffffffc                             r3 load str located at 4294967292
    mov64 r4, r2                                    r4 = r2
    and64 r4, r3                                    r4 &= r3   ///  r4 = r4.and(r3)
    rsh64 r4, 1                                     r4 >>= 1   ///  r4 = r4.wrapping_shr(1)
    mov64 r3, r2                                    r3 = r2
    or64 r3, r4                                     r3 |= r4   ///  r3 = r3.or(r4)
    lddw r4, 0xfffffff8                             r4 load str located at 4294967288
    mov64 r5, r3                                    r5 = r3
    and64 r5, r4                                    r5 &= r4   ///  r5 = r5.and(r4)
    rsh64 r5, 2                                     r5 >>= 2   ///  r5 = r5.wrapping_shr(2)
    or64 r3, r5                                     r3 |= r5   ///  r3 = r3.or(r5)
    mov64 r4, 0                                     r4 = 0 as i32 as i64 as u64
    stxb [r10-0x8], r4                      
    stxh [r10-0xa], r4                      
    lddw r4, 0xffffffe0                             r4 load str located at 4294967264
    mov64 r5, r3                                    r5 = r3
    and64 r5, r4                                    r5 &= r4   ///  r5 = r5.and(r4)
    rsh64 r5, 4                                     r5 >>= 4   ///  r5 = r5.wrapping_shr(4)
    or64 r3, r5                                     r3 |= r5   ///  r3 = r3.or(r5)
    mov64 r4, r2                                    r4 = r2
    rsh64 r4, 4                                     r4 >>= 4   ///  r4 = r4.wrapping_shr(4)
    and64 r4, 15                                    r4 &= 15   ///  r4 = r4.and(15)
    mov64 r0, r2                                    r0 = r2
    rsh64 r0, 8                                     r0 >>= 8   ///  r0 = r0.wrapping_shr(8)
    and64 r0, 15                                    r0 &= 15   ///  r0 = r0.and(15)
    mov64 r7, r2                                    r7 = r2
    rsh64 r7, 12                                    r7 >>= 12   ///  r7 = r7.wrapping_shr(12)
    and64 r7, 15                                    r7 &= 15   ///  r7 = r7.and(15)
    mov64 r8, r2                                    r8 = r2
    rsh64 r8, 16                                    r8 >>= 16   ///  r8 = r8.wrapping_shr(16)
    and64 r8, 15                                    r8 &= 15   ///  r8 = r8.and(15)
    mov64 r6, r2                                    r6 = r2
    rsh64 r6, 20                                    r6 >>= 20   ///  r6 = r6.wrapping_shr(20)
    and64 r6, 15                                    r6 &= 15   ///  r6 = r6.and(15)
    lddw r9, 0x10003e7f0 --> b"0123456789abcdefAC_03AC_02called `Result::unwrap()"        r9 load str located at 4295223280
    lddw r5, 0x10003e7f0 --> b"0123456789abcdefAC_03AC_02called `Result::unwrap()"        r5 load str located at 4295223280
    add64 r5, r6                                    r5 += r6   ///  r5 = r5.wrapping_add(r6)
    lddw r6, 0x10003e7f0 --> b"0123456789abcdefAC_03AC_02called `Result::unwrap()"        r6 load str located at 4295223280
    add64 r6, r8                                    r6 += r8   ///  r6 = r6.wrapping_add(r8)
    lddw r8, 0x10003e7f0 --> b"0123456789abcdefAC_03AC_02called `Result::unwrap()"        r8 load str located at 4295223280
    add64 r8, r7                                    r8 += r7   ///  r8 = r8.wrapping_add(r7)
    lddw r7, 0x10003e7f0 --> b"0123456789abcdefAC_03AC_02called `Result::unwrap()"        r7 load str located at 4295223280
    add64 r7, r0                                    r7 += r0   ///  r7 = r7.wrapping_add(r0)
    lddw r0, 0x10003e7f0 --> b"0123456789abcdefAC_03AC_02called `Result::unwrap()"        r0 load str located at 4295223280
    add64 r0, r4                                    r0 += r4   ///  r0 = r0.wrapping_add(r4)
    and64 r2, 15                                    r2 &= 15   ///  r2 = r2.and(15)
    add64 r9, r2                                    r9 += r2   ///  r9 = r9.wrapping_add(r2)
    mov64 r2, 125                                   r2 = 125 as i32 as i64 as u64
    stxb [r10-0x1], r2                      
    ldxb r2, [r9+0x0]                       
    stxb [r10-0x2], r2                      
    ldxb r2, [r0+0x0]                       
    stxb [r10-0x3], r2                      
    ldxb r2, [r7+0x0]                       
    stxb [r10-0x4], r2                      
    ldxb r2, [r8+0x0]                       
    stxb [r10-0x5], r2                      
    ldxb r2, [r6+0x0]                       
    stxb [r10-0x6], r2                      
    ldxb r2, [r5+0x0]                       
    stxb [r10-0x7], r2                      
    lddw r2, 0xfffffe00                             r2 load str located at 4294966784
    mov64 r4, r3                                    r4 = r3
    and64 r4, r2                                    r4 &= r2   ///  r4 = r4.and(r2)
    rsh64 r4, 8                                     r4 >>= 8   ///  r4 = r4.wrapping_shr(8)
    or64 r3, r4                                     r3 |= r4   ///  r3 = r3.or(r4)
    lddw r2, 0xfffe0000                             r2 load str located at 4294836224
    mov64 r4, r3                                    r4 = r3
    and64 r4, r2                                    r4 &= r2   ///  r4 = r4.and(r2)
    rsh64 r4, 16                                    r4 >>= 16   ///  r4 = r4.wrapping_shr(16)
    or64 r3, r4                                     r3 |= r4   ///  r3 = r3.or(r4)
    xor64 r3, -1                                    r3 ^= -1   ///  r3 = r3.xor(-1)
    mov64 r4, r3                                    r4 = r3
    and64 r4, -2                                    r4 &= -2   ///  r4 = r4.and(-2)
    rsh64 r3, 1                                     r3 >>= 1   ///  r3 = r3.wrapping_shr(1)
    and64 r3, 1431655765                            r3 &= 1431655765   ///  r3 = r3.and(1431655765)
    sub64 r4, r3                                    r4 -= r3   ///  r4 = r4.wrapping_sub(r3)
    mov64 r2, r4                                    r2 = r4
    and64 r2, 858993459                             r2 &= 858993459   ///  r2 = r2.and(858993459)
    rsh64 r4, 2                                     r4 >>= 2   ///  r4 = r4.wrapping_shr(2)
    and64 r4, 858993459                             r4 &= 858993459   ///  r4 = r4.and(858993459)
    add64 r2, r4                                    r2 += r4   ///  r2 = r2.wrapping_add(r4)
    mov64 r3, r2                                    r3 = r2
    rsh64 r3, 4                                     r3 >>= 4   ///  r3 = r3.wrapping_shr(4)
    add64 r2, r3                                    r2 += r3   ///  r2 = r2.wrapping_add(r3)
    and64 r2, 252645135                             r2 &= 252645135   ///  r2 = r2.and(252645135)
    mul64 r2, 16843009                              r2 *= 16843009   ///  r2 = r2.wrapping_mul(16843009 as u64)
    rsh64 r2, 26                                    r2 >>= 26   ///  r2 = r2.wrapping_shr(26)
    and64 r2, 63                                    r2 &= 63   ///  r2 = r2.and(63)
    add64 r2, -2                                    r2 += -2   ///  r2 = r2.wrapping_add(-2 as i32 as i64 as u64)
    mov64 r3, 11                                    r3 = 11 as i32 as i64 as u64
    jgt r3, r2, lbb_25680                           if r3 > r2 { pc += 168 }
    mov64 r1, r2                                    r1 = r2
    ja lbb_25654                                    if true { pc += 140 }
lbb_25514:
    mov64 r2, 512                                   r2 = 512 as i32 as i64 as u64
    stxh [r1+0xa], r2                       
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
    stxdw [r1+0x2], r2                      
    mov64 r2, 12380                                 r2 = 12380 as i32 as i64 as u64
    ja lbb_25678                                    if true { pc += 158 }
lbb_25520:
    mov64 r2, 512                                   r2 = 512 as i32 as i64 as u64
    stxh [r1+0xa], r2                       
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
    stxdw [r1+0x2], r2                      
    mov64 r2, 29276                                 r2 = 29276 as i32 as i64 as u64
    ja lbb_25678                                    if true { pc += 152 }
lbb_25526:
    and64 r3, 256                                   r3 &= 256   ///  r3 = r3.and(256)
    jeq r3, 0, lbb_25529                            if r3 == (0 as i32 as i64 as u64) { pc += 1 }
    ja lbb_25673                                    if true { pc += 144 }
lbb_25529:
    mov64 r6, r1                                    r6 = r1
    mov64 r7, r2                                    r7 = r2
    mov64 r1, r2                                    r1 = r2
    call function_29179                     
    jne r0, 0, lbb_25535                            if r0 != (0 as i32 as i64 as u64) { pc += 1 }
    ja lbb_25551                                    if true { pc += 16 }
lbb_25535:
    stxw [r6+0x4], r7                       
    mov64 r1, 128                                   r1 = 128 as i32 as i64 as u64
    stxb [r6+0x0], r1                       
    ja lbb_25679                                    if true { pc += 140 }
lbb_25539:
    mov64 r2, 512                                   r2 = 512 as i32 as i64 as u64
    stxh [r1+0xa], r2                       
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
    stxdw [r1+0x2], r2                      
    mov64 r2, 23644                                 r2 = 23644 as i32 as i64 as u64
    ja lbb_25678                                    if true { pc += 133 }
lbb_25545:
    mov64 r2, 512                                   r2 = 512 as i32 as i64 as u64
    stxh [r1+0xa], r2                       
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
    stxdw [r1+0x2], r2                      
    mov64 r2, 29788                                 r2 = 29788 as i32 as i64 as u64
    ja lbb_25678                                    if true { pc += 127 }
lbb_25551:
    lddw r1, 0xfffffffc                             r1 load str located at 4294967292
    mov64 r2, r7                                    r2 = r7
    mov64 r3, r2                                    r3 = r2
    and64 r3, r1                                    r3 &= r1   ///  r3 = r3.and(r1)
    rsh64 r3, 1                                     r3 >>= 1   ///  r3 = r3.wrapping_shr(1)
    mov64 r1, r2                                    r1 = r2
    or64 r1, r3                                     r1 |= r3   ///  r1 = r1.or(r3)
    lddw r3, 0xfffffff8                             r3 load str located at 4294967288
    mov64 r4, r1                                    r4 = r1
    and64 r4, r3                                    r4 &= r3   ///  r4 = r4.and(r3)
    rsh64 r4, 2                                     r4 >>= 2   ///  r4 = r4.wrapping_shr(2)
    or64 r1, r4                                     r1 |= r4   ///  r1 = r1.or(r4)
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
    stxb [r10-0x8], r3                      
    stxh [r10-0xa], r3                      
    lddw r3, 0xffffffe0                             r3 load str located at 4294967264
    mov64 r4, r1                                    r4 = r1
    and64 r4, r3                                    r4 &= r3   ///  r4 = r4.and(r3)
    rsh64 r4, 4                                     r4 >>= 4   ///  r4 = r4.wrapping_shr(4)
    or64 r1, r4                                     r1 |= r4   ///  r1 = r1.or(r4)
    mov64 r3, r2                                    r3 = r2
    rsh64 r3, 4                                     r3 >>= 4   ///  r3 = r3.wrapping_shr(4)
    and64 r3, 15                                    r3 &= 15   ///  r3 = r3.and(15)
    mov64 r5, r2                                    r5 = r2
    rsh64 r5, 8                                     r5 >>= 8   ///  r5 = r5.wrapping_shr(8)
    and64 r5, 15                                    r5 &= 15   ///  r5 = r5.and(15)
    rsh64 r7, 12                                    r7 >>= 12   ///  r7 = r7.wrapping_shr(12)
    and64 r7, 15                                    r7 &= 15   ///  r7 = r7.and(15)
    mov64 r8, r2                                    r8 = r2
    rsh64 r8, 16                                    r8 >>= 16   ///  r8 = r8.wrapping_shr(16)
    and64 r8, 15                                    r8 &= 15   ///  r8 = r8.and(15)
    mov64 r0, r2                                    r0 = r2
    rsh64 r0, 20                                    r0 >>= 20   ///  r0 = r0.wrapping_shr(20)
    and64 r0, 15                                    r0 &= 15   ///  r0 = r0.and(15)
    lddw r9, 0x10003e7f0 --> b"0123456789abcdefAC_03AC_02called `Result::unwrap()"        r9 load str located at 4295223280
    lddw r4, 0x10003e7f0 --> b"0123456789abcdefAC_03AC_02called `Result::unwrap()"        r4 load str located at 4295223280
    add64 r4, r0                                    r4 += r0   ///  r4 = r4.wrapping_add(r0)
    lddw r0, 0x10003e7f0 --> b"0123456789abcdefAC_03AC_02called `Result::unwrap()"        r0 load str located at 4295223280
    add64 r0, r8                                    r0 += r8   ///  r0 = r0.wrapping_add(r8)
    lddw r8, 0x10003e7f0 --> b"0123456789abcdefAC_03AC_02called `Result::unwrap()"        r8 load str located at 4295223280
    add64 r8, r7                                    r8 += r7   ///  r8 = r8.wrapping_add(r7)
    lddw r7, 0x10003e7f0 --> b"0123456789abcdefAC_03AC_02called `Result::unwrap()"        r7 load str located at 4295223280
    add64 r7, r5                                    r7 += r5   ///  r7 = r7.wrapping_add(r5)
    lddw r5, 0x10003e7f0 --> b"0123456789abcdefAC_03AC_02called `Result::unwrap()"        r5 load str located at 4295223280
    add64 r5, r3                                    r5 += r3   ///  r5 = r5.wrapping_add(r3)
    and64 r2, 15                                    r2 &= 15   ///  r2 = r2.and(15)
    add64 r9, r2                                    r9 += r2   ///  r9 = r9.wrapping_add(r2)
    mov64 r2, 125                                   r2 = 125 as i32 as i64 as u64
    stxb [r10-0x1], r2                      
    ldxb r2, [r9+0x0]                       
    stxb [r10-0x2], r2                      
    ldxb r2, [r5+0x0]                       
    stxb [r10-0x3], r2                      
    ldxb r2, [r7+0x0]                       
    stxb [r10-0x4], r2                      
    ldxb r2, [r8+0x0]                       
    stxb [r10-0x5], r2                      
    ldxb r2, [r0+0x0]                       
    stxb [r10-0x6], r2                      
    ldxb r2, [r4+0x0]                       
    stxb [r10-0x7], r2                      
    lddw r2, 0xfffffe00                             r2 load str located at 4294966784
    mov64 r3, r1                                    r3 = r1
    and64 r3, r2                                    r3 &= r2   ///  r3 = r3.and(r2)
    rsh64 r3, 8                                     r3 >>= 8   ///  r3 = r3.wrapping_shr(8)
    or64 r1, r3                                     r1 |= r3   ///  r1 = r1.or(r3)
    lddw r2, 0xfffe0000                             r2 load str located at 4294836224
    mov64 r3, r1                                    r3 = r1
    and64 r3, r2                                    r3 &= r2   ///  r3 = r3.and(r2)
    rsh64 r3, 16                                    r3 >>= 16   ///  r3 = r3.wrapping_shr(16)
    or64 r1, r3                                     r1 |= r3   ///  r1 = r1.or(r3)
    xor64 r1, -1                                    r1 ^= -1   ///  r1 = r1.xor(-1)
    mov64 r2, r1                                    r2 = r1
    and64 r2, -2                                    r2 &= -2   ///  r2 = r2.and(-2)
    rsh64 r1, 1                                     r1 >>= 1   ///  r1 = r1.wrapping_shr(1)
    and64 r1, 1431655765                            r1 &= 1431655765   ///  r1 = r1.and(1431655765)
    sub64 r2, r1                                    r2 -= r1   ///  r2 = r2.wrapping_sub(r1)
    mov64 r1, r2                                    r1 = r2
    and64 r1, 858993459                             r1 &= 858993459   ///  r1 = r1.and(858993459)
    rsh64 r2, 2                                     r2 >>= 2   ///  r2 = r2.wrapping_shr(2)
    and64 r2, 858993459                             r2 &= 858993459   ///  r2 = r2.and(858993459)
    add64 r1, r2                                    r1 += r2   ///  r1 = r1.wrapping_add(r2)
    mov64 r2, r1                                    r2 = r1
    rsh64 r2, 4                                     r2 >>= 4   ///  r2 = r2.wrapping_shr(4)
    add64 r1, r2                                    r1 += r2   ///  r1 = r1.wrapping_add(r2)
    and64 r1, 252645135                             r1 &= 252645135   ///  r1 = r1.and(252645135)
    mul64 r1, 16843009                              r1 *= 16843009   ///  r1 = r1.wrapping_mul(16843009 as u64)
    rsh64 r1, 26                                    r1 >>= 26   ///  r1 = r1.wrapping_shr(26)
    and64 r1, 63                                    r1 &= 63   ///  r1 = r1.and(63)
    add64 r1, -2                                    r1 += -2   ///  r1 = r1.wrapping_add(-2 as i32 as i64 as u64)
    mov64 r2, 11                                    r2 = 11 as i32 as i64 as u64
    jgt r2, r1, lbb_25658                           if r2 > r1 { pc += 4 }
lbb_25654:
    mov64 r2, 10                                    r2 = 10 as i32 as i64 as u64
    lddw r3, 0x1000421e0 --> b"\x00\x00\x00\x00?\x08\x04\x00\x1a\x00\x00\x00\x00\x00\x00\x008\x00\x00\x0…        r3 load str located at 4295238112
    call function_28325                     
lbb_25658:
    mov64 r2, r10                                   r2 = r10
    add64 r2, -10                                   r2 += -10   ///  r2 = r2.wrapping_add(-10 as i32 as i64 as u64)
    add64 r2, r1                                    r2 += r1   ///  r2 = r2.wrapping_add(r1)
    mov64 r3, 123                                   r3 = 123 as i32 as i64 as u64
    stxb [r2+0x2], r3                       
    mov64 r3, 30044                                 r3 = 30044 as i32 as i64 as u64
    stxh [r2+0x0], r3                       
    ldxh r2, [r10-0x2]                      
    stxh [r6+0x8], r2                       
    ldxdw r2, [r10-0xa]                     
    stxdw [r6+0x0], r2                      
    mov64 r2, 10                                    r2 = 10 as i32 as i64 as u64
    stxb [r6+0xb], r2                       
    stxb [r6+0xa], r1                       
    ja lbb_25679                                    if true { pc += 6 }
lbb_25673:
    mov64 r2, 512                                   r2 = 512 as i32 as i64 as u64
    stxh [r1+0xa], r2                       
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
    stxdw [r1+0x2], r2                      
    mov64 r2, 10076                                 r2 = 10076 as i32 as i64 as u64
lbb_25678:
    stxh [r1+0x0], r2                       
lbb_25679:
    exit                                    
lbb_25680:
    mov64 r3, r10                                   r3 = r10
    add64 r3, -10                                   r3 += -10   ///  r3 = r3.wrapping_add(-10 as i32 as i64 as u64)
    add64 r3, r2                                    r3 += r2   ///  r3 = r3.wrapping_add(r2)
    mov64 r4, 123                                   r4 = 123 as i32 as i64 as u64
    stxb [r3+0x2], r4                       
    mov64 r4, 30044                                 r4 = 30044 as i32 as i64 as u64
    stxh [r3+0x0], r4                       
    ldxh r3, [r10-0x2]                      
    stxh [r1+0x8], r3                       
    ldxdw r3, [r10-0xa]                     
    stxdw [r1+0x0], r3                      
    mov64 r3, 10                                    r3 = 10 as i32 as i64 as u64
    stxb [r1+0xb], r3                       
    stxb [r1+0xa], r2                       
    ja lbb_25679                                    if true { pc += -16 }

function_25695:
    mov64 r3, r1                                    r3 = r1
    lddw r1, 0x10003fea9 --> b"called `Option::unwrap()` on a `None` value"        r1 load str located at 4295229097
    mov64 r2, 43                                    r2 = 43 as i32 as i64 as u64
    call function_25816                     

function_25700:
    mov64 r9, r1                                    r9 = r1
    ldxdw r6, [r2+0x20]                     
    ldxdw r7, [r2+0x28]                     
    ldxdw r4, [r7+0x18]                     
    mov64 r1, r6                                    r1 = r6
    lddw r2, 0x10003fed4 --> b"panicked at "        r2 load str located at 4295229140
    mov64 r3, 12                                    r3 = 12 as i32 as i64 as u64
    stxdw [r10-0x78], r4                    
    callx r4                                
    mov64 r8, 1                                     r8 = 1 as i32 as i64 as u64
    jne r0, 0, lbb_25803                            if r0 != (0 as i32 as i64 as u64) { pc += 91 }
    ldxdw r1, [r9+0x18]                     
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
    stxdw [r10-0x40], r2                    
    lddw r2, 0x100041e80 --> b"\x01\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\…        r2 load str located at 4295237248
    stxdw [r10-0x60], r2                    
    mov64 r2, 3                                     r2 = 3 as i32 as i64 as u64
    stxdw [r10-0x58], r2                    
    stxdw [r10-0x48], r2                    
    mov64 r2, r10                                   r2 = r10
    add64 r2, -48                                   r2 += -48   ///  r2 = r2.wrapping_add(-48 as i32 as i64 as u64)
    stxdw [r10-0x50], r2                    
    mov64 r2, r1                                    r2 = r1
    add64 r2, 20                                    r2 += 20   ///  r2 = r2.wrapping_add(20 as i32 as i64 as u64)
    stxdw [r10-0x10], r2                    
    lddw r2, 0x10003b160 --> b"\xbf#\x00\x00\x00\x00\x00\x00a\x11\x00\x00\x00\x00\x00\x00\xb7\x02\x00\x0…        r2 load str located at 4295209312
    stxdw [r10-0x8], r2                     
    stxdw [r10-0x18], r2                    
    mov64 r2, r1                                    r2 = r1
    add64 r2, 16                                    r2 += 16   ///  r2 = r2.wrapping_add(16 as i32 as i64 as u64)
    stxdw [r10-0x20], r2                    
    lddw r2, 0x10003b258 --> b"\xbf$\x00\x00\x00\x00\x00\x00y\x13\x08\x00\x00\x00\x00\x00y\x12\x00\x00\x…        r2 load str located at 4295209560
    stxdw [r10-0x28], r2                    
    stxdw [r10-0x30], r1                    
    mov64 r3, r10                                   r3 = r10
    add64 r3, -96                                   r3 += -96   ///  r3 = r3.wrapping_add(-96 as i32 as i64 as u64)
    mov64 r1, r6                                    r1 = r6
    mov64 r2, r7                                    r2 = r7
    call function_26898                     
    jne r0, 0, lbb_25803                            if r0 != (0 as i32 as i64 as u64) { pc += 59 }
    mov64 r1, r6                                    r1 = r6
    lddw r2, 0x10003fea8 --> b":"                   r2 load str located at 4295229096
    mov64 r3, 1                                     r3 = 1 as i32 as i64 as u64
    ldxdw r4, [r10-0x78]                    
    callx r4                                
    jne r0, 0, lbb_25803                            if r0 != (0 as i32 as i64 as u64) { pc += 52 }
    ldxdw r1, [r9+0x10]                     
    jeq r1, 0, lbb_25772                            if r1 == (0 as i32 as i64 as u64) { pc += 19 }
    mov64 r9, r1                                    r9 = r1
    mov64 r1, r6                                    r1 = r6
    lddw r2, 0x10003fee0 --> b"\x0a"                r2 load str located at 4295229152
    mov64 r3, 1                                     r3 = 1 as i32 as i64 as u64
    ldxdw r4, [r10-0x78]                    
    callx r4                                
    jne r0, 0, lbb_25803                            if r0 != (0 as i32 as i64 as u64) { pc += 42 }
    mov64 r8, r10                                   r8 = r10
    add64 r8, -48                                   r8 += -48   ///  r8 = r8.wrapping_add(-48 as i32 as i64 as u64)
    mov64 r1, r8                                    r1 = r8
    mov64 r2, r9                                    r2 = r9
    mov64 r3, 48                                    r3 = 48 as i32 as i64 as u64
    call function_30349                     
    mov64 r1, r6                                    r1 = r6
    mov64 r2, r7                                    r2 = r7
    mov64 r3, r8                                    r3 = r8
    call function_26898                     
    ja lbb_25802                                    if true { pc += 30 }
lbb_25772:
    ldxdw r7, [r9+0x0]                      
    ldxdw r1, [r9+0x8]                      
    ldxdw r3, [r1+0x18]                     
    mov64 r1, r10                                   r1 = r10
    add64 r1, -112                                  r1 += -112   ///  r1 = r1.wrapping_add(-112 as i32 as i64 as u64)
    mov64 r2, r7                                    r2 = r7
    callx r3                                
    mov64 r8, 0                                     r8 = 0 as i32 as i64 as u64
    ldxdw r1, [r10-0x70]                    
    lddw r2, 0xb98b1b7157a64178                     r2 load str located at -5076933981314334344
    jne r1, r2, lbb_25803                           if r1 != r2 { pc += 19 }
    ldxdw r1, [r10-0x68]                    
    lddw r2, 0x63eb502cd6cb5d6d                     r2 load str located at 7199936582794304877
    jeq r1, r2, lbb_25789                           if r1 == r2 { pc += 1 }
    ja lbb_25803                                    if true { pc += 14 }
lbb_25789:
    mov64 r8, 1                                     r8 = 1 as i32 as i64 as u64
    mov64 r1, r6                                    r1 = r6
    lddw r2, 0x10003fee0 --> b"\x0a"                r2 load str located at 4295229152
    mov64 r3, 1                                     r3 = 1 as i32 as i64 as u64
    ldxdw r4, [r10-0x78]                    
    callx r4                                
    jne r0, 0, lbb_25803                            if r0 != (0 as i32 as i64 as u64) { pc += 6 }
    ldxdw r3, [r7+0x8]                      
    ldxdw r2, [r7+0x0]                      
    mov64 r1, r6                                    r1 = r6
    ldxdw r4, [r10-0x78]                    
    callx r4                                
lbb_25802:
    mov64 r8, r0                                    r8 = r0
lbb_25803:
    mov64 r0, r8                                    r0 = r8
    exit                                    

function_25805:
    stxdw [r10-0x10], r2                    
    stxdw [r10-0x18], r1                    
    lddw r1, 0x100041eb0 --> b"\x00\x00\x00\x00 \xa9\x02\x00\x00\x00\x00\x00\x00\x00\x00\x00\x01\x00\x00…        r1 load str located at 4295237296
    stxdw [r10-0x20], r1                    
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    stxh [r10-0x8], r1                      
    stxdw [r10-0x28], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -40                                   r1 += -40   ///  r1 = r1.wrapping_add(-40 as i32 as i64 as u64)
    call function_21174                     

function_25816:
    mov64 r4, 1                                     r4 = 1 as i32 as i64 as u64
    stxdw [r10-0x38], r4                    
    mov64 r4, r10                                   r4 = r10
    add64 r4, -16                                   r4 += -16   ///  r4 = r4.wrapping_add(-16 as i32 as i64 as u64)
    stxdw [r10-0x40], r4                    
    mov64 r4, 0                                     r4 = 0 as i32 as i64 as u64
    stxdw [r10-0x20], r4                    
    stxdw [r10-0x28], r4                    
    mov64 r4, 8                                     r4 = 8 as i32 as i64 as u64
    stxdw [r10-0x30], r4                    
    stxdw [r10-0x8], r2                     
    stxdw [r10-0x10], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -64                                   r1 += -64   ///  r1 = r1.wrapping_add(-64 as i32 as i64 as u64)
    mov64 r2, r3                                    r2 = r3
    call function_25805                     

function_25832:
    stxdw [r10-0x58], r2                    
    stxdw [r10-0x60], r1                    
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    stxdw [r10-0x30], r1                    
    lddw r1, 0x100041ed0 --> b"\x00\x00\x00\x00\xd8\xed\x03\x00 \x00\x00\x00\x00\x00\x00\x00\x00\x00\x00…        r1 load str located at 4295237328
    stxdw [r10-0x50], r1                    
    mov64 r1, 2                                     r1 = 2 as i32 as i64 as u64
    stxdw [r10-0x48], r1                    
    stxdw [r10-0x38], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -32                                   r1 += -32   ///  r1 = r1.wrapping_add(-32 as i32 as i64 as u64)
    stxdw [r10-0x40], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -96                                   r1 += -96   ///  r1 = r1.wrapping_add(-96 as i32 as i64 as u64)
    stxdw [r10-0x10], r1                    
    lddw r1, 0x10003b1e0 --> b"\xbf#\x00\x00\x00\x00\x00\x00y\x11\x00\x00\x00\x00\x00\x00\xb7\x02\x00\x0…        r1 load str located at 4295209440
    stxdw [r10-0x8], r1                     
    stxdw [r10-0x18], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -88                                   r1 += -88   ///  r1 = r1.wrapping_add(-88 as i32 as i64 as u64)
    stxdw [r10-0x20], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -80                                   r1 += -80   ///  r1 = r1.wrapping_add(-80 as i32 as i64 as u64)
    mov64 r2, r3                                    r2 = r3
    call function_25805                     

function_25859:
    stxdw [r10-0x8], r2                     
    stxdw [r10-0x10], r1                    
    stxdw [r10-0xff8], r3                   
    lddw r1, 0x100041a40 --> b"\x00\x00\x00\x00\x96\xf5\x03\x00!\x00\x00\x00\x00\x00\x00\x00N\x00\x00\x0…        r1 load str located at 4295236160
    stxdw [r10-0xff0], r1                   
    lddw r1, 0x100041ef0 --> b"\x00\x00\x00\x00\x18\xa9\x02\x00\x08\x00\x00\x00\x00\x00\x00\x00\x08\x00\…        r1 load str located at 4295237360
    stxdw [r10-0x1000], r1                  
    mov64 r2, r10                                   r2 = r10
    add64 r2, -16                                   r2 += -16   ///  r2 = r2.wrapping_add(-16 as i32 as i64 as u64)
    mov64 r4, r10                                   r4 = r10
    add64 r4, -8                                    r4 += -8   ///  r4 = r4.wrapping_add(-8 as i32 as i64 as u64)
    mov64 r5, r10                                   r5 = r10
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    lddw r3, 0x100041ef0 --> b"\x00\x00\x00\x00\x18\xa9\x02\x00\x08\x00\x00\x00\x00\x00\x00\x00\x08\x00\…        r3 load str located at 4295237360
    call function_25877                     

function_25877:
    stxdw [r10-0xc8], r3                    
    stxdw [r10-0xd0], r2                    
    stxdw [r10-0xc0], r4                    
    ldxdw r2, [r5-0x1000]                   
    stxdw [r10-0xb8], r2                    
    ldxdw r6, [r5-0xff0]                    
    ldxdw r2, [r5-0xff8]                    
    and64 r1, 255                                   r1 &= 255   ///  r1 = r1.and(255)
    jeq r1, 0, lbb_25929                            if r1 == (0 as i32 as i64 as u64) { pc += 43 }
    jeq r1, 1, lbb_25926                            if r1 == (1 as i32 as i64 as u64) { pc += 39 }
    lddw r1, 0x10003fef7 --> b"matches right` failed\x0a  left: \x0a right: \x0a  left: : "        r1 load str located at 4295229175
    stxdw [r10-0xb0], r1                    
    mov64 r1, 7                                     r1 = 7 as i32 as i64 as u64
    stxdw [r10-0xa8], r1                    
    ldxdw r1, [r2+0x0]                      
    jne r1, 0, lbb_25895                            if r1 != (0 as i32 as i64 as u64) { pc += 1 }
    ja lbb_25936                                    if true { pc += 41 }
lbb_25895:
    mov64 r7, r10                                   r7 = r10
    add64 r7, -160                                  r7 += -160   ///  r7 = r7.wrapping_add(-160 as i32 as i64 as u64)
    mov64 r1, r7                                    r1 = r7
    mov64 r3, 48                                    r3 = 48 as i32 as i64 as u64
    call function_30349                     
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    stxdw [r10-0x10], r1                    
    lddw r1, 0x100041f40 --> b"\x00\x00\x00\x00\x10\xe7\x03\x00\x10\x00\x00\x00\x00\x00\x00\x00\x00\x00\…        r1 load str located at 4295237440
    stxdw [r10-0x30], r1                    
    mov64 r1, 4                                     r1 = 4 as i32 as i64 as u64
    stxdw [r10-0x28], r1                    
    stxdw [r10-0x18], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -112                                  r1 += -112   ///  r1 = r1.wrapping_add(-112 as i32 as i64 as u64)
    stxdw [r10-0x20], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -192                                  r1 += -192   ///  r1 = r1.wrapping_add(-192 as i32 as i64 as u64)
    stxdw [r10-0x40], r1                    
    lddw r1, 0x10003b208 --> b"y\x13\x00\x00\x00\x00\x00\x00y\x11\x08\x00\x00\x00\x00\x00y\x14\x18\x00\x…        r1 load str located at 4295209480
    stxdw [r10-0x38], r1                    
    stxdw [r10-0x48], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -208                                  r1 += -208   ///  r1 = r1.wrapping_add(-208 as i32 as i64 as u64)
    stxdw [r10-0x50], r1                    
    lddw r1, 0x100034980 --> b"\xbf\x13\x00\x00\x00\x00\x00\x00y$(\x00\x00\x00\x00\x00y! \x00\x00\x00\x0…        r1 load str located at 4295182720
    stxdw [r10-0x58], r1                    
    stxdw [r10-0x60], r7                    
    ja lbb_25957                                    if true { pc += 31 }
lbb_25926:
    lddw r1, 0x10003fef5 --> b"!=matches right` failed\x0a  left: \x0a right: \x0a  left: "        r1 load str located at 4295229173
    ja lbb_25931                                    if true { pc += 2 }
lbb_25929:
    lddw r1, 0x10003fef3 --> b"==!=matches right` failed\x0a  left: \x0a right: \x0a  left"        r1 load str located at 4295229171
lbb_25931:
    stxdw [r10-0xb0], r1                    
    mov64 r1, 2                                     r1 = 2 as i32 as i64 as u64
    stxdw [r10-0xa8], r1                    
    ldxdw r1, [r2+0x0]                      
    jne r1, 0, lbb_25895                            if r1 != (0 as i32 as i64 as u64) { pc += -41 }
lbb_25936:
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    stxdw [r10-0x10], r1                    
    lddw r1, 0x100041f10 --> b"\x00\x00\x00\x00\x10\xe7\x03\x00\x10\x00\x00\x00\x00\x00\x00\x00\x00\x00\…        r1 load str located at 4295237392
    stxdw [r10-0x30], r1                    
    mov64 r1, 3                                     r1 = 3 as i32 as i64 as u64
    stxdw [r10-0x28], r1                    
    stxdw [r10-0x18], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -112                                  r1 += -112   ///  r1 = r1.wrapping_add(-112 as i32 as i64 as u64)
    stxdw [r10-0x20], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -192                                  r1 += -192   ///  r1 = r1.wrapping_add(-192 as i32 as i64 as u64)
    stxdw [r10-0x50], r1                    
    lddw r1, 0x10003b208 --> b"y\x13\x00\x00\x00\x00\x00\x00y\x11\x08\x00\x00\x00\x00\x00y\x14\x18\x00\x…        r1 load str located at 4295209480
    stxdw [r10-0x48], r1                    
    stxdw [r10-0x58], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -208                                  r1 += -208   ///  r1 = r1.wrapping_add(-208 as i32 as i64 as u64)
    stxdw [r10-0x60], r1                    
lbb_25957:
    lddw r1, 0x10003b258 --> b"\xbf$\x00\x00\x00\x00\x00\x00y\x13\x08\x00\x00\x00\x00\x00y\x12\x00\x00\x…        r1 load str located at 4295209560
    stxdw [r10-0x68], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -176                                  r1 += -176   ///  r1 = r1.wrapping_add(-176 as i32 as i64 as u64)
    stxdw [r10-0x70], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -48                                   r1 += -48   ///  r1 = r1.wrapping_add(-48 as i32 as i64 as u64)
    mov64 r2, r6                                    r2 = r6
    call function_25805                     

function_25967:
    stxdw [r10-0x68], r2                    
    stxdw [r10-0x70], r1                    
    stxdw [r10-0x58], r4                    
    stxdw [r10-0x60], r3                    
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    stxdw [r10-0x30], r1                    
    lddw r1, 0x100041f80 --> b"\x01\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\…        r1 load str located at 4295237504
    stxdw [r10-0x50], r1                    
    mov64 r1, 2                                     r1 = 2 as i32 as i64 as u64
    stxdw [r10-0x48], r1                    
    stxdw [r10-0x38], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -32                                   r1 += -32   ///  r1 = r1.wrapping_add(-32 as i32 as i64 as u64)
    stxdw [r10-0x40], r1                    
    lddw r1, 0x10003b208 --> b"y\x13\x00\x00\x00\x00\x00\x00y\x11\x08\x00\x00\x00\x00\x00y\x14\x18\x00\x…        r1 load str located at 4295209480
    stxdw [r10-0x8], r1                     
    mov64 r1, r10                                   r1 = r10
    add64 r1, -96                                   r1 += -96   ///  r1 = r1.wrapping_add(-96 as i32 as i64 as u64)
    stxdw [r10-0x10], r1                    
    lddw r1, 0x10003b258 --> b"\xbf$\x00\x00\x00\x00\x00\x00y\x13\x08\x00\x00\x00\x00\x00y\x12\x00\x00\x…        r1 load str located at 4295209560
    stxdw [r10-0x18], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -112                                  r1 += -112   ///  r1 = r1.wrapping_add(-112 as i32 as i64 as u64)
    stxdw [r10-0x20], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -80                                   r1 += -80   ///  r1 = r1.wrapping_add(-80 as i32 as i64 as u64)
    mov64 r2, r5                                    r2 = r5
    call function_25805                     

function_25998:
    mov64 r7, r3                                    r7 = r3
    mov64 r6, 0                                     r6 = 0 as i32 as i64 as u64
    stxdw [r10-0x18], r2                    
    add64 r2, -1                                    r2 += -1   ///  r2 = r2.wrapping_add(-1 as i32 as i64 as u64)
    stxdw [r10-0x40], r2                    
    ldxdw r2, [r1+0x8]                      
    stxdw [r10-0x28], r2                    
    ldxdw r2, [r1+0x0]                      
    stxdw [r10-0x30], r2                    
    ldxdw r1, [r1+0x10]                     
    stxdw [r10-0x20], r1                    
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    stxdw [r10-0x8], r1                     
    ja lbb_26031                                    if true { pc += 19 }
lbb_26012:
    ldxdw r2, [r10-0x18]                    
    ldxdw r3, [r10-0x8]                     
    add64 r2, r3                                    r2 += r3   ///  r2 = r2.wrapping_add(r3)
    sub64 r9, r3                                    r9 -= r3   ///  r9 = r9.wrapping_sub(r3)
    and64 r1, 1                                     r1 &= 1   ///  r1 = r1.and(1)
    ldxdw r3, [r10-0x20]                    
    stxb [r3+0x0], r1                       
    ldxdw r1, [r10-0x28]                    
    ldxdw r4, [r1+0x18]                     
    ldxdw r1, [r10-0x30]                    
    mov64 r3, r9                                    r3 = r9
    callx r4                                
    mov64 r1, r0                                    r1 = r0
    neg64 r0                                        r0 = -r0   ///  r0 = (r0 as i64).wrapping_neg() as u64
    jne r1, 0, lbb_26158                            if r1 != (0 as i32 as i64 as u64) { pc += 131 }
    ldxdw r1, [r10-0x10]                    
    xor64 r1, 1                                     r1 ^= 1   ///  r1 = r1.xor(1)
    stxdw [r10-0x8], r8                     
    jne r1, 0, lbb_26158                            if r1 != (0 as i32 as i64 as u64) { pc += 127 }
lbb_26031:
    jgt r6, r7, lbb_26129                           if r6 > r7 { pc += 97 }
    mov64 r1, r6                                    r1 = r6
lbb_26033:
    ldxdw r2, [r10-0x18]                    
    add64 r2, r1                                    r2 += r1   ///  r2 = r2.wrapping_add(r1)
    mov64 r3, r7                                    r3 = r7
    sub64 r3, r1                                    r3 -= r1   ///  r3 = r3.wrapping_sub(r1)
    mov64 r4, 16                                    r4 = 16 as i32 as i64 as u64
    jgt r4, r3, lbb_26099                           if r4 > r3 { pc += 60 }
    mov64 r6, r2                                    r6 = r2
    add64 r6, 7                                     r6 += 7   ///  r6 = r6.wrapping_add(7 as i32 as i64 as u64)
    and64 r6, -8                                    r6 &= -8   ///  r6 = r6.and(-8)
    mov64 r4, r6                                    r4 = r6
    sub64 r4, r2                                    r4 -= r2   ///  r4 = r4.wrapping_sub(r2)
    jeq r4, 0, lbb_26052                            if r4 == (0 as i32 as i64 as u64) { pc += 7 }
    mov64 r5, 0                                     r5 = 0 as i32 as i64 as u64
lbb_26046:
    mov64 r0, r2                                    r0 = r2
    add64 r0, r5                                    r0 += r5   ///  r0 = r0.wrapping_add(r5)
    ldxb r0, [r0+0x0]                       
    jeq r0, 10, lbb_26112                           if r0 == (10 as i32 as i64 as u64) { pc += 62 }
    add64 r5, 1                                     r5 += 1   ///  r5 = r5.wrapping_add(1 as i32 as i64 as u64)
    jgt r4, r5, lbb_26046                           if r4 > r5 { pc += -6 }
lbb_26052:
    stxdw [r10-0x38], r1                    
    mov64 r1, r3                                    r1 = r3
    add64 r1, -16                                   r1 += -16   ///  r1 = r1.wrapping_add(-16 as i32 as i64 as u64)
    stxdw [r10-0x10], r1                    
    jgt r4, r1, lbb_26085                           if r4 > r1 { pc += 28 }
    mov64 r0, 8                                     r0 = 8 as i32 as i64 as u64
    add64 r0, r6                                    r0 += r6   ///  r0 = r0.wrapping_add(r6)
    ja lbb_26064                                    if true { pc += 4 }
lbb_26060:
    add64 r0, 16                                    r0 += 16   ///  r0 = r0.wrapping_add(16 as i32 as i64 as u64)
    add64 r4, 16                                    r4 += 16   ///  r4 = r4.wrapping_add(16 as i32 as i64 as u64)
    ldxdw r1, [r10-0x10]                    
    jgt r4, r1, lbb_26085                           if r4 > r1 { pc += 21 }
lbb_26064:
    ldxdw r6, [r0-0x8]                      
    mov64 r8, r6                                    r8 = r6
    lddw r1, 0xa0a0a0a0a0a0a0a                      r1 load str located at 723401728380766730
    xor64 r8, r1                                    r8 ^= r1   ///  r8 = r8.xor(r1)
    lddw r5, 0xfefefefefefefeff                     r5 load str located at -72340172838076673
    add64 r8, r5                                    r8 += r5   ///  r8 = r8.wrapping_add(r5)
    xor64 r6, -1                                    r6 ^= -1   ///  r6 = r6.xor(-1)
    and64 r8, r6                                    r8 &= r6   ///  r8 = r8.and(r6)
    ldxdw r6, [r0+0x0]                      
    mov64 r9, r6                                    r9 = r6
    xor64 r9, r1                                    r9 ^= r1   ///  r9 = r9.xor(r1)
    add64 r9, r5                                    r9 += r5   ///  r9 = r9.wrapping_add(r5)
    xor64 r6, -1                                    r6 ^= -1   ///  r6 = r6.xor(-1)
    and64 r9, r6                                    r9 &= r6   ///  r9 = r9.and(r6)
    or64 r9, r8                                     r9 |= r8   ///  r9 = r9.or(r8)
    lddw r1, 0x8080808080808080                     r1 load str located at -9187201950435737472
    and64 r9, r1                                    r9 &= r1   ///  r9 = r9.and(r1)
    jeq r9, 0, lbb_26060                            if r9 == (0 as i32 as i64 as u64) { pc += -25 }
lbb_26085:
    mov64 r6, r7                                    r6 = r7
    ldxdw r1, [r10-0x38]                    
    jeq r3, r4, lbb_26129                           if r3 == r4 { pc += 41 }
    sub64 r3, r4                                    r3 -= r4   ///  r3 = r3.wrapping_sub(r4)
    add64 r2, r4                                    r2 += r4   ///  r2 = r2.wrapping_add(r4)
    mov64 r5, 0                                     r5 = 0 as i32 as i64 as u64
lbb_26091:
    mov64 r0, r2                                    r0 = r2
    add64 r0, r5                                    r0 += r5   ///  r0 = r0.wrapping_add(r5)
    ldxb r0, [r0+0x0]                       
    jeq r0, 10, lbb_26110                           if r0 == (10 as i32 as i64 as u64) { pc += 15 }
    add64 r5, 1                                     r5 += 1   ///  r5 = r5.wrapping_add(1 as i32 as i64 as u64)
    mov64 r6, r7                                    r6 = r7
    jgt r3, r5, lbb_26091                           if r3 > r5 { pc += -7 }
    ja lbb_26129                                    if true { pc += 30 }
lbb_26099:
    mov64 r6, r7                                    r6 = r7
    jeq r7, r1, lbb_26129                           if r7 == r1 { pc += 28 }
    mov64 r5, 0                                     r5 = 0 as i32 as i64 as u64
lbb_26102:
    mov64 r4, r2                                    r4 = r2
    add64 r4, r5                                    r4 += r5   ///  r4 = r4.wrapping_add(r5)
    ldxb r4, [r4+0x0]                       
    jeq r4, 10, lbb_26112                           if r4 == (10 as i32 as i64 as u64) { pc += 6 }
    add64 r5, 1                                     r5 += 1   ///  r5 = r5.wrapping_add(1 as i32 as i64 as u64)
    mov64 r6, r7                                    r6 = r7
    jgt r3, r5, lbb_26102                           if r3 > r5 { pc += -7 }
    ja lbb_26129                                    if true { pc += 19 }
lbb_26110:
    add64 r4, r5                                    r4 += r5   ///  r4 = r4.wrapping_add(r5)
    mov64 r5, r4                                    r5 = r4
lbb_26112:
    mov64 r2, r1                                    r2 = r1
    add64 r2, r5                                    r2 += r5   ///  r2 = r2.wrapping_add(r5)
    mov64 r6, r2                                    r6 = r2
    add64 r6, 1                                     r6 += 1   ///  r6 = r6.wrapping_add(1 as i32 as i64 as u64)
    jgt r7, r2, lbb_26120                           if r7 > r2 { pc += 3 }
lbb_26117:
    mov64 r1, r6                                    r1 = r6
    jgt r6, r7, lbb_26129                           if r6 > r7 { pc += 10 }
    ja lbb_26033                                    if true { pc += -87 }
lbb_26120:
    ldxdw r2, [r10-0x18]                    
    add64 r2, r1                                    r2 += r1   ///  r2 = r2.wrapping_add(r1)
    add64 r2, r5                                    r2 += r5   ///  r2 = r2.wrapping_add(r5)
    mov64 r0, 1                                     r0 = 1 as i32 as i64 as u64
    ldxb r1, [r2+0x0]                       
    mov64 r8, r6                                    r8 = r6
    mov64 r9, r6                                    r9 = r6
    jeq r1, 10, lbb_26134                           if r1 == (10 as i32 as i64 as u64) { pc += 6 }
    ja lbb_26117                                    if true { pc += -12 }
lbb_26129:
    mov64 r0, 0                                     r0 = 0 as i32 as i64 as u64
    ldxdw r1, [r10-0x8]                     
    mov64 r8, r1                                    r8 = r1
    mov64 r9, r7                                    r9 = r7
    jeq r1, r7, lbb_26158                           if r1 == r7 { pc += 24 }
lbb_26134:
    stxdw [r10-0x10], r0                    
    ldxdw r1, [r10-0x20]                    
    ldxb r1, [r1+0x0]                       
    jeq r1, 0, lbb_26148                            if r1 == (0 as i32 as i64 as u64) { pc += 10 }
    ldxdw r1, [r10-0x28]                    
    ldxdw r4, [r1+0x18]                     
    ldxdw r1, [r10-0x30]                    
    lddw r2, 0x10003edd2 --> b"    "                r2 load str located at 4295224786
    mov64 r3, 4                                     r3 = 4 as i32 as i64 as u64
    callx r4                                
    mov64 r1, r0                                    r1 = r0
    mov64 r0, 1                                     r0 = 1 as i32 as i64 as u64
    jne r1, 0, lbb_26158                            if r1 != (0 as i32 as i64 as u64) { pc += 10 }
lbb_26148:
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    ldxdw r2, [r10-0x8]                     
    jeq r9, r2, lbb_26012                           if r9 == r2 { pc += -139 }
    ldxdw r1, [r10-0x40]                    
    add64 r1, r9                                    r1 += r9   ///  r1 = r1.wrapping_add(r9)
    ldxb r2, [r1+0x0]                       
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    jeq r2, 10, lbb_26012                           if r2 == (10 as i32 as i64 as u64) { pc += -144 }
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    ja lbb_26012                                    if true { pc += -146 }
lbb_26158:
    and64 r0, 1                                     r0 &= 1   ///  r0 = r0.and(1)
    exit                                    

function_26160:
    ldxdw r7, [r1+0x8]                      
    ldxdw r6, [r1+0x0]                      
    ldxdw r8, [r1+0x10]                     
    ldxb r1, [r8+0x0]                       
    jne r1, 0, lbb_26176                            if r1 != (0 as i32 as i64 as u64) { pc += 11 }
lbb_26165:
    mov64 r3, r2                                    r3 = r2
    lsh64 r3, 32                                    r3 <<= 32   ///  r3 = r3.wrapping_shl(32)
    rsh64 r3, 32                                    r3 >>= 32   ///  r3 = r3.wrapping_shr(32)
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    jeq r3, 10, lbb_26171                           if r3 == (10 as i32 as i64 as u64) { pc += 1 }
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
lbb_26171:
    stxb [r8+0x0], r1                       
    ldxdw r3, [r7+0x20]                     
    mov64 r1, r6                                    r1 = r6
    callx r3                                
    ja lbb_26187                                    if true { pc += 11 }
lbb_26176:
    ldxdw r4, [r7+0x18]                     
    mov64 r1, r6                                    r1 = r6
    mov64 r9, r2                                    r9 = r2
    lddw r2, 0x10003edd2 --> b"    "                r2 load str located at 4295224786
    mov64 r3, 4                                     r3 = 4 as i32 as i64 as u64
    callx r4                                
    mov64 r2, r9                                    r2 = r9
    mov64 r1, r0                                    r1 = r0
    mov64 r0, 1                                     r0 = 1 as i32 as i64 as u64
    jeq r1, 0, lbb_26165                            if r1 == (0 as i32 as i64 as u64) { pc += -22 }
lbb_26187:
    exit                                    

function_26188:
    mov64 r8, r2                                    r8 = r2
    mov64 r6, r1                                    r6 = r1
    mov64 r2, 1                                     r2 = 1 as i32 as i64 as u64
    ldxb r1, [r6+0x8]                       
    mov64 r7, 1                                     r7 = 1 as i32 as i64 as u64
    jne r1, 0, lbb_26309                            if r1 != (0 as i32 as i64 as u64) { pc += 115 }
    stxdw [r10-0x68], r3                    
    ldxb r2, [r6+0x9]                       
    ldxdw r9, [r6+0x0]                      
    ldxw r1, [r9+0x34]                      
    mov64 r3, r1                                    r3 = r1
    and64 r3, 4                                     r3 &= 4   ///  r3 = r3.and(4)
    stxdw [r10-0x70], r4                    
    stxdw [r10-0x78], r5                    
    jne r3, 0, lbb_26243                            if r3 != (0 as i32 as i64 as u64) { pc += 40 }
    mov64 r1, r2                                    r1 = r2
    lddw r2, 0x10003ff29 --> b" { ,  {\x0a,\x0a} }((\x0a,library/core/src/fmt/num.rs0x0001"        r2 load str located at 4295229225
    jeq r1, 0, lbb_26209                            if r1 == (0 as i32 as i64 as u64) { pc += 2 }
    lddw r2, 0x10003ff2c --> b",  "                 r2 load str located at 4295229228
lbb_26209:
    mov64 r3, 3                                     r3 = 3 as i32 as i64 as u64
    jeq r1, 0, lbb_26212                            if r1 == (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r3, 2                                     r3 = 2 as i32 as i64 as u64
lbb_26212:
    ldxdw r1, [r9+0x20]                     
    ldxdw r4, [r9+0x28]                     
    ldxdw r4, [r4+0x18]                     
    callx r4                                
    mov64 r2, 1                                     r2 = 1 as i32 as i64 as u64
    ldxdw r3, [r10-0x68]                    
    jne r0, 0, lbb_26309                            if r0 != (0 as i32 as i64 as u64) { pc += 90 }
    ldxdw r1, [r9+0x20]                     
    ldxdw r2, [r9+0x28]                     
    ldxdw r4, [r2+0x18]                     
    mov64 r2, r8                                    r2 = r8
    callx r4                                
    mov64 r2, 1                                     r2 = 1 as i32 as i64 as u64
    jne r0, 0, lbb_26309                            if r0 != (0 as i32 as i64 as u64) { pc += 83 }
    ldxdw r1, [r9+0x20]                     
    ldxdw r2, [r9+0x28]                     
    ldxdw r4, [r2+0x18]                     
    lddw r2, 0x10003ff27 --> b": "                  r2 load str located at 4295229223
    mov64 r3, 2                                     r3 = 2 as i32 as i64 as u64
    callx r4                                
    ldxdw r3, [r10-0x78]                    
    ldxdw r1, [r10-0x70]                    
    mov64 r2, 1                                     r2 = 1 as i32 as i64 as u64
    jne r0, 0, lbb_26309                            if r0 != (0 as i32 as i64 as u64) { pc += 72 }
    ldxdw r3, [r3+0x18]                     
    mov64 r2, r9                                    r2 = r9
    callx r3                                
    mov64 r2, 1                                     r2 = 1 as i32 as i64 as u64
    mov64 r7, r0                                    r7 = r0
    ja lbb_26309                                    if true { pc += 66 }
lbb_26243:
    jeq r2, 0, lbb_26245                            if r2 == (0 as i32 as i64 as u64) { pc += 1 }
    ja lbb_26255                                    if true { pc += 10 }
lbb_26245:
    ldxdw r1, [r9+0x20]                     
    ldxdw r2, [r9+0x28]                     
    ldxdw r4, [r2+0x18]                     
    lddw r2, 0x10003ff2e --> b" {\x0a"              r2 load str located at 4295229230
    mov64 r3, 3                                     r3 = 3 as i32 as i64 as u64
    callx r4                                
    mov64 r2, 1                                     r2 = 1 as i32 as i64 as u64
    jne r0, 0, lbb_26309                            if r0 != (0 as i32 as i64 as u64) { pc += 55 }
    ldxw r1, [r9+0x34]                      
lbb_26255:
    stxb [r10-0x41], r7                     
    ldxdw r2, [r9+0x20]                     
    ldxdw r3, [r9+0x28]                     
    mov64 r4, r10                                   r4 = r10
    add64 r4, -65                                   r4 += -65   ///  r4 = r4.wrapping_add(-65 as i32 as i64 as u64)
    stxdw [r10-0x50], r4                    
    stxdw [r10-0x58], r3                    
    stxdw [r10-0x60], r2                    
    ldxdw r2, [r9+0x0]                      
    ldxdw r3, [r9+0x8]                      
    ldxdw r4, [r9+0x10]                     
    ldxdw r5, [r9+0x18]                     
    ldxw r0, [r9+0x30]                      
    ldxb r9, [r9+0x38]                      
    stxb [r10-0x8], r9                      
    stxw [r10-0x10], r0                     
    stxw [r10-0xc], r1                      
    lddw r1, 0x100041fa0 --> b"\x00\x00\x00\x00\x18\xa9\x02\x00\x18\x00\x00\x00\x00\x00\x00\x00\x08\x00\…        r1 load str located at 4295237536
    stxdw [r10-0x18], r1                    
    stxdw [r10-0x28], r5                    
    stxdw [r10-0x30], r4                    
    stxdw [r10-0x38], r3                    
    stxdw [r10-0x40], r2                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -96                                   r1 += -96   ///  r1 = r1.wrapping_add(-96 as i32 as i64 as u64)
    stxdw [r10-0x20], r1                    
    mov64 r2, r8                                    r2 = r8
    ldxdw r3, [r10-0x68]                    
    call function_25998                     
    jne r0, 0, lbb_26308                            if r0 != (0 as i32 as i64 as u64) { pc += 22 }
    mov64 r1, r10                                   r1 = r10
    add64 r1, -96                                   r1 += -96   ///  r1 = r1.wrapping_add(-96 as i32 as i64 as u64)
    lddw r2, 0x10003ff27 --> b": "                  r2 load str located at 4295229223
    mov64 r3, 2                                     r3 = 2 as i32 as i64 as u64
    call function_25998                     
    jne r0, 0, lbb_26308                            if r0 != (0 as i32 as i64 as u64) { pc += 15 }
    ldxdw r1, [r10-0x78]                    
    ldxdw r3, [r1+0x18]                     
    mov64 r2, r10                                   r2 = r10
    add64 r2, -64                                   r2 += -64   ///  r2 = r2.wrapping_add(-64 as i32 as i64 as u64)
    ldxdw r1, [r10-0x70]                    
    callx r3                                
    jne r0, 0, lbb_26308                            if r0 != (0 as i32 as i64 as u64) { pc += 8 }
    ldxdw r1, [r10-0x18]                    
    ldxdw r4, [r1+0x18]                     
    ldxdw r1, [r10-0x20]                    
    lddw r2, 0x10003ff31 --> b",\x0a"               r2 load str located at 4295229233
    mov64 r3, 2                                     r3 = 2 as i32 as i64 as u64
    callx r4                                
    mov64 r7, r0                                    r7 = r0
lbb_26308:
    mov64 r2, 1                                     r2 = 1 as i32 as i64 as u64
lbb_26309:
    stxb [r6+0x9], r2                       
    stxb [r6+0x8], r7                       
    mov64 r0, r6                                    r0 = r6
    exit                                    

function_26313:
    ldxb r2, [r1+0x8]                       
    ldxb r3, [r1+0x9]                       
    jne r3, 0, lbb_26321                            if r3 != (0 as i32 as i64 as u64) { pc += 5 }
    mov64 r1, r2                                    r1 = r2
    mov64 r0, 1                                     r0 = 1 as i32 as i64 as u64
    jne r1, 0, lbb_26344                            if r1 != (0 as i32 as i64 as u64) { pc += 25 }
    mov64 r0, 0                                     r0 = 0 as i32 as i64 as u64
    ja lbb_26344                                    if true { pc += 23 }
lbb_26321:
    mov64 r0, 1                                     r0 = 1 as i32 as i64 as u64
    jne r2, 0, lbb_26343                            if r2 != (0 as i32 as i64 as u64) { pc += 20 }
    mov64 r6, r1                                    r6 = r1
    ldxdw r2, [r1+0x0]                      
    ldxw r1, [r2+0x34]                      
    and64 r1, 4                                     r1 &= 4   ///  r1 = r1.and(4)
    jne r1, 0, lbb_26335                            if r1 != (0 as i32 as i64 as u64) { pc += 7 }
    ldxdw r1, [r2+0x20]                     
    ldxdw r2, [r2+0x28]                     
    ldxdw r4, [r2+0x18]                     
    lddw r2, 0x10003ff34 --> b" }"                  r2 load str located at 4295229236
    mov64 r3, 2                                     r3 = 2 as i32 as i64 as u64
    ja lbb_26341                                    if true { pc += 6 }
lbb_26335:
    ldxdw r1, [r2+0x20]                     
    ldxdw r2, [r2+0x28]                     
    ldxdw r4, [r2+0x18]                     
    lddw r2, 0x10003ff33 --> b"}"                   r2 load str located at 4295229235
    mov64 r3, 1                                     r3 = 1 as i32 as i64 as u64
lbb_26341:
    callx r4                                
    mov64 r1, r6                                    r1 = r6
lbb_26343:
    stxb [r1+0x8], r0                       
lbb_26344:
    and64 r0, 1                                     r0 &= 1   ///  r0 = r0.and(1)
    exit                                    

function_26346:
    mov64 r6, r1                                    r6 = r1
    mov64 r7, 1                                     r7 = 1 as i32 as i64 as u64
    ldxdw r9, [r6+0x0]                      
    ldxb r1, [r6+0x10]                      
    jne r1, 0, lbb_26439                            if r1 != (0 as i32 as i64 as u64) { pc += 88 }
    ldxdw r8, [r6+0x8]                      
    ldxw r1, [r8+0x34]                      
    mov64 r4, r1                                    r4 = r1
    and64 r4, 4                                     r4 &= 4   ///  r4 = r4.and(4)
    jne r4, 0, lbb_26378                            if r4 != (0 as i32 as i64 as u64) { pc += 22 }
    lddw r4, 0x10003ff36 --> b"((\x0a,library/core/src/fmt/num.rs0x00010203040506070"        r4 load str located at 4295229238
    jeq r9, 0, lbb_26361                            if r9 == (0 as i32 as i64 as u64) { pc += 2 }
    lddw r4, 0x10003ff2c --> b",  {\x0a,\x0a} }((\x0a,library/core/src/fmt/num.rs0x0001020"        r4 load str located at 4295229228
lbb_26361:
    stxdw [r10-0x68], r3                    
    stxdw [r10-0x70], r2                    
    mov64 r3, 1                                     r3 = 1 as i32 as i64 as u64
    jeq r9, 0, lbb_26366                            if r9 == (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r3, 2                                     r3 = 2 as i32 as i64 as u64
lbb_26366:
    ldxdw r1, [r8+0x20]                     
    ldxdw r2, [r8+0x28]                     
    ldxdw r5, [r2+0x18]                     
    mov64 r2, r4                                    r2 = r4
    callx r5                                
    ldxdw r1, [r10-0x70]                    
    ldxdw r2, [r10-0x68]                    
    jne r0, 0, lbb_26439                            if r0 != (0 as i32 as i64 as u64) { pc += 65 }
    ldxdw r3, [r2+0x18]                     
    mov64 r2, r8                                    r2 = r8
    callx r3                                
    ja lbb_26438                                    if true { pc += 60 }
lbb_26378:
    jeq r9, 0, lbb_26380                            if r9 == (0 as i32 as i64 as u64) { pc += 1 }
    ja lbb_26393                                    if true { pc += 13 }
lbb_26380:
    ldxdw r1, [r8+0x20]                     
    ldxdw r4, [r8+0x28]                     
    ldxdw r4, [r4+0x18]                     
    stxdw [r10-0x70], r2                    
    lddw r2, 0x10003ff37 --> b"(\x0a,library/core/src/fmt/num.rs0x000102030405060708"        r2 load str located at 4295229239
    stxdw [r10-0x68], r3                    
    mov64 r3, 2                                     r3 = 2 as i32 as i64 as u64
    callx r4                                
    ldxdw r3, [r10-0x68]                    
    ldxdw r2, [r10-0x70]                    
    jne r0, 0, lbb_26439                            if r0 != (0 as i32 as i64 as u64) { pc += 47 }
    ldxw r1, [r8+0x34]                      
lbb_26393:
    stxb [r10-0x41], r7                     
    ldxdw r4, [r8+0x20]                     
    ldxdw r5, [r8+0x28]                     
    mov64 r0, r10                                   r0 = r10
    add64 r0, -65                                   r0 += -65   ///  r0 = r0.wrapping_add(-65 as i32 as i64 as u64)
    stxdw [r10-0x50], r0                    
    stxdw [r10-0x58], r5                    
    stxdw [r10-0x60], r4                    
    ldxdw r4, [r8+0x0]                      
    stxdw [r10-0x68], r4                    
    ldxdw r4, [r8+0x8]                      
    stxdw [r10-0x70], r4                    
    ldxdw r0, [r8+0x10]                     
    ldxdw r5, [r8+0x18]                     
    ldxw r4, [r8+0x30]                      
    ldxb r8, [r8+0x38]                      
    stxb [r10-0x8], r8                      
    stxw [r10-0x10], r4                     
    stxw [r10-0xc], r1                      
    lddw r1, 0x100041fa0 --> b"\x00\x00\x00\x00\x18\xa9\x02\x00\x18\x00\x00\x00\x00\x00\x00\x00\x08\x00\…        r1 load str located at 4295237536
    stxdw [r10-0x18], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -96                                   r1 += -96   ///  r1 = r1.wrapping_add(-96 as i32 as i64 as u64)
    stxdw [r10-0x20], r1                    
    stxdw [r10-0x28], r5                    
    stxdw [r10-0x30], r0                    
    ldxdw r1, [r10-0x70]                    
    stxdw [r10-0x38], r1                    
    ldxdw r1, [r10-0x68]                    
    stxdw [r10-0x40], r1                    
    ldxdw r4, [r3+0x18]                     
    mov64 r3, r10                                   r3 = r10
    add64 r3, -64                                   r3 += -64   ///  r3 = r3.wrapping_add(-64 as i32 as i64 as u64)
    mov64 r1, r2                                    r1 = r2
    mov64 r2, r3                                    r2 = r3
    callx r4                                
    jne r0, 0, lbb_26439                            if r0 != (0 as i32 as i64 as u64) { pc += 8 }
    ldxdw r1, [r10-0x18]                    
    ldxdw r4, [r1+0x18]                     
    ldxdw r1, [r10-0x20]                    
    lddw r2, 0x10003ff31 --> b",\x0a"               r2 load str located at 4295229233
    mov64 r3, 2                                     r3 = 2 as i32 as i64 as u64
    callx r4                                
lbb_26438:
    mov64 r7, r0                                    r7 = r0
lbb_26439:
    stxb [r6+0x10], r7                      
    add64 r9, 1                                     r9 += 1   ///  r9 = r9.wrapping_add(1 as i32 as i64 as u64)
    stxdw [r6+0x0], r9                      
    mov64 r0, r6                                    r0 = r6
    exit                                    

function_26444:
    ldxb r3, [r1+0x10]                      
    ldxdw r2, [r1+0x0]                      
    jne r2, 0, lbb_26452                            if r2 != (0 as i32 as i64 as u64) { pc += 5 }
    mov64 r1, r3                                    r1 = r3
    mov64 r0, 1                                     r0 = 1 as i32 as i64 as u64
    jne r1, 0, lbb_26487                            if r1 != (0 as i32 as i64 as u64) { pc += 37 }
    mov64 r0, 0                                     r0 = 0 as i32 as i64 as u64
    ja lbb_26487                                    if true { pc += 35 }
lbb_26452:
    mov64 r0, 1                                     r0 = 1 as i32 as i64 as u64
    jeq r3, 0, lbb_26455                            if r3 == (0 as i32 as i64 as u64) { pc += 1 }
    ja lbb_26486                                    if true { pc += 31 }
lbb_26455:
    ldxdw r6, [r1+0x8]                      
    jne r2, 1, lbb_26459                            if r2 != (1 as i32 as i64 as u64) { pc += 2 }
    ldxb r2, [r1+0x11]                      
    jne r2, 0, lbb_26470                            if r2 != (0 as i32 as i64 as u64) { pc += 11 }
lbb_26459:
    ldxdw r2, [r6+0x20]                     
    ldxdw r3, [r6+0x28]                     
    ldxdw r4, [r3+0x18]                     
    mov64 r6, r1                                    r6 = r1
    mov64 r1, r2                                    r1 = r2
    lddw r2, 0x10003fe60 --> b")"                   r2 load str located at 4295229024
    mov64 r3, 1                                     r3 = 1 as i32 as i64 as u64
    callx r4                                
    mov64 r1, r6                                    r1 = r6
    ja lbb_26486                                    if true { pc += 16 }
lbb_26470:
    ldxw r2, [r6+0x34]                      
    and64 r2, 4                                     r2 &= 4   ///  r2 = r2.and(4)
    jne r2, 0, lbb_26459                            if r2 != (0 as i32 as i64 as u64) { pc += -14 }
    ldxdw r2, [r6+0x20]                     
    ldxdw r3, [r6+0x28]                     
    ldxdw r4, [r3+0x18]                     
    mov64 r7, r1                                    r7 = r1
    mov64 r1, r2                                    r1 = r2
    lddw r2, 0x10003ff39 --> b","                   r2 load str located at 4295229241
    mov64 r3, 1                                     r3 = 1 as i32 as i64 as u64
    callx r4                                
    mov64 r1, r7                                    r1 = r7
    mov64 r2, r0                                    r2 = r0
    mov64 r0, 1                                     r0 = 1 as i32 as i64 as u64
    jeq r2, 0, lbb_26459                            if r2 == (0 as i32 as i64 as u64) { pc += -27 }
lbb_26486:
    stxb [r1+0x10], r0                      
lbb_26487:
    and64 r0, 1                                     r0 &= 1   ///  r0 = r0.and(1)
    exit                                    

function_26489:
    stxdw [r10-0x4c0], r4                   
    stxdw [r10-0x4d0], r3                   
    mov64 r9, r2                                    r9 = r2
    stxdw [r10-0x4b8], r1                   
    mov64 r7, r9                                    r7 = r9
    lsh64 r7, 1                                     r7 <<= 1   ///  r7 = r7.wrapping_shl(1)
    lddw r1, 0x1ffffffffffffe                       r1 load str located at 9007199254740990
    and64 r7, r1                                    r7 &= r1   ///  r7 = r7.and(r1)
    lddw r1, 0xfffffffffffff                        r1 load str located at 4503599627370495
    mov64 r8, r9                                    r8 = r9
    and64 r8, r1                                    r8 &= r1   ///  r8 = r8.and(r1)
    mov64 r6, r9                                    r6 = r9
    rsh64 r6, 52                                    r6 >>= 52   ///  r6 = r6.wrapping_shr(52)
    and64 r6, 2047                                  r6 &= 2047   ///  r6 = r6.and(2047)
    jeq r6, 0, lbb_26510                            if r6 == (0 as i32 as i64 as u64) { pc += 4 }
    lddw r1, 0x10000000000000                       r1 load str located at 4503599627370496
    mov64 r7, r8                                    r7 = r8
    or64 r7, r1                                     r7 |= r1   ///  r7 = r7.or(r1)
lbb_26510:
    mov64 r1, r9                                    r1 = r9
    mov64 r2, r9                                    r2 = r9
    call function_31780                     
    mov64 r2, 2                                     r2 = 2 as i32 as i64 as u64
    jne r0, 0, lbb_26552                            if r0 != (0 as i32 as i64 as u64) { pc += 37 }
    mov64 r3, r7                                    r3 = r7
    and64 r3, 1                                     r3 &= 1   ///  r3 = r3.and(1)
    lddw r4, 0x7ff0000000000000                     r4 load str located at 9218868437227405312
    mov64 r0, r9                                    r0 = r9
    and64 r0, r4                                    r0 &= r4   ///  r0 = r0.and(r4)
    jne r8, 0, lbb_26527                            if r8 != (0 as i32 as i64 as u64) { pc += 5 }
    mov64 r2, 3                                     r2 = 3 as i32 as i64 as u64
    jeq r0, r4, lbb_26552                           if r0 == r4 { pc += 28 }
    mov64 r2, 4                                     r2 = 4 as i32 as i64 as u64
    jeq r0, 0, lbb_26552                            if r0 == (0 as i32 as i64 as u64) { pc += 26 }
    ja lbb_26528                                    if true { pc += 1 }
lbb_26527:
    jeq r0, 0, lbb_26546                            if r0 == (0 as i32 as i64 as u64) { pc += 18 }
lbb_26528:
    mov64 r5, 2                                     r5 = 2 as i32 as i64 as u64
    lddw r2, 0x10000000000000                       r2 load str located at 4503599627370496
    jeq r7, r2, lbb_26533                           if r7 == r2 { pc += 1 }
    mov64 r5, 1                                     r5 = 1 as i32 as i64 as u64
lbb_26533:
    lddw r4, 0x40000000000000                       r4 load str located at 18014398509481984
    jeq r7, r2, lbb_26538                           if r7 == r2 { pc += 2 }
    mov64 r4, r7                                    r4 = r7
    lsh64 r4, 1                                     r4 <<= 1   ///  r4 = r4.wrapping_shl(1)
lbb_26538:
    mov64 r1, -1077                                 r1 = -1077 as i32 as i64 as u64
    jeq r7, r2, lbb_26541                           if r7 == r2 { pc += 1 }
    mov64 r1, -1076                                 r1 = -1076 as i32 as i64 as u64
lbb_26541:
    add64 r1, r6                                    r1 += r6   ///  r1 = r1.wrapping_add(r6)
    xor64 r3, 1                                     r3 ^= 1   ///  r3 = r3.xor(1)
    mov64 r2, r3                                    r2 = r3
    stxdw [r10-0x4c8], r4                   
    ja lbb_26552                                    if true { pc += 6 }
lbb_26546:
    add64 r6, -1075                                 r6 += -1075   ///  r6 = r6.wrapping_add(-1075 as i32 as i64 as u64)
    mov64 r5, 1                                     r5 = 1 as i32 as i64 as u64
    xor64 r3, 1                                     r3 ^= 1   ///  r3 = r3.xor(1)
    stxdw [r10-0x4c8], r7                   
    mov64 r1, r6                                    r1 = r6
    mov64 r2, r3                                    r2 = r3
lbb_26552:
    stxh [r10-0x8], r1                      
    stxdw [r10-0x10], r5                    
    ldxdw r3, [r10-0x4c8]                   
    stxdw [r10-0x20], r3                    
    mov64 r6, 1                                     r6 = 1 as i32 as i64 as u64
    stxdw [r10-0x18], r6                    
    mov64 r7, 0                                     r7 = 0 as i32 as i64 as u64
    stxb [r10-0x6], r2                      
    jeq r2, 2, lbb_26579                            if r2 == (2 as i32 as i64 as u64) { pc += 18 }
    ldxdw r3, [r10-0x4d0]                   
    jne r3, 0, lbb_26564                            if r3 != (0 as i32 as i64 as u64) { pc += 1 }
    ja lbb_26572                                    if true { pc += 8 }
lbb_26564:
    lddw r6, 0x10003fe17 --> b"-+NaNinf0assertion failed: buf.len() >= maxlenlibr"        r6 load str located at 4295228951
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
    jsgt r3, r9, lbb_26570                          if (r3 as i64) > (r9 as i64) { pc += 2 }
    lddw r6, 0x10003fe18 --> b"+"                   r6 load str located at 4295228952
lbb_26570:
    mov64 r7, 1                                     r7 = 1 as i32 as i64 as u64
    ja lbb_26579                                    if true { pc += 7 }
lbb_26572:
    lddw r6, 0x10003fe17 --> b"-+NaNinf0assertion failed: buf.len() >= maxlenlibr"        r6 load str located at 4295228951
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
    jsgt r3, r9, lbb_26577                          if (r3 as i64) > (r9 as i64) { pc += 1 }
    mov64 r6, 1                                     r6 = 1 as i32 as i64 as u64
lbb_26577:
    rsh64 r9, 63                                    r9 >>= 63   ///  r9 = r9.wrapping_shr(63)
    mov64 r7, r9                                    r7 = r9
lbb_26579:
    add64 r2, -2                                    r2 += -2   ///  r2 = r2.wrapping_add(-2 as i32 as i64 as u64)
    and64 r2, 255                                   r2 &= 255   ///  r2 = r2.and(255)
    mov64 r3, 3                                     r3 = 3 as i32 as i64 as u64
    jgt r3, r2, lbb_26584                           if r3 > r2 { pc += 1 }
    mov64 r2, 3                                     r2 = 3 as i32 as i64 as u64
lbb_26584:
    jsgt r2, 1, lbb_26591                           if (r2 as i64) > (1 as i32 as i64) { pc += 6 }
    jeq r2, 0, lbb_26607                            if r2 == (0 as i32 as i64 as u64) { pc += 21 }
    mov64 r1, 3                                     r1 = 3 as i32 as i64 as u64
    stxdw [r10-0x90], r1                    
    lddw r1, 0x10003fe1c --> b"inf0assertion failed: buf.len() >= maxlenlibrary/c"        r1 load str located at 4295228956
    ja lbb_26611                                    if true { pc += 20 }
lbb_26591:
    jeq r2, 2, lbb_26616                            if r2 == (2 as i32 as i64 as u64) { pc += 24 }
    lsh64 r1, 48                                    r1 <<= 48   ///  r1 = r1.wrapping_shl(48)
    arsh64 r1, 48                                   r1 >>= 48 (signed)   ///  r1 = (r1 as i64).wrapping_shr(48)
    mov64 r8, -12                                   r8 = -12 as i32 as i64 as u64
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
    jsgt r2, r1, lbb_26598                          if (r2 as i64) > (r1 as i64) { pc += 1 }
    mov64 r8, 5                                     r8 = 5 as i32 as i64 as u64
lbb_26598:
    mul64 r8, r1                                    r8 *= r1   ///  r8 = r8.wrapping_mul(r1)
    mov64 r1, 16064                                 r1 = 16064 as i32 as i64 as u64
    jgt r1, r8, lbb_26627                           if r1 > r8 { pc += 26 }
    lddw r1, 0x10003fe20 --> b"assertion failed: buf.len() >= maxlen"        r1 load str located at 4295228960
    mov64 r2, 37                                    r2 = 37 as i32 as i64 as u64
    lddw r3, 0x100041e48 --> b"\x00\x00\x00\x00\xb0\xfd\x03\x00#\x00\x00\x00\x00\x00\x00\x00\x7f\x02\x00…        r3 load str located at 4295237192
    call function_25816                     
lbb_26607:
    mov64 r1, 3                                     r1 = 3 as i32 as i64 as u64
    stxdw [r10-0x90], r1                    
    lddw r1, 0x10003fe19 --> b"NaNinf0assertion failed: buf.len() >= maxlenlibrar"        r1 load str located at 4295228953
lbb_26611:
    stxdw [r10-0x98], r1                    
    mov64 r1, 2                                     r1 = 2 as i32 as i64 as u64
    stxh [r10-0xa0], r1                     
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    ja lbb_26693                                    if true { pc += 77 }
lbb_26616:
    mov64 r1, 2                                     r1 = 2 as i32 as i64 as u64
    stxh [r10-0xa0], r1                     
    ldxdw r2, [r10-0x4c0]                   
    jeq r2, 0, lbb_26688                            if r2 == (0 as i32 as i64 as u64) { pc += 68 }
lbb_26620:
    stxdw [r10-0x80], r2                    
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
    stxh [r10-0x88], r2                     
    lddw r2, 0x10003fe15 --> b"0.-+NaNinf0assertion failed: buf.len() >= maxlenli"        r2 load str located at 4295228949
    stxdw [r10-0x98], r2                    
    ja lbb_26692                                    if true { pc += 65 }
lbb_26627:
    rsh64 r8, 4                                     r8 >>= 4   ///  r8 = r8.wrapping_shr(4)
    add64 r8, 21                                    r8 += 21   ///  r8 = r8.wrapping_add(21 as i32 as i64 as u64)
    ldxdw r2, [r10-0x4c0]                   
    mov64 r9, r2                                    r9 = r2
    neg64 r9                                        r9 = -r9   ///  r9 = (r9 as i64).wrapping_neg() as u64
    mov64 r1, 32768                                 r1 = 32768 as i32 as i64 as u64
    jgt r1, r2, lbb_26635                           if r1 > r2 { pc += 1 }
    mov64 r9, -32768                                r9 = -32768 as i32 as i64 as u64
lbb_26635:
    mov64 r1, r10                                   r1 = r10
    add64 r1, -160                                  r1 += -160   ///  r1 = r1.wrapping_add(-160 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -32                                   r2 += -32   ///  r2 = r2.wrapping_add(-32 as i32 as i64 as u64)
    mov64 r3, r10                                   r3 = r10
    add64 r3, -1184                                 r3 += -1184   ///  r3 = r3.wrapping_add(-1184 as i32 as i64 as u64)
    mov64 r4, r8                                    r4 = r8
    mov64 r5, r9                                    r5 = r9
    call function_24669                     
    lsh64 r9, 48                                    r9 <<= 48   ///  r9 = r9.wrapping_shl(48)
    arsh64 r9, 48                                   r9 >>= 48 (signed)   ///  r9 = (r9 as i64).wrapping_shr(48)
    ldxdw r1, [r10-0xa0]                    
    jne r1, 0, lbb_26658                            if r1 != (0 as i32 as i64 as u64) { pc += 10 }
    mov64 r1, r10                                   r1 = r10
    add64 r1, -64                                   r1 += -64   ///  r1 = r1.wrapping_add(-64 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -32                                   r2 += -32   ///  r2 = r2.wrapping_add(-32 as i32 as i64 as u64)
    mov64 r3, r10                                   r3 = r10
    add64 r3, -1184                                 r3 += -1184   ///  r3 = r3.wrapping_add(-1184 as i32 as i64 as u64)
    mov64 r4, r8                                    r4 = r8
    mov64 r5, r9                                    r5 = r9
    call function_22974                     
    ja lbb_26664                                    if true { pc += 6 }
lbb_26658:
    ldxdw r1, [r10-0x90]                    
    stxdw [r10-0x30], r1                    
    ldxdw r1, [r10-0x98]                    
    stxdw [r10-0x38], r1                    
    ldxdw r1, [r10-0xa0]                    
    stxdw [r10-0x40], r1                    
lbb_26664:
    ldxh r4, [r10-0x30]                     
    lsh64 r4, 48                                    r4 <<= 48   ///  r4 = r4.wrapping_shl(48)
    arsh64 r4, 48                                   r4 >>= 48 (signed)   ///  r4 = (r4 as i64).wrapping_shr(48)
    jsge r9, r4, lbb_26684                          if (r9 as i64) >= (r4 as i64) { pc += 16 }
    ldxdw r3, [r10-0x38]                    
    ldxdw r2, [r10-0x40]                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -160                                  r1 += -160   ///  r1 = r1.wrapping_add(-160 as i32 as i64 as u64)
    stxdw [r10-0xff8], r1                   
    mov64 r1, 4                                     r1 = 4 as i32 as i64 as u64
    stxdw [r10-0xff0], r1                   
    ldxdw r1, [r10-0x4c0]                   
    stxdw [r10-0x1000], r1                  
    mov64 r1, r10                                   r1 = r10
    add64 r1, -1200                                 r1 += -1200   ///  r1 = r1.wrapping_add(-1200 as i32 as i64 as u64)
    mov64 r5, r10                                   r5 = r10
    call function_25186                     
    ldxdw r1, [r10-0x4a8]                   
    ldxdw r2, [r10-0x4b0]                   
    ja lbb_26695                                    if true { pc += 11 }
lbb_26684:
    mov64 r1, 2                                     r1 = 2 as i32 as i64 as u64
    stxh [r10-0xa0], r1                     
    ldxdw r2, [r10-0x4c0]                   
    jne r2, 0, lbb_26620                            if r2 != (0 as i32 as i64 as u64) { pc += -68 }
lbb_26688:
    lddw r1, 0x10003fe1f --> b"0assertion failed: buf.len() >= maxlenlibrary/core"        r1 load str located at 4295228959
    stxdw [r10-0x98], r1                    
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
lbb_26692:
    stxdw [r10-0x90], r1                    
lbb_26693:
    mov64 r2, r10                                   r2 = r10
    add64 r2, -160                                  r2 += -160   ///  r2 = r2.wrapping_add(-160 as i32 as i64 as u64)
lbb_26695:
    stxdw [r10-0x28], r1                    
    stxdw [r10-0x30], r2                    
    stxdw [r10-0x38], r7                    
    stxdw [r10-0x40], r6                    
    mov64 r2, r10                                   r2 = r10
    add64 r2, -64                                   r2 += -64   ///  r2 = r2.wrapping_add(-64 as i32 as i64 as u64)
    ldxdw r1, [r10-0x4b8]                   
    call function_27424                     
    exit                                    

function_26704:
    stxdw [r10-0xe0], r4                    
    stxdw [r10-0xe8], r3                    
    mov64 r9, r2                                    r9 = r2
    stxdw [r10-0xd0], r1                    
    mov64 r7, r9                                    r7 = r9
    lsh64 r7, 1                                     r7 <<= 1   ///  r7 = r7.wrapping_shl(1)
    lddw r1, 0x1ffffffffffffe                       r1 load str located at 9007199254740990
    and64 r7, r1                                    r7 &= r1   ///  r7 = r7.and(r1)
    lddw r1, 0xfffffffffffff                        r1 load str located at 4503599627370495
    mov64 r8, r9                                    r8 = r9
    and64 r8, r1                                    r8 &= r1   ///  r8 = r8.and(r1)
    mov64 r6, r9                                    r6 = r9
    rsh64 r6, 52                                    r6 >>= 52   ///  r6 = r6.wrapping_shr(52)
    and64 r6, 2047                                  r6 &= 2047   ///  r6 = r6.and(2047)
    jeq r6, 0, lbb_26725                            if r6 == (0 as i32 as i64 as u64) { pc += 4 }
    lddw r1, 0x10000000000000                       r1 load str located at 4503599627370496
    mov64 r7, r8                                    r7 = r8
    or64 r7, r1                                     r7 |= r1   ///  r7 = r7.or(r1)
lbb_26725:
    mov64 r1, r9                                    r1 = r9
    mov64 r2, r9                                    r2 = r9
    call function_31780                     
    mov64 r1, 2                                     r1 = 2 as i32 as i64 as u64
    jne r0, 0, lbb_26767                            if r0 != (0 as i32 as i64 as u64) { pc += 37 }
    mov64 r2, r7                                    r2 = r7
    and64 r2, 1                                     r2 &= 1   ///  r2 = r2.and(1)
    lddw r3, 0x7ff0000000000000                     r3 load str located at 9218868437227405312
    mov64 r0, r9                                    r0 = r9
    and64 r0, r3                                    r0 &= r3   ///  r0 = r0.and(r3)
    jne r8, 0, lbb_26742                            if r8 != (0 as i32 as i64 as u64) { pc += 5 }
    mov64 r1, 3                                     r1 = 3 as i32 as i64 as u64
    jeq r0, r3, lbb_26767                           if r0 == r3 { pc += 28 }
    mov64 r1, 4                                     r1 = 4 as i32 as i64 as u64
    jeq r0, 0, lbb_26767                            if r0 == (0 as i32 as i64 as u64) { pc += 26 }
    ja lbb_26743                                    if true { pc += 1 }
lbb_26742:
    jeq r0, 0, lbb_26761                            if r0 == (0 as i32 as i64 as u64) { pc += 18 }
lbb_26743:
    mov64 r4, 2                                     r4 = 2 as i32 as i64 as u64
    lddw r1, 0x10000000000000                       r1 load str located at 4503599627370496
    jeq r7, r1, lbb_26748                           if r7 == r1 { pc += 1 }
    mov64 r4, 1                                     r4 = 1 as i32 as i64 as u64
lbb_26748:
    lddw r3, 0x40000000000000                       r3 load str located at 18014398509481984
    jeq r7, r1, lbb_26753                           if r7 == r1 { pc += 2 }
    mov64 r3, r7                                    r3 = r7
    lsh64 r3, 1                                     r3 <<= 1   ///  r3 = r3.wrapping_shl(1)
lbb_26753:
    mov64 r5, -1077                                 r5 = -1077 as i32 as i64 as u64
    jeq r7, r1, lbb_26756                           if r7 == r1 { pc += 1 }
    mov64 r5, -1076                                 r5 = -1076 as i32 as i64 as u64
lbb_26756:
    add64 r5, r6                                    r5 += r6   ///  r5 = r5.wrapping_add(r6)
    xor64 r2, 1                                     r2 ^= 1   ///  r2 = r2.xor(1)
    mov64 r1, r2                                    r1 = r2
    stxdw [r10-0xd8], r3                    
    ja lbb_26767                                    if true { pc += 6 }
lbb_26761:
    add64 r6, -1075                                 r6 += -1075   ///  r6 = r6.wrapping_add(-1075 as i32 as i64 as u64)
    mov64 r4, 1                                     r4 = 1 as i32 as i64 as u64
    xor64 r2, 1                                     r2 ^= 1   ///  r2 = r2.xor(1)
    stxdw [r10-0xd8], r7                    
    mov64 r5, r6                                    r5 = r6
    mov64 r1, r2                                    r1 = r2
lbb_26767:
    stxh [r10-0x8], r5                      
    stxdw [r10-0x10], r4                    
    ldxdw r2, [r10-0xd8]                    
    stxdw [r10-0x20], r2                    
    mov64 r6, 0                                     r6 = 0 as i32 as i64 as u64
    mov64 r7, 1                                     r7 = 1 as i32 as i64 as u64
    stxdw [r10-0x18], r7                    
    stxb [r10-0x6], r1                      
    jeq r1, 2, lbb_26794                            if r1 == (2 as i32 as i64 as u64) { pc += 18 }
    ldxdw r2, [r10-0xe8]                    
    jne r2, 0, lbb_26779                            if r2 != (0 as i32 as i64 as u64) { pc += 1 }
    ja lbb_26787                                    if true { pc += 8 }
lbb_26779:
    lddw r7, 0x10003fe17 --> b"-+NaNinf0assertion failed: buf.len() >= maxlenlibr"        r7 load str located at 4295228951
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
    jsgt r2, r9, lbb_26785                          if (r2 as i64) > (r9 as i64) { pc += 2 }
    lddw r7, 0x10003fe18 --> b"+"                   r7 load str located at 4295228952
lbb_26785:
    mov64 r6, 1                                     r6 = 1 as i32 as i64 as u64
    ja lbb_26794                                    if true { pc += 7 }
lbb_26787:
    lddw r7, 0x10003fe17 --> b"-+NaNinf0assertion failed: buf.len() >= maxlenlibr"        r7 load str located at 4295228951
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
    jsgt r2, r9, lbb_26792                          if (r2 as i64) > (r9 as i64) { pc += 1 }
    mov64 r7, 1                                     r7 = 1 as i32 as i64 as u64
lbb_26792:
    rsh64 r9, 63                                    r9 >>= 63   ///  r9 = r9.wrapping_shr(63)
    mov64 r6, r9                                    r6 = r9
lbb_26794:
    add64 r1, -2                                    r1 += -2   ///  r1 = r1.wrapping_add(-2 as i32 as i64 as u64)
    and64 r1, 255                                   r1 &= 255   ///  r1 = r1.and(255)
    mov64 r2, 3                                     r2 = 3 as i32 as i64 as u64
    jgt r2, r1, lbb_26799                           if r2 > r1 { pc += 1 }
    mov64 r1, 3                                     r1 = 3 as i32 as i64 as u64
lbb_26799:
    jsgt r1, 1, lbb_26806                           if (r1 as i64) > (1 as i32 as i64) { pc += 6 }
    jeq r1, 0, lbb_26825                            if r1 == (0 as i32 as i64 as u64) { pc += 24 }
    mov64 r1, 3                                     r1 = 3 as i32 as i64 as u64
    stxdw [r10-0x90], r1                    
    lddw r1, 0x10003fe1c --> b"inf0assertion failed: buf.len() >= maxlenlibrary/c"        r1 load str located at 4295228956
    ja lbb_26829                                    if true { pc += 23 }
lbb_26806:
    jeq r1, 2, lbb_26834                            if r1 == (2 as i32 as i64 as u64) { pc += 27 }
    mov64 r1, r10                                   r1 = r10
    add64 r1, -160                                  r1 += -160   ///  r1 = r1.wrapping_add(-160 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -32                                   r2 += -32   ///  r2 = r2.wrapping_add(-32 as i32 as i64 as u64)
    mov64 r3, r10                                   r3 = r10
    add64 r3, -177                                  r3 += -177   ///  r3 = r3.wrapping_add(-177 as i32 as i64 as u64)
    mov64 r4, 17                                    r4 = 17 as i32 as i64 as u64
    call function_23917                     
    ldxdw r1, [r10-0xa0]                    
    jne r1, 0, lbb_26818                            if r1 != (0 as i32 as i64 as u64) { pc += 1 }
    ja lbb_26846                                    if true { pc += 28 }
lbb_26818:
    ldxdw r1, [r10-0x90]                    
    stxdw [r10-0x30], r1                    
    ldxdw r1, [r10-0x98]                    
    stxdw [r10-0x38], r1                    
    ldxdw r1, [r10-0xa0]                    
    stxdw [r10-0x40], r1                    
    ja lbb_26854                                    if true { pc += 29 }
lbb_26825:
    mov64 r1, 3                                     r1 = 3 as i32 as i64 as u64
    stxdw [r10-0x90], r1                    
    lddw r1, 0x10003fe19 --> b"NaNinf0assertion failed: buf.len() >= maxlenlibrar"        r1 load str located at 4295228953
lbb_26829:
    stxdw [r10-0x98], r1                    
    mov64 r1, 2                                     r1 = 2 as i32 as i64 as u64
    stxh [r10-0xa0], r1                     
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    ja lbb_26876                                    if true { pc += 42 }
lbb_26834:
    mov64 r1, 2                                     r1 = 2 as i32 as i64 as u64
    stxh [r10-0xa0], r1                     
    ldxdw r2, [r10-0xe0]                    
    jeq r2, 0, lbb_26871                            if r2 == (0 as i32 as i64 as u64) { pc += 33 }
    mov64 r2, 1                                     r2 = 1 as i32 as i64 as u64
    stxdw [r10-0x80], r2                    
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
    stxh [r10-0x88], r2                     
    lddw r2, 0x10003fe15 --> b"0.-+NaNinf0assertion failed: buf.len() >= maxlenli"        r2 load str located at 4295228949
    stxdw [r10-0x98], r2                    
    ja lbb_26875                                    if true { pc += 29 }
lbb_26846:
    mov64 r1, r10                                   r1 = r10
    add64 r1, -64                                   r1 += -64   ///  r1 = r1.wrapping_add(-64 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -32                                   r2 += -32   ///  r2 = r2.wrapping_add(-32 as i32 as i64 as u64)
    mov64 r3, r10                                   r3 = r10
    add64 r3, -177                                  r3 += -177   ///  r3 = r3.wrapping_add(-177 as i32 as i64 as u64)
    mov64 r4, 17                                    r4 = 17 as i32 as i64 as u64
    call function_21881                     
lbb_26854:
    ldxdw r2, [r10-0x40]                    
    ldxdw r3, [r10-0x38]                    
    ldxh r4, [r10-0x30]                     
    mov64 r1, r10                                   r1 = r10
    add64 r1, -160                                  r1 += -160   ///  r1 = r1.wrapping_add(-160 as i32 as i64 as u64)
    stxdw [r10-0xff8], r1                   
    mov64 r1, 4                                     r1 = 4 as i32 as i64 as u64
    stxdw [r10-0xff0], r1                   
    ldxdw r1, [r10-0xe0]                    
    stxdw [r10-0x1000], r1                  
    mov64 r1, r10                                   r1 = r10
    add64 r1, -200                                  r1 += -200   ///  r1 = r1.wrapping_add(-200 as i32 as i64 as u64)
    mov64 r5, r10                                   r5 = r10
    call function_25186                     
    ldxdw r1, [r10-0xc0]                    
    ldxdw r2, [r10-0xc8]                    
    ja lbb_26878                                    if true { pc += 7 }
lbb_26871:
    lddw r1, 0x10003fe1f --> b"0assertion failed: buf.len() >= maxlenlibrary/core"        r1 load str located at 4295228959
    stxdw [r10-0x98], r1                    
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
lbb_26875:
    stxdw [r10-0x90], r1                    
lbb_26876:
    mov64 r2, r10                                   r2 = r10
    add64 r2, -160                                  r2 += -160   ///  r2 = r2.wrapping_add(-160 as i32 as i64 as u64)
lbb_26878:
    stxdw [r10-0x28], r1                    
    stxdw [r10-0x30], r2                    
    stxdw [r10-0x38], r6                    
    stxdw [r10-0x40], r7                    
    mov64 r2, r10                                   r2 = r10
    add64 r2, -64                                   r2 += -64   ///  r2 = r2.wrapping_add(-64 as i32 as i64 as u64)
    ldxdw r1, [r10-0xd0]                    
    call function_27424                     
    exit                                    

function_26887:
    mov64 r3, r2                                    r3 = r2
    lddw r2, 0x100041fa0 --> b"\x00\x00\x00\x00\x18\xa9\x02\x00\x18\x00\x00\x00\x00\x00\x00\x00\x08\x00\…        r2 load str located at 4295237536
    call function_26898                     
    exit                                    

function_26892:
    mov64 r3, r1                                    r3 = r1
    ldxdw r4, [r2+0x28]                     
    ldxdw r1, [r2+0x20]                     
    mov64 r2, r4                                    r2 = r4
    call function_26898                     
    exit                                    

function_26898:
    mov64 r4, 3                                     r4 = 3 as i32 as i64 as u64
    stxb [r10-0x8], r4                      
    mov64 r4, 32                                    r4 = 32 as i32 as i64 as u64
    stxdw [r10-0x10], r4                    
    stxdw [r10-0x18], r2                    
    stxdw [r10-0x20], r1                    
    mov64 r7, 0                                     r7 = 0 as i32 as i64 as u64
    stxdw [r10-0x30], r7                    
    stxdw [r10-0x40], r7                    
    ldxdw r8, [r3+0x20]                     
    stxdw [r10-0x50], r3                    
    jne r8, 0, lbb_26939                            if r8 != (0 as i32 as i64 as u64) { pc += 29 }
    ldxdw r6, [r3+0x18]                     
    jeq r6, 0, lbb_27012                            if r6 == (0 as i32 as i64 as u64) { pc += 100 }
    ldxdw r1, [r10-0x50]                    
    ldxdw r8, [r1+0x10]                     
    add64 r8, 8                                     r8 += 8   ///  r8 = r8.wrapping_add(8 as i32 as i64 as u64)
    lsh64 r6, 4                                     r6 <<= 4   ///  r6 = r6.wrapping_shl(4)
    ldxdw r9, [r1+0x0]                      
    add64 r9, 8                                     r9 += 8   ///  r9 = r9.wrapping_add(8 as i32 as i64 as u64)
    ja lbb_26936                                    if true { pc += 17 }
lbb_26919:
    ldxdw r1, [r10-0x18]                    
    ldxdw r4, [r1+0x18]                     
    ldxdw r2, [r9-0x8]                      
    ldxdw r1, [r10-0x20]                    
    callx r4                                
    jne r0, 0, lbb_27029                            if r0 != (0 as i32 as i64 as u64) { pc += 104 }
lbb_26925:
    ldxdw r1, [r8-0x8]                      
    ldxdw r3, [r8+0x0]                      
    mov64 r2, r10                                   r2 = r10
    add64 r2, -64                                   r2 += -64   ///  r2 = r2.wrapping_add(-64 as i32 as i64 as u64)
    callx r3                                
    jne r0, 0, lbb_27029                            if r0 != (0 as i32 as i64 as u64) { pc += 98 }
    add64 r7, 1                                     r7 += 1   ///  r7 = r7.wrapping_add(1 as i32 as i64 as u64)
    add64 r8, 16                                    r8 += 16   ///  r8 = r8.wrapping_add(16 as i32 as i64 as u64)
    add64 r9, 16                                    r9 += 16   ///  r9 = r9.wrapping_add(16 as i32 as i64 as u64)
    add64 r6, -16                                   r6 += -16   ///  r6 = r6.wrapping_add(-16 as i32 as i64 as u64)
    jeq r6, 0, lbb_27012                            if r6 == (0 as i32 as i64 as u64) { pc += 76 }
lbb_26936:
    ldxdw r3, [r9+0x0]                      
    jeq r3, 0, lbb_26925                            if r3 == (0 as i32 as i64 as u64) { pc += -13 }
    ja lbb_26919                                    if true { pc += -20 }
lbb_26939:
    ldxdw r9, [r3+0x28]                     
    jeq r9, 0, lbb_27012                            if r9 == (0 as i32 as i64 as u64) { pc += 71 }
    add64 r8, 24                                    r8 += 24   ///  r8 = r8.wrapping_add(24 as i32 as i64 as u64)
    mul64 r9, 56                                    r9 *= 56   ///  r9 = r9.wrapping_mul(56 as u64)
    ldxdw r1, [r10-0x50]                    
    ldxdw r2, [r1+0x10]                     
    stxdw [r10-0x48], r2                    
    ldxdw r6, [r1+0x0]                      
    add64 r6, 8                                     r6 += 8   ///  r6 = r6.wrapping_add(8 as i32 as i64 as u64)
    ja lbb_26966                                    if true { pc += 17 }
lbb_26949:
    stxdw [r10-0x28], r2                    
    stxdw [r10-0x30], r1                    
    ldxdw r1, [r8+0x8]                      
    lsh64 r1, 4                                     r1 <<= 4   ///  r1 = r1.wrapping_shl(4)
    ldxdw r2, [r10-0x48]                    
    add64 r2, r1                                    r2 += r1   ///  r2 = r2.wrapping_add(r1)
    ldxdw r1, [r2+0x0]                      
    ldxdw r3, [r2+0x8]                      
    mov64 r2, r10                                   r2 = r10
    add64 r2, -64                                   r2 += -64   ///  r2 = r2.wrapping_add(-64 as i32 as i64 as u64)
    callx r3                                
    jne r0, 0, lbb_27029                            if r0 != (0 as i32 as i64 as u64) { pc += 68 }
    add64 r7, 1                                     r7 += 1   ///  r7 = r7.wrapping_add(1 as i32 as i64 as u64)
    add64 r8, 56                                    r8 += 56   ///  r8 = r8.wrapping_add(56 as i32 as i64 as u64)
    add64 r6, 16                                    r6 += 16   ///  r6 = r6.wrapping_add(16 as i32 as i64 as u64)
    add64 r9, -56                                   r9 += -56   ///  r9 = r9.wrapping_add(-56 as i32 as i64 as u64)
    jeq r9, 0, lbb_27012                            if r9 == (0 as i32 as i64 as u64) { pc += 46 }
lbb_26966:
    ldxdw r3, [r6+0x0]                      
    jeq r3, 0, lbb_26974                            if r3 == (0 as i32 as i64 as u64) { pc += 6 }
    ldxdw r1, [r10-0x18]                    
    ldxdw r4, [r1+0x18]                     
    ldxdw r2, [r6-0x8]                      
    ldxdw r1, [r10-0x20]                    
    callx r4                                
    jne r0, 0, lbb_27029                            if r0 != (0 as i32 as i64 as u64) { pc += 55 }
lbb_26974:
    ldxw r1, [r8+0x10]                      
    stxw [r10-0x10], r1                     
    ldxb r1, [r8+0x18]                      
    stxb [r10-0x8], r1                      
    ldxw r1, [r8+0x14]                      
    stxw [r10-0xc], r1                      
    ldxdw r1, [r8+0x0]                      
    ldxdw r3, [r8-0x8]                      
    jeq r3, 0, lbb_26994                            if r3 == (0 as i32 as i64 as u64) { pc += 11 }
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
    jeq r3, 1, lbb_26986                            if r3 == (1 as i32 as i64 as u64) { pc += 1 }
    ja lbb_26995                                    if true { pc += 9 }
lbb_26986:
    lsh64 r1, 4                                     r1 <<= 4   ///  r1 = r1.wrapping_shl(4)
    ldxdw r3, [r10-0x48]                    
    add64 r3, r1                                    r3 += r1   ///  r3 = r3.wrapping_add(r1)
    ldxdw r4, [r3+0x8]                      
    jne r4, 0, lbb_26995                            if r4 != (0 as i32 as i64 as u64) { pc += 4 }
    mov64 r2, 1                                     r2 = 1 as i32 as i64 as u64
    ldxdw r1, [r3+0x0]                      
    ja lbb_26995                                    if true { pc += 1 }
lbb_26994:
    mov64 r2, 1                                     r2 = 1 as i32 as i64 as u64
lbb_26995:
    stxdw [r10-0x38], r1                    
    stxdw [r10-0x40], r2                    
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    ldxdw r3, [r8-0x18]                     
    jeq r3, 2, lbb_26949                            if r3 == (2 as i32 as i64 as u64) { pc += -51 }
    ldxdw r2, [r8-0x10]                     
    jeq r3, 1, lbb_27004                            if r3 == (1 as i32 as i64 as u64) { pc += 2 }
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    ja lbb_26949                                    if true { pc += -55 }
lbb_27004:
    lsh64 r2, 4                                     r2 <<= 4   ///  r2 = r2.wrapping_shl(4)
    ldxdw r3, [r10-0x48]                    
    add64 r3, r2                                    r3 += r2   ///  r3 = r3.wrapping_add(r2)
    ldxdw r4, [r3+0x8]                      
    jne r4, 0, lbb_26949                            if r4 != (0 as i32 as i64 as u64) { pc += -60 }
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    ldxdw r2, [r3+0x0]                      
    ja lbb_26949                                    if true { pc += -63 }
lbb_27012:
    ldxdw r1, [r10-0x50]                    
    ldxdw r1, [r1+0x8]                      
    jgt r1, r7, lbb_27016                           if r1 > r7 { pc += 1 }
    ja lbb_27027                                    if true { pc += 11 }
lbb_27016:
    lsh64 r7, 4                                     r7 <<= 4   ///  r7 = r7.wrapping_shl(4)
    ldxdw r1, [r10-0x50]                    
    ldxdw r1, [r1+0x0]                      
    add64 r1, r7                                    r1 += r7   ///  r1 = r1.wrapping_add(r7)
    ldxdw r3, [r1+0x8]                      
    ldxdw r2, [r1+0x0]                      
    ldxdw r1, [r10-0x18]                    
    ldxdw r4, [r1+0x18]                     
    ldxdw r1, [r10-0x20]                    
    callx r4                                
    jne r0, 0, lbb_27029                            if r0 != (0 as i32 as i64 as u64) { pc += 2 }
lbb_27027:
    mov64 r0, 0                                     r0 = 0 as i32 as i64 as u64
    ja lbb_27030                                    if true { pc += 1 }
lbb_27029:
    mov64 r0, 1                                     r0 = 1 as i32 as i64 as u64
lbb_27030:
    exit                                    

function_27031:
    mov64 r9, r4                                    r9 = r4
    ldxdw r7, [r5-0xff8]                    
    stxdw [r10-0x18], r7                    
    jne r2, 0, lbb_27039                            if r2 != (0 as i32 as i64 as u64) { pc += 4 }
    mov64 r0, 45                                    r0 = 45 as i32 as i64 as u64
    ldxw r6, [r1+0x34]                      
    add64 r7, 1                                     r7 += 1   ///  r7 = r7.wrapping_add(1 as i32 as i64 as u64)
    ja lbb_27044                                    if true { pc += 5 }
lbb_27039:
    mov64 r0, 1114112                               r0 = 1114112 as i32 as i64 as u64
    ldxw r6, [r1+0x34]                      
    mov64 r2, r6                                    r2 = r6
    and64 r2, 1                                     r2 &= 1   ///  r2 = r2.and(1)
    jne r2, 0, lbb_27110                            if r2 != (0 as i32 as i64 as u64) { pc += 66 }
lbb_27044:
    ldxdw r2, [r5-0x1000]                   
    stxdw [r10-0x20], r2                    
    mov64 r4, 0                                     r4 = 0 as i32 as i64 as u64
    mov64 r2, r6                                    r2 = r6
    and64 r2, 4                                     r2 &= 4   ///  r2 = r2.and(4)
    jeq r2, 0, lbb_27051                            if r2 == (0 as i32 as i64 as u64) { pc += 1 }
    ja lbb_27079                                    if true { pc += 28 }
lbb_27051:
    ldxdw r2, [r1+0x0]                      
    jne r2, 0, lbb_27063                            if r2 != (0 as i32 as i64 as u64) { pc += 10 }
    ldxdw r8, [r1+0x28]                     
    ldxdw r7, [r1+0x20]                     
    mov64 r1, r7                                    r1 = r7
    mov64 r2, r8                                    r2 = r8
    mov64 r3, r0                                    r3 = r0
    mov64 r5, r9                                    r5 = r9
    call function_27229                     
    mov64 r6, 1                                     r6 = 1 as i32 as i64 as u64
    jne r0, 0, lbb_27107                            if r0 != (0 as i32 as i64 as u64) { pc += 45 }
    ja lbb_27101                                    if true { pc += 38 }
lbb_27063:
    ldxdw r8, [r1+0x8]                      
    jgt r8, r7, lbb_27066                           if r8 > r7 { pc += 1 }
    ja lbb_27092                                    if true { pc += 26 }
lbb_27066:
    stxdw [r10-0x30], r9                    
    and64 r6, 8                                     r6 &= 8   ///  r6 = r6.and(8)
    jeq r6, 0, lbb_27070                            if r6 == (0 as i32 as i64 as u64) { pc += 1 }
    ja lbb_27135                                    if true { pc += 65 }
lbb_27070:
    sub64 r8, r7                                    r8 -= r7   ///  r8 = r8.wrapping_sub(r7)
    ldxb r9, [r1+0x38]                      
    stxdw [r10-0x28], r0                    
    stxdw [r10-0x38], r4                    
    jsgt r9, 1, lbb_27163                           if (r9 as i64) > (1 as i32 as i64) { pc += 88 }
    jeq r9, 0, lbb_27182                            if r9 == (0 as i32 as i64 as u64) { pc += 106 }
lbb_27076:
    mov64 r9, r8                                    r9 = r8
    mov64 r8, 0                                     r8 = 0 as i32 as i64 as u64
    ja lbb_27182                                    if true { pc += 103 }
lbb_27079:
    stxdw [r10-0x28], r0                    
    mov64 r2, 32                                    r2 = 32 as i32 as i64 as u64
    jgt r2, r9, lbb_27114                           if r2 > r9 { pc += 32 }
    stxdw [r10-0x10], r1                    
    mov64 r1, r3                                    r1 = r3
    mov64 r2, r9                                    r2 = r9
    mov64 r8, r9                                    r8 = r9
    mov64 r9, r3                                    r9 = r3
    call function_28639                     
    mov64 r3, r9                                    r3 = r9
    mov64 r9, r8                                    r9 = r8
    ldxdw r1, [r10-0x10]                    
    ja lbb_27123                                    if true { pc += 31 }
lbb_27092:
    ldxdw r8, [r1+0x28]                     
    ldxdw r7, [r1+0x20]                     
    mov64 r1, r7                                    r1 = r7
    mov64 r2, r8                                    r2 = r8
    mov64 r3, r0                                    r3 = r0
    mov64 r5, r9                                    r5 = r9
    call function_27229                     
    mov64 r6, 1                                     r6 = 1 as i32 as i64 as u64
    jne r0, 0, lbb_27107                            if r0 != (0 as i32 as i64 as u64) { pc += 6 }
lbb_27101:
    ldxdw r4, [r8+0x18]                     
    mov64 r1, r7                                    r1 = r7
    ldxdw r2, [r10-0x20]                    
    ldxdw r3, [r10-0x18]                    
    callx r4                                
    mov64 r6, r0                                    r6 = r0
lbb_27107:
    and64 r6, 1                                     r6 &= 1   ///  r6 = r6.and(1)
    mov64 r0, r6                                    r0 = r6
    exit                                    
lbb_27110:
    mov64 r0, 43                                    r0 = 43 as i32 as i64 as u64
    ldxdw r7, [r10-0x18]                    
    add64 r7, 1                                     r7 += 1   ///  r7 = r7.wrapping_add(1 as i32 as i64 as u64)
    ja lbb_27044                                    if true { pc += -70 }
lbb_27114:
    mov64 r0, 0                                     r0 = 0 as i32 as i64 as u64
    jeq r9, 0, lbb_27123                            if r9 == (0 as i32 as i64 as u64) { pc += 7 }
    mov64 r2, r3                                    r2 = r3
    mov64 r4, r9                                    r4 = r9
    ja lbb_27128                                    if true { pc += 9 }
lbb_27119:
    add64 r0, r5                                    r0 += r5   ///  r0 = r0.wrapping_add(r5)
    add64 r2, 1                                     r2 += 1   ///  r2 = r2.wrapping_add(1 as i32 as i64 as u64)
    add64 r4, -1                                    r4 += -1   ///  r4 = r4.wrapping_add(-1 as i32 as i64 as u64)
    jne r4, 0, lbb_27128                            if r4 != (0 as i32 as i64 as u64) { pc += 5 }
lbb_27123:
    add64 r0, r7                                    r0 += r7   ///  r0 = r0.wrapping_add(r7)
    mov64 r7, r0                                    r7 = r0
    mov64 r4, r3                                    r4 = r3
    ldxdw r0, [r10-0x28]                    
    ja lbb_27051                                    if true { pc += -77 }
lbb_27128:
    ldxb r8, [r2+0x0]                       
    lsh64 r8, 56                                    r8 <<= 56   ///  r8 = r8.wrapping_shl(56)
    arsh64 r8, 56                                   r8 >>= 56 (signed)   ///  r8 = (r8 as i64).wrapping_shr(56)
    mov64 r5, 1                                     r5 = 1 as i32 as i64 as u64
    jsgt r8, -65, lbb_27119                         if (r8 as i64) > (-65 as i32 as i64) { pc += -14 }
    mov64 r5, 0                                     r5 = 0 as i32 as i64 as u64
    ja lbb_27119                                    if true { pc += -16 }
lbb_27135:
    ldxw r2, [r1+0x30]                      
    stxdw [r10-0x40], r2                    
    mov64 r2, 48                                    r2 = 48 as i32 as i64 as u64
    stxw [r1+0x30], r2                      
    ldxb r2, [r1+0x38]                      
    stxdw [r10-0x48], r2                    
    mov64 r6, 1                                     r6 = 1 as i32 as i64 as u64
    stxb [r1+0x38], r6                      
    ldxdw r2, [r1+0x20]                     
    stxdw [r10-0x10], r1                    
    ldxdw r9, [r1+0x28]                     
    stxdw [r10-0x8], r2                     
    mov64 r1, r2                                    r1 = r2
    mov64 r2, r9                                    r2 = r9
    mov64 r3, r0                                    r3 = r0
    ldxdw r5, [r10-0x30]                    
    call function_27229                     
    jne r0, 0, lbb_27107                            if r0 != (0 as i32 as i64 as u64) { pc += -46 }
    sub64 r8, r7                                    r8 -= r7   ///  r8 = r8.wrapping_sub(r7)
    add64 r8, 1                                     r8 += 1   ///  r8 = r8.wrapping_add(1 as i32 as i64 as u64)
lbb_27155:
    add64 r8, -1                                    r8 += -1   ///  r8 = r8.wrapping_add(-1 as i32 as i64 as u64)
    jeq r8, 0, lbb_27165                            if r8 == (0 as i32 as i64 as u64) { pc += 8 }
    ldxdw r3, [r9+0x20]                     
    ldxdw r1, [r10-0x8]                     
    mov64 r2, 48                                    r2 = 48 as i32 as i64 as u64
    callx r3                                
    jne r0, 0, lbb_27107                            if r0 != (0 as i32 as i64 as u64) { pc += -55 }
    ja lbb_27155                                    if true { pc += -8 }
lbb_27163:
    jeq r9, 2, lbb_27178                            if r9 == (2 as i32 as i64 as u64) { pc += 14 }
    ja lbb_27076                                    if true { pc += -89 }
lbb_27165:
    ldxdw r4, [r9+0x18]                     
    ldxdw r1, [r10-0x8]                     
    ldxdw r2, [r10-0x20]                    
    ldxdw r3, [r10-0x18]                    
    callx r4                                
    jne r0, 0, lbb_27107                            if r0 != (0 as i32 as i64 as u64) { pc += -64 }
    ldxdw r1, [r10-0x10]                    
    ldxdw r2, [r10-0x48]                    
    stxb [r1+0x38], r2                      
    ldxdw r2, [r10-0x40]                    
    stxw [r1+0x30], r2                      
    mov64 r6, 0                                     r6 = 0 as i32 as i64 as u64
    ja lbb_27107                                    if true { pc += -71 }
lbb_27178:
    mov64 r9, r8                                    r9 = r8
    rsh64 r9, 1                                     r9 >>= 1   ///  r9 = r9.wrapping_shr(1)
    add64 r8, 1                                     r8 += 1   ///  r8 = r8.wrapping_add(1 as i32 as i64 as u64)
    rsh64 r8, 1                                     r8 >>= 1   ///  r8 = r8.wrapping_shr(1)
lbb_27182:
    add64 r9, 1                                     r9 += 1   ///  r9 = r9.wrapping_add(1 as i32 as i64 as u64)
    ldxw r2, [r1+0x30]                      
    stxdw [r10-0x10], r2                    
    ldxdw r2, [r1+0x28]                     
    stxdw [r10-0x8], r2                     
    ldxdw r7, [r1+0x20]                     
    mov64 r6, 1                                     r6 = 1 as i32 as i64 as u64
lbb_27189:
    add64 r9, -1                                    r9 += -1   ///  r9 = r9.wrapping_add(-1 as i32 as i64 as u64)
    jeq r9, 0, lbb_27198                            if r9 == (0 as i32 as i64 as u64) { pc += 7 }
    ldxdw r1, [r10-0x8]                     
    ldxdw r3, [r1+0x20]                     
    mov64 r1, r7                                    r1 = r7
    ldxdw r2, [r10-0x10]                    
    callx r3                                
    jne r0, 0, lbb_27107                            if r0 != (0 as i32 as i64 as u64) { pc += -90 }
    ja lbb_27189                                    if true { pc += -9 }
lbb_27198:
    mov64 r1, r7                                    r1 = r7
    ldxdw r2, [r10-0x8]                     
    ldxdw r3, [r10-0x28]                    
    ldxdw r4, [r10-0x38]                    
    ldxdw r5, [r10-0x30]                    
    call function_27229                     
    mov64 r6, 1                                     r6 = 1 as i32 as i64 as u64
    jne r0, 0, lbb_27107                            if r0 != (0 as i32 as i64 as u64) { pc += -99 }
    ldxdw r1, [r10-0x8]                     
    ldxdw r4, [r1+0x18]                     
    mov64 r1, r7                                    r1 = r7
    ldxdw r2, [r10-0x20]                    
    ldxdw r3, [r10-0x18]                    
    callx r4                                
    jne r0, 0, lbb_27107                            if r0 != (0 as i32 as i64 as u64) { pc += -106 }
    mov64 r6, 0                                     r6 = 0 as i32 as i64 as u64
lbb_27214:
    mov64 r1, r8                                    r1 = r8
    jeq r8, r6, lbb_27225                           if r8 == r6 { pc += 9 }
    ldxdw r1, [r10-0x8]                     
    ldxdw r3, [r1+0x20]                     
    mov64 r1, r7                                    r1 = r7
    ldxdw r2, [r10-0x10]                    
    callx r3                                
    add64 r6, 1                                     r6 += 1   ///  r6 = r6.wrapping_add(1 as i32 as i64 as u64)
    jeq r0, 0, lbb_27214                            if r0 == (0 as i32 as i64 as u64) { pc += -9 }
    add64 r6, -1                                    r6 += -1   ///  r6 = r6.wrapping_add(-1 as i32 as i64 as u64)
    mov64 r1, r6                                    r1 = r6
lbb_27225:
    mov64 r6, 1                                     r6 = 1 as i32 as i64 as u64
    jgt r8, r1, lbb_27107                           if r8 > r1 { pc += -120 }
    mov64 r6, 0                                     r6 = 0 as i32 as i64 as u64
    ja lbb_27107                                    if true { pc += -122 }

function_27229:
    mov64 r6, r5                                    r6 = r5
    mov64 r7, r4                                    r7 = r4
    mov64 r8, r2                                    r8 = r2
    mov64 r2, r3                                    r2 = r3
    lsh64 r2, 32                                    r2 <<= 32   ///  r2 = r2.wrapping_shl(32)
    rsh64 r2, 32                                    r2 >>= 32   ///  r2 = r2.wrapping_shr(32)
    jeq r2, 1114112, lbb_27244                      if r2 == (1114112 as i32 as i64 as u64) { pc += 8 }
    ldxdw r4, [r8+0x20]                     
    mov64 r9, r1                                    r9 = r1
    mov64 r2, r3                                    r2 = r3
    callx r4                                
    mov64 r1, r9                                    r1 = r9
    mov64 r2, r0                                    r2 = r0
    mov64 r0, 1                                     r0 = 1 as i32 as i64 as u64
    jne r2, 0, lbb_27246                            if r2 != (0 as i32 as i64 as u64) { pc += 2 }
lbb_27244:
    mov64 r0, 0                                     r0 = 0 as i32 as i64 as u64
    jne r7, 0, lbb_27247                            if r7 != (0 as i32 as i64 as u64) { pc += 1 }
lbb_27246:
    exit                                    
lbb_27247:
    ldxdw r4, [r8+0x18]                     
    mov64 r2, r7                                    r2 = r7
    mov64 r3, r6                                    r3 = r6
    callx r4                                
    ja lbb_27246                                    if true { pc += -6 }

function_27252:
    ldxdw r5, [r1+0x10]                     
    ldxdw r0, [r1+0x0]                      
    mov64 r4, r0                                    r4 = r0
    or64 r4, r5                                     r4 |= r5   ///  r4 = r4.or(r5)
    jeq r4, 0, lbb_27309                            if r4 == (0 as i32 as i64 as u64) { pc += 52 }
    stxdw [r10-0x18], r0                    
    stxdw [r10-0x8], r2                     
    stxdw [r10-0x10], r3                    
    jeq r5, 0, lbb_27323                            if r5 == (0 as i32 as i64 as u64) { pc += 62 }
    ldxdw r6, [r10-0x8]                     
    mov64 r3, r6                                    r3 = r6
    ldxdw r4, [r10-0x10]                    
    add64 r3, r4                                    r3 += r4   ///  r3 = r3.wrapping_add(r4)
    mov64 r4, 0                                     r4 = 0 as i32 as i64 as u64
    ldxdw r5, [r1+0x18]                     
    jeq r5, 0, lbb_27296                            if r5 == (0 as i32 as i64 as u64) { pc += 28 }
    mov64 r2, 224                                   r2 = 224 as i32 as i64 as u64
    mov64 r7, 0                                     r7 = 0 as i32 as i64 as u64
    ldxdw r6, [r10-0x8]                     
lbb_27271:
    mov64 r8, r6                                    r8 = r6
    mov64 r9, r4                                    r9 = r4
    jeq r8, r3, lbb_27323                           if r8 == r3 { pc += 49 }
    mov64 r6, r8                                    r6 = r8
    add64 r6, 1                                     r6 += 1   ///  r6 = r6.wrapping_add(1 as i32 as i64 as u64)
    ldxb r0, [r8+0x0]                       
    mov64 r4, r0                                    r4 = r0
    lsh64 r4, 56                                    r4 <<= 56   ///  r4 = r4.wrapping_shl(56)
    arsh64 r4, 56                                   r4 >>= 56 (signed)   ///  r4 = (r4 as i64).wrapping_shr(56)
    jsgt r4, -1, lbb_27291                          if (r4 as i64) > (-1 as i32 as i64) { pc += 10 }
    mov64 r6, r8                                    r6 = r8
    add64 r6, 2                                     r6 += 2   ///  r6 = r6.wrapping_add(2 as i32 as i64 as u64)
    mov64 r4, r0                                    r4 = r0
    jgt r2, r4, lbb_27291                           if r2 > r4 { pc += 6 }
    mov64 r6, r8                                    r6 = r8
    add64 r6, 3                                     r6 += 3   ///  r6 = r6.wrapping_add(3 as i32 as i64 as u64)
    mov64 r0, 240                                   r0 = 240 as i32 as i64 as u64
    jgt r0, r4, lbb_27291                           if r0 > r4 { pc += 2 }
    mov64 r6, r8                                    r6 = r8
    add64 r6, 4                                     r6 += 4   ///  r6 = r6.wrapping_add(4 as i32 as i64 as u64)
lbb_27291:
    add64 r7, 1                                     r7 += 1   ///  r7 = r7.wrapping_add(1 as i32 as i64 as u64)
    mov64 r4, r6                                    r4 = r6
    sub64 r4, r8                                    r4 -= r8   ///  r4 = r4.wrapping_sub(r8)
    add64 r4, r9                                    r4 += r9   ///  r4 = r4.wrapping_add(r9)
    jgt r5, r7, lbb_27271                           if r5 > r7 { pc += -25 }
lbb_27296:
    jeq r6, r3, lbb_27323                           if r6 == r3 { pc += 26 }
    ldxb r3, [r6+0x0]                       
    mov64 r5, r3                                    r5 = r3
    lsh64 r5, 56                                    r5 <<= 56   ///  r5 = r5.wrapping_shl(56)
    arsh64 r5, 56                                   r5 >>= 56 (signed)   ///  r5 = (r5 as i64).wrapping_shr(56)
    jsgt r5, -1, lbb_27304                          if (r5 as i64) > (-1 as i32 as i64) { pc += 2 }
    mov64 r5, 224                                   r5 = 224 as i32 as i64 as u64
    jgt r5, r3, lbb_27304                           if r5 > r3 { pc += 0 }
lbb_27304:
    jeq r4, 0, lbb_27322                            if r4 == (0 as i32 as i64 as u64) { pc += 17 }
    ldxdw r3, [r10-0x10]                    
    jgt r3, r4, lbb_27315                           if r3 > r4 { pc += 8 }
    jeq r4, r3, lbb_27322                           if r4 == r3 { pc += 14 }
    ja lbb_27323                                    if true { pc += 14 }
lbb_27309:
    ldxdw r5, [r1+0x20]                     
    ldxdw r1, [r1+0x28]                     
    ldxdw r4, [r1+0x18]                     
    mov64 r1, r5                                    r1 = r5
    callx r4                                
    ja lbb_27422                                    if true { pc += 107 }
lbb_27315:
    ldxdw r3, [r10-0x8]                     
    add64 r3, r4                                    r3 += r4   ///  r3 = r3.wrapping_add(r4)
    ldxb r3, [r3+0x0]                       
    lsh64 r3, 56                                    r3 <<= 56   ///  r3 = r3.wrapping_shl(56)
    arsh64 r3, 56                                   r3 >>= 56 (signed)   ///  r3 = (r3 as i64).wrapping_shr(56)
    mov64 r5, -64                                   r5 = -64 as i32 as i64 as u64
    jsgt r5, r3, lbb_27323                          if (r5 as i64) > (r3 as i64) { pc += 1 }
lbb_27322:
    stxdw [r10-0x10], r4                    
lbb_27323:
    ldxdw r2, [r10-0x18]                    
    jne r2, 0, lbb_27333                            if r2 != (0 as i32 as i64 as u64) { pc += 8 }
    ldxdw r2, [r1+0x20]                     
    ldxdw r1, [r1+0x28]                     
    ldxdw r4, [r1+0x18]                     
    mov64 r1, r2                                    r1 = r2
    ldxdw r2, [r10-0x8]                     
    ldxdw r3, [r10-0x10]                    
    callx r4                                
    ja lbb_27422                                    if true { pc += 89 }
lbb_27333:
    ldxdw r9, [r1+0x8]                      
    mov64 r2, 32                                    r2 = 32 as i32 as i64 as u64
    ldxdw r7, [r10-0x10]                    
    ldxdw r8, [r10-0x8]                     
    jgt r2, r7, lbb_27344                           if r2 > r7 { pc += 6 }
    mov64 r6, r1                                    r6 = r1
    mov64 r1, r8                                    r1 = r8
    mov64 r2, r7                                    r2 = r7
    call function_28639                     
    mov64 r1, r6                                    r1 = r6
    ja lbb_27353                                    if true { pc += 9 }
lbb_27344:
    mov64 r0, 0                                     r0 = 0 as i32 as i64 as u64
    jeq r7, 0, lbb_27353                            if r7 == (0 as i32 as i64 as u64) { pc += 7 }
    mov64 r2, r8                                    r2 = r8
    mov64 r3, r7                                    r3 = r7
    ja lbb_27362                                    if true { pc += 13 }
lbb_27349:
    add64 r0, r4                                    r0 += r4   ///  r0 = r0.wrapping_add(r4)
    add64 r2, 1                                     r2 += 1   ///  r2 = r2.wrapping_add(1 as i32 as i64 as u64)
    add64 r3, -1                                    r3 += -1   ///  r3 = r3.wrapping_add(-1 as i32 as i64 as u64)
    jne r3, 0, lbb_27362                            if r3 != (0 as i32 as i64 as u64) { pc += 9 }
lbb_27353:
    jge r0, r9, lbb_27369                           if r0 >= r9 { pc += 15 }
    sub64 r9, r0                                    r9 -= r0   ///  r9 = r9.wrapping_sub(r0)
    mov64 r7, 0                                     r7 = 0 as i32 as i64 as u64
    ldxb r2, [r1+0x38]                      
    jsgt r2, 1, lbb_27377                           if (r2 as i64) > (1 as i32 as i64) { pc += 19 }
    jeq r2, 0, lbb_27383                            if r2 == (0 as i32 as i64 as u64) { pc += 24 }
    mov64 r7, r9                                    r7 = r9
    mov64 r9, 0                                     r9 = 0 as i32 as i64 as u64
    ja lbb_27383                                    if true { pc += 21 }
lbb_27362:
    ldxb r5, [r2+0x0]                       
    lsh64 r5, 56                                    r5 <<= 56   ///  r5 = r5.wrapping_shl(56)
    arsh64 r5, 56                                   r5 >>= 56 (signed)   ///  r5 = (r5 as i64).wrapping_shr(56)
    mov64 r4, 1                                     r4 = 1 as i32 as i64 as u64
    jsgt r5, -65, lbb_27349                         if (r5 as i64) > (-65 as i32 as i64) { pc += -18 }
    mov64 r4, 0                                     r4 = 0 as i32 as i64 as u64
    ja lbb_27349                                    if true { pc += -20 }
lbb_27369:
    ldxdw r2, [r1+0x20]                     
    ldxdw r1, [r1+0x28]                     
    ldxdw r4, [r1+0x18]                     
    mov64 r1, r2                                    r1 = r2
    mov64 r2, r8                                    r2 = r8
    mov64 r3, r7                                    r3 = r7
    callx r4                                
    ja lbb_27422                                    if true { pc += 45 }
lbb_27377:
    jeq r2, 2, lbb_27379                            if r2 == (2 as i32 as i64 as u64) { pc += 1 }
    ja lbb_27383                                    if true { pc += 4 }
lbb_27379:
    mov64 r7, r9                                    r7 = r9
    rsh64 r7, 1                                     r7 >>= 1   ///  r7 = r7.wrapping_shr(1)
    add64 r9, 1                                     r9 += 1   ///  r9 = r9.wrapping_add(1 as i32 as i64 as u64)
    rsh64 r9, 1                                     r9 >>= 1   ///  r9 = r9.wrapping_shr(1)
lbb_27383:
    stxdw [r10-0x18], r9                    
    add64 r7, 1                                     r7 += 1   ///  r7 = r7.wrapping_add(1 as i32 as i64 as u64)
    ldxw r8, [r1+0x30]                      
    ldxdw r6, [r1+0x28]                     
    ldxdw r9, [r1+0x20]                     
lbb_27388:
    add64 r7, -1                                    r7 += -1   ///  r7 = r7.wrapping_add(-1 as i32 as i64 as u64)
    jeq r7, 0, lbb_27398                            if r7 == (0 as i32 as i64 as u64) { pc += 8 }
    ldxdw r3, [r6+0x20]                     
    mov64 r1, r9                                    r1 = r9
    mov64 r2, r8                                    r2 = r8
    callx r3                                
    mov64 r1, r0                                    r1 = r0
    mov64 r0, 1                                     r0 = 1 as i32 as i64 as u64
    jne r1, 0, lbb_27422                            if r1 != (0 as i32 as i64 as u64) { pc += 25 }
    ja lbb_27388                                    if true { pc += -10 }
lbb_27398:
    ldxdw r4, [r6+0x18]                     
    mov64 r1, r9                                    r1 = r9
    ldxdw r2, [r10-0x8]                     
    ldxdw r3, [r10-0x10]                    
    callx r4                                
    mov64 r1, r0                                    r1 = r0
    mov64 r0, 1                                     r0 = 1 as i32 as i64 as u64
    jne r1, 0, lbb_27422                            if r1 != (0 as i32 as i64 as u64) { pc += 16 }
    mov64 r7, 0                                     r7 = 0 as i32 as i64 as u64
lbb_27407:
    ldxdw r2, [r10-0x18]                    
    mov64 r1, r2                                    r1 = r2
    jeq r2, r7, lbb_27418                           if r2 == r7 { pc += 8 }
    ldxdw r3, [r6+0x20]                     
    mov64 r1, r9                                    r1 = r9
    mov64 r2, r8                                    r2 = r8
    callx r3                                
    add64 r7, 1                                     r7 += 1   ///  r7 = r7.wrapping_add(1 as i32 as i64 as u64)
    jeq r0, 0, lbb_27407                            if r0 == (0 as i32 as i64 as u64) { pc += -9 }
    add64 r7, -1                                    r7 += -1   ///  r7 = r7.wrapping_add(-1 as i32 as i64 as u64)
    mov64 r1, r7                                    r1 = r7
lbb_27418:
    mov64 r0, 1                                     r0 = 1 as i32 as i64 as u64
    ldxdw r2, [r10-0x18]                    
    jgt r2, r1, lbb_27422                           if r2 > r1 { pc += 1 }
    mov64 r0, 0                                     r0 = 0 as i32 as i64 as u64
lbb_27422:
    and64 r0, 1                                     r0 &= 1   ///  r0 = r0.and(1)
    exit                                    

function_27424:
    mov64 r3, r2                                    r3 = r2
    mov64 r4, r1                                    r4 = r1
    ldxdw r1, [r4+0x0]                      
    jeq r1, 0, lbb_27508                            if r1 == (0 as i32 as i64 as u64) { pc += 80 }
    ldxdw r1, [r4+0x8]                      
    stxdw [r10-0x28], r1                    
    ldxdw r2, [r3+0x0]                      
    ldxdw r8, [r3+0x8]                      
    ldxdw r9, [r3+0x10]                     
    ldxdw r6, [r3+0x18]                     
    stxdw [r10-0x8], r6                     
    stxdw [r10-0x10], r9                    
    stxdw [r10-0x18], r8                    
    stxdw [r10-0x20], r2                    
    ldxb r7, [r4+0x38]                      
    ldxw r3, [r4+0x30]                      
    ldxw r1, [r4+0x34]                      
    and64 r1, 8                                     r1 &= 8   ///  r1 = r1.and(8)
    stxdw [r10-0x40], r3                    
    stxdw [r10-0x30], r3                    
    stxdw [r10-0x48], r7                    
    stxdw [r10-0x38], r4                    
    jeq r1, 0, lbb_27474                            if r1 == (0 as i32 as i64 as u64) { pc += 27 }
    ldxdw r1, [r4+0x20]                     
    ldxdw r3, [r4+0x28]                     
    ldxdw r4, [r3+0x18]                     
    mov64 r3, r8                                    r3 = r8
    callx r4                                
    jne r0, 0, lbb_27554                            if r0 != (0 as i32 as i64 as u64) { pc += 101 }
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    stxdw [r10-0x18], r1                    
    mov64 r7, 1                                     r7 = 1 as i32 as i64 as u64
    stxdw [r10-0x20], r7                    
    ldxdw r1, [r10-0x38]                    
    stxb [r1+0x38], r7                      
    mov64 r3, 48                                    r3 = 48 as i32 as i64 as u64
    mov64 r2, 48                                    r2 = 48 as i32 as i64 as u64
    stxdw [r10-0x30], r2                    
    stxw [r1+0x30], r3                      
    ldxdw r3, [r10-0x28]                    
    mov64 r1, r3                                    r1 = r3
    sub64 r1, r8                                    r1 -= r8   ///  r1 = r1.wrapping_sub(r8)
    mov64 r2, 1                                     r2 = 1 as i32 as i64 as u64
    jgt r1, r3, lbb_27469                           if r1 > r3 { pc += 1 }
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
lbb_27469:
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
    stxdw [r10-0x28], r3                    
    jne r2, 0, lbb_27473                            if r2 != (0 as i32 as i64 as u64) { pc += 1 }
    stxdw [r10-0x28], r1                    
lbb_27473:
    mov64 r8, 0                                     r8 = 0 as i32 as i64 as u64
lbb_27474:
    jeq r6, 0, lbb_27487                            if r6 == (0 as i32 as i64 as u64) { pc += 12 }
    mul64 r6, 24                                    r6 *= 24   ///  r6 = r6.wrapping_mul(24 as u64)
    add64 r9, 8                                     r9 += 8   ///  r9 = r9.wrapping_add(8 as i32 as i64 as u64)
    mov64 r1, 1000                                  r1 = 1000 as i32 as i64 as u64
    mov64 r2, 10                                    r2 = 10 as i32 as i64 as u64
    mov64 r3, 100                                   r3 = 100 as i32 as i64 as u64
    mov64 r4, 10000                                 r4 = 10000 as i32 as i64 as u64
    ja lbb_27490                                    if true { pc += 8 }
lbb_27482:
    ldxdw r8, [r9+0x0]                      
lbb_27483:
    add64 r8, r5                                    r8 += r5   ///  r8 = r8.wrapping_add(r5)
    add64 r9, 24                                    r9 += 24   ///  r9 = r9.wrapping_add(24 as i32 as i64 as u64)
    add64 r6, -24                                   r6 += -24   ///  r6 = r6.wrapping_add(-24 as i32 as i64 as u64)
    jne r6, 0, lbb_27490                            if r6 != (0 as i32 as i64 as u64) { pc += 3 }
lbb_27487:
    ldxdw r1, [r10-0x28]                    
    jgt r1, r8, lbb_27524                           if r1 > r8 { pc += 35 }
    ja lbb_27512                                    if true { pc += 22 }
lbb_27490:
    mov64 r5, r8                                    r5 = r8
    ldxh r0, [r9-0x8]                       
    jeq r0, 0, lbb_27482                            if r0 == (0 as i32 as i64 as u64) { pc += -11 }
    jeq r0, 1, lbb_27496                            if r0 == (1 as i32 as i64 as u64) { pc += 2 }
    ldxdw r8, [r9+0x8]                      
    ja lbb_27483                                    if true { pc += -13 }
lbb_27496:
    ldxh r0, [r9-0x6]                       
    jgt r1, r0, lbb_27502                           if r1 > r0 { pc += 4 }
    mov64 r8, 4                                     r8 = 4 as i32 as i64 as u64
    jgt r4, r0, lbb_27483                           if r4 > r0 { pc += -17 }
    mov64 r8, 5                                     r8 = 5 as i32 as i64 as u64
    ja lbb_27483                                    if true { pc += -19 }
lbb_27502:
    mov64 r8, 1                                     r8 = 1 as i32 as i64 as u64
    jgt r2, r0, lbb_27483                           if r2 > r0 { pc += -21 }
    mov64 r8, 2                                     r8 = 2 as i32 as i64 as u64
    jgt r3, r0, lbb_27483                           if r3 > r0 { pc += -23 }
    mov64 r8, 3                                     r8 = 3 as i32 as i64 as u64
    ja lbb_27483                                    if true { pc += -25 }
lbb_27508:
    ldxdw r2, [r4+0x28]                     
    ldxdw r1, [r4+0x20]                     
    call function_27580                     
    ja lbb_27555                                    if true { pc += 43 }
lbb_27512:
    ldxdw r6, [r10-0x38]                    
    ldxdw r2, [r6+0x28]                     
    ldxdw r1, [r6+0x20]                     
    mov64 r3, r10                                   r3 = r10
    add64 r3, -32                                   r3 += -32   ///  r3 = r3.wrapping_add(-32 as i32 as i64 as u64)
    call function_27580                     
    mov64 r2, r6                                    r2 = r6
lbb_27519:
    ldxdw r1, [r10-0x48]                    
    stxb [r2+0x38], r1                      
    ldxdw r1, [r10-0x40]                    
    stxw [r2+0x30], r1                      
    ja lbb_27555                                    if true { pc += 31 }
lbb_27524:
    sub64 r1, r8                                    r1 -= r8   ///  r1 = r1.wrapping_sub(r8)
    stxdw [r10-0x28], r1                    
    and64 r7, 255                                   r7 &= 255   ///  r7 = r7.and(255)
    ldxdw r1, [r10-0x38]                    
    jsgt r7, 1, lbb_27534                           if (r7 as i64) > (1 as i32 as i64) { pc += 5 }
    ldxdw r6, [r10-0x30]                    
    jeq r7, 0, lbb_27543                            if r7 == (0 as i32 as i64 as u64) { pc += 12 }
lbb_27531:
    ldxdw r7, [r10-0x28]                    
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
    ja lbb_27542                                    if true { pc += 8 }
lbb_27534:
    ldxdw r6, [r10-0x30]                    
    jeq r7, 2, lbb_27537                            if r7 == (2 as i32 as i64 as u64) { pc += 1 }
    ja lbb_27531                                    if true { pc += -6 }
lbb_27537:
    ldxdw r2, [r10-0x28]                    
    mov64 r7, r2                                    r7 = r2
    rsh64 r7, 1                                     r7 >>= 1   ///  r7 = r7.wrapping_shr(1)
    add64 r2, 1                                     r2 += 1   ///  r2 = r2.wrapping_add(1 as i32 as i64 as u64)
    rsh64 r2, 1                                     r2 >>= 1   ///  r2 = r2.wrapping_shr(1)
lbb_27542:
    stxdw [r10-0x28], r2                    
lbb_27543:
    add64 r7, 1                                     r7 += 1   ///  r7 = r7.wrapping_add(1 as i32 as i64 as u64)
    ldxdw r8, [r1+0x28]                     
    ldxdw r9, [r1+0x20]                     
lbb_27546:
    add64 r7, -1                                    r7 += -1   ///  r7 = r7.wrapping_add(-1 as i32 as i64 as u64)
    jeq r7, 0, lbb_27557                            if r7 == (0 as i32 as i64 as u64) { pc += 9 }
    ldxdw r3, [r8+0x20]                     
    mov64 r1, r9                                    r1 = r9
    mov64 r2, r6                                    r2 = r6
    callx r3                                
    jne r0, 0, lbb_27554                            if r0 != (0 as i32 as i64 as u64) { pc += 1 }
    ja lbb_27546                                    if true { pc += -8 }
lbb_27554:
    mov64 r0, 1                                     r0 = 1 as i32 as i64 as u64
lbb_27555:
    and64 r0, 1                                     r0 &= 1   ///  r0 = r0.and(1)
    exit                                    
lbb_27557:
    mov64 r3, r10                                   r3 = r10
    add64 r3, -32                                   r3 += -32   ///  r3 = r3.wrapping_add(-32 as i32 as i64 as u64)
    mov64 r1, r9                                    r1 = r9
    mov64 r2, r8                                    r2 = r8
    call function_27580                     
    jne r0, 0, lbb_27554                            if r0 != (0 as i32 as i64 as u64) { pc += -9 }
    mov64 r6, 0                                     r6 = 0 as i32 as i64 as u64
    ldxdw r7, [r10-0x28]                    
lbb_27565:
    mov64 r1, r7                                    r1 = r7
    jeq r7, r6, lbb_27575                           if r7 == r6 { pc += 8 }
    ldxdw r3, [r8+0x20]                     
    mov64 r1, r9                                    r1 = r9
    ldxdw r2, [r10-0x30]                    
    callx r3                                
    add64 r6, 1                                     r6 += 1   ///  r6 = r6.wrapping_add(1 as i32 as i64 as u64)
    jeq r0, 0, lbb_27565                            if r0 == (0 as i32 as i64 as u64) { pc += -8 }
    add64 r6, -1                                    r6 += -1   ///  r6 = r6.wrapping_add(-1 as i32 as i64 as u64)
    mov64 r1, r6                                    r1 = r6
lbb_27575:
    mov64 r0, 1                                     r0 = 1 as i32 as i64 as u64
    ldxdw r2, [r10-0x38]                    
    jgt r7, r1, lbb_27519                           if r7 > r1 { pc += -59 }
    mov64 r0, 0                                     r0 = 0 as i32 as i64 as u64
    ja lbb_27519                                    if true { pc += -61 }

function_27580:
    mov64 r8, r3                                    r8 = r3
    stxdw [r10-0x10], r2                    
    mov64 r7, r1                                    r7 = r1
    ldxdw r3, [r8+0x8]                      
    jeq r3, 0, lbb_27593                            if r3 == (0 as i32 as i64 as u64) { pc += 8 }
    ldxdw r1, [r10-0x10]                    
    ldxdw r4, [r1+0x18]                     
    ldxdw r2, [r8+0x0]                      
    mov64 r1, r7                                    r1 = r7
    callx r4                                
    mov64 r1, r0                                    r1 = r0
    mov64 r0, 1                                     r0 = 1 as i32 as i64 as u64
    jne r1, 0, lbb_27690                            if r1 != (0 as i32 as i64 as u64) { pc += 97 }
lbb_27593:
    mov64 r0, 0                                     r0 = 0 as i32 as i64 as u64
    ldxdw r1, [r8+0x18]                     
    jeq r1, 0, lbb_27690                            if r1 == (0 as i32 as i64 as u64) { pc += 94 }
    ldxdw r9, [r8+0x10]                     
    mul64 r1, 24                                    r1 *= 24   ///  r1 = r1.wrapping_mul(24 as u64)
    mov64 r2, r9                                    r2 = r9
    add64 r2, r1                                    r2 += r1   ///  r2 = r2.wrapping_add(r1)
    stxdw [r10-0x18], r2                    
    ja lbb_27617                                    if true { pc += 15 }
lbb_27602:
    jeq r8, 0, lbb_27613                            if r8 == (0 as i32 as i64 as u64) { pc += 10 }
lbb_27603:
    ldxdw r1, [r10-0x10]                    
    ldxdw r4, [r1+0x18]                     
    mov64 r1, r7                                    r1 = r7
    lddw r2, 0x10004001f --> b"00000000000000000000000000000000000000000000000000"        r2 load str located at 4295229471
    mov64 r3, r8                                    r3 = r8
    callx r4                                
    mov64 r1, r0                                    r1 = r0
    mov64 r0, 1                                     r0 = 1 as i32 as i64 as u64
    jne r1, 0, lbb_27690                            if r1 != (0 as i32 as i64 as u64) { pc += 77 }
lbb_27613:
    add64 r9, 24                                    r9 += 24   ///  r9 = r9.wrapping_add(24 as i32 as i64 as u64)
    mov64 r0, 0                                     r0 = 0 as i32 as i64 as u64
    ldxdw r1, [r10-0x18]                    
    jeq r9, r1, lbb_27690                           if r9 == r1 { pc += 73 }
lbb_27617:
    ldxh r1, [r9+0x0]                       
    jeq r1, 0, lbb_27641                            if r1 == (0 as i32 as i64 as u64) { pc += 22 }
    jeq r1, 1, lbb_27630                            if r1 == (1 as i32 as i64 as u64) { pc += 10 }
    ldxdw r1, [r10-0x10]                    
    ldxdw r4, [r1+0x18]                     
    ldxdw r3, [r9+0x10]                     
    ldxdw r2, [r9+0x8]                      
    mov64 r1, r7                                    r1 = r7
    callx r4                                
    mov64 r1, r0                                    r1 = r0
    mov64 r0, 1                                     r0 = 1 as i32 as i64 as u64
    jne r1, 0, lbb_27690                            if r1 != (0 as i32 as i64 as u64) { pc += 61 }
    ja lbb_27613                                    if true { pc += -17 }
lbb_27630:
    ldxh r1, [r9+0x2]                       
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
    stxb [r10-0x4], r2                      
    stxw [r10-0x8], r2                      
    mov64 r2, 1000                                  r2 = 1000 as i32 as i64 as u64
    jgt r2, r1, lbb_27657                           if r2 > r1 { pc += 21 }
    mov64 r3, 4                                     r3 = 4 as i32 as i64 as u64
    mov64 r2, 10000                                 r2 = 10000 as i32 as i64 as u64
    jgt r2, r1, lbb_27664                           if r2 > r1 { pc += 25 }
    mov64 r3, 5                                     r3 = 5 as i32 as i64 as u64
    ja lbb_27664                                    if true { pc += 23 }
lbb_27641:
    ldxdw r8, [r9+0x8]                      
    mov64 r1, 65                                    r1 = 65 as i32 as i64 as u64
    jgt r1, r8, lbb_27602                           if r1 > r8 { pc += -42 }
    ldxdw r1, [r10-0x10]                    
    ldxdw r6, [r1+0x18]                     
lbb_27646:
    mov64 r1, r7                                    r1 = r7
    lddw r2, 0x10004001f --> b"0000000000000000000000000000000000000000000000000000000000000000"        r2 load str located at 4295229471
    mov64 r3, 64                                    r3 = 64 as i32 as i64 as u64
    callx r6                                
    mov64 r1, r0                                    r1 = r0
    mov64 r0, 1                                     r0 = 1 as i32 as i64 as u64
    jne r1, 0, lbb_27690                            if r1 != (0 as i32 as i64 as u64) { pc += 36 }
    add64 r8, -64                                   r8 += -64   ///  r8 = r8.wrapping_add(-64 as i32 as i64 as u64)
    jgt r8, 64, lbb_27646                           if r8 > (64 as i32 as i64 as u64) { pc += -10 }
    ja lbb_27603                                    if true { pc += -54 }
lbb_27657:
    mov64 r3, 1                                     r3 = 1 as i32 as i64 as u64
    mov64 r2, 10                                    r2 = 10 as i32 as i64 as u64
    jgt r2, r1, lbb_27664                           if r2 > r1 { pc += 4 }
    mov64 r3, 2                                     r3 = 2 as i32 as i64 as u64
    mov64 r2, 100                                   r2 = 100 as i32 as i64 as u64
    jgt r2, r1, lbb_27664                           if r2 > r1 { pc += 1 }
    mov64 r3, 3                                     r3 = 3 as i32 as i64 as u64
lbb_27664:
    mov64 r2, r3                                    r2 = r3
    mov64 r4, r1                                    r4 = r1
lbb_27666:
    and64 r4, 65535                                 r4 &= 65535   ///  r4 = r4.and(65535)
    div64 r4, 10                                    r4 /= 10   ///  r4 = r4 / (10 as u64)
    mov64 r5, r4                                    r5 = r4
    mul64 r5, 10                                    r5 *= 10   ///  r5 = r5.wrapping_mul(10 as u64)
    sub64 r1, r5                                    r1 -= r5   ///  r1 = r1.wrapping_sub(r5)
    mov64 r5, r10                                   r5 = r10
    add64 r5, -8                                    r5 += -8   ///  r5 = r5.wrapping_add(-8 as i32 as i64 as u64)
    add64 r5, r2                                    r5 += r2   ///  r5 = r5.wrapping_add(r2)
    or64 r1, 48                                     r1 |= 48   ///  r1 = r1.or(48)
    stxb [r5-0x1], r1                       
    add64 r2, -1                                    r2 += -1   ///  r2 = r2.wrapping_add(-1 as i32 as i64 as u64)
    mov64 r1, r4                                    r1 = r4
    jeq r2, 0, lbb_27680                            if r2 == (0 as i32 as i64 as u64) { pc += 1 }
    ja lbb_27666                                    if true { pc += -14 }
lbb_27680:
    ldxdw r1, [r10-0x10]                    
    ldxdw r4, [r1+0x18]                     
    mov64 r2, r10                                   r2 = r10
    add64 r2, -8                                    r2 += -8   ///  r2 = r2.wrapping_add(-8 as i32 as i64 as u64)
    mov64 r1, r7                                    r1 = r7
    callx r4                                
    mov64 r1, r0                                    r1 = r0
    mov64 r0, 1                                     r0 = 1 as i32 as i64 as u64
    jne r1, 0, lbb_27690                            if r1 != (0 as i32 as i64 as u64) { pc += 1 }
    ja lbb_27613                                    if true { pc += -77 }
lbb_27690:
    exit                                    

function_27691:
    ldxdw r4, [r1+0x20]                     
    ldxdw r1, [r1+0x28]                     
    ldxdw r5, [r1+0x18]                     
    mov64 r1, r4                                    r1 = r4
    callx r5                                
    exit                                    

function_27697:
    mov64 r6, r2                                    r6 = r2
    mov64 r7, r1                                    r7 = r1
    ldxdw r1, [r6+0x28]                     
    ldxdw r5, [r1+0x18]                     
    ldxdw r1, [r6+0x20]                     
    mov64 r2, r3                                    r2 = r3
    mov64 r3, r4                                    r3 = r4
    callx r5                                
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    stxb [r7+0x9], r1                       
    stxb [r7+0x8], r0                       
    stxdw [r7+0x0], r6                      
    exit                                    

function_27710:
    mov64 r6, r5                                    r6 = r5
    mov64 r7, r4                                    r7 = r4
    mov64 r8, r1                                    r8 = r1
    ldxdw r1, [r8+0x28]                     
    ldxdw r4, [r1+0x18]                     
    ldxdw r1, [r8+0x20]                     
    callx r4                                
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    stxb [r10-0x7], r1                      
    stxb [r10-0x8], r0                      
    stxdw [r10-0x10], r8                    
    ldxdw r3, [r6-0x1000]                   
    ldxdw r4, [r6-0xff8]                    
    ldxdw r5, [r6-0xff0]                    
    mov64 r8, r10                                   r8 = r10
    add64 r8, -16                                   r8 += -16   ///  r8 = r8.wrapping_add(-16 as i32 as i64 as u64)
    mov64 r1, r8                                    r1 = r8
    mov64 r2, r7                                    r2 = r7
    call function_26188                     
    ldxdw r2, [r6-0xfe8]                    
    ldxdw r3, [r6-0xfe0]                    
    ldxdw r4, [r6-0xfd8]                    
    ldxdw r5, [r6-0xfd0]                    
    mov64 r1, r8                                    r1 = r8
    call function_26188                     
    ldxb r1, [r10-0x8]                      
    ldxb r2, [r10-0x7]                      
    jne r2, 0, lbb_27742                            if r2 != (0 as i32 as i64 as u64) { pc += 4 }
    mov64 r0, 1                                     r0 = 1 as i32 as i64 as u64
    jne r1, 0, lbb_27762                            if r1 != (0 as i32 as i64 as u64) { pc += 22 }
    mov64 r0, 0                                     r0 = 0 as i32 as i64 as u64
    ja lbb_27762                                    if true { pc += 20 }
lbb_27742:
    mov64 r0, 1                                     r0 = 1 as i32 as i64 as u64
    jne r1, 0, lbb_27762                            if r1 != (0 as i32 as i64 as u64) { pc += 18 }
    ldxdw r2, [r10-0x10]                    
    ldxw r1, [r2+0x34]                      
    and64 r1, 4                                     r1 &= 4   ///  r1 = r1.and(4)
    jne r1, 0, lbb_27755                            if r1 != (0 as i32 as i64 as u64) { pc += 7 }
    ldxdw r1, [r2+0x20]                     
    ldxdw r2, [r2+0x28]                     
    ldxdw r4, [r2+0x18]                     
    lddw r2, 0x10003ff34 --> b" }"                  r2 load str located at 4295229236
    mov64 r3, 2                                     r3 = 2 as i32 as i64 as u64
    ja lbb_27761                                    if true { pc += 6 }
lbb_27755:
    ldxdw r1, [r2+0x20]                     
    ldxdw r2, [r2+0x28]                     
    ldxdw r4, [r2+0x18]                     
    lddw r2, 0x10003ff33 --> b"}"                   r2 load str located at 4295229235
    mov64 r3, 1                                     r3 = 1 as i32 as i64 as u64
lbb_27761:
    callx r4                                
lbb_27762:
    and64 r0, 1                                     r0 &= 1   ///  r0 = r0.and(1)
    exit                                    

function_27764:
    mov64 r7, r4                                    r7 = r4
    mov64 r8, r2                                    r8 = r2
    mov64 r6, r1                                    r6 = r1
    ldxdw r1, [r8+0x28]                     
    ldxdw r4, [r1+0x18]                     
    ldxdw r1, [r8+0x20]                     
    mov64 r2, r3                                    r2 = r3
    mov64 r3, r7                                    r3 = r7
    callx r4                                
    stxb [r6+0x10], r0                      
    stxdw [r6+0x8], r8                      
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    mov64 r2, 1                                     r2 = 1 as i32 as i64 as u64
    jeq r7, 0, lbb_27779                            if r7 == (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
lbb_27779:
    stxb [r6+0x11], r2                      
    stxdw [r6+0x0], r1                      
    exit                                    

function_27782:
    mov64 r6, r5                                    r6 = r5
    mov64 r7, r4                                    r7 = r4
    mov64 r8, r3                                    r8 = r3
    mov64 r9, r1                                    r9 = r1
    ldxdw r1, [r9+0x28]                     
    ldxdw r4, [r1+0x18]                     
    ldxdw r1, [r9+0x20]                     
    callx r4                                
    stxb [r10-0x8], r0                      
    stxdw [r10-0x10], r9                    
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    mov64 r2, 1                                     r2 = 1 as i32 as i64 as u64
    jeq r8, 0, lbb_27796                            if r8 == (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
lbb_27796:
    stxb [r10-0x7], r2                      
    stxdw [r10-0x18], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -24                                   r1 += -24   ///  r1 = r1.wrapping_add(-24 as i32 as i64 as u64)
    mov64 r2, r7                                    r2 = r7
    mov64 r3, r6                                    r3 = r6
    call function_26346                     
    ldxb r2, [r10-0x8]                      
    ldxdw r1, [r10-0x18]                    
    jne r1, 0, lbb_27811                            if r1 != (0 as i32 as i64 as u64) { pc += 5 }
    mov64 r1, r2                                    r1 = r2
    mov64 r0, 1                                     r0 = 1 as i32 as i64 as u64
    jne r1, 0, lbb_27838                            if r1 != (0 as i32 as i64 as u64) { pc += 29 }
    mov64 r0, 0                                     r0 = 0 as i32 as i64 as u64
    ja lbb_27838                                    if true { pc += 27 }
lbb_27811:
    mov64 r0, 1                                     r0 = 1 as i32 as i64 as u64
    jne r2, 0, lbb_27838                            if r2 != (0 as i32 as i64 as u64) { pc += 25 }
    ldxdw r6, [r10-0x10]                    
    jne r1, 1, lbb_27817                            if r1 != (1 as i32 as i64 as u64) { pc += 2 }
    ldxb r1, [r10-0x7]                      
    jne r1, 0, lbb_27825                            if r1 != (0 as i32 as i64 as u64) { pc += 8 }
lbb_27817:
    ldxdw r1, [r6+0x20]                     
    ldxdw r2, [r6+0x28]                     
    ldxdw r4, [r2+0x18]                     
    lddw r2, 0x10003fe60 --> b")"                   r2 load str located at 4295229024
    mov64 r3, 1                                     r3 = 1 as i32 as i64 as u64
    callx r4                                
    ja lbb_27838                                    if true { pc += 13 }
lbb_27825:
    ldxw r1, [r6+0x34]                      
    and64 r1, 4                                     r1 &= 4   ///  r1 = r1.and(4)
    jne r1, 0, lbb_27817                            if r1 != (0 as i32 as i64 as u64) { pc += -11 }
    ldxdw r1, [r6+0x20]                     
    ldxdw r2, [r6+0x28]                     
    ldxdw r4, [r2+0x18]                     
    lddw r2, 0x10003ff39 --> b","                   r2 load str located at 4295229241
    mov64 r3, 1                                     r3 = 1 as i32 as i64 as u64
    callx r4                                
    mov64 r1, r0                                    r1 = r0
    mov64 r0, 1                                     r0 = 1 as i32 as i64 as u64
    jeq r1, 0, lbb_27817                            if r1 == (0 as i32 as i64 as u64) { pc += -21 }
lbb_27838:
    and64 r0, 1                                     r0 &= 1   ///  r0 = r0.and(1)
    exit                                    

function_27840:
    ldxdw r3, [r1+0x20]                     
    ldxdw r1, [r1+0x28]                     
    ldxdw r4, [r1+0x20]                     
    mov64 r1, r3                                    r1 = r3
    callx r4                                
    exit                                    

function_27846:
    ldxb r1, [r1+0x0]                       
    jne r1, 0, lbb_27853                            if r1 != (0 as i32 as i64 as u64) { pc += 5 }
    mov64 r1, r2                                    r1 = r2
    lddw r2, 0x10004005f --> b"false"               r2 load str located at 4295229535
    mov64 r3, 5                                     r3 = 5 as i32 as i64 as u64
    ja lbb_27857                                    if true { pc += 4 }
lbb_27853:
    mov64 r1, r2                                    r1 = r2
    lddw r2, 0x10003edc6 --> b"true"                r2 load str located at 4295224774
    mov64 r3, 4                                     r3 = 4 as i32 as i64 as u64
lbb_27857:
    call function_27252                     
    exit                                    

function_27859:
    mov64 r6, r2                                    r6 = r2
    mov64 r8, r1                                    r8 = r1
    ldxdw r7, [r3+0x20]                     
    ldxdw r1, [r3+0x28]                     
    stxdw [r10-0x50], r1                    
    ldxdw r3, [r1+0x20]                     
    mov64 r1, r7                                    r1 = r7
    mov64 r2, 34                                    r2 = 34 as i32 as i64 as u64
    stxdw [r10-0x28], r3                    
    callx r3                                
    mov64 r9, 1                                     r9 = 1 as i32 as i64 as u64
    jne r0, 0, lbb_28084                            if r0 != (0 as i32 as i64 as u64) { pc += 213 }
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    jeq r6, 0, lbb_28070                            if r6 == (0 as i32 as i64 as u64) { pc += 197 }
    mov64 r1, r8                                    r1 = r8
    add64 r1, r6                                    r1 += r6   ///  r1 = r1.wrapping_add(r6)
    stxdw [r10-0x48], r1                    
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    stxdw [r10-0x58], r1                    
    mov64 r5, r8                                    r5 = r8
    mov64 r9, 0                                     r9 = 0 as i32 as i64 as u64
    stxdw [r10-0x60], r6                    
    stxdw [r10-0x68], r8                    
    ja lbb_27890                                    if true { pc += 7 }
lbb_27883:
    add64 r2, r9                                    r2 += r9   ///  r2 = r2.wrapping_add(r9)
    stxdw [r10-0x58], r2                    
lbb_27885:
    sub64 r9, r3                                    r9 -= r3   ///  r9 = r9.wrapping_sub(r3)
    ldxdw r5, [r10-0x30]                    
    add64 r9, r5                                    r9 += r5   ///  r9 = r9.wrapping_add(r5)
    ldxdw r1, [r10-0x48]                    
    jeq r5, r1, lbb_28062                           if r5 == r1 { pc += 172 }
lbb_27890:
    ldxb r0, [r5+0x0]                       
    mov64 r1, r0                                    r1 = r0
    lsh64 r1, 56                                    r1 <<= 56   ///  r1 = r1.wrapping_shl(56)
    arsh64 r1, 56                                   r1 >>= 56 (signed)   ///  r1 = (r1 as i64).wrapping_shr(56)
    jsgt r1, -1, lbb_27932                          if (r1 as i64) > (-1 as i32 as i64) { pc += 37 }
    mov64 r1, r5                                    r1 = r5
    add64 r1, 2                                     r1 += 2   ///  r1 = r1.wrapping_add(2 as i32 as i64 as u64)
    stxdw [r10-0x30], r1                    
    ldxb r1, [r5+0x1]                       
    and64 r1, 63                                    r1 &= 63   ///  r1 = r1.and(63)
    mov64 r3, r0                                    r3 = r0
    and64 r3, 31                                    r3 &= 31   ///  r3 = r3.and(31)
    mov64 r2, r3                                    r2 = r3
    lsh64 r2, 6                                     r2 <<= 6   ///  r2 = r2.wrapping_shl(6)
    or64 r2, r1                                     r2 |= r1   ///  r2 = r2.or(r1)
    jgt r0, 223, lbb_27907                          if r0 > (223 as i32 as i64 as u64) { pc += 1 }
    ja lbb_27936                                    if true { pc += 29 }
lbb_27907:
    lsh64 r1, 6                                     r1 <<= 6   ///  r1 = r1.wrapping_shl(6)
    ldxb r4, [r5+0x2]                       
    and64 r4, 63                                    r4 &= 63   ///  r4 = r4.and(63)
    or64 r1, r4                                     r1 |= r4   ///  r1 = r1.or(r4)
    mov64 r4, r5                                    r4 = r5
    add64 r4, 3                                     r4 += 3   ///  r4 = r4.wrapping_add(3 as i32 as i64 as u64)
    stxdw [r10-0x30], r4                    
    mov64 r4, r3                                    r4 = r3
    lsh64 r4, 12                                    r4 <<= 12   ///  r4 = r4.wrapping_shl(12)
    mov64 r2, r1                                    r2 = r1
    or64 r2, r4                                     r2 |= r4   ///  r2 = r2.or(r4)
    mov64 r4, 240                                   r4 = 240 as i32 as i64 as u64
    jgt r4, r0, lbb_27936                           if r4 > r0 { pc += 16 }
    lsh64 r1, 6                                     r1 <<= 6   ///  r1 = r1.wrapping_shl(6)
    ldxb r2, [r5+0x3]                       
    and64 r2, 63                                    r2 &= 63   ///  r2 = r2.and(63)
    or64 r1, r2                                     r1 |= r2   ///  r1 = r1.or(r2)
    lsh64 r3, 18                                    r3 <<= 18   ///  r3 = r3.wrapping_shl(18)
    and64 r3, 1835008                               r3 &= 1835008   ///  r3 = r3.and(1835008)
    or64 r1, r3                                     r1 |= r3   ///  r1 = r1.or(r3)
    mov64 r2, r5                                    r2 = r5
    add64 r2, 4                                     r2 += 4   ///  r2 = r2.wrapping_add(4 as i32 as i64 as u64)
    stxdw [r10-0x30], r2                    
    mov64 r2, r1                                    r2 = r1
    ja lbb_27936                                    if true { pc += 4 }
lbb_27932:
    mov64 r1, r5                                    r1 = r5
    add64 r1, 1                                     r1 += 1   ///  r1 = r1.wrapping_add(1 as i32 as i64 as u64)
    stxdw [r10-0x30], r1                    
    mov64 r2, r0                                    r2 = r0
lbb_27936:
    mov64 r1, r10                                   r1 = r10
    add64 r1, -28                                   r1 += -28   ///  r1 = r1.wrapping_add(-28 as i32 as i64 as u64)
    stxdw [r10-0x40], r2                    
    mov64 r3, 65537                                 r3 = 65537 as i32 as i64 as u64
    stxdw [r10-0x38], r5                    
    call function_25366                     
    ldxdw r3, [r10-0x38]                    
    ldxb r1, [r10-0x1c]                     
    jeq r1, 128, lbb_27885                          if r1 == (128 as i32 as i64 as u64) { pc += -60 }
    ldxb r1, [r10-0x12]                     
    ldxb r2, [r10-0x11]                     
    sub64 r2, r1                                    r2 -= r1   ///  r2 = r2.wrapping_sub(r1)
    and64 r2, 255                                   r2 &= 255   ///  r2 = r2.and(255)
    jeq r2, 1, lbb_27885                            if r2 == (1 as i32 as i64 as u64) { pc += -65 }
    ldxdw r4, [r10-0x58]                    
    jgt r4, r9, lbb_28008                           if r4 > r9 { pc += 56 }
    jeq r4, 0, lbb_27963                            if r4 == (0 as i32 as i64 as u64) { pc += 10 }
    jgt r6, r4, lbb_27956                           if r6 > r4 { pc += 2 }
    jeq r4, r6, lbb_27963                           if r4 == r6 { pc += 8 }
    ja lbb_28008                                    if true { pc += 52 }
lbb_27956:
    mov64 r1, r8                                    r1 = r8
    add64 r1, r4                                    r1 += r4   ///  r1 = r1.wrapping_add(r4)
    ldxb r1, [r1+0x0]                       
    lsh64 r1, 56                                    r1 <<= 56   ///  r1 = r1.wrapping_shl(56)
    arsh64 r1, 56                                   r1 >>= 56 (signed)   ///  r1 = (r1 as i64).wrapping_shr(56)
    mov64 r2, -64                                   r2 = -64 as i32 as i64 as u64
    jsgt r2, r1, lbb_28008                          if (r2 as i64) > (r1 as i64) { pc += 45 }
lbb_27963:
    jeq r9, 0, lbb_27967                            if r9 == (0 as i32 as i64 as u64) { pc += 3 }
    jgt r6, r9, lbb_28002                           if r6 > r9 { pc += 37 }
    jeq r9, r6, lbb_27967                           if r9 == r6 { pc += 1 }
    ja lbb_28008                                    if true { pc += 41 }
lbb_27967:
    mov64 r2, r8                                    r2 = r8
    add64 r2, r4                                    r2 += r4   ///  r2 = r2.wrapping_add(r4)
    mov64 r3, r9                                    r3 = r9
    sub64 r3, r4                                    r3 -= r4   ///  r3 = r3.wrapping_sub(r4)
    ldxdw r1, [r10-0x50]                    
    ldxdw r4, [r1+0x18]                     
    mov64 r1, r7                                    r1 = r7
    callx r4                                
    jne r0, 0, lbb_28060                            if r0 != (0 as i32 as i64 as u64) { pc += 84 }
    mov64 r8, r7                                    r8 = r7
    ldxw r1, [r10-0x14]                     
    stxw [r10-0x8], r1                      
    ldxdw r1, [r10-0x1c]                    
    stxdw [r10-0x10], r1                    
    and64 r1, 255                                   r1 &= 255   ///  r1 = r1.and(255)
    jne r1, 128, lbb_27985                          if r1 != (128 as i32 as i64 as u64) { pc += 2 }
    mov64 r7, 128                                   r7 = 128 as i32 as i64 as u64
    ja lbb_28035                                    if true { pc += 50 }
lbb_27985:
    ldxb r7, [r10-0x5]                      
    ldxb r1, [r10-0x6]                      
lbb_27987:
    jge r1, r7, lbb_28044                           if r1 >= r7 { pc += 56 }
    mov64 r6, r1                                    r6 = r1
    add64 r6, 1                                     r6 += 1   ///  r6 = r6.wrapping_add(1 as i32 as i64 as u64)
    stxb [r10-0x6], r6                      
    jgt r1, 9, lbb_28023                            if r1 > (9 as i32 as i64 as u64) { pc += 31 }
    mov64 r2, r10                                   r2 = r10
    add64 r2, -16                                   r2 += -16   ///  r2 = r2.wrapping_add(-16 as i32 as i64 as u64)
    add64 r2, r1                                    r2 += r1   ///  r2 = r2.wrapping_add(r1)
    ldxb r2, [r2+0x0]                       
    mov64 r1, r8                                    r1 = r8
    ldxdw r3, [r10-0x28]                    
    callx r3                                
    mov64 r1, r6                                    r1 = r6
    jne r0, 0, lbb_28060                            if r0 != (0 as i32 as i64 as u64) { pc += 59 }
    ja lbb_27987                                    if true { pc += -15 }
lbb_28002:
    mov64 r1, r8                                    r1 = r8
    add64 r1, r9                                    r1 += r9   ///  r1 = r1.wrapping_add(r9)
    ldxb r1, [r1+0x0]                       
    lsh64 r1, 56                                    r1 <<= 56   ///  r1 = r1.wrapping_shl(56)
    arsh64 r1, 56                                   r1 >>= 56 (signed)   ///  r1 = (r1 as i64).wrapping_shr(56)
    jsgt r1, -65, lbb_27967                         if (r1 as i64) > (-65 as i32 as i64) { pc += -41 }
lbb_28008:
    mov64 r1, r8                                    r1 = r8
    mov64 r2, r6                                    r2 = r6
    mov64 r3, r4                                    r3 = r4
    mov64 r4, r9                                    r4 = r9
    lddw r5, 0x100042000 --> b"\x00\x00\x00\x00E\xfe\x03\x00\x1b\x00\x00\x00\x00\x00\x00\x00_\x09\x00\x0…        r5 load str located at 4295237632
    call function_28827                     
lbb_28015:
    ldxb r1, [r10-0x6]                      
    ldxb r2, [r10-0x5]                      
    jge r1, r2, lbb_28044                           if r1 >= r2 { pc += 26 }
    mov64 r2, r1                                    r2 = r1
    add64 r2, 1                                     r2 += 1   ///  r2 = r2.wrapping_add(1 as i32 as i64 as u64)
    stxb [r10-0x6], r2                      
    mov64 r2, 10                                    r2 = 10 as i32 as i64 as u64
    jgt r2, r1, lbb_28027                           if r2 > r1 { pc += 4 }
lbb_28023:
    mov64 r2, 10                                    r2 = 10 as i32 as i64 as u64
    lddw r3, 0x1000421f8 --> b"\x00\x00\x00\x00?\x08\x04\x00\x1a\x00\x00\x00\x00\x00\x00\x00f\x00\x00\x0…        r3 load str located at 4295238136
    call function_25832                     
lbb_28027:
    mov64 r2, r10                                   r2 = r10
    add64 r2, -16                                   r2 += -16   ///  r2 = r2.wrapping_add(-16 as i32 as i64 as u64)
    add64 r2, r1                                    r2 += r1   ///  r2 = r2.wrapping_add(r1)
    ldxb r2, [r2+0x0]                       
lbb_28031:
    mov64 r1, r8                                    r1 = r8
    ldxdw r3, [r10-0x28]                    
    callx r3                                
    jne r0, 0, lbb_28060                            if r0 != (0 as i32 as i64 as u64) { pc += 25 }
lbb_28035:
    mov64 r1, r7                                    r1 = r7
    and64 r1, 255                                   r1 &= 255   ///  r1 = r1.and(255)
    jeq r1, 128, lbb_28039                          if r1 == (128 as i32 as i64 as u64) { pc += 1 }
    ja lbb_28015                                    if true { pc += -24 }
lbb_28039:
    mov64 r7, 0                                     r7 = 0 as i32 as i64 as u64
    stxw [r10-0x8], r7                      
    ldxw r2, [r10-0xc]                      
    stxdw [r10-0x10], r7                    
    ja lbb_28031                                    if true { pc += -13 }
lbb_28044:
    mov64 r2, 1                                     r2 = 1 as i32 as i64 as u64
    ldxdw r6, [r10-0x60]                    
    mov64 r7, r8                                    r7 = r8
    ldxdw r8, [r10-0x68]                    
    mov64 r1, 128                                   r1 = 128 as i32 as i64 as u64
    ldxdw r3, [r10-0x38]                    
    ldxdw r4, [r10-0x40]                    
    jgt r1, r4, lbb_27883                           if r1 > r4 { pc += -169 }
    mov64 r2, 2                                     r2 = 2 as i32 as i64 as u64
    mov64 r1, 2048                                  r1 = 2048 as i32 as i64 as u64
    jgt r1, r4, lbb_27883                           if r1 > r4 { pc += -172 }
    mov64 r2, 3                                     r2 = 3 as i32 as i64 as u64
    mov64 r1, 65536                                 r1 = 65536 as i32 as i64 as u64
    jgt r1, r4, lbb_27883                           if r1 > r4 { pc += -175 }
    mov64 r2, 4                                     r2 = 4 as i32 as i64 as u64
    ja lbb_27883                                    if true { pc += -177 }
lbb_28060:
    mov64 r9, 1                                     r9 = 1 as i32 as i64 as u64
    ja lbb_28084                                    if true { pc += 22 }
lbb_28062:
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    mov64 r9, 1                                     r9 = 1 as i32 as i64 as u64
    ldxdw r3, [r10-0x58]                    
    jeq r3, 0, lbb_28070                            if r3 == (0 as i32 as i64 as u64) { pc += 4 }
    jgt r6, r3, lbb_28086                           if r6 > r3 { pc += 19 }
    mov64 r1, r3                                    r1 = r3
    jeq r3, r6, lbb_28070                           if r3 == r6 { pc += 1 }
    ja lbb_28093                                    if true { pc += 23 }
lbb_28070:
    add64 r8, r1                                    r8 += r1   ///  r8 = r8.wrapping_add(r1)
    sub64 r6, r1                                    r6 -= r1   ///  r6 = r6.wrapping_sub(r1)
    ldxdw r1, [r10-0x50]                    
    ldxdw r4, [r1+0x18]                     
    mov64 r1, r7                                    r1 = r7
    mov64 r2, r8                                    r2 = r8
    mov64 r3, r6                                    r3 = r6
    callx r4                                
    jne r0, 0, lbb_28084                            if r0 != (0 as i32 as i64 as u64) { pc += 5 }
    mov64 r1, r7                                    r1 = r7
    mov64 r2, 34                                    r2 = 34 as i32 as i64 as u64
    ldxdw r3, [r10-0x28]                    
    callx r3                                
    mov64 r9, r0                                    r9 = r0
lbb_28084:
    mov64 r0, r9                                    r0 = r9
    exit                                    
lbb_28086:
    mov64 r1, r8                                    r1 = r8
    add64 r1, r3                                    r1 += r3   ///  r1 = r1.wrapping_add(r3)
    ldxb r2, [r1+0x0]                       
    lsh64 r2, 56                                    r2 <<= 56   ///  r2 = r2.wrapping_shl(56)
    arsh64 r2, 56                                   r2 >>= 56 (signed)   ///  r2 = (r2 as i64).wrapping_shr(56)
    mov64 r1, r3                                    r1 = r3
    jsgt r2, -65, lbb_28070                         if (r2 as i64) > (-65 as i32 as i64) { pc += -23 }
lbb_28093:
    mov64 r1, r8                                    r1 = r8
    mov64 r2, r6                                    r2 = r6
    mov64 r4, r6                                    r4 = r6
    lddw r5, 0x100041fe8 --> b"\x00\x00\x00\x00E\xfe\x03\x00\x1b\x00\x00\x00\x00\x00\x00\x00f\x09\x00\x0…        r5 load str located at 4295237608
    call function_28827                     

function_28099:
    mov64 r4, r2                                    r4 = r2
    mov64 r2, r1                                    r2 = r1
    mov64 r1, r3                                    r1 = r3
    mov64 r3, r4                                    r3 = r4
    call function_27252                     
    exit                                    

function_28105:
    mov64 r8, r1                                    r8 = r1
    ldxdw r6, [r2+0x20]                     
    ldxdw r1, [r2+0x28]                     
    ldxdw r9, [r1+0x20]                     
    mov64 r1, r6                                    r1 = r6
    mov64 r2, 39                                    r2 = 39 as i32 as i64 as u64
    callx r9                                
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    jne r0, 0, lbb_28176                            if r0 != (0 as i32 as i64 as u64) { pc += 62 }
    ldxw r2, [r8+0x0]                       
    mov64 r1, r10                                   r1 = r10
    add64 r1, -16                                   r1 += -16   ///  r1 = r1.wrapping_add(-16 as i32 as i64 as u64)
    mov64 r3, 257                                   r3 = 257 as i32 as i64 as u64
    call function_25366                     
    ldxb r1, [r10-0x10]                     
    jne r1, 128, lbb_28124                          if r1 != (128 as i32 as i64 as u64) { pc += 3 }
    mov64 r7, 128                                   r7 = 128 as i32 as i64 as u64
    mov64 r8, 10                                    r8 = 10 as i32 as i64 as u64
    ja lbb_28158                                    if true { pc += 34 }
lbb_28124:
    ldxb r7, [r10-0x5]                      
    ldxb r1, [r10-0x6]                      
lbb_28126:
    jge r1, r7, lbb_28172                           if r1 >= r7 { pc += 45 }
    mov64 r8, r1                                    r8 = r1
    add64 r8, 1                                     r8 += 1   ///  r8 = r8.wrapping_add(1 as i32 as i64 as u64)
    stxb [r10-0x6], r8                      
    jgt r1, 9, lbb_28147                            if r1 > (9 as i32 as i64 as u64) { pc += 16 }
    mov64 r2, r10                                   r2 = r10
    add64 r2, -16                                   r2 += -16   ///  r2 = r2.wrapping_add(-16 as i32 as i64 as u64)
    add64 r2, r1                                    r2 += r1   ///  r2 = r2.wrapping_add(r1)
    ldxb r2, [r2+0x0]                       
    mov64 r1, r6                                    r1 = r6
    callx r9                                
    mov64 r1, r8                                    r1 = r8
    jne r0, 0, lbb_28170                            if r0 != (0 as i32 as i64 as u64) { pc += 31 }
    ja lbb_28126                                    if true { pc += -14 }
lbb_28140:
    ldxb r1, [r10-0x6]                      
    ldxb r2, [r10-0x5]                      
    jge r1, r2, lbb_28172                           if r1 >= r2 { pc += 29 }
    mov64 r2, r1                                    r2 = r1
    add64 r2, 1                                     r2 += 1   ///  r2 = r2.wrapping_add(1 as i32 as i64 as u64)
    stxb [r10-0x6], r2                      
    jgt r8, r1, lbb_28151                           if r8 > r1 { pc += 4 }
lbb_28147:
    mov64 r2, 10                                    r2 = 10 as i32 as i64 as u64
    lddw r3, 0x1000421f8 --> b"\x00\x00\x00\x00?\x08\x04\x00\x1a\x00\x00\x00\x00\x00\x00\x00f\x00\x00\x0…        r3 load str located at 4295238136
    call function_25832                     
lbb_28151:
    mov64 r2, r10                                   r2 = r10
    add64 r2, -16                                   r2 += -16   ///  r2 = r2.wrapping_add(-16 as i32 as i64 as u64)
    add64 r2, r1                                    r2 += r1   ///  r2 = r2.wrapping_add(r1)
    ldxb r2, [r2+0x0]                       
    mov64 r1, r6                                    r1 = r6
    callx r9                                
    jne r0, 0, lbb_28170                            if r0 != (0 as i32 as i64 as u64) { pc += 12 }
lbb_28158:
    mov64 r1, r7                                    r1 = r7
    and64 r1, 255                                   r1 &= 255   ///  r1 = r1.and(255)
    jeq r1, 128, lbb_28162                          if r1 == (128 as i32 as i64 as u64) { pc += 1 }
    ja lbb_28140                                    if true { pc += -22 }
lbb_28162:
    mov64 r7, 0                                     r7 = 0 as i32 as i64 as u64
    stxw [r10-0x8], r7                      
    ldxw r2, [r10-0xc]                      
    stxdw [r10-0x10], r7                    
    mov64 r1, r6                                    r1 = r6
    callx r9                                
    jne r0, 0, lbb_28170                            if r0 != (0 as i32 as i64 as u64) { pc += 1 }
    ja lbb_28158                                    if true { pc += -12 }
lbb_28170:
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    ja lbb_28176                                    if true { pc += 4 }
lbb_28172:
    mov64 r1, r6                                    r1 = r6
    mov64 r2, 39                                    r2 = 39 as i32 as i64 as u64
    callx r9                                
    mov64 r1, r0                                    r1 = r0
lbb_28176:
    mov64 r0, r1                                    r0 = r1
    exit                                    

function_28178:
    ldxdw r3, [r2+0x10]                     
    ldxdw r4, [r2+0x0]                      
    or64 r4, r3                                     r4 |= r3   ///  r4 = r4.or(r3)
    ldxw r3, [r1+0x0]                       
    jeq r4, 0, lbb_28208                            if r4 == (0 as i32 as i64 as u64) { pc += 25 }
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    stxw [r10-0x4], r1                      
    mov64 r1, r3                                    r1 = r3
    mov64 r4, 128                                   r4 = 128 as i32 as i64 as u64
    jgt r4, r1, lbb_28214                           if r4 > r1 { pc += 26 }
    mov64 r4, 2048                                  r4 = 2048 as i32 as i64 as u64
    jgt r4, r1, lbb_28217                           if r4 > r1 { pc += 27 }
    mov64 r1, r3                                    r1 = r3
    mov64 r4, 65536                                 r4 = 65536 as i32 as i64 as u64
    jgt r4, r1, lbb_28194                           if r4 > r1 { pc += 1 }
    ja lbb_28226                                    if true { pc += 32 }
lbb_28194:
    mov64 r1, r3                                    r1 = r3
    and64 r1, 63                                    r1 &= 63   ///  r1 = r1.and(63)
    or64 r1, 128                                    r1 |= 128   ///  r1 = r1.or(128)
    stxb [r10-0x2], r1                      
    mov64 r1, r3                                    r1 = r3
    rsh64 r1, 12                                    r1 >>= 12   ///  r1 = r1.wrapping_shr(12)
    or64 r1, 224                                    r1 |= 224   ///  r1 = r1.or(224)
    stxb [r10-0x4], r1                      
    rsh64 r3, 6                                     r3 >>= 6   ///  r3 = r3.wrapping_shr(6)
    and64 r3, 63                                    r3 &= 63   ///  r3 = r3.and(63)
    or64 r3, 128                                    r3 |= 128   ///  r3 = r3.or(128)
    stxb [r10-0x3], r3                      
    mov64 r3, 3                                     r3 = 3 as i32 as i64 as u64
    ja lbb_28244                                    if true { pc += 36 }
lbb_28208:
    ldxdw r1, [r2+0x20]                     
    ldxdw r2, [r2+0x28]                     
    ldxdw r4, [r2+0x20]                     
    mov64 r2, r3                                    r2 = r3
    callx r4                                
    ja lbb_28249                                    if true { pc += 35 }
lbb_28214:
    stxb [r10-0x4], r3                      
    mov64 r3, 1                                     r3 = 1 as i32 as i64 as u64
    ja lbb_28244                                    if true { pc += 27 }
lbb_28217:
    mov64 r1, r3                                    r1 = r3
    and64 r1, 63                                    r1 &= 63   ///  r1 = r1.and(63)
    or64 r1, 128                                    r1 |= 128   ///  r1 = r1.or(128)
    stxb [r10-0x3], r1                      
    rsh64 r3, 6                                     r3 >>= 6   ///  r3 = r3.wrapping_shr(6)
    or64 r3, 192                                    r3 |= 192   ///  r3 = r3.or(192)
    stxb [r10-0x4], r3                      
    mov64 r3, 2                                     r3 = 2 as i32 as i64 as u64
    ja lbb_28244                                    if true { pc += 18 }
lbb_28226:
    mov64 r1, r3                                    r1 = r3
    and64 r1, 63                                    r1 &= 63   ///  r1 = r1.and(63)
    or64 r1, 128                                    r1 |= 128   ///  r1 = r1.or(128)
    stxb [r10-0x1], r1                      
    mov64 r1, r3                                    r1 = r3
    rsh64 r1, 18                                    r1 >>= 18   ///  r1 = r1.wrapping_shr(18)
    or64 r1, 240                                    r1 |= 240   ///  r1 = r1.or(240)
    stxb [r10-0x4], r1                      
    mov64 r1, r3                                    r1 = r3
    rsh64 r1, 6                                     r1 >>= 6   ///  r1 = r1.wrapping_shr(6)
    and64 r1, 63                                    r1 &= 63   ///  r1 = r1.and(63)
    or64 r1, 128                                    r1 |= 128   ///  r1 = r1.or(128)
    stxb [r10-0x2], r1                      
    rsh64 r3, 12                                    r3 >>= 12   ///  r3 = r3.wrapping_shr(12)
    and64 r3, 63                                    r3 &= 63   ///  r3 = r3.and(63)
    or64 r3, 128                                    r3 |= 128   ///  r3 = r3.or(128)
    stxb [r10-0x3], r3                      
    mov64 r3, 4                                     r3 = 4 as i32 as i64 as u64
lbb_28244:
    mov64 r4, r10                                   r4 = r10
    add64 r4, -4                                    r4 += -4   ///  r4 = r4.wrapping_add(-4 as i32 as i64 as u64)
    mov64 r1, r2                                    r1 = r2
    mov64 r2, r4                                    r2 = r4
    call function_27252                     
lbb_28249:
    exit                                    

function_28250:
    mov64 r5, 0                                     r5 = 0 as i32 as i64 as u64
    mov64 r0, r3                                    r0 = r3
    add64 r0, 7                                     r0 += 7   ///  r0 = r0.wrapping_add(7 as i32 as i64 as u64)
    and64 r0, -8                                    r0 &= -8   ///  r0 = r0.and(-8)
    jeq r0, r3, lbb_28270                           if r0 == r3 { pc += 15 }
    sub64 r0, r3                                    r0 -= r3   ///  r0 = r0.wrapping_sub(r3)
    jgt r4, r0, lbb_28258                           if r4 > r0 { pc += 1 }
    mov64 r0, r4                                    r0 = r4
lbb_28258:
    jeq r0, 0, lbb_28270                            if r0 == (0 as i32 as i64 as u64) { pc += 11 }
    mov64 r6, 0                                     r6 = 0 as i32 as i64 as u64
    mov64 r7, 1                                     r7 = 1 as i32 as i64 as u64
lbb_28261:
    mov64 r5, r3                                    r5 = r3
    add64 r5, r6                                    r5 += r6   ///  r5 = r5.wrapping_add(r6)
    ldxb r5, [r5+0x0]                       
    mov64 r8, r2                                    r8 = r2
    and64 r8, 255                                   r8 &= 255   ///  r8 = r8.and(255)
    jeq r5, r8, lbb_28322                           if r5 == r8 { pc += 55 }
    add64 r6, 1                                     r6 += 1   ///  r6 = r6.wrapping_add(1 as i32 as i64 as u64)
    mov64 r5, r0                                    r5 = r0
    jgt r0, r6, lbb_28261                           if r0 > r6 { pc += -9 }
lbb_28270:
    stxdw [r10-0x8], r1                     
    mov64 r0, r4                                    r0 = r4
    add64 r0, -16                                   r0 += -16   ///  r0 = r0.wrapping_add(-16 as i32 as i64 as u64)
    jgt r5, r0, lbb_28303                           if r5 > r0 { pc += 29 }
    mov64 r6, r2                                    r6 = r2
    and64 r6, 255                                   r6 &= 255   ///  r6 = r6.and(255)
    lddw r7, 0x101010101010101                      r7 load str located at 72340172838076673
    mul64 r6, r7                                    r6 *= r7   ///  r6 = r6.wrapping_mul(r7)
    lddw r7, 0xfefefefefefefeff                     r7 load str located at -72340172838076673
    ja lbb_28284                                    if true { pc += 2 }
lbb_28282:
    add64 r5, 16                                    r5 += 16   ///  r5 = r5.wrapping_add(16 as i32 as i64 as u64)
    jgt r5, r0, lbb_28303                           if r5 > r0 { pc += 19 }
lbb_28284:
    mov64 r9, r3                                    r9 = r3
    add64 r9, r5                                    r9 += r5   ///  r9 = r9.wrapping_add(r5)
    ldxdw r8, [r9+0x0]                      
    xor64 r8, r6                                    r8 ^= r6   ///  r8 = r8.xor(r6)
    mov64 r1, r8                                    r1 = r8
    add64 r1, r7                                    r1 += r7   ///  r1 = r1.wrapping_add(r7)
    xor64 r8, -1                                    r8 ^= -1   ///  r8 = r8.xor(-1)
    and64 r1, r8                                    r1 &= r8   ///  r1 = r1.and(r8)
    ldxdw r8, [r9+0x8]                      
    xor64 r8, r6                                    r8 ^= r6   ///  r8 = r8.xor(r6)
    mov64 r9, r8                                    r9 = r8
    add64 r9, r7                                    r9 += r7   ///  r9 = r9.wrapping_add(r7)
    xor64 r8, -1                                    r8 ^= -1   ///  r8 = r8.xor(-1)
    and64 r9, r8                                    r9 &= r8   ///  r9 = r9.and(r8)
    or64 r9, r1                                     r9 |= r1   ///  r9 = r9.or(r1)
    lddw r1, 0x8080808080808080                     r1 load str located at -9187201950435737472
    and64 r9, r1                                    r9 &= r1   ///  r9 = r9.and(r1)
    jeq r9, 0, lbb_28282                            if r9 == (0 as i32 as i64 as u64) { pc += -21 }
lbb_28303:
    mov64 r7, 0                                     r7 = 0 as i32 as i64 as u64
    ldxdw r1, [r10-0x8]                     
    jeq r4, r5, lbb_28322                           if r4 == r5 { pc += 16 }
    sub64 r4, r5                                    r4 -= r5   ///  r4 = r4.wrapping_sub(r5)
    add64 r3, r5                                    r3 += r5   ///  r3 = r3.wrapping_add(r5)
    mov64 r0, 0                                     r0 = 0 as i32 as i64 as u64
lbb_28309:
    mov64 r6, r3                                    r6 = r3
    add64 r6, r0                                    r6 += r0   ///  r6 = r6.wrapping_add(r0)
    ldxb r7, [r6+0x0]                       
    mov64 r6, r2                                    r6 = r2
    and64 r6, 255                                   r6 &= 255   ///  r6 = r6.and(255)
    jeq r7, r6, lbb_28319                           if r7 == r6 { pc += 4 }
    mov64 r7, 0                                     r7 = 0 as i32 as i64 as u64
    add64 r0, 1                                     r0 += 1   ///  r0 = r0.wrapping_add(1 as i32 as i64 as u64)
    jgt r4, r0, lbb_28309                           if r4 > r0 { pc += -9 }
    ja lbb_28322                                    if true { pc += 3 }
lbb_28319:
    add64 r5, r0                                    r5 += r0   ///  r5 = r5.wrapping_add(r0)
    mov64 r7, 1                                     r7 = 1 as i32 as i64 as u64
    mov64 r6, r5                                    r6 = r5
lbb_28322:
    stxdw [r1+0x8], r6                      
    stxdw [r1+0x0], r7                      
    exit                                    

function_28325:
    call function_28326                     

function_28326:
    stxdw [r10-0x58], r2                    
    stxdw [r10-0x60], r1                    
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    stxdw [r10-0x30], r1                    
    lddw r1, 0x100042018 --> b"\x00\x00\x00\x00d\x00\x04\x00\x12\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00…        r1 load str located at 4295237656
    stxdw [r10-0x50], r1                    
    mov64 r1, 2                                     r1 = 2 as i32 as i64 as u64
    stxdw [r10-0x48], r1                    
    stxdw [r10-0x38], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -32                                   r1 += -32   ///  r1 = r1.wrapping_add(-32 as i32 as i64 as u64)
    stxdw [r10-0x40], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -88                                   r1 += -88   ///  r1 = r1.wrapping_add(-88 as i32 as i64 as u64)
    stxdw [r10-0x10], r1                    
    lddw r1, 0x10003b1e0 --> b"\xbf#\x00\x00\x00\x00\x00\x00y\x11\x00\x00\x00\x00\x00\x00\xb7\x02\x00\x0…        r1 load str located at 4295209440
    stxdw [r10-0x8], r1                     
    stxdw [r10-0x18], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -96                                   r1 += -96   ///  r1 = r1.wrapping_add(-96 as i32 as i64 as u64)
    stxdw [r10-0x20], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -80                                   r1 += -80   ///  r1 = r1.wrapping_add(-80 as i32 as i64 as u64)
    mov64 r2, r3                                    r2 = r3
    call function_25805                     

function_28353:
    call function_28354                     

function_28354:
    stxdw [r10-0x58], r2                    
    stxdw [r10-0x60], r1                    
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    stxdw [r10-0x30], r1                    
    lddw r1, 0x100042038 --> b"\x00\x00\x00\x00\x80\xe7\x03\x00\x10\x00\x00\x00\x00\x00\x00\x00\x00\x00\…        r1 load str located at 4295237688
    stxdw [r10-0x50], r1                    
    mov64 r1, 2                                     r1 = 2 as i32 as i64 as u64
    stxdw [r10-0x48], r1                    
    stxdw [r10-0x38], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -32                                   r1 += -32   ///  r1 = r1.wrapping_add(-32 as i32 as i64 as u64)
    stxdw [r10-0x40], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -88                                   r1 += -88   ///  r1 = r1.wrapping_add(-88 as i32 as i64 as u64)
    stxdw [r10-0x10], r1                    
    lddw r1, 0x10003b1e0 --> b"\xbf#\x00\x00\x00\x00\x00\x00y\x11\x00\x00\x00\x00\x00\x00\xb7\x02\x00\x0…        r1 load str located at 4295209440
    stxdw [r10-0x8], r1                     
    stxdw [r10-0x18], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -96                                   r1 += -96   ///  r1 = r1.wrapping_add(-96 as i32 as i64 as u64)
    stxdw [r10-0x20], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -80                                   r1 += -80   ///  r1 = r1.wrapping_add(-80 as i32 as i64 as u64)
    mov64 r2, r3                                    r2 = r3
    call function_25805                     

function_28381:
    call function_28382                     

function_28382:
    stxdw [r10-0x58], r2                    
    stxdw [r10-0x60], r1                    
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    stxdw [r10-0x30], r1                    
    lddw r1, 0x100042058 --> b"\x00\x00\x00\x00\x98\x00\x04\x00\x16\x00\x00\x00\x00\x00\x00\x00\x00\x00\…        r1 load str located at 4295237720
    stxdw [r10-0x50], r1                    
    mov64 r1, 2                                     r1 = 2 as i32 as i64 as u64
    stxdw [r10-0x48], r1                    
    stxdw [r10-0x38], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -32                                   r1 += -32   ///  r1 = r1.wrapping_add(-32 as i32 as i64 as u64)
    stxdw [r10-0x40], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -88                                   r1 += -88   ///  r1 = r1.wrapping_add(-88 as i32 as i64 as u64)
    stxdw [r10-0x10], r1                    
    lddw r1, 0x10003b1e0 --> b"\xbf#\x00\x00\x00\x00\x00\x00y\x11\x00\x00\x00\x00\x00\x00\xb7\x02\x00\x0…        r1 load str located at 4295209440
    stxdw [r10-0x8], r1                     
    stxdw [r10-0x18], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -96                                   r1 += -96   ///  r1 = r1.wrapping_add(-96 as i32 as i64 as u64)
    stxdw [r10-0x20], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -80                                   r1 += -80   ///  r1 = r1.wrapping_add(-80 as i32 as i64 as u64)
    mov64 r2, r3                                    r2 = r3
    call function_25805                     

function_28409:
    stxdw [r10-0x58], r2                    
    stxdw [r10-0x60], r1                    
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    stxdw [r10-0x30], r1                    
    mov64 r1, 3                                     r1 = 3 as i32 as i64 as u64
    stxdw [r10-0x48], r1                    
    lddw r1, 0x100042078 --> b"\x00\x00\x00\x00\xbb\x00\x04\x00\x15\x00\x00\x00\x00\x00\x00\x00\x00\x00\…        r1 load str located at 4295237752
    stxdw [r10-0x50], r1                    
    mov64 r1, 2                                     r1 = 2 as i32 as i64 as u64
    stxdw [r10-0x38], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -32                                   r1 += -32   ///  r1 = r1.wrapping_add(-32 as i32 as i64 as u64)
    stxdw [r10-0x40], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -96                                   r1 += -96   ///  r1 = r1.wrapping_add(-96 as i32 as i64 as u64)
    stxdw [r10-0x10], r1                    
    lddw r1, 0x10003b1e0 --> b"\xbf#\x00\x00\x00\x00\x00\x00y\x11\x00\x00\x00\x00\x00\x00\xb7\x02\x00\x0…        r1 load str located at 4295209440
    stxdw [r10-0x8], r1                     
    stxdw [r10-0x18], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -88                                   r1 += -88   ///  r1 = r1.wrapping_add(-88 as i32 as i64 as u64)
    stxdw [r10-0x20], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -80                                   r1 += -80   ///  r1 = r1.wrapping_add(-80 as i32 as i64 as u64)
    mov64 r2, r3                                    r2 = r3
    call function_25805                     

function_28437:
    stxdw [r10-0x8], r1                     
    mov64 r1, r3                                    r1 = r3
    add64 r1, -15                                   r1 += -15   ///  r1 = r1.wrapping_add(-15 as i32 as i64 as u64)
    mov64 r4, 0                                     r4 = 0 as i32 as i64 as u64
    mov64 r5, 1                                     r5 = 1 as i32 as i64 as u64
    jgt r1, r3, lbb_28444                           if r1 > r3 { pc += 1 }
    mov64 r5, 0                                     r5 = 0 as i32 as i64 as u64
lbb_28444:
    jne r5, 0, lbb_28446                            if r5 != (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r4, r1                                    r4 = r1
lbb_28446:
    jeq r3, 0, lbb_28632                            if r3 == (0 as i32 as i64 as u64) { pc += 185 }
    mov64 r5, r2                                    r5 = r2
    add64 r5, 7                                     r5 += 7   ///  r5 = r5.wrapping_add(7 as i32 as i64 as u64)
    and64 r5, -8                                    r5 &= -8   ///  r5 = r5.and(-8)
    sub64 r5, r2                                    r5 -= r2   ///  r5 = r5.wrapping_sub(r2)
    mov64 r0, 0                                     r0 = 0 as i32 as i64 as u64
    lddw r8, 0x8080808080808080                     r8 load str located at -9187201950435737472
    mov64 r6, 0                                     r6 = 0 as i32 as i64 as u64
    ja lbb_28470                                    if true { pc += 14 }
lbb_28456:
    mov64 r1, r2                                    r1 = r2
    add64 r1, r7                                    r1 += r7   ///  r1 = r1.wrapping_add(r7)
    ldxb r1, [r1+0x0]                       
    lsh64 r1, 56                                    r1 <<= 56   ///  r1 = r1.wrapping_shl(56)
    arsh64 r1, 56                                   r1 >>= 56 (signed)   ///  r1 = (r1 as i64).wrapping_shr(56)
    mov64 r8, 1                                     r8 = 1 as i32 as i64 as u64
    mov64 r9, 1                                     r9 = 1 as i32 as i64 as u64
    jsgt r1, -65, lbb_28626                         if (r1 as i64) > (-65 as i32 as i64) { pc += 162 }
lbb_28464:
    add64 r7, 1                                     r7 += 1   ///  r7 = r7.wrapping_add(1 as i32 as i64 as u64)
    mov64 r6, r7                                    r6 = r7
    lddw r8, 0x8080808080808080                     r8 load str located at -9187201950435737472
    jgt r3, r6, lbb_28470                           if r3 > r6 { pc += 1 }
    ja lbb_28632                                    if true { pc += 162 }
lbb_28470:
    mov64 r1, r2                                    r1 = r2
    add64 r1, r6                                    r1 += r6   ///  r1 = r1.wrapping_add(r6)
    ldxb r7, [r1+0x0]                       
    mov64 r1, r7                                    r1 = r7
    lsh64 r1, 56                                    r1 <<= 56   ///  r1 = r1.wrapping_shl(56)
    arsh64 r1, 56                                   r1 >>= 56 (signed)   ///  r1 = (r1 as i64).wrapping_shr(56)
    jsgt r0, r1, lbb_28505                          if (r0 as i64) > (r1 as i64) { pc += 28 }
    mov64 r1, r5                                    r1 = r5
    sub64 r1, r6                                    r1 -= r6   ///  r1 = r1.wrapping_sub(r6)
    and64 r1, 7                                     r1 &= 7   ///  r1 = r1.and(7)
    jne r1, 0, lbb_28502                            if r1 != (0 as i32 as i64 as u64) { pc += 21 }
    jge r6, r4, lbb_28489                           if r6 >= r4 { pc += 7 }
lbb_28482:
    mov64 r1, r2                                    r1 = r2
    add64 r1, r6                                    r1 += r6   ///  r1 = r1.wrapping_add(r6)
    ldxdw r7, [r1+0x0]                      
    ldxdw r1, [r1+0x8]                      
    or64 r1, r7                                     r1 |= r7   ///  r1 = r1.or(r7)
    and64 r1, r8                                    r1 &= r8   ///  r1 = r1.and(r8)
    jeq r1, 0, lbb_28499                            if r1 == (0 as i32 as i64 as u64) { pc += 10 }
lbb_28489:
    jge r6, r3, lbb_28503                           if r6 >= r3 { pc += 13 }
lbb_28490:
    mov64 r1, r2                                    r1 = r2
    add64 r1, r6                                    r1 += r6   ///  r1 = r1.wrapping_add(r6)
    ldxb r1, [r1+0x0]                       
    lsh64 r1, 56                                    r1 <<= 56   ///  r1 = r1.wrapping_shl(56)
    arsh64 r1, 56                                   r1 >>= 56 (signed)   ///  r1 = (r1 as i64).wrapping_shr(56)
    jsgt r0, r1, lbb_28503                          if (r0 as i64) > (r1 as i64) { pc += 7 }
    add64 r6, 1                                     r6 += 1   ///  r6 = r6.wrapping_add(1 as i32 as i64 as u64)
    jgt r3, r6, lbb_28490                           if r3 > r6 { pc += -8 }
    ja lbb_28632                                    if true { pc += 133 }
lbb_28499:
    add64 r6, 16                                    r6 += 16   ///  r6 = r6.wrapping_add(16 as i32 as i64 as u64)
    jgt r4, r6, lbb_28482                           if r4 > r6 { pc += -19 }
    ja lbb_28489                                    if true { pc += -13 }
lbb_28502:
    add64 r6, 1                                     r6 += 1   ///  r6 = r6.wrapping_add(1 as i32 as i64 as u64)
lbb_28503:
    jgt r3, r6, lbb_28470                           if r3 > r6 { pc += -34 }
    ja lbb_28632                                    if true { pc += 127 }
lbb_28505:
    lddw r1, 0x1000400fb --> b"\x01\x01\x01\x01\x01\x01\x01\x01\x01\x01\x01\x01\x01\x01\x01\x01\x01\x01\…        r1 load str located at 4295229691
    add64 r1, r7                                    r1 += r7   ///  r1 = r1.wrapping_add(r7)
    ldxb r1, [r1+0x0]                       
    jeq r1, 4, lbb_28542                            if r1 == (4 as i32 as i64 as u64) { pc += 32 }
    jeq r1, 3, lbb_28519                            if r1 == (3 as i32 as i64 as u64) { pc += 8 }
    mov64 r8, 1                                     r8 = 1 as i32 as i64 as u64
    mov64 r9, 1                                     r9 = 1 as i32 as i64 as u64
    jne r1, 2, lbb_28626                            if r1 != (2 as i32 as i64 as u64) { pc += 112 }
    mov64 r9, 0                                     r9 = 0 as i32 as i64 as u64
    mov64 r7, r6                                    r7 = r6
    add64 r7, 1                                     r7 += 1   ///  r7 = r7.wrapping_add(1 as i32 as i64 as u64)
    jgt r3, r7, lbb_28456                           if r3 > r7 { pc += -62 }
    ja lbb_28626                                    if true { pc += 107 }
lbb_28519:
    mov64 r9, 0                                     r9 = 0 as i32 as i64 as u64
    mov64 r1, r6                                    r1 = r6
    add64 r1, 1                                     r1 += 1   ///  r1 = r1.wrapping_add(1 as i32 as i64 as u64)
    jgt r3, r1, lbb_28524                           if r3 > r1 { pc += 1 }
    ja lbb_28626                                    if true { pc += 102 }
lbb_28524:
    mov64 r8, r2                                    r8 = r2
    add64 r8, r1                                    r8 += r1   ///  r8 = r8.wrapping_add(r1)
    ldxb r1, [r8+0x0]                       
    lsh64 r1, 56                                    r1 <<= 56   ///  r1 = r1.wrapping_shl(56)
    arsh64 r1, 56                                   r1 >>= 56 (signed)   ///  r1 = (r1 as i64).wrapping_shr(56)
    jeq r7, 224, lbb_28562                          if r7 == (224 as i32 as i64 as u64) { pc += 32 }
    jeq r7, 237, lbb_28609                          if r7 == (237 as i32 as i64 as u64) { pc += 78 }
    mov64 r8, r7                                    r8 = r7
    add64 r8, 31                                    r8 += 31   ///  r8 = r8.wrapping_add(31 as i32 as i64 as u64)
    and64 r8, 255                                   r8 &= 255   ///  r8 = r8.and(255)
    mov64 r9, 12                                    r9 = 12 as i32 as i64 as u64
    jgt r9, r8, lbb_28537                           if r9 > r8 { pc += 1 }
    ja lbb_28602                                    if true { pc += 65 }
lbb_28537:
    mov64 r8, 1                                     r8 = 1 as i32 as i64 as u64
    mov64 r9, 1                                     r9 = 1 as i32 as i64 as u64
    mov64 r7, -64                                   r7 = -64 as i32 as i64 as u64
    jsgt r7, r1, lbb_28612                          if (r7 as i64) > (r1 as i64) { pc += 71 }
    ja lbb_28626                                    if true { pc += 84 }
lbb_28542:
    mov64 r1, r6                                    r1 = r6
    add64 r1, 1                                     r1 += 1   ///  r1 = r1.wrapping_add(1 as i32 as i64 as u64)
    mov64 r9, 0                                     r9 = 0 as i32 as i64 as u64
    jgt r3, r1, lbb_28547                           if r3 > r1 { pc += 1 }
    ja lbb_28626                                    if true { pc += 79 }
lbb_28547:
    mov64 r8, r2                                    r8 = r2
    add64 r8, r1                                    r8 += r1   ///  r8 = r8.wrapping_add(r1)
    ldxb r1, [r8+0x0]                       
    lsh64 r1, 56                                    r1 <<= 56   ///  r1 = r1.wrapping_shl(56)
    arsh64 r1, 56                                   r1 >>= 56 (signed)   ///  r1 = (r1 as i64).wrapping_shr(56)
    jeq r7, 240, lbb_28567                          if r7 == (240 as i32 as i64 as u64) { pc += 14 }
    jeq r7, 244, lbb_28574                          if r7 == (244 as i32 as i64 as u64) { pc += 20 }
    add64 r7, 15                                    r7 += 15   ///  r7 = r7.wrapping_add(15 as i32 as i64 as u64)
    and64 r7, 255                                   r7 &= 255   ///  r7 = r7.and(255)
    mov64 r8, 1                                     r8 = 1 as i32 as i64 as u64
    mov64 r9, 1                                     r9 = 1 as i32 as i64 as u64
    jgt r7, 2, lbb_28626                            if r7 > (2 as i32 as i64 as u64) { pc += 67 }
    mov64 r7, -64                                   r7 = -64 as i32 as i64 as u64
    jsgt r7, r1, lbb_28577                          if (r7 as i64) > (r1 as i64) { pc += 16 }
    ja lbb_28626                                    if true { pc += 64 }
lbb_28562:
    and64 r1, -32                                   r1 &= -32   ///  r1 = r1.and(-32)
    mov64 r8, 1                                     r8 = 1 as i32 as i64 as u64
    mov64 r9, 1                                     r9 = 1 as i32 as i64 as u64
    jeq r1, -96, lbb_28612                          if r1 == (-96 as i32 as i64 as u64) { pc += 46 }
    ja lbb_28626                                    if true { pc += 59 }
lbb_28567:
    add64 r1, 112                                   r1 += 112   ///  r1 = r1.wrapping_add(112 as i32 as i64 as u64)
    and64 r1, 255                                   r1 &= 255   ///  r1 = r1.and(255)
    mov64 r8, 1                                     r8 = 1 as i32 as i64 as u64
    mov64 r9, 1                                     r9 = 1 as i32 as i64 as u64
    mov64 r7, 48                                    r7 = 48 as i32 as i64 as u64
    jgt r7, r1, lbb_28577                           if r7 > r1 { pc += 4 }
    ja lbb_28626                                    if true { pc += 52 }
lbb_28574:
    mov64 r8, 1                                     r8 = 1 as i32 as i64 as u64
    mov64 r9, 1                                     r9 = 1 as i32 as i64 as u64
    jsgt r1, -113, lbb_28626                        if (r1 as i64) > (-113 as i32 as i64) { pc += 49 }
lbb_28577:
    mov64 r1, r6                                    r1 = r6
    add64 r1, 2                                     r1 += 2   ///  r1 = r1.wrapping_add(2 as i32 as i64 as u64)
    mov64 r9, 0                                     r9 = 0 as i32 as i64 as u64
    jge r1, r3, lbb_28626                           if r1 >= r3 { pc += 45 }
    mov64 r7, r2                                    r7 = r2
    add64 r7, r1                                    r7 += r1   ///  r7 = r7.wrapping_add(r1)
    mov64 r8, 2                                     r8 = 2 as i32 as i64 as u64
    ldxb r1, [r7+0x0]                       
    lsh64 r1, 56                                    r1 <<= 56   ///  r1 = r1.wrapping_shl(56)
    arsh64 r1, 56                                   r1 >>= 56 (signed)   ///  r1 = (r1 as i64).wrapping_shr(56)
    mov64 r9, 1                                     r9 = 1 as i32 as i64 as u64
    jsgt r1, -65, lbb_28626                         if (r1 as i64) > (-65 as i32 as i64) { pc += 37 }
    mov64 r7, r6                                    r7 = r6
    add64 r7, 3                                     r7 += 3   ///  r7 = r7.wrapping_add(3 as i32 as i64 as u64)
    mov64 r9, 0                                     r9 = 0 as i32 as i64 as u64
    jge r7, r3, lbb_28626                           if r7 >= r3 { pc += 33 }
    mov64 r1, r2                                    r1 = r2
    add64 r1, r7                                    r1 += r7   ///  r1 = r1.wrapping_add(r7)
    mov64 r8, 3                                     r8 = 3 as i32 as i64 as u64
    ldxb r1, [r1+0x0]                       
    lsh64 r1, 56                                    r1 <<= 56   ///  r1 = r1.wrapping_shl(56)
    arsh64 r1, 56                                   r1 >>= 56 (signed)   ///  r1 = (r1 as i64).wrapping_shr(56)
    mov64 r9, 1                                     r9 = 1 as i32 as i64 as u64
    jsgt r1, -65, lbb_28626                         if (r1 as i64) > (-65 as i32 as i64) { pc += 25 }
    ja lbb_28464                                    if true { pc += -138 }
lbb_28602:
    and64 r7, 254                                   r7 &= 254   ///  r7 = r7.and(254)
    mov64 r8, 1                                     r8 = 1 as i32 as i64 as u64
    mov64 r9, 1                                     r9 = 1 as i32 as i64 as u64
    jne r7, 238, lbb_28626                          if r7 != (238 as i32 as i64 as u64) { pc += 20 }
    mov64 r7, -64                                   r7 = -64 as i32 as i64 as u64
    jsgt r7, r1, lbb_28612                          if (r7 as i64) > (r1 as i64) { pc += 4 }
    ja lbb_28626                                    if true { pc += 17 }
lbb_28609:
    mov64 r8, 1                                     r8 = 1 as i32 as i64 as u64
    mov64 r9, 1                                     r9 = 1 as i32 as i64 as u64
    jsgt r1, -97, lbb_28626                         if (r1 as i64) > (-97 as i32 as i64) { pc += 14 }
lbb_28612:
    mov64 r7, r6                                    r7 = r6
    add64 r7, 2                                     r7 += 2   ///  r7 = r7.wrapping_add(2 as i32 as i64 as u64)
    mov64 r9, 0                                     r9 = 0 as i32 as i64 as u64
    jgt r3, r7, lbb_28617                           if r3 > r7 { pc += 1 }
    ja lbb_28626                                    if true { pc += 9 }
lbb_28617:
    mov64 r1, r2                                    r1 = r2
    add64 r1, r7                                    r1 += r7   ///  r1 = r1.wrapping_add(r7)
    mov64 r8, 2                                     r8 = 2 as i32 as i64 as u64
    ldxb r1, [r1+0x0]                       
    lsh64 r1, 56                                    r1 <<= 56   ///  r1 = r1.wrapping_shl(56)
    arsh64 r1, 56                                   r1 >>= 56 (signed)   ///  r1 = (r1 as i64).wrapping_shr(56)
    mov64 r9, 1                                     r9 = 1 as i32 as i64 as u64
    jsgt r1, -65, lbb_28626                         if (r1 as i64) > (-65 as i32 as i64) { pc += 1 }
    ja lbb_28464                                    if true { pc += -162 }
lbb_28626:
    ldxdw r3, [r10-0x8]                     
    stxb [r3+0x11], r8                      
    stxb [r3+0x10], r9                      
    stxdw [r3+0x8], r6                      
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    ja lbb_28637                                    if true { pc += 5 }
lbb_28632:
    ldxdw r1, [r10-0x8]                     
    stxdw [r1+0x10], r3                     
    mov64 r3, r1                                    r3 = r1
    stxdw [r3+0x8], r2                      
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
lbb_28637:
    stxdw [r3+0x0], r1                      
    exit                                    

function_28639:
    mov64 r7, r1                                    r7 = r1
    add64 r7, 7                                     r7 += 7   ///  r7 = r7.wrapping_add(7 as i32 as i64 as u64)
    and64 r7, -8                                    r7 &= -8   ///  r7 = r7.and(-8)
    mov64 r4, r7                                    r4 = r7
    sub64 r4, r1                                    r4 -= r1   ///  r4 = r4.wrapping_sub(r1)
    jgt r4, r2, lbb_28782                           if r4 > r2 { pc += 137 }
    mov64 r5, r2                                    r5 = r2
    sub64 r5, r4                                    r5 -= r4   ///  r5 = r5.wrapping_sub(r4)
    mov64 r3, 8                                     r3 = 8 as i32 as i64 as u64
    jgt r3, r5, lbb_28782                           if r3 > r5 { pc += 133 }
    stxdw [r10-0x8], r4                     
    mov64 r2, r5                                    r2 = r5
    and64 r2, 7                                     r2 &= 7   ///  r2 = r2.and(7)
    mov64 r0, 0                                     r0 = 0 as i32 as i64 as u64
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
    jeq r7, r1, lbb_28662                           if r7 == r1 { pc += 7 }
    mov64 r6, r1                                    r6 = r1
    sub64 r6, r7                                    r6 -= r7   ///  r6 = r6.wrapping_sub(r7)
    mov64 r7, r1                                    r7 = r1
    ja lbb_28671                                    if true { pc += 12 }
lbb_28659:
    add64 r3, r9                                    r3 += r9   ///  r3 = r3.wrapping_add(r9)
    add64 r7, 1                                     r7 += 1   ///  r7 = r7.wrapping_add(1 as i32 as i64 as u64)
    jne r8, 1, lbb_28671                            if r8 != (1 as i32 as i64 as u64) { pc += 9 }
lbb_28662:
    ldxdw r4, [r10-0x8]                     
    add64 r1, r4                                    r1 += r4   ///  r1 = r1.wrapping_add(r4)
    jeq r2, 0, lbb_28686                            if r2 == (0 as i32 as i64 as u64) { pc += 21 }
    mov64 r0, r5                                    r0 = r5
    and64 r0, -8                                    r0 &= -8   ///  r0 = r0.and(-8)
    mov64 r4, r1                                    r4 = r1
    add64 r4, r0                                    r4 += r0   ///  r4 = r4.wrapping_add(r0)
    mov64 r0, 0                                     r0 = 0 as i32 as i64 as u64
    ja lbb_28691                                    if true { pc += 20 }
lbb_28671:
    ldxb r4, [r7+0x0]                       
    lsh64 r4, 56                                    r4 <<= 56   ///  r4 = r4.wrapping_shl(56)
    arsh64 r4, 56                                   r4 >>= 56 (signed)   ///  r4 = (r4 as i64).wrapping_shr(56)
    mov64 r8, 1                                     r8 = 1 as i32 as i64 as u64
    mov64 r9, 1                                     r9 = 1 as i32 as i64 as u64
    jsgt r4, -65, lbb_28678                         if (r4 as i64) > (-65 as i32 as i64) { pc += 1 }
    mov64 r9, 0                                     r9 = 0 as i32 as i64 as u64
lbb_28678:
    add64 r6, 1                                     r6 += 1   ///  r6 = r6.wrapping_add(1 as i32 as i64 as u64)
    jeq r6, 0, lbb_28659                            if r6 == (0 as i32 as i64 as u64) { pc += -21 }
    mov64 r8, 0                                     r8 = 0 as i32 as i64 as u64
    ja lbb_28659                                    if true { pc += -23 }
lbb_28682:
    add64 r0, r6                                    r0 += r6   ///  r0 = r0.wrapping_add(r6)
    add64 r4, 1                                     r4 += 1   ///  r4 = r4.wrapping_add(1 as i32 as i64 as u64)
    add64 r2, -1                                    r2 += -1   ///  r2 = r2.wrapping_add(-1 as i32 as i64 as u64)
    jne r2, 0, lbb_28691                            if r2 != (0 as i32 as i64 as u64) { pc += 5 }
lbb_28686:
    rsh64 r5, 3                                     r5 >>= 3   ///  r5 = r5.wrapping_shr(3)
    add64 r0, r3                                    r0 += r3   ///  r0 = r0.wrapping_add(r3)
    lddw r6, 0x101010101010101                      r6 load str located at 72340172838076673
    ja lbb_28764                                    if true { pc += 73 }
lbb_28691:
    ldxb r7, [r4+0x0]                       
    lsh64 r7, 56                                    r7 <<= 56   ///  r7 = r7.wrapping_shl(56)
    arsh64 r7, 56                                   r7 >>= 56 (signed)   ///  r7 = (r7 as i64).wrapping_shr(56)
    mov64 r6, 1                                     r6 = 1 as i32 as i64 as u64
    jsgt r7, -65, lbb_28682                         if (r7 as i64) > (-65 as i32 as i64) { pc += -14 }
    mov64 r6, 0                                     r6 = 0 as i32 as i64 as u64
    ja lbb_28682                                    if true { pc += -16 }
lbb_28698:
    ldxdw r8, [r2+0x0]                      
    mov64 r7, r8                                    r7 = r8
    rsh64 r7, 6                                     r7 >>= 6   ///  r7 = r7.wrapping_shr(6)
    xor64 r8, -1                                    r8 ^= -1   ///  r8 = r8.xor(-1)
    rsh64 r8, 7                                     r8 >>= 7   ///  r8 = r8.wrapping_shr(7)
    or64 r8, r7                                     r8 |= r7   ///  r8 = r8.or(r7)
    and64 r8, r6                                    r8 &= r6   ///  r8 = r8.and(r6)
    add64 r8, r4                                    r8 += r4   ///  r8 = r8.wrapping_add(r4)
    ldxdw r4, [r2+0x8]                      
    mov64 r7, r4                                    r7 = r4
    rsh64 r7, 6                                     r7 >>= 6   ///  r7 = r7.wrapping_shr(6)
    xor64 r4, -1                                    r4 ^= -1   ///  r4 = r4.xor(-1)
    rsh64 r4, 7                                     r4 >>= 7   ///  r4 = r4.wrapping_shr(7)
    or64 r4, r7                                     r4 |= r7   ///  r4 = r4.or(r7)
    and64 r4, r6                                    r4 &= r6   ///  r4 = r4.and(r6)
    add64 r4, r8                                    r4 += r8   ///  r4 = r4.wrapping_add(r8)
    ldxdw r8, [r2+0x10]                     
    mov64 r7, r8                                    r7 = r8
    rsh64 r7, 6                                     r7 >>= 6   ///  r7 = r7.wrapping_shr(6)
    xor64 r8, -1                                    r8 ^= -1   ///  r8 = r8.xor(-1)
    rsh64 r8, 7                                     r8 >>= 7   ///  r8 = r8.wrapping_shr(7)
    or64 r8, r7                                     r8 |= r7   ///  r8 = r8.or(r7)
    and64 r8, r6                                    r8 &= r6   ///  r8 = r8.and(r6)
    add64 r8, r4                                    r8 += r4   ///  r8 = r8.wrapping_add(r4)
    ldxdw r4, [r2+0x18]                     
    mov64 r7, r4                                    r7 = r4
    rsh64 r7, 6                                     r7 >>= 6   ///  r7 = r7.wrapping_shr(6)
    xor64 r4, -1                                    r4 ^= -1   ///  r4 = r4.xor(-1)
    rsh64 r4, 7                                     r4 >>= 7   ///  r4 = r4.wrapping_shr(7)
    or64 r4, r7                                     r4 |= r7   ///  r4 = r4.or(r7)
    and64 r4, r6                                    r4 &= r6   ///  r4 = r4.and(r6)
    add64 r4, r8                                    r4 += r8   ///  r4 = r4.wrapping_add(r8)
    add64 r2, 32                                    r2 += 32   ///  r2 = r2.wrapping_add(32 as i32 as i64 as u64)
    jne r2, r1, lbb_28698                           if r2 != r1 { pc += -34 }
lbb_28732:
    mov64 r1, r9                                    r1 = r9
    add64 r1, r5                                    r1 += r5   ///  r1 = r1.wrapping_add(r5)
    ldxdw r8, [r10-0x8]                     
    mov64 r2, r8                                    r2 = r8
    and64 r2, 3                                     r2 &= 3   ///  r2 = r2.and(3)
    mov64 r5, r3                                    r5 = r3
    sub64 r5, r8                                    r5 -= r8   ///  r5 = r5.wrapping_sub(r8)
    mov64 r7, r4                                    r7 = r4
    stxdw [r10-0x10], r9                    
    mov64 r9, r3                                    r9 = r3
    lddw r3, 0xff00ff00ff00ff                       r3 load str located at 71777214294589695
    and64 r7, r3                                    r7 &= r3   ///  r7 = r7.and(r3)
    rsh64 r4, 8                                     r4 >>= 8   ///  r4 = r4.wrapping_shr(8)
    and64 r4, r3                                    r4 &= r3   ///  r4 = r4.and(r3)
    add64 r4, r7                                    r4 += r7   ///  r4 = r4.wrapping_add(r7)
    lddw r7, 0x1000100010001                        r7 load str located at 281479271743489
    mul64 r4, r7                                    r4 *= r7   ///  r4 = r4.wrapping_mul(r7)
    rsh64 r4, 48                                    r4 >>= 48   ///  r4 = r4.wrapping_shr(48)
    add64 r4, r0                                    r4 += r0   ///  r4 = r4.wrapping_add(r0)
    mov64 r0, r4                                    r0 = r4
    jeq r2, 0, lbb_28764                            if r2 == (0 as i32 as i64 as u64) { pc += 9 }
    mov64 r0, 0                                     r0 = 0 as i32 as i64 as u64
    ldxdw r6, [r10-0x10]                    
    jeq r2, 0, lbb_28814                            if r2 == (0 as i32 as i64 as u64) { pc += 56 }
    and64 r8, 252                                   r8 &= 252   ///  r8 = r8.and(252)
    lsh64 r8, 3                                     r8 <<= 3   ///  r8 = r8.wrapping_shl(3)
    mov64 r1, 192                                   r1 = 192 as i32 as i64 as u64
    jgt r1, r9, lbb_28795                           if r1 > r9 { pc += 33 }
    mov64 r9, 192                                   r9 = 192 as i32 as i64 as u64
    ja lbb_28795                                    if true { pc += 31 }
lbb_28764:
    mov64 r3, r5                                    r3 = r5
    mov64 r9, r1                                    r9 = r1
    jeq r3, 0, lbb_28826                            if r3 == (0 as i32 as i64 as u64) { pc += 59 }
    mov64 r1, 192                                   r1 = 192 as i32 as i64 as u64
    mov64 r5, r3                                    r5 = r3
    jgt r1, r3, lbb_28771                           if r1 > r3 { pc += 1 }
    mov64 r5, 192                                   r5 = 192 as i32 as i64 as u64
lbb_28771:
    stxdw [r10-0x8], r5                     
    lsh64 r5, 3                                     r5 <<= 3   ///  r5 = r5.wrapping_shl(3)
    mov64 r4, 0                                     r4 = 0 as i32 as i64 as u64
    mov64 r1, 4                                     r1 = 4 as i32 as i64 as u64
    jgt r1, r3, lbb_28732                           if r1 > r3 { pc += -44 }
    mov64 r2, r5                                    r2 = r5
    and64 r2, 2016                                  r2 &= 2016   ///  r2 = r2.and(2016)
    mov64 r1, r9                                    r1 = r9
    add64 r1, r2                                    r1 += r2   ///  r1 = r1.wrapping_add(r2)
    mov64 r2, r9                                    r2 = r9
    ja lbb_28698                                    if true { pc += -84 }
lbb_28782:
    mov64 r0, 0                                     r0 = 0 as i32 as i64 as u64
    jeq r2, 0, lbb_28826                            if r2 == (0 as i32 as i64 as u64) { pc += 42 }
lbb_28784:
    ldxb r4, [r1+0x0]                       
    lsh64 r4, 56                                    r4 <<= 56   ///  r4 = r4.wrapping_shl(56)
    arsh64 r4, 56                                   r4 >>= 56 (signed)   ///  r4 = (r4 as i64).wrapping_shr(56)
    mov64 r3, 1                                     r3 = 1 as i32 as i64 as u64
    jsgt r4, -65, lbb_28790                         if (r4 as i64) > (-65 as i32 as i64) { pc += 1 }
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
lbb_28790:
    add64 r0, r3                                    r0 += r3   ///  r0 = r0.wrapping_add(r3)
    add64 r1, 1                                     r1 += 1   ///  r1 = r1.wrapping_add(1 as i32 as i64 as u64)
    add64 r2, -1                                    r2 += -1   ///  r2 = r2.wrapping_add(-1 as i32 as i64 as u64)
    jeq r2, 0, lbb_28826                            if r2 == (0 as i32 as i64 as u64) { pc += 32 }
    ja lbb_28784                                    if true { pc += -11 }
lbb_28795:
    add64 r6, r8                                    r6 += r8   ///  r6 = r6.wrapping_add(r8)
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
    and64 r9, 3                                     r9 &= 3   ///  r9 = r9.and(3)
    lsh64 r9, 3                                     r9 <<= 3   ///  r9 = r9.wrapping_shl(3)
    lddw r1, 0x101010101010101                      r1 load str located at 72340172838076673
lbb_28801:
    ldxdw r0, [r6+0x0]                      
    mov64 r5, r0                                    r5 = r0
    rsh64 r5, 6                                     r5 >>= 6   ///  r5 = r5.wrapping_shr(6)
    xor64 r0, -1                                    r0 ^= -1   ///  r0 = r0.xor(-1)
    rsh64 r0, 7                                     r0 >>= 7   ///  r0 = r0.wrapping_shr(7)
    or64 r0, r5                                     r0 |= r5   ///  r0 = r0.or(r5)
    and64 r0, r1                                    r0 &= r1   ///  r0 = r0.and(r1)
    add64 r0, r2                                    r0 += r2   ///  r0 = r0.wrapping_add(r2)
    add64 r6, 8                                     r6 += 8   ///  r6 = r6.wrapping_add(8 as i32 as i64 as u64)
    add64 r9, -8                                    r9 += -8   ///  r9 = r9.wrapping_add(-8 as i32 as i64 as u64)
    mov64 r2, r0                                    r2 = r0
    jeq r9, 0, lbb_28814                            if r9 == (0 as i32 as i64 as u64) { pc += 1 }
    ja lbb_28801                                    if true { pc += -13 }
lbb_28814:
    lddw r1, 0xff00ff00ff00ff                       r1 load str located at 71777214294589695
    mov64 r2, r0                                    r2 = r0
    and64 r2, r1                                    r2 &= r1   ///  r2 = r2.and(r1)
    rsh64 r0, 8                                     r0 >>= 8   ///  r0 = r0.wrapping_shr(8)
    and64 r0, r1                                    r0 &= r1   ///  r0 = r0.and(r1)
    add64 r0, r2                                    r0 += r2   ///  r0 = r0.wrapping_add(r2)
    lddw r1, 0x1000100010001                        r1 load str located at 281479271743489
    mul64 r0, r1                                    r0 *= r1   ///  r0 = r0.wrapping_mul(r1)
    rsh64 r0, 48                                    r0 >>= 48   ///  r0 = r0.wrapping_shr(48)
    add64 r0, r4                                    r0 += r4   ///  r0 = r0.wrapping_add(r4)
lbb_28826:
    exit                                    

function_28827:
    call function_28828                     

function_28828:
    stxdw [r10-0xc8], r4                    
    stxdw [r10-0xd0], r3                    
    mov64 r0, 257                                   r0 = 257 as i32 as i64 as u64
    jgt r0, r2, lbb_28857                           if r0 > r2 { pc += 25 }
    mov64 r0, 256                                   r0 = 256 as i32 as i64 as u64
    ldxb r6, [r1+0x100]                     
    lsh64 r6, 56                                    r6 <<= 56   ///  r6 = r6.wrapping_shl(56)
    arsh64 r6, 56                                   r6 >>= 56 (signed)   ///  r6 = (r6 as i64).wrapping_shr(56)
    jsgt r6, -65, lbb_28848                         if (r6 as i64) > (-65 as i32 as i64) { pc += 11 }
    mov64 r0, 255                                   r0 = 255 as i32 as i64 as u64
    ldxb r6, [r1+0xff]                      
    lsh64 r6, 56                                    r6 <<= 56   ///  r6 = r6.wrapping_shl(56)
    arsh64 r6, 56                                   r6 >>= 56 (signed)   ///  r6 = (r6 as i64).wrapping_shr(56)
    jsgt r6, -65, lbb_28848                         if (r6 as i64) > (-65 as i32 as i64) { pc += 6 }
    mov64 r0, 254                                   r0 = 254 as i32 as i64 as u64
    ldxb r6, [r1+0xfe]                      
    lsh64 r6, 56                                    r6 <<= 56   ///  r6 = r6.wrapping_shl(56)
    arsh64 r6, 56                                   r6 >>= 56 (signed)   ///  r6 = (r6 as i64).wrapping_shr(56)
    jsgt r6, -65, lbb_28848                         if (r6 as i64) > (-65 as i32 as i64) { pc += 1 }
    mov64 r0, 253                                   r0 = 253 as i32 as i64 as u64
lbb_28848:
    mov64 r6, r1                                    r6 = r1
    add64 r6, r0                                    r6 += r0   ///  r6 = r6.wrapping_add(r0)
    ldxb r6, [r6+0x0]                       
    lsh64 r6, 56                                    r6 <<= 56   ///  r6 = r6.wrapping_shl(56)
    arsh64 r6, 56                                   r6 >>= 56 (signed)   ///  r6 = (r6 as i64).wrapping_shr(56)
    jsgt r6, -65, lbb_28858                         if (r6 as i64) > (-65 as i32 as i64) { pc += 4 }
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
    mov64 r4, r0                                    r4 = r0
    call function_28827                     
lbb_28857:
    mov64 r0, r2                                    r0 = r2
lbb_28858:
    lddw r6, 0x1000401fb --> b"[...]begin <= end (`byte index  is not a char boun"        r6 load str located at 4295229947
    jgt r2, r0, lbb_28862                           if r2 > r0 { pc += 1 }
    mov64 r6, 1                                     r6 = 1 as i32 as i64 as u64
lbb_28862:
    mov64 r7, 5                                     r7 = 5 as i32 as i64 as u64
    jgt r2, r0, lbb_28865                           if r2 > r0 { pc += 1 }
    mov64 r7, 0                                     r7 = 0 as i32 as i64 as u64
lbb_28865:
    stxdw [r10-0xb8], r0                    
    stxdw [r10-0xc0], r1                    
    stxdw [r10-0xa8], r7                    
    stxdw [r10-0xb0], r6                    
    jgt r3, r2, lbb_28903                           if r3 > r2 { pc += 33 }
    jgt r4, r2, lbb_28903                           if r4 > r2 { pc += 32 }
    jge r4, r3, lbb_28937                           if r4 >= r3 { pc += 65 }
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    stxdw [r10-0x60], r1                    
    lddw r1, 0x1000420a8 --> b"\x00\x00\x00\x00\x00\x02\x04\x00\x0e\x00\x00\x00\x00\x00\x00\x00\x00\x00\…        r1 load str located at 4295237800
    stxdw [r10-0x80], r1                    
    mov64 r1, 4                                     r1 = 4 as i32 as i64 as u64
    stxdw [r10-0x78], r1                    
    stxdw [r10-0x68], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -80                                   r1 += -80   ///  r1 = r1.wrapping_add(-80 as i32 as i64 as u64)
    stxdw [r10-0x70], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -176                                  r1 += -176   ///  r1 = r1.wrapping_add(-176 as i32 as i64 as u64)
    stxdw [r10-0x20], r1                    
    lddw r1, 0x10003b258 --> b"\xbf$\x00\x00\x00\x00\x00\x00y\x13\x08\x00\x00\x00\x00\x00y\x12\x00\x00\x…        r1 load str located at 4295209560
    stxdw [r10-0x18], r1                    
    stxdw [r10-0x28], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -192                                  r1 += -192   ///  r1 = r1.wrapping_add(-192 as i32 as i64 as u64)
    stxdw [r10-0x30], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -200                                  r1 += -200   ///  r1 = r1.wrapping_add(-200 as i32 as i64 as u64)
    stxdw [r10-0x40], r1                    
    lddw r1, 0x10003b1e0 --> b"\xbf#\x00\x00\x00\x00\x00\x00y\x11\x00\x00\x00\x00\x00\x00\xb7\x02\x00\x0…        r1 load str located at 4295209440
    stxdw [r10-0x38], r1                    
    stxdw [r10-0x48], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -208                                  r1 += -208   ///  r1 = r1.wrapping_add(-208 as i32 as i64 as u64)
    ja lbb_28932                                    if true { pc += 29 }
lbb_28903:
    jgt r3, r2, lbb_28905                           if r3 > r2 { pc += 1 }
    mov64 r3, r4                                    r3 = r4
lbb_28905:
    stxdw [r10-0x90], r3                    
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    stxdw [r10-0x60], r1                    
    lddw r1, 0x100042138 --> b"\x00\x00\x00\x00\x0f\x02\x04\x00\x0b\x00\x00\x00\x00\x00\x00\x00\x00\x00\…        r1 load str located at 4295237944
    stxdw [r10-0x80], r1                    
    mov64 r1, 3                                     r1 = 3 as i32 as i64 as u64
    stxdw [r10-0x78], r1                    
    stxdw [r10-0x68], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -80                                   r1 += -80   ///  r1 = r1.wrapping_add(-80 as i32 as i64 as u64)
    stxdw [r10-0x70], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -176                                  r1 += -176   ///  r1 = r1.wrapping_add(-176 as i32 as i64 as u64)
    stxdw [r10-0x30], r1                    
    lddw r1, 0x10003b258 --> b"\xbf$\x00\x00\x00\x00\x00\x00y\x13\x08\x00\x00\x00\x00\x00y\x12\x00\x00\x…        r1 load str located at 4295209560
    stxdw [r10-0x28], r1                    
    stxdw [r10-0x38], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -192                                  r1 += -192   ///  r1 = r1.wrapping_add(-192 as i32 as i64 as u64)
    stxdw [r10-0x40], r1                    
    lddw r1, 0x10003b1e0 --> b"\xbf#\x00\x00\x00\x00\x00\x00y\x11\x00\x00\x00\x00\x00\x00\xb7\x02\x00\x0…        r1 load str located at 4295209440
    stxdw [r10-0x48], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -144                                  r1 += -144   ///  r1 = r1.wrapping_add(-144 as i32 as i64 as u64)
lbb_28932:
    stxdw [r10-0x50], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -128                                  r1 += -128   ///  r1 = r1.wrapping_add(-128 as i32 as i64 as u64)
    mov64 r2, r5                                    r2 = r5
    call function_25805                     
lbb_28937:
    jeq r3, 0, lbb_28946                            if r3 == (0 as i32 as i64 as u64) { pc += 8 }
    jge r3, r2, lbb_28946                           if r3 >= r2 { pc += 7 }
    mov64 r0, r1                                    r0 = r1
    add64 r0, r3                                    r0 += r3   ///  r0 = r0.wrapping_add(r3)
    ldxb r0, [r0+0x0]                       
    lsh64 r0, 56                                    r0 <<= 56   ///  r0 = r0.wrapping_shl(56)
    arsh64 r0, 56                                   r0 >>= 56 (signed)   ///  r0 = (r0 as i64).wrapping_shr(56)
    mov64 r6, -64                                   r6 = -64 as i32 as i64 as u64
    jsgt r6, r0, lbb_28947                          if (r6 as i64) > (r0 as i64) { pc += 1 }
lbb_28946:
    mov64 r3, r4                                    r3 = r4
lbb_28947:
    stxdw [r10-0xa0], r3                    
    mov64 r0, r3                                    r0 = r3
    mov64 r3, r2                                    r3 = r2
    mov64 r4, r0                                    r4 = r0
    jge r0, r2, lbb_28986                           if r0 >= r2 { pc += 34 }
    mov64 r3, r4                                    r3 = r4
    mov64 r0, r3                                    r0 = r3
    add64 r0, -3                                    r0 += -3   ///  r0 = r0.wrapping_add(-3 as i32 as i64 as u64)
    mov64 r4, 0                                     r4 = 0 as i32 as i64 as u64
    mov64 r6, 1                                     r6 = 1 as i32 as i64 as u64
    jgt r0, r3, lbb_28959                           if r0 > r3 { pc += 1 }
    mov64 r6, 0                                     r6 = 0 as i32 as i64 as u64
lbb_28959:
    jne r6, 0, lbb_28961                            if r6 != (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r4, r0                                    r4 = r0
lbb_28961:
    mov64 r0, r3                                    r0 = r3
    add64 r0, 1                                     r0 += 1   ///  r0 = r0.wrapping_add(1 as i32 as i64 as u64)
    jge r0, r4, lbb_28969                           if r0 >= r4 { pc += 5 }
    mov64 r1, r4                                    r1 = r4
    mov64 r2, r0                                    r2 = r0
    lddw r3, 0x100042168 --> b"\x00\x00\x00\x00\\x02\x04\x00\x1b\x00\x00\x00\x00\x00\x00\x00\x05\x01\x00…        r3 load str located at 4295237992
    call function_28381                     
lbb_28969:
    mov64 r6, r1                                    r6 = r1
    add64 r6, r4                                    r6 += r4   ///  r6 = r6.wrapping_add(r4)
    mov64 r7, r3                                    r7 = r3
    mov64 r3, r1                                    r3 = r1
    add64 r3, r0                                    r3 += r0   ///  r3 = r3.wrapping_add(r0)
    sub64 r3, r6                                    r3 -= r6   ///  r3 = r3.wrapping_sub(r6)
    mov64 r0, r1                                    r0 = r1
    add64 r0, r7                                    r0 += r7   ///  r0 = r0.wrapping_add(r7)
    mov64 r6, -64                                   r6 = -64 as i32 as i64 as u64
lbb_28978:
    jeq r3, 0, lbb_28985                            if r3 == (0 as i32 as i64 as u64) { pc += 6 }
    add64 r3, -1                                    r3 += -1   ///  r3 = r3.wrapping_add(-1 as i32 as i64 as u64)
    ldxb r7, [r0+0x0]                       
    add64 r0, -1                                    r0 += -1   ///  r0 = r0.wrapping_add(-1 as i32 as i64 as u64)
    lsh64 r7, 56                                    r7 <<= 56   ///  r7 = r7.wrapping_shl(56)
    arsh64 r7, 56                                   r7 >>= 56 (signed)   ///  r7 = (r7 as i64).wrapping_shr(56)
    jsgt r6, r7, lbb_28978                          if (r6 as i64) > (r7 as i64) { pc += -7 }
lbb_28985:
    add64 r3, r4                                    r3 += r4   ///  r3 = r3.wrapping_add(r4)
lbb_28986:
    jeq r3, 0, lbb_28990                            if r3 == (0 as i32 as i64 as u64) { pc += 3 }
    jgt r2, r3, lbb_29027                           if r2 > r3 { pc += 39 }
    jeq r3, r2, lbb_28990                           if r3 == r2 { pc += 1 }
    ja lbb_29033                                    if true { pc += 43 }
lbb_28990:
    jeq r3, r2, lbb_29025                           if r3 == r2 { pc += 34 }
    add64 r1, r3                                    r1 += r3   ///  r1 = r1.wrapping_add(r3)
    ldxb r0, [r1+0x0]                       
    mov64 r2, r0                                    r2 = r0
    lsh64 r2, 56                                    r2 <<= 56   ///  r2 = r2.wrapping_shl(56)
    arsh64 r2, 56                                   r2 >>= 56 (signed)   ///  r2 = (r2 as i64).wrapping_shr(56)
    jsgt r2, -1, lbb_29035                          if (r2 as i64) > (-1 as i32 as i64) { pc += 38 }
    ldxb r2, [r1+0x1]                       
    and64 r2, 63                                    r2 &= 63   ///  r2 = r2.and(63)
    mov64 r4, r0                                    r4 = r0
    and64 r4, 31                                    r4 &= 31   ///  r4 = r4.and(31)
    mov64 r6, r4                                    r6 = r4
    lsh64 r6, 6                                     r6 <<= 6   ///  r6 = r6.wrapping_shl(6)
    or64 r6, r2                                     r6 |= r2   ///  r6 = r6.or(r2)
    jgt r0, 223, lbb_29006                          if r0 > (223 as i32 as i64 as u64) { pc += 1 }
    ja lbb_29036                                    if true { pc += 30 }
lbb_29006:
    lsh64 r2, 6                                     r2 <<= 6   ///  r2 = r2.wrapping_shl(6)
    ldxb r6, [r1+0x2]                       
    and64 r6, 63                                    r6 &= 63   ///  r6 = r6.and(63)
    or64 r2, r6                                     r2 |= r6   ///  r2 = r2.or(r6)
    mov64 r7, r4                                    r7 = r4
    lsh64 r7, 12                                    r7 <<= 12   ///  r7 = r7.wrapping_shl(12)
    mov64 r6, r2                                    r6 = r2
    or64 r6, r7                                     r6 |= r7   ///  r6 = r6.or(r7)
    mov64 r7, 240                                   r7 = 240 as i32 as i64 as u64
    jgt r7, r0, lbb_29036                           if r7 > r0 { pc += 20 }
    lsh64 r2, 6                                     r2 <<= 6   ///  r2 = r2.wrapping_shl(6)
    ldxb r1, [r1+0x3]                       
    and64 r1, 63                                    r1 &= 63   ///  r1 = r1.and(63)
    or64 r2, r1                                     r2 |= r1   ///  r2 = r2.or(r1)
    lsh64 r4, 18                                    r4 <<= 18   ///  r4 = r4.wrapping_shl(18)
    and64 r4, 1835008                               r4 &= 1835008   ///  r4 = r4.and(1835008)
    or64 r2, r4                                     r2 |= r4   ///  r2 = r2.or(r4)
    mov64 r6, r2                                    r6 = r2
    ja lbb_29036                                    if true { pc += 11 }
lbb_29025:
    mov64 r1, r5                                    r1 = r5
    call function_25695                     
lbb_29027:
    mov64 r4, r1                                    r4 = r1
    add64 r4, r3                                    r4 += r3   ///  r4 = r4.wrapping_add(r3)
    ldxb r4, [r4+0x0]                       
    lsh64 r4, 56                                    r4 <<= 56   ///  r4 = r4.wrapping_shl(56)
    arsh64 r4, 56                                   r4 >>= 56 (signed)   ///  r4 = (r4 as i64).wrapping_shr(56)
    jsgt r4, -65, lbb_28990                         if (r4 as i64) > (-65 as i32 as i64) { pc += -43 }
lbb_29033:
    mov64 r4, r2                                    r4 = r2
    call function_28827                     
lbb_29035:
    mov64 r6, r0                                    r6 = r0
lbb_29036:
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    stxw [r10-0x94], r6                     
    mov64 r2, 128                                   r2 = 128 as i32 as i64 as u64
    jgt r2, r6, lbb_29047                           if r2 > r6 { pc += 7 }
    mov64 r1, 2                                     r1 = 2 as i32 as i64 as u64
    mov64 r2, 2048                                  r2 = 2048 as i32 as i64 as u64
    jgt r2, r6, lbb_29047                           if r2 > r6 { pc += 4 }
    mov64 r1, 3                                     r1 = 3 as i32 as i64 as u64
    mov64 r2, 65536                                 r2 = 65536 as i32 as i64 as u64
    jgt r2, r6, lbb_29047                           if r2 > r6 { pc += 1 }
    mov64 r1, 4                                     r1 = 4 as i32 as i64 as u64
lbb_29047:
    stxdw [r10-0x90], r3                    
    add64 r1, r3                                    r1 += r3   ///  r1 = r1.wrapping_add(r3)
    stxdw [r10-0x88], r1                    
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    stxdw [r10-0x60], r1                    
    lddw r1, 0x1000420e8 --> b"\x00\x00\x00\x00\x0f\x02\x04\x00\x0b\x00\x00\x00\x00\x00\x00\x00\x00\x00\…        r1 load str located at 4295237864
    stxdw [r10-0x80], r1                    
    mov64 r1, 5                                     r1 = 5 as i32 as i64 as u64
    stxdw [r10-0x78], r1                    
    stxdw [r10-0x68], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -80                                   r1 += -80   ///  r1 = r1.wrapping_add(-80 as i32 as i64 as u64)
    stxdw [r10-0x70], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -176                                  r1 += -176   ///  r1 = r1.wrapping_add(-176 as i32 as i64 as u64)
    stxdw [r10-0x10], r1                    
    lddw r1, 0x10003b258 --> b"\xbf$\x00\x00\x00\x00\x00\x00y\x13\x08\x00\x00\x00\x00\x00y\x12\x00\x00\x…        r1 load str located at 4295209560
    stxdw [r10-0x8], r1                     
    stxdw [r10-0x18], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -192                                  r1 += -192   ///  r1 = r1.wrapping_add(-192 as i32 as i64 as u64)
    stxdw [r10-0x20], r1                    
    lddw r1, 0x100031728 --> b"\xbf&\x00\x00\x00\x00\x00\x00\xbf\x17\x00\x00\x00\x00\x00\x00\x85\x10\x00…        r1 load str located at 4295169832
    stxdw [r10-0x28], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -144                                  r1 += -144   ///  r1 = r1.wrapping_add(-144 as i32 as i64 as u64)
    stxdw [r10-0x30], r1                    
    lddw r1, 0x100036f68 --> b"\xbf\x18\x00\x00\x00\x00\x00\x00y& \x00\x00\x00\x00\x00y!(\x00\x00\x00\x0…        r1 load str located at 4295192424
    stxdw [r10-0x38], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -148                                  r1 += -148   ///  r1 = r1.wrapping_add(-148 as i32 as i64 as u64)
    stxdw [r10-0x40], r1                    
    lddw r1, 0x10003b1e0 --> b"\xbf#\x00\x00\x00\x00\x00\x00y\x11\x00\x00\x00\x00\x00\x00\xb7\x02\x00\x0…        r1 load str located at 4295209440
    stxdw [r10-0x48], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -160                                  r1 += -160   ///  r1 = r1.wrapping_add(-160 as i32 as i64 as u64)
    ja lbb_28932                                    if true { pc += -157 }

function_29089:
    mov64 r9, r1                                    r9 = r1
    ldxdw r1, [r5-0xff0]                    
    stxdw [r10-0x10], r1                    
    ldxdw r6, [r5-0xff8]                    
    jeq r3, 0, lbb_29135                            if r3 == (0 as i32 as i64 as u64) { pc += 41 }
    lsh64 r3, 1                                     r3 <<= 1   ///  r3 = r3.wrapping_shl(1)
    mov64 r1, r2                                    r1 = r2
    add64 r1, r3                                    r1 += r3   ///  r1 = r1.wrapping_add(r3)
    stxdw [r10-0x8], r1                     
    ldxdw r8, [r5-0x1000]                   
    mov64 r3, r9                                    r3 = r9
    and64 r3, 65280                                 r3 &= 65280   ///  r3 = r3.and(65280)
    rsh64 r3, 8                                     r3 >>= 8   ///  r3 = r3.wrapping_shr(8)
    mov64 r0, 0                                     r0 = 0 as i32 as i64 as u64
    stxdw [r10-0x20], r4                    
    stxdw [r10-0x18], r8                    
    ja lbb_29110                                    if true { pc += 4 }
lbb_29106:
    jgt r1, r3, lbb_29135                           if r1 > r3 { pc += 28 }
    mov64 r0, r5                                    r0 = r5
    ldxdw r1, [r10-0x8]                     
    jeq r2, r1, lbb_29135                           if r2 == r1 { pc += 25 }
lbb_29110:
    ldxb r7, [r2+0x1]                       
    mov64 r5, r0                                    r5 = r0
    add64 r5, r7                                    r5 += r7   ///  r5 = r5.wrapping_add(r7)
    ldxb r1, [r2+0x0]                       
    add64 r2, 2                                     r2 += 2   ///  r2 = r2.wrapping_add(2 as i32 as i64 as u64)
    jeq r1, r3, lbb_29117                           if r1 == r3 { pc += 1 }
    ja lbb_29106                                    if true { pc += -11 }
lbb_29117:
    jgt r0, r5, lbb_29174                           if r0 > r5 { pc += 56 }
    jgt r5, r8, lbb_29169                           if r5 > r8 { pc += 50 }
    add64 r4, r0                                    r4 += r0   ///  r4 = r4.wrapping_add(r0)
lbb_29120:
    jeq r7, 0, lbb_29129                            if r7 == (0 as i32 as i64 as u64) { pc += 8 }
    mov64 r0, 0                                     r0 = 0 as i32 as i64 as u64
    add64 r7, -1                                    r7 += -1   ///  r7 = r7.wrapping_add(-1 as i32 as i64 as u64)
    mov64 r1, r9                                    r1 = r9
    and64 r1, 255                                   r1 &= 255   ///  r1 = r1.and(255)
    ldxb r8, [r4+0x0]                       
    add64 r4, 1                                     r4 += 1   ///  r4 = r4.wrapping_add(1 as i32 as i64 as u64)
    jeq r8, r1, lbb_29164                           if r8 == r1 { pc += 36 }
    ja lbb_29120                                    if true { pc += -9 }
lbb_29129:
    mov64 r0, r5                                    r0 = r5
    ldxdw r4, [r10-0x20]                    
    ldxdw r8, [r10-0x18]                    
    ldxdw r1, [r10-0x8]                     
    jeq r2, r1, lbb_29135                           if r2 == r1 { pc += 1 }
    ja lbb_29110                                    if true { pc += -25 }
lbb_29135:
    mov64 r0, 1                                     r0 = 1 as i32 as i64 as u64
    ldxdw r1, [r10-0x10]                    
    jeq r1, 0, lbb_29164                            if r1 == (0 as i32 as i64 as u64) { pc += 26 }
    mov64 r2, r6                                    r2 = r6
    ldxdw r1, [r10-0x10]                    
    add64 r2, r1                                    r2 += r1   ///  r2 = r2.wrapping_add(r1)
    and64 r9, 65535                                 r9 &= 65535   ///  r9 = r9.and(65535)
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
lbb_29143:
    mov64 r5, r6                                    r5 = r6
    add64 r5, 1                                     r5 += 1   ///  r5 = r5.wrapping_add(1 as i32 as i64 as u64)
    ldxb r4, [r6+0x0]                       
    mov64 r7, r4                                    r7 = r4
    lsh64 r7, 56                                    r7 <<= 56   ///  r7 = r7.wrapping_shl(56)
    arsh64 r7, 56                                   r7 >>= 56 (signed)   ///  r7 = (r7 as i64).wrapping_shr(56)
    jsgt r3, r7, lbb_29152                          if (r3 as i64) > (r7 as i64) { pc += 2 }
    mov64 r6, r5                                    r6 = r5
    ja lbb_29158                                    if true { pc += 6 }
lbb_29152:
    jeq r5, r2, lbb_29166                           if r5 == r2 { pc += 13 }
    and64 r4, 127                                   r4 &= 127   ///  r4 = r4.and(127)
    lsh64 r4, 8                                     r4 <<= 8   ///  r4 = r4.wrapping_shl(8)
    ldxb r5, [r6+0x1]                       
    or64 r4, r5                                     r4 |= r5   ///  r4 = r4.or(r5)
    add64 r6, 2                                     r6 += 2   ///  r6 = r6.wrapping_add(2 as i32 as i64 as u64)
lbb_29158:
    sub64 r9, r4                                    r9 -= r4   ///  r9 = r9.wrapping_sub(r4)
    lsh64 r9, 32                                    r9 <<= 32   ///  r9 = r9.wrapping_shl(32)
    arsh64 r9, 32                                   r9 >>= 32 (signed)   ///  r9 = (r9 as i64).wrapping_shr(32)
    jsgt r3, r9, lbb_29164                          if (r3 as i64) > (r9 as i64) { pc += 2 }
    xor64 r0, 1                                     r0 ^= 1   ///  r0 = r0.xor(1)
    jne r6, r2, lbb_29143                           if r6 != r2 { pc += -21 }
lbb_29164:
    and64 r0, 1                                     r0 &= 1   ///  r0 = r0.and(1)
    exit                                    
lbb_29166:
    lddw r1, 0x100042180 --> b"\x00\x00\x00\x00w\x02\x04\x00%\x00\x00\x00\x00\x00\x00\x00\x1a\x00\x00\x0…        r1 load str located at 4295238016
    call function_25695                     
lbb_29169:
    mov64 r1, r5                                    r1 = r5
    ldxdw r2, [r10-0x18]                    
    lddw r3, 0x100042198 --> b"\x00\x00\x00\x00w\x02\x04\x00%\x00\x00\x00\x00\x00\x00\x00\x0a\x00\x00\x0…        r3 load str located at 4295238040
    call function_28353                     
lbb_29174:
    mov64 r1, r0                                    r1 = r0
    mov64 r2, r5                                    r2 = r5
    lddw r3, 0x100042198 --> b"\x00\x00\x00\x00w\x02\x04\x00%\x00\x00\x00\x00\x00\x00\x00\x0a\x00\x00\x0…        r3 load str located at 4295238040
    call function_28381                     

function_29179:
    mov64 r0, 0                                     r0 = 0 as i32 as i64 as u64
    mov64 r2, r1                                    r2 = r1
    lsh64 r2, 32                                    r2 <<= 32   ///  r2 = r2.wrapping_shl(32)
    rsh64 r2, 32                                    r2 >>= 32   ///  r2 = r2.wrapping_shr(32)
    mov64 r3, 32                                    r3 = 32 as i32 as i64 as u64
    jgt r3, r2, lbb_29224                           if r3 > r2 { pc += 39 }
    mov64 r0, 1                                     r0 = 1 as i32 as i64 as u64
    mov64 r3, 127                                   r3 = 127 as i32 as i64 as u64
    jgt r3, r2, lbb_29224                           if r3 > r2 { pc += 36 }
    mov64 r2, r1                                    r2 = r1
    lsh64 r2, 32                                    r2 <<= 32   ///  r2 = r2.wrapping_shl(32)
    rsh64 r2, 32                                    r2 >>= 32   ///  r2 = r2.wrapping_shr(32)
    mov64 r3, 65536                                 r3 = 65536 as i32 as i64 as u64
    jgt r3, r2, lbb_29210                           if r3 > r2 { pc += 17 }
    mov64 r3, 131072                                r3 = 131072 as i32 as i64 as u64
    jgt r3, r2, lbb_29196                           if r3 > r2 { pc += 1 }
    ja lbb_29226                                    if true { pc += 30 }
lbb_29196:
    lddw r2, 0x1000403b8 --> b"^"{\x05\x03\x04-\x03f\x03\x01/.\x80\x82\x1d\x031\x0f\x1c\x04$\x09\x1e\x05…        r2 load str located at 4295230392
    stxdw [r10-0xff8], r2                   
    mov64 r2, 450                                   r2 = 450 as i32 as i64 as u64
    stxdw [r10-0xff0], r2                   
    mov64 r2, 196                                   r2 = 196 as i32 as i64 as u64
    stxdw [r10-0x1000], r2                  
    mov64 r5, r10                                   r5 = r10
    lddw r2, 0x10004029c --> b"\x00\x06\x01\x01\x03\x01\x04\x02\x05\x07\x07\x02\x08\x08\x09\x02\x0a\x05\…        r2 load str located at 4295230108
    mov64 r3, 44                                    r3 = 44 as i32 as i64 as u64
    lddw r4, 0x1000402f4 --> b"\x0c';>NO\x8f\x9e\x9e\x9f{\x8b\x93\x96\xa2\xb2\xba\x86\xb1\x06\x07\x096=>…        r4 load str located at 4295230196
    ja lbb_29223                                    if true { pc += 13 }
lbb_29210:
    lddw r2, 0x1000406ea --> b"\x00 _"\x82\xdf\x04\x82D\x08\x1b\x04\x06\x11\x81\xac\x0e\x80\xab\x05\x1f\…        r2 load str located at 4295231210
    stxdw [r10-0xff8], r2                   
    mov64 r2, 301                                   r2 = 301 as i32 as i64 as u64
    stxdw [r10-0xff0], r2                   
    mov64 r2, 288                                   r2 = 288 as i32 as i64 as u64
    stxdw [r10-0x1000], r2                  
    mov64 r5, r10                                   r5 = r10
    lddw r2, 0x10004057a --> b"\x00\x01\x03\x05\x05\x06\x06\x02\x07\x06\x08\x07\x09\x11\x0a\x1c\x0b\x19\…        r2 load str located at 4295230842
    mov64 r3, 40                                    r3 = 40 as i32 as i64 as u64
    lddw r4, 0x1000405ca --> b"\xadxy\x8b\x8d\xa20WX\x8b\x8c\x90\x1c\xdd\x0e\x0fKL\xfb\xfc./?\]_\xe2\x84…        r4 load str located at 4295230922
lbb_29223:
    call function_29089                     
lbb_29224:
    and64 r0, 1                                     r0 &= 1   ///  r0 = r0.and(1)
    exit                                    
lbb_29226:
    mov64 r4, r1                                    r4 = r1
    add64 r4, -177978                               r4 += -177978   ///  r4 = r4.wrapping_add(-177978 as i32 as i64 as u64)
    lsh64 r4, 32                                    r4 <<= 32   ///  r4 = r4.wrapping_shl(32)
    rsh64 r4, 32                                    r4 >>= 32   ///  r4 = r4.wrapping_shr(32)
    mov64 r0, 0                                     r0 = 0 as i32 as i64 as u64
    mov64 r3, 1                                     r3 = 1 as i32 as i64 as u64
    mov64 r5, 6                                     r5 = 6 as i32 as i64 as u64
    mov64 r2, 1                                     r2 = 1 as i32 as i64 as u64
    jgt r5, r4, lbb_29236                           if r5 > r4 { pc += 1 }
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
lbb_29236:
    mov64 r5, r1                                    r5 = r1
    add64 r5, -183970                               r5 += -183970   ///  r5 = r5.wrapping_add(-183970 as i32 as i64 as u64)
    lsh64 r5, 32                                    r5 <<= 32   ///  r5 = r5.wrapping_shl(32)
    rsh64 r5, 32                                    r5 >>= 32   ///  r5 = r5.wrapping_shr(32)
    mov64 r6, 14                                    r6 = 14 as i32 as i64 as u64
    mov64 r4, 1                                     r4 = 1 as i32 as i64 as u64
    jgt r6, r5, lbb_29244                           if r6 > r5 { pc += 1 }
    mov64 r4, 0                                     r4 = 0 as i32 as i64 as u64
lbb_29244:
    mov64 r6, r1                                    r6 = r1
    add64 r6, -192094                               r6 += -192094   ///  r6 = r6.wrapping_add(-192094 as i32 as i64 as u64)
    lsh64 r6, 32                                    r6 <<= 32   ///  r6 = r6.wrapping_shl(32)
    rsh64 r6, 32                                    r6 >>= 32   ///  r6 = r6.wrapping_shr(32)
    mov64 r7, 2466                                  r7 = 2466 as i32 as i64 as u64
    mov64 r5, 1                                     r5 = 1 as i32 as i64 as u64
    jgt r7, r6, lbb_29252                           if r7 > r6 { pc += 1 }
    mov64 r5, 0                                     r5 = 0 as i32 as i64 as u64
lbb_29252:
    mov64 r6, r1                                    r6 = r1
    add64 r6, -191457                               r6 += -191457   ///  r6 = r6.wrapping_add(-191457 as i32 as i64 as u64)
    lsh64 r6, 32                                    r6 <<= 32   ///  r6 = r6.wrapping_shl(32)
    rsh64 r6, 32                                    r6 >>= 32   ///  r6 = r6.wrapping_shr(32)
    mov64 r7, 15                                    r7 = 15 as i32 as i64 as u64
    jgt r7, r6, lbb_29259                           if r7 > r6 { pc += 1 }
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
lbb_29259:
    lsh64 r3, 2                                     r3 <<= 2   ///  r3 = r3.wrapping_shl(2)
    lsh64 r5, 3                                     r5 <<= 3   ///  r5 = r5.wrapping_shl(3)
    or64 r5, r3                                     r5 |= r3   ///  r5 = r5.or(r3)
    lsh64 r4, 1                                     r4 <<= 1   ///  r4 = r4.wrapping_shl(1)
    or64 r2, r4                                     r2 |= r4   ///  r2 = r2.or(r4)
    or64 r2, r5                                     r2 |= r5   ///  r2 = r2.or(r5)
    jne r2, 0, lbb_29224                            if r2 != (0 as i32 as i64 as u64) { pc += -42 }
    mov64 r2, r1                                    r2 = r1
    add64 r2, -195102                               r2 += -195102   ///  r2 = r2.wrapping_add(-195102 as i32 as i64 as u64)
    lsh64 r2, 32                                    r2 <<= 32   ///  r2 = r2.wrapping_shl(32)
    rsh64 r2, 32                                    r2 >>= 32   ///  r2 = r2.wrapping_shr(32)
    mov64 r3, 1506                                  r3 = 1506 as i32 as i64 as u64
    jgt r3, r2, lbb_29224                           if r3 > r2 { pc += -48 }
    mov64 r2, r1                                    r2 = r1
    add64 r2, -201547                               r2 += -201547   ///  r2 = r2.wrapping_add(-201547 as i32 as i64 as u64)
    lsh64 r2, 32                                    r2 <<= 32   ///  r2 = r2.wrapping_shl(32)
    rsh64 r2, 32                                    r2 >>= 32   ///  r2 = r2.wrapping_shr(32)
    mov64 r3, 5                                     r3 = 5 as i32 as i64 as u64
    jgt r3, r2, lbb_29224                           if r3 > r2 { pc += -54 }
    mov64 r2, r1                                    r2 = r1
    add64 r2, -205744                               r2 += -205744   ///  r2 = r2.wrapping_add(-205744 as i32 as i64 as u64)
    lsh64 r2, 32                                    r2 <<= 32   ///  r2 = r2.wrapping_shl(32)
    rsh64 r2, 32                                    r2 >>= 32   ///  r2 = r2.wrapping_shr(32)
    mov64 r3, 712016                                r3 = 712016 as i32 as i64 as u64
    jgt r3, r2, lbb_29224                           if r3 > r2 { pc += -60 }
    mov64 r2, r1                                    r2 = r1
    and64 r2, -32                                   r2 &= -32   ///  r2 = r2.and(-32)
    lsh64 r2, 32                                    r2 <<= 32   ///  r2 = r2.wrapping_shl(32)
    rsh64 r2, 32                                    r2 >>= 32   ///  r2 = r2.wrapping_shr(32)
    jeq r2, 173792, lbb_29224                       if r2 == (173792 as i32 as i64 as u64) { pc += -65 }
    mov64 r2, r1                                    r2 = r1
    and64 r2, -2                                    r2 &= -2   ///  r2 = r2.and(-2)
    lsh64 r2, 32                                    r2 <<= 32   ///  r2 = r2.wrapping_shl(32)
    rsh64 r2, 32                                    r2 >>= 32   ///  r2 = r2.wrapping_shr(32)
    jeq r2, 178206, lbb_29224                       if r2 == (178206 as i32 as i64 as u64) { pc += -70 }
    add64 r1, -1114112                              r1 += -1114112   ///  r1 = r1.wrapping_add(-1114112 as i32 as i64 as u64)
    lsh64 r1, 32                                    r1 <<= 32   ///  r1 = r1.wrapping_shl(32)
    rsh64 r1, 32                                    r1 >>= 32   ///  r1 = r1.wrapping_shr(32)
    mov64 r0, 1                                     r0 = 1 as i32 as i64 as u64
    lddw r2, 0xfffd01f0                             r2 load str located at 4294771184
    jgt r2, r1, lbb_29224                           if r2 > r1 { pc += -77 }
    mov64 r0, 0                                     r0 = 0 as i32 as i64 as u64
    ja lbb_29224                                    if true { pc += -79 }

function_29303:
    mov64 r7, r2                                    r7 = r2
    mov64 r2, 1280                                  r2 = 1280 as i32 as i64 as u64
    jgt r2, r7, lbb_29312                           if r2 > r7 { pc += 6 }
    lddw r1, 0x100040891 --> b"assertion failed: digits < 40"        r1 load str located at 4295231633
    mov64 r2, 29                                    r2 = 29 as i32 as i64 as u64
    lddw r3, 0x100042210 --> b"\x00\x00\x00\x00Y\x08\x04\x00\x1e\x00\x00\x00\x00\x00\x00\x00\xac\x01\x00…        r3 load str located at 4295238160
    call function_25816                     
lbb_29312:
    mov64 r8, r7                                    r8 = r7
    rsh64 r8, 5                                     r8 >>= 5   ///  r8 = r8.wrapping_shr(5)
    stxdw [r10-0x8], r1                     
    ldxdw r3, [r1+0xa0]                     
    jeq r3, 0, lbb_29344                            if r3 == (0 as i32 as i64 as u64) { pc += 27 }
    mov64 r4, r3                                    r4 = r3
    add64 r4, r8                                    r4 += r8   ///  r4 = r4.wrapping_add(r8)
    lsh64 r4, 2                                     r4 <<= 2   ///  r4 = r4.wrapping_shl(2)
    ldxdw r1, [r10-0x8]                     
    add64 r4, r1                                    r4 += r1   ///  r4 = r4.wrapping_add(r1)
    mov64 r5, r3                                    r5 = r3
    lsh64 r5, 2                                     r5 <<= 2   ///  r5 = r5.wrapping_shl(2)
    add64 r5, r1                                    r5 += r1   ///  r5 = r5.wrapping_add(r1)
    mov64 r1, r3                                    r1 = r3
    add64 r1, -1                                    r1 += -1   ///  r1 = r1.wrapping_add(-1 as i32 as i64 as u64)
    add64 r5, -4                                    r5 += -4   ///  r5 = r5.wrapping_add(-4 as i32 as i64 as u64)
    add64 r4, -4                                    r4 += -4   ///  r4 = r4.wrapping_add(-4 as i32 as i64 as u64)
    mov64 r0, 41                                    r0 = 41 as i32 as i64 as u64
    mov64 r9, 40                                    r9 = 40 as i32 as i64 as u64
lbb_29331:
    jgt r0, r3, lbb_29333                           if r0 > r3 { pc += 1 }
    ja lbb_29419                                    if true { pc += 86 }
lbb_29333:
    mov64 r2, r8                                    r2 = r8
    add64 r2, r1                                    r2 += r1   ///  r2 = r2.wrapping_add(r1)
    jgt r9, r2, lbb_29337                           if r9 > r2 { pc += 1 }
    ja lbb_29413                                    if true { pc += 76 }
lbb_29337:
    ldxw r2, [r5+0x0]                       
    stxw [r4+0x0], r2                       
    add64 r4, -4                                    r4 += -4   ///  r4 = r4.wrapping_add(-4 as i32 as i64 as u64)
    add64 r5, -4                                    r5 += -4   ///  r5 = r5.wrapping_add(-4 as i32 as i64 as u64)
    add64 r1, -1                                    r1 += -1   ///  r1 = r1.wrapping_add(-1 as i32 as i64 as u64)
    jeq r1, -1, lbb_29344                           if r1 == (-1 as i32 as i64 as u64) { pc += 1 }
    ja lbb_29331                                    if true { pc += -13 }
lbb_29344:
    mov64 r9, r7                                    r9 = r7
    and64 r9, 31                                    r9 &= 31   ///  r9 = r9.and(31)
    mov64 r1, 32                                    r1 = 32 as i32 as i64 as u64
    jgt r1, r7, lbb_29353                           if r1 > r7 { pc += 5 }
    mov64 r3, r8                                    r3 = r8
    lsh64 r3, 2                                     r3 <<= 2   ///  r3 = r3.wrapping_shl(2)
    ldxdw r1, [r10-0x8]                     
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
    call function_30383                     
lbb_29353:
    ldxdw r0, [r10-0x8]                     
    ldxdw r2, [r0+0xa0]                     
    add64 r2, r8                                    r2 += r8   ///  r2 = r2.wrapping_add(r8)
    jne r9, 0, lbb_29359                            if r9 != (0 as i32 as i64 as u64) { pc += 2 }
lbb_29357:
    stxdw [r0+0xa0], r2                     
    exit                                    
lbb_29359:
    mov64 r1, r2                                    r1 = r2
    add64 r1, -1                                    r1 += -1   ///  r1 = r1.wrapping_add(-1 as i32 as i64 as u64)
    jgt r1, 39, lbb_29419                           if r1 > (39 as i32 as i64 as u64) { pc += 57 }
    lsh64 r1, 2                                     r1 <<= 2   ///  r1 = r1.wrapping_shl(2)
    mov64 r3, r0                                    r3 = r0
    add64 r3, r1                                    r3 += r1   ///  r3 = r3.wrapping_add(r1)
    ldxw r3, [r3+0x0]                       
    neg64 r7                                        r7 = -r7   ///  r7 = (r7 as i64).wrapping_neg() as u64
    and64 r7, 31                                    r7 &= 31   ///  r7 = r7.and(31)
    mov64 r4, r3                                    r4 = r3
    rsh64 r4, r7                                    r4 >>= r7   ///  r4 = r4.wrapping_shr(r7 as u32)
    mov64 r1, r2                                    r1 = r2
    jeq r4, 0, lbb_29380                            if r4 == (0 as i32 as i64 as u64) { pc += 8 }
    jgt r2, 39, lbb_29413                           if r2 > (39 as i32 as i64 as u64) { pc += 40 }
    mov64 r1, r2                                    r1 = r2
    lsh64 r1, 2                                     r1 <<= 2   ///  r1 = r1.wrapping_shl(2)
    mov64 r5, r0                                    r5 = r0
    add64 r5, r1                                    r5 += r1   ///  r5 = r5.wrapping_add(r1)
    stxw [r5+0x0], r4                       
    mov64 r1, r2                                    r1 = r2
    add64 r1, 1                                     r1 += 1   ///  r1 = r1.wrapping_add(1 as i32 as i64 as u64)
lbb_29380:
    stxdw [r10-0x10], r1                    
    mov64 r4, r8                                    r4 = r8
    add64 r4, 1                                     r4 += 1   ///  r4 = r4.wrapping_add(1 as i32 as i64 as u64)
    jge r4, r2, lbb_29404                           if r4 >= r2 { pc += 20 }
    mov64 r5, r2                                    r5 = r2
    lsh64 r5, 2                                     r5 <<= 2   ///  r5 = r5.wrapping_shl(2)
    ldxdw r1, [r10-0x8]                     
    add64 r5, r1                                    r5 += r1   ///  r5 = r5.wrapping_add(r1)
    add64 r5, -4                                    r5 += -4   ///  r5 = r5.wrapping_add(-4 as i32 as i64 as u64)
    mov64 r0, 40                                    r0 = 40 as i32 as i64 as u64
lbb_29390:
    mov64 r1, r2                                    r1 = r2
    add64 r1, -2                                    r1 += -2   ///  r1 = r1.wrapping_add(-2 as i32 as i64 as u64)
    jgt r0, r1, lbb_29394                           if r0 > r1 { pc += 1 }
    ja lbb_29418                                    if true { pc += 24 }
lbb_29394:
    lsh64 r3, r9                                    r3 <<= r9   ///  r3 = r3.wrapping_shl(r9 as u32)
    ldxw r6, [r5-0x4]                       
    mov64 r1, r6                                    r1 = r6
    rsh64 r1, r7                                    r1 >>= r7   ///  r1 = r1.wrapping_shr(r7 as u32)
    or64 r1, r3                                     r1 |= r3   ///  r1 = r1.or(r3)
    stxw [r5+0x0], r1                       
    add64 r5, -4                                    r5 += -4   ///  r5 = r5.wrapping_add(-4 as i32 as i64 as u64)
    add64 r2, -1                                    r2 += -1   ///  r2 = r2.wrapping_add(-1 as i32 as i64 as u64)
    mov64 r3, r6                                    r3 = r6
    jgt r2, r4, lbb_29390                           if r2 > r4 { pc += -14 }
lbb_29404:
    lsh64 r8, 2                                     r8 <<= 2   ///  r8 = r8.wrapping_shl(2)
    ldxdw r0, [r10-0x8]                     
    mov64 r1, r0                                    r1 = r0
    add64 r1, r8                                    r1 += r8   ///  r1 = r1.wrapping_add(r8)
    ldxw r3, [r1+0x0]                       
    lsh64 r3, r9                                    r3 <<= r9   ///  r3 = r3.wrapping_shl(r9 as u32)
    stxw [r1+0x0], r3                       
    ldxdw r2, [r10-0x10]                    
    ja lbb_29357                                    if true { pc += -56 }
lbb_29413:
    mov64 r1, r2                                    r1 = r2
    mov64 r2, 40                                    r2 = 40 as i32 as i64 as u64
    lddw r3, 0x100042210 --> b"\x00\x00\x00\x00Y\x08\x04\x00\x1e\x00\x00\x00\x00\x00\x00\x00\xac\x01\x00…        r3 load str located at 4295238160
    call function_25832                     
lbb_29418:
    mov64 r1, -1                                    r1 = -1 as i32 as i64 as u64
lbb_29419:
    mov64 r2, 40                                    r2 = 40 as i32 as i64 as u64
    lddw r3, 0x100042210 --> b"\x00\x00\x00\x00Y\x08\x04\x00\x1e\x00\x00\x00\x00\x00\x00\x00\xac\x01\x00…        r3 load str located at 4295238160
    call function_25832                     

function_29423:
    mov64 r8, r3                                    r8 = r3
    mov64 r7, r2                                    r7 = r2
    mov64 r6, r1                                    r6 = r1
    mov64 r1, r10                                   r1 = r10
    add64 r1, -160                                  r1 += -160   ///  r1 = r1.wrapping_add(-160 as i32 as i64 as u64)
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
    mov64 r3, 160                                   r3 = 160 as i32 as i64 as u64
    call function_30383                     
    ldxdw r0, [r6+0xa0]                     
    mov64 r1, 41                                    r1 = 41 as i32 as i64 as u64
    jgt r1, r0, lbb_29439                           if r1 > r0 { pc += 5 }
    mov64 r1, r0                                    r1 = r0
    mov64 r2, 40                                    r2 = 40 as i32 as i64 as u64
    lddw r3, 0x100042210 --> b"\x00\x00\x00\x00Y\x08\x04\x00\x1e\x00\x00\x00\x00\x00\x00\x00\xac\x01\x00…        r3 load str located at 4295238160
    call function_28353                     
lbb_29439:
    stxdw [r10-0xb0], r6                    
    jgt r8, r0, lbb_29513                           if r8 > r0 { pc += 72 }
    lsh64 r8, 2                                     r8 <<= 2   ///  r8 = r8.wrapping_shl(2)
    mov64 r5, r7                                    r5 = r7
    add64 r5, r8                                    r5 += r8   ///  r5 = r5.wrapping_add(r8)
    jeq r0, 0, lbb_29585                            if r0 == (0 as i32 as i64 as u64) { pc += 140 }
    mov64 r1, r0                                    r1 = r0
    add64 r1, 1                                     r1 += 1   ///  r1 = r1.wrapping_add(1 as i32 as i64 as u64)
    stxdw [r10-0xd8], r1                    
    mov64 r8, 0                                     r8 = 0 as i32 as i64 as u64
    mov64 r1, r0                                    r1 = r0
    lsh64 r1, 2                                     r1 <<= 2   ///  r1 = r1.wrapping_shl(2)
    stxdw [r10-0xc0], r1                    
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    stxdw [r10-0xa8], r1                    
lbb_29454:
    mov64 r3, r8                                    r3 = r8
    lsh64 r3, 2                                     r3 <<= 2   ///  r3 = r3.wrapping_shl(2)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -160                                  r2 += -160   ///  r2 = r2.wrapping_add(-160 as i32 as i64 as u64)
    add64 r2, r3                                    r2 += r3   ///  r2 = r2.wrapping_add(r3)
lbb_29459:
    mov64 r9, r8                                    r9 = r8
    mov64 r4, r2                                    r4 = r2
    jeq r7, r5, lbb_29590                           if r7 == r5 { pc += 128 }
    mov64 r2, r4                                    r2 = r4
    add64 r2, 4                                     r2 += 4   ///  r2 = r2.wrapping_add(4 as i32 as i64 as u64)
    mov64 r8, r9                                    r8 = r9
    add64 r8, 1                                     r8 += 1   ///  r8 = r8.wrapping_add(1 as i32 as i64 as u64)
    ldxw r6, [r7+0x0]                       
    add64 r7, 4                                     r7 += 4   ///  r7 = r7.wrapping_add(4 as i32 as i64 as u64)
    jeq r6, 0, lbb_29459                            if r6 == (0 as i32 as i64 as u64) { pc += -10 }
    stxdw [r10-0xc8], r0                    
    stxdw [r10-0xd0], r5                    
    stxdw [r10-0xb8], r7                    
    mov64 r5, 0                                     r5 = 0 as i32 as i64 as u64
    ldxdw r0, [r10-0xc0]                    
    mov64 r2, r9                                    r2 = r9
    ldxdw r3, [r10-0xb0]                    
lbb_29476:
    mov64 r1, 40                                    r1 = 40 as i32 as i64 as u64
    jgt r1, r2, lbb_29479                           if r1 > r2 { pc += 1 }
    ja lbb_29614                                    if true { pc += 135 }
lbb_29479:
    ldxw r7, [r3+0x0]                       
    mul64 r7, r6                                    r7 *= r6   ///  r7 = r7.wrapping_mul(r6)
    ldxw r1, [r4+0x0]                       
    add64 r5, r1                                    r5 += r1   ///  r5 = r5.wrapping_add(r1)
    add64 r5, r7                                    r5 += r7   ///  r5 = r5.wrapping_add(r7)
    stxw [r4+0x0], r5                       
    add64 r4, 4                                     r4 += 4   ///  r4 = r4.wrapping_add(4 as i32 as i64 as u64)
    add64 r2, 1                                     r2 += 1   ///  r2 = r2.wrapping_add(1 as i32 as i64 as u64)
    add64 r3, 4                                     r3 += 4   ///  r3 = r3.wrapping_add(4 as i32 as i64 as u64)
    rsh64 r5, 32                                    r5 >>= 32   ///  r5 = r5.wrapping_shr(32)
    add64 r0, -4                                    r0 += -4   ///  r0 = r0.wrapping_add(-4 as i32 as i64 as u64)
    jeq r0, 0, lbb_29492                            if r0 == (0 as i32 as i64 as u64) { pc += 1 }
    ja lbb_29476                                    if true { pc += -16 }
lbb_29492:
    ldxdw r0, [r10-0xc8]                    
    mov64 r2, r0                                    r2 = r0
    jeq r5, 0, lbb_29506                            if r5 == (0 as i32 as i64 as u64) { pc += 11 }
    mov64 r2, r9                                    r2 = r9
    add64 r2, r0                                    r2 += r0   ///  r2 = r2.wrapping_add(r0)
    mov64 r1, 40                                    r1 = 40 as i32 as i64 as u64
    jgt r1, r2, lbb_29500                           if r1 > r2 { pc += 1 }
    ja lbb_29614                                    if true { pc += 114 }
lbb_29500:
    lsh64 r2, 2                                     r2 <<= 2   ///  r2 = r2.wrapping_shl(2)
    mov64 r3, r10                                   r3 = r10
    add64 r3, -160                                  r3 += -160   ///  r3 = r3.wrapping_add(-160 as i32 as i64 as u64)
    add64 r3, r2                                    r3 += r2   ///  r3 = r3.wrapping_add(r2)
    stxw [r3+0x0], r5                       
    ldxdw r2, [r10-0xd8]                    
lbb_29506:
    add64 r2, r9                                    r2 += r9   ///  r2 = r2.wrapping_add(r9)
    ldxdw r1, [r10-0xa8]                    
    jgt r1, r2, lbb_29510                           if r1 > r2 { pc += 1 }
    stxdw [r10-0xa8], r2                    
lbb_29510:
    ldxdw r7, [r10-0xb8]                    
    ldxdw r5, [r10-0xd0]                    
    ja lbb_29454                                    if true { pc += -59 }
lbb_29513:
    lsh64 r0, 2                                     r0 <<= 2   ///  r0 = r0.wrapping_shl(2)
    mov64 r2, r6                                    r2 = r6
    add64 r2, r0                                    r2 += r0   ///  r2 = r2.wrapping_add(r0)
    mov64 r9, 0                                     r9 = 0 as i32 as i64 as u64
    mov64 r5, r8                                    r5 = r8
    lsh64 r5, 2                                     r5 <<= 2   ///  r5 = r5.wrapping_shl(2)
    stxdw [r10-0xc8], r8                    
    add64 r8, 1                                     r8 += 1   ///  r8 = r8.wrapping_add(1 as i32 as i64 as u64)
    stxdw [r10-0xe0], r8                    
    mov64 r0, r6                                    r0 = r6
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    stxdw [r10-0xa8], r1                    
lbb_29525:
    mov64 r3, r9                                    r3 = r9
    lsh64 r3, 2                                     r3 <<= 2   ///  r3 = r3.wrapping_shl(2)
    mov64 r1, r10                                   r1 = r10
    add64 r1, -160                                  r1 += -160   ///  r1 = r1.wrapping_add(-160 as i32 as i64 as u64)
    add64 r1, r3                                    r1 += r3   ///  r1 = r1.wrapping_add(r3)
lbb_29530:
    mov64 r4, r9                                    r4 = r9
    mov64 r3, r1                                    r3 = r1
    jeq r0, r2, lbb_29590                           if r0 == r2 { pc += 57 }
    mov64 r1, r3                                    r1 = r3
    add64 r1, 4                                     r1 += 4   ///  r1 = r1.wrapping_add(4 as i32 as i64 as u64)
    mov64 r9, r4                                    r9 = r4
    add64 r9, 1                                     r9 += 1   ///  r9 = r9.wrapping_add(1 as i32 as i64 as u64)
    ldxw r8, [r0+0x0]                       
    add64 r0, 4                                     r0 += 4   ///  r0 = r0.wrapping_add(4 as i32 as i64 as u64)
    jeq r8, 0, lbb_29530                            if r8 == (0 as i32 as i64 as u64) { pc += -10 }
    stxdw [r10-0xd8], r2                    
    mov64 r1, r4                                    r1 = r4
    mov64 r6, 0                                     r6 = 0 as i32 as i64 as u64
    stxdw [r10-0xd0], r5                    
    stxdw [r10-0xc0], r1                    
    stxdw [r10-0xb8], r7                    
lbb_29546:
    mov64 r2, 40                                    r2 = 40 as i32 as i64 as u64
    jgt r2, r1, lbb_29549                           if r2 > r1 { pc += 1 }
    ja lbb_29611                                    if true { pc += 62 }
lbb_29549:
    ldxw r2, [r7+0x0]                       
    mul64 r2, r8                                    r2 *= r8   ///  r2 = r2.wrapping_mul(r8)
    ldxw r4, [r3+0x0]                       
    add64 r6, r4                                    r6 += r4   ///  r6 = r6.wrapping_add(r4)
    add64 r6, r2                                    r6 += r2   ///  r6 = r6.wrapping_add(r2)
    stxw [r3+0x0], r6                       
    add64 r3, 4                                     r3 += 4   ///  r3 = r3.wrapping_add(4 as i32 as i64 as u64)
    add64 r1, 1                                     r1 += 1   ///  r1 = r1.wrapping_add(1 as i32 as i64 as u64)
    add64 r7, 4                                     r7 += 4   ///  r7 = r7.wrapping_add(4 as i32 as i64 as u64)
    rsh64 r6, 32                                    r6 >>= 32   ///  r6 = r6.wrapping_shr(32)
    add64 r5, -4                                    r5 += -4   ///  r5 = r5.wrapping_add(-4 as i32 as i64 as u64)
    jeq r5, 0, lbb_29562                            if r5 == (0 as i32 as i64 as u64) { pc += 1 }
    ja lbb_29546                                    if true { pc += -16 }
lbb_29562:
    ldxdw r2, [r10-0xc8]                    
    mov64 r1, r2                                    r1 = r2
    ldxdw r7, [r10-0xb8]                    
    ldxdw r5, [r10-0xd0]                    
    jeq r6, 0, lbb_29578                            if r6 == (0 as i32 as i64 as u64) { pc += 11 }
    ldxdw r1, [r10-0xc0]                    
    add64 r1, r2                                    r1 += r2   ///  r1 = r1.wrapping_add(r2)
    mov64 r2, 40                                    r2 = 40 as i32 as i64 as u64
    jgt r2, r1, lbb_29572                           if r2 > r1 { pc += 1 }
    ja lbb_29611                                    if true { pc += 39 }
lbb_29572:
    lsh64 r1, 2                                     r1 <<= 2   ///  r1 = r1.wrapping_shl(2)
    mov64 r3, r10                                   r3 = r10
    add64 r3, -160                                  r3 += -160   ///  r3 = r3.wrapping_add(-160 as i32 as i64 as u64)
    add64 r3, r1                                    r3 += r1   ///  r3 = r3.wrapping_add(r1)
    stxw [r3+0x0], r6                       
    ldxdw r1, [r10-0xe0]                    
lbb_29578:
    ldxdw r2, [r10-0xc0]                    
    add64 r1, r2                                    r1 += r2   ///  r1 = r1.wrapping_add(r2)
    ldxdw r2, [r10-0xa8]                    
    jgt r2, r1, lbb_29583                           if r2 > r1 { pc += 1 }
    stxdw [r10-0xa8], r1                    
lbb_29583:
    ldxdw r2, [r10-0xd8]                    
    ja lbb_29525                                    if true { pc += -60 }
lbb_29585:
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    stxdw [r10-0xa8], r1                    
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
    jeq r7, r5, lbb_29590                           if r7 == r5 { pc += 1 }
    ja lbb_29601                                    if true { pc += 11 }
lbb_29590:
    mov64 r2, r10                                   r2 = r10
    add64 r2, -160                                  r2 += -160   ///  r2 = r2.wrapping_add(-160 as i32 as i64 as u64)
    ldxdw r6, [r10-0xb0]                    
    mov64 r1, r6                                    r1 = r6
    mov64 r3, 160                                   r3 = 160 as i32 as i64 as u64
    call function_30349                     
    ldxdw r1, [r10-0xa8]                    
    stxdw [r6+0xa0], r1                     
    mov64 r0, r6                                    r0 = r6
    exit                                    
lbb_29600:
    jeq r7, r5, lbb_29590                           if r7 == r5 { pc += -11 }
lbb_29601:
    add64 r2, 1                                     r2 += 1   ///  r2 = r2.wrapping_add(1 as i32 as i64 as u64)
    ldxw r3, [r7+0x0]                       
    add64 r7, 4                                     r7 += 4   ///  r7 = r7.wrapping_add(4 as i32 as i64 as u64)
    jeq r3, 0, lbb_29600                            if r3 == (0 as i32 as i64 as u64) { pc += -5 }
    mov64 r3, r2                                    r3 = r2
    add64 r3, -1                                    r3 += -1   ///  r3 = r3.wrapping_add(-1 as i32 as i64 as u64)
    ldxdw r1, [r10-0xa8]                    
    jgt r1, r3, lbb_29600                           if r1 > r3 { pc += -9 }
    stxdw [r10-0xa8], r3                    
    ja lbb_29600                                    if true { pc += -11 }
lbb_29611:
    lddw r3, 0x100042210 --> b"\x00\x00\x00\x00Y\x08\x04\x00\x1e\x00\x00\x00\x00\x00\x00\x00\xac\x01\x00…        r3 load str located at 4295238160
    call function_25832                     
lbb_29614:
    mov64 r1, r2                                    r1 = r2
    mov64 r2, 40                                    r2 = 40 as i32 as i64 as u64
    lddw r3, 0x100042210 --> b"\x00\x00\x00\x00Y\x08\x04\x00\x1e\x00\x00\x00\x00\x00\x00\x00\xac\x01\x00…        r3 load str located at 4295238160
    call function_25832                     

function_29619:
    mov64 r2, r1                                    r2 = r1
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    stxdw [r10-0x28], r1                    
    lddw r1, 0x100042228 --> b"\x00\x00\x00\x00\xc9\x08\x04\x00\x19\x00\x00\x00\x00\x00\x00\x00\x00\x00\…        r1 load str located at 4295238184
    stxdw [r10-0x30], r1                    
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    stxdw [r10-0x10], r1                    
    stxdw [r10-0x18], r1                    
    mov64 r1, 8                                     r1 = 8 as i32 as i64 as u64
    stxdw [r10-0x20], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -48                                   r1 += -48   ///  r1 = r1.wrapping_add(-48 as i32 as i64 as u64)
    call function_25805                     

function_29633:
    mov64 r2, r1                                    r2 = r1
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    stxdw [r10-0x28], r1                    
    lddw r1, 0x100042238 --> b"\x00\x00\x00\x00\xe2\x08\x04\x009\x00\x00\x00\x00\x00\x00\x00\x1e\x00\x00…        r1 load str located at 4295238200
    stxdw [r10-0x30], r1                    
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    stxdw [r10-0x10], r1                    
    stxdw [r10-0x18], r1                    
    mov64 r1, 8                                     r1 = 8 as i32 as i64 as u64
    stxdw [r10-0x20], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -48                                   r1 += -48   ///  r1 = r1.wrapping_add(-48 as i32 as i64 as u64)
    call function_25805                     
    mov64 r5, r2                                    r5 = r2
    ldxdw r2, [r1+0x0]                      
    ldxw r3, [r5+0x34]                      
    and64 r3, 1                                     r3 &= 1   ///  r3 = r3.and(1)
    ldxdw r1, [r5+0x10]                     
    jeq r1, 0, lbb_29657                            if r1 == (0 as i32 as i64 as u64) { pc += 4 }
    ldxdw r4, [r5+0x18]                     
    mov64 r1, r5                                    r1 = r5
    call function_26489                     
    ja lbb_29660                                    if true { pc += 3 }
lbb_29657:
    mov64 r1, r5                                    r1 = r5
    mov64 r4, 0                                     r4 = 0 as i32 as i64 as u64
    call function_26704                     
lbb_29660:
    exit                                    

function_29661:
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
    ldxb r5, [r1+0x0]                       
    mov64 r1, 10                                    r1 = 10 as i32 as i64 as u64
    mov64 r4, 16                                    r4 = 16 as i32 as i64 as u64
    ja lbb_29676                                    if true { pc += 10 }
lbb_29666:
    mov64 r6, r10                                   r6 = r10
    add64 r6, -128                                  r6 += -128   ///  r6 = r6.wrapping_add(-128 as i32 as i64 as u64)
    add64 r6, r3                                    r6 += r3   ///  r6 = r6.wrapping_add(r3)
    stxb [r6+0x7f], r0                      
    add64 r3, -1                                    r3 += -1   ///  r3 = r3.wrapping_add(-1 as i32 as i64 as u64)
    mov64 r0, r5                                    r0 = r5
    and64 r0, 255                                   r0 &= 255   ///  r0 = r0.and(255)
    mov64 r5, r0                                    r5 = r0
    rsh64 r5, 4                                     r5 >>= 4   ///  r5 = r5.wrapping_shr(4)
    jgt r4, r0, lbb_29684                           if r4 > r0 { pc += 8 }
lbb_29676:
    mov64 r6, r5                                    r6 = r5
    and64 r6, 15                                    r6 &= 15   ///  r6 = r6.and(15)
    mov64 r0, r6                                    r0 = r6
    or64 r0, 48                                     r0 |= 48   ///  r0 = r0.or(48)
    jgt r1, r6, lbb_29666                           if r1 > r6 { pc += -15 }
    add64 r6, 87                                    r6 += 87   ///  r6 = r6.wrapping_add(87 as i32 as i64 as u64)
    mov64 r0, r6                                    r0 = r6
    ja lbb_29666                                    if true { pc += -18 }
lbb_29684:
    mov64 r1, r3                                    r1 = r3
    add64 r1, 128                                   r1 += 128   ///  r1 = r1.wrapping_add(128 as i32 as i64 as u64)
    mov64 r4, 129                                   r4 = 129 as i32 as i64 as u64
    jgt r4, r1, lbb_29692                           if r4 > r1 { pc += 4 }
    mov64 r2, 128                                   r2 = 128 as i32 as i64 as u64
    lddw r3, 0x100041fd0 --> b"\x00\x00\x00\x00:\xff\x03\x00\x1b\x00\x00\x00\x00\x00\x00\x00i\x00\x00\x0…        r3 load str located at 4295237584
    call function_28325                     
lbb_29692:
    mov64 r1, r3                                    r1 = r3
    neg64 r1                                        r1 = -r1   ///  r1 = (r1 as i64).wrapping_neg() as u64
    stxdw [r10-0xff8], r1                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -128                                  r1 += -128   ///  r1 = r1.wrapping_add(-128 as i32 as i64 as u64)
    add64 r1, r3                                    r1 += r3   ///  r1 = r1.wrapping_add(r3)
    add64 r1, 128                                   r1 += 128   ///  r1 = r1.wrapping_add(128 as i32 as i64 as u64)
    stxdw [r10-0x1000], r1                  
    mov64 r5, r10                                   r5 = r10
    mov64 r1, r2                                    r1 = r2
    mov64 r2, 1                                     r2 = 1 as i32 as i64 as u64
    lddw r3, 0x10003ff55 --> b"0x"                  r3 load str located at 4295229269
    mov64 r4, 2                                     r4 = 2 as i32 as i64 as u64
    call function_27031                     
    exit                                    

function_29708:
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
    ldxb r5, [r1+0x0]                       
    mov64 r1, 10                                    r1 = 10 as i32 as i64 as u64
    mov64 r4, 16                                    r4 = 16 as i32 as i64 as u64
    ja lbb_29723                                    if true { pc += 10 }
lbb_29713:
    mov64 r6, r10                                   r6 = r10
    add64 r6, -128                                  r6 += -128   ///  r6 = r6.wrapping_add(-128 as i32 as i64 as u64)
    add64 r6, r3                                    r6 += r3   ///  r6 = r6.wrapping_add(r3)
    stxb [r6+0x7f], r0                      
    add64 r3, -1                                    r3 += -1   ///  r3 = r3.wrapping_add(-1 as i32 as i64 as u64)
    mov64 r0, r5                                    r0 = r5
    and64 r0, 255                                   r0 &= 255   ///  r0 = r0.and(255)
    mov64 r5, r0                                    r5 = r0
    rsh64 r5, 4                                     r5 >>= 4   ///  r5 = r5.wrapping_shr(4)
    jgt r4, r0, lbb_29731                           if r4 > r0 { pc += 8 }
lbb_29723:
    mov64 r6, r5                                    r6 = r5
    and64 r6, 15                                    r6 &= 15   ///  r6 = r6.and(15)
    mov64 r0, r6                                    r0 = r6
    or64 r0, 48                                     r0 |= 48   ///  r0 = r0.or(48)
    jgt r1, r6, lbb_29713                           if r1 > r6 { pc += -15 }
    add64 r6, 55                                    r6 += 55   ///  r6 = r6.wrapping_add(55 as i32 as i64 as u64)
    mov64 r0, r6                                    r0 = r6
    ja lbb_29713                                    if true { pc += -18 }
lbb_29731:
    mov64 r1, r3                                    r1 = r3
    add64 r1, 128                                   r1 += 128   ///  r1 = r1.wrapping_add(128 as i32 as i64 as u64)
    mov64 r4, 129                                   r4 = 129 as i32 as i64 as u64
    jgt r4, r1, lbb_29739                           if r4 > r1 { pc += 4 }
    mov64 r2, 128                                   r2 = 128 as i32 as i64 as u64
    lddw r3, 0x100041fd0 --> b"\x00\x00\x00\x00:\xff\x03\x00\x1b\x00\x00\x00\x00\x00\x00\x00i\x00\x00\x0…        r3 load str located at 4295237584
    call function_28325                     
lbb_29739:
    mov64 r1, r3                                    r1 = r3
    neg64 r1                                        r1 = -r1   ///  r1 = (r1 as i64).wrapping_neg() as u64
    stxdw [r10-0xff8], r1                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -128                                  r1 += -128   ///  r1 = r1.wrapping_add(-128 as i32 as i64 as u64)
    add64 r1, r3                                    r1 += r3   ///  r1 = r1.wrapping_add(r3)
    add64 r1, 128                                   r1 += 128   ///  r1 = r1.wrapping_add(128 as i32 as i64 as u64)
    stxdw [r10-0x1000], r1                  
    mov64 r5, r10                                   r5 = r10
    mov64 r1, r2                                    r1 = r2
    mov64 r2, 1                                     r2 = 1 as i32 as i64 as u64
    lddw r3, 0x10003ff55 --> b"0x"                  r3 load str located at 4295229269
    mov64 r4, 2                                     r4 = 2 as i32 as i64 as u64
    call function_27031                     
    exit                                    

function_29755:
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
    ldxw r5, [r1+0x0]                       
    mov64 r1, 10                                    r1 = 10 as i32 as i64 as u64
    mov64 r4, 16                                    r4 = 16 as i32 as i64 as u64
    ja lbb_29771                                    if true { pc += 11 }
lbb_29760:
    mov64 r6, r10                                   r6 = r10
    add64 r6, -128                                  r6 += -128   ///  r6 = r6.wrapping_add(-128 as i32 as i64 as u64)
    add64 r6, r3                                    r6 += r3   ///  r6 = r6.wrapping_add(r3)
    stxb [r6+0x7f], r0                      
    add64 r3, -1                                    r3 += -1   ///  r3 = r3.wrapping_add(-1 as i32 as i64 as u64)
    lsh64 r5, 32                                    r5 <<= 32   ///  r5 = r5.wrapping_shl(32)
    mov64 r0, r5                                    r0 = r5
    rsh64 r0, 32                                    r0 >>= 32   ///  r0 = r0.wrapping_shr(32)
    mov64 r5, r0                                    r5 = r0
    rsh64 r5, 4                                     r5 >>= 4   ///  r5 = r5.wrapping_shr(4)
    jgt r4, r0, lbb_29779                           if r4 > r0 { pc += 8 }
lbb_29771:
    mov64 r6, r5                                    r6 = r5
    and64 r6, 15                                    r6 &= 15   ///  r6 = r6.and(15)
    mov64 r0, r6                                    r0 = r6
    or64 r0, 48                                     r0 |= 48   ///  r0 = r0.or(48)
    jgt r1, r6, lbb_29760                           if r1 > r6 { pc += -16 }
    add64 r6, 87                                    r6 += 87   ///  r6 = r6.wrapping_add(87 as i32 as i64 as u64)
    mov64 r0, r6                                    r0 = r6
    ja lbb_29760                                    if true { pc += -19 }
lbb_29779:
    mov64 r1, r3                                    r1 = r3
    add64 r1, 128                                   r1 += 128   ///  r1 = r1.wrapping_add(128 as i32 as i64 as u64)
    mov64 r4, 129                                   r4 = 129 as i32 as i64 as u64
    jgt r4, r1, lbb_29787                           if r4 > r1 { pc += 4 }
    mov64 r2, 128                                   r2 = 128 as i32 as i64 as u64
    lddw r3, 0x100041fd0 --> b"\x00\x00\x00\x00:\xff\x03\x00\x1b\x00\x00\x00\x00\x00\x00\x00i\x00\x00\x0…        r3 load str located at 4295237584
    call function_28325                     
lbb_29787:
    mov64 r1, r3                                    r1 = r3
    neg64 r1                                        r1 = -r1   ///  r1 = (r1 as i64).wrapping_neg() as u64
    stxdw [r10-0xff8], r1                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -128                                  r1 += -128   ///  r1 = r1.wrapping_add(-128 as i32 as i64 as u64)
    add64 r1, r3                                    r1 += r3   ///  r1 = r1.wrapping_add(r3)
    add64 r1, 128                                   r1 += 128   ///  r1 = r1.wrapping_add(128 as i32 as i64 as u64)
    stxdw [r10-0x1000], r1                  
    mov64 r5, r10                                   r5 = r10
    mov64 r1, r2                                    r1 = r2
    mov64 r2, 1                                     r2 = 1 as i32 as i64 as u64
    lddw r3, 0x10003ff55 --> b"0x"                  r3 load str located at 4295229269
    mov64 r4, 2                                     r4 = 2 as i32 as i64 as u64
    call function_27031                     
    exit                                    

function_29803:
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
    ldxw r5, [r1+0x0]                       
    mov64 r1, 10                                    r1 = 10 as i32 as i64 as u64
    mov64 r4, 16                                    r4 = 16 as i32 as i64 as u64
    ja lbb_29819                                    if true { pc += 11 }
lbb_29808:
    mov64 r6, r10                                   r6 = r10
    add64 r6, -128                                  r6 += -128   ///  r6 = r6.wrapping_add(-128 as i32 as i64 as u64)
    add64 r6, r3                                    r6 += r3   ///  r6 = r6.wrapping_add(r3)
    stxb [r6+0x7f], r0                      
    add64 r3, -1                                    r3 += -1   ///  r3 = r3.wrapping_add(-1 as i32 as i64 as u64)
    lsh64 r5, 32                                    r5 <<= 32   ///  r5 = r5.wrapping_shl(32)
    mov64 r0, r5                                    r0 = r5
    rsh64 r0, 32                                    r0 >>= 32   ///  r0 = r0.wrapping_shr(32)
    mov64 r5, r0                                    r5 = r0
    rsh64 r5, 4                                     r5 >>= 4   ///  r5 = r5.wrapping_shr(4)
    jgt r4, r0, lbb_29827                           if r4 > r0 { pc += 8 }
lbb_29819:
    mov64 r6, r5                                    r6 = r5
    and64 r6, 15                                    r6 &= 15   ///  r6 = r6.and(15)
    mov64 r0, r6                                    r0 = r6
    or64 r0, 48                                     r0 |= 48   ///  r0 = r0.or(48)
    jgt r1, r6, lbb_29808                           if r1 > r6 { pc += -16 }
    add64 r6, 55                                    r6 += 55   ///  r6 = r6.wrapping_add(55 as i32 as i64 as u64)
    mov64 r0, r6                                    r0 = r6
    ja lbb_29808                                    if true { pc += -19 }
lbb_29827:
    mov64 r1, r3                                    r1 = r3
    add64 r1, 128                                   r1 += 128   ///  r1 = r1.wrapping_add(128 as i32 as i64 as u64)
    mov64 r4, 129                                   r4 = 129 as i32 as i64 as u64
    jgt r4, r1, lbb_29835                           if r4 > r1 { pc += 4 }
    mov64 r2, 128                                   r2 = 128 as i32 as i64 as u64
    lddw r3, 0x100041fd0 --> b"\x00\x00\x00\x00:\xff\x03\x00\x1b\x00\x00\x00\x00\x00\x00\x00i\x00\x00\x0…        r3 load str located at 4295237584
    call function_28325                     
lbb_29835:
    mov64 r1, r3                                    r1 = r3
    neg64 r1                                        r1 = -r1   ///  r1 = (r1 as i64).wrapping_neg() as u64
    stxdw [r10-0xff8], r1                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -128                                  r1 += -128   ///  r1 = r1.wrapping_add(-128 as i32 as i64 as u64)
    add64 r1, r3                                    r1 += r3   ///  r1 = r1.wrapping_add(r3)
    add64 r1, 128                                   r1 += 128   ///  r1 = r1.wrapping_add(128 as i32 as i64 as u64)
    stxdw [r10-0x1000], r1                  
    mov64 r5, r10                                   r5 = r10
    mov64 r1, r2                                    r1 = r2
    mov64 r2, 1                                     r2 = 1 as i32 as i64 as u64
    lddw r3, 0x10003ff55 --> b"0x"                  r3 load str located at 4295229269
    mov64 r4, 2                                     r4 = 2 as i32 as i64 as u64
    call function_27031                     
    exit                                    

function_29851:
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
    ldxdw r0, [r1+0x0]                      
    mov64 r1, 10                                    r1 = 10 as i32 as i64 as u64
    mov64 r4, 16                                    r4 = 16 as i32 as i64 as u64
    ja lbb_29864                                    if true { pc += 8 }
lbb_29856:
    mov64 r6, r10                                   r6 = r10
    add64 r6, -128                                  r6 += -128   ///  r6 = r6.wrapping_add(-128 as i32 as i64 as u64)
    add64 r6, r3                                    r6 += r3   ///  r6 = r6.wrapping_add(r3)
    stxb [r6+0x7f], r0                      
    add64 r3, -1                                    r3 += -1   ///  r3 = r3.wrapping_add(-1 as i32 as i64 as u64)
    mov64 r0, r5                                    r0 = r5
    rsh64 r0, 4                                     r0 >>= 4   ///  r0 = r0.wrapping_shr(4)
    jgt r4, r5, lbb_29873                           if r4 > r5 { pc += 9 }
lbb_29864:
    mov64 r5, r0                                    r5 = r0
    mov64 r6, r5                                    r6 = r5
    and64 r6, 15                                    r6 &= 15   ///  r6 = r6.and(15)
    mov64 r0, r6                                    r0 = r6
    or64 r0, 48                                     r0 |= 48   ///  r0 = r0.or(48)
    jgt r1, r6, lbb_29856                           if r1 > r6 { pc += -14 }
    add64 r6, 87                                    r6 += 87   ///  r6 = r6.wrapping_add(87 as i32 as i64 as u64)
    mov64 r0, r6                                    r0 = r6
    ja lbb_29856                                    if true { pc += -17 }
lbb_29873:
    mov64 r1, r3                                    r1 = r3
    add64 r1, 128                                   r1 += 128   ///  r1 = r1.wrapping_add(128 as i32 as i64 as u64)
    mov64 r4, 129                                   r4 = 129 as i32 as i64 as u64
    jgt r4, r1, lbb_29881                           if r4 > r1 { pc += 4 }
    mov64 r2, 128                                   r2 = 128 as i32 as i64 as u64
    lddw r3, 0x100041fd0 --> b"\x00\x00\x00\x00:\xff\x03\x00\x1b\x00\x00\x00\x00\x00\x00\x00i\x00\x00\x0…        r3 load str located at 4295237584
    call function_28325                     
lbb_29881:
    mov64 r1, r3                                    r1 = r3
    neg64 r1                                        r1 = -r1   ///  r1 = (r1 as i64).wrapping_neg() as u64
    stxdw [r10-0xff8], r1                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -128                                  r1 += -128   ///  r1 = r1.wrapping_add(-128 as i32 as i64 as u64)
    add64 r1, r3                                    r1 += r3   ///  r1 = r1.wrapping_add(r3)
    add64 r1, 128                                   r1 += 128   ///  r1 = r1.wrapping_add(128 as i32 as i64 as u64)
    stxdw [r10-0x1000], r1                  
    mov64 r5, r10                                   r5 = r10
    mov64 r1, r2                                    r1 = r2
    mov64 r2, 1                                     r2 = 1 as i32 as i64 as u64
    lddw r3, 0x10003ff55 --> b"0x"                  r3 load str located at 4295229269
    mov64 r4, 2                                     r4 = 2 as i32 as i64 as u64
    call function_27031                     
    exit                                    

function_29897:
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
    ldxdw r0, [r1+0x0]                      
    mov64 r1, 10                                    r1 = 10 as i32 as i64 as u64
    mov64 r4, 16                                    r4 = 16 as i32 as i64 as u64
    ja lbb_29910                                    if true { pc += 8 }
lbb_29902:
    mov64 r6, r10                                   r6 = r10
    add64 r6, -128                                  r6 += -128   ///  r6 = r6.wrapping_add(-128 as i32 as i64 as u64)
    add64 r6, r3                                    r6 += r3   ///  r6 = r6.wrapping_add(r3)
    stxb [r6+0x7f], r0                      
    add64 r3, -1                                    r3 += -1   ///  r3 = r3.wrapping_add(-1 as i32 as i64 as u64)
    mov64 r0, r5                                    r0 = r5
    rsh64 r0, 4                                     r0 >>= 4   ///  r0 = r0.wrapping_shr(4)
    jgt r4, r5, lbb_29919                           if r4 > r5 { pc += 9 }
lbb_29910:
    mov64 r5, r0                                    r5 = r0
    mov64 r6, r5                                    r6 = r5
    and64 r6, 15                                    r6 &= 15   ///  r6 = r6.and(15)
    mov64 r0, r6                                    r0 = r6
    or64 r0, 48                                     r0 |= 48   ///  r0 = r0.or(48)
    jgt r1, r6, lbb_29902                           if r1 > r6 { pc += -14 }
    add64 r6, 55                                    r6 += 55   ///  r6 = r6.wrapping_add(55 as i32 as i64 as u64)
    mov64 r0, r6                                    r0 = r6
    ja lbb_29902                                    if true { pc += -17 }
lbb_29919:
    mov64 r1, r3                                    r1 = r3
    add64 r1, 128                                   r1 += 128   ///  r1 = r1.wrapping_add(128 as i32 as i64 as u64)
    mov64 r4, 129                                   r4 = 129 as i32 as i64 as u64
    jgt r4, r1, lbb_29927                           if r4 > r1 { pc += 4 }
    mov64 r2, 128                                   r2 = 128 as i32 as i64 as u64
    lddw r3, 0x100041fd0 --> b"\x00\x00\x00\x00:\xff\x03\x00\x1b\x00\x00\x00\x00\x00\x00\x00i\x00\x00\x0…        r3 load str located at 4295237584
    call function_28325                     
lbb_29927:
    mov64 r1, r3                                    r1 = r3
    neg64 r1                                        r1 = -r1   ///  r1 = (r1 as i64).wrapping_neg() as u64
    stxdw [r10-0xff8], r1                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -128                                  r1 += -128   ///  r1 = r1.wrapping_add(-128 as i32 as i64 as u64)
    add64 r1, r3                                    r1 += r3   ///  r1 = r1.wrapping_add(r3)
    add64 r1, 128                                   r1 += 128   ///  r1 = r1.wrapping_add(128 as i32 as i64 as u64)
    stxdw [r10-0x1000], r1                  
    mov64 r5, r10                                   r5 = r10
    mov64 r1, r2                                    r1 = r2
    mov64 r2, 1                                     r2 = 1 as i32 as i64 as u64
    lddw r3, 0x10003ff55 --> b"0x"                  r3 load str located at 4295229269
    mov64 r4, 2                                     r4 = 2 as i32 as i64 as u64
    call function_27031                     
    exit                                    

function_29943:
    mov64 r3, r2                                    r3 = r2
    ldxw r2, [r3+0x34]                      
    mov64 r4, r2                                    r4 = r2
    and64 r4, 16                                    r4 &= 16   ///  r4 = r4.and(16)
    jne r4, 0, lbb_29954                            if r4 != (0 as i32 as i64 as u64) { pc += 6 }
    and64 r2, 32                                    r2 &= 32   ///  r2 = r2.and(32)
    jeq r2, 0, lbb_29951                            if r2 == (0 as i32 as i64 as u64) { pc += 1 }
    ja lbb_29975                                    if true { pc += 24 }
lbb_29951:
    mov64 r2, 1                                     r2 = 1 as i32 as i64 as u64
    call function_30110                     
    ja lbb_30024                                    if true { pc += 70 }
lbb_29954:
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
    mov64 r4, 10                                    r4 = 10 as i32 as i64 as u64
    mov64 r5, 16                                    r5 = 16 as i32 as i64 as u64
    ja lbb_29966                                    if true { pc += 8 }
lbb_29958:
    mov64 r6, r10                                   r6 = r10
    add64 r6, -128                                  r6 += -128   ///  r6 = r6.wrapping_add(-128 as i32 as i64 as u64)
    add64 r6, r2                                    r6 += r2   ///  r6 = r6.wrapping_add(r2)
    stxb [r6+0x7f], r1                      
    add64 r2, -1                                    r2 += -1   ///  r2 = r2.wrapping_add(-1 as i32 as i64 as u64)
    mov64 r1, r0                                    r1 = r0
    rsh64 r1, 4                                     r1 >>= 4   ///  r1 = r1.wrapping_shr(4)
    jgt r5, r0, lbb_30001                           if r5 > r0 { pc += 35 }
lbb_29966:
    mov64 r0, r1                                    r0 = r1
    mov64 r6, r0                                    r6 = r0
    and64 r6, 15                                    r6 &= 15   ///  r6 = r6.and(15)
    mov64 r1, r6                                    r1 = r6
    or64 r1, 48                                     r1 |= 48   ///  r1 = r1.or(48)
    jgt r4, r6, lbb_29958                           if r4 > r6 { pc += -14 }
    add64 r6, 87                                    r6 += 87   ///  r6 = r6.wrapping_add(87 as i32 as i64 as u64)
    mov64 r1, r6                                    r1 = r6
    ja lbb_29958                                    if true { pc += -17 }
lbb_29975:
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
    mov64 r4, 10                                    r4 = 10 as i32 as i64 as u64
    mov64 r5, 16                                    r5 = 16 as i32 as i64 as u64
    ja lbb_29987                                    if true { pc += 8 }
lbb_29979:
    mov64 r6, r10                                   r6 = r10
    add64 r6, -128                                  r6 += -128   ///  r6 = r6.wrapping_add(-128 as i32 as i64 as u64)
    add64 r6, r2                                    r6 += r2   ///  r6 = r6.wrapping_add(r2)
    stxb [r6+0x7f], r1                      
    add64 r2, -1                                    r2 += -1   ///  r2 = r2.wrapping_add(-1 as i32 as i64 as u64)
    mov64 r1, r0                                    r1 = r0
    rsh64 r1, 4                                     r1 >>= 4   ///  r1 = r1.wrapping_shr(4)
    jgt r5, r0, lbb_29996                           if r5 > r0 { pc += 9 }
lbb_29987:
    mov64 r0, r1                                    r0 = r1
    mov64 r6, r0                                    r6 = r0
    and64 r6, 15                                    r6 &= 15   ///  r6 = r6.and(15)
    mov64 r1, r6                                    r1 = r6
    or64 r1, 48                                     r1 |= 48   ///  r1 = r1.or(48)
    jgt r4, r6, lbb_29979                           if r4 > r6 { pc += -14 }
    add64 r6, 55                                    r6 += 55   ///  r6 = r6.wrapping_add(55 as i32 as i64 as u64)
    mov64 r1, r6                                    r1 = r6
    ja lbb_29979                                    if true { pc += -17 }
lbb_29996:
    mov64 r1, r2                                    r1 = r2
    add64 r1, 128                                   r1 += 128   ///  r1 = r1.wrapping_add(128 as i32 as i64 as u64)
    mov64 r4, 129                                   r4 = 129 as i32 as i64 as u64
    jgt r4, r1, lbb_30009                           if r4 > r1 { pc += 9 }
    ja lbb_30005                                    if true { pc += 4 }
lbb_30001:
    mov64 r1, r2                                    r1 = r2
    add64 r1, 128                                   r1 += 128   ///  r1 = r1.wrapping_add(128 as i32 as i64 as u64)
    mov64 r4, 129                                   r4 = 129 as i32 as i64 as u64
    jgt r4, r1, lbb_30009                           if r4 > r1 { pc += 4 }
lbb_30005:
    mov64 r2, 128                                   r2 = 128 as i32 as i64 as u64
    lddw r3, 0x100041fd0 --> b"\x00\x00\x00\x00:\xff\x03\x00\x1b\x00\x00\x00\x00\x00\x00\x00i\x00\x00\x0…        r3 load str located at 4295237584
    call function_28325                     
lbb_30009:
    mov64 r1, r2                                    r1 = r2
    neg64 r1                                        r1 = -r1   ///  r1 = (r1 as i64).wrapping_neg() as u64
    stxdw [r10-0xff8], r1                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -128                                  r1 += -128   ///  r1 = r1.wrapping_add(-128 as i32 as i64 as u64)
    add64 r1, r2                                    r1 += r2   ///  r1 = r1.wrapping_add(r2)
    add64 r1, 128                                   r1 += 128   ///  r1 = r1.wrapping_add(128 as i32 as i64 as u64)
    stxdw [r10-0x1000], r1                  
    mov64 r5, r10                                   r5 = r10
    mov64 r1, r3                                    r1 = r3
    mov64 r2, 1                                     r2 = 1 as i32 as i64 as u64
    lddw r3, 0x10003ff55 --> b"0x"                  r3 load str located at 4295229269
    mov64 r4, 2                                     r4 = 2 as i32 as i64 as u64
    call function_27031                     
lbb_30024:
    exit                                    

function_30025:
    mov64 r3, r2                                    r3 = r2
    ldxw r2, [r3+0x34]                      
    mov64 r4, r2                                    r4 = r2
    and64 r4, 16                                    r4 &= 16   ///  r4 = r4.and(16)
    jne r4, 0, lbb_30037                            if r4 != (0 as i32 as i64 as u64) { pc += 7 }
    and64 r2, 32                                    r2 &= 32   ///  r2 = r2.and(32)
    jeq r2, 0, lbb_30033                            if r2 == (0 as i32 as i64 as u64) { pc += 1 }
    ja lbb_30059                                    if true { pc += 26 }
lbb_30033:
    ldxdw r1, [r1+0x0]                      
    mov64 r2, 1                                     r2 = 1 as i32 as i64 as u64
    call function_30110                     
    ja lbb_30109                                    if true { pc += 72 }
lbb_30037:
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
    ldxdw r0, [r1+0x0]                      
    mov64 r1, 10                                    r1 = 10 as i32 as i64 as u64
    mov64 r4, 16                                    r4 = 16 as i32 as i64 as u64
    ja lbb_30050                                    if true { pc += 8 }
lbb_30042:
    mov64 r6, r10                                   r6 = r10
    add64 r6, -128                                  r6 += -128   ///  r6 = r6.wrapping_add(-128 as i32 as i64 as u64)
    add64 r6, r2                                    r6 += r2   ///  r6 = r6.wrapping_add(r2)
    stxb [r6+0x7f], r0                      
    add64 r2, -1                                    r2 += -1   ///  r2 = r2.wrapping_add(-1 as i32 as i64 as u64)
    mov64 r0, r5                                    r0 = r5
    rsh64 r0, 4                                     r0 >>= 4   ///  r0 = r0.wrapping_shr(4)
    jgt r4, r5, lbb_30086                           if r4 > r5 { pc += 36 }
lbb_30050:
    mov64 r5, r0                                    r5 = r0
    mov64 r6, r5                                    r6 = r5
    and64 r6, 15                                    r6 &= 15   ///  r6 = r6.and(15)
    mov64 r0, r6                                    r0 = r6
    or64 r0, 48                                     r0 |= 48   ///  r0 = r0.or(48)
    jgt r1, r6, lbb_30042                           if r1 > r6 { pc += -14 }
    add64 r6, 87                                    r6 += 87   ///  r6 = r6.wrapping_add(87 as i32 as i64 as u64)
    mov64 r0, r6                                    r0 = r6
    ja lbb_30042                                    if true { pc += -17 }
lbb_30059:
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
    ldxdw r0, [r1+0x0]                      
    mov64 r1, 10                                    r1 = 10 as i32 as i64 as u64
    mov64 r4, 16                                    r4 = 16 as i32 as i64 as u64
    ja lbb_30072                                    if true { pc += 8 }
lbb_30064:
    mov64 r6, r10                                   r6 = r10
    add64 r6, -128                                  r6 += -128   ///  r6 = r6.wrapping_add(-128 as i32 as i64 as u64)
    add64 r6, r2                                    r6 += r2   ///  r6 = r6.wrapping_add(r2)
    stxb [r6+0x7f], r0                      
    add64 r2, -1                                    r2 += -1   ///  r2 = r2.wrapping_add(-1 as i32 as i64 as u64)
    mov64 r0, r5                                    r0 = r5
    rsh64 r0, 4                                     r0 >>= 4   ///  r0 = r0.wrapping_shr(4)
    jgt r4, r5, lbb_30081                           if r4 > r5 { pc += 9 }
lbb_30072:
    mov64 r5, r0                                    r5 = r0
    mov64 r6, r5                                    r6 = r5
    and64 r6, 15                                    r6 &= 15   ///  r6 = r6.and(15)
    mov64 r0, r6                                    r0 = r6
    or64 r0, 48                                     r0 |= 48   ///  r0 = r0.or(48)
    jgt r1, r6, lbb_30064                           if r1 > r6 { pc += -14 }
    add64 r6, 55                                    r6 += 55   ///  r6 = r6.wrapping_add(55 as i32 as i64 as u64)
    mov64 r0, r6                                    r0 = r6
    ja lbb_30064                                    if true { pc += -17 }
lbb_30081:
    mov64 r1, r2                                    r1 = r2
    add64 r1, 128                                   r1 += 128   ///  r1 = r1.wrapping_add(128 as i32 as i64 as u64)
    mov64 r4, 129                                   r4 = 129 as i32 as i64 as u64
    jgt r4, r1, lbb_30094                           if r4 > r1 { pc += 9 }
    ja lbb_30090                                    if true { pc += 4 }
lbb_30086:
    mov64 r1, r2                                    r1 = r2
    add64 r1, 128                                   r1 += 128   ///  r1 = r1.wrapping_add(128 as i32 as i64 as u64)
    mov64 r4, 129                                   r4 = 129 as i32 as i64 as u64
    jgt r4, r1, lbb_30094                           if r4 > r1 { pc += 4 }
lbb_30090:
    mov64 r2, 128                                   r2 = 128 as i32 as i64 as u64
    lddw r3, 0x100041fd0 --> b"\x00\x00\x00\x00:\xff\x03\x00\x1b\x00\x00\x00\x00\x00\x00\x00i\x00\x00\x0…        r3 load str located at 4295237584
    call function_28325                     
lbb_30094:
    mov64 r1, r2                                    r1 = r2
    neg64 r1                                        r1 = -r1   ///  r1 = (r1 as i64).wrapping_neg() as u64
    stxdw [r10-0xff8], r1                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -128                                  r1 += -128   ///  r1 = r1.wrapping_add(-128 as i32 as i64 as u64)
    add64 r1, r2                                    r1 += r2   ///  r1 = r1.wrapping_add(r2)
    add64 r1, 128                                   r1 += 128   ///  r1 = r1.wrapping_add(128 as i32 as i64 as u64)
    stxdw [r10-0x1000], r1                  
    mov64 r5, r10                                   r5 = r10
    mov64 r1, r3                                    r1 = r3
    mov64 r2, 1                                     r2 = 1 as i32 as i64 as u64
    lddw r3, 0x10003ff55 --> b"0x"                  r3 load str located at 4295229269
    mov64 r4, 2                                     r4 = 2 as i32 as i64 as u64
    call function_27031                     
lbb_30109:
    exit                                    

function_30110:
    mov64 r4, 39                                    r4 = 39 as i32 as i64 as u64
    mov64 r5, 10000                                 r5 = 10000 as i32 as i64 as u64
    jgt r5, r1, lbb_30145                           if r5 > r1 { pc += 32 }
    mov64 r4, 0                                     r4 = 0 as i32 as i64 as u64
lbb_30114:
    mov64 r5, r1                                    r5 = r1
    div64 r1, 10000                                 r1 /= 10000   ///  r1 = r1 / (10000 as u64)
    mov64 r6, r1                                    r6 = r1
    mul64 r6, 10000                                 r6 *= 10000   ///  r6 = r6.wrapping_mul(10000 as u64)
    mov64 r0, r5                                    r0 = r5
    sub64 r0, r6                                    r0 -= r6   ///  r0 = r0.wrapping_sub(r6)
    mov64 r6, r0                                    r6 = r0
    and64 r6, 65535                                 r6 &= 65535   ///  r6 = r6.and(65535)
    div64 r6, 100                                   r6 /= 100   ///  r6 = r6 / (100 as u64)
    mov64 r7, r6                                    r7 = r6
    mul64 r7, 100                                   r7 *= 100   ///  r7 = r7.wrapping_mul(100 as u64)
    sub64 r0, r7                                    r0 -= r7   ///  r0 = r0.wrapping_sub(r7)
    mov64 r7, r10                                   r7 = r10
    add64 r7, -39                                   r7 += -39   ///  r7 = r7.wrapping_add(-39 as i32 as i64 as u64)
    add64 r7, r4                                    r7 += r4   ///  r7 = r7.wrapping_add(r4)
    lsh64 r6, 1                                     r6 <<= 1   ///  r6 = r6.wrapping_shl(1)
    lddw r8, 0x10003ff57 --> b"00010203040506070809101112131415161718192021222324"        r8 load str located at 4295229271
    add64 r8, r6                                    r8 += r6   ///  r8 = r8.wrapping_add(r6)
    ldxh r6, [r8+0x0]                       
    stxh [r7+0x23], r6                      
    lsh64 r0, 1                                     r0 <<= 1   ///  r0 = r0.wrapping_shl(1)
    and64 r0, 65534                                 r0 &= 65534   ///  r0 = r0.and(65534)
    lddw r6, 0x10003ff57 --> b"00010203040506070809101112131415161718192021222324"        r6 load str located at 4295229271
    add64 r6, r0                                    r6 += r0   ///  r6 = r6.wrapping_add(r0)
    ldxh r0, [r6+0x0]                       
    stxh [r7+0x25], r0                      
    add64 r4, -4                                    r4 += -4   ///  r4 = r4.wrapping_add(-4 as i32 as i64 as u64)
    jgt r5, 99999999, lbb_30114                     if r5 > (99999999 as i32 as i64 as u64) { pc += -30 }
    add64 r4, 39                                    r4 += 39   ///  r4 = r4.wrapping_add(39 as i32 as i64 as u64)
lbb_30145:
    jgt r1, 99, lbb_30147                           if r1 > (99 as i32 as i64 as u64) { pc += 1 }
    ja lbb_30165                                    if true { pc += 18 }
lbb_30147:
    mov64 r5, r1                                    r5 = r1
    and64 r5, 65535                                 r5 &= 65535   ///  r5 = r5.and(65535)
    div64 r5, 100                                   r5 /= 100   ///  r5 = r5 / (100 as u64)
    mov64 r0, r5                                    r0 = r5
    mul64 r0, 100                                   r0 *= 100   ///  r0 = r0.wrapping_mul(100 as u64)
    sub64 r1, r0                                    r1 -= r0   ///  r1 = r1.wrapping_sub(r0)
    lsh64 r1, 1                                     r1 <<= 1   ///  r1 = r1.wrapping_shl(1)
    and64 r1, 65534                                 r1 &= 65534   ///  r1 = r1.and(65534)
    lddw r0, 0x10003ff57 --> b"00010203040506070809101112131415161718192021222324"        r0 load str located at 4295229271
    add64 r0, r1                                    r0 += r1   ///  r0 = r0.wrapping_add(r1)
    add64 r4, -2                                    r4 += -2   ///  r4 = r4.wrapping_add(-2 as i32 as i64 as u64)
    mov64 r1, r10                                   r1 = r10
    add64 r1, -39                                   r1 += -39   ///  r1 = r1.wrapping_add(-39 as i32 as i64 as u64)
    add64 r1, r4                                    r1 += r4   ///  r1 = r1.wrapping_add(r4)
    ldxh r0, [r0+0x0]                       
    stxh [r1+0x0], r0                       
    mov64 r1, r5                                    r1 = r5
lbb_30165:
    mov64 r5, 10                                    r5 = 10 as i32 as i64 as u64
    jgt r5, r1, lbb_30178                           if r5 > r1 { pc += 11 }
    lsh64 r1, 1                                     r1 <<= 1   ///  r1 = r1.wrapping_shl(1)
    lddw r5, 0x10003ff57 --> b"00010203040506070809101112131415161718192021222324"        r5 load str located at 4295229271
    add64 r5, r1                                    r5 += r1   ///  r5 = r5.wrapping_add(r1)
    add64 r4, -2                                    r4 += -2   ///  r4 = r4.wrapping_add(-2 as i32 as i64 as u64)
    mov64 r1, r10                                   r1 = r10
    add64 r1, -39                                   r1 += -39   ///  r1 = r1.wrapping_add(-39 as i32 as i64 as u64)
    add64 r1, r4                                    r1 += r4   ///  r1 = r1.wrapping_add(r4)
    ldxh r5, [r5+0x0]                       
    stxh [r1+0x0], r5                       
    ja lbb_30184                                    if true { pc += 6 }
lbb_30178:
    add64 r4, -1                                    r4 += -1   ///  r4 = r4.wrapping_add(-1 as i32 as i64 as u64)
    mov64 r5, r10                                   r5 = r10
    add64 r5, -39                                   r5 += -39   ///  r5 = r5.wrapping_add(-39 as i32 as i64 as u64)
    add64 r5, r4                                    r5 += r4   ///  r5 = r5.wrapping_add(r4)
    or64 r1, 48                                     r1 |= 48   ///  r1 = r1.or(48)
    stxb [r5+0x0], r1                       
lbb_30184:
    mov64 r1, r10                                   r1 = r10
    add64 r1, -39                                   r1 += -39   ///  r1 = r1.wrapping_add(-39 as i32 as i64 as u64)
    add64 r1, r4                                    r1 += r4   ///  r1 = r1.wrapping_add(r4)
    stxdw [r10-0x1000], r1                  
    mov64 r1, 39                                    r1 = 39 as i32 as i64 as u64
    sub64 r1, r4                                    r1 -= r4   ///  r1 = r1.wrapping_sub(r4)
    stxdw [r10-0xff8], r1                   
    mov64 r5, r10                                   r5 = r10
    mov64 r1, r3                                    r1 = r3
    mov64 r3, 1                                     r3 = 1 as i32 as i64 as u64
    mov64 r4, 0                                     r4 = 0 as i32 as i64 as u64
    call function_27031                     
    exit                                    

function_30197:
    mov64 r3, r2                                    r3 = r2
    ldxb r1, [r1+0x0]                       
    mov64 r2, 1                                     r2 = 1 as i32 as i64 as u64
    call function_30110                     
    exit                                    

function_30202:
    mov64 r3, r2                                    r3 = r2
    ldxw r4, [r1+0x0]                       
    lsh64 r4, 32                                    r4 <<= 32   ///  r4 = r4.wrapping_shl(32)
    arsh64 r4, 32                                   r4 >>= 32 (signed)   ///  r4 = (r4 as i64).wrapping_shr(32)
    jsgt r4, -1, lbb_30210                          if (r4 as i64) > (-1 as i32 as i64) { pc += 3 }
    mov64 r1, r4                                    r1 = r4
    neg64 r1                                        r1 = -r1   ///  r1 = (r1 as i64).wrapping_neg() as u64
    ja lbb_30211                                    if true { pc += 1 }
lbb_30210:
    mov64 r1, r4                                    r1 = r4
lbb_30211:
    mov64 r2, 1                                     r2 = 1 as i32 as i64 as u64
    jsgt r4, -1, lbb_30214                          if (r4 as i64) > (-1 as i32 as i64) { pc += 1 }
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
lbb_30214:
    call function_30110                     
    exit                                    

function_30216:
    mov64 r3, r2                                    r3 = r2
    ldxw r1, [r1+0x0]                       
    mov64 r2, 1                                     r2 = 1 as i32 as i64 as u64
    call function_30110                     
    exit                                    

function_30221:
    mov64 r3, r2                                    r3 = r2
    ldxdw r2, [r1+0x0]                      
    mov64 r4, r2                                    r4 = r2
    arsh64 r4, 63                                   r4 >>= 63 (signed)   ///  r4 = (r4 as i64).wrapping_shr(63)
    mov64 r1, r2                                    r1 = r2
    xor64 r1, r4                                    r1 ^= r4   ///  r1 = r1.xor(r4)
    sub64 r1, r4                                    r1 -= r4   ///  r1 = r1.wrapping_sub(r4)
    xor64 r2, -1                                    r2 ^= -1   ///  r2 = r2.xor(-1)
    rsh64 r2, 63                                    r2 >>= 63   ///  r2 = r2.wrapping_shr(63)
    call function_30110                     
    exit                                    

function_30232:
    mov64 r3, r2                                    r3 = r2
    ldxdw r1, [r1+0x0]                      
    mov64 r2, 1                                     r2 = 1 as i32 as i64 as u64
    call function_30110                     
    exit                                    

function_30237:
    ldxdw r3, [r1+0x0]                      
    ldxdw r1, [r1+0x8]                      
    ldxdw r4, [r1+0x18]                     
    mov64 r1, r3                                    r1 = r3
    callx r4                                
    exit                                    

function_30243:
    ldxdw r1, [r1+0x0]                      
    ldxdw r1, [r1+0x0]                      
    call function_29943                     
    exit                                    

function_30247:
    mov64 r4, r2                                    r4 = r2
    ldxdw r3, [r1+0x8]                      
    ldxdw r2, [r1+0x0]                      
    mov64 r1, r4                                    r1 = r4
    call function_27252                     
    exit                                    

function_30253:
    mov64 r0, 0                                     r0 = 0 as i32 as i64 as u64
    mov64 r3, 33                                    r3 = 33 as i32 as i64 as u64
    mov64 r4, r1                                    r4 = r1
    lsh64 r4, 11                                    r4 <<= 11   ///  r4 = r4.wrapping_shl(11)
    mov64 r5, 33                                    r5 = 33 as i32 as i64 as u64
    ja lbb_30264                                    if true { pc += 5 }
lbb_30259:
    mov64 r5, r3                                    r5 = r3
    sub64 r3, r2                                    r3 -= r2   ///  r3 = r3.wrapping_sub(r2)
    mov64 r0, r2                                    r0 = r2
    jgt r5, r2, lbb_30264                           if r5 > r2 { pc += 1 }
    ja lbb_30288                                    if true { pc += 24 }
lbb_30264:
    rsh64 r3, 1                                     r3 >>= 1   ///  r3 = r3.wrapping_shr(1)
    add64 r3, r0                                    r3 += r0   ///  r3 = r3.wrapping_add(r0)
    mov64 r2, r3                                    r2 = r3
    lsh64 r2, 2                                     r2 <<= 2   ///  r2 = r2.wrapping_shl(2)
    lddw r6, 0x10004091c --> b"\x00\x03\x00\x00\x83\x04 \x00\x91\x05`\x00]\x13\xa0\x00\x12\x17 \x1f\x0c …        r6 load str located at 4295231772
    add64 r6, r2                                    r6 += r2   ///  r6 = r6.wrapping_add(r2)
    ldxw r6, [r6+0x0]                       
    lsh64 r6, 11                                    r6 <<= 11   ///  r6 = r6.wrapping_shl(11)
    lsh64 r6, 32                                    r6 <<= 32   ///  r6 = r6.wrapping_shl(32)
    mov64 r7, r4                                    r7 = r4
    lsh64 r7, 32                                    r7 <<= 32   ///  r7 = r7.wrapping_shl(32)
    rsh64 r6, 32                                    r6 >>= 32   ///  r6 = r6.wrapping_shr(32)
    rsh64 r7, 32                                    r7 >>= 32   ///  r7 = r7.wrapping_shr(32)
    jeq r6, r7, lbb_30286                           if r6 == r7 { pc += 7 }
    mov64 r2, r3                                    r2 = r3
    add64 r2, 1                                     r2 += 1   ///  r2 = r2.wrapping_add(1 as i32 as i64 as u64)
    jgt r7, r6, lbb_30283                           if r7 > r6 { pc += 1 }
    mov64 r2, r0                                    r2 = r0
lbb_30283:
    jgt r6, r7, lbb_30259                           if r6 > r7 { pc += -25 }
    mov64 r3, r5                                    r3 = r5
    ja lbb_30259                                    if true { pc += -27 }
lbb_30286:
    add64 r3, 1                                     r3 += 1   ///  r3 = r3.wrapping_add(1 as i32 as i64 as u64)
    mov64 r2, r3                                    r2 = r3
lbb_30288:
    jgt r2, 32, lbb_30344                           if r2 > (32 as i32 as i64 as u64) { pc += 55 }
    mov64 r3, r2                                    r3 = r2
    lsh64 r3, 2                                     r3 <<= 2   ///  r3 = r3.wrapping_shl(2)
    lddw r4, 0x10004091c --> b"\x00\x03\x00\x00\x83\x04 \x00\x91\x05`\x00]\x13\xa0\x00\x12\x17 \x1f\x0c …        r4 load str located at 4295231772
    add64 r4, r3                                    r4 += r3   ///  r4 = r4.wrapping_add(r3)
    mov64 r3, 727                                   r3 = 727 as i32 as i64 as u64
    ldxw r0, [r4+0x0]                       
    jeq r2, 32, lbb_30301                           if r2 == (32 as i32 as i64 as u64) { pc += 4 }
    add64 r4, 4                                     r4 += 4   ///  r4 = r4.wrapping_add(4 as i32 as i64 as u64)
    jeq r4, 0, lbb_30301                            if r4 == (0 as i32 as i64 as u64) { pc += 2 }
    ldxw r3, [r4+0x0]                       
    rsh64 r3, 21                                    r3 >>= 21   ///  r3 = r3.wrapping_shr(21)
lbb_30301:
    rsh64 r0, 21                                    r0 >>= 21   ///  r0 = r0.wrapping_shr(21)
    mov64 r4, 0                                     r4 = 0 as i32 as i64 as u64
    jne r2, 0, lbb_30332                            if r2 != (0 as i32 as i64 as u64) { pc += 28 }
lbb_30304:
    mov64 r2, r0                                    r2 = r0
    xor64 r2, -1                                    r2 ^= -1   ///  r2 = r2.xor(-1)
    add64 r3, r2                                    r3 += r2   ///  r3 = r3.wrapping_add(r2)
    jeq r3, 0, lbb_30330                            if r3 == (0 as i32 as i64 as u64) { pc += 22 }
    sub64 r1, r4                                    r1 -= r4   ///  r1 = r1.wrapping_sub(r4)
    lddw r5, 0x1000409a0 --> b"\x00p\x00\x07\x00-\x01\x01\x01\x02\x01\x02\x01\x01H\x0b0\x15\x10\x01e\x07…        r5 load str located at 4295231904
    add64 r5, r0                                    r5 += r0   ///  r5 = r5.wrapping_add(r0)
    mov64 r4, 0                                     r4 = 0 as i32 as i64 as u64
    lsh64 r1, 32                                    r1 <<= 32   ///  r1 = r1.wrapping_shl(32)
    rsh64 r1, 32                                    r1 >>= 32   ///  r1 = r1.wrapping_shr(32)
    mov64 r6, 0                                     r6 = 0 as i32 as i64 as u64
lbb_30316:
    mov64 r2, r0                                    r2 = r0
    add64 r2, r4                                    r2 += r4   ///  r2 = r2.wrapping_add(r4)
    jgt r2, 726, lbb_30339                          if r2 > (726 as i32 as i64 as u64) { pc += 20 }
    mov64 r2, r5                                    r2 = r5
    add64 r2, r4                                    r2 += r4   ///  r2 = r2.wrapping_add(r4)
    ldxb r2, [r2+0x0]                       
    add64 r6, r2                                    r6 += r2   ///  r6 = r6.wrapping_add(r2)
    mov64 r2, r6                                    r2 = r6
    lsh64 r2, 32                                    r2 <<= 32   ///  r2 = r2.wrapping_shl(32)
    rsh64 r2, 32                                    r2 >>= 32   ///  r2 = r2.wrapping_shr(32)
    jgt r2, r1, lbb_30329                           if r2 > r1 { pc += 2 }
    add64 r4, 1                                     r4 += 1   ///  r4 = r4.wrapping_add(1 as i32 as i64 as u64)
    jgt r3, r4, lbb_30316                           if r3 > r4 { pc += -13 }
lbb_30329:
    add64 r0, r4                                    r0 += r4   ///  r0 = r0.wrapping_add(r4)
lbb_30330:
    and64 r0, 1                                     r0 &= 1   ///  r0 = r0.and(1)
    exit                                    
lbb_30332:
    lsh64 r2, 2                                     r2 <<= 2   ///  r2 = r2.wrapping_shl(2)
    lddw r4, 0x10004091c --> b"\x00\x03\x00\x00\x83\x04 \x00\x91\x05`\x00]\x13\xa0\x00\x12\x17 \x1f\x0c …        r4 load str located at 4295231772
    add64 r2, r4                                    r2 += r4   ///  r2 = r2.wrapping_add(r4)
    ldxw r4, [r2-0x4]                       
    and64 r4, 2097151                               r4 &= 2097151   ///  r4 = r4.and(2097151)
    ja lbb_30304                                    if true { pc += -35 }
lbb_30339:
    mov64 r1, r2                                    r1 = r2
    mov64 r2, 727                                   r2 = 727 as i32 as i64 as u64
    lddw r3, 0x1000421c8 --> b"\x00\x00\x00\x00\x17\x08\x04\x00(\x00\x00\x00\x00\x00\x00\x00\\x00\x00\x0…        r3 load str located at 4295238088
    call function_25832                     
lbb_30344:
    mov64 r1, r2                                    r1 = r2
    mov64 r2, 33                                    r2 = 33 as i32 as i64 as u64
    lddw r3, 0x1000421b0 --> b"\x00\x00\x00\x00\x17\x08\x04\x00(\x00\x00\x00\x00\x00\x00\x00P\x00\x00\x0…        r3 load str located at 4295238064
    call function_25832                     

function_30349:
    mov64 r6, r1                                    r6 = r1
    mov64 r4, r3                                    r4 = r3
    rsh64 r4, 3                                     r4 >>= 3   ///  r4 = r4.wrapping_shr(3)
    mov64 r1, r4                                    r1 = r4
    mul64 r1, -7                                    r1 *= -7   ///  r1 = r1.wrapping_mul(-7 as u64)
    add64 r1, r3                                    r1 += r3   ///  r1 = r1.wrapping_add(r3)
    jgt r1, 15, lbb_30380                           if r1 > (15 as i32 as i64 as u64) { pc += 24 }
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    mov64 r5, 8                                     r5 = 8 as i32 as i64 as u64
    jgt r5, r3, lbb_30369                           if r5 > r3 { pc += 10 }
    mov64 r5, 0                                     r5 = 0 as i32 as i64 as u64
lbb_30360:
    mov64 r0, r6                                    r0 = r6
    add64 r0, r1                                    r0 += r1   ///  r0 = r0.wrapping_add(r1)
    mov64 r7, r2                                    r7 = r2
    add64 r7, r1                                    r7 += r1   ///  r7 = r7.wrapping_add(r1)
    ldxdw r7, [r7+0x0]                      
    stxdw [r0+0x0], r7                      
    add64 r1, 8                                     r1 += 8   ///  r1 = r1.wrapping_add(8 as i32 as i64 as u64)
    add64 r5, 1                                     r5 += 1   ///  r5 = r5.wrapping_add(1 as i32 as i64 as u64)
    jgt r4, r5, lbb_30360                           if r4 > r5 { pc += -9 }
lbb_30369:
    jsge r1, r3, lbb_30378                          if (r1 as i64) >= (r3 as i64) { pc += 8 }
lbb_30370:
    mov64 r4, r6                                    r4 = r6
    add64 r4, r1                                    r4 += r1   ///  r4 = r4.wrapping_add(r1)
    mov64 r5, r2                                    r5 = r2
    add64 r5, r1                                    r5 += r1   ///  r5 = r5.wrapping_add(r1)
    ldxb r5, [r5+0x0]                       
    stxb [r4+0x0], r5                       
    add64 r1, 1                                     r1 += 1   ///  r1 = r1.wrapping_add(1 as i32 as i64 as u64)
    jsgt r3, r1, lbb_30370                          if (r3 as i64) > (r1 as i64) { pc += -8 }
lbb_30378:
    mov64 r0, r6                                    r0 = r6
    exit                                    
lbb_30380:
    mov64 r1, r6                                    r1 = r6
    syscall [invalid]                       
    ja lbb_30378                                    if true { pc += -5 }

function_30383:
    mov64 r6, r1                                    r6 = r1
    mov64 r4, r3                                    r4 = r3
    rsh64 r4, 3                                     r4 >>= 3   ///  r4 = r4.wrapping_shr(3)
    mov64 r1, r4                                    r1 = r4
    mul64 r1, -7                                    r1 *= -7   ///  r1 = r1.wrapping_mul(-7 as u64)
    add64 r1, r3                                    r1 += r3   ///  r1 = r1.wrapping_add(r3)
    jgt r1, 15, lbb_30413                           if r1 > (15 as i32 as i64 as u64) { pc += 23 }
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    mov64 r5, 8                                     r5 = 8 as i32 as i64 as u64
    jgt r5, r3, lbb_30406                           if r5 > r3 { pc += 13 }
    mov64 r5, r2                                    r5 = r2
    and64 r5, 255                                   r5 &= 255   ///  r5 = r5.and(255)
    lddw r1, 0x101010101010101                      r1 load str located at 72340172838076673
    mul64 r5, r1                                    r5 *= r1   ///  r5 = r5.wrapping_mul(r1)
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    mov64 r0, 0                                     r0 = 0 as i32 as i64 as u64
lbb_30400:
    mov64 r7, r6                                    r7 = r6
    add64 r7, r1                                    r7 += r1   ///  r7 = r7.wrapping_add(r1)
    stxdw [r7+0x0], r5                      
    add64 r1, 8                                     r1 += 8   ///  r1 = r1.wrapping_add(8 as i32 as i64 as u64)
    add64 r0, 1                                     r0 += 1   ///  r0 = r0.wrapping_add(1 as i32 as i64 as u64)
    jgt r4, r0, lbb_30400                           if r4 > r0 { pc += -6 }
lbb_30406:
    jsge r1, r3, lbb_30416                          if (r1 as i64) >= (r3 as i64) { pc += 9 }
lbb_30407:
    mov64 r4, r6                                    r4 = r6
    add64 r4, r1                                    r4 += r1   ///  r4 = r4.wrapping_add(r1)
    stxb [r4+0x0], r2                       
    add64 r1, 1                                     r1 += 1   ///  r1 = r1.wrapping_add(1 as i32 as i64 as u64)
    jsgt r3, r1, lbb_30407                          if (r3 as i64) > (r1 as i64) { pc += -5 }
    ja lbb_30416                                    if true { pc += 3 }
lbb_30413:
    and64 r2, 255                                   r2 &= 255   ///  r2 = r2.and(255)
    mov64 r1, r6                                    r1 = r6
    syscall [invalid]                       
lbb_30416:
    mov64 r0, r6                                    r0 = r6
    exit                                    

function_30418:
    mov64 r8, r2                                    r8 = r2
    mov64 r2, r3                                    r2 = r3
    rsh64 r2, 3                                     r2 >>= 3   ///  r2 = r2.wrapping_shr(3)
    mov64 r5, r2                                    r5 = r2
    mul64 r5, -7                                    r5 *= -7   ///  r5 = r5.wrapping_mul(-7 as u64)
    add64 r5, r3                                    r5 += r3   ///  r5 = r5.wrapping_add(r3)
    jgt r5, 15, lbb_30462                           if r5 > (15 as i32 as i64 as u64) { pc += 37 }
    mov64 r0, 0                                     r0 = 0 as i32 as i64 as u64
    mov64 r6, 8                                     r6 = 8 as i32 as i64 as u64
    mov64 r5, 0                                     r5 = 0 as i32 as i64 as u64
    jgt r6, r3, lbb_30448                           if r6 > r3 { pc += 19 }
    mov64 r6, 0                                     r6 = 0 as i32 as i64 as u64
    stxdw [r10-0x18], r1                    
    mov64 r7, r1                                    r7 = r1
    stxdw [r10-0x10], r8                    
    ja lbb_30440                                    if true { pc += 6 }
lbb_30434:
    add64 r7, 8                                     r7 += 8   ///  r7 = r7.wrapping_add(8 as i32 as i64 as u64)
    add64 r8, 8                                     r8 += 8   ///  r8 = r8.wrapping_add(8 as i32 as i64 as u64)
    add64 r6, 1                                     r6 += 1   ///  r6 = r6.wrapping_add(1 as i32 as i64 as u64)
    mov64 r5, r2                                    r5 = r2
    jgt r2, r6, lbb_30440                           if r2 > r6 { pc += 1 }
    ja lbb_30444                                    if true { pc += 4 }
lbb_30440:
    ldxdw r9, [r8+0x0]                      
    ldxdw r4, [r7+0x0]                      
    mov64 r5, r6                                    r5 = r6
    jeq r4, r9, lbb_30434                           if r4 == r9 { pc += -10 }
lbb_30444:
    lsh64 r5, 3                                     r5 <<= 3   ///  r5 = r5.wrapping_shl(3)
    ldxdw r8, [r10-0x10]                    
    ldxdw r1, [r10-0x18]                    
    mov64 r0, 0                                     r0 = 0 as i32 as i64 as u64
lbb_30448:
    jsge r5, r3, lbb_30469                          if (r5 as i64) >= (r3 as i64) { pc += 20 }
    ja lbb_30452                                    if true { pc += 2 }
lbb_30450:
    add64 r5, 1                                     r5 += 1   ///  r5 = r5.wrapping_add(1 as i32 as i64 as u64)
    jsge r5, r3, lbb_30469                          if (r5 as i64) >= (r3 as i64) { pc += 17 }
lbb_30452:
    mov64 r2, r1                                    r2 = r1
    add64 r2, r5                                    r2 += r5   ///  r2 = r2.wrapping_add(r5)
    mov64 r4, r8                                    r4 = r8
    add64 r4, r5                                    r4 += r5   ///  r4 = r4.wrapping_add(r5)
    ldxb r4, [r4+0x0]                       
    ldxb r6, [r2+0x0]                       
    jeq r6, r4, lbb_30450                           if r6 == r4 { pc += -9 }
    sub64 r6, r4                                    r6 -= r4   ///  r6 = r6.wrapping_sub(r4)
    mov64 r0, r6                                    r0 = r6
    ja lbb_30469                                    if true { pc += 7 }
lbb_30462:
    mov64 r4, 0                                     r4 = 0 as i32 as i64 as u64
    stxw [r10-0x4], r4                      
    mov64 r4, r10                                   r4 = r10
    add64 r4, -4                                    r4 += -4   ///  r4 = r4.wrapping_add(-4 as i32 as i64 as u64)
    mov64 r2, r8                                    r2 = r8
    syscall [invalid]                       
    ldxw r0, [r10-0x4]                      
lbb_30469:
    lsh64 r0, 32                                    r0 <<= 32   ///  r0 = r0.wrapping_shl(32)
    arsh64 r0, 32                                   r0 >>= 32 (signed)   ///  r0 = (r0 as i64).wrapping_shr(32)
    exit                                    

function_30472:
    mov64 r0, 0                                     r0 = 0 as i32 as i64 as u64
    lddw r2, 0x3ff0000000000000                     r2 load str located at 4607182418800017408
    jgt r2, r1, lbb_30495                           if r2 > r1 { pc += 19 }
    lddw r2, 0x43f0000000000000                     r2 load str located at 4895412794951729152
    jgt r2, r1, lbb_30485                           if r2 > r1 { pc += 6 }
    mov64 r0, -1                                    r0 = -1 as i32 as i64 as u64
    lddw r2, 0x7ff0000000000001                     r2 load str located at 9218868437227405313
    jgt r2, r1, lbb_30495                           if r2 > r1 { pc += 12 }
    mov64 r0, 0                                     r0 = 0 as i32 as i64 as u64
    ja lbb_30495                                    if true { pc += 10 }
lbb_30485:
    mov64 r0, r1                                    r0 = r1
    lsh64 r0, 11                                    r0 <<= 11   ///  r0 = r0.wrapping_shl(11)
    lddw r2, 0x8000000000000000                     r2 load str located at -9223372036854775808
    or64 r0, r2                                     r0 |= r2   ///  r0 = r0.or(r2)
    rsh64 r1, 52                                    r1 >>= 52   ///  r1 = r1.wrapping_shr(52)
    mov64 r2, 62                                    r2 = 62 as i32 as i64 as u64
    sub64 r2, r1                                    r2 -= r1   ///  r2 = r2.wrapping_sub(r1)
    and64 r2, 63                                    r2 &= 63   ///  r2 = r2.and(63)
    rsh64 r0, r2                                    r0 >>= r2   ///  r0 = r0.wrapping_shr(r2 as u32)
lbb_30495:
    exit                                    

function_30496:
    mov64 r6, r1                                    r6 = r1
    mov64 r1, r10                                   r1 = r10
    add64 r1, -32                                   r1 += -32   ///  r1 = r1.wrapping_add(-32 as i32 as i64 as u64)
    call function_30505                     
    ldxdw r1, [r10-0x20]                    
    ldxdw r2, [r10-0x18]                    
    stxdw [r6+0x8], r2                      
    stxdw [r6+0x0], r1                      
    exit                                    

function_30505:
    stxdw [r10-0xc0], r4                    
    mov64 r0, r3                                    r0 = r3
    stxdw [r10-0xb8], r2                    
    stxdw [r10-0xd0], r1                    
    mov64 r2, r5                                    r2 = r5
    rsh64 r2, 1                                     r2 >>= 1   ///  r2 = r2.wrapping_shr(1)
    mov64 r4, r5                                    r4 = r5
    or64 r4, r2                                     r4 |= r2   ///  r4 = r4.or(r2)
    mov64 r2, r4                                    r2 = r4
    rsh64 r2, 2                                     r2 >>= 2   ///  r2 = r2.wrapping_shr(2)
    or64 r4, r2                                     r4 |= r2   ///  r4 = r4.or(r2)
    mov64 r2, r4                                    r2 = r4
    rsh64 r2, 4                                     r2 >>= 4   ///  r2 = r2.wrapping_shr(4)
    or64 r4, r2                                     r4 |= r2   ///  r4 = r4.or(r2)
    mov64 r2, r4                                    r2 = r4
    rsh64 r2, 8                                     r2 >>= 8   ///  r2 = r2.wrapping_shr(8)
    or64 r4, r2                                     r4 |= r2   ///  r4 = r4.or(r2)
    mov64 r2, r4                                    r2 = r4
    rsh64 r2, 16                                    r2 >>= 16   ///  r2 = r2.wrapping_shr(16)
    or64 r4, r2                                     r4 |= r2   ///  r4 = r4.or(r2)
    mov64 r2, r0                                    r2 = r0
    rsh64 r2, 1                                     r2 >>= 1   ///  r2 = r2.wrapping_shr(1)
    mov64 r7, r0                                    r7 = r0
    or64 r7, r2                                     r7 |= r2   ///  r7 = r7.or(r2)
    mov64 r2, r7                                    r2 = r7
    rsh64 r2, 2                                     r2 >>= 2   ///  r2 = r2.wrapping_shr(2)
    or64 r7, r2                                     r7 |= r2   ///  r7 = r7.or(r2)
    mov64 r2, r4                                    r2 = r4
    rsh64 r2, 32                                    r2 >>= 32   ///  r2 = r2.wrapping_shr(32)
    or64 r4, r2                                     r4 |= r2   ///  r4 = r4.or(r2)
    mov64 r2, r7                                    r2 = r7
    rsh64 r2, 4                                     r2 >>= 4   ///  r2 = r2.wrapping_shr(4)
    or64 r7, r2                                     r7 |= r2   ///  r7 = r7.or(r2)
    mov64 r2, r7                                    r2 = r7
    rsh64 r2, 8                                     r2 >>= 8   ///  r2 = r2.wrapping_shr(8)
    or64 r7, r2                                     r7 |= r2   ///  r7 = r7.or(r2)
    lddw r2, 0x5555555555555555                     r2 load str located at 6148914691236517205
    xor64 r4, -1                                    r4 ^= -1   ///  r4 = r4.xor(-1)
    mov64 r3, r4                                    r3 = r4
    rsh64 r3, 1                                     r3 >>= 1   ///  r3 = r3.wrapping_shr(1)
    and64 r3, r2                                    r3 &= r2   ///  r3 = r3.and(r2)
    sub64 r4, r3                                    r4 -= r3   ///  r4 = r4.wrapping_sub(r3)
    mov64 r3, r7                                    r3 = r7
    rsh64 r3, 16                                    r3 >>= 16   ///  r3 = r3.wrapping_shr(16)
    or64 r7, r3                                     r7 |= r3   ///  r7 = r7.or(r3)
    mov64 r3, r7                                    r3 = r7
    rsh64 r3, 32                                    r3 >>= 32   ///  r3 = r3.wrapping_shr(32)
    or64 r7, r3                                     r7 |= r3   ///  r7 = r7.or(r3)
    lddw r3, 0x3333333333333333                     r3 load str located at 3689348814741910323
    mov64 r6, r4                                    r6 = r4
    and64 r6, r3                                    r6 &= r3   ///  r6 = r6.and(r3)
    rsh64 r4, 2                                     r4 >>= 2   ///  r4 = r4.wrapping_shr(2)
    and64 r4, r3                                    r4 &= r3   ///  r4 = r4.and(r3)
    add64 r6, r4                                    r6 += r4   ///  r6 = r6.wrapping_add(r4)
    xor64 r7, -1                                    r7 ^= -1   ///  r7 = r7.xor(-1)
    mov64 r4, r7                                    r4 = r7
    rsh64 r4, 1                                     r4 >>= 1   ///  r4 = r4.wrapping_shr(1)
    and64 r4, r2                                    r4 &= r2   ///  r4 = r4.and(r2)
    sub64 r7, r4                                    r7 -= r4   ///  r7 = r7.wrapping_sub(r4)
    mov64 r4, r6                                    r4 = r6
    rsh64 r4, 4                                     r4 >>= 4   ///  r4 = r4.wrapping_shr(4)
    add64 r6, r4                                    r6 += r4   ///  r6 = r6.wrapping_add(r4)
    mov64 r9, r7                                    r9 = r7
    and64 r9, r3                                    r9 &= r3   ///  r9 = r9.and(r3)
    rsh64 r7, 2                                     r7 >>= 2   ///  r7 = r7.wrapping_shr(2)
    and64 r7, r3                                    r7 &= r3   ///  r7 = r7.and(r3)
    add64 r9, r7                                    r9 += r7   ///  r9 = r9.wrapping_add(r7)
    mov64 r4, r9                                    r4 = r9
    rsh64 r4, 4                                     r4 >>= 4   ///  r4 = r4.wrapping_shr(4)
    add64 r9, r4                                    r9 += r4   ///  r9 = r9.wrapping_add(r4)
    lddw r1, 0xf0f0f0f0f0f0f0f                      r1 load str located at 1085102592571150095
    and64 r9, r1                                    r9 &= r1   ///  r9 = r9.and(r1)
    and64 r6, r1                                    r6 &= r1   ///  r6 = r6.and(r1)
    lddw r4, 0x101010101010101                      r4 load str located at 72340172838076673
    mul64 r6, r4                                    r6 *= r4   ///  r6 = r6.wrapping_mul(r4)
    mul64 r9, r4                                    r9 *= r4   ///  r9 = r9.wrapping_mul(r4)
    rsh64 r9, 56                                    r9 >>= 56   ///  r9 = r9.wrapping_shr(56)
    stxdw [r10-0xc8], r5                    
    jne r0, 0, lbb_30628                            if r0 != (0 as i32 as i64 as u64) { pc += 40 }
    ldxdw r9, [r10-0xb8]                    
    mov64 r7, r9                                    r7 = r9
    rsh64 r7, 1                                     r7 >>= 1   ///  r7 = r7.wrapping_shr(1)
    mov64 r8, r0                                    r8 = r0
    mov64 r0, r9                                    r0 = r9
    or64 r0, r7                                     r0 |= r7   ///  r0 = r0.or(r7)
    mov64 r7, r0                                    r7 = r0
    rsh64 r7, 2                                     r7 >>= 2   ///  r7 = r7.wrapping_shr(2)
    or64 r0, r7                                     r0 |= r7   ///  r0 = r0.or(r7)
    mov64 r7, r0                                    r7 = r0
    rsh64 r7, 4                                     r7 >>= 4   ///  r7 = r7.wrapping_shr(4)
    or64 r0, r7                                     r0 |= r7   ///  r0 = r0.or(r7)
    mov64 r7, r0                                    r7 = r0
    rsh64 r7, 8                                     r7 >>= 8   ///  r7 = r7.wrapping_shr(8)
    or64 r0, r7                                     r0 |= r7   ///  r0 = r0.or(r7)
    mov64 r7, r0                                    r7 = r0
    rsh64 r7, 16                                    r7 >>= 16   ///  r7 = r7.wrapping_shr(16)
    or64 r0, r7                                     r0 |= r7   ///  r0 = r0.or(r7)
    mov64 r7, r0                                    r7 = r0
    rsh64 r7, 32                                    r7 >>= 32   ///  r7 = r7.wrapping_shr(32)
    or64 r0, r7                                     r0 |= r7   ///  r0 = r0.or(r7)
    xor64 r0, -1                                    r0 ^= -1   ///  r0 = r0.xor(-1)
    mov64 r7, r0                                    r7 = r0
    rsh64 r7, 1                                     r7 >>= 1   ///  r7 = r7.wrapping_shr(1)
    and64 r7, r2                                    r7 &= r2   ///  r7 = r7.and(r2)
    sub64 r0, r7                                    r0 -= r7   ///  r0 = r0.wrapping_sub(r7)
    ldxdw r5, [r10-0xc8]                    
    mov64 r9, r0                                    r9 = r0
    and64 r9, r3                                    r9 &= r3   ///  r9 = r9.and(r3)
    rsh64 r0, 2                                     r0 >>= 2   ///  r0 = r0.wrapping_shr(2)
    and64 r0, r3                                    r0 &= r3   ///  r0 = r0.and(r3)
    add64 r9, r0                                    r9 += r0   ///  r9 = r9.wrapping_add(r0)
    mov64 r0, r9                                    r0 = r9
    rsh64 r0, 4                                     r0 >>= 4   ///  r0 = r0.wrapping_shr(4)
    add64 r9, r0                                    r9 += r0   ///  r9 = r9.wrapping_add(r0)
    mov64 r0, r8                                    r0 = r8
    and64 r9, r1                                    r9 &= r1   ///  r9 = r9.and(r1)
    mul64 r9, r4                                    r9 *= r4   ///  r9 = r9.wrapping_mul(r4)
    rsh64 r9, 56                                    r9 >>= 56   ///  r9 = r9.wrapping_shr(56)
    add64 r9, 64                                    r9 += 64   ///  r9 = r9.wrapping_add(64 as i32 as i64 as u64)
lbb_30628:
    rsh64 r6, 56                                    r6 >>= 56   ///  r6 = r6.wrapping_shr(56)
    jne r5, 0, lbb_30669                            if r5 != (0 as i32 as i64 as u64) { pc += 39 }
    mov64 r7, r0                                    r7 = r0
    ldxdw r6, [r10-0xc0]                    
    mov64 r0, r6                                    r0 = r6
    rsh64 r0, 1                                     r0 >>= 1   ///  r0 = r0.wrapping_shr(1)
    or64 r6, r0                                     r6 |= r0   ///  r6 = r6.or(r0)
    mov64 r0, r6                                    r0 = r6
    rsh64 r0, 2                                     r0 >>= 2   ///  r0 = r0.wrapping_shr(2)
    or64 r6, r0                                     r6 |= r0   ///  r6 = r6.or(r0)
    mov64 r0, r6                                    r0 = r6
    rsh64 r0, 4                                     r0 >>= 4   ///  r0 = r0.wrapping_shr(4)
    or64 r6, r0                                     r6 |= r0   ///  r6 = r6.or(r0)
    mov64 r0, r6                                    r0 = r6
    rsh64 r0, 8                                     r0 >>= 8   ///  r0 = r0.wrapping_shr(8)
    or64 r6, r0                                     r6 |= r0   ///  r6 = r6.or(r0)
    mov64 r0, r6                                    r0 = r6
    rsh64 r0, 16                                    r0 >>= 16   ///  r0 = r0.wrapping_shr(16)
    or64 r6, r0                                     r6 |= r0   ///  r6 = r6.or(r0)
    mov64 r0, r6                                    r0 = r6
    rsh64 r0, 32                                    r0 >>= 32   ///  r0 = r0.wrapping_shr(32)
    or64 r6, r0                                     r6 |= r0   ///  r6 = r6.or(r0)
    xor64 r6, -1                                    r6 ^= -1   ///  r6 = r6.xor(-1)
    mov64 r0, r6                                    r0 = r6
    rsh64 r0, 1                                     r0 >>= 1   ///  r0 = r0.wrapping_shr(1)
    and64 r0, r2                                    r0 &= r2   ///  r0 = r0.and(r2)
    sub64 r6, r0                                    r6 -= r0   ///  r6 = r6.wrapping_sub(r0)
    mov64 r0, r7                                    r0 = r7
    ldxdw r5, [r10-0xc8]                    
    mov64 r2, r6                                    r2 = r6
    rsh64 r2, 2                                     r2 >>= 2   ///  r2 = r2.wrapping_shr(2)
    and64 r6, r3                                    r6 &= r3   ///  r6 = r6.and(r3)
    and64 r2, r3                                    r2 &= r3   ///  r2 = r2.and(r3)
    add64 r6, r2                                    r6 += r2   ///  r6 = r6.wrapping_add(r2)
    mov64 r2, r6                                    r2 = r6
    rsh64 r2, 4                                     r2 >>= 4   ///  r2 = r2.wrapping_shr(4)
    add64 r6, r2                                    r6 += r2   ///  r6 = r6.wrapping_add(r2)
    and64 r6, r1                                    r6 &= r1   ///  r6 = r6.and(r1)
    mul64 r6, r4                                    r6 *= r4   ///  r6 = r6.wrapping_mul(r4)
    rsh64 r6, 56                                    r6 >>= 56   ///  r6 = r6.wrapping_shr(56)
    add64 r6, 64                                    r6 += 64   ///  r6 = r6.wrapping_add(64 as i32 as i64 as u64)
lbb_30669:
    jge r9, r6, lbb_30686                           if r9 >= r6 { pc += 16 }
    mov64 r2, r9                                    r2 = r9
    lsh64 r2, 32                                    r2 <<= 32   ///  r2 = r2.wrapping_shl(32)
    rsh64 r2, 32                                    r2 >>= 32   ///  r2 = r2.wrapping_shr(32)
    ldxdw r4, [r10-0xb8]                    
    ldxdw r1, [r10-0xd0]                    
    jgt r2, 63, lbb_30677                           if r2 > (63 as i32 as i64 as u64) { pc += 1 }
    ja lbb_30709                                    if true { pc += 32 }
lbb_30677:
    ldxdw r2, [r10-0xc0]                    
    mov64 r9, r4                                    r9 = r4
    jeq r2, 0, lbb_30682                            if r2 == (0 as i32 as i64 as u64) { pc += 2 }
    mov64 r8, r9                                    r8 = r9
    div64 r8, r2                                    r8 /= r2   ///  r8 = r8 / r2
lbb_30682:
    mod64 r9, r2                                    r9 %= r2   ///  r9 = r9 % r2
    mov64 r0, 0                                     r0 = 0 as i32 as i64 as u64
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
    ja lbb_30745                                    if true { pc += 59 }
lbb_30686:
    mov64 r8, 0                                     r8 = 0 as i32 as i64 as u64
    mov64 r2, 1                                     r2 = 1 as i32 as i64 as u64
    mov64 r3, 1                                     r3 = 1 as i32 as i64 as u64
    ldxdw r9, [r10-0xb8]                    
    ldxdw r4, [r10-0xc0]                    
    ldxdw r1, [r10-0xd0]                    
    jgt r4, r9, lbb_30694                           if r4 > r9 { pc += 1 }
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
lbb_30694:
    jgt r5, r0, lbb_30696                           if r5 > r0 { pc += 1 }
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
lbb_30696:
    jeq r0, r5, lbb_30698                           if r0 == r5 { pc += 1 }
    mov64 r3, r2                                    r3 = r2
lbb_30698:
    and64 r3, 1                                     r3 &= 1   ///  r3 = r3.and(1)
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
    jne r3, 0, lbb_30745                            if r3 != (0 as i32 as i64 as u64) { pc += 44 }
    sub64 r0, r5                                    r0 -= r5   ///  r0 = r0.wrapping_sub(r5)
    mov64 r8, 1                                     r8 = 1 as i32 as i64 as u64
    mov64 r3, 1                                     r3 = 1 as i32 as i64 as u64
    jgt r4, r9, lbb_30706                           if r4 > r9 { pc += 1 }
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
lbb_30706:
    sub64 r0, r3                                    r0 -= r3   ///  r0 = r0.wrapping_sub(r3)
    sub64 r9, r4                                    r9 -= r4   ///  r9 = r9.wrapping_sub(r4)
    ja lbb_30745                                    if true { pc += 36 }
lbb_30709:
    mov64 r2, r6                                    r2 = r6
    lsh64 r2, 32                                    r2 <<= 32   ///  r2 = r2.wrapping_shl(32)
    rsh64 r2, 32                                    r2 >>= 32   ///  r2 = r2.wrapping_shr(32)
    jgt r2, 95, lbb_30714                           if r2 > (95 as i32 as i64 as u64) { pc += 1 }
    ja lbb_30750                                    if true { pc += 36 }
lbb_30714:
    ldxdw r6, [r10-0xc0]                    
    lsh64 r6, 32                                    r6 <<= 32   ///  r6 = r6.wrapping_shl(32)
    rsh64 r6, 32                                    r6 >>= 32   ///  r6 = r6.wrapping_shr(32)
    jeq r6, 0, lbb_30720                            if r6 == (0 as i32 as i64 as u64) { pc += 2 }
    mov64 r3, r0                                    r3 = r0
    div64 r3, r6                                    r3 /= r6   ///  r3 = r3 / r6
lbb_30720:
    mod64 r0, r6                                    r0 %= r6   ///  r0 = r0 % r6
    lsh64 r0, 32                                    r0 <<= 32   ///  r0 = r0.wrapping_shl(32)
    mov64 r5, r4                                    r5 = r4
    rsh64 r4, 32                                    r4 >>= 32   ///  r4 = r4.wrapping_shr(32)
    or64 r0, r4                                     r0 |= r4   ///  r0 = r0.or(r4)
    div64 r0, r6                                    r0 /= r6   ///  r0 = r0 / r6
    mov64 r2, r0                                    r2 = r0
    mul64 r2, r6                                    r2 *= r6   ///  r2 = r2.wrapping_mul(r6)
    sub64 r4, r2                                    r4 -= r2   ///  r4 = r4.wrapping_sub(r2)
    lsh64 r4, 32                                    r4 <<= 32   ///  r4 = r4.wrapping_shl(32)
    lsh64 r5, 32                                    r5 <<= 32   ///  r5 = r5.wrapping_shl(32)
    rsh64 r5, 32                                    r5 >>= 32   ///  r5 = r5.wrapping_shr(32)
    or64 r4, r5                                     r4 |= r5   ///  r4 = r4.or(r5)
    mov64 r2, r4                                    r2 = r4
    div64 r2, r6                                    r2 /= r6   ///  r2 = r2 / r6
    mov64 r8, r0                                    r8 = r0
    lsh64 r8, 32                                    r8 <<= 32   ///  r8 = r8.wrapping_shl(32)
    or64 r8, r2                                     r8 |= r2   ///  r8 = r8.or(r2)
    mul64 r2, r6                                    r2 *= r6   ///  r2 = r2.wrapping_mul(r6)
    sub64 r4, r2                                    r4 -= r2   ///  r4 = r4.wrapping_sub(r2)
    rsh64 r0, 32                                    r0 >>= 32   ///  r0 = r0.wrapping_shr(32)
    mov64 r2, r0                                    r2 = r0
    or64 r2, r3                                     r2 |= r3   ///  r2 = r2.or(r3)
    mov64 r0, 0                                     r0 = 0 as i32 as i64 as u64
lbb_30744:
    mov64 r9, r4                                    r9 = r4
lbb_30745:
    stxdw [r1+0x10], r9                     
    stxdw [r1+0x0], r8                      
    stxdw [r1+0x18], r0                     
    stxdw [r1+0x8], r2                      
    exit                                    
lbb_30750:
    stxdw [r10-0xd8], r0                    
    mov64 r1, r6                                    r1 = r6
    sub64 r1, r9                                    r1 -= r9   ///  r1 = r1.wrapping_sub(r9)
    lsh64 r1, 32                                    r1 <<= 32   ///  r1 = r1.wrapping_shl(32)
    rsh64 r1, 32                                    r1 >>= 32   ///  r1 = r1.wrapping_shr(32)
    mov64 r2, 32                                    r2 = 32 as i32 as i64 as u64
    jgt r2, r1, lbb_30758                           if r2 > r1 { pc += 1 }
    ja lbb_30827                                    if true { pc += 69 }
lbb_30758:
    mov64 r3, r5                                    r3 = r5
    mov64 r7, 64                                    r7 = 64 as i32 as i64 as u64
    sub64 r7, r9                                    r7 -= r9   ///  r7 = r7.wrapping_sub(r9)
    lsh64 r7, 32                                    r7 <<= 32   ///  r7 = r7.wrapping_shl(32)
    arsh64 r7, 32                                   r7 >>= 32 (signed)   ///  r7 = (r7 as i64).wrapping_shr(32)
    mov64 r1, r10                                   r1 = r10
    add64 r1, -128                                  r1 += -128   ///  r1 = r1.wrapping_add(-128 as i32 as i64 as u64)
    ldxdw r9, [r10-0xc0]                    
    mov64 r2, r9                                    r2 = r9
    mov64 r4, r7                                    r4 = r7
    call function_31684                     
    ldxdw r6, [r10-0x80]                    
    jeq r6, 0, lbb_30779                            if r6 == (0 as i32 as i64 as u64) { pc += 8 }
    mov64 r1, r10                                   r1 = r10
    add64 r1, -144                                  r1 += -144   ///  r1 = r1.wrapping_add(-144 as i32 as i64 as u64)
    ldxdw r2, [r10-0xb8]                    
    ldxdw r3, [r10-0xd8]                    
    mov64 r4, r7                                    r4 = r7
    call function_31684                     
    ldxdw r8, [r10-0x90]                    
    div64 r8, r6                                    r8 /= r6   ///  r8 = r8 / r6
lbb_30779:
    mov64 r1, r10                                   r1 = r10
    add64 r1, -160                                  r1 += -160   ///  r1 = r1.wrapping_add(-160 as i32 as i64 as u64)
    mov64 r2, r9                                    r2 = r9
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
    mov64 r4, r8                                    r4 = r8
    mov64 r5, 0                                     r5 = 0 as i32 as i64 as u64
    call function_31300                     
    mov64 r1, r10                                   r1 = r10
    add64 r1, -176                                  r1 += -176   ///  r1 = r1.wrapping_add(-176 as i32 as i64 as u64)
    ldxdw r7, [r10-0xc8]                    
    mov64 r2, r7                                    r2 = r7
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
    mov64 r4, r8                                    r4 = r8
    mov64 r5, 0                                     r5 = 0 as i32 as i64 as u64
    call function_31300                     
    ldxdw r2, [r10-0x98]                    
    ldxdw r1, [r10-0xb0]                    
    mov64 r4, r2                                    r4 = r2
    add64 r4, r1                                    r4 += r1   ///  r4 = r4.wrapping_add(r1)
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    jgt r2, r4, lbb_30801                           if r2 > r4 { pc += 1 }
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
lbb_30801:
    ldxdw r2, [r10-0xa8]                    
    add64 r2, r1                                    r2 += r1   ///  r2 = r2.wrapping_add(r1)
    ldxdw r3, [r10-0xa0]                    
    ldxdw r1, [r10-0xd0]                    
    ldxdw r0, [r10-0xd8]                    
    jne r2, 0, lbb_31044                            if r2 != (0 as i32 as i64 as u64) { pc += 237 }
    mov64 r5, 1                                     r5 = 1 as i32 as i64 as u64
    mov64 r2, 1                                     r2 = 1 as i32 as i64 as u64
    ldxdw r6, [r10-0xb8]                    
    jgt r3, r6, lbb_30812                           if r3 > r6 { pc += 1 }
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
lbb_30812:
    jgt r4, r0, lbb_30814                           if r4 > r0 { pc += 1 }
    mov64 r5, 0                                     r5 = 0 as i32 as i64 as u64
lbb_30814:
    jeq r0, r4, lbb_30816                           if r0 == r4 { pc += 1 }
    mov64 r2, r5                                    r2 = r5
lbb_30816:
    and64 r2, 1                                     r2 &= 1   ///  r2 = r2.and(1)
    jne r2, 0, lbb_31044                            if r2 != (0 as i32 as i64 as u64) { pc += 226 }
    sub64 r0, r4                                    r0 -= r4   ///  r0 = r0.wrapping_sub(r4)
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
    mov64 r4, 1                                     r4 = 1 as i32 as i64 as u64
    ldxdw r9, [r10-0xb8]                    
    jgt r3, r9, lbb_30824                           if r3 > r9 { pc += 1 }
    mov64 r4, 0                                     r4 = 0 as i32 as i64 as u64
lbb_30824:
    sub64 r0, r4                                    r0 -= r4   ///  r0 = r0.wrapping_sub(r4)
    sub64 r9, r3                                    r9 -= r3   ///  r9 = r9.wrapping_sub(r3)
    ja lbb_30745                                    if true { pc += -82 }
lbb_30827:
    mov64 r1, 96                                    r1 = 96 as i32 as i64 as u64
    sub64 r1, r6                                    r1 -= r6   ///  r1 = r1.wrapping_sub(r6)
    stxdw [r10-0xf8], r1                    
    mov64 r4, r1                                    r4 = r1
    lsh64 r4, 32                                    r4 <<= 32   ///  r4 = r4.wrapping_shl(32)
    stxdw [r10-0xf0], r4                    
    arsh64 r4, 32                                   r4 >>= 32 (signed)   ///  r4 = (r4 as i64).wrapping_shr(32)
    mov64 r1, r10                                   r1 = r10
    add64 r1, -16                                   r1 += -16   ///  r1 = r1.wrapping_add(-16 as i32 as i64 as u64)
    ldxdw r2, [r10-0xc0]                    
    mov64 r3, r5                                    r3 = r5
    call function_31684                     
    mov64 r4, 0                                     r4 = 0 as i32 as i64 as u64
    ldxdw r1, [r10-0x10]                    
    lsh64 r1, 32                                    r1 <<= 32   ///  r1 = r1.wrapping_shl(32)
    rsh64 r1, 32                                    r1 >>= 32   ///  r1 = r1.wrapping_shr(32)
    add64 r1, 1                                     r1 += 1   ///  r1 = r1.wrapping_add(1 as i32 as i64 as u64)
    stxdw [r10-0x100], r1                   
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
    ldxdw r0, [r10-0xd8]                    
    ldxdw r5, [r10-0xb8]                    
lbb_30848:
    stxdw [r10-0xe8], r4                    
    stxdw [r10-0xe0], r3                    
    mov64 r8, 64                                    r8 = 64 as i32 as i64 as u64
    sub64 r8, r9                                    r8 -= r9   ///  r8 = r8.wrapping_sub(r9)
    mov64 r7, r8                                    r7 = r8
    lsh64 r7, 32                                    r7 <<= 32   ///  r7 = r7.wrapping_shl(32)
    mov64 r9, r7                                    r9 = r7
    arsh64 r9, 32                                   r9 >>= 32 (signed)   ///  r9 = (r9 as i64).wrapping_shr(32)
    mov64 r1, r10                                   r1 = r10
    add64 r1, -32                                   r1 += -32   ///  r1 = r1.wrapping_add(-32 as i32 as i64 as u64)
    mov64 r2, r5                                    r2 = r5
    stxdw [r10-0xb8], r2                    
    stxdw [r10-0xd8], r0                    
    mov64 r3, r0                                    r3 = r0
    mov64 r4, r9                                    r4 = r9
    call function_31684                     
    ldxdw r2, [r10-0x20]                    
    rsh64 r7, 32                                    r7 >>= 32   ///  r7 = r7.wrapping_shr(32)
    ldxdw r1, [r10-0xf0]                    
    rsh64 r1, 32                                    r1 >>= 32   ///  r1 = r1.wrapping_shr(32)
    jge r7, r1, lbb_30882                           if r7 >= r1 { pc += 13 }
    mov64 r1, r10                                   r1 = r10
    add64 r1, -96                                   r1 += -96   ///  r1 = r1.wrapping_add(-96 as i32 as i64 as u64)
    mov64 r7, r2                                    r7 = r2
    ldxdw r2, [r10-0xc0]                    
    ldxdw r6, [r10-0xc8]                    
    mov64 r3, r6                                    r3 = r6
    mov64 r4, r9                                    r4 = r9
    call function_31684                     
    mov64 r2, r7                                    r2 = r7
    ldxdw r1, [r10-0x60]                    
    jeq r1, 0, lbb_31063                            if r1 == (0 as i32 as i64 as u64) { pc += 183 }
    div64 r2, r1                                    r2 /= r1   ///  r2 = r2 / r1
    ja lbb_31063                                    if true { pc += 181 }
lbb_30882:
    ldxdw r1, [r10-0x100]                   
    div64 r2, r1                                    r2 /= r1   ///  r2 = r2 / r1
    ldxdw r1, [r10-0xf8]                    
    sub64 r8, r1                                    r8 -= r1   ///  r8 = r8.wrapping_sub(r1)
    and64 r8, 127                                   r8 &= 127   ///  r8 = r8.and(127)
    mov64 r1, r10                                   r1 = r10
    add64 r1, -48                                   r1 += -48   ///  r1 = r1.wrapping_add(-48 as i32 as i64 as u64)
    mov64 r7, r2                                    r7 = r2
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
    mov64 r4, r8                                    r4 = r8
    call function_31827                     
    mov64 r1, r10                                   r1 = r10
    add64 r1, -64                                   r1 += -64   ///  r1 = r1.wrapping_add(-64 as i32 as i64 as u64)
    mov64 r2, r7                                    r2 = r7
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
    ldxdw r4, [r10-0xc0]                    
    ldxdw r7, [r10-0xc8]                    
    mov64 r5, r7                                    r5 = r7
    call function_31300                     
    mov64 r1, r10                                   r1 = r10
    add64 r1, -80                                   r1 += -80   ///  r1 = r1.wrapping_add(-80 as i32 as i64 as u64)
    ldxdw r2, [r10-0x40]                    
    ldxdw r3, [r10-0x38]                    
    mov64 r4, r8                                    r4 = r8
    call function_31827                     
    ldxdw r3, [r10-0x30]                    
    mov64 r8, r3                                    r8 = r3
    ldxdw r1, [r10-0xe8]                    
    add64 r8, r1                                    r8 += r1   ///  r8 = r8.wrapping_add(r1)
    mov64 r2, 1                                     r2 = 1 as i32 as i64 as u64
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    jgt r3, r8, lbb_30915                           if r3 > r8 { pc += 1 }
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
lbb_30915:
    ldxdw r4, [r10-0x50]                    
    ldxdw r0, [r10-0xd8]                    
    ldxdw r5, [r10-0xb8]                    
    jgt r4, r5, lbb_30920                           if r4 > r5 { pc += 1 }
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
lbb_30920:
    ldxdw r3, [r10-0x48]                    
    sub64 r0, r3                                    r0 -= r3   ///  r0 = r0.wrapping_sub(r3)
    sub64 r0, r2                                    r0 -= r2   ///  r0 = r0.wrapping_sub(r2)
    mov64 r2, r0                                    r2 = r0
    rsh64 r2, 1                                     r2 >>= 1   ///  r2 = r2.wrapping_shr(1)
    mov64 r3, r0                                    r3 = r0
    or64 r3, r2                                     r3 |= r2   ///  r3 = r3.or(r2)
    mov64 r2, r3                                    r2 = r3
    rsh64 r2, 2                                     r2 >>= 2   ///  r2 = r2.wrapping_shr(2)
    or64 r3, r2                                     r3 |= r2   ///  r3 = r3.or(r2)
    ldxdw r2, [r10-0x28]                    
    sub64 r5, r4                                    r5 -= r4   ///  r5 = r5.wrapping_sub(r4)
    mov64 r4, r3                                    r4 = r3
    rsh64 r4, 4                                     r4 >>= 4   ///  r4 = r4.wrapping_shr(4)
    or64 r3, r4                                     r3 |= r4   ///  r3 = r3.or(r4)
    mov64 r4, r3                                    r4 = r3
    rsh64 r4, 8                                     r4 >>= 8   ///  r4 = r4.wrapping_shr(8)
    or64 r3, r4                                     r3 |= r4   ///  r3 = r3.or(r4)
    mov64 r4, r3                                    r4 = r3
    rsh64 r4, 16                                    r4 >>= 16   ///  r4 = r4.wrapping_shr(16)
    or64 r3, r4                                     r3 |= r4   ///  r3 = r3.or(r4)
    mov64 r4, r3                                    r4 = r3
    rsh64 r4, 32                                    r4 >>= 32   ///  r4 = r4.wrapping_shr(32)
    or64 r3, r4                                     r3 |= r4   ///  r3 = r3.or(r4)
    xor64 r3, -1                                    r3 ^= -1   ///  r3 = r3.xor(-1)
    mov64 r4, r3                                    r4 = r3
    rsh64 r4, 1                                     r4 >>= 1   ///  r4 = r4.wrapping_shr(1)
    lddw r9, 0x5555555555555555                     r9 load str located at 6148914691236517205
    and64 r4, r9                                    r4 &= r9   ///  r4 = r4.and(r9)
    sub64 r3, r4                                    r3 -= r4   ///  r3 = r3.wrapping_sub(r4)
    mov64 r9, r3                                    r9 = r3
    lddw r4, 0x3333333333333333                     r4 load str located at 3689348814741910323
    and64 r9, r4                                    r9 &= r4   ///  r9 = r9.and(r4)
    rsh64 r3, 2                                     r3 >>= 2   ///  r3 = r3.wrapping_shr(2)
    and64 r3, r4                                    r3 &= r4   ///  r3 = r3.and(r4)
    add64 r9, r3                                    r9 += r3   ///  r9 = r9.wrapping_add(r3)
    mov64 r3, r9                                    r3 = r9
    rsh64 r3, 4                                     r3 >>= 4   ///  r3 = r3.wrapping_shr(4)
    add64 r9, r3                                    r9 += r3   ///  r9 = r9.wrapping_add(r3)
    lddw r3, 0xf0f0f0f0f0f0f0f                      r3 load str located at 1085102592571150095
    and64 r9, r3                                    r9 &= r3   ///  r9 = r9.and(r3)
    lddw r3, 0x101010101010101                      r3 load str located at 72340172838076673
    mul64 r9, r3                                    r9 *= r3   ///  r9 = r9.wrapping_mul(r3)
    rsh64 r9, 56                                    r9 >>= 56   ///  r9 = r9.wrapping_shr(56)
    jne r0, 0, lbb_31013                            if r0 != (0 as i32 as i64 as u64) { pc += 44 }
    mov64 r3, r5                                    r3 = r5
    mov64 r4, r3                                    r4 = r3
    rsh64 r4, 1                                     r4 >>= 1   ///  r4 = r4.wrapping_shr(1)
    or64 r3, r4                                     r3 |= r4   ///  r3 = r3.or(r4)
    mov64 r4, r3                                    r4 = r3
    rsh64 r4, 2                                     r4 >>= 2   ///  r4 = r4.wrapping_shr(2)
    or64 r3, r4                                     r3 |= r4   ///  r3 = r3.or(r4)
    mov64 r4, r3                                    r4 = r3
    rsh64 r4, 4                                     r4 >>= 4   ///  r4 = r4.wrapping_shr(4)
    or64 r3, r4                                     r3 |= r4   ///  r3 = r3.or(r4)
    mov64 r4, r3                                    r4 = r3
    rsh64 r4, 8                                     r4 >>= 8   ///  r4 = r4.wrapping_shr(8)
    or64 r3, r4                                     r3 |= r4   ///  r3 = r3.or(r4)
    mov64 r4, r3                                    r4 = r3
    rsh64 r4, 16                                    r4 >>= 16   ///  r4 = r4.wrapping_shr(16)
    or64 r3, r4                                     r3 |= r4   ///  r3 = r3.or(r4)
    mov64 r4, r3                                    r4 = r3
    rsh64 r4, 32                                    r4 >>= 32   ///  r4 = r4.wrapping_shr(32)
    or64 r3, r4                                     r3 |= r4   ///  r3 = r3.or(r4)
    xor64 r3, -1                                    r3 ^= -1   ///  r3 = r3.xor(-1)
    mov64 r4, r3                                    r4 = r3
    rsh64 r4, 1                                     r4 >>= 1   ///  r4 = r4.wrapping_shr(1)
    lddw r9, 0x5555555555555555                     r9 load str located at 6148914691236517205
    and64 r4, r9                                    r4 &= r9   ///  r4 = r4.and(r9)
    sub64 r3, r4                                    r3 -= r4   ///  r3 = r3.wrapping_sub(r4)
    mov64 r9, r3                                    r9 = r3
    lddw r4, 0x3333333333333333                     r4 load str located at 3689348814741910323
    and64 r9, r4                                    r9 &= r4   ///  r9 = r9.and(r4)
    rsh64 r3, 2                                     r3 >>= 2   ///  r3 = r3.wrapping_shr(2)
    and64 r3, r4                                    r3 &= r4   ///  r3 = r3.and(r4)
    add64 r9, r3                                    r9 += r3   ///  r9 = r9.wrapping_add(r3)
    mov64 r3, r9                                    r3 = r9
    rsh64 r3, 4                                     r3 >>= 4   ///  r3 = r3.wrapping_shr(4)
    add64 r9, r3                                    r9 += r3   ///  r9 = r9.wrapping_add(r3)
    lddw r3, 0xf0f0f0f0f0f0f0f                      r3 load str located at 1085102592571150095
    and64 r9, r3                                    r9 &= r3   ///  r9 = r9.and(r3)
    lddw r3, 0x101010101010101                      r3 load str located at 72340172838076673
    mul64 r9, r3                                    r9 *= r3   ///  r9 = r9.wrapping_mul(r3)
    rsh64 r9, 56                                    r9 >>= 56   ///  r9 = r9.wrapping_shr(56)
    add64 r9, 64                                    r9 += 64   ///  r9 = r9.wrapping_add(64 as i32 as i64 as u64)
lbb_31013:
    ldxdw r3, [r10-0xe0]                    
    add64 r2, r3                                    r2 += r3   ///  r2 = r2.wrapping_add(r3)
    add64 r2, r1                                    r2 += r1   ///  r2 = r2.wrapping_add(r1)
    mov64 r1, r6                                    r1 = r6
    lsh64 r1, 32                                    r1 <<= 32   ///  r1 = r1.wrapping_shl(32)
    rsh64 r1, 32                                    r1 >>= 32   ///  r1 = r1.wrapping_shr(32)
    jgt r1, r9, lbb_31021                           if r1 > r9 { pc += 1 }
    ja lbb_31113                                    if true { pc += 92 }
lbb_31021:
    mov64 r1, r9                                    r1 = r9
    lsh64 r1, 32                                    r1 <<= 32   ///  r1 = r1.wrapping_shl(32)
    rsh64 r1, 32                                    r1 >>= 32   ///  r1 = r1.wrapping_shr(32)
    mov64 r4, r8                                    r4 = r8
    mov64 r3, r2                                    r3 = r2
    jgt r1, 63, lbb_31028                           if r1 > (63 as i32 as i64 as u64) { pc += 1 }
    ja lbb_30848                                    if true { pc += -180 }
lbb_31028:
    ldxdw r6, [r10-0xc0]                    
    mov64 r9, r5                                    r9 = r5
    jeq r6, 0, lbb_31033                            if r6 == (0 as i32 as i64 as u64) { pc += 2 }
    mov64 r1, r9                                    r1 = r9
    div64 r1, r6                                    r1 /= r6   ///  r1 = r1 / r6
lbb_31033:
    mov64 r3, r8                                    r3 = r8
    add64 r3, r1                                    r3 += r1   ///  r3 = r3.wrapping_add(r1)
    mov64 r0, 0                                     r0 = 0 as i32 as i64 as u64
    mov64 r4, 1                                     r4 = 1 as i32 as i64 as u64
    ldxdw r1, [r10-0xd0]                    
    jgt r8, r3, lbb_31040                           if r8 > r3 { pc += 1 }
    mov64 r4, 0                                     r4 = 0 as i32 as i64 as u64
lbb_31040:
    mod64 r9, r6                                    r9 %= r6   ///  r9 = r9 % r6
    add64 r2, r4                                    r2 += r4   ///  r2 = r2.wrapping_add(r4)
    mov64 r8, r3                                    r8 = r3
    ja lbb_30745                                    if true { pc += -299 }
lbb_31044:
    add64 r7, r0                                    r7 += r0   ///  r7 = r7.wrapping_add(r0)
    mov64 r5, r9                                    r5 = r9
    ldxdw r2, [r10-0xb8]                    
    add64 r5, r2                                    r5 += r2   ///  r5 = r5.wrapping_add(r2)
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
    mov64 r0, 1                                     r0 = 1 as i32 as i64 as u64
    mov64 r6, 1                                     r6 = 1 as i32 as i64 as u64
    jgt r9, r5, lbb_31053                           if r9 > r5 { pc += 1 }
    mov64 r6, 0                                     r6 = 0 as i32 as i64 as u64
lbb_31053:
    add64 r7, r6                                    r7 += r6   ///  r7 = r7.wrapping_add(r6)
    sub64 r7, r4                                    r7 -= r4   ///  r7 = r7.wrapping_sub(r4)
    jgt r3, r5, lbb_31057                           if r3 > r5 { pc += 1 }
    mov64 r0, 0                                     r0 = 0 as i32 as i64 as u64
lbb_31057:
    sub64 r7, r0                                    r7 -= r0   ///  r7 = r7.wrapping_sub(r0)
    sub64 r5, r3                                    r5 -= r3   ///  r5 = r5.wrapping_sub(r3)
    add64 r8, -1                                    r8 += -1   ///  r8 = r8.wrapping_add(-1 as i32 as i64 as u64)
    mov64 r9, r5                                    r9 = r5
    mov64 r0, r7                                    r0 = r7
    ja lbb_30745                                    if true { pc += -318 }
lbb_31063:
    mov64 r1, r10                                   r1 = r10
    add64 r1, -112                                  r1 += -112   ///  r1 = r1.wrapping_add(-112 as i32 as i64 as u64)
    mov64 r9, r2                                    r9 = r2
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
    ldxdw r8, [r10-0xc0]                    
    mov64 r4, r8                                    r4 = r8
    mov64 r5, r6                                    r5 = r6
    call function_31300                     
    mov64 r5, 1                                     r5 = 1 as i32 as i64 as u64
    ldxdw r2, [r10-0x70]                    
    mov64 r4, 1                                     r4 = 1 as i32 as i64 as u64
    ldxdw r1, [r10-0xb8]                    
    jgt r2, r1, lbb_31077                           if r2 > r1 { pc += 1 }
    mov64 r4, 0                                     r4 = 0 as i32 as i64 as u64
lbb_31077:
    ldxdw r3, [r10-0x68]                    
    ldxdw r1, [r10-0xd0]                    
    ldxdw r0, [r10-0xd8]                    
    jgt r3, r0, lbb_31082                           if r3 > r0 { pc += 1 }
    mov64 r5, 0                                     r5 = 0 as i32 as i64 as u64
lbb_31082:
    jeq r0, r3, lbb_31084                           if r0 == r3 { pc += 1 }
    mov64 r4, r5                                    r4 = r5
lbb_31084:
    and64 r4, 1                                     r4 &= 1   ///  r4 = r4.and(1)
    jne r4, 0, lbb_31087                            if r4 != (0 as i32 as i64 as u64) { pc += 1 }
    ja lbb_31138                                    if true { pc += 51 }
lbb_31087:
    add64 r0, r6                                    r0 += r6   ///  r0 = r0.wrapping_add(r6)
    mov64 r6, r0                                    r6 = r0
    ldxdw r7, [r10-0xb8]                    
    mov64 r4, r7                                    r4 = r7
    add64 r4, r8                                    r4 += r8   ///  r4 = r4.wrapping_add(r8)
    mov64 r5, 1                                     r5 = 1 as i32 as i64 as u64
    mov64 r0, 1                                     r0 = 1 as i32 as i64 as u64
    jgt r7, r4, lbb_31096                           if r7 > r4 { pc += 1 }
    mov64 r0, 0                                     r0 = 0 as i32 as i64 as u64
lbb_31096:
    add64 r6, r0                                    r6 += r0   ///  r6 = r6.wrapping_add(r0)
    ldxdw r7, [r10-0xe8]                    
    add64 r9, r7                                    r9 += r7   ///  r9 = r9.wrapping_add(r7)
    add64 r9, -1                                    r9 += -1   ///  r9 = r9.wrapping_add(-1 as i32 as i64 as u64)
    mov64 r0, 1                                     r0 = 1 as i32 as i64 as u64
    mov64 r8, r9                                    r8 = r9
    jgt r7, r9, lbb_31104                           if r7 > r9 { pc += 1 }
    mov64 r0, 0                                     r0 = 0 as i32 as i64 as u64
lbb_31104:
    sub64 r6, r3                                    r6 -= r3   ///  r6 = r6.wrapping_sub(r3)
    jgt r2, r4, lbb_31107                           if r2 > r4 { pc += 1 }
    mov64 r5, 0                                     r5 = 0 as i32 as i64 as u64
lbb_31107:
    sub64 r6, r5                                    r6 -= r5   ///  r6 = r6.wrapping_sub(r5)
    sub64 r4, r2                                    r4 -= r2   ///  r4 = r4.wrapping_sub(r2)
    ldxdw r2, [r10-0xe0]                    
    add64 r2, r0                                    r2 += r0   ///  r2 = r2.wrapping_add(r0)
    mov64 r0, r6                                    r0 = r6
    ja lbb_30744                                    if true { pc += -369 }
lbb_31113:
    mov64 r4, 1                                     r4 = 1 as i32 as i64 as u64
    mov64 r3, 1                                     r3 = 1 as i32 as i64 as u64
    ldxdw r1, [r10-0xd0]                    
    ldxdw r6, [r10-0xc0]                    
    mov64 r9, r5                                    r9 = r5
    jgt r6, r9, lbb_31120                           if r6 > r9 { pc += 1 }
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
lbb_31120:
    jgt r7, r0, lbb_31122                           if r7 > r0 { pc += 1 }
    mov64 r4, 0                                     r4 = 0 as i32 as i64 as u64
lbb_31122:
    jeq r0, r7, lbb_31124                           if r0 == r7 { pc += 1 }
    mov64 r3, r4                                    r3 = r4
lbb_31124:
    and64 r3, 1                                     r3 &= 1   ///  r3 = r3.and(1)
    jne r3, 0, lbb_30745                            if r3 != (0 as i32 as i64 as u64) { pc += -381 }
    mov64 r3, 1                                     r3 = 1 as i32 as i64 as u64
    mov64 r4, 1                                     r4 = 1 as i32 as i64 as u64
    jgt r6, r9, lbb_31130                           if r6 > r9 { pc += 1 }
    mov64 r4, 0                                     r4 = 0 as i32 as i64 as u64
lbb_31130:
    sub64 r0, r7                                    r0 -= r7   ///  r0 = r0.wrapping_sub(r7)
    add64 r8, 1                                     r8 += 1   ///  r8 = r8.wrapping_add(1 as i32 as i64 as u64)
    jeq r8, 0, lbb_31134                            if r8 == (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
lbb_31134:
    sub64 r0, r4                                    r0 -= r4   ///  r0 = r0.wrapping_sub(r4)
    add64 r2, r3                                    r2 += r3   ///  r2 = r2.wrapping_add(r3)
    sub64 r9, r6                                    r9 -= r6   ///  r9 = r9.wrapping_sub(r6)
    ja lbb_30745                                    if true { pc += -393 }
lbb_31138:
    ldxdw r6, [r10-0xe8]                    
    mov64 r8, r6                                    r8 = r6
    add64 r8, r9                                    r8 += r9   ///  r8 = r8.wrapping_add(r9)
    mov64 r5, 1                                     r5 = 1 as i32 as i64 as u64
    mov64 r4, 1                                     r4 = 1 as i32 as i64 as u64
    jgt r6, r8, lbb_31145                           if r6 > r8 { pc += 1 }
    mov64 r4, 0                                     r4 = 0 as i32 as i64 as u64
lbb_31145:
    ldxdw r6, [r10-0xb8]                    
    jgt r2, r6, lbb_31148                           if r2 > r6 { pc += 1 }
    mov64 r5, 0                                     r5 = 0 as i32 as i64 as u64
lbb_31148:
    sub64 r0, r3                                    r0 -= r3   ///  r0 = r0.wrapping_sub(r3)
    sub64 r0, r5                                    r0 -= r5   ///  r0 = r0.wrapping_sub(r5)
    ldxdw r9, [r10-0xb8]                    
    sub64 r9, r2                                    r9 -= r2   ///  r9 = r9.wrapping_sub(r2)
    ldxdw r2, [r10-0xe0]                    
    add64 r2, r4                                    r2 += r4   ///  r2 = r2.wrapping_add(r4)
    ja lbb_30745                                    if true { pc += -410 }

function_31155:
    mov64 r8, 0                                     r8 = 0 as i32 as i64 as u64
    jgt r3, r2, lbb_31297                           if r3 > r2 { pc += 140 }
    mov64 r4, r3                                    r4 = r3
    rsh64 r4, 1                                     r4 >>= 1   ///  r4 = r4.wrapping_shr(1)
    mov64 r6, r3                                    r6 = r3
    or64 r6, r4                                     r6 |= r4   ///  r6 = r6.or(r4)
    mov64 r4, r6                                    r4 = r6
    rsh64 r4, 2                                     r4 >>= 2   ///  r4 = r4.wrapping_shr(2)
    or64 r6, r4                                     r6 |= r4   ///  r6 = r6.or(r4)
    mov64 r4, r6                                    r4 = r6
    rsh64 r4, 4                                     r4 >>= 4   ///  r4 = r4.wrapping_shr(4)
    or64 r6, r4                                     r6 |= r4   ///  r6 = r6.or(r4)
    mov64 r4, r6                                    r4 = r6
    rsh64 r4, 8                                     r4 >>= 8   ///  r4 = r4.wrapping_shr(8)
    or64 r6, r4                                     r6 |= r4   ///  r6 = r6.or(r4)
    mov64 r4, r6                                    r4 = r6
    rsh64 r4, 16                                    r4 >>= 16   ///  r4 = r4.wrapping_shr(16)
    or64 r6, r4                                     r6 |= r4   ///  r6 = r6.or(r4)
    mov64 r4, r6                                    r4 = r6
    rsh64 r4, 32                                    r4 >>= 32   ///  r4 = r4.wrapping_shr(32)
    or64 r6, r4                                     r6 |= r4   ///  r6 = r6.or(r4)
    xor64 r6, -1                                    r6 ^= -1   ///  r6 = r6.xor(-1)
    lddw r0, 0x5555555555555555                     r0 load str located at 6148914691236517205
    mov64 r4, r6                                    r4 = r6
    rsh64 r4, 1                                     r4 >>= 1   ///  r4 = r4.wrapping_shr(1)
    and64 r4, r0                                    r4 &= r0   ///  r4 = r4.and(r0)
    sub64 r6, r4                                    r6 -= r4   ///  r6 = r6.wrapping_sub(r4)
    lddw r5, 0x3333333333333333                     r5 load str located at 3689348814741910323
    mov64 r4, r6                                    r4 = r6
    and64 r4, r5                                    r4 &= r5   ///  r4 = r4.and(r5)
    rsh64 r6, 2                                     r6 >>= 2   ///  r6 = r6.wrapping_shr(2)
    and64 r6, r5                                    r6 &= r5   ///  r6 = r6.and(r5)
    add64 r4, r6                                    r4 += r6   ///  r4 = r4.wrapping_add(r6)
    mov64 r6, r4                                    r6 = r4
    rsh64 r6, 4                                     r6 >>= 4   ///  r6 = r6.wrapping_shr(4)
    add64 r4, r6                                    r4 += r6   ///  r4 = r4.wrapping_add(r6)
    lddw r6, 0xf0f0f0f0f0f0f0f                      r6 load str located at 1085102592571150095
    and64 r4, r6                                    r4 &= r6   ///  r4 = r4.and(r6)
    lddw r7, 0x101010101010101                      r7 load str located at 72340172838076673
    mul64 r4, r7                                    r4 *= r7   ///  r4 = r4.wrapping_mul(r7)
    mov64 r9, 64                                    r9 = 64 as i32 as i64 as u64
    rsh64 r4, 56                                    r4 >>= 56   ///  r4 = r4.wrapping_shr(56)
    jeq r2, 0, lbb_31237                            if r2 == (0 as i32 as i64 as u64) { pc += 35 }
    mov64 r9, r2                                    r9 = r2
    rsh64 r9, 1                                     r9 >>= 1   ///  r9 = r9.wrapping_shr(1)
    mov64 r8, r2                                    r8 = r2
    or64 r8, r9                                     r8 |= r9   ///  r8 = r8.or(r9)
    mov64 r9, r8                                    r9 = r8
    rsh64 r9, 2                                     r9 >>= 2   ///  r9 = r9.wrapping_shr(2)
    or64 r8, r9                                     r8 |= r9   ///  r8 = r8.or(r9)
    mov64 r9, r8                                    r9 = r8
    rsh64 r9, 4                                     r9 >>= 4   ///  r9 = r9.wrapping_shr(4)
    or64 r8, r9                                     r8 |= r9   ///  r8 = r8.or(r9)
    mov64 r9, r8                                    r9 = r8
    rsh64 r9, 8                                     r9 >>= 8   ///  r9 = r9.wrapping_shr(8)
    or64 r8, r9                                     r8 |= r9   ///  r8 = r8.or(r9)
    mov64 r9, r8                                    r9 = r8
    rsh64 r9, 16                                    r9 >>= 16   ///  r9 = r9.wrapping_shr(16)
    or64 r8, r9                                     r8 |= r9   ///  r8 = r8.or(r9)
    mov64 r9, r8                                    r9 = r8
    rsh64 r9, 32                                    r9 >>= 32   ///  r9 = r9.wrapping_shr(32)
    or64 r8, r9                                     r8 |= r9   ///  r8 = r8.or(r9)
    xor64 r8, -1                                    r8 ^= -1   ///  r8 = r8.xor(-1)
    mov64 r9, r8                                    r9 = r8
    rsh64 r9, 1                                     r9 >>= 1   ///  r9 = r9.wrapping_shr(1)
    and64 r9, r0                                    r9 &= r0   ///  r9 = r9.and(r0)
    sub64 r8, r9                                    r8 -= r9   ///  r8 = r8.wrapping_sub(r9)
    mov64 r9, r8                                    r9 = r8
    and64 r9, r5                                    r9 &= r5   ///  r9 = r9.and(r5)
    rsh64 r8, 2                                     r8 >>= 2   ///  r8 = r8.wrapping_shr(2)
    and64 r8, r5                                    r8 &= r5   ///  r8 = r8.and(r5)
    add64 r9, r8                                    r9 += r8   ///  r9 = r9.wrapping_add(r8)
    mov64 r5, r9                                    r5 = r9
    rsh64 r5, 4                                     r5 >>= 4   ///  r5 = r5.wrapping_shr(4)
    add64 r9, r5                                    r9 += r5   ///  r9 = r9.wrapping_add(r5)
    and64 r9, r6                                    r9 &= r6   ///  r9 = r9.and(r6)
    mul64 r9, r7                                    r9 *= r7   ///  r9 = r9.wrapping_mul(r7)
    rsh64 r9, 56                                    r9 >>= 56   ///  r9 = r9.wrapping_shr(56)
lbb_31237:
    sub64 r4, r9                                    r4 -= r9   ///  r4 = r4.wrapping_sub(r9)
    mov64 r5, r4                                    r5 = r4
    and64 r5, 63                                    r5 &= 63   ///  r5 = r5.and(63)
    mov64 r0, r3                                    r0 = r3
    lsh64 r0, r5                                    r0 <<= r5   ///  r0 = r0.wrapping_shl(r5 as u32)
    mov64 r8, 1                                     r8 = 1 as i32 as i64 as u64
    mov64 r5, 1                                     r5 = 1 as i32 as i64 as u64
    jgt r0, r2, lbb_31246                           if r0 > r2 { pc += 1 }
    mov64 r5, 0                                     r5 = 0 as i32 as i64 as u64
lbb_31246:
    lsh64 r4, 32                                    r4 <<= 32   ///  r4 = r4.wrapping_shl(32)
    rsh64 r4, 32                                    r4 >>= 32   ///  r4 = r4.wrapping_shr(32)
    sub64 r4, r5                                    r4 -= r5   ///  r4 = r4.wrapping_sub(r5)
    mov64 r0, r4                                    r0 = r4
    and64 r0, 63                                    r0 &= 63   ///  r0 = r0.and(63)
    lsh64 r8, r0                                    r8 <<= r0   ///  r8 = r8.wrapping_shl(r0 as u32)
    mov64 r5, r3                                    r5 = r3
    lsh64 r5, r0                                    r5 <<= r0   ///  r5 = r5.wrapping_shl(r0 as u32)
    sub64 r2, r5                                    r2 -= r5   ///  r2 = r2.wrapping_sub(r5)
    jgt r3, r2, lbb_31297                           if r3 > r2 { pc += 41 }
    mov64 r0, r8                                    r0 = r8
    mov64 r6, r8                                    r6 = r8
    mov64 r7, r2                                    r7 = r2
    jsgt r5, -1, lbb_31277                          if (r5 as i64) > (-1 as i32 as i64) { pc += 17 }
    add64 r4, -1                                    r4 += -1   ///  r4 = r4.wrapping_add(-1 as i32 as i64 as u64)
    mov64 r6, r4                                    r6 = r4
    and64 r6, 63                                    r6 &= 63   ///  r6 = r6.and(63)
    mov64 r0, 1                                     r0 = 1 as i32 as i64 as u64
    lsh64 r0, r6                                    r0 <<= r6   ///  r0 = r0.wrapping_shl(r6 as u32)
    rsh64 r5, 1                                     r5 >>= 1   ///  r5 = r5.wrapping_shr(1)
    mov64 r7, r2                                    r7 = r2
    sub64 r7, r5                                    r7 -= r5   ///  r7 = r7.wrapping_sub(r5)
    mov64 r6, r0                                    r6 = r0
    jsgt r7, -1, lbb_31271                          if (r7 as i64) > (-1 as i32 as i64) { pc += 1 }
    mov64 r6, 0                                     r6 = 0 as i32 as i64 as u64
lbb_31271:
    jsgt r7, -1, lbb_31273                          if (r7 as i64) > (-1 as i32 as i64) { pc += 1 }
    mov64 r7, r2                                    r7 = r2
lbb_31273:
    or64 r6, r8                                     r6 |= r8   ///  r6 = r6.or(r8)
    mov64 r2, r7                                    r2 = r7
    mov64 r8, r6                                    r8 = r6
    jgt r3, r7, lbb_31297                           if r3 > r7 { pc += 20 }
lbb_31277:
    add64 r0, -1                                    r0 += -1   ///  r0 = r0.wrapping_add(-1 as i32 as i64 as u64)
    jeq r4, 0, lbb_31291                            if r4 == (0 as i32 as i64 as u64) { pc += 12 }
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
    mov64 r3, r4                                    r3 = r4
    ja lbb_31284                                    if true { pc += 2 }
lbb_31282:
    add64 r3, -1                                    r3 += -1   ///  r3 = r3.wrapping_add(-1 as i32 as i64 as u64)
    jeq r3, 0, lbb_31291                            if r3 == (0 as i32 as i64 as u64) { pc += 7 }
lbb_31284:
    lsh64 r7, 1                                     r7 <<= 1   ///  r7 = r7.wrapping_shl(1)
    mov64 r8, r7                                    r8 = r7
    sub64 r8, r5                                    r8 -= r5   ///  r8 = r8.wrapping_sub(r5)
    add64 r8, 1                                     r8 += 1   ///  r8 = r8.wrapping_add(1 as i32 as i64 as u64)
    jsgt r2, r8, lbb_31282                          if (r2 as i64) > (r8 as i64) { pc += -7 }
    mov64 r7, r8                                    r7 = r8
    ja lbb_31282                                    if true { pc += -9 }
lbb_31291:
    and64 r4, 63                                    r4 &= 63   ///  r4 = r4.and(63)
    mov64 r2, r7                                    r2 = r7
    rsh64 r2, r4                                    r2 >>= r4   ///  r2 = r2.wrapping_shr(r4 as u32)
    and64 r7, r0                                    r7 &= r0   ///  r7 = r7.and(r0)
    or64 r7, r6                                     r7 |= r6   ///  r7 = r7.or(r6)
    mov64 r8, r7                                    r8 = r7
lbb_31297:
    stxdw [r1+0x8], r2                      
    stxdw [r1+0x0], r8                      
    exit                                    

function_31300:
    stxdw [r10-0x10], r3                    
    stxdw [r10-0x8], r1                     
    mov64 r1, r2                                    r1 = r2
    lsh64 r1, 32                                    r1 <<= 32   ///  r1 = r1.wrapping_shl(32)
    rsh64 r1, 32                                    r1 >>= 32   ///  r1 = r1.wrapping_shr(32)
    mov64 r7, r4                                    r7 = r4
    lsh64 r7, 32                                    r7 <<= 32   ///  r7 = r7.wrapping_shl(32)
    rsh64 r7, 32                                    r7 >>= 32   ///  r7 = r7.wrapping_shr(32)
    mov64 r6, r2                                    r6 = r2
    rsh64 r6, 32                                    r6 >>= 32   ///  r6 = r6.wrapping_shr(32)
    mov64 r3, r7                                    r3 = r7
    mul64 r3, r1                                    r3 *= r1   ///  r3 = r3.wrapping_mul(r1)
    mul64 r7, r6                                    r7 *= r6   ///  r7 = r7.wrapping_mul(r6)
    mov64 r0, r4                                    r0 = r4
    rsh64 r0, 32                                    r0 >>= 32   ///  r0 = r0.wrapping_shr(32)
    mov64 r9, r0                                    r9 = r0
    mul64 r9, r1                                    r9 *= r1   ///  r9 = r9.wrapping_mul(r1)
    mov64 r1, r9                                    r1 = r9
    add64 r1, r7                                    r1 += r7   ///  r1 = r1.wrapping_add(r7)
    mov64 r8, 1                                     r8 = 1 as i32 as i64 as u64
    jgt r9, r1, lbb_31322                           if r9 > r1 { pc += 1 }
    mov64 r8, 0                                     r8 = 0 as i32 as i64 as u64
lbb_31322:
    mov64 r9, r1                                    r9 = r1
    lsh64 r9, 32                                    r9 <<= 32   ///  r9 = r9.wrapping_shl(32)
    mov64 r7, r3                                    r7 = r3
    add64 r7, r9                                    r7 += r9   ///  r7 = r7.wrapping_add(r9)
    mov64 r9, 1                                     r9 = 1 as i32 as i64 as u64
    jgt r3, r7, lbb_31329                           if r3 > r7 { pc += 1 }
    mov64 r9, 0                                     r9 = 0 as i32 as i64 as u64
lbb_31329:
    ldxdw r3, [r10-0x8]                     
    stxdw [r3+0x0], r7                      
    rsh64 r1, 32                                    r1 >>= 32   ///  r1 = r1.wrapping_shr(32)
    lsh64 r8, 32                                    r8 <<= 32   ///  r8 = r8.wrapping_shl(32)
    or64 r8, r1                                     r8 |= r1   ///  r8 = r8.or(r1)
    ldxdw r1, [r10-0x10]                    
    mul64 r4, r1                                    r4 *= r1   ///  r4 = r4.wrapping_mul(r1)
    mul64 r5, r2                                    r5 *= r2   ///  r5 = r5.wrapping_mul(r2)
    mul64 r0, r6                                    r0 *= r6   ///  r0 = r0.wrapping_mul(r6)
    add64 r0, r8                                    r0 += r8   ///  r0 = r0.wrapping_add(r8)
    add64 r5, r4                                    r5 += r4   ///  r5 = r5.wrapping_add(r4)
    add64 r0, r9                                    r0 += r9   ///  r0 = r0.wrapping_add(r9)
    add64 r5, r0                                    r5 += r0   ///  r5 = r5.wrapping_add(r0)
    stxdw [r3+0x8], r5                      
    exit                                    

function_31344:
    mov64 r3, r2                                    r3 = r2
    mov64 r0, r1                                    r0 = r1
    mov64 r6, r3                                    r6 = r3
    xor64 r6, r0                                    r6 ^= r0   ///  r6 = r6.xor(r0)
    lddw r1, 0x8000000000000000                     r1 load str located at -9223372036854775808
    and64 r6, r1                                    r6 &= r1   ///  r6 = r6.and(r1)
    lddw r1, 0xfffffffffffff                        r1 load str located at 4503599627370495
    and64 r2, r1                                    r2 &= r1   ///  r2 = r2.and(r1)
    mov64 r4, r0                                    r4 = r0
    and64 r4, r1                                    r4 &= r1   ///  r4 = r4.and(r1)
    mov64 r7, r3                                    r7 = r3
    rsh64 r7, 52                                    r7 >>= 52   ///  r7 = r7.wrapping_shr(52)
    and64 r7, 2047                                  r7 &= 2047   ///  r7 = r7.and(2047)
    mov64 r8, r0                                    r8 = r0
    rsh64 r8, 52                                    r8 >>= 52   ///  r8 = r8.wrapping_shr(52)
    and64 r8, 2047                                  r8 &= 2047   ///  r8 = r8.and(2047)
    mov64 r5, r8                                    r5 = r8
    add64 r5, -2047                                 r5 += -2047   ///  r5 = r5.wrapping_add(-2047 as i32 as i64 as u64)
    mov64 r1, -2046                                 r1 = -2046 as i32 as i64 as u64
    jgt r1, r5, lbb_31405                           if r1 > r5 { pc += 39 }
    mov64 r9, 0                                     r9 = 0 as i32 as i64 as u64
    mov64 r5, r7                                    r5 = r7
    add64 r5, -2047                                 r5 += -2047   ///  r5 = r5.wrapping_add(-2047 as i32 as i64 as u64)
    jgt r1, r5, lbb_31405                           if r1 > r5 { pc += 35 }
lbb_31370:
    stxdw [r10-0x18], r6                    
    lsh64 r2, 11                                    r2 <<= 11   ///  r2 = r2.wrapping_shl(11)
    lddw r1, 0x8000000000000000                     r1 load str located at -9223372036854775808
    or64 r2, r1                                     r2 |= r1   ///  r2 = r2.or(r1)
    lddw r6, 0x10000000000000                       r6 load str located at 4503599627370496
    or64 r4, r6                                     r4 |= r6   ///  r4 = r4.or(r6)
    mov64 r1, r10                                   r1 = r10
    add64 r1, -16                                   r1 += -16   ///  r1 = r1.wrapping_add(-16 as i32 as i64 as u64)
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
    mov64 r5, 0                                     r5 = 0 as i32 as i64 as u64
    call function_31300                     
    add64 r7, r8                                    r7 += r8   ///  r7 = r7.wrapping_add(r8)
    add64 r7, r9                                    r7 += r9   ///  r7 = r7.wrapping_add(r9)
    ldxdw r2, [r10-0x8]                     
    mov64 r3, r2                                    r3 = r2
    and64 r3, r6                                    r3 &= r6   ///  r3 = r3.and(r6)
    ldxdw r1, [r10-0x10]                    
    jeq r3, 0, lbb_31391                            if r3 == (0 as i32 as i64 as u64) { pc += 1 }
    ja lbb_31421                                    if true { pc += 30 }
lbb_31391:
    lsh64 r2, 1                                     r2 <<= 1   ///  r2 = r2.wrapping_shl(1)
    mov64 r3, r1                                    r3 = r1
    rsh64 r3, 63                                    r3 >>= 63   ///  r3 = r3.wrapping_shr(63)
    or64 r2, r3                                     r2 |= r3   ///  r2 = r2.or(r3)
    lsh64 r1, 1                                     r1 <<= 1   ///  r1 = r1.wrapping_shl(1)
    add64 r7, -1023                                 r7 += -1023   ///  r7 = r7.wrapping_add(-1023 as i32 as i64 as u64)
    ldxdw r5, [r10-0x18]                    
    jsgt r7, 2046, lbb_31400                        if (r7 as i64) > (2046 as i32 as i64) { pc += 1 }
    ja lbb_31424                                    if true { pc += 24 }
lbb_31400:
    lddw r1, 0x7ff0000000000000                     r1 load str located at 9218868437227405312
    or64 r5, r1                                     r5 |= r1   ///  r5 = r5.or(r1)
    mov64 r0, r5                                    r0 = r5
    ja lbb_31482                                    if true { pc += 77 }
lbb_31405:
    lddw r9, 0x7fffffffffffffff                     r9 load str located at 9223372036854775807
    mov64 r5, r0                                    r5 = r0
    and64 r5, r9                                    r5 &= r9   ///  r5 = r5.and(r9)
    lddw r1, 0x7ff0000000000000                     r1 load str located at 9218868437227405312
    jgt r5, r1, lbb_31432                           if r5 > r1 { pc += 20 }
    mov64 r0, r3                                    r0 = r3
    and64 r0, r9                                    r0 &= r9   ///  r0 = r0.and(r9)
    jgt r0, r1, lbb_31416                           if r0 > r1 { pc += 1 }
    ja lbb_31436                                    if true { pc += 20 }
lbb_31416:
    lddw r1, 0x8000000000000                        r1 load str located at 2251799813685248
    or64 r3, r1                                     r3 |= r1   ///  r3 = r3.or(r1)
    mov64 r0, r3                                    r0 = r3
    ja lbb_31482                                    if true { pc += 61 }
lbb_31421:
    add64 r7, -1022                                 r7 += -1022   ///  r7 = r7.wrapping_add(-1022 as i32 as i64 as u64)
    ldxdw r5, [r10-0x18]                    
    jsgt r7, 2046, lbb_31400                        if (r7 as i64) > (2046 as i32 as i64) { pc += -24 }
lbb_31424:
    mov64 r3, 1                                     r3 = 1 as i32 as i64 as u64
    jsgt r3, r7, lbb_31445                          if (r3 as i64) > (r7 as i64) { pc += 19 }
    lddw r3, 0xfffffffffffff                        r3 load str located at 4503599627370495
    and64 r2, r3                                    r2 &= r3   ///  r2 = r2.and(r3)
    lsh64 r7, 52                                    r7 <<= 52   ///  r7 = r7.wrapping_shl(52)
    or64 r7, r2                                     r7 |= r2   ///  r7 = r7.or(r2)
    ja lbb_31471                                    if true { pc += 39 }
lbb_31432:
    lddw r1, 0x8000000000000                        r1 load str located at 2251799813685248
    or64 r0, r1                                     r0 |= r1   ///  r0 = r0.or(r1)
    ja lbb_31482                                    if true { pc += 46 }
lbb_31436:
    jeq r5, r1, lbb_31438                           if r5 == r1 { pc += 1 }
    ja lbb_31450                                    if true { pc += 12 }
lbb_31438:
    mov64 r1, r0                                    r1 = r0
    lddw r0, 0x7ff8000000000000                     r0 load str located at 9221120237041090560
    jeq r1, 0, lbb_31482                            if r1 == (0 as i32 as i64 as u64) { pc += 40 }
    lddw r1, 0x7ff0000000000000                     r1 load str located at 9218868437227405312
    ja lbb_31455                                    if true { pc += 10 }
lbb_31445:
    sub64 r3, r7                                    r3 -= r7   ///  r3 = r3.wrapping_sub(r7)
    jgt r3, 63, lbb_31448                           if r3 > (63 as i32 as i64 as u64) { pc += 1 }
    ja lbb_31458                                    if true { pc += 10 }
lbb_31448:
    mov64 r0, r5                                    r0 = r5
    ja lbb_31482                                    if true { pc += 32 }
lbb_31450:
    jeq r0, r1, lbb_31452                           if r0 == r1 { pc += 1 }
    ja lbb_31483                                    if true { pc += 31 }
lbb_31452:
    lddw r0, 0x7ff8000000000000                     r0 load str located at 9221120237041090560
    jeq r5, 0, lbb_31482                            if r5 == (0 as i32 as i64 as u64) { pc += 27 }
lbb_31455:
    or64 r6, r1                                     r6 |= r1   ///  r6 = r6.or(r1)
lbb_31456:
    mov64 r0, r6                                    r0 = r6
    ja lbb_31482                                    if true { pc += 24 }
lbb_31458:
    add64 r7, 63                                    r7 += 63   ///  r7 = r7.wrapping_add(63 as i32 as i64 as u64)
    lsh64 r7, 32                                    r7 <<= 32   ///  r7 = r7.wrapping_shl(32)
    rsh64 r7, 32                                    r7 >>= 32   ///  r7 = r7.wrapping_shr(32)
    mov64 r4, r2                                    r4 = r2
    or64 r4, r1                                     r4 |= r1   ///  r4 = r4.or(r1)
    lsh64 r4, r7                                    r4 <<= r7   ///  r4 = r4.wrapping_shl(r7 as u32)
    lsh64 r3, 32                                    r3 <<= 32   ///  r3 = r3.wrapping_shl(32)
    rsh64 r3, 32                                    r3 >>= 32   ///  r3 = r3.wrapping_shr(32)
    rsh64 r1, r3                                    r1 >>= r3   ///  r1 = r1.wrapping_shr(r3 as u32)
    or64 r4, r1                                     r4 |= r1   ///  r4 = r4.or(r1)
    rsh64 r2, r3                                    r2 >>= r3   ///  r2 = r2.wrapping_shr(r3 as u32)
    mov64 r1, r4                                    r1 = r4
    mov64 r7, r2                                    r7 = r2
lbb_31471:
    mov64 r0, r7                                    r0 = r7
    or64 r0, r5                                     r0 |= r5   ///  r0 = r0.or(r5)
    lddw r2, 0x8000000000000000                     r2 load str located at -9223372036854775808
    jgt r1, r2, lbb_31477                           if r1 > r2 { pc += 1 }
    ja lbb_31479                                    if true { pc += 2 }
lbb_31477:
    add64 r0, 1                                     r0 += 1   ///  r0 = r0.wrapping_add(1 as i32 as i64 as u64)
    ja lbb_31482                                    if true { pc += 3 }
lbb_31479:
    jne r1, r2, lbb_31482                           if r1 != r2 { pc += 2 }
    and64 r7, 1                                     r7 &= 1   ///  r7 = r7.and(1)
    add64 r0, r7                                    r0 += r7   ///  r0 = r0.wrapping_add(r7)
lbb_31482:
    exit                                    
lbb_31483:
    jeq r5, 0, lbb_31456                            if r5 == (0 as i32 as i64 as u64) { pc += -28 }
    jeq r0, 0, lbb_31456                            if r0 == (0 as i32 as i64 as u64) { pc += -29 }
    mov64 r9, 0                                     r9 = 0 as i32 as i64 as u64
    lddw r1, 0x10000000000000                       r1 load str located at 4503599627370496
    jgt r1, r5, lbb_31490                           if r1 > r5 { pc += 1 }
    ja lbb_31540                                    if true { pc += 50 }
lbb_31490:
    mov64 r5, 64                                    r5 = 64 as i32 as i64 as u64
    jeq r4, 0, lbb_31535                            if r4 == (0 as i32 as i64 as u64) { pc += 43 }
    mov64 r1, r4                                    r1 = r4
    rsh64 r1, 1                                     r1 >>= 1   ///  r1 = r1.wrapping_shr(1)
    mov64 r3, r4                                    r3 = r4
    or64 r3, r1                                     r3 |= r1   ///  r3 = r3.or(r1)
    mov64 r1, r3                                    r1 = r3
    rsh64 r1, 2                                     r1 >>= 2   ///  r1 = r1.wrapping_shr(2)
    or64 r3, r1                                     r3 |= r1   ///  r3 = r3.or(r1)
    mov64 r1, r3                                    r1 = r3
    rsh64 r1, 4                                     r1 >>= 4   ///  r1 = r1.wrapping_shr(4)
    or64 r3, r1                                     r3 |= r1   ///  r3 = r3.or(r1)
    mov64 r1, r3                                    r1 = r3
    rsh64 r1, 8                                     r1 >>= 8   ///  r1 = r1.wrapping_shr(8)
    or64 r3, r1                                     r3 |= r1   ///  r3 = r3.or(r1)
    mov64 r1, r3                                    r1 = r3
    rsh64 r1, 16                                    r1 >>= 16   ///  r1 = r1.wrapping_shr(16)
    or64 r3, r1                                     r3 |= r1   ///  r3 = r3.or(r1)
    mov64 r1, r3                                    r1 = r3
    rsh64 r1, 32                                    r1 >>= 32   ///  r1 = r1.wrapping_shr(32)
    or64 r3, r1                                     r3 |= r1   ///  r3 = r3.or(r1)
    xor64 r3, -1                                    r3 ^= -1   ///  r3 = r3.xor(-1)
    lddw r1, 0x5555555555555555                     r1 load str located at 6148914691236517205
    mov64 r5, r3                                    r5 = r3
    rsh64 r5, 1                                     r5 >>= 1   ///  r5 = r5.wrapping_shr(1)
    and64 r5, r1                                    r5 &= r1   ///  r5 = r5.and(r1)
    sub64 r3, r5                                    r3 -= r5   ///  r3 = r3.wrapping_sub(r5)
    lddw r1, 0x3333333333333333                     r1 load str located at 3689348814741910323
    mov64 r5, r3                                    r5 = r3
    and64 r5, r1                                    r5 &= r1   ///  r5 = r5.and(r1)
    rsh64 r3, 2                                     r3 >>= 2   ///  r3 = r3.wrapping_shr(2)
    and64 r3, r1                                    r3 &= r1   ///  r3 = r3.and(r1)
    add64 r5, r3                                    r5 += r3   ///  r5 = r5.wrapping_add(r3)
    mov64 r1, r5                                    r1 = r5
    rsh64 r1, 4                                     r1 >>= 4   ///  r1 = r1.wrapping_shr(4)
    add64 r5, r1                                    r5 += r1   ///  r5 = r5.wrapping_add(r1)
    lddw r1, 0xf0f0f0f0f0f0f0f                      r1 load str located at 1085102592571150095
    and64 r5, r1                                    r5 &= r1   ///  r5 = r5.and(r1)
    lddw r1, 0x101010101010101                      r1 load str located at 72340172838076673
    mul64 r5, r1                                    r5 *= r1   ///  r5 = r5.wrapping_mul(r1)
    rsh64 r5, 56                                    r5 >>= 56   ///  r5 = r5.wrapping_shr(56)
lbb_31535:
    mov64 r9, 12                                    r9 = 12 as i32 as i64 as u64
    sub64 r9, r5                                    r9 -= r5   ///  r9 = r9.wrapping_sub(r5)
    add64 r5, 53                                    r5 += 53   ///  r5 = r5.wrapping_add(53 as i32 as i64 as u64)
    and64 r5, 63                                    r5 &= 63   ///  r5 = r5.and(63)
    lsh64 r4, r5                                    r4 <<= r5   ///  r4 = r4.wrapping_shl(r5 as u32)
lbb_31540:
    lddw r1, 0xfffffffffffff                        r1 load str located at 4503599627370495
    jgt r0, r1, lbb_31370                           if r0 > r1 { pc += -173 }
    mov64 r3, 64                                    r3 = 64 as i32 as i64 as u64
    jeq r2, 0, lbb_31588                            if r2 == (0 as i32 as i64 as u64) { pc += 43 }
    mov64 r3, r2                                    r3 = r2
    rsh64 r3, 1                                     r3 >>= 1   ///  r3 = r3.wrapping_shr(1)
    mov64 r1, r2                                    r1 = r2
    or64 r1, r3                                     r1 |= r3   ///  r1 = r1.or(r3)
    mov64 r3, r1                                    r3 = r1
    rsh64 r3, 2                                     r3 >>= 2   ///  r3 = r3.wrapping_shr(2)
    or64 r1, r3                                     r1 |= r3   ///  r1 = r1.or(r3)
    mov64 r3, r1                                    r3 = r1
    rsh64 r3, 4                                     r3 >>= 4   ///  r3 = r3.wrapping_shr(4)
    or64 r1, r3                                     r1 |= r3   ///  r1 = r1.or(r3)
    mov64 r3, r1                                    r3 = r1
    rsh64 r3, 8                                     r3 >>= 8   ///  r3 = r3.wrapping_shr(8)
    or64 r1, r3                                     r1 |= r3   ///  r1 = r1.or(r3)
    mov64 r3, r1                                    r3 = r1
    rsh64 r3, 16                                    r3 >>= 16   ///  r3 = r3.wrapping_shr(16)
    or64 r1, r3                                     r1 |= r3   ///  r1 = r1.or(r3)
    mov64 r3, r1                                    r3 = r1
    rsh64 r3, 32                                    r3 >>= 32   ///  r3 = r3.wrapping_shr(32)
    or64 r1, r3                                     r1 |= r3   ///  r1 = r1.or(r3)
    xor64 r1, -1                                    r1 ^= -1   ///  r1 = r1.xor(-1)
    lddw r3, 0x5555555555555555                     r3 load str located at 6148914691236517205
    mov64 r5, r1                                    r5 = r1
    rsh64 r5, 1                                     r5 >>= 1   ///  r5 = r5.wrapping_shr(1)
    and64 r5, r3                                    r5 &= r3   ///  r5 = r5.and(r3)
    sub64 r1, r5                                    r1 -= r5   ///  r1 = r1.wrapping_sub(r5)
    lddw r5, 0x3333333333333333                     r5 load str located at 3689348814741910323
    mov64 r3, r1                                    r3 = r1
    and64 r3, r5                                    r3 &= r5   ///  r3 = r3.and(r5)
    rsh64 r1, 2                                     r1 >>= 2   ///  r1 = r1.wrapping_shr(2)
    and64 r1, r5                                    r1 &= r5   ///  r1 = r1.and(r5)
    add64 r3, r1                                    r3 += r1   ///  r3 = r3.wrapping_add(r1)
    mov64 r1, r3                                    r1 = r3
    rsh64 r1, 4                                     r1 >>= 4   ///  r1 = r1.wrapping_shr(4)
    add64 r3, r1                                    r3 += r1   ///  r3 = r3.wrapping_add(r1)
    lddw r1, 0xf0f0f0f0f0f0f0f                      r1 load str located at 1085102592571150095
    and64 r3, r1                                    r3 &= r1   ///  r3 = r3.and(r1)
    lddw r1, 0x101010101010101                      r1 load str located at 72340172838076673
    mul64 r3, r1                                    r3 *= r1   ///  r3 = r3.wrapping_mul(r1)
    rsh64 r3, 56                                    r3 >>= 56   ///  r3 = r3.wrapping_shr(56)
lbb_31588:
    sub64 r9, r3                                    r9 -= r3   ///  r9 = r9.wrapping_sub(r3)
    add64 r3, 53                                    r3 += 53   ///  r3 = r3.wrapping_add(53 as i32 as i64 as u64)
    and64 r3, 63                                    r3 &= 63   ///  r3 = r3.and(63)
    lsh64 r2, r3                                    r2 <<= r3   ///  r2 = r2.wrapping_shl(r3 as u32)
    add64 r9, 12                                    r9 += 12   ///  r9 = r9.wrapping_add(12 as i32 as i64 as u64)
    ja lbb_31370                                    if true { pc += -224 }

function_31594:
    lddw r0, 0xffffffff                             r0 load str located at 4294967295
    lddw r5, 0x7fffffffffffffff                     r5 load str located at 9223372036854775807
    mov64 r3, r1                                    r3 = r1
    and64 r3, r5                                    r3 &= r5   ///  r3 = r3.and(r5)
    lddw r6, 0x7ff0000000000000                     r6 load str located at 9218868437227405312
    jgt r3, r6, lbb_31625                           if r3 > r6 { pc += 22 }
    mov64 r4, r2                                    r4 = r2
    and64 r4, r5                                    r4 &= r5   ///  r4 = r4.and(r5)
    jgt r4, r6, lbb_31625                           if r4 > r6 { pc += 19 }
    or64 r4, r3                                     r4 |= r3   ///  r4 = r4.or(r3)
    mov64 r0, 0                                     r0 = 0 as i32 as i64 as u64
    jeq r4, 0, lbb_31625                            if r4 == (0 as i32 as i64 as u64) { pc += 16 }
    mov64 r3, r2                                    r3 = r2
    and64 r3, r1                                    r3 &= r1   ///  r3 = r3.and(r1)
    jsgt r3, -1, lbb_31618                          if (r3 as i64) > (-1 as i32 as i64) { pc += 6 }
    lddw r0, 0xffffffff                             r0 load str located at 4294967295
    jsgt r1, r2, lbb_31625                          if (r1 as i64) > (r2 as i64) { pc += 10 }
    mov64 r0, 1                                     r0 = 1 as i32 as i64 as u64
    jeq r1, r2, lbb_31624                           if r1 == r2 { pc += 7 }
    ja lbb_31625                                    if true { pc += 7 }
lbb_31618:
    lddw r0, 0xffffffff                             r0 load str located at 4294967295
    jsgt r2, r1, lbb_31625                          if (r2 as i64) > (r1 as i64) { pc += 4 }
    mov64 r0, 1                                     r0 = 1 as i32 as i64 as u64
    jeq r1, r2, lbb_31624                           if r1 == r2 { pc += 1 }
    ja lbb_31625                                    if true { pc += 1 }
lbb_31624:
    mov64 r0, 0                                     r0 = 0 as i32 as i64 as u64
lbb_31625:
    lsh64 r0, 32                                    r0 <<= 32   ///  r0 = r0.wrapping_shl(32)
    arsh64 r0, 32                                   r0 >>= 32 (signed)   ///  r0 = (r0 as i64).wrapping_shr(32)
    exit                                    

function_31628:
    lddw r0, 0xffffffff                             r0 load str located at 4294967295
    lddw r5, 0x7fffffffffffffff                     r5 load str located at 9223372036854775807
    mov64 r3, r1                                    r3 = r1
    and64 r3, r5                                    r3 &= r5   ///  r3 = r3.and(r5)
    lddw r6, 0x7ff0000000000000                     r6 load str located at 9218868437227405312
    jgt r3, r6, lbb_31659                           if r3 > r6 { pc += 22 }
    mov64 r4, r2                                    r4 = r2
    and64 r4, r5                                    r4 &= r5   ///  r4 = r4.and(r5)
    jgt r4, r6, lbb_31659                           if r4 > r6 { pc += 19 }
    or64 r4, r3                                     r4 |= r3   ///  r4 = r4.or(r3)
    mov64 r0, 0                                     r0 = 0 as i32 as i64 as u64
    jeq r4, 0, lbb_31659                            if r4 == (0 as i32 as i64 as u64) { pc += 16 }
    mov64 r3, r2                                    r3 = r2
    and64 r3, r1                                    r3 &= r1   ///  r3 = r3.and(r1)
    jsgt r3, -1, lbb_31652                          if (r3 as i64) > (-1 as i32 as i64) { pc += 6 }
    lddw r0, 0xffffffff                             r0 load str located at 4294967295
    jsgt r1, r2, lbb_31659                          if (r1 as i64) > (r2 as i64) { pc += 10 }
    mov64 r0, 1                                     r0 = 1 as i32 as i64 as u64
    jeq r1, r2, lbb_31658                           if r1 == r2 { pc += 7 }
    ja lbb_31659                                    if true { pc += 7 }
lbb_31652:
    lddw r0, 0xffffffff                             r0 load str located at 4294967295
    jsgt r2, r1, lbb_31659                          if (r2 as i64) > (r1 as i64) { pc += 4 }
    mov64 r0, 1                                     r0 = 1 as i32 as i64 as u64
    jeq r1, r2, lbb_31658                           if r1 == r2 { pc += 1 }
    ja lbb_31659                                    if true { pc += 1 }
lbb_31658:
    mov64 r0, 0                                     r0 = 0 as i32 as i64 as u64
lbb_31659:
    lsh64 r0, 32                                    r0 <<= 32   ///  r0 = r0.wrapping_shl(32)
    arsh64 r0, 32                                   r0 >>= 32 (signed)   ///  r0 = (r0 as i64).wrapping_shr(32)
    exit                                    

function_31662:
    mov64 r6, r2                                    r6 = r2
    mov64 r7, r1                                    r7 = r1
    arsh64 r1, 63                                   r1 >>= 63 (signed)   ///  r1 = (r1 as i64).wrapping_shr(63)
    mov64 r2, r7                                    r2 = r7
    xor64 r2, r1                                    r2 ^= r1   ///  r2 = r2.xor(r1)
    sub64 r2, r1                                    r2 -= r1   ///  r2 = r2.wrapping_sub(r1)
    mov64 r1, r6                                    r1 = r6
    arsh64 r1, 63                                   r1 >>= 63 (signed)   ///  r1 = (r1 as i64).wrapping_shr(63)
    mov64 r3, r6                                    r3 = r6
    xor64 r3, r1                                    r3 ^= r1   ///  r3 = r3.xor(r1)
    sub64 r3, r1                                    r3 -= r1   ///  r3 = r3.wrapping_sub(r1)
    mov64 r1, r10                                   r1 = r10
    add64 r1, -16                                   r1 += -16   ///  r1 = r1.wrapping_add(-16 as i32 as i64 as u64)
    call function_31155                     
    xor64 r6, r7                                    r6 ^= r7   ///  r6 = r6.xor(r7)
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
    ldxdw r1, [r10-0x10]                    
    mov64 r0, r1                                    r0 = r1
    neg64 r0                                        r0 = -r0   ///  r0 = (r0 as i64).wrapping_neg() as u64
    jsgt r2, r6, lbb_31683                          if (r2 as i64) > (r6 as i64) { pc += 1 }
    mov64 r0, r1                                    r0 = r1
lbb_31683:
    exit                                    

function_31684:
    mov64 r5, r4                                    r5 = r4
    and64 r5, 64                                    r5 &= 64   ///  r5 = r5.and(64)
    jne r5, 0, lbb_31699                            if r5 != (0 as i32 as i64 as u64) { pc += 12 }
    jeq r4, 0, lbb_31703                            if r4 == (0 as i32 as i64 as u64) { pc += 15 }
    mov64 r5, r4                                    r5 = r4
    and64 r5, 63                                    r5 &= 63   ///  r5 = r5.and(63)
    rsh64 r2, r5                                    r2 >>= r5   ///  r2 = r2.wrapping_shr(r5 as u32)
    neg64 r4                                        r4 = -r4   ///  r4 = (r4 as i64).wrapping_neg() as u64
    and64 r4, 63                                    r4 &= 63   ///  r4 = r4.and(63)
    mov64 r0, r3                                    r0 = r3
    lsh64 r0, r4                                    r0 <<= r4   ///  r0 = r0.wrapping_shl(r4 as u32)
    or64 r0, r2                                     r0 |= r2   ///  r0 = r0.or(r2)
    rsh64 r3, r5                                    r3 >>= r5   ///  r3 = r3.wrapping_shr(r5 as u32)
    mov64 r2, r0                                    r2 = r0
    ja lbb_31703                                    if true { pc += 4 }
lbb_31699:
    and64 r4, 63                                    r4 &= 63   ///  r4 = r4.and(63)
    rsh64 r3, r4                                    r3 >>= r4   ///  r3 = r3.wrapping_shr(r4 as u32)
    mov64 r2, r3                                    r2 = r3
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
lbb_31703:
    stxdw [r1+0x8], r3                      
    stxdw [r1+0x0], r2                      
    exit                                    

function_31706:
    mov64 r6, r1                                    r6 = r1
    mov64 r1, r10                                   r1 = r10
    add64 r1, -32                                   r1 += -32   ///  r1 = r1.wrapping_add(-32 as i32 as i64 as u64)
    call function_30505                     
    ldxdw r1, [r10-0x10]                    
    ldxdw r2, [r10-0x8]                     
    stxdw [r6+0x8], r2                      
    stxdw [r6+0x0], r1                      
    exit                                    

function_31715:
    mov64 r0, 0                                     r0 = 0 as i32 as i64 as u64
    jeq r1, 0, lbb_31777                            if r1 == (0 as i32 as i64 as u64) { pc += 60 }
    mov64 r3, r1                                    r3 = r1
    rsh64 r3, 1                                     r3 >>= 1   ///  r3 = r3.wrapping_shr(1)
    mov64 r2, r1                                    r2 = r1
    or64 r2, r3                                     r2 |= r3   ///  r2 = r2.or(r3)
    mov64 r3, r2                                    r3 = r2
    rsh64 r3, 2                                     r3 >>= 2   ///  r3 = r3.wrapping_shr(2)
    or64 r2, r3                                     r2 |= r3   ///  r2 = r2.or(r3)
    mov64 r3, r2                                    r3 = r2
    rsh64 r3, 4                                     r3 >>= 4   ///  r3 = r3.wrapping_shr(4)
    or64 r2, r3                                     r2 |= r3   ///  r2 = r2.or(r3)
    mov64 r3, r2                                    r3 = r2
    rsh64 r3, 8                                     r3 >>= 8   ///  r3 = r3.wrapping_shr(8)
    or64 r2, r3                                     r2 |= r3   ///  r2 = r2.or(r3)
    mov64 r3, r2                                    r3 = r2
    rsh64 r3, 16                                    r3 >>= 16   ///  r3 = r3.wrapping_shr(16)
    or64 r2, r3                                     r2 |= r3   ///  r2 = r2.or(r3)
    mov64 r3, r2                                    r3 = r2
    rsh64 r3, 32                                    r3 >>= 32   ///  r3 = r3.wrapping_shr(32)
    or64 r2, r3                                     r2 |= r3   ///  r2 = r2.or(r3)
    xor64 r2, -1                                    r2 ^= -1   ///  r2 = r2.xor(-1)
    lddw r3, 0x5555555555555555                     r3 load str located at 6148914691236517205
    mov64 r4, r2                                    r4 = r2
    rsh64 r4, 1                                     r4 >>= 1   ///  r4 = r4.wrapping_shr(1)
    and64 r4, r3                                    r4 &= r3   ///  r4 = r4.and(r3)
    sub64 r2, r4                                    r2 -= r4   ///  r2 = r2.wrapping_sub(r4)
    lddw r4, 0x3333333333333333                     r4 load str located at 3689348814741910323
    mov64 r3, r2                                    r3 = r2
    and64 r3, r4                                    r3 &= r4   ///  r3 = r3.and(r4)
    rsh64 r2, 2                                     r2 >>= 2   ///  r2 = r2.wrapping_shr(2)
    and64 r2, r4                                    r2 &= r4   ///  r2 = r2.and(r4)
    add64 r3, r2                                    r3 += r2   ///  r3 = r3.wrapping_add(r2)
    mov64 r2, r3                                    r2 = r3
    rsh64 r2, 4                                     r2 >>= 4   ///  r2 = r2.wrapping_shr(4)
    add64 r3, r2                                    r3 += r2   ///  r3 = r3.wrapping_add(r2)
    lddw r2, 0xf0f0f0f0f0f0f0f                      r2 load str located at 1085102592571150095
    and64 r3, r2                                    r3 &= r2   ///  r3 = r3.and(r2)
    lddw r2, 0x101010101010101                      r2 load str located at 72340172838076673
    mul64 r3, r2                                    r3 *= r2   ///  r3 = r3.wrapping_mul(r2)
    rsh64 r3, 56                                    r3 >>= 56   ///  r3 = r3.wrapping_shr(56)
    lsh64 r1, r3                                    r1 <<= r3   ///  r1 = r1.wrapping_shl(r3 as u32)
    lsh64 r3, 52                                    r3 <<= 52   ///  r3 = r3.wrapping_shl(52)
    mov64 r2, r1                                    r2 = r1
    rsh64 r2, 11                                    r2 >>= 11   ///  r2 = r2.wrapping_shr(11)
    mov64 r0, r2                                    r0 = r2
    sub64 r0, r3                                    r0 -= r3   ///  r0 = r0.wrapping_sub(r3)
    xor64 r2, -1                                    r2 ^= -1   ///  r2 = r2.xor(-1)
    lsh64 r1, 53                                    r1 <<= 53   ///  r1 = r1.wrapping_shl(53)
    mov64 r3, r1                                    r3 = r1
    rsh64 r3, 63                                    r3 >>= 63   ///  r3 = r3.wrapping_shr(63)
    and64 r3, r2                                    r3 &= r2   ///  r3 = r3.and(r2)
    sub64 r1, r3                                    r1 -= r3   ///  r1 = r1.wrapping_sub(r3)
    rsh64 r1, 63                                    r1 >>= 63   ///  r1 = r1.wrapping_shr(63)
    add64 r0, r1                                    r0 += r1   ///  r0 = r0.wrapping_add(r1)
    lddw r1, 0x43d0000000000000                     r1 load str located at 4886405595696988160
    add64 r0, r1                                    r0 += r1   ///  r0 = r0.wrapping_add(r1)
lbb_31777:
    exit                                    

function_31778:
    call function_31344                     
    exit                                    

function_31780:
    lddw r3, 0x7fffffffffffffff                     r3 load str located at 9223372036854775807
    and64 r1, r3                                    r1 &= r3   ///  r1 = r1.and(r3)
    and64 r2, r3                                    r2 &= r3   ///  r2 = r2.and(r3)
    mov64 r0, 1                                     r0 = 1 as i32 as i64 as u64
    lddw r4, 0x7ff0000000000000                     r4 load str located at 9218868437227405312
    mov64 r3, 1                                     r3 = 1 as i32 as i64 as u64
    jgt r2, r4, lbb_31790                           if r2 > r4 { pc += 1 }
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
lbb_31790:
    jgt r1, r4, lbb_31792                           if r1 > r4 { pc += 1 }
    mov64 r0, 0                                     r0 = 0 as i32 as i64 as u64
lbb_31792:
    or64 r0, r3                                     r0 |= r3   ///  r0 = r0.or(r3)
    exit                                    

function_31794:
    mov64 r0, 1                                     r0 = 1 as i32 as i64 as u64
    lddw r5, 0x7fffffffffffffff                     r5 load str located at 9223372036854775807
    mov64 r3, r1                                    r3 = r1
    and64 r3, r5                                    r3 &= r5   ///  r3 = r3.and(r5)
    lddw r6, 0x7ff0000000000000                     r6 load str located at 9218868437227405312
    jgt r3, r6, lbb_31824                           if r3 > r6 { pc += 22 }
    mov64 r4, r2                                    r4 = r2
    and64 r4, r5                                    r4 &= r5   ///  r4 = r4.and(r5)
    jgt r4, r6, lbb_31824                           if r4 > r6 { pc += 19 }
    or64 r4, r3                                     r4 |= r3   ///  r4 = r4.or(r3)
    mov64 r0, 0                                     r0 = 0 as i32 as i64 as u64
    jeq r4, 0, lbb_31824                            if r4 == (0 as i32 as i64 as u64) { pc += 16 }
    mov64 r3, r2                                    r3 = r2
    and64 r3, r1                                    r3 &= r1   ///  r3 = r3.and(r1)
    jsgt r3, -1, lbb_31817                          if (r3 as i64) > (-1 as i32 as i64) { pc += 6 }
    lddw r0, 0xffffffff                             r0 load str located at 4294967295
    jsgt r1, r2, lbb_31824                          if (r1 as i64) > (r2 as i64) { pc += 10 }
    mov64 r0, 1                                     r0 = 1 as i32 as i64 as u64
    jeq r1, r2, lbb_31823                           if r1 == r2 { pc += 7 }
    ja lbb_31824                                    if true { pc += 7 }
lbb_31817:
    lddw r0, 0xffffffff                             r0 load str located at 4294967295
    jsgt r2, r1, lbb_31824                          if (r2 as i64) > (r1 as i64) { pc += 4 }
    mov64 r0, 1                                     r0 = 1 as i32 as i64 as u64
    jeq r1, r2, lbb_31823                           if r1 == r2 { pc += 1 }
    ja lbb_31824                                    if true { pc += 1 }
lbb_31823:
    mov64 r0, 0                                     r0 = 0 as i32 as i64 as u64
lbb_31824:
    lsh64 r0, 32                                    r0 <<= 32   ///  r0 = r0.wrapping_shl(32)
    arsh64 r0, 32                                   r0 >>= 32 (signed)   ///  r0 = (r0 as i64).wrapping_shr(32)
    exit                                    

function_31827:
    mov64 r5, r4                                    r5 = r4
    and64 r5, 64                                    r5 &= 64   ///  r5 = r5.and(64)
    jne r5, 0, lbb_31841                            if r5 != (0 as i32 as i64 as u64) { pc += 11 }
    jeq r4, 0, lbb_31845                            if r4 == (0 as i32 as i64 as u64) { pc += 14 }
    mov64 r5, r4                                    r5 = r4
    and64 r5, 63                                    r5 &= 63   ///  r5 = r5.and(63)
    lsh64 r3, r5                                    r3 <<= r5   ///  r3 = r3.wrapping_shl(r5 as u32)
    neg64 r4                                        r4 = -r4   ///  r4 = (r4 as i64).wrapping_neg() as u64
    and64 r4, 63                                    r4 &= 63   ///  r4 = r4.and(63)
    mov64 r0, r2                                    r0 = r2
    rsh64 r0, r4                                    r0 >>= r4   ///  r0 = r0.wrapping_shr(r4 as u32)
    or64 r3, r0                                     r3 |= r0   ///  r3 = r3.or(r0)
    lsh64 r2, r5                                    r2 <<= r5   ///  r2 = r2.wrapping_shl(r5 as u32)
    ja lbb_31845                                    if true { pc += 4 }
lbb_31841:
    and64 r4, 63                                    r4 &= 63   ///  r4 = r4.and(63)
    mov64 r3, r2                                    r3 = r2
    lsh64 r3, r4                                    r3 <<= r4   ///  r3 = r3.wrapping_shl(r4 as u32)
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
lbb_31845:
    stxdw [r1+0x8], r3                      
    stxdw [r1+0x0], r2                      
    exit                                    
