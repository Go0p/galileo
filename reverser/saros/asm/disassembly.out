function_0:
    lddw r0, 0x6436232572d50cba                     r0 load str located at 7220997696282496186
    exit                                    

function_3:
    lddw r1, 0x10002d960 --> b"\x00\x00\x00\x00\x98\xc3\x02\x00\x0b\x00\x00\x00\x00\x00\x00\x00\x0a\x00\…        r1 load str located at 4295154016
    stxdw [r10-0x10], r1                    
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    stxb [r10-0x8], r1                      
    stxdw [r10-0x18], r1                    
    lddw r1, 0x10002d900 --> b"\x00\x00\x00\x00x\x02\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x01\x00\x00…        r1 load str located at 4295153920
    stxdw [r10-0x20], r1                    
    lddw r1, 0x10002c350 --> b") when slicing `already borrowedrange end index al"        r1 load str located at 4295148368
    stxdw [r10-0x28], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -40                                   r1 += -40   ///  r1 = r1.wrapping_add(-40 as i32 as i64 as u64)
    call function_18571                     
    syscall [invalid]                       
    mov64 r6, r2                                    r6 = r2
    ldxdw r7, [r1+0x0]                      
    mov64 r1, r6                                    r1 = r6
    call function_20532                     
    jne r0, 0, lbb_32                               if r0 != (0 as i32 as i64 as u64) { pc += 8 }
    mov64 r1, r6                                    r1 = r6
    call function_20536                     
    jne r0, 0, lbb_28                               if r0 != (0 as i32 as i64 as u64) { pc += 1 }
    ja lbb_36                                       if true { pc += 8 }
lbb_28:
    mov64 r1, r7                                    r1 = r7
    mov64 r2, r6                                    r2 = r6
    call function_21427                     
    ja lbb_39                                       if true { pc += 7 }
lbb_32:
    mov64 r1, r7                                    r1 = r7
    mov64 r2, r6                                    r2 = r6
    call function_21384                     
    ja lbb_39                                       if true { pc += 3 }
lbb_36:
    mov64 r1, r7                                    r1 = r7
    mov64 r2, r6                                    r2 = r6
    call function_21644                     
lbb_39:
    exit                                    

function_40:
    ldxdw r1, [r1+0x0]                      
    call function_19200                     
    exit                                    

function_43:
    exit                                    

function_44:
    mov64 r6, r1                                    r6 = r1
    ldxdw r1, [r6+0x138]                    
    ldxdw r2, [r1+0x0]                      
    ldxdw r1, [r6+0x130]                    
    callx r2                                
    ldxdw r3, [r6+0x138]                    
    ldxdw r2, [r3+0x8]                      
    jeq r2, 0, lbb_55                               if r2 == (0 as i32 as i64 as u64) { pc += 3 }
    ldxdw r1, [r6+0x130]                    
    ldxdw r3, [r3+0x10]                     
    call function_11637                     
lbb_55:
    exit                                    

function_56:
    mov64 r6, r1                                    r6 = r1
    ldxdw r1, [r6+0x8]                      
    ldxdw r2, [r1+0x0]                      
    add64 r2, -1                                    r2 += -1   ///  r2 = r2.wrapping_add(-1 as i32 as i64 as u64)
    stxdw [r1+0x0], r2                      
    jne r2, 0, lbb_69                               if r2 != (0 as i32 as i64 as u64) { pc += 7 }
    ldxdw r2, [r1+0x8]                      
    add64 r2, -1                                    r2 += -1   ///  r2 = r2.wrapping_add(-1 as i32 as i64 as u64)
    stxdw [r1+0x8], r2                      
    jne r2, 0, lbb_69                               if r2 != (0 as i32 as i64 as u64) { pc += 3 }
    mov64 r2, 32                                    r2 = 32 as i32 as i64 as u64
    mov64 r3, 8                                     r3 = 8 as i32 as i64 as u64
    call function_11637                     
lbb_69:
    ldxdw r1, [r6+0x10]                     
    ldxdw r2, [r1+0x0]                      
    add64 r2, -1                                    r2 += -1   ///  r2 = r2.wrapping_add(-1 as i32 as i64 as u64)
    stxdw [r1+0x0], r2                      
    jne r2, 0, lbb_81                               if r2 != (0 as i32 as i64 as u64) { pc += 7 }
    ldxdw r2, [r1+0x8]                      
    add64 r2, -1                                    r2 += -1   ///  r2 = r2.wrapping_add(-1 as i32 as i64 as u64)
    stxdw [r1+0x8], r2                      
    jne r2, 0, lbb_81                               if r2 != (0 as i32 as i64 as u64) { pc += 3 }
    mov64 r2, 40                                    r2 = 40 as i32 as i64 as u64
    mov64 r3, 8                                     r3 = 8 as i32 as i64 as u64
    call function_11637                     
lbb_81:
    exit                                    

function_82:
    mov64 r6, r1                                    r6 = r1
    ldxdw r1, [r6+0x8]                      
    ldxdw r2, [r1+0x0]                      
    ldxdw r1, [r6+0x0]                      
    callx r2                                
    ldxdw r3, [r6+0x8]                      
    ldxdw r2, [r3+0x8]                      
    jeq r2, 0, lbb_93                               if r2 == (0 as i32 as i64 as u64) { pc += 3 }
    ldxdw r1, [r6+0x0]                      
    ldxdw r3, [r3+0x10]                     
    call function_11637                     
lbb_93:
    exit                                    

function_94:
    mov64 r6, r1                                    r6 = r1
    ldxdw r1, [r6+0x8]                      
    ldxdw r2, [r1+0x0]                      
    add64 r2, -1                                    r2 += -1   ///  r2 = r2.wrapping_add(-1 as i32 as i64 as u64)
    stxdw [r1+0x0], r2                      
    jne r2, 0, lbb_107                              if r2 != (0 as i32 as i64 as u64) { pc += 7 }
    ldxdw r2, [r1+0x8]                      
    add64 r2, -1                                    r2 += -1   ///  r2 = r2.wrapping_add(-1 as i32 as i64 as u64)
    stxdw [r1+0x8], r2                      
    jne r2, 0, lbb_107                              if r2 != (0 as i32 as i64 as u64) { pc += 3 }
    mov64 r2, 32                                    r2 = 32 as i32 as i64 as u64
    mov64 r3, 8                                     r3 = 8 as i32 as i64 as u64
    call function_11637                     
lbb_107:
    ldxdw r1, [r6+0x10]                     
    ldxdw r2, [r1+0x0]                      
    add64 r2, -1                                    r2 += -1   ///  r2 = r2.wrapping_add(-1 as i32 as i64 as u64)
    stxdw [r1+0x0], r2                      
    jne r2, 0, lbb_119                              if r2 != (0 as i32 as i64 as u64) { pc += 7 }
    ldxdw r2, [r1+0x8]                      
    add64 r2, -1                                    r2 += -1   ///  r2 = r2.wrapping_add(-1 as i32 as i64 as u64)
    stxdw [r1+0x8], r2                      
    jne r2, 0, lbb_119                              if r2 != (0 as i32 as i64 as u64) { pc += 3 }
    mov64 r2, 40                                    r2 = 40 as i32 as i64 as u64
    mov64 r3, 8                                     r3 = 8 as i32 as i64 as u64
    call function_11637                     
lbb_119:
    ldxdw r1, [r6+0x38]                     
    ldxdw r2, [r1+0x0]                      
    add64 r2, -1                                    r2 += -1   ///  r2 = r2.wrapping_add(-1 as i32 as i64 as u64)
    stxdw [r1+0x0], r2                      
    jne r2, 0, lbb_131                              if r2 != (0 as i32 as i64 as u64) { pc += 7 }
    ldxdw r2, [r1+0x8]                      
    add64 r2, -1                                    r2 += -1   ///  r2 = r2.wrapping_add(-1 as i32 as i64 as u64)
    stxdw [r1+0x8], r2                      
    jne r2, 0, lbb_131                              if r2 != (0 as i32 as i64 as u64) { pc += 3 }
    mov64 r2, 32                                    r2 = 32 as i32 as i64 as u64
    mov64 r3, 8                                     r3 = 8 as i32 as i64 as u64
    call function_11637                     
lbb_131:
    ldxdw r1, [r6+0x40]                     
    ldxdw r2, [r1+0x0]                      
    add64 r2, -1                                    r2 += -1   ///  r2 = r2.wrapping_add(-1 as i32 as i64 as u64)
    stxdw [r1+0x0], r2                      
    jne r2, 0, lbb_143                              if r2 != (0 as i32 as i64 as u64) { pc += 7 }
    ldxdw r2, [r1+0x8]                      
    add64 r2, -1                                    r2 += -1   ///  r2 = r2.wrapping_add(-1 as i32 as i64 as u64)
    stxdw [r1+0x8], r2                      
    jne r2, 0, lbb_143                              if r2 != (0 as i32 as i64 as u64) { pc += 3 }
    mov64 r2, 40                                    r2 = 40 as i32 as i64 as u64
    mov64 r3, 8                                     r3 = 8 as i32 as i64 as u64
    call function_11637                     
lbb_143:
    ldxdw r1, [r6+0x68]                     
    ldxdw r2, [r1+0x0]                      
    add64 r2, -1                                    r2 += -1   ///  r2 = r2.wrapping_add(-1 as i32 as i64 as u64)
    stxdw [r1+0x0], r2                      
    jne r2, 0, lbb_155                              if r2 != (0 as i32 as i64 as u64) { pc += 7 }
    ldxdw r2, [r1+0x8]                      
    add64 r2, -1                                    r2 += -1   ///  r2 = r2.wrapping_add(-1 as i32 as i64 as u64)
    stxdw [r1+0x8], r2                      
    jne r2, 0, lbb_155                              if r2 != (0 as i32 as i64 as u64) { pc += 3 }
    mov64 r2, 32                                    r2 = 32 as i32 as i64 as u64
    mov64 r3, 8                                     r3 = 8 as i32 as i64 as u64
    call function_11637                     
lbb_155:
    ldxdw r1, [r6+0x70]                     
    ldxdw r2, [r1+0x0]                      
    add64 r2, -1                                    r2 += -1   ///  r2 = r2.wrapping_add(-1 as i32 as i64 as u64)
    stxdw [r1+0x0], r2                      
    jne r2, 0, lbb_167                              if r2 != (0 as i32 as i64 as u64) { pc += 7 }
    ldxdw r2, [r1+0x8]                      
    add64 r2, -1                                    r2 += -1   ///  r2 = r2.wrapping_add(-1 as i32 as i64 as u64)
    stxdw [r1+0x8], r2                      
    jne r2, 0, lbb_167                              if r2 != (0 as i32 as i64 as u64) { pc += 3 }
    mov64 r2, 40                                    r2 = 40 as i32 as i64 as u64
    mov64 r3, 8                                     r3 = 8 as i32 as i64 as u64
    call function_11637                     
lbb_167:
    ldxdw r1, [r6+0x98]                     
    ldxdw r2, [r1+0x0]                      
    add64 r2, -1                                    r2 += -1   ///  r2 = r2.wrapping_add(-1 as i32 as i64 as u64)
    stxdw [r1+0x0], r2                      
    jne r2, 0, lbb_179                              if r2 != (0 as i32 as i64 as u64) { pc += 7 }
    ldxdw r2, [r1+0x8]                      
    add64 r2, -1                                    r2 += -1   ///  r2 = r2.wrapping_add(-1 as i32 as i64 as u64)
    stxdw [r1+0x8], r2                      
    jne r2, 0, lbb_179                              if r2 != (0 as i32 as i64 as u64) { pc += 3 }
    mov64 r2, 32                                    r2 = 32 as i32 as i64 as u64
    mov64 r3, 8                                     r3 = 8 as i32 as i64 as u64
    call function_11637                     
lbb_179:
    ldxdw r1, [r6+0xa0]                     
    ldxdw r2, [r1+0x0]                      
    add64 r2, -1                                    r2 += -1   ///  r2 = r2.wrapping_add(-1 as i32 as i64 as u64)
    stxdw [r1+0x0], r2                      
    jne r2, 0, lbb_191                              if r2 != (0 as i32 as i64 as u64) { pc += 7 }
    ldxdw r2, [r1+0x8]                      
    add64 r2, -1                                    r2 += -1   ///  r2 = r2.wrapping_add(-1 as i32 as i64 as u64)
    stxdw [r1+0x8], r2                      
    jne r2, 0, lbb_191                              if r2 != (0 as i32 as i64 as u64) { pc += 3 }
    mov64 r2, 40                                    r2 = 40 as i32 as i64 as u64
    mov64 r3, 8                                     r3 = 8 as i32 as i64 as u64
    call function_11637                     
lbb_191:
    exit                                    

function_192:
    ldxdw r3, [r2+0x0]                      
    jeq r3, 0, lbb_205                              if r3 == (0 as i32 as i64 as u64) { pc += 11 }
    mov64 r3, r10                                   r3 = r10
    add64 r3, -8                                    r3 += -8   ///  r3 = r3.wrapping_add(-8 as i32 as i64 as u64)
    lddw r1, 0x10002c360 --> b"already borrowed"        r1 load str located at 4295148384
    mov64 r2, 16                                    r2 = 16 as i32 as i64 as u64
    lddw r4, 0x10002d920 --> b"\x00\x00\x00\x00x\x02\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x01\x00\x00…        r4 load str located at 4295153952
    lddw r5, 0x10002dca0 --> b"\x00\x00\x00\x00\x15\xc4\x02\x00\x18\x00\x00\x00\x00\x00\x00\x00C\x01\x00…        r5 load str located at 4295154848
    call function_19366                     
    syscall [invalid]                       
lbb_205:
    mov64 r3, -1                                    r3 = -1 as i32 as i64 as u64
    stxdw [r2+0x0], r3                      
    stxdw [r1+0x8], r2                      
    add64 r2, 8                                     r2 += 8   ///  r2 = r2.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r1+0x0], r2                      
    exit                                    

function_211:
    mov64 r5, r3                                    r5 = r3
    ldxdw r3, [r2+0x0]                      
    lddw r4, 0x7fffffffffffffff                     r4 load str located at 9223372036854775807
    jgt r4, r3, lbb_225                             if r4 > r3 { pc += 9 }
    mov64 r3, r10                                   r3 = r10
    add64 r3, -8                                    r3 += -8   ///  r3 = r3.wrapping_add(-8 as i32 as i64 as u64)
    lddw r1, 0x10002c380 --> b"already mutably borrowed"        r1 load str located at 4295148416
    mov64 r2, 24                                    r2 = 24 as i32 as i64 as u64
    lddw r4, 0x10002d940 --> b"\x00\x00\x00\x00x\x02\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x01\x00\x00…        r4 load str located at 4295153984
    call function_19366                     
    syscall [invalid]                       
lbb_225:
    add64 r3, 1                                     r3 += 1   ///  r3 = r3.wrapping_add(1 as i32 as i64 as u64)
    stxdw [r2+0x0], r3                      
    stxdw [r1+0x8], r2                      
    add64 r2, 8                                     r2 += 8   ///  r2 = r2.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r1+0x0], r2                      
    exit                                    

function_231:
    ldxdw r3, [r2+0x8]                      
    ldxdw r4, [r3+0x0]                      
    mov64 r6, r4                                    r6 = r4
    add64 r6, 1                                     r6 += 1   ///  r6 = r6.wrapping_add(1 as i32 as i64 as u64)
    mov64 r7, 1                                     r7 = 1 as i32 as i64 as u64
    jgt r4, r6, lbb_238                             if r4 > r6 { pc += 1 }
    mov64 r7, 0                                     r7 = 0 as i32 as i64 as u64
lbb_238:
    ldxb r0, [r2+0x29]                      
    ldxb r5, [r2+0x28]                      
    ldxdw r4, [r2+0x0]                      
    stxdw [r3+0x0], r6                      
    jne r7, 1, lbb_245                              if r7 != (1 as i32 as i64 as u64) { pc += 2 }
lbb_243:
    syscall [invalid]                       
    syscall [invalid]                       
lbb_245:
    ldxdw r6, [r2+0x10]                     
    ldxdw r9, [r6+0x0]                      
    mov64 r7, r9                                    r7 = r9
    add64 r7, 1                                     r7 += 1   ///  r7 = r7.wrapping_add(1 as i32 as i64 as u64)
    mov64 r8, 1                                     r8 = 1 as i32 as i64 as u64
    jgt r9, r7, lbb_252                             if r9 > r7 { pc += 1 }
    mov64 r8, 0                                     r8 = 0 as i32 as i64 as u64
lbb_252:
    stxdw [r6+0x0], r7                      
    jne r8, 1, lbb_255                              if r8 != (1 as i32 as i64 as u64) { pc += 1 }
    ja lbb_243                                      if true { pc += -12 }
lbb_255:
    ldxdw r7, [r2+0x20]                     
    ldxdw r8, [r2+0x18]                     
    ldxb r2, [r2+0x2a]                      
    stxb [r1+0x29], r0                      
    stxb [r1+0x28], r5                      
    stxdw [r1+0x0], r4                      
    stxb [r1+0x2a], r2                      
    stxdw [r1+0x18], r8                     
    stxdw [r1+0x10], r6                     
    stxdw [r1+0x8], r3                      
    stxdw [r1+0x20], r7                     
    exit                                    

function_267:
    ldxdw r4, [r3+0x0]                      
    ldxdw r2, [r2+0x20]                     
    ldxdw r5, [r2+0x0]                      
    jgt r5, r4, lbb_292                             if r5 > r4 { pc += 21 }
    ldxdw r4, [r2+0x8]                      
    ldxdw r5, [r3+0x8]                      
    jne r5, r4, lbb_292                             if r5 != r4 { pc += 18 }
    ldxdw r4, [r3+0x10]                     
    ldxdw r5, [r2+0x10]                     
    jgt r5, r4, lbb_292                             if r5 > r4 { pc += 15 }
    ldxdw r4, [r2+0x18]                     
    ldxdw r5, [r3+0x18]                     
    jne r5, r4, lbb_292                             if r5 != r4 { pc += 12 }
    ldxdw r4, [r3+0x20]                     
    ldxdw r5, [r2+0x20]                     
    jgt r5, r4, lbb_292                             if r5 > r4 { pc += 9 }
    ldxdw r4, [r2+0x28]                     
    ldxdw r5, [r3+0x28]                     
    jne r5, r4, lbb_292                             if r5 != r4 { pc += 6 }
    ldxdw r4, [r2+0x30]                     
    ldxdw r5, [r3+0x30]                     
    jne r5, r4, lbb_292                             if r5 != r4 { pc += 3 }
    ldxdw r2, [r2+0x38]                     
    ldxdw r3, [r3+0x38]                     
    jeq r3, r2, lbb_296                             if r3 == r2 { pc += 4 }
lbb_292:
    lddw r2, 0x1700000000                           r2 load str located at 98784247808
    stxdw [r1+0x0], r2                      
lbb_295:
    exit                                    
lbb_296:
    mov64 r2, 20                                    r2 = 20 as i32 as i64 as u64
    stxw [r1+0x0], r2                       
    ja lbb_295                                      if true { pc += -4 }

function_299:
    stxdw [r10-0xd8], r2                    
    stxdw [r10-0xa0], r1                    
    mov64 r9, 0                                     r9 = 0 as i32 as i64 as u64
    mov64 r0, 0                                     r0 = 0 as i32 as i64 as u64
    stxdw [r10-0x90], r4                    
    stxdw [r10-0x98], r3                    
    ldxdw r2, [r5-0xfe8]                    
    ldxdw r1, [r5-0xff0]                    
    stxdw [r10-0xd0], r1                    
    ldxdw r1, [r5-0xff8]                    
    stxdw [r10-0xc0], r1                    
    ldxdw r1, [r5-0x1000]                   
    stxdw [r10-0xc8], r1                    
    ldxdw r1, [r5-0xfe0]                    
    stxdw [r10-0xe0], r1                    
    ldxdw r7, [r5-0xfd8]                    
    ldxdw r6, [r7+0x0]                      
    mov64 r5, 0                                     r5 = 0 as i32 as i64 as u64
    stxdw [r10-0xa8], r2                    
    jeq r6, 0, lbb_379                              if r6 == (0 as i32 as i64 as u64) { pc += 60 }
    mov64 r1, r3                                    r1 = r3
    or64 r1, r4                                     r1 |= r4   ///  r1 = r1.or(r4)
    mov64 r5, 0                                     r5 = 0 as i32 as i64 as u64
    jeq r1, 0, lbb_379                              if r1 == (0 as i32 as i64 as u64) { pc += 56 }
    stxdw [r10-0xb8], r3                    
    stxdw [r10-0xb0], r4                    
    ldxdw r9, [r7+0x8]                      
    mov64 r1, r10                                   r1 = r10
    add64 r1, -72                                   r1 += -72   ///  r1 = r1.wrapping_add(-72 as i32 as i64 as u64)
    mov64 r8, 0                                     r8 = 0 as i32 as i64 as u64
    ldxdw r2, [r10-0x90]                    
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
    mov64 r4, r6                                    r4 = r6
    mov64 r5, 0                                     r5 = 0 as i32 as i64 as u64
    call function_21911                     
    mov64 r1, r10                                   r1 = r10
    add64 r1, -56                                   r1 += -56   ///  r1 = r1.wrapping_add(-56 as i32 as i64 as u64)
    ldxdw r2, [r10-0x98]                    
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
    mov64 r4, r6                                    r4 = r6
    mov64 r5, 0                                     r5 = 0 as i32 as i64 as u64
    call function_21911                     
    mov64 r2, 1                                     r2 = 1 as i32 as i64 as u64
    ldxdw r3, [r10-0x40]                    
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    jne r3, 0, lbb_346                              if r3 != (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
lbb_346:
    ldxdw r3, [r10-0x30]                    
    ldxdw r4, [r10-0x48]                    
    mov64 r6, r3                                    r6 = r3
    add64 r6, r4                                    r6 += r4   ///  r6 = r6.wrapping_add(r4)
    jgt r3, r6, lbb_352                             if r3 > r6 { pc += 1 }
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
lbb_352:
    or64 r1, r2                                     r1 |= r2   ///  r1 = r1.or(r2)
    and64 r1, 1                                     r1 &= 1   ///  r1 = r1.and(1)
    jne r1, 0, lbb_540                              if r1 != (0 as i32 as i64 as u64) { pc += 185 }
    jeq r9, 0, lbb_540                              if r9 == (0 as i32 as i64 as u64) { pc += 184 }
    ldxdw r8, [r10-0x38]                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -88                                   r1 += -88   ///  r1 = r1.wrapping_add(-88 as i32 as i64 as u64)
    mov64 r2, r8                                    r2 = r8
    mov64 r3, r6                                    r3 = r6
    mov64 r4, r9                                    r4 = r9
    mov64 r5, 0                                     r5 = 0 as i32 as i64 as u64
    call function_21948                     
    mov64 r0, 1                                     r0 = 1 as i32 as i64 as u64
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    jgt r9, r8, lbb_368                             if r9 > r8 { pc += 1 }
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
lbb_368:
    ldxdw r2, [r10-0xa8]                    
    mov64 r9, 0                                     r9 = 0 as i32 as i64 as u64
    jeq r6, 0, lbb_372                              if r6 == (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
lbb_372:
    mov64 r5, 0                                     r5 = 0 as i32 as i64 as u64
    ldxdw r4, [r10-0xb0]                    
    ldxdw r3, [r10-0xb8]                    
    jne r1, 0, lbb_377                              if r1 != (0 as i32 as i64 as u64) { pc += 1 }
    ldxdw r5, [r10-0x50]                    
lbb_377:
    jne r1, 0, lbb_379                              if r1 != (0 as i32 as i64 as u64) { pc += 1 }
    ldxdw r0, [r10-0x58]                    
lbb_379:
    ldxdw r6, [r7+0x10]                     
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
    stxdw [r10-0xe8], r0                    
    stxdw [r10-0xf0], r5                    
    jeq r6, 0, lbb_444                              if r6 == (0 as i32 as i64 as u64) { pc += 60 }
    mov64 r1, r3                                    r1 = r3
    or64 r1, r4                                     r1 |= r4   ///  r1 = r1.or(r4)
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
    jeq r1, 0, lbb_444                              if r1 == (0 as i32 as i64 as u64) { pc += 56 }
    stxdw [r10-0xb8], r3                    
    stxdw [r10-0xb0], r4                    
    ldxdw r7, [r7+0x18]                     
    mov64 r1, r10                                   r1 = r10
    add64 r1, -120                                  r1 += -120   ///  r1 = r1.wrapping_add(-120 as i32 as i64 as u64)
    mov64 r8, 0                                     r8 = 0 as i32 as i64 as u64
    ldxdw r2, [r10-0x90]                    
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
    mov64 r4, r6                                    r4 = r6
    mov64 r5, 0                                     r5 = 0 as i32 as i64 as u64
    call function_21911                     
    mov64 r1, r10                                   r1 = r10
    add64 r1, -104                                  r1 += -104   ///  r1 = r1.wrapping_add(-104 as i32 as i64 as u64)
    ldxdw r2, [r10-0x98]                    
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
    mov64 r4, r6                                    r4 = r6
    mov64 r5, 0                                     r5 = 0 as i32 as i64 as u64
    call function_21911                     
    mov64 r2, 1                                     r2 = 1 as i32 as i64 as u64
    ldxdw r3, [r10-0x70]                    
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    jne r3, 0, lbb_411                              if r3 != (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
lbb_411:
    ldxdw r3, [r10-0x60]                    
    ldxdw r4, [r10-0x78]                    
    mov64 r6, r3                                    r6 = r3
    add64 r6, r4                                    r6 += r4   ///  r6 = r6.wrapping_add(r4)
    jgt r3, r6, lbb_417                             if r3 > r6 { pc += 1 }
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
lbb_417:
    or64 r1, r2                                     r1 |= r2   ///  r1 = r1.or(r2)
    and64 r1, 1                                     r1 &= 1   ///  r1 = r1.and(1)
    jne r1, 0, lbb_540                              if r1 != (0 as i32 as i64 as u64) { pc += 120 }
    jeq r7, 0, lbb_540                              if r7 == (0 as i32 as i64 as u64) { pc += 119 }
    ldxdw r8, [r10-0x68]                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -136                                  r1 += -136   ///  r1 = r1.wrapping_add(-136 as i32 as i64 as u64)
    mov64 r2, r8                                    r2 = r8
    mov64 r3, r6                                    r3 = r6
    mov64 r4, r7                                    r4 = r7
    mov64 r5, 0                                     r5 = 0 as i32 as i64 as u64
    call function_21948                     
    mov64 r9, 1                                     r9 = 1 as i32 as i64 as u64
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    jgt r7, r8, lbb_433                             if r7 > r8 { pc += 1 }
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
lbb_433:
    ldxdw r0, [r10-0xe8]                    
    jeq r6, 0, lbb_436                              if r6 == (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
lbb_436:
    ldxdw r5, [r10-0xf0]                    
    ldxdw r4, [r10-0xb0]                    
    ldxdw r3, [r10-0xb8]                    
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
    jne r1, 0, lbb_442                              if r1 != (0 as i32 as i64 as u64) { pc += 1 }
    ldxdw r2, [r10-0x80]                    
lbb_442:
    jne r1, 0, lbb_444                              if r1 != (0 as i32 as i64 as u64) { pc += 1 }
    ldxdw r9, [r10-0x88]                    
lbb_444:
    stxdw [r10-0xb0], r2                    
    mov64 r7, r0                                    r7 = r0
    add64 r7, r9                                    r7 += r9   ///  r7 = r7.wrapping_add(r9)
    mov64 r2, 1                                     r2 = 1 as i32 as i64 as u64
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    jgt r0, r7, lbb_451                             if r0 > r7 { pc += 1 }
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
lbb_451:
    mov64 r6, r5                                    r6 = r5
    ldxdw r8, [r10-0xb0]                    
    add64 r6, r8                                    r6 += r8   ///  r6 = r6.wrapping_add(r8)
    add64 r6, r1                                    r6 += r1   ///  r6 = r6.wrapping_add(r1)
    jgt r5, r6, lbb_457                             if r5 > r6 { pc += 1 }
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
lbb_457:
    jeq r6, r5, lbb_459                             if r6 == r5 { pc += 1 }
    mov64 r1, r2                                    r1 = r2
lbb_459:
    and64 r1, 1                                     r1 &= 1   ///  r1 = r1.and(1)
    mov64 r8, 0                                     r8 = 0 as i32 as i64 as u64
    jne r1, 0, lbb_540                              if r1 != (0 as i32 as i64 as u64) { pc += 78 }
    sub64 r4, r6                                    r4 -= r6   ///  r4 = r4.wrapping_sub(r6)
    mov64 r8, 0                                     r8 = 0 as i32 as i64 as u64
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    mov64 r2, 1                                     r2 = 1 as i32 as i64 as u64
    ldxdw r5, [r10-0x98]                    
    jgt r7, r5, lbb_469                             if r7 > r5 { pc += 1 }
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
lbb_469:
    sub64 r4, r2                                    r4 -= r2   ///  r4 = r4.wrapping_sub(r2)
    mov64 r5, r3                                    r5 = r3
    sub64 r5, r7                                    r5 -= r7   ///  r5 = r5.wrapping_sub(r7)
    mov64 r2, 1                                     r2 = 1 as i32 as i64 as u64
    mov64 r3, r5                                    r3 = r5
    ldxdw r0, [r10-0x98]                    
    jgt r5, r0, lbb_477                             if r5 > r0 { pc += 1 }
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
lbb_477:
    ldxdw r5, [r10-0x90]                    
    jgt r4, r5, lbb_480                             if r4 > r5 { pc += 1 }
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
lbb_480:
    ldxdw r5, [r10-0x90]                    
    jeq r4, r5, lbb_483                             if r4 == r5 { pc += 1 }
    mov64 r2, r1                                    r2 = r1
lbb_483:
    and64 r2, 1                                     r2 &= 1   ///  r2 = r2.and(1)
    jne r2, 0, lbb_540                              if r2 != (0 as i32 as i64 as u64) { pc += 55 }
    ldxdw r1, [r10-0xd8]                    
    ldxdw r2, [r1+0x8]                      
    ldxdw r1, [r1+0x10]                     
    ldxdw r0, [r1+0x30]                     
    ldxdw r1, [r10-0xa8]                    
    stxdw [r10-0xfe8], r1                   
    ldxdw r1, [r10-0xe0]                    
    stxdw [r10-0xfe0], r1                   
    ldxdw r1, [r10-0xd0]                    
    stxdw [r10-0xff0], r1                   
    ldxdw r1, [r10-0xc0]                    
    stxdw [r10-0xff8], r1                   
    ldxdw r1, [r10-0xc8]                    
    stxdw [r10-0x1000], r1                  
    mov64 r1, r10                                   r1 = r10
    add64 r1, -40                                   r1 += -40   ///  r1 = r1.wrapping_add(-40 as i32 as i64 as u64)
    mov64 r5, r10                                   r5 = r10
    callx r0                                
    ldxdw r1, [r10-0x28]                    
    jeq r1, 0, lbb_540                              if r1 == (0 as i32 as i64 as u64) { pc += 35 }
    ldxdw r2, [r10-0x20]                    
    mov64 r1, r2                                    r1 = r2
    add64 r1, r7                                    r1 += r7   ///  r1 = r1.wrapping_add(r7)
    mov64 r8, 0                                     r8 = 0 as i32 as i64 as u64
    mov64 r4, 1                                     r4 = 1 as i32 as i64 as u64
    mov64 r3, 1                                     r3 = 1 as i32 as i64 as u64
    jgt r2, r1, lbb_513                             if r2 > r1 { pc += 1 }
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
lbb_513:
    ldxdw r5, [r10-0x18]                    
    mov64 r2, r5                                    r2 = r5
    add64 r2, r6                                    r2 += r6   ///  r2 = r2.wrapping_add(r6)
    add64 r2, r3                                    r2 += r3   ///  r2 = r2.wrapping_add(r3)
    jgt r5, r2, lbb_519                             if r5 > r2 { pc += 1 }
    mov64 r4, 0                                     r4 = 0 as i32 as i64 as u64
lbb_519:
    jeq r2, r5, lbb_521                             if r2 == r5 { pc += 1 }
    mov64 r3, r4                                    r3 = r4
lbb_521:
    and64 r3, 1                                     r3 &= 1   ///  r3 = r3.and(1)
    jne r3, 0, lbb_540                              if r3 != (0 as i32 as i64 as u64) { pc += 17 }
    ldxdw r4, [r10-0xc8]                    
    mov64 r3, r4                                    r3 = r4
    add64 r3, r1                                    r3 += r1   ///  r3 = r3.wrapping_add(r1)
    mov64 r8, 0                                     r8 = 0 as i32 as i64 as u64
    mov64 r0, 1                                     r0 = 1 as i32 as i64 as u64
    mov64 r5, 1                                     r5 = 1 as i32 as i64 as u64
    jgt r4, r3, lbb_531                             if r4 > r3 { pc += 1 }
    mov64 r5, 0                                     r5 = 0 as i32 as i64 as u64
lbb_531:
    ldxdw r6, [r10-0xc0]                    
    mov64 r4, r6                                    r4 = r6
    add64 r4, r2                                    r4 += r2   ///  r4 = r4.wrapping_add(r2)
    add64 r4, r5                                    r4 += r5   ///  r4 = r4.wrapping_add(r5)
    jgt r6, r4, lbb_537                             if r6 > r4 { pc += 1 }
    mov64 r0, 0                                     r0 = 0 as i32 as i64 as u64
lbb_537:
    jeq r4, r6, lbb_539                             if r4 == r6 { pc += 1 }
    mov64 r5, r0                                    r5 = r0
lbb_539:
    jne r5, 1, lbb_543                              if r5 != (1 as i32 as i64 as u64) { pc += 3 }
lbb_540:
    ldxdw r1, [r10-0xa0]                    
    stxdw [r1+0x0], r8                      
    exit                                    
lbb_543:
    ldxdw r5, [r10-0x8]                     
    ldxdw r6, [r10-0x10]                    
    ldxdw r0, [r10-0xa8]                    
    stxdw [r10-0x98], r5                    
    sub64 r0, r5                                    r0 -= r5   ///  r0 = r0.wrapping_sub(r5)
    mov64 r8, 0                                     r8 = 0 as i32 as i64 as u64
    mov64 r5, 1                                     r5 = 1 as i32 as i64 as u64
    stxdw [r10-0x90], r5                    
    mov64 r7, 1                                     r7 = 1 as i32 as i64 as u64
    ldxdw r5, [r10-0xd0]                    
    jgt r6, r5, lbb_555                             if r6 > r5 { pc += 1 }
    mov64 r7, 0                                     r7 = 0 as i32 as i64 as u64
lbb_555:
    sub64 r0, r7                                    r0 -= r7   ///  r0 = r0.wrapping_sub(r7)
    mov64 r7, r5                                    r7 = r5
    stxdw [r10-0xb8], r6                    
    sub64 r7, r6                                    r7 -= r6   ///  r7 = r7.wrapping_sub(r6)
    mov64 r6, 1                                     r6 = 1 as i32 as i64 as u64
    jgt r7, r5, lbb_562                             if r7 > r5 { pc += 1 }
    mov64 r6, 0                                     r6 = 0 as i32 as i64 as u64
lbb_562:
    ldxdw r5, [r10-0xa8]                    
    jgt r0, r5, lbb_568                             if r0 > r5 { pc += 4 }
    stxdw [r10-0xc0], r7                    
    mov64 r7, 0                                     r7 = 0 as i32 as i64 as u64
    stxdw [r10-0x90], r7                    
    ldxdw r7, [r10-0xc0]                    
lbb_568:
    jeq r0, r5, lbb_570                             if r0 == r5 { pc += 1 }
    ldxdw r6, [r10-0x90]                    
lbb_570:
    and64 r6, 1                                     r6 &= 1   ///  r6 = r6.and(1)
    jne r6, 0, lbb_540                              if r6 != (0 as i32 as i64 as u64) { pc += -32 }
    ldxdw r5, [r10-0xa0]                    
    stxdw [r5+0x58], r9                     
    ldxdw r6, [r10-0xe8]                    
    stxdw [r5+0x48], r6                     
    ldxdw r6, [r10-0xb8]                    
    stxdw [r5+0x38], r6                     
    stxdw [r5+0x28], r1                     
    stxdw [r5+0x18], r7                     
    stxdw [r5+0x8], r3                      
    ldxdw r1, [r10-0xb0]                    
    stxdw [r5+0x60], r1                     
    ldxdw r1, [r10-0xf0]                    
    stxdw [r5+0x50], r1                     
    ldxdw r1, [r10-0x98]                    
    stxdw [r5+0x40], r1                     
    stxdw [r5+0x30], r2                     
    stxdw [r5+0x20], r0                     
    stxdw [r5+0x10], r4                     
    mov64 r8, 1                                     r8 = 1 as i32 as i64 as u64
    ja lbb_540                                      if true { pc += -52 }

function_592:
    mov64 r6, r5                                    r6 = r5
    mov64 r9, r1                                    r9 = r1
    ldxdw r0, [r2+0x8]                      
    ldxdw r1, [r2+0x10]                     
    ldxdw r7, [r1+0x38]                     
    ldxdw r1, [r6-0xfe0]                    
    stxdw [r10-0xfe0], r1                   
    ldxdw r8, [r6-0xfe8]                    
    stxdw [r10-0xfe8], r8                   
    ldxdw r1, [r6-0xff0]                    
    stxdw [r10-0xe8], r1                    
    stxdw [r10-0xff0], r1                   
    ldxdw r1, [r6-0xff8]                    
    stxdw [r10-0xd8], r1                    
    stxdw [r10-0xff8], r1                   
    ldxdw r1, [r6-0x1000]                   
    stxdw [r10-0xe0], r1                    
    stxdw [r10-0x1000], r1                  
    mov64 r1, r10                                   r1 = r10
    add64 r1, -56                                   r1 += -56   ///  r1 = r1.wrapping_add(-56 as i32 as i64 as u64)
    mov64 r5, r10                                   r5 = r10
    mov64 r2, r0                                    r2 = r0
    callx r7                                
    ldxdw r1, [r10-0x38]                    
    jeq r1, 0, lbb_835                              if r1 == (0 as i32 as i64 as u64) { pc += 218 }
    stxdw [r10-0xf0], r8                    
    ldxdw r8, [r6-0xfd8]                    
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    stxdw [r10-0xf8], r1                    
    ldxdw r1, [r10-0x18]                    
    stxdw [r10-0xd0], r1                    
    ldxdw r1, [r10-0x20]                    
    stxdw [r10-0x110], r1                   
    ldxdw r2, [r10-0x28]                    
    ldxdw r7, [r10-0x30]                    
    ldxdw r6, [r8+0x0]                      
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
    mov64 r4, 0                                     r4 = 0 as i32 as i64 as u64
    stxdw [r10-0xc0], r2                    
    jeq r6, 0, lbb_692                              if r6 == (0 as i32 as i64 as u64) { pc += 60 }
    mov64 r1, r7                                    r1 = r7
    or64 r1, r2                                     r1 |= r2   ///  r1 = r1.or(r2)
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
    mov64 r4, 0                                     r4 = 0 as i32 as i64 as u64
    jeq r1, 0, lbb_692                              if r1 == (0 as i32 as i64 as u64) { pc += 55 }
    stxdw [r10-0xc8], r9                    
    ldxdw r9, [r8+0x8]                      
    mov64 r1, r10                                   r1 = r10
    add64 r1, -88                                   r1 += -88   ///  r1 = r1.wrapping_add(-88 as i32 as i64 as u64)
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
    mov64 r4, r6                                    r4 = r6
    mov64 r5, 0                                     r5 = 0 as i32 as i64 as u64
    call function_21911                     
    mov64 r1, r10                                   r1 = r10
    add64 r1, -72                                   r1 += -72   ///  r1 = r1.wrapping_add(-72 as i32 as i64 as u64)
    stxdw [r10-0x108], r7                   
    mov64 r2, r7                                    r2 = r7
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
    mov64 r4, r6                                    r4 = r6
    mov64 r5, 0                                     r5 = 0 as i32 as i64 as u64
    call function_21911                     
    mov64 r2, 1                                     r2 = 1 as i32 as i64 as u64
    ldxdw r3, [r10-0x50]                    
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    jne r3, 0, lbb_658                              if r3 != (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
lbb_658:
    ldxdw r3, [r10-0x40]                    
    ldxdw r4, [r10-0x58]                    
    mov64 r6, r3                                    r6 = r3
    add64 r6, r4                                    r6 += r4   ///  r6 = r6.wrapping_add(r4)
    jgt r3, r6, lbb_664                             if r3 > r6 { pc += 1 }
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
lbb_664:
    or64 r1, r2                                     r1 |= r2   ///  r1 = r1.or(r2)
    and64 r1, 1                                     r1 &= 1   ///  r1 = r1.and(1)
    jne r1, 0, lbb_838                              if r1 != (0 as i32 as i64 as u64) { pc += 171 }
    jeq r9, 0, lbb_838                              if r9 == (0 as i32 as i64 as u64) { pc += 170 }
    ldxdw r1, [r10-0xd0]                    
    ldxdw r7, [r10-0x48]                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -104                                  r1 += -104   ///  r1 = r1.wrapping_add(-104 as i32 as i64 as u64)
    mov64 r2, r7                                    r2 = r7
    mov64 r3, r6                                    r3 = r6
    mov64 r4, r9                                    r4 = r9
    mov64 r5, 0                                     r5 = 0 as i32 as i64 as u64
    call function_21948                     
    mov64 r3, 1                                     r3 = 1 as i32 as i64 as u64
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    jgt r9, r7, lbb_681                             if r9 > r7 { pc += 1 }
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
lbb_681:
    ldxdw r2, [r10-0xd0]                    
    ldxdw r2, [r10-0xc0]                    
    ldxdw r7, [r10-0x108]                   
    jeq r6, 0, lbb_686                              if r6 == (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
lbb_686:
    ldxdw r9, [r10-0xc8]                    
    mov64 r4, 0                                     r4 = 0 as i32 as i64 as u64
    jne r1, 0, lbb_690                              if r1 != (0 as i32 as i64 as u64) { pc += 1 }
    ldxdw r4, [r10-0x60]                    
lbb_690:
    jne r1, 0, lbb_692                              if r1 != (0 as i32 as i64 as u64) { pc += 1 }
    ldxdw r3, [r10-0x68]                    
lbb_692:
    stxdw [r10-0x118], r3                   
    stxdw [r10-0x100], r4                   
    ldxdw r6, [r8+0x10]                     
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
    jeq r6, 0, lbb_757                              if r6 == (0 as i32 as i64 as u64) { pc += 60 }
    mov64 r1, r7                                    r1 = r7
    or64 r1, r2                                     r1 |= r2   ///  r1 = r1.or(r2)
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
    jeq r1, 0, lbb_757                              if r1 == (0 as i32 as i64 as u64) { pc += 56 }
    stxdw [r10-0xc8], r9                    
    ldxdw r9, [r8+0x18]                     
    mov64 r1, r10                                   r1 = r10
    add64 r1, -136                                  r1 += -136   ///  r1 = r1.wrapping_add(-136 as i32 as i64 as u64)
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
    mov64 r4, r6                                    r4 = r6
    mov64 r5, 0                                     r5 = 0 as i32 as i64 as u64
    call function_21911                     
    mov64 r1, r10                                   r1 = r10
    add64 r1, -120                                  r1 += -120   ///  r1 = r1.wrapping_add(-120 as i32 as i64 as u64)
    stxdw [r10-0x108], r7                   
    mov64 r2, r7                                    r2 = r7
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
    mov64 r4, r6                                    r4 = r6
    mov64 r5, 0                                     r5 = 0 as i32 as i64 as u64
    call function_21911                     
    mov64 r2, 1                                     r2 = 1 as i32 as i64 as u64
    ldxdw r3, [r10-0x80]                    
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    jne r3, 0, lbb_722                              if r3 != (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
lbb_722:
    ldxdw r3, [r10-0x70]                    
    ldxdw r4, [r10-0x88]                    
    mov64 r6, r3                                    r6 = r3
    add64 r6, r4                                    r6 += r4   ///  r6 = r6.wrapping_add(r4)
    jgt r3, r6, lbb_728                             if r3 > r6 { pc += 1 }
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
lbb_728:
    or64 r1, r2                                     r1 |= r2   ///  r1 = r1.or(r2)
    and64 r1, 1                                     r1 &= 1   ///  r1 = r1.and(1)
    jne r1, 0, lbb_838                              if r1 != (0 as i32 as i64 as u64) { pc += 107 }
    jeq r9, 0, lbb_838                              if r9 == (0 as i32 as i64 as u64) { pc += 106 }
    ldxdw r8, [r10-0xd0]                    
    ldxdw r7, [r10-0x78]                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -152                                  r1 += -152   ///  r1 = r1.wrapping_add(-152 as i32 as i64 as u64)
    mov64 r2, r7                                    r2 = r7
    mov64 r3, r6                                    r3 = r6
    mov64 r4, r9                                    r4 = r9
    mov64 r5, 0                                     r5 = 0 as i32 as i64 as u64
    call function_21948                     
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    stxdw [r10-0xf8], r1                    
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    jgt r9, r7, lbb_746                             if r9 > r7 { pc += 1 }
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
lbb_746:
    ldxdw r2, [r10-0xc0]                    
    ldxdw r7, [r10-0x108]                   
    jeq r6, 0, lbb_750                              if r6 == (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
lbb_750:
    ldxdw r9, [r10-0xc8]                    
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
    jne r1, 0, lbb_754                              if r1 != (0 as i32 as i64 as u64) { pc += 1 }
    ldxdw r3, [r10-0x90]                    
lbb_754:
    jne r1, 0, lbb_757                              if r1 != (0 as i32 as i64 as u64) { pc += 2 }
    ldxdw r1, [r10-0x98]                    
    stxdw [r10-0xf8], r1                    
lbb_757:
    mov64 r8, r3                                    r8 = r3
    mov64 r1, r10                                   r1 = r10
    add64 r1, -184                                  r1 += -184   ///  r1 = r1.wrapping_add(-184 as i32 as i64 as u64)
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
    mov64 r4, r7                                    r4 = r7
    mov64 r5, 0                                     r5 = 0 as i32 as i64 as u64
    mov64 r6, r7                                    r6 = r7
    call function_21911                     
    mov64 r1, r10                                   r1 = r10
    add64 r1, -168                                  r1 += -168   ///  r1 = r1.wrapping_add(-168 as i32 as i64 as u64)
    mov64 r2, r6                                    r2 = r6
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
    mov64 r4, r6                                    r4 = r6
    mov64 r5, 0                                     r5 = 0 as i32 as i64 as u64
    call function_21911                     
    mov64 r3, 1                                     r3 = 1 as i32 as i64 as u64
    mov64 r2, 1                                     r2 = 1 as i32 as i64 as u64
    ldxdw r1, [r10-0xc0]                    
    jne r1, 0, lbb_777                              if r1 != (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
lbb_777:
    ldxdw r1, [r10-0xb0]                    
    mov64 r4, 1                                     r4 = 1 as i32 as i64 as u64
    ldxdw r5, [r10-0xf0]                    
    jne r1, 0, lbb_782                              if r1 != (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r4, 0                                     r4 = 0 as i32 as i64 as u64
lbb_782:
    ldxdw r5, [r10-0xb8]                    
    add64 r5, r5                                    r5 += r5   ///  r5 = r5.wrapping_add(r5)
    ldxdw r0, [r10-0xa0]                    
    mov64 r1, r0                                    r1 = r0
    add64 r1, r5                                    r1 += r5   ///  r1 = r1.wrapping_add(r5)
    jgt r0, r1, lbb_789                             if r0 > r1 { pc += 1 }
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
lbb_789:
    or64 r2, r4                                     r2 |= r4   ///  r2 = r2.or(r4)
    or64 r2, r4                                     r2 |= r4   ///  r2 = r2.or(r4)
    or64 r2, r3                                     r2 |= r3   ///  r2 = r2.or(r3)
    and64 r2, 1                                     r2 &= 1   ///  r2 = r2.and(1)
    jne r2, 0, lbb_835                              if r2 != (0 as i32 as i64 as u64) { pc += 41 }
    ldxdw r0, [r10-0x118]                   
    mov64 r2, r0                                    r2 = r0
    ldxdw r3, [r10-0xf8]                    
    add64 r2, r3                                    r2 += r3   ///  r2 = r2.wrapping_add(r3)
    mov64 r5, 1                                     r5 = 1 as i32 as i64 as u64
    mov64 r4, 1                                     r4 = 1 as i32 as i64 as u64
    jgt r0, r2, lbb_802                             if r0 > r2 { pc += 1 }
    mov64 r4, 0                                     r4 = 0 as i32 as i64 as u64
lbb_802:
    ldxdw r0, [r10-0x100]                   
    mov64 r3, r0                                    r3 = r0
    add64 r3, r8                                    r3 += r8   ///  r3 = r3.wrapping_add(r8)
    add64 r3, r4                                    r3 += r4   ///  r3 = r3.wrapping_add(r4)
    jgt r0, r3, lbb_808                             if r0 > r3 { pc += 1 }
    mov64 r5, 0                                     r5 = 0 as i32 as i64 as u64
lbb_808:
    ldxdw r0, [r10-0xa8]                    
    ldxdw r6, [r10-0x100]                   
    jeq r3, r6, lbb_812                             if r3 == r6 { pc += 1 }
    mov64 r4, r5                                    r4 = r5
lbb_812:
    stxdw [r10-0x10], r0                    
    stxdw [r10-0x8], r1                     
    and64 r4, 1                                     r4 &= 1   ///  r4 = r4.and(1)
    jne r4, 0, lbb_835                              if r4 != (0 as i32 as i64 as u64) { pc += 19 }
    ldxdw r5, [r10-0xc0]                    
    mov64 r4, r5                                    r4 = r5
    sub64 r4, r3                                    r4 -= r3   ///  r4 = r4.wrapping_sub(r3)
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    mov64 r3, 1                                     r3 = 1 as i32 as i64 as u64
    mov64 r0, r7                                    r0 = r7
    jgt r2, r0, lbb_824                             if r2 > r0 { pc += 1 }
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
lbb_824:
    sub64 r4, r3                                    r4 -= r3   ///  r4 = r4.wrapping_sub(r3)
    mov64 r3, r0                                    r3 = r0
    sub64 r3, r2                                    r3 -= r2   ///  r3 = r3.wrapping_sub(r2)
    mov64 r2, 1                                     r2 = 1 as i32 as i64 as u64
    jgt r3, r0, lbb_830                             if r3 > r0 { pc += 1 }
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
lbb_830:
    jgt r4, r5, lbb_832                             if r4 > r5 { pc += 1 }
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
lbb_832:
    jeq r4, r5, lbb_834                             if r4 == r5 { pc += 1 }
    mov64 r2, r1                                    r2 = r1
lbb_834:
    jne r2, 1, lbb_842                              if r2 != (1 as i32 as i64 as u64) { pc += 7 }
lbb_835:
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    stxdw [r9+0x0], r1                      
    ja lbb_841                                      if true { pc += 3 }
lbb_838:
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    ldxdw r2, [r10-0xc8]                    
    stxdw [r2+0x0], r1                      
lbb_841:
    exit                                    
lbb_842:
    mov64 r1, r10                                   r1 = r10
    add64 r1, -56                                   r1 += -56   ///  r1 = r1.wrapping_add(-56 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -16                                   r2 += -16   ///  r2 = r2.wrapping_add(-16 as i32 as i64 as u64)
    call function_13303                     
    ldxdw r1, [r10-0x38]                    
    jeq r1, 0, lbb_835                              if r1 == (0 as i32 as i64 as u64) { pc += -14 }
    ldxdw r6, [r10-0x30]                    
    ldxdw r2, [r10-0xe0]                    
    mov64 r1, r2                                    r1 = r2
    add64 r1, r6                                    r1 += r6   ///  r1 = r1.wrapping_add(r6)
    mov64 r0, 1                                     r0 = 1 as i32 as i64 as u64
    mov64 r5, 1                                     r5 = 1 as i32 as i64 as u64
    jgt r2, r1, lbb_857                             if r2 > r1 { pc += 1 }
    mov64 r5, 0                                     r5 = 0 as i32 as i64 as u64
lbb_857:
    ldxdw r4, [r10-0x28]                    
    ldxdw r2, [r10-0xd8]                    
    mov64 r3, r2                                    r3 = r2
    add64 r3, r4                                    r3 += r4   ///  r3 = r3.wrapping_add(r4)
    add64 r3, r5                                    r3 += r5   ///  r3 = r3.wrapping_add(r5)
    jgt r2, r3, lbb_864                             if r2 > r3 { pc += 1 }
    mov64 r0, 0                                     r0 = 0 as i32 as i64 as u64
lbb_864:
    jeq r3, r2, lbb_866                             if r3 == r2 { pc += 1 }
    mov64 r5, r0                                    r5 = r0
lbb_866:
    and64 r5, 1                                     r5 &= 1   ///  r5 = r5.and(1)
    jne r5, 0, lbb_835                              if r5 != (0 as i32 as i64 as u64) { pc += -33 }
    stxdw [r10-0xc0], r6                    
    ldxdw r5, [r10-0xf0]                    
    ldxdw r2, [r10-0xd0]                    
    sub64 r5, r2                                    r5 -= r2   ///  r5 = r5.wrapping_sub(r2)
    mov64 r6, 1                                     r6 = 1 as i32 as i64 as u64
    mov64 r0, 1                                     r0 = 1 as i32 as i64 as u64
    ldxdw r7, [r10-0x110]                   
    ldxdw r2, [r10-0xe8]                    
    jgt r7, r2, lbb_878                             if r7 > r2 { pc += 1 }
    mov64 r0, 0                                     r0 = 0 as i32 as i64 as u64
lbb_878:
    sub64 r5, r0                                    r5 -= r0   ///  r5 = r5.wrapping_sub(r0)
    ldxdw r0, [r10-0xe8]                    
    mov64 r2, r0                                    r2 = r0
    ldxdw r7, [r10-0x110]                   
    sub64 r2, r7                                    r2 -= r7   ///  r2 = r2.wrapping_sub(r7)
    mov64 r7, 1                                     r7 = 1 as i32 as i64 as u64
    jgt r2, r0, lbb_886                             if r2 > r0 { pc += 1 }
    mov64 r7, 0                                     r7 = 0 as i32 as i64 as u64
lbb_886:
    ldxdw r0, [r10-0xf0]                    
    jgt r5, r0, lbb_889                             if r5 > r0 { pc += 1 }
    mov64 r6, 0                                     r6 = 0 as i32 as i64 as u64
lbb_889:
    ldxdw r0, [r10-0xf0]                    
    jeq r5, r0, lbb_892                             if r5 == r0 { pc += 1 }
    mov64 r7, r6                                    r7 = r6
lbb_892:
    and64 r7, 1                                     r7 &= 1   ///  r7 = r7.and(1)
    jne r7, 0, lbb_835                              if r7 != (0 as i32 as i64 as u64) { pc += -59 }
    ldxdw r0, [r10-0xf8]                    
    stxdw [r9+0x58], r0                     
    ldxdw r0, [r10-0x118]                   
    stxdw [r9+0x48], r0                     
    ldxdw r6, [r10-0x110]                   
    stxdw [r9+0x38], r6                     
    ldxdw r0, [r10-0xc0]                    
    stxdw [r9+0x28], r0                     
    stxdw [r9+0x18], r2                     
    stxdw [r9+0x8], r1                      
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    stxdw [r9+0x0], r1                      
    stxdw [r9+0x60], r8                     
    ldxdw r1, [r10-0x100]                   
    stxdw [r9+0x50], r1                     
    ldxdw r1, [r10-0xd0]                    
    stxdw [r9+0x40], r1                     
    stxdw [r9+0x30], r4                     
    stxdw [r9+0x20], r5                     
    stxdw [r9+0x10], r3                     
    ja lbb_841                                      if true { pc += -74 }

function_915:
    mov64 r7, r4                                    r7 = r4
    mov64 r0, r2                                    r0 = r2
    mov64 r8, r1                                    r8 = r1
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    mov64 r4, r3                                    r4 = r3
    or64 r4, r7                                     r4 |= r7   ///  r4 = r4.or(r7)
    mov64 r6, 1                                     r6 = 1 as i32 as i64 as u64
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
    jeq r4, 0, lbb_1066                             if r4 == (0 as i32 as i64 as u64) { pc += 142 }
    stxdw [r10-0x50], r7                    
    mov64 r4, r3                                    r4 = r3
    ldxdw r1, [r5-0xfd8]                    
    stxdw [r10-0x90], r1                    
    ldxdw r1, [r5-0xfe0]                    
    stxdw [r10-0x88], r1                    
    ldxdw r1, [r5-0xfe8]                    
    stxdw [r10-0x80], r1                    
    ldxdw r1, [r5-0xff0]                    
    stxdw [r10-0x78], r1                    
    ldxdw r1, [r5-0xff8]                    
    stxdw [r10-0x70], r1                    
    ldxdw r1, [r5-0x1000]                   
    stxdw [r10-0x68], r1                    
    ldxdw r1, [r5-0xfc8]                    
    ldxdw r2, [r5-0xfd0]                    
    stxdw [r10-0x98], r2                    
    ldxdw r9, [r1+0x0]                      
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
    mov64 r5, 0                                     r5 = 0 as i32 as i64 as u64
    jeq r9, 0, lbb_1025                             if r9 == (0 as i32 as i64 as u64) { pc += 80 }
    stxdw [r10-0xa0], r8                    
    mov64 r6, 0                                     r6 = 0 as i32 as i64 as u64
    mov64 r8, 1                                     r8 = 1 as i32 as i64 as u64
    stxdw [r10-0xb0], r4                    
    jgt r4, 1, lbb_951                              if r4 > (1 as i32 as i64 as u64) { pc += 1 }
    mov64 r8, 0                                     r8 = 0 as i32 as i64 as u64
lbb_951:
    mov64 r2, 1                                     r2 = 1 as i32 as i64 as u64
    ldxdw r4, [r10-0x50]                    
    jne r4, 0, lbb_955                              if r4 != (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
lbb_955:
    jeq r4, 0, lbb_957                              if r4 == (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r8, r2                                    r8 = r2
lbb_957:
    stxdw [r10-0xa8], r0                    
    stxdw [r10-0x58], r3                    
    mov64 r2, r7                                    r2 = r7
    rsh64 r2, 1                                     r2 >>= 1   ///  r2 = r2.wrapping_shr(1)
    jne r8, 0, lbb_963                              if r8 != (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
lbb_963:
    ldxdw r1, [r1+0x8]                      
    stxdw [r10-0x60], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -32                                   r1 += -32   ///  r1 = r1.wrapping_add(-32 as i32 as i64 as u64)
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
    mov64 r4, r9                                    r4 = r9
    mov64 r5, 0                                     r5 = 0 as i32 as i64 as u64
    call function_21911                     
    ldxdw r2, [r10-0x58]                    
    rsh64 r2, 1                                     r2 >>= 1   ///  r2 = r2.wrapping_shr(1)
    mov64 r1, r7                                    r1 = r7
    lsh64 r1, 63                                    r1 <<= 63   ///  r1 = r1.wrapping_shl(63)
    or64 r2, r1                                     r2 |= r1   ///  r2 = r2.or(r1)
    jne r8, 0, lbb_978                              if r8 != (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r2, 1                                     r2 = 1 as i32 as i64 as u64
lbb_978:
    mov64 r1, r10                                   r1 = r10
    add64 r1, -16                                   r1 += -16   ///  r1 = r1.wrapping_add(-16 as i32 as i64 as u64)
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
    mov64 r4, r9                                    r4 = r9
    mov64 r5, 0                                     r5 = 0 as i32 as i64 as u64
    call function_21911                     
    ldxdw r1, [r10-0x18]                    
    mov64 r3, 1                                     r3 = 1 as i32 as i64 as u64
    jne r1, 0, lbb_988                              if r1 != (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
lbb_988:
    ldxdw r1, [r10-0x20]                    
    ldxdw r2, [r10-0x8]                     
    mov64 r9, r2                                    r9 = r2
    add64 r9, r1                                    r9 += r1   ///  r9 = r9.wrapping_add(r1)
    ldxdw r8, [r10-0xa0]                    
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    jgt r2, r9, lbb_996                             if r2 > r9 { pc += 1 }
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
lbb_996:
    or64 r3, r1                                     r3 |= r1   ///  r3 = r3.or(r1)
    and64 r3, 1                                     r3 &= 1   ///  r3 = r3.and(1)
    jne r3, 0, lbb_1066                             if r3 != (0 as i32 as i64 as u64) { pc += 67 }
    ldxdw r3, [r10-0x60]                    
    jeq r3, 0, lbb_1066                             if r3 == (0 as i32 as i64 as u64) { pc += 65 }
    ldxdw r2, [r10-0x10]                    
    stxdw [r10-0xb8], r2                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -48                                   r1 += -48   ///  r1 = r1.wrapping_add(-48 as i32 as i64 as u64)
    mov64 r3, r9                                    r3 = r9
    ldxdw r6, [r10-0x60]                    
    mov64 r4, r6                                    r4 = r6
    mov64 r5, 0                                     r5 = 0 as i32 as i64 as u64
    call function_21948                     
    mov64 r2, 1                                     r2 = 1 as i32 as i64 as u64
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    ldxdw r3, [r10-0xb8]                    
    jgt r6, r3, lbb_1015                            if r6 > r3 { pc += 1 }
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
lbb_1015:
    ldxdw r4, [r10-0xb0]                    
    jeq r9, 0, lbb_1018                             if r9 == (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
lbb_1018:
    ldxdw r3, [r10-0x58]                    
    ldxdw r0, [r10-0xa8]                    
    mov64 r5, 0                                     r5 = 0 as i32 as i64 as u64
    jne r1, 0, lbb_1023                             if r1 != (0 as i32 as i64 as u64) { pc += 1 }
    ldxdw r5, [r10-0x28]                    
lbb_1023:
    jne r1, 0, lbb_1025                             if r1 != (0 as i32 as i64 as u64) { pc += 1 }
    ldxdw r2, [r10-0x30]                    
lbb_1025:
    add64 r3, r2                                    r3 += r2   ///  r3 = r3.wrapping_add(r2)
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    mov64 r2, r4                                    r2 = r4
    mov64 r4, 1                                     r4 = 1 as i32 as i64 as u64
    jgt r2, r3, lbb_1031                            if r2 > r3 { pc += 1 }
    mov64 r4, 0                                     r4 = 0 as i32 as i64 as u64
lbb_1031:
    add64 r7, r5                                    r7 += r5   ///  r7 = r7.wrapping_add(r5)
    add64 r7, r4                                    r7 += r4   ///  r7 = r7.wrapping_add(r4)
    ldxdw r2, [r10-0x50]                    
    jgt r2, r7, lbb_1036                            if r2 > r7 { pc += 1 }
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
lbb_1036:
    jeq r7, r2, lbb_1038                            if r7 == r2 { pc += 1 }
    mov64 r4, r1                                    r4 = r1
lbb_1038:
    and64 r4, 1                                     r4 &= 1   ///  r4 = r4.and(1)
    mov64 r6, 0                                     r6 = 0 as i32 as i64 as u64
    jne r4, 0, lbb_1066                             if r4 != (0 as i32 as i64 as u64) { pc += 25 }
    ldxdw r2, [r0+0x8]                      
    ldxdw r1, [r0+0x10]                     
    ldxdw r0, [r1+0x58]                     
    ldxdw r1, [r10-0x90]                    
    stxdw [r10-0xfd8], r1                   
    ldxdw r1, [r10-0x98]                    
    stxdw [r10-0xfd0], r1                   
    ldxdw r1, [r10-0x88]                    
    stxdw [r10-0xfe0], r1                   
    ldxdw r1, [r10-0x80]                    
    stxdw [r10-0xfe8], r1                   
    ldxdw r1, [r10-0x78]                    
    stxdw [r10-0xff0], r1                   
    ldxdw r1, [r10-0x70]                    
    stxdw [r10-0xff8], r1                   
    ldxdw r1, [r10-0x68]                    
    stxdw [r10-0x1000], r1                  
    mov64 r1, r10                                   r1 = r10
    add64 r1, -72                                   r1 += -72   ///  r1 = r1.wrapping_add(-72 as i32 as i64 as u64)
    mov64 r5, r10                                   r5 = r10
    mov64 r4, r7                                    r4 = r7
    callx r0                                
    ldxdw r2, [r10-0x38]                    
    ldxdw r1, [r10-0x40]                    
    ldxdw r6, [r10-0x48]                    
lbb_1066:
    stxdw [r8+0x8], r1                      
    stxdw [r8+0x0], r6                      
    stxdw [r8+0x10], r2                     
    exit                                    

function_1070:
    mov64 r6, r1                                    r6 = r1
    jgt r3, 32, lbb_1078                            if r3 > (32 as i32 as i64 as u64) { pc += 6 }
    mov64 r1, 33                                    r1 = 33 as i32 as i64 as u64
    mov64 r2, r3                                    r2 = r3
    lddw r3, 0x10002da18 --> b"\x00\x00\x00\x00\xa3\xc3\x02\x00\x19\x00\x00\x00\x00\x00\x00\x00\x0c\x01\…        r3 load str located at 4295154200
    call function_20726                     
    syscall [invalid]                       
lbb_1078:
    ldxb r4, [r2+0x0]                       
    jsgt r4, 1, lbb_1096                            if (r4 as i64) > (1 as i32 as i64) { pc += 16 }
    lddw r1, 0x10002d998 --> b"\x00"                r1 load str located at 4295154072
    mov64 r0, 1                                     r0 = 1 as i32 as i64 as u64
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
    jeq r4, 0, lbb_1124                             if r4 == (0 as i32 as i64 as u64) { pc += 39 }
    jeq r4, 1, lbb_1087                             if r4 == (1 as i32 as i64 as u64) { pc += 1 }
    ja lbb_1098                                     if true { pc += 11 }
lbb_1087:
    ldxdw r7, [r2+0x1]                      
    mov64 r1, 8                                     r1 = 8 as i32 as i64 as u64
    mov64 r2, 8                                     r2 = 8 as i32 as i64 as u64
    call function_11635                     
    lddw r1, 0x10002db90 --> b"\x00"                r1 load str located at 4295154576
    mov64 r3, 1                                     r3 = 1 as i32 as i64 as u64
    jne r0, 0, lbb_1123                             if r0 != (0 as i32 as i64 as u64) { pc += 28 }
    ja lbb_1119                                     if true { pc += 23 }
lbb_1096:
    jeq r4, 2, lbb_1102                             if r4 == (2 as i32 as i64 as u64) { pc += 5 }
    jeq r4, 3, lbb_1111                             if r4 == (3 as i32 as i64 as u64) { pc += 13 }
lbb_1098:
    mov64 r1, 3                                     r1 = 3 as i32 as i64 as u64
    stxw [r6+0x8], r1                       
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    ja lbb_1128                                     if true { pc += 26 }
lbb_1102:
    ldxdw r7, [r2+0x1]                      
    mov64 r1, 8                                     r1 = 8 as i32 as i64 as u64
    mov64 r2, 8                                     r2 = 8 as i32 as i64 as u64
    call function_11635                     
    lddw r1, 0x10002daf0 --> b"\x00\x00"            r1 load str located at 4295154416
    mov64 r3, 2                                     r3 = 2 as i32 as i64 as u64
    jne r0, 0, lbb_1123                             if r0 != (0 as i32 as i64 as u64) { pc += 13 }
    ja lbb_1119                                     if true { pc += 8 }
lbb_1111:
    ldxdw r7, [r2+0x1]                      
    mov64 r1, 8                                     r1 = 8 as i32 as i64 as u64
    mov64 r2, 8                                     r2 = 8 as i32 as i64 as u64
    call function_11635                     
    lddw r1, 0x10002da50 --> b"\x00\x00\x00"        r1 load str located at 4295154256
    mov64 r3, 3                                     r3 = 3 as i32 as i64 as u64
    jne r0, 0, lbb_1123                             if r0 != (0 as i32 as i64 as u64) { pc += 4 }
lbb_1119:
    mov64 r1, 8                                     r1 = 8 as i32 as i64 as u64
    mov64 r2, 8                                     r2 = 8 as i32 as i64 as u64
    call function_18762                     
    syscall [invalid]                       
lbb_1123:
    stxdw [r0+0x0], r7                      
lbb_1124:
    stxdw [r6+0x18], r1                     
    stxdw [r6+0x10], r0                     
    stxw [r6+0x8], r3                       
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
lbb_1128:
    stxdw [r6+0x0], r1                      
    exit                                    

function_1130:
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
    stxdw [r1+0x8], r2                      
    mov64 r2, 1000000000                            r2 = 1000000000 as i32 as i64 as u64
    stxdw [r1+0x0], r2                      
    exit                                    

function_1135:
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
    stxdw [r1+0x8], r2                      
    mov64 r2, 1000000000                            r2 = 1000000000 as i32 as i64 as u64
    stxdw [r1+0x0], r2                      
    exit                                    

function_1140:
    mov64 r0, 6                                     r0 = 6 as i32 as i64 as u64
    jeq r2, 0, lbb_1145                             if r2 == (0 as i32 as i64 as u64) { pc += 3 }
    mov64 r0, 6                                     r0 = 6 as i32 as i64 as u64
    jeq r3, 0, lbb_1145                             if r3 == (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r0, 28                                    r0 = 28 as i32 as i64 as u64
lbb_1145:
    exit                                    

function_1146:
    mov64 r0, 6                                     r0 = 6 as i32 as i64 as u64
    jeq r2, 0, lbb_1151                             if r2 == (0 as i32 as i64 as u64) { pc += 3 }
    mov64 r0, 6                                     r0 = 6 as i32 as i64 as u64
    jeq r3, 0, lbb_1151                             if r3 == (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r0, 28                                    r0 = 28 as i32 as i64 as u64
lbb_1151:
    exit                                    

function_1152:
    mov64 r8, r5                                    r8 = r5
    mov64 r9, r4                                    r9 = r4
    mov64 r7, r3                                    r7 = r3
    stxdw [r10-0x158], r1                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -336                                  r1 += -336   ///  r1 = r1.wrapping_add(-336 as i32 as i64 as u64)
    call function_17493                     
    ldxdw r1, [r8-0xfd8]                    
    stxdw [r10-0x180], r1                   
    ldxdw r1, [r8-0xfe0]                    
    stxdw [r10-0x188], r1                   
    ldxdw r1, [r8-0xfe8]                    
    stxdw [r10-0x160], r1                   
    ldxdw r6, [r8-0xff0]                    
    ldxdw r1, [r8-0xff8]                    
    stxdw [r10-0x168], r1                   
    ldxdw r1, [r8-0x1000]                   
    stxdw [r10-0x170], r1                   
    ldxdw r1, [r8-0xfc8]                    
    stxdw [r10-0x178], r1                   
    ldxdw r1, [r8-0xfd0]                    
    lsh64 r1, 32                                    r1 <<= 32   ///  r1 = r1.wrapping_shl(32)
    rsh64 r1, 32                                    r1 >>= 32   ///  r1 = r1.wrapping_shr(32)
    jne r1, 0, lbb_1182                             if r1 != (0 as i32 as i64 as u64) { pc += 6 }
    mov64 r1, r10                                   r1 = r10
    add64 r1, -304                                  r1 += -304   ///  r1 = r1.wrapping_add(-304 as i32 as i64 as u64)
    mov64 r2, r7                                    r2 = r7
    mov64 r3, r9                                    r3 = r9
    call function_15530                     
    ja lbb_1212                                     if true { pc += 30 }
lbb_1182:
    mov64 r8, r10                                   r8 = r10
    add64 r8, -32                                   r8 += -32   ///  r8 = r8.wrapping_add(-32 as i32 as i64 as u64)
    mov64 r1, r8                                    r1 = r8
    mov64 r2, r7                                    r2 = r7
    mov64 r3, r9                                    r3 = r9
    call function_15530                     
    ldxdw r1, [r10-0x138]                   
    stxdw [r10-0x50], r1                    
    ldxdw r1, [r10-0x140]                   
    stxdw [r10-0x58], r1                    
    ldxdw r1, [r10-0x148]                   
    stxdw [r10-0x60], r1                    
    ldxdw r1, [r10-0x150]                   
    stxdw [r10-0x68], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -208                                  r1 += -208   ///  r1 = r1.wrapping_add(-208 as i32 as i64 as u64)
    mov64 r3, r10                                   r3 = r10
    add64 r3, -104                                  r3 += -104   ///  r3 = r3.wrapping_add(-104 as i32 as i64 as u64)
    mov64 r2, r8                                    r2 = r8
    call function_17050                     
    ldxdw r1, [r10-0xd0]                    
    jeq r1, 0, lbb_1384                             if r1 == (0 as i32 as i64 as u64) { pc += 180 }
    ldxdw r1, [r10-0xb0]                    
    stxdw [r10-0x118], r1                   
    ldxdw r1, [r10-0xb8]                    
    stxdw [r10-0x120], r1                   
    ldxdw r1, [r10-0xc0]                    
    stxdw [r10-0x128], r1                   
    ldxdw r1, [r10-0xc8]                    
    stxdw [r10-0x130], r1                   
lbb_1212:
    mov64 r7, r10                                   r7 = r10
    add64 r7, -64                                   r7 += -64   ///  r7 = r7.wrapping_add(-64 as i32 as i64 as u64)
    mov64 r1, r7                                    r1 = r7
    mov64 r2, r6                                    r2 = r6
    ldxdw r3, [r10-0x160]                   
    call function_15530                     
    ldxdw r1, [r10-0x138]                   
    stxdw [r10-0x8], r1                     
    ldxdw r1, [r10-0x140]                   
    stxdw [r10-0x10], r1                    
    ldxdw r1, [r10-0x148]                   
    stxdw [r10-0x18], r1                    
    ldxdw r1, [r10-0x150]                   
    stxdw [r10-0x20], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -208                                  r1 += -208   ///  r1 = r1.wrapping_add(-208 as i32 as i64 as u64)
    mov64 r3, r10                                   r3 = r10
    add64 r3, -32                                   r3 += -32   ///  r3 = r3.wrapping_add(-32 as i32 as i64 as u64)
    mov64 r2, r7                                    r2 = r7
    call function_17050                     
    ldxdw r1, [r10-0xd0]                    
    jeq r1, 0, lbb_1384                             if r1 == (0 as i32 as i64 as u64) { pc += 150 }
    ldxdw r1, [r10-0xb0]                    
    stxdw [r10-0x70], r1                    
    ldxdw r1, [r10-0xb8]                    
    stxdw [r10-0x78], r1                    
    ldxdw r1, [r10-0xc0]                    
    stxdw [r10-0x80], r1                    
    ldxdw r1, [r10-0xc8]                    
    stxdw [r10-0x88], r1                    
    mov64 r6, r10                                   r6 = r10
    add64 r6, -208                                  r6 += -208   ///  r6 = r6.wrapping_add(-208 as i32 as i64 as u64)
    mov64 r1, r6                                    r1 = r6
    ldxdw r2, [r10-0x170]                   
    ldxdw r3, [r10-0x168]                   
    call function_15530                     
    mov64 r1, r10                                   r1 = r10
    add64 r1, -104                                  r1 += -104   ///  r1 = r1.wrapping_add(-104 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -136                                  r2 += -136   ///  r2 = r2.wrapping_add(-136 as i32 as i64 as u64)
    mov64 r3, r6                                    r3 = r6
    call function_16882                     
    ldxdw r1, [r10-0x68]                    
    jeq r1, 0, lbb_1384                             if r1 == (0 as i32 as i64 as u64) { pc += 128 }
    ldxdw r1, [r10-0x48]                    
    stxdw [r10-0xf8], r1                    
    ldxdw r1, [r10-0x50]                    
    stxdw [r10-0x100], r1                   
    ldxdw r1, [r10-0x58]                    
    stxdw [r10-0x108], r1                   
    ldxdw r1, [r10-0x60]                    
    stxdw [r10-0x110], r1                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -240                                  r1 += -240   ///  r1 = r1.wrapping_add(-240 as i32 as i64 as u64)
    ldxdw r2, [r10-0x188]                   
    ldxdw r3, [r10-0x180]                   
    call function_15530                     
    ldxdw r1, [r10-0x178]                   
    lsh64 r1, 32                                    r1 <<= 32   ///  r1 = r1.wrapping_shl(32)
    rsh64 r1, 32                                    r1 >>= 32   ///  r1 = r1.wrapping_shr(32)
    jeq r1, 0, lbb_1329                             if r1 == (0 as i32 as i64 as u64) { pc += 56 }
    ldxdw r1, [r10-0xd8]                    
    stxdw [r10-0x28], r1                    
    ldxdw r1, [r10-0xe0]                    
    stxdw [r10-0x30], r1                    
    ldxdw r1, [r10-0xe8]                    
    stxdw [r10-0x38], r1                    
    ldxdw r1, [r10-0xf0]                    
    stxdw [r10-0x40], r1                    
    ldxdw r1, [r10-0x118]                   
    stxdw [r10-0x8], r1                     
    ldxdw r1, [r10-0x120]                   
    stxdw [r10-0x10], r1                    
    ldxdw r1, [r10-0x128]                   
    stxdw [r10-0x18], r1                    
    ldxdw r1, [r10-0x130]                   
    stxdw [r10-0x20], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -104                                  r1 += -104   ///  r1 = r1.wrapping_add(-104 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -64                                   r2 += -64   ///  r2 = r2.wrapping_add(-64 as i32 as i64 as u64)
    mov64 r3, r10                                   r3 = r10
    add64 r3, -32                                   r3 += -32   ///  r3 = r3.wrapping_add(-32 as i32 as i64 as u64)
    call function_17050                     
    ldxdw r1, [r10-0x68]                    
    jeq r1, 0, lbb_1384                             if r1 == (0 as i32 as i64 as u64) { pc += 86 }
    ldxdw r1, [r10-0x48]                    
    stxdw [r10-0x70], r1                    
    ldxdw r1, [r10-0x50]                    
    stxdw [r10-0x78], r1                    
    ldxdw r1, [r10-0x58]                    
    stxdw [r10-0x80], r1                    
    ldxdw r1, [r10-0x60]                    
    stxdw [r10-0x88], r1                    
    ldxdw r1, [r10-0xf8]                    
    stxdw [r10-0x50], r1                    
    ldxdw r1, [r10-0x100]                   
    stxdw [r10-0x58], r1                    
    ldxdw r1, [r10-0x108]                   
    stxdw [r10-0x60], r1                    
    ldxdw r1, [r10-0x110]                   
    stxdw [r10-0x68], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -208                                  r1 += -208   ///  r1 = r1.wrapping_add(-208 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -136                                  r2 += -136   ///  r2 = r2.wrapping_add(-136 as i32 as i64 as u64)
    mov64 r3, r10                                   r3 = r10
    add64 r3, -104                                  r3 += -104   ///  r3 = r3.wrapping_add(-104 as i32 as i64 as u64)
    call function_13419                     
    ldxdw r1, [r10-0xd0]                    
    jeq r1, 0, lbb_1384                             if r1 == (0 as i32 as i64 as u64) { pc += 61 }
    ldxdw r1, [r10-0xb0]                    
    ldxdw r2, [r10-0xb8]                    
    or64 r2, r1                                     r2 |= r1   ///  r2 = r2.or(r1)
    jeq r2, 0, lbb_1390                             if r2 == (0 as i32 as i64 as u64) { pc += 63 }
lbb_1327:
    call function_3                         
    syscall [invalid]                       
lbb_1329:
    ldxdw r1, [r10-0xd8]                    
    stxdw [r10-0x28], r1                    
    ldxdw r1, [r10-0xe0]                    
    stxdw [r10-0x30], r1                    
    ldxdw r1, [r10-0xe8]                    
    stxdw [r10-0x38], r1                    
    ldxdw r1, [r10-0xf0]                    
    stxdw [r10-0x40], r1                    
    ldxdw r1, [r10-0x118]                   
    stxdw [r10-0x8], r1                     
    ldxdw r1, [r10-0x120]                   
    stxdw [r10-0x10], r1                    
    ldxdw r1, [r10-0x128]                   
    stxdw [r10-0x18], r1                    
    ldxdw r1, [r10-0x130]                   
    stxdw [r10-0x20], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -208                                  r1 += -208   ///  r1 = r1.wrapping_add(-208 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -64                                   r2 += -64   ///  r2 = r2.wrapping_add(-64 as i32 as i64 as u64)
    mov64 r3, r10                                   r3 = r10
    add64 r3, -32                                   r3 += -32   ///  r3 = r3.wrapping_add(-32 as i32 as i64 as u64)
    call function_17050                     
    ldxdw r1, [r10-0xd0]                    
    jeq r1, 0, lbb_1384                             if r1 == (0 as i32 as i64 as u64) { pc += 30 }
    ldxdw r1, [r10-0xb0]                    
    stxdw [r10-0x70], r1                    
    ldxdw r1, [r10-0xb8]                    
    stxdw [r10-0x78], r1                    
    ldxdw r1, [r10-0xc0]                    
    stxdw [r10-0x80], r1                    
    ldxdw r1, [r10-0xc8]                    
    stxdw [r10-0x88], r1                    
    ldxdw r1, [r10-0xf8]                    
    stxdw [r10-0xb8], r1                    
    ldxdw r1, [r10-0x100]                   
    stxdw [r10-0xc0], r1                    
    ldxdw r1, [r10-0x108]                   
    stxdw [r10-0xc8], r1                    
    ldxdw r1, [r10-0x110]                   
    stxdw [r10-0xd0], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -104                                  r1 += -104   ///  r1 = r1.wrapping_add(-104 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -136                                  r2 += -136   ///  r2 = r2.wrapping_add(-136 as i32 as i64 as u64)
    mov64 r3, r10                                   r3 = r10
    add64 r3, -208                                  r3 += -208   ///  r3 = r3.wrapping_add(-208 as i32 as i64 as u64)
    call function_17405                     
    ldxdw r1, [r10-0x68]                    
    jeq r1, 0, lbb_1384                             if r1 == (0 as i32 as i64 as u64) { pc += 5 }
    ldxdw r1, [r10-0x48]                    
    ldxdw r2, [r10-0x50]                    
    or64 r2, r1                                     r2 |= r1   ///  r2 = r2.or(r1)
    jeq r2, 0, lbb_1394                             if r2 == (0 as i32 as i64 as u64) { pc += 11 }
    ja lbb_1327                                     if true { pc += -57 }
lbb_1384:
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
lbb_1385:
    ldxdw r4, [r10-0x158]                   
    stxdw [r4+0x8], r2                      
    stxdw [r4+0x0], r1                      
    stxdw [r4+0x10], r3                     
    exit                                    
lbb_1390:
    ldxdw r3, [r10-0xc0]                    
    ldxdw r2, [r10-0xc8]                    
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    ja lbb_1385                                     if true { pc += -9 }
lbb_1394:
    ldxdw r3, [r10-0x58]                    
    ldxdw r2, [r10-0x60]                    
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    ja lbb_1385                                     if true { pc += -13 }

function_1398:
    mov64 r7, r4                                    r7 = r4
    mov64 r0, r7                                    r0 = r7
    mov64 r9, r3                                    r9 = r3
    ldxdw r6, [r2+0x0]                      
    ldxdw r2, [r5-0xfe0]                    
    lsh64 r2, 32                                    r2 <<= 32   ///  r2 = r2.wrapping_shl(32)
    rsh64 r2, 32                                    r2 >>= 32   ///  r2 = r2.wrapping_shr(32)
    stxdw [r10-0x48], r9                    
    jne r2, 0, lbb_1470                             if r2 != (0 as i32 as i64 as u64) { pc += 63 }
    stxdw [r10-0x60], r3                    
    mov64 r8, 0                                     r8 = 0 as i32 as i64 as u64
    jeq r6, 0, lbb_1517                             if r6 == (0 as i32 as i64 as u64) { pc += 107 }
    stxdw [r10-0x50], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -48                                   r1 += -48   ///  r1 = r1.wrapping_add(-48 as i32 as i64 as u64)
    ldxdw r8, [r10-0x48]                    
    mov64 r2, r8                                    r2 = r8
    mov64 r3, r0                                    r3 = r0
    mov64 r4, r6                                    r4 = r6
    mov64 r5, 0                                     r5 = 0 as i32 as i64 as u64
    stxdw [r10-0x68], r0                    
    call function_21948                     
    mov64 r1, r10                                   r1 = r10
    add64 r1, -64                                   r1 += -64   ///  r1 = r1.wrapping_add(-64 as i32 as i64 as u64)
    ldxdw r2, [r10-0x30]                    
    ldxdw r9, [r10-0x28]                    
    stxdw [r10-0x58], r2                    
    mov64 r3, r9                                    r3 = r9
    mov64 r4, r6                                    r4 = r6
    mov64 r5, 0                                     r5 = 0 as i32 as i64 as u64
    call function_21911                     
    mov64 r2, 1                                     r2 = 1 as i32 as i64 as u64
    ldxdw r3, [r10-0x40]                    
    jgt r3, r8, lbb_1433                            if r3 > r8 { pc += 1 }
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
lbb_1433:
    ldxdw r4, [r10-0x38]                    
    ldxdw r0, [r10-0x68]                    
    mov64 r5, r0                                    r5 = r0
    sub64 r5, r4                                    r5 -= r4   ///  r5 = r5.wrapping_sub(r4)
    sub64 r5, r2                                    r5 -= r2   ///  r5 = r5.wrapping_sub(r2)
    mov64 r2, r8                                    r2 = r8
    sub64 r2, r3                                    r2 -= r3   ///  r2 = r2.wrapping_sub(r3)
    mov64 r3, r2                                    r3 = r2
    or64 r3, r5                                     r3 |= r5   ///  r3 = r3.or(r5)
    ldxdw r1, [r10-0x50]                    
    ldxdw r4, [r10-0x58]                    
    jeq r3, 0, lbb_1504                             if r3 == (0 as i32 as i64 as u64) { pc += 59 }
    sub64 r7, r5                                    r7 -= r5   ///  r7 = r7.wrapping_sub(r5)
    mov64 r8, 0                                     r8 = 0 as i32 as i64 as u64
    mov64 r4, 1                                     r4 = 1 as i32 as i64 as u64
    mov64 r3, 1                                     r3 = 1 as i32 as i64 as u64
    ldxdw r5, [r10-0x48]                    
    jgt r2, r5, lbb_1452                            if r2 > r5 { pc += 1 }
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
lbb_1452:
    sub64 r7, r3                                    r7 -= r3   ///  r7 = r7.wrapping_sub(r3)
    ldxdw r6, [r10-0x60]                    
    sub64 r6, r2                                    r6 -= r2   ///  r6 = r6.wrapping_sub(r2)
    mov64 r2, 1                                     r2 = 1 as i32 as i64 as u64
    ldxdw r3, [r10-0x48]                    
    mov64 r5, r6                                    r5 = r6
    jgt r6, r3, lbb_1460                            if r6 > r3 { pc += 1 }
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
lbb_1460:
    jgt r7, r0, lbb_1462                            if r7 > r0 { pc += 1 }
    mov64 r4, 0                                     r4 = 0 as i32 as i64 as u64
lbb_1462:
    jeq r7, r0, lbb_1464                            if r7 == r0 { pc += 1 }
    mov64 r2, r4                                    r2 = r4
lbb_1464:
    and64 r2, 1                                     r2 &= 1   ///  r2 = r2.and(1)
    stxdw [r10-0x48], r5                    
    mov64 r0, r7                                    r0 = r7
    ldxdw r4, [r10-0x58]                    
    jne r2, 0, lbb_1517                             if r2 != (0 as i32 as i64 as u64) { pc += 48 }
    ja lbb_1504                                     if true { pc += 34 }
lbb_1470:
    stxdw [r10-0x50], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -32                                   r1 += -32   ///  r1 = r1.wrapping_add(-32 as i32 as i64 as u64)
    mov64 r8, 0                                     r8 = 0 as i32 as i64 as u64
    mov64 r7, r0                                    r7 = r0
    mov64 r2, r0                                    r2 = r0
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
    mov64 r4, r6                                    r4 = r6
    mov64 r5, 0                                     r5 = 0 as i32 as i64 as u64
    call function_21911                     
    mov64 r1, r10                                   r1 = r10
    add64 r1, -16                                   r1 += -16   ///  r1 = r1.wrapping_add(-16 as i32 as i64 as u64)
    mov64 r2, r9                                    r2 = r9
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
    mov64 r4, r6                                    r4 = r6
    mov64 r5, 0                                     r5 = 0 as i32 as i64 as u64
    call function_21911                     
    mov64 r2, 1                                     r2 = 1 as i32 as i64 as u64
    ldxdw r3, [r10-0x18]                    
    mov64 r5, 1                                     r5 = 1 as i32 as i64 as u64
    jne r3, 0, lbb_1492                             if r3 != (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r5, 0                                     r5 = 0 as i32 as i64 as u64
lbb_1492:
    ldxdw r3, [r10-0x8]                     
    ldxdw r4, [r10-0x20]                    
    mov64 r9, r3                                    r9 = r3
    add64 r9, r4                                    r9 += r4   ///  r9 = r9.wrapping_add(r4)
    jgt r3, r9, lbb_1498                            if r3 > r9 { pc += 1 }
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
lbb_1498:
    or64 r5, r2                                     r5 |= r2   ///  r5 = r5.or(r2)
    ldxdw r4, [r10-0x10]                    
    and64 r5, 1                                     r5 &= 1   ///  r5 = r5.and(1)
    ldxdw r1, [r10-0x50]                    
    mov64 r0, r7                                    r0 = r7
    jne r5, 0, lbb_1517                             if r5 != (0 as i32 as i64 as u64) { pc += 13 }
lbb_1504:
    ldxdw r2, [r10-0x48]                    
    or64 r2, r0                                     r2 |= r0   ///  r2 = r2.or(r0)
    mov64 r8, 0                                     r8 = 0 as i32 as i64 as u64
    jeq r2, 0, lbb_1517                             if r2 == (0 as i32 as i64 as u64) { pc += 9 }
    mov64 r2, r4                                    r2 = r4
    or64 r2, r9                                     r2 |= r9   ///  r2 = r2.or(r9)
    jeq r2, 0, lbb_1517                             if r2 == (0 as i32 as i64 as u64) { pc += 6 }
    stxdw [r1+0x18], r4                     
    ldxdw r2, [r10-0x48]                    
    stxdw [r1+0x8], r2                      
    stxdw [r1+0x20], r9                     
    stxdw [r1+0x10], r0                     
    mov64 r8, 1                                     r8 = 1 as i32 as i64 as u64
lbb_1517:
    stxdw [r1+0x0], r8                      
    exit                                    

function_1519:
    mov64 r0, r4                                    r0 = r4
    mov64 r6, r3                                    r6 = r3
    ldxdw r9, [r2+0x0]                      
    ldxdw r2, [r5-0xfe0]                    
    lsh64 r2, 32                                    r2 <<= 32   ///  r2 = r2.wrapping_shl(32)
    rsh64 r2, 32                                    r2 >>= 32   ///  r2 = r2.wrapping_shr(32)
    stxdw [r10-0x48], r6                    
    stxdw [r10-0x60], r3                    
    jne r2, 0, lbb_1563                             if r2 != (0 as i32 as i64 as u64) { pc += 35 }
    stxdw [r10-0x50], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -64                                   r1 += -64   ///  r1 = r1.wrapping_add(-64 as i32 as i64 as u64)
    mov64 r8, 0                                     r8 = 0 as i32 as i64 as u64
    stxdw [r10-0x58], r0                    
    mov64 r2, r0                                    r2 = r0
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
    mov64 r4, r9                                    r4 = r9
    mov64 r5, 0                                     r5 = 0 as i32 as i64 as u64
    call function_21911                     
    mov64 r1, r10                                   r1 = r10
    add64 r1, -48                                   r1 += -48   ///  r1 = r1.wrapping_add(-48 as i32 as i64 as u64)
    mov64 r2, r6                                    r2 = r6
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
    mov64 r4, r9                                    r4 = r9
    mov64 r5, 0                                     r5 = 0 as i32 as i64 as u64
    call function_21911                     
    mov64 r2, 1                                     r2 = 1 as i32 as i64 as u64
    ldxdw r3, [r10-0x38]                    
    mov64 r5, 1                                     r5 = 1 as i32 as i64 as u64
    jne r3, 0, lbb_1550                             if r3 != (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r5, 0                                     r5 = 0 as i32 as i64 as u64
lbb_1550:
    ldxdw r3, [r10-0x28]                    
    ldxdw r4, [r10-0x40]                    
    mov64 r7, r3                                    r7 = r3
    add64 r7, r4                                    r7 += r4   ///  r7 = r7.wrapping_add(r4)
    jgt r3, r7, lbb_1556                            if r3 > r7 { pc += 1 }
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
lbb_1556:
    or64 r5, r2                                     r5 |= r2   ///  r5 = r5.or(r2)
    ldxdw r6, [r10-0x30]                    
    and64 r5, 1                                     r5 &= 1   ///  r5 = r5.and(1)
    ldxdw r1, [r10-0x50]                    
    ldxdw r0, [r10-0x58]                    
    jne r5, 0, lbb_1627                             if r5 != (0 as i32 as i64 as u64) { pc += 65 }
    ja lbb_1614                                     if true { pc += 51 }
lbb_1563:
    mov64 r8, 0                                     r8 = 0 as i32 as i64 as u64
    jeq r9, 0, lbb_1627                             if r9 == (0 as i32 as i64 as u64) { pc += 62 }
    stxdw [r10-0x50], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -16                                   r1 += -16   ///  r1 = r1.wrapping_add(-16 as i32 as i64 as u64)
    ldxdw r8, [r10-0x48]                    
    mov64 r2, r8                                    r2 = r8
    mov64 r3, r0                                    r3 = r0
    mov64 r4, r9                                    r4 = r9
    mov64 r5, 0                                     r5 = 0 as i32 as i64 as u64
    stxdw [r10-0x58], r0                    
    call function_21948                     
    mov64 r1, r10                                   r1 = r10
    add64 r1, -32                                   r1 += -32   ///  r1 = r1.wrapping_add(-32 as i32 as i64 as u64)
    ldxdw r6, [r10-0x10]                    
    ldxdw r7, [r10-0x8]                     
    mov64 r2, r6                                    r2 = r6
    mov64 r3, r7                                    r3 = r7
    mov64 r4, r9                                    r4 = r9
    mov64 r5, 0                                     r5 = 0 as i32 as i64 as u64
    call function_21911                     
    mov64 r2, 1                                     r2 = 1 as i32 as i64 as u64
    ldxdw r1, [r10-0x20]                    
    jgt r1, r8, lbb_1588                            if r1 > r8 { pc += 1 }
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
lbb_1588:
    ldxdw r3, [r10-0x18]                    
    ldxdw r0, [r10-0x58]                    
    mov64 r4, r0                                    r4 = r0
    sub64 r4, r3                                    r4 -= r3   ///  r4 = r4.wrapping_sub(r3)
    sub64 r4, r2                                    r4 -= r2   ///  r4 = r4.wrapping_sub(r2)
    sub64 r8, r1                                    r8 -= r1   ///  r8 = r8.wrapping_sub(r1)
    or64 r8, r4                                     r8 |= r4   ///  r8 = r8.or(r4)
    ldxdw r1, [r10-0x50]                    
    jeq r8, 0, lbb_1614                             if r8 == (0 as i32 as i64 as u64) { pc += 17 }
    mov64 r5, r6                                    r5 = r6
    add64 r5, 1                                     r5 += 1   ///  r5 = r5.wrapping_add(1 as i32 as i64 as u64)
    mov64 r8, 0                                     r8 = 0 as i32 as i64 as u64
    mov64 r4, 1                                     r4 = 1 as i32 as i64 as u64
    mov64 r2, 1                                     r2 = 1 as i32 as i64 as u64
    jgt r6, r5, lbb_1604                            if r6 > r5 { pc += 1 }
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
lbb_1604:
    mov64 r3, r7                                    r3 = r7
    add64 r3, r2                                    r3 += r2   ///  r3 = r3.wrapping_add(r2)
    jgt r7, r3, lbb_1608                            if r7 > r3 { pc += 1 }
    mov64 r4, 0                                     r4 = 0 as i32 as i64 as u64
lbb_1608:
    jge r5, r6, lbb_1610                            if r5 >= r6 { pc += 1 }
    mov64 r2, r4                                    r2 = r4
lbb_1610:
    and64 r2, 1                                     r2 &= 1   ///  r2 = r2.and(1)
    mov64 r6, r5                                    r6 = r5
    mov64 r7, r3                                    r7 = r3
    jne r2, 0, lbb_1627                             if r2 != (0 as i32 as i64 as u64) { pc += 13 }
lbb_1614:
    mov64 r2, r6                                    r2 = r6
    or64 r2, r7                                     r2 |= r7   ///  r2 = r2.or(r7)
    mov64 r8, 0                                     r8 = 0 as i32 as i64 as u64
    jeq r2, 0, lbb_1627                             if r2 == (0 as i32 as i64 as u64) { pc += 9 }
    ldxdw r2, [r10-0x60]                    
    or64 r2, r0                                     r2 |= r0   ///  r2 = r2.or(r0)
    jeq r2, 0, lbb_1627                             if r2 == (0 as i32 as i64 as u64) { pc += 6 }
    ldxdw r2, [r10-0x48]                    
    stxdw [r1+0x18], r2                     
    stxdw [r1+0x8], r6                      
    stxdw [r1+0x20], r0                     
    stxdw [r1+0x10], r7                     
    mov64 r8, 1                                     r8 = 1 as i32 as i64 as u64
lbb_1627:
    stxdw [r1+0x0], r8                      
    exit                                    

function_1629:
    mov64 r8, r5                                    r8 = r5
    mov64 r6, r4                                    r6 = r4
    mov64 r9, r3                                    r9 = r3
    stxdw [r10-0x128], r1                   
    ldxdw r7, [r2+0x0]                      
    ldxdw r2, [r8-0xfd8]                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -120                                  r1 += -120   ///  r1 = r1.wrapping_add(-120 as i32 as i64 as u64)
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
    mov64 r4, r7                                    r4 = r7
    mov64 r5, 0                                     r5 = 0 as i32 as i64 as u64
    call function_21911                     
    ldxdw r2, [r8-0xfe0]                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -104                                  r1 += -104   ///  r1 = r1.wrapping_add(-104 as i32 as i64 as u64)
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
    mov64 r4, r7                                    r4 = r7
    mov64 r5, 0                                     r5 = 0 as i32 as i64 as u64
    call function_21911                     
    mov64 r3, 1                                     r3 = 1 as i32 as i64 as u64
    ldxdw r1, [r10-0x70]                    
    mov64 r2, 1                                     r2 = 1 as i32 as i64 as u64
    jne r1, 0, lbb_1653                             if r1 != (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
lbb_1653:
    ldxdw r4, [r10-0x78]                    
    ldxdw r5, [r10-0x60]                    
    mov64 r1, r5                                    r1 = r5
    add64 r1, r4                                    r1 += r4   ///  r1 = r1.wrapping_add(r4)
    jgt r5, r1, lbb_1659                            if r5 > r1 { pc += 1 }
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
lbb_1659:
    or64 r2, r3                                     r2 |= r3   ///  r2 = r2.or(r3)
    and64 r2, 1                                     r2 &= 1   ///  r2 = r2.and(1)
    jne r2, 0, lbb_1768                             if r2 != (0 as i32 as i64 as u64) { pc += 106 }
    ldxdw r4, [r8-0xfe8]                    
    ldxdw r3, [r8-0xff0]                    
    ldxdw r5, [r10-0x68]                    
    mov64 r2, r3                                    r2 = r3
    add64 r2, r5                                    r2 += r5   ///  r2 = r2.wrapping_add(r5)
    mov64 r0, 1                                     r0 = 1 as i32 as i64 as u64
    mov64 r5, 1                                     r5 = 1 as i32 as i64 as u64
    jgt r3, r2, lbb_1671                            if r3 > r2 { pc += 1 }
    mov64 r5, 0                                     r5 = 0 as i32 as i64 as u64
lbb_1671:
    mov64 r3, r4                                    r3 = r4
    add64 r3, r1                                    r3 += r1   ///  r3 = r3.wrapping_add(r1)
    add64 r3, r5                                    r3 += r5   ///  r3 = r3.wrapping_add(r5)
    jgt r4, r3, lbb_1676                            if r4 > r3 { pc += 1 }
    mov64 r0, 0                                     r0 = 0 as i32 as i64 as u64
lbb_1676:
    jeq r3, r4, lbb_1678                            if r3 == r4 { pc += 1 }
    mov64 r5, r0                                    r5 = r0
lbb_1678:
    and64 r5, 1                                     r5 &= 1   ///  r5 = r5.and(1)
    jne r5, 0, lbb_1768                             if r5 != (0 as i32 as i64 as u64) { pc += 88 }
    ldxdw r1, [r8-0xff8]                    
    stxdw [r10-0x138], r1                   
    ldxdw r1, [r8-0x1000]                   
    stxdw [r10-0x130], r1                   
    ldxdw r8, [r8-0xfd0]                    
    rsh64 r2, 1                                     r2 >>= 1   ///  r2 = r2.wrapping_shr(1)
    mov64 r1, r3                                    r1 = r3
    lsh64 r1, 63                                    r1 <<= 63   ///  r1 = r1.wrapping_shl(63)
    or64 r2, r1                                     r2 |= r1   ///  r2 = r2.or(r1)
    rsh64 r3, 1                                     r3 >>= 1   ///  r3 = r3.wrapping_shr(1)
    mov64 r1, r10                                   r1 = r10
    add64 r1, -40                                   r1 += -40   ///  r1 = r1.wrapping_add(-40 as i32 as i64 as u64)
    call function_13690                     
    ldxdw r1, [r10-0x28]                    
    jeq r1, 0, lbb_1768                             if r1 == (0 as i32 as i64 as u64) { pc += 73 }
    ldxdw r1, [r10-0x8]                     
    stxdw [r10-0x40], r1                    
    ldxdw r1, [r10-0x10]                    
    stxdw [r10-0x48], r1                    
    ldxdw r1, [r10-0x18]                    
    stxdw [r10-0x50], r1                    
    ldxdw r1, [r10-0x20]                    
    stxdw [r10-0x58], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -144                                  r1 += -144   ///  r1 = r1.wrapping_add(-144 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -88                                   r2 += -88   ///  r2 = r2.wrapping_add(-88 as i32 as i64 as u64)
    call function_13722                     
    ldxdw r1, [r10-0x90]                    
    jeq r1, 0, lbb_1768                             if r1 == (0 as i32 as i64 as u64) { pc += 58 }
    ldxdw r2, [r10-0x80]                    
    ldxdw r4, [r10-0x88]                    
    lsh64 r8, 32                                    r8 <<= 32   ///  r8 = r8.wrapping_shl(32)
    rsh64 r8, 32                                    r8 >>= 32   ///  r8 = r8.wrapping_shr(32)
    stxdw [r10-0x140], r2                   
    jne r8, 0, lbb_1772                             if r8 != (0 as i32 as i64 as u64) { pc += 56 }
    mov64 r1, r10                                   r1 = r10
    add64 r1, -224                                  r1 += -224   ///  r1 = r1.wrapping_add(-224 as i32 as i64 as u64)
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
    mov64 r8, r4                                    r8 = r4
    mov64 r4, r9                                    r4 = r9
    mov64 r5, 0                                     r5 = 0 as i32 as i64 as u64
    call function_21911                     
    mov64 r1, r10                                   r1 = r10
    add64 r1, -240                                  r1 += -240   ///  r1 = r1.wrapping_add(-240 as i32 as i64 as u64)
    mov64 r2, r6                                    r2 = r6
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
    mov64 r4, r8                                    r4 = r8
    mov64 r5, 0                                     r5 = 0 as i32 as i64 as u64
    call function_21911                     
    mov64 r1, r10                                   r1 = r10
    add64 r1, -208                                  r1 += -208   ///  r1 = r1.wrapping_add(-208 as i32 as i64 as u64)
    mov64 r2, r9                                    r2 = r9
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
    mov64 r4, r8                                    r4 = r8
    mov64 r5, 0                                     r5 = 0 as i32 as i64 as u64
    call function_21911                     
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    ldxdw r3, [r10-0xd8]                    
    mov64 r2, 1                                     r2 = 1 as i32 as i64 as u64
    jne r3, 0, lbb_1742                             if r3 != (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
lbb_1742:
    ldxdw r4, [r10-0xe8]                    
    mov64 r3, 1                                     r3 = 1 as i32 as i64 as u64
    jne r4, 0, lbb_1746                             if r4 != (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
lbb_1746:
    ldxdw r4, [r10-0xe0]                    
    ldxdw r0, [r10-0xf0]                    
    mov64 r5, 1                                     r5 = 1 as i32 as i64 as u64
    ldxdw r8, [r10-0x140]                   
    jne r8, 0, lbb_1752                             if r8 != (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r5, 0                                     r5 = 0 as i32 as i64 as u64
lbb_1752:
    add64 r0, r4                                    r0 += r4   ///  r0 = r0.wrapping_add(r4)
    mov64 r4, 1                                     r4 = 1 as i32 as i64 as u64
    jne r6, 0, lbb_1756                             if r6 != (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r4, 0                                     r4 = 0 as i32 as i64 as u64
lbb_1756:
    ldxdw r9, [r10-0xc8]                    
    mov64 r8, r9                                    r8 = r9
    add64 r8, r0                                    r8 += r0   ///  r8 = r8.wrapping_add(r0)
    jgt r9, r8, lbb_1761                            if r9 > r8 { pc += 1 }
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
lbb_1761:
    and64 r4, r5                                    r4 &= r5   ///  r4 = r4.and(r5)
    or64 r4, r3                                     r4 |= r3   ///  r4 = r4.or(r3)
    or64 r4, r2                                     r4 |= r2   ///  r4 = r4.or(r2)
    or64 r4, r1                                     r4 |= r1   ///  r4 = r4.or(r1)
    and64 r4, 1                                     r4 &= 1   ///  r4 = r4.and(1)
    jne r4, 0, lbb_1768                             if r4 != (0 as i32 as i64 as u64) { pc += 1 }
    ja lbb_1853                                     if true { pc += 85 }
lbb_1768:
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    ldxdw r2, [r10-0x128]                   
    stxdw [r2+0x0], r1                      
lbb_1771:
    exit                                    
lbb_1772:
    mov64 r1, r10                                   r1 = r10
    add64 r1, -176                                  r1 += -176   ///  r1 = r1.wrapping_add(-176 as i32 as i64 as u64)
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
    mov64 r8, r4                                    r8 = r4
    mov64 r4, r9                                    r4 = r9
    mov64 r5, 0                                     r5 = 0 as i32 as i64 as u64
    call function_21911                     
    mov64 r1, r10                                   r1 = r10
    add64 r1, -192                                  r1 += -192   ///  r1 = r1.wrapping_add(-192 as i32 as i64 as u64)
    mov64 r2, r6                                    r2 = r6
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
    mov64 r4, r8                                    r4 = r8
    mov64 r5, 0                                     r5 = 0 as i32 as i64 as u64
    call function_21911                     
    mov64 r1, r10                                   r1 = r10
    add64 r1, -160                                  r1 += -160   ///  r1 = r1.wrapping_add(-160 as i32 as i64 as u64)
    mov64 r2, r9                                    r2 = r9
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
    mov64 r4, r8                                    r4 = r8
    mov64 r5, 0                                     r5 = 0 as i32 as i64 as u64
    call function_21911                     
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    ldxdw r3, [r10-0xa8]                    
    mov64 r2, 1                                     r2 = 1 as i32 as i64 as u64
    jne r3, 0, lbb_1798                             if r3 != (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
lbb_1798:
    ldxdw r4, [r10-0xb8]                    
    mov64 r3, 1                                     r3 = 1 as i32 as i64 as u64
    jne r4, 0, lbb_1802                             if r4 != (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
lbb_1802:
    ldxdw r4, [r10-0xb0]                    
    ldxdw r0, [r10-0xc0]                    
    mov64 r5, 1                                     r5 = 1 as i32 as i64 as u64
    ldxdw r8, [r10-0x140]                   
    jne r8, 0, lbb_1808                             if r8 != (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r5, 0                                     r5 = 0 as i32 as i64 as u64
lbb_1808:
    add64 r0, r4                                    r0 += r4   ///  r0 = r0.wrapping_add(r4)
    mov64 r4, 1                                     r4 = 1 as i32 as i64 as u64
    jne r6, 0, lbb_1812                             if r6 != (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r4, 0                                     r4 = 0 as i32 as i64 as u64
lbb_1812:
    ldxdw r9, [r10-0x98]                    
    mov64 r8, r9                                    r8 = r9
    add64 r8, r0                                    r8 += r0   ///  r8 = r8.wrapping_add(r0)
    jgt r9, r8, lbb_1817                            if r9 > r8 { pc += 1 }
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
lbb_1817:
    and64 r4, r5                                    r4 &= r5   ///  r4 = r4.and(r5)
    or64 r4, r3                                     r4 |= r3   ///  r4 = r4.or(r3)
    or64 r4, r2                                     r4 |= r2   ///  r4 = r4.or(r2)
    or64 r4, r1                                     r4 |= r1   ///  r4 = r4.or(r1)
    and64 r4, 1                                     r4 &= 1   ///  r4 = r4.and(1)
    jne r4, 0, lbb_1768                             if r4 != (0 as i32 as i64 as u64) { pc += -55 }
    ldxdw r9, [r10-0xa0]                    
    stxdw [r10-0x58], r9                    
    stxdw [r10-0x50], r8                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -40                                   r1 += -40   ///  r1 = r1.wrapping_add(-40 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -88                                   r2 += -88   ///  r2 = r2.wrapping_add(-88 as i32 as i64 as u64)
    ldxdw r3, [r10-0x130]                   
    ldxdw r4, [r10-0x138]                   
    call function_13303                     
    ldxdw r1, [r10-0x28]                    
    jeq r1, 0, lbb_1768                             if r1 == (0 as i32 as i64 as u64) { pc += -67 }
    ldxdw r6, [r10-0x18]                    
    ldxdw r1, [r10-0x20]                    
    stxdw [r10-0x140], r1                   
    stxdw [r10-0x50], r8                    
    stxdw [r10-0x58], r9                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -40                                   r1 += -40   ///  r1 = r1.wrapping_add(-40 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -88                                   r2 += -88   ///  r2 = r2.wrapping_add(-88 as i32 as i64 as u64)
    mov64 r8, 0                                     r8 = 0 as i32 as i64 as u64
    mov64 r3, r7                                    r3 = r7
    mov64 r4, 0                                     r4 = 0 as i32 as i64 as u64
    call function_13303                     
    ldxdw r1, [r10-0x28]                    
    jne r1, 0, lbb_1887                             if r1 != (0 as i32 as i64 as u64) { pc += 37 }
    ldxdw r1, [r10-0x128]                   
    stxdw [r1+0x0], r8                      
    ja lbb_1771                                     if true { pc += -82 }
lbb_1853:
    ldxdw r1, [r10-0x130]                   
    ldxdw r2, [r10-0x138]                   
    or64 r1, r2                                     r1 |= r2   ///  r1 = r1.or(r2)
    jeq r1, 0, lbb_1768                             if r1 == (0 as i32 as i64 as u64) { pc += -89 }
    jeq r7, 0, lbb_1768                             if r7 == (0 as i32 as i64 as u64) { pc += -90 }
    ldxdw r9, [r10-0xd0]                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -272                                  r1 += -272   ///  r1 = r1.wrapping_add(-272 as i32 as i64 as u64)
    mov64 r2, r9                                    r2 = r9
    mov64 r3, r8                                    r3 = r8
    ldxdw r4, [r10-0x130]                   
    ldxdw r6, [r10-0x138]                   
    mov64 r5, r6                                    r5 = r6
    call function_21948                     
    mov64 r1, r10                                   r1 = r10
    add64 r1, -256                                  r1 += -256   ///  r1 = r1.wrapping_add(-256 as i32 as i64 as u64)
    mov64 r2, r9                                    r2 = r9
    mov64 r3, r8                                    r3 = r8
    mov64 r4, r7                                    r4 = r7
    mov64 r5, 0                                     r5 = 0 as i32 as i64 as u64
    call function_21948                     
    mov64 r1, r10                                   r1 = r10
    add64 r1, -288                                  r1 += -288   ///  r1 = r1.wrapping_add(-288 as i32 as i64 as u64)
    ldxdw r2, [r10-0x100]                   
    ldxdw r3, [r10-0xf8]                    
    ldxdw r4, [r10-0x130]                   
    mov64 r5, r6                                    r5 = r6
    call function_21948                     
    ldxdw r6, [r10-0x108]                   
    ldxdw r4, [r10-0x110]                   
    ldxdw r1, [r10-0x118]                   
    ldxdw r2, [r10-0x120]                   
    ldxdw r3, [r10-0x128]                   
    ja lbb_1904                                     if true { pc += 17 }
lbb_1887:
    ldxdw r1, [r10-0x20]                    
    ldxdw r2, [r10-0x18]                    
    stxdw [r10-0x30], r2                    
    stxdw [r10-0x38], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -40                                   r1 += -40   ///  r1 = r1.wrapping_add(-40 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -56                                   r2 += -56   ///  r2 = r2.wrapping_add(-56 as i32 as i64 as u64)
    ldxdw r3, [r10-0x130]                   
    ldxdw r4, [r10-0x138]                   
    call function_13303                     
    ldxdw r1, [r10-0x28]                    
    jeq r1, 0, lbb_1768                             if r1 == (0 as i32 as i64 as u64) { pc += -132 }
    ldxdw r1, [r10-0x18]                    
    ldxdw r2, [r10-0x20]                    
    ldxdw r3, [r10-0x128]                   
    ldxdw r4, [r10-0x140]                   
lbb_1904:
    stxdw [r3+0x18], r2                     
    stxdw [r3+0x8], r4                      
    mov64 r2, 1                                     r2 = 1 as i32 as i64 as u64
    stxdw [r3+0x0], r2                      
    stxdw [r3+0x20], r1                     
    stxdw [r3+0x10], r6                     
    ja lbb_1771                                     if true { pc += -140 }

function_1911:
    mov64 r6, r1                                    r6 = r1
    ldxdw r2, [r2+0x0]                      
    ldxdw r1, [r5-0xfd0]                    
    stxdw [r10-0xfd0], r1                   
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    stxdw [r10-0xfc8], r1                   
    ldxdw r1, [r5-0xfd8]                    
    stxdw [r10-0xfd8], r1                   
    ldxdw r1, [r5-0xfe0]                    
    stxdw [r10-0xfe0], r1                   
    ldxdw r1, [r5-0xfe8]                    
    stxdw [r10-0xfe8], r1                   
    ldxdw r1, [r5-0xff0]                    
    stxdw [r10-0xff0], r1                   
    ldxdw r1, [r5-0xff8]                    
    stxdw [r10-0xff8], r1                   
    ldxdw r1, [r5-0x1000]                   
    stxdw [r10-0x1000], r1                  
    mov64 r1, r10                                   r1 = r10
    add64 r1, -24                                   r1 += -24   ///  r1 = r1.wrapping_add(-24 as i32 as i64 as u64)
    mov64 r5, r10                                   r5 = r10
    call function_1152                      
    ldxdw r1, [r10-0x8]                     
    ldxdw r2, [r10-0x10]                    
    ldxdw r3, [r10-0x18]                    
    stxdw [r6+0x0], r3                      
    stxdw [r6+0x8], r2                      
    stxdw [r6+0x10], r1                     
    exit                                    

function_1940:
    mov64 r6, r1                                    r6 = r1
    ldxdw r2, [r2+0x0]                      
    ldxdw r1, [r5-0xfd0]                    
    stxdw [r10-0xfd0], r1                   
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    stxdw [r10-0xfc8], r1                   
    ldxdw r1, [r5-0xfd8]                    
    stxdw [r10-0xfd8], r1                   
    ldxdw r1, [r5-0xfe0]                    
    stxdw [r10-0xfe0], r1                   
    ldxdw r1, [r5-0xfe8]                    
    stxdw [r10-0xfe8], r1                   
    ldxdw r1, [r5-0xff0]                    
    stxdw [r10-0xff0], r1                   
    ldxdw r1, [r5-0xff8]                    
    stxdw [r10-0xff8], r1                   
    ldxdw r1, [r5-0x1000]                   
    stxdw [r10-0x1000], r1                  
    mov64 r1, r10                                   r1 = r10
    add64 r1, -24                                   r1 += -24   ///  r1 = r1.wrapping_add(-24 as i32 as i64 as u64)
    mov64 r5, r10                                   r5 = r10
    call function_1152                      
    ldxdw r1, [r10-0x8]                     
    ldxdw r2, [r10-0x10]                    
    ldxdw r3, [r10-0x18]                    
    stxdw [r6+0x0], r3                      
    stxdw [r6+0x8], r2                      
    stxdw [r6+0x10], r1                     
    exit                                    

function_1969:
    mov64 r9, r5                                    r9 = r5
    mov64 r6, r4                                    r6 = r4
    mov64 r8, r3                                    r8 = r3
    stxdw [r10-0x28], r1                    
    ldxdw r7, [r2+0x0]                      
    ldxdw r2, [r9-0xff8]                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -32                                   r1 += -32   ///  r1 = r1.wrapping_add(-32 as i32 as i64 as u64)
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
    mov64 r4, r7                                    r4 = r7
    mov64 r5, 0                                     r5 = 0 as i32 as i64 as u64
    call function_21911                     
    ldxdw r2, [r9-0x1000]                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -16                                   r1 += -16   ///  r1 = r1.wrapping_add(-16 as i32 as i64 as u64)
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
    mov64 r4, r7                                    r4 = r7
    mov64 r5, 0                                     r5 = 0 as i32 as i64 as u64
    call function_21911                     
    mov64 r2, 1                                     r2 = 1 as i32 as i64 as u64
    ldxdw r1, [r10-0x18]                    
    mov64 r3, 1                                     r3 = 1 as i32 as i64 as u64
    jne r1, 0, lbb_1993                             if r1 != (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
lbb_1993:
    ldxdw r4, [r10-0x20]                    
    ldxdw r5, [r10-0x8]                     
    mov64 r1, r5                                    r1 = r5
    add64 r1, r4                                    r1 += r4   ///  r1 = r1.wrapping_add(r4)
    jgt r5, r1, lbb_1999                            if r5 > r1 { pc += 1 }
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
lbb_1999:
    or64 r3, r2                                     r3 |= r2   ///  r3 = r3.or(r2)
    jne r3, 1, lbb_2005                             if r3 != (1 as i32 as i64 as u64) { pc += 4 }
lbb_2001:
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    ldxdw r2, [r10-0x28]                    
    stxdw [r2+0x0], r1                      
    ja lbb_2029                                     if true { pc += 24 }
lbb_2005:
    mov64 r3, r6                                    r3 = r6
    ldxdw r4, [r10-0x10]                    
    mov64 r2, r8                                    r2 = r8
    add64 r2, r4                                    r2 += r4   ///  r2 = r2.wrapping_add(r4)
    mov64 r5, 1                                     r5 = 1 as i32 as i64 as u64
    mov64 r4, 1                                     r4 = 1 as i32 as i64 as u64
    jgt r8, r2, lbb_2013                            if r8 > r2 { pc += 1 }
    mov64 r4, 0                                     r4 = 0 as i32 as i64 as u64
lbb_2013:
    add64 r6, r1                                    r6 += r1   ///  r6 = r6.wrapping_add(r1)
    add64 r6, r4                                    r6 += r4   ///  r6 = r6.wrapping_add(r4)
    jgt r3, r6, lbb_2017                            if r3 > r6 { pc += 1 }
    mov64 r5, 0                                     r5 = 0 as i32 as i64 as u64
lbb_2017:
    jeq r6, r3, lbb_2019                            if r6 == r3 { pc += 1 }
    mov64 r4, r5                                    r4 = r5
lbb_2019:
    and64 r4, 1                                     r4 &= 1   ///  r4 = r4.and(1)
    jne r4, 0, lbb_2001                             if r4 != (0 as i32 as i64 as u64) { pc += -20 }
    rsh64 r2, 1                                     r2 >>= 1   ///  r2 = r2.wrapping_shr(1)
    mov64 r1, r6                                    r1 = r6
    lsh64 r1, 63                                    r1 <<= 63   ///  r1 = r1.wrapping_shl(63)
    or64 r2, r1                                     r2 |= r1   ///  r2 = r2.or(r1)
    rsh64 r6, 1                                     r6 >>= 1   ///  r6 = r6.wrapping_shr(1)
    ldxdw r1, [r10-0x28]                    
    mov64 r3, r6                                    r3 = r6
    call function_13690                     
lbb_2029:
    exit                                    

function_2030:
    jgt r3, 7, lbb_2037                             if r3 > (7 as i32 as i64 as u64) { pc += 6 }
    mov64 r1, 8                                     r1 = 8 as i32 as i64 as u64
    mov64 r2, r3                                    r2 = r3
    lddw r3, 0x10002dc10 --> b"\x00\x00\x00\x00\xbc\xc3\x02\x00#\x00\x00\x00\x00\x00\x00\x00#\x01\x00\x0…        r3 load str located at 4295154704
    call function_20726                     
    syscall [invalid]                       
lbb_2037:
    ldxdw r1, [r1+0x0]                      
    stxdw [r2+0x0], r1                      
    exit                                    

function_2040:
    mov64 r8, r5                                    r8 = r5
    mov64 r9, r3                                    r9 = r3
    mov64 r7, r2                                    r7 = r2
    mov64 r6, r1                                    r6 = r1
    ldxdw r1, [r8-0xfd8]                    
    lsh64 r1, 32                                    r1 <<= 32   ///  r1 = r1.wrapping_shl(32)
    rsh64 r1, 32                                    r1 >>= 32   ///  r1 = r1.wrapping_shr(32)
    jeq r1, 0, lbb_2049                             if r1 == (0 as i32 as i64 as u64) { pc += 1 }
    ldxdw r4, [r8-0xff8]                    
lbb_2049:
    mov64 r2, r8                                    r2 = r8
    add64 r2, -4096                                 r2 += -4096   ///  r2 = r2.wrapping_add(-4096 as i32 as i64 as u64)
    jeq r1, 0, lbb_2054                             if r1 == (0 as i32 as i64 as u64) { pc += 2 }
    mov64 r2, r8                                    r2 = r8
    add64 r2, -4080                                 r2 += -4080   ///  r2 = r2.wrapping_add(-4080 as i32 as i64 as u64)
lbb_2054:
    ldxdw r3, [r2+0x0]                      
    mov64 r1, r10                                   r1 = r10
    add64 r1, -40                                   r1 += -40   ///  r1 = r1.wrapping_add(-40 as i32 as i64 as u64)
    mov64 r2, r4                                    r2 = r4
    call function_13690                     
    ldxdw r1, [r10-0x28]                    
    jeq r1, 0, lbb_2254                             if r1 == (0 as i32 as i64 as u64) { pc += 193 }
    ldxdw r1, [r8-0xfe0]                    
    stxdw [r10-0x188], r1                   
    ldxdw r1, [r8-0xfe8]                    
    stxdw [r10-0x190], r1                   
    ldxdw r8, [r8-0xfd0]                    
    ldxdw r1, [r10-0x8]                     
    stxdw [r10-0x138], r1                   
    ldxdw r1, [r10-0x10]                    
    stxdw [r10-0x140], r1                   
    ldxdw r1, [r10-0x18]                    
    stxdw [r10-0x148], r1                   
    ldxdw r1, [r10-0x20]                    
    stxdw [r10-0x150], r1                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -40                                   r1 += -40   ///  r1 = r1.wrapping_add(-40 as i32 as i64 as u64)
    mov64 r2, r7                                    r2 = r7
    mov64 r3, r9                                    r3 = r9
    call function_13690                     
    ldxdw r1, [r10-0x28]                    
    jeq r1, 0, lbb_2254                             if r1 == (0 as i32 as i64 as u64) { pc += 173 }
    ldxdw r1, [r10-0x8]                     
    stxdw [r10-0x118], r1                   
    ldxdw r1, [r10-0x10]                    
    stxdw [r10-0x120], r1                   
    ldxdw r1, [r10-0x18]                    
    stxdw [r10-0x128], r1                   
    ldxdw r1, [r10-0x20]                    
    stxdw [r10-0x130], r1                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -40                                   r1 += -40   ///  r1 = r1.wrapping_add(-40 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -304                                  r2 += -304   ///  r2 = r2.wrapping_add(-304 as i32 as i64 as u64)
    mov64 r3, r10                                   r3 = r10
    add64 r3, -336                                  r3 += -336   ///  r3 = r3.wrapping_add(-336 as i32 as i64 as u64)
    call function_13949                     
    ldxdw r1, [r10-0x28]                    
    jeq r1, 0, lbb_2254                             if r1 == (0 as i32 as i64 as u64) { pc += 156 }
    ldxdw r1, [r10-0x8]                     
    stxdw [r10-0xf8], r1                    
    ldxdw r1, [r10-0x10]                    
    stxdw [r10-0x100], r1                   
    ldxdw r1, [r10-0x18]                    
    stxdw [r10-0x108], r1                   
    ldxdw r1, [r10-0x20]                    
    stxdw [r10-0x110], r1                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -40                                   r1 += -40   ///  r1 = r1.wrapping_add(-40 as i32 as i64 as u64)
    mov64 r7, 0                                     r7 = 0 as i32 as i64 as u64
    mov64 r2, 1                                     r2 = 1 as i32 as i64 as u64
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
    call function_13690                     
    ldxdw r1, [r10-0x28]                    
    jeq r1, 0, lbb_2255                             if r1 == (0 as i32 as i64 as u64) { pc += 141 }
    ldxdw r1, [r10-0x8]                     
    stxdw [r10-0xd8], r1                    
    ldxdw r1, [r10-0x10]                    
    stxdw [r10-0xe0], r1                    
    ldxdw r1, [r10-0x18]                    
    stxdw [r10-0xe8], r1                    
    ldxdw r1, [r10-0x20]                    
    stxdw [r10-0xf0], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -40                                   r1 += -40   ///  r1 = r1.wrapping_add(-40 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -240                                  r2 += -240   ///  r2 = r2.wrapping_add(-240 as i32 as i64 as u64)
    mov64 r3, r10                                   r3 = r10
    add64 r3, -272                                  r3 += -272   ///  r3 = r3.wrapping_add(-272 as i32 as i64 as u64)
    call function_14416                     
    ldxdw r1, [r10-0x28]                    
    jeq r1, 0, lbb_2254                             if r1 == (0 as i32 as i64 as u64) { pc += 123 }
    ldxdw r1, [r10-0x8]                     
    stxdw [r10-0xb8], r1                    
    ldxdw r1, [r10-0x10]                    
    stxdw [r10-0xc0], r1                    
    ldxdw r1, [r10-0x18]                    
    stxdw [r10-0xc8], r1                    
    ldxdw r1, [r10-0x20]                    
    stxdw [r10-0xd0], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -40                                   r1 += -40   ///  r1 = r1.wrapping_add(-40 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -208                                  r2 += -208   ///  r2 = r2.wrapping_add(-208 as i32 as i64 as u64)
    call function_15298                     
    ldxdw r1, [r10-0x28]                    
    jeq r1, 0, lbb_2254                             if r1 == (0 as i32 as i64 as u64) { pc += 108 }
    ldxdw r1, [r10-0x8]                     
    stxdw [r10-0x30], r1                    
    ldxdw r1, [r10-0x10]                    
    stxdw [r10-0x38], r1                    
    ldxdw r1, [r10-0x18]                    
    stxdw [r10-0x40], r1                    
    ldxdw r1, [r10-0x20]                    
    stxdw [r10-0x48], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -144                                  r1 += -144   ///  r1 = r1.wrapping_add(-144 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -72                                   r2 += -72   ///  r2 = r2.wrapping_add(-72 as i32 as i64 as u64)
    mov64 r3, r10                                   r3 = r10
    add64 r3, -240                                  r3 += -240   ///  r3 = r3.wrapping_add(-240 as i32 as i64 as u64)
    call function_14500                     
    ldxdw r1, [r10-0x90]                    
    jeq r1, 0, lbb_2254                             if r1 == (0 as i32 as i64 as u64) { pc += 91 }
    ldxdw r1, [r10-0x70]                    
    stxdw [r10-0x98], r1                    
    ldxdw r1, [r10-0x78]                    
    stxdw [r10-0xa0], r1                    
    ldxdw r1, [r10-0x80]                    
    stxdw [r10-0xa8], r1                    
    ldxdw r1, [r10-0x88]                    
    stxdw [r10-0xb0], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -40                                   r1 += -40   ///  r1 = r1.wrapping_add(-40 as i32 as i64 as u64)
    ldxdw r2, [r10-0x190]                   
    ldxdw r3, [r10-0x188]                   
    call function_13690                     
    ldxdw r1, [r10-0x28]                    
    jeq r1, 0, lbb_2254                             if r1 == (0 as i32 as i64 as u64) { pc += 76 }
    ldxdw r1, [r10-0x8]                     
    stxdw [r10-0x50], r1                    
    ldxdw r1, [r10-0x10]                    
    stxdw [r10-0x58], r1                    
    ldxdw r1, [r10-0x18]                    
    stxdw [r10-0x60], r1                    
    ldxdw r1, [r10-0x20]                    
    stxdw [r10-0x68], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -40                                   r1 += -40   ///  r1 = r1.wrapping_add(-40 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -104                                  r2 += -104   ///  r2 = r2.wrapping_add(-104 as i32 as i64 as u64)
    mov64 r3, r10                                   r3 = r10
    add64 r3, -176                                  r3 += -176   ///  r3 = r3.wrapping_add(-176 as i32 as i64 as u64)
    call function_14167                     
    ldxdw r1, [r10-0x28]                    
    jeq r1, 0, lbb_2254                             if r1 == (0 as i32 as i64 as u64) { pc += 59 }
    ldxdw r1, [r10-0x8]                     
    stxdw [r10-0x30], r1                    
    ldxdw r1, [r10-0x10]                    
    stxdw [r10-0x38], r1                    
    ldxdw r1, [r10-0x18]                    
    stxdw [r10-0x40], r1                    
    ldxdw r1, [r10-0x20]                    
    stxdw [r10-0x48], r1                    
    lsh64 r8, 32                                    r8 <<= 32   ///  r8 = r8.wrapping_shl(32)
    rsh64 r8, 32                                    r8 >>= 32   ///  r8 = r8.wrapping_shr(32)
    jeq r8, 0, lbb_2230                             if r8 == (0 as i32 as i64 as u64) { pc += 24 }
    mov64 r1, r10                                   r1 = r10
    add64 r1, -40                                   r1 += -40   ///  r1 = r1.wrapping_add(-40 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -72                                   r2 += -72   ///  r2 = r2.wrapping_add(-72 as i32 as i64 as u64)
    call function_13852                     
    ldxdw r1, [r10-0x28]                    
    jeq r1, 0, lbb_2254                             if r1 == (0 as i32 as i64 as u64) { pc += 41 }
    ldxdw r1, [r10-0x8]                     
    stxdw [r10-0x78], r1                    
    ldxdw r1, [r10-0x10]                    
    stxdw [r10-0x80], r1                    
    ldxdw r1, [r10-0x18]                    
    stxdw [r10-0x88], r1                    
    ldxdw r1, [r10-0x20]                    
    stxdw [r10-0x90], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -360                                  r1 += -360   ///  r1 = r1.wrapping_add(-360 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -144                                  r2 += -144   ///  r2 = r2.wrapping_add(-144 as i32 as i64 as u64)
    call function_13722                     
    ldxdw r2, [r10-0x158]                   
    ldxdw r1, [r10-0x160]                   
    ldxdw r7, [r10-0x168]                   
    ja lbb_2255                                     if true { pc += 25 }
lbb_2230:
    mov64 r1, r10                                   r1 = r10
    add64 r1, -40                                   r1 += -40   ///  r1 = r1.wrapping_add(-40 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -72                                   r2 += -72   ///  r2 = r2.wrapping_add(-72 as i32 as i64 as u64)
    call function_13797                     
    ldxdw r1, [r10-0x28]                    
    jeq r1, 0, lbb_2254                             if r1 == (0 as i32 as i64 as u64) { pc += 17 }
    ldxdw r1, [r10-0x8]                     
    stxdw [r10-0x78], r1                    
    ldxdw r1, [r10-0x10]                    
    stxdw [r10-0x80], r1                    
    ldxdw r1, [r10-0x18]                    
    stxdw [r10-0x88], r1                    
    ldxdw r1, [r10-0x20]                    
    stxdw [r10-0x90], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -384                                  r1 += -384   ///  r1 = r1.wrapping_add(-384 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -144                                  r2 += -144   ///  r2 = r2.wrapping_add(-144 as i32 as i64 as u64)
    call function_13722                     
    ldxdw r2, [r10-0x170]                   
    ldxdw r1, [r10-0x178]                   
    ldxdw r7, [r10-0x180]                   
    ja lbb_2255                                     if true { pc += 1 }
lbb_2254:
    mov64 r7, 0                                     r7 = 0 as i32 as i64 as u64
lbb_2255:
    stxdw [r6+0x8], r1                      
    stxdw [r6+0x0], r7                      
    stxdw [r6+0x10], r2                     
    exit                                    

function_2259:
    mov64 r8, r5                                    r8 = r5
    mov64 r9, r3                                    r9 = r3
    mov64 r7, r2                                    r7 = r2
    mov64 r6, r1                                    r6 = r1
    ldxdw r1, [r8-0xfd8]                    
    lsh64 r1, 32                                    r1 <<= 32   ///  r1 = r1.wrapping_shl(32)
    rsh64 r1, 32                                    r1 >>= 32   ///  r1 = r1.wrapping_shr(32)
    jeq r1, 0, lbb_2268                             if r1 == (0 as i32 as i64 as u64) { pc += 1 }
    ldxdw r4, [r8-0xff8]                    
lbb_2268:
    mov64 r2, r8                                    r2 = r8
    add64 r2, -4096                                 r2 += -4096   ///  r2 = r2.wrapping_add(-4096 as i32 as i64 as u64)
    jeq r1, 0, lbb_2273                             if r1 == (0 as i32 as i64 as u64) { pc += 2 }
    mov64 r2, r8                                    r2 = r8
    add64 r2, -4080                                 r2 += -4080   ///  r2 = r2.wrapping_add(-4080 as i32 as i64 as u64)
lbb_2273:
    ldxdw r3, [r2+0x0]                      
    mov64 r1, r10                                   r1 = r10
    add64 r1, -40                                   r1 += -40   ///  r1 = r1.wrapping_add(-40 as i32 as i64 as u64)
    mov64 r2, r4                                    r2 = r4
    call function_13690                     
    ldxdw r1, [r10-0x28]                    
    jeq r1, 0, lbb_2473                             if r1 == (0 as i32 as i64 as u64) { pc += 193 }
    ldxdw r1, [r8-0xfe0]                    
    stxdw [r10-0x188], r1                   
    ldxdw r1, [r8-0xfe8]                    
    stxdw [r10-0x190], r1                   
    ldxdw r8, [r8-0xfd0]                    
    ldxdw r1, [r10-0x8]                     
    stxdw [r10-0x138], r1                   
    ldxdw r1, [r10-0x10]                    
    stxdw [r10-0x140], r1                   
    ldxdw r1, [r10-0x18]                    
    stxdw [r10-0x148], r1                   
    ldxdw r1, [r10-0x20]                    
    stxdw [r10-0x150], r1                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -40                                   r1 += -40   ///  r1 = r1.wrapping_add(-40 as i32 as i64 as u64)
    mov64 r2, r7                                    r2 = r7
    mov64 r3, r9                                    r3 = r9
    call function_13690                     
    ldxdw r1, [r10-0x28]                    
    jeq r1, 0, lbb_2473                             if r1 == (0 as i32 as i64 as u64) { pc += 173 }
    ldxdw r1, [r10-0x8]                     
    stxdw [r10-0x118], r1                   
    ldxdw r1, [r10-0x10]                    
    stxdw [r10-0x120], r1                   
    ldxdw r1, [r10-0x18]                    
    stxdw [r10-0x128], r1                   
    ldxdw r1, [r10-0x20]                    
    stxdw [r10-0x130], r1                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -40                                   r1 += -40   ///  r1 = r1.wrapping_add(-40 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -304                                  r2 += -304   ///  r2 = r2.wrapping_add(-304 as i32 as i64 as u64)
    mov64 r3, r10                                   r3 = r10
    add64 r3, -336                                  r3 += -336   ///  r3 = r3.wrapping_add(-336 as i32 as i64 as u64)
    call function_13949                     
    ldxdw r1, [r10-0x28]                    
    jeq r1, 0, lbb_2473                             if r1 == (0 as i32 as i64 as u64) { pc += 156 }
    ldxdw r1, [r10-0x8]                     
    stxdw [r10-0xf8], r1                    
    ldxdw r1, [r10-0x10]                    
    stxdw [r10-0x100], r1                   
    ldxdw r1, [r10-0x18]                    
    stxdw [r10-0x108], r1                   
    ldxdw r1, [r10-0x20]                    
    stxdw [r10-0x110], r1                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -40                                   r1 += -40   ///  r1 = r1.wrapping_add(-40 as i32 as i64 as u64)
    mov64 r7, 0                                     r7 = 0 as i32 as i64 as u64
    mov64 r2, 1                                     r2 = 1 as i32 as i64 as u64
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
    call function_13690                     
    ldxdw r1, [r10-0x28]                    
    jeq r1, 0, lbb_2474                             if r1 == (0 as i32 as i64 as u64) { pc += 141 }
    ldxdw r1, [r10-0x8]                     
    stxdw [r10-0xd8], r1                    
    ldxdw r1, [r10-0x10]                    
    stxdw [r10-0xe0], r1                    
    ldxdw r1, [r10-0x18]                    
    stxdw [r10-0xe8], r1                    
    ldxdw r1, [r10-0x20]                    
    stxdw [r10-0xf0], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -40                                   r1 += -40   ///  r1 = r1.wrapping_add(-40 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -240                                  r2 += -240   ///  r2 = r2.wrapping_add(-240 as i32 as i64 as u64)
    mov64 r3, r10                                   r3 = r10
    add64 r3, -272                                  r3 += -272   ///  r3 = r3.wrapping_add(-272 as i32 as i64 as u64)
    call function_14500                     
    ldxdw r1, [r10-0x28]                    
    jeq r1, 0, lbb_2473                             if r1 == (0 as i32 as i64 as u64) { pc += 123 }
    ldxdw r1, [r10-0x8]                     
    stxdw [r10-0xb8], r1                    
    ldxdw r1, [r10-0x10]                    
    stxdw [r10-0xc0], r1                    
    ldxdw r1, [r10-0x18]                    
    stxdw [r10-0xc8], r1                    
    ldxdw r1, [r10-0x20]                    
    stxdw [r10-0xd0], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -40                                   r1 += -40   ///  r1 = r1.wrapping_add(-40 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -208                                  r2 += -208   ///  r2 = r2.wrapping_add(-208 as i32 as i64 as u64)
    call function_15298                     
    ldxdw r1, [r10-0x28]                    
    jeq r1, 0, lbb_2473                             if r1 == (0 as i32 as i64 as u64) { pc += 108 }
    ldxdw r1, [r10-0x8]                     
    stxdw [r10-0x30], r1                    
    ldxdw r1, [r10-0x10]                    
    stxdw [r10-0x38], r1                    
    ldxdw r1, [r10-0x18]                    
    stxdw [r10-0x40], r1                    
    ldxdw r1, [r10-0x20]                    
    stxdw [r10-0x48], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -144                                  r1 += -144   ///  r1 = r1.wrapping_add(-144 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -240                                  r2 += -240   ///  r2 = r2.wrapping_add(-240 as i32 as i64 as u64)
    mov64 r3, r10                                   r3 = r10
    add64 r3, -72                                   r3 += -72   ///  r3 = r3.wrapping_add(-72 as i32 as i64 as u64)
    call function_14500                     
    ldxdw r1, [r10-0x90]                    
    jeq r1, 0, lbb_2473                             if r1 == (0 as i32 as i64 as u64) { pc += 91 }
    ldxdw r1, [r10-0x70]                    
    stxdw [r10-0x98], r1                    
    ldxdw r1, [r10-0x78]                    
    stxdw [r10-0xa0], r1                    
    ldxdw r1, [r10-0x80]                    
    stxdw [r10-0xa8], r1                    
    ldxdw r1, [r10-0x88]                    
    stxdw [r10-0xb0], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -40                                   r1 += -40   ///  r1 = r1.wrapping_add(-40 as i32 as i64 as u64)
    ldxdw r2, [r10-0x190]                   
    ldxdw r3, [r10-0x188]                   
    call function_13690                     
    ldxdw r1, [r10-0x28]                    
    jeq r1, 0, lbb_2473                             if r1 == (0 as i32 as i64 as u64) { pc += 76 }
    ldxdw r1, [r10-0x8]                     
    stxdw [r10-0x50], r1                    
    ldxdw r1, [r10-0x10]                    
    stxdw [r10-0x58], r1                    
    ldxdw r1, [r10-0x18]                    
    stxdw [r10-0x60], r1                    
    ldxdw r1, [r10-0x20]                    
    stxdw [r10-0x68], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -40                                   r1 += -40   ///  r1 = r1.wrapping_add(-40 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -104                                  r2 += -104   ///  r2 = r2.wrapping_add(-104 as i32 as i64 as u64)
    mov64 r3, r10                                   r3 = r10
    add64 r3, -176                                  r3 += -176   ///  r3 = r3.wrapping_add(-176 as i32 as i64 as u64)
    call function_14167                     
    ldxdw r1, [r10-0x28]                    
    jeq r1, 0, lbb_2473                             if r1 == (0 as i32 as i64 as u64) { pc += 59 }
    ldxdw r1, [r10-0x8]                     
    stxdw [r10-0x30], r1                    
    ldxdw r1, [r10-0x10]                    
    stxdw [r10-0x38], r1                    
    ldxdw r1, [r10-0x18]                    
    stxdw [r10-0x40], r1                    
    ldxdw r1, [r10-0x20]                    
    stxdw [r10-0x48], r1                    
    lsh64 r8, 32                                    r8 <<= 32   ///  r8 = r8.wrapping_shl(32)
    rsh64 r8, 32                                    r8 >>= 32   ///  r8 = r8.wrapping_shr(32)
    jeq r8, 0, lbb_2449                             if r8 == (0 as i32 as i64 as u64) { pc += 24 }
    mov64 r1, r10                                   r1 = r10
    add64 r1, -40                                   r1 += -40   ///  r1 = r1.wrapping_add(-40 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -72                                   r2 += -72   ///  r2 = r2.wrapping_add(-72 as i32 as i64 as u64)
    call function_13852                     
    ldxdw r1, [r10-0x28]                    
    jeq r1, 0, lbb_2473                             if r1 == (0 as i32 as i64 as u64) { pc += 41 }
    ldxdw r1, [r10-0x8]                     
    stxdw [r10-0x78], r1                    
    ldxdw r1, [r10-0x10]                    
    stxdw [r10-0x80], r1                    
    ldxdw r1, [r10-0x18]                    
    stxdw [r10-0x88], r1                    
    ldxdw r1, [r10-0x20]                    
    stxdw [r10-0x90], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -360                                  r1 += -360   ///  r1 = r1.wrapping_add(-360 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -144                                  r2 += -144   ///  r2 = r2.wrapping_add(-144 as i32 as i64 as u64)
    call function_13722                     
    ldxdw r2, [r10-0x158]                   
    ldxdw r1, [r10-0x160]                   
    ldxdw r7, [r10-0x168]                   
    ja lbb_2474                                     if true { pc += 25 }
lbb_2449:
    mov64 r1, r10                                   r1 = r10
    add64 r1, -40                                   r1 += -40   ///  r1 = r1.wrapping_add(-40 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -72                                   r2 += -72   ///  r2 = r2.wrapping_add(-72 as i32 as i64 as u64)
    call function_13797                     
    ldxdw r1, [r10-0x28]                    
    jeq r1, 0, lbb_2473                             if r1 == (0 as i32 as i64 as u64) { pc += 17 }
    ldxdw r1, [r10-0x8]                     
    stxdw [r10-0x78], r1                    
    ldxdw r1, [r10-0x10]                    
    stxdw [r10-0x80], r1                    
    ldxdw r1, [r10-0x18]                    
    stxdw [r10-0x88], r1                    
    ldxdw r1, [r10-0x20]                    
    stxdw [r10-0x90], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -384                                  r1 += -384   ///  r1 = r1.wrapping_add(-384 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -144                                  r2 += -144   ///  r2 = r2.wrapping_add(-144 as i32 as i64 as u64)
    call function_13722                     
    ldxdw r2, [r10-0x170]                   
    ldxdw r1, [r10-0x178]                   
    ldxdw r7, [r10-0x180]                   
    ja lbb_2474                                     if true { pc += 1 }
lbb_2473:
    mov64 r7, 0                                     r7 = 0 as i32 as i64 as u64
lbb_2474:
    stxdw [r6+0x8], r1                      
    stxdw [r6+0x0], r7                      
    stxdw [r6+0x10], r2                     
    exit                                    

function_2478:
    mov64 r8, r5                                    r8 = r5
    stxdw [r10-0x78], r4                    
    stxdw [r10-0x80], r3                    
    stxdw [r10-0x70], r1                    
    ldxdw r7, [r8-0xfe8]                    
    ldxdw r9, [r8-0x1000]                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -88                                   r1 += -88   ///  r1 = r1.wrapping_add(-88 as i32 as i64 as u64)
    mov64 r2, r7                                    r2 = r7
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
    mov64 r4, r9                                    r4 = r9
    mov64 r5, 0                                     r5 = 0 as i32 as i64 as u64
    call function_21911                     
    ldxdw r6, [r8-0xff8]                    
    ldxdw r8, [r8-0xff0]                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -104                                  r1 += -104   ///  r1 = r1.wrapping_add(-104 as i32 as i64 as u64)
    mov64 r2, r6                                    r2 = r6
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
    mov64 r4, r8                                    r4 = r8
    mov64 r5, 0                                     r5 = 0 as i32 as i64 as u64
    call function_21911                     
    mov64 r1, r10                                   r1 = r10
    add64 r1, -72                                   r1 += -72   ///  r1 = r1.wrapping_add(-72 as i32 as i64 as u64)
    mov64 r2, r9                                    r2 = r9
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
    mov64 r4, r8                                    r4 = r8
    mov64 r5, 0                                     r5 = 0 as i32 as i64 as u64
    call function_21911                     
    ldxdw r1, [r10-0x58]                    
    ldxdw r5, [r10-0x68]                    
    mov64 r2, 1                                     r2 = 1 as i32 as i64 as u64
    ldxdw r4, [r10-0x50]                    
    mov64 r3, 1                                     r3 = 1 as i32 as i64 as u64
    jne r4, 0, lbb_2514                             if r4 != (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
lbb_2514:
    add64 r5, r1                                    r5 += r1   ///  r5 = r5.wrapping_add(r1)
    ldxdw r1, [r10-0x60]                    
    mov64 r4, 1                                     r4 = 1 as i32 as i64 as u64
    jne r1, 0, lbb_2519                             if r1 != (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r4, 0                                     r4 = 0 as i32 as i64 as u64
lbb_2519:
    ldxdw r0, [r10-0x40]                    
    mov64 r1, r0                                    r1 = r0
    add64 r1, r5                                    r1 += r5   ///  r1 = r1.wrapping_add(r5)
    mov64 r5, 1                                     r5 = 1 as i32 as i64 as u64
    jgt r0, r1, lbb_2525                            if r0 > r1 { pc += 1 }
    mov64 r5, 0                                     r5 = 0 as i32 as i64 as u64
lbb_2525:
    mov64 r0, 1                                     r0 = 1 as i32 as i64 as u64
    jne r7, 0, lbb_2528                             if r7 != (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r0, 0                                     r0 = 0 as i32 as i64 as u64
lbb_2528:
    jne r6, 0, lbb_2530                             if r6 != (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
lbb_2530:
    and64 r2, r0                                    r2 &= r0   ///  r2 = r2.and(r0)
    or64 r2, r4                                     r2 |= r4   ///  r2 = r2.or(r4)
    or64 r2, r3                                     r2 |= r3   ///  r2 = r2.or(r3)
    or64 r2, r5                                     r2 |= r5   ///  r2 = r2.or(r5)
    and64 r2, 1                                     r2 &= 1   ///  r2 = r2.and(1)
    jne r2, 0, lbb_2555                             if r2 != (0 as i32 as i64 as u64) { pc += 19 }
    mov64 r3, r9                                    r3 = r9
    ldxdw r2, [r10-0x80]                    
    add64 r3, r2                                    r3 += r2   ///  r3 = r3.wrapping_add(r2)
    mov64 r5, 1                                     r5 = 1 as i32 as i64 as u64
    mov64 r2, 1                                     r2 = 1 as i32 as i64 as u64
    jgt r9, r3, lbb_2543                            if r9 > r3 { pc += 1 }
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
lbb_2543:
    mov64 r4, r6                                    r4 = r6
    ldxdw r0, [r10-0x78]                    
    add64 r4, r0                                    r4 += r0   ///  r4 = r4.wrapping_add(r0)
    add64 r4, r2                                    r4 += r2   ///  r4 = r4.wrapping_add(r2)
    jgt r6, r4, lbb_2549                            if r6 > r4 { pc += 1 }
    mov64 r5, 0                                     r5 = 0 as i32 as i64 as u64
lbb_2549:
    ldxdw r0, [r10-0x48]                    
    jeq r4, r6, lbb_2552                            if r4 == r6 { pc += 1 }
    mov64 r2, r5                                    r2 = r5
lbb_2552:
    stxdw [r10-0x38], r0                    
    stxdw [r10-0x30], r1                    
    jne r2, 1, lbb_2559                             if r2 != (1 as i32 as i64 as u64) { pc += 4 }
lbb_2555:
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    ldxdw r2, [r10-0x70]                    
    stxdw [r2+0x0], r1                      
lbb_2558:
    exit                                    
lbb_2559:
    mov64 r1, r10                                   r1 = r10
    add64 r1, -40                                   r1 += -40   ///  r1 = r1.wrapping_add(-40 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -56                                   r2 += -56   ///  r2 = r2.wrapping_add(-56 as i32 as i64 as u64)
    call function_13303                     
    ldxdw r1, [r10-0x28]                    
    jeq r1, 0, lbb_2555                             if r1 == (0 as i32 as i64 as u64) { pc += -11 }
    ldxdw r3, [r10-0x8]                     
    mov64 r1, r3                                    r1 = r3
    sub64 r1, r6                                    r1 -= r6   ///  r1 = r1.wrapping_sub(r6)
    mov64 r4, 1                                     r4 = 1 as i32 as i64 as u64
    ldxdw r0, [r10-0x10]                    
    mov64 r2, 1                                     r2 = 1 as i32 as i64 as u64
    jgt r9, r0, lbb_2574                            if r9 > r0 { pc += 1 }
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
lbb_2574:
    sub64 r1, r2                                    r1 -= r2   ///  r1 = r1.wrapping_sub(r2)
    mov64 r2, r0                                    r2 = r0
    sub64 r2, r9                                    r2 -= r9   ///  r2 = r2.wrapping_sub(r9)
    mov64 r5, 1                                     r5 = 1 as i32 as i64 as u64
    jgt r2, r0, lbb_2580                            if r2 > r0 { pc += 1 }
    mov64 r5, 0                                     r5 = 0 as i32 as i64 as u64
lbb_2580:
    jgt r1, r3, lbb_2582                            if r1 > r3 { pc += 1 }
    mov64 r4, 0                                     r4 = 0 as i32 as i64 as u64
lbb_2582:
    jeq r1, r3, lbb_2584                            if r1 == r3 { pc += 1 }
    mov64 r5, r4                                    r5 = r4
lbb_2584:
    and64 r5, 1                                     r5 &= 1   ///  r5 = r5.and(1)
    jne r5, 0, lbb_2555                             if r5 != (0 as i32 as i64 as u64) { pc += -31 }
    ldxdw r4, [r10-0x18]                    
    ldxdw r0, [r10-0x20]                    
    mov64 r3, r7                                    r3 = r7
    sub64 r3, r4                                    r3 -= r4   ///  r3 = r3.wrapping_sub(r4)
    mov64 r5, 1                                     r5 = 1 as i32 as i64 as u64
    mov64 r4, 1                                     r4 = 1 as i32 as i64 as u64
    jgt r0, r8, lbb_2594                            if r0 > r8 { pc += 1 }
    mov64 r4, 0                                     r4 = 0 as i32 as i64 as u64
lbb_2594:
    sub64 r3, r4                                    r3 -= r4   ///  r3 = r3.wrapping_sub(r4)
    mov64 r4, r8                                    r4 = r8
    sub64 r4, r0                                    r4 -= r0   ///  r4 = r4.wrapping_sub(r0)
    mov64 r0, 1                                     r0 = 1 as i32 as i64 as u64
    jgt r4, r8, lbb_2600                            if r4 > r8 { pc += 1 }
    mov64 r0, 0                                     r0 = 0 as i32 as i64 as u64
lbb_2600:
    jgt r3, r7, lbb_2602                            if r3 > r7 { pc += 1 }
    mov64 r5, 0                                     r5 = 0 as i32 as i64 as u64
lbb_2602:
    jeq r3, r7, lbb_2604                            if r3 == r7 { pc += 1 }
    mov64 r0, r5                                    r0 = r5
lbb_2604:
    and64 r0, 1                                     r0 &= 1   ///  r0 = r0.and(1)
    jne r0, 0, lbb_2555                             if r0 != (0 as i32 as i64 as u64) { pc += -51 }
    mov64 r5, r4                                    r5 = r4
    or64 r5, r3                                     r5 |= r3   ///  r5 = r5.or(r3)
    jeq r5, 0, lbb_2555                             if r5 == (0 as i32 as i64 as u64) { pc += -54 }
    ldxdw r5, [r10-0x70]                    
    stxdw [r5+0x18], r4                     
    stxdw [r5+0x8], r2                      
    mov64 r2, 1                                     r2 = 1 as i32 as i64 as u64
    stxdw [r5+0x0], r2                      
    stxdw [r5+0x20], r3                     
    stxdw [r5+0x10], r1                     
    ja lbb_2558                                     if true { pc += -59 }

function_2617:
    mov64 r8, r5                                    r8 = r5
    stxdw [r10-0x80], r4                    
    stxdw [r10-0x78], r3                    
    stxdw [r10-0x70], r1                    
    ldxdw r7, [r8-0xfe8]                    
    ldxdw r9, [r8-0x1000]                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -88                                   r1 += -88   ///  r1 = r1.wrapping_add(-88 as i32 as i64 as u64)
    mov64 r2, r7                                    r2 = r7
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
    mov64 r4, r9                                    r4 = r9
    mov64 r5, 0                                     r5 = 0 as i32 as i64 as u64
    call function_21911                     
    ldxdw r6, [r8-0xff8]                    
    ldxdw r8, [r8-0xff0]                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -104                                  r1 += -104   ///  r1 = r1.wrapping_add(-104 as i32 as i64 as u64)
    mov64 r2, r6                                    r2 = r6
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
    mov64 r4, r8                                    r4 = r8
    mov64 r5, 0                                     r5 = 0 as i32 as i64 as u64
    call function_21911                     
    mov64 r1, r10                                   r1 = r10
    add64 r1, -72                                   r1 += -72   ///  r1 = r1.wrapping_add(-72 as i32 as i64 as u64)
    mov64 r2, r9                                    r2 = r9
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
    mov64 r4, r8                                    r4 = r8
    mov64 r5, 0                                     r5 = 0 as i32 as i64 as u64
    call function_21911                     
    ldxdw r1, [r10-0x58]                    
    ldxdw r5, [r10-0x68]                    
    mov64 r2, 1                                     r2 = 1 as i32 as i64 as u64
    ldxdw r4, [r10-0x50]                    
    mov64 r3, 1                                     r3 = 1 as i32 as i64 as u64
    jne r4, 0, lbb_2653                             if r4 != (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
lbb_2653:
    add64 r5, r1                                    r5 += r1   ///  r5 = r5.wrapping_add(r1)
    ldxdw r1, [r10-0x60]                    
    mov64 r4, 1                                     r4 = 1 as i32 as i64 as u64
    jne r1, 0, lbb_2658                             if r1 != (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r4, 0                                     r4 = 0 as i32 as i64 as u64
lbb_2658:
    ldxdw r0, [r10-0x40]                    
    mov64 r1, r0                                    r1 = r0
    add64 r1, r5                                    r1 += r5   ///  r1 = r1.wrapping_add(r5)
    mov64 r5, 1                                     r5 = 1 as i32 as i64 as u64
    jgt r0, r1, lbb_2664                            if r0 > r1 { pc += 1 }
    mov64 r5, 0                                     r5 = 0 as i32 as i64 as u64
lbb_2664:
    mov64 r0, 1                                     r0 = 1 as i32 as i64 as u64
    jne r7, 0, lbb_2667                             if r7 != (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r0, 0                                     r0 = 0 as i32 as i64 as u64
lbb_2667:
    jne r6, 0, lbb_2669                             if r6 != (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
lbb_2669:
    and64 r2, r0                                    r2 &= r0   ///  r2 = r2.and(r0)
    or64 r2, r4                                     r2 |= r4   ///  r2 = r2.or(r4)
    or64 r2, r3                                     r2 |= r3   ///  r2 = r2.or(r3)
    or64 r2, r5                                     r2 |= r5   ///  r2 = r2.or(r5)
    and64 r2, 1                                     r2 &= 1   ///  r2 = r2.and(1)
    jne r2, 0, lbb_2697                             if r2 != (0 as i32 as i64 as u64) { pc += 22 }
    mov64 r4, r7                                    r4 = r7
    ldxdw r2, [r10-0x80]                    
    sub64 r4, r2                                    r4 -= r2   ///  r4 = r4.wrapping_sub(r2)
    mov64 r2, 1                                     r2 = 1 as i32 as i64 as u64
    mov64 r3, 1                                     r3 = 1 as i32 as i64 as u64
    ldxdw r5, [r10-0x78]                    
    jgt r5, r8, lbb_2683                            if r5 > r8 { pc += 1 }
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
lbb_2683:
    sub64 r4, r3                                    r4 -= r3   ///  r4 = r4.wrapping_sub(r3)
    mov64 r3, r8                                    r3 = r8
    sub64 r3, r5                                    r3 -= r5   ///  r3 = r3.wrapping_sub(r5)
    mov64 r5, 1                                     r5 = 1 as i32 as i64 as u64
    jgt r3, r8, lbb_2689                            if r3 > r8 { pc += 1 }
    mov64 r5, 0                                     r5 = 0 as i32 as i64 as u64
lbb_2689:
    jgt r4, r7, lbb_2691                            if r4 > r7 { pc += 1 }
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
lbb_2691:
    ldxdw r0, [r10-0x48]                    
    jeq r4, r7, lbb_2694                            if r4 == r7 { pc += 1 }
    mov64 r5, r2                                    r5 = r2
lbb_2694:
    stxdw [r10-0x38], r0                    
    stxdw [r10-0x30], r1                    
    jne r5, 1, lbb_2701                             if r5 != (1 as i32 as i64 as u64) { pc += 4 }
lbb_2697:
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    ldxdw r2, [r10-0x70]                    
    stxdw [r2+0x0], r1                      
lbb_2700:
    exit                                    
lbb_2701:
    mov64 r1, r10                                   r1 = r10
    add64 r1, -40                                   r1 += -40   ///  r1 = r1.wrapping_add(-40 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -56                                   r2 += -56   ///  r2 = r2.wrapping_add(-56 as i32 as i64 as u64)
    call function_13303                     
    ldxdw r1, [r10-0x28]                    
    jeq r1, 0, lbb_2697                             if r1 == (0 as i32 as i64 as u64) { pc += -11 }
    ldxdw r3, [r10-0x18]                    
    mov64 r1, r3                                    r1 = r3
    sub64 r1, r6                                    r1 -= r6   ///  r1 = r1.wrapping_sub(r6)
    mov64 r4, 1                                     r4 = 1 as i32 as i64 as u64
    ldxdw r0, [r10-0x20]                    
    mov64 r2, 1                                     r2 = 1 as i32 as i64 as u64
    jgt r9, r0, lbb_2716                            if r9 > r0 { pc += 1 }
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
lbb_2716:
    sub64 r1, r2                                    r1 -= r2   ///  r1 = r1.wrapping_sub(r2)
    mov64 r2, r0                                    r2 = r0
    sub64 r2, r9                                    r2 -= r9   ///  r2 = r2.wrapping_sub(r9)
    mov64 r5, 1                                     r5 = 1 as i32 as i64 as u64
    jgt r2, r0, lbb_2722                            if r2 > r0 { pc += 1 }
    mov64 r5, 0                                     r5 = 0 as i32 as i64 as u64
lbb_2722:
    jgt r1, r3, lbb_2724                            if r1 > r3 { pc += 1 }
    mov64 r4, 0                                     r4 = 0 as i32 as i64 as u64
lbb_2724:
    jeq r1, r3, lbb_2726                            if r1 == r3 { pc += 1 }
    mov64 r5, r4                                    r5 = r4
lbb_2726:
    and64 r5, 1                                     r5 &= 1   ///  r5 = r5.and(1)
    jne r5, 0, lbb_2697                             if r5 != (0 as i32 as i64 as u64) { pc += -31 }
    mov64 r3, r2                                    r3 = r2
    or64 r3, r1                                     r3 |= r1   ///  r3 = r3.or(r1)
    jeq r3, 0, lbb_2697                             if r3 == (0 as i32 as i64 as u64) { pc += -34 }
    ldxdw r4, [r10-0x8]                     
    ldxdw r0, [r10-0x10]                    
    mov64 r3, r7                                    r3 = r7
    sub64 r3, r4                                    r3 -= r4   ///  r3 = r3.wrapping_sub(r4)
    mov64 r5, 1                                     r5 = 1 as i32 as i64 as u64
    mov64 r4, 1                                     r4 = 1 as i32 as i64 as u64
    jgt r0, r8, lbb_2739                            if r0 > r8 { pc += 1 }
    mov64 r4, 0                                     r4 = 0 as i32 as i64 as u64
lbb_2739:
    sub64 r3, r4                                    r3 -= r4   ///  r3 = r3.wrapping_sub(r4)
    mov64 r4, r8                                    r4 = r8
    sub64 r4, r0                                    r4 -= r0   ///  r4 = r4.wrapping_sub(r0)
    mov64 r0, 1                                     r0 = 1 as i32 as i64 as u64
    jgt r4, r8, lbb_2745                            if r4 > r8 { pc += 1 }
    mov64 r0, 0                                     r0 = 0 as i32 as i64 as u64
lbb_2745:
    jgt r3, r7, lbb_2747                            if r3 > r7 { pc += 1 }
    mov64 r5, 0                                     r5 = 0 as i32 as i64 as u64
lbb_2747:
    jeq r3, r7, lbb_2749                            if r3 == r7 { pc += 1 }
    mov64 r0, r5                                    r0 = r5
lbb_2749:
    and64 r0, 1                                     r0 &= 1   ///  r0 = r0.and(1)
    jne r0, 0, lbb_2697                             if r0 != (0 as i32 as i64 as u64) { pc += -54 }
    ldxdw r5, [r10-0x70]                    
    stxdw [r5+0x18], r4                     
    stxdw [r5+0x8], r2                      
    mov64 r2, 1                                     r2 = 1 as i32 as i64 as u64
    stxdw [r5+0x0], r2                      
    stxdw [r5+0x20], r3                     
    stxdw [r5+0x10], r1                     
    ja lbb_2700                                     if true { pc += -59 }

function_2759:
    mov64 r9, r5                                    r9 = r5
    mov64 r6, r3                                    r6 = r3
    stxdw [r10-0xb0], r1                    
    ldxdw r7, [r9-0xff0]                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -48                                   r1 += -48   ///  r1 = r1.wrapping_add(-48 as i32 as i64 as u64)
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
    stxdw [r10-0xa8], r2                    
    stxdw [r10-0xb8], r4                    
    mov64 r2, r4                                    r2 = r4
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
    mov64 r4, r7                                    r4 = r7
    mov64 r5, 0                                     r5 = 0 as i32 as i64 as u64
    call function_21911                     
    ldxdw r8, [r9-0xfe8]                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -32                                   r1 += -32   ///  r1 = r1.wrapping_add(-32 as i32 as i64 as u64)
    mov64 r2, r8                                    r2 = r8
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
    mov64 r4, r6                                    r4 = r6
    mov64 r5, 0                                     r5 = 0 as i32 as i64 as u64
    call function_21911                     
    mov64 r1, r10                                   r1 = r10
    add64 r1, -16                                   r1 += -16   ///  r1 = r1.wrapping_add(-16 as i32 as i64 as u64)
    stxdw [r10-0xc0], r6                    
    mov64 r2, r6                                    r2 = r6
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
    mov64 r4, r7                                    r4 = r7
    mov64 r5, 0                                     r5 = 0 as i32 as i64 as u64
    call function_21911                     
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    mov64 r3, 1                                     r3 = 1 as i32 as i64 as u64
    jne r8, 0, lbb_2793                             if r8 != (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
lbb_2793:
    mov64 r2, 1                                     r2 = 1 as i32 as i64 as u64
    ldxdw r8, [r10-0xb8]                    
    jne r8, 0, lbb_2797                             if r8 != (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
lbb_2797:
    and64 r2, r3                                    r2 &= r3   ///  r2 = r2.and(r3)
    ldxdw r4, [r10-0x28]                    
    mov64 r3, 1                                     r3 = 1 as i32 as i64 as u64
    jne r4, 0, lbb_2802                             if r4 != (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
lbb_2802:
    or64 r2, r3                                     r2 |= r3   ///  r2 = r2.or(r3)
    ldxdw r4, [r10-0x18]                    
    mov64 r3, 1                                     r3 = 1 as i32 as i64 as u64
    jne r4, 0, lbb_2807                             if r4 != (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
lbb_2807:
    or64 r2, r3                                     r2 |= r3   ///  r2 = r2.or(r3)
    ldxdw r3, [r10-0x20]                    
    ldxdw r4, [r10-0x30]                    
    add64 r4, r3                                    r4 += r3   ///  r4 = r4.wrapping_add(r3)
    ldxdw r5, [r10-0x8]                     
    mov64 r3, r5                                    r3 = r5
    add64 r3, r4                                    r3 += r4   ///  r3 = r3.wrapping_add(r4)
    jgt r5, r3, lbb_2816                            if r5 > r3 { pc += 1 }
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
lbb_2816:
    or64 r2, r1                                     r2 |= r1   ///  r2 = r2.or(r1)
    and64 r2, 1                                     r2 &= 1   ///  r2 = r2.and(1)
    jne r2, 0, lbb_3001                             if r2 != (0 as i32 as i64 as u64) { pc += 182 }
    ldxdw r5, [r9-0xff8]                    
    ldxdw r4, [r9-0x1000]                   
    mov64 r1, r4                                    r1 = r4
    or64 r1, r5                                     r1 |= r5   ///  r1 = r1.or(r5)
    jeq r1, 0, lbb_3001                             if r1 == (0 as i32 as i64 as u64) { pc += 177 }
    ldxdw r6, [r9-0xfd8]                    
    ldxdw r7, [r9-0xfe0]                    
    ldxdw r1, [r9-0xfd0]                    
    stxdw [r10-0xd8], r1                    
    ldxdw r2, [r10-0x10]                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -64                                   r1 += -64   ///  r1 = r1.wrapping_add(-64 as i32 as i64 as u64)
    stxdw [r10-0xe8], r2                    
    stxdw [r10-0xe0], r3                    
    stxdw [r10-0xc8], r4                    
    stxdw [r10-0xd0], r5                    
    call function_21948                     
    mov64 r1, r10                                   r1 = r10
    add64 r1, -112                                  r1 += -112   ///  r1 = r1.wrapping_add(-112 as i32 as i64 as u64)
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
    stxdw [r10-0xa8], r2                    
    mov64 r2, r8                                    r2 = r8
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
    mov64 r4, r7                                    r4 = r7
    mov64 r5, 0                                     r5 = 0 as i32 as i64 as u64
    call function_21911                     
    mov64 r1, r10                                   r1 = r10
    add64 r1, -96                                   r1 += -96   ///  r1 = r1.wrapping_add(-96 as i32 as i64 as u64)
    mov64 r2, r6                                    r2 = r6
    mov64 r9, r6                                    r9 = r6
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
    ldxdw r6, [r10-0xc0]                    
    mov64 r4, r6                                    r4 = r6
    mov64 r5, 0                                     r5 = 0 as i32 as i64 as u64
    call function_21911                     
    mov64 r1, r10                                   r1 = r10
    add64 r1, -80                                   r1 += -80   ///  r1 = r1.wrapping_add(-80 as i32 as i64 as u64)
    mov64 r2, r6                                    r2 = r6
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
    mov64 r4, r7                                    r4 = r7
    mov64 r5, 0                                     r5 = 0 as i32 as i64 as u64
    call function_21911                     
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    mov64 r3, 1                                     r3 = 1 as i32 as i64 as u64
    jne r9, 0, lbb_2865                             if r9 != (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
lbb_2865:
    mov64 r2, 1                                     r2 = 1 as i32 as i64 as u64
    jne r8, 0, lbb_2868                             if r8 != (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
lbb_2868:
    and64 r2, r3                                    r2 &= r3   ///  r2 = r2.and(r3)
    ldxdw r4, [r10-0x68]                    
    mov64 r3, 1                                     r3 = 1 as i32 as i64 as u64
    ldxdw r9, [r10-0xd0]                    
    jne r4, 0, lbb_2874                             if r4 != (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
lbb_2874:
    or64 r2, r3                                     r2 |= r3   ///  r2 = r2.or(r3)
    ldxdw r4, [r10-0x58]                    
    mov64 r3, 1                                     r3 = 1 as i32 as i64 as u64
    jne r4, 0, lbb_2879                             if r4 != (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
lbb_2879:
    or64 r2, r3                                     r2 |= r3   ///  r2 = r2.or(r3)
    ldxdw r3, [r10-0x60]                    
    ldxdw r4, [r10-0x70]                    
    add64 r4, r3                                    r4 += r3   ///  r4 = r4.wrapping_add(r3)
    ldxdw r3, [r10-0x48]                    
    mov64 r8, r3                                    r8 = r3
    add64 r8, r4                                    r8 += r4   ///  r8 = r8.wrapping_add(r4)
    jgt r3, r8, lbb_2888                            if r3 > r8 { pc += 1 }
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
lbb_2888:
    or64 r2, r1                                     r2 |= r1   ///  r2 = r2.or(r1)
    and64 r2, 1                                     r2 &= 1   ///  r2 = r2.and(1)
    ldxdw r7, [r10-0xc8]                    
    jne r2, 0, lbb_3001                             if r2 != (0 as i32 as i64 as u64) { pc += 109 }
    ldxdw r2, [r10-0x50]                    
    ldxdw r1, [r10-0x38]                    
    stxdw [r10-0xa8], r1                    
    ldxdw r6, [r10-0x40]                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -128                                  r1 += -128   ///  r1 = r1.wrapping_add(-128 as i32 as i64 as u64)
    stxdw [r10-0xb8], r2                    
    mov64 r3, r8                                    r3 = r8
    mov64 r4, r7                                    r4 = r7
    mov64 r5, r9                                    r5 = r9
    call function_21948                     
    mov64 r4, r6                                    r4 = r6
    ldxdw r3, [r10-0xa8]                    
    ldxdw r6, [r10-0x78]                    
    ldxdw r5, [r10-0x80]                    
    ldxdw r1, [r10-0xd8]                    
    lsh64 r1, 32                                    r1 <<= 32   ///  r1 = r1.wrapping_shl(32)
    rsh64 r1, 32                                    r1 >>= 32   ///  r1 = r1.wrapping_shr(32)
    jeq r1, 0, lbb_2994                             if r1 == (0 as i32 as i64 as u64) { pc += 83 }
    mov64 r1, r10                                   r1 = r10
    add64 r1, -144                                  r1 += -144   ///  r1 = r1.wrapping_add(-144 as i32 as i64 as u64)
    stxdw [r10-0xc0], r4                    
    stxdw [r10-0xf0], r6                    
    mov64 r6, r5                                    r6 = r5
    mov64 r2, r4                                    r2 = r4
    mov64 r4, r7                                    r4 = r7
    mov64 r5, r9                                    r5 = r9
    call function_21911                     
    mov64 r1, r10                                   r1 = r10
    add64 r1, -160                                  r1 += -160   ///  r1 = r1.wrapping_add(-160 as i32 as i64 as u64)
    stxdw [r10-0xd8], r6                    
    mov64 r2, r6                                    r2 = r6
    ldxdw r6, [r10-0xf0]                    
    mov64 r3, r6                                    r3 = r6
    mov64 r4, r7                                    r4 = r7
    mov64 r5, r9                                    r5 = r9
    call function_21911                     
    mov64 r2, 1                                     r2 = 1 as i32 as i64 as u64
    mov64 r4, r7                                    r4 = r7
    ldxdw r1, [r10-0xb8]                    
    jge r1, r4, lbb_2934                            if r1 >= r4 { pc += 1 }
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
lbb_2934:
    mov64 r3, 1                                     r3 = 1 as i32 as i64 as u64
    ldxdw r0, [r10-0xe0]                    
    ldxdw r7, [r10-0xe8]                    
    jge r8, r9, lbb_2939                            if r8 >= r9 { pc += 1 }
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
lbb_2939:
    jeq r8, r9, lbb_2941                            if r8 == r9 { pc += 1 }
    mov64 r2, r3                                    r2 = r3
lbb_2941:
    mov64 r3, 1                                     r3 = 1 as i32 as i64 as u64
    jge r7, r4, lbb_2944                            if r7 >= r4 { pc += 1 }
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
lbb_2944:
    mov64 r4, 1                                     r4 = 1 as i32 as i64 as u64
    jge r0, r9, lbb_2947                            if r0 >= r9 { pc += 1 }
    mov64 r4, 0                                     r4 = 0 as i32 as i64 as u64
lbb_2947:
    jeq r0, r9, lbb_2949                            if r0 == r9 { pc += 1 }
    mov64 r3, r4                                    r3 = r4
lbb_2949:
    ldxdw r4, [r10-0x98]                    
    sub64 r8, r4                                    r8 -= r4   ///  r8 = r8.wrapping_sub(r4)
    ldxdw r4, [r10-0xa0]                    
    mov64 r5, 1                                     r5 = 1 as i32 as i64 as u64
    jgt r4, r1, lbb_2955                            if r4 > r1 { pc += 1 }
    mov64 r5, 0                                     r5 = 0 as i32 as i64 as u64
lbb_2955:
    mov64 r9, r6                                    r9 = r6
    sub64 r8, r5                                    r8 -= r5   ///  r8 = r8.wrapping_sub(r5)
    sub64 r1, r4                                    r1 -= r4   ///  r1 = r1.wrapping_sub(r4)
    or64 r1, r8                                     r1 |= r8   ///  r1 = r1.or(r8)
    ldxdw r5, [r10-0x88]                    
    mov64 r4, 1                                     r4 = 1 as i32 as i64 as u64
    jne r1, 0, lbb_2963                             if r1 != (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r4, 0                                     r4 = 0 as i32 as i64 as u64
lbb_2963:
    sub64 r0, r5                                    r0 -= r5   ///  r0 = r0.wrapping_sub(r5)
    ldxdw r5, [r10-0x90]                    
    mov64 r6, r0                                    r6 = r0
    mov64 r0, 1                                     r0 = 1 as i32 as i64 as u64
    jgt r5, r7, lbb_2969                            if r5 > r7 { pc += 1 }
    mov64 r0, 0                                     r0 = 0 as i32 as i64 as u64
lbb_2969:
    sub64 r6, r0                                    r6 -= r0   ///  r6 = r6.wrapping_sub(r0)
    sub64 r7, r5                                    r7 -= r5   ///  r7 = r7.wrapping_sub(r5)
    or64 r7, r6                                     r7 |= r6   ///  r7 = r7.or(r6)
    mov64 r5, 1                                     r5 = 1 as i32 as i64 as u64
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    jne r7, 0, lbb_2976                             if r7 != (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r5, 0                                     r5 = 0 as i32 as i64 as u64
lbb_2976:
    and64 r2, r4                                    r2 &= r4   ///  r2 = r2.and(r4)
    and64 r3, r5                                    r3 &= r5   ///  r3 = r3.and(r5)
    ldxdw r5, [r10-0xc0]                    
    mov64 r4, r5                                    r4 = r5
    add64 r4, r3                                    r4 += r3   ///  r4 = r4.wrapping_add(r3)
    mov64 r3, 1                                     r3 = 1 as i32 as i64 as u64
    mov64 r6, r9                                    r6 = r9
    jgt r5, r4, lbb_2985                            if r5 > r4 { pc += 1 }
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
lbb_2985:
    ldxdw r0, [r10-0xd8]                    
    mov64 r5, r0                                    r5 = r0
    add64 r5, r2                                    r5 += r2   ///  r5 = r5.wrapping_add(r2)
    jgt r0, r5, lbb_2990                            if r0 > r5 { pc += 1 }
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
lbb_2990:
    add64 r6, r1                                    r6 += r1   ///  r6 = r6.wrapping_add(r1)
    ldxdw r1, [r10-0xa8]                    
    add64 r1, r3                                    r1 += r3   ///  r1 = r1.wrapping_add(r3)
    mov64 r3, r1                                    r3 = r1
lbb_2994:
    ldxdw r1, [r10-0xb0]                    
    stxdw [r1+0x18], r5                     
    stxdw [r1+0x8], r4                      
    stxdw [r1+0x20], r6                     
    stxdw [r1+0x10], r3                     
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    stxdw [r10-0xa8], r1                    
lbb_3001:
    ldxdw r1, [r10-0xb0]                    
    ldxdw r2, [r10-0xa8]                    
    stxdw [r1+0x0], r2                      
    exit                                    

function_3005:
    mov64 r0, r4                                    r0 = r4
    mov64 r2, r3                                    r2 = r3
    mov64 r6, r1                                    r6 = r1
    ldxdw r1, [r5-0xfd0]                    
    stxdw [r10-0xfd8], r1                   
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    stxdw [r10-0xfd0], r1                   
    ldxdw r1, [r5-0xfd8]                    
    stxdw [r10-0xfe0], r1                   
    ldxdw r1, [r5-0xfe0]                    
    stxdw [r10-0xfe8], r1                   
    ldxdw r1, [r5-0xfe8]                    
    stxdw [r10-0xff0], r1                   
    ldxdw r1, [r5-0xff0]                    
    stxdw [r10-0xff8], r1                   
    ldxdw r1, [r5-0xff8]                    
    stxdw [r10-0x1000], r1                  
    ldxdw r4, [r5-0x1000]                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -24                                   r1 += -24   ///  r1 = r1.wrapping_add(-24 as i32 as i64 as u64)
    mov64 r5, r10                                   r5 = r10
    mov64 r3, r0                                    r3 = r0
    call function_2040                      
    ldxdw r1, [r10-0x8]                     
    ldxdw r2, [r10-0x10]                    
    ldxdw r3, [r10-0x18]                    
    stxdw [r6+0x0], r3                      
    stxdw [r6+0x8], r2                      
    stxdw [r6+0x10], r1                     
    exit                                    

function_3035:
    mov64 r0, r4                                    r0 = r4
    mov64 r2, r3                                    r2 = r3
    mov64 r6, r1                                    r6 = r1
    ldxdw r1, [r5-0xfd0]                    
    stxdw [r10-0xfd8], r1                   
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    stxdw [r10-0xfd0], r1                   
    ldxdw r1, [r5-0xfd8]                    
    stxdw [r10-0xfe0], r1                   
    ldxdw r1, [r5-0xfe0]                    
    stxdw [r10-0xfe8], r1                   
    ldxdw r1, [r5-0xfe8]                    
    stxdw [r10-0xff0], r1                   
    ldxdw r1, [r5-0xff0]                    
    stxdw [r10-0xff8], r1                   
    ldxdw r1, [r5-0xff8]                    
    stxdw [r10-0x1000], r1                  
    ldxdw r4, [r5-0x1000]                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -24                                   r1 += -24   ///  r1 = r1.wrapping_add(-24 as i32 as i64 as u64)
    mov64 r5, r10                                   r5 = r10
    mov64 r3, r0                                    r3 = r0
    call function_2259                      
    ldxdw r1, [r10-0x8]                     
    ldxdw r2, [r10-0x10]                    
    ldxdw r3, [r10-0x18]                    
    stxdw [r6+0x0], r3                      
    stxdw [r6+0x8], r2                      
    stxdw [r6+0x10], r1                     
    exit                                    

function_3065:
    mov64 r7, r5                                    r7 = r5
    mov64 r2, r3                                    r2 = r3
    mov64 r6, r1                                    r6 = r1
    mov64 r1, r10                                   r1 = r10
    add64 r1, -40                                   r1 += -40   ///  r1 = r1.wrapping_add(-40 as i32 as i64 as u64)
    mov64 r3, r4                                    r3 = r4
    call function_13690                     
    ldxdw r1, [r10-0x28]                    
    jeq r1, 0, lbb_3119                             if r1 == (0 as i32 as i64 as u64) { pc += 45 }
    ldxdw r3, [r7-0xff8]                    
    ldxdw r2, [r7-0x1000]                   
    ldxdw r1, [r10-0x8]                     
    stxdw [r10-0x70], r1                    
    ldxdw r1, [r10-0x10]                    
    stxdw [r10-0x78], r1                    
    ldxdw r1, [r10-0x18]                    
    stxdw [r10-0x80], r1                    
    ldxdw r1, [r10-0x20]                    
    stxdw [r10-0x88], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -40                                   r1 += -40   ///  r1 = r1.wrapping_add(-40 as i32 as i64 as u64)
    call function_13690                     
    ldxdw r1, [r10-0x28]                    
    jeq r1, 0, lbb_3119                             if r1 == (0 as i32 as i64 as u64) { pc += 30 }
    ldxdw r1, [r10-0x8]                     
    stxdw [r10-0x50], r1                    
    ldxdw r1, [r10-0x10]                    
    stxdw [r10-0x58], r1                    
    ldxdw r1, [r10-0x18]                    
    stxdw [r10-0x60], r1                    
    ldxdw r1, [r10-0x20]                    
    stxdw [r10-0x68], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -40                                   r1 += -40   ///  r1 = r1.wrapping_add(-40 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -136                                  r2 += -136   ///  r2 = r2.wrapping_add(-136 as i32 as i64 as u64)
    mov64 r3, r10                                   r3 = r10
    add64 r3, -104                                  r3 += -104   ///  r3 = r3.wrapping_add(-104 as i32 as i64 as u64)
    call function_14167                     
    ldxdw r1, [r10-0x28]                    
    jeq r1, 0, lbb_3119                             if r1 == (0 as i32 as i64 as u64) { pc += 13 }
    ldxdw r1, [r10-0x8]                     
    stxdw [r10-0x30], r1                    
    ldxdw r1, [r10-0x10]                    
    stxdw [r10-0x38], r1                    
    ldxdw r1, [r10-0x18]                    
    stxdw [r10-0x40], r1                    
    ldxdw r1, [r10-0x20]                    
    stxdw [r10-0x48], r1                    
    mov64 r2, r10                                   r2 = r10
    add64 r2, -72                                   r2 += -72   ///  r2 = r2.wrapping_add(-72 as i32 as i64 as u64)
    mov64 r1, r6                                    r1 = r6
    call function_15298                     
    ja lbb_3121                                     if true { pc += 2 }
lbb_3119:
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    stxdw [r6+0x0], r1                      
lbb_3121:
    exit                                    

function_3122:
    mov64 r0, 28                                    r0 = 28 as i32 as i64 as u64
    exit                                    

function_3124:
    mov64 r0, 1                                     r0 = 1 as i32 as i64 as u64
    exit                                    

function_3126:
    exit                                    

function_3127:
    mov64 r8, r3                                    r8 = r3
    mov64 r6, r1                                    r6 = r1
    mov64 r7, 0                                     r7 = 0 as i32 as i64 as u64
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    mov64 r5, 1                                     r5 = 1 as i32 as i64 as u64
    ldxdw r9, [r2+0x20]                     
    jeq r9, 0, lbb_3192                             if r9 == (0 as i32 as i64 as u64) { pc += 58 }
    mov64 r3, r8                                    r3 = r8
    or64 r3, r4                                     r3 |= r4   ///  r3 = r3.or(r4)
    jeq r3, 0, lbb_3192                             if r3 == (0 as i32 as i64 as u64) { pc += 55 }
    ldxdw r1, [r2+0x28]                     
    stxdw [r10-0x38], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -32                                   r1 += -32   ///  r1 = r1.wrapping_add(-32 as i32 as i64 as u64)
    mov64 r2, r4                                    r2 = r4
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
    mov64 r4, r9                                    r4 = r9
    mov64 r5, 0                                     r5 = 0 as i32 as i64 as u64
    call function_21911                     
    mov64 r1, r10                                   r1 = r10
    add64 r1, -16                                   r1 += -16   ///  r1 = r1.wrapping_add(-16 as i32 as i64 as u64)
    mov64 r2, r8                                    r2 = r8
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
    mov64 r4, r9                                    r4 = r9
    mov64 r5, 0                                     r5 = 0 as i32 as i64 as u64
    call function_21911                     
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    ldxdw r3, [r10-0x18]                    
    mov64 r2, 1                                     r2 = 1 as i32 as i64 as u64
    jne r3, 0, lbb_3158                             if r3 != (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
lbb_3158:
    ldxdw r3, [r10-0x8]                     
    ldxdw r4, [r10-0x20]                    
    mov64 r8, r3                                    r8 = r3
    add64 r8, r4                                    r8 += r4   ///  r8 = r8.wrapping_add(r4)
    jgt r3, r8, lbb_3164                            if r3 > r8 { pc += 1 }
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
lbb_3164:
    or64 r2, r1                                     r2 |= r1   ///  r2 = r2.or(r1)
    and64 r2, 1                                     r2 &= 1   ///  r2 = r2.and(1)
    mov64 r5, 0                                     r5 = 0 as i32 as i64 as u64
    jne r2, 0, lbb_3192                             if r2 != (0 as i32 as i64 as u64) { pc += 24 }
    ldxdw r2, [r10-0x38]                    
    jeq r2, 0, lbb_3192                             if r2 == (0 as i32 as i64 as u64) { pc += 22 }
    ldxdw r2, [r10-0x10]                    
    stxdw [r10-0x40], r2                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -48                                   r1 += -48   ///  r1 = r1.wrapping_add(-48 as i32 as i64 as u64)
    mov64 r7, 0                                     r7 = 0 as i32 as i64 as u64
    mov64 r3, r8                                    r3 = r8
    ldxdw r9, [r10-0x38]                    
    mov64 r4, r9                                    r4 = r9
    mov64 r5, 0                                     r5 = 0 as i32 as i64 as u64
    call function_21948                     
    mov64 r5, 1                                     r5 = 1 as i32 as i64 as u64
    mov64 r2, 1                                     r2 = 1 as i32 as i64 as u64
    ldxdw r1, [r10-0x40]                    
    jgt r9, r1, lbb_3185                            if r9 > r1 { pc += 1 }
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
lbb_3185:
    jeq r8, 0, lbb_3187                             if r8 == (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
lbb_3187:
    jne r2, 0, lbb_3189                             if r2 != (0 as i32 as i64 as u64) { pc += 1 }
    ldxdw r7, [r10-0x28]                    
lbb_3189:
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    jne r2, 0, lbb_3192                             if r2 != (0 as i32 as i64 as u64) { pc += 1 }
    ldxdw r1, [r10-0x30]                    
lbb_3192:
    stxdw [r6+0x8], r1                      
    stxdw [r6+0x0], r5                      
    stxdw [r6+0x10], r7                     
    exit                                    

function_3196:
    mov64 r8, r3                                    r8 = r3
    mov64 r6, r1                                    r6 = r1
    mov64 r7, 0                                     r7 = 0 as i32 as i64 as u64
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    mov64 r5, 1                                     r5 = 1 as i32 as i64 as u64
    ldxdw r9, [r2+0x30]                     
    jeq r9, 0, lbb_3261                             if r9 == (0 as i32 as i64 as u64) { pc += 58 }
    mov64 r3, r8                                    r3 = r8
    or64 r3, r4                                     r3 |= r4   ///  r3 = r3.or(r4)
    jeq r3, 0, lbb_3261                             if r3 == (0 as i32 as i64 as u64) { pc += 55 }
    ldxdw r1, [r2+0x38]                     
    stxdw [r10-0x38], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -32                                   r1 += -32   ///  r1 = r1.wrapping_add(-32 as i32 as i64 as u64)
    mov64 r2, r4                                    r2 = r4
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
    mov64 r4, r9                                    r4 = r9
    mov64 r5, 0                                     r5 = 0 as i32 as i64 as u64
    call function_21911                     
    mov64 r1, r10                                   r1 = r10
    add64 r1, -16                                   r1 += -16   ///  r1 = r1.wrapping_add(-16 as i32 as i64 as u64)
    mov64 r2, r8                                    r2 = r8
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
    mov64 r4, r9                                    r4 = r9
    mov64 r5, 0                                     r5 = 0 as i32 as i64 as u64
    call function_21911                     
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    ldxdw r3, [r10-0x18]                    
    mov64 r2, 1                                     r2 = 1 as i32 as i64 as u64
    jne r3, 0, lbb_3227                             if r3 != (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
lbb_3227:
    ldxdw r3, [r10-0x8]                     
    ldxdw r4, [r10-0x20]                    
    mov64 r8, r3                                    r8 = r3
    add64 r8, r4                                    r8 += r4   ///  r8 = r8.wrapping_add(r4)
    jgt r3, r8, lbb_3233                            if r3 > r8 { pc += 1 }
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
lbb_3233:
    or64 r2, r1                                     r2 |= r1   ///  r2 = r2.or(r1)
    and64 r2, 1                                     r2 &= 1   ///  r2 = r2.and(1)
    mov64 r5, 0                                     r5 = 0 as i32 as i64 as u64
    jne r2, 0, lbb_3261                             if r2 != (0 as i32 as i64 as u64) { pc += 24 }
    ldxdw r2, [r10-0x38]                    
    jeq r2, 0, lbb_3261                             if r2 == (0 as i32 as i64 as u64) { pc += 22 }
    ldxdw r2, [r10-0x10]                    
    stxdw [r10-0x40], r2                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -48                                   r1 += -48   ///  r1 = r1.wrapping_add(-48 as i32 as i64 as u64)
    mov64 r7, 0                                     r7 = 0 as i32 as i64 as u64
    mov64 r3, r8                                    r3 = r8
    ldxdw r9, [r10-0x38]                    
    mov64 r4, r9                                    r4 = r9
    mov64 r5, 0                                     r5 = 0 as i32 as i64 as u64
    call function_21948                     
    mov64 r5, 1                                     r5 = 1 as i32 as i64 as u64
    mov64 r2, 1                                     r2 = 1 as i32 as i64 as u64
    ldxdw r1, [r10-0x40]                    
    jgt r9, r1, lbb_3254                            if r9 > r1 { pc += 1 }
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
lbb_3254:
    jeq r8, 0, lbb_3256                             if r8 == (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
lbb_3256:
    jne r2, 0, lbb_3258                             if r2 != (0 as i32 as i64 as u64) { pc += 1 }
    ldxdw r7, [r10-0x28]                    
lbb_3258:
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    jne r2, 0, lbb_3261                             if r2 != (0 as i32 as i64 as u64) { pc += 1 }
    ldxdw r1, [r10-0x30]                    
lbb_3261:
    stxdw [r6+0x8], r1                      
    stxdw [r6+0x0], r5                      
    stxdw [r6+0x10], r7                     
    exit                                    

function_3265:
    mov64 r0, 23                                    r0 = 23 as i32 as i64 as u64
    ldxdw r2, [r1+0x8]                      
    ldxdw r3, [r1+0x0]                      
    mov64 r4, r2                                    r4 = r2
    or64 r4, r3                                     r4 |= r3   ///  r4 = r4.or(r3)
    jeq r4, 0, lbb_3272                             if r4 == (0 as i32 as i64 as u64) { pc += 1 }
    jge r3, r2, lbb_3278                            if r3 >= r2 { pc += 6 }
lbb_3272:
    ldxdw r2, [r1+0x18]                     
    ldxdw r3, [r1+0x10]                     
    mov64 r4, r2                                    r4 = r2
    or64 r4, r3                                     r4 |= r3   ///  r4 = r4.or(r3)
    jeq r4, 0, lbb_3279                             if r4 == (0 as i32 as i64 as u64) { pc += 2 }
    jgt r2, r3, lbb_3279                            if r2 > r3 { pc += 1 }
lbb_3278:
    exit                                    
lbb_3279:
    ldxdw r2, [r1+0x28]                     
    ldxdw r3, [r1+0x20]                     
    mov64 r4, r2                                    r4 = r2
    or64 r4, r3                                     r4 |= r3   ///  r4 = r4.or(r3)
    jeq r4, 0, lbb_3285                             if r4 == (0 as i32 as i64 as u64) { pc += 1 }
    jge r3, r2, lbb_3278                            if r3 >= r2 { pc += -7 }
lbb_3285:
    ldxdw r2, [r1+0x38]                     
    ldxdw r1, [r1+0x30]                     
    mov64 r3, r2                                    r3 = r2
    or64 r3, r1                                     r3 |= r1   ///  r3 = r3.or(r1)
    jeq r3, 0, lbb_3291                             if r3 == (0 as i32 as i64 as u64) { pc += 1 }
    jge r1, r2, lbb_3278                            if r1 >= r2 { pc += -13 }
lbb_3291:
    mov64 r0, 28                                    r0 = 28 as i32 as i64 as u64
    ja lbb_3278                                     if true { pc += -15 }

function_3293:
    stxdw [r10-0x80], r3                    
    stxdw [r10-0x70], r1                    
    ldxdw r7, [r5-0xfe8]                    
    ldxdw r6, [r5-0xff0]                    
    ldxdw r3, [r5-0xff8]                    
    ldxdw r1, [r5-0x1000]                   
    ldxdw r0, [r2+0x0]                      
    ldxdw r2, [r5-0xfe0]                    
    lsh64 r2, 32                                    r2 <<= 32   ///  r2 = r2.wrapping_shl(32)
    rsh64 r2, 32                                    r2 >>= 32   ///  r2 = r2.wrapping_shr(32)
    jeq r2, 0, lbb_3319                             if r2 == (0 as i32 as i64 as u64) { pc += 15 }
    stxdw [r10-0x78], r6                    
    mov64 r9, r1                                    r9 = r1
    add64 r9, r0                                    r9 += r0   ///  r9 = r9.wrapping_add(r0)
    mov64 r5, 1                                     r5 = 1 as i32 as i64 as u64
    mov64 r2, 1                                     r2 = 1 as i32 as i64 as u64
    jgt r1, r9, lbb_3311                            if r1 > r9 { pc += 1 }
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
lbb_3311:
    mov64 r6, r3                                    r6 = r3
    add64 r6, r2                                    r6 += r2   ///  r6 = r6.wrapping_add(r2)
    jgt r3, r6, lbb_3315                            if r3 > r6 { pc += 1 }
    mov64 r5, 0                                     r5 = 0 as i32 as i64 as u64
lbb_3315:
    jge r9, r1, lbb_3317                            if r9 >= r1 { pc += 1 }
    mov64 r2, r5                                    r2 = r5
lbb_3317:
    jne r2, 1, lbb_3337                             if r2 != (1 as i32 as i64 as u64) { pc += 19 }
    ja lbb_3411                                     if true { pc += 92 }
lbb_3319:
    mov64 r2, r6                                    r2 = r6
    add64 r2, r0                                    r2 += r0   ///  r2 = r2.wrapping_add(r0)
    mov64 r0, 1                                     r0 = 1 as i32 as i64 as u64
    mov64 r8, 1                                     r8 = 1 as i32 as i64 as u64
    jgt r6, r2, lbb_3325                            if r6 > r2 { pc += 1 }
    mov64 r8, 0                                     r8 = 0 as i32 as i64 as u64
lbb_3325:
    mov64 r5, r7                                    r5 = r7
    add64 r5, r8                                    r5 += r8   ///  r5 = r5.wrapping_add(r8)
    jgt r7, r5, lbb_3329                            if r7 > r5 { pc += 1 }
    mov64 r0, 0                                     r0 = 0 as i32 as i64 as u64
lbb_3329:
    jge r2, r6, lbb_3331                            if r2 >= r6 { pc += 1 }
    mov64 r8, r0                                    r8 = r0
lbb_3331:
    and64 r8, 1                                     r8 &= 1   ///  r8 = r8.and(1)
    mov64 r9, r1                                    r9 = r1
    mov64 r6, r3                                    r6 = r3
    stxdw [r10-0x78], r2                    
    mov64 r7, r5                                    r7 = r5
    jne r8, 0, lbb_3411                             if r8 != (0 as i32 as i64 as u64) { pc += 74 }
lbb_3337:
    stxdw [r10-0x88], r4                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -88                                   r1 += -88   ///  r1 = r1.wrapping_add(-88 as i32 as i64 as u64)
    mov64 r2, r7                                    r2 = r7
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
    mov64 r4, r9                                    r4 = r9
    mov64 r5, 0                                     r5 = 0 as i32 as i64 as u64
    call function_21911                     
    mov64 r1, r10                                   r1 = r10
    add64 r1, -104                                  r1 += -104   ///  r1 = r1.wrapping_add(-104 as i32 as i64 as u64)
    mov64 r2, r6                                    r2 = r6
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
    ldxdw r8, [r10-0x78]                    
    mov64 r4, r8                                    r4 = r8
    mov64 r5, 0                                     r5 = 0 as i32 as i64 as u64
    call function_21911                     
    mov64 r1, r10                                   r1 = r10
    add64 r1, -72                                   r1 += -72   ///  r1 = r1.wrapping_add(-72 as i32 as i64 as u64)
    mov64 r2, r9                                    r2 = r9
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
    mov64 r4, r8                                    r4 = r8
    mov64 r5, 0                                     r5 = 0 as i32 as i64 as u64
    call function_21911                     
    ldxdw r1, [r10-0x50]                    
    mov64 r3, 1                                     r3 = 1 as i32 as i64 as u64
    jne r1, 0, lbb_3364                             if r1 != (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
lbb_3364:
    mov64 r2, r7                                    r2 = r7
    ldxdw r1, [r10-0x60]                    
    mov64 r4, 1                                     r4 = 1 as i32 as i64 as u64
    jne r1, 0, lbb_3369                             if r1 != (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r4, 0                                     r4 = 0 as i32 as i64 as u64
lbb_3369:
    ldxdw r1, [r10-0x58]                    
    ldxdw r7, [r10-0x68]                    
    mov64 r0, 1                                     r0 = 1 as i32 as i64 as u64
    jne r2, 0, lbb_3374                             if r2 != (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r0, 0                                     r0 = 0 as i32 as i64 as u64
lbb_3374:
    ldxdw r5, [r10-0x70]                    
    add64 r7, r1                                    r7 += r1   ///  r7 = r7.wrapping_add(r1)
    mov64 r5, 1                                     r5 = 1 as i32 as i64 as u64
    jne r6, 0, lbb_3379                             if r6 != (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r5, 0                                     r5 = 0 as i32 as i64 as u64
lbb_3379:
    ldxdw r1, [r10-0x40]                    
    mov64 r8, r1                                    r8 = r1
    add64 r8, r7                                    r8 += r7   ///  r8 = r8.wrapping_add(r7)
    mov64 r7, 1                                     r7 = 1 as i32 as i64 as u64
    jgt r1, r8, lbb_3385                            if r1 > r8 { pc += 1 }
    mov64 r7, 0                                     r7 = 0 as i32 as i64 as u64
lbb_3385:
    and64 r5, r0                                    r5 &= r0   ///  r5 = r5.and(r0)
    or64 r5, r4                                     r5 |= r4   ///  r5 = r5.or(r4)
    or64 r5, r3                                     r5 |= r3   ///  r5 = r5.or(r3)
    or64 r5, r7                                     r5 |= r7   ///  r5 = r5.or(r7)
    and64 r5, 1                                     r5 &= 1   ///  r5 = r5.and(1)
    mov64 r7, r2                                    r7 = r2
    jne r5, 0, lbb_3411                             if r5 != (0 as i32 as i64 as u64) { pc += 19 }
    mov64 r3, r9                                    r3 = r9
    ldxdw r1, [r10-0x80]                    
    add64 r3, r1                                    r3 += r1   ///  r3 = r3.wrapping_add(r1)
    mov64 r5, 1                                     r5 = 1 as i32 as i64 as u64
    mov64 r2, 1                                     r2 = 1 as i32 as i64 as u64
    jgt r9, r3, lbb_3399                            if r9 > r3 { pc += 1 }
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
lbb_3399:
    mov64 r4, r6                                    r4 = r6
    ldxdw r1, [r10-0x88]                    
    add64 r4, r1                                    r4 += r1   ///  r4 = r4.wrapping_add(r1)
    add64 r4, r2                                    r4 += r2   ///  r4 = r4.wrapping_add(r2)
    jgt r6, r4, lbb_3405                            if r6 > r4 { pc += 1 }
    mov64 r5, 0                                     r5 = 0 as i32 as i64 as u64
lbb_3405:
    ldxdw r0, [r10-0x48]                    
    jeq r4, r6, lbb_3408                            if r4 == r6 { pc += 1 }
    mov64 r2, r5                                    r2 = r5
lbb_3408:
    stxdw [r10-0x38], r0                    
    stxdw [r10-0x30], r8                    
    jne r2, 1, lbb_3415                             if r2 != (1 as i32 as i64 as u64) { pc += 4 }
lbb_3411:
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    ldxdw r2, [r10-0x70]                    
    stxdw [r2+0x0], r1                      
lbb_3414:
    exit                                    
lbb_3415:
    mov64 r1, r10                                   r1 = r10
    add64 r1, -40                                   r1 += -40   ///  r1 = r1.wrapping_add(-40 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -56                                   r2 += -56   ///  r2 = r2.wrapping_add(-56 as i32 as i64 as u64)
    call function_13303                     
    ldxdw r1, [r10-0x28]                    
    jeq r1, 0, lbb_3411                             if r1 == (0 as i32 as i64 as u64) { pc += -11 }
    ldxdw r3, [r10-0x8]                     
    mov64 r1, r3                                    r1 = r3
    sub64 r1, r6                                    r1 -= r6   ///  r1 = r1.wrapping_sub(r6)
    mov64 r4, 1                                     r4 = 1 as i32 as i64 as u64
    ldxdw r0, [r10-0x10]                    
    mov64 r2, 1                                     r2 = 1 as i32 as i64 as u64
    jgt r9, r0, lbb_3430                            if r9 > r0 { pc += 1 }
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
lbb_3430:
    sub64 r1, r2                                    r1 -= r2   ///  r1 = r1.wrapping_sub(r2)
    mov64 r2, r0                                    r2 = r0
    sub64 r2, r9                                    r2 -= r9   ///  r2 = r2.wrapping_sub(r9)
    mov64 r5, 1                                     r5 = 1 as i32 as i64 as u64
    jgt r2, r0, lbb_3436                            if r2 > r0 { pc += 1 }
    mov64 r5, 0                                     r5 = 0 as i32 as i64 as u64
lbb_3436:
    jgt r1, r3, lbb_3438                            if r1 > r3 { pc += 1 }
    mov64 r4, 0                                     r4 = 0 as i32 as i64 as u64
lbb_3438:
    jeq r1, r3, lbb_3440                            if r1 == r3 { pc += 1 }
    mov64 r5, r4                                    r5 = r4
lbb_3440:
    and64 r5, 1                                     r5 &= 1   ///  r5 = r5.and(1)
    jne r5, 0, lbb_3411                             if r5 != (0 as i32 as i64 as u64) { pc += -31 }
    ldxdw r4, [r10-0x18]                    
    ldxdw r0, [r10-0x20]                    
    mov64 r3, r7                                    r3 = r7
    sub64 r3, r4                                    r3 -= r4   ///  r3 = r3.wrapping_sub(r4)
    mov64 r5, 1                                     r5 = 1 as i32 as i64 as u64
    mov64 r4, 1                                     r4 = 1 as i32 as i64 as u64
    ldxdw r6, [r10-0x78]                    
    jgt r0, r6, lbb_3451                            if r0 > r6 { pc += 1 }
    mov64 r4, 0                                     r4 = 0 as i32 as i64 as u64
lbb_3451:
    sub64 r3, r4                                    r3 -= r4   ///  r3 = r3.wrapping_sub(r4)
    mov64 r4, r6                                    r4 = r6
    sub64 r4, r0                                    r4 -= r0   ///  r4 = r4.wrapping_sub(r0)
    mov64 r0, 1                                     r0 = 1 as i32 as i64 as u64
    jgt r4, r6, lbb_3457                            if r4 > r6 { pc += 1 }
    mov64 r0, 0                                     r0 = 0 as i32 as i64 as u64
lbb_3457:
    jgt r3, r7, lbb_3459                            if r3 > r7 { pc += 1 }
    mov64 r5, 0                                     r5 = 0 as i32 as i64 as u64
lbb_3459:
    jeq r3, r7, lbb_3461                            if r3 == r7 { pc += 1 }
    mov64 r0, r5                                    r0 = r5
lbb_3461:
    and64 r0, 1                                     r0 &= 1   ///  r0 = r0.and(1)
    jne r0, 0, lbb_3411                             if r0 != (0 as i32 as i64 as u64) { pc += -52 }
    mov64 r5, r4                                    r5 = r4
    or64 r5, r3                                     r5 |= r3   ///  r5 = r5.or(r3)
    jeq r5, 0, lbb_3411                             if r5 == (0 as i32 as i64 as u64) { pc += -55 }
    ldxdw r5, [r10-0x70]                    
    stxdw [r5+0x18], r4                     
    stxdw [r5+0x8], r2                      
    mov64 r2, 1                                     r2 = 1 as i32 as i64 as u64
    stxdw [r5+0x0], r2                      
    stxdw [r5+0x20], r3                     
    stxdw [r5+0x10], r1                     
    ja lbb_3414                                     if true { pc += -60 }

function_3474:
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
    stxdw [r1+0x0], r2                      
    exit                                    

function_3477:
    stxdw [r10-0xa8], r3                    
    mov64 r7, r1                                    r7 = r1
    ldxdw r1, [r2+0x0]                      
    ldxdw r2, [r5-0xfe0]                    
    mov64 r6, r2                                    r6 = r2
    add64 r6, r1                                    r6 += r1   ///  r6 = r6.wrapping_add(r1)
    mov64 r0, 0                                     r0 = 0 as i32 as i64 as u64
    mov64 r3, 1                                     r3 = 1 as i32 as i64 as u64
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    jgt r2, r6, lbb_3488                            if r2 > r6 { pc += 1 }
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
lbb_3488:
    ldxdw r8, [r5-0xfd8]                    
    mov64 r9, r8                                    r9 = r8
    add64 r9, r1                                    r9 += r1   ///  r9 = r9.wrapping_add(r1)
    stxdw [r10-0xc8], r9                    
    jgt r8, r9, lbb_3494                            if r8 > r9 { pc += 1 }
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
lbb_3494:
    jge r6, r2, lbb_3496                            if r6 >= r2 { pc += 1 }
    mov64 r1, r3                                    r1 = r3
lbb_3496:
    and64 r1, 1                                     r1 &= 1   ///  r1 = r1.and(1)
    jne r1, 0, lbb_3736                             if r1 != (0 as i32 as i64 as u64) { pc += 238 }
    stxdw [r10-0xd0], r7                    
    mov64 r2, r4                                    r2 = r4
    ldxdw r8, [r5-0xfe8]                    
    ldxdw r7, [r5-0xff0]                    
    ldxdw r1, [r5-0xff8]                    
    stxdw [r10-0xb0], r1                    
    ldxdw r1, [r5-0x1000]                   
    stxdw [r10-0xb8], r1                    
    ldxdw r1, [r5-0xfd0]                    
    stxdw [r10-0xd8], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -48                                   r1 += -48   ///  r1 = r1.wrapping_add(-48 as i32 as i64 as u64)
    stxdw [r10-0xc0], r2                    
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
    mov64 r4, r7                                    r4 = r7
    mov64 r5, 0                                     r5 = 0 as i32 as i64 as u64
    call function_21911                     
    mov64 r1, r10                                   r1 = r10
    add64 r1, -32                                   r1 += -32   ///  r1 = r1.wrapping_add(-32 as i32 as i64 as u64)
    mov64 r2, r8                                    r2 = r8
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
    ldxdw r9, [r10-0xa8]                    
    mov64 r4, r9                                    r4 = r9
    mov64 r5, 0                                     r5 = 0 as i32 as i64 as u64
    call function_21911                     
    mov64 r1, r10                                   r1 = r10
    add64 r1, -16                                   r1 += -16   ///  r1 = r1.wrapping_add(-16 as i32 as i64 as u64)
    mov64 r2, r9                                    r2 = r9
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
    mov64 r4, r7                                    r4 = r7
    mov64 r5, 0                                     r5 = 0 as i32 as i64 as u64
    call function_21911                     
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    mov64 r3, 1                                     r3 = 1 as i32 as i64 as u64
    jne r8, 0, lbb_3534                             if r8 != (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
lbb_3534:
    mov64 r2, 1                                     r2 = 1 as i32 as i64 as u64
    ldxdw r8, [r10-0xc0]                    
    jne r8, 0, lbb_3538                             if r8 != (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
lbb_3538:
    and64 r2, r3                                    r2 &= r3   ///  r2 = r2.and(r3)
    ldxdw r4, [r10-0x28]                    
    mov64 r3, 1                                     r3 = 1 as i32 as i64 as u64
    ldxdw r7, [r10-0xd0]                    
    ldxdw r5, [r10-0xb0]                    
    jne r4, 0, lbb_3545                             if r4 != (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
lbb_3545:
    or64 r2, r3                                     r2 |= r3   ///  r2 = r2.or(r3)
    ldxdw r4, [r10-0x18]                    
    mov64 r3, 1                                     r3 = 1 as i32 as i64 as u64
    jne r4, 0, lbb_3550                             if r4 != (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
lbb_3550:
    or64 r2, r3                                     r2 |= r3   ///  r2 = r2.or(r3)
    ldxdw r3, [r10-0x20]                    
    ldxdw r4, [r10-0x30]                    
    add64 r4, r3                                    r4 += r3   ///  r4 = r4.wrapping_add(r3)
    ldxdw r0, [r10-0x8]                     
    mov64 r3, r0                                    r3 = r0
    add64 r3, r4                                    r3 += r4   ///  r3 = r3.wrapping_add(r4)
    jgt r0, r3, lbb_3559                            if r0 > r3 { pc += 1 }
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
lbb_3559:
    or64 r2, r1                                     r2 |= r1   ///  r2 = r2.or(r1)
    and64 r2, 1                                     r2 &= 1   ///  r2 = r2.and(1)
    ldxdw r4, [r10-0xb8]                    
    mov64 r0, 0                                     r0 = 0 as i32 as i64 as u64
    jne r2, 0, lbb_3736                             if r2 != (0 as i32 as i64 as u64) { pc += 172 }
    mov64 r1, r4                                    r1 = r4
    or64 r1, r5                                     r1 |= r5   ///  r1 = r1.or(r5)
    jeq r1, 0, lbb_3736                             if r1 == (0 as i32 as i64 as u64) { pc += 169 }
    ldxdw r2, [r10-0x10]                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -64                                   r1 += -64   ///  r1 = r1.wrapping_add(-64 as i32 as i64 as u64)
    stxdw [r10-0xe0], r2                    
    stxdw [r10-0xe8], r3                    
    call function_21948                     
    mov64 r1, r10                                   r1 = r10
    add64 r1, -112                                  r1 += -112   ///  r1 = r1.wrapping_add(-112 as i32 as i64 as u64)
    mov64 r2, r8                                    r2 = r8
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
    mov64 r4, r6                                    r4 = r6
    mov64 r5, 0                                     r5 = 0 as i32 as i64 as u64
    call function_21911                     
    mov64 r1, r10                                   r1 = r10
    add64 r1, -96                                   r1 += -96   ///  r1 = r1.wrapping_add(-96 as i32 as i64 as u64)
    ldxdw r8, [r10-0xc8]                    
    mov64 r2, r8                                    r2 = r8
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
    ldxdw r9, [r10-0xa8]                    
    mov64 r4, r9                                    r4 = r9
    mov64 r5, 0                                     r5 = 0 as i32 as i64 as u64
    call function_21911                     
    mov64 r1, r10                                   r1 = r10
    add64 r1, -80                                   r1 += -80   ///  r1 = r1.wrapping_add(-80 as i32 as i64 as u64)
    mov64 r2, r9                                    r2 = r9
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
    mov64 r4, r6                                    r4 = r6
    mov64 r5, 0                                     r5 = 0 as i32 as i64 as u64
    call function_21911                     
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    mov64 r3, 1                                     r3 = 1 as i32 as i64 as u64
    jne r8, 0, lbb_3600                             if r8 != (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
lbb_3600:
    mov64 r2, 1                                     r2 = 1 as i32 as i64 as u64
    ldxdw r4, [r10-0xc0]                    
    jne r4, 0, lbb_3604                             if r4 != (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
lbb_3604:
    and64 r2, r3                                    r2 &= r3   ///  r2 = r2.and(r3)
    ldxdw r4, [r10-0x68]                    
    mov64 r3, 1                                     r3 = 1 as i32 as i64 as u64
    ldxdw r8, [r10-0xb0]                    
    mov64 r0, 0                                     r0 = 0 as i32 as i64 as u64
    jne r4, 0, lbb_3611                             if r4 != (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
lbb_3611:
    or64 r2, r3                                     r2 |= r3   ///  r2 = r2.or(r3)
    ldxdw r4, [r10-0x58]                    
    mov64 r3, 1                                     r3 = 1 as i32 as i64 as u64
    jne r4, 0, lbb_3616                             if r4 != (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
lbb_3616:
    or64 r2, r3                                     r2 |= r3   ///  r2 = r2.or(r3)
    ldxdw r3, [r10-0x60]                    
    ldxdw r4, [r10-0x70]                    
    add64 r4, r3                                    r4 += r3   ///  r4 = r4.wrapping_add(r3)
    ldxdw r3, [r10-0x48]                    
    mov64 r6, r3                                    r6 = r3
    add64 r6, r4                                    r6 += r4   ///  r6 = r6.wrapping_add(r4)
    jgt r3, r6, lbb_3625                            if r3 > r6 { pc += 1 }
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
lbb_3625:
    or64 r2, r1                                     r2 |= r1   ///  r2 = r2.or(r1)
    and64 r2, 1                                     r2 &= 1   ///  r2 = r2.and(1)
    ldxdw r9, [r10-0xb8]                    
    jne r2, 0, lbb_3736                             if r2 != (0 as i32 as i64 as u64) { pc += 107 }
    ldxdw r2, [r10-0x50]                    
    ldxdw r1, [r10-0x38]                    
    stxdw [r10-0xa8], r1                    
    ldxdw r7, [r10-0x40]                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -128                                  r1 += -128   ///  r1 = r1.wrapping_add(-128 as i32 as i64 as u64)
    stxdw [r10-0xc8], r2                    
    mov64 r3, r6                                    r3 = r6
    mov64 r4, r9                                    r4 = r9
    mov64 r5, r8                                    r5 = r8
    call function_21948                     
    mov64 r4, r7                                    r4 = r7
    ldxdw r3, [r10-0xa8]                    
    ldxdw r2, [r10-0x78]                    
    ldxdw r0, [r10-0x80]                    
    ldxdw r1, [r10-0xd8]                    
    lsh64 r1, 32                                    r1 <<= 32   ///  r1 = r1.wrapping_shl(32)
    rsh64 r1, 32                                    r1 >>= 32   ///  r1 = r1.wrapping_shr(32)
    jeq r1, 0, lbb_3730                             if r1 == (0 as i32 as i64 as u64) { pc += 82 }
    mov64 r1, r10                                   r1 = r10
    add64 r1, -144                                  r1 += -144   ///  r1 = r1.wrapping_add(-144 as i32 as i64 as u64)
    stxdw [r10-0xc0], r2                    
    stxdw [r10-0xd8], r4                    
    mov64 r2, r4                                    r2 = r4
    mov64 r4, r9                                    r4 = r9
    mov64 r5, r8                                    r5 = r8
    mov64 r7, r0                                    r7 = r0
    call function_21911                     
    mov64 r1, r10                                   r1 = r10
    add64 r1, -160                                  r1 += -160   ///  r1 = r1.wrapping_add(-160 as i32 as i64 as u64)
    stxdw [r10-0xf0], r7                    
    mov64 r2, r7                                    r2 = r7
    ldxdw r3, [r10-0xc0]                    
    mov64 r4, r9                                    r4 = r9
    mov64 r5, r8                                    r5 = r8
    call function_21911                     
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    mov64 r2, 1                                     r2 = 1 as i32 as i64 as u64
    ldxdw r7, [r10-0xc8]                    
    jge r7, r9, lbb_3670                            if r7 >= r9 { pc += 1 }
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
lbb_3670:
    mov64 r3, 1                                     r3 = 1 as i32 as i64 as u64
    ldxdw r0, [r10-0xe8]                    
    jge r6, r8, lbb_3674                            if r6 >= r8 { pc += 1 }
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
lbb_3674:
    jeq r6, r8, lbb_3676                            if r6 == r8 { pc += 1 }
    mov64 r2, r3                                    r2 = r3
lbb_3676:
    mov64 r3, 1                                     r3 = 1 as i32 as i64 as u64
    ldxdw r4, [r10-0xe0]                    
    jge r4, r9, lbb_3680                            if r4 >= r9 { pc += 1 }
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
lbb_3680:
    mov64 r4, 1                                     r4 = 1 as i32 as i64 as u64
    jge r0, r8, lbb_3683                            if r0 >= r8 { pc += 1 }
    mov64 r4, 0                                     r4 = 0 as i32 as i64 as u64
lbb_3683:
    jeq r0, r8, lbb_3685                            if r0 == r8 { pc += 1 }
    mov64 r3, r4                                    r3 = r4
lbb_3685:
    ldxdw r4, [r10-0x98]                    
    sub64 r6, r4                                    r6 -= r4   ///  r6 = r6.wrapping_sub(r4)
    ldxdw r4, [r10-0xa0]                    
    mov64 r5, 1                                     r5 = 1 as i32 as i64 as u64
    jgt r4, r7, lbb_3691                            if r4 > r7 { pc += 1 }
    mov64 r5, 0                                     r5 = 0 as i32 as i64 as u64
lbb_3691:
    sub64 r6, r5                                    r6 -= r5   ///  r6 = r6.wrapping_sub(r5)
    sub64 r7, r4                                    r7 -= r4   ///  r7 = r7.wrapping_sub(r4)
    or64 r7, r6                                     r7 |= r6   ///  r7 = r7.or(r6)
    ldxdw r5, [r10-0x88]                    
    mov64 r4, 1                                     r4 = 1 as i32 as i64 as u64
    jne r7, 0, lbb_3698                             if r7 != (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r4, 0                                     r4 = 0 as i32 as i64 as u64
lbb_3698:
    sub64 r0, r5                                    r0 -= r5   ///  r0 = r0.wrapping_sub(r5)
    ldxdw r5, [r10-0x90]                    
    mov64 r6, r0                                    r6 = r0
    mov64 r0, 1                                     r0 = 1 as i32 as i64 as u64
    ldxdw r7, [r10-0xe0]                    
    jgt r5, r7, lbb_3705                            if r5 > r7 { pc += 1 }
    mov64 r0, 0                                     r0 = 0 as i32 as i64 as u64
lbb_3705:
    sub64 r6, r0                                    r6 -= r0   ///  r6 = r6.wrapping_sub(r0)
    sub64 r7, r5                                    r7 -= r5   ///  r7 = r7.wrapping_sub(r5)
    or64 r7, r6                                     r7 |= r6   ///  r7 = r7.or(r6)
    mov64 r5, 1                                     r5 = 1 as i32 as i64 as u64
    jne r7, 0, lbb_3711                             if r7 != (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r5, 0                                     r5 = 0 as i32 as i64 as u64
lbb_3711:
    and64 r2, r4                                    r2 &= r4   ///  r2 = r2.and(r4)
    and64 r3, r5                                    r3 &= r5   ///  r3 = r3.and(r5)
    ldxdw r5, [r10-0xd8]                    
    mov64 r4, r5                                    r4 = r5
    add64 r4, r3                                    r4 += r3   ///  r4 = r4.wrapping_add(r3)
    mov64 r3, 1                                     r3 = 1 as i32 as i64 as u64
    ldxdw r0, [r10-0xf0]                    
    jgt r5, r4, lbb_3720                            if r5 > r4 { pc += 1 }
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
lbb_3720:
    mov64 r5, r0                                    r5 = r0
    add64 r5, r2                                    r5 += r2   ///  r5 = r5.wrapping_add(r2)
    jgt r0, r5, lbb_3724                            if r0 > r5 { pc += 1 }
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
lbb_3724:
    ldxdw r2, [r10-0xc0]                    
    add64 r2, r1                                    r2 += r1   ///  r2 = r2.wrapping_add(r1)
    ldxdw r1, [r10-0xa8]                    
    add64 r1, r3                                    r1 += r3   ///  r1 = r1.wrapping_add(r3)
    mov64 r3, r1                                    r3 = r1
    mov64 r0, r5                                    r0 = r5
lbb_3730:
    ldxdw r7, [r10-0xd0]                    
    stxdw [r7+0x18], r0                     
    stxdw [r7+0x8], r4                      
    stxdw [r7+0x20], r2                     
    stxdw [r7+0x10], r3                     
    mov64 r0, 1                                     r0 = 1 as i32 as i64 as u64
lbb_3736:
    stxdw [r7+0x0], r0                      
    exit                                    

function_3738:
    stxdw [r10-0x20], r4                    
    mov64 r6, r1                                    r6 = r1
    ldxdw r2, [r2+0x0]                      
    ldxdw r8, [r5-0xff0]                    
    mov64 r1, r8                                    r1 = r8
    add64 r1, r2                                    r1 += r2   ///  r1 = r1.wrapping_add(r2)
    mov64 r4, 0                                     r4 = 0 as i32 as i64 as u64
    mov64 r9, 1                                     r9 = 1 as i32 as i64 as u64
    mov64 r0, 1                                     r0 = 1 as i32 as i64 as u64
    jgt r8, r1, lbb_3749                            if r8 > r1 { pc += 1 }
    mov64 r0, 0                                     r0 = 0 as i32 as i64 as u64
lbb_3749:
    ldxdw r7, [r5-0xfe8]                    
    mov64 r2, r7                                    r2 = r7
    add64 r2, r0                                    r2 += r0   ///  r2 = r2.wrapping_add(r0)
    jgt r7, r2, lbb_3754                            if r7 > r2 { pc += 1 }
    mov64 r9, 0                                     r9 = 0 as i32 as i64 as u64
lbb_3754:
    jge r1, r8, lbb_3756                            if r1 >= r8 { pc += 1 }
    mov64 r0, r9                                    r0 = r9
lbb_3756:
    and64 r0, 1                                     r0 &= 1   ///  r0 = r0.and(1)
    jne r0, 0, lbb_3781                             if r0 != (0 as i32 as i64 as u64) { pc += 23 }
    ldxdw r4, [r5-0xfd8]                    
    ldxdw r7, [r5-0xfe0]                    
    ldxdw r8, [r5-0xff8]                    
    ldxdw r0, [r5-0x1000]                   
    ldxdw r5, [r5-0xfd0]                    
    stxdw [r10-0xfd8], r5                   
    mov64 r5, 0                                     r5 = 0 as i32 as i64 as u64
    stxdw [r10-0xfd0], r5                   
    stxdw [r10-0xfe0], r4                   
    stxdw [r10-0xfe8], r7                   
    stxdw [r10-0xff0], r2                   
    stxdw [r10-0xff8], r1                   
    stxdw [r10-0x1000], r8                  
    mov64 r1, r10                                   r1 = r10
    add64 r1, -24                                   r1 += -24   ///  r1 = r1.wrapping_add(-24 as i32 as i64 as u64)
    mov64 r5, r10                                   r5 = r10
    mov64 r2, r3                                    r2 = r3
    ldxdw r3, [r10-0x20]                    
    mov64 r4, r0                                    r4 = r0
    call function_2040                      
    ldxdw r8, [r10-0x8]                     
    ldxdw r9, [r10-0x10]                    
    ldxdw r4, [r10-0x18]                    
lbb_3781:
    stxdw [r6+0x8], r9                      
    stxdw [r6+0x0], r4                      
    stxdw [r6+0x10], r8                     
    exit                                    

function_3785:
    stxdw [r10-0x20], r4                    
    mov64 r6, r1                                    r6 = r1
    ldxdw r2, [r2+0x0]                      
    ldxdw r8, [r5-0xff0]                    
    mov64 r1, r8                                    r1 = r8
    add64 r1, r2                                    r1 += r2   ///  r1 = r1.wrapping_add(r2)
    mov64 r4, 0                                     r4 = 0 as i32 as i64 as u64
    mov64 r9, 1                                     r9 = 1 as i32 as i64 as u64
    mov64 r0, 1                                     r0 = 1 as i32 as i64 as u64
    jgt r8, r1, lbb_3796                            if r8 > r1 { pc += 1 }
    mov64 r0, 0                                     r0 = 0 as i32 as i64 as u64
lbb_3796:
    ldxdw r7, [r5-0xfe8]                    
    mov64 r2, r7                                    r2 = r7
    add64 r2, r0                                    r2 += r0   ///  r2 = r2.wrapping_add(r0)
    jgt r7, r2, lbb_3801                            if r7 > r2 { pc += 1 }
    mov64 r9, 0                                     r9 = 0 as i32 as i64 as u64
lbb_3801:
    jge r1, r8, lbb_3803                            if r1 >= r8 { pc += 1 }
    mov64 r0, r9                                    r0 = r9
lbb_3803:
    and64 r0, 1                                     r0 &= 1   ///  r0 = r0.and(1)
    jne r0, 0, lbb_3828                             if r0 != (0 as i32 as i64 as u64) { pc += 23 }
    ldxdw r4, [r5-0xfd8]                    
    ldxdw r7, [r5-0xfe0]                    
    ldxdw r8, [r5-0xff8]                    
    ldxdw r0, [r5-0x1000]                   
    ldxdw r5, [r5-0xfd0]                    
    stxdw [r10-0xfd8], r5                   
    mov64 r5, 1                                     r5 = 1 as i32 as i64 as u64
    stxdw [r10-0xfd0], r5                   
    stxdw [r10-0xfe0], r4                   
    stxdw [r10-0xfe8], r7                   
    stxdw [r10-0xff0], r2                   
    stxdw [r10-0xff8], r1                   
    stxdw [r10-0x1000], r8                  
    mov64 r1, r10                                   r1 = r10
    add64 r1, -24                                   r1 += -24   ///  r1 = r1.wrapping_add(-24 as i32 as i64 as u64)
    mov64 r5, r10                                   r5 = r10
    mov64 r2, r3                                    r2 = r3
    ldxdw r3, [r10-0x20]                    
    mov64 r4, r0                                    r4 = r0
    call function_2259                      
    ldxdw r8, [r10-0x8]                     
    ldxdw r9, [r10-0x10]                    
    ldxdw r4, [r10-0x18]                    
lbb_3828:
    stxdw [r6+0x8], r9                      
    stxdw [r6+0x0], r4                      
    stxdw [r6+0x10], r8                     
    exit                                    

function_3832:
    ldxdw r1, [r1+0x0]                      
    mov64 r0, 26                                    r0 = 26 as i32 as i64 as u64
    jeq r1, 0, lbb_3836                             if r1 == (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r0, 28                                    r0 = 28 as i32 as i64 as u64
lbb_3836:
    exit                                    

function_3837:
    mov64 r0, 6                                     r0 = 6 as i32 as i64 as u64
    jeq r2, 0, lbb_3840                             if r2 == (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r0, 28                                    r0 = 28 as i32 as i64 as u64
lbb_3840:
    exit                                    

function_3841:
    mov64 r0, 0                                     r0 = 0 as i32 as i64 as u64
    exit                                    

function_3843:
    mov64 r6, r1                                    r6 = r1
    ldxdw r2, [r2+0x0]                      
    ldxdw r1, [r5-0x1000]                   
    mov64 r7, r1                                    r7 = r1
    add64 r7, r2                                    r7 += r2   ///  r7 = r7.wrapping_add(r2)
    ldxdw r0, [r5-0xff8]                    
    mov64 r5, 1                                     r5 = 1 as i32 as i64 as u64
    mov64 r2, 1                                     r2 = 1 as i32 as i64 as u64
    jgt r1, r7, lbb_3853                            if r1 > r7 { pc += 1 }
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
lbb_3853:
    mov64 r8, r0                                    r8 = r0
    add64 r8, r2                                    r8 += r2   ///  r8 = r8.wrapping_add(r2)
    jgt r0, r8, lbb_3857                            if r0 > r8 { pc += 1 }
    mov64 r5, 0                                     r5 = 0 as i32 as i64 as u64
lbb_3857:
    jge r7, r1, lbb_3859                            if r7 >= r1 { pc += 1 }
    mov64 r2, r5                                    r2 = r5
lbb_3859:
    and64 r2, 1                                     r2 &= 1   ///  r2 = r2.and(1)
    jne r2, 0, lbb_3913                             if r2 != (0 as i32 as i64 as u64) { pc += 52 }
    mov64 r1, r10                                   r1 = r10
    add64 r1, -40                                   r1 += -40   ///  r1 = r1.wrapping_add(-40 as i32 as i64 as u64)
    mov64 r2, r3                                    r2 = r3
    mov64 r3, r4                                    r3 = r4
    call function_13690                     
    ldxdw r1, [r10-0x28]                    
    jeq r1, 0, lbb_3913                             if r1 == (0 as i32 as i64 as u64) { pc += 45 }
    ldxdw r1, [r10-0x8]                     
    stxdw [r10-0x70], r1                    
    ldxdw r1, [r10-0x10]                    
    stxdw [r10-0x78], r1                    
    ldxdw r1, [r10-0x18]                    
    stxdw [r10-0x80], r1                    
    ldxdw r1, [r10-0x20]                    
    stxdw [r10-0x88], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -40                                   r1 += -40   ///  r1 = r1.wrapping_add(-40 as i32 as i64 as u64)
    mov64 r2, r7                                    r2 = r7
    mov64 r3, r8                                    r3 = r8
    call function_13690                     
    ldxdw r1, [r10-0x28]                    
    jeq r1, 0, lbb_3913                             if r1 == (0 as i32 as i64 as u64) { pc += 30 }
    ldxdw r1, [r10-0x8]                     
    stxdw [r10-0x50], r1                    
    ldxdw r1, [r10-0x10]                    
    stxdw [r10-0x58], r1                    
    ldxdw r1, [r10-0x18]                    
    stxdw [r10-0x60], r1                    
    ldxdw r1, [r10-0x20]                    
    stxdw [r10-0x68], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -40                                   r1 += -40   ///  r1 = r1.wrapping_add(-40 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -136                                  r2 += -136   ///  r2 = r2.wrapping_add(-136 as i32 as i64 as u64)
    mov64 r3, r10                                   r3 = r10
    add64 r3, -104                                  r3 += -104   ///  r3 = r3.wrapping_add(-104 as i32 as i64 as u64)
    call function_14167                     
    ldxdw r1, [r10-0x28]                    
    jeq r1, 0, lbb_3913                             if r1 == (0 as i32 as i64 as u64) { pc += 13 }
    ldxdw r1, [r10-0x8]                     
    stxdw [r10-0x30], r1                    
    ldxdw r1, [r10-0x10]                    
    stxdw [r10-0x38], r1                    
    ldxdw r1, [r10-0x18]                    
    stxdw [r10-0x40], r1                    
    ldxdw r1, [r10-0x20]                    
    stxdw [r10-0x48], r1                    
    mov64 r2, r10                                   r2 = r10
    add64 r2, -72                                   r2 += -72   ///  r2 = r2.wrapping_add(-72 as i32 as i64 as u64)
    mov64 r1, r6                                    r1 = r6
    call function_15298                     
    ja lbb_3915                                     if true { pc += 2 }
lbb_3913:
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    stxdw [r6+0x0], r1                      
lbb_3915:
    exit                                    

function_3916:
    mov64 r0, 1                                     r0 = 1 as i32 as i64 as u64
    exit                                    

function_3918:
    jgt r3, 7, lbb_3925                             if r3 > (7 as i32 as i64 as u64) { pc += 6 }
    mov64 r1, 8                                     r1 = 8 as i32 as i64 as u64
    mov64 r2, r3                                    r2 = r3
    lddw r3, 0x10002dc28 --> b"\x00\x00\x00\x00\xdf\xc3\x02\x00\x1b\x00\x00\x00\x00\x00\x00\x00\xbf\x00\…        r3 load str located at 4295154728
    call function_20726                     
    syscall [invalid]                       
lbb_3925:
    ldxdw r1, [r1+0x0]                      
    stxdw [r2+0x0], r1                      
    exit                                    

function_3928:
    mov64 r7, r3                                    r7 = r3
    mov64 r8, r2                                    r8 = r2
    stxdw [r10-0x90], r1                    
    ldxdw r1, [r8+0x18]                     
    stxdw [r10-0x70], r1                    
    ldxdw r1, [r8+0x10]                     
    stxdw [r10-0x78], r1                    
    ldxdw r1, [r8+0x8]                      
    stxdw [r10-0x80], r1                    
    ldxdw r1, [r8+0x0]                      
    stxdw [r10-0x88], r1                    
    and64 r7, 255                                   r7 &= 255   ///  r7 = r7.and(255)
    mov64 r1, 2                                     r1 = 2 as i32 as i64 as u64
    jgt r1, r7, lbb_3982                            if r1 > r7 { pc += 40 }
    mov64 r9, 1                                     r9 = 1 as i32 as i64 as u64
    mov64 r6, r10                                   r6 = r10
    add64 r6, -96                                   r6 += -96   ///  r6 = r6.wrapping_add(-96 as i32 as i64 as u64)
lbb_3945:
    ldxdw r1, [r10-0x70]                    
    stxdw [r10-0x28], r1                    
    ldxdw r1, [r10-0x78]                    
    stxdw [r10-0x30], r1                    
    ldxdw r1, [r10-0x80]                    
    stxdw [r10-0x38], r1                    
    ldxdw r1, [r10-0x88]                    
    stxdw [r10-0x40], r1                    
    ldxdw r1, [r8+0x18]                     
    stxdw [r10-0x8], r1                     
    ldxdw r1, [r8+0x10]                     
    stxdw [r10-0x10], r1                    
    ldxdw r1, [r8+0x8]                      
    stxdw [r10-0x18], r1                    
    ldxdw r1, [r8+0x0]                      
    stxdw [r10-0x20], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -104                                  r1 += -104   ///  r1 = r1.wrapping_add(-104 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -64                                   r2 += -64   ///  r2 = r2.wrapping_add(-64 as i32 as i64 as u64)
    mov64 r3, r10                                   r3 = r10
    add64 r3, -32                                   r3 += -32   ///  r3 = r3.wrapping_add(-32 as i32 as i64 as u64)
    call function_16882                     
    ldxdw r1, [r10-0x68]                    
    jeq r1, 0, lbb_3993                             if r1 == (0 as i32 as i64 as u64) { pc += 23 }
    ldxdw r1, [r6+0x18]                     
    stxdw [r10-0x70], r1                    
    ldxdw r1, [r6+0x10]                     
    stxdw [r10-0x78], r1                    
    ldxdw r1, [r6+0x8]                      
    stxdw [r10-0x80], r1                    
    ldxdw r1, [r6+0x0]                      
    stxdw [r10-0x88], r1                    
    add64 r9, 1                                     r9 += 1   ///  r9 = r9.wrapping_add(1 as i32 as i64 as u64)
    mov64 r1, r9                                    r1 = r9
    and64 r1, 255                                   r1 &= 255   ///  r1 = r1.and(255)
    jgt r7, r1, lbb_3945                            if r7 > r1 { pc += -37 }
lbb_3982:
    ldxdw r1, [r10-0x70]                    
    ldxdw r2, [r10-0x90]                    
    stxdw [r2+0x20], r1                     
    ldxdw r1, [r10-0x78]                    
    stxdw [r2+0x18], r1                     
    ldxdw r1, [r10-0x80]                    
    stxdw [r2+0x10], r1                     
    ldxdw r1, [r10-0x88]                    
    stxdw [r2+0x8], r1                      
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    ja lbb_3995                                     if true { pc += 2 }
lbb_3993:
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    ldxdw r2, [r10-0x90]                    
lbb_3995:
    stxdw [r2+0x0], r1                      
    exit                                    

function_3997:
    mov64 r7, r5                                    r7 = r5
    mov64 r8, r4                                    r8 = r4
    mov64 r9, r3                                    r9 = r3
    stxdw [r10-0x208], r2                   
    mov64 r6, r1                                    r6 = r1
    mov64 r1, r10                                   r1 = r10
    add64 r1, -136                                  r1 += -136   ///  r1 = r1.wrapping_add(-136 as i32 as i64 as u64)
    mov64 r2, r9                                    r2 = r9
    mov64 r3, r8                                    r3 = r8
    call function_15530                     
    ldxdw r1, [r10-0x70]                    
    stxdw [r10-0x8], r1                     
    ldxdw r2, [r10-0x78]                    
    stxdw [r10-0x10], r2                    
    ldxdw r3, [r10-0x80]                    
    stxdw [r10-0x18], r3                    
    ldxdw r4, [r10-0x88]                    
    stxdw [r10-0x20], r4                    
    stxdw [r10-0x140], r1                   
    stxdw [r10-0x148], r2                   
    stxdw [r10-0x150], r3                   
    stxdw [r10-0x158], r4                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -72                                   r1 += -72   ///  r1 = r1.wrapping_add(-72 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -32                                   r2 += -32   ///  r2 = r2.wrapping_add(-32 as i32 as i64 as u64)
    mov64 r3, r10                                   r3 = r10
    add64 r3, -344                                  r3 += -344   ///  r3 = r3.wrapping_add(-344 as i32 as i64 as u64)
    call function_16882                     
    ldxdw r1, [r10-0x48]                    
    jeq r1, 0, lbb_4553                             if r1 == (0 as i32 as i64 as u64) { pc += 525 }
    stxdw [r10-0x210], r8                   
    stxdw [r10-0x200], r6                   
    ldxdw r8, [r7-0xff8]                    
    ldxdw r7, [r7-0x1000]                   
    ldxdw r1, [r10-0x40]                    
    stxdw [r10-0xa8], r1                    
    ldxdw r1, [r10-0x38]                    
    stxdw [r10-0xa0], r1                    
    ldxdw r1, [r10-0x30]                    
    stxdw [r10-0x98], r1                    
    ldxdw r1, [r10-0x28]                    
    stxdw [r10-0x50], r1                    
    stxdw [r10-0x90], r1                    
    mov64 r6, r10                                   r6 = r10
    add64 r6, -72                                   r6 += -72   ///  r6 = r6.wrapping_add(-72 as i32 as i64 as u64)
    mov64 r1, r6                                    r1 = r6
    mov64 r2, 1                                     r2 = 1 as i32 as i64 as u64
    call function_17493                     
    mov64 r1, r10                                   r1 = r10
    add64 r1, -208                                  r1 += -208   ///  r1 = r1.wrapping_add(-208 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -168                                  r2 += -168   ///  r2 = r2.wrapping_add(-168 as i32 as i64 as u64)
    mov64 r3, r6                                    r3 = r6
    call function_16882                     
    ldxdw r1, [r10-0xd0]                    
    jeq r1, 0, lbb_4166                             if r1 == (0 as i32 as i64 as u64) { pc += 112 }
    ldxdw r1, [r10-0xb0]                    
    stxdw [r10-0x1e0], r1                   
    ldxdw r1, [r10-0xb8]                    
    stxdw [r10-0x1e8], r1                   
    ldxdw r1, [r10-0xc0]                    
    stxdw [r10-0x1f0], r1                   
    ldxdw r1, [r10-0xc8]                    
    stxdw [r10-0x1f8], r1                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -136                                  r1 += -136   ///  r1 = r1.wrapping_add(-136 as i32 as i64 as u64)
    mov64 r2, r7                                    r2 = r7
    mov64 r3, r8                                    r3 = r8
    call function_15530                     
    ldxdw r1, [r10-0x70]                    
    stxdw [r10-0x8], r1                     
    ldxdw r2, [r10-0x78]                    
    stxdw [r10-0x10], r2                    
    ldxdw r3, [r10-0x80]                    
    stxdw [r10-0x18], r3                    
    ldxdw r4, [r10-0x88]                    
    stxdw [r10-0x20], r4                    
    stxdw [r10-0x140], r1                   
    stxdw [r10-0x148], r2                   
    stxdw [r10-0x150], r3                   
    stxdw [r10-0x158], r4                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -72                                   r1 += -72   ///  r1 = r1.wrapping_add(-72 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -32                                   r2 += -32   ///  r2 = r2.wrapping_add(-32 as i32 as i64 as u64)
    mov64 r3, r10                                   r3 = r10
    add64 r3, -344                                  r3 += -344   ///  r3 = r3.wrapping_add(-344 as i32 as i64 as u64)
    call function_16882                     
    ldxdw r1, [r10-0x48]                    
    jeq r1, 0, lbb_4552                             if r1 == (0 as i32 as i64 as u64) { pc += 464 }
    ldxdw r1, [r10-0x40]                    
    stxdw [r10-0xa8], r1                    
    ldxdw r1, [r10-0x38]                    
    stxdw [r10-0xa0], r1                    
    ldxdw r1, [r10-0x30]                    
    stxdw [r10-0x98], r1                    
    ldxdw r1, [r10-0x28]                    
    stxdw [r10-0x50], r1                    
    stxdw [r10-0x90], r1                    
    mov64 r6, r10                                   r6 = r10
    add64 r6, -72                                   r6 += -72   ///  r6 = r6.wrapping_add(-72 as i32 as i64 as u64)
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    stxdw [r10-0x218], r1                   
    mov64 r1, r6                                    r1 = r6
    mov64 r2, 1                                     r2 = 1 as i32 as i64 as u64
    call function_17493                     
    mov64 r1, r10                                   r1 = r10
    add64 r1, -208                                  r1 += -208   ///  r1 = r1.wrapping_add(-208 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -168                                  r2 += -168   ///  r2 = r2.wrapping_add(-168 as i32 as i64 as u64)
    mov64 r3, r6                                    r3 = r6
    call function_16882                     
    ldxdw r1, [r10-0xd0]                    
    jeq r1, 0, lbb_4552                             if r1 == (0 as i32 as i64 as u64) { pc += 440 }
    ldxdw r4, [r10-0x210]                   
    mov64 r2, r9                                    r2 = r9
    add64 r2, r7                                    r2 += r7   ///  r2 = r2.wrapping_add(r7)
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    jgt r9, r2, lbb_4118                            if r9 > r2 { pc += 1 }
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
lbb_4118:
    ldxdw r3, [r10-0x210]                   
    add64 r3, r8                                    r3 += r8   ///  r3 = r3.wrapping_add(r8)
    add64 r3, r1                                    r3 += r1   ///  r3 = r3.wrapping_add(r1)
    jgt r4, r3, lbb_4124                            if r4 > r3 { pc += 2 }
    mov64 r5, 0                                     r5 = 0 as i32 as i64 as u64
    stxdw [r10-0x218], r5                   
lbb_4124:
    ldxdw r6, [r10-0x200]                   
    jeq r3, r4, lbb_4127                            if r3 == r4 { pc += 1 }
    ldxdw r1, [r10-0x218]                   
lbb_4127:
    ldxdw r4, [r10-0xb0]                    
    stxdw [r10-0x1c0], r4                   
    ldxdw r4, [r10-0xb8]                    
    stxdw [r10-0x1c8], r4                   
    ldxdw r4, [r10-0xc0]                    
    stxdw [r10-0x1d0], r4                   
    ldxdw r4, [r10-0xc8]                    
    stxdw [r10-0x1d8], r4                   
    and64 r1, 1                                     r1 &= 1   ///  r1 = r1.and(1)
    jne r1, 0, lbb_4553                             if r1 != (0 as i32 as i64 as u64) { pc += 416 }
    mov64 r4, r2                                    r4 = r2
    or64 r4, r3                                     r4 |= r3   ///  r4 = r4.or(r3)
    mov64 r0, 0                                     r0 = 0 as i32 as i64 as u64
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    mov64 r5, 0                                     r5 = 0 as i32 as i64 as u64
    jeq r4, 0, lbb_4554                             if r4 == (0 as i32 as i64 as u64) { pc += 411 }
    mov64 r1, r10                                   r1 = r10
    add64 r1, -408                                  r1 += -408   ///  r1 = r1.wrapping_add(-408 as i32 as i64 as u64)
    stxdw [r10-0x220], r2                   
    stxdw [r10-0x210], r3                   
    call function_15530                     
    ldxdw r1, [r10-0x208]                   
    mov64 r2, r1                                    r2 = r1
    add64 r2, -1                                    r2 += -1   ///  r2 = r2.wrapping_add(-1 as i32 as i64 as u64)
    mov64 r6, 0                                     r6 = 0 as i32 as i64 as u64
    mov64 r7, 1                                     r7 = 1 as i32 as i64 as u64
    stxdw [r10-0x230], r2                   
    jgt r2, r1, lbb_4156                            if r2 > r1 { pc += 1 }
    mov64 r7, 0                                     r7 = 0 as i32 as i64 as u64
lbb_4156:
    mov64 r1, r10                                   r1 = r10
    add64 r1, -336                                  r1 += -336   ///  r1 = r1.wrapping_add(-336 as i32 as i64 as u64)
    stxdw [r10-0x238], r1                   
    mov64 r9, r10                                   r9 = r10
    add64 r9, -64                                   r9 += -64   ///  r9 = r9.wrapping_add(-64 as i32 as i64 as u64)
    mov64 r8, r10                                   r8 = r10
    add64 r8, -200                                  r8 += -200   ///  r8 = r8.wrapping_add(-200 as i32 as i64 as u64)
    and64 r7, 1                                     r7 &= 1   ///  r7 = r7.and(1)
    stxdw [r10-0x228], r7                   
    ja lbb_4255                                     if true { pc += 89 }
lbb_4166:
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    ldxdw r6, [r10-0x200]                   
    ja lbb_4554                                     if true { pc += 385 }
lbb_4169:
    ldxdw r1, [r9+0x18]                     
    stxdw [r10-0x70], r1                    
    ldxdw r1, [r9+0x10]                     
    stxdw [r10-0x78], r1                    
    ldxdw r1, [r9+0x8]                      
    stxdw [r10-0x80], r1                    
    ldxdw r1, [r9+0x0]                      
    stxdw [r10-0x88], r1                    
    ldxdw r1, [r10-0x90]                    
    stxdw [r10-0x8], r1                     
    ldxdw r1, [r10-0x98]                    
    stxdw [r10-0x10], r1                    
    ldxdw r1, [r10-0xa0]                    
    stxdw [r10-0x18], r1                    
    ldxdw r1, [r10-0xa8]                    
    stxdw [r10-0x20], r1                    
    ldxdw r1, [r10-0x70]                    
    stxdw [r10-0xb8], r1                    
    ldxdw r1, [r10-0x78]                    
    stxdw [r10-0xc0], r1                    
    ldxdw r1, [r10-0x80]                    
    stxdw [r10-0xc8], r1                    
    ldxdw r1, [r10-0x88]                    
    stxdw [r10-0xd0], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -72                                   r1 += -72   ///  r1 = r1.wrapping_add(-72 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -32                                   r2 += -32   ///  r2 = r2.wrapping_add(-32 as i32 as i64 as u64)
    mov64 r3, r10                                   r3 = r10
    add64 r3, -208                                  r3 += -208   ///  r3 = r3.wrapping_add(-208 as i32 as i64 as u64)
    call function_16882                     
    ldxdw r1, [r10-0x48]                    
    jeq r1, 0, lbb_4550                             if r1 == (0 as i32 as i64 as u64) { pc += 348 }
    ldxdw r1, [r9+0x18]                     
    stxdw [r10-0x50], r1                    
    ldxdw r1, [r9+0x10]                     
    stxdw [r10-0x58], r1                    
    ldxdw r1, [r9+0x8]                      
    stxdw [r10-0x60], r1                    
    ldxdw r1, [r9+0x0]                      
    stxdw [r10-0x68], r1                    
    ldxdw r1, [r10-0xd8]                    
    stxdw [r10-0xb8], r1                    
    ldxdw r1, [r10-0xe0]                    
    stxdw [r10-0xc0], r1                    
    ldxdw r1, [r10-0xe8]                    
    stxdw [r10-0xc8], r1                    
    ldxdw r1, [r10-0xf0]                    
    stxdw [r10-0xd0], r1                    
    ldxdw r1, [r10-0x50]                    
    stxdw [r10-0x30], r1                    
    ldxdw r1, [r10-0x58]                    
    stxdw [r10-0x38], r1                    
    ldxdw r1, [r10-0x60]                    
    stxdw [r10-0x40], r1                    
    ldxdw r1, [r10-0x68]                    
    stxdw [r10-0x48], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -344                                  r1 += -344   ///  r1 = r1.wrapping_add(-344 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -208                                  r2 += -208   ///  r2 = r2.wrapping_add(-208 as i32 as i64 as u64)
    mov64 r3, r10                                   r3 = r10
    add64 r3, -72                                   r3 += -72   ///  r3 = r3.wrapping_add(-72 as i32 as i64 as u64)
    call function_17405                     
    ldxdw r1, [r10-0x158]                   
    jeq r1, 0, lbb_4552                             if r1 == (0 as i32 as i64 as u64) { pc += 317 }
    ldxdw r6, [r10-0x218]                   
    add64 r6, 1                                     r6 += 1   ///  r6 = r6.wrapping_add(1 as i32 as i64 as u64)
    ldxdw r2, [r10-0x238]                   
    ldxdw r1, [r2+0x18]                     
    stxdw [r10-0x180], r1                   
    ldxdw r1, [r2+0x10]                     
    stxdw [r10-0x188], r1                   
    ldxdw r1, [r2+0x8]                      
    stxdw [r10-0x190], r1                   
    ldxdw r1, [r2+0x0]                      
    stxdw [r10-0x198], r1                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -408                                  r1 += -408   ///  r1 = r1.wrapping_add(-408 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -440                                  r2 += -440   ///  r2 = r2.wrapping_add(-440 as i32 as i64 as u64)
    mov64 r3, 32                                    r3 = 32 as i32 as i64 as u64
    call function_21867                     
    lsh64 r0, 32                                    r0 <<= 32   ///  r0 = r0.wrapping_shl(32)
    rsh64 r0, 32                                    r0 >>= 32   ///  r0 = r0.wrapping_shr(32)
    jeq r0, 0, lbb_4259                             if r0 == (0 as i32 as i64 as u64) { pc += 4 }
lbb_4255:
    mov64 r1, r6                                    r1 = r6
    and64 r1, 255                                   r1 &= 255   ///  r1 = r1.and(255)
    mov64 r2, 32                                    r2 = 32 as i32 as i64 as u64
    jgt r2, r1, lbb_4269                            if r2 > r1 { pc += 10 }
lbb_4259:
    ldxdw r1, [r10-0x180]                   
    ldxdw r4, [r10-0x188]                   
    or64 r4, r1                                     r4 |= r1   ///  r4 = r4.or(r1)
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    ldxdw r6, [r10-0x200]                   
    jne r4, 0, lbb_4554                             if r4 != (0 as i32 as i64 as u64) { pc += 289 }
    ldxdw r5, [r10-0x190]                   
    ldxdw r0, [r10-0x198]                   
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    ja lbb_4554                                     if true { pc += 285 }
lbb_4269:
    ldxdw r1, [r10-0x180]                   
    stxdw [r10-0x160], r1                   
    ldxdw r2, [r10-0x188]                   
    stxdw [r10-0x168], r2                   
    ldxdw r3, [r10-0x190]                   
    stxdw [r10-0x170], r3                   
    ldxdw r4, [r10-0x198]                   
    stxdw [r10-0x178], r4                   
    stxdw [r10-0x8], r1                     
    stxdw [r10-0x10], r2                    
    stxdw [r10-0x18], r3                    
    stxdw [r10-0x20], r4                    
    ldxdw r1, [r10-0x180]                   
    stxdw [r10-0x140], r1                   
    ldxdw r1, [r10-0x188]                   
    stxdw [r10-0x148], r1                   
    ldxdw r1, [r10-0x190]                   
    stxdw [r10-0x150], r1                   
    ldxdw r1, [r10-0x198]                   
    stxdw [r10-0x158], r1                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -72                                   r1 += -72   ///  r1 = r1.wrapping_add(-72 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -32                                   r2 += -32   ///  r2 = r2.wrapping_add(-32 as i32 as i64 as u64)
    mov64 r3, r10                                   r3 = r10
    add64 r3, -344                                  r3 += -344   ///  r3 = r3.wrapping_add(-344 as i32 as i64 as u64)
    call function_17050                     
    ldxdw r1, [r10-0x48]                    
    jeq r1, 0, lbb_4552                             if r1 == (0 as i32 as i64 as u64) { pc += 254 }
    ldxdw r1, [r9+0x18]                     
    stxdw [r10-0x50], r1                    
    ldxdw r1, [r9+0x10]                     
    stxdw [r10-0x58], r1                    
    ldxdw r1, [r9+0x8]                      
    stxdw [r10-0x60], r1                    
    ldxdw r1, [r9+0x0]                      
    stxdw [r10-0x68], r1                    
    ldxdw r1, [r10-0x1e0]                   
    stxdw [r10-0x30], r1                    
    ldxdw r1, [r10-0x1e8]                   
    stxdw [r10-0x38], r1                    
    ldxdw r1, [r10-0x1f0]                   
    stxdw [r10-0x40], r1                    
    ldxdw r1, [r10-0x1f8]                   
    stxdw [r10-0x48], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -208                                  r1 += -208   ///  r1 = r1.wrapping_add(-208 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -104                                  r2 += -104   ///  r2 = r2.wrapping_add(-104 as i32 as i64 as u64)
    mov64 r3, r10                                   r3 = r10
    add64 r3, -72                                   r3 += -72   ///  r3 = r3.wrapping_add(-72 as i32 as i64 as u64)
    call function_17405                     
    ldxdw r1, [r10-0xd0]                    
    jeq r1, 0, lbb_4552                             if r1 == (0 as i32 as i64 as u64) { pc += 229 }
    ldxdw r1, [r8+0x18]                     
    stxdw [r10-0x160], r1                   
    ldxdw r2, [r8+0x10]                     
    stxdw [r10-0x168], r2                   
    ldxdw r3, [r8+0x8]                      
    stxdw [r10-0x170], r3                   
    ldxdw r4, [r8+0x0]                      
    stxdw [r10-0x178], r4                   
    stxdw [r10-0x8], r1                     
    stxdw [r10-0x10], r2                    
    stxdw [r10-0x18], r3                    
    stxdw [r10-0x20], r4                    
    ldxdw r1, [r10-0x180]                   
    stxdw [r10-0x140], r1                   
    ldxdw r1, [r10-0x188]                   
    stxdw [r10-0x148], r1                   
    ldxdw r1, [r10-0x190]                   
    stxdw [r10-0x150], r1                   
    ldxdw r1, [r10-0x198]                   
    stxdw [r10-0x158], r1                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -72                                   r1 += -72   ///  r1 = r1.wrapping_add(-72 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -32                                   r2 += -32   ///  r2 = r2.wrapping_add(-32 as i32 as i64 as u64)
    mov64 r3, r10                                   r3 = r10
    add64 r3, -344                                  r3 += -344   ///  r3 = r3.wrapping_add(-344 as i32 as i64 as u64)
    call function_17050                     
    ldxdw r1, [r10-0x48]                    
    jeq r1, 0, lbb_4552                             if r1 == (0 as i32 as i64 as u64) { pc += 200 }
    ldxdw r1, [r9+0x18]                     
    stxdw [r10-0x50], r1                    
    ldxdw r1, [r9+0x10]                     
    stxdw [r10-0x58], r1                    
    ldxdw r1, [r9+0x8]                      
    stxdw [r10-0x60], r1                    
    ldxdw r1, [r9+0x0]                      
    stxdw [r10-0x68], r1                    
    ldxdw r1, [r10-0x1c0]                   
    stxdw [r10-0x30], r1                    
    ldxdw r1, [r10-0x1c8]                   
    stxdw [r10-0x38], r1                    
    ldxdw r1, [r10-0x1d0]                   
    stxdw [r10-0x40], r1                    
    ldxdw r1, [r10-0x1d8]                   
    stxdw [r10-0x48], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -208                                  r1 += -208   ///  r1 = r1.wrapping_add(-208 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -104                                  r2 += -104   ///  r2 = r2.wrapping_add(-104 as i32 as i64 as u64)
    mov64 r3, r10                                   r3 = r10
    add64 r3, -72                                   r3 += -72   ///  r3 = r3.wrapping_add(-72 as i32 as i64 as u64)
    call function_17405                     
    ldxdw r1, [r10-0xd0]                    
    jeq r1, 0, lbb_4552                             if r1 == (0 as i32 as i64 as u64) { pc += 175 }
    stxdw [r10-0x218], r6                   
    ldxdw r1, [r8+0x18]                     
    stxdw [r10-0x160], r1                   
    ldxdw r1, [r8+0x10]                     
    stxdw [r10-0x168], r1                   
    ldxdw r1, [r8+0x8]                      
    stxdw [r10-0x170], r1                   
    ldxdw r1, [r8+0x0]                      
    stxdw [r10-0x178], r1                   
    ldxdw r1, [r10-0x198]                   
    stxdw [r10-0x1b8], r1                   
    ldxdw r1, [r10-0x190]                   
    stxdw [r10-0x1b0], r1                   
    ldxdw r1, [r10-0x188]                   
    stxdw [r10-0x1a8], r1                   
    ldxdw r1, [r10-0x180]                   
    stxdw [r10-0x1a0], r1                   
    mov64 r6, r10                                   r6 = r10
    add64 r6, -32                                   r6 += -32   ///  r6 = r6.wrapping_add(-32 as i32 as i64 as u64)
    mov64 r1, r6                                    r1 = r6
    ldxdw r2, [r10-0x208]                   
    call function_17493                     
    mov64 r7, r10                                   r7 = r10
    add64 r7, -208                                  r7 += -208   ///  r7 = r7.wrapping_add(-208 as i32 as i64 as u64)
    mov64 r1, r7                                    r1 = r7
    ldxdw r2, [r10-0x220]                   
    ldxdw r3, [r10-0x210]                   
    call function_15530                     
    mov64 r1, r10                                   r1 = r10
    add64 r1, -72                                   r1 += -72   ///  r1 = r1.wrapping_add(-72 as i32 as i64 as u64)
    mov64 r2, r6                                    r2 = r6
    mov64 r3, r7                                    r3 = r7
    call function_17050                     
    ldxdw r1, [r10-0x48]                    
    jeq r1, 0, lbb_4552                             if r1 == (0 as i32 as i64 as u64) { pc += 140 }
    ldxdw r1, [r9+0x18]                     
    stxdw [r10-0x118], r1                   
    ldxdw r1, [r9+0x10]                     
    stxdw [r10-0x120], r1                   
    ldxdw r1, [r9+0x8]                      
    stxdw [r10-0x128], r1                   
    ldxdw r1, [r9+0x0]                      
    stxdw [r10-0x130], r1                   
    ldxdw r1, [r10-0x160]                   
    stxdw [r10-0x8], r1                     
    ldxdw r1, [r10-0x168]                   
    stxdw [r10-0x10], r1                    
    ldxdw r1, [r10-0x170]                   
    stxdw [r10-0x18], r1                    
    ldxdw r1, [r10-0x178]                   
    stxdw [r10-0x20], r1                    
    ldxdw r1, [r10-0x160]                   
    stxdw [r10-0xb8], r1                    
    ldxdw r1, [r10-0x168]                   
    stxdw [r10-0xc0], r1                    
    ldxdw r1, [r10-0x170]                   
    stxdw [r10-0xc8], r1                    
    ldxdw r1, [r10-0x178]                   
    stxdw [r10-0xd0], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -72                                   r1 += -72   ///  r1 = r1.wrapping_add(-72 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -32                                   r2 += -32   ///  r2 = r2.wrapping_add(-32 as i32 as i64 as u64)
    mov64 r3, r10                                   r3 = r10
    add64 r3, -208                                  r3 += -208   ///  r3 = r3.wrapping_add(-208 as i32 as i64 as u64)
    call function_16882                     
    ldxdw r1, [r10-0x48]                    
    jeq r1, 0, lbb_4550                             if r1 == (0 as i32 as i64 as u64) { pc += 105 }
    ldxdw r1, [r9+0x18]                     
    stxdw [r10-0xf8], r1                    
    ldxdw r1, [r9+0x10]                     
    stxdw [r10-0x100], r1                   
    ldxdw r1, [r9+0x8]                      
    stxdw [r10-0x108], r1                   
    ldxdw r1, [r9+0x0]                      
    stxdw [r10-0x110], r1                   
    ldxdw r1, [r10-0x118]                   
    stxdw [r10-0x50], r1                    
    ldxdw r1, [r10-0x120]                   
    stxdw [r10-0x58], r1                    
    ldxdw r1, [r10-0x128]                   
    stxdw [r10-0x60], r1                    
    ldxdw r1, [r10-0x130]                   
    stxdw [r10-0x68], r1                    
    ldxdw r1, [r10-0xf8]                    
    stxdw [r10-0x8], r1                     
    ldxdw r1, [r10-0x100]                   
    stxdw [r10-0x10], r1                    
    ldxdw r1, [r10-0x108]                   
    stxdw [r10-0x18], r1                    
    ldxdw r1, [r10-0x110]                   
    stxdw [r10-0x20], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -72                                   r1 += -72   ///  r1 = r1.wrapping_add(-72 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -104                                  r2 += -104   ///  r2 = r2.wrapping_add(-104 as i32 as i64 as u64)
    mov64 r3, r10                                   r3 = r10
    add64 r3, -32                                   r3 += -32   ///  r3 = r3.wrapping_add(-32 as i32 as i64 as u64)
    call function_16882                     
    ldxdw r1, [r10-0x48]                    
    jeq r1, 0, lbb_4550                             if r1 == (0 as i32 as i64 as u64) { pc += 72 }
    ldxdw r1, [r9+0x18]                     
    stxdw [r10-0x70], r1                    
    ldxdw r1, [r9+0x10]                     
    stxdw [r10-0x78], r1                    
    ldxdw r1, [r9+0x8]                      
    stxdw [r10-0x80], r1                    
    ldxdw r1, [r9+0x0]                      
    stxdw [r10-0x88], r1                    
    ldxdw r1, [r10-0x180]                   
    stxdw [r10-0x30], r1                    
    ldxdw r1, [r10-0x188]                   
    stxdw [r10-0x38], r1                    
    ldxdw r1, [r10-0x190]                   
    stxdw [r10-0x40], r1                    
    ldxdw r1, [r10-0x198]                   
    stxdw [r10-0x48], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -208                                  r1 += -208   ///  r1 = r1.wrapping_add(-208 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -136                                  r2 += -136   ///  r2 = r2.wrapping_add(-136 as i32 as i64 as u64)
    mov64 r3, r10                                   r3 = r10
    add64 r3, -72                                   r3 += -72   ///  r3 = r3.wrapping_add(-72 as i32 as i64 as u64)
    call function_17050                     
    ldxdw r1, [r10-0xd0]                    
    jeq r1, 0, lbb_4550                             if r1 == (0 as i32 as i64 as u64) { pc += 47 }
    ldxdw r1, [r8+0x18]                     
    stxdw [r10-0xd8], r1                    
    ldxdw r1, [r8+0x10]                     
    stxdw [r10-0xe0], r1                    
    ldxdw r1, [r8+0x8]                      
    stxdw [r10-0xe8], r1                    
    ldxdw r1, [r8+0x0]                      
    stxdw [r10-0xf0], r1                    
    ldxdw r1, [r10-0x180]                   
    stxdw [r10-0x8], r1                     
    ldxdw r1, [r10-0x188]                   
    stxdw [r10-0x10], r1                    
    ldxdw r1, [r10-0x190]                   
    stxdw [r10-0x18], r1                    
    ldxdw r1, [r10-0x198]                   
    stxdw [r10-0x20], r1                    
    ldxdw r7, [r10-0x228]                   
    jne r7, 0, lbb_4550                             if r7 != (0 as i32 as i64 as u64) { pc += 29 }
    mov64 r6, r10                                   r6 = r10
    add64 r6, -208                                  r6 += -208   ///  r6 = r6.wrapping_add(-208 as i32 as i64 as u64)
    mov64 r1, r6                                    r1 = r6
    ldxdw r2, [r10-0x230]                   
    call function_17493                     
    mov64 r1, r10                                   r1 = r10
    add64 r1, -72                                   r1 += -72   ///  r1 = r1.wrapping_add(-72 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -32                                   r2 += -32   ///  r2 = r2.wrapping_add(-32 as i32 as i64 as u64)
    mov64 r3, r6                                    r3 = r6
    call function_17050                     
    ldxdw r1, [r10-0x48]                    
    jeq r1, 0, lbb_4550                             if r1 == (0 as i32 as i64 as u64) { pc += 16 }
    ldxdw r1, [r9+0x18]                     
    stxdw [r10-0x90], r1                    
    ldxdw r1, [r9+0x10]                     
    stxdw [r10-0x98], r1                    
    ldxdw r1, [r9+0x8]                      
    stxdw [r10-0xa0], r1                    
    ldxdw r1, [r9+0x0]                      
    stxdw [r10-0xa8], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -72                                   r1 += -72   ///  r1 = r1.wrapping_add(-72 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -376                                  r2 += -376   ///  r2 = r2.wrapping_add(-376 as i32 as i64 as u64)
    mov64 r3, 3                                     r3 = 3 as i32 as i64 as u64
    call function_3928                      
    ldxdw r1, [r10-0x48]                    
    jne r1, 0, lbb_4169                             if r1 != (0 as i32 as i64 as u64) { pc += -381 }
lbb_4550:
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    stxdw [r10-0x158], r1                   
lbb_4552:
    ldxdw r6, [r10-0x200]                   
lbb_4553:
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
lbb_4554:
    stxdw [r6+0x8], r0                      
    stxdw [r6+0x0], r1                      
    stxdw [r6+0x10], r5                     
    exit                                    

function_4558:
    mov64 r0, r4                                    r0 = r4
    stxdw [r10-0x268], r3                   
    mov64 r6, r1                                    r6 = r1
    ldxdw r2, [r2+0x0]                      
    mov64 r9, r2                                    r9 = r2
    add64 r9, r9                                    r9 += r9   ///  r9 = r9.wrapping_add(r9)
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    stxdw [r10-0x260], r1                   
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    jgt r2, r9, lbb_4569                            if r2 > r9 { pc += 1 }
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
lbb_4569:
    and64 r1, 1                                     r1 &= 1   ///  r1 = r1.and(1)
    jne r1, 0, lbb_5080                             if r1 != (0 as i32 as i64 as u64) { pc += 509 }
    ldxdw r4, [r5-0xff8]                    
    ldxdw r3, [r5-0x1000]                   
    mov64 r7, r3                                    r7 = r3
    ldxdw r1, [r10-0x268]                   
    add64 r7, r1                                    r7 += r1   ///  r7 = r7.wrapping_add(r1)
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    stxdw [r10-0x260], r1                   
    mov64 r2, 1                                     r2 = 1 as i32 as i64 as u64
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    jgt r3, r7, lbb_4582                            if r3 > r7 { pc += 1 }
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
lbb_4582:
    mov64 r8, r4                                    r8 = r4
    add64 r8, r0                                    r8 += r0   ///  r8 = r8.wrapping_add(r0)
    add64 r8, r1                                    r8 += r1   ///  r8 = r8.wrapping_add(r1)
    jgt r4, r8, lbb_4587                            if r4 > r8 { pc += 1 }
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
lbb_4587:
    jeq r8, r4, lbb_4589                            if r8 == r4 { pc += 1 }
    mov64 r1, r2                                    r1 = r2
lbb_4589:
    and64 r1, 1                                     r1 &= 1   ///  r1 = r1.and(1)
    jne r1, 0, lbb_5080                             if r1 != (0 as i32 as i64 as u64) { pc += 489 }
    ldxdw r1, [r5-0xfe8]                    
    ldxdw r2, [r5-0xff0]                    
    stxdw [r10-0x290], r2                   
    stxdw [r10-0x1000], r2                  
    stxdw [r10-0x288], r1                   
    stxdw [r10-0xff8], r1                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -600                                  r1 += -600   ///  r1 = r1.wrapping_add(-600 as i32 as i64 as u64)
    mov64 r5, r10                                   r5 = r10
    mov64 r2, r9                                    r2 = r9
    stxdw [r10-0x280], r0                   
    call function_3997                      
    ldxdw r1, [r10-0x258]                   
    jeq r1, 0, lbb_5080                             if r1 == (0 as i32 as i64 as u64) { pc += 475 }
    stxdw [r10-0x278], r6                   
    ldxdw r1, [r10-0x248]                   
    stxdw [r10-0x270], r1                   
    ldxdw r6, [r10-0x250]                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -576                                  r1 += -576   ///  r1 = r1.wrapping_add(-576 as i32 as i64 as u64)
    mov64 r2, r9                                    r2 = r9
    call function_17493                     
    mov64 r1, r10                                   r1 = r10
    add64 r1, -544                                  r1 += -544   ///  r1 = r1.wrapping_add(-544 as i32 as i64 as u64)
    mov64 r2, r7                                    r2 = r7
    mov64 r3, r8                                    r3 = r8
    call function_15530                     
    mov64 r1, r10                                   r1 = r10
    add64 r1, -512                                  r1 += -512   ///  r1 = r1.wrapping_add(-512 as i32 as i64 as u64)
    mov64 r2, r6                                    r2 = r6
    ldxdw r3, [r10-0x270]                   
    call function_15530                     
    ldxdw r1, [r10-0x1e8]                   
    stxdw [r10-0x148], r1                   
    ldxdw r2, [r10-0x1f0]                   
    stxdw [r10-0x150], r2                   
    ldxdw r3, [r10-0x1f8]                   
    stxdw [r10-0x158], r3                   
    ldxdw r4, [r10-0x200]                   
    stxdw [r10-0x160], r4                   
    stxdw [r10-0x98], r1                    
    stxdw [r10-0xa0], r2                    
    stxdw [r10-0xa8], r3                    
    stxdw [r10-0xb0], r4                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -104                                  r1 += -104   ///  r1 = r1.wrapping_add(-104 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -352                                  r2 += -352   ///  r2 = r2.wrapping_add(-352 as i32 as i64 as u64)
    mov64 r3, r10                                   r3 = r10
    add64 r3, -176                                  r3 += -176   ///  r3 = r3.wrapping_add(-176 as i32 as i64 as u64)
    call function_17050                     
    ldxdw r1, [r10-0x68]                    
    jeq r1, 0, lbb_5079                             if r1 == (0 as i32 as i64 as u64) { pc += 435 }
    mov64 r6, r10                                   r6 = r10
    add64 r6, -96                                   r6 += -96   ///  r6 = r6.wrapping_add(-96 as i32 as i64 as u64)
    ldxdw r1, [r6+0x18]                     
    stxdw [r10-0x8], r1                     
    ldxdw r2, [r6+0x10]                     
    stxdw [r10-0x10], r2                    
    ldxdw r3, [r6+0x8]                      
    stxdw [r10-0x18], r3                    
    ldxdw r4, [r6+0x0]                      
    stxdw [r10-0x20], r4                    
    stxdw [r10-0x148], r1                   
    stxdw [r10-0x150], r2                   
    stxdw [r10-0x158], r3                   
    stxdw [r10-0x160], r4                   
    ldxdw r1, [r10-0x1e8]                   
    stxdw [r10-0x98], r1                    
    ldxdw r1, [r10-0x1f0]                   
    stxdw [r10-0xa0], r1                    
    ldxdw r1, [r10-0x1f8]                   
    stxdw [r10-0xa8], r1                    
    ldxdw r1, [r10-0x200]                   
    stxdw [r10-0xb0], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -104                                  r1 += -104   ///  r1 = r1.wrapping_add(-104 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -352                                  r2 += -352   ///  r2 = r2.wrapping_add(-352 as i32 as i64 as u64)
    mov64 r3, r10                                   r3 = r10
    add64 r3, -176                                  r3 += -176   ///  r3 = r3.wrapping_add(-176 as i32 as i64 as u64)
    call function_17050                     
    ldxdw r1, [r10-0x68]                    
    jeq r1, 0, lbb_5079                             if r1 == (0 as i32 as i64 as u64) { pc += 404 }
    ldxdw r1, [r6+0x18]                     
    ldxdw r2, [r6+0x10]                     
    ldxdw r3, [r6+0x8]                      
    ldxdw r4, [r6+0x0]                      
    stxdw [r10-0x118], r4                   
    stxdw [r10-0x110], r3                   
    stxdw [r10-0x108], r2                   
    stxdw [r10-0x8], r1                     
    stxdw [r10-0x100], r1                   
    ldxdw r1, [r10-0x208]                   
    stxdw [r10-0x8], r1                     
    ldxdw r1, [r10-0x210]                   
    stxdw [r10-0x10], r1                    
    ldxdw r1, [r10-0x218]                   
    stxdw [r10-0x18], r1                    
    ldxdw r1, [r10-0x220]                   
    stxdw [r10-0x20], r1                    
    ldxdw r1, [r10-0x208]                   
    stxdw [r10-0x148], r1                   
    ldxdw r1, [r10-0x210]                   
    stxdw [r10-0x150], r1                   
    ldxdw r1, [r10-0x218]                   
    stxdw [r10-0x158], r1                   
    ldxdw r1, [r10-0x220]                   
    stxdw [r10-0x160], r1                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -104                                  r1 += -104   ///  r1 = r1.wrapping_add(-104 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -32                                   r2 += -32   ///  r2 = r2.wrapping_add(-32 as i32 as i64 as u64)
    mov64 r3, r10                                   r3 = r10
    add64 r3, -352                                  r3 += -352   ///  r3 = r3.wrapping_add(-352 as i32 as i64 as u64)
    call function_16882                     
    ldxdw r1, [r10-0x68]                    
    jeq r1, 0, lbb_5079                             if r1 == (0 as i32 as i64 as u64) { pc += 370 }
    ldxdw r1, [r6+0x18]                     
    stxdw [r10-0x28], r1                    
    ldxdw r2, [r6+0x10]                     
    stxdw [r10-0x30], r2                    
    ldxdw r3, [r6+0x8]                      
    stxdw [r10-0x38], r3                    
    ldxdw r4, [r6+0x0]                      
    stxdw [r10-0x40], r4                    
    stxdw [r10-0x8], r1                     
    stxdw [r10-0x10], r2                    
    stxdw [r10-0x18], r3                    
    stxdw [r10-0x20], r4                    
    ldxdw r1, [r10-0x208]                   
    stxdw [r10-0x148], r1                   
    ldxdw r1, [r10-0x210]                   
    stxdw [r10-0x150], r1                   
    ldxdw r1, [r10-0x218]                   
    stxdw [r10-0x158], r1                   
    ldxdw r1, [r10-0x220]                   
    stxdw [r10-0x160], r1                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -104                                  r1 += -104   ///  r1 = r1.wrapping_add(-104 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -32                                   r2 += -32   ///  r2 = r2.wrapping_add(-32 as i32 as i64 as u64)
    mov64 r3, r10                                   r3 = r10
    add64 r3, -352                                  r3 += -352   ///  r3 = r3.wrapping_add(-352 as i32 as i64 as u64)
    call function_16882                     
    ldxdw r1, [r10-0x68]                    
    jeq r1, 0, lbb_5079                             if r1 == (0 as i32 as i64 as u64) { pc += 341 }
    ldxdw r1, [r6+0x18]                     
    stxdw [r10-0x28], r1                    
    ldxdw r2, [r6+0x10]                     
    stxdw [r10-0x30], r2                    
    ldxdw r3, [r6+0x8]                      
    stxdw [r10-0x38], r3                    
    ldxdw r4, [r6+0x0]                      
    stxdw [r10-0x40], r4                    
    stxdw [r10-0x8], r1                     
    stxdw [r10-0x10], r2                    
    stxdw [r10-0x18], r3                    
    stxdw [r10-0x20], r4                    
    ldxdw r1, [r10-0x208]                   
    stxdw [r10-0x148], r1                   
    ldxdw r1, [r10-0x210]                   
    stxdw [r10-0x150], r1                   
    ldxdw r1, [r10-0x218]                   
    stxdw [r10-0x158], r1                   
    ldxdw r1, [r10-0x220]                   
    stxdw [r10-0x160], r1                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -104                                  r1 += -104   ///  r1 = r1.wrapping_add(-104 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -32                                   r2 += -32   ///  r2 = r2.wrapping_add(-32 as i32 as i64 as u64)
    mov64 r3, r10                                   r3 = r10
    add64 r3, -352                                  r3 += -352   ///  r3 = r3.wrapping_add(-352 as i32 as i64 as u64)
    call function_16882                     
    ldxdw r1, [r10-0x68]                    
    jeq r1, 0, lbb_5079                             if r1 == (0 as i32 as i64 as u64) { pc += 312 }
    ldxdw r1, [r6+0x18]                     
    ldxdw r2, [r6+0x10]                     
    ldxdw r3, [r6+0x8]                      
    ldxdw r4, [r6+0x0]                      
    stxdw [r10-0x88], r4                    
    stxdw [r10-0x80], r3                    
    stxdw [r10-0x78], r2                    
    stxdw [r10-0x28], r1                    
    stxdw [r10-0x70], r1                    
    ldxdw r1, [r10-0x228]                   
    stxdw [r10-0x50], r1                    
    ldxdw r1, [r10-0x230]                   
    stxdw [r10-0x58], r1                    
    ldxdw r1, [r10-0x238]                   
    stxdw [r10-0x60], r1                    
    ldxdw r1, [r10-0x240]                   
    stxdw [r10-0x68], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -176                                  r1 += -176   ///  r1 = r1.wrapping_add(-176 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -136                                  r2 += -136   ///  r2 = r2.wrapping_add(-136 as i32 as i64 as u64)
    mov64 r3, r10                                   r3 = r10
    add64 r3, -104                                  r3 += -104   ///  r3 = r3.wrapping_add(-104 as i32 as i64 as u64)
    call function_17050                     
    ldxdw r1, [r10-0xb0]                    
    jeq r1, 0, lbb_5079                             if r1 == (0 as i32 as i64 as u64) { pc += 286 }
    ldxdw r1, [r10-0x90]                    
    stxdw [r10-0xb8], r1                    
    ldxdw r1, [r10-0x98]                    
    stxdw [r10-0xc0], r1                    
    ldxdw r1, [r10-0xa0]                    
    stxdw [r10-0xc8], r1                    
    ldxdw r1, [r10-0xa8]                    
    stxdw [r10-0xd0], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -248                                  r1 += -248   ///  r1 = r1.wrapping_add(-248 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -280                                  r2 += -280   ///  r2 = r2.wrapping_add(-280 as i32 as i64 as u64)
    mov64 r3, r10                                   r3 = r10
    add64 r3, -208                                  r3 += -208   ///  r3 = r3.wrapping_add(-208 as i32 as i64 as u64)
    call function_17405                     
    ldxdw r1, [r10-0xf8]                    
    jeq r1, 0, lbb_5079                             if r1 == (0 as i32 as i64 as u64) { pc += 269 }
    ldxdw r1, [r10-0xd8]                    
    stxdw [r10-0x1c8], r1                   
    ldxdw r1, [r10-0xe0]                    
    stxdw [r10-0x1d0], r1                   
    ldxdw r1, [r10-0xe8]                    
    stxdw [r10-0x1d8], r1                   
    ldxdw r1, [r10-0xf0]                    
    stxdw [r10-0x1e0], r1                   
    ldxdw r1, [r10-0x208]                   
    stxdw [r10-0x28], r1                    
    ldxdw r1, [r10-0x210]                   
    stxdw [r10-0x30], r1                    
    ldxdw r1, [r10-0x218]                   
    stxdw [r10-0x38], r1                    
    ldxdw r1, [r10-0x220]                   
    stxdw [r10-0x40], r1                    
    ldxdw r1, [r10-0x1e8]                   
    stxdw [r10-0x148], r1                   
    ldxdw r1, [r10-0x1f0]                   
    stxdw [r10-0x150], r1                   
    ldxdw r1, [r10-0x1f8]                   
    stxdw [r10-0x158], r1                   
    ldxdw r1, [r10-0x200]                   
    stxdw [r10-0x160], r1                   
    ldxdw r1, [r10-0x228]                   
    stxdw [r10-0xe0], r1                    
    ldxdw r1, [r10-0x230]                   
    stxdw [r10-0xe8], r1                    
    ldxdw r1, [r10-0x238]                   
    stxdw [r10-0xf0], r1                    
    ldxdw r1, [r10-0x240]                   
    stxdw [r10-0xf8], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -104                                  r1 += -104   ///  r1 = r1.wrapping_add(-104 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -352                                  r2 += -352   ///  r2 = r2.wrapping_add(-352 as i32 as i64 as u64)
    mov64 r3, r10                                   r3 = r10
    add64 r3, -248                                  r3 += -248   ///  r3 = r3.wrapping_add(-248 as i32 as i64 as u64)
    call function_17405                     
    ldxdw r1, [r10-0x68]                    
    jeq r1, 0, lbb_5079                             if r1 == (0 as i32 as i64 as u64) { pc += 228 }
    ldxdw r1, [r10-0x48]                    
    stxdw [r10-0x8], r1                     
    ldxdw r1, [r10-0x50]                    
    stxdw [r10-0x10], r1                    
    ldxdw r1, [r10-0x58]                    
    stxdw [r10-0x18], r1                    
    ldxdw r1, [r10-0x60]                    
    stxdw [r10-0x20], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -176                                  r1 += -176   ///  r1 = r1.wrapping_add(-176 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -64                                   r2 += -64   ///  r2 = r2.wrapping_add(-64 as i32 as i64 as u64)
    mov64 r3, r10                                   r3 = r10
    add64 r3, -32                                   r3 += -32   ///  r3 = r3.wrapping_add(-32 as i32 as i64 as u64)
    call function_16882                     
    ldxdw r1, [r10-0xb0]                    
    jeq r1, 0, lbb_5079                             if r1 == (0 as i32 as i64 as u64) { pc += 211 }
    ldxdw r1, [r10-0x90]                    
    stxdw [r10-0x1a8], r1                   
    ldxdw r1, [r10-0x98]                    
    stxdw [r10-0x1b0], r1                   
    ldxdw r1, [r10-0xa0]                    
    stxdw [r10-0x1b8], r1                   
    ldxdw r1, [r10-0xa8]                    
    stxdw [r10-0x1c0], r1                   
    ldxdw r1, [r10-0x1e8]                   
    stxdw [r10-0x168], r1                   
    ldxdw r1, [r10-0x1f0]                   
    stxdw [r10-0x170], r1                   
    ldxdw r1, [r10-0x1f8]                   
    stxdw [r10-0x178], r1                   
    ldxdw r1, [r10-0x200]                   
    stxdw [r10-0x180], r1                   
    mov64 r7, 0                                     r7 = 0 as i32 as i64 as u64
    mov64 r1, r10                                   r1 = r10
    add64 r1, -344                                  r1 += -344   ///  r1 = r1.wrapping_add(-344 as i32 as i64 as u64)
    stxdw [r10-0x260], r1                   
    mov64 r9, r10                                   r9 = r10
    add64 r9, -240                                  r9 += -240   ///  r9 = r9.wrapping_add(-240 as i32 as i64 as u64)
    mov64 r8, r10                                   r8 = r10
    add64 r8, -168                                  r8 += -168   ///  r8 = r8.wrapping_add(-168 as i32 as i64 as u64)
    ja lbb_5066                                     if true { pc += 173 }
lbb_4893:
    ldxdw r1, [r10-0x168]                   
    stxdw [r10-0x188], r1                   
    ldxdw r2, [r10-0x170]                   
    stxdw [r10-0x190], r2                   
    ldxdw r3, [r10-0x178]                   
    stxdw [r10-0x198], r3                   
    ldxdw r4, [r10-0x180]                   
    stxdw [r10-0x1a0], r4                   
    stxdw [r10-0x8], r1                     
    stxdw [r10-0x10], r2                    
    stxdw [r10-0x18], r3                    
    stxdw [r10-0x20], r4                    
    ldxdw r1, [r10-0x168]                   
    stxdw [r10-0xe0], r1                    
    ldxdw r1, [r10-0x170]                   
    stxdw [r10-0xe8], r1                    
    ldxdw r1, [r10-0x178]                   
    stxdw [r10-0xf0], r1                    
    ldxdw r1, [r10-0x180]                   
    stxdw [r10-0xf8], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -104                                  r1 += -104   ///  r1 = r1.wrapping_add(-104 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -32                                   r2 += -32   ///  r2 = r2.wrapping_add(-32 as i32 as i64 as u64)
    mov64 r3, r10                                   r3 = r10
    add64 r3, -248                                  r3 += -248   ///  r3 = r3.wrapping_add(-248 as i32 as i64 as u64)
    call function_17050                     
    ldxdw r1, [r10-0x68]                    
    jeq r1, 0, lbb_5077                             if r1 == (0 as i32 as i64 as u64) { pc += 155 }
    ldxdw r1, [r6+0x18]                     
    stxdw [r10-0x28], r1                    
    ldxdw r1, [r6+0x10]                     
    stxdw [r10-0x30], r1                    
    ldxdw r1, [r6+0x8]                      
    stxdw [r10-0x38], r1                    
    ldxdw r1, [r6+0x0]                      
    stxdw [r10-0x40], r1                    
    ldxdw r1, [r10-0x1c8]                   
    stxdw [r10-0x50], r1                    
    ldxdw r1, [r10-0x1d0]                   
    stxdw [r10-0x58], r1                    
    ldxdw r1, [r10-0x1d8]                   
    stxdw [r10-0x60], r1                    
    ldxdw r1, [r10-0x1e0]                   
    stxdw [r10-0x68], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -176                                  r1 += -176   ///  r1 = r1.wrapping_add(-176 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -64                                   r2 += -64   ///  r2 = r2.wrapping_add(-64 as i32 as i64 as u64)
    mov64 r3, r10                                   r3 = r10
    add64 r3, -104                                  r3 += -104   ///  r3 = r3.wrapping_add(-104 as i32 as i64 as u64)
    call function_16882                     
    ldxdw r1, [r10-0xb0]                    
    jeq r1, 0, lbb_5077                             if r1 == (0 as i32 as i64 as u64) { pc += 130 }
    ldxdw r1, [r8+0x18]                     
    stxdw [r10-0x120], r1                   
    ldxdw r1, [r8+0x10]                     
    stxdw [r10-0x128], r1                   
    ldxdw r1, [r8+0x8]                      
    stxdw [r10-0x130], r1                   
    ldxdw r1, [r8+0x0]                      
    stxdw [r10-0x138], r1                   
    ldxdw r1, [r10-0x168]                   
    stxdw [r10-0x28], r1                    
    ldxdw r1, [r10-0x170]                   
    stxdw [r10-0x30], r1                    
    ldxdw r1, [r10-0x178]                   
    stxdw [r10-0x38], r1                    
    ldxdw r1, [r10-0x180]                   
    stxdw [r10-0x40], r1                    
    ldxdw r1, [r10-0x168]                   
    stxdw [r10-0x8], r1                     
    ldxdw r1, [r10-0x170]                   
    stxdw [r10-0x10], r1                    
    ldxdw r1, [r10-0x178]                   
    stxdw [r10-0x18], r1                    
    ldxdw r1, [r10-0x180]                   
    stxdw [r10-0x20], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -104                                  r1 += -104   ///  r1 = r1.wrapping_add(-104 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -64                                   r2 += -64   ///  r2 = r2.wrapping_add(-64 as i32 as i64 as u64)
    mov64 r3, r10                                   r3 = r10
    add64 r3, -32                                   r3 += -32   ///  r3 = r3.wrapping_add(-32 as i32 as i64 as u64)
    call function_16882                     
    ldxdw r1, [r10-0x68]                    
    jeq r1, 0, lbb_5077                             if r1 == (0 as i32 as i64 as u64) { pc += 97 }
    ldxdw r1, [r6+0x18]                     
    stxdw [r10-0x70], r1                    
    ldxdw r1, [r6+0x10]                     
    stxdw [r10-0x78], r1                    
    ldxdw r1, [r6+0x8]                      
    stxdw [r10-0x80], r1                    
    ldxdw r1, [r6+0x0]                      
    stxdw [r10-0x88], r1                    
    ldxdw r1, [r10-0x1a8]                   
    stxdw [r10-0x50], r1                    
    ldxdw r1, [r10-0x1b0]                   
    stxdw [r10-0x58], r1                    
    ldxdw r1, [r10-0x1b8]                   
    stxdw [r10-0x60], r1                    
    ldxdw r1, [r10-0x1c0]                   
    stxdw [r10-0x68], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -176                                  r1 += -176   ///  r1 = r1.wrapping_add(-176 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -136                                  r2 += -136   ///  r2 = r2.wrapping_add(-136 as i32 as i64 as u64)
    mov64 r3, r10                                   r3 = r10
    add64 r3, -104                                  r3 += -104   ///  r3 = r3.wrapping_add(-104 as i32 as i64 as u64)
    call function_16882                     
    ldxdw r1, [r10-0xb0]                    
    jeq r1, 0, lbb_5077                             if r1 == (0 as i32 as i64 as u64) { pc += 72 }
    ldxdw r1, [r8+0x18]                     
    stxdw [r10-0xb8], r1                    
    ldxdw r1, [r8+0x10]                     
    stxdw [r10-0xc0], r1                    
    ldxdw r1, [r8+0x8]                      
    stxdw [r10-0xc8], r1                    
    ldxdw r1, [r8+0x0]                      
    stxdw [r10-0xd0], r1                    
    ldxdw r1, [r10-0x1e8]                   
    stxdw [r10-0x50], r1                    
    ldxdw r1, [r10-0x1f0]                   
    stxdw [r10-0x58], r1                    
    ldxdw r1, [r10-0x1f8]                   
    stxdw [r10-0x60], r1                    
    ldxdw r1, [r10-0x200]                   
    stxdw [r10-0x68], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -248                                  r1 += -248   ///  r1 = r1.wrapping_add(-248 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -208                                  r2 += -208   ///  r2 = r2.wrapping_add(-208 as i32 as i64 as u64)
    mov64 r3, r10                                   r3 = r10
    add64 r3, -104                                  r3 += -104   ///  r3 = r3.wrapping_add(-104 as i32 as i64 as u64)
    call function_16966                     
    ldxdw r1, [r10-0xf8]                    
    jeq r1, 0, lbb_5077                             if r1 == (0 as i32 as i64 as u64) { pc += 47 }
    ldxdw r1, [r9+0x18]                     
    stxdw [r10-0x100], r1                   
    ldxdw r1, [r9+0x10]                     
    stxdw [r10-0x108], r1                   
    ldxdw r1, [r9+0x8]                      
    stxdw [r10-0x110], r1                   
    ldxdw r1, [r9+0x0]                      
    stxdw [r10-0x118], r1                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -352                                  r1 += -352   ///  r1 = r1.wrapping_add(-352 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -312                                  r2 += -312   ///  r2 = r2.wrapping_add(-312 as i32 as i64 as u64)
    mov64 r3, r10                                   r3 = r10
    add64 r3, -280                                  r3 += -280   ///  r3 = r3.wrapping_add(-280 as i32 as i64 as u64)
    call function_17405                     
    ldxdw r1, [r10-0x160]                   
    jeq r1, 0, lbb_5077                             if r1 == (0 as i32 as i64 as u64) { pc += 30 }
    add64 r7, 1                                     r7 += 1   ///  r7 = r7.wrapping_add(1 as i32 as i64 as u64)
    ldxdw r2, [r10-0x260]                   
    ldxdw r1, [r2+0x18]                     
    stxdw [r10-0x168], r1                   
    ldxdw r1, [r2+0x10]                     
    stxdw [r10-0x170], r1                   
    ldxdw r1, [r2+0x8]                      
    stxdw [r10-0x178], r1                   
    ldxdw r1, [r2+0x0]                      
    stxdw [r10-0x180], r1                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -384                                  r1 += -384   ///  r1 = r1.wrapping_add(-384 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -416                                  r2 += -416   ///  r2 = r2.wrapping_add(-416 as i32 as i64 as u64)
    mov64 r3, 32                                    r3 = 32 as i32 as i64 as u64
    call function_21867                     
    lsh64 r0, 32                                    r0 <<= 32   ///  r0 = r0.wrapping_shl(32)
    rsh64 r0, 32                                    r0 >>= 32   ///  r0 = r0.wrapping_shr(32)
    jeq r0, 0, lbb_5070                             if r0 == (0 as i32 as i64 as u64) { pc += 4 }
lbb_5066:
    mov64 r1, r7                                    r1 = r7
    and64 r1, 255                                   r1 &= 255   ///  r1 = r1.and(255)
    mov64 r2, 32                                    r2 = 32 as i32 as i64 as u64
    jgt r2, r1, lbb_4893                            if r2 > r1 { pc += -177 }
lbb_5070:
    ldxdw r1, [r10-0x168]                   
    ldxdw r2, [r10-0x170]                   
    or64 r2, r1                                     r2 |= r1   ///  r2 = r2.or(r1)
    ldxdw r6, [r10-0x278]                   
    jeq r2, 0, lbb_5083                             if r2 == (0 as i32 as i64 as u64) { pc += 8 }
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    ja lbb_5114                                     if true { pc += 37 }
lbb_5077:
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    stxdw [r10-0x260], r1                   
lbb_5079:
    ldxdw r6, [r10-0x278]                   
lbb_5080:
    ldxdw r1, [r10-0x260]                   
    stxdw [r6+0x0], r1                      
    exit                                    
lbb_5083:
    ldxdw r2, [r10-0x178]                   
    ldxdw r0, [r10-0x288]                   
    mov64 r1, r0                                    r1 = r0
    sub64 r1, r2                                    r1 -= r2   ///  r1 = r1.wrapping_sub(r2)
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
    stxdw [r10-0x260], r2                   
    mov64 r3, 1                                     r3 = 1 as i32 as i64 as u64
    ldxdw r4, [r10-0x180]                   
    mov64 r2, 1                                     r2 = 1 as i32 as i64 as u64
    ldxdw r7, [r10-0x290]                   
    jgt r4, r7, lbb_5095                            if r4 > r7 { pc += 1 }
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
lbb_5095:
    sub64 r1, r2                                    r1 -= r2   ///  r1 = r1.wrapping_sub(r2)
    mov64 r2, r7                                    r2 = r7
    sub64 r2, r4                                    r2 -= r4   ///  r2 = r2.wrapping_sub(r4)
    mov64 r4, 1                                     r4 = 1 as i32 as i64 as u64
    ldxdw r5, [r10-0x280]                   
    jgt r2, r7, lbb_5102                            if r2 > r7 { pc += 1 }
    mov64 r4, 0                                     r4 = 0 as i32 as i64 as u64
lbb_5102:
    jgt r1, r0, lbb_5104                            if r1 > r0 { pc += 1 }
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
lbb_5104:
    jeq r1, r0, lbb_5106                            if r1 == r0 { pc += 1 }
    mov64 r4, r3                                    r4 = r3
lbb_5106:
    and64 r4, 1                                     r4 &= 1   ///  r4 = r4.and(1)
    jne r4, 0, lbb_5080                             if r4 != (0 as i32 as i64 as u64) { pc += -28 }
    stxdw [r6+0x18], r2                     
    ldxdw r2, [r10-0x268]                   
    stxdw [r6+0x8], r2                      
    stxdw [r6+0x20], r1                     
    stxdw [r6+0x10], r5                     
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
lbb_5114:
    stxdw [r10-0x260], r1                   
    ja lbb_5080                                     if true { pc += -36 }

function_5116:
    mov64 r9, r5                                    r9 = r5
    mov64 r6, r3                                    r6 = r3
    stxdw [r10-0xb0], r1                    
    ldxdw r7, [r9-0xff0]                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -48                                   r1 += -48   ///  r1 = r1.wrapping_add(-48 as i32 as i64 as u64)
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
    stxdw [r10-0xa8], r2                    
    stxdw [r10-0xb8], r4                    
    mov64 r2, r4                                    r2 = r4
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
    mov64 r4, r7                                    r4 = r7
    mov64 r5, 0                                     r5 = 0 as i32 as i64 as u64
    call function_21911                     
    ldxdw r8, [r9-0xfe8]                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -32                                   r1 += -32   ///  r1 = r1.wrapping_add(-32 as i32 as i64 as u64)
    mov64 r2, r8                                    r2 = r8
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
    mov64 r4, r6                                    r4 = r6
    mov64 r5, 0                                     r5 = 0 as i32 as i64 as u64
    call function_21911                     
    mov64 r1, r10                                   r1 = r10
    add64 r1, -16                                   r1 += -16   ///  r1 = r1.wrapping_add(-16 as i32 as i64 as u64)
    stxdw [r10-0xc0], r6                    
    mov64 r2, r6                                    r2 = r6
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
    mov64 r4, r7                                    r4 = r7
    mov64 r5, 0                                     r5 = 0 as i32 as i64 as u64
    call function_21911                     
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    mov64 r3, 1                                     r3 = 1 as i32 as i64 as u64
    jne r8, 0, lbb_5150                             if r8 != (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
lbb_5150:
    mov64 r2, 1                                     r2 = 1 as i32 as i64 as u64
    ldxdw r8, [r10-0xb8]                    
    jne r8, 0, lbb_5154                             if r8 != (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
lbb_5154:
    and64 r2, r3                                    r2 &= r3   ///  r2 = r2.and(r3)
    ldxdw r4, [r10-0x28]                    
    mov64 r3, 1                                     r3 = 1 as i32 as i64 as u64
    jne r4, 0, lbb_5159                             if r4 != (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
lbb_5159:
    or64 r2, r3                                     r2 |= r3   ///  r2 = r2.or(r3)
    ldxdw r4, [r10-0x18]                    
    mov64 r3, 1                                     r3 = 1 as i32 as i64 as u64
    jne r4, 0, lbb_5164                             if r4 != (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
lbb_5164:
    or64 r2, r3                                     r2 |= r3   ///  r2 = r2.or(r3)
    ldxdw r3, [r10-0x20]                    
    ldxdw r4, [r10-0x30]                    
    add64 r4, r3                                    r4 += r3   ///  r4 = r4.wrapping_add(r3)
    ldxdw r5, [r10-0x8]                     
    mov64 r3, r5                                    r3 = r5
    add64 r3, r4                                    r3 += r4   ///  r3 = r3.wrapping_add(r4)
    jgt r5, r3, lbb_5173                            if r5 > r3 { pc += 1 }
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
lbb_5173:
    or64 r2, r1                                     r2 |= r1   ///  r2 = r2.or(r1)
    and64 r2, 1                                     r2 &= 1   ///  r2 = r2.and(1)
    jne r2, 0, lbb_5357                             if r2 != (0 as i32 as i64 as u64) { pc += 181 }
    ldxdw r5, [r9-0xff8]                    
    ldxdw r4, [r9-0x1000]                   
    mov64 r1, r4                                    r1 = r4
    or64 r1, r5                                     r1 |= r5   ///  r1 = r1.or(r5)
    jeq r1, 0, lbb_5357                             if r1 == (0 as i32 as i64 as u64) { pc += 176 }
    ldxdw r6, [r9-0xfd8]                    
    ldxdw r7, [r9-0xfe0]                    
    ldxdw r1, [r9-0xfd0]                    
    stxdw [r10-0xd8], r1                    
    ldxdw r2, [r10-0x10]                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -64                                   r1 += -64   ///  r1 = r1.wrapping_add(-64 as i32 as i64 as u64)
    stxdw [r10-0xe8], r2                    
    stxdw [r10-0xe0], r3                    
    stxdw [r10-0xc8], r4                    
    stxdw [r10-0xd0], r5                    
    call function_21948                     
    mov64 r1, r10                                   r1 = r10
    add64 r1, -112                                  r1 += -112   ///  r1 = r1.wrapping_add(-112 as i32 as i64 as u64)
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
    stxdw [r10-0xa8], r2                    
    mov64 r2, r8                                    r2 = r8
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
    mov64 r4, r7                                    r4 = r7
    mov64 r5, 0                                     r5 = 0 as i32 as i64 as u64
    call function_21911                     
    mov64 r1, r10                                   r1 = r10
    add64 r1, -96                                   r1 += -96   ///  r1 = r1.wrapping_add(-96 as i32 as i64 as u64)
    mov64 r2, r6                                    r2 = r6
    mov64 r9, r6                                    r9 = r6
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
    ldxdw r6, [r10-0xc0]                    
    mov64 r4, r6                                    r4 = r6
    mov64 r5, 0                                     r5 = 0 as i32 as i64 as u64
    call function_21911                     
    mov64 r1, r10                                   r1 = r10
    add64 r1, -80                                   r1 += -80   ///  r1 = r1.wrapping_add(-80 as i32 as i64 as u64)
    mov64 r2, r6                                    r2 = r6
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
    mov64 r4, r7                                    r4 = r7
    mov64 r5, 0                                     r5 = 0 as i32 as i64 as u64
    call function_21911                     
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    mov64 r3, 1                                     r3 = 1 as i32 as i64 as u64
    jne r9, 0, lbb_5222                             if r9 != (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
lbb_5222:
    mov64 r2, 1                                     r2 = 1 as i32 as i64 as u64
    jne r8, 0, lbb_5225                             if r8 != (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
lbb_5225:
    and64 r2, r3                                    r2 &= r3   ///  r2 = r2.and(r3)
    ldxdw r4, [r10-0x68]                    
    mov64 r3, 1                                     r3 = 1 as i32 as i64 as u64
    ldxdw r9, [r10-0xd0]                    
    jne r4, 0, lbb_5231                             if r4 != (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
lbb_5231:
    or64 r2, r3                                     r2 |= r3   ///  r2 = r2.or(r3)
    ldxdw r4, [r10-0x58]                    
    mov64 r3, 1                                     r3 = 1 as i32 as i64 as u64
    jne r4, 0, lbb_5236                             if r4 != (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
lbb_5236:
    or64 r2, r3                                     r2 |= r3   ///  r2 = r2.or(r3)
    ldxdw r3, [r10-0x60]                    
    ldxdw r4, [r10-0x70]                    
    add64 r4, r3                                    r4 += r3   ///  r4 = r4.wrapping_add(r3)
    ldxdw r3, [r10-0x48]                    
    mov64 r8, r3                                    r8 = r3
    add64 r8, r4                                    r8 += r4   ///  r8 = r8.wrapping_add(r4)
    jgt r3, r8, lbb_5245                            if r3 > r8 { pc += 1 }
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
lbb_5245:
    or64 r2, r1                                     r2 |= r1   ///  r2 = r2.or(r1)
    and64 r2, 1                                     r2 &= 1   ///  r2 = r2.and(1)
    ldxdw r7, [r10-0xc8]                    
    jne r2, 0, lbb_5357                             if r2 != (0 as i32 as i64 as u64) { pc += 108 }
    ldxdw r2, [r10-0x50]                    
    ldxdw r1, [r10-0x38]                    
    stxdw [r10-0xa8], r1                    
    ldxdw r6, [r10-0x40]                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -128                                  r1 += -128   ///  r1 = r1.wrapping_add(-128 as i32 as i64 as u64)
    stxdw [r10-0xb8], r2                    
    mov64 r3, r8                                    r3 = r8
    mov64 r4, r7                                    r4 = r7
    mov64 r5, r9                                    r5 = r9
    call function_21948                     
    mov64 r2, r6                                    r2 = r6
    ldxdw r3, [r10-0xa8]                    
    ldxdw r6, [r10-0x78]                    
    ldxdw r5, [r10-0x80]                    
    ldxdw r1, [r10-0xd8]                    
    lsh64 r1, 32                                    r1 <<= 32   ///  r1 = r1.wrapping_shl(32)
    rsh64 r1, 32                                    r1 >>= 32   ///  r1 = r1.wrapping_shr(32)
    jeq r1, 0, lbb_5350                             if r1 == (0 as i32 as i64 as u64) { pc += 82 }
    mov64 r1, r10                                   r1 = r10
    add64 r1, -144                                  r1 += -144   ///  r1 = r1.wrapping_add(-144 as i32 as i64 as u64)
    stxdw [r10-0xc0], r2                    
    stxdw [r10-0xf0], r6                    
    mov64 r6, r5                                    r6 = r5
    mov64 r4, r7                                    r4 = r7
    mov64 r5, r9                                    r5 = r9
    call function_21911                     
    mov64 r1, r10                                   r1 = r10
    add64 r1, -160                                  r1 += -160   ///  r1 = r1.wrapping_add(-160 as i32 as i64 as u64)
    stxdw [r10-0xd8], r6                    
    mov64 r2, r6                                    r2 = r6
    ldxdw r6, [r10-0xf0]                    
    mov64 r3, r6                                    r3 = r6
    mov64 r4, r7                                    r4 = r7
    mov64 r5, r9                                    r5 = r9
    call function_21911                     
    mov64 r2, 1                                     r2 = 1 as i32 as i64 as u64
    mov64 r4, r7                                    r4 = r7
    ldxdw r1, [r10-0xb8]                    
    jge r1, r4, lbb_5290                            if r1 >= r4 { pc += 1 }
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
lbb_5290:
    mov64 r3, 1                                     r3 = 1 as i32 as i64 as u64
    ldxdw r0, [r10-0xe0]                    
    ldxdw r7, [r10-0xe8]                    
    jge r8, r9, lbb_5295                            if r8 >= r9 { pc += 1 }
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
lbb_5295:
    jeq r8, r9, lbb_5297                            if r8 == r9 { pc += 1 }
    mov64 r2, r3                                    r2 = r3
lbb_5297:
    mov64 r3, 1                                     r3 = 1 as i32 as i64 as u64
    jge r7, r4, lbb_5300                            if r7 >= r4 { pc += 1 }
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
lbb_5300:
    mov64 r4, 1                                     r4 = 1 as i32 as i64 as u64
    jge r0, r9, lbb_5303                            if r0 >= r9 { pc += 1 }
    mov64 r4, 0                                     r4 = 0 as i32 as i64 as u64
lbb_5303:
    jeq r0, r9, lbb_5305                            if r0 == r9 { pc += 1 }
    mov64 r3, r4                                    r3 = r4
lbb_5305:
    ldxdw r4, [r10-0x98]                    
    sub64 r8, r4                                    r8 -= r4   ///  r8 = r8.wrapping_sub(r4)
    ldxdw r4, [r10-0xa0]                    
    mov64 r5, 1                                     r5 = 1 as i32 as i64 as u64
    jgt r4, r1, lbb_5311                            if r4 > r1 { pc += 1 }
    mov64 r5, 0                                     r5 = 0 as i32 as i64 as u64
lbb_5311:
    mov64 r9, r6                                    r9 = r6
    sub64 r8, r5                                    r8 -= r5   ///  r8 = r8.wrapping_sub(r5)
    sub64 r1, r4                                    r1 -= r4   ///  r1 = r1.wrapping_sub(r4)
    or64 r1, r8                                     r1 |= r8   ///  r1 = r1.or(r8)
    ldxdw r5, [r10-0x88]                    
    mov64 r4, 1                                     r4 = 1 as i32 as i64 as u64
    jne r1, 0, lbb_5319                             if r1 != (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r4, 0                                     r4 = 0 as i32 as i64 as u64
lbb_5319:
    sub64 r0, r5                                    r0 -= r5   ///  r0 = r0.wrapping_sub(r5)
    ldxdw r5, [r10-0x90]                    
    mov64 r6, r0                                    r6 = r0
    mov64 r0, 1                                     r0 = 1 as i32 as i64 as u64
    jgt r5, r7, lbb_5325                            if r5 > r7 { pc += 1 }
    mov64 r0, 0                                     r0 = 0 as i32 as i64 as u64
lbb_5325:
    sub64 r6, r0                                    r6 -= r0   ///  r6 = r6.wrapping_sub(r0)
    sub64 r7, r5                                    r7 -= r5   ///  r7 = r7.wrapping_sub(r5)
    or64 r7, r6                                     r7 |= r6   ///  r7 = r7.or(r6)
    mov64 r5, 1                                     r5 = 1 as i32 as i64 as u64
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    jne r7, 0, lbb_5332                             if r7 != (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r5, 0                                     r5 = 0 as i32 as i64 as u64
lbb_5332:
    and64 r4, r2                                    r4 &= r2   ///  r4 = r4.and(r2)
    and64 r5, r3                                    r5 &= r3   ///  r5 = r5.and(r3)
    ldxdw r0, [r10-0xc0]                    
    mov64 r2, r0                                    r2 = r0
    add64 r2, r5                                    r2 += r5   ///  r2 = r2.wrapping_add(r5)
    mov64 r3, 1                                     r3 = 1 as i32 as i64 as u64
    mov64 r6, r9                                    r6 = r9
    jgt r0, r2, lbb_5341                            if r0 > r2 { pc += 1 }
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
lbb_5341:
    ldxdw r0, [r10-0xd8]                    
    mov64 r5, r0                                    r5 = r0
    add64 r5, r4                                    r5 += r4   ///  r5 = r5.wrapping_add(r4)
    jgt r0, r5, lbb_5346                            if r0 > r5 { pc += 1 }
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
lbb_5346:
    add64 r6, r1                                    r6 += r1   ///  r6 = r6.wrapping_add(r1)
    ldxdw r1, [r10-0xa8]                    
    add64 r1, r3                                    r1 += r3   ///  r1 = r1.wrapping_add(r3)
    mov64 r3, r1                                    r3 = r1
lbb_5350:
    ldxdw r1, [r10-0xb0]                    
    stxdw [r1+0x18], r5                     
    stxdw [r1+0x8], r2                      
    stxdw [r1+0x20], r6                     
    stxdw [r1+0x10], r3                     
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    stxdw [r10-0xa8], r1                    
lbb_5357:
    ldxdw r1, [r10-0xb0]                    
    ldxdw r2, [r10-0xa8]                    
    stxdw [r1+0x0], r2                      
    exit                                    

function_5361:
    mov64 r8, r4                                    r8 = r4
    mov64 r7, r3                                    r7 = r3
    mov64 r6, r1                                    r6 = r1
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    mov64 r4, r7                                    r4 = r7
    or64 r4, r8                                     r4 |= r8   ///  r4 = r4.or(r8)
    mov64 r0, 1                                     r0 = 1 as i32 as i64 as u64
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
    jeq r4, 0, lbb_5569                             if r4 == (0 as i32 as i64 as u64) { pc += 199 }
    ldxdw r1, [r2+0x0]                      
    mov64 r9, r1                                    r9 = r1
    add64 r9, r9                                    r9 += r9   ///  r9 = r9.wrapping_add(r9)
    mov64 r0, 0                                     r0 = 0 as i32 as i64 as u64
    mov64 r2, 1                                     r2 = 1 as i32 as i64 as u64
    jgt r1, r9, lbb_5377                            if r1 > r9 { pc += 1 }
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
lbb_5377:
    and64 r2, 1                                     r2 &= 1   ///  r2 = r2.and(1)
    jne r2, 0, lbb_5569                             if r2 != (0 as i32 as i64 as u64) { pc += 190 }
    ldxdw r1, [r5-0xfd8]                    
    stxdw [r10-0x1b0], r1                   
    ldxdw r1, [r5-0xfe0]                    
    stxdw [r10-0x1b8], r1                   
    ldxdw r1, [r5-0xfe8]                    
    ldxdw r2, [r5-0xff0]                    
    ldxdw r0, [r5-0xff8]                    
    ldxdw r3, [r5-0x1000]                   
    ldxdw r4, [r5-0xfd0]                    
    stxdw [r10-0x188], r4                   
    stxdw [r10-0x1a8], r2                   
    stxdw [r10-0x1000], r2                  
    stxdw [r10-0x1a0], r1                   
    stxdw [r10-0xff8], r1                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -336                                  r1 += -336   ///  r1 = r1.wrapping_add(-336 as i32 as i64 as u64)
    mov64 r5, r10                                   r5 = r10
    mov64 r2, r9                                    r2 = r9
    stxdw [r10-0x190], r3                   
    stxdw [r10-0x198], r0                   
    mov64 r4, r0                                    r4 = r0
    call function_3997                      
    ldxdw r1, [r10-0x150]                   
    jeq r1, 0, lbb_5568                             if r1 == (0 as i32 as i64 as u64) { pc += 165 }
    ldxdw r3, [r10-0x140]                   
    ldxdw r2, [r10-0x148]                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -40                                   r1 += -40   ///  r1 = r1.wrapping_add(-40 as i32 as i64 as u64)
    call function_13690                     
    ldxdw r1, [r10-0x28]                    
    jeq r1, 0, lbb_5568                             if r1 == (0 as i32 as i64 as u64) { pc += 158 }
    ldxdw r2, [r10-0x188]                   
    lsh64 r2, 32                                    r2 <<= 32   ///  r2 = r2.wrapping_shl(32)
    rsh64 r2, 32                                    r2 >>= 32   ///  r2 = r2.wrapping_shr(32)
    ldxdw r1, [r10-0x198]                   
    jeq r2, 0, lbb_5416                             if r2 == (0 as i32 as i64 as u64) { pc += 1 }
    ldxdw r1, [r10-0x1a0]                   
lbb_5416:
    ldxdw r4, [r10-0x190]                   
    jeq r2, 0, lbb_5419                             if r2 == (0 as i32 as i64 as u64) { pc += 1 }
    ldxdw r4, [r10-0x1a8]                   
lbb_5419:
    mov64 r3, r4                                    r3 = r4
    add64 r3, r7                                    r3 += r7   ///  r3 = r3.wrapping_add(r7)
    mov64 r5, 1                                     r5 = 1 as i32 as i64 as u64
    mov64 r2, 1                                     r2 = 1 as i32 as i64 as u64
    jgt r4, r3, lbb_5425                            if r4 > r3 { pc += 1 }
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
lbb_5425:
    mov64 r4, r1                                    r4 = r1
    add64 r4, r8                                    r4 += r8   ///  r4 = r4.wrapping_add(r8)
    add64 r4, r2                                    r4 += r2   ///  r4 = r4.wrapping_add(r2)
    mov64 r0, 0                                     r0 = 0 as i32 as i64 as u64
    jgt r1, r4, lbb_5431                            if r1 > r4 { pc += 1 }
    mov64 r5, 0                                     r5 = 0 as i32 as i64 as u64
lbb_5431:
    jeq r4, r1, lbb_5433                            if r4 == r1 { pc += 1 }
    mov64 r2, r5                                    r2 = r5
lbb_5433:
    ldxdw r1, [r10-0x8]                     
    stxdw [r10-0x120], r1                   
    ldxdw r1, [r10-0x10]                    
    stxdw [r10-0x128], r1                   
    ldxdw r1, [r10-0x18]                    
    stxdw [r10-0x130], r1                   
    ldxdw r1, [r10-0x20]                    
    stxdw [r10-0x138], r1                   
    and64 r2, 1                                     r2 &= 1   ///  r2 = r2.and(1)
    jne r2, 0, lbb_5569                             if r2 != (0 as i32 as i64 as u64) { pc += 126 }
    ldxdw r1, [r10-0x188]                   
    lsh64 r1, 32                                    r1 <<= 32   ///  r1 = r1.wrapping_shl(32)
    rsh64 r1, 32                                    r1 >>= 32   ///  r1 = r1.wrapping_shr(32)
    jeq r1, 0, lbb_5449                             if r1 == (0 as i32 as i64 as u64) { pc += 2 }
    ldxdw r2, [r10-0x198]                   
    stxdw [r10-0x1a0], r2                   
lbb_5449:
    jeq r1, 0, lbb_5452                             if r1 == (0 as i32 as i64 as u64) { pc += 2 }
    ldxdw r1, [r10-0x190]                   
    stxdw [r10-0x1a8], r1                   
lbb_5452:
    ldxdw r1, [r10-0x1a8]                   
    stxdw [r10-0x1000], r1                  
    ldxdw r1, [r10-0x1a0]                   
    stxdw [r10-0xff8], r1                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -360                                  r1 += -360   ///  r1 = r1.wrapping_add(-360 as i32 as i64 as u64)
    mov64 r5, r10                                   r5 = r10
    mov64 r2, r9                                    r2 = r9
    call function_3997                      
    ldxdw r1, [r10-0x168]                   
    jeq r1, 0, lbb_5568                             if r1 == (0 as i32 as i64 as u64) { pc += 105 }
    ldxdw r3, [r10-0x158]                   
    ldxdw r2, [r10-0x160]                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -40                                   r1 += -40   ///  r1 = r1.wrapping_add(-40 as i32 as i64 as u64)
    call function_13690                     
    ldxdw r1, [r10-0x28]                    
    jeq r1, 0, lbb_5568                             if r1 == (0 as i32 as i64 as u64) { pc += 98 }
    ldxdw r1, [r10-0x8]                     
    stxdw [r10-0x100], r1                   
    ldxdw r1, [r10-0x10]                    
    stxdw [r10-0x108], r1                   
    ldxdw r1, [r10-0x18]                    
    stxdw [r10-0x110], r1                   
    ldxdw r1, [r10-0x20]                    
    stxdw [r10-0x118], r1                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -40                                   r1 += -40   ///  r1 = r1.wrapping_add(-40 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -280                                  r2 += -280   ///  r2 = r2.wrapping_add(-280 as i32 as i64 as u64)
    mov64 r3, r10                                   r3 = r10
    add64 r3, -312                                  r3 += -312   ///  r3 = r3.wrapping_add(-312 as i32 as i64 as u64)
    call function_14500                     
    ldxdw r1, [r10-0x28]                    
    jeq r1, 0, lbb_5568                             if r1 == (0 as i32 as i64 as u64) { pc += 81 }
    ldxdw r1, [r10-0x8]                     
    stxdw [r10-0xe0], r1                    
    ldxdw r1, [r10-0x10]                    
    stxdw [r10-0xe8], r1                    
    ldxdw r1, [r10-0x18]                    
    stxdw [r10-0xf0], r1                    
    ldxdw r1, [r10-0x20]                    
    stxdw [r10-0xf8], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -40                                   r1 += -40   ///  r1 = r1.wrapping_add(-40 as i32 as i64 as u64)
    ldxdw r2, [r10-0x1b8]                   
    ldxdw r3, [r10-0x1b0]                   
    call function_13690                     
    ldxdw r1, [r10-0x28]                    
    jeq r1, 0, lbb_5568                             if r1 == (0 as i32 as i64 as u64) { pc += 66 }
    ldxdw r1, [r10-0x8]                     
    stxdw [r10-0x30], r1                    
    ldxdw r1, [r10-0x10]                    
    stxdw [r10-0x38], r1                    
    ldxdw r1, [r10-0x18]                    
    stxdw [r10-0x40], r1                    
    ldxdw r1, [r10-0x20]                    
    stxdw [r10-0x48], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -112                                  r1 += -112   ///  r1 = r1.wrapping_add(-112 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -248                                  r2 += -248   ///  r2 = r2.wrapping_add(-248 as i32 as i64 as u64)
    mov64 r3, r10                                   r3 = r10
    add64 r3, -72                                   r3 += -72   ///  r3 = r3.wrapping_add(-72 as i32 as i64 as u64)
    call function_14167                     
    ldxdw r1, [r10-0x70]                    
    jeq r1, 0, lbb_5568                             if r1 == (0 as i32 as i64 as u64) { pc += 49 }
    ldxdw r1, [r10-0x50]                    
    stxdw [r10-0x78], r1                    
    ldxdw r1, [r10-0x58]                    
    stxdw [r10-0x80], r1                    
    ldxdw r1, [r10-0x60]                    
    stxdw [r10-0x88], r1                    
    ldxdw r1, [r10-0x68]                    
    stxdw [r10-0x90], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -184                                  r1 += -184   ///  r1 = r1.wrapping_add(-184 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -144                                  r2 += -144   ///  r2 = r2.wrapping_add(-144 as i32 as i64 as u64)
    mov64 r3, r10                                   r3 = r10
    add64 r3, -312                                  r3 += -312   ///  r3 = r3.wrapping_add(-312 as i32 as i64 as u64)
    call function_13949                     
    ldxdw r1, [r10-0xb8]                    
    jeq r1, 0, lbb_5568                             if r1 == (0 as i32 as i64 as u64) { pc += 32 }
    ldxdw r1, [r10-0x98]                    
    stxdw [r10-0xc0], r1                    
    ldxdw r1, [r10-0xa0]                    
    stxdw [r10-0xc8], r1                    
    ldxdw r1, [r10-0xa8]                    
    stxdw [r10-0xd0], r1                    
    ldxdw r1, [r10-0xb0]                    
    stxdw [r10-0xd8], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -40                                   r1 += -40   ///  r1 = r1.wrapping_add(-40 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -216                                  r2 += -216   ///  r2 = r2.wrapping_add(-216 as i32 as i64 as u64)
    call function_13797                     
    ldxdw r1, [r10-0x28]                    
    jeq r1, 0, lbb_5568                             if r1 == (0 as i32 as i64 as u64) { pc += 17 }
    ldxdw r1, [r10-0x8]                     
    stxdw [r10-0x58], r1                    
    ldxdw r1, [r10-0x10]                    
    stxdw [r10-0x60], r1                    
    ldxdw r1, [r10-0x18]                    
    stxdw [r10-0x68], r1                    
    ldxdw r1, [r10-0x20]                    
    stxdw [r10-0x70], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -384                                  r1 += -384   ///  r1 = r1.wrapping_add(-384 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -112                                  r2 += -112   ///  r2 = r2.wrapping_add(-112 as i32 as i64 as u64)
    call function_13722                     
    ldxdw r3, [r10-0x170]                   
    ldxdw r1, [r10-0x178]                   
    ldxdw r0, [r10-0x180]                   
    ja lbb_5569                                     if true { pc += 1 }
lbb_5568:
    mov64 r0, 0                                     r0 = 0 as i32 as i64 as u64
lbb_5569:
    stxdw [r6+0x8], r1                      
    stxdw [r6+0x0], r0                      
    stxdw [r6+0x10], r3                     
    exit                                    

function_5573:
    mov64 r8, r4                                    r8 = r4
    mov64 r7, r3                                    r7 = r3
    mov64 r6, r1                                    r6 = r1
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    mov64 r4, r7                                    r4 = r7
    or64 r4, r8                                     r4 |= r8   ///  r4 = r4.or(r8)
    mov64 r0, 1                                     r0 = 1 as i32 as i64 as u64
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
    jeq r4, 0, lbb_5784                             if r4 == (0 as i32 as i64 as u64) { pc += 202 }
    ldxdw r1, [r2+0x0]                      
    mov64 r9, r1                                    r9 = r1
    add64 r9, r9                                    r9 += r9   ///  r9 = r9.wrapping_add(r9)
    mov64 r0, 0                                     r0 = 0 as i32 as i64 as u64
    mov64 r2, 1                                     r2 = 1 as i32 as i64 as u64
    jgt r1, r9, lbb_5589                            if r1 > r9 { pc += 1 }
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
lbb_5589:
    and64 r2, 1                                     r2 &= 1   ///  r2 = r2.and(1)
    jne r2, 0, lbb_5784                             if r2 != (0 as i32 as i64 as u64) { pc += 193 }
    ldxdw r1, [r5-0xfd8]                    
    stxdw [r10-0x1b0], r1                   
    ldxdw r1, [r5-0xfe0]                    
    stxdw [r10-0x1b8], r1                   
    ldxdw r1, [r5-0xfe8]                    
    ldxdw r2, [r5-0xff0]                    
    ldxdw r0, [r5-0xff8]                    
    ldxdw r3, [r5-0x1000]                   
    ldxdw r4, [r5-0xfd0]                    
    stxdw [r10-0x188], r4                   
    stxdw [r10-0x1a8], r2                   
    stxdw [r10-0x1000], r2                  
    stxdw [r10-0x1a0], r1                   
    stxdw [r10-0xff8], r1                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -336                                  r1 += -336   ///  r1 = r1.wrapping_add(-336 as i32 as i64 as u64)
    mov64 r5, r10                                   r5 = r10
    mov64 r2, r9                                    r2 = r9
    stxdw [r10-0x190], r3                   
    stxdw [r10-0x198], r0                   
    mov64 r4, r0                                    r4 = r0
    call function_3997                      
    ldxdw r1, [r10-0x150]                   
    jeq r1, 0, lbb_5783                             if r1 == (0 as i32 as i64 as u64) { pc += 168 }
    ldxdw r3, [r10-0x140]                   
    ldxdw r2, [r10-0x148]                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -40                                   r1 += -40   ///  r1 = r1.wrapping_add(-40 as i32 as i64 as u64)
    call function_13690                     
    ldxdw r1, [r10-0x28]                    
    jeq r1, 0, lbb_5783                             if r1 == (0 as i32 as i64 as u64) { pc += 161 }
    ldxdw r3, [r10-0x188]                   
    lsh64 r3, 32                                    r3 <<= 32   ///  r3 = r3.wrapping_shl(32)
    rsh64 r3, 32                                    r3 >>= 32   ///  r3 = r3.wrapping_shr(32)
    ldxdw r2, [r10-0x190]                   
    jeq r3, 0, lbb_5628                             if r3 == (0 as i32 as i64 as u64) { pc += 1 }
    ldxdw r2, [r10-0x1a8]                   
lbb_5628:
    ldxdw r1, [r10-0x198]                   
    jeq r3, 0, lbb_5631                             if r3 == (0 as i32 as i64 as u64) { pc += 1 }
    ldxdw r1, [r10-0x1a0]                   
lbb_5631:
    mov64 r4, r1                                    r4 = r1
    sub64 r4, r8                                    r4 -= r8   ///  r4 = r4.wrapping_sub(r8)
    mov64 r0, 1                                     r0 = 1 as i32 as i64 as u64
    mov64 r3, 1                                     r3 = 1 as i32 as i64 as u64
    jgt r7, r2, lbb_5637                            if r7 > r2 { pc += 1 }
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
lbb_5637:
    sub64 r4, r3                                    r4 -= r3   ///  r4 = r4.wrapping_sub(r3)
    mov64 r3, r2                                    r3 = r2
    sub64 r3, r7                                    r3 -= r7   ///  r3 = r3.wrapping_sub(r7)
    mov64 r5, 1                                     r5 = 1 as i32 as i64 as u64
    jgt r3, r2, lbb_5643                            if r3 > r2 { pc += 1 }
    mov64 r5, 0                                     r5 = 0 as i32 as i64 as u64
lbb_5643:
    jgt r4, r1, lbb_5645                            if r4 > r1 { pc += 1 }
    mov64 r0, 0                                     r0 = 0 as i32 as i64 as u64
lbb_5645:
    jeq r4, r1, lbb_5647                            if r4 == r1 { pc += 1 }
    mov64 r5, r0                                    r5 = r0
lbb_5647:
    ldxdw r1, [r10-0x8]                     
    stxdw [r10-0x120], r1                   
    ldxdw r1, [r10-0x10]                    
    stxdw [r10-0x128], r1                   
    ldxdw r1, [r10-0x18]                    
    stxdw [r10-0x130], r1                   
    ldxdw r1, [r10-0x20]                    
    stxdw [r10-0x138], r1                   
    and64 r5, 1                                     r5 &= 1   ///  r5 = r5.and(1)
    mov64 r0, 0                                     r0 = 0 as i32 as i64 as u64
    jne r5, 0, lbb_5784                             if r5 != (0 as i32 as i64 as u64) { pc += 126 }
    ldxdw r1, [r10-0x188]                   
    lsh64 r1, 32                                    r1 <<= 32   ///  r1 = r1.wrapping_shl(32)
    rsh64 r1, 32                                    r1 >>= 32   ///  r1 = r1.wrapping_shr(32)
    jeq r1, 0, lbb_5664                             if r1 == (0 as i32 as i64 as u64) { pc += 2 }
    ldxdw r2, [r10-0x198]                   
    stxdw [r10-0x1a0], r2                   
lbb_5664:
    jeq r1, 0, lbb_5667                             if r1 == (0 as i32 as i64 as u64) { pc += 2 }
    ldxdw r1, [r10-0x190]                   
    stxdw [r10-0x1a8], r1                   
lbb_5667:
    ldxdw r1, [r10-0x1a8]                   
    stxdw [r10-0x1000], r1                  
    ldxdw r1, [r10-0x1a0]                   
    stxdw [r10-0xff8], r1                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -360                                  r1 += -360   ///  r1 = r1.wrapping_add(-360 as i32 as i64 as u64)
    mov64 r5, r10                                   r5 = r10
    mov64 r2, r9                                    r2 = r9
    call function_3997                      
    ldxdw r1, [r10-0x168]                   
    jeq r1, 0, lbb_5783                             if r1 == (0 as i32 as i64 as u64) { pc += 105 }
    ldxdw r3, [r10-0x158]                   
    ldxdw r2, [r10-0x160]                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -40                                   r1 += -40   ///  r1 = r1.wrapping_add(-40 as i32 as i64 as u64)
    call function_13690                     
    ldxdw r1, [r10-0x28]                    
    jeq r1, 0, lbb_5783                             if r1 == (0 as i32 as i64 as u64) { pc += 98 }
    ldxdw r1, [r10-0x8]                     
    stxdw [r10-0x100], r1                   
    ldxdw r1, [r10-0x10]                    
    stxdw [r10-0x108], r1                   
    ldxdw r1, [r10-0x18]                    
    stxdw [r10-0x110], r1                   
    ldxdw r1, [r10-0x20]                    
    stxdw [r10-0x118], r1                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -40                                   r1 += -40   ///  r1 = r1.wrapping_add(-40 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -312                                  r2 += -312   ///  r2 = r2.wrapping_add(-312 as i32 as i64 as u64)
    mov64 r3, r10                                   r3 = r10
    add64 r3, -280                                  r3 += -280   ///  r3 = r3.wrapping_add(-280 as i32 as i64 as u64)
    call function_14500                     
    ldxdw r1, [r10-0x28]                    
    jeq r1, 0, lbb_5783                             if r1 == (0 as i32 as i64 as u64) { pc += 81 }
    ldxdw r1, [r10-0x8]                     
    stxdw [r10-0xe0], r1                    
    ldxdw r1, [r10-0x10]                    
    stxdw [r10-0xe8], r1                    
    ldxdw r1, [r10-0x18]                    
    stxdw [r10-0xf0], r1                    
    ldxdw r1, [r10-0x20]                    
    stxdw [r10-0xf8], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -40                                   r1 += -40   ///  r1 = r1.wrapping_add(-40 as i32 as i64 as u64)
    ldxdw r2, [r10-0x1b8]                   
    ldxdw r3, [r10-0x1b0]                   
    call function_13690                     
    ldxdw r1, [r10-0x28]                    
    jeq r1, 0, lbb_5783                             if r1 == (0 as i32 as i64 as u64) { pc += 66 }
    ldxdw r1, [r10-0x8]                     
    stxdw [r10-0x30], r1                    
    ldxdw r1, [r10-0x10]                    
    stxdw [r10-0x38], r1                    
    ldxdw r1, [r10-0x18]                    
    stxdw [r10-0x40], r1                    
    ldxdw r1, [r10-0x20]                    
    stxdw [r10-0x48], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -112                                  r1 += -112   ///  r1 = r1.wrapping_add(-112 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -248                                  r2 += -248   ///  r2 = r2.wrapping_add(-248 as i32 as i64 as u64)
    mov64 r3, r10                                   r3 = r10
    add64 r3, -72                                   r3 += -72   ///  r3 = r3.wrapping_add(-72 as i32 as i64 as u64)
    call function_14167                     
    ldxdw r1, [r10-0x70]                    
    jeq r1, 0, lbb_5783                             if r1 == (0 as i32 as i64 as u64) { pc += 49 }
    ldxdw r1, [r10-0x50]                    
    stxdw [r10-0x78], r1                    
    ldxdw r1, [r10-0x58]                    
    stxdw [r10-0x80], r1                    
    ldxdw r1, [r10-0x60]                    
    stxdw [r10-0x88], r1                    
    ldxdw r1, [r10-0x68]                    
    stxdw [r10-0x90], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -184                                  r1 += -184   ///  r1 = r1.wrapping_add(-184 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -144                                  r2 += -144   ///  r2 = r2.wrapping_add(-144 as i32 as i64 as u64)
    mov64 r3, r10                                   r3 = r10
    add64 r3, -312                                  r3 += -312   ///  r3 = r3.wrapping_add(-312 as i32 as i64 as u64)
    call function_13949                     
    ldxdw r1, [r10-0xb8]                    
    jeq r1, 0, lbb_5783                             if r1 == (0 as i32 as i64 as u64) { pc += 32 }
    ldxdw r1, [r10-0x98]                    
    stxdw [r10-0xc0], r1                    
    ldxdw r1, [r10-0xa0]                    
    stxdw [r10-0xc8], r1                    
    ldxdw r1, [r10-0xa8]                    
    stxdw [r10-0xd0], r1                    
    ldxdw r1, [r10-0xb0]                    
    stxdw [r10-0xd8], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -40                                   r1 += -40   ///  r1 = r1.wrapping_add(-40 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -216                                  r2 += -216   ///  r2 = r2.wrapping_add(-216 as i32 as i64 as u64)
    call function_13852                     
    ldxdw r1, [r10-0x28]                    
    jeq r1, 0, lbb_5783                             if r1 == (0 as i32 as i64 as u64) { pc += 17 }
    ldxdw r1, [r10-0x8]                     
    stxdw [r10-0x58], r1                    
    ldxdw r1, [r10-0x10]                    
    stxdw [r10-0x60], r1                    
    ldxdw r1, [r10-0x18]                    
    stxdw [r10-0x68], r1                    
    ldxdw r1, [r10-0x20]                    
    stxdw [r10-0x70], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -384                                  r1 += -384   ///  r1 = r1.wrapping_add(-384 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -112                                  r2 += -112   ///  r2 = r2.wrapping_add(-112 as i32 as i64 as u64)
    call function_13722                     
    ldxdw r3, [r10-0x170]                   
    ldxdw r1, [r10-0x178]                   
    ldxdw r0, [r10-0x180]                   
    ja lbb_5784                                     if true { pc += 1 }
lbb_5783:
    mov64 r0, 0                                     r0 = 0 as i32 as i64 as u64
lbb_5784:
    stxdw [r6+0x8], r1                      
    stxdw [r6+0x0], r0                      
    stxdw [r6+0x10], r3                     
    exit                                    

function_5788:
    mov64 r6, r1                                    r6 = r1
    ldxdw r0, [r2+0x0]                      
    mov64 r2, r0                                    r2 = r0
    add64 r2, r2                                    r2 += r2   ///  r2 = r2.wrapping_add(r2)
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    jgt r0, r2, lbb_5795                            if r0 > r2 { pc += 1 }
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
lbb_5795:
    and64 r1, 1                                     r1 &= 1   ///  r1 = r1.and(1)
    jne r1, 0, lbb_5812                             if r1 != (0 as i32 as i64 as u64) { pc += 15 }
    ldxdw r1, [r5-0xff8]                    
    ldxdw r5, [r5-0x1000]                   
    stxdw [r10-0x1000], r5                  
    stxdw [r10-0xff8], r1                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -24                                   r1 += -24   ///  r1 = r1.wrapping_add(-24 as i32 as i64 as u64)
    mov64 r5, r10                                   r5 = r10
    call function_3997                      
    ldxdw r1, [r10-0x18]                    
    jeq r1, 0, lbb_5812                             if r1 == (0 as i32 as i64 as u64) { pc += 5 }
    ldxdw r3, [r10-0x8]                     
    ldxdw r2, [r10-0x10]                    
    mov64 r1, r6                                    r1 = r6
    call function_13690                     
    ja lbb_5814                                     if true { pc += 2 }
lbb_5812:
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    stxdw [r6+0x0], r1                      
lbb_5814:
    exit                                    

function_5815:
    mov64 r0, 28                                    r0 = 28 as i32 as i64 as u64
    exit                                    

function_5817:
    jgt r3, 7, lbb_5824                             if r3 > (7 as i32 as i64 as u64) { pc += 6 }
    mov64 r1, 8                                     r1 = 8 as i32 as i64 as u64
    mov64 r2, r3                                    r2 = r3
    lddw r3, 0x10002dc40 --> b"\x00\x00\x00\x00\xfa\xc3\x02\x00\x1b\x00\x00\x00\x00\x00\x00\x00_\x01\x00…        r3 load str located at 4295154752
    call function_20726                     
    syscall [invalid]                       
lbb_5824:
    ldxdw r1, [r1+0x0]                      
    stxdw [r2+0x0], r1                      
    exit                                    

function_5827:
    mov64 r6, r1                                    r6 = r1
    jeq r3, 0, lbb_5872                             if r3 == (0 as i32 as i64 as u64) { pc += 43 }
    mov64 r1, r3                                    r1 = r3
    add64 r1, -1                                    r1 += -1   ///  r1 = r1.wrapping_add(-1 as i32 as i64 as u64)
    ldxb r4, [r2+0x0]                       
    jsgt r4, 2, lbb_5850                            if (r4 as i64) > (2 as i32 as i64) { pc += 17 }
    jeq r4, 0, lbb_5862                             if r4 == (0 as i32 as i64 as u64) { pc += 28 }
    jeq r4, 1, lbb_5878                             if r4 == (1 as i32 as i64 as u64) { pc += 43 }
    jeq r4, 2, lbb_5837                             if r4 == (2 as i32 as i64 as u64) { pc += 1 }
    ja lbb_5872                                     if true { pc += 35 }
lbb_5837:
    jgt r1, 7, lbb_5839                             if r1 > (7 as i32 as i64 as u64) { pc += 1 }
    ja lbb_5940                                     if true { pc += 101 }
lbb_5839:
    mov64 r4, r3                                    r4 = r3
    add64 r4, -17                                   r4 += -17   ///  r4 = r4.wrapping_add(-17 as i32 as i64 as u64)
    mov64 r1, -8                                    r1 = -8 as i32 as i64 as u64
    jgt r1, r4, lbb_5844                            if r1 > r4 { pc += 1 }
    ja lbb_5940                                     if true { pc += 96 }
lbb_5844:
    add64 r3, -25                                   r3 += -25   ///  r3 = r3.wrapping_add(-25 as i32 as i64 as u64)
    jgt r1, r3, lbb_5847                            if r1 > r3 { pc += 1 }
    ja lbb_5940                                     if true { pc += 93 }
lbb_5847:
    ldxdw r4, [r2+0x1]                      
    mov64 r1, 2                                     r1 = 2 as i32 as i64 as u64
    ja lbb_5898                                     if true { pc += 48 }
lbb_5850:
    jsgt r4, 4, lbb_5870                            if (r4 as i64) > (4 as i32 as i64) { pc += 19 }
    jeq r4, 3, lbb_5886                             if r4 == (3 as i32 as i64 as u64) { pc += 34 }
    jeq r4, 4, lbb_5854                             if r4 == (4 as i32 as i64 as u64) { pc += 1 }
    ja lbb_5872                                     if true { pc += 18 }
lbb_5854:
    jgt r1, 7, lbb_5856                             if r1 > (7 as i32 as i64 as u64) { pc += 1 }
    ja lbb_5940                                     if true { pc += 84 }
lbb_5856:
    add64 r3, -17                                   r3 += -17   ///  r3 = r3.wrapping_add(-17 as i32 as i64 as u64)
    mov64 r1, -8                                    r1 = -8 as i32 as i64 as u64
    jgt r1, r3, lbb_5860                            if r1 > r3 { pc += 1 }
    ja lbb_5940                                     if true { pc += 80 }
lbb_5860:
    mov64 r1, 4                                     r1 = 4 as i32 as i64 as u64
    ja lbb_5916                                     if true { pc += 54 }
lbb_5862:
    jgt r1, 63, lbb_5864                            if r1 > (63 as i32 as i64 as u64) { pc += 1 }
    ja lbb_5872                                     if true { pc += 8 }
lbb_5864:
    jeq r3, 98, lbb_5946                            if r3 == (98 as i32 as i64 as u64) { pc += 81 }
    mov64 r1, 3                                     r1 = 3 as i32 as i64 as u64
    stxw [r10-0x20], r1                     
    mov64 r1, r10                                   r1 = r10
    add64 r1, -32                                   r1 += -32   ///  r1 = r1.wrapping_add(-32 as i32 as i64 as u64)
    ja lbb_5955                                     if true { pc += 85 }
lbb_5870:
    jeq r4, 5, lbb_5901                             if r4 == (5 as i32 as i64 as u64) { pc += 30 }
    jeq r4, 6, lbb_5909                             if r4 == (6 as i32 as i64 as u64) { pc += 37 }
lbb_5872:
    lddw r1, 0xe00000000                            r1 load str located at 60129542144
lbb_5874:
    stxdw [r6+0x8], r1                      
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
lbb_5876:
    stxdw [r6+0x0], r1                      
    ja lbb_5945                                     if true { pc += 67 }
lbb_5878:
    jgt r1, 7, lbb_5880                             if r1 > (7 as i32 as i64 as u64) { pc += 1 }
    ja lbb_5940                                     if true { pc += 60 }
lbb_5880:
    add64 r3, -17                                   r3 += -17   ///  r3 = r3.wrapping_add(-17 as i32 as i64 as u64)
    mov64 r1, -8                                    r1 = -8 as i32 as i64 as u64
    jgt r1, r3, lbb_5884                            if r1 > r3 { pc += 1 }
    ja lbb_5940                                     if true { pc += 56 }
lbb_5884:
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    ja lbb_5916                                     if true { pc += 30 }
lbb_5886:
    jgt r1, 7, lbb_5888                             if r1 > (7 as i32 as i64 as u64) { pc += 1 }
    ja lbb_5940                                     if true { pc += 52 }
lbb_5888:
    mov64 r4, r3                                    r4 = r3
    add64 r4, -17                                   r4 += -17   ///  r4 = r4.wrapping_add(-17 as i32 as i64 as u64)
    mov64 r1, -8                                    r1 = -8 as i32 as i64 as u64
    jgt r1, r4, lbb_5893                            if r1 > r4 { pc += 1 }
    ja lbb_5940                                     if true { pc += 47 }
lbb_5893:
    add64 r3, -25                                   r3 += -25   ///  r3 = r3.wrapping_add(-25 as i32 as i64 as u64)
    jgt r1, r3, lbb_5896                            if r1 > r3 { pc += 1 }
    ja lbb_5940                                     if true { pc += 44 }
lbb_5896:
    ldxdw r4, [r2+0x1]                      
    mov64 r1, 3                                     r1 = 3 as i32 as i64 as u64
lbb_5898:
    ldxdw r5, [r2+0x11]                     
    ldxdw r3, [r2+0x9]                      
    ja lbb_5918                                     if true { pc += 17 }
lbb_5901:
    jgt r1, 7, lbb_5903                             if r1 > (7 as i32 as i64 as u64) { pc += 1 }
    ja lbb_5940                                     if true { pc += 37 }
lbb_5903:
    add64 r3, -17                                   r3 += -17   ///  r3 = r3.wrapping_add(-17 as i32 as i64 as u64)
    mov64 r1, -8                                    r1 = -8 as i32 as i64 as u64
    jgt r1, r3, lbb_5907                            if r1 > r3 { pc += 1 }
    ja lbb_5940                                     if true { pc += 33 }
lbb_5907:
    mov64 r1, 5                                     r1 = 5 as i32 as i64 as u64
    ja lbb_5916                                     if true { pc += 7 }
lbb_5909:
    jgt r1, 7, lbb_5911                             if r1 > (7 as i32 as i64 as u64) { pc += 1 }
    ja lbb_5940                                     if true { pc += 29 }
lbb_5911:
    add64 r3, -17                                   r3 += -17   ///  r3 = r3.wrapping_add(-17 as i32 as i64 as u64)
    mov64 r1, -8                                    r1 = -8 as i32 as i64 as u64
    jgt r1, r3, lbb_5915                            if r1 > r3 { pc += 1 }
    ja lbb_5940                                     if true { pc += 25 }
lbb_5915:
    mov64 r1, 6                                     r1 = 6 as i32 as i64 as u64
lbb_5916:
    ldxdw r3, [r2+0x9]                      
    ldxdw r4, [r2+0x1]                      
lbb_5918:
    mov64 r2, 10000                                 r2 = 10000 as i32 as i64 as u64
    stxdw [r6+0x28], r2                     
    stxdw [r6+0x20], r5                     
    stxdw [r6+0x18], r3                     
    stxdw [r6+0x10], r4                     
    stxw [r6+0x8], r1                       
    ldxdw r1, [r10-0x58]                    
    stxdw [r6+0x30], r1                     
    ldxdw r1, [r10-0x50]                    
    stxdw [r6+0x38], r1                     
    mov64 r1, 100                                   r1 = 100 as i32 as i64 as u64
    stxdw [r6+0x48], r1                     
    mov64 r1, 20                                    r1 = 20 as i32 as i64 as u64
    stxdw [r6+0x40], r1                     
    ldxdw r1, [r10-0x70]                    
    stxdw [r6+0x50], r1                     
    ldxdw r1, [r10-0x68]                    
    stxdw [r6+0x58], r1                     
    ldxdw r1, [r10-0x60]                    
    stxdw [r6+0x60], r1                     
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    ja lbb_5876                                     if true { pc += -64 }
lbb_5940:
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    stxdw [r6+0x0], r1                      
    lddw r1, 0xe00000000                            r1 load str located at 60129542144
    stxdw [r6+0x8], r1                      
lbb_5945:
    exit                                    
lbb_5946:
    add64 r2, 65                                    r2 += 65   ///  r2 = r2.wrapping_add(65 as i32 as i64 as u64)
    mov64 r1, r10                                   r1 = r10
    add64 r1, -40                                   r1 += -40   ///  r1 = r1.wrapping_add(-40 as i32 as i64 as u64)
    mov64 r3, 33                                    r3 = 33 as i32 as i64 as u64
    call function_1070                      
    mov64 r1, r10                                   r1 = r10
    add64 r1, -32                                   r1 += -32   ///  r1 = r1.wrapping_add(-32 as i32 as i64 as u64)
    ldxdw r2, [r10-0x28]                    
    jeq r2, 0, lbb_5967                             if r2 == (0 as i32 as i64 as u64) { pc += 12 }
lbb_5955:
    ldxdw r2, [r1+0x18]                     
    stxdw [r10-0x30], r2                    
    ldxdw r3, [r1+0x10]                     
    stxdw [r10-0x38], r3                    
    ldxdw r4, [r1+0x8]                      
    stxdw [r10-0x40], r4                    
    ldxdw r1, [r1+0x0]                      
    stxdw [r10-0x48], r1                    
    stxdw [r6+0x20], r2                     
    stxdw [r6+0x18], r3                     
    stxdw [r6+0x10], r4                     
    ja lbb_5874                                     if true { pc += -93 }
lbb_5967:
    ldxdw r2, [r1+0x10]                     
    ldxdw r3, [r1+0x8]                      
    ldxdw r1, [r1+0x0]                      
    stxdw [r10-0x70], r1                    
    stxdw [r10-0x68], r3                    
    stxdw [r10-0x60], r2                    
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    stxdw [r10-0x58], r1                    
    stxdw [r10-0x50], r1                    
    mov64 r3, 10000                                 r3 = 10000 as i32 as i64 as u64
    mov64 r5, 2                                     r5 = 2 as i32 as i64 as u64
    mov64 r4, 2                                     r4 = 2 as i32 as i64 as u64
    ja lbb_5918                                     if true { pc += -62 }

function_5980:
    mov64 r7, r2                                    r7 = r2
    mov64 r6, r1                                    r6 = r1
    ldxdw r1, [r7+0x18]                     
    mov64 r2, r3                                    r2 = r3
    mov64 r3, 32                                    r3 = 32 as i32 as i64 as u64
    call function_21867                     
    lsh64 r0, 32                                    r0 <<= 32   ///  r0 = r0.wrapping_shl(32)
    rsh64 r0, 32                                    r0 >>= 32   ///  r0 = r0.wrapping_shr(32)
    jne r0, 0, lbb_6005                             if r0 != (0 as i32 as i64 as u64) { pc += 16 }
    ldxdw r8, [r7+0x10]                     
    ldxdw r1, [r8+0x10]                     
    lddw r2, 0x7fffffffffffffff                     r2 load str located at 9223372036854775807
    jgt r2, r1, lbb_6008                            if r2 > r1 { pc += 14 }
    mov64 r3, r10                                   r3 = r10
    add64 r3, -184                                  r3 += -184   ///  r3 = r3.wrapping_add(-184 as i32 as i64 as u64)
    lddw r1, 0x10002c380 --> b"already mutably borrowed"        r1 load str located at 4295148416
    mov64 r2, 24                                    r2 = 24 as i32 as i64 as u64
    lddw r4, 0x10002d940 --> b"\x00\x00\x00\x00x\x02\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x01\x00\x00…        r4 load str located at 4295153984
    lddw r5, 0x10002dc58 --> b"\x00\x00\x00\x00\x15\xc4\x02\x00\x18\x00\x00\x00\x00\x00\x00\x00+\x00\x00…        r5 load str located at 4295154776
    call function_19366                     
    syscall [invalid]                       
lbb_6005:
    mov64 r1, 6145                                  r1 = 6145 as i32 as i64 as u64
    stxh [r6+0x0], r1                       
    ja lbb_6058                                     if true { pc += 50 }
lbb_6008:
    add64 r1, 1                                     r1 += 1   ///  r1 = r1.wrapping_add(1 as i32 as i64 as u64)
    stxdw [r8+0x10], r1                     
    ldxdw r1, [r8+0x20]                     
    jeq r1, 165, lbb_6013                           if r1 == (165 as i32 as i64 as u64) { pc += 1 }
    ja lbb_6051                                     if true { pc += 38 }
lbb_6013:
    ldxdw r2, [r8+0x18]                     
    mov64 r1, r10                                   r1 = r10
    add64 r1, -184                                  r1 += -184   ///  r1 = r1.wrapping_add(-184 as i32 as i64 as u64)
    mov64 r3, 165                                   r3 = 165 as i32 as i64 as u64
    call function_13016                     
    ldxdw r1, [r10-0xb8]                    
    jne r1, 0, lbb_6044                             if r1 != (0 as i32 as i64 as u64) { pc += 24 }
    ldxdw r1, [r10-0xb0]                    
    stxdw [r10-0x170], r1                   
    ldxdw r1, [r10-0xa8]                    
    stxdw [r10-0x178], r1                   
    ldxdw r9, [r10-0xa0]                    
    ldxdw r7, [r10-0x98]                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -328                                  r1 += -328   ///  r1 = r1.wrapping_add(-328 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -144                                  r2 += -144   ///  r2 = r2.wrapping_add(-144 as i32 as i64 as u64)
    stxdw [r10-0x180], r1                   
    mov64 r3, 144                                   r3 = 144 as i32 as i64 as u64
    call function_21797                     
    stxdw [r10-0x150], r7                   
    stxdw [r10-0x158], r9                   
    ldxdw r1, [r10-0x178]                   
    stxdw [r10-0x160], r1                   
    ldxdw r1, [r10-0x170]                   
    stxdw [r10-0x168], r1                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -360                                  r1 += -360   ///  r1 = r1.wrapping_add(-360 as i32 as i64 as u64)
    call function_13011                     
    jne r0, 0, lbb_6059                             if r0 != (0 as i32 as i64 as u64) { pc += 16 }
    ja lbb_6051                                     if true { pc += 7 }
lbb_6044:
    ldxw r1, [r10-0xb0]                     
    jne r1, 14, lbb_6051                            if r1 != (14 as i32 as i64 as u64) { pc += 5 }
    ldxdw r2, [r10-0xa0]                    
    jeq r2, 0, lbb_6051                             if r2 == (0 as i32 as i64 as u64) { pc += 3 }
    ldxdw r1, [r10-0xa8]                    
    mov64 r3, 1                                     r3 = 1 as i32 as i64 as u64
    call function_11637                     
lbb_6051:
    mov64 r1, 5                                     r1 = 5 as i32 as i64 as u64
    stxb [r6+0x1], r1                       
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
lbb_6054:
    stxb [r6+0x0], r1                       
    ldxdw r1, [r8+0x10]                     
    add64 r1, -1                                    r1 += -1   ///  r1 = r1.wrapping_add(-1 as i32 as i64 as u64)
    stxdw [r8+0x10], r1                     
lbb_6058:
    exit                                    
lbb_6059:
    ldxdw r1, [r10-0x168]                   
    stxdw [r10-0x170], r1                   
    ldxdw r1, [r10-0x160]                   
    stxdw [r10-0x178], r1                   
    ldxdw r7, [r10-0x158]                   
    ldxdw r9, [r10-0x150]                   
    mov64 r1, r6                                    r1 = r6
    add64 r1, 40                                    r1 += 40   ///  r1 = r1.wrapping_add(40 as i32 as i64 as u64)
    ldxdw r2, [r10-0x180]                   
    mov64 r3, 144                                   r3 = 144 as i32 as i64 as u64
    call function_21797                     
    stxdw [r6+0x20], r9                     
    stxdw [r6+0x18], r7                     
    ldxdw r1, [r10-0x178]                   
    stxdw [r6+0x10], r1                     
    ldxdw r1, [r10-0x170]                   
    stxdw [r6+0x8], r1                      
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    ja lbb_6054                                     if true { pc += -24 }

function_6078:
    mov64 r7, r2                                    r7 = r2
    mov64 r6, r1                                    r6 = r1
    ldxdw r1, [r7+0x18]                     
    mov64 r2, r3                                    r2 = r3
    mov64 r3, 32                                    r3 = 32 as i32 as i64 as u64
    call function_21867                     
    lsh64 r0, 32                                    r0 <<= 32   ///  r0 = r0.wrapping_shl(32)
    rsh64 r0, 32                                    r0 >>= 32   ///  r0 = r0.wrapping_shr(32)
    jne r0, 0, lbb_6103                             if r0 != (0 as i32 as i64 as u64) { pc += 16 }
    ldxdw r8, [r7+0x10]                     
    ldxdw r1, [r8+0x10]                     
    lddw r2, 0x7fffffffffffffff                     r2 load str located at 9223372036854775807
    jgt r2, r1, lbb_6106                            if r2 > r1 { pc += 14 }
    mov64 r3, r10                                   r3 = r10
    add64 r3, -96                                   r3 += -96   ///  r3 = r3.wrapping_add(-96 as i32 as i64 as u64)
    lddw r1, 0x10002c380 --> b"already mutably borrowed"        r1 load str located at 4295148416
    mov64 r2, 24                                    r2 = 24 as i32 as i64 as u64
    lddw r4, 0x10002d940 --> b"\x00\x00\x00\x00x\x02\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x01\x00\x00…        r4 load str located at 4295153984
    lddw r5, 0x10002dc70 --> b"\x00\x00\x00\x00\x15\xc4\x02\x00\x18\x00\x00\x00\x00\x00\x00\x008\x00\x00…        r5 load str located at 4295154800
    call function_19366                     
    syscall [invalid]                       
lbb_6103:
    mov64 r1, 6145                                  r1 = 6145 as i32 as i64 as u64
    stxh [r6+0x0], r1                       
    ja lbb_6156                                     if true { pc += 50 }
lbb_6106:
    add64 r1, 1                                     r1 += 1   ///  r1 = r1.wrapping_add(1 as i32 as i64 as u64)
    stxdw [r8+0x10], r1                     
    ldxdw r1, [r8+0x20]                     
    jeq r1, 82, lbb_6111                            if r1 == (82 as i32 as i64 as u64) { pc += 1 }
    ja lbb_6149                                     if true { pc += 38 }
lbb_6111:
    ldxdw r2, [r8+0x18]                     
    mov64 r1, r10                                   r1 = r10
    add64 r1, -96                                   r1 += -96   ///  r1 = r1.wrapping_add(-96 as i32 as i64 as u64)
    mov64 r3, 82                                    r3 = 82 as i32 as i64 as u64
    call function_12852                     
    ldxdw r1, [r10-0x60]                    
    jne r1, 0, lbb_6142                             if r1 != (0 as i32 as i64 as u64) { pc += 24 }
    ldxdw r1, [r10-0x58]                    
    stxdw [r10-0xc0], r1                    
    ldxdw r1, [r10-0x50]                    
    stxdw [r10-0xc8], r1                    
    ldxdw r9, [r10-0x48]                    
    ldxdw r7, [r10-0x40]                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -152                                  r1 += -152   ///  r1 = r1.wrapping_add(-152 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -56                                   r2 += -56   ///  r2 = r2.wrapping_add(-56 as i32 as i64 as u64)
    stxdw [r10-0xd0], r1                    
    mov64 r3, 56                                    r3 = 56 as i32 as i64 as u64
    call function_21797                     
    stxdw [r10-0xa0], r7                    
    stxdw [r10-0xa8], r9                    
    ldxdw r1, [r10-0xc8]                    
    stxdw [r10-0xb0], r1                    
    ldxdw r1, [r10-0xc0]                    
    stxdw [r10-0xb8], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -184                                  r1 += -184   ///  r1 = r1.wrapping_add(-184 as i32 as i64 as u64)
    call function_12850                     
    jne r0, 0, lbb_6157                             if r0 != (0 as i32 as i64 as u64) { pc += 16 }
    ja lbb_6149                                     if true { pc += 7 }
lbb_6142:
    ldxw r1, [r10-0x58]                     
    jne r1, 14, lbb_6149                            if r1 != (14 as i32 as i64 as u64) { pc += 5 }
    ldxdw r2, [r10-0x48]                    
    jeq r2, 0, lbb_6149                             if r2 == (0 as i32 as i64 as u64) { pc += 3 }
    ldxdw r1, [r10-0x50]                    
    mov64 r3, 1                                     r3 = 1 as i32 as i64 as u64
    call function_11637                     
lbb_6149:
    mov64 r1, 4                                     r1 = 4 as i32 as i64 as u64
    stxb [r6+0x1], r1                       
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
lbb_6152:
    stxb [r6+0x0], r1                       
    ldxdw r1, [r8+0x10]                     
    add64 r1, -1                                    r1 += -1   ///  r1 = r1.wrapping_add(-1 as i32 as i64 as u64)
    stxdw [r8+0x10], r1                     
lbb_6156:
    exit                                    
lbb_6157:
    ldxdw r1, [r10-0xb8]                    
    stxdw [r10-0xc0], r1                    
    ldxdw r1, [r10-0xb0]                    
    stxdw [r10-0xc8], r1                    
    ldxdw r7, [r10-0xa8]                    
    ldxdw r9, [r10-0xa0]                    
    mov64 r1, r6                                    r1 = r6
    add64 r1, 40                                    r1 += 40   ///  r1 = r1.wrapping_add(40 as i32 as i64 as u64)
    ldxdw r2, [r10-0xd0]                    
    mov64 r3, 56                                    r3 = 56 as i32 as i64 as u64
    call function_21797                     
    stxdw [r6+0x20], r9                     
    stxdw [r6+0x18], r7                     
    ldxdw r1, [r10-0xc8]                    
    stxdw [r6+0x10], r1                     
    ldxdw r1, [r10-0xc0]                    
    stxdw [r6+0x8], r1                      
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    ja lbb_6152                                     if true { pc += -24 }

function_6176:
    mov64 r8, r4                                    r8 = r4
    stxdw [r10-0x78], r2                    
    mov64 r6, r1                                    r6 = r1
    ldxdw r1, [r3+0x18]                     
    stxdw [r10-0x58], r1                    
    ldxdw r1, [r3+0x10]                     
    stxdw [r10-0x60], r1                    
    ldxdw r1, [r3+0x8]                      
    stxdw [r10-0x68], r1                    
    ldxdw r1, [r3+0x0]                      
    stxdw [r10-0x70], r1                    
    mov64 r9, r10                                   r9 = r10
    add64 r9, -33                                   r9 += -33   ///  r9 = r9.wrapping_add(-33 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -112                                  r2 += -112   ///  r2 = r2.wrapping_add(-112 as i32 as i64 as u64)
    mov64 r1, r9                                    r1 = r9
    call function_17977                     
    mov64 r7, 1                                     r7 = 1 as i32 as i64 as u64
    stxdw [r10-0x30], r7                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -1                                    r1 += -1   ///  r1 = r1.wrapping_add(-1 as i32 as i64 as u64)
    stxdw [r10-0x38], r1                    
    mov64 r1, 32                                    r1 = 32 as i32 as i64 as u64
    stxdw [r10-0x40], r1                    
    stxdw [r10-0x48], r9                    
    stxb [r10-0x1], r8                      
    mov64 r1, r10                                   r1 = r10
    add64 r1, -112                                  r1 += -112   ///  r1 = r1.wrapping_add(-112 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -72                                   r2 += -72   ///  r2 = r2.wrapping_add(-72 as i32 as i64 as u64)
    mov64 r3, 2                                     r3 = 2 as i32 as i64 as u64
    ldxdw r4, [r10-0x78]                    
    call function_18335                     
    ldxb r1, [r10-0x70]                     
    jne r1, 0, lbb_6221                             if r1 != (0 as i32 as i64 as u64) { pc += 10 }
    ldxdw r1, [r10-0x57]                    
    stxdw [r6+0x19], r1                     
    ldxdw r1, [r10-0x5f]                    
    stxdw [r6+0x11], r1                     
    ldxdw r1, [r10-0x67]                    
    stxdw [r6+0x9], r1                      
    ldxdw r1, [r10-0x6f]                    
    stxdw [r6+0x1], r1                      
    mov64 r7, 0                                     r7 = 0 as i32 as i64 as u64
    ja lbb_6222                                     if true { pc += 1 }
lbb_6221:
    stxb [r6+0x1], r7                       
lbb_6222:
    stxb [r6+0x0], r7                       
    exit                                    

function_6224:
    mov64 r7, r5                                    r7 = r5
    mov64 r8, r4                                    r8 = r4
    mov64 r9, r3                                    r9 = r3
    stxdw [r10-0x1d0], r1                   
    ldxdw r1, [r2+0x18]                     
    stxdw [r10-0xa8], r1                    
    ldxdw r1, [r2+0x10]                     
    stxdw [r10-0xb0], r1                    
    ldxdw r1, [r2+0x8]                      
    stxdw [r10-0xb8], r1                    
    ldxdw r1, [r2+0x0]                      
    stxdw [r10-0xc0], r1                    
    mov64 r6, r10                                   r6 = r10
    add64 r6, -440                                  r6 += -440   ///  r6 = r6.wrapping_add(-440 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -192                                  r2 += -192   ///  r2 = r2.wrapping_add(-192 as i32 as i64 as u64)
    mov64 r1, r6                                    r1 = r6
    call function_17977                     
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    stxdw [r10-0x180], r1                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -369                                  r1 += -369   ///  r1 = r1.wrapping_add(-369 as i32 as i64 as u64)
    stxdw [r10-0x188], r1                   
    mov64 r1, 32                                    r1 = 32 as i32 as i64 as u64
    stxdw [r10-0x190], r1                   
    stxdw [r10-0x198], r6                   
    ldxdw r1, [r7-0xff0]                    
    stxb [r10-0x171], r1                    
    mov64 r1, 2                                     r1 = 2 as i32 as i64 as u64
    stxdw [r10-0x168], r1                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -408                                  r1 += -408   ///  r1 = r1.wrapping_add(-408 as i32 as i64 as u64)
    stxdw [r10-0x170], r1                   
    ldxdw r3, [r8+0x0]                      
    stxdw [r10-0x1d8], r9                   
    ldxdw r2, [r9+0x0]                      
    ldxdw r6, [r7-0xff8]                    
    ldxdw r9, [r7-0x1000]                   
    ldxdw r4, [r9+0x0]                      
    ldxdw r1, [r6+0x0]                      
    mov64 r5, 0                                     r5 = 0 as i32 as i64 as u64
    stxdw [r10-0xff0], r5                   
    ldxdw r5, [r7-0xfe8]                    
    stxdw [r10-0xfe8], r5                   
    lddw r5, 0x10002c350 --> b") when slicing `already borrowedrange end index al"        r5 load str located at 4295148368
    stxdw [r10-0xff8], r5                   
    stxdw [r10-0x1000], r1                  
    mov64 r1, r10                                   r1 = r10
    add64 r1, -192                                  r1 += -192   ///  r1 = r1.wrapping_add(-192 as i32 as i64 as u64)
    mov64 r5, r10                                   r5 = r10
    call function_12599                     
    mov64 r2, r10                                   r2 = r10
    add64 r2, -184                                  r2 += -184   ///  r2 = r2.wrapping_add(-184 as i32 as i64 as u64)
    ldxdw r1, [r10-0xc0]                    
    jne r1, 0, lbb_6351                             if r1 != (0 as i32 as i64 as u64) { pc += 71 }
    mov64 r7, r10                                   r7 = r10
    add64 r7, -272                                  r7 += -272   ///  r7 = r7.wrapping_add(-272 as i32 as i64 as u64)
    mov64 r1, r7                                    r1 = r7
    mov64 r3, 80                                    r3 = 80 as i32 as i64 as u64
    call function_21797                     
    mov64 r1, r10                                   r1 = r10
    add64 r1, -352                                  r1 += -352   ///  r1 = r1.wrapping_add(-352 as i32 as i64 as u64)
    stxdw [r10-0x1e0], r1                   
    mov64 r2, r7                                    r2 = r7
    mov64 r3, 80                                    r3 = 80 as i32 as i64 as u64
    call function_21797                     
    mov64 r7, r10                                   r7 = r10
    add64 r7, -192                                  r7 += -192   ///  r7 = r7.wrapping_add(-192 as i32 as i64 as u64)
    mov64 r1, r7                                    r1 = r7
    mov64 r2, r8                                    r2 = r8
    mov64 r3, 48                                    r3 = 48 as i32 as i64 as u64
    call function_21797                     
    mov64 r1, r10                                   r1 = r10
    add64 r1, -144                                  r1 += -144   ///  r1 = r1.wrapping_add(-144 as i32 as i64 as u64)
    mov64 r2, r9                                    r2 = r9
    mov64 r3, 48                                    r3 = 48 as i32 as i64 as u64
    call function_21797                     
    mov64 r1, r10                                   r1 = r10
    add64 r1, -96                                   r1 += -96   ///  r1 = r1.wrapping_add(-96 as i32 as i64 as u64)
    mov64 r2, r6                                    r2 = r6
    mov64 r3, 48                                    r3 = 48 as i32 as i64 as u64
    call function_21797                     
    mov64 r1, r10                                   r1 = r10
    add64 r1, -48                                   r1 += -48   ///  r1 = r1.wrapping_add(-48 as i32 as i64 as u64)
    ldxdw r2, [r10-0x1d8]                   
    mov64 r3, 48                                    r3 = 48 as i32 as i64 as u64
    call function_21797                     
    mov64 r1, r10                                   r1 = r10
    add64 r1, -368                                  r1 += -368   ///  r1 = r1.wrapping_add(-368 as i32 as i64 as u64)
    stxdw [r10-0x1000], r1                  
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    stxdw [r10-0xff8], r1                   
    mov64 r5, r10                                   r5 = r10
    ldxdw r1, [r10-0x1d0]                   
    ldxdw r2, [r10-0x1e0]                   
    mov64 r3, r7                                    r3 = r7
    mov64 r4, 4                                     r4 = 4 as i32 as i64 as u64
    call function_18010                     
    ldxdw r2, [r10-0x158]                   
    jeq r2, 0, lbb_6342                             if r2 == (0 as i32 as i64 as u64) { pc += 17 }
    ldxdw r6, [r10-0x160]                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -456                                  r1 += -456   ///  r1 = r1.wrapping_add(-456 as i32 as i64 as u64)
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
    mov64 r4, 34                                    r4 = 34 as i32 as i64 as u64
    mov64 r5, 0                                     r5 = 0 as i32 as i64 as u64
    call function_21911                     
    mov64 r3, 1                                     r3 = 1 as i32 as i64 as u64
    ldxdw r1, [r10-0x1c0]                   
    jne r1, 0, lbb_6336                             if r1 != (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
lbb_6336:
    ldxdw r2, [r10-0x1c8]                   
    jeq r2, 0, lbb_6342                             if r2 == (0 as i32 as i64 as u64) { pc += 4 }
    xor64 r3, -1                                    r3 ^= -1   ///  r3 = r3.xor(-1)
    and64 r3, 1                                     r3 &= 1   ///  r3 = r3.and(1)
    mov64 r1, r6                                    r1 = r6
    call function_11637                     
lbb_6342:
    ldxdw r2, [r10-0x140]                   
    jeq r2, 0, lbb_6347                             if r2 == (0 as i32 as i64 as u64) { pc += 3 }
    ldxdw r1, [r10-0x148]                   
    mov64 r3, 1                                     r3 = 1 as i32 as i64 as u64
    call function_11637                     
lbb_6347:
    mov64 r1, r10                                   r1 = r10
    add64 r1, -192                                  r1 += -192   ///  r1 = r1.wrapping_add(-192 as i32 as i64 as u64)
    call function_94                        
lbb_6350:
    exit                                    
lbb_6351:
    mov64 r7, r8                                    r7 = r8
    ldxdw r8, [r10-0x1d8]                   
    ldxdw r1, [r2+0x18]                     
    stxdw [r10-0xf8], r1                    
    ldxdw r3, [r2+0x10]                     
    stxdw [r10-0x100], r3                   
    ldxdw r4, [r2+0x8]                      
    stxdw [r10-0x108], r4                   
    ldxdw r2, [r2+0x0]                      
    stxdw [r10-0x110], r2                   
    ldxdw r5, [r10-0x1d0]                   
    stxdw [r5+0x18], r1                     
    stxdw [r5+0x10], r3                     
    stxdw [r5+0x8], r4                      
    stxdw [r5+0x0], r2                      
    ldxdw r1, [r6+0x8]                      
    ldxdw r2, [r1+0x0]                      
    add64 r2, -1                                    r2 += -1   ///  r2 = r2.wrapping_add(-1 as i32 as i64 as u64)
    stxdw [r1+0x0], r2                      
    jne r2, 0, lbb_6378                             if r2 != (0 as i32 as i64 as u64) { pc += 7 }
    ldxdw r2, [r1+0x8]                      
    add64 r2, -1                                    r2 += -1   ///  r2 = r2.wrapping_add(-1 as i32 as i64 as u64)
    stxdw [r1+0x8], r2                      
    jne r2, 0, lbb_6378                             if r2 != (0 as i32 as i64 as u64) { pc += 3 }
    mov64 r2, 32                                    r2 = 32 as i32 as i64 as u64
    mov64 r3, 8                                     r3 = 8 as i32 as i64 as u64
    call function_11637                     
lbb_6378:
    ldxdw r1, [r6+0x10]                     
    ldxdw r2, [r1+0x0]                      
    add64 r2, -1                                    r2 += -1   ///  r2 = r2.wrapping_add(-1 as i32 as i64 as u64)
    stxdw [r1+0x0], r2                      
    jne r2, 0, lbb_6390                             if r2 != (0 as i32 as i64 as u64) { pc += 7 }
    ldxdw r2, [r1+0x8]                      
    add64 r2, -1                                    r2 += -1   ///  r2 = r2.wrapping_add(-1 as i32 as i64 as u64)
    stxdw [r1+0x8], r2                      
    jne r2, 0, lbb_6390                             if r2 != (0 as i32 as i64 as u64) { pc += 3 }
    mov64 r2, 40                                    r2 = 40 as i32 as i64 as u64
    mov64 r3, 8                                     r3 = 8 as i32 as i64 as u64
    call function_11637                     
lbb_6390:
    ldxdw r1, [r9+0x8]                      
    ldxdw r2, [r1+0x0]                      
    add64 r2, -1                                    r2 += -1   ///  r2 = r2.wrapping_add(-1 as i32 as i64 as u64)
    stxdw [r1+0x0], r2                      
    mov64 r6, r8                                    r6 = r8
    jne r2, 0, lbb_6403                             if r2 != (0 as i32 as i64 as u64) { pc += 7 }
    ldxdw r2, [r1+0x8]                      
    add64 r2, -1                                    r2 += -1   ///  r2 = r2.wrapping_add(-1 as i32 as i64 as u64)
    stxdw [r1+0x8], r2                      
    jne r2, 0, lbb_6403                             if r2 != (0 as i32 as i64 as u64) { pc += 3 }
    mov64 r2, 32                                    r2 = 32 as i32 as i64 as u64
    mov64 r3, 8                                     r3 = 8 as i32 as i64 as u64
    call function_11637                     
lbb_6403:
    ldxdw r1, [r9+0x10]                     
    ldxdw r2, [r1+0x0]                      
    add64 r2, -1                                    r2 += -1   ///  r2 = r2.wrapping_add(-1 as i32 as i64 as u64)
    stxdw [r1+0x0], r2                      
    jne r2, 0, lbb_6415                             if r2 != (0 as i32 as i64 as u64) { pc += 7 }
    ldxdw r2, [r1+0x8]                      
    add64 r2, -1                                    r2 += -1   ///  r2 = r2.wrapping_add(-1 as i32 as i64 as u64)
    stxdw [r1+0x8], r2                      
    jne r2, 0, lbb_6415                             if r2 != (0 as i32 as i64 as u64) { pc += 3 }
    mov64 r2, 40                                    r2 = 40 as i32 as i64 as u64
    mov64 r3, 8                                     r3 = 8 as i32 as i64 as u64
    call function_11637                     
lbb_6415:
    ldxdw r1, [r7+0x8]                      
    ldxdw r2, [r1+0x0]                      
    add64 r2, -1                                    r2 += -1   ///  r2 = r2.wrapping_add(-1 as i32 as i64 as u64)
    stxdw [r1+0x0], r2                      
    jne r2, 0, lbb_6427                             if r2 != (0 as i32 as i64 as u64) { pc += 7 }
    ldxdw r2, [r1+0x8]                      
    add64 r2, -1                                    r2 += -1   ///  r2 = r2.wrapping_add(-1 as i32 as i64 as u64)
    stxdw [r1+0x8], r2                      
    jne r2, 0, lbb_6427                             if r2 != (0 as i32 as i64 as u64) { pc += 3 }
    mov64 r2, 32                                    r2 = 32 as i32 as i64 as u64
    mov64 r3, 8                                     r3 = 8 as i32 as i64 as u64
    call function_11637                     
lbb_6427:
    ldxdw r1, [r7+0x10]                     
    ldxdw r2, [r1+0x0]                      
    add64 r2, -1                                    r2 += -1   ///  r2 = r2.wrapping_add(-1 as i32 as i64 as u64)
    stxdw [r1+0x0], r2                      
    jne r2, 0, lbb_6439                             if r2 != (0 as i32 as i64 as u64) { pc += 7 }
    ldxdw r2, [r1+0x8]                      
    add64 r2, -1                                    r2 += -1   ///  r2 = r2.wrapping_add(-1 as i32 as i64 as u64)
    stxdw [r1+0x8], r2                      
    jne r2, 0, lbb_6439                             if r2 != (0 as i32 as i64 as u64) { pc += 3 }
    mov64 r2, 40                                    r2 = 40 as i32 as i64 as u64
    mov64 r3, 8                                     r3 = 8 as i32 as i64 as u64
    call function_11637                     
lbb_6439:
    ldxdw r1, [r6+0x8]                      
    ldxdw r2, [r1+0x0]                      
    add64 r2, -1                                    r2 += -1   ///  r2 = r2.wrapping_add(-1 as i32 as i64 as u64)
    stxdw [r1+0x0], r2                      
    jne r2, 0, lbb_6451                             if r2 != (0 as i32 as i64 as u64) { pc += 7 }
    ldxdw r2, [r1+0x8]                      
    add64 r2, -1                                    r2 += -1   ///  r2 = r2.wrapping_add(-1 as i32 as i64 as u64)
    stxdw [r1+0x8], r2                      
    jne r2, 0, lbb_6451                             if r2 != (0 as i32 as i64 as u64) { pc += 3 }
    mov64 r2, 32                                    r2 = 32 as i32 as i64 as u64
    mov64 r3, 8                                     r3 = 8 as i32 as i64 as u64
    call function_11637                     
lbb_6451:
    ldxdw r1, [r6+0x10]                     
    ldxdw r2, [r1+0x0]                      
    add64 r2, -1                                    r2 += -1   ///  r2 = r2.wrapping_add(-1 as i32 as i64 as u64)
    stxdw [r1+0x0], r2                      
    jne r2, 0, lbb_6350                             if r2 != (0 as i32 as i64 as u64) { pc += -106 }
    ldxdw r2, [r1+0x8]                      
    add64 r2, -1                                    r2 += -1   ///  r2 = r2.wrapping_add(-1 as i32 as i64 as u64)
    stxdw [r1+0x8], r2                      
    jne r2, 0, lbb_6350                             if r2 != (0 as i32 as i64 as u64) { pc += -110 }
    mov64 r2, 40                                    r2 = 40 as i32 as i64 as u64
    mov64 r3, 8                                     r3 = 8 as i32 as i64 as u64
    call function_11637                     
    ja lbb_6350                                     if true { pc += -114 }

function_6464:
    mov64 r7, r5                                    r7 = r5
    mov64 r8, r4                                    r8 = r4
    mov64 r9, r3                                    r9 = r3
    stxdw [r10-0x1d0], r1                   
    ldxdw r1, [r2+0x18]                     
    stxdw [r10-0xa8], r1                    
    ldxdw r1, [r2+0x10]                     
    stxdw [r10-0xb0], r1                    
    ldxdw r1, [r2+0x8]                      
    stxdw [r10-0xb8], r1                    
    ldxdw r1, [r2+0x0]                      
    stxdw [r10-0xc0], r1                    
    mov64 r6, r10                                   r6 = r10
    add64 r6, -440                                  r6 += -440   ///  r6 = r6.wrapping_add(-440 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -192                                  r2 += -192   ///  r2 = r2.wrapping_add(-192 as i32 as i64 as u64)
    mov64 r1, r6                                    r1 = r6
    call function_17977                     
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    stxdw [r10-0x180], r1                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -369                                  r1 += -369   ///  r1 = r1.wrapping_add(-369 as i32 as i64 as u64)
    stxdw [r10-0x188], r1                   
    mov64 r1, 32                                    r1 = 32 as i32 as i64 as u64
    stxdw [r10-0x190], r1                   
    stxdw [r10-0x198], r6                   
    ldxdw r1, [r7-0xff0]                    
    stxb [r10-0x171], r1                    
    mov64 r1, 2                                     r1 = 2 as i32 as i64 as u64
    stxdw [r10-0x168], r1                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -408                                  r1 += -408   ///  r1 = r1.wrapping_add(-408 as i32 as i64 as u64)
    stxdw [r10-0x170], r1                   
    ldxdw r3, [r8+0x0]                      
    stxdw [r10-0x1d8], r9                   
    ldxdw r2, [r9+0x0]                      
    ldxdw r6, [r7-0xff8]                    
    ldxdw r9, [r7-0x1000]                   
    ldxdw r4, [r9+0x0]                      
    ldxdw r1, [r6+0x0]                      
    mov64 r5, 0                                     r5 = 0 as i32 as i64 as u64
    stxdw [r10-0xff0], r5                   
    ldxdw r5, [r7-0xfe8]                    
    stxdw [r10-0xfe8], r5                   
    lddw r5, 0x10002c350 --> b") when slicing `already borrowedrange end index al"        r5 load str located at 4295148368
    stxdw [r10-0xff8], r5                   
    stxdw [r10-0x1000], r1                  
    mov64 r1, r10                                   r1 = r10
    add64 r1, -192                                  r1 += -192   ///  r1 = r1.wrapping_add(-192 as i32 as i64 as u64)
    mov64 r5, r10                                   r5 = r10
    call function_12348                     
    mov64 r2, r10                                   r2 = r10
    add64 r2, -184                                  r2 += -184   ///  r2 = r2.wrapping_add(-184 as i32 as i64 as u64)
    ldxdw r1, [r10-0xc0]                    
    jne r1, 0, lbb_6591                             if r1 != (0 as i32 as i64 as u64) { pc += 71 }
    mov64 r7, r10                                   r7 = r10
    add64 r7, -272                                  r7 += -272   ///  r7 = r7.wrapping_add(-272 as i32 as i64 as u64)
    mov64 r1, r7                                    r1 = r7
    mov64 r3, 80                                    r3 = 80 as i32 as i64 as u64
    call function_21797                     
    mov64 r1, r10                                   r1 = r10
    add64 r1, -352                                  r1 += -352   ///  r1 = r1.wrapping_add(-352 as i32 as i64 as u64)
    stxdw [r10-0x1e0], r1                   
    mov64 r2, r7                                    r2 = r7
    mov64 r3, 80                                    r3 = 80 as i32 as i64 as u64
    call function_21797                     
    mov64 r7, r10                                   r7 = r10
    add64 r7, -192                                  r7 += -192   ///  r7 = r7.wrapping_add(-192 as i32 as i64 as u64)
    mov64 r1, r7                                    r1 = r7
    mov64 r2, r8                                    r2 = r8
    mov64 r3, 48                                    r3 = 48 as i32 as i64 as u64
    call function_21797                     
    mov64 r1, r10                                   r1 = r10
    add64 r1, -144                                  r1 += -144   ///  r1 = r1.wrapping_add(-144 as i32 as i64 as u64)
    mov64 r2, r9                                    r2 = r9
    mov64 r3, 48                                    r3 = 48 as i32 as i64 as u64
    call function_21797                     
    mov64 r1, r10                                   r1 = r10
    add64 r1, -96                                   r1 += -96   ///  r1 = r1.wrapping_add(-96 as i32 as i64 as u64)
    mov64 r2, r6                                    r2 = r6
    mov64 r3, 48                                    r3 = 48 as i32 as i64 as u64
    call function_21797                     
    mov64 r1, r10                                   r1 = r10
    add64 r1, -48                                   r1 += -48   ///  r1 = r1.wrapping_add(-48 as i32 as i64 as u64)
    ldxdw r2, [r10-0x1d8]                   
    mov64 r3, 48                                    r3 = 48 as i32 as i64 as u64
    call function_21797                     
    mov64 r1, r10                                   r1 = r10
    add64 r1, -368                                  r1 += -368   ///  r1 = r1.wrapping_add(-368 as i32 as i64 as u64)
    stxdw [r10-0x1000], r1                  
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    stxdw [r10-0xff8], r1                   
    mov64 r5, r10                                   r5 = r10
    ldxdw r1, [r10-0x1d0]                   
    ldxdw r2, [r10-0x1e0]                   
    mov64 r3, r7                                    r3 = r7
    mov64 r4, 4                                     r4 = 4 as i32 as i64 as u64
    call function_18010                     
    ldxdw r2, [r10-0x158]                   
    jeq r2, 0, lbb_6582                             if r2 == (0 as i32 as i64 as u64) { pc += 17 }
    ldxdw r6, [r10-0x160]                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -456                                  r1 += -456   ///  r1 = r1.wrapping_add(-456 as i32 as i64 as u64)
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
    mov64 r4, 34                                    r4 = 34 as i32 as i64 as u64
    mov64 r5, 0                                     r5 = 0 as i32 as i64 as u64
    call function_21911                     
    mov64 r3, 1                                     r3 = 1 as i32 as i64 as u64
    ldxdw r1, [r10-0x1c0]                   
    jne r1, 0, lbb_6576                             if r1 != (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
lbb_6576:
    ldxdw r2, [r10-0x1c8]                   
    jeq r2, 0, lbb_6582                             if r2 == (0 as i32 as i64 as u64) { pc += 4 }
    xor64 r3, -1                                    r3 ^= -1   ///  r3 = r3.xor(-1)
    and64 r3, 1                                     r3 &= 1   ///  r3 = r3.and(1)
    mov64 r1, r6                                    r1 = r6
    call function_11637                     
lbb_6582:
    ldxdw r2, [r10-0x140]                   
    jeq r2, 0, lbb_6587                             if r2 == (0 as i32 as i64 as u64) { pc += 3 }
    ldxdw r1, [r10-0x148]                   
    mov64 r3, 1                                     r3 = 1 as i32 as i64 as u64
    call function_11637                     
lbb_6587:
    mov64 r1, r10                                   r1 = r10
    add64 r1, -192                                  r1 += -192   ///  r1 = r1.wrapping_add(-192 as i32 as i64 as u64)
    call function_94                        
lbb_6590:
    exit                                    
lbb_6591:
    mov64 r7, r8                                    r7 = r8
    ldxdw r8, [r10-0x1d8]                   
    ldxdw r1, [r2+0x18]                     
    stxdw [r10-0xf8], r1                    
    ldxdw r3, [r2+0x10]                     
    stxdw [r10-0x100], r3                   
    ldxdw r4, [r2+0x8]                      
    stxdw [r10-0x108], r4                   
    ldxdw r2, [r2+0x0]                      
    stxdw [r10-0x110], r2                   
    ldxdw r5, [r10-0x1d0]                   
    stxdw [r5+0x18], r1                     
    stxdw [r5+0x10], r3                     
    stxdw [r5+0x8], r4                      
    stxdw [r5+0x0], r2                      
    ldxdw r1, [r6+0x8]                      
    ldxdw r2, [r1+0x0]                      
    add64 r2, -1                                    r2 += -1   ///  r2 = r2.wrapping_add(-1 as i32 as i64 as u64)
    stxdw [r1+0x0], r2                      
    jne r2, 0, lbb_6618                             if r2 != (0 as i32 as i64 as u64) { pc += 7 }
    ldxdw r2, [r1+0x8]                      
    add64 r2, -1                                    r2 += -1   ///  r2 = r2.wrapping_add(-1 as i32 as i64 as u64)
    stxdw [r1+0x8], r2                      
    jne r2, 0, lbb_6618                             if r2 != (0 as i32 as i64 as u64) { pc += 3 }
    mov64 r2, 32                                    r2 = 32 as i32 as i64 as u64
    mov64 r3, 8                                     r3 = 8 as i32 as i64 as u64
    call function_11637                     
lbb_6618:
    ldxdw r1, [r6+0x10]                     
    ldxdw r2, [r1+0x0]                      
    add64 r2, -1                                    r2 += -1   ///  r2 = r2.wrapping_add(-1 as i32 as i64 as u64)
    stxdw [r1+0x0], r2                      
    jne r2, 0, lbb_6630                             if r2 != (0 as i32 as i64 as u64) { pc += 7 }
    ldxdw r2, [r1+0x8]                      
    add64 r2, -1                                    r2 += -1   ///  r2 = r2.wrapping_add(-1 as i32 as i64 as u64)
    stxdw [r1+0x8], r2                      
    jne r2, 0, lbb_6630                             if r2 != (0 as i32 as i64 as u64) { pc += 3 }
    mov64 r2, 40                                    r2 = 40 as i32 as i64 as u64
    mov64 r3, 8                                     r3 = 8 as i32 as i64 as u64
    call function_11637                     
lbb_6630:
    ldxdw r1, [r9+0x8]                      
    ldxdw r2, [r1+0x0]                      
    add64 r2, -1                                    r2 += -1   ///  r2 = r2.wrapping_add(-1 as i32 as i64 as u64)
    stxdw [r1+0x0], r2                      
    mov64 r6, r8                                    r6 = r8
    jne r2, 0, lbb_6643                             if r2 != (0 as i32 as i64 as u64) { pc += 7 }
    ldxdw r2, [r1+0x8]                      
    add64 r2, -1                                    r2 += -1   ///  r2 = r2.wrapping_add(-1 as i32 as i64 as u64)
    stxdw [r1+0x8], r2                      
    jne r2, 0, lbb_6643                             if r2 != (0 as i32 as i64 as u64) { pc += 3 }
    mov64 r2, 32                                    r2 = 32 as i32 as i64 as u64
    mov64 r3, 8                                     r3 = 8 as i32 as i64 as u64
    call function_11637                     
lbb_6643:
    ldxdw r1, [r9+0x10]                     
    ldxdw r2, [r1+0x0]                      
    add64 r2, -1                                    r2 += -1   ///  r2 = r2.wrapping_add(-1 as i32 as i64 as u64)
    stxdw [r1+0x0], r2                      
    jne r2, 0, lbb_6655                             if r2 != (0 as i32 as i64 as u64) { pc += 7 }
    ldxdw r2, [r1+0x8]                      
    add64 r2, -1                                    r2 += -1   ///  r2 = r2.wrapping_add(-1 as i32 as i64 as u64)
    stxdw [r1+0x8], r2                      
    jne r2, 0, lbb_6655                             if r2 != (0 as i32 as i64 as u64) { pc += 3 }
    mov64 r2, 40                                    r2 = 40 as i32 as i64 as u64
    mov64 r3, 8                                     r3 = 8 as i32 as i64 as u64
    call function_11637                     
lbb_6655:
    ldxdw r1, [r7+0x8]                      
    ldxdw r2, [r1+0x0]                      
    add64 r2, -1                                    r2 += -1   ///  r2 = r2.wrapping_add(-1 as i32 as i64 as u64)
    stxdw [r1+0x0], r2                      
    jne r2, 0, lbb_6667                             if r2 != (0 as i32 as i64 as u64) { pc += 7 }
    ldxdw r2, [r1+0x8]                      
    add64 r2, -1                                    r2 += -1   ///  r2 = r2.wrapping_add(-1 as i32 as i64 as u64)
    stxdw [r1+0x8], r2                      
    jne r2, 0, lbb_6667                             if r2 != (0 as i32 as i64 as u64) { pc += 3 }
    mov64 r2, 32                                    r2 = 32 as i32 as i64 as u64
    mov64 r3, 8                                     r3 = 8 as i32 as i64 as u64
    call function_11637                     
lbb_6667:
    ldxdw r1, [r7+0x10]                     
    ldxdw r2, [r1+0x0]                      
    add64 r2, -1                                    r2 += -1   ///  r2 = r2.wrapping_add(-1 as i32 as i64 as u64)
    stxdw [r1+0x0], r2                      
    jne r2, 0, lbb_6679                             if r2 != (0 as i32 as i64 as u64) { pc += 7 }
    ldxdw r2, [r1+0x8]                      
    add64 r2, -1                                    r2 += -1   ///  r2 = r2.wrapping_add(-1 as i32 as i64 as u64)
    stxdw [r1+0x8], r2                      
    jne r2, 0, lbb_6679                             if r2 != (0 as i32 as i64 as u64) { pc += 3 }
    mov64 r2, 40                                    r2 = 40 as i32 as i64 as u64
    mov64 r3, 8                                     r3 = 8 as i32 as i64 as u64
    call function_11637                     
lbb_6679:
    ldxdw r1, [r6+0x8]                      
    ldxdw r2, [r1+0x0]                      
    add64 r2, -1                                    r2 += -1   ///  r2 = r2.wrapping_add(-1 as i32 as i64 as u64)
    stxdw [r1+0x0], r2                      
    jne r2, 0, lbb_6691                             if r2 != (0 as i32 as i64 as u64) { pc += 7 }
    ldxdw r2, [r1+0x8]                      
    add64 r2, -1                                    r2 += -1   ///  r2 = r2.wrapping_add(-1 as i32 as i64 as u64)
    stxdw [r1+0x8], r2                      
    jne r2, 0, lbb_6691                             if r2 != (0 as i32 as i64 as u64) { pc += 3 }
    mov64 r2, 32                                    r2 = 32 as i32 as i64 as u64
    mov64 r3, 8                                     r3 = 8 as i32 as i64 as u64
    call function_11637                     
lbb_6691:
    ldxdw r1, [r6+0x10]                     
    ldxdw r2, [r1+0x0]                      
    add64 r2, -1                                    r2 += -1   ///  r2 = r2.wrapping_add(-1 as i32 as i64 as u64)
    stxdw [r1+0x0], r2                      
    jne r2, 0, lbb_6590                             if r2 != (0 as i32 as i64 as u64) { pc += -106 }
    ldxdw r2, [r1+0x8]                      
    add64 r2, -1                                    r2 += -1   ///  r2 = r2.wrapping_add(-1 as i32 as i64 as u64)
    stxdw [r1+0x8], r2                      
    jne r2, 0, lbb_6590                             if r2 != (0 as i32 as i64 as u64) { pc += -110 }
    mov64 r2, 40                                    r2 = 40 as i32 as i64 as u64
    mov64 r3, 8                                     r3 = 8 as i32 as i64 as u64
    call function_11637                     
    ja lbb_6590                                     if true { pc += -114 }

function_6704:
    mov64 r7, r5                                    r7 = r5
    mov64 r8, r4                                    r8 = r4
    mov64 r9, r3                                    r9 = r3
    stxdw [r10-0x1d0], r1                   
    ldxdw r1, [r2+0x18]                     
    stxdw [r10-0xa8], r1                    
    ldxdw r1, [r2+0x10]                     
    stxdw [r10-0xb0], r1                    
    ldxdw r1, [r2+0x8]                      
    stxdw [r10-0xb8], r1                    
    ldxdw r1, [r2+0x0]                      
    stxdw [r10-0xc0], r1                    
    mov64 r6, r10                                   r6 = r10
    add64 r6, -440                                  r6 += -440   ///  r6 = r6.wrapping_add(-440 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -192                                  r2 += -192   ///  r2 = r2.wrapping_add(-192 as i32 as i64 as u64)
    mov64 r1, r6                                    r1 = r6
    call function_17977                     
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    stxdw [r10-0x180], r1                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -369                                  r1 += -369   ///  r1 = r1.wrapping_add(-369 as i32 as i64 as u64)
    stxdw [r10-0x188], r1                   
    mov64 r1, 32                                    r1 = 32 as i32 as i64 as u64
    stxdw [r10-0x190], r1                   
    stxdw [r10-0x198], r6                   
    ldxdw r1, [r7-0xff0]                    
    stxb [r10-0x171], r1                    
    mov64 r1, 2                                     r1 = 2 as i32 as i64 as u64
    stxdw [r10-0x168], r1                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -408                                  r1 += -408   ///  r1 = r1.wrapping_add(-408 as i32 as i64 as u64)
    stxdw [r10-0x170], r1                   
    ldxdw r3, [r8+0x0]                      
    stxdw [r10-0x1d8], r9                   
    ldxdw r2, [r9+0x0]                      
    ldxdw r6, [r7-0xff8]                    
    ldxdw r9, [r7-0x1000]                   
    ldxdw r4, [r9+0x0]                      
    ldxdw r1, [r6+0x0]                      
    mov64 r5, 0                                     r5 = 0 as i32 as i64 as u64
    stxdw [r10-0xff0], r5                   
    ldxdw r5, [r7-0xfe8]                    
    stxdw [r10-0xfe8], r5                   
    lddw r5, 0x10002c350 --> b") when slicing `already borrowedrange end index al"        r5 load str located at 4295148368
    stxdw [r10-0xff8], r5                   
    stxdw [r10-0x1000], r1                  
    mov64 r1, r10                                   r1 = r10
    add64 r1, -192                                  r1 += -192   ///  r1 = r1.wrapping_add(-192 as i32 as i64 as u64)
    mov64 r5, r10                                   r5 = r10
    call function_12097                     
    mov64 r2, r10                                   r2 = r10
    add64 r2, -184                                  r2 += -184   ///  r2 = r2.wrapping_add(-184 as i32 as i64 as u64)
    ldxdw r1, [r10-0xc0]                    
    jne r1, 0, lbb_6831                             if r1 != (0 as i32 as i64 as u64) { pc += 71 }
    mov64 r7, r10                                   r7 = r10
    add64 r7, -272                                  r7 += -272   ///  r7 = r7.wrapping_add(-272 as i32 as i64 as u64)
    mov64 r1, r7                                    r1 = r7
    mov64 r3, 80                                    r3 = 80 as i32 as i64 as u64
    call function_21797                     
    mov64 r1, r10                                   r1 = r10
    add64 r1, -352                                  r1 += -352   ///  r1 = r1.wrapping_add(-352 as i32 as i64 as u64)
    stxdw [r10-0x1e0], r1                   
    mov64 r2, r7                                    r2 = r7
    mov64 r3, 80                                    r3 = 80 as i32 as i64 as u64
    call function_21797                     
    mov64 r7, r10                                   r7 = r10
    add64 r7, -192                                  r7 += -192   ///  r7 = r7.wrapping_add(-192 as i32 as i64 as u64)
    mov64 r1, r7                                    r1 = r7
    mov64 r2, r8                                    r2 = r8
    mov64 r3, 48                                    r3 = 48 as i32 as i64 as u64
    call function_21797                     
    mov64 r1, r10                                   r1 = r10
    add64 r1, -144                                  r1 += -144   ///  r1 = r1.wrapping_add(-144 as i32 as i64 as u64)
    mov64 r2, r9                                    r2 = r9
    mov64 r3, 48                                    r3 = 48 as i32 as i64 as u64
    call function_21797                     
    mov64 r1, r10                                   r1 = r10
    add64 r1, -96                                   r1 += -96   ///  r1 = r1.wrapping_add(-96 as i32 as i64 as u64)
    mov64 r2, r6                                    r2 = r6
    mov64 r3, 48                                    r3 = 48 as i32 as i64 as u64
    call function_21797                     
    mov64 r1, r10                                   r1 = r10
    add64 r1, -48                                   r1 += -48   ///  r1 = r1.wrapping_add(-48 as i32 as i64 as u64)
    ldxdw r2, [r10-0x1d8]                   
    mov64 r3, 48                                    r3 = 48 as i32 as i64 as u64
    call function_21797                     
    mov64 r1, r10                                   r1 = r10
    add64 r1, -368                                  r1 += -368   ///  r1 = r1.wrapping_add(-368 as i32 as i64 as u64)
    stxdw [r10-0x1000], r1                  
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    stxdw [r10-0xff8], r1                   
    mov64 r5, r10                                   r5 = r10
    ldxdw r1, [r10-0x1d0]                   
    ldxdw r2, [r10-0x1e0]                   
    mov64 r3, r7                                    r3 = r7
    mov64 r4, 4                                     r4 = 4 as i32 as i64 as u64
    call function_18010                     
    ldxdw r2, [r10-0x158]                   
    jeq r2, 0, lbb_6822                             if r2 == (0 as i32 as i64 as u64) { pc += 17 }
    ldxdw r6, [r10-0x160]                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -456                                  r1 += -456   ///  r1 = r1.wrapping_add(-456 as i32 as i64 as u64)
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
    mov64 r4, 34                                    r4 = 34 as i32 as i64 as u64
    mov64 r5, 0                                     r5 = 0 as i32 as i64 as u64
    call function_21911                     
    mov64 r3, 1                                     r3 = 1 as i32 as i64 as u64
    ldxdw r1, [r10-0x1c0]                   
    jne r1, 0, lbb_6816                             if r1 != (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
lbb_6816:
    ldxdw r2, [r10-0x1c8]                   
    jeq r2, 0, lbb_6822                             if r2 == (0 as i32 as i64 as u64) { pc += 4 }
    xor64 r3, -1                                    r3 ^= -1   ///  r3 = r3.xor(-1)
    and64 r3, 1                                     r3 &= 1   ///  r3 = r3.and(1)
    mov64 r1, r6                                    r1 = r6
    call function_11637                     
lbb_6822:
    ldxdw r2, [r10-0x140]                   
    jeq r2, 0, lbb_6827                             if r2 == (0 as i32 as i64 as u64) { pc += 3 }
    ldxdw r1, [r10-0x148]                   
    mov64 r3, 1                                     r3 = 1 as i32 as i64 as u64
    call function_11637                     
lbb_6827:
    mov64 r1, r10                                   r1 = r10
    add64 r1, -192                                  r1 += -192   ///  r1 = r1.wrapping_add(-192 as i32 as i64 as u64)
    call function_94                        
lbb_6830:
    exit                                    
lbb_6831:
    mov64 r7, r8                                    r7 = r8
    ldxdw r8, [r10-0x1d8]                   
    ldxdw r1, [r2+0x18]                     
    stxdw [r10-0xf8], r1                    
    ldxdw r3, [r2+0x10]                     
    stxdw [r10-0x100], r3                   
    ldxdw r4, [r2+0x8]                      
    stxdw [r10-0x108], r4                   
    ldxdw r2, [r2+0x0]                      
    stxdw [r10-0x110], r2                   
    ldxdw r5, [r10-0x1d0]                   
    stxdw [r5+0x18], r1                     
    stxdw [r5+0x10], r3                     
    stxdw [r5+0x8], r4                      
    stxdw [r5+0x0], r2                      
    ldxdw r1, [r6+0x8]                      
    ldxdw r2, [r1+0x0]                      
    add64 r2, -1                                    r2 += -1   ///  r2 = r2.wrapping_add(-1 as i32 as i64 as u64)
    stxdw [r1+0x0], r2                      
    jne r2, 0, lbb_6858                             if r2 != (0 as i32 as i64 as u64) { pc += 7 }
    ldxdw r2, [r1+0x8]                      
    add64 r2, -1                                    r2 += -1   ///  r2 = r2.wrapping_add(-1 as i32 as i64 as u64)
    stxdw [r1+0x8], r2                      
    jne r2, 0, lbb_6858                             if r2 != (0 as i32 as i64 as u64) { pc += 3 }
    mov64 r2, 32                                    r2 = 32 as i32 as i64 as u64
    mov64 r3, 8                                     r3 = 8 as i32 as i64 as u64
    call function_11637                     
lbb_6858:
    ldxdw r1, [r6+0x10]                     
    ldxdw r2, [r1+0x0]                      
    add64 r2, -1                                    r2 += -1   ///  r2 = r2.wrapping_add(-1 as i32 as i64 as u64)
    stxdw [r1+0x0], r2                      
    jne r2, 0, lbb_6870                             if r2 != (0 as i32 as i64 as u64) { pc += 7 }
    ldxdw r2, [r1+0x8]                      
    add64 r2, -1                                    r2 += -1   ///  r2 = r2.wrapping_add(-1 as i32 as i64 as u64)
    stxdw [r1+0x8], r2                      
    jne r2, 0, lbb_6870                             if r2 != (0 as i32 as i64 as u64) { pc += 3 }
    mov64 r2, 40                                    r2 = 40 as i32 as i64 as u64
    mov64 r3, 8                                     r3 = 8 as i32 as i64 as u64
    call function_11637                     
lbb_6870:
    ldxdw r1, [r9+0x8]                      
    ldxdw r2, [r1+0x0]                      
    add64 r2, -1                                    r2 += -1   ///  r2 = r2.wrapping_add(-1 as i32 as i64 as u64)
    stxdw [r1+0x0], r2                      
    mov64 r6, r8                                    r6 = r8
    jne r2, 0, lbb_6883                             if r2 != (0 as i32 as i64 as u64) { pc += 7 }
    ldxdw r2, [r1+0x8]                      
    add64 r2, -1                                    r2 += -1   ///  r2 = r2.wrapping_add(-1 as i32 as i64 as u64)
    stxdw [r1+0x8], r2                      
    jne r2, 0, lbb_6883                             if r2 != (0 as i32 as i64 as u64) { pc += 3 }
    mov64 r2, 32                                    r2 = 32 as i32 as i64 as u64
    mov64 r3, 8                                     r3 = 8 as i32 as i64 as u64
    call function_11637                     
lbb_6883:
    ldxdw r1, [r9+0x10]                     
    ldxdw r2, [r1+0x0]                      
    add64 r2, -1                                    r2 += -1   ///  r2 = r2.wrapping_add(-1 as i32 as i64 as u64)
    stxdw [r1+0x0], r2                      
    jne r2, 0, lbb_6895                             if r2 != (0 as i32 as i64 as u64) { pc += 7 }
    ldxdw r2, [r1+0x8]                      
    add64 r2, -1                                    r2 += -1   ///  r2 = r2.wrapping_add(-1 as i32 as i64 as u64)
    stxdw [r1+0x8], r2                      
    jne r2, 0, lbb_6895                             if r2 != (0 as i32 as i64 as u64) { pc += 3 }
    mov64 r2, 40                                    r2 = 40 as i32 as i64 as u64
    mov64 r3, 8                                     r3 = 8 as i32 as i64 as u64
    call function_11637                     
lbb_6895:
    ldxdw r1, [r7+0x8]                      
    ldxdw r2, [r1+0x0]                      
    add64 r2, -1                                    r2 += -1   ///  r2 = r2.wrapping_add(-1 as i32 as i64 as u64)
    stxdw [r1+0x0], r2                      
    jne r2, 0, lbb_6907                             if r2 != (0 as i32 as i64 as u64) { pc += 7 }
    ldxdw r2, [r1+0x8]                      
    add64 r2, -1                                    r2 += -1   ///  r2 = r2.wrapping_add(-1 as i32 as i64 as u64)
    stxdw [r1+0x8], r2                      
    jne r2, 0, lbb_6907                             if r2 != (0 as i32 as i64 as u64) { pc += 3 }
    mov64 r2, 32                                    r2 = 32 as i32 as i64 as u64
    mov64 r3, 8                                     r3 = 8 as i32 as i64 as u64
    call function_11637                     
lbb_6907:
    ldxdw r1, [r7+0x10]                     
    ldxdw r2, [r1+0x0]                      
    add64 r2, -1                                    r2 += -1   ///  r2 = r2.wrapping_add(-1 as i32 as i64 as u64)
    stxdw [r1+0x0], r2                      
    jne r2, 0, lbb_6919                             if r2 != (0 as i32 as i64 as u64) { pc += 7 }
    ldxdw r2, [r1+0x8]                      
    add64 r2, -1                                    r2 += -1   ///  r2 = r2.wrapping_add(-1 as i32 as i64 as u64)
    stxdw [r1+0x8], r2                      
    jne r2, 0, lbb_6919                             if r2 != (0 as i32 as i64 as u64) { pc += 3 }
    mov64 r2, 40                                    r2 = 40 as i32 as i64 as u64
    mov64 r3, 8                                     r3 = 8 as i32 as i64 as u64
    call function_11637                     
lbb_6919:
    ldxdw r1, [r6+0x8]                      
    ldxdw r2, [r1+0x0]                      
    add64 r2, -1                                    r2 += -1   ///  r2 = r2.wrapping_add(-1 as i32 as i64 as u64)
    stxdw [r1+0x0], r2                      
    jne r2, 0, lbb_6931                             if r2 != (0 as i32 as i64 as u64) { pc += 7 }
    ldxdw r2, [r1+0x8]                      
    add64 r2, -1                                    r2 += -1   ///  r2 = r2.wrapping_add(-1 as i32 as i64 as u64)
    stxdw [r1+0x8], r2                      
    jne r2, 0, lbb_6931                             if r2 != (0 as i32 as i64 as u64) { pc += 3 }
    mov64 r2, 32                                    r2 = 32 as i32 as i64 as u64
    mov64 r3, 8                                     r3 = 8 as i32 as i64 as u64
    call function_11637                     
lbb_6931:
    ldxdw r1, [r6+0x10]                     
    ldxdw r2, [r1+0x0]                      
    add64 r2, -1                                    r2 += -1   ///  r2 = r2.wrapping_add(-1 as i32 as i64 as u64)
    stxdw [r1+0x0], r2                      
    jne r2, 0, lbb_6830                             if r2 != (0 as i32 as i64 as u64) { pc += -106 }
    ldxdw r2, [r1+0x8]                      
    add64 r2, -1                                    r2 += -1   ///  r2 = r2.wrapping_add(-1 as i32 as i64 as u64)
    stxdw [r1+0x8], r2                      
    jne r2, 0, lbb_6830                             if r2 != (0 as i32 as i64 as u64) { pc += -110 }
    mov64 r2, 40                                    r2 = 40 as i32 as i64 as u64
    mov64 r3, 8                                     r3 = 8 as i32 as i64 as u64
    call function_11637                     
    ja lbb_6830                                     if true { pc += -114 }

function_6944:
    mov64 r7, r5                                    r7 = r5
    mov64 r9, r4                                    r9 = r4
    stxdw [r10-0xb0], r3                    
    stxdw [r10-0xb8], r2                    
    mov64 r6, r1                                    r6 = r1
    ldxdw r8, [r7-0x1000]                   
    ldxdw r1, [r8+0x18]                     
    mov64 r2, r9                                    r2 = r9
    mov64 r3, 32                                    r3 = 32 as i32 as i64 as u64
    call function_21867                     
    lsh64 r0, 32                                    r0 <<= 32   ///  r0 = r0.wrapping_shl(32)
    rsh64 r0, 32                                    r0 >>= 32   ///  r0 = r0.wrapping_shr(32)
    jne r0, 0, lbb_7044                             if r0 != (0 as i32 as i64 as u64) { pc += 87 }
    ldxdw r1, [r7-0xfc0]                    
    stxdw [r10-0xe0], r1                    
    ldxdw r1, [r7-0xfc8]                    
    stxdw [r10-0xd8], r1                    
    ldxdw r1, [r7-0xfd0]                    
    stxdw [r10-0xd0], r1                    
    ldxdw r1, [r7-0xfd8]                    
    stxdw [r10-0xc8], r1                    
    ldxdw r1, [r7-0xfe0]                    
    stxdw [r10-0xc0], r1                    
    ldxdw r1, [r7-0xfe8]                    
    stxdw [r10-0xf0], r1                    
    ldxdw r1, [r7-0xff0]                    
    stxdw [r10-0xf8], r1                    
    ldxdw r1, [r7-0xff8]                    
    ldxdw r1, [r1+0x0]                      
    stxdw [r10-0xe8], r1                    
    ldxdw r7, [r8+0x0]                      
    ldxdw r1, [r10-0xb0]                    
    ldxdw r2, [r1+0x20]                     
    ldxdw r1, [r10-0xb8]                    
    callx r2                                
    mov64 r8, r0                                    r8 = r0
    ldxdw r1, [r7+0x18]                     
    stxdw [r10-0x8], r1                     
    ldxdw r1, [r7+0x10]                     
    stxdw [r10-0x10], r1                    
    ldxdw r1, [r7+0x8]                      
    stxdw [r10-0x18], r1                    
    ldxdw r1, [r7+0x0]                      
    stxdw [r10-0x20], r1                    
    mov64 r7, r10                                   r7 = r10
    add64 r7, -64                                   r7 += -64   ///  r7 = r7.wrapping_add(-64 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -32                                   r2 += -32   ///  r2 = r2.wrapping_add(-32 as i32 as i64 as u64)
    mov64 r1, r7                                    r1 = r7
    call function_17977                     
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    stxdw [r10-0x48], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -32                                   r1 += -32   ///  r1 = r1.wrapping_add(-32 as i32 as i64 as u64)
    stxdw [r10-0x50], r1                    
    mov64 r1, 32                                    r1 = 32 as i32 as i64 as u64
    stxdw [r10-0x58], r1                    
    stxdw [r10-0x60], r7                    
    stxb [r10-0x20], r8                     
    mov64 r1, r10                                   r1 = r10
    add64 r1, -136                                  r1 += -136   ///  r1 = r1.wrapping_add(-136 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -96                                   r2 += -96   ///  r2 = r2.wrapping_add(-96 as i32 as i64 as u64)
    mov64 r3, 2                                     r3 = 2 as i32 as i64 as u64
    mov64 r4, r9                                    r4 = r9
    call function_18335                     
    ldxb r1, [r10-0x88]                     
    jeq r1, 0, lbb_7013                             if r1 == (0 as i32 as i64 as u64) { pc += 1 }
    ja lbb_7040                                     if true { pc += 27 }
lbb_7013:
    ldxdw r7, [r10-0xf8]                    
    ldxdw r9, [r10-0xf0]                    
    ldxdw r1, [r10-0xc0]                    
    ldxdw r1, [r10-0xc8]                    
    ldxdw r1, [r10-0xd0]                    
    ldxdw r1, [r10-0xd8]                    
    ldxdw r1, [r10-0xe0]                    
    ldxdw r1, [r10-0xb0]                    
    ldxdw r8, [r10-0xb8]                    
    ldxdw r1, [r10-0x86]                    
    stxdw [r10-0xa7], r1                    
    ldxdw r1, [r10-0x7e]                    
    stxdw [r10-0x9f], r1                    
    ldxdw r1, [r10-0x76]                    
    stxdw [r10-0x97], r1                    
    ldxdw r1, [r10-0x6f]                    
    stxdw [r10-0x90], r1                    
    ldxb r1, [r10-0x87]                     
    stxb [r10-0xa8], r1                     
    mov64 r2, r10                                   r2 = r10
    add64 r2, -168                                  r2 += -168   ///  r2 = r2.wrapping_add(-168 as i32 as i64 as u64)
    ldxdw r1, [r10-0xe8]                    
    mov64 r3, 32                                    r3 = 32 as i32 as i64 as u64
    call function_21867                     
    lsh64 r0, 32                                    r0 <<= 32   ///  r0 = r0.wrapping_shl(32)
    rsh64 r0, 32                                    r0 >>= 32   ///  r0 = r0.wrapping_shr(32)
    jeq r0, 0, lbb_7047                             if r0 == (0 as i32 as i64 as u64) { pc += 7 }
lbb_7040:
    lddw r1, 0x100000000                            r1 load str located at 4294967296
    stxdw [r6+0x0], r1                      
    ja lbb_7046                                     if true { pc += 2 }
lbb_7044:
    mov64 r1, 6                                     r1 = 6 as i32 as i64 as u64
    stxw [r6+0x0], r1                       
lbb_7046:
    exit                                    
lbb_7047:
    stxdw [r10-0xe8], r6                    
    ldxdw r7, [r7+0x0]                      
    ldxdw r6, [r10-0xb0]                    
    ldxdw r2, [r6+0x30]                     
    mov64 r1, r8                                    r1 = r8
    callx r2                                
    mov64 r1, r7                                    r1 = r7
    mov64 r2, r0                                    r2 = r0
    mov64 r3, 32                                    r3 = 32 as i32 as i64 as u64
    call function_21867                     
    lsh64 r0, 32                                    r0 <<= 32   ///  r0 = r0.wrapping_shl(32)
    rsh64 r0, 32                                    r0 >>= 32   ///  r0 = r0.wrapping_shr(32)
    jeq r0, 0, lbb_7061                             if r0 == (0 as i32 as i64 as u64) { pc += 1 }
    ja lbb_7073                                     if true { pc += 12 }
lbb_7061:
    stxdw [r10-0xf8], r7                    
    ldxdw r9, [r9+0x0]                      
    ldxdw r2, [r6+0x38]                     
    mov64 r1, r8                                    r1 = r8
    callx r2                                
    mov64 r1, r9                                    r1 = r9
    mov64 r2, r0                                    r2 = r0
    mov64 r3, 32                                    r3 = 32 as i32 as i64 as u64
    call function_21867                     
    lsh64 r0, 32                                    r0 <<= 32   ///  r0 = r0.wrapping_shl(32)
    rsh64 r0, 32                                    r0 >>= 32   ///  r0 = r0.wrapping_shr(32)
    jeq r0, 0, lbb_7078                             if r0 == (0 as i32 as i64 as u64) { pc += 5 }
lbb_7073:
    lddw r1, 0xa00000000                            r1 load str located at 42949672960
lbb_7075:
    ldxdw r2, [r10-0xe8]                    
    stxdw [r2+0x0], r1                      
    ja lbb_7046                                     if true { pc += -32 }
lbb_7078:
    mov64 r7, r6                                    r7 = r6
    ldxdw r1, [r10-0xc0]                    
    ldxdw r6, [r1+0x0]                      
    ldxdw r2, [r7+0x40]                     
    mov64 r1, r8                                    r1 = r8
    callx r2                                
    mov64 r1, r6                                    r1 = r6
    mov64 r2, r0                                    r2 = r0
    mov64 r3, 32                                    r3 = 32 as i32 as i64 as u64
    call function_21867                     
    lsh64 r0, 32                                    r0 <<= 32   ///  r0 = r0.wrapping_shl(32)
    rsh64 r0, 32                                    r0 >>= 32   ///  r0 = r0.wrapping_shr(32)
    jeq r0, 0, lbb_7094                             if r0 == (0 as i32 as i64 as u64) { pc += 3 }
    lddw r1, 0xb00000000                            r1 load str located at 47244640256
    ja lbb_7075                                     if true { pc += -19 }
lbb_7094:
    ldxdw r1, [r10-0xc8]                    
    ldxdw r6, [r1+0x0]                      
    ldxdw r2, [r7+0x28]                     
    mov64 r1, r8                                    r1 = r8
    callx r2                                
    mov64 r1, r6                                    r1 = r6
    mov64 r2, r0                                    r2 = r0
    mov64 r3, 32                                    r3 = 32 as i32 as i64 as u64
    call function_21867                     
    lsh64 r0, 32                                    r0 <<= 32   ///  r0 = r0.wrapping_shl(32)
    rsh64 r0, 32                                    r0 >>= 32   ///  r0 = r0.wrapping_shr(32)
    jeq r0, 0, lbb_7109                             if r0 == (0 as i32 as i64 as u64) { pc += 3 }
    lddw r1, 0x1800000000                           r1 load str located at 103079215104
    ja lbb_7075                                     if true { pc += -34 }
lbb_7109:
    ldxdw r1, [r10-0xd0]                    
    jeq r1, 0, lbb_7118                             if r1 == (0 as i32 as i64 as u64) { pc += 7 }
    ldxdw r2, [r1+0x0]                      
    ldxdw r1, [r10-0xf8]                    
    mov64 r3, 32                                    r3 = 32 as i32 as i64 as u64
    call function_21867                     
    lsh64 r0, 32                                    r0 <<= 32   ///  r0 = r0.wrapping_shl(32)
    rsh64 r0, 32                                    r0 >>= 32   ///  r0 = r0.wrapping_shr(32)
    jeq r0, 0, lbb_7145                             if r0 == (0 as i32 as i64 as u64) { pc += 27 }
lbb_7118:
    ldxdw r1, [r10-0xd8]                    
    jeq r1, 0, lbb_7127                             if r1 == (0 as i32 as i64 as u64) { pc += 7 }
    ldxdw r2, [r1+0x0]                      
    mov64 r1, r9                                    r1 = r9
    mov64 r3, 32                                    r3 = 32 as i32 as i64 as u64
    call function_21867                     
    lsh64 r0, 32                                    r0 <<= 32   ///  r0 = r0.wrapping_shl(32)
    rsh64 r0, 32                                    r0 >>= 32   ///  r0 = r0.wrapping_shr(32)
    jeq r0, 0, lbb_7145                             if r0 == (0 as i32 as i64 as u64) { pc += 18 }
lbb_7127:
    ldxdw r1, [r10-0xe0]                    
    jeq r1, 0, lbb_7141                             if r1 == (0 as i32 as i64 as u64) { pc += 12 }
    ldxdw r7, [r1+0x0]                      
    ldxdw r1, [r10-0xb0]                    
    ldxdw r2, [r1+0x58]                     
    mov64 r1, r8                                    r1 = r8
    callx r2                                
    mov64 r1, r7                                    r1 = r7
    mov64 r2, r0                                    r2 = r0
    mov64 r3, 32                                    r3 = 32 as i32 as i64 as u64
    call function_21867                     
    lsh64 r0, 32                                    r0 <<= 32   ///  r0 = r0.wrapping_shl(32)
    rsh64 r0, 32                                    r0 >>= 32   ///  r0 = r0.wrapping_shr(32)
    jne r0, 0, lbb_7148                             if r0 != (0 as i32 as i64 as u64) { pc += 7 }
lbb_7141:
    mov64 r1, 20                                    r1 = 20 as i32 as i64 as u64
    ldxdw r2, [r10-0xe8]                    
    stxw [r2+0x0], r1                       
    ja lbb_7046                                     if true { pc += -99 }
lbb_7145:
    lddw r1, 0x900000000                            r1 load str located at 38654705664
    ja lbb_7075                                     if true { pc += -73 }
lbb_7148:
    lddw r1, 0x1300000000                           r1 load str located at 81604378624
    ja lbb_7075                                     if true { pc += -76 }

function_7151:
    mov64 r6, r4                                    r6 = r4
    mov64 r8, r3                                    r8 = r3
    mov64 r9, r2                                    r9 = r2
    mov64 r7, r1                                    r7 = r1
    ldxdw r1, [r5-0xff8]                    
    jeq r1, 0, lbb_7246                             if r1 == (0 as i32 as i64 as u64) { pc += 89 }
    jeq r1, 1, lbb_7246                             if r1 == (1 as i32 as i64 as u64) { pc += 88 }
    jeq r1, 2, lbb_7246                             if r1 == (2 as i32 as i64 as u64) { pc += 87 }
    jeq r1, 3, lbb_7246                             if r1 == (3 as i32 as i64 as u64) { pc += 86 }
    jeq r1, 4, lbb_7246                             if r1 == (4 as i32 as i64 as u64) { pc += 85 }
    jeq r1, 5, lbb_7246                             if r1 == (5 as i32 as i64 as u64) { pc += 84 }
    jeq r1, 6, lbb_7246                             if r1 == (6 as i32 as i64 as u64) { pc += 83 }
    jeq r1, 7, lbb_7246                             if r1 == (7 as i32 as i64 as u64) { pc += 82 }
    ldxdw r1, [r5-0xff0]                    
    stxdw [r10-0x638], r1                   
    ldxdw r3, [r5-0x1000]                   
    ldxdw r1, [r3+0x150]                    
    ldxdw r2, [r1+0x18]                     
    stxdw [r10-0x5d8], r2                   
    ldxdw r2, [r1+0x10]                     
    stxdw [r10-0x5e0], r2                   
    ldxdw r2, [r1+0x8]                      
    stxdw [r10-0x5e8], r2                   
    ldxdw r1, [r1+0x0]                      
    stxdw [r10-0x5f0], r1                   
    stxdw [r10-0x628], r3                   
    ldxdw r2, [r3+0x10]                     
    add64 r2, 16                                    r2 += 16   ///  r2 = r2.wrapping_add(16 as i32 as i64 as u64)
    mov64 r1, r10                                   r1 = r10
    add64 r1, -1536                                 r1 += -1536   ///  r1 = r1.wrapping_add(-1536 as i32 as i64 as u64)
    lddw r3, 0x10002dc88 --> b"\x00\x00\x00\x00\x15\xc4\x02\x00\x18\x00\x00\x00\x00\x00\x00\x00\xe1\x00\…        r3 load str located at 4295154824
    call function_211                       
    ldxdw r2, [r10-0x600]                   
    ldxdw r1, [r2+0x0]                      
    ldxdw r2, [r2+0x8]                      
    ldxdw r3, [r10-0x5f8]                   
    stxdw [r10-0x630], r3                   
    call function_10528                     
    ldxdw r2, [r10-0x630]                   
    ldxdw r1, [r2+0x0]                      
    add64 r1, -1                                    r1 += -1   ///  r1 = r1.wrapping_add(-1 as i32 as i64 as u64)
    stxdw [r2+0x0], r1                      
    jne r0, 0, lbb_7259                             if r0 != (0 as i32 as i64 as u64) { pc += 64 }
    ldxdw r1, [r10-0x628]                   
    ldxdw r2, [r1+0x0]                      
    ldxdw r1, [r2+0x18]                     
    stxdw [r10-0x128], r1                   
    ldxdw r1, [r2+0x10]                     
    stxdw [r10-0x130], r1                   
    ldxdw r1, [r2+0x8]                      
    stxdw [r10-0x138], r1                   
    stxdw [r10-0x640], r2                   
    ldxdw r1, [r2+0x0]                      
    stxdw [r10-0x140], r1                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -752                                  r1 += -752   ///  r1 = r1.wrapping_add(-752 as i32 as i64 as u64)
    stxdw [r10-0x630], r1                   
    mov64 r2, r10                                   r2 = r10
    add64 r2, -320                                  r2 += -320   ///  r2 = r2.wrapping_add(-320 as i32 as i64 as u64)
    call function_17977                     
    ldxdw r1, [r10-0x630]                   
    stxdw [r10-0x3a0], r1                   
    mov64 r1, 32                                    r1 = 32 as i32 as i64 as u64
    stxdw [r10-0x398], r1                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -320                                  r1 += -320   ///  r1 = r1.wrapping_add(-320 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -928                                  r2 += -928   ///  r2 = r2.wrapping_add(-928 as i32 as i64 as u64)
    mov64 r3, 1                                     r3 = 1 as i32 as i64 as u64
    mov64 r4, r9                                    r4 = r9
    call function_18383                     
    ldxdw r1, [r10-0x128]                   
    stxdw [r10-0x5b8], r1                   
    ldxdw r1, [r10-0x130]                   
    stxdw [r10-0x5c0], r1                   
    ldxdw r1, [r10-0x138]                   
    stxdw [r10-0x5c8], r1                   
    ldxdw r1, [r10-0x140]                   
    stxdw [r10-0x5d0], r1                   
    ldxb r1, [r10-0x120]                    
    stxdw [r10-0x648], r1                   
    ldxdw r9, [r10-0x628]                   
    ldxdw r1, [r9+0x30]                     
    mov64 r2, r10                                   r2 = r10
    add64 r2, -1488                                 r2 += -1488   ///  r2 = r2.wrapping_add(-1488 as i32 as i64 as u64)
    stxdw [r10-0x630], r1                   
    mov64 r3, 32                                    r3 = 32 as i32 as i64 as u64
    call function_21867                     
    lsh64 r0, 32                                    r0 <<= 32   ///  r0 = r0.wrapping_shl(32)
    rsh64 r0, 32                                    r0 >>= 32   ///  r0 = r0.wrapping_shr(32)
    jeq r0, 0, lbb_7261                             if r0 == (0 as i32 as i64 as u64) { pc += 18 }
    lddw r1, 0x100000000                            r1 load str located at 4294967296
    ja lbb_7247                                     if true { pc += 1 }
lbb_7246:
    mov64 r1, 10                                    r1 = 10 as i32 as i64 as u64
lbb_7247:
    stxdw [r7+0x0], r1                      
lbb_7248:
    ldxdw r7, [r6+0x8]                      
    ldxdw r6, [r6+0x10]                     
    ldxdw r2, [r6+0x0]                      
    mov64 r1, r7                                    r1 = r7
    callx r2                                
    ldxdw r2, [r6+0x8]                      
    jeq r2, 0, lbb_7258                             if r2 == (0 as i32 as i64 as u64) { pc += 3 }
    ldxdw r3, [r6+0x10]                     
    mov64 r1, r7                                    r1 = r7
    call function_11637                     
lbb_7258:
    exit                                    
lbb_7259:
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    ja lbb_7247                                     if true { pc += -14 }
lbb_7261:
    ldxdw r1, [r10-0x630]                   
    ldxdw r1, [r10-0x648]                   
    ldxdw r1, [r10-0x640]                   
    mov64 r2, r9                                    r2 = r9
    add64 r2, 96                                    r2 += 96   ///  r2 = r2.wrapping_add(96 as i32 as i64 as u64)
    mov64 r1, r10                                   r1 = r10
    add64 r1, -320                                  r1 += -320   ///  r1 = r1.wrapping_add(-320 as i32 as i64 as u64)
    mov64 r3, r10                                   r3 = r10
    add64 r3, -1520                                 r3 += -1520   ///  r3 = r3.wrapping_add(-1520 as i32 as i64 as u64)
    call function_5980                      
    ldxb r1, [r10-0x140]                    
    jeq r1, 0, lbb_7274                             if r1 == (0 as i32 as i64 as u64) { pc += 1 }
    ja lbb_7366                                     if true { pc += 92 }
lbb_7274:
    add64 r9, 144                                   r9 += 144   ///  r9 = r9.wrapping_add(144 as i32 as i64 as u64)
    mov64 r1, r10                                   r1 = r10
    add64 r1, -746                                  r1 += -746   ///  r1 = r1.wrapping_add(-746 as i32 as i64 as u64)
    stxdw [r10-0x650], r1                   
    mov64 r2, r10                                   r2 = r10
    add64 r2, -312                                  r2 += -312   ///  r2 = r2.wrapping_add(-312 as i32 as i64 as u64)
    mov64 r3, 176                                   r3 = 176 as i32 as i64 as u64
    call function_21797                     
    mov64 r1, r10                                   r1 = r10
    add64 r1, -1456                                 r1 += -1456   ///  r1 = r1.wrapping_add(-1456 as i32 as i64 as u64)
    ldxdw r2, [r10-0x650]                   
    mov64 r3, 176                                   r3 = 176 as i32 as i64 as u64
    call function_21797                     
    mov64 r1, r10                                   r1 = r10
    add64 r1, -320                                  r1 += -320   ///  r1 = r1.wrapping_add(-320 as i32 as i64 as u64)
    mov64 r3, r10                                   r3 = r10
    add64 r3, -1520                                 r3 += -1520   ///  r3 = r3.wrapping_add(-1520 as i32 as i64 as u64)
    mov64 r2, r9                                    r2 = r9
    call function_5980                      
    ldxb r1, [r10-0x140]                    
    jeq r1, 0, lbb_7296                             if r1 == (0 as i32 as i64 as u64) { pc += 1 }
    ja lbb_7366                                     if true { pc += 70 }
lbb_7296:
    ldxdw r9, [r10-0x628]                   
    add64 r9, 240                                   r9 += 240   ///  r9 = r9.wrapping_add(240 as i32 as i64 as u64)
    mov64 r1, r10                                   r1 = r10
    add64 r1, -746                                  r1 += -746   ///  r1 = r1.wrapping_add(-746 as i32 as i64 as u64)
    stxdw [r10-0x650], r1                   
    mov64 r2, r10                                   r2 = r10
    add64 r2, -312                                  r2 += -312   ///  r2 = r2.wrapping_add(-312 as i32 as i64 as u64)
    mov64 r3, 176                                   r3 = 176 as i32 as i64 as u64
    call function_21797                     
    mov64 r1, r10                                   r1 = r10
    add64 r1, -1280                                 r1 += -1280   ///  r1 = r1.wrapping_add(-1280 as i32 as i64 as u64)
    ldxdw r2, [r10-0x650]                   
    mov64 r3, 176                                   r3 = 176 as i32 as i64 as u64
    call function_21797                     
    mov64 r1, r10                                   r1 = r10
    add64 r1, -320                                  r1 += -320   ///  r1 = r1.wrapping_add(-320 as i32 as i64 as u64)
    mov64 r3, r10                                   r3 = r10
    add64 r3, -1520                                 r3 += -1520   ///  r3 = r3.wrapping_add(-1520 as i32 as i64 as u64)
    mov64 r2, r9                                    r2 = r9
    call function_5980                      
    ldxb r1, [r10-0x140]                    
    jeq r1, 0, lbb_7319                             if r1 == (0 as i32 as i64 as u64) { pc += 1 }
    ja lbb_7366                                     if true { pc += 47 }
lbb_7319:
    ldxdw r9, [r10-0x628]                   
    add64 r9, 288                                   r9 += 288   ///  r9 = r9.wrapping_add(288 as i32 as i64 as u64)
    mov64 r1, r10                                   r1 = r10
    add64 r1, -746                                  r1 += -746   ///  r1 = r1.wrapping_add(-746 as i32 as i64 as u64)
    stxdw [r10-0x650], r1                   
    mov64 r2, r10                                   r2 = r10
    add64 r2, -312                                  r2 += -312   ///  r2 = r2.wrapping_add(-312 as i32 as i64 as u64)
    mov64 r3, 176                                   r3 = 176 as i32 as i64 as u64
    call function_21797                     
    mov64 r1, r10                                   r1 = r10
    add64 r1, -1104                                 r1 += -1104   ///  r1 = r1.wrapping_add(-1104 as i32 as i64 as u64)
    ldxdw r2, [r10-0x650]                   
    mov64 r3, 176                                   r3 = 176 as i32 as i64 as u64
    call function_21797                     
    mov64 r1, r10                                   r1 = r10
    add64 r1, -320                                  r1 += -320   ///  r1 = r1.wrapping_add(-320 as i32 as i64 as u64)
    mov64 r3, r10                                   r3 = r10
    add64 r3, -1520                                 r3 += -1520   ///  r3 = r3.wrapping_add(-1520 as i32 as i64 as u64)
    stxdw [r10-0x650], r9                   
    mov64 r2, r9                                    r2 = r9
    call function_5980                      
    ldxb r1, [r10-0x140]                    
    jeq r1, 0, lbb_7343                             if r1 == (0 as i32 as i64 as u64) { pc += 1 }
    ja lbb_7366                                     if true { pc += 23 }
lbb_7343:
    ldxdw r9, [r10-0x628]                   
    add64 r9, 192                                   r9 += 192   ///  r9 = r9.wrapping_add(192 as i32 as i64 as u64)
    mov64 r1, r10                                   r1 = r10
    add64 r1, -746                                  r1 += -746   ///  r1 = r1.wrapping_add(-746 as i32 as i64 as u64)
    stxdw [r10-0x658], r1                   
    mov64 r2, r10                                   r2 = r10
    add64 r2, -312                                  r2 += -312   ///  r2 = r2.wrapping_add(-312 as i32 as i64 as u64)
    mov64 r3, 176                                   r3 = 176 as i32 as i64 as u64
    call function_21797                     
    mov64 r1, r10                                   r1 = r10
    add64 r1, -928                                  r1 += -928   ///  r1 = r1.wrapping_add(-928 as i32 as i64 as u64)
    ldxdw r2, [r10-0x658]                   
    mov64 r3, 176                                   r3 = 176 as i32 as i64 as u64
    call function_21797                     
    mov64 r1, r10                                   r1 = r10
    add64 r1, -320                                  r1 += -320   ///  r1 = r1.wrapping_add(-320 as i32 as i64 as u64)
    mov64 r3, r10                                   r3 = r10
    add64 r3, -1520                                 r3 += -1520   ///  r3 = r3.wrapping_add(-1520 as i32 as i64 as u64)
    stxdw [r10-0x658], r9                   
    mov64 r2, r9                                    r2 = r9
    call function_6078                      
    ldxb r1, [r10-0x140]                    
    jeq r1, 0, lbb_7371                             if r1 == (0 as i32 as i64 as u64) { pc += 5 }
lbb_7366:
    ldxb r1, [r10-0x13f]                    
    stxw [r7+0x4], r1                       
lbb_7368:
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    stxw [r7+0x0], r1                       
    ja lbb_7248                                     if true { pc += -123 }
lbb_7371:
    mov64 r9, r10                                   r9 = r10
    add64 r9, -746                                  r9 += -746   ///  r9 = r9.wrapping_add(-746 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -312                                  r2 += -312   ///  r2 = r2.wrapping_add(-312 as i32 as i64 as u64)
    mov64 r1, r9                                    r1 = r9
    mov64 r3, 88                                    r3 = 88 as i32 as i64 as u64
    call function_21797                     
    mov64 r1, r10                                   r1 = r10
    add64 r1, -568                                  r1 += -568   ///  r1 = r1.wrapping_add(-568 as i32 as i64 as u64)
    mov64 r2, r9                                    r2 = r9
    mov64 r3, 88                                    r3 = 88 as i32 as i64 as u64
    call function_21797                     
    mov64 r2, r10                                   r2 = r10
    add64 r2, -1424                                 r2 += -1424   ///  r2 = r2.wrapping_add(-1424 as i32 as i64 as u64)
    ldxdw r1, [r10-0x630]                   
    mov64 r3, 32                                    r3 = 32 as i32 as i64 as u64
    call function_21867                     
    lsh64 r0, 32                                    r0 <<= 32   ///  r0 = r0.wrapping_shl(32)
    rsh64 r0, 32                                    r0 >>= 32   ///  r0 = r0.wrapping_shr(32)
    jeq r0, 0, lbb_7392                             if r0 == (0 as i32 as i64 as u64) { pc += 1 }
    ja lbb_7429                                     if true { pc += 37 }
lbb_7392:
    mov64 r2, r10                                   r2 = r10
    add64 r2, -1248                                 r2 += -1248   ///  r2 = r2.wrapping_add(-1248 as i32 as i64 as u64)
    ldxdw r1, [r10-0x630]                   
    mov64 r3, 32                                    r3 = 32 as i32 as i64 as u64
    call function_21867                     
    lsh64 r0, 32                                    r0 <<= 32   ///  r0 = r0.wrapping_shl(32)
    rsh64 r0, 32                                    r0 >>= 32   ///  r0 = r0.wrapping_shr(32)
    jeq r0, 0, lbb_7401                             if r0 == (0 as i32 as i64 as u64) { pc += 1 }
    ja lbb_7429                                     if true { pc += 28 }
lbb_7401:
    mov64 r2, r10                                   r2 = r10
    add64 r2, -896                                  r2 += -896   ///  r2 = r2.wrapping_add(-896 as i32 as i64 as u64)
    ldxdw r1, [r10-0x630]                   
    mov64 r3, 32                                    r3 = 32 as i32 as i64 as u64
    call function_21867                     
    lsh64 r0, 32                                    r0 <<= 32   ///  r0 = r0.wrapping_shl(32)
    rsh64 r0, 32                                    r0 >>= 32   ///  r0 = r0.wrapping_shr(32)
    jeq r0, 0, lbb_7432                             if r0 == (0 as i32 as i64 as u64) { pc += 23 }
    mov64 r2, r10                                   r2 = r10
    add64 r2, -1072                                 r2 += -1072   ///  r2 = r2.wrapping_add(-1072 as i32 as i64 as u64)
    ldxdw r1, [r10-0x630]                   
    mov64 r9, r2                                    r9 = r2
    mov64 r3, 32                                    r3 = 32 as i32 as i64 as u64
    call function_21867                     
    lsh64 r0, 32                                    r0 <<= 32   ///  r0 = r0.wrapping_shl(32)
    rsh64 r0, 32                                    r0 >>= 32   ///  r0 = r0.wrapping_shr(32)
    jeq r0, 0, lbb_7432                             if r0 == (0 as i32 as i64 as u64) { pc += 14 }
    ldxdw r2, [r10-0x630]                   
    ldxdw r1, [r2+0x18]                     
    stxdw [r10-0x124], r1                   
    ldxdw r1, [r2+0x10]                     
    stxdw [r10-0x12c], r1                   
    ldxdw r1, [r2+0x8]                      
    stxdw [r10-0x134], r1                   
    ldxdw r1, [r2+0x0]                      
    stxdw [r10-0x13c], r1                   
    ldxw r1, [r10-0x238]                    
    jeq r1, 1, lbb_7435                             if r1 == (1 as i32 as i64 as u64) { pc += 6 }
lbb_7429:
    lddw r1, 0x200000000                            r1 load str located at 8589934592
    ja lbb_7247                                     if true { pc += -185 }
lbb_7432:
    lddw r1, 0x300000000                            r1 load str located at 12884901888
    ja lbb_7247                                     if true { pc += -188 }
lbb_7435:
    mov64 r1, r10                                   r1 = r10
    add64 r1, -316                                  r1 += -316   ///  r1 = r1.wrapping_add(-316 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -564                                  r2 += -564   ///  r2 = r2.wrapping_add(-564 as i32 as i64 as u64)
    mov64 r3, 32                                    r3 = 32 as i32 as i64 as u64
    call function_21867                     
    lsh64 r0, 32                                    r0 <<= 32   ///  r0 = r0.wrapping_shl(32)
    rsh64 r0, 32                                    r0 >>= 32   ///  r0 = r0.wrapping_shr(32)
    jeq r0, 0, lbb_7445                             if r0 == (0 as i32 as i64 as u64) { pc += 1 }
    ja lbb_7429                                     if true { pc += -16 }
lbb_7445:
    mov64 r1, r10                                   r1 = r10
    add64 r1, -1456                                 r1 += -1456   ///  r1 = r1.wrapping_add(-1456 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -1280                                 r2 += -1280   ///  r2 = r2.wrapping_add(-1280 as i32 as i64 as u64)
    mov64 r3, 32                                    r3 = 32 as i32 as i64 as u64
    call function_21867                     
    lsh64 r0, 32                                    r0 <<= 32   ///  r0 = r0.wrapping_shl(32)
    rsh64 r0, 32                                    r0 >>= 32   ///  r0 = r0.wrapping_shr(32)
    jeq r0, 0, lbb_7472                             if r0 == (0 as i32 as i64 as u64) { pc += 18 }
    ldxdw r1, [r6+0x8]                      
    ldxdw r2, [r6+0x10]                     
    stxdw [r10-0x660], r2                   
    ldxdw r4, [r2+0x68]                     
    ldxdw r3, [r10-0x4c0]                   
    ldxdw r2, [r10-0x570]                   
    stxdw [r10-0x630], r1                   
    callx r4                                
    and64 r0, 255                                   r0 &= 255   ///  r0 = r0.and(255)
    jeq r0, 28, lbb_7465                            if r0 == (28 as i32 as i64 as u64) { pc += 1 }
    ja lbb_7486                                     if true { pc += 21 }
lbb_7465:
    ldxw r1, [r10-0x568]                    
    jne r1, 0, lbb_7469                             if r1 != (0 as i32 as i64 as u64) { pc += 2 }
    ldxw r1, [r10-0x4b8]                    
    jeq r1, 0, lbb_7475                             if r1 == (0 as i32 as i64 as u64) { pc += 6 }
lbb_7469:
    lddw r1, 0x800000000                            r1 load str located at 34359738368
    ja lbb_7247                                     if true { pc += -225 }
lbb_7472:
    lddw r1, 0xf00000000                            r1 load str located at 64424509440
    ja lbb_7247                                     if true { pc += -228 }
lbb_7475:
    ldxw r1, [r10-0x528]                    
    jeq r1, 0, lbb_7478                             if r1 == (0 as i32 as i64 as u64) { pc += 1 }
    ja lbb_7480                                     if true { pc += 2 }
lbb_7478:
    ldxw r1, [r10-0x478]                    
    jeq r1, 0, lbb_7483                             if r1 == (0 as i32 as i64 as u64) { pc += 3 }
lbb_7480:
    lddw r1, 0x1100000000                           r1 load str located at 73014444032
    ja lbb_7247                                     if true { pc += -236 }
lbb_7483:
    mov64 r0, 7                                     r0 = 7 as i32 as i64 as u64
    ldxdw r1, [r10-0x210]                   
    jeq r1, 0, lbb_7488                             if r1 == (0 as i32 as i64 as u64) { pc += 2 }
lbb_7486:
    stxw [r7+0x4], r0                       
    ja lbb_7368                                     if true { pc += -120 }
lbb_7488:
    ldxw r1, [r10-0x204]                    
    jne r1, 0, lbb_7503                             if r1 != (0 as i32 as i64 as u64) { pc += 13 }
    ldxdw r1, [r10-0x658]                   
    ldxdw r1, [r1+0x0]                      
    mov64 r2, r10                                   r2 = r10
    add64 r2, -1104                                 r2 += -1104   ///  r2 = r2.wrapping_add(-1104 as i32 as i64 as u64)
    stxdw [r10-0x668], r1                   
    mov64 r3, 32                                    r3 = 32 as i32 as i64 as u64
    call function_21867                     
    lsh64 r0, 32                                    r0 <<= 32   ///  r0 = r0.wrapping_shl(32)
    rsh64 r0, 32                                    r0 >>= 32   ///  r0 = r0.wrapping_shr(32)
    jeq r0, 0, lbb_7506                             if r0 == (0 as i32 as i64 as u64) { pc += 6 }
    lddw r1, 0xb00000000                            r1 load str located at 47244640256
    ja lbb_7247                                     if true { pc += -256 }
lbb_7503:
    lddw r1, 0x1200000000                           r1 load str located at 77309411328
    ja lbb_7247                                     if true { pc += -259 }
lbb_7506:
    ldxdw r1, [r10-0x638]                   
    ldxdw r2, [r1+0x0]                      
    jeq r2, 0, lbb_7555                             if r2 == (0 as i32 as i64 as u64) { pc += 46 }
    ldxdw r1, [r10-0x638]                   
    ldxdw r3, [r1+0x8]                      
    mov64 r1, r10                                   r1 = r10
    add64 r1, -320                                  r1 += -320   ///  r1 = r1.wrapping_add(-320 as i32 as i64 as u64)
    call function_17895                     
    ldxb r1, [r10-0x140]                    
    jeq r1, 0, lbb_7517                             if r1 == (0 as i32 as i64 as u64) { pc += 1 }
    ja lbb_7429                                     if true { pc += -88 }
lbb_7517:
    ldxdw r1, [r10-0x13e]                   
    stxdw [r10-0x2ef], r1                   
    ldxdw r1, [r10-0x136]                   
    stxdw [r10-0x2e7], r1                   
    ldxdw r1, [r10-0x12e]                   
    stxdw [r10-0x2df], r1                   
    ldxdw r1, [r10-0x127]                   
    stxdw [r10-0x2d8], r1                   
    ldxb r1, [r10-0x13f]                    
    stxb [r10-0x2f0], r1                    
    mov64 r2, r10                                   r2 = r10
    add64 r2, -752                                  r2 += -752   ///  r2 = r2.wrapping_add(-752 as i32 as i64 as u64)
    mov64 r1, r9                                    r1 = r9
    mov64 r3, 32                                    r3 = 32 as i32 as i64 as u64
    call function_21867                     
    lsh64 r0, 32                                    r0 <<= 32   ///  r0 = r0.wrapping_shl(32)
    rsh64 r0, 32                                    r0 >>= 32   ///  r0 = r0.wrapping_shr(32)
    jeq r0, 0, lbb_7536                             if r0 == (0 as i32 as i64 as u64) { pc += 1 }
    ja lbb_7429                                     if true { pc += -107 }
lbb_7536:
    ldxw r3, [r6+0x0]                       
    ldxdw r2, [r10-0x638]                   
    ldxdw r1, [r2+0x10]                     
    ldxdw r2, [r2+0x18]                     
    lsh64 r2, 2                                     r2 <<= 2   ///  r2 = r2.wrapping_shl(2)
lbb_7541:
    jeq r2, 0, lbb_7753                             if r2 == (0 as i32 as i64 as u64) { pc += 211 }
    add64 r2, -4                                    r2 += -4   ///  r2 = r2.wrapping_add(-4 as i32 as i64 as u64)
    ldxw r4, [r1+0x0]                       
    add64 r1, 4                                     r1 += 4   ///  r1 = r1.wrapping_add(4 as i32 as i64 as u64)
    jeq r3, r4, lbb_7547                            if r3 == r4 { pc += 1 }
    ja lbb_7541                                     if true { pc += -6 }
lbb_7547:
    mov64 r1, r10                                   r1 = r10
    add64 r1, -320                                  r1 += -320   ///  r1 = r1.wrapping_add(-320 as i32 as i64 as u64)
    ldxdw r2, [r10-0x638]                   
    mov64 r3, r8                                    r3 = r8
    call function_267                       
    ldxw r1, [r10-0x140]                    
    jeq r1, 20, lbb_7555                            if r1 == (20 as i32 as i64 as u64) { pc += 1 }
    ja lbb_7765                                     if true { pc += 210 }
lbb_7555:
    mov64 r1, r8                                    r1 = r8
    call function_3265                      
    and64 r0, 255                                   r0 &= 255   ///  r0 = r0.and(255)
    jeq r0, 28, lbb_7560                            if r0 == (28 as i32 as i64 as u64) { pc += 1 }
    ja lbb_7486                                     if true { pc += -74 }
lbb_7560:
    ldxdw r1, [r10-0x660]                   
    ldxdw r2, [r1+0x60]                     
    ldxdw r1, [r10-0x630]                   
    callx r2                                
    and64 r0, 255                                   r0 &= 255   ///  r0 = r0.and(255)
    jne r0, 28, lbb_7486                            if r0 != (28 as i32 as i64 as u64) { pc += -80 }
    ldxdw r9, [r10-0x628]                   
    mov64 r2, r9                                    r2 = r9
    add64 r2, 48                                    r2 += 48   ///  r2 = r2.wrapping_add(48 as i32 as i64 as u64)
    stxdw [r10-0x638], r2                   
    add64 r9, 336                                   r9 += 336   ///  r9 = r9.wrapping_add(336 as i32 as i64 as u64)
    ldxdw r1, [r10-0x660]                   
    ldxdw r3, [r1+0x40]                     
    mov64 r1, r10                                   r1 = r10
    add64 r1, -1552                                 r1 += -1552   ///  r1 = r1.wrapping_add(-1552 as i32 as i64 as u64)
    ldxdw r2, [r10-0x630]                   
    callx r3                                
    ldxdw r1, [r10-0x608]                   
    stxdw [r10-0x630], r1                   
    ldxdw r1, [r10-0x610]                   
    stxdw [r10-0x660], r1                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -416                                  r1 += -416   ///  r1 = r1.wrapping_add(-416 as i32 as i64 as u64)
    mov64 r2, r9                                    r2 = r9
    call function_231                       
    mov64 r1, r10                                   r1 = r10
    add64 r1, -368                                  r1 += -368   ///  r1 = r1.wrapping_add(-368 as i32 as i64 as u64)
    ldxdw r2, [r10-0x658]                   
    call function_231                       
    mov64 r1, r10                                   r1 = r10
    add64 r1, -752                                  r1 += -752   ///  r1 = r1.wrapping_add(-752 as i32 as i64 as u64)
    ldxdw r2, [r10-0x650]                   
    call function_231                       
    mov64 r1, r10                                   r1 = r10
    add64 r1, -320                                  r1 += -320   ///  r1 = r1.wrapping_add(-320 as i32 as i64 as u64)
    ldxdw r2, [r10-0x638]                   
    call function_231                       
    ldxdw r1, [r10-0x630]                   
    jne r1, 0, lbb_7737                             if r1 != (0 as i32 as i64 as u64) { pc += 138 }
    ldxdw r1, [r10-0x648]                   
    stxdw [r10-0xff0], r1                   
    ldxdw r1, [r10-0x660]                   
    stxdw [r10-0xfe8], r1                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -320                                  r1 += -320   ///  r1 = r1.wrapping_add(-320 as i32 as i64 as u64)
    stxdw [r10-0xff8], r1                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -752                                  r1 += -752   ///  r1 = r1.wrapping_add(-752 as i32 as i64 as u64)
    stxdw [r10-0x1000], r1                  
    mov64 r1, r10                                   r1 = r10
    add64 r1, -448                                  r1 += -448   ///  r1 = r1.wrapping_add(-448 as i32 as i64 as u64)
    mov64 r3, r10                                   r3 = r10
    add64 r3, -416                                  r3 += -416   ///  r3 = r3.wrapping_add(-416 as i32 as i64 as u64)
    mov64 r4, r10                                   r4 = r10
    add64 r4, -368                                  r4 += -368   ///  r4 = r4.wrapping_add(-368 as i32 as i64 as u64)
    mov64 r5, r10                                   r5 = r10
    ldxdw r2, [r10-0x640]                   
    call function_6464                      
    ldxw r1, [r10-0x1c0]                    
    jeq r1, 20, lbb_7621                            if r1 == (20 as i32 as i64 as u64) { pc += 1 }
    ja lbb_7756                                     if true { pc += 135 }
lbb_7621:
    ldxdw r1, [r10-0x628]                   
    ldxdw r2, [r1+0xf0]                     
    stxdw [r10-0x630], r2                   
    ldxdw r2, [r1+0x90]                     
    stxdw [r10-0x638], r2                   
    ldxdw r9, [r1+0x60]                     
    mov64 r1, r10                                   r1 = r10
    add64 r1, -314                                  r1 += -314   ///  r1 = r1.wrapping_add(-314 as i32 as i64 as u64)
    mov64 r2, r8                                    r2 = r8
    mov64 r3, 64                                    r3 = 64 as i32 as i64 as u64
    call function_21797                     
    mov64 r8, r10                                   r8 = r10
    add64 r8, -752                                  r8 += -752   ///  r8 = r8.wrapping_add(-752 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -320                                  r2 += -320   ///  r2 = r2.wrapping_add(-320 as i32 as i64 as u64)
    mov64 r1, r8                                    r1 = r8
    mov64 r3, 70                                    r3 = 70 as i32 as i64 as u64
    call function_21797                     
    ldxdw r1, [r10-0x5d8]                   
    stxdw [r10-0x126], r1                   
    ldxdw r1, [r10-0x5e0]                   
    stxdw [r10-0x12e], r1                   
    ldxdw r1, [r10-0x5e8]                   
    stxdw [r10-0x136], r1                   
    ldxdw r1, [r10-0x5f0]                   
    stxdw [r10-0x13e], r1                   
    ldxdw r1, [r10-0x648]                   
    stxb [r10-0x13f], r1                    
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    stxb [r10-0x140], r1                    
    ldxdw r1, [r9+0x18]                     
    stxdw [r10-0x106], r1                   
    ldxdw r1, [r9+0x10]                     
    stxdw [r10-0x10e], r1                   
    ldxdw r1, [r9+0x8]                      
    stxdw [r10-0x116], r1                   
    ldxdw r1, [r9+0x0]                      
    stxdw [r10-0x11e], r1                   
    ldxdw r2, [r10-0x638]                   
    ldxdw r1, [r2+0x18]                     
    stxdw [r10-0xe6], r1                    
    ldxdw r1, [r2+0x10]                     
    stxdw [r10-0xee], r1                    
    ldxdw r1, [r2+0x8]                      
    stxdw [r10-0xf6], r1                    
    ldxdw r1, [r2+0x0]                      
    stxdw [r10-0xfe], r1                    
    ldxdw r2, [r10-0x668]                   
    ldxdw r1, [r2+0x18]                     
    stxdw [r10-0xc6], r1                    
    ldxdw r1, [r2+0x10]                     
    stxdw [r10-0xce], r1                    
    ldxdw r1, [r2+0x8]                      
    stxdw [r10-0xd6], r1                    
    ldxdw r1, [r2+0x0]                      
    stxdw [r10-0xde], r1                    
    ldxdw r1, [r10-0x598]                   
    stxdw [r10-0xa6], r1                    
    ldxdw r1, [r10-0x5a0]                   
    stxdw [r10-0xae], r1                    
    ldxdw r1, [r10-0x5a8]                   
    stxdw [r10-0xb6], r1                    
    ldxdw r1, [r10-0x5b0]                   
    stxdw [r10-0xbe], r1                    
    ldxdw r1, [r10-0x4e8]                   
    stxdw [r10-0x86], r1                    
    ldxdw r1, [r10-0x4f0]                   
    stxdw [r10-0x8e], r1                    
    ldxdw r1, [r10-0x4f8]                   
    stxdw [r10-0x96], r1                    
    ldxdw r1, [r10-0x500]                   
    stxdw [r10-0x9e], r1                    
    ldxdw r2, [r10-0x630]                   
    ldxdw r1, [r2+0x18]                     
    stxdw [r10-0x66], r1                    
    ldxdw r1, [r2+0x10]                     
    stxdw [r10-0x6e], r1                    
    ldxdw r1, [r2+0x8]                      
    stxdw [r10-0x76], r1                    
    ldxdw r1, [r2+0x0]                      
    stxdw [r10-0x7e], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -94                                   r1 += -94   ///  r1 = r1.wrapping_add(-94 as i32 as i64 as u64)
    mov64 r2, r8                                    r2 = r8
    mov64 r3, 70                                    r3 = 70 as i32 as i64 as u64
    call function_21797                     
    ldxdw r1, [r6+0x0]                      
    stxdw [r10-0x18], r1                    
    ldxdw r1, [r6+0x8]                      
    stxdw [r10-0x10], r1                    
    ldxdw r1, [r6+0x10]                     
    stxdw [r10-0x8], r1                     
    ldxdw r1, [r10-0x628]                   
    ldxdw r2, [r1+0x10]                     
    add64 r2, 16                                    r2 += 16   ///  r2 = r2.wrapping_add(16 as i32 as i64 as u64)
    mov64 r1, r10                                   r1 = r10
    add64 r1, -1568                                 r1 += -1568   ///  r1 = r1.wrapping_add(-1568 as i32 as i64 as u64)
    call function_192                       
    ldxdw r1, [r10-0x620]                   
    ldxdw r3, [r1+0x0]                      
    ldxdw r4, [r1+0x8]                      
    ldxdw r6, [r10-0x618]                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -368                                  r1 += -368   ///  r1 = r1.wrapping_add(-368 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -320                                  r2 += -320   ///  r2 = r2.wrapping_add(-320 as i32 as i64 as u64)
    call function_10337                     
    ldxw r1, [r10-0x170]                    
    jeq r1, 20, lbb_7731                            if r1 == (20 as i32 as i64 as u64) { pc += 1 }
    ja lbb_7779                                     if true { pc += 48 }
lbb_7731:
    ldxdw r1, [r6+0x0]                      
    add64 r1, 1                                     r1 += 1   ///  r1 = r1.wrapping_add(1 as i32 as i64 as u64)
    stxdw [r6+0x0], r1                      
    mov64 r1, 20                                    r1 = 20 as i32 as i64 as u64
    stxw [r7+0x0], r1                       
    ja lbb_7258                                     if true { pc += -479 }
lbb_7737:
    lddw r1, 0x1600000000                           r1 load str located at 94489280512
    stxdw [r7+0x0], r1                      
    mov64 r1, r10                                   r1 = r10
    add64 r1, -320                                  r1 += -320   ///  r1 = r1.wrapping_add(-320 as i32 as i64 as u64)
    call function_56                        
    mov64 r1, r10                                   r1 = r10
    add64 r1, -752                                  r1 += -752   ///  r1 = r1.wrapping_add(-752 as i32 as i64 as u64)
    call function_56                        
    mov64 r1, r10                                   r1 = r10
    add64 r1, -368                                  r1 += -368   ///  r1 = r1.wrapping_add(-368 as i32 as i64 as u64)
    call function_56                        
    mov64 r1, r10                                   r1 = r10
    add64 r1, -416                                  r1 += -416   ///  r1 = r1.wrapping_add(-416 as i32 as i64 as u64)
    call function_56                        
    ja lbb_7248                                     if true { pc += -505 }
lbb_7753:
    lddw r1, 0x1900000000                           r1 load str located at 107374182400
    ja lbb_7247                                     if true { pc += -509 }
lbb_7756:
    ldxw r2, [r10-0x1a4]                    
    stxw [r10-0x1c8], r2                    
    ldxdw r3, [r10-0x1ac]                   
    stxdw [r10-0x1d0], r3                   
    ldxdw r4, [r10-0x1b4]                   
    stxdw [r10-0x1d8], r4                   
    ldxdw r5, [r10-0x1bc]                   
    stxdw [r10-0x1e0], r5                   
    ja lbb_7773                                     if true { pc += 8 }
lbb_7765:
    ldxw r2, [r10-0x124]                    
    stxw [r10-0x158], r2                    
    ldxdw r3, [r10-0x12c]                   
    stxdw [r10-0x160], r3                   
    ldxdw r4, [r10-0x134]                   
    stxdw [r10-0x168], r4                   
    ldxdw r5, [r10-0x13c]                   
    stxdw [r10-0x170], r5                   
lbb_7773:
    stxw [r7+0x1c], r2                      
    stxdw [r7+0x14], r3                     
    stxdw [r7+0xc], r4                      
    stxdw [r7+0x4], r5                      
    stxw [r7+0x0], r1                       
    ja lbb_7248                                     if true { pc += -531 }
lbb_7779:
    ldxw r2, [r10-0x154]                    
    stxw [r10-0x188], r2                    
    ldxdw r3, [r10-0x15c]                   
    stxdw [r10-0x190], r3                   
    ldxdw r4, [r10-0x164]                   
    stxdw [r10-0x198], r4                   
    ldxdw r5, [r10-0x16c]                   
    stxdw [r10-0x1a0], r5                   
    stxw [r7+0x1c], r2                      
    stxdw [r7+0x14], r3                     
    stxdw [r7+0xc], r4                      
    stxdw [r7+0x4], r5                      
    stxw [r7+0x0], r1                       
    ldxdw r1, [r6+0x0]                      
    add64 r1, 1                                     r1 += 1   ///  r1 = r1.wrapping_add(1 as i32 as i64 as u64)
    stxdw [r6+0x0], r1                      
    ja lbb_7258                                     if true { pc += -538 }

function_7796:
    mov64 r8, r4                                    r8 = r4
    mov64 r7, r3                                    r7 = r3
    mov64 r9, r2                                    r9 = r2
    mov64 r2, r1                                    r2 = r1
    ldxdw r6, [r5-0xff8]                    
    jeq r6, 0, lbb_7825                             if r6 == (0 as i32 as i64 as u64) { pc += 23 }
    jeq r6, 1, lbb_7825                             if r6 == (1 as i32 as i64 as u64) { pc += 22 }
    jeq r6, 2, lbb_7825                             if r6 == (2 as i32 as i64 as u64) { pc += 21 }
    jeq r6, 3, lbb_7825                             if r6 == (3 as i32 as i64 as u64) { pc += 20 }
    jeq r6, 4, lbb_7825                             if r6 == (4 as i32 as i64 as u64) { pc += 19 }
    jeq r6, 5, lbb_7825                             if r6 == (5 as i32 as i64 as u64) { pc += 18 }
    jeq r6, 6, lbb_7825                             if r6 == (6 as i32 as i64 as u64) { pc += 17 }
    jeq r6, 7, lbb_7825                             if r6 == (7 as i32 as i64 as u64) { pc += 16 }
    jeq r6, 8, lbb_7825                             if r6 == (8 as i32 as i64 as u64) { pc += 15 }
    jeq r6, 9, lbb_7825                             if r6 == (9 as i32 as i64 as u64) { pc += 14 }
    stxdw [r10-0x318], r2                   
    ldxdw r1, [r5-0x1000]                   
    stxdw [r10-0x320], r1                   
    ldxdw r1, [r1+0x18]                     
    mov64 r2, r9                                    r2 = r9
    mov64 r3, 32                                    r3 = 32 as i32 as i64 as u64
    call function_21867                     
    lsh64 r0, 32                                    r0 <<= 32   ///  r0 = r0.wrapping_shl(32)
    rsh64 r0, 32                                    r0 >>= 32   ///  r0 = r0.wrapping_shr(32)
    jeq r0, 0, lbb_7828                             if r0 == (0 as i32 as i64 as u64) { pc += 7 }
    mov64 r1, 6                                     r1 = 6 as i32 as i64 as u64
    ldxdw r2, [r10-0x318]                   
    stxw [r2+0x0], r1                       
    ja lbb_7827                                     if true { pc += 2 }
lbb_7825:
    mov64 r1, 10                                    r1 = 10 as i32 as i64 as u64
lbb_7826:
    stxdw [r2+0x0], r1                      
lbb_7827:
    exit                                    
lbb_7828:
    ldxdw r1, [r10-0x320]                   
    ldxdw r2, [r1+0x10]                     
    add64 r2, 16                                    r2 += 16   ///  r2 = r2.wrapping_add(16 as i32 as i64 as u64)
    mov64 r1, r10                                   r1 = r10
    add64 r1, -736                                  r1 += -736   ///  r1 = r1.wrapping_add(-736 as i32 as i64 as u64)
    lddw r3, 0x10002dcb8 --> b"\x00\x00\x00\x00\x15\xc4\x02\x00\x18\x00\x00\x00\x00\x00\x00\x00]\x01\x00…        r3 load str located at 4295154872
    call function_211                       
    ldxdw r1, [r10-0x2e0]                   
    ldxdw r2, [r1+0x0]                      
    ldxdw r3, [r1+0x8]                      
    ldxdw r1, [r10-0x2d8]                   
    stxdw [r10-0x328], r1                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -344                                  r1 += -344   ///  r1 = r1.wrapping_add(-344 as i32 as i64 as u64)
    call function_10385                     
    ldxdw r2, [r10-0x148]                   
    ldxdw r1, [r10-0x150]                   
    ldxdw r3, [r10-0x158]                   
    jeq r3, 0, lbb_7861                             if r3 == (0 as i32 as i64 as u64) { pc += 13 }
    ldxdw r3, [r10-0x138]                   
    stxdw [r10-0x208], r3                   
    ldxdw r4, [r10-0x140]                   
    stxdw [r10-0x210], r4                   
    ldxdw r5, [r10-0x318]                   
    stxdw [r5+0x8], r2                      
    stxdw [r5+0x0], r1                      
    stxdw [r5+0x18], r3                     
    stxdw [r5+0x10], r4                     
    ldxdw r2, [r10-0x328]                   
    ldxdw r1, [r2+0x0]                      
    add64 r1, -1                                    r1 += -1   ///  r1 = r1.wrapping_add(-1 as i32 as i64 as u64)
    ja lbb_7826                                     if true { pc += -35 }
lbb_7861:
    stxdw [r10-0x2c8], r2                   
    stxdw [r10-0x2d0], r1                   
    ldxdw r2, [r10-0x328]                   
    ldxdw r1, [r2+0x0]                      
    add64 r1, -1                                    r1 += -1   ///  r1 = r1.wrapping_add(-1 as i32 as i64 as u64)
    stxdw [r2+0x0], r1                      
    ldxdw r1, [r10-0x320]                   
    ldxdw r2, [r1+0x30]                     
    stxdw [r10-0x330], r2                   
    ldxdw r1, [r1+0x0]                      
    stxdw [r10-0x328], r1                   
    ldxdw r1, [r10-0x2c8]                   
    ldxdw r2, [r1+0x20]                     
    ldxdw r1, [r10-0x2d0]                   
    callx r2                                
    mov64 r1, r10                                   r1 = r10
    add64 r1, -344                                  r1 += -344   ///  r1 = r1.wrapping_add(-344 as i32 as i64 as u64)
    mov64 r2, r9                                    r2 = r9
    ldxdw r3, [r10-0x328]                   
    mov64 r4, r0                                    r4 = r0
    call function_6176                      
    ldxb r1, [r10-0x157]                    
    ldxb r2, [r10-0x158]                    
    jeq r2, 0, lbb_7890                             if r2 == (0 as i32 as i64 as u64) { pc += 5 }
lbb_7885:
    ldxdw r2, [r10-0x318]                   
    stxw [r2+0x4], r1                       
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    stxw [r2+0x0], r1                       
    ja lbb_8018                                     if true { pc += 128 }
lbb_7890:
    ldxdw r2, [r10-0x13f]                   
    stxdw [r10-0x1f8], r2                   
    ldxdw r2, [r10-0x146]                   
    stxdw [r10-0x1ff], r2                   
    ldxdw r2, [r10-0x14e]                   
    stxdw [r10-0x207], r2                   
    ldxdw r2, [r10-0x156]                   
    stxdw [r10-0x20f], r2                   
    stxb [r10-0x210], r1                    
    mov64 r2, r10                                   r2 = r10
    add64 r2, -528                                  r2 += -528   ///  r2 = r2.wrapping_add(-528 as i32 as i64 as u64)
    ldxdw r1, [r10-0x330]                   
    mov64 r3, 32                                    r3 = 32 as i32 as i64 as u64
    call function_21867                     
    lsh64 r0, 32                                    r0 <<= 32   ///  r0 = r0.wrapping_shl(32)
    rsh64 r0, 32                                    r0 >>= 32   ///  r0 = r0.wrapping_shr(32)
    jeq r0, 0, lbb_7910                             if r0 == (0 as i32 as i64 as u64) { pc += 3 }
    lddw r1, 0x100000000                            r1 load str located at 4294967296
    ja lbb_8016                                     if true { pc += 106 }
lbb_7910:
    ldxdw r1, [r10-0x320]                   
    add64 r1, 192                                   r1 += 192   ///  r1 = r1.wrapping_add(192 as i32 as i64 as u64)
    stxdw [r10-0x350], r1                   
    ldxdw r9, [r1+0x0]                      
    ldxdw r1, [r10-0x2c8]                   
    stxdw [r10-0x340], r1                   
    ldxdw r2, [r1+0x30]                     
    ldxdw r1, [r10-0x2d0]                   
    stxdw [r10-0x330], r1                   
    stxdw [r10-0x348], r2                   
    callx r2                                
    stxdw [r10-0x338], r9                   
    mov64 r1, r9                                    r1 = r9
    mov64 r2, r0                                    r2 = r0
    mov64 r3, 32                                    r3 = 32 as i32 as i64 as u64
    call function_21867                     
    lsh64 r0, 32                                    r0 <<= 32   ///  r0 = r0.wrapping_shl(32)
    rsh64 r0, 32                                    r0 >>= 32   ///  r0 = r0.wrapping_shr(32)
    jeq r0, 0, lbb_7940                             if r0 == (0 as i32 as i64 as u64) { pc += 11 }
    ldxdw r1, [r10-0x340]                   
    ldxdw r2, [r1+0x38]                     
    ldxdw r1, [r10-0x330]                   
    callx r2                                
    ldxdw r1, [r10-0x338]                   
    mov64 r2, r0                                    r2 = r0
    mov64 r3, 32                                    r3 = 32 as i32 as i64 as u64
    call function_21867                     
    lsh64 r0, 32                                    r0 <<= 32   ///  r0 = r0.wrapping_shl(32)
    rsh64 r0, 32                                    r0 >>= 32   ///  r0 = r0.wrapping_shr(32)
    jne r0, 0, lbb_8011                             if r0 != (0 as i32 as i64 as u64) { pc += 71 }
lbb_7940:
    ldxdw r1, [r10-0x320]                   
    add64 r1, 240                                   r1 += 240   ///  r1 = r1.wrapping_add(240 as i32 as i64 as u64)
    stxdw [r10-0x358], r1                   
    ldxdw r9, [r1+0x0]                      
    ldxdw r1, [r10-0x330]                   
    ldxdw r2, [r10-0x348]                   
    callx r2                                
    mov64 r1, r9                                    r1 = r9
    mov64 r2, r0                                    r2 = r0
    mov64 r3, 32                                    r3 = 32 as i32 as i64 as u64
    call function_21867                     
    lsh64 r0, 32                                    r0 <<= 32   ///  r0 = r0.wrapping_shl(32)
    rsh64 r0, 32                                    r0 >>= 32   ///  r0 = r0.wrapping_shr(32)
    jeq r0, 0, lbb_7965                             if r0 == (0 as i32 as i64 as u64) { pc += 11 }
    ldxdw r1, [r10-0x340]                   
    ldxdw r2, [r1+0x38]                     
    ldxdw r1, [r10-0x330]                   
    callx r2                                
    mov64 r1, r9                                    r1 = r9
    mov64 r2, r0                                    r2 = r0
    mov64 r3, 32                                    r3 = 32 as i32 as i64 as u64
    call function_21867                     
    lsh64 r0, 32                                    r0 <<= 32   ///  r0 = r0.wrapping_shl(32)
    rsh64 r0, 32                                    r0 >>= 32   ///  r0 = r0.wrapping_shr(32)
    jne r0, 0, lbb_8011                             if r0 != (0 as i32 as i64 as u64) { pc += 46 }
lbb_7965:
    ldxdw r1, [r10-0x338]                   
    mov64 r2, r9                                    r2 = r9
    mov64 r3, 32                                    r3 = 32 as i32 as i64 as u64
    call function_21867                     
    lsh64 r0, 32                                    r0 <<= 32   ///  r0 = r0.wrapping_shl(32)
    rsh64 r0, 32                                    r0 >>= 32   ///  r0 = r0.wrapping_shr(32)
    jeq r0, 0, lbb_8014                             if r0 == (0 as i32 as i64 as u64) { pc += 42 }
    ldxdw r1, [r10-0x320]                   
    add64 r1, 144                                   r1 += 144   ///  r1 = r1.wrapping_add(144 as i32 as i64 as u64)
    stxdw [r10-0x360], r1                   
    ldxdw r2, [r1+0x0]                      
    ldxdw r1, [r10-0x338]                   
    mov64 r3, 32                                    r3 = 32 as i32 as i64 as u64
    call function_21867                     
    lsh64 r0, 32                                    r0 <<= 32   ///  r0 = r0.wrapping_shl(32)
    rsh64 r0, 32                                    r0 >>= 32   ///  r0 = r0.wrapping_shr(32)
    jeq r0, 0, lbb_8014                             if r0 == (0 as i32 as i64 as u64) { pc += 32 }
    ldxdw r1, [r10-0x320]                   
    add64 r1, 288                                   r1 += 288   ///  r1 = r1.wrapping_add(288 as i32 as i64 as u64)
    stxdw [r10-0x368], r1                   
    ldxdw r2, [r1+0x0]                      
    mov64 r1, r9                                    r1 = r9
    mov64 r3, 32                                    r3 = 32 as i32 as i64 as u64
    call function_21867                     
    lsh64 r0, 32                                    r0 <<= 32   ///  r0 = r0.wrapping_shl(32)
    rsh64 r0, 32                                    r0 >>= 32   ///  r0 = r0.wrapping_shr(32)
    jeq r0, 0, lbb_8014                             if r0 == (0 as i32 as i64 as u64) { pc += 22 }
    ldxdw r1, [r10-0x320]                   
    add64 r1, 336                                   r1 += 336   ///  r1 = r1.wrapping_add(336 as i32 as i64 as u64)
    stxdw [r10-0x370], r1                   
    ldxdw r9, [r1+0x0]                      
    ldxdw r1, [r10-0x340]                   
    ldxdw r2, [r1+0x40]                     
    ldxdw r1, [r10-0x330]                   
    callx r2                                
    stxdw [r10-0x378], r9                   
    mov64 r1, r9                                    r1 = r9
    mov64 r2, r0                                    r2 = r0
    mov64 r3, 32                                    r3 = 32 as i32 as i64 as u64
    call function_21867                     
    lsh64 r0, 32                                    r0 <<= 32   ///  r0 = r0.wrapping_shl(32)
    rsh64 r0, 32                                    r0 >>= 32   ///  r0 = r0.wrapping_shr(32)
    jeq r0, 0, lbb_8022                             if r0 == (0 as i32 as i64 as u64) { pc += 14 }
lbb_8008:
    lddw r1, 0xb00000000                            r1 load str located at 47244640256
    ja lbb_8016                                     if true { pc += 5 }
lbb_8011:
    lddw r1, 0xa00000000                            r1 load str located at 42949672960
    ja lbb_8016                                     if true { pc += 2 }
lbb_8014:
    lddw r1, 0x900000000                            r1 load str located at 38654705664
lbb_8016:
    ldxdw r2, [r10-0x318]                   
    stxdw [r2+0x0], r1                      
lbb_8018:
    mov64 r1, r10                                   r1 = r10
    add64 r1, -720                                  r1 += -720   ///  r1 = r1.wrapping_add(-720 as i32 as i64 as u64)
    call function_82                        
    ja lbb_7827                                     if true { pc += -195 }
lbb_8022:
    ldxdw r1, [r10-0x320]                   
    add64 r1, 384                                   r1 += 384   ///  r1 = r1.wrapping_add(384 as i32 as i64 as u64)
    stxdw [r10-0x380], r1                   
    ldxdw r9, [r1+0x0]                      
    ldxdw r1, [r10-0x340]                   
    ldxdw r2, [r1+0x58]                     
    ldxdw r1, [r10-0x330]                   
    callx r2                                
    mov64 r1, r9                                    r1 = r9
    mov64 r2, r0                                    r2 = r0
    mov64 r3, 32                                    r3 = 32 as i32 as i64 as u64
    call function_21867                     
    lsh64 r0, 32                                    r0 <<= 32   ///  r0 = r0.wrapping_shl(32)
    rsh64 r0, 32                                    r0 >>= 32   ///  r0 = r0.wrapping_shr(32)
    jeq r0, 0, lbb_8040                             if r0 == (0 as i32 as i64 as u64) { pc += 3 }
    lddw r1, 0x1300000000                           r1 load str located at 81604378624
    ja lbb_8016                                     if true { pc += -24 }
lbb_8040:
    ldxdw r1, [r10-0x320]                   
    add64 r1, 432                                   r1 += 432   ///  r1 = r1.wrapping_add(432 as i32 as i64 as u64)
    stxdw [r10-0x390], r1                   
    ldxdw r9, [r1+0x0]                      
    ldxdw r1, [r10-0x340]                   
    ldxdw r2, [r1+0x28]                     
    ldxdw r1, [r10-0x330]                   
    stxdw [r10-0x388], r2                   
    callx r2                                
    mov64 r1, r9                                    r1 = r9
    mov64 r2, r0                                    r2 = r0
    mov64 r3, 32                                    r3 = 32 as i32 as i64 as u64
    call function_21867                     
    lsh64 r0, 32                                    r0 <<= 32   ///  r0 = r0.wrapping_shl(32)
    rsh64 r0, 32                                    r0 >>= 32   ///  r0 = r0.wrapping_shr(32)
    jeq r0, 0, lbb_8059                             if r0 == (0 as i32 as i64 as u64) { pc += 3 }
    lddw r1, 0x1800000000                           r1 load str located at 103079215104
    ja lbb_8016                                     if true { pc += -43 }
lbb_8059:
    ldxdw r1, [r10-0x330]                   
    ldxdw r2, [r10-0x388]                   
    callx r2                                
    mov64 r1, r10                                   r1 = r10
    add64 r1, -344                                  r1 += -344   ///  r1 = r1.wrapping_add(-344 as i32 as i64 as u64)
    ldxdw r2, [r10-0x350]                   
    mov64 r3, r0                                    r3 = r0
    call function_5980                      
    ldxb r1, [r10-0x158]                    
    jeq r1, 0, lbb_8070                             if r1 == (0 as i32 as i64 as u64) { pc += 1 }
    ja lbb_8082                                     if true { pc += 12 }
lbb_8070:
    ldxdw r1, [r10-0x110]                   
    stxdw [r10-0x398], r1                   
    ldxdw r1, [r10-0x330]                   
    ldxdw r2, [r10-0x388]                   
    callx r2                                
    mov64 r1, r10                                   r1 = r10
    add64 r1, -344                                  r1 += -344   ///  r1 = r1.wrapping_add(-344 as i32 as i64 as u64)
    ldxdw r2, [r10-0x358]                   
    mov64 r3, r0                                    r3 = r0
    call function_5980                      
    ldxb r1, [r10-0x158]                    
    jeq r1, 0, lbb_8084                             if r1 == (0 as i32 as i64 as u64) { pc += 2 }
lbb_8082:
    ldxb r1, [r10-0x157]                    
    ja lbb_7885                                     if true { pc += -199 }
lbb_8084:
    ldxdw r1, [r10-0x110]                   
    stxdw [r10-0x3a0], r1                   
    ldxdw r1, [r10-0x330]                   
    ldxdw r2, [r10-0x388]                   
    callx r2                                
    mov64 r1, r10                                   r1 = r10
    add64 r1, -344                                  r1 += -344   ///  r1 = r1.wrapping_add(-344 as i32 as i64 as u64)
    ldxdw r2, [r10-0x370]                   
    mov64 r3, r0                                    r3 = r0
    call function_6078                      
    ldxb r1, [r10-0x158]                    
    jeq r1, 0, lbb_8097                             if r1 == (0 as i32 as i64 as u64) { pc += 1 }
    ja lbb_8082                                     if true { pc += -15 }
lbb_8097:
    ldxdw r1, [r10-0x128]                   
    stxdw [r10-0x3b8], r1                   
    ldxdw r1, [r10-0x330]                   
    ldxdw r2, [r10-0x348]                   
    callx r2                                
    ldxdw r1, [r10-0x338]                   
    mov64 r2, r0                                    r2 = r0
    mov64 r3, 32                                    r3 = 32 as i32 as i64 as u64
    call function_21867                     
    stxdw [r10-0x3a8], r0                   
    mov64 r1, r0                                    r1 = r0
    lsh64 r1, 32                                    r1 <<= 32   ///  r1 = r1.wrapping_shl(32)
    rsh64 r1, 32                                    r1 >>= 32   ///  r1 = r1.wrapping_shr(32)
    mov64 r2, 1                                     r2 = 1 as i32 as i64 as u64
    stxdw [r10-0x338], r2                   
    jne r1, 0, lbb_8115                             if r1 != (0 as i32 as i64 as u64) { pc += 2 }
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    stxdw [r10-0x338], r1                   
lbb_8115:
    ldxdw r1, [r10-0x340]                   
    ldxdw r2, [r1+0x68]                     
    ldxdw r9, [r10-0x330]                   
    mov64 r1, r9                                    r1 = r9
    stxdw [r10-0x3c0], r2                   
    callx r2                                
    stxdw [r10-0x348], r0                   
    ldxdw r1, [r10-0x340]                   
    ldxdw r2, [r1+0x60]                     
    mov64 r1, r9                                    r1 = r9
    stxdw [r10-0x3b0], r2                   
    callx r2                                
    stxdw [r10-0xfd8], r0                   
    ldxdw r1, [r10-0x3a0]                   
    stxdw [r10-0xff0], r1                   
    ldxdw r1, [r10-0x398]                   
    stxdw [r10-0x1000], r1                  
    ldxdw r1, [r10-0x338]                   
    stxdw [r10-0xfe0], r1                   
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    stxdw [r10-0xfe8], r1                   
    stxdw [r10-0xff8], r1                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -344                                  r1 += -344   ///  r1 = r1.wrapping_add(-344 as i32 as i64 as u64)
    mov64 r5, r10                                   r5 = r10
    ldxdw r2, [r10-0x348]                   
    mov64 r3, r7                                    r3 = r7
    mov64 r4, 0                                     r4 = 0 as i32 as i64 as u64
    call function_299                       
    ldxdw r1, [r10-0x158]                   
    jne r1, 0, lbb_8149                             if r1 != (0 as i32 as i64 as u64) { pc += 3 }
    lddw r1, 0x1400000000                           r1 load str located at 85899345920
    ja lbb_8016                                     if true { pc += -133 }
lbb_8149:
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    ldxdw r2, [r10-0x120]                   
    stxdw [r10-0x3c8], r2                   
    jgt r8, r2, lbb_8154                            if r8 > r2 { pc += 1 }
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
lbb_8154:
    ldxdw r2, [r10-0x118]                   
    stxdw [r10-0x3a0], r2                   
    jeq r2, 0, lbb_8158                             if r2 == (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
lbb_8158:
    and64 r1, 1                                     r1 &= 1   ///  r1 = r1.and(1)
    jne r1, 0, lbb_8232                             if r1 != (0 as i32 as i64 as u64) { pc += 72 }
    ldxdw r9, [r10-0x320]                   
    add64 r9, 96                                    r9 += 96   ///  r9 = r9.wrapping_add(96 as i32 as i64 as u64)
    ldxdw r1, [r10-0xf8]                    
    stxdw [r10-0x3e0], r1                   
    ldxdw r1, [r10-0x100]                   
    stxdw [r10-0x3e8], r1                   
    ldxdw r1, [r10-0x128]                   
    stxdw [r10-0x3d0], r1                   
    ldxdw r1, [r10-0x130]                   
    stxdw [r10-0x3d8], r1                   
    ldxdw r8, [r10-0x138]                   
    ldxdw r7, [r10-0x140]                   
    ldxdw r1, [r10-0x148]                   
    stxdw [r10-0x398], r1                   
    ldxdw r1, [r10-0x150]                   
    stxdw [r10-0x348], r1                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -48                                   r1 += -48   ///  r1 = r1.wrapping_add(-48 as i32 as i64 as u64)
    ldxdw r2, [r10-0x390]                   
    call function_231                       
    mov64 r1, r10                                   r1 = r10
    add64 r1, -704                                  r1 += -704   ///  r1 = r1.wrapping_add(-704 as i32 as i64 as u64)
    ldxdw r2, [r10-0x360]                   
    call function_231                       
    mov64 r1, r10                                   r1 = r10
    add64 r1, -528                                  r1 += -528   ///  r1 = r1.wrapping_add(-528 as i32 as i64 as u64)
    ldxdw r2, [r10-0x350]                   
    call function_231                       
    mov64 r1, r10                                   r1 = r10
    add64 r1, -344                                  r1 += -344   ///  r1 = r1.wrapping_add(-344 as i32 as i64 as u64)
    mov64 r2, r9                                    r2 = r9
    call function_231                       
    ldxdw r2, [r10-0x3a8]                   
    lsh64 r2, 32                                    r2 <<= 32   ///  r2 = r2.wrapping_shl(32)
    rsh64 r2, 32                                    r2 >>= 32   ///  r2 = r2.wrapping_shr(32)
    stxdw [r10-0x350], r8                   
    mov64 r1, r2                                    r1 = r2
    jeq r2, 0, lbb_8200                             if r2 == (0 as i32 as i64 as u64) { pc += 2 }
    ldxdw r2, [r10-0x398]                   
    stxdw [r10-0x350], r2                   
lbb_8200:
    jeq r1, 0, lbb_8202                             if r1 == (0 as i32 as i64 as u64) { pc += 1 }
    stxdw [r10-0x398], r8                   
lbb_8202:
    mov64 r9, r7                                    r9 = r7
    jeq r1, 0, lbb_8205                             if r1 == (0 as i32 as i64 as u64) { pc += 1 }
    ldxdw r9, [r10-0x348]                   
lbb_8205:
    jeq r1, 0, lbb_8207                             if r1 == (0 as i32 as i64 as u64) { pc += 1 }
    stxdw [r10-0x348], r7                   
lbb_8207:
    ldxdw r1, [r10-0x340]                   
    ldxdw r2, [r1+0x20]                     
    ldxdw r1, [r10-0x330]                   
    stxdw [r10-0x340], r2                   
    callx r2                                
    ldxdw r1, [r10-0x3d0]                   
    jne r1, 0, lbb_8215                             if r1 != (0 as i32 as i64 as u64) { pc += 1 }
    ja lbb_8235                                     if true { pc += 20 }
lbb_8215:
    lddw r1, 0x1600000000                           r1 load str located at 94489280512
    ldxdw r2, [r10-0x318]                   
    stxdw [r2+0x0], r1                      
    mov64 r1, r10                                   r1 = r10
    add64 r1, -344                                  r1 += -344   ///  r1 = r1.wrapping_add(-344 as i32 as i64 as u64)
    call function_56                        
    mov64 r1, r10                                   r1 = r10
    add64 r1, -528                                  r1 += -528   ///  r1 = r1.wrapping_add(-528 as i32 as i64 as u64)
    call function_56                        
    mov64 r1, r10                                   r1 = r10
    add64 r1, -704                                  r1 += -704   ///  r1 = r1.wrapping_add(-704 as i32 as i64 as u64)
    call function_56                        
    mov64 r1, r10                                   r1 = r10
    add64 r1, -48                                   r1 += -48   ///  r1 = r1.wrapping_add(-48 as i32 as i64 as u64)
    call function_56                        
    ja lbb_8018                                     if true { pc += -214 }
lbb_8232:
    lddw r1, 0x1000000000                           r1 load str located at 68719476736
    ja lbb_8016                                     if true { pc += -219 }
lbb_8235:
    stxdw [r10-0xff0], r0                   
    ldxdw r1, [r10-0x3d8]                   
    stxdw [r10-0xfe8], r1                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -344                                  r1 += -344   ///  r1 = r1.wrapping_add(-344 as i32 as i64 as u64)
    stxdw [r10-0xff8], r1                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -528                                  r1 += -528   ///  r1 = r1.wrapping_add(-528 as i32 as i64 as u64)
    stxdw [r10-0x1000], r1                  
    mov64 r1, r10                                   r1 = r10
    add64 r1, -96                                   r1 += -96   ///  r1 = r1.wrapping_add(-96 as i32 as i64 as u64)
    mov64 r3, r10                                   r3 = r10
    add64 r3, -48                                   r3 += -48   ///  r3 = r3.wrapping_add(-48 as i32 as i64 as u64)
    mov64 r4, r10                                   r4 = r10
    add64 r4, -704                                  r4 += -704   ///  r4 = r4.wrapping_add(-704 as i32 as i64 as u64)
    mov64 r5, r10                                   r5 = r10
    ldxdw r2, [r10-0x328]                   
    call function_6704                      
    ldxw r1, [r10-0x60]                     
    jeq r1, 20, lbb_8270                            if r1 == (20 as i32 as i64 as u64) { pc += 15 }
lbb_8255:
    ldxw r2, [r10-0x44]                     
    stxw [r10-0x68], r2                     
    ldxdw r3, [r10-0x4c]                    
    stxdw [r10-0x70], r3                    
    ldxdw r4, [r10-0x54]                    
    stxdw [r10-0x78], r4                    
    ldxdw r5, [r10-0x5c]                    
    stxdw [r10-0x80], r5                    
lbb_8263:
    ldxdw r0, [r10-0x318]                   
    stxw [r0+0x1c], r2                      
    stxdw [r0+0x14], r3                     
    stxdw [r0+0xc], r4                      
    stxdw [r0+0x4], r5                      
    stxw [r0+0x0], r1                       
    ja lbb_8018                                     if true { pc += -252 }
lbb_8270:
    ldxdw r7, [r10-0x330]                   
    mov64 r1, r7                                    r1 = r7
    ldxdw r2, [r10-0x3c0]                   
    callx r2                                
    mov64 r8, r0                                    r8 = r0
    mov64 r1, r7                                    r1 = r7
    ldxdw r2, [r10-0x3b0]                   
    callx r2                                
    ldxdw r1, [r10-0x338]                   
    stxdw [r10-0xfd0], r1                   
    stxdw [r10-0xfc8], r0                   
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    stxdw [r10-0xfd8], r1                   
    ldxdw r1, [r10-0x3b8]                   
    stxdw [r10-0xfe0], r1                   
    ldxdw r1, [r10-0x350]                   
    stxdw [r10-0xfe8], r1                   
    stxdw [r10-0xff0], r9                   
    ldxdw r1, [r10-0x398]                   
    stxdw [r10-0xff8], r1                   
    ldxdw r1, [r10-0x348]                   
    stxdw [r10-0x1000], r1                  
    mov64 r1, r10                                   r1 = r10
    add64 r1, -760                                  r1 += -760   ///  r1 = r1.wrapping_add(-760 as i32 as i64 as u64)
    mov64 r5, r10                                   r5 = r10
    mov64 r2, r8                                    r2 = r8
    ldxdw r3, [r10-0x3e8]                   
    ldxdw r4, [r10-0x3e0]                   
    call function_915                       
    ldxdw r1, [r10-0x2f8]                   
    jne r1, 0, lbb_8304                             if r1 != (0 as i32 as i64 as u64) { pc += 3 }
lbb_8301:
    lddw r1, 0x1500000000                           r1 load str located at 90194313216
    ja lbb_8016                                     if true { pc += -288 }
lbb_8304:
    ldxdw r1, [r10-0x320]                   
    add64 r1, 48                                    r1 += 48   ///  r1 = r1.wrapping_add(48 as i32 as i64 as u64)
    stxdw [r10-0x338], r1                   
    ldxdw r8, [r10-0x2e8]                   
    ldxdw r9, [r10-0x2f0]                   
    mov64 r1, r9                                    r1 = r9
    or64 r1, r8                                     r1 |= r8   ///  r1 = r1.or(r8)
    jne r1, 0, lbb_8358                             if r1 != (0 as i32 as i64 as u64) { pc += 46 }
lbb_8312:
    mov64 r1, r10                                   r1 = r10
    add64 r1, -48                                   r1 += -48   ///  r1 = r1.wrapping_add(-48 as i32 as i64 as u64)
    ldxdw r2, [r10-0x390]                   
    call function_231                       
    mov64 r1, r10                                   r1 = r10
    add64 r1, -704                                  r1 += -704   ///  r1 = r1.wrapping_add(-704 as i32 as i64 as u64)
    ldxdw r2, [r10-0x358]                   
    call function_231                       
    mov64 r1, r10                                   r1 = r10
    add64 r1, -528                                  r1 += -528   ///  r1 = r1.wrapping_add(-528 as i32 as i64 as u64)
    ldxdw r2, [r10-0x368]                   
    call function_231                       
    mov64 r1, r10                                   r1 = r10
    add64 r1, -344                                  r1 += -344   ///  r1 = r1.wrapping_add(-344 as i32 as i64 as u64)
    ldxdw r2, [r10-0x338]                   
    call function_231                       
    ldxdw r1, [r10-0x330]                   
    ldxdw r2, [r10-0x340]                   
    callx r2                                
    ldxdw r1, [r10-0x3a0]                   
    jne r1, 0, lbb_8215                             if r1 != (0 as i32 as i64 as u64) { pc += -118 }
    stxdw [r10-0xff0], r0                   
    ldxdw r1, [r10-0x3c8]                   
    stxdw [r10-0xfe8], r1                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -344                                  r1 += -344   ///  r1 = r1.wrapping_add(-344 as i32 as i64 as u64)
    stxdw [r10-0xff8], r1                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -528                                  r1 += -528   ///  r1 = r1.wrapping_add(-528 as i32 as i64 as u64)
    stxdw [r10-0x1000], r1                  
    mov64 r1, r10                                   r1 = r10
    add64 r1, -96                                   r1 += -96   ///  r1 = r1.wrapping_add(-96 as i32 as i64 as u64)
    mov64 r3, r10                                   r3 = r10
    add64 r3, -48                                   r3 += -48   ///  r3 = r3.wrapping_add(-48 as i32 as i64 as u64)
    mov64 r4, r10                                   r4 = r10
    add64 r4, -704                                  r4 += -704   ///  r4 = r4.wrapping_add(-704 as i32 as i64 as u64)
    mov64 r5, r10                                   r5 = r10
    ldxdw r2, [r10-0x328]                   
    call function_6704                      
    ldxw r1, [r10-0x60]                     
    jeq r1, 20, lbb_8354                            if r1 == (20 as i32 as i64 as u64) { pc += 1 }
    ja lbb_8255                                     if true { pc += -99 }
lbb_8354:
    mov64 r1, 20                                    r1 = 20 as i32 as i64 as u64
    ldxdw r2, [r10-0x318]                   
    stxw [r2+0x0], r1                       
    ja lbb_8018                                     if true { pc += -340 }
lbb_8358:
    jeq r6, 10, lbb_8477                            if r6 == (10 as i32 as i64 as u64) { pc += 118 }
    ldxdw r6, [r10-0x320]                   
    add64 r6, 480                                   r6 += 480   ///  r6 = r6.wrapping_add(480 as i32 as i64 as u64)
    ldxdw r1, [r10-0x330]                   
    ldxdw r2, [r10-0x388]                   
    callx r2                                
    mov64 r1, r10                                   r1 = r10
    add64 r1, -344                                  r1 += -344   ///  r1 = r1.wrapping_add(-344 as i32 as i64 as u64)
    stxdw [r10-0x320], r6                   
    mov64 r2, r6                                    r2 = r6
    mov64 r3, r0                                    r3 = r0
    call function_5980                      
    ldxb r1, [r10-0x158]                    
    jeq r1, 0, lbb_8373                             if r1 == (0 as i32 as i64 as u64) { pc += 1 }
    ja lbb_8082                                     if true { pc += -291 }
lbb_8373:
    mov64 r7, r10                                   r7 = r10
    add64 r7, -522                                  r7 += -522   ///  r7 = r7.wrapping_add(-522 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -336                                  r2 += -336   ///  r2 = r2.wrapping_add(-336 as i32 as i64 as u64)
    mov64 r1, r7                                    r1 = r7
    mov64 r3, 176                                   r3 = 176 as i32 as i64 as u64
    call function_21797                     
    mov64 r6, r10                                   r6 = r10
    add64 r6, -704                                  r6 += -704   ///  r6 = r6.wrapping_add(-704 as i32 as i64 as u64)
    mov64 r1, r6                                    r1 = r6
    mov64 r2, r7                                    r2 = r7
    mov64 r3, 176                                   r3 = 176 as i32 as i64 as u64
    call function_21797                     
    ldxdw r1, [r10-0x378]                   
    mov64 r2, r6                                    r2 = r6
    mov64 r3, 32                                    r3 = 32 as i32 as i64 as u64
    call function_21867                     
    lsh64 r0, 32                                    r0 <<= 32   ///  r0 = r0.wrapping_shl(32)
    rsh64 r0, 32                                    r0 >>= 32   ///  r0 = r0.wrapping_shr(32)
    jeq r0, 0, lbb_8394                             if r0 == (0 as i32 as i64 as u64) { pc += 1 }
    ja lbb_8008                                     if true { pc += -386 }
lbb_8394:
    ldxdw r1, [r10-0x330]                   
    ldxdw r2, [r10-0x3b0]                   
    callx r2                                
    mov64 r1, r10                                   r1 = r10
    add64 r1, -784                                  r1 += -784   ///  r1 = r1.wrapping_add(-784 as i32 as i64 as u64)
    mov64 r2, r0                                    r2 = r0
    mov64 r3, r9                                    r3 = r9
    mov64 r4, r8                                    r4 = r8
    call function_3196                      
    ldxdw r1, [r10-0x310]                   
    jeq r1, 0, lbb_8301                             if r1 == (0 as i32 as i64 as u64) { pc += -104 }
    ldxdw r2, [r10-0x300]                   
    ldxdw r1, [r10-0x308]                   
    stxdw [r10-0x348], r1                   
    stxdw [r10-0x350], r2                   
    or64 r1, r2                                     r1 |= r2   ///  r1 = r1.or(r2)
    jeq r1, 0, lbb_8477                             if r1 == (0 as i32 as i64 as u64) { pc += 66 }
    mov64 r6, r8                                    r6 = r8
    ldxdw r1, [r10-0x350]                   
    sub64 r6, r1                                    r6 -= r1   ///  r6 = r6.wrapping_sub(r1)
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    mov64 r2, 1                                     r2 = 1 as i32 as i64 as u64
    ldxdw r3, [r10-0x348]                   
    jgt r3, r9, lbb_8419                            if r3 > r9 { pc += 1 }
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
lbb_8419:
    sub64 r6, r2                                    r6 -= r2   ///  r6 = r6.wrapping_sub(r2)
    mov64 r3, r9                                    r3 = r9
    ldxdw r2, [r10-0x348]                   
    sub64 r3, r2                                    r3 -= r2   ///  r3 = r3.wrapping_sub(r2)
    mov64 r2, 1                                     r2 = 1 as i32 as i64 as u64
    stxdw [r10-0x360], r3                   
    jgt r3, r9, lbb_8427                            if r3 > r9 { pc += 1 }
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
lbb_8427:
    jgt r6, r8, lbb_8429                            if r6 > r8 { pc += 1 }
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
lbb_8429:
    jeq r6, r8, lbb_8431                            if r6 == r8 { pc += 1 }
    mov64 r2, r1                                    r2 = r1
lbb_8431:
    and64 r2, 1                                     r2 &= 1   ///  r2 = r2.and(1)
    jne r2, 0, lbb_8301                             if r2 != (0 as i32 as i64 as u64) { pc += -132 }
    mov64 r1, r10                                   r1 = r10
    add64 r1, -96                                   r1 += -96   ///  r1 = r1.wrapping_add(-96 as i32 as i64 as u64)
    ldxdw r2, [r10-0x390]                   
    call function_231                       
    mov64 r1, r10                                   r1 = r10
    add64 r1, -48                                   r1 += -48   ///  r1 = r1.wrapping_add(-48 as i32 as i64 as u64)
    ldxdw r2, [r10-0x370]                   
    call function_231                       
    mov64 r1, r10                                   r1 = r10
    add64 r1, -528                                  r1 += -528   ///  r1 = r1.wrapping_add(-528 as i32 as i64 as u64)
    ldxdw r2, [r10-0x320]                   
    call function_231                       
    mov64 r1, r10                                   r1 = r10
    add64 r1, -344                                  r1 += -344   ///  r1 = r1.wrapping_add(-344 as i32 as i64 as u64)
    ldxdw r2, [r10-0x338]                   
    call function_231                       
    ldxdw r1, [r10-0x330]                   
    ldxdw r2, [r10-0x340]                   
    callx r2                                
    ldxdw r1, [r10-0x350]                   
    jne r1, 0, lbb_8517                             if r1 != (0 as i32 as i64 as u64) { pc += 63 }
    stxdw [r10-0xff0], r0                   
    ldxdw r1, [r10-0x348]                   
    stxdw [r10-0xfe8], r1                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -344                                  r1 += -344   ///  r1 = r1.wrapping_add(-344 as i32 as i64 as u64)
    stxdw [r10-0xff8], r1                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -528                                  r1 += -528   ///  r1 = r1.wrapping_add(-528 as i32 as i64 as u64)
    stxdw [r10-0x1000], r1                  
    mov64 r1, r10                                   r1 = r10
    add64 r1, -128                                  r1 += -128   ///  r1 = r1.wrapping_add(-128 as i32 as i64 as u64)
    mov64 r3, r10                                   r3 = r10
    add64 r3, -96                                   r3 += -96   ///  r3 = r3.wrapping_add(-96 as i32 as i64 as u64)
    mov64 r4, r10                                   r4 = r10
    add64 r4, -48                                   r4 += -48   ///  r4 = r4.wrapping_add(-48 as i32 as i64 as u64)
    mov64 r5, r10                                   r5 = r10
    ldxdw r2, [r10-0x328]                   
    call function_6464                      
    ldxw r1, [r10-0x80]                     
    jeq r1, 20, lbb_8475                            if r1 == (20 as i32 as i64 as u64) { pc += 1 }
    ja lbb_8534                                     if true { pc += 59 }
lbb_8475:
    ldxdw r9, [r10-0x360]                   
    mov64 r8, r6                                    r8 = r6
lbb_8477:
    mov64 r1, r10                                   r1 = r10
    add64 r1, -48                                   r1 += -48   ///  r1 = r1.wrapping_add(-48 as i32 as i64 as u64)
    ldxdw r2, [r10-0x390]                   
    call function_231                       
    mov64 r1, r10                                   r1 = r10
    add64 r1, -704                                  r1 += -704   ///  r1 = r1.wrapping_add(-704 as i32 as i64 as u64)
    ldxdw r2, [r10-0x370]                   
    call function_231                       
    mov64 r1, r10                                   r1 = r10
    add64 r1, -528                                  r1 += -528   ///  r1 = r1.wrapping_add(-528 as i32 as i64 as u64)
    ldxdw r2, [r10-0x380]                   
    call function_231                       
    mov64 r1, r10                                   r1 = r10
    add64 r1, -344                                  r1 += -344   ///  r1 = r1.wrapping_add(-344 as i32 as i64 as u64)
    ldxdw r2, [r10-0x338]                   
    call function_231                       
    ldxdw r1, [r10-0x330]                   
    ldxdw r2, [r10-0x340]                   
    callx r2                                
    jne r8, 0, lbb_8215                             if r8 != (0 as i32 as i64 as u64) { pc += -282 }
    stxdw [r10-0xff0], r0                   
    stxdw [r10-0xfe8], r9                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -344                                  r1 += -344   ///  r1 = r1.wrapping_add(-344 as i32 as i64 as u64)
    stxdw [r10-0xff8], r1                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -528                                  r1 += -528   ///  r1 = r1.wrapping_add(-528 as i32 as i64 as u64)
    stxdw [r10-0x1000], r1                  
    mov64 r1, r10                                   r1 = r10
    add64 r1, -96                                   r1 += -96   ///  r1 = r1.wrapping_add(-96 as i32 as i64 as u64)
    mov64 r3, r10                                   r3 = r10
    add64 r3, -48                                   r3 += -48   ///  r3 = r3.wrapping_add(-48 as i32 as i64 as u64)
    mov64 r4, r10                                   r4 = r10
    add64 r4, -704                                  r4 += -704   ///  r4 = r4.wrapping_add(-704 as i32 as i64 as u64)
    mov64 r5, r10                                   r5 = r10
    ldxdw r2, [r10-0x328]                   
    call function_6464                      
    ldxw r1, [r10-0x60]                     
    jeq r1, 20, lbb_8312                            if r1 == (20 as i32 as i64 as u64) { pc += -204 }
    ja lbb_8255                                     if true { pc += -262 }
lbb_8517:
    lddw r1, 0x1600000000                           r1 load str located at 94489280512
    ldxdw r2, [r10-0x318]                   
    stxdw [r2+0x0], r1                      
    mov64 r1, r10                                   r1 = r10
    add64 r1, -344                                  r1 += -344   ///  r1 = r1.wrapping_add(-344 as i32 as i64 as u64)
    call function_56                        
    mov64 r1, r10                                   r1 = r10
    add64 r1, -528                                  r1 += -528   ///  r1 = r1.wrapping_add(-528 as i32 as i64 as u64)
    call function_56                        
    mov64 r1, r10                                   r1 = r10
    add64 r1, -48                                   r1 += -48   ///  r1 = r1.wrapping_add(-48 as i32 as i64 as u64)
    call function_56                        
    mov64 r1, r10                                   r1 = r10
    add64 r1, -96                                   r1 += -96   ///  r1 = r1.wrapping_add(-96 as i32 as i64 as u64)
    call function_56                        
    ja lbb_8018                                     if true { pc += -516 }
lbb_8534:
    ldxw r2, [r10-0x64]                     
    stxw [r10-0x88], r2                     
    ldxdw r3, [r10-0x6c]                    
    stxdw [r10-0x90], r3                    
    ldxdw r4, [r10-0x74]                    
    stxdw [r10-0x98], r4                    
    ldxdw r5, [r10-0x7c]                    
    stxdw [r10-0xa0], r5                    
    ja lbb_8263                                     if true { pc += -280 }

function_8543:
    mov64 r8, r4                                    r8 = r4
    mov64 r7, r3                                    r7 = r3
    mov64 r9, r2                                    r9 = r2
    mov64 r2, r1                                    r2 = r1
    ldxdw r6, [r5-0xff8]                    
    jeq r6, 0, lbb_8572                             if r6 == (0 as i32 as i64 as u64) { pc += 23 }
    jeq r6, 1, lbb_8572                             if r6 == (1 as i32 as i64 as u64) { pc += 22 }
    jeq r6, 2, lbb_8572                             if r6 == (2 as i32 as i64 as u64) { pc += 21 }
    jeq r6, 3, lbb_8572                             if r6 == (3 as i32 as i64 as u64) { pc += 20 }
    jeq r6, 4, lbb_8572                             if r6 == (4 as i32 as i64 as u64) { pc += 19 }
    jeq r6, 5, lbb_8572                             if r6 == (5 as i32 as i64 as u64) { pc += 18 }
    jeq r6, 6, lbb_8572                             if r6 == (6 as i32 as i64 as u64) { pc += 17 }
    jeq r6, 7, lbb_8572                             if r6 == (7 as i32 as i64 as u64) { pc += 16 }
    jeq r6, 8, lbb_8572                             if r6 == (8 as i32 as i64 as u64) { pc += 15 }
    jeq r6, 9, lbb_8572                             if r6 == (9 as i32 as i64 as u64) { pc += 14 }
    stxdw [r10-0x318], r2                   
    ldxdw r1, [r5-0x1000]                   
    stxdw [r10-0x320], r1                   
    ldxdw r1, [r1+0x18]                     
    mov64 r2, r9                                    r2 = r9
    mov64 r3, 32                                    r3 = 32 as i32 as i64 as u64
    call function_21867                     
    lsh64 r0, 32                                    r0 <<= 32   ///  r0 = r0.wrapping_shl(32)
    rsh64 r0, 32                                    r0 >>= 32   ///  r0 = r0.wrapping_shr(32)
    jeq r0, 0, lbb_8575                             if r0 == (0 as i32 as i64 as u64) { pc += 7 }
    mov64 r1, 6                                     r1 = 6 as i32 as i64 as u64
    ldxdw r2, [r10-0x318]                   
    stxw [r2+0x0], r1                       
    ja lbb_8574                                     if true { pc += 2 }
lbb_8572:
    mov64 r1, 10                                    r1 = 10 as i32 as i64 as u64
lbb_8573:
    stxdw [r2+0x0], r1                      
lbb_8574:
    exit                                    
lbb_8575:
    ldxdw r1, [r10-0x320]                   
    ldxdw r2, [r1+0x10]                     
    add64 r2, 16                                    r2 += 16   ///  r2 = r2.wrapping_add(16 as i32 as i64 as u64)
    mov64 r1, r10                                   r1 = r10
    add64 r1, -736                                  r1 += -736   ///  r1 = r1.wrapping_add(-736 as i32 as i64 as u64)
    lddw r3, 0x10002dcd0 --> b"\x00\x00\x00\x00\x15\xc4\x02\x00\x18\x00\x00\x00\x00\x00\x00\x00\x06\x02\…        r3 load str located at 4295154896
    call function_211                       
    ldxdw r1, [r10-0x2e0]                   
    ldxdw r2, [r1+0x0]                      
    ldxdw r3, [r1+0x8]                      
    ldxdw r1, [r10-0x2d8]                   
    stxdw [r10-0x328], r1                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -344                                  r1 += -344   ///  r1 = r1.wrapping_add(-344 as i32 as i64 as u64)
    call function_10385                     
    ldxdw r2, [r10-0x148]                   
    ldxdw r1, [r10-0x150]                   
    ldxdw r3, [r10-0x158]                   
    jeq r3, 0, lbb_8608                             if r3 == (0 as i32 as i64 as u64) { pc += 13 }
    ldxdw r3, [r10-0x138]                   
    stxdw [r10-0x208], r3                   
    ldxdw r4, [r10-0x140]                   
    stxdw [r10-0x210], r4                   
    ldxdw r5, [r10-0x318]                   
    stxdw [r5+0x8], r2                      
    stxdw [r5+0x0], r1                      
    stxdw [r5+0x18], r3                     
    stxdw [r5+0x10], r4                     
    ldxdw r2, [r10-0x328]                   
    ldxdw r1, [r2+0x0]                      
    add64 r1, -1                                    r1 += -1   ///  r1 = r1.wrapping_add(-1 as i32 as i64 as u64)
    ja lbb_8573                                     if true { pc += -35 }
lbb_8608:
    stxdw [r10-0x2c8], r2                   
    stxdw [r10-0x2d0], r1                   
    ldxdw r2, [r10-0x328]                   
    ldxdw r1, [r2+0x0]                      
    add64 r1, -1                                    r1 += -1   ///  r1 = r1.wrapping_add(-1 as i32 as i64 as u64)
    stxdw [r2+0x0], r1                      
    ldxdw r1, [r10-0x320]                   
    ldxdw r2, [r1+0x30]                     
    stxdw [r10-0x330], r2                   
    ldxdw r1, [r1+0x0]                      
    stxdw [r10-0x328], r1                   
    ldxdw r1, [r10-0x2c8]                   
    ldxdw r2, [r1+0x20]                     
    ldxdw r1, [r10-0x2d0]                   
    callx r2                                
    mov64 r1, r10                                   r1 = r10
    add64 r1, -344                                  r1 += -344   ///  r1 = r1.wrapping_add(-344 as i32 as i64 as u64)
    mov64 r2, r9                                    r2 = r9
    ldxdw r3, [r10-0x328]                   
    mov64 r4, r0                                    r4 = r0
    call function_6176                      
    ldxb r1, [r10-0x157]                    
    ldxb r2, [r10-0x158]                    
    jeq r2, 0, lbb_8637                             if r2 == (0 as i32 as i64 as u64) { pc += 5 }
lbb_8632:
    ldxdw r2, [r10-0x318]                   
    stxw [r2+0x4], r1                       
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    stxw [r2+0x0], r1                       
    ja lbb_8765                                     if true { pc += 128 }
lbb_8637:
    ldxdw r2, [r10-0x13f]                   
    stxdw [r10-0x1f8], r2                   
    ldxdw r2, [r10-0x146]                   
    stxdw [r10-0x1ff], r2                   
    ldxdw r2, [r10-0x14e]                   
    stxdw [r10-0x207], r2                   
    ldxdw r2, [r10-0x156]                   
    stxdw [r10-0x20f], r2                   
    stxb [r10-0x210], r1                    
    mov64 r2, r10                                   r2 = r10
    add64 r2, -528                                  r2 += -528   ///  r2 = r2.wrapping_add(-528 as i32 as i64 as u64)
    ldxdw r1, [r10-0x330]                   
    mov64 r3, 32                                    r3 = 32 as i32 as i64 as u64
    call function_21867                     
    lsh64 r0, 32                                    r0 <<= 32   ///  r0 = r0.wrapping_shl(32)
    rsh64 r0, 32                                    r0 >>= 32   ///  r0 = r0.wrapping_shr(32)
    jeq r0, 0, lbb_8657                             if r0 == (0 as i32 as i64 as u64) { pc += 3 }
    lddw r1, 0x100000000                            r1 load str located at 4294967296
    ja lbb_8763                                     if true { pc += 106 }
lbb_8657:
    ldxdw r1, [r10-0x320]                   
    add64 r1, 192                                   r1 += 192   ///  r1 = r1.wrapping_add(192 as i32 as i64 as u64)
    stxdw [r10-0x350], r1                   
    ldxdw r9, [r1+0x0]                      
    ldxdw r1, [r10-0x2c8]                   
    stxdw [r10-0x340], r1                   
    ldxdw r2, [r1+0x30]                     
    ldxdw r1, [r10-0x2d0]                   
    stxdw [r10-0x330], r1                   
    stxdw [r10-0x348], r2                   
    callx r2                                
    stxdw [r10-0x338], r9                   
    mov64 r1, r9                                    r1 = r9
    mov64 r2, r0                                    r2 = r0
    mov64 r3, 32                                    r3 = 32 as i32 as i64 as u64
    call function_21867                     
    lsh64 r0, 32                                    r0 <<= 32   ///  r0 = r0.wrapping_shl(32)
    rsh64 r0, 32                                    r0 >>= 32   ///  r0 = r0.wrapping_shr(32)
    jeq r0, 0, lbb_8687                             if r0 == (0 as i32 as i64 as u64) { pc += 11 }
    ldxdw r1, [r10-0x340]                   
    ldxdw r2, [r1+0x38]                     
    ldxdw r1, [r10-0x330]                   
    callx r2                                
    ldxdw r1, [r10-0x338]                   
    mov64 r2, r0                                    r2 = r0
    mov64 r3, 32                                    r3 = 32 as i32 as i64 as u64
    call function_21867                     
    lsh64 r0, 32                                    r0 <<= 32   ///  r0 = r0.wrapping_shl(32)
    rsh64 r0, 32                                    r0 >>= 32   ///  r0 = r0.wrapping_shr(32)
    jne r0, 0, lbb_8758                             if r0 != (0 as i32 as i64 as u64) { pc += 71 }
lbb_8687:
    ldxdw r1, [r10-0x320]                   
    add64 r1, 240                                   r1 += 240   ///  r1 = r1.wrapping_add(240 as i32 as i64 as u64)
    stxdw [r10-0x358], r1                   
    ldxdw r9, [r1+0x0]                      
    ldxdw r1, [r10-0x330]                   
    ldxdw r2, [r10-0x348]                   
    callx r2                                
    mov64 r1, r9                                    r1 = r9
    mov64 r2, r0                                    r2 = r0
    mov64 r3, 32                                    r3 = 32 as i32 as i64 as u64
    call function_21867                     
    lsh64 r0, 32                                    r0 <<= 32   ///  r0 = r0.wrapping_shl(32)
    rsh64 r0, 32                                    r0 >>= 32   ///  r0 = r0.wrapping_shr(32)
    jeq r0, 0, lbb_8712                             if r0 == (0 as i32 as i64 as u64) { pc += 11 }
    ldxdw r1, [r10-0x340]                   
    ldxdw r2, [r1+0x38]                     
    ldxdw r1, [r10-0x330]                   
    callx r2                                
    mov64 r1, r9                                    r1 = r9
    mov64 r2, r0                                    r2 = r0
    mov64 r3, 32                                    r3 = 32 as i32 as i64 as u64
    call function_21867                     
    lsh64 r0, 32                                    r0 <<= 32   ///  r0 = r0.wrapping_shl(32)
    rsh64 r0, 32                                    r0 >>= 32   ///  r0 = r0.wrapping_shr(32)
    jne r0, 0, lbb_8758                             if r0 != (0 as i32 as i64 as u64) { pc += 46 }
lbb_8712:
    ldxdw r1, [r10-0x338]                   
    mov64 r2, r9                                    r2 = r9
    mov64 r3, 32                                    r3 = 32 as i32 as i64 as u64
    call function_21867                     
    lsh64 r0, 32                                    r0 <<= 32   ///  r0 = r0.wrapping_shl(32)
    rsh64 r0, 32                                    r0 >>= 32   ///  r0 = r0.wrapping_shr(32)
    jeq r0, 0, lbb_8761                             if r0 == (0 as i32 as i64 as u64) { pc += 42 }
    ldxdw r1, [r10-0x320]                   
    add64 r1, 144                                   r1 += 144   ///  r1 = r1.wrapping_add(144 as i32 as i64 as u64)
    stxdw [r10-0x360], r1                   
    ldxdw r2, [r1+0x0]                      
    ldxdw r1, [r10-0x338]                   
    mov64 r3, 32                                    r3 = 32 as i32 as i64 as u64
    call function_21867                     
    lsh64 r0, 32                                    r0 <<= 32   ///  r0 = r0.wrapping_shl(32)
    rsh64 r0, 32                                    r0 >>= 32   ///  r0 = r0.wrapping_shr(32)
    jeq r0, 0, lbb_8761                             if r0 == (0 as i32 as i64 as u64) { pc += 32 }
    ldxdw r1, [r10-0x320]                   
    add64 r1, 288                                   r1 += 288   ///  r1 = r1.wrapping_add(288 as i32 as i64 as u64)
    stxdw [r10-0x368], r1                   
    ldxdw r2, [r1+0x0]                      
    mov64 r1, r9                                    r1 = r9
    mov64 r3, 32                                    r3 = 32 as i32 as i64 as u64
    call function_21867                     
    lsh64 r0, 32                                    r0 <<= 32   ///  r0 = r0.wrapping_shl(32)
    rsh64 r0, 32                                    r0 >>= 32   ///  r0 = r0.wrapping_shr(32)
    jeq r0, 0, lbb_8761                             if r0 == (0 as i32 as i64 as u64) { pc += 22 }
    ldxdw r1, [r10-0x320]                   
    add64 r1, 336                                   r1 += 336   ///  r1 = r1.wrapping_add(336 as i32 as i64 as u64)
    stxdw [r10-0x370], r1                   
    ldxdw r9, [r1+0x0]                      
    ldxdw r1, [r10-0x340]                   
    ldxdw r2, [r1+0x40]                     
    ldxdw r1, [r10-0x330]                   
    callx r2                                
    stxdw [r10-0x378], r9                   
    mov64 r1, r9                                    r1 = r9
    mov64 r2, r0                                    r2 = r0
    mov64 r3, 32                                    r3 = 32 as i32 as i64 as u64
    call function_21867                     
    lsh64 r0, 32                                    r0 <<= 32   ///  r0 = r0.wrapping_shl(32)
    rsh64 r0, 32                                    r0 >>= 32   ///  r0 = r0.wrapping_shr(32)
    jeq r0, 0, lbb_8769                             if r0 == (0 as i32 as i64 as u64) { pc += 14 }
lbb_8755:
    lddw r1, 0xb00000000                            r1 load str located at 47244640256
    ja lbb_8763                                     if true { pc += 5 }
lbb_8758:
    lddw r1, 0xa00000000                            r1 load str located at 42949672960
    ja lbb_8763                                     if true { pc += 2 }
lbb_8761:
    lddw r1, 0x900000000                            r1 load str located at 38654705664
lbb_8763:
    ldxdw r2, [r10-0x318]                   
    stxdw [r2+0x0], r1                      
lbb_8765:
    mov64 r1, r10                                   r1 = r10
    add64 r1, -720                                  r1 += -720   ///  r1 = r1.wrapping_add(-720 as i32 as i64 as u64)
    call function_82                        
    ja lbb_8574                                     if true { pc += -195 }
lbb_8769:
    ldxdw r1, [r10-0x320]                   
    add64 r1, 384                                   r1 += 384   ///  r1 = r1.wrapping_add(384 as i32 as i64 as u64)
    stxdw [r10-0x380], r1                   
    ldxdw r9, [r1+0x0]                      
    ldxdw r1, [r10-0x340]                   
    ldxdw r2, [r1+0x58]                     
    ldxdw r1, [r10-0x330]                   
    callx r2                                
    mov64 r1, r9                                    r1 = r9
    mov64 r2, r0                                    r2 = r0
    mov64 r3, 32                                    r3 = 32 as i32 as i64 as u64
    call function_21867                     
    lsh64 r0, 32                                    r0 <<= 32   ///  r0 = r0.wrapping_shl(32)
    rsh64 r0, 32                                    r0 >>= 32   ///  r0 = r0.wrapping_shr(32)
    jeq r0, 0, lbb_8787                             if r0 == (0 as i32 as i64 as u64) { pc += 3 }
    lddw r1, 0x1300000000                           r1 load str located at 81604378624
    ja lbb_8763                                     if true { pc += -24 }
lbb_8787:
    ldxdw r1, [r10-0x320]                   
    add64 r1, 432                                   r1 += 432   ///  r1 = r1.wrapping_add(432 as i32 as i64 as u64)
    stxdw [r10-0x390], r1                   
    ldxdw r9, [r1+0x0]                      
    ldxdw r1, [r10-0x340]                   
    ldxdw r2, [r1+0x28]                     
    ldxdw r1, [r10-0x330]                   
    stxdw [r10-0x388], r2                   
    callx r2                                
    mov64 r1, r9                                    r1 = r9
    mov64 r2, r0                                    r2 = r0
    mov64 r3, 32                                    r3 = 32 as i32 as i64 as u64
    call function_21867                     
    lsh64 r0, 32                                    r0 <<= 32   ///  r0 = r0.wrapping_shl(32)
    rsh64 r0, 32                                    r0 >>= 32   ///  r0 = r0.wrapping_shr(32)
    jeq r0, 0, lbb_8806                             if r0 == (0 as i32 as i64 as u64) { pc += 3 }
    lddw r1, 0x1800000000                           r1 load str located at 103079215104
    ja lbb_8763                                     if true { pc += -43 }
lbb_8806:
    ldxdw r1, [r10-0x330]                   
    ldxdw r2, [r10-0x388]                   
    callx r2                                
    mov64 r1, r10                                   r1 = r10
    add64 r1, -344                                  r1 += -344   ///  r1 = r1.wrapping_add(-344 as i32 as i64 as u64)
    ldxdw r2, [r10-0x350]                   
    mov64 r3, r0                                    r3 = r0
    call function_5980                      
    ldxb r1, [r10-0x158]                    
    jeq r1, 0, lbb_8817                             if r1 == (0 as i32 as i64 as u64) { pc += 1 }
    ja lbb_8829                                     if true { pc += 12 }
lbb_8817:
    ldxdw r1, [r10-0x110]                   
    stxdw [r10-0x398], r1                   
    ldxdw r1, [r10-0x330]                   
    ldxdw r2, [r10-0x388]                   
    callx r2                                
    mov64 r1, r10                                   r1 = r10
    add64 r1, -344                                  r1 += -344   ///  r1 = r1.wrapping_add(-344 as i32 as i64 as u64)
    ldxdw r2, [r10-0x358]                   
    mov64 r3, r0                                    r3 = r0
    call function_5980                      
    ldxb r1, [r10-0x158]                    
    jeq r1, 0, lbb_8831                             if r1 == (0 as i32 as i64 as u64) { pc += 2 }
lbb_8829:
    ldxb r1, [r10-0x157]                    
    ja lbb_8632                                     if true { pc += -199 }
lbb_8831:
    ldxdw r1, [r10-0x110]                   
    stxdw [r10-0x3a0], r1                   
    ldxdw r1, [r10-0x330]                   
    ldxdw r2, [r10-0x388]                   
    callx r2                                
    mov64 r1, r10                                   r1 = r10
    add64 r1, -344                                  r1 += -344   ///  r1 = r1.wrapping_add(-344 as i32 as i64 as u64)
    ldxdw r2, [r10-0x370]                   
    mov64 r3, r0                                    r3 = r0
    call function_6078                      
    ldxb r1, [r10-0x158]                    
    jeq r1, 0, lbb_8844                             if r1 == (0 as i32 as i64 as u64) { pc += 1 }
    ja lbb_8829                                     if true { pc += -15 }
lbb_8844:
    ldxdw r1, [r10-0x128]                   
    stxdw [r10-0x3b8], r1                   
    ldxdw r1, [r10-0x330]                   
    ldxdw r2, [r10-0x348]                   
    callx r2                                
    ldxdw r1, [r10-0x338]                   
    mov64 r2, r0                                    r2 = r0
    mov64 r3, 32                                    r3 = 32 as i32 as i64 as u64
    call function_21867                     
    stxdw [r10-0x3a8], r0                   
    mov64 r1, r0                                    r1 = r0
    lsh64 r1, 32                                    r1 <<= 32   ///  r1 = r1.wrapping_shl(32)
    rsh64 r1, 32                                    r1 >>= 32   ///  r1 = r1.wrapping_shr(32)
    mov64 r2, 1                                     r2 = 1 as i32 as i64 as u64
    stxdw [r10-0x338], r2                   
    jne r1, 0, lbb_8862                             if r1 != (0 as i32 as i64 as u64) { pc += 2 }
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    stxdw [r10-0x338], r1                   
lbb_8862:
    ldxdw r1, [r10-0x340]                   
    ldxdw r2, [r1+0x68]                     
    ldxdw r9, [r10-0x330]                   
    mov64 r1, r9                                    r1 = r9
    stxdw [r10-0x3c0], r2                   
    callx r2                                
    stxdw [r10-0x348], r0                   
    ldxdw r1, [r10-0x340]                   
    ldxdw r2, [r1+0x60]                     
    mov64 r1, r9                                    r1 = r9
    stxdw [r10-0x3b0], r2                   
    callx r2                                
    stxdw [r10-0xfd8], r0                   
    ldxdw r1, [r10-0x3a0]                   
    stxdw [r10-0xff0], r1                   
    ldxdw r1, [r10-0x398]                   
    stxdw [r10-0x1000], r1                  
    ldxdw r1, [r10-0x338]                   
    stxdw [r10-0xfe0], r1                   
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    stxdw [r10-0xfe8], r1                   
    stxdw [r10-0xff8], r1                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -344                                  r1 += -344   ///  r1 = r1.wrapping_add(-344 as i32 as i64 as u64)
    mov64 r5, r10                                   r5 = r10
    ldxdw r2, [r10-0x348]                   
    mov64 r3, r7                                    r3 = r7
    mov64 r4, 0                                     r4 = 0 as i32 as i64 as u64
    call function_592                       
    ldxdw r1, [r10-0x158]                   
    jne r1, 0, lbb_8896                             if r1 != (0 as i32 as i64 as u64) { pc += 3 }
    lddw r1, 0x1400000000                           r1 load str located at 85899345920
    ja lbb_8763                                     if true { pc += -133 }
lbb_8896:
    mov64 r2, 1                                     r2 = 1 as i32 as i64 as u64
    ldxdw r3, [r10-0x130]                   
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    stxdw [r10-0x348], r3                   
    jgt r3, r8, lbb_8902                            if r3 > r8 { pc += 1 }
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
lbb_8902:
    ldxdw r8, [r10-0x128]                   
    jne r8, 0, lbb_8905                             if r8 != (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
lbb_8905:
    jeq r8, 0, lbb_8907                             if r8 == (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r1, r2                                    r1 = r2
lbb_8907:
    and64 r1, 1                                     r1 &= 1   ///  r1 = r1.and(1)
    jne r1, 0, lbb_8982                             if r1 != (0 as i32 as i64 as u64) { pc += 73 }
    ldxdw r9, [r10-0x320]                   
    add64 r9, 96                                    r9 += 96   ///  r9 = r9.wrapping_add(96 as i32 as i64 as u64)
    ldxdw r1, [r10-0xf8]                    
    stxdw [r10-0x3d0], r1                   
    ldxdw r1, [r10-0x100]                   
    stxdw [r10-0x3d8], r1                   
    ldxdw r1, [r10-0x118]                   
    stxdw [r10-0x3e0], r1                   
    ldxdw r1, [r10-0x120]                   
    stxdw [r10-0x3e8], r1                   
    ldxdw r7, [r10-0x138]                   
    ldxdw r1, [r10-0x140]                   
    stxdw [r10-0x398], r1                   
    ldxdw r1, [r10-0x148]                   
    stxdw [r10-0x3c8], r1                   
    ldxdw r1, [r10-0x150]                   
    stxdw [r10-0x3a0], r1                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -48                                   r1 += -48   ///  r1 = r1.wrapping_add(-48 as i32 as i64 as u64)
    ldxdw r2, [r10-0x390]                   
    call function_231                       
    mov64 r1, r10                                   r1 = r10
    add64 r1, -704                                  r1 += -704   ///  r1 = r1.wrapping_add(-704 as i32 as i64 as u64)
    ldxdw r2, [r10-0x360]                   
    call function_231                       
    mov64 r1, r10                                   r1 = r10
    add64 r1, -528                                  r1 += -528   ///  r1 = r1.wrapping_add(-528 as i32 as i64 as u64)
    ldxdw r2, [r10-0x350]                   
    call function_231                       
    mov64 r1, r10                                   r1 = r10
    add64 r1, -344                                  r1 += -344   ///  r1 = r1.wrapping_add(-344 as i32 as i64 as u64)
    mov64 r2, r9                                    r2 = r9
    call function_231                       
    ldxdw r2, [r10-0x3a8]                   
    lsh64 r2, 32                                    r2 <<= 32   ///  r2 = r2.wrapping_shl(32)
    rsh64 r2, 32                                    r2 >>= 32   ///  r2 = r2.wrapping_shr(32)
    stxdw [r10-0x350], r7                   
    mov64 r1, r2                                    r1 = r2
    jeq r2, 0, lbb_8950                             if r2 == (0 as i32 as i64 as u64) { pc += 2 }
    ldxdw r2, [r10-0x3c8]                   
    stxdw [r10-0x350], r2                   
lbb_8950:
    jeq r1, 0, lbb_8952                             if r1 == (0 as i32 as i64 as u64) { pc += 1 }
    stxdw [r10-0x3c8], r7                   
lbb_8952:
    ldxdw r9, [r10-0x398]                   
    jeq r1, 0, lbb_8955                             if r1 == (0 as i32 as i64 as u64) { pc += 1 }
    ldxdw r9, [r10-0x3a0]                   
lbb_8955:
    jeq r1, 0, lbb_8958                             if r1 == (0 as i32 as i64 as u64) { pc += 2 }
    ldxdw r1, [r10-0x398]                   
    stxdw [r10-0x3a0], r1                   
lbb_8958:
    ldxdw r1, [r10-0x340]                   
    ldxdw r2, [r1+0x20]                     
    ldxdw r1, [r10-0x330]                   
    stxdw [r10-0x340], r2                   
    callx r2                                
    jne r8, 0, lbb_8965                             if r8 != (0 as i32 as i64 as u64) { pc += 1 }
    ja lbb_8985                                     if true { pc += 20 }
lbb_8965:
    lddw r1, 0x1600000000                           r1 load str located at 94489280512
    ldxdw r2, [r10-0x318]                   
    stxdw [r2+0x0], r1                      
    mov64 r1, r10                                   r1 = r10
    add64 r1, -344                                  r1 += -344   ///  r1 = r1.wrapping_add(-344 as i32 as i64 as u64)
    call function_56                        
    mov64 r1, r10                                   r1 = r10
    add64 r1, -528                                  r1 += -528   ///  r1 = r1.wrapping_add(-528 as i32 as i64 as u64)
    call function_56                        
    mov64 r1, r10                                   r1 = r10
    add64 r1, -704                                  r1 += -704   ///  r1 = r1.wrapping_add(-704 as i32 as i64 as u64)
    call function_56                        
    mov64 r1, r10                                   r1 = r10
    add64 r1, -48                                   r1 += -48   ///  r1 = r1.wrapping_add(-48 as i32 as i64 as u64)
    call function_56                        
    ja lbb_8765                                     if true { pc += -217 }
lbb_8982:
    lddw r1, 0x1000000000                           r1 load str located at 68719476736
    ja lbb_8763                                     if true { pc += -222 }
lbb_8985:
    stxdw [r10-0xff0], r0                   
    ldxdw r1, [r10-0x348]                   
    stxdw [r10-0xfe8], r1                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -344                                  r1 += -344   ///  r1 = r1.wrapping_add(-344 as i32 as i64 as u64)
    stxdw [r10-0xff8], r1                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -528                                  r1 += -528   ///  r1 = r1.wrapping_add(-528 as i32 as i64 as u64)
    stxdw [r10-0x1000], r1                  
    mov64 r1, r10                                   r1 = r10
    add64 r1, -96                                   r1 += -96   ///  r1 = r1.wrapping_add(-96 as i32 as i64 as u64)
    mov64 r3, r10                                   r3 = r10
    add64 r3, -48                                   r3 += -48   ///  r3 = r3.wrapping_add(-48 as i32 as i64 as u64)
    mov64 r4, r10                                   r4 = r10
    add64 r4, -704                                  r4 += -704   ///  r4 = r4.wrapping_add(-704 as i32 as i64 as u64)
    mov64 r5, r10                                   r5 = r10
    ldxdw r2, [r10-0x328]                   
    call function_6704                      
    ldxw r1, [r10-0x60]                     
    jeq r1, 20, lbb_9020                            if r1 == (20 as i32 as i64 as u64) { pc += 15 }
lbb_9005:
    ldxw r2, [r10-0x44]                     
    stxw [r10-0x68], r2                     
    ldxdw r3, [r10-0x4c]                    
    stxdw [r10-0x70], r3                    
    ldxdw r4, [r10-0x54]                    
    stxdw [r10-0x78], r4                    
    ldxdw r5, [r10-0x5c]                    
    stxdw [r10-0x80], r5                    
lbb_9013:
    ldxdw r0, [r10-0x318]                   
    stxw [r0+0x1c], r2                      
    stxdw [r0+0x14], r3                     
    stxdw [r0+0xc], r4                      
    stxdw [r0+0x4], r5                      
    stxw [r0+0x0], r1                       
    ja lbb_8765                                     if true { pc += -255 }
lbb_9020:
    ldxdw r8, [r10-0x330]                   
    mov64 r1, r8                                    r1 = r8
    ldxdw r2, [r10-0x3c0]                   
    callx r2                                
    mov64 r7, r0                                    r7 = r0
    mov64 r1, r8                                    r1 = r8
    ldxdw r2, [r10-0x3b0]                   
    callx r2                                
    ldxdw r1, [r10-0x338]                   
    stxdw [r10-0xfd0], r1                   
    stxdw [r10-0xfc8], r0                   
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    stxdw [r10-0xfd8], r1                   
    ldxdw r1, [r10-0x3b8]                   
    stxdw [r10-0xfe0], r1                   
    ldxdw r1, [r10-0x350]                   
    stxdw [r10-0xfe8], r1                   
    stxdw [r10-0xff0], r9                   
    ldxdw r1, [r10-0x3c8]                   
    stxdw [r10-0xff8], r1                   
    ldxdw r1, [r10-0x3a0]                   
    stxdw [r10-0x1000], r1                  
    mov64 r1, r10                                   r1 = r10
    add64 r1, -760                                  r1 += -760   ///  r1 = r1.wrapping_add(-760 as i32 as i64 as u64)
    mov64 r5, r10                                   r5 = r10
    mov64 r2, r7                                    r2 = r7
    ldxdw r3, [r10-0x3d8]                   
    ldxdw r4, [r10-0x3d0]                   
    call function_915                       
    ldxdw r1, [r10-0x2f8]                   
    jne r1, 0, lbb_9054                             if r1 != (0 as i32 as i64 as u64) { pc += 3 }
lbb_9051:
    lddw r1, 0x1500000000                           r1 load str located at 90194313216
    ja lbb_8763                                     if true { pc += -291 }
lbb_9054:
    ldxdw r1, [r10-0x320]                   
    add64 r1, 48                                    r1 += 48   ///  r1 = r1.wrapping_add(48 as i32 as i64 as u64)
    stxdw [r10-0x338], r1                   
    ldxdw r8, [r10-0x2e8]                   
    ldxdw r7, [r10-0x2f0]                   
    mov64 r1, r7                                    r1 = r7
    or64 r1, r8                                     r1 |= r8   ///  r1 = r1.or(r8)
    jne r1, 0, lbb_9108                             if r1 != (0 as i32 as i64 as u64) { pc += 46 }
lbb_9062:
    mov64 r1, r10                                   r1 = r10
    add64 r1, -48                                   r1 += -48   ///  r1 = r1.wrapping_add(-48 as i32 as i64 as u64)
    ldxdw r2, [r10-0x390]                   
    call function_231                       
    mov64 r1, r10                                   r1 = r10
    add64 r1, -704                                  r1 += -704   ///  r1 = r1.wrapping_add(-704 as i32 as i64 as u64)
    ldxdw r2, [r10-0x358]                   
    call function_231                       
    mov64 r1, r10                                   r1 = r10
    add64 r1, -528                                  r1 += -528   ///  r1 = r1.wrapping_add(-528 as i32 as i64 as u64)
    ldxdw r2, [r10-0x368]                   
    call function_231                       
    mov64 r1, r10                                   r1 = r10
    add64 r1, -344                                  r1 += -344   ///  r1 = r1.wrapping_add(-344 as i32 as i64 as u64)
    ldxdw r2, [r10-0x338]                   
    call function_231                       
    ldxdw r1, [r10-0x330]                   
    ldxdw r2, [r10-0x340]                   
    callx r2                                
    ldxdw r1, [r10-0x3e0]                   
    jne r1, 0, lbb_8965                             if r1 != (0 as i32 as i64 as u64) { pc += -118 }
    stxdw [r10-0xff0], r0                   
    ldxdw r1, [r10-0x3e8]                   
    stxdw [r10-0xfe8], r1                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -344                                  r1 += -344   ///  r1 = r1.wrapping_add(-344 as i32 as i64 as u64)
    stxdw [r10-0xff8], r1                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -528                                  r1 += -528   ///  r1 = r1.wrapping_add(-528 as i32 as i64 as u64)
    stxdw [r10-0x1000], r1                  
    mov64 r1, r10                                   r1 = r10
    add64 r1, -96                                   r1 += -96   ///  r1 = r1.wrapping_add(-96 as i32 as i64 as u64)
    mov64 r3, r10                                   r3 = r10
    add64 r3, -48                                   r3 += -48   ///  r3 = r3.wrapping_add(-48 as i32 as i64 as u64)
    mov64 r4, r10                                   r4 = r10
    add64 r4, -704                                  r4 += -704   ///  r4 = r4.wrapping_add(-704 as i32 as i64 as u64)
    mov64 r5, r10                                   r5 = r10
    ldxdw r2, [r10-0x328]                   
    call function_6704                      
    ldxw r1, [r10-0x60]                     
    jeq r1, 20, lbb_9104                            if r1 == (20 as i32 as i64 as u64) { pc += 1 }
    ja lbb_9005                                     if true { pc += -99 }
lbb_9104:
    mov64 r1, 20                                    r1 = 20 as i32 as i64 as u64
    ldxdw r2, [r10-0x318]                   
    stxw [r2+0x0], r1                       
    ja lbb_8765                                     if true { pc += -343 }
lbb_9108:
    jeq r6, 10, lbb_9227                            if r6 == (10 as i32 as i64 as u64) { pc += 118 }
    ldxdw r9, [r10-0x320]                   
    add64 r9, 480                                   r9 += 480   ///  r9 = r9.wrapping_add(480 as i32 as i64 as u64)
    ldxdw r1, [r10-0x330]                   
    ldxdw r2, [r10-0x388]                   
    callx r2                                
    mov64 r1, r10                                   r1 = r10
    add64 r1, -344                                  r1 += -344   ///  r1 = r1.wrapping_add(-344 as i32 as i64 as u64)
    stxdw [r10-0x320], r9                   
    mov64 r2, r9                                    r2 = r9
    mov64 r3, r0                                    r3 = r0
    call function_5980                      
    ldxb r1, [r10-0x158]                    
    jeq r1, 0, lbb_9123                             if r1 == (0 as i32 as i64 as u64) { pc += 1 }
    ja lbb_8829                                     if true { pc += -294 }
lbb_9123:
    mov64 r6, r10                                   r6 = r10
    add64 r6, -522                                  r6 += -522   ///  r6 = r6.wrapping_add(-522 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -336                                  r2 += -336   ///  r2 = r2.wrapping_add(-336 as i32 as i64 as u64)
    mov64 r1, r6                                    r1 = r6
    mov64 r3, 176                                   r3 = 176 as i32 as i64 as u64
    call function_21797                     
    mov64 r9, r10                                   r9 = r10
    add64 r9, -704                                  r9 += -704   ///  r9 = r9.wrapping_add(-704 as i32 as i64 as u64)
    mov64 r1, r9                                    r1 = r9
    mov64 r2, r6                                    r2 = r6
    mov64 r3, 176                                   r3 = 176 as i32 as i64 as u64
    call function_21797                     
    ldxdw r1, [r10-0x378]                   
    mov64 r2, r9                                    r2 = r9
    mov64 r3, 32                                    r3 = 32 as i32 as i64 as u64
    call function_21867                     
    lsh64 r0, 32                                    r0 <<= 32   ///  r0 = r0.wrapping_shl(32)
    rsh64 r0, 32                                    r0 >>= 32   ///  r0 = r0.wrapping_shr(32)
    jeq r0, 0, lbb_9144                             if r0 == (0 as i32 as i64 as u64) { pc += 1 }
    ja lbb_8755                                     if true { pc += -389 }
lbb_9144:
    ldxdw r1, [r10-0x330]                   
    ldxdw r2, [r10-0x3b0]                   
    callx r2                                
    mov64 r1, r10                                   r1 = r10
    add64 r1, -784                                  r1 += -784   ///  r1 = r1.wrapping_add(-784 as i32 as i64 as u64)
    mov64 r2, r0                                    r2 = r0
    mov64 r3, r7                                    r3 = r7
    mov64 r4, r8                                    r4 = r8
    call function_3196                      
    ldxdw r1, [r10-0x310]                   
    jeq r1, 0, lbb_9051                             if r1 == (0 as i32 as i64 as u64) { pc += -104 }
    ldxdw r2, [r10-0x300]                   
    ldxdw r1, [r10-0x308]                   
    stxdw [r10-0x348], r1                   
    stxdw [r10-0x350], r2                   
    or64 r1, r2                                     r1 |= r2   ///  r1 = r1.or(r2)
    jeq r1, 0, lbb_9227                             if r1 == (0 as i32 as i64 as u64) { pc += 66 }
    mov64 r9, r8                                    r9 = r8
    ldxdw r1, [r10-0x350]                   
    sub64 r9, r1                                    r9 -= r1   ///  r9 = r9.wrapping_sub(r1)
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    mov64 r2, 1                                     r2 = 1 as i32 as i64 as u64
    ldxdw r3, [r10-0x348]                   
    jgt r3, r7, lbb_9169                            if r3 > r7 { pc += 1 }
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
lbb_9169:
    sub64 r9, r2                                    r9 -= r2   ///  r9 = r9.wrapping_sub(r2)
    mov64 r3, r7                                    r3 = r7
    ldxdw r2, [r10-0x348]                   
    sub64 r3, r2                                    r3 -= r2   ///  r3 = r3.wrapping_sub(r2)
    mov64 r2, 1                                     r2 = 1 as i32 as i64 as u64
    stxdw [r10-0x360], r3                   
    jgt r3, r7, lbb_9177                            if r3 > r7 { pc += 1 }
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
lbb_9177:
    jgt r9, r8, lbb_9179                            if r9 > r8 { pc += 1 }
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
lbb_9179:
    jeq r9, r8, lbb_9181                            if r9 == r8 { pc += 1 }
    mov64 r2, r1                                    r2 = r1
lbb_9181:
    and64 r2, 1                                     r2 &= 1   ///  r2 = r2.and(1)
    jne r2, 0, lbb_9051                             if r2 != (0 as i32 as i64 as u64) { pc += -132 }
    mov64 r1, r10                                   r1 = r10
    add64 r1, -96                                   r1 += -96   ///  r1 = r1.wrapping_add(-96 as i32 as i64 as u64)
    ldxdw r2, [r10-0x390]                   
    call function_231                       
    mov64 r1, r10                                   r1 = r10
    add64 r1, -48                                   r1 += -48   ///  r1 = r1.wrapping_add(-48 as i32 as i64 as u64)
    ldxdw r2, [r10-0x370]                   
    call function_231                       
    mov64 r1, r10                                   r1 = r10
    add64 r1, -528                                  r1 += -528   ///  r1 = r1.wrapping_add(-528 as i32 as i64 as u64)
    ldxdw r2, [r10-0x320]                   
    call function_231                       
    mov64 r1, r10                                   r1 = r10
    add64 r1, -344                                  r1 += -344   ///  r1 = r1.wrapping_add(-344 as i32 as i64 as u64)
    ldxdw r2, [r10-0x338]                   
    call function_231                       
    ldxdw r1, [r10-0x330]                   
    ldxdw r2, [r10-0x340]                   
    callx r2                                
    ldxdw r1, [r10-0x350]                   
    jne r1, 0, lbb_9267                             if r1 != (0 as i32 as i64 as u64) { pc += 63 }
    stxdw [r10-0xff0], r0                   
    ldxdw r1, [r10-0x348]                   
    stxdw [r10-0xfe8], r1                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -344                                  r1 += -344   ///  r1 = r1.wrapping_add(-344 as i32 as i64 as u64)
    stxdw [r10-0xff8], r1                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -528                                  r1 += -528   ///  r1 = r1.wrapping_add(-528 as i32 as i64 as u64)
    stxdw [r10-0x1000], r1                  
    mov64 r1, r10                                   r1 = r10
    add64 r1, -128                                  r1 += -128   ///  r1 = r1.wrapping_add(-128 as i32 as i64 as u64)
    mov64 r3, r10                                   r3 = r10
    add64 r3, -96                                   r3 += -96   ///  r3 = r3.wrapping_add(-96 as i32 as i64 as u64)
    mov64 r4, r10                                   r4 = r10
    add64 r4, -48                                   r4 += -48   ///  r4 = r4.wrapping_add(-48 as i32 as i64 as u64)
    mov64 r5, r10                                   r5 = r10
    ldxdw r2, [r10-0x328]                   
    call function_6464                      
    ldxw r1, [r10-0x80]                     
    jeq r1, 20, lbb_9225                            if r1 == (20 as i32 as i64 as u64) { pc += 1 }
    ja lbb_9284                                     if true { pc += 59 }
lbb_9225:
    ldxdw r7, [r10-0x360]                   
    mov64 r8, r9                                    r8 = r9
lbb_9227:
    mov64 r1, r10                                   r1 = r10
    add64 r1, -48                                   r1 += -48   ///  r1 = r1.wrapping_add(-48 as i32 as i64 as u64)
    ldxdw r2, [r10-0x390]                   
    call function_231                       
    mov64 r1, r10                                   r1 = r10
    add64 r1, -704                                  r1 += -704   ///  r1 = r1.wrapping_add(-704 as i32 as i64 as u64)
    ldxdw r2, [r10-0x370]                   
    call function_231                       
    mov64 r1, r10                                   r1 = r10
    add64 r1, -528                                  r1 += -528   ///  r1 = r1.wrapping_add(-528 as i32 as i64 as u64)
    ldxdw r2, [r10-0x380]                   
    call function_231                       
    mov64 r1, r10                                   r1 = r10
    add64 r1, -344                                  r1 += -344   ///  r1 = r1.wrapping_add(-344 as i32 as i64 as u64)
    ldxdw r2, [r10-0x338]                   
    call function_231                       
    ldxdw r1, [r10-0x330]                   
    ldxdw r2, [r10-0x340]                   
    callx r2                                
    jne r8, 0, lbb_8965                             if r8 != (0 as i32 as i64 as u64) { pc += -282 }
    stxdw [r10-0xff0], r0                   
    stxdw [r10-0xfe8], r7                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -344                                  r1 += -344   ///  r1 = r1.wrapping_add(-344 as i32 as i64 as u64)
    stxdw [r10-0xff8], r1                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -528                                  r1 += -528   ///  r1 = r1.wrapping_add(-528 as i32 as i64 as u64)
    stxdw [r10-0x1000], r1                  
    mov64 r1, r10                                   r1 = r10
    add64 r1, -96                                   r1 += -96   ///  r1 = r1.wrapping_add(-96 as i32 as i64 as u64)
    mov64 r3, r10                                   r3 = r10
    add64 r3, -48                                   r3 += -48   ///  r3 = r3.wrapping_add(-48 as i32 as i64 as u64)
    mov64 r4, r10                                   r4 = r10
    add64 r4, -704                                  r4 += -704   ///  r4 = r4.wrapping_add(-704 as i32 as i64 as u64)
    mov64 r5, r10                                   r5 = r10
    ldxdw r2, [r10-0x328]                   
    call function_6464                      
    ldxw r1, [r10-0x60]                     
    jeq r1, 20, lbb_9062                            if r1 == (20 as i32 as i64 as u64) { pc += -204 }
    ja lbb_9005                                     if true { pc += -262 }
lbb_9267:
    lddw r1, 0x1600000000                           r1 load str located at 94489280512
    ldxdw r2, [r10-0x318]                   
    stxdw [r2+0x0], r1                      
    mov64 r1, r10                                   r1 = r10
    add64 r1, -344                                  r1 += -344   ///  r1 = r1.wrapping_add(-344 as i32 as i64 as u64)
    call function_56                        
    mov64 r1, r10                                   r1 = r10
    add64 r1, -528                                  r1 += -528   ///  r1 = r1.wrapping_add(-528 as i32 as i64 as u64)
    call function_56                        
    mov64 r1, r10                                   r1 = r10
    add64 r1, -48                                   r1 += -48   ///  r1 = r1.wrapping_add(-48 as i32 as i64 as u64)
    call function_56                        
    mov64 r1, r10                                   r1 = r10
    add64 r1, -96                                   r1 += -96   ///  r1 = r1.wrapping_add(-96 as i32 as i64 as u64)
    call function_56                        
    ja lbb_8765                                     if true { pc += -519 }
lbb_9284:
    ldxw r2, [r10-0x64]                     
    stxw [r10-0x88], r2                     
    ldxdw r3, [r10-0x6c]                    
    stxdw [r10-0x90], r3                    
    ldxdw r4, [r10-0x74]                    
    stxdw [r10-0x98], r4                    
    ldxdw r5, [r10-0x7c]                    
    stxdw [r10-0xa0], r5                    
    ja lbb_9013                                     if true { pc += -280 }

function_9293:
    mov64 r9, r4                                    r9 = r4
    mov64 r7, r3                                    r7 = r3
    mov64 r8, r2                                    r8 = r2
    mov64 r6, r1                                    r6 = r1
    ldxdw r1, [r5-0xff0]                    
    jeq r1, 0, lbb_9344                             if r1 == (0 as i32 as i64 as u64) { pc += 45 }
    jeq r1, 1, lbb_9344                             if r1 == (1 as i32 as i64 as u64) { pc += 44 }
    jeq r1, 2, lbb_9344                             if r1 == (2 as i32 as i64 as u64) { pc += 43 }
    jeq r1, 3, lbb_9344                             if r1 == (3 as i32 as i64 as u64) { pc += 42 }
    jeq r1, 4, lbb_9344                             if r1 == (4 as i32 as i64 as u64) { pc += 41 }
    jeq r1, 5, lbb_9344                             if r1 == (5 as i32 as i64 as u64) { pc += 40 }
    jeq r1, 6, lbb_9344                             if r1 == (6 as i32 as i64 as u64) { pc += 39 }
    jeq r1, 7, lbb_9344                             if r1 == (7 as i32 as i64 as u64) { pc += 38 }
    jeq r1, 8, lbb_9344                             if r1 == (8 as i32 as i64 as u64) { pc += 37 }
    jeq r1, 9, lbb_9344                             if r1 == (9 as i32 as i64 as u64) { pc += 36 }
    ldxdw r1, [r5-0xff8]                    
    ldxdw r2, [r5-0x1000]                   
    stxdw [r10-0x1e0], r2                   
    stxdw [r10-0x1d8], r1                   
    ldxdw r2, [r1+0x10]                     
    add64 r2, 16                                    r2 += 16   ///  r2 = r2.wrapping_add(16 as i32 as i64 as u64)
    mov64 r1, r10                                   r1 = r10
    add64 r1, -424                                  r1 += -424   ///  r1 = r1.wrapping_add(-424 as i32 as i64 as u64)
    lddw r3, 0x10002dce8 --> b"\x00\x00\x00\x00\x15\xc4\x02\x00\x18\x00\x00\x00\x00\x00\x00\x00\xad\x02\…        r3 load str located at 4295154920
    call function_211                       
    ldxdw r1, [r10-0x1a8]                   
    ldxdw r2, [r1+0x0]                      
    ldxdw r3, [r1+0x8]                      
    ldxdw r1, [r10-0x1a0]                   
    stxdw [r10-0x1d0], r1                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -392                                  r1 += -392   ///  r1 = r1.wrapping_add(-392 as i32 as i64 as u64)
    call function_10385                     
    ldxdw r2, [r10-0x178]                   
    ldxdw r1, [r10-0x180]                   
    ldxdw r3, [r10-0x188]                   
    jeq r3, 0, lbb_9347                             if r3 == (0 as i32 as i64 as u64) { pc += 16 }
    ldxdw r3, [r10-0x168]                   
    stxdw [r10-0x28], r3                    
    ldxdw r4, [r10-0x170]                   
    stxdw [r10-0x30], r4                    
    stxdw [r6+0x8], r2                      
    stxdw [r6+0x0], r1                      
    stxdw [r6+0x18], r3                     
    stxdw [r6+0x10], r4                     
    ldxdw r2, [r10-0x1d0]                   
    ldxdw r1, [r2+0x0]                      
    add64 r1, -1                                    r1 += -1   ///  r1 = r1.wrapping_add(-1 as i32 as i64 as u64)
    stxdw [r2+0x0], r1                      
    ja lbb_9346                                     if true { pc += 2 }
lbb_9344:
    mov64 r1, 10                                    r1 = 10 as i32 as i64 as u64
    stxdw [r6+0x0], r1                      
lbb_9346:
    exit                                    
lbb_9347:
    ldxdw r3, [r10-0x1e0]                   
    ldxdw r3, [r10-0x1d8]                   
    stxdw [r10-0x190], r2                   
    stxdw [r10-0x198], r1                   
    ldxdw r2, [r10-0x1d0]                   
    ldxdw r1, [r2+0x0]                      
    add64 r1, -1                                    r1 += -1   ///  r1 = r1.wrapping_add(-1 as i32 as i64 as u64)
    stxdw [r2+0x0], r1                      
    ldxdw r1, [r10-0x190]                   
    stxdw [r10-0x1e8], r1                   
    ldxdw r2, [r1+0x68]                     
    ldxdw r1, [r10-0x198]                   
    stxdw [r10-0x1d0], r1                   
    callx r2                                
    ldxdw r1, [r0+0x10]                     
    ldxdw r2, [r1+0x70]                     
    stxdw [r10-0x1f8], r0                   
    ldxdw r1, [r0+0x8]                      
    callx r2                                
    jne r0, 0, lbb_9368                             if r0 != (0 as i32 as i64 as u64) { pc += 1 }
    ja lbb_9451                                     if true { pc += 83 }
lbb_9368:
    ldxdw r2, [r10-0x1d8]                   
    mov64 r1, r2                                    r1 = r2
    add64 r1, 48                                    r1 += 48   ///  r1 = r1.wrapping_add(48 as i32 as i64 as u64)
    stxdw [r10-0x200], r1                   
    mov64 r3, r2                                    r3 = r2
    add64 r3, 144                                   r3 += 144   ///  r3 = r3.wrapping_add(144 as i32 as i64 as u64)
    mov64 r1, r2                                    r1 = r2
    add64 r1, 192                                   r1 += 192   ///  r1 = r1.wrapping_add(192 as i32 as i64 as u64)
    mov64 r4, r2                                    r4 = r2
    add64 r4, 240                                   r4 += 240   ///  r4 = r4.wrapping_add(240 as i32 as i64 as u64)
    stxdw [r10-0x1f0], r4                   
    mov64 r0, r2                                    r0 = r2
    add64 r0, 288                                   r0 += 288   ///  r0 = r0.wrapping_add(288 as i32 as i64 as u64)
    mov64 r4, r2                                    r4 = r2
    add64 r4, 336                                   r4 += 336   ///  r4 = r4.wrapping_add(336 as i32 as i64 as u64)
    mov64 r5, r2                                    r5 = r2
    add64 r5, 432                                   r5 += 432   ///  r5 = r5.wrapping_add(432 as i32 as i64 as u64)
    stxdw [r10-0x228], r1                   
    stxdw [r10-0xfc8], r1                   
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    stxdw [r10-0xfc0], r1                   
    stxdw [r10-0x220], r3                   
    stxdw [r10-0xfd0], r3                   
    stxdw [r10-0x218], r5                   
    stxdw [r10-0xfd8], r5                   
    stxdw [r10-0x210], r4                   
    stxdw [r10-0xfe0], r4                   
    stxdw [r10-0x208], r0                   
    stxdw [r10-0xfe8], r0                   
    ldxdw r1, [r10-0x1f0]                   
    stxdw [r10-0xff0], r1                   
    ldxdw r1, [r10-0x200]                   
    stxdw [r10-0xff8], r1                   
    stxdw [r10-0x1000], r2                  
    mov64 r1, r10                                   r1 = r10
    add64 r1, -392                                  r1 += -392   ///  r1 = r1.wrapping_add(-392 as i32 as i64 as u64)
    mov64 r5, r10                                   r5 = r10
    ldxdw r2, [r10-0x1d0]                   
    ldxdw r3, [r10-0x1e8]                   
    mov64 r4, r8                                    r4 = r8
    call function_6944                      
    ldxw r1, [r10-0x188]                    
    jeq r1, 20, lbb_9412                            if r1 == (20 as i32 as i64 as u64) { pc += 1 }
    ja lbb_9455                                     if true { pc += 43 }
lbb_9412:
    ldxdw r1, [r10-0x1e8]                   
    ldxdw r8, [r1+0x28]                     
    ldxdw r1, [r10-0x1d0]                   
    callx r8                                
    mov64 r1, r10                                   r1 = r10
    add64 r1, -392                                  r1 += -392   ///  r1 = r1.wrapping_add(-392 as i32 as i64 as u64)
    ldxdw r2, [r10-0x1f0]                   
    mov64 r3, r0                                    r3 = r0
    call function_5980                      
    ldxb r1, [r10-0x188]                    
    jeq r1, 0, lbb_9424                             if r1 == (0 as i32 as i64 as u64) { pc += 1 }
    ja lbb_9447                                     if true { pc += 23 }
lbb_9424:
    ldxdw r1, [r10-0x140]                   
    stxdw [r10-0x230], r1                   
    ldxdw r1, [r10-0x1d0]                   
    callx r8                                
    mov64 r1, r10                                   r1 = r10
    add64 r1, -392                                  r1 += -392   ///  r1 = r1.wrapping_add(-392 as i32 as i64 as u64)
    ldxdw r2, [r10-0x208]                   
    mov64 r3, r0                                    r3 = r0
    call function_5980                      
    ldxb r1, [r10-0x188]                    
    jeq r1, 0, lbb_9436                             if r1 == (0 as i32 as i64 as u64) { pc += 1 }
    ja lbb_9447                                     if true { pc += 11 }
lbb_9436:
    ldxdw r1, [r10-0x140]                   
    stxdw [r10-0x238], r1                   
    ldxdw r1, [r10-0x1d0]                   
    callx r8                                
    mov64 r1, r10                                   r1 = r10
    add64 r1, -392                                  r1 += -392   ///  r1 = r1.wrapping_add(-392 as i32 as i64 as u64)
    ldxdw r2, [r10-0x210]                   
    mov64 r3, r0                                    r3 = r0
    call function_6078                      
    ldxb r1, [r10-0x188]                    
    jeq r1, 0, lbb_9472                             if r1 == (0 as i32 as i64 as u64) { pc += 25 }
lbb_9447:
    ldxb r1, [r10-0x187]                    
    stxw [r6+0x4], r1                       
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    ja lbb_9467                                     if true { pc += 16 }
lbb_9451:
    lddw r1, 0x1b00000000                           r1 load str located at 115964116992
lbb_9453:
    stxdw [r6+0x0], r1                      
    ja lbb_9468                                     if true { pc += 13 }
lbb_9455:
    ldxw r2, [r10-0x16c]                    
    stxw [r10-0x18], r2                     
    ldxdw r3, [r10-0x174]                   
    stxdw [r10-0x20], r3                    
    ldxdw r4, [r10-0x17c]                   
    stxdw [r10-0x28], r4                    
    ldxdw r5, [r10-0x184]                   
    stxdw [r10-0x30], r5                    
lbb_9463:
    stxw [r6+0x1c], r2                      
    stxdw [r6+0x14], r3                     
    stxdw [r6+0xc], r4                      
    stxdw [r6+0x4], r5                      
lbb_9467:
    stxw [r6+0x0], r1                       
lbb_9468:
    mov64 r1, r10                                   r1 = r10
    add64 r1, -408                                  r1 += -408   ///  r1 = r1.wrapping_add(-408 as i32 as i64 as u64)
    call function_82                        
    ja lbb_9346                                     if true { pc += -126 }
lbb_9472:
    ldxdw r1, [r10-0x158]                   
    jne r1, 0, lbb_9493                             if r1 != (0 as i32 as i64 as u64) { pc += 19 }
    ldxdw r7, [r10-0x1f8]                   
    ldxdw r1, [r7+0x10]                     
    ldxdw r3, [r1+0x40]                     
    ldxdw r2, [r7+0x8]                      
    mov64 r1, r10                                   r1 = r10
    add64 r1, -440                                  r1 += -440   ///  r1 = r1.wrapping_add(-440 as i32 as i64 as u64)
    callx r3                                
    ldxdw r2, [r7+0x8]                      
    ldxdw r1, [r7+0x10]                     
    ldxdw r3, [r1+0x40]                     
    ldxdw r1, [r10-0x1b0]                   
    stxdw [r10-0x240], r1                   
    ldxdw r7, [r10-0x1b8]                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -456                                  r1 += -456   ///  r1 = r1.wrapping_add(-456 as i32 as i64 as u64)
    callx r3                                
    ldxdw r3, [r10-0x1c0]                   
    ldxdw r1, [r10-0x1c8]                   
    ja lbb_9496                                     if true { pc += 3 }
lbb_9493:
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
    stxdw [r10-0x240], r2                   
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
lbb_9496:
    ldxdw r4, [r10-0x1f8]                   
    ldxdw r2, [r4+0x8]                      
    ldxdw r4, [r4+0x10]                     
    ldxdw r0, [r4+0x48]                     
    mov64 r4, 1                                     r4 = 1 as i32 as i64 as u64
    stxdw [r10-0xfd0], r4                   
    ldxdw r4, [r10-0x238]                   
    stxdw [r10-0xfe0], r4                   
    mov64 r4, 0                                     r4 = 0 as i32 as i64 as u64
    stxdw [r10-0xfd8], r4                   
    stxdw [r10-0xfe8], r4                   
    ldxdw r4, [r10-0x230]                   
    stxdw [r10-0xff0], r4                   
    stxdw [r10-0xff8], r3                   
    stxdw [r10-0x1000], r1                  
    mov64 r1, r10                                   r1 = r10
    add64 r1, -392                                  r1 += -392   ///  r1 = r1.wrapping_add(-392 as i32 as i64 as u64)
    mov64 r5, r10                                   r5 = r10
    mov64 r3, r7                                    r3 = r7
    ldxdw r4, [r10-0x240]                   
    callx r0                                
    ldxdw r1, [r10-0x188]                   
    jeq r1, 0, lbb_9658                             if r1 == (0 as i32 as i64 as u64) { pc += 139 }
    ldxdw r1, [r10-0x178]                   
    jne r1, 0, lbb_9661                             if r1 != (0 as i32 as i64 as u64) { pc += 140 }
    ldxdw r8, [r10-0x180]                   
    jgt r8, r9, lbb_9664                            if r8 > r9 { pc += 141 }
    jeq r8, 0, lbb_9658                             if r8 == (0 as i32 as i64 as u64) { pc += 134 }
    ldxdw r1, [r10-0x168]                   
    jne r1, 0, lbb_9661                             if r1 != (0 as i32 as i64 as u64) { pc += 135 }
    ldxdw r9, [r10-0x170]                   
    ldxdw r1, [r10-0x1e0]                   
    jgt r9, r1, lbb_9664                            if r9 > r1 { pc += 135 }
    jeq r9, 0, lbb_9658                             if r9 == (0 as i32 as i64 as u64) { pc += 128 }
    ldxdw r1, [r10-0x240]                   
    jne r1, 0, lbb_9661                             if r1 != (0 as i32 as i64 as u64) { pc += 129 }
    ldxdw r1, [r10-0x1d8]                   
    mov64 r2, r1                                    r2 = r1
    add64 r2, 96                                    r2 += 96   ///  r2 = r2.wrapping_add(96 as i32 as i64 as u64)
    stxdw [r10-0x1f8], r2                   
    ldxdw r1, [r1+0x0]                      
    stxdw [r10-0x1e0], r1                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -144                                  r1 += -144   ///  r1 = r1.wrapping_add(-144 as i32 as i64 as u64)
    stxdw [r10-0x230], r1                   
    ldxdw r2, [r10-0x218]                   
    call function_231                       
    mov64 r1, r10                                   r1 = r10
    add64 r1, -96                                   r1 += -96   ///  r1 = r1.wrapping_add(-96 as i32 as i64 as u64)
    stxdw [r10-0x238], r1                   
    ldxdw r2, [r10-0x220]                   
    call function_231                       
    mov64 r1, r10                                   r1 = r10
    add64 r1, -48                                   r1 += -48   ///  r1 = r1.wrapping_add(-48 as i32 as i64 as u64)
    stxdw [r10-0x220], r1                   
    ldxdw r2, [r10-0x1f0]                   
    call function_231                       
    mov64 r1, r10                                   r1 = r10
    add64 r1, -392                                  r1 += -392   ///  r1 = r1.wrapping_add(-392 as i32 as i64 as u64)
    stxdw [r10-0x1f0], r1                   
    ldxdw r2, [r10-0x1f8]                   
    call function_231                       
    ldxdw r1, [r10-0x1e8]                   
    ldxdw r2, [r1+0x20]                     
    ldxdw r1, [r10-0x1d0]                   
    stxdw [r10-0x1e8], r2                   
    callx r2                                
    stxdw [r10-0xff0], r0                   
    stxdw [r10-0xfe8], r8                   
    ldxdw r1, [r10-0x1f0]                   
    stxdw [r10-0xff8], r1                   
    ldxdw r1, [r10-0x220]                   
    stxdw [r10-0x1000], r1                  
    mov64 r1, r10                                   r1 = r10
    add64 r1, -176                                  r1 += -176   ///  r1 = r1.wrapping_add(-176 as i32 as i64 as u64)
    mov64 r5, r10                                   r5 = r10
    ldxdw r2, [r10-0x1e0]                   
    ldxdw r3, [r10-0x230]                   
    ldxdw r4, [r10-0x238]                   
    call function_6704                      
    ldxw r1, [r10-0xb0]                     
    jeq r1, 20, lbb_9579                            if r1 == (20 as i32 as i64 as u64) { pc += 1 }
    ja lbb_9667                                     if true { pc += 88 }
lbb_9579:
    mov64 r1, r10                                   r1 = r10
    add64 r1, -144                                  r1 += -144   ///  r1 = r1.wrapping_add(-144 as i32 as i64 as u64)
    stxdw [r10-0x1f0], r1                   
    ldxdw r2, [r10-0x218]                   
    call function_231                       
    mov64 r1, r10                                   r1 = r10
    add64 r1, -96                                   r1 += -96   ///  r1 = r1.wrapping_add(-96 as i32 as i64 as u64)
    stxdw [r10-0x220], r1                   
    ldxdw r2, [r10-0x228]                   
    call function_231                       
    mov64 r1, r10                                   r1 = r10
    add64 r1, -48                                   r1 += -48   ///  r1 = r1.wrapping_add(-48 as i32 as i64 as u64)
    stxdw [r10-0x228], r1                   
    ldxdw r2, [r10-0x208]                   
    call function_231                       
    mov64 r8, r10                                   r8 = r10
    add64 r8, -392                                  r8 += -392   ///  r8 = r8.wrapping_add(-392 as i32 as i64 as u64)
    mov64 r1, r8                                    r1 = r8
    ldxdw r2, [r10-0x1f8]                   
    call function_231                       
    ldxdw r1, [r10-0x1d0]                   
    ldxdw r2, [r10-0x1e8]                   
    callx r2                                
    stxdw [r10-0xff0], r0                   
    stxdw [r10-0xfe8], r9                   
    stxdw [r10-0xff8], r8                   
    ldxdw r1, [r10-0x228]                   
    stxdw [r10-0x1000], r1                  
    mov64 r1, r10                                   r1 = r10
    add64 r1, -176                                  r1 += -176   ///  r1 = r1.wrapping_add(-176 as i32 as i64 as u64)
    mov64 r5, r10                                   r5 = r10
    ldxdw r2, [r10-0x1e0]                   
    ldxdw r3, [r10-0x1f0]                   
    ldxdw r4, [r10-0x220]                   
    call function_6704                      
    ldxw r1, [r10-0xb0]                     
    jeq r1, 20, lbb_9617                            if r1 == (20 as i32 as i64 as u64) { pc += 1 }
    ja lbb_9667                                     if true { pc += 50 }
lbb_9617:
    ldxdw r9, [r10-0x1d8]                   
    add64 r9, 384                                   r9 += 384   ///  r9 = r9.wrapping_add(384 as i32 as i64 as u64)
    mov64 r1, r10                                   r1 = r10
    add64 r1, -144                                  r1 += -144   ///  r1 = r1.wrapping_add(-144 as i32 as i64 as u64)
    stxdw [r10-0x1d8], r1                   
    ldxdw r2, [r10-0x218]                   
    call function_231                       
    mov64 r1, r10                                   r1 = r10
    add64 r1, -96                                   r1 += -96   ///  r1 = r1.wrapping_add(-96 as i32 as i64 as u64)
    stxdw [r10-0x1f0], r1                   
    ldxdw r2, [r10-0x210]                   
    call function_231                       
    mov64 r8, r10                                   r8 = r10
    add64 r8, -48                                   r8 += -48   ///  r8 = r8.wrapping_add(-48 as i32 as i64 as u64)
    mov64 r1, r8                                    r1 = r8
    mov64 r2, r9                                    r2 = r9
    call function_231                       
    mov64 r9, r10                                   r9 = r10
    add64 r9, -392                                  r9 += -392   ///  r9 = r9.wrapping_add(-392 as i32 as i64 as u64)
    mov64 r1, r9                                    r1 = r9
    ldxdw r2, [r10-0x200]                   
    call function_231                       
    ldxdw r1, [r10-0x1d0]                   
    ldxdw r2, [r10-0x1e8]                   
    callx r2                                
    stxdw [r10-0xff0], r0                   
    stxdw [r10-0xfe8], r7                   
    stxdw [r10-0xff8], r9                   
    stxdw [r10-0x1000], r8                  
    mov64 r1, r10                                   r1 = r10
    add64 r1, -176                                  r1 += -176   ///  r1 = r1.wrapping_add(-176 as i32 as i64 as u64)
    mov64 r5, r10                                   r5 = r10
    ldxdw r2, [r10-0x1e0]                   
    ldxdw r3, [r10-0x1d8]                   
    ldxdw r4, [r10-0x1f0]                   
    call function_6464                      
    ldxw r1, [r10-0xb0]                     
    jeq r1, 20, lbb_9656                            if r1 == (20 as i32 as i64 as u64) { pc += 1 }
    ja lbb_9667                                     if true { pc += 11 }
lbb_9656:
    mov64 r1, 20                                    r1 = 20 as i32 as i64 as u64
    ja lbb_9467                                     if true { pc += -191 }
lbb_9658:
    lddw r1, 0x1400000000                           r1 load str located at 85899345920
    ja lbb_9453                                     if true { pc += -208 }
lbb_9661:
    lddw r1, 0x1600000000                           r1 load str located at 94489280512
    ja lbb_9453                                     if true { pc += -211 }
lbb_9664:
    lddw r1, 0x1000000000                           r1 load str located at 68719476736
    ja lbb_9453                                     if true { pc += -214 }
lbb_9667:
    ldxw r2, [r10-0x94]                     
    stxw [r10-0xb8], r2                     
    ldxdw r3, [r10-0x9c]                    
    stxdw [r10-0xc0], r3                    
    ldxdw r4, [r10-0xa4]                    
    stxdw [r10-0xc8], r4                    
    ldxdw r5, [r10-0xac]                    
    stxdw [r10-0xd0], r5                    
    ja lbb_9463                                     if true { pc += -213 }

function_9676:
    mov64 r8, r4                                    r8 = r4
    mov64 r9, r3                                    r9 = r3
    mov64 r7, r2                                    r7 = r2
    mov64 r6, r1                                    r6 = r1
    ldxdw r1, [r5-0xff0]                    
    jeq r1, 0, lbb_9728                             if r1 == (0 as i32 as i64 as u64) { pc += 46 }
    jeq r1, 1, lbb_9728                             if r1 == (1 as i32 as i64 as u64) { pc += 45 }
    jeq r1, 2, lbb_9728                             if r1 == (2 as i32 as i64 as u64) { pc += 44 }
    jeq r1, 3, lbb_9728                             if r1 == (3 as i32 as i64 as u64) { pc += 43 }
    jeq r1, 4, lbb_9728                             if r1 == (4 as i32 as i64 as u64) { pc += 42 }
    jeq r1, 5, lbb_9728                             if r1 == (5 as i32 as i64 as u64) { pc += 41 }
    jeq r1, 6, lbb_9728                             if r1 == (6 as i32 as i64 as u64) { pc += 40 }
    jeq r1, 7, lbb_9728                             if r1 == (7 as i32 as i64 as u64) { pc += 39 }
    jeq r1, 8, lbb_9728                             if r1 == (8 as i32 as i64 as u64) { pc += 38 }
    jeq r1, 9, lbb_9728                             if r1 == (9 as i32 as i64 as u64) { pc += 37 }
    jeq r1, 10, lbb_9728                            if r1 == (10 as i32 as i64 as u64) { pc += 36 }
    ldxdw r1, [r5-0xff8]                    
    ldxdw r2, [r5-0x1000]                   
    stxdw [r10-0x1d8], r2                   
    stxdw [r10-0x1d0], r1                   
    ldxdw r2, [r1+0x10]                     
    add64 r2, 16                                    r2 += 16   ///  r2 = r2.wrapping_add(16 as i32 as i64 as u64)
    mov64 r1, r10                                   r1 = r10
    add64 r1, -424                                  r1 += -424   ///  r1 = r1.wrapping_add(-424 as i32 as i64 as u64)
    lddw r3, 0x10002dd00 --> b"\x00\x00\x00\x00\x15\xc4\x02\x00\x18\x00\x00\x00\x00\x00\x00\x00\x18\x03\…        r3 load str located at 4295154944
    call function_211                       
    ldxdw r1, [r10-0x1a8]                   
    ldxdw r2, [r1+0x0]                      
    ldxdw r3, [r1+0x8]                      
    ldxdw r1, [r10-0x1a0]                   
    stxdw [r10-0x1c8], r1                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -392                                  r1 += -392   ///  r1 = r1.wrapping_add(-392 as i32 as i64 as u64)
    call function_10385                     
    ldxdw r1, [r10-0x178]                   
    ldxdw r2, [r10-0x180]                   
    ldxdw r3, [r10-0x188]                   
    jeq r3, 0, lbb_9731                             if r3 == (0 as i32 as i64 as u64) { pc += 16 }
    ldxdw r3, [r10-0x168]                   
    stxdw [r10-0x28], r3                    
    ldxdw r4, [r10-0x170]                   
    stxdw [r10-0x30], r4                    
    stxdw [r6+0x8], r1                      
    stxdw [r6+0x0], r2                      
    stxdw [r6+0x18], r3                     
    stxdw [r6+0x10], r4                     
    ldxdw r2, [r10-0x1c8]                   
    ldxdw r1, [r2+0x0]                      
    add64 r1, -1                                    r1 += -1   ///  r1 = r1.wrapping_add(-1 as i32 as i64 as u64)
    stxdw [r2+0x0], r1                      
    ja lbb_9730                                     if true { pc += 2 }
lbb_9728:
    mov64 r1, 10                                    r1 = 10 as i32 as i64 as u64
    stxdw [r6+0x0], r1                      
lbb_9730:
    exit                                    
lbb_9731:
    stxdw [r10-0x1e0], r2                   
    ldxdw r2, [r10-0x1d8]                   
    ldxdw r4, [r10-0x1d0]                   
    mov64 r2, r4                                    r2 = r4
    add64 r2, 48                                    r2 += 48   ///  r2 = r2.wrapping_add(48 as i32 as i64 as u64)
    stxdw [r10-0x200], r2                   
    mov64 r2, r4                                    r2 = r4
    add64 r2, 144                                   r2 += 144   ///  r2 = r2.wrapping_add(144 as i32 as i64 as u64)
    stxdw [r10-0x1f8], r2                   
    mov64 r2, r4                                    r2 = r4
    add64 r2, 240                                   r2 += 240   ///  r2 = r2.wrapping_add(240 as i32 as i64 as u64)
    stxdw [r10-0x1e8], r2                   
    mov64 r2, r4                                    r2 = r4
    add64 r2, 288                                   r2 += 288   ///  r2 = r2.wrapping_add(288 as i32 as i64 as u64)
    stxdw [r10-0x1f0], r2                   
    mov64 r2, r4                                    r2 = r4
    add64 r2, 336                                   r2 += 336   ///  r2 = r2.wrapping_add(336 as i32 as i64 as u64)
    stxdw [r10-0x208], r2                   
    mov64 r3, r4                                    r3 = r4
    add64 r3, 384                                   r3 += 384   ///  r3 = r3.wrapping_add(384 as i32 as i64 as u64)
    mov64 r2, r4                                    r2 = r4
    add64 r2, 432                                   r2 += 432   ///  r2 = r2.wrapping_add(432 as i32 as i64 as u64)
    mov64 r0, r4                                    r0 = r4
    add64 r0, 480                                   r0 += 480   ///  r0 = r0.wrapping_add(480 as i32 as i64 as u64)
    stxdw [r10-0x190], r1                   
    ldxdw r1, [r10-0x1e0]                   
    stxdw [r10-0x198], r1                   
    ldxdw r1, [r10-0x1c8]                   
    ldxdw r1, [r10-0x1c8]                   
    ldxdw r1, [r1+0x0]                      
    add64 r1, -1                                    r1 += -1   ///  r1 = r1.wrapping_add(-1 as i32 as i64 as u64)
    ldxdw r5, [r10-0x1c8]                   
    stxdw [r5+0x0], r1                      
    ldxdw r1, [r10-0x198]                   
    stxdw [r10-0x1c8], r1                   
    ldxdw r1, [r10-0x190]                   
    stxdw [r10-0x1e0], r1                   
    stxdw [r10-0x220], r3                   
    stxdw [r10-0xfc8], r3                   
    stxdw [r10-0x210], r2                   
    stxdw [r10-0xfc0], r2                   
    ldxdw r1, [r10-0x208]                   
    stxdw [r10-0xfd0], r1                   
    stxdw [r10-0x218], r0                   
    stxdw [r10-0xfd8], r0                   
    ldxdw r1, [r10-0x1f8]                   
    stxdw [r10-0xfe0], r1                   
    ldxdw r1, [r10-0x1f0]                   
    stxdw [r10-0xfe8], r1                   
    ldxdw r1, [r10-0x1e8]                   
    stxdw [r10-0xff0], r1                   
    ldxdw r1, [r10-0x200]                   
    stxdw [r10-0xff8], r1                   
    stxdw [r10-0x1000], r4                  
    mov64 r1, r10                                   r1 = r10
    add64 r1, -392                                  r1 += -392   ///  r1 = r1.wrapping_add(-392 as i32 as i64 as u64)
    mov64 r5, r10                                   r5 = r10
    ldxdw r2, [r10-0x1c8]                   
    ldxdw r3, [r10-0x1e0]                   
    mov64 r4, r7                                    r4 = r7
    call function_6944                      
    ldxw r1, [r10-0x188]                    
    jeq r1, 20, lbb_9795                            if r1 == (20 as i32 as i64 as u64) { pc += 1 }
    ja lbb_9834                                     if true { pc += 39 }
lbb_9795:
    ldxdw r1, [r10-0x1e0]                   
    ldxdw r7, [r1+0x28]                     
    ldxdw r1, [r10-0x1c8]                   
    callx r7                                
    mov64 r1, r10                                   r1 = r10
    add64 r1, -392                                  r1 += -392   ///  r1 = r1.wrapping_add(-392 as i32 as i64 as u64)
    ldxdw r2, [r10-0x1e8]                   
    mov64 r3, r0                                    r3 = r0
    call function_5980                      
    ldxb r1, [r10-0x188]                    
    jeq r1, 0, lbb_9807                             if r1 == (0 as i32 as i64 as u64) { pc += 1 }
    ja lbb_9830                                     if true { pc += 23 }
lbb_9807:
    ldxdw r1, [r10-0x140]                   
    stxdw [r10-0x228], r1                   
    ldxdw r1, [r10-0x1c8]                   
    callx r7                                
    mov64 r1, r10                                   r1 = r10
    add64 r1, -392                                  r1 += -392   ///  r1 = r1.wrapping_add(-392 as i32 as i64 as u64)
    ldxdw r2, [r10-0x1f0]                   
    mov64 r3, r0                                    r3 = r0
    call function_5980                      
    ldxb r1, [r10-0x188]                    
    jeq r1, 0, lbb_9819                             if r1 == (0 as i32 as i64 as u64) { pc += 1 }
    ja lbb_9830                                     if true { pc += 11 }
lbb_9819:
    ldxdw r1, [r10-0x140]                   
    stxdw [r10-0x238], r1                   
    ldxdw r1, [r10-0x1c8]                   
    callx r7                                
    mov64 r1, r10                                   r1 = r10
    add64 r1, -392                                  r1 += -392   ///  r1 = r1.wrapping_add(-392 as i32 as i64 as u64)
    ldxdw r2, [r10-0x1f8]                   
    mov64 r3, r0                                    r3 = r0
    call function_6078                      
    ldxb r1, [r10-0x188]                    
    jeq r1, 0, lbb_9851                             if r1 == (0 as i32 as i64 as u64) { pc += 21 }
lbb_9830:
    ldxb r1, [r10-0x187]                    
    stxw [r6+0x4], r1                       
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    ja lbb_9846                                     if true { pc += 12 }
lbb_9834:
    ldxw r2, [r10-0x16c]                    
    stxw [r10-0x18], r2                     
    ldxdw r3, [r10-0x174]                   
    stxdw [r10-0x20], r3                    
    ldxdw r4, [r10-0x17c]                   
    stxdw [r10-0x28], r4                    
    ldxdw r5, [r10-0x184]                   
    stxdw [r10-0x30], r5                    
lbb_9842:
    stxw [r6+0x1c], r2                      
    stxdw [r6+0x14], r3                     
    stxdw [r6+0xc], r4                      
    stxdw [r6+0x4], r5                      
lbb_9846:
    stxw [r6+0x0], r1                       
lbb_9847:
    mov64 r1, r10                                   r1 = r10
    add64 r1, -408                                  r1 += -408   ///  r1 = r1.wrapping_add(-408 as i32 as i64 as u64)
    call function_82                        
    ja lbb_9730                                     if true { pc += -121 }
lbb_9851:
    ldxdw r7, [r10-0x1d0]                   
    add64 r7, 192                                   r7 += 192   ///  r7 = r7.wrapping_add(192 as i32 as i64 as u64)
    ldxdw r1, [r10-0x158]                   
    stxdw [r10-0x250], r1                   
    ldxdw r1, [r10-0x1e0]                   
    ldxdw r2, [r1+0x68]                     
    ldxdw r1, [r10-0x1c8]                   
    callx r2                                
    stxdw [r10-0x258], r0                   
    ldxdw r1, [r10-0x210]                   
    ldxdw r1, [r1+0x0]                      
    stxdw [r10-0x268], r7                   
    ldxdw r2, [r7+0x0]                      
    mov64 r3, 32                                    r3 = 32 as i32 as i64 as u64
    call function_21867                     
    lsh64 r0, 32                                    r0 <<= 32   ///  r0 = r0.wrapping_shl(32)
    rsh64 r0, 32                                    r0 >>= 32   ///  r0 = r0.wrapping_shr(32)
    jne r0, 0, lbb_9875                             if r0 != (0 as i32 as i64 as u64) { pc += 6 }
    mov64 r7, 0                                     r7 = 0 as i32 as i64 as u64
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    stxdw [r10-0x240], r1                   
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    stxdw [r10-0x248], r1                   
    ja lbb_9896                                     if true { pc += 21 }
lbb_9875:
    ldxdw r1, [r10-0x1e0]                   
    ldxdw r2, [r1+0x60]                     
    ldxdw r1, [r10-0x1c8]                   
    callx r2                                
    mov64 r1, r10                                   r1 = r10
    add64 r1, -448                                  r1 += -448   ///  r1 = r1.wrapping_add(-448 as i32 as i64 as u64)
    mov64 r7, 0                                     r7 = 0 as i32 as i64 as u64
    mov64 r2, r0                                    r2 = r0
    mov64 r3, r9                                    r3 = r9
    mov64 r4, 0                                     r4 = 0 as i32 as i64 as u64
    call function_3127                      
    ldxdw r1, [r10-0x1c0]                   
    jne r1, 0, lbb_9892                             if r1 != (0 as i32 as i64 as u64) { pc += 4 }
    lddw r1, 0x1500000000                           r1 load str located at 90194313216
    stxdw [r6+0x0], r1                      
    ja lbb_9847                                     if true { pc += -45 }
lbb_9892:
    ldxdw r1, [r10-0x1b0]                   
    stxdw [r10-0x248], r1                   
    ldxdw r1, [r10-0x1b8]                   
    stxdw [r10-0x240], r1                   
lbb_9896:
    mov64 r1, r7                                    r1 = r7
    ldxdw r2, [r10-0x248]                   
    sub64 r1, r2                                    r1 -= r2   ///  r1 = r1.wrapping_sub(r2)
    stxdw [r10-0x230], r1                   
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    mov64 r2, 1                                     r2 = 1 as i32 as i64 as u64
    ldxdw r3, [r10-0x240]                   
    jgt r3, r9, lbb_9905                            if r3 > r9 { pc += 1 }
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
lbb_9905:
    ldxdw r3, [r10-0x230]                   
    sub64 r3, r2                                    r3 -= r2   ///  r3 = r3.wrapping_sub(r2)
    stxdw [r10-0x230], r3                   
    mov64 r3, r9                                    r3 = r9
    ldxdw r2, [r10-0x240]                   
    sub64 r3, r2                                    r3 -= r2   ///  r3 = r3.wrapping_sub(r2)
    mov64 r2, 1                                     r2 = 1 as i32 as i64 as u64
    stxdw [r10-0x260], r3                   
    jgt r3, r9, lbb_9915                            if r3 > r9 { pc += 1 }
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
lbb_9915:
    ldxdw r3, [r10-0x230]                   
    jgt r3, r7, lbb_9918                            if r3 > r7 { pc += 1 }
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
lbb_9918:
    ldxdw r3, [r10-0x230]                   
    jeq r3, r7, lbb_9921                            if r3 == r7 { pc += 1 }
    mov64 r2, r1                                    r2 = r1
lbb_9921:
    jne r2, 1, lbb_9926                             if r2 != (1 as i32 as i64 as u64) { pc += 4 }
    lddw r1, 0xd00000000                            r1 load str located at 55834574848
    stxdw [r6+0x0], r1                      
    ja lbb_9847                                     if true { pc += -79 }
lbb_9926:
    ldxdw r1, [r10-0x258]                   
    ldxdw r2, [r1+0x8]                      
    ldxdw r1, [r1+0x10]                     
    ldxdw r0, [r1+0x48]                     
    ldxdw r1, [r10-0x238]                   
    stxdw [r10-0xfe0], r1                   
    ldxdw r1, [r10-0x228]                   
    stxdw [r10-0xff0], r1                   
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    stxdw [r10-0xfd8], r1                   
    stxdw [r10-0xfd0], r1                   
    stxdw [r10-0xfe8], r1                   
    stxdw [r10-0xff8], r1                   
    ldxdw r1, [r10-0x250]                   
    stxdw [r10-0x1000], r1                  
    mov64 r1, r10                                   r1 = r10
    add64 r1, -392                                  r1 += -392   ///  r1 = r1.wrapping_add(-392 as i32 as i64 as u64)
    mov64 r5, r10                                   r5 = r10
    ldxdw r3, [r10-0x260]                   
    ldxdw r4, [r10-0x230]                   
    callx r0                                
    ldxdw r1, [r10-0x188]                   
    jne r1, 0, lbb_9953                             if r1 != (0 as i32 as i64 as u64) { pc += 4 }
lbb_9949:
    lddw r1, 0x1400000000                           r1 load str located at 85899345920
    stxdw [r6+0x0], r1                      
    ja lbb_9847                                     if true { pc += -106 }
lbb_9953:
    ldxdw r1, [r10-0x178]                   
    jne r1, 0, lbb_9976                             if r1 != (0 as i32 as i64 as u64) { pc += 21 }
    ldxdw r9, [r10-0x180]                   
    ldxdw r1, [r10-0x228]                   
    jgt r1, r9, lbb_9959                            if r1 > r9 { pc += 1 }
    ldxdw r9, [r10-0x228]                   
lbb_9959:
    jgt r8, r9, lbb_9972                            if r8 > r9 { pc += 12 }
    ldxdw r1, [r10-0x168]                   
    ldxdw r8, [r10-0x170]                   
    jne r9, 0, lbb_9965                             if r9 != (0 as i32 as i64 as u64) { pc += 2 }
    ldxdw r2, [r10-0x228]                   
    jne r2, 0, lbb_9949                             if r2 != (0 as i32 as i64 as u64) { pc += -16 }
lbb_9965:
    jne r1, 0, lbb_9976                             if r1 != (0 as i32 as i64 as u64) { pc += 10 }
    ldxdw r1, [r10-0x238]                   
    jgt r1, r8, lbb_9969                            if r1 > r8 { pc += 1 }
    ldxdw r8, [r10-0x238]                   
lbb_9969:
    ldxdw r1, [r10-0x1d8]                   
    jgt r1, r8, lbb_9972                            if r1 > r8 { pc += 1 }
    ja lbb_9980                                     if true { pc += 8 }
lbb_9972:
    lddw r1, 0x1000000000                           r1 load str located at 68719476736
    stxdw [r6+0x0], r1                      
    ja lbb_9847                                     if true { pc += -129 }
lbb_9976:
    lddw r1, 0x1600000000                           r1 load str located at 94489280512
    stxdw [r6+0x0], r1                      
    ja lbb_9847                                     if true { pc += -133 }
lbb_9980:
    jne r8, 0, lbb_9983                             if r8 != (0 as i32 as i64 as u64) { pc += 2 }
    ldxdw r1, [r10-0x238]                   
    jne r1, 0, lbb_9949                             if r1 != (0 as i32 as i64 as u64) { pc += -34 }
lbb_9983:
    ldxdw r7, [r10-0x1d0]                   
    add64 r7, 96                                    r7 += 96   ///  r7 = r7.wrapping_add(96 as i32 as i64 as u64)
    ldxdw r1, [r10-0x240]                   
    ldxdw r2, [r10-0x248]                   
    or64 r1, r2                                     r1 |= r2   ///  r1 = r1.or(r2)
    jne r1, 0, lbb_10129                            if r1 != (0 as i32 as i64 as u64) { pc += 140 }
    ldxdw r1, [r10-0x1d0]                   
    ldxdw r1, [r1+0x0]                      
    stxdw [r10-0x1d0], r1                   
lbb_9992:
    mov64 r1, r10                                   r1 = r10
    add64 r1, -144                                  r1 += -144   ///  r1 = r1.wrapping_add(-144 as i32 as i64 as u64)
    ldxdw r2, [r10-0x218]                   
    call function_231                       
    mov64 r1, r10                                   r1 = r10
    add64 r1, -96                                   r1 += -96   ///  r1 = r1.wrapping_add(-96 as i32 as i64 as u64)
    ldxdw r2, [r10-0x268]                   
    call function_231                       
    mov64 r1, r10                                   r1 = r10
    add64 r1, -48                                   r1 += -48   ///  r1 = r1.wrapping_add(-48 as i32 as i64 as u64)
    ldxdw r2, [r10-0x1f8]                   
    call function_231                       
    mov64 r1, r10                                   r1 = r10
    add64 r1, -392                                  r1 += -392   ///  r1 = r1.wrapping_add(-392 as i32 as i64 as u64)
    mov64 r2, r7                                    r2 = r7
    call function_231                       
    ldxdw r1, [r10-0x1e0]                   
    ldxdw r7, [r1+0x20]                     
    ldxdw r1, [r10-0x1c8]                   
    callx r7                                
    ldxdw r1, [r10-0x230]                   
    jne r1, 0, lbb_10015                            if r1 != (0 as i32 as i64 as u64) { pc += 1 }
    ja lbb_10031                                    if true { pc += 16 }
lbb_10015:
    lddw r1, 0x1600000000                           r1 load str located at 94489280512
    stxdw [r6+0x0], r1                      
    mov64 r1, r10                                   r1 = r10
    add64 r1, -392                                  r1 += -392   ///  r1 = r1.wrapping_add(-392 as i32 as i64 as u64)
    call function_56                        
    mov64 r1, r10                                   r1 = r10
    add64 r1, -48                                   r1 += -48   ///  r1 = r1.wrapping_add(-48 as i32 as i64 as u64)
    call function_56                        
    mov64 r1, r10                                   r1 = r10
    add64 r1, -96                                   r1 += -96   ///  r1 = r1.wrapping_add(-96 as i32 as i64 as u64)
    call function_56                        
    mov64 r1, r10                                   r1 = r10
    add64 r1, -144                                  r1 += -144   ///  r1 = r1.wrapping_add(-144 as i32 as i64 as u64)
    call function_56                        
    ja lbb_9847                                     if true { pc += -184 }
lbb_10031:
    stxdw [r10-0xff0], r0                   
    ldxdw r1, [r10-0x260]                   
    stxdw [r10-0xfe8], r1                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -392                                  r1 += -392   ///  r1 = r1.wrapping_add(-392 as i32 as i64 as u64)
    stxdw [r10-0xff8], r1                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -48                                   r1 += -48   ///  r1 = r1.wrapping_add(-48 as i32 as i64 as u64)
    stxdw [r10-0x1000], r1                  
    mov64 r1, r10                                   r1 = r10
    add64 r1, -176                                  r1 += -176   ///  r1 = r1.wrapping_add(-176 as i32 as i64 as u64)
    mov64 r3, r10                                   r3 = r10
    add64 r3, -144                                  r3 += -144   ///  r3 = r3.wrapping_add(-144 as i32 as i64 as u64)
    mov64 r4, r10                                   r4 = r10
    add64 r4, -96                                   r4 += -96   ///  r4 = r4.wrapping_add(-96 as i32 as i64 as u64)
    mov64 r5, r10                                   r5 = r10
    ldxdw r2, [r10-0x1d0]                   
    call function_6224                      
    ldxw r1, [r10-0xb0]                     
    jeq r1, 20, lbb_10052                           if r1 == (20 as i32 as i64 as u64) { pc += 1 }
    ja lbb_10174                                    if true { pc += 122 }
lbb_10052:
    jeq r9, 0, lbb_10090                            if r9 == (0 as i32 as i64 as u64) { pc += 37 }
    mov64 r1, r10                                   r1 = r10
    add64 r1, -144                                  r1 += -144   ///  r1 = r1.wrapping_add(-144 as i32 as i64 as u64)
    stxdw [r10-0x1d8], r1                   
    ldxdw r2, [r10-0x218]                   
    call function_231                       
    mov64 r1, r10                                   r1 = r10
    add64 r1, -96                                   r1 += -96   ///  r1 = r1.wrapping_add(-96 as i32 as i64 as u64)
    stxdw [r10-0x1e0], r1                   
    ldxdw r2, [r10-0x1e8]                   
    call function_231                       
    mov64 r1, r10                                   r1 = r10
    add64 r1, -48                                   r1 += -48   ///  r1 = r1.wrapping_add(-48 as i32 as i64 as u64)
    stxdw [r10-0x1e8], r1                   
    ldxdw r2, [r10-0x208]                   
    call function_231                       
    mov64 r1, r10                                   r1 = r10
    add64 r1, -392                                  r1 += -392   ///  r1 = r1.wrapping_add(-392 as i32 as i64 as u64)
    stxdw [r10-0x1f8], r1                   
    ldxdw r2, [r10-0x200]                   
    call function_231                       
    ldxdw r1, [r10-0x1c8]                   
    callx r7                                
    stxdw [r10-0xff0], r0                   
    stxdw [r10-0xfe8], r9                   
    ldxdw r1, [r10-0x1f8]                   
    stxdw [r10-0xff8], r1                   
    ldxdw r1, [r10-0x1e8]                   
    stxdw [r10-0x1000], r1                  
    mov64 r1, r10                                   r1 = r10
    add64 r1, -176                                  r1 += -176   ///  r1 = r1.wrapping_add(-176 as i32 as i64 as u64)
    mov64 r5, r10                                   r5 = r10
    ldxdw r2, [r10-0x1d0]                   
    ldxdw r3, [r10-0x1d8]                   
    ldxdw r4, [r10-0x1e0]                   
    call function_6704                      
    ldxw r1, [r10-0xb0]                     
    jne r1, 20, lbb_10174                           if r1 != (20 as i32 as i64 as u64) { pc += 84 }
lbb_10090:
    jeq r8, 0, lbb_10127                            if r8 == (0 as i32 as i64 as u64) { pc += 36 }
    mov64 r1, r10                                   r1 = r10
    add64 r1, -144                                  r1 += -144   ///  r1 = r1.wrapping_add(-144 as i32 as i64 as u64)
    stxdw [r10-0x1d8], r1                   
    ldxdw r2, [r10-0x218]                   
    call function_231                       
    mov64 r1, r10                                   r1 = r10
    add64 r1, -96                                   r1 += -96   ///  r1 = r1.wrapping_add(-96 as i32 as i64 as u64)
    stxdw [r10-0x1e0], r1                   
    ldxdw r2, [r10-0x1f0]                   
    call function_231                       
    mov64 r1, r10                                   r1 = r10
    add64 r1, -48                                   r1 += -48   ///  r1 = r1.wrapping_add(-48 as i32 as i64 as u64)
    stxdw [r10-0x1e8], r1                   
    ldxdw r2, [r10-0x220]                   
    call function_231                       
    mov64 r9, r10                                   r9 = r10
    add64 r9, -392                                  r9 += -392   ///  r9 = r9.wrapping_add(-392 as i32 as i64 as u64)
    mov64 r1, r9                                    r1 = r9
    ldxdw r2, [r10-0x200]                   
    call function_231                       
    ldxdw r1, [r10-0x1c8]                   
    callx r7                                
    stxdw [r10-0xff0], r0                   
    stxdw [r10-0xfe8], r8                   
    stxdw [r10-0xff8], r9                   
    ldxdw r1, [r10-0x1e8]                   
    stxdw [r10-0x1000], r1                  
    mov64 r1, r10                                   r1 = r10
    add64 r1, -176                                  r1 += -176   ///  r1 = r1.wrapping_add(-176 as i32 as i64 as u64)
    mov64 r5, r10                                   r5 = r10
    ldxdw r2, [r10-0x1d0]                   
    ldxdw r3, [r10-0x1d8]                   
    ldxdw r4, [r10-0x1e0]                   
    call function_6704                      
    ldxw r1, [r10-0xb0]                     
    jne r1, 20, lbb_10174                           if r1 != (20 as i32 as i64 as u64) { pc += 47 }
lbb_10127:
    mov64 r1, 20                                    r1 = 20 as i32 as i64 as u64
    ja lbb_9846                                     if true { pc += -283 }
lbb_10129:
    ldxdw r1, [r10-0x1d0]                   
    ldxdw r1, [r1+0x0]                      
    stxdw [r10-0x1d0], r1                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -144                                  r1 += -144   ///  r1 = r1.wrapping_add(-144 as i32 as i64 as u64)
    ldxdw r2, [r10-0x218]                   
    call function_231                       
    mov64 r1, r10                                   r1 = r10
    add64 r1, -96                                   r1 += -96   ///  r1 = r1.wrapping_add(-96 as i32 as i64 as u64)
    ldxdw r2, [r10-0x268]                   
    call function_231                       
    mov64 r1, r10                                   r1 = r10
    add64 r1, -48                                   r1 += -48   ///  r1 = r1.wrapping_add(-48 as i32 as i64 as u64)
    ldxdw r2, [r10-0x210]                   
    call function_231                       
    mov64 r1, r10                                   r1 = r10
    add64 r1, -392                                  r1 += -392   ///  r1 = r1.wrapping_add(-392 as i32 as i64 as u64)
    mov64 r2, r7                                    r2 = r7
    call function_231                       
    ldxdw r1, [r10-0x1e0]                   
    ldxdw r2, [r1+0x20]                     
    ldxdw r1, [r10-0x1c8]                   
    callx r2                                
    ldxdw r1, [r10-0x248]                   
    jne r1, 0, lbb_10015                            if r1 != (0 as i32 as i64 as u64) { pc += -139 }
    stxdw [r10-0xff0], r0                   
    ldxdw r1, [r10-0x240]                   
    stxdw [r10-0xfe8], r1                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -392                                  r1 += -392   ///  r1 = r1.wrapping_add(-392 as i32 as i64 as u64)
    stxdw [r10-0xff8], r1                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -48                                   r1 += -48   ///  r1 = r1.wrapping_add(-48 as i32 as i64 as u64)
    stxdw [r10-0x1000], r1                  
    mov64 r1, r10                                   r1 = r10
    add64 r1, -176                                  r1 += -176   ///  r1 = r1.wrapping_add(-176 as i32 as i64 as u64)
    mov64 r3, r10                                   r3 = r10
    add64 r3, -144                                  r3 += -144   ///  r3 = r3.wrapping_add(-144 as i32 as i64 as u64)
    mov64 r4, r10                                   r4 = r10
    add64 r4, -96                                   r4 += -96   ///  r4 = r4.wrapping_add(-96 as i32 as i64 as u64)
    mov64 r5, r10                                   r5 = r10
    ldxdw r2, [r10-0x1d0]                   
    call function_6704                      
    ldxw r1, [r10-0xb0]                     
    jeq r1, 20, lbb_9992                            if r1 == (20 as i32 as i64 as u64) { pc += -182 }
lbb_10174:
    ldxw r2, [r10-0x94]                     
    stxw [r10-0xb8], r2                     
    ldxdw r3, [r10-0x9c]                    
    stxdw [r10-0xc0], r3                    
    ldxdw r4, [r10-0xa4]                    
    stxdw [r10-0xc8], r4                    
    ldxdw r5, [r10-0xac]                    
    stxdw [r10-0xd0], r5                    
    ja lbb_9842                                     if true { pc += -341 }

function_10183:
    mov64 r7, r5                                    r7 = r5
    stxdw [r10-0xc8], r4                    
    mov64 r6, r3                                    r6 = r3
    mov64 r8, r2                                    r8 = r2
    mov64 r9, r1                                    r9 = r1
    ldxdw r2, [r7-0x1000]                   
    ldxdw r3, [r7-0xff8]                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -128                                  r1 += -128   ///  r1 = r1.wrapping_add(-128 as i32 as i64 as u64)
    call function_5827                      
    ldxdw r1, [r10-0x80]                    
    jne r1, 0, lbb_10233                            if r1 != (0 as i32 as i64 as u64) { pc += 38 }
    stxdw [r10-0xd0], r9                    
    ldxdw r1, [r10-0xc8]                    
    stxdw [r10-0xd8], r8                    
    ldxdw r9, [r7-0xff0]                    
    ldxdw r1, [r10-0x60]                    
    stxdw [r10-0xe8], r1                    
    ldxdw r8, [r10-0x68]                    
    ldxdw r1, [r10-0x70]                    
    stxdw [r10-0xe0], r1                    
    ldxw r7, [r10-0x78]                     
    mov64 r1, r10                                   r1 = r10
    add64 r1, -192                                  r1 += -192   ///  r1 = r1.wrapping_add(-192 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -88                                   r2 += -88   ///  r2 = r2.wrapping_add(-88 as i32 as i64 as u64)
    mov64 r3, 64                                    r3 = 64 as i32 as i64 as u64
    call function_21797                     
    jsgt r7, 2, lbb_10242                           if (r7 as i64) > (2 as i32 as i64) { pc += 30 }
    stxdw [r10-0xf8], r9                    
    jeq r7, 0, lbb_10266                            if r7 == (0 as i32 as i64 as u64) { pc += 52 }
    stxdw [r10-0xf0], r8                    
    ldxdw r9, [r10-0xc8]                    
    ldxdw r8, [r10-0xd0]                    
    jeq r7, 1, lbb_10301                            if r7 == (1 as i32 as i64 as u64) { pc += 83 }
    lddw r1, 0x10002c54d --> b"Instruction: DepositAllTokenTypes"        r1 load str located at 4295148877
    mov64 r2, 33                                    r2 = 33 as i32 as i64 as u64
    syscall [invalid]                       
    stxdw [r10-0xff8], r6                   
    stxdw [r10-0xff0], r9                   
    ldxdw r1, [r10-0xe8]                    
    stxdw [r10-0x1000], r1                  
    mov64 r5, r10                                   r5 = r10
    mov64 r1, r8                                    r1 = r8
    ldxdw r2, [r10-0xd8]                    
    ldxdw r3, [r10-0xe0]                    
    ldxdw r4, [r10-0xf0]                    
    call function_9293                      
    ja lbb_10241                                    if true { pc += 8 }
lbb_10233:
    ldxdw r1, [r10-0x78]                    
    ldxdw r2, [r10-0x70]                    
    ldxdw r3, [r10-0x68]                    
    ldxdw r4, [r10-0x60]                    
    stxdw [r9+0x18], r4                     
    stxdw [r9+0x10], r3                     
    stxdw [r9+0x8], r2                      
    stxdw [r9+0x0], r1                      
lbb_10241:
    exit                                    
lbb_10242:
    stxdw [r10-0xf0], r8                    
    jsgt r7, 4, lbb_10250                           if (r7 as i64) > (4 as i32 as i64) { pc += 6 }
    ldxdw r8, [r10-0xd0]                    
    jeq r7, 3, lbb_10314                            if r7 == (3 as i32 as i64 as u64) { pc += 68 }
    lddw r1, 0x10002c4fb --> b"Instruction: DepositSingleTokenTypeExactAmountIn"        r1 load str located at 4295148795
    mov64 r2, 48                                    r2 = 48 as i32 as i64 as u64
    ja lbb_10333                                    if true { pc += 83 }
lbb_10250:
    ldxdw r8, [r10-0xd0]                    
    jeq r7, 5, lbb_10330                            if r7 == (5 as i32 as i64 as u64) { pc += 78 }
    lddw r1, 0x10002c4b0 --> b"Instruction: SwapExactOut"        r1 load str located at 4295148720
    mov64 r2, 25                                    r2 = 25 as i32 as i64 as u64
    syscall [invalid]                       
    stxdw [r10-0x1000], r6                  
    ldxdw r1, [r10-0xc8]                    
    stxdw [r10-0xff8], r1                   
    mov64 r5, r10                                   r5 = r10
    mov64 r1, r8                                    r1 = r8
    ldxdw r2, [r10-0xd8]                    
    ldxdw r3, [r10-0xe0]                    
    ldxdw r4, [r10-0xf0]                    
    call function_8543                      
    ja lbb_10241                                    if true { pc += -25 }
lbb_10266:
    lddw r1, 0x10002c57f --> b"Instruction: Init"        r1 load str located at 4295148927
    mov64 r2, 17                                    r2 = 17 as i32 as i64 as u64
    syscall [invalid]                       
    ldxdw r1, [r10-0xe8]                    
    stxdw [r10-0x70], r1                    
    stxdw [r10-0x78], r8                    
    ldxdw r1, [r10-0xe0]                    
    stxdw [r10-0x80], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -104                                  r1 += -104   ///  r1 = r1.wrapping_add(-104 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -192                                  r2 += -192   ///  r2 = r2.wrapping_add(-192 as i32 as i64 as u64)
    mov64 r3, 40                                    r3 = 40 as i32 as i64 as u64
    call function_21797                     
    ldxdw r1, [r10-0x88]                    
    stxdw [r10-0x8], r1                     
    ldxdw r1, [r10-0x90]                    
    stxdw [r10-0x10], r1                    
    ldxdw r1, [r10-0x98]                    
    stxdw [r10-0x18], r1                    
    ldxdw r1, [r10-0xc8]                    
    stxdw [r10-0xff8], r1                   
    ldxdw r1, [r10-0xf8]                    
    stxdw [r10-0xff0], r1                   
    stxdw [r10-0x1000], r6                  
    mov64 r3, r10                                   r3 = r10
    add64 r3, -128                                  r3 += -128   ///  r3 = r3.wrapping_add(-128 as i32 as i64 as u64)
    mov64 r4, r10                                   r4 = r10
    add64 r4, -24                                   r4 += -24   ///  r4 = r4.wrapping_add(-24 as i32 as i64 as u64)
    mov64 r5, r10                                   r5 = r10
    ldxdw r1, [r10-0xd0]                    
    ldxdw r2, [r10-0xd8]                    
    call function_7151                      
    ja lbb_10241                                    if true { pc += -60 }
lbb_10301:
    lddw r1, 0x10002c56e --> b"Instruction: Swap"        r1 load str located at 4295148910
    mov64 r2, 17                                    r2 = 17 as i32 as i64 as u64
    syscall [invalid]                       
    stxdw [r10-0x1000], r6                  
    stxdw [r10-0xff8], r9                   
    mov64 r5, r10                                   r5 = r10
    mov64 r1, r8                                    r1 = r8
    ldxdw r2, [r10-0xd8]                    
    ldxdw r3, [r10-0xe0]                    
    ldxdw r4, [r10-0xf0]                    
    call function_7796                      
    ja lbb_10241                                    if true { pc += -73 }
lbb_10314:
    lddw r1, 0x10002c52b --> b"Instruction: WithdrawAllTokenTypes"        r1 load str located at 4295148843
    mov64 r2, 34                                    r2 = 34 as i32 as i64 as u64
    syscall [invalid]                       
    stxdw [r10-0xff8], r6                   
    ldxdw r1, [r10-0xc8]                    
    stxdw [r10-0xff0], r1                   
    ldxdw r1, [r10-0xe8]                    
    stxdw [r10-0x1000], r1                  
    mov64 r5, r10                                   r5 = r10
    mov64 r1, r8                                    r1 = r8
    ldxdw r2, [r10-0xd8]                    
    ldxdw r3, [r10-0xe0]                    
    ldxdw r4, [r10-0xf0]                    
    call function_9676                      
    ja lbb_10241                                    if true { pc += -89 }
lbb_10330:
    lddw r1, 0x10002c4c9 --> b"Instruction: WithdrawSingleTokenTypeExactAmountOut"        r1 load str located at 4295148745
    mov64 r2, 50                                    r2 = 50 as i32 as i64 as u64
lbb_10333:
    syscall [invalid]                       
    mov64 r1, 20                                    r1 = 20 as i32 as i64 as u64
    stxw [r8+0x0], r1                       
    ja lbb_10241                                    if true { pc += -96 }

function_10337:
    mov64 r8, r4                                    r8 = r4
    mov64 r7, r3                                    r7 = r3
    mov64 r6, r1                                    r6 = r1
    jeq r8, 0, lbb_10379                            if r8 == (0 as i32 as i64 as u64) { pc += 38 }
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    stxb [r7+0x0], r1                       
    mov64 r1, r10                                   r1 = r10
    add64 r1, -320                                  r1 += -320   ///  r1 = r1.wrapping_add(-320 as i32 as i64 as u64)
    mov64 r3, 320                                   r3 = 320 as i32 as i64 as u64
    call function_21797                     
    jne r8, 324, lbb_10366                          if r8 != (324 as i32 as i64 as u64) { pc += 18 }
    add64 r7, 1                                     r7 += 1   ///  r7 = r7.wrapping_add(1 as i32 as i64 as u64)
    mov64 r1, r10                                   r1 = r10
    add64 r1, -320                                  r1 += -320   ///  r1 = r1.wrapping_add(-320 as i32 as i64 as u64)
    mov64 r2, r7                                    r2 = r7
    mov64 r3, 323                                   r3 = 323 as i32 as i64 as u64
    call function_10592                     
    mov64 r1, 20                                    r1 = 20 as i32 as i64 as u64
    stxw [r6+0x0], r1                       
    ldxdw r1, [r10-0x8]                     
    ldxdw r2, [r1+0x0]                      
    ldxdw r1, [r10-0x10]                    
    callx r2                                
    ldxdw r3, [r10-0x8]                     
    ldxdw r2, [r3+0x8]                      
    jeq r2, 0, lbb_10378                            if r2 == (0 as i32 as i64 as u64) { pc += 15 }
    ldxdw r1, [r10-0x10]                    
    ldxdw r3, [r3+0x10]                     
    ja lbb_10377                                    if true { pc += 11 }
lbb_10366:
    mov64 r1, 3                                     r1 = 3 as i32 as i64 as u64
    stxw [r6+0x0], r1                       
    ldxdw r7, [r10-0x8]                     
    ldxdw r2, [r7+0x0]                      
    ldxdw r6, [r10-0x10]                    
    mov64 r1, r6                                    r1 = r6
    callx r2                                
    ldxdw r2, [r7+0x8]                      
    jeq r2, 0, lbb_10378                            if r2 == (0 as i32 as i64 as u64) { pc += 3 }
    ldxdw r3, [r7+0x10]                     
    mov64 r1, r6                                    r1 = r6
lbb_10377:
    call function_11637                     
lbb_10378:
    exit                                    
lbb_10379:
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
    lddw r3, 0x10002dd40 --> b"\x00\x00\x00\x00\xd9\xca\x02\x00\x14\x00\x00\x00\x00\x00\x00\x00<\x00\x00…        r3 load str located at 4295155008
    call function_19324                     
    syscall [invalid]                       

function_10385:
    mov64 r6, r1                                    r6 = r1
    jeq r3, 0, lbb_10429                            if r3 == (0 as i32 as i64 as u64) { pc += 42 }
    ldxb r1, [r2+0x0]                       
    jeq r1, 1, lbb_10390                            if r1 == (1 as i32 as i64 as u64) { pc += 1 }
    ja lbb_10434                                    if true { pc += 44 }
lbb_10390:
    jeq r3, 324, lbb_10439                          if r3 == (324 as i32 as i64 as u64) { pc += 48 }
    mov64 r9, 3                                     r9 = 3 as i32 as i64 as u64
    stxw [r10-0x140], r9                    
    mov64 r2, r10                                   r2 = r10
    add64 r2, -319                                  r2 += -319   ///  r2 = r2.wrapping_add(-319 as i32 as i64 as u64)
lbb_10395:
    ldxh r1, [r2+0x0]                       
    ldxb r2, [r2+0x2]                       
    ldxdw r3, [r10-0x13c]                   
    stxdw [r10-0x4d0], r3                   
    ldxdw r3, [r10-0x134]                   
    stxdw [r10-0x4c8], r3                   
    ldxdw r3, [r10-0x12c]                   
    stxdw [r10-0x4c0], r3                   
    ldxw r3, [r10-0x124]                    
    stxw [r10-0x4b8], r3                    
    lsh64 r2, 16                                    r2 <<= 16   ///  r2 = r2.wrapping_shl(16)
    or64 r1, r2                                     r1 |= r2   ///  r1 = r1.or(r2)
    lsh64 r1, 8                                     r1 <<= 8   ///  r1 = r1.wrapping_shl(8)
lbb_10408:
    ldxw r2, [r10-0x4b8]                    
    stxw [r10-0x5e8], r2                    
    ldxdw r2, [r10-0x4c0]                   
    stxdw [r10-0x5f0], r2                   
    ldxdw r2, [r10-0x4c8]                   
    stxdw [r10-0x5f8], r2                   
    ldxdw r2, [r10-0x4d0]                   
    stxdw [r10-0x600], r2                   
    or64 r1, r9                                     r1 |= r9   ///  r1 = r1.or(r9)
    stxw [r6+0x8], r1                       
    ldxdw r1, [r10-0x600]                   
    stxdw [r6+0xc], r1                      
    ldxdw r1, [r10-0x5f8]                   
    stxdw [r6+0x14], r1                     
    ldxdw r1, [r10-0x5f0]                   
    stxdw [r6+0x1c], r1                     
    ldxw r1, [r10-0x5e8]                    
    stxw [r6+0x24], r1                      
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    stxdw [r6+0x0], r1                      
    ja lbb_10438                                    if true { pc += 9 }
lbb_10429:
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    stxdw [r6+0x0], r1                      
    mov64 r1, 3                                     r1 = 3 as i32 as i64 as u64
    stxdw [r6+0x8], r1                      
    ja lbb_10438                                    if true { pc += 4 }
lbb_10434:
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    stxdw [r6+0x0], r1                      
    mov64 r1, 9                                     r1 = 9 as i32 as i64 as u64
    stxw [r6+0x8], r1                       
lbb_10438:
    exit                                    
lbb_10439:
    add64 r2, 1                                     r2 += 1   ///  r2 = r2.wrapping_add(1 as i32 as i64 as u64)
    mov64 r1, r10                                   r1 = r10
    add64 r1, -328                                  r1 += -328   ///  r1 = r1.wrapping_add(-328 as i32 as i64 as u64)
    mov64 r3, 323                                   r3 = 323 as i32 as i64 as u64
    call function_10788                     
    mov64 r2, r10                                   r2 = r10
    add64 r2, -319                                  r2 += -319   ///  r2 = r2.wrapping_add(-319 as i32 as i64 as u64)
    ldxb r9, [r10-0x140]                    
    ldxdw r1, [r10-0x148]                   
    jne r1, 0, lbb_10395                            if r1 != (0 as i32 as i64 as u64) { pc += -54 }
    ldxh r1, [r10-0x13f]                    
    stxdw [r10-0x610], r1                   
    ldxb r1, [r10-0x13d]                    
    stxdw [r10-0x618], r1                   
    mov64 r8, r10                                   r8 = r10
    add64 r8, -632                                  r8 += -632   ///  r8 = r8.wrapping_add(-632 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -316                                  r2 += -316   ///  r2 = r2.wrapping_add(-316 as i32 as i64 as u64)
    mov64 r1, r8                                    r1 = r8
    mov64 r3, 300                                   r3 = 300 as i32 as i64 as u64
    call function_21797                     
    ldxdw r1, [r10-0x10]                    
    stxdw [r10-0x608], r1                   
    ldxdw r7, [r10-0x8]                     
    mov64 r1, r10                                   r1 = r10
    add64 r1, -932                                  r1 += -932   ///  r1 = r1.wrapping_add(-932 as i32 as i64 as u64)
    mov64 r2, r8                                    r2 = r8
    mov64 r3, 300                                   r3 = 300 as i32 as i64 as u64
    call function_21797                     
    jeq r9, 0, lbb_10516                            if r9 == (0 as i32 as i64 as u64) { pc += 47 }
    stxdw [r10-0x620], r7                   
    ldxdw r1, [r10-0x608]                   
    mov64 r8, r10                                   r8 = r10
    add64 r8, -1232                                 r8 += -1232   ///  r8 = r8.wrapping_add(-1232 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -932                                  r2 += -932   ///  r2 = r2.wrapping_add(-932 as i32 as i64 as u64)
    mov64 r1, r8                                    r1 = r8
    mov64 r3, 300                                   r3 = 300 as i32 as i64 as u64
    call function_21797                     
    mov64 r1, r10                                   r1 = r10
    add64 r1, -1536                                 r1 += -1536   ///  r1 = r1.wrapping_add(-1536 as i32 as i64 as u64)
    mov64 r2, r8                                    r2 = r8
    mov64 r3, 300                                   r3 = 300 as i32 as i64 as u64
    call function_21797                     
    mov64 r1, 320                                   r1 = 320 as i32 as i64 as u64
    mov64 r2, 8                                     r2 = 8 as i32 as i64 as u64
    call function_11635                     
    mov64 r8, r0                                    r8 = r0
    jne r8, 0, lbb_10492                            if r8 != (0 as i32 as i64 as u64) { pc += 4 }
    mov64 r1, 320                                   r1 = 320 as i32 as i64 as u64
    mov64 r2, 8                                     r2 = 8 as i32 as i64 as u64
    call function_18762                     
    syscall [invalid]                       
lbb_10492:
    ldxdw r2, [r10-0x618]                   
    lsh64 r2, 16                                    r2 <<= 16   ///  r2 = r2.wrapping_shl(16)
    ldxdw r1, [r10-0x610]                   
    or64 r1, r2                                     r1 |= r2   ///  r1 = r1.or(r2)
    lsh64 r1, 8                                     r1 <<= 8   ///  r1 = r1.wrapping_shl(8)
    or64 r1, r9                                     r1 |= r9   ///  r1 = r1.or(r9)
    stxw [r8+0x0], r1                       
    mov64 r1, r8                                    r1 = r8
    add64 r1, 4                                     r1 += 4   ///  r1 = r1.wrapping_add(4 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -1536                                 r2 += -1536   ///  r2 = r2.wrapping_add(-1536 as i32 as i64 as u64)
    mov64 r3, 300                                   r3 = 300 as i32 as i64 as u64
    call function_21797                     
    ldxdw r1, [r10-0x620]                   
    stxdw [r8+0x138], r1                    
    ldxdw r1, [r10-0x608]                   
    stxdw [r8+0x130], r1                    
    stxdw [r6+0x8], r8                      
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    stxdw [r6+0x0], r1                      
    lddw r1, 0x10002dd58 --> b"\x00\x00\x00\x00\x80\x02\x00\x00@\x01\x00\x00\x00\x00\x00\x00\x08\x00\x00…        r1 load str located at 4295155032
    stxdw [r6+0x10], r1                     
    ja lbb_10438                                    if true { pc += -78 }
lbb_10516:
    ldxdw r2, [r7+0x0]                      
    ldxdw r8, [r10-0x608]                   
    mov64 r1, r8                                    r1 = r8
    callx r2                                
    ldxdw r2, [r7+0x8]                      
    jeq r2, 0, lbb_10525                            if r2 == (0 as i32 as i64 as u64) { pc += 3 }
    ldxdw r3, [r7+0x10]                     
    mov64 r1, r8                                    r1 = r8
    call function_11637                     
lbb_10525:
    mov64 r9, 9                                     r9 = 9 as i32 as i64 as u64
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    ja lbb_10408                                    if true { pc += -120 }

function_10528:
    mov64 r3, r2                                    r3 = r2
    mov64 r2, r1                                    r2 = r1
    mov64 r1, r10                                   r1 = r10
    add64 r1, -40                                   r1 += -40   ///  r1 = r1.wrapping_add(-40 as i32 as i64 as u64)
    call function_10385                     
    ldxdw r1, [r10-0x28]                    
    jne r1, 0, lbb_10550                            if r1 != (0 as i32 as i64 as u64) { pc += 15 }
    ldxdw r8, [r10-0x18]                    
    ldxdw r2, [r8+0x18]                     
    ldxdw r7, [r10-0x20]                    
    mov64 r1, r7                                    r1 = r7
    callx r2                                
    mov64 r6, r0                                    r6 = r0
    ldxdw r2, [r8+0x0]                      
    mov64 r1, r7                                    r1 = r7
    callx r2                                
    ldxdw r2, [r8+0x8]                      
    jeq r2, 0, lbb_10553                            if r2 == (0 as i32 as i64 as u64) { pc += 7 }
    ldxdw r3, [r8+0x10]                     
    mov64 r1, r7                                    r1 = r7
    call function_11637                     
    ja lbb_10553                                    if true { pc += 3 }
lbb_10550:
    mov64 r6, 0                                     r6 = 0 as i32 as i64 as u64
    ldxw r1, [r10-0x20]                     
    jeq r1, 14, lbb_10555                           if r1 == (14 as i32 as i64 as u64) { pc += 2 }
lbb_10553:
    mov64 r0, r6                                    r0 = r6
    exit                                    
lbb_10555:
    ldxdw r2, [r10-0x10]                    
    jeq r2, 0, lbb_10553                            if r2 == (0 as i32 as i64 as u64) { pc += -4 }
    ldxdw r1, [r10-0x18]                    
    mov64 r3, 1                                     r3 = 1 as i32 as i64 as u64
    call function_11637                     
    ja lbb_10553                                    if true { pc += -8 }

function_10561:
    ldxb r0, [r1+0x0]                       
    exit                                    

function_10563:
    ldxb r0, [r1+0x1]                       
    exit                                    

function_10565:
    mov64 r0, r1                                    r0 = r1
    add64 r0, 2                                     r0 += 2   ///  r0 = r0.wrapping_add(2 as i32 as i64 as u64)
    exit                                    

function_10568:
    mov64 r0, r1                                    r0 = r1
    add64 r0, 34                                    r0 += 34   ///  r0 = r0.wrapping_add(34 as i32 as i64 as u64)
    exit                                    

function_10571:
    mov64 r0, r1                                    r0 = r1
    add64 r0, 66                                    r0 += 66   ///  r0 = r0.wrapping_add(66 as i32 as i64 as u64)
    exit                                    

function_10574:
    mov64 r0, r1                                    r0 = r1
    add64 r0, 98                                    r0 += 98   ///  r0 = r0.wrapping_add(98 as i32 as i64 as u64)
    exit                                    

function_10577:
    mov64 r0, r1                                    r0 = r1
    add64 r0, 130                                   r0 += 130   ///  r0 = r0.wrapping_add(130 as i32 as i64 as u64)
    exit                                    

function_10580:
    mov64 r0, r1                                    r0 = r1
    add64 r0, 162                                   r0 += 162   ///  r0 = r0.wrapping_add(162 as i32 as i64 as u64)
    exit                                    

function_10583:
    mov64 r0, r1                                    r0 = r1
    add64 r0, 194                                   r0 += 194   ///  r0 = r0.wrapping_add(194 as i32 as i64 as u64)
    exit                                    

function_10586:
    mov64 r0, r1                                    r0 = r1
    add64 r0, 232                                   r0 += 232   ///  r0 = r0.wrapping_add(232 as i32 as i64 as u64)
    exit                                    

function_10589:
    mov64 r0, r1                                    r0 = r1
    add64 r0, 296                                   r0 += 296   ///  r0 = r0.wrapping_add(296 as i32 as i64 as u64)
    exit                                    

function_10592:
    mov64 r6, r2                                    r6 = r2
    mov64 r7, r1                                    r7 = r1
    jgt r3, 322, lbb_10601                          if r3 > (322 as i32 as i64 as u64) { pc += 6 }
    mov64 r1, 323                                   r1 = 323 as i32 as i64 as u64
    mov64 r2, r3                                    r2 = r3
    lddw r3, 0x10002ddc8 --> b"\x00\x00\x00\x00\xd9\xca\x02\x00\x14\x00\x00\x00\x00\x00\x00\x00\xba\x00\…        r3 load str located at 4295155144
    call function_20726                     
    syscall [invalid]                       
lbb_10601:
    ldxb r1, [r7+0x0]                       
    stxb [r6+0x0], r1                       
    ldxb r1, [r7+0x1]                       
    stxb [r6+0x1], r1                       
    mov64 r2, r7                                    r2 = r7
    add64 r2, 2                                     r2 += 2   ///  r2 = r2.wrapping_add(2 as i32 as i64 as u64)
    mov64 r1, r10                                   r1 = r10
    add64 r1, -16                                   r1 += -16   ///  r1 = r1.wrapping_add(-16 as i32 as i64 as u64)
    call function_17891                     
    ldxdw r2, [r10-0x8]                     
    jeq r2, 32, lbb_10617                           if r2 == (32 as i32 as i64 as u64) { pc += 5 }
    mov64 r1, 32                                    r1 = 32 as i32 as i64 as u64
    lddw r3, 0x10002dde0 --> b"\x00\x00\x00\x00\xd9\xca\x02\x00\x14\x00\x00\x00\x00\x00\x00\x00\xca\x00\…        r3 load str located at 4295155168
    call function_20788                     
    syscall [invalid]                       
lbb_10617:
    ldxdw r1, [r10-0x10]                    
    ldxdw r2, [r1+0x18]                     
    stxdw [r6+0x1a], r2                     
    ldxdw r2, [r1+0x10]                     
    stxdw [r6+0x12], r2                     
    ldxdw r2, [r1+0x8]                      
    stxdw [r6+0xa], r2                      
    ldxdw r1, [r1+0x0]                      
    stxdw [r6+0x2], r1                      
    mov64 r2, r7                                    r2 = r7
    add64 r2, 34                                    r2 += 34   ///  r2 = r2.wrapping_add(34 as i32 as i64 as u64)
    mov64 r1, r10                                   r1 = r10
    add64 r1, -32                                   r1 += -32   ///  r1 = r1.wrapping_add(-32 as i32 as i64 as u64)
    call function_17891                     
    ldxdw r2, [r10-0x18]                    
    jeq r2, 32, lbb_10638                           if r2 == (32 as i32 as i64 as u64) { pc += 5 }
    mov64 r1, 32                                    r1 = 32 as i32 as i64 as u64
    lddw r3, 0x10002ddf8 --> b"\x00\x00\x00\x00\xd9\xca\x02\x00\x14\x00\x00\x00\x00\x00\x00\x00\xcb\x00\…        r3 load str located at 4295155192
    call function_20788                     
    syscall [invalid]                       
lbb_10638:
    mov64 r1, r6                                    r1 = r6
    add64 r1, 34                                    r1 += 34   ///  r1 = r1.wrapping_add(34 as i32 as i64 as u64)
    ldxdw r2, [r10-0x20]                    
    ldxdw r3, [r2+0x18]                     
    stxdw [r1+0x18], r3                     
    ldxdw r3, [r2+0x10]                     
    stxdw [r1+0x10], r3                     
    ldxdw r3, [r2+0x8]                      
    stxdw [r1+0x8], r3                      
    ldxdw r2, [r2+0x0]                      
    stxdw [r1+0x0], r2                      
    mov64 r2, r7                                    r2 = r7
    add64 r2, 66                                    r2 += 66   ///  r2 = r2.wrapping_add(66 as i32 as i64 as u64)
    mov64 r1, r10                                   r1 = r10
    add64 r1, -48                                   r1 += -48   ///  r1 = r1.wrapping_add(-48 as i32 as i64 as u64)
    call function_17891                     
    ldxdw r2, [r10-0x28]                    
    jeq r2, 32, lbb_10661                           if r2 == (32 as i32 as i64 as u64) { pc += 5 }
    mov64 r1, 32                                    r1 = 32 as i32 as i64 as u64
    lddw r3, 0x10002de10 --> b"\x00\x00\x00\x00\xd9\xca\x02\x00\x14\x00\x00\x00\x00\x00\x00\x00\xcc\x00\…        r3 load str located at 4295155216
    call function_20788                     
    syscall [invalid]                       
lbb_10661:
    mov64 r1, r6                                    r1 = r6
    add64 r1, 66                                    r1 += 66   ///  r1 = r1.wrapping_add(66 as i32 as i64 as u64)
    ldxdw r2, [r10-0x30]                    
    ldxdw r3, [r2+0x18]                     
    stxdw [r1+0x18], r3                     
    ldxdw r3, [r2+0x10]                     
    stxdw [r1+0x10], r3                     
    ldxdw r3, [r2+0x8]                      
    stxdw [r1+0x8], r3                      
    ldxdw r2, [r2+0x0]                      
    stxdw [r1+0x0], r2                      
    mov64 r2, r7                                    r2 = r7
    add64 r2, 98                                    r2 += 98   ///  r2 = r2.wrapping_add(98 as i32 as i64 as u64)
    mov64 r1, r10                                   r1 = r10
    add64 r1, -64                                   r1 += -64   ///  r1 = r1.wrapping_add(-64 as i32 as i64 as u64)
    call function_17891                     
    ldxdw r2, [r10-0x38]                    
    jeq r2, 32, lbb_10684                           if r2 == (32 as i32 as i64 as u64) { pc += 5 }
    mov64 r1, 32                                    r1 = 32 as i32 as i64 as u64
    lddw r3, 0x10002de28 --> b"\x00\x00\x00\x00\xd9\xca\x02\x00\x14\x00\x00\x00\x00\x00\x00\x00\xcd\x00\…        r3 load str located at 4295155240
    call function_20788                     
    syscall [invalid]                       
lbb_10684:
    mov64 r1, r6                                    r1 = r6
    add64 r1, 98                                    r1 += 98   ///  r1 = r1.wrapping_add(98 as i32 as i64 as u64)
    ldxdw r2, [r10-0x40]                    
    ldxdw r3, [r2+0x18]                     
    stxdw [r1+0x18], r3                     
    ldxdw r3, [r2+0x10]                     
    stxdw [r1+0x10], r3                     
    ldxdw r3, [r2+0x8]                      
    stxdw [r1+0x8], r3                      
    ldxdw r2, [r2+0x0]                      
    stxdw [r1+0x0], r2                      
    mov64 r2, r7                                    r2 = r7
    add64 r2, 130                                   r2 += 130   ///  r2 = r2.wrapping_add(130 as i32 as i64 as u64)
    mov64 r1, r10                                   r1 = r10
    add64 r1, -80                                   r1 += -80   ///  r1 = r1.wrapping_add(-80 as i32 as i64 as u64)
    call function_17891                     
    ldxdw r2, [r10-0x48]                    
    jeq r2, 32, lbb_10707                           if r2 == (32 as i32 as i64 as u64) { pc += 5 }
    mov64 r1, 32                                    r1 = 32 as i32 as i64 as u64
    lddw r3, 0x10002de40 --> b"\x00\x00\x00\x00\xd9\xca\x02\x00\x14\x00\x00\x00\x00\x00\x00\x00\xce\x00\…        r3 load str located at 4295155264
    call function_20788                     
    syscall [invalid]                       
lbb_10707:
    mov64 r1, r6                                    r1 = r6
    add64 r1, 130                                   r1 += 130   ///  r1 = r1.wrapping_add(130 as i32 as i64 as u64)
    ldxdw r2, [r10-0x50]                    
    ldxdw r3, [r2+0x18]                     
    stxdw [r1+0x18], r3                     
    ldxdw r3, [r2+0x10]                     
    stxdw [r1+0x10], r3                     
    ldxdw r3, [r2+0x8]                      
    stxdw [r1+0x8], r3                      
    ldxdw r2, [r2+0x0]                      
    stxdw [r1+0x0], r2                      
    mov64 r2, r7                                    r2 = r7
    add64 r2, 162                                   r2 += 162   ///  r2 = r2.wrapping_add(162 as i32 as i64 as u64)
    mov64 r1, r10                                   r1 = r10
    add64 r1, -96                                   r1 += -96   ///  r1 = r1.wrapping_add(-96 as i32 as i64 as u64)
    call function_17891                     
    ldxdw r2, [r10-0x58]                    
    jeq r2, 32, lbb_10730                           if r2 == (32 as i32 as i64 as u64) { pc += 5 }
    mov64 r1, 32                                    r1 = 32 as i32 as i64 as u64
    lddw r3, 0x10002de58 --> b"\x00\x00\x00\x00\xd9\xca\x02\x00\x14\x00\x00\x00\x00\x00\x00\x00\xcf\x00\…        r3 load str located at 4295155288
    call function_20788                     
    syscall [invalid]                       
lbb_10730:
    mov64 r1, r6                                    r1 = r6
    add64 r1, 162                                   r1 += 162   ///  r1 = r1.wrapping_add(162 as i32 as i64 as u64)
    ldxdw r2, [r10-0x60]                    
    ldxdw r3, [r2+0x18]                     
    stxdw [r1+0x18], r3                     
    ldxdw r3, [r2+0x10]                     
    stxdw [r1+0x10], r3                     
    ldxdw r3, [r2+0x8]                      
    stxdw [r1+0x8], r3                      
    ldxdw r2, [r2+0x0]                      
    stxdw [r1+0x0], r2                      
    mov64 r2, r7                                    r2 = r7
    add64 r2, 194                                   r2 += 194   ///  r2 = r2.wrapping_add(194 as i32 as i64 as u64)
    mov64 r1, r10                                   r1 = r10
    add64 r1, -112                                  r1 += -112   ///  r1 = r1.wrapping_add(-112 as i32 as i64 as u64)
    call function_17891                     
    ldxdw r2, [r10-0x68]                    
    jeq r2, 32, lbb_10753                           if r2 == (32 as i32 as i64 as u64) { pc += 5 }
    mov64 r1, 32                                    r1 = 32 as i32 as i64 as u64
    lddw r3, 0x10002de70 --> b"\x00\x00\x00\x00\xd9\xca\x02\x00\x14\x00\x00\x00\x00\x00\x00\x00\xd0\x00\…        r3 load str located at 4295155312
    call function_20788                     
    syscall [invalid]                       
lbb_10753:
    ldxdw r1, [r10-0x70]                    
    ldxdw r2, [r1+0x18]                     
    stxdw [r6+0xda], r2                     
    ldxdw r2, [r1+0x10]                     
    stxdw [r6+0xd2], r2                     
    ldxdw r2, [r1+0x8]                      
    stxdw [r6+0xca], r2                     
    ldxdw r1, [r1+0x0]                      
    stxdw [r6+0xc2], r1                     
    ldxdw r1, [r7+0xe8]                     
    stxdw [r6+0xe2], r1                     
    ldxdw r1, [r7+0xf0]                     
    stxdw [r6+0xea], r1                     
    ldxdw r1, [r7+0xf8]                     
    stxdw [r6+0xf2], r1                     
    ldxdw r1, [r7+0x100]                    
    stxdw [r6+0xfa], r1                     
    ldxdw r1, [r7+0x108]                    
    stxdw [r6+0x102], r1                    
    ldxdw r1, [r7+0x110]                    
    stxdw [r6+0x10a], r1                    
    ldxdw r1, [r7+0x118]                    
    stxdw [r6+0x112], r1                    
    ldxdw r1, [r7+0x120]                    
    stxdw [r6+0x11a], r1                    
    ldxw r1, [r7+0x128]                     
    stxb [r6+0x122], r1                     
    add64 r6, 291                                   r6 += 291   ///  r6 = r6.wrapping_add(291 as i32 as i64 as u64)
    ldxdw r1, [r7+0x130]                    
    ldxdw r2, [r7+0x138]                    
    ldxdw r4, [r2+0x20]                     
    mov64 r2, r6                                    r2 = r6
    mov64 r3, 32                                    r3 = 32 as i32 as i64 as u64
    callx r4                                
    exit                                    

function_10788:
    jgt r3, 322, lbb_10795                          if r3 > (322 as i32 as i64 as u64) { pc += 6 }
    mov64 r1, 323                                   r1 = 323 as i32 as i64 as u64
    mov64 r2, r3                                    r2 = r3
    lddw r3, 0x10002de88 --> b"\x00\x00\x00\x00\xd9\xca\x02\x00\x14\x00\x00\x00\x00\x00\x00\x00\xd7\x00\…        r3 load str located at 4295155336
    call function_20726                     
    syscall [invalid]                       
lbb_10795:
    mov64 r4, 0                                     r4 = 0 as i32 as i64 as u64
    ldxb r3, [r2+0x0]                       
    jeq r3, 0, lbb_10805                            if r3 == (0 as i32 as i64 as u64) { pc += 7 }
    jeq r3, 1, lbb_10804                            if r3 == (1 as i32 as i64 as u64) { pc += 5 }
    mov64 r2, 1                                     r2 = 1 as i32 as i64 as u64
    stxdw [r1+0x0], r2                      
    mov64 r2, 3                                     r2 = 3 as i32 as i64 as u64
    stxw [r1+0x8], r2                       
    ja lbb_11085                                    if true { pc += 281 }
lbb_10804:
    mov64 r4, 1                                     r4 = 1 as i32 as i64 as u64
lbb_10805:
    stxdw [r10-0x230], r4                   
    stxdw [r10-0x210], r1                   
    mov64 r1, r2                                    r1 = r2
    add64 r1, 290                                   r1 += 290   ///  r1 = r1.wrapping_add(290 as i32 as i64 as u64)
    stxdw [r10-0x218], r1                   
    mov64 r1, r2                                    r1 = r2
    add64 r1, 194                                   r1 += 194   ///  r1 = r1.wrapping_add(194 as i32 as i64 as u64)
    stxdw [r10-0x220], r1                   
    mov64 r1, r2                                    r1 = r2
    add64 r1, 162                                   r1 += 162   ///  r1 = r1.wrapping_add(162 as i32 as i64 as u64)
    stxdw [r10-0x228], r1                   
    mov64 r7, r2                                    r7 = r2
    add64 r7, 130                                   r7 += 130   ///  r7 = r7.wrapping_add(130 as i32 as i64 as u64)
    mov64 r9, r2                                    r9 = r2
    add64 r9, 98                                    r9 += 98   ///  r9 = r9.wrapping_add(98 as i32 as i64 as u64)
    mov64 r8, r2                                    r8 = r2
    add64 r8, 66                                    r8 += 66   ///  r8 = r8.wrapping_add(66 as i32 as i64 as u64)
    mov64 r6, r2                                    r6 = r2
    add64 r6, 34                                    r6 += 34   ///  r6 = r6.wrapping_add(34 as i32 as i64 as u64)
    ldxb r1, [r2+0x1]                       
    stxdw [r10-0x238], r1                   
    add64 r2, 2                                     r2 += 2   ///  r2 = r2.wrapping_add(2 as i32 as i64 as u64)
    ldxdw r1, [r2+0x18]                     
    stxdw [r10-0x10], r1                    
    ldxdw r1, [r2+0x10]                     
    stxdw [r10-0x18], r1                    
    ldxdw r1, [r2+0x8]                      
    stxdw [r10-0x20], r1                    
    ldxdw r1, [r2+0x0]                      
    stxdw [r10-0x28], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -296                                  r1 += -296   ///  r1 = r1.wrapping_add(-296 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -40                                   r2 += -40   ///  r2 = r2.wrapping_add(-40 as i32 as i64 as u64)
    call function_17968                     
    ldxdw r1, [r6+0x18]                     
    stxdw [r10-0x10], r1                    
    ldxdw r1, [r6+0x10]                     
    stxdw [r10-0x18], r1                    
    ldxdw r1, [r6+0x8]                      
    stxdw [r10-0x20], r1                    
    ldxdw r1, [r6+0x0]                      
    stxdw [r10-0x28], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -264                                  r1 += -264   ///  r1 = r1.wrapping_add(-264 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -40                                   r2 += -40   ///  r2 = r2.wrapping_add(-40 as i32 as i64 as u64)
    call function_17968                     
    ldxdw r1, [r8+0x18]                     
    stxdw [r10-0x10], r1                    
    ldxdw r1, [r8+0x10]                     
    stxdw [r10-0x18], r1                    
    ldxdw r1, [r8+0x8]                      
    stxdw [r10-0x20], r1                    
    ldxdw r1, [r8+0x0]                      
    stxdw [r10-0x28], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -232                                  r1 += -232   ///  r1 = r1.wrapping_add(-232 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -40                                   r2 += -40   ///  r2 = r2.wrapping_add(-40 as i32 as i64 as u64)
    call function_17968                     
    ldxdw r1, [r9+0x18]                     
    stxdw [r10-0x10], r1                    
    ldxdw r1, [r9+0x10]                     
    stxdw [r10-0x18], r1                    
    ldxdw r1, [r9+0x8]                      
    stxdw [r10-0x20], r1                    
    ldxdw r1, [r9+0x0]                      
    stxdw [r10-0x28], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -200                                  r1 += -200   ///  r1 = r1.wrapping_add(-200 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -40                                   r2 += -40   ///  r2 = r2.wrapping_add(-40 as i32 as i64 as u64)
    call function_17968                     
    ldxdw r1, [r7+0x18]                     
    stxdw [r10-0x10], r1                    
    ldxdw r1, [r7+0x10]                     
    stxdw [r10-0x18], r1                    
    ldxdw r1, [r7+0x8]                      
    stxdw [r10-0x20], r1                    
    ldxdw r1, [r7+0x0]                      
    stxdw [r10-0x28], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -168                                  r1 += -168   ///  r1 = r1.wrapping_add(-168 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -40                                   r2 += -40   ///  r2 = r2.wrapping_add(-40 as i32 as i64 as u64)
    call function_17968                     
    ldxdw r2, [r10-0x228]                   
    ldxdw r1, [r2+0x18]                     
    stxdw [r10-0x10], r1                    
    ldxdw r1, [r2+0x10]                     
    stxdw [r10-0x18], r1                    
    ldxdw r1, [r2+0x8]                      
    stxdw [r10-0x20], r1                    
    ldxdw r1, [r2+0x0]                      
    stxdw [r10-0x28], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -136                                  r1 += -136   ///  r1 = r1.wrapping_add(-136 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -40                                   r2 += -40   ///  r2 = r2.wrapping_add(-40 as i32 as i64 as u64)
    call function_17968                     
    ldxdw r2, [r10-0x220]                   
    ldxdw r1, [r2+0x18]                     
    stxdw [r10-0x10], r1                    
    ldxdw r1, [r2+0x10]                     
    stxdw [r10-0x18], r1                    
    ldxdw r1, [r2+0x8]                      
    stxdw [r10-0x20], r1                    
    ldxdw r1, [r2+0x0]                      
    stxdw [r10-0x28], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -104                                  r1 += -104   ///  r1 = r1.wrapping_add(-104 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -40                                   r2 += -40   ///  r2 = r2.wrapping_add(-40 as i32 as i64 as u64)
    call function_17968                     
    mov64 r1, r10                                   r1 = r10
    add64 r1, -40                                   r1 += -40   ///  r1 = r1.wrapping_add(-40 as i32 as i64 as u64)
    ldxdw r2, [r10-0x218]                   
    mov64 r3, 33                                    r3 = 33 as i32 as i64 as u64
    call function_1070                      
    mov64 r1, r10                                   r1 = r10
    add64 r1, -32                                   r1 += -32   ///  r1 = r1.wrapping_add(-32 as i32 as i64 as u64)
    ldxdw r2, [r10-0x28]                    
    jeq r2, 0, lbb_10945                            if r2 == (0 as i32 as i64 as u64) { pc += 16 }
    ldxdw r2, [r1+0x18]                     
    stxdw [r10-0x30], r2                    
    ldxdw r3, [r1+0x10]                     
    stxdw [r10-0x38], r3                    
    ldxdw r4, [r1+0x8]                      
    stxdw [r10-0x40], r4                    
    ldxdw r1, [r1+0x0]                      
    stxdw [r10-0x48], r1                    
    ldxdw r5, [r10-0x210]                   
    stxdw [r5+0x20], r2                     
    stxdw [r5+0x18], r3                     
    stxdw [r5+0x10], r4                     
    stxdw [r5+0x8], r1                      
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    stxdw [r5+0x0], r1                      
    ja lbb_11085                                    if true { pc += 140 }
lbb_10945:
    ldxdw r2, [r1+0x10]                     
    stxdw [r10-0x38], r2                    
    ldxdw r3, [r1+0x8]                      
    stxdw [r10-0x40], r3                    
    ldxdw r1, [r1+0x0]                      
    stxdw [r10-0x48], r1                    
    ldxdw r4, [r10-0x210]                   
    stxdw [r4+0x140], r2                    
    stxdw [r4+0x138], r3                    
    stxdw [r4+0x130], r1                    
    ldxdw r1, [r10-0x128]                   
    stxdw [r10-0x148], r1                   
    ldxdw r1, [r10-0x120]                   
    stxdw [r10-0x140], r1                   
    ldxdw r1, [r10-0x118]                   
    stxdw [r10-0x138], r1                   
    ldxdw r1, [r10-0x110]                   
    stxdw [r10-0x130], r1                   
    ldxdw r1, [r10-0x108]                   
    stxdw [r10-0x168], r1                   
    ldxdw r1, [r10-0x100]                   
    stxdw [r10-0x160], r1                   
    ldxdw r1, [r10-0xf8]                    
    stxdw [r10-0x158], r1                   
    ldxdw r1, [r10-0xf0]                    
    stxdw [r10-0x150], r1                   
    ldxdw r1, [r10-0xe8]                    
    stxdw [r10-0x188], r1                   
    ldxdw r1, [r10-0xe0]                    
    stxdw [r10-0x180], r1                   
    ldxdw r1, [r10-0xd8]                    
    stxdw [r10-0x178], r1                   
    ldxdw r1, [r10-0xd0]                    
    stxdw [r10-0x170], r1                   
    ldxdw r1, [r10-0xb0]                    
    stxdw [r10-0x190], r1                   
    ldxdw r1, [r10-0xb8]                    
    stxdw [r10-0x198], r1                   
    ldxdw r1, [r10-0xc0]                    
    stxdw [r10-0x1a0], r1                   
    ldxdw r1, [r10-0xc8]                    
    stxdw [r10-0x1a8], r1                   
    ldxdw r1, [r10-0x90]                    
    stxdw [r10-0x1b0], r1                   
    ldxdw r1, [r10-0x98]                    
    stxdw [r10-0x1b8], r1                   
    ldxdw r1, [r10-0xa0]                    
    stxdw [r10-0x1c0], r1                   
    ldxdw r1, [r10-0xa8]                    
    stxdw [r10-0x1c8], r1                   
    ldxdw r1, [r10-0x70]                    
    stxdw [r10-0x1d0], r1                   
    ldxdw r1, [r10-0x78]                    
    stxdw [r10-0x1d8], r1                   
    ldxdw r1, [r10-0x80]                    
    stxdw [r10-0x1e0], r1                   
    ldxdw r1, [r10-0x88]                    
    stxdw [r10-0x1e8], r1                   
    ldxdw r1, [r10-0x50]                    
    stxdw [r10-0x1f0], r1                   
    ldxdw r1, [r10-0x58]                    
    stxdw [r10-0x1f8], r1                   
    ldxdw r1, [r10-0x60]                    
    stxdw [r10-0x200], r1                   
    ldxdw r1, [r10-0x68]                    
    stxdw [r10-0x208], r1                   
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    stxdw [r4+0x118], r1                    
    stxdw [r4+0x110], r1                    
    ldxdw r2, [r10-0x238]                   
    stxb [r4+0x9], r2                       
    ldxdw r2, [r10-0x230]                   
    stxb [r4+0x8], r2                       
    ldxdw r2, [r10-0x130]                   
    stxdw [r4+0x22], r2                     
    ldxdw r2, [r10-0x138]                   
    stxdw [r4+0x1a], r2                     
    ldxdw r2, [r10-0x140]                   
    stxdw [r4+0x12], r2                     
    ldxdw r2, [r10-0x148]                   
    stxdw [r4+0xa], r2                      
    ldxdw r2, [r10-0x150]                   
    stxdw [r4+0x42], r2                     
    ldxdw r2, [r10-0x158]                   
    stxdw [r4+0x3a], r2                     
    ldxdw r2, [r10-0x160]                   
    stxdw [r4+0x32], r2                     
    ldxdw r2, [r10-0x168]                   
    stxdw [r4+0x2a], r2                     
    ldxdw r2, [r10-0x188]                   
    stxdw [r4+0x4a], r2                     
    ldxdw r2, [r10-0x180]                   
    stxdw [r4+0x52], r2                     
    ldxdw r2, [r10-0x178]                   
    stxdw [r4+0x5a], r2                     
    ldxdw r2, [r10-0x170]                   
    stxdw [r4+0x62], r2                     
    ldxdw r2, [r10-0x1a8]                   
    stxdw [r4+0x6a], r2                     
    ldxdw r2, [r10-0x1a0]                   
    stxdw [r4+0x72], r2                     
    ldxdw r2, [r10-0x198]                   
    stxdw [r4+0x7a], r2                     
    ldxdw r2, [r10-0x190]                   
    stxdw [r4+0x82], r2                     
    ldxdw r2, [r10-0x1c8]                   
    stxdw [r4+0x8a], r2                     
    ldxdw r2, [r10-0x1c0]                   
    stxdw [r4+0x92], r2                     
    ldxdw r2, [r10-0x1b8]                   
    stxdw [r4+0x9a], r2                     
    ldxdw r2, [r10-0x1b0]                   
    stxdw [r4+0xa2], r2                     
    ldxdw r2, [r10-0x1e8]                   
    stxdw [r4+0xaa], r2                     
    ldxdw r2, [r10-0x1e0]                   
    stxdw [r4+0xb2], r2                     
    ldxdw r2, [r10-0x1d8]                   
    stxdw [r4+0xba], r2                     
    ldxdw r2, [r10-0x1d0]                   
    stxdw [r4+0xc2], r2                     
    ldxdw r2, [r10-0x208]                   
    stxdw [r4+0xca], r2                     
    ldxdw r2, [r10-0x200]                   
    stxdw [r4+0xd2], r2                     
    ldxdw r2, [r10-0x1f0]                   
    stxdw [r4+0xe2], r2                     
    ldxdw r2, [r10-0x1f8]                   
    stxdw [r4+0xda], r2                     
    mov64 r2, 2                                     r2 = 2 as i32 as i64 as u64
    stxdw [r4+0xf0], r2                     
    stxdw [r4+0x100], r2                    
    mov64 r2, 10000                                 r2 = 10000 as i32 as i64 as u64
    stxdw [r4+0xf8], r2                     
    stxdw [r4+0x108], r2                    
    mov64 r2, 20                                    r2 = 20 as i32 as i64 as u64
    stxdw [r4+0x120], r2                    
    stxdw [r4+0x0], r1                      
    mov64 r1, 100                                   r1 = 100 as i32 as i64 as u64
    stxdw [r4+0x128], r1                    
lbb_11085:
    exit                                    

function_11086:
    mov64 r7, r1                                    r7 = r1
    mov64 r6, r10                                   r6 = r10
    add64 r6, -24                                   r6 += -24   ///  r6 = r6.wrapping_add(-24 as i32 as i64 as u64)
    mov64 r1, r6                                    r1 = r6
    lddw r3, 0x10002caed --> b"ConstantPriceCurve"        r3 load str located at 4295150317
    mov64 r4, 18                                    r4 = 18 as i32 as i64 as u64
    call function_20540                     
    stxdw [r10-0x8], r7                     
    mov64 r4, r10                                   r4 = r10
    add64 r4, -8                                    r4 += -8   ///  r4 = r4.wrapping_add(-8 as i32 as i64 as u64)
    mov64 r1, r6                                    r1 = r6
    lddw r2, 0x10002caff --> b"token_b_price"        r2 load str located at 4295150335
    mov64 r3, 13                                    r3 = 13 as i32 as i64 as u64
    lddw r5, 0x10002dea0 --> b"\x00\x00\x00\x00x\x02\x00\x00\x08\x00\x00\x00\x00\x00\x00\x00\x08\x00\x00…        r5 load str located at 4295155360
    call function_19584                     
    mov64 r1, r6                                    r1 = r6
    call function_19715                     
    exit                                    

function_11107:
    mov64 r1, r2                                    r1 = r2
    lddw r2, 0x10002cb0c --> b"ConstantProductCurve"        r2 load str located at 4295150348
    mov64 r3, 20                                    r3 = 20 as i32 as i64 as u64
    call function_20526                     
    exit                                    

function_11113:
    mov64 r7, r1                                    r7 = r1
    mov64 r6, r10                                   r6 = r10
    add64 r6, -24                                   r6 += -24   ///  r6 = r6.wrapping_add(-24 as i32 as i64 as u64)
    mov64 r1, r6                                    r1 = r6
    lddw r3, 0x10002cb20 --> b"OffsetCurve"         r3 load str located at 4295150368
    mov64 r4, 11                                    r4 = 11 as i32 as i64 as u64
    call function_20540                     
    stxdw [r10-0x8], r7                     
    mov64 r4, r10                                   r4 = r10
    add64 r4, -8                                    r4 += -8   ///  r4 = r4.wrapping_add(-8 as i32 as i64 as u64)
    mov64 r1, r6                                    r1 = r6
    lddw r2, 0x10002cb2b --> b"token_b_offset"        r2 load str located at 4295150379
    mov64 r3, 14                                    r3 = 14 as i32 as i64 as u64
    lddw r5, 0x10002dea0 --> b"\x00\x00\x00\x00x\x02\x00\x00\x08\x00\x00\x00\x00\x00\x00\x00\x08\x00\x00…        r5 load str located at 4295155360
    call function_19584                     
    mov64 r1, r6                                    r1 = r6
    call function_19715                     
    exit                                    

function_11134:
    mov64 r7, r1                                    r7 = r1
    mov64 r6, r10                                   r6 = r10
    add64 r6, -24                                   r6 += -24   ///  r6 = r6.wrapping_add(-24 as i32 as i64 as u64)
    mov64 r1, r6                                    r1 = r6
    lddw r3, 0x10002cb39 --> b"StableCurve"         r3 load str located at 4295150393
    mov64 r4, 11                                    r4 = 11 as i32 as i64 as u64
    call function_20540                     
    stxdw [r10-0x8], r7                     
    mov64 r4, r10                                   r4 = r10
    add64 r4, -8                                    r4 += -8   ///  r4 = r4.wrapping_add(-8 as i32 as i64 as u64)
    mov64 r1, r6                                    r1 = r6
    lddw r2, 0x10002cb44 --> b"amp"                 r2 load str located at 4295150404
    mov64 r3, 3                                     r3 = 3 as i32 as i64 as u64
    lddw r5, 0x10002dea0 --> b"\x00\x00\x00\x00x\x02\x00\x00\x08\x00\x00\x00\x00\x00\x00\x00\x08\x00\x00…        r5 load str located at 4295155360
    call function_19584                     
    mov64 r1, r6                                    r1 = r6
    call function_19715                     
    exit                                    

entrypoint:
    mov64 r2, r1                                    r2 = r1
    mov64 r1, r10                                   r1 = r10
    add64 r1, -72                                   r1 += -72   ///  r1 = r1.wrapping_add(-72 as i32 as i64 as u64)
    call function_17626                     
    ldxdw r6, [r10-0x38]                    
    ldxdw r8, [r10-0x30]                    
    ldxdw r7, [r10-0x40]                    
    ldxdw r2, [r10-0x48]                    
    ldxdw r1, [r10-0x28]                    
    ldxdw r3, [r10-0x20]                    
    stxdw [r10-0xff8], r3                   
    lddw r3, 0x10002dd18 --> b"\x00\x00\x00\x00-\xc4\x02\x00,\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x0…        r3 load str located at 4295154968
    stxdw [r10-0xff0], r3                   
    stxdw [r10-0x1000], r1                  
    mov64 r1, r10                                   r1 = r10
    add64 r1, -72                                   r1 += -72   ///  r1 = r1.wrapping_add(-72 as i32 as i64 as u64)
    mov64 r5, r10                                   r5 = r10
    mov64 r3, r7                                    r3 = r7
    mov64 r4, r8                                    r4 = r8
    call function_10183                     
    ldxw r9, [r10-0x48]                     
    stxdw [r10-0x60], r6                    
    jeq r9, 20, lbb_11189                           if r9 == (20 as i32 as i64 as u64) { pc += 10 }
    ldxw r1, [r10-0x44]                     
    stxdw [r10-0x68], r1                    
    jsgt r9, 9, lbb_11192                           if (r9 as i64) > (9 as i32 as i64) { pc += 10 }
    jsgt r9, 4, lbb_11199                           if (r9 as i64) > (4 as i32 as i64) { pc += 16 }
    jsgt r9, 1, lbb_11211                           if (r9 as i64) > (1 as i32 as i64) { pc += 27 }
    jeq r9, 0, lbb_11235                            if r9 == (0 as i32 as i64 as u64) { pc += 50 }
    lddw r1, 0x10002c326 --> b"Error: InvalidArgument"        r1 load str located at 4295148326
    mov64 r2, 22                                    r2 = 22 as i32 as i64 as u64
    ja lbb_11289                                    if true { pc += 100 }
lbb_11189:
    mov64 r9, 0                                     r9 = 0 as i32 as i64 as u64
    jeq r8, 0, lbb_11326                            if r8 == (0 as i32 as i64 as u64) { pc += 135 }
    ja lbb_11307                                    if true { pc += 115 }
lbb_11192:
    jsgt r9, 14, lbb_11205                          if (r9 as i64) > (14 as i32 as i64) { pc += 12 }
    jsgt r9, 11, lbb_11217                          if (r9 as i64) > (11 as i32 as i64) { pc += 23 }
    jeq r9, 10, lbb_11246                           if r9 == (10 as i32 as i64 as u64) { pc += 51 }
    lddw r1, 0x10002c1d6 --> b"Error: AccountBorrowFailed"        r1 load str located at 4295147990
    mov64 r2, 26                                    r2 = 26 as i32 as i64 as u64
    ja lbb_11289                                    if true { pc += 90 }
lbb_11199:
    jsgt r9, 6, lbb_11223                           if (r9 as i64) > (6 as i32 as i64) { pc += 23 }
    jeq r9, 5, lbb_11250                            if r9 == (5 as i32 as i64 as u64) { pc += 49 }
    lddw r1, 0x10002c2a5 --> b"Error: IncorrectProgramId"        r1 load str located at 4295148197
    mov64 r2, 25                                    r2 = 25 as i32 as i64 as u64
    ja lbb_11289                                    if true { pc += 84 }
lbb_11205:
    jsgt r9, 16, lbb_11229                          if (r9 as i64) > (16 as i32 as i64) { pc += 23 }
    jeq r9, 15, lbb_11254                           if r9 == (15 as i32 as i64 as u64) { pc += 47 }
    lddw r1, 0x10002c161 --> b"Error: UnsupportedSysvar"        r1 load str located at 4295147873
    mov64 r2, 24                                    r2 = 24 as i32 as i64 as u64
    ja lbb_11289                                    if true { pc += 78 }
lbb_11211:
    jeq r9, 2, lbb_11258                            if r9 == (2 as i32 as i64 as u64) { pc += 46 }
    jeq r9, 3, lbb_11262                            if r9 == (3 as i32 as i64 as u64) { pc += 49 }
    lddw r1, 0x10002c2d6 --> b"Error: AccountDataTooSmall"        r1 load str located at 4295148246
    mov64 r2, 26                                    r2 = 26 as i32 as i64 as u64
    ja lbb_11289                                    if true { pc += 72 }
lbb_11217:
    jeq r9, 12, lbb_11266                           if r9 == (12 as i32 as i64 as u64) { pc += 48 }
    jeq r9, 13, lbb_11270                           if r9 == (13 as i32 as i64 as u64) { pc += 51 }
    lddw r1, 0x10002c194 --> b"Error: BorshIoError"        r1 load str located at 4295147924
    mov64 r2, 19                                    r2 = 19 as i32 as i64 as u64
    ja lbb_11289                                    if true { pc += 66 }
lbb_11223:
    jeq r9, 7, lbb_11274                            if r9 == (7 as i32 as i64 as u64) { pc += 50 }
    jeq r9, 8, lbb_11278                            if r9 == (8 as i32 as i64 as u64) { pc += 53 }
    lddw r1, 0x10002c20b --> b"Error: UninitializedAccount"        r1 load str located at 4295148043
    mov64 r2, 27                                    r2 = 27 as i32 as i64 as u64
    ja lbb_11289                                    if true { pc += 60 }
lbb_11229:
    jeq r9, 17, lbb_11282                           if r9 == (17 as i32 as i64 as u64) { pc += 52 }
    jeq r9, 18, lbb_11286                           if r9 == (18 as i32 as i64 as u64) { pc += 55 }
    lddw r1, 0x10002c110 --> b"Error: ActiveVoteAccountClose"        r1 load str located at 4295147792
    mov64 r2, 29                                    r2 = 29 as i32 as i64 as u64
    ja lbb_11289                                    if true { pc += 54 }
lbb_11235:
    jsgt r1, 13, lbb_11355                          if (r1 as i64) > (13 as i32 as i64) { pc += 119 }
    jsgt r1, 6, lbb_11365                           if (r1 as i64) > (6 as i32 as i64) { pc += 128 }
    jsgt r1, 2, lbb_11383                           if (r1 as i64) > (2 as i32 as i64) { pc += 145 }
    jeq r1, 0, lbb_11443                            if r1 == (0 as i32 as i64 as u64) { pc += 204 }
    jeq r1, 1, lbb_11447                            if r1 == (1 as i32 as i64 as u64) { pc += 207 }
    jeq r1, 2, lbb_11242                            if r1 == (2 as i32 as i64 as u64) { pc += 1 }
    ja lbb_11507                                    if true { pc += 265 }
lbb_11242:
    lddw r1, 0x10002ca3f --> b"Error: The input account owner is not the program address"        r1 load str located at 4295150143
    mov64 r2, 57                                    r2 = 57 as i32 as i64 as u64
    ja lbb_11289                                    if true { pc += 43 }
lbb_11246:
    lddw r1, 0x10002c1f0 --> b"Error: NotEnoughAccountKeys"        r1 load str located at 4295148016
    mov64 r2, 27                                    r2 = 27 as i32 as i64 as u64
    ja lbb_11289                                    if true { pc += 39 }
lbb_11250:
    lddw r1, 0x10002c2be --> b"Error: InsufficientFunds"        r1 load str located at 4295148222
    mov64 r2, 24                                    r2 = 24 as i32 as i64 as u64
    ja lbb_11289                                    if true { pc += 35 }
lbb_11254:
    lddw r1, 0x10002c179 --> b"Error: AccountNotRentExempt"        r1 load str located at 4295147897
    mov64 r2, 27                                    r2 = 27 as i32 as i64 as u64
    ja lbb_11289                                    if true { pc += 31 }
lbb_11258:
    lddw r1, 0x10002c309 --> b"Error: InvalidInstructionData"        r1 load str located at 4295148297
    mov64 r2, 29                                    r2 = 29 as i32 as i64 as u64
    ja lbb_11289                                    if true { pc += 27 }
lbb_11262:
    lddw r1, 0x10002c2f0 --> b"Error: InvalidAccountData"        r1 load str located at 4295148272
    mov64 r2, 25                                    r2 = 25 as i32 as i64 as u64
    ja lbb_11289                                    if true { pc += 23 }
lbb_11266:
    lddw r1, 0x10002c1ba --> b"Error: MaxSeedLengthExceeded"        r1 load str located at 4295147962
    mov64 r2, 28                                    r2 = 28 as i32 as i64 as u64
    ja lbb_11289                                    if true { pc += 19 }
lbb_11270:
    lddw r1, 0x10002c1a7 --> b"Error: InvalidSeeds"        r1 load str located at 4295147943
    mov64 r2, 19                                    r2 = 19 as i32 as i64 as u64
    ja lbb_11289                                    if true { pc += 15 }
lbb_11274:
    lddw r1, 0x10002c286 --> b"Error: MissingRequiredSignature"        r1 load str located at 4295148166
    mov64 r2, 31                                    r2 = 31 as i32 as i64 as u64
    ja lbb_11289                                    if true { pc += 11 }
lbb_11278:
    lddw r1, 0x10002c226 --> b"Error: AccountAlreadyInitialized"        r1 load str located at 4295148070
    mov64 r2, 32                                    r2 = 32 as i32 as i64 as u64
    ja lbb_11289                                    if true { pc += 7 }
lbb_11282:
    lddw r1, 0x10002c14e --> b"Error: IllegalOwner"        r1 load str located at 4295147854
    mov64 r2, 19                                    r2 = 19 as i32 as i64 as u64
    ja lbb_11289                                    if true { pc += 3 }
lbb_11286:
    lddw r1, 0x10002c12d --> b"Error: AccountsDataBudgetExceeded"        r1 load str located at 4295147821
    mov64 r2, 33                                    r2 = 33 as i32 as i64 as u64
lbb_11289:
    syscall [invalid]                       
    ldxdw r1, [r10-0x30]                    
    stxdw [r10-0x8], r1                     
    ldxdw r2, [r10-0x38]                    
    stxdw [r10-0x10], r2                    
    ldxdw r3, [r10-0x40]                    
    stxdw [r10-0x18], r3                    
    ldxdw r4, [r10-0x68]                    
    stxw [r10-0x44], r4                     
    stxw [r10-0x48], r9                     
    stxdw [r10-0x40], r3                    
    stxdw [r10-0x38], r2                    
    stxdw [r10-0x30], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -72                                   r1 += -72   ///  r1 = r1.wrapping_add(-72 as i32 as i64 as u64)
    call function_18142                     
    mov64 r9, r0                                    r9 = r0
    jeq r8, 0, lbb_11326                            if r8 == (0 as i32 as i64 as u64) { pc += 19 }
lbb_11307:
    mul64 r8, 48                                    r8 *= 48   ///  r8 = r8.wrapping_mul(48 as u64)
    mov64 r6, r7                                    r6 = r7
    add64 r6, 16                                    r6 += 16   ///  r6 = r6.wrapping_add(16 as i32 as i64 as u64)
    ja lbb_11340                                    if true { pc += 29 }
lbb_11311:
    ldxdw r1, [r6+0x0]                      
    ldxdw r2, [r1+0x0]                      
    add64 r2, -1                                    r2 += -1   ///  r2 = r2.wrapping_add(-1 as i32 as i64 as u64)
    stxdw [r1+0x0], r2                      
    jne r2, 0, lbb_11323                            if r2 != (0 as i32 as i64 as u64) { pc += 7 }
    ldxdw r2, [r1+0x8]                      
    add64 r2, -1                                    r2 += -1   ///  r2 = r2.wrapping_add(-1 as i32 as i64 as u64)
    stxdw [r1+0x8], r2                      
    jne r2, 0, lbb_11323                            if r2 != (0 as i32 as i64 as u64) { pc += 3 }
    mov64 r2, 40                                    r2 = 40 as i32 as i64 as u64
    mov64 r3, 8                                     r3 = 8 as i32 as i64 as u64
    call function_11637                     
lbb_11323:
    add64 r6, 48                                    r6 += 48   ///  r6 = r6.wrapping_add(48 as i32 as i64 as u64)
    add64 r8, -48                                   r8 += -48   ///  r8 = r8.wrapping_add(-48 as i32 as i64 as u64)
    jne r8, 0, lbb_11340                            if r8 != (0 as i32 as i64 as u64) { pc += 14 }
lbb_11326:
    ldxdw r2, [r10-0x60]                    
    jeq r2, 0, lbb_11353                            if r2 == (0 as i32 as i64 as u64) { pc += 25 }
    mov64 r1, r10                                   r1 = r10
    add64 r1, -88                                   r1 += -88   ///  r1 = r1.wrapping_add(-88 as i32 as i64 as u64)
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
    mov64 r4, 48                                    r4 = 48 as i32 as i64 as u64
    mov64 r5, 0                                     r5 = 0 as i32 as i64 as u64
    call function_21911                     
    ldxdw r2, [r10-0x58]                    
    jeq r2, 0, lbb_11353                            if r2 == (0 as i32 as i64 as u64) { pc += 17 }
    mov64 r1, r7                                    r1 = r7
    mov64 r3, 8                                     r3 = 8 as i32 as i64 as u64
    call function_11637                     
    ja lbb_11353                                    if true { pc += 13 }
lbb_11340:
    ldxdw r1, [r6-0x8]                      
    ldxdw r2, [r1+0x0]                      
    add64 r2, -1                                    r2 += -1   ///  r2 = r2.wrapping_add(-1 as i32 as i64 as u64)
    stxdw [r1+0x0], r2                      
    jne r2, 0, lbb_11311                            if r2 != (0 as i32 as i64 as u64) { pc += -34 }
    ldxdw r2, [r1+0x8]                      
    add64 r2, -1                                    r2 += -1   ///  r2 = r2.wrapping_add(-1 as i32 as i64 as u64)
    stxdw [r1+0x8], r2                      
    jne r2, 0, lbb_11311                            if r2 != (0 as i32 as i64 as u64) { pc += -38 }
    mov64 r2, 32                                    r2 = 32 as i32 as i64 as u64
    mov64 r3, 8                                     r3 = 8 as i32 as i64 as u64
    call function_11637                     
    ja lbb_11311                                    if true { pc += -42 }
lbb_11353:
    mov64 r0, r9                                    r0 = r9
    exit                                    
lbb_11355:
    jsgt r1, 20, lbb_11374                          if (r1 as i64) > (20 as i32 as i64) { pc += 18 }
    jsgt r1, 16, lbb_11391                          if (r1 as i64) > (16 as i32 as i64) { pc += 34 }
    jeq r1, 14, lbb_11451                           if r1 == (14 as i32 as i64 as u64) { pc += 93 }
    jeq r1, 15, lbb_11455                           if r1 == (15 as i32 as i64 as u64) { pc += 96 }
    jeq r1, 16, lbb_11361                           if r1 == (16 as i32 as i64 as u64) { pc += 1 }
    ja lbb_11507                                    if true { pc += 146 }
lbb_11361:
    lddw r1, 0x10002c80c --> b"Error: Swap instruction exceeds desired slippage limit"        r1 load str located at 4295149580
    mov64 r2, 54                                    r2 = 54 as i32 as i64 as u64
    ja lbb_11289                                    if true { pc += -76 }
lbb_11365:
    jsgt r1, 9, lbb_11399                           if (r1 as i64) > (9 as i32 as i64) { pc += 33 }
    jeq r1, 7, lbb_11459                            if r1 == (7 as i32 as i64 as u64) { pc += 92 }
    jeq r1, 8, lbb_11463                            if r1 == (8 as i32 as i64 as u64) { pc += 95 }
    jeq r1, 9, lbb_11370                            if r1 == (9 as i32 as i64 as u64) { pc += 1 }
    ja lbb_11507                                    if true { pc += 137 }
lbb_11370:
    lddw r1, 0x10002c934 --> b"Error: InvalidInput"        r1 load str located at 4295149876
    mov64 r2, 19                                    r2 = 19 as i32 as i64 as u64
    ja lbb_11289                                    if true { pc += -85 }
lbb_11374:
    jsgt r1, 23, lbb_11407                          if (r1 as i64) > (23 as i32 as i64) { pc += 32 }
    jeq r1, 21, lbb_11467                           if r1 == (21 as i32 as i64 as u64) { pc += 91 }
    jeq r1, 22, lbb_11471                           if r1 == (22 as i32 as i64 as u64) { pc += 94 }
    jeq r1, 23, lbb_11379                           if r1 == (23 as i32 as i64 as u64) { pc += 1 }
    ja lbb_11507                                    if true { pc += 128 }
lbb_11379:
    lddw r1, 0x10002c696 --> b"Error: The provided fee does not match the program owner's constraints"        r1 load str located at 4295149206
    mov64 r2, 70                                    r2 = 70 as i32 as i64 as u64
    ja lbb_11289                                    if true { pc += -94 }
lbb_11383:
    jsgt r1, 4, lbb_11415                           if (r1 as i64) > (4 as i32 as i64) { pc += 31 }
    jeq r1, 3, lbb_11475                            if r1 == (3 as i32 as i64 as u64) { pc += 90 }
    jeq r1, 4, lbb_11387                            if r1 == (4 as i32 as i64 as u64) { pc += 1 }
    ja lbb_11507                                    if true { pc += 120 }
lbb_11387:
    lddw r1, 0x10002c9cd --> b"Error: Deserialized account is not an SPL Token mint"        r1 load str located at 4295150029
    mov64 r2, 52                                    r2 = 52 as i32 as i64 as u64
    ja lbb_11289                                    if true { pc += -102 }
lbb_11391:
    jsgt r1, 18, lbb_11422                          if (r1 as i64) > (18 as i32 as i64) { pc += 30 }
    jeq r1, 17, lbb_11479                           if r1 == (17 as i32 as i64 as u64) { pc += 86 }
    jeq r1, 18, lbb_11395                           if r1 == (18 as i32 as i64 as u64) { pc += 1 }
    ja lbb_11507                                    if true { pc += 112 }
lbb_11395:
    lddw r1, 0x10002c7b5 --> b"Error: Pool token mint has a freeze authority"        r1 load str located at 4295149493
    mov64 r2, 45                                    r2 = 45 as i32 as i64 as u64
    ja lbb_11289                                    if true { pc += -110 }
lbb_11399:
    jsgt r1, 11, lbb_11429                          if (r1 as i64) > (11 as i32 as i64) { pc += 29 }
    jeq r1, 10, lbb_11483                           if r1 == (10 as i32 as i64 as u64) { pc += 82 }
    jeq r1, 11, lbb_11403                           if r1 == (11 as i32 as i64 as u64) { pc += 1 }
    ja lbb_11507                                    if true { pc += 104 }
lbb_11403:
    lddw r1, 0x10002c8bb --> b"Error: Address of the provided pool token mint is incorrect"        r1 load str located at 4295149755
    mov64 r2, 59                                    r2 = 59 as i32 as i64 as u64
    ja lbb_11289                                    if true { pc += -118 }
lbb_11407:
    jsgt r1, 25, lbb_11436                          if (r1 as i64) > (25 as i32 as i64) { pc += 28 }
    jeq r1, 24, lbb_11487                           if r1 == (24 as i32 as i64 as u64) { pc += 78 }
    jeq r1, 25, lbb_11411                           if r1 == (25 as i32 as i64 as u64) { pc += 1 }
    ja lbb_11507                                    if true { pc += 96 }
lbb_11411:
    lddw r1, 0x10002c5fb --> b"Error: The provided curve type is not supported by the program owner"        r1 load str located at 4295149051
    mov64 r2, 68                                    r2 = 68 as i32 as i64 as u64
    ja lbb_11289                                    if true { pc += -126 }
lbb_11415:
    jeq r1, 5, lbb_11491                            if r1 == (5 as i32 as i64 as u64) { pc += 75 }
    jeq r1, 6, lbb_11418                            if r1 == (6 as i32 as i64 as u64) { pc += 1 }
    ja lbb_11507                                    if true { pc += 89 }
lbb_11418:
    lddw r1, 0x10002c266 --> b"Error: Input token account empty"        r1 load str located at 4295148134
    mov64 r2, 32                                    r2 = 32 as i32 as i64 as u64
    ja lbb_11289                                    if true { pc += -133 }
lbb_11422:
    jeq r1, 19, lbb_11495                           if r1 == (19 as i32 as i64 as u64) { pc += 72 }
    jeq r1, 20, lbb_11425                           if r1 == (20 as i32 as i64 as u64) { pc += 1 }
    ja lbb_11507                                    if true { pc += 82 }
lbb_11425:
    lddw r1, 0x10002c751 --> b"Error: Given pool token amount results in zero trading tokens"        r1 load str located at 4295149393
    mov64 r2, 61                                    r2 = 61 as i32 as i64 as u64
    ja lbb_11289                                    if true { pc += -140 }
lbb_11429:
    jeq r1, 12, lbb_11499                           if r1 == (12 as i32 as i64 as u64) { pc += 69 }
    jeq r1, 13, lbb_11432                           if r1 == (13 as i32 as i64 as u64) { pc += 1 }
    ja lbb_11507                                    if true { pc += 75 }
lbb_11432:
    lddw r1, 0x10002c88e --> b"Error: CalculationFailure"        r1 load str located at 4295149710
    mov64 r2, 25                                    r2 = 25 as i32 as i64 as u64
    ja lbb_11289                                    if true { pc += -147 }
lbb_11436:
    jeq r1, 26, lbb_11503                           if r1 == (26 as i32 as i64 as u64) { pc += 66 }
    jeq r1, 27, lbb_11439                           if r1 == (27 as i32 as i64 as u64) { pc += 1 }
    ja lbb_11507                                    if true { pc += 68 }
lbb_11439:
    lddw r1, 0x10002c590 --> b"Error: The operation cannot be performed on the given curve"        r1 load str located at 4295148944
    mov64 r2, 59                                    r2 = 59 as i32 as i64 as u64
    ja lbb_11289                                    if true { pc += -154 }
lbb_11443:
    lddw r1, 0x10002cab7 --> b"Error: Swap account already in use"        r1 load str located at 4295150263
    mov64 r2, 34                                    r2 = 34 as i32 as i64 as u64
    ja lbb_11289                                    if true { pc += -158 }
lbb_11447:
    lddw r1, 0x10002ca78 --> b"Error: Invalid program address generated from bump seed and key"        r1 load str located at 4295150200
    mov64 r2, 63                                    r2 = 63 as i32 as i64 as u64
    ja lbb_11289                                    if true { pc += -162 }
lbb_11451:
    lddw r1, 0x10002c875 --> b"Error: InvalidInstruction"        r1 load str located at 4295149685
    mov64 r2, 25                                    r2 = 25 as i32 as i64 as u64
    ja lbb_11289                                    if true { pc += -166 }
lbb_11455:
    lddw r1, 0x10002c842 --> b"Error: Swap input token accounts have the same mint"        r1 load str located at 4295149634
    mov64 r2, 51                                    r2 = 51 as i32 as i64 as u64
    ja lbb_11289                                    if true { pc += -170 }
lbb_11459:
    lddw r1, 0x10002c96a --> b"Error: Pool token mint has a non-zero supply"        r1 load str located at 4295149930
    mov64 r2, 44                                    r2 = 44 as i32 as i64 as u64
    ja lbb_11289                                    if true { pc += -174 }
lbb_11463:
    lddw r1, 0x10002c947 --> b"Error: Token account has a delegate"        r1 load str located at 4295149895
    mov64 r2, 35                                    r2 = 35 as i32 as i64 as u64
    ja lbb_11289                                    if true { pc += -178 }
lbb_11467:
    lddw r1, 0x10002c704 --> b"Error: The fee calculation failed due to overflow, underflow, or unexpect…        r1 load str located at 4295149316
    mov64 r2, 77                                    r2 = 77 as i32 as i64 as u64
    ja lbb_11289                                    if true { pc += -182 }
lbb_11471:
    lddw r1, 0x10002c6dc --> b"Error: Conversion to or from u64 failed."        r1 load str located at 4295149276
    mov64 r2, 40                                    r2 = 40 as i32 as i64 as u64
    ja lbb_11289                                    if true { pc += -186 }
lbb_11475:
    lddw r1, 0x10002ca01 --> b"Error: Output pool account owner cannot be the program address"        r1 load str located at 4295150081
    mov64 r2, 62                                    r2 = 62 as i32 as i64 as u64
    ja lbb_11289                                    if true { pc += -190 }
lbb_11479:
    lddw r1, 0x10002c7e2 --> b"Error: Token account has a close authority"        r1 load str located at 4295149538
    mov64 r2, 42                                    r2 = 42 as i32 as i64 as u64
    ja lbb_11289                                    if true { pc += -194 }
lbb_11483:
    lddw r1, 0x10002c8f6 --> b"Error: Address of the provided swap token account is incorrect"        r1 load str located at 4295149814
    mov64 r2, 62                                    r2 = 62 as i32 as i64 as u64
    ja lbb_11289                                    if true { pc += -198 }
lbb_11487:
    lddw r1, 0x10002c63f --> b"Error: The provided token program does not match the token program expect…        r1 load str located at 4295149119
    mov64 r2, 87                                    r2 = 87 as i32 as i64 as u64
    ja lbb_11289                                    if true { pc += -202 }
lbb_11491:
    lddw r1, 0x10002c996 --> b"Error: Deserialized account is not an SPL Token account"        r1 load str located at 4295149974
    mov64 r2, 55                                    r2 = 55 as i32 as i64 as u64
    ja lbb_11289                                    if true { pc += -206 }
lbb_11495:
    lddw r1, 0x10002c78e --> b"Error: Pool fee token account incorrect"        r1 load str located at 4295149454
    mov64 r2, 39                                    r2 = 39 as i32 as i64 as u64
    ja lbb_11289                                    if true { pc += -210 }
lbb_11499:
    lddw r1, 0x10002c8a7 --> b"Error: InvalidOutput"        r1 load str located at 4295149735
    mov64 r2, 20                                    r2 = 20 as i32 as i64 as u64
    ja lbb_11289                                    if true { pc += -214 }
lbb_11503:
    lddw r1, 0x10002c5cb --> b"Error: The provided curve parameters are invalid"        r1 load str located at 4295149003
    mov64 r2, 48                                    r2 = 48 as i32 as i64 as u64
    ja lbb_11289                                    if true { pc += -218 }
lbb_11507:
    lddw r1, 0x10002c33c --> b"Error: Unknown"        r1 load str located at 4295148348
    mov64 r2, 14                                    r2 = 14 as i32 as i64 as u64
    ja lbb_11289                                    if true { pc += -222 }

function_11511:
    lddw r3, 0x300000000                            r3 load str located at 12884901888
    ldxdw r3, [r3+0x0]                      
    lddw r4, 0x300008000                            r4 load str located at 12884934656
    jeq r3, 0, lbb_11518                            if r3 == (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r4, r3                                    r4 = r3
lbb_11518:
    mov64 r3, r4                                    r3 = r4
    sub64 r3, r1                                    r3 -= r1   ///  r3 = r3.wrapping_sub(r1)
    mov64 r0, 0                                     r0 = 0 as i32 as i64 as u64
    mov64 r5, 1                                     r5 = 1 as i32 as i64 as u64
    jgt r3, r4, lbb_11524                           if r3 > r4 { pc += 1 }
    mov64 r5, 0                                     r5 = 0 as i32 as i64 as u64
lbb_11524:
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    jne r5, 0, lbb_11527                            if r5 != (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r1, r3                                    r1 = r3
lbb_11527:
    neg64 r2                                        r2 = -r2   ///  r2 = (r2 as i64).wrapping_neg() as u64
    and64 r1, r2                                    r1 &= r2   ///  r1 = r1.and(r2)
    lddw r2, 0x300000008                            r2 load str located at 12884901896
    jgt r2, r1, lbb_11536                           if r2 > r1 { pc += 4 }
    lddw r2, 0x300000000                            r2 load str located at 12884901888
    stxdw [r2+0x0], r1                      
    mov64 r0, r1                                    r0 = r1
lbb_11536:
    exit                                    

function_11537:
    exit                                    

function_11538:
    mov64 r5, r1                                    r5 = r1
    lddw r1, 0x300000000                            r1 load str located at 12884901888
    ldxdw r1, [r1+0x0]                      
    lddw r6, 0x300008000                            r6 load str located at 12884934656
    jeq r1, 0, lbb_11546                            if r1 == (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r6, r1                                    r6 = r1
lbb_11546:
    mov64 r1, r6                                    r1 = r6
    sub64 r1, r4                                    r1 -= r4   ///  r1 = r1.wrapping_sub(r4)
    mov64 r0, 0                                     r0 = 0 as i32 as i64 as u64
    mov64 r7, 1                                     r7 = 1 as i32 as i64 as u64
    jgt r1, r6, lbb_11552                           if r1 > r6 { pc += 1 }
    mov64 r7, 0                                     r7 = 0 as i32 as i64 as u64
lbb_11552:
    mov64 r6, 0                                     r6 = 0 as i32 as i64 as u64
    jne r7, 0, lbb_11555                            if r7 != (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r6, r1                                    r6 = r1
lbb_11555:
    neg64 r3                                        r3 = -r3   ///  r3 = (r3 as i64).wrapping_neg() as u64
    and64 r6, r3                                    r6 &= r3   ///  r6 = r6.and(r3)
    lddw r1, 0x300000008                            r1 load str located at 12884901896
    jgt r1, r6, lbb_11570                           if r1 > r6 { pc += 10 }
    lddw r1, 0x300000000                            r1 load str located at 12884901888
    stxdw [r1+0x0], r6                      
    jgt r2, r4, lbb_11565                           if r2 > r4 { pc += 1 }
    mov64 r4, r2                                    r4 = r2
lbb_11565:
    mov64 r1, r6                                    r1 = r6
    mov64 r2, r5                                    r2 = r5
    mov64 r3, r4                                    r3 = r4
    call function_21797                     
    mov64 r0, r6                                    r0 = r6
lbb_11570:
    exit                                    

function_11571:
    mov64 r3, r1                                    r3 = r1
    lddw r1, 0x300000000                            r1 load str located at 12884901888
    ldxdw r1, [r1+0x0]                      
    lddw r4, 0x300008000                            r4 load str located at 12884934656
    jeq r1, 0, lbb_11579                            if r1 == (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r4, r1                                    r4 = r1
lbb_11579:
    mov64 r1, r4                                    r1 = r4
    sub64 r1, r3                                    r1 -= r3   ///  r1 = r1.wrapping_sub(r3)
    mov64 r0, 0                                     r0 = 0 as i32 as i64 as u64
    mov64 r5, 1                                     r5 = 1 as i32 as i64 as u64
    jgt r1, r4, lbb_11585                           if r1 > r4 { pc += 1 }
    mov64 r5, 0                                     r5 = 0 as i32 as i64 as u64
lbb_11585:
    mov64 r6, 0                                     r6 = 0 as i32 as i64 as u64
    jne r5, 0, lbb_11588                            if r5 != (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r6, r1                                    r6 = r1
lbb_11588:
    neg64 r2                                        r2 = -r2   ///  r2 = (r2 as i64).wrapping_neg() as u64
    and64 r6, r2                                    r6 &= r2   ///  r6 = r6.and(r2)
    lddw r1, 0x300000008                            r1 load str located at 12884901896
    jgt r1, r6, lbb_11600                           if r1 > r6 { pc += 7 }
    lddw r1, 0x300000000                            r1 load str located at 12884901888
    stxdw [r1+0x0], r6                      
    mov64 r1, r6                                    r1 = r6
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
    call function_21832                     
    mov64 r0, r6                                    r0 = r6
lbb_11600:
    exit                                    

custom_panic:
    stxdw [r10-0x60], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -16                                   r1 += -16   ///  r1 = r1.wrapping_add(-16 as i32 as i64 as u64)
    stxdw [r10-0x20], r1                    
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    stxdw [r10-0x30], r1                    
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    stxdw [r10-0x18], r1                    
    stxdw [r10-0x38], r1                    
    lddw r1, 0x10002dec0 --> b"\x00\x00\x00\x00P\xc3\x02\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00…        r1 load str located at 4295155392
    stxdw [r10-0x40], r1                    
    lddw r1, 0x100000260 --> b"y\x11\x00\x00\x00\x00\x00\x00\x85\x10\x00\x00\xd6J\x00\x00\x95\x00\x00\x0…        r1 load str located at 4294967904
    stxdw [r10-0x8], r1                     
    mov64 r1, r10                                   r1 = r10
    add64 r1, -96                                   r1 += -96   ///  r1 = r1.wrapping_add(-96 as i32 as i64 as u64)
    stxdw [r10-0x10], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -88                                   r1 += -88   ///  r1 = r1.wrapping_add(-88 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -64                                   r2 += -64   ///  r2 = r2.wrapping_add(-64 as i32 as i64 as u64)
    call function_18768                     
    ldxdw r6, [r10-0x50]                    
    ldxdw r7, [r10-0x58]                    
    ldxdw r2, [r10-0x48]                    
    mov64 r1, r7                                    r1 = r7
    syscall [invalid]                       
    jeq r6, 0, lbb_11634                            if r6 == (0 as i32 as i64 as u64) { pc += 4 }
    mov64 r1, r7                                    r1 = r7
    mov64 r2, r6                                    r2 = r6
    mov64 r3, 1                                     r3 = 1 as i32 as i64 as u64
    call function_11637                     
lbb_11634:
    exit                                    

function_11635:
    call function_11511                     
    exit                                    

function_11637:
    call function_11537                     
    exit                                    

function_11639:
    call function_11538                     
    exit                                    

function_11641:
    call function_11571                     
    exit                                    

function_11643:
    call function_18766                     
    exit                                    

function_11645:
    mov64 r8, r3                                    r8 = r3
    mov64 r7, r2                                    r7 = r2
    mov64 r6, r1                                    r6 = r1
    jeq r8, 0, lbb_11659                            if r8 == (0 as i32 as i64 as u64) { pc += 10 }
    ldxdw r1, [r4+0x10]                     
    jeq r1, 0, lbb_11669                            if r1 == (0 as i32 as i64 as u64) { pc += 18 }
    ldxdw r2, [r4+0x8]                      
    jne r2, 0, lbb_11663                            if r2 != (0 as i32 as i64 as u64) { pc += 10 }
    jeq r7, 0, lbb_11679                            if r7 == (0 as i32 as i64 as u64) { pc += 25 }
    mov64 r1, r7                                    r1 = r7
    mov64 r2, r8                                    r2 = r8
    call function_11635                     
    jeq r0, 0, lbb_11675                            if r0 == (0 as i32 as i64 as u64) { pc += 17 }
    ja lbb_11681                                    if true { pc += 22 }
lbb_11659:
    stxdw [r6+0x8], r7                      
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    mov64 r7, 0                                     r7 = 0 as i32 as i64 as u64
    ja lbb_11683                                    if true { pc += 20 }
lbb_11663:
    ldxdw r1, [r4+0x0]                      
    mov64 r3, r8                                    r3 = r8
    mov64 r4, r7                                    r4 = r7
    call function_11639                     
    jeq r0, 0, lbb_11675                            if r0 == (0 as i32 as i64 as u64) { pc += 7 }
    ja lbb_11681                                    if true { pc += 12 }
lbb_11669:
    jeq r7, 0, lbb_11679                            if r7 == (0 as i32 as i64 as u64) { pc += 9 }
    mov64 r1, r7                                    r1 = r7
    mov64 r2, r8                                    r2 = r8
    call function_11635                     
    jeq r0, 0, lbb_11675                            if r0 == (0 as i32 as i64 as u64) { pc += 1 }
    ja lbb_11681                                    if true { pc += 6 }
lbb_11675:
    stxdw [r6+0x8], r7                      
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    mov64 r7, r8                                    r7 = r8
    ja lbb_11683                                    if true { pc += 4 }
lbb_11679:
    mov64 r7, 0                                     r7 = 0 as i32 as i64 as u64
    mov64 r0, r8                                    r0 = r8
lbb_11681:
    stxdw [r6+0x8], r0                      
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
lbb_11683:
    stxdw [r6+0x0], r1                      
    stxdw [r6+0x10], r7                     
    exit                                    

function_11686:
    mov64 r4, r2                                    r4 = r2
    add64 r4, 1                                     r4 += 1   ///  r4 = r4.wrapping_add(1 as i32 as i64 as u64)
    mov64 r3, 1                                     r3 = 1 as i32 as i64 as u64
    jgt r2, r4, lbb_11691                           if r2 > r4 { pc += 1 }
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
lbb_11691:
    and64 r3, 1                                     r3 &= 1   ///  r3 = r3.and(1)
    jne r3, 0, lbb_11751                            if r3 != (0 as i32 as i64 as u64) { pc += 58 }
    ldxdw r9, [r1+0x8]                      
    mov64 r7, r9                                    r7 = r9
    lsh64 r7, 1                                     r7 <<= 1   ///  r7 = r7.wrapping_shl(1)
    jgt r7, r4, lbb_11698                           if r7 > r4 { pc += 1 }
    mov64 r7, r4                                    r7 = r4
lbb_11698:
    stxdw [r10-0x58], r1                    
    jgt r7, 4, lbb_11701                            if r7 > (4 as i32 as i64 as u64) { pc += 1 }
    mov64 r7, 4                                     r7 = 4 as i32 as i64 as u64
lbb_11701:
    mov64 r1, r10                                   r1 = r10
    add64 r1, -64                                   r1 += -64   ///  r1 = r1.wrapping_add(-64 as i32 as i64 as u64)
    mov64 r6, 0                                     r6 = 0 as i32 as i64 as u64
    mov64 r2, r7                                    r2 = r7
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
    mov64 r4, 34                                    r4 = 34 as i32 as i64 as u64
    mov64 r5, 0                                     r5 = 0 as i32 as i64 as u64
    call function_21911                     
    mov64 r8, 1                                     r8 = 1 as i32 as i64 as u64
    ldxdw r1, [r10-0x38]                    
    jne r1, 0, lbb_11713                            if r1 != (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r8, 0                                     r8 = 0 as i32 as i64 as u64
lbb_11713:
    ldxdw r2, [r10-0x40]                    
    xor64 r8, 1                                     r8 ^= 1   ///  r8 = r8.xor(1)
    jeq r9, 0, lbb_11735                            if r9 == (0 as i32 as i64 as u64) { pc += 19 }
    stxdw [r10-0x60], r2                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -80                                   r1 += -80   ///  r1 = r1.wrapping_add(-80 as i32 as i64 as u64)
    mov64 r2, r9                                    r2 = r9
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
    mov64 r4, 34                                    r4 = 34 as i32 as i64 as u64
    mov64 r5, 0                                     r5 = 0 as i32 as i64 as u64
    call function_21911                     
    mov64 r6, 1                                     r6 = 1 as i32 as i64 as u64
    ldxdw r1, [r10-0x48]                    
    jne r1, 0, lbb_11728                            if r1 != (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r6, 0                                     r6 = 0 as i32 as i64 as u64
lbb_11728:
    ldxdw r1, [r10-0x58]                    
    ldxdw r1, [r1+0x0]                      
    stxdw [r10-0x18], r1                    
    ldxdw r1, [r10-0x50]                    
    stxdw [r10-0x10], r1                    
    xor64 r6, 1                                     r6 ^= 1   ///  r6 = r6.xor(1)
    ldxdw r2, [r10-0x60]                    
lbb_11735:
    stxdw [r10-0x8], r6                     
    mov64 r1, r10                                   r1 = r10
    add64 r1, -48                                   r1 += -48   ///  r1 = r1.wrapping_add(-48 as i32 as i64 as u64)
    mov64 r4, r10                                   r4 = r10
    add64 r4, -24                                   r4 += -24   ///  r4 = r4.wrapping_add(-24 as i32 as i64 as u64)
    mov64 r3, r8                                    r3 = r8
    call function_11645                     
    ldxdw r1, [r10-0x30]                    
    jne r1, 0, lbb_11749                            if r1 != (0 as i32 as i64 as u64) { pc += 5 }
    ldxdw r1, [r10-0x28]                    
    ldxdw r2, [r10-0x58]                    
    stxdw [r2+0x8], r7                      
    stxdw [r2+0x0], r1                      
    exit                                    
lbb_11749:
    ldxdw r2, [r10-0x20]                    
    jne r2, 0, lbb_11753                            if r2 != (0 as i32 as i64 as u64) { pc += 2 }
lbb_11751:
    call function_18745                     
    syscall [invalid]                       
lbb_11753:
    ldxdw r1, [r10-0x28]                    
    call function_18762                     
    syscall [invalid]                       

function_11756:
    mov64 r6, r1                                    r6 = r1
    mov64 r3, r2                                    r3 = r2
    add64 r3, 1                                     r3 += 1   ///  r3 = r3.wrapping_add(1 as i32 as i64 as u64)
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    jgt r2, r3, lbb_11762                           if r2 > r3 { pc += 1 }
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
lbb_11762:
    and64 r1, 1                                     r1 &= 1   ///  r1 = r1.and(1)
    jne r1, 0, lbb_11793                            if r1 != (0 as i32 as i64 as u64) { pc += 29 }
    ldxdw r1, [r6+0x8]                      
    mov64 r7, r1                                    r7 = r1
    lsh64 r7, 1                                     r7 <<= 1   ///  r7 = r7.wrapping_shl(1)
    jgt r7, r3, lbb_11769                           if r7 > r3 { pc += 1 }
    mov64 r7, r3                                    r7 = r3
lbb_11769:
    jgt r7, 8, lbb_11771                            if r7 > (8 as i32 as i64 as u64) { pc += 1 }
    mov64 r7, 8                                     r7 = 8 as i32 as i64 as u64
lbb_11771:
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
    jeq r1, 0, lbb_11777                            if r1 == (0 as i32 as i64 as u64) { pc += 4 }
    ldxdw r2, [r6+0x0]                      
    stxdw [r10-0x10], r1                    
    stxdw [r10-0x18], r2                    
    mov64 r2, 1                                     r2 = 1 as i32 as i64 as u64
lbb_11777:
    stxdw [r10-0x8], r2                     
    mov64 r1, r10                                   r1 = r10
    add64 r1, -48                                   r1 += -48   ///  r1 = r1.wrapping_add(-48 as i32 as i64 as u64)
    mov64 r4, r10                                   r4 = r10
    add64 r4, -24                                   r4 += -24   ///  r4 = r4.wrapping_add(-24 as i32 as i64 as u64)
    mov64 r2, r7                                    r2 = r7
    mov64 r3, 1                                     r3 = 1 as i32 as i64 as u64
    call function_11645                     
    ldxdw r1, [r10-0x30]                    
    jne r1, 0, lbb_11791                            if r1 != (0 as i32 as i64 as u64) { pc += 4 }
    ldxdw r1, [r10-0x28]                    
    stxdw [r6+0x8], r7                      
    stxdw [r6+0x0], r1                      
    exit                                    
lbb_11791:
    ldxdw r2, [r10-0x20]                    
    jne r2, 0, lbb_11795                            if r2 != (0 as i32 as i64 as u64) { pc += 2 }
lbb_11793:
    call function_18745                     
    syscall [invalid]                       
lbb_11795:
    ldxdw r1, [r10-0x28]                    
    call function_18762                     
    syscall [invalid]                       

function_11798:
    mov64 r6, r1                                    r6 = r1
    mov64 r4, r2                                    r4 = r2
    add64 r4, r3                                    r4 += r3   ///  r4 = r4.wrapping_add(r3)
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    jgt r2, r4, lbb_11804                           if r2 > r4 { pc += 1 }
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
lbb_11804:
    and64 r1, 1                                     r1 &= 1   ///  r1 = r1.and(1)
    jne r1, 0, lbb_11835                            if r1 != (0 as i32 as i64 as u64) { pc += 29 }
    ldxdw r1, [r6+0x8]                      
    mov64 r7, r1                                    r7 = r1
    lsh64 r7, 1                                     r7 <<= 1   ///  r7 = r7.wrapping_shl(1)
    jgt r7, r4, lbb_11811                           if r7 > r4 { pc += 1 }
    mov64 r7, r4                                    r7 = r4
lbb_11811:
    jgt r7, 8, lbb_11813                            if r7 > (8 as i32 as i64 as u64) { pc += 1 }
    mov64 r7, 8                                     r7 = 8 as i32 as i64 as u64
lbb_11813:
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
    jeq r1, 0, lbb_11819                            if r1 == (0 as i32 as i64 as u64) { pc += 4 }
    ldxdw r2, [r6+0x0]                      
    stxdw [r10-0x10], r1                    
    stxdw [r10-0x18], r2                    
    mov64 r2, 1                                     r2 = 1 as i32 as i64 as u64
lbb_11819:
    stxdw [r10-0x8], r2                     
    mov64 r1, r10                                   r1 = r10
    add64 r1, -48                                   r1 += -48   ///  r1 = r1.wrapping_add(-48 as i32 as i64 as u64)
    mov64 r4, r10                                   r4 = r10
    add64 r4, -24                                   r4 += -24   ///  r4 = r4.wrapping_add(-24 as i32 as i64 as u64)
    mov64 r2, r7                                    r2 = r7
    mov64 r3, 1                                     r3 = 1 as i32 as i64 as u64
    call function_11645                     
    ldxdw r1, [r10-0x30]                    
    jne r1, 0, lbb_11833                            if r1 != (0 as i32 as i64 as u64) { pc += 4 }
    ldxdw r1, [r10-0x28]                    
    stxdw [r6+0x8], r7                      
    stxdw [r6+0x0], r1                      
    exit                                    
lbb_11833:
    ldxdw r2, [r10-0x20]                    
    jne r2, 0, lbb_11837                            if r2 != (0 as i32 as i64 as u64) { pc += 2 }
lbb_11835:
    call function_18745                     
    syscall [invalid]                       
lbb_11837:
    ldxdw r1, [r10-0x28]                    
    call function_18762                     
    syscall [invalid]                       

function_11840:
    mov64 r7, r2                                    r7 = r2
    mov64 r6, r1                                    r6 = r1
    mov64 r8, 80                                    r8 = 80 as i32 as i64 as u64
    mov64 r1, 80                                    r1 = 80 as i32 as i64 as u64
    mov64 r2, 1                                     r2 = 1 as i32 as i64 as u64
    call function_11635                     
    jne r0, 0, lbb_11851                            if r0 != (0 as i32 as i64 as u64) { pc += 4 }
    mov64 r1, 80                                    r1 = 80 as i32 as i64 as u64
    mov64 r2, 1                                     r2 = 1 as i32 as i64 as u64
    call function_18762                     
    syscall [invalid]                       
lbb_11851:
    stxdw [r6+0x8], r8                      
    stxdw [r6+0x0], r0                      
    ldxw r1, [r7+0x0]                       
    jsgt r1, 8, lbb_11862                           if (r1 as i64) > (8 as i32 as i64) { pc += 7 }
    jsgt r1, 3, lbb_11867                           if (r1 as i64) > (3 as i32 as i64) { pc += 11 }
    jsgt r1, 1, lbb_11889                           if (r1 as i64) > (1 as i32 as i64) { pc += 32 }
    jeq r1, 0, lbb_11901                            if r1 == (0 as i32 as i64 as u64) { pc += 43 }
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    stxb [r0+0x0], r1                       
    stxdw [r6+0x10], r1                     
    ja lbb_12028                                    if true { pc += 166 }
lbb_11862:
    jsgt r1, 12, lbb_11871                          if (r1 as i64) > (12 as i32 as i64) { pc += 8 }
    jsgt r1, 10, lbb_11894                          if (r1 as i64) > (10 as i32 as i64) { pc += 30 }
    jeq r1, 9, lbb_11933                            if r1 == (9 as i32 as i64 as u64) { pc += 68 }
    mov64 r1, 10                                    r1 = 10 as i32 as i64 as u64
    ja lbb_12014                                    if true { pc += 147 }
lbb_11867:
    jsgt r1, 5, lbb_11879                           if (r1 as i64) > (5 as i32 as i64) { pc += 11 }
    jeq r1, 4, lbb_11935                            if r1 == (4 as i32 as i64 as u64) { pc += 66 }
    mov64 r1, 5                                     r1 = 5 as i32 as i64 as u64
    ja lbb_12014                                    if true { pc += 143 }
lbb_11871:
    jsgt r1, 14, lbb_11885                          if (r1 as i64) > (14 as i32 as i64) { pc += 13 }
    jeq r1, 13, lbb_11939                           if r1 == (13 as i32 as i64 as u64) { pc += 66 }
    ldxdw r1, [r7+0x8]                      
    ldxb r2, [r7+0x10]                      
    stxb [r0+0x9], r2                       
    stxdw [r0+0x1], r1                      
    mov64 r1, 14                                    r1 = 14 as i32 as i64 as u64
    ja lbb_11967                                    if true { pc += 88 }
lbb_11879:
    jeq r1, 6, lbb_11945                            if r1 == (6 as i32 as i64 as u64) { pc += 65 }
    jeq r1, 7, lbb_11955                            if r1 == (7 as i32 as i64 as u64) { pc += 74 }
    ldxdw r1, [r7+0x8]                      
    stxdw [r0+0x1], r1                      
    mov64 r1, 8                                     r1 = 8 as i32 as i64 as u64
    ja lbb_11958                                    if true { pc += 73 }
lbb_11885:
    jeq r1, 15, lbb_11962                           if r1 == (15 as i32 as i64 as u64) { pc += 76 }
    jeq r1, 16, lbb_11971                           if r1 == (16 as i32 as i64 as u64) { pc += 84 }
    mov64 r1, 17                                    r1 = 17 as i32 as i64 as u64
    ja lbb_12014                                    if true { pc += 125 }
lbb_11889:
    jeq r1, 2, lbb_12007                            if r1 == (2 as i32 as i64 as u64) { pc += 117 }
    ldxdw r1, [r7+0x8]                      
    stxdw [r0+0x1], r1                      
    mov64 r1, 3                                     r1 = 3 as i32 as i64 as u64
    ja lbb_11958                                    if true { pc += 64 }
lbb_11894:
    jeq r1, 11, lbb_12013                           if r1 == (11 as i32 as i64 as u64) { pc += 118 }
    ldxdw r1, [r7+0x8]                      
    ldxb r2, [r7+0x10]                      
    stxb [r0+0x9], r2                       
    stxdw [r0+0x1], r1                      
    mov64 r1, 12                                    r1 = 12 as i32 as i64 as u64
    ja lbb_11967                                    if true { pc += 66 }
lbb_11901:
    ldxb r1, [r7+0x8]                       
    stxb [r0+0x1], r1                       
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    stxb [r0+0x0], r1                       
    mov64 r1, 2                                     r1 = 2 as i32 as i64 as u64
    stxdw [r6+0x10], r1                     
    mov64 r2, r7                                    r2 = r7
    add64 r2, 9                                     r2 += 9   ///  r2 = r2.wrapping_add(9 as i32 as i64 as u64)
    mov64 r1, r10                                   r1 = r10
    add64 r1, -64                                   r1 += -64   ///  r1 = r1.wrapping_add(-64 as i32 as i64 as u64)
    call function_17891                     
    add64 r7, 44                                    r7 += 44   ///  r7 = r7.wrapping_add(44 as i32 as i64 as u64)
    ldxdw r8, [r6+0x10]                     
    ldxdw r1, [r6+0x8]                      
    sub64 r1, r8                                    r1 -= r8   ///  r1 = r1.wrapping_sub(r8)
    ldxdw r2, [r10-0x40]                    
    ldxdw r9, [r10-0x38]                    
    jge r1, r9, lbb_11926                           if r1 >= r9 { pc += 7 }
    mov64 r1, r6                                    r1 = r6
    stxdw [r10-0x48], r2                    
    mov64 r2, r8                                    r2 = r8
    mov64 r3, r9                                    r3 = r9
    call function_11798                     
    ldxdw r2, [r10-0x48]                    
    ldxdw r8, [r6+0x10]                     
lbb_11926:
    ldxdw r1, [r6+0x0]                      
    add64 r1, r8                                    r1 += r8   ///  r1 = r1.wrapping_add(r8)
    mov64 r3, r9                                    r3 = r9
    call function_21797                     
    add64 r8, r9                                    r8 += r9   ///  r8 = r8.wrapping_add(r9)
    stxdw [r6+0x10], r8                     
    ja lbb_12025                                    if true { pc += 92 }
lbb_11933:
    mov64 r1, 9                                     r1 = 9 as i32 as i64 as u64
    ja lbb_12014                                    if true { pc += 79 }
lbb_11935:
    ldxdw r1, [r7+0x8]                      
    stxdw [r0+0x1], r1                      
    mov64 r1, 4                                     r1 = 4 as i32 as i64 as u64
    ja lbb_11958                                    if true { pc += 19 }
lbb_11939:
    ldxdw r1, [r7+0x8]                      
    ldxb r2, [r7+0x10]                      
    stxb [r0+0x9], r2                       
    stxdw [r0+0x1], r1                      
    mov64 r1, 13                                    r1 = 13 as i32 as i64 as u64
    ja lbb_11967                                    if true { pc += 22 }
lbb_11945:
    mov64 r1, 6                                     r1 = 6 as i32 as i64 as u64
    stxb [r0+0x0], r1                       
    ldxb r2, [r7+0x8]                       
    add64 r7, 12                                    r7 += 12   ///  r7 = r7.wrapping_add(12 as i32 as i64 as u64)
    and64 r2, 3                                     r2 &= 3   ///  r2 = r2.and(3)
    jsgt r2, 1, lbb_12018                           if (r2 as i64) > (1 as i32 as i64) { pc += 67 }
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    jeq r2, 0, lbb_12022                            if r2 == (0 as i32 as i64 as u64) { pc += 69 }
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    ja lbb_12022                                    if true { pc += 67 }
lbb_11955:
    ldxdw r1, [r7+0x8]                      
    stxdw [r0+0x1], r1                      
    mov64 r1, 7                                     r1 = 7 as i32 as i64 as u64
lbb_11958:
    stxb [r0+0x0], r1                       
    mov64 r1, 9                                     r1 = 9 as i32 as i64 as u64
    stxdw [r6+0x10], r1                     
    ja lbb_12028                                    if true { pc += 66 }
lbb_11962:
    ldxdw r1, [r7+0x8]                      
    ldxb r2, [r7+0x10]                      
    stxb [r0+0x9], r2                       
    stxdw [r0+0x1], r1                      
    mov64 r1, 15                                    r1 = 15 as i32 as i64 as u64
lbb_11967:
    stxb [r0+0x0], r1                       
    mov64 r1, 10                                    r1 = 10 as i32 as i64 as u64
    stxdw [r6+0x10], r1                     
    ja lbb_12028                                    if true { pc += 57 }
lbb_11971:
    ldxdw r1, [r7+0x20]                     
    stxdw [r10-0x8], r1                     
    ldxdw r1, [r7+0x18]                     
    stxdw [r10-0x10], r1                    
    ldxdw r1, [r7+0x10]                     
    stxdw [r10-0x18], r1                    
    ldxdw r1, [r7+0x8]                      
    stxdw [r10-0x20], r1                    
    mov64 r1, 16                                    r1 = 16 as i32 as i64 as u64
    stxb [r0+0x0], r1                       
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    stxdw [r6+0x10], r1                     
    mov64 r1, r10                                   r1 = r10
    add64 r1, -48                                   r1 += -48   ///  r1 = r1.wrapping_add(-48 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -32                                   r2 += -32   ///  r2 = r2.wrapping_add(-32 as i32 as i64 as u64)
    call function_17891                     
    ldxdw r7, [r6+0x10]                     
    ldxdw r1, [r6+0x8]                      
    sub64 r1, r7                                    r1 -= r7   ///  r1 = r1.wrapping_sub(r7)
    ldxdw r9, [r10-0x30]                    
    ldxdw r8, [r10-0x28]                    
    jge r1, r8, lbb_11999                           if r1 >= r8 { pc += 5 }
    mov64 r1, r6                                    r1 = r6
    mov64 r2, r7                                    r2 = r7
    mov64 r3, r8                                    r3 = r8
    call function_11798                     
    ldxdw r7, [r6+0x10]                     
lbb_11999:
    ldxdw r1, [r6+0x0]                      
    add64 r1, r7                                    r1 += r7   ///  r1 = r1.wrapping_add(r7)
    mov64 r2, r9                                    r2 = r9
    mov64 r3, r8                                    r3 = r8
    call function_21797                     
    add64 r7, r8                                    r7 += r8   ///  r7 = r7.wrapping_add(r8)
    stxdw [r6+0x10], r7                     
    ja lbb_12028                                    if true { pc += 21 }
lbb_12007:
    ldxb r1, [r7+0x8]                       
    stxb [r0+0x1], r1                       
    mov64 r1, 2                                     r1 = 2 as i32 as i64 as u64
    stxb [r0+0x0], r1                       
    stxdw [r6+0x10], r1                     
    ja lbb_12028                                    if true { pc += 15 }
lbb_12013:
    mov64 r1, 11                                    r1 = 11 as i32 as i64 as u64
lbb_12014:
    stxb [r0+0x0], r1                       
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    stxdw [r6+0x10], r1                     
    ja lbb_12028                                    if true { pc += 10 }
lbb_12018:
    jeq r2, 2, lbb_12021                            if r2 == (2 as i32 as i64 as u64) { pc += 2 }
    mov64 r1, 3                                     r1 = 3 as i32 as i64 as u64
    ja lbb_12022                                    if true { pc += 1 }
lbb_12021:
    mov64 r1, 2                                     r1 = 2 as i32 as i64 as u64
lbb_12022:
    stxb [r0+0x1], r1                       
    mov64 r1, 2                                     r1 = 2 as i32 as i64 as u64
    stxdw [r6+0x10], r1                     
lbb_12025:
    mov64 r1, r7                                    r1 = r7
    mov64 r2, r6                                    r2 = r6
    call function_12029                     
lbb_12028:
    exit                                    

function_12029:
    mov64 r6, r2                                    r6 = r2
    mov64 r8, r1                                    r8 = r1
    ldxw r1, [r8+0x0]                       
    jne r1, 0, lbb_12046                            if r1 != (0 as i32 as i64 as u64) { pc += 13 }
    ldxdw r2, [r6+0x10]                     
    ldxdw r1, [r6+0x8]                      
    jne r2, r1, lbb_12039                           if r2 != r1 { pc += 3 }
    mov64 r1, r6                                    r1 = r6
    call function_11756                     
    ldxdw r2, [r6+0x10]                     
lbb_12039:
    ldxdw r1, [r6+0x0]                      
    add64 r1, r2                                    r1 += r2   ///  r1 = r1.wrapping_add(r2)
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
    stxb [r1+0x0], r3                       
    add64 r2, 1                                     r2 += 1   ///  r2 = r2.wrapping_add(1 as i32 as i64 as u64)
    stxdw [r6+0x10], r2                     
    ja lbb_12096                                    if true { pc += 50 }
lbb_12046:
    add64 r8, 4                                     r8 += 4   ///  r8 = r8.wrapping_add(4 as i32 as i64 as u64)
    ldxdw r1, [r6+0x8]                      
    ldxdw r7, [r6+0x10]                     
    jne r7, r1, lbb_12055                           if r7 != r1 { pc += 5 }
    mov64 r1, r6                                    r1 = r6
    mov64 r2, r7                                    r2 = r7
    call function_11756                     
    ldxdw r1, [r6+0x8]                      
    ldxdw r7, [r6+0x10]                     
lbb_12055:
    stxdw [r10-0x48], r1                    
    ldxdw r9, [r6+0x0]                      
    mov64 r1, r9                                    r1 = r9
    add64 r1, r7                                    r1 += r7   ///  r1 = r1.wrapping_add(r7)
    mov64 r2, 1                                     r2 = 1 as i32 as i64 as u64
    stxb [r1+0x0], r2                       
    add64 r7, 1                                     r7 += 1   ///  r7 = r7.wrapping_add(1 as i32 as i64 as u64)
    stxdw [r6+0x10], r7                     
    ldxdw r1, [r8+0x18]                     
    stxdw [r10-0x8], r1                     
    ldxdw r1, [r8+0x10]                     
    stxdw [r10-0x10], r1                    
    ldxdw r1, [r8+0x8]                      
    stxdw [r10-0x18], r1                    
    ldxdw r1, [r8+0x0]                      
    stxdw [r10-0x20], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -64                                   r1 += -64   ///  r1 = r1.wrapping_add(-64 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -32                                   r2 += -32   ///  r2 = r2.wrapping_add(-32 as i32 as i64 as u64)
    call function_17977                     
    ldxdw r1, [r10-0x48]                    
    sub64 r1, r7                                    r1 -= r7   ///  r1 = r1.wrapping_sub(r7)
    jgt r1, 31, lbb_12085                           if r1 > (31 as i32 as i64 as u64) { pc += 6 }
    mov64 r1, r6                                    r1 = r6
    mov64 r2, r7                                    r2 = r7
    mov64 r3, 32                                    r3 = 32 as i32 as i64 as u64
    call function_11798                     
    ldxdw r9, [r6+0x0]                      
    ldxdw r7, [r6+0x10]                     
lbb_12085:
    add64 r9, r7                                    r9 += r7   ///  r9 = r9.wrapping_add(r7)
    ldxdw r1, [r10-0x28]                    
    stxdw [r9+0x18], r1                     
    ldxdw r1, [r10-0x30]                    
    stxdw [r9+0x10], r1                     
    ldxdw r1, [r10-0x38]                    
    stxdw [r9+0x8], r1                      
    ldxdw r1, [r10-0x40]                    
    stxdw [r9+0x0], r1                      
    add64 r7, 32                                    r7 += 32   ///  r7 = r7.wrapping_add(32 as i32 as i64 as u64)
    stxdw [r6+0x10], r7                     
lbb_12096:
    exit                                    

function_12097:
    mov64 r8, r5                                    r8 = r5
    stxdw [r10-0xc0], r4                    
    mov64 r9, r3                                    r9 = r3
    mov64 r7, r2                                    r7 = r2
    mov64 r6, r1                                    r6 = r1
    mov64 r1, r7                                    r1 = r7
    lddw r2, 0x10002cb53 --> b"\x06\xdd\xf6\xe1\xd7e\xa1\x93\xd9\xcb\xe1F\xce\xeby\xac\x1c\xb4\x85\xed_[…        r2 load str located at 4295150419
    mov64 r3, 32                                    r3 = 32 as i32 as i64 as u64
    call function_21867                     
    lsh64 r0, 32                                    r0 <<= 32   ///  r0 = r0.wrapping_shl(32)
    rsh64 r0, 32                                    r0 >>= 32   ///  r0 = r0.wrapping_shr(32)
    jne r0, 0, lbb_12159                            if r0 != (0 as i32 as i64 as u64) { pc += 49 }
    stxdw [r10-0xe0], r9                    
    ldxdw r1, [r10-0xc0]                    
    stxdw [r10-0xd0], r7                    
    stxdw [r10-0xc8], r6                    
    ldxdw r1, [r8-0xfe8]                    
    ldxdw r6, [r8-0xff0]                    
    ldxdw r7, [r8-0xff8]                    
    ldxdw r2, [r8-0x1000]                   
    stxdw [r10-0xd8], r2                    
    mov64 r2, 3                                     r2 = 3 as i32 as i64 as u64
    stxw [r10-0x50], r2                     
    stxdw [r10-0x48], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -160                                  r1 += -160   ///  r1 = r1.wrapping_add(-160 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -80                                   r2 += -80   ///  r2 = r2.wrapping_add(-80 as i32 as i64 as u64)
    call function_11840                     
    mov64 r8, 1                                     r8 = 1 as i32 as i64 as u64
    mov64 r2, r6                                    r2 = r6
    add64 r2, 3                                     r2 += 3   ///  r2 = r2.wrapping_add(3 as i32 as i64 as u64)
    stxdw [r10-0xb8], r2                    
    jeq r2, 0, lbb_12166                            if r2 == (0 as i32 as i64 as u64) { pc += 34 }
    mov64 r1, r10                                   r1 = r10
    add64 r1, -176                                  r1 += -176   ///  r1 = r1.wrapping_add(-176 as i32 as i64 as u64)
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
    mov64 r4, 34                                    r4 = 34 as i32 as i64 as u64
    mov64 r5, 0                                     r5 = 0 as i32 as i64 as u64
    call function_21911                     
    mov64 r9, 1                                     r9 = 1 as i32 as i64 as u64
    ldxdw r1, [r10-0xa8]                    
    jne r1, 0, lbb_12142                            if r1 != (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r9, 0                                     r9 = 0 as i32 as i64 as u64
lbb_12142:
    mov64 r1, r9                                    r1 = r9
    and64 r1, 1                                     r1 &= 1   ///  r1 = r1.and(1)
    jne r1, 0, lbb_12346                            if r1 != (0 as i32 as i64 as u64) { pc += 201 }
    ldxdw r1, [r10-0xb0]                    
    xor64 r9, 1                                     r9 ^= 1   ///  r9 = r9.xor(1)
    jeq r1, 0, lbb_12164                            if r1 == (0 as i32 as i64 as u64) { pc += 16 }
    stxdw [r10-0xe8], r1                    
    mov64 r2, r9                                    r2 = r9
    call function_11635                     
    mov64 r8, r0                                    r8 = r0
    ldxdw r2, [r10-0xb8]                    
    jeq r8, 0, lbb_12155                            if r8 == (0 as i32 as i64 as u64) { pc += 1 }
    ja lbb_12166                                    if true { pc += 11 }
lbb_12155:
    ldxdw r1, [r10-0xe8]                    
    mov64 r2, r9                                    r2 = r9
    call function_18762                     
    syscall [invalid]                       
lbb_12159:
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    stxdw [r6+0x0], r1                      
    mov64 r1, 6                                     r1 = 6 as i32 as i64 as u64
    stxw [r6+0x8], r1                       
    ja lbb_12345                                    if true { pc += 181 }
lbb_12164:
    mov64 r8, r9                                    r8 = r9
    ldxdw r2, [r10-0xb8]                    
lbb_12166:
    stxdw [r10-0x88], r8                    
    mov64 r9, 0                                     r9 = 0 as i32 as i64 as u64
    stxdw [r10-0x78], r9                    
    stxdw [r10-0x80], r2                    
    ldxdw r2, [r10-0xe0]                    
    ldxdw r1, [r2+0x18]                     
    stxdw [r10-0x58], r1                    
    ldxdw r1, [r2+0x10]                     
    stxdw [r10-0x60], r1                    
    ldxdw r1, [r2+0x8]                      
    stxdw [r10-0x68], r1                    
    ldxdw r1, [r2+0x0]                      
    stxdw [r10-0x70], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -80                                   r1 += -80   ///  r1 = r1.wrapping_add(-80 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -112                                  r2 += -112   ///  r2 = r2.wrapping_add(-112 as i32 as i64 as u64)
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
    call function_17986                     
    ldxdw r1, [r10-0xb8]                    
    jeq r1, 0, lbb_12188                            if r1 == (0 as i32 as i64 as u64) { pc += 1 }
    ja lbb_12196                                    if true { pc += 8 }
lbb_12188:
    mov64 r1, r10                                   r1 = r10
    add64 r1, -136                                  r1 += -136   ///  r1 = r1.wrapping_add(-136 as i32 as i64 as u64)
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
    call function_11686                     
    ldxdw r1, [r10-0x80]                    
    stxdw [r10-0xb8], r1                    
    ldxdw r8, [r10-0x88]                    
    ldxdw r9, [r10-0x78]                    
lbb_12196:
    mov64 r2, r9                                    r2 = r9
    mul64 r2, 34                                    r2 *= 34   ///  r2 = r2.wrapping_mul(34 as u64)
    mov64 r1, r8                                    r1 = r8
    add64 r1, r2                                    r1 += r2   ///  r1 = r1.wrapping_add(r2)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -80                                   r2 += -80   ///  r2 = r2.wrapping_add(-80 as i32 as i64 as u64)
    mov64 r3, 34                                    r3 = 34 as i32 as i64 as u64
    call function_21797                     
    add64 r9, 1                                     r9 += 1   ///  r9 = r9.wrapping_add(1 as i32 as i64 as u64)
    stxdw [r10-0x78], r9                    
    ldxdw r2, [r10-0xc0]                    
    ldxdw r1, [r2+0x18]                     
    stxdw [r10-0x58], r1                    
    ldxdw r1, [r2+0x10]                     
    stxdw [r10-0x60], r1                    
    ldxdw r1, [r2+0x8]                      
    stxdw [r10-0x68], r1                    
    ldxdw r1, [r2+0x0]                      
    stxdw [r10-0x70], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -80                                   r1 += -80   ///  r1 = r1.wrapping_add(-80 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -112                                  r2 += -112   ///  r2 = r2.wrapping_add(-112 as i32 as i64 as u64)
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
    call function_17986                     
    ldxdw r2, [r10-0xb8]                    
    jne r9, r2, lbb_12229                           if r9 != r2 { pc += 6 }
    mov64 r1, r10                                   r1 = r10
    add64 r1, -136                                  r1 += -136   ///  r1 = r1.wrapping_add(-136 as i32 as i64 as u64)
    call function_11686                     
    ldxdw r2, [r10-0x80]                    
    ldxdw r8, [r10-0x88]                    
    ldxdw r9, [r10-0x78]                    
lbb_12229:
    stxdw [r10-0xb8], r2                    
    mov64 r2, r9                                    r2 = r9
    mul64 r2, 34                                    r2 *= 34   ///  r2 = r2.wrapping_mul(34 as u64)
    mov64 r1, r8                                    r1 = r8
    add64 r1, r2                                    r1 += r2   ///  r1 = r1.wrapping_add(r2)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -80                                   r2 += -80   ///  r2 = r2.wrapping_add(-80 as i32 as i64 as u64)
    mov64 r3, 34                                    r3 = 34 as i32 as i64 as u64
    call function_21797                     
    mov64 r3, 1                                     r3 = 1 as i32 as i64 as u64
    jeq r6, 0, lbb_12241                            if r6 == (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
lbb_12241:
    add64 r9, 1                                     r9 += 1   ///  r9 = r9.wrapping_add(1 as i32 as i64 as u64)
    stxdw [r10-0x78], r9                    
    ldxdw r2, [r10-0xd8]                    
    ldxdw r1, [r2+0x18]                     
    stxdw [r10-0x58], r1                    
    ldxdw r1, [r2+0x10]                     
    stxdw [r10-0x60], r1                    
    ldxdw r1, [r2+0x8]                      
    stxdw [r10-0x68], r1                    
    ldxdw r1, [r2+0x0]                      
    stxdw [r10-0x70], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -80                                   r1 += -80   ///  r1 = r1.wrapping_add(-80 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -112                                  r2 += -112   ///  r2 = r2.wrapping_add(-112 as i32 as i64 as u64)
    call function_17998                     
    ldxdw r2, [r10-0xb8]                    
    jne r9, r2, lbb_12264                           if r9 != r2 { pc += 5 }
    mov64 r1, r10                                   r1 = r10
    add64 r1, -136                                  r1 += -136   ///  r1 = r1.wrapping_add(-136 as i32 as i64 as u64)
    call function_11686                     
    ldxdw r8, [r10-0x88]                    
    ldxdw r9, [r10-0x78]                    
lbb_12264:
    mov64 r2, r9                                    r2 = r9
    mul64 r2, 34                                    r2 *= 34   ///  r2 = r2.wrapping_mul(34 as u64)
    mov64 r1, r8                                    r1 = r8
    add64 r1, r2                                    r1 += r2   ///  r1 = r1.wrapping_add(r2)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -80                                   r2 += -80   ///  r2 = r2.wrapping_add(-80 as i32 as i64 as u64)
    mov64 r3, 34                                    r3 = 34 as i32 as i64 as u64
    call function_21797                     
    add64 r9, 1                                     r9 += 1   ///  r9 = r9.wrapping_add(1 as i32 as i64 as u64)
    stxdw [r10-0x78], r9                    
    jeq r6, 0, lbb_12315                            if r6 == (0 as i32 as i64 as u64) { pc += 40 }
    lsh64 r6, 3                                     r6 <<= 3   ///  r6 = r6.wrapping_shl(3)
    ja lbb_12290                                    if true { pc += 13 }
lbb_12277:
    add64 r7, 8                                     r7 += 8   ///  r7 = r7.wrapping_add(8 as i32 as i64 as u64)
    mov64 r2, r9                                    r2 = r9
    mul64 r2, 34                                    r2 *= 34   ///  r2 = r2.wrapping_mul(34 as u64)
    mov64 r1, r8                                    r1 = r8
    add64 r1, r2                                    r1 += r2   ///  r1 = r1.wrapping_add(r2)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -80                                   r2 += -80   ///  r2 = r2.wrapping_add(-80 as i32 as i64 as u64)
    mov64 r3, 34                                    r3 = 34 as i32 as i64 as u64
    call function_21797                     
    add64 r9, 1                                     r9 += 1   ///  r9 = r9.wrapping_add(1 as i32 as i64 as u64)
    stxdw [r10-0x78], r9                    
    add64 r6, -8                                    r6 += -8   ///  r6 = r6.wrapping_add(-8 as i32 as i64 as u64)
    jeq r6, 0, lbb_12315                            if r6 == (0 as i32 as i64 as u64) { pc += 25 }
lbb_12290:
    ldxdw r1, [r7+0x0]                      
    ldxdw r2, [r1+0x18]                     
    stxdw [r10-0x58], r2                    
    ldxdw r2, [r1+0x10]                     
    stxdw [r10-0x60], r2                    
    ldxdw r2, [r1+0x8]                      
    stxdw [r10-0x68], r2                    
    ldxdw r1, [r1+0x0]                      
    stxdw [r10-0x70], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -80                                   r1 += -80   ///  r1 = r1.wrapping_add(-80 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -112                                  r2 += -112   ///  r2 = r2.wrapping_add(-112 as i32 as i64 as u64)
    mov64 r3, 1                                     r3 = 1 as i32 as i64 as u64
    call function_17998                     
    ldxdw r1, [r10-0x80]                    
    jeq r9, r1, lbb_12308                           if r9 == r1 { pc += 1 }
    ja lbb_12277                                    if true { pc += -31 }
lbb_12308:
    mov64 r1, r10                                   r1 = r10
    add64 r1, -136                                  r1 += -136   ///  r1 = r1.wrapping_add(-136 as i32 as i64 as u64)
    mov64 r2, r9                                    r2 = r9
    call function_11686                     
    ldxdw r8, [r10-0x88]                    
    ldxdw r9, [r10-0x78]                    
    ja lbb_12277                                    if true { pc += -38 }
lbb_12315:
    ldxdw r2, [r10-0xd0]                    
    ldxdw r1, [r2+0x18]                     
    stxdw [r10-0x8], r1                     
    ldxdw r1, [r2+0x10]                     
    stxdw [r10-0x10], r1                    
    ldxdw r1, [r2+0x8]                      
    stxdw [r10-0x18], r1                    
    ldxdw r1, [r2+0x0]                      
    stxdw [r10-0x20], r1                    
    ldxdw r1, [r10-0x88]                    
    stxdw [r10-0x50], r1                    
    ldxdw r1, [r10-0x80]                    
    stxdw [r10-0x48], r1                    
    ldxdw r1, [r10-0x78]                    
    stxdw [r10-0x40], r1                    
    ldxdw r1, [r10-0xa0]                    
    stxdw [r10-0x38], r1                    
    ldxdw r1, [r10-0x98]                    
    stxdw [r10-0x30], r1                    
    ldxdw r1, [r10-0x90]                    
    stxdw [r10-0x28], r1                    
    ldxdw r6, [r10-0xc8]                    
    mov64 r1, r6                                    r1 = r6
    add64 r1, 8                                     r1 += 8   ///  r1 = r1.wrapping_add(8 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -80                                   r2 += -80   ///  r2 = r2.wrapping_add(-80 as i32 as i64 as u64)
    mov64 r3, 80                                    r3 = 80 as i32 as i64 as u64
    call function_21797                     
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    stxdw [r6+0x0], r1                      
lbb_12345:
    exit                                    
lbb_12346:
    call function_18745                     
    syscall [invalid]                       

function_12348:
    mov64 r8, r5                                    r8 = r5
    stxdw [r10-0xc0], r4                    
    mov64 r9, r3                                    r9 = r3
    mov64 r7, r2                                    r7 = r2
    mov64 r6, r1                                    r6 = r1
    mov64 r1, r7                                    r1 = r7
    lddw r2, 0x10002cb53 --> b"\x06\xdd\xf6\xe1\xd7e\xa1\x93\xd9\xcb\xe1F\xce\xeby\xac\x1c\xb4\x85\xed_[…        r2 load str located at 4295150419
    mov64 r3, 32                                    r3 = 32 as i32 as i64 as u64
    call function_21867                     
    lsh64 r0, 32                                    r0 <<= 32   ///  r0 = r0.wrapping_shl(32)
    rsh64 r0, 32                                    r0 >>= 32   ///  r0 = r0.wrapping_shr(32)
    jne r0, 0, lbb_12410                            if r0 != (0 as i32 as i64 as u64) { pc += 49 }
    stxdw [r10-0xe0], r9                    
    ldxdw r1, [r10-0xc0]                    
    stxdw [r10-0xd0], r7                    
    stxdw [r10-0xc8], r6                    
    ldxdw r1, [r8-0xfe8]                    
    ldxdw r6, [r8-0xff0]                    
    ldxdw r7, [r8-0xff8]                    
    ldxdw r2, [r8-0x1000]                   
    stxdw [r10-0xd8], r2                    
    mov64 r2, 7                                     r2 = 7 as i32 as i64 as u64
    stxw [r10-0x50], r2                     
    stxdw [r10-0x48], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -160                                  r1 += -160   ///  r1 = r1.wrapping_add(-160 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -80                                   r2 += -80   ///  r2 = r2.wrapping_add(-80 as i32 as i64 as u64)
    call function_11840                     
    mov64 r8, 1                                     r8 = 1 as i32 as i64 as u64
    mov64 r2, r6                                    r2 = r6
    add64 r2, 3                                     r2 += 3   ///  r2 = r2.wrapping_add(3 as i32 as i64 as u64)
    stxdw [r10-0xb8], r2                    
    jeq r2, 0, lbb_12417                            if r2 == (0 as i32 as i64 as u64) { pc += 34 }
    mov64 r1, r10                                   r1 = r10
    add64 r1, -176                                  r1 += -176   ///  r1 = r1.wrapping_add(-176 as i32 as i64 as u64)
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
    mov64 r4, 34                                    r4 = 34 as i32 as i64 as u64
    mov64 r5, 0                                     r5 = 0 as i32 as i64 as u64
    call function_21911                     
    mov64 r9, 1                                     r9 = 1 as i32 as i64 as u64
    ldxdw r1, [r10-0xa8]                    
    jne r1, 0, lbb_12393                            if r1 != (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r9, 0                                     r9 = 0 as i32 as i64 as u64
lbb_12393:
    mov64 r1, r9                                    r1 = r9
    and64 r1, 1                                     r1 &= 1   ///  r1 = r1.and(1)
    jne r1, 0, lbb_12597                            if r1 != (0 as i32 as i64 as u64) { pc += 201 }
    ldxdw r1, [r10-0xb0]                    
    xor64 r9, 1                                     r9 ^= 1   ///  r9 = r9.xor(1)
    jeq r1, 0, lbb_12415                            if r1 == (0 as i32 as i64 as u64) { pc += 16 }
    stxdw [r10-0xe8], r1                    
    mov64 r2, r9                                    r2 = r9
    call function_11635                     
    mov64 r8, r0                                    r8 = r0
    ldxdw r2, [r10-0xb8]                    
    jeq r8, 0, lbb_12406                            if r8 == (0 as i32 as i64 as u64) { pc += 1 }
    ja lbb_12417                                    if true { pc += 11 }
lbb_12406:
    ldxdw r1, [r10-0xe8]                    
    mov64 r2, r9                                    r2 = r9
    call function_18762                     
    syscall [invalid]                       
lbb_12410:
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    stxdw [r6+0x0], r1                      
    mov64 r1, 6                                     r1 = 6 as i32 as i64 as u64
    stxw [r6+0x8], r1                       
    ja lbb_12596                                    if true { pc += 181 }
lbb_12415:
    mov64 r8, r9                                    r8 = r9
    ldxdw r2, [r10-0xb8]                    
lbb_12417:
    stxdw [r10-0x88], r8                    
    mov64 r9, 0                                     r9 = 0 as i32 as i64 as u64
    stxdw [r10-0x78], r9                    
    stxdw [r10-0x80], r2                    
    ldxdw r2, [r10-0xe0]                    
    ldxdw r1, [r2+0x18]                     
    stxdw [r10-0x58], r1                    
    ldxdw r1, [r2+0x10]                     
    stxdw [r10-0x60], r1                    
    ldxdw r1, [r2+0x8]                      
    stxdw [r10-0x68], r1                    
    ldxdw r1, [r2+0x0]                      
    stxdw [r10-0x70], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -80                                   r1 += -80   ///  r1 = r1.wrapping_add(-80 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -112                                  r2 += -112   ///  r2 = r2.wrapping_add(-112 as i32 as i64 as u64)
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
    call function_17986                     
    ldxdw r1, [r10-0xb8]                    
    jeq r1, 0, lbb_12439                            if r1 == (0 as i32 as i64 as u64) { pc += 1 }
    ja lbb_12447                                    if true { pc += 8 }
lbb_12439:
    mov64 r1, r10                                   r1 = r10
    add64 r1, -136                                  r1 += -136   ///  r1 = r1.wrapping_add(-136 as i32 as i64 as u64)
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
    call function_11686                     
    ldxdw r1, [r10-0x80]                    
    stxdw [r10-0xb8], r1                    
    ldxdw r8, [r10-0x88]                    
    ldxdw r9, [r10-0x78]                    
lbb_12447:
    mov64 r2, r9                                    r2 = r9
    mul64 r2, 34                                    r2 *= 34   ///  r2 = r2.wrapping_mul(34 as u64)
    mov64 r1, r8                                    r1 = r8
    add64 r1, r2                                    r1 += r2   ///  r1 = r1.wrapping_add(r2)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -80                                   r2 += -80   ///  r2 = r2.wrapping_add(-80 as i32 as i64 as u64)
    mov64 r3, 34                                    r3 = 34 as i32 as i64 as u64
    call function_21797                     
    add64 r9, 1                                     r9 += 1   ///  r9 = r9.wrapping_add(1 as i32 as i64 as u64)
    stxdw [r10-0x78], r9                    
    ldxdw r2, [r10-0xc0]                    
    ldxdw r1, [r2+0x18]                     
    stxdw [r10-0x58], r1                    
    ldxdw r1, [r2+0x10]                     
    stxdw [r10-0x60], r1                    
    ldxdw r1, [r2+0x8]                      
    stxdw [r10-0x68], r1                    
    ldxdw r1, [r2+0x0]                      
    stxdw [r10-0x70], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -80                                   r1 += -80   ///  r1 = r1.wrapping_add(-80 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -112                                  r2 += -112   ///  r2 = r2.wrapping_add(-112 as i32 as i64 as u64)
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
    call function_17986                     
    ldxdw r2, [r10-0xb8]                    
    jne r9, r2, lbb_12480                           if r9 != r2 { pc += 6 }
    mov64 r1, r10                                   r1 = r10
    add64 r1, -136                                  r1 += -136   ///  r1 = r1.wrapping_add(-136 as i32 as i64 as u64)
    call function_11686                     
    ldxdw r2, [r10-0x80]                    
    ldxdw r8, [r10-0x88]                    
    ldxdw r9, [r10-0x78]                    
lbb_12480:
    stxdw [r10-0xb8], r2                    
    mov64 r2, r9                                    r2 = r9
    mul64 r2, 34                                    r2 *= 34   ///  r2 = r2.wrapping_mul(34 as u64)
    mov64 r1, r8                                    r1 = r8
    add64 r1, r2                                    r1 += r2   ///  r1 = r1.wrapping_add(r2)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -80                                   r2 += -80   ///  r2 = r2.wrapping_add(-80 as i32 as i64 as u64)
    mov64 r3, 34                                    r3 = 34 as i32 as i64 as u64
    call function_21797                     
    mov64 r3, 1                                     r3 = 1 as i32 as i64 as u64
    jeq r6, 0, lbb_12492                            if r6 == (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
lbb_12492:
    add64 r9, 1                                     r9 += 1   ///  r9 = r9.wrapping_add(1 as i32 as i64 as u64)
    stxdw [r10-0x78], r9                    
    ldxdw r2, [r10-0xd8]                    
    ldxdw r1, [r2+0x18]                     
    stxdw [r10-0x58], r1                    
    ldxdw r1, [r2+0x10]                     
    stxdw [r10-0x60], r1                    
    ldxdw r1, [r2+0x8]                      
    stxdw [r10-0x68], r1                    
    ldxdw r1, [r2+0x0]                      
    stxdw [r10-0x70], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -80                                   r1 += -80   ///  r1 = r1.wrapping_add(-80 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -112                                  r2 += -112   ///  r2 = r2.wrapping_add(-112 as i32 as i64 as u64)
    call function_17998                     
    ldxdw r2, [r10-0xb8]                    
    jne r9, r2, lbb_12515                           if r9 != r2 { pc += 5 }
    mov64 r1, r10                                   r1 = r10
    add64 r1, -136                                  r1 += -136   ///  r1 = r1.wrapping_add(-136 as i32 as i64 as u64)
    call function_11686                     
    ldxdw r8, [r10-0x88]                    
    ldxdw r9, [r10-0x78]                    
lbb_12515:
    mov64 r2, r9                                    r2 = r9
    mul64 r2, 34                                    r2 *= 34   ///  r2 = r2.wrapping_mul(34 as u64)
    mov64 r1, r8                                    r1 = r8
    add64 r1, r2                                    r1 += r2   ///  r1 = r1.wrapping_add(r2)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -80                                   r2 += -80   ///  r2 = r2.wrapping_add(-80 as i32 as i64 as u64)
    mov64 r3, 34                                    r3 = 34 as i32 as i64 as u64
    call function_21797                     
    add64 r9, 1                                     r9 += 1   ///  r9 = r9.wrapping_add(1 as i32 as i64 as u64)
    stxdw [r10-0x78], r9                    
    jeq r6, 0, lbb_12566                            if r6 == (0 as i32 as i64 as u64) { pc += 40 }
    lsh64 r6, 3                                     r6 <<= 3   ///  r6 = r6.wrapping_shl(3)
    ja lbb_12541                                    if true { pc += 13 }
lbb_12528:
    add64 r7, 8                                     r7 += 8   ///  r7 = r7.wrapping_add(8 as i32 as i64 as u64)
    mov64 r2, r9                                    r2 = r9
    mul64 r2, 34                                    r2 *= 34   ///  r2 = r2.wrapping_mul(34 as u64)
    mov64 r1, r8                                    r1 = r8
    add64 r1, r2                                    r1 += r2   ///  r1 = r1.wrapping_add(r2)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -80                                   r2 += -80   ///  r2 = r2.wrapping_add(-80 as i32 as i64 as u64)
    mov64 r3, 34                                    r3 = 34 as i32 as i64 as u64
    call function_21797                     
    add64 r9, 1                                     r9 += 1   ///  r9 = r9.wrapping_add(1 as i32 as i64 as u64)
    stxdw [r10-0x78], r9                    
    add64 r6, -8                                    r6 += -8   ///  r6 = r6.wrapping_add(-8 as i32 as i64 as u64)
    jeq r6, 0, lbb_12566                            if r6 == (0 as i32 as i64 as u64) { pc += 25 }
lbb_12541:
    ldxdw r1, [r7+0x0]                      
    ldxdw r2, [r1+0x18]                     
    stxdw [r10-0x58], r2                    
    ldxdw r2, [r1+0x10]                     
    stxdw [r10-0x60], r2                    
    ldxdw r2, [r1+0x8]                      
    stxdw [r10-0x68], r2                    
    ldxdw r1, [r1+0x0]                      
    stxdw [r10-0x70], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -80                                   r1 += -80   ///  r1 = r1.wrapping_add(-80 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -112                                  r2 += -112   ///  r2 = r2.wrapping_add(-112 as i32 as i64 as u64)
    mov64 r3, 1                                     r3 = 1 as i32 as i64 as u64
    call function_17998                     
    ldxdw r1, [r10-0x80]                    
    jeq r9, r1, lbb_12559                           if r9 == r1 { pc += 1 }
    ja lbb_12528                                    if true { pc += -31 }
lbb_12559:
    mov64 r1, r10                                   r1 = r10
    add64 r1, -136                                  r1 += -136   ///  r1 = r1.wrapping_add(-136 as i32 as i64 as u64)
    mov64 r2, r9                                    r2 = r9
    call function_11686                     
    ldxdw r8, [r10-0x88]                    
    ldxdw r9, [r10-0x78]                    
    ja lbb_12528                                    if true { pc += -38 }
lbb_12566:
    ldxdw r2, [r10-0xd0]                    
    ldxdw r1, [r2+0x18]                     
    stxdw [r10-0x8], r1                     
    ldxdw r1, [r2+0x10]                     
    stxdw [r10-0x10], r1                    
    ldxdw r1, [r2+0x8]                      
    stxdw [r10-0x18], r1                    
    ldxdw r1, [r2+0x0]                      
    stxdw [r10-0x20], r1                    
    ldxdw r1, [r10-0x88]                    
    stxdw [r10-0x50], r1                    
    ldxdw r1, [r10-0x80]                    
    stxdw [r10-0x48], r1                    
    ldxdw r1, [r10-0x78]                    
    stxdw [r10-0x40], r1                    
    ldxdw r1, [r10-0xa0]                    
    stxdw [r10-0x38], r1                    
    ldxdw r1, [r10-0x98]                    
    stxdw [r10-0x30], r1                    
    ldxdw r1, [r10-0x90]                    
    stxdw [r10-0x28], r1                    
    ldxdw r6, [r10-0xc8]                    
    mov64 r1, r6                                    r1 = r6
    add64 r1, 8                                     r1 += 8   ///  r1 = r1.wrapping_add(8 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -80                                   r2 += -80   ///  r2 = r2.wrapping_add(-80 as i32 as i64 as u64)
    mov64 r3, 80                                    r3 = 80 as i32 as i64 as u64
    call function_21797                     
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    stxdw [r6+0x0], r1                      
lbb_12596:
    exit                                    
lbb_12597:
    call function_18745                     
    syscall [invalid]                       

function_12599:
    mov64 r8, r5                                    r8 = r5
    stxdw [r10-0xc0], r4                    
    mov64 r9, r3                                    r9 = r3
    mov64 r7, r2                                    r7 = r2
    mov64 r6, r1                                    r6 = r1
    mov64 r1, r7                                    r1 = r7
    lddw r2, 0x10002cb53 --> b"\x06\xdd\xf6\xe1\xd7e\xa1\x93\xd9\xcb\xe1F\xce\xeby\xac\x1c\xb4\x85\xed_[…        r2 load str located at 4295150419
    mov64 r3, 32                                    r3 = 32 as i32 as i64 as u64
    call function_21867                     
    lsh64 r0, 32                                    r0 <<= 32   ///  r0 = r0.wrapping_shl(32)
    rsh64 r0, 32                                    r0 >>= 32   ///  r0 = r0.wrapping_shr(32)
    jne r0, 0, lbb_12661                            if r0 != (0 as i32 as i64 as u64) { pc += 49 }
    stxdw [r10-0xe0], r9                    
    ldxdw r1, [r10-0xc0]                    
    stxdw [r10-0xd0], r7                    
    stxdw [r10-0xc8], r6                    
    ldxdw r1, [r8-0xfe8]                    
    ldxdw r6, [r8-0xff0]                    
    ldxdw r7, [r8-0xff8]                    
    ldxdw r2, [r8-0x1000]                   
    stxdw [r10-0xd8], r2                    
    mov64 r2, 8                                     r2 = 8 as i32 as i64 as u64
    stxw [r10-0x50], r2                     
    stxdw [r10-0x48], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -160                                  r1 += -160   ///  r1 = r1.wrapping_add(-160 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -80                                   r2 += -80   ///  r2 = r2.wrapping_add(-80 as i32 as i64 as u64)
    call function_11840                     
    mov64 r8, 1                                     r8 = 1 as i32 as i64 as u64
    mov64 r2, r6                                    r2 = r6
    add64 r2, 3                                     r2 += 3   ///  r2 = r2.wrapping_add(3 as i32 as i64 as u64)
    stxdw [r10-0xb8], r2                    
    jeq r2, 0, lbb_12668                            if r2 == (0 as i32 as i64 as u64) { pc += 34 }
    mov64 r1, r10                                   r1 = r10
    add64 r1, -176                                  r1 += -176   ///  r1 = r1.wrapping_add(-176 as i32 as i64 as u64)
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
    mov64 r4, 34                                    r4 = 34 as i32 as i64 as u64
    mov64 r5, 0                                     r5 = 0 as i32 as i64 as u64
    call function_21911                     
    mov64 r9, 1                                     r9 = 1 as i32 as i64 as u64
    ldxdw r1, [r10-0xa8]                    
    jne r1, 0, lbb_12644                            if r1 != (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r9, 0                                     r9 = 0 as i32 as i64 as u64
lbb_12644:
    mov64 r1, r9                                    r1 = r9
    and64 r1, 1                                     r1 &= 1   ///  r1 = r1.and(1)
    jne r1, 0, lbb_12848                            if r1 != (0 as i32 as i64 as u64) { pc += 201 }
    ldxdw r1, [r10-0xb0]                    
    xor64 r9, 1                                     r9 ^= 1   ///  r9 = r9.xor(1)
    jeq r1, 0, lbb_12666                            if r1 == (0 as i32 as i64 as u64) { pc += 16 }
    stxdw [r10-0xe8], r1                    
    mov64 r2, r9                                    r2 = r9
    call function_11635                     
    mov64 r8, r0                                    r8 = r0
    ldxdw r2, [r10-0xb8]                    
    jeq r8, 0, lbb_12657                            if r8 == (0 as i32 as i64 as u64) { pc += 1 }
    ja lbb_12668                                    if true { pc += 11 }
lbb_12657:
    ldxdw r1, [r10-0xe8]                    
    mov64 r2, r9                                    r2 = r9
    call function_18762                     
    syscall [invalid]                       
lbb_12661:
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    stxdw [r6+0x0], r1                      
    mov64 r1, 6                                     r1 = 6 as i32 as i64 as u64
    stxw [r6+0x8], r1                       
    ja lbb_12847                                    if true { pc += 181 }
lbb_12666:
    mov64 r8, r9                                    r8 = r9
    ldxdw r2, [r10-0xb8]                    
lbb_12668:
    stxdw [r10-0x88], r8                    
    mov64 r9, 0                                     r9 = 0 as i32 as i64 as u64
    stxdw [r10-0x78], r9                    
    stxdw [r10-0x80], r2                    
    ldxdw r2, [r10-0xe0]                    
    ldxdw r1, [r2+0x18]                     
    stxdw [r10-0x58], r1                    
    ldxdw r1, [r2+0x10]                     
    stxdw [r10-0x60], r1                    
    ldxdw r1, [r2+0x8]                      
    stxdw [r10-0x68], r1                    
    ldxdw r1, [r2+0x0]                      
    stxdw [r10-0x70], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -80                                   r1 += -80   ///  r1 = r1.wrapping_add(-80 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -112                                  r2 += -112   ///  r2 = r2.wrapping_add(-112 as i32 as i64 as u64)
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
    call function_17986                     
    ldxdw r1, [r10-0xb8]                    
    jeq r1, 0, lbb_12690                            if r1 == (0 as i32 as i64 as u64) { pc += 1 }
    ja lbb_12698                                    if true { pc += 8 }
lbb_12690:
    mov64 r1, r10                                   r1 = r10
    add64 r1, -136                                  r1 += -136   ///  r1 = r1.wrapping_add(-136 as i32 as i64 as u64)
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
    call function_11686                     
    ldxdw r1, [r10-0x80]                    
    stxdw [r10-0xb8], r1                    
    ldxdw r8, [r10-0x88]                    
    ldxdw r9, [r10-0x78]                    
lbb_12698:
    mov64 r2, r9                                    r2 = r9
    mul64 r2, 34                                    r2 *= 34   ///  r2 = r2.wrapping_mul(34 as u64)
    mov64 r1, r8                                    r1 = r8
    add64 r1, r2                                    r1 += r2   ///  r1 = r1.wrapping_add(r2)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -80                                   r2 += -80   ///  r2 = r2.wrapping_add(-80 as i32 as i64 as u64)
    mov64 r3, 34                                    r3 = 34 as i32 as i64 as u64
    call function_21797                     
    add64 r9, 1                                     r9 += 1   ///  r9 = r9.wrapping_add(1 as i32 as i64 as u64)
    stxdw [r10-0x78], r9                    
    ldxdw r2, [r10-0xc0]                    
    ldxdw r1, [r2+0x18]                     
    stxdw [r10-0x58], r1                    
    ldxdw r1, [r2+0x10]                     
    stxdw [r10-0x60], r1                    
    ldxdw r1, [r2+0x8]                      
    stxdw [r10-0x68], r1                    
    ldxdw r1, [r2+0x0]                      
    stxdw [r10-0x70], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -80                                   r1 += -80   ///  r1 = r1.wrapping_add(-80 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -112                                  r2 += -112   ///  r2 = r2.wrapping_add(-112 as i32 as i64 as u64)
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
    call function_17986                     
    ldxdw r2, [r10-0xb8]                    
    jne r9, r2, lbb_12731                           if r9 != r2 { pc += 6 }
    mov64 r1, r10                                   r1 = r10
    add64 r1, -136                                  r1 += -136   ///  r1 = r1.wrapping_add(-136 as i32 as i64 as u64)
    call function_11686                     
    ldxdw r2, [r10-0x80]                    
    ldxdw r8, [r10-0x88]                    
    ldxdw r9, [r10-0x78]                    
lbb_12731:
    stxdw [r10-0xb8], r2                    
    mov64 r2, r9                                    r2 = r9
    mul64 r2, 34                                    r2 *= 34   ///  r2 = r2.wrapping_mul(34 as u64)
    mov64 r1, r8                                    r1 = r8
    add64 r1, r2                                    r1 += r2   ///  r1 = r1.wrapping_add(r2)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -80                                   r2 += -80   ///  r2 = r2.wrapping_add(-80 as i32 as i64 as u64)
    mov64 r3, 34                                    r3 = 34 as i32 as i64 as u64
    call function_21797                     
    mov64 r3, 1                                     r3 = 1 as i32 as i64 as u64
    jeq r6, 0, lbb_12743                            if r6 == (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
lbb_12743:
    add64 r9, 1                                     r9 += 1   ///  r9 = r9.wrapping_add(1 as i32 as i64 as u64)
    stxdw [r10-0x78], r9                    
    ldxdw r2, [r10-0xd8]                    
    ldxdw r1, [r2+0x18]                     
    stxdw [r10-0x58], r1                    
    ldxdw r1, [r2+0x10]                     
    stxdw [r10-0x60], r1                    
    ldxdw r1, [r2+0x8]                      
    stxdw [r10-0x68], r1                    
    ldxdw r1, [r2+0x0]                      
    stxdw [r10-0x70], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -80                                   r1 += -80   ///  r1 = r1.wrapping_add(-80 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -112                                  r2 += -112   ///  r2 = r2.wrapping_add(-112 as i32 as i64 as u64)
    call function_17998                     
    ldxdw r2, [r10-0xb8]                    
    jne r9, r2, lbb_12766                           if r9 != r2 { pc += 5 }
    mov64 r1, r10                                   r1 = r10
    add64 r1, -136                                  r1 += -136   ///  r1 = r1.wrapping_add(-136 as i32 as i64 as u64)
    call function_11686                     
    ldxdw r8, [r10-0x88]                    
    ldxdw r9, [r10-0x78]                    
lbb_12766:
    mov64 r2, r9                                    r2 = r9
    mul64 r2, 34                                    r2 *= 34   ///  r2 = r2.wrapping_mul(34 as u64)
    mov64 r1, r8                                    r1 = r8
    add64 r1, r2                                    r1 += r2   ///  r1 = r1.wrapping_add(r2)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -80                                   r2 += -80   ///  r2 = r2.wrapping_add(-80 as i32 as i64 as u64)
    mov64 r3, 34                                    r3 = 34 as i32 as i64 as u64
    call function_21797                     
    add64 r9, 1                                     r9 += 1   ///  r9 = r9.wrapping_add(1 as i32 as i64 as u64)
    stxdw [r10-0x78], r9                    
    jeq r6, 0, lbb_12817                            if r6 == (0 as i32 as i64 as u64) { pc += 40 }
    lsh64 r6, 3                                     r6 <<= 3   ///  r6 = r6.wrapping_shl(3)
    ja lbb_12792                                    if true { pc += 13 }
lbb_12779:
    add64 r7, 8                                     r7 += 8   ///  r7 = r7.wrapping_add(8 as i32 as i64 as u64)
    mov64 r2, r9                                    r2 = r9
    mul64 r2, 34                                    r2 *= 34   ///  r2 = r2.wrapping_mul(34 as u64)
    mov64 r1, r8                                    r1 = r8
    add64 r1, r2                                    r1 += r2   ///  r1 = r1.wrapping_add(r2)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -80                                   r2 += -80   ///  r2 = r2.wrapping_add(-80 as i32 as i64 as u64)
    mov64 r3, 34                                    r3 = 34 as i32 as i64 as u64
    call function_21797                     
    add64 r9, 1                                     r9 += 1   ///  r9 = r9.wrapping_add(1 as i32 as i64 as u64)
    stxdw [r10-0x78], r9                    
    add64 r6, -8                                    r6 += -8   ///  r6 = r6.wrapping_add(-8 as i32 as i64 as u64)
    jeq r6, 0, lbb_12817                            if r6 == (0 as i32 as i64 as u64) { pc += 25 }
lbb_12792:
    ldxdw r1, [r7+0x0]                      
    ldxdw r2, [r1+0x18]                     
    stxdw [r10-0x58], r2                    
    ldxdw r2, [r1+0x10]                     
    stxdw [r10-0x60], r2                    
    ldxdw r2, [r1+0x8]                      
    stxdw [r10-0x68], r2                    
    ldxdw r1, [r1+0x0]                      
    stxdw [r10-0x70], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -80                                   r1 += -80   ///  r1 = r1.wrapping_add(-80 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -112                                  r2 += -112   ///  r2 = r2.wrapping_add(-112 as i32 as i64 as u64)
    mov64 r3, 1                                     r3 = 1 as i32 as i64 as u64
    call function_17998                     
    ldxdw r1, [r10-0x80]                    
    jeq r9, r1, lbb_12810                           if r9 == r1 { pc += 1 }
    ja lbb_12779                                    if true { pc += -31 }
lbb_12810:
    mov64 r1, r10                                   r1 = r10
    add64 r1, -136                                  r1 += -136   ///  r1 = r1.wrapping_add(-136 as i32 as i64 as u64)
    mov64 r2, r9                                    r2 = r9
    call function_11686                     
    ldxdw r8, [r10-0x88]                    
    ldxdw r9, [r10-0x78]                    
    ja lbb_12779                                    if true { pc += -38 }
lbb_12817:
    ldxdw r2, [r10-0xd0]                    
    ldxdw r1, [r2+0x18]                     
    stxdw [r10-0x8], r1                     
    ldxdw r1, [r2+0x10]                     
    stxdw [r10-0x10], r1                    
    ldxdw r1, [r2+0x8]                      
    stxdw [r10-0x18], r1                    
    ldxdw r1, [r2+0x0]                      
    stxdw [r10-0x20], r1                    
    ldxdw r1, [r10-0x88]                    
    stxdw [r10-0x50], r1                    
    ldxdw r1, [r10-0x80]                    
    stxdw [r10-0x48], r1                    
    ldxdw r1, [r10-0x78]                    
    stxdw [r10-0x40], r1                    
    ldxdw r1, [r10-0xa0]                    
    stxdw [r10-0x38], r1                    
    ldxdw r1, [r10-0x98]                    
    stxdw [r10-0x30], r1                    
    ldxdw r1, [r10-0x90]                    
    stxdw [r10-0x28], r1                    
    ldxdw r6, [r10-0xc8]                    
    mov64 r1, r6                                    r1 = r6
    add64 r1, 8                                     r1 += 8   ///  r1 = r1.wrapping_add(8 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -80                                   r2 += -80   ///  r2 = r2.wrapping_add(-80 as i32 as i64 as u64)
    mov64 r3, 80                                    r3 = 80 as i32 as i64 as u64
    call function_21797                     
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    stxdw [r6+0x0], r1                      
lbb_12847:
    exit                                    
lbb_12848:
    call function_18745                     
    syscall [invalid]                       

function_12850:
    ldxb r0, [r1+0x31]                      
    exit                                    

function_12852:
    mov64 r7, r2                                    r7 = r2
    mov64 r6, r1                                    r6 = r1
    jgt r3, 81, lbb_12861                           if r3 > (81 as i32 as i64 as u64) { pc += 6 }
    mov64 r1, 82                                    r1 = 82 as i32 as i64 as u64
    mov64 r2, r3                                    r2 = r3
    lddw r3, 0x10002ded0 --> b"\x00\x00\x00\x00G\xcb\x02\x00\x0c\x00\x00\x00\x00\x00\x00\x00'\x00\x00\x0…        r3 load str located at 4295155408
    call function_20726                     
    syscall [invalid]                       
lbb_12861:
    ldxb r1, [r7+0x0]                       
    jeq r1, 0, lbb_12881                            if r1 == (0 as i32 as i64 as u64) { pc += 18 }
    jeq r1, 1, lbb_12889                            if r1 == (1 as i32 as i64 as u64) { pc += 25 }
lbb_12864:
    mov64 r1, 3                                     r1 = 3 as i32 as i64 as u64
    stxw [r10-0x40], r1                     
    ldxdw r1, [r10-0x38]                    
    stxdw [r10-0x60], r1                    
    ldxdw r2, [r10-0x30]                    
    stxdw [r10-0x58], r2                    
    ldxdw r3, [r10-0x28]                    
    stxdw [r10-0x50], r3                    
    ldxdw r4, [r10-0x40]                    
    stxdw [r10-0x68], r4                    
    stxdw [r6+0x20], r3                     
    stxdw [r6+0x18], r2                     
    stxdw [r6+0x10], r1                     
    stxdw [r6+0x8], r4                      
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
lbb_12879:
    stxdw [r6+0x0], r1                      
lbb_12880:
    exit                                    
lbb_12881:
    ldxb r1, [r7+0x1]                       
    jne r1, 0, lbb_12864                            if r1 != (0 as i32 as i64 as u64) { pc += -19 }
    ldxb r1, [r7+0x2]                       
    jne r1, 0, lbb_12864                            if r1 != (0 as i32 as i64 as u64) { pc += -21 }
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    ldxb r2, [r7+0x3]                       
    jeq r2, 0, lbb_12911                            if r2 == (0 as i32 as i64 as u64) { pc += 23 }
    ja lbb_12864                                    if true { pc += -25 }
lbb_12889:
    ldxb r1, [r7+0x1]                       
    jne r1, 0, lbb_12864                            if r1 != (0 as i32 as i64 as u64) { pc += -27 }
    ldxb r1, [r7+0x2]                       
    jne r1, 0, lbb_12864                            if r1 != (0 as i32 as i64 as u64) { pc += -29 }
    ldxb r1, [r7+0x3]                       
    jne r1, 0, lbb_12864                            if r1 != (0 as i32 as i64 as u64) { pc += -31 }
    mov64 r1, r7                                    r1 = r7
    add64 r1, 4                                     r1 += 4   ///  r1 = r1.wrapping_add(4 as i32 as i64 as u64)
    ldxdw r2, [r1+0x18]                     
    stxdw [r10-0x78], r2                    
    ldxdw r2, [r1+0x10]                     
    stxdw [r10-0x80], r2                    
    ldxdw r2, [r1+0x8]                      
    stxdw [r10-0x88], r2                    
    ldxdw r1, [r1+0x0]                      
    stxdw [r10-0x90], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -64                                   r1 += -64   ///  r1 = r1.wrapping_add(-64 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -144                                  r2 += -144   ///  r2 = r2.wrapping_add(-144 as i32 as i64 as u64)
    call function_17968                     
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
lbb_12911:
    stxw [r10-0x44], r1                     
    mov64 r8, r10                                   r8 = r10
    add64 r8, -108                                  r8 += -108   ///  r8 = r8.wrapping_add(-108 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -68                                   r2 += -68   ///  r2 = r2.wrapping_add(-68 as i32 as i64 as u64)
    mov64 r1, r8                                    r1 = r8
    mov64 r3, 36                                    r3 = 36 as i32 as i64 as u64
    call function_21797                     
    mov64 r1, r10                                   r1 = r10
    add64 r1, -184                                  r1 += -184   ///  r1 = r1.wrapping_add(-184 as i32 as i64 as u64)
    mov64 r2, r8                                    r2 = r8
    mov64 r3, 36                                    r3 = 36 as i32 as i64 as u64
    call function_21797                     
    mov64 r9, 0                                     r9 = 0 as i32 as i64 as u64
    ldxb r3, [r7+0x2c]                      
    ldxdw r8, [r7+0x24]                     
    ldxb r1, [r7+0x2d]                      
    jeq r1, 0, lbb_12936                            if r1 == (0 as i32 as i64 as u64) { pc += 7 }
    jeq r1, 1, lbb_12935                            if r1 == (1 as i32 as i64 as u64) { pc += 5 }
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    stxdw [r6+0x0], r1                      
    mov64 r1, 3                                     r1 = 3 as i32 as i64 as u64
    stxw [r6+0x8], r1                       
    ja lbb_12880                                    if true { pc += -55 }
lbb_12935:
    mov64 r9, 1                                     r9 = 1 as i32 as i64 as u64
lbb_12936:
    ldxb r1, [r7+0x2e]                      
    jeq r1, 0, lbb_12940                            if r1 == (0 as i32 as i64 as u64) { pc += 2 }
    jeq r1, 1, lbb_12948                            if r1 == (1 as i32 as i64 as u64) { pc += 9 }
lbb_12939:
    ja lbb_12864                                    if true { pc += -76 }
lbb_12940:
    ldxb r1, [r7+0x2f]                      
    jne r1, 0, lbb_12939                            if r1 != (0 as i32 as i64 as u64) { pc += -3 }
    ldxb r1, [r7+0x30]                      
    jne r1, 0, lbb_12939                            if r1 != (0 as i32 as i64 as u64) { pc += -5 }
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    ldxb r2, [r7+0x31]                      
    jeq r2, 0, lbb_12971                            if r2 == (0 as i32 as i64 as u64) { pc += 24 }
    ja lbb_12939                                    if true { pc += -9 }
lbb_12948:
    ldxb r1, [r7+0x2f]                      
    jne r1, 0, lbb_12939                            if r1 != (0 as i32 as i64 as u64) { pc += -11 }
    ldxb r1, [r7+0x30]                      
    jne r1, 0, lbb_12939                            if r1 != (0 as i32 as i64 as u64) { pc += -13 }
    ldxb r1, [r7+0x31]                      
    jne r1, 0, lbb_12939                            if r1 != (0 as i32 as i64 as u64) { pc += -15 }
    add64 r7, 50                                    r7 += 50   ///  r7 = r7.wrapping_add(50 as i32 as i64 as u64)
    ldxdw r1, [r7+0x18]                     
    stxdw [r10-0x8], r1                     
    ldxdw r1, [r7+0x10]                     
    stxdw [r10-0x10], r1                    
    ldxdw r1, [r7+0x8]                      
    stxdw [r10-0x18], r1                    
    ldxdw r1, [r7+0x0]                      
    stxdw [r10-0x20], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -64                                   r1 += -64   ///  r1 = r1.wrapping_add(-64 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -32                                   r2 += -32   ///  r2 = r2.wrapping_add(-32 as i32 as i64 as u64)
    mov64 r7, r3                                    r7 = r3
    call function_17968                     
    mov64 r3, r7                                    r3 = r7
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
lbb_12971:
    stxdw [r10-0xc0], r3                    
    stxw [r10-0x44], r1                     
    mov64 r7, r10                                   r7 = r10
    add64 r7, -108                                  r7 += -108   ///  r7 = r7.wrapping_add(-108 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -68                                   r2 += -68   ///  r2 = r2.wrapping_add(-68 as i32 as i64 as u64)
    mov64 r1, r7                                    r1 = r7
    mov64 r3, 36                                    r3 = 36 as i32 as i64 as u64
    call function_21797                     
    stxdw [r10-0xc8], r8                    
    mov64 r8, r10                                   r8 = r10
    add64 r8, -144                                  r8 += -144   ///  r8 = r8.wrapping_add(-144 as i32 as i64 as u64)
    mov64 r1, r8                                    r1 = r8
    mov64 r2, r7                                    r2 = r7
    mov64 r3, 36                                    r3 = 36 as i32 as i64 as u64
    call function_21797                     
    mov64 r1, r6                                    r1 = r6
    add64 r1, 8                                     r1 += 8   ///  r1 = r1.wrapping_add(8 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -184                                  r2 += -184   ///  r2 = r2.wrapping_add(-184 as i32 as i64 as u64)
    mov64 r3, 36                                    r3 = 36 as i32 as i64 as u64
    call function_21797                     
    mov64 r1, r10                                   r1 = r10
    add64 r1, -70                                   r1 += -70   ///  r1 = r1.wrapping_add(-70 as i32 as i64 as u64)
    mov64 r2, r8                                    r2 = r8
    mov64 r3, 36                                    r3 = 36 as i32 as i64 as u64
    call function_21797                     
    stxb [r6+0x39], r9                      
    ldxdw r1, [r10-0xc0]                    
    stxb [r6+0x38], r1                      
    ldxdw r1, [r10-0xc8]                    
    stxdw [r6+0x30], r1                     
    mov64 r1, r6                                    r1 = r6
    add64 r1, 58                                    r1 += 58   ///  r1 = r1.wrapping_add(58 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -72                                   r2 += -72   ///  r2 = r2.wrapping_add(-72 as i32 as i64 as u64)
    mov64 r3, 38                                    r3 = 38 as i32 as i64 as u64
    call function_21797                     
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    ja lbb_12879                                    if true { pc += -132 }

function_13011:
    ldxb r1, [r1+0x6c]                      
    mov64 r0, 1                                     r0 = 1 as i32 as i64 as u64
    jne r1, 0, lbb_13015                            if r1 != (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r0, 0                                     r0 = 0 as i32 as i64 as u64
lbb_13015:
    exit                                    

function_13016:
    mov64 r7, r2                                    r7 = r2
    mov64 r6, r1                                    r6 = r1
    jgt r3, 164, lbb_13025                          if r3 > (164 as i32 as i64 as u64) { pc += 6 }
    mov64 r1, 165                                   r1 = 165 as i32 as i64 as u64
    mov64 r2, r3                                    r2 = r3
    lddw r3, 0x10002dee8 --> b"\x00\x00\x00\x00G\xcb\x02\x00\x0c\x00\x00\x00\x00\x00\x00\x00~\x00\x00\x0…        r3 load str located at 4295155432
    call function_20726                     
    syscall [invalid]                       
lbb_13025:
    ldxdw r1, [r7+0x18]                     
    stxdw [r10-0x30], r1                    
    ldxdw r1, [r7+0x10]                     
    stxdw [r10-0x38], r1                    
    ldxdw r1, [r7+0x8]                      
    stxdw [r10-0x40], r1                    
    ldxdw r1, [r7+0x0]                      
    stxdw [r10-0x48], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -216                                  r1 += -216   ///  r1 = r1.wrapping_add(-216 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -72                                   r2 += -72   ///  r2 = r2.wrapping_add(-72 as i32 as i64 as u64)
    call function_17968                     
    ldxdw r1, [r7+0x38]                     
    stxdw [r10-0x30], r1                    
    ldxdw r1, [r7+0x30]                     
    stxdw [r10-0x38], r1                    
    ldxdw r1, [r7+0x28]                     
    stxdw [r10-0x40], r1                    
    ldxdw r1, [r7+0x20]                     
    stxdw [r10-0x48], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -184                                  r1 += -184   ///  r1 = r1.wrapping_add(-184 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -72                                   r2 += -72   ///  r2 = r2.wrapping_add(-72 as i32 as i64 as u64)
    call function_17968                     
    ldxdw r8, [r7+0x40]                     
    ldxb r1, [r7+0x48]                      
    jeq r1, 0, lbb_13072                            if r1 == (0 as i32 as i64 as u64) { pc += 18 }
    jeq r1, 1, lbb_13080                            if r1 == (1 as i32 as i64 as u64) { pc += 25 }
lbb_13055:
    mov64 r1, 3                                     r1 = 3 as i32 as i64 as u64
    stxw [r10-0x40], r1                     
    ldxdw r1, [r10-0x38]                    
    stxdw [r10-0x88], r1                    
    ldxdw r2, [r10-0x30]                    
    stxdw [r10-0x80], r2                    
    ldxdw r3, [r10-0x28]                    
    stxdw [r10-0x78], r3                    
    ldxdw r4, [r10-0x40]                    
    stxdw [r10-0x90], r4                    
lbb_13065:
    stxdw [r6+0x20], r3                     
    stxdw [r6+0x18], r2                     
    stxdw [r6+0x10], r1                     
    stxdw [r6+0x8], r4                      
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
lbb_13070:
    stxdw [r6+0x0], r1                      
lbb_13071:
    exit                                    
lbb_13072:
    ldxb r1, [r7+0x49]                      
    jne r1, 0, lbb_13055                            if r1 != (0 as i32 as i64 as u64) { pc += -19 }
    ldxb r1, [r7+0x4a]                      
    jne r1, 0, lbb_13055                            if r1 != (0 as i32 as i64 as u64) { pc += -21 }
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    ldxb r2, [r7+0x4b]                      
    jeq r2, 0, lbb_13102                            if r2 == (0 as i32 as i64 as u64) { pc += 23 }
    ja lbb_13055                                    if true { pc += -25 }
lbb_13080:
    ldxb r1, [r7+0x49]                      
    jne r1, 0, lbb_13055                            if r1 != (0 as i32 as i64 as u64) { pc += -27 }
    ldxb r1, [r7+0x4a]                      
    jne r1, 0, lbb_13055                            if r1 != (0 as i32 as i64 as u64) { pc += -29 }
    ldxb r1, [r7+0x4b]                      
    jne r1, 0, lbb_13055                            if r1 != (0 as i32 as i64 as u64) { pc += -31 }
    mov64 r1, r7                                    r1 = r7
    add64 r1, 76                                    r1 += 76   ///  r1 = r1.wrapping_add(76 as i32 as i64 as u64)
    ldxdw r2, [r1+0x18]                     
    stxdw [r10-0x58], r2                    
    ldxdw r2, [r1+0x10]                     
    stxdw [r10-0x60], r2                    
    ldxdw r2, [r1+0x8]                      
    stxdw [r10-0x68], r2                    
    ldxdw r1, [r1+0x0]                      
    stxdw [r10-0x70], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -64                                   r1 += -64   ///  r1 = r1.wrapping_add(-64 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -112                                  r2 += -112   ///  r2 = r2.wrapping_add(-112 as i32 as i64 as u64)
    call function_17968                     
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
lbb_13102:
    stxw [r10-0x44], r1                     
    mov64 r1, r10                                   r1 = r10
    add64 r1, -148                                  r1 += -148   ///  r1 = r1.wrapping_add(-148 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -68                                   r2 += -68   ///  r2 = r2.wrapping_add(-68 as i32 as i64 as u64)
    mov64 r3, 36                                    r3 = 36 as i32 as i64 as u64
    call function_21797                     
    ldxb r9, [r7+0x6c]                      
    mov64 r1, 3                                     r1 = 3 as i32 as i64 as u64
    jgt r1, r9, lbb_13113                           if r1 > r9 { pc += 1 }
    ja lbb_13128                                    if true { pc += 15 }
lbb_13113:
    ldxb r1, [r7+0x6d]                      
    jeq r1, 1, lbb_13132                            if r1 == (1 as i32 as i64 as u64) { pc += 17 }
    jne r1, 0, lbb_13123                            if r1 != (0 as i32 as i64 as u64) { pc += 7 }
    ldxb r1, [r7+0x6e]                      
    jne r1, 0, lbb_13123                            if r1 != (0 as i32 as i64 as u64) { pc += 5 }
    ldxb r1, [r7+0x6f]                      
    jne r1, 0, lbb_13123                            if r1 != (0 as i32 as i64 as u64) { pc += 3 }
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
    ldxb r1, [r7+0x70]                      
    jeq r1, 0, lbb_13141                            if r1 == (0 as i32 as i64 as u64) { pc += 18 }
lbb_13123:
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    stxdw [r6+0x0], r1                      
    mov64 r1, 3                                     r1 = 3 as i32 as i64 as u64
    stxw [r6+0x8], r1                       
    ja lbb_13071                                    if true { pc += -57 }
lbb_13128:
    mov64 r2, 1                                     r2 = 1 as i32 as i64 as u64
    stxdw [r6+0x0], r2                      
    stxw [r6+0x8], r1                       
    ja lbb_13071                                    if true { pc += -61 }
lbb_13132:
    ldxb r1, [r7+0x6e]                      
    jne r1, 0, lbb_13123                            if r1 != (0 as i32 as i64 as u64) { pc += -11 }
    ldxb r1, [r7+0x6f]                      
    jne r1, 0, lbb_13123                            if r1 != (0 as i32 as i64 as u64) { pc += -13 }
    ldxb r1, [r7+0x70]                      
    jne r1, 0, lbb_13123                            if r1 != (0 as i32 as i64 as u64) { pc += -15 }
    mov64 r3, 1                                     r3 = 1 as i32 as i64 as u64
    ldxdw r1, [r7+0x71]                     
    stxdw [r10-0x128], r1                   
lbb_13141:
    ldxdw r4, [r7+0x79]                     
    ldxb r1, [r7+0x81]                      
    jeq r1, 0, lbb_13156                            if r1 == (0 as i32 as i64 as u64) { pc += 12 }
    jeq r1, 1, lbb_13164                            if r1 == (1 as i32 as i64 as u64) { pc += 19 }
lbb_13145:
    mov64 r1, 3                                     r1 = 3 as i32 as i64 as u64
    stxw [r10-0x40], r1                     
    ldxdw r1, [r10-0x38]                    
    stxdw [r10-0x64], r1                    
    ldxdw r2, [r10-0x30]                    
    stxdw [r10-0x5c], r2                    
    ldxdw r3, [r10-0x28]                    
    stxdw [r10-0x54], r3                    
    ldxdw r4, [r10-0x40]                    
    stxdw [r10-0x6c], r4                    
    ja lbb_13065                                    if true { pc += -91 }
lbb_13156:
    ldxb r1, [r7+0x82]                      
    jne r1, 0, lbb_13145                            if r1 != (0 as i32 as i64 as u64) { pc += -13 }
    ldxb r1, [r7+0x83]                      
    jne r1, 0, lbb_13145                            if r1 != (0 as i32 as i64 as u64) { pc += -15 }
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    ldxb r2, [r7+0x84]                      
    jeq r2, 0, lbb_13189                            if r2 == (0 as i32 as i64 as u64) { pc += 26 }
    ja lbb_13145                                    if true { pc += -19 }
lbb_13164:
    ldxb r1, [r7+0x82]                      
    jne r1, 0, lbb_13145                            if r1 != (0 as i32 as i64 as u64) { pc += -21 }
    ldxb r1, [r7+0x83]                      
    jne r1, 0, lbb_13145                            if r1 != (0 as i32 as i64 as u64) { pc += -23 }
    ldxb r1, [r7+0x84]                      
    jne r1, 0, lbb_13145                            if r1 != (0 as i32 as i64 as u64) { pc += -25 }
    add64 r7, 133                                   r7 += 133   ///  r7 = r7.wrapping_add(133 as i32 as i64 as u64)
    ldxdw r1, [r7+0x18]                     
    stxdw [r10-0x8], r1                     
    ldxdw r1, [r7+0x10]                     
    stxdw [r10-0x10], r1                    
    ldxdw r1, [r7+0x8]                      
    stxdw [r10-0x18], r1                    
    ldxdw r1, [r7+0x0]                      
    stxdw [r10-0x20], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -64                                   r1 += -64   ///  r1 = r1.wrapping_add(-64 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -32                                   r2 += -32   ///  r2 = r2.wrapping_add(-32 as i32 as i64 as u64)
    stxdw [r10-0x120], r3                   
    mov64 r7, r4                                    r7 = r4
    call function_17968                     
    mov64 r4, r7                                    r4 = r7
    ldxdw r3, [r10-0x120]                   
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
lbb_13189:
    stxdw [r10-0x130], r4                   
    stxdw [r10-0x120], r3                   
    stxw [r10-0x44], r1                     
    mov64 r7, r10                                   r7 = r10
    add64 r7, -112                                  r7 += -112   ///  r7 = r7.wrapping_add(-112 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -68                                   r2 += -68   ///  r2 = r2.wrapping_add(-68 as i32 as i64 as u64)
    mov64 r1, r7                                    r1 = r7
    mov64 r3, 36                                    r3 = 36 as i32 as i64 as u64
    call function_21797                     
    mov64 r1, r6                                    r1 = r6
    add64 r1, 144                                   r1 += 144   ///  r1 = r1.wrapping_add(144 as i32 as i64 as u64)
    mov64 r2, r7                                    r2 = r7
    mov64 r3, 36                                    r3 = 36 as i32 as i64 as u64
    call function_21797                     
    ldxdw r1, [r10-0xd8]                    
    stxdw [r10-0x118], r1                   
    ldxdw r1, [r10-0xd0]                    
    stxdw [r10-0x110], r1                   
    ldxdw r1, [r10-0xc8]                    
    stxdw [r10-0x108], r1                   
    ldxdw r1, [r10-0xc0]                    
    stxdw [r10-0x100], r1                   
    ldxdw r1, [r10-0xb8]                    
    stxdw [r10-0xf8], r1                    
    ldxdw r1, [r10-0xb0]                    
    stxdw [r10-0xf0], r1                    
    ldxdw r1, [r10-0xa8]                    
    stxdw [r10-0xe8], r1                    
    ldxdw r1, [r10-0xa0]                    
    stxdw [r10-0xe0], r1                    
    mov64 r1, r6                                    r1 = r6
    add64 r1, 80                                    r1 += 80   ///  r1 = r1.wrapping_add(80 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -148                                  r2 += -148   ///  r2 = r2.wrapping_add(-148 as i32 as i64 as u64)
    mov64 r3, 36                                    r3 = 36 as i32 as i64 as u64
    call function_21797                     
    mov64 r1, r6                                    r1 = r6
    add64 r1, 8                                     r1 += 8   ///  r1 = r1.wrapping_add(8 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -280                                  r2 += -280   ///  r2 = r2.wrapping_add(-280 as i32 as i64 as u64)
    mov64 r3, 64                                    r3 = 64 as i32 as i64 as u64
    call function_21797                     
    ldxdw r1, [r10-0x130]                   
    stxdw [r6+0x88], r1                     
    ldxdw r1, [r10-0x128]                   
    stxdw [r6+0x80], r1                     
    ldxdw r1, [r10-0x120]                   
    stxw [r6+0x78], r1                      
    stxb [r6+0x74], r9                      
    stxdw [r6+0x48], r8                     
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    ja lbb_13070                                    if true { pc += -172 }

function_13242:
    lddw r0, 0x6436232572d50cba                     r0 load str located at 7220997696282496186
    exit                                    

function_13245:
    stxdw [r10-0x10], r1                    
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    stxb [r10-0x8], r1                      
    stxdw [r10-0x18], r1                    
    lddw r1, 0x10002df00 --> b"\x00\x00\x00\x00\xd0\xa0\x01\x00\x00\x00\x00\x00\x00\x00\x00\x00\x01\x00\…        r1 load str located at 4295155456
    stxdw [r10-0x20], r1                    
    lddw r1, 0x10002cb78 --> b"called `Option::unwrap()` on a `None` valuesrc/pre"        r1 load str located at 4295150456
    stxdw [r10-0x28], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -40                                   r1 += -40   ///  r1 = r1.wrapping_add(-40 as i32 as i64 as u64)
    call function_18571                     
    syscall [invalid]                       

function_13259:
    ldxdw r4, [r2+0x18]                     
    ldxdw r5, [r1+0x18]                     
    mov64 r0, 1                                     r0 = 1 as i32 as i64 as u64
    jne r5, r4, lbb_13264                           if r5 != r4 { pc += 1 }
    mov64 r0, 0                                     r0 = 0 as i32 as i64 as u64
lbb_13264:
    mov64 r3, -1                                    r3 = -1 as i32 as i64 as u64
    jgt r4, r5, lbb_13267                           if r4 > r5 { pc += 1 }
    mov64 r3, r0                                    r3 = r0
lbb_13267:
    jne r3, 0, lbb_13296                            if r3 != (0 as i32 as i64 as u64) { pc += 28 }
    ldxdw r4, [r2+0x10]                     
    ldxdw r5, [r1+0x10]                     
    mov64 r0, 1                                     r0 = 1 as i32 as i64 as u64
    jne r5, r4, lbb_13273                           if r5 != r4 { pc += 1 }
    mov64 r0, 0                                     r0 = 0 as i32 as i64 as u64
lbb_13273:
    mov64 r3, -1                                    r3 = -1 as i32 as i64 as u64
    jgt r4, r5, lbb_13276                           if r4 > r5 { pc += 1 }
    mov64 r3, r0                                    r3 = r0
lbb_13276:
    jne r3, 0, lbb_13296                            if r3 != (0 as i32 as i64 as u64) { pc += 19 }
    ldxdw r4, [r2+0x8]                      
    ldxdw r5, [r1+0x8]                      
    mov64 r0, 1                                     r0 = 1 as i32 as i64 as u64
    jne r5, r4, lbb_13282                           if r5 != r4 { pc += 1 }
    mov64 r0, 0                                     r0 = 0 as i32 as i64 as u64
lbb_13282:
    mov64 r3, -1                                    r3 = -1 as i32 as i64 as u64
    jgt r4, r5, lbb_13285                           if r4 > r5 { pc += 1 }
    mov64 r3, r0                                    r3 = r0
lbb_13285:
    jne r3, 0, lbb_13296                            if r3 != (0 as i32 as i64 as u64) { pc += 10 }
    ldxdw r2, [r2+0x0]                      
    ldxdw r4, [r1+0x0]                      
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    mov64 r5, 1                                     r5 = 1 as i32 as i64 as u64
    jne r4, r2, lbb_13292                           if r4 != r2 { pc += 1 }
    mov64 r5, 0                                     r5 = 0 as i32 as i64 as u64
lbb_13292:
    mov64 r3, -1                                    r3 = -1 as i32 as i64 as u64
    jgt r2, r4, lbb_13295                           if r2 > r4 { pc += 1 }
    mov64 r3, r5                                    r3 = r5
lbb_13295:
    jeq r3, 0, lbb_13297                            if r3 == (0 as i32 as i64 as u64) { pc += 1 }
lbb_13296:
    mov64 r1, r3                                    r1 = r3
lbb_13297:
    and64 r1, 255                                   r1 &= 255   ///  r1 = r1.and(255)
    mov64 r0, 1                                     r0 = 1 as i32 as i64 as u64
    jeq r1, 1, lbb_13301                            if r1 == (1 as i32 as i64 as u64) { pc += 1 }
    mov64 r0, 0                                     r0 = 0 as i32 as i64 as u64
lbb_13301:
    exit                                    

function_13302:
    exit                                    

function_13303:
    mov64 r9, r4                                    r9 = r4
    mov64 r6, r3                                    r6 = r3
    or64 r3, r9                                     r3 |= r9   ///  r3 = r3.or(r9)
    mov64 r0, 0                                     r0 = 0 as i32 as i64 as u64
    jeq r3, 0, lbb_13359                            if r3 == (0 as i32 as i64 as u64) { pc += 51 }
    stxdw [r10-0x48], r1                    
    ldxdw r8, [r2+0x8]                      
    ldxdw r7, [r2+0x0]                      
    mov64 r1, r10                                   r1 = r10
    add64 r1, -16                                   r1 += -16   ///  r1 = r1.wrapping_add(-16 as i32 as i64 as u64)
    mov64 r2, r7                                    r2 = r7
    mov64 r3, r8                                    r3 = r8
    mov64 r4, r6                                    r4 = r6
    mov64 r5, r9                                    r5 = r9
    call function_21948                     
    mov64 r0, 0                                     r0 = 0 as i32 as i64 as u64
    mov64 r3, 1                                     r3 = 1 as i32 as i64 as u64
    mov64 r2, 1                                     r2 = 1 as i32 as i64 as u64
    jgt r6, r7, lbb_13323                           if r6 > r7 { pc += 1 }
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
lbb_13323:
    jgt r9, r8, lbb_13325                           if r9 > r8 { pc += 1 }
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
lbb_13325:
    ldxdw r1, [r10-0x48]                    
    jeq r8, r9, lbb_13328                           if r8 == r9 { pc += 1 }
    mov64 r2, r3                                    r2 = r3
lbb_13328:
    and64 r2, 1                                     r2 &= 1   ///  r2 = r2.and(1)
    jne r2, 0, lbb_13359                            if r2 != (0 as i32 as i64 as u64) { pc += 29 }
    ldxdw r3, [r10-0x8]                     
    ldxdw r2, [r10-0x10]                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -32                                   r1 += -32   ///  r1 = r1.wrapping_add(-32 as i32 as i64 as u64)
    stxdw [r10-0x50], r2                    
    stxdw [r10-0x58], r3                    
    mov64 r4, r6                                    r4 = r6
    mov64 r5, r9                                    r5 = r9
    call function_21911                     
    mov64 r2, 1                                     r2 = 1 as i32 as i64 as u64
    ldxdw r1, [r10-0x20]                    
    jgt r1, r7, lbb_13343                           if r1 > r7 { pc += 1 }
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
lbb_13343:
    ldxdw r3, [r10-0x18]                    
    mov64 r4, r8                                    r4 = r8
    sub64 r4, r3                                    r4 -= r3   ///  r4 = r4.wrapping_sub(r3)
    sub64 r4, r2                                    r4 -= r2   ///  r4 = r4.wrapping_sub(r2)
    mov64 r2, r7                                    r2 = r7
    sub64 r2, r1                                    r2 -= r1   ///  r2 = r2.wrapping_sub(r1)
    or64 r2, r4                                     r2 |= r4   ///  r2 = r2.or(r4)
    ldxdw r1, [r10-0x48]                    
    jne r2, 0, lbb_13361                            if r2 != (0 as i32 as i64 as u64) { pc += 9 }
lbb_13352:
    stxdw [r1+0x18], r6                     
    ldxdw r2, [r10-0x50]                    
    stxdw [r1+0x8], r2                      
    stxdw [r1+0x20], r9                     
    ldxdw r2, [r10-0x58]                    
    stxdw [r1+0x10], r2                     
    mov64 r0, 1                                     r0 = 1 as i32 as i64 as u64
lbb_13359:
    stxdw [r1+0x0], r0                      
    exit                                    
lbb_13361:
    ldxdw r6, [r10-0x50]                    
    mov64 r4, r6                                    r4 = r6
    add64 r4, 1                                     r4 += 1   ///  r4 = r4.wrapping_add(1 as i32 as i64 as u64)
    mov64 r0, 0                                     r0 = 0 as i32 as i64 as u64
    mov64 r3, 1                                     r3 = 1 as i32 as i64 as u64
    mov64 r2, 1                                     r2 = 1 as i32 as i64 as u64
    jgt r6, r4, lbb_13369                           if r6 > r4 { pc += 1 }
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
lbb_13369:
    ldxdw r9, [r10-0x58]                    
    mov64 r5, r9                                    r5 = r9
    add64 r5, r2                                    r5 += r2   ///  r5 = r5.wrapping_add(r2)
    jgt r9, r5, lbb_13374                           if r9 > r5 { pc += 1 }
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
lbb_13374:
    jge r4, r6, lbb_13376                           if r4 >= r6 { pc += 1 }
    mov64 r2, r3                                    r2 = r3
lbb_13376:
    and64 r2, 1                                     r2 &= 1   ///  r2 = r2.and(1)
    jne r2, 0, lbb_13359                            if r2 != (0 as i32 as i64 as u64) { pc += -19 }
    mov64 r1, r10                                   r1 = r10
    add64 r1, -48                                   r1 += -48   ///  r1 = r1.wrapping_add(-48 as i32 as i64 as u64)
    mov64 r2, r7                                    r2 = r7
    mov64 r3, r8                                    r3 = r8
    stxdw [r10-0x60], r4                    
    stxdw [r10-0x68], r5                    
    call function_21948                     
    mov64 r1, r10                                   r1 = r10
    add64 r1, -64                                   r1 += -64   ///  r1 = r1.wrapping_add(-64 as i32 as i64 as u64)
    ldxdw r6, [r10-0x30]                    
    ldxdw r9, [r10-0x28]                    
    mov64 r2, r6                                    r2 = r6
    mov64 r3, r9                                    r3 = r9
    ldxdw r4, [r10-0x60]                    
    ldxdw r5, [r10-0x68]                    
    call function_21911                     
    mov64 r2, 1                                     r2 = 1 as i32 as i64 as u64
    ldxdw r1, [r10-0x40]                    
    jgt r1, r7, lbb_13398                           if r1 > r7 { pc += 1 }
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
lbb_13398:
    ldxdw r3, [r10-0x38]                    
    sub64 r8, r3                                    r8 -= r3   ///  r8 = r8.wrapping_sub(r3)
    sub64 r8, r2                                    r8 -= r2   ///  r8 = r8.wrapping_sub(r2)
    sub64 r7, r1                                    r7 -= r1   ///  r7 = r7.wrapping_sub(r1)
    or64 r7, r8                                     r7 |= r8   ///  r7 = r7.or(r8)
    ldxdw r4, [r10-0x60]                    
    stxdw [r10-0x50], r4                    
    ldxdw r5, [r10-0x68]                    
    stxdw [r10-0x58], r5                    
    ldxdw r1, [r10-0x48]                    
    jeq r7, 0, lbb_13352                            if r7 == (0 as i32 as i64 as u64) { pc += -57 }
    mov64 r3, r6                                    r3 = r6
    add64 r3, 1                                     r3 += 1   ///  r3 = r3.wrapping_add(1 as i32 as i64 as u64)
    mov64 r2, 1                                     r2 = 1 as i32 as i64 as u64
    jgt r6, r3, lbb_13414                           if r6 > r3 { pc += 1 }
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
lbb_13414:
    add64 r9, r2                                    r9 += r2   ///  r9 = r9.wrapping_add(r2)
    stxdw [r10-0x50], r4                    
    stxdw [r10-0x58], r5                    
    mov64 r6, r3                                    r6 = r3
    ja lbb_13352                                    if true { pc += -67 }

function_13419:
    mov64 r8, r2                                    r8 = r2
    ldxdw r4, [r3+0x18]                     
    ldxdw r2, [r3+0x10]                     
    ldxdw r6, [r3+0x8]                      
    ldxdw r9, [r3+0x0]                      
    jne r9, 0, lbb_13428                            if r9 != (0 as i32 as i64 as u64) { pc += 3 }
    jne r6, 0, lbb_13428                            if r6 != (0 as i32 as i64 as u64) { pc += 2 }
    jne r2, 0, lbb_13428                            if r2 != (0 as i32 as i64 as u64) { pc += 1 }
    jeq r4, 0, lbb_13529                            if r4 == (0 as i32 as i64 as u64) { pc += 101 }
lbb_13428:
    stxdw [r10-0x100], r3                   
    stxdw [r10-0xe8], r1                    
    ldxdw r1, [r8+0x18]                     
    stxdw [r10-0x28], r1                    
    ldxdw r1, [r8+0x10]                     
    stxdw [r10-0x30], r1                    
    ldxdw r1, [r8+0x8]                      
    stxdw [r10-0x38], r1                    
    ldxdw r1, [r8+0x0]                      
    stxdw [r10-0x40], r1                    
    stxdw [r10-0x8], r4                     
    stxdw [r10-0x10], r2                    
    stxdw [r10-0x18], r6                    
    stxdw [r10-0x20], r9                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -128                                  r1 += -128   ///  r1 = r1.wrapping_add(-128 as i32 as i64 as u64)
    stxdw [r10-0xf0], r2                    
    mov64 r2, r10                                   r2 = r10
    add64 r2, -64                                   r2 += -64   ///  r2 = r2.wrapping_add(-64 as i32 as i64 as u64)
    mov64 r3, r10                                   r3 = r10
    add64 r3, -32                                   r3 += -32   ///  r3 = r3.wrapping_add(-32 as i32 as i64 as u64)
    stxdw [r10-0xf8], r4                    
    call function_15536                     
    ldxdw r1, [r10-0x80]                    
    stxdw [r10-0xe0], r1                    
    ldxdw r1, [r10-0x78]                    
    stxdw [r10-0xd8], r1                    
    ldxdw r1, [r10-0x70]                    
    stxdw [r10-0xd0], r1                    
    ldxdw r1, [r10-0x68]                    
    stxdw [r10-0xc8], r1                    
    mov64 r7, 0                                     r7 = 0 as i32 as i64 as u64
    stxdw [r10-0xa8], r7                    
    stxdw [r10-0xb0], r7                    
    stxdw [r10-0xb8], r7                    
    stxdw [r10-0xc0], r7                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -224                                  r1 += -224   ///  r1 = r1.wrapping_add(-224 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -192                                  r2 += -192   ///  r2 = r2.wrapping_add(-192 as i32 as i64 as u64)
    mov64 r3, 32                                    r3 = 32 as i32 as i64 as u64
    call function_21867                     
    lsh64 r0, 32                                    r0 <<= 32   ///  r0 = r0.wrapping_shl(32)
    rsh64 r0, 32                                    r0 >>= 32   ///  r0 = r0.wrapping_shr(32)
    jeq r0, 0, lbb_13532                            if r0 == (0 as i32 as i64 as u64) { pc += 59 }
    ldxdw r1, [r8+0x18]                     
    stxdw [r10-0x28], r1                    
    ldxdw r1, [r8+0x10]                     
    stxdw [r10-0x30], r1                    
    ldxdw r1, [r8+0x8]                      
    stxdw [r10-0x38], r1                    
    ldxdw r1, [r8+0x0]                      
    stxdw [r10-0x40], r1                    
    ldxdw r1, [r10-0xf8]                    
    stxdw [r10-0x8], r1                     
    ldxdw r1, [r10-0xf0]                    
    stxdw [r10-0x10], r1                    
    stxdw [r10-0x18], r6                    
    stxdw [r10-0x20], r9                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -128                                  r1 += -128   ///  r1 = r1.wrapping_add(-128 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -64                                   r2 += -64   ///  r2 = r2.wrapping_add(-64 as i32 as i64 as u64)
    mov64 r3, r10                                   r3 = r10
    add64 r3, -32                                   r3 += -32   ///  r3 = r3.wrapping_add(-32 as i32 as i64 as u64)
    call function_15536                     
    ldxdw r1, [r10-0x48]                    
    jne r1, 0, lbb_13535                            if r1 != (0 as i32 as i64 as u64) { pc += 39 }
    ldxdw r1, [r10-0x50]                    
    jne r1, 0, lbb_13535                            if r1 != (0 as i32 as i64 as u64) { pc += 37 }
    ldxdw r1, [r10-0x58]                    
    jne r1, 0, lbb_13535                            if r1 != (0 as i32 as i64 as u64) { pc += 35 }
    ldxdw r1, [r10-0x60]                    
    jne r1, 0, lbb_13535                            if r1 != (0 as i32 as i64 as u64) { pc += 33 }
lbb_13502:
    ldxdw r1, [r10-0xc8]                    
    stxdw [r10-0x68], r1                    
    ldxdw r1, [r10-0xd0]                    
    stxdw [r10-0x70], r1                    
    ldxdw r1, [r10-0xd8]                    
    stxdw [r10-0x78], r1                    
    ldxdw r1, [r10-0xe0]                    
    stxdw [r10-0x80], r1                    
    ldxdw r2, [r10-0x100]                   
    ldxdw r1, [r2+0x0]                      
    stxdw [r10-0x60], r1                    
    ldxdw r1, [r2+0x8]                      
    stxdw [r10-0x58], r1                    
    ldxdw r1, [r2+0x10]                     
    stxdw [r10-0x50], r1                    
    ldxdw r1, [r2+0x18]                     
    stxdw [r10-0x48], r1                    
    ldxdw r6, [r10-0xe8]                    
    mov64 r1, r6                                    r1 = r6
    add64 r1, 8                                     r1 += 8   ///  r1 = r1.wrapping_add(8 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -128                                  r2 += -128   ///  r2 = r2.wrapping_add(-128 as i32 as i64 as u64)
    mov64 r3, 64                                    r3 = 64 as i32 as i64 as u64
    call function_21797                     
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    stxdw [r6+0x0], r1                      
    ja lbb_13689                                    if true { pc += 160 }
lbb_13529:
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
    stxdw [r1+0x0], r2                      
    ja lbb_13689                                    if true { pc += 157 }
lbb_13532:
    ldxdw r1, [r10-0xe8]                    
    stxdw [r1+0x0], r7                      
    ja lbb_13689                                    if true { pc += 154 }
lbb_13535:
    ldxdw r2, [r10-0xe0]                    
    mov64 r1, r2                                    r1 = r2
    add64 r1, 1                                     r1 += 1   ///  r1 = r1.wrapping_add(1 as i32 as i64 as u64)
    mov64 r6, 1                                     r6 = 1 as i32 as i64 as u64
    mov64 r4, 1                                     r4 = 1 as i32 as i64 as u64
    jgt r2, r1, lbb_13542                           if r2 > r1 { pc += 1 }
    mov64 r4, 0                                     r4 = 0 as i32 as i64 as u64
lbb_13542:
    mov64 r9, r8                                    r9 = r8
    ldxdw r0, [r10-0xd8]                    
    mov64 r2, r0                                    r2 = r0
    add64 r2, 1                                     r2 += 1   ///  r2 = r2.wrapping_add(1 as i32 as i64 as u64)
    mov64 r3, 1                                     r3 = 1 as i32 as i64 as u64
    jgt r0, r2, lbb_13549                           if r0 > r2 { pc += 1 }
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
lbb_13549:
    mov64 r7, r4                                    r7 = r4
    and64 r7, r3                                    r7 &= r3   ///  r7 = r7.and(r3)
    ldxdw r5, [r10-0xd0]                    
    mov64 r3, r5                                    r3 = r5
    add64 r3, r7                                    r3 += r7   ///  r3 = r3.wrapping_add(r7)
    mov64 r8, 1                                     r8 = 1 as i32 as i64 as u64
    jgt r5, r3, lbb_13557                           if r5 > r3 { pc += 1 }
    mov64 r8, 0                                     r8 = 0 as i32 as i64 as u64
lbb_13557:
    jne r7, 0, lbb_13559                            if r7 != (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r3, r5                                    r3 = r5
lbb_13559:
    and64 r7, r8                                    r7 &= r8   ///  r7 = r7.and(r8)
    ldxdw r8, [r10-0xc8]                    
    mov64 r5, r8                                    r5 = r8
    add64 r5, r7                                    r5 += r7   ///  r5 = r5.wrapping_add(r7)
    jgt r8, r5, lbb_13565                           if r8 > r5 { pc += 1 }
    mov64 r6, 0                                     r6 = 0 as i32 as i64 as u64
lbb_13565:
    jne r7, 0, lbb_13567                            if r7 != (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r5, r8                                    r5 = r8
lbb_13567:
    and64 r7, r6                                    r7 &= r6   ///  r7 = r7.and(r6)
    and64 r7, 1                                     r7 &= 1   ///  r7 = r7.and(1)
    jne r7, 0, lbb_13686                            if r7 != (0 as i32 as i64 as u64) { pc += 116 }
    mov64 r6, r4                                    r6 = r4
    and64 r6, 1                                     r6 &= 1   ///  r6 = r6.and(1)
    jne r6, 0, lbb_13574                            if r6 != (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r2, r0                                    r2 = r0
lbb_13574:
    mov64 r0, 1                                     r0 = 1 as i32 as i64 as u64
    jeq r2, 0, lbb_13577                            if r2 == (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r0, 0                                     r0 = 0 as i32 as i64 as u64
lbb_13577:
    and64 r4, r0                                    r4 &= r0   ///  r4 = r4.and(r0)
    stxdw [r10-0xc8], r5                    
    stxdw [r10-0xd0], r3                    
    stxdw [r10-0xe0], r1                    
    stxdw [r10-0xd8], r2                    
    jne r4, 1, lbb_13585                            if r4 != (1 as i32 as i64 as u64) { pc += 2 }
    jne r3, 0, lbb_13585                            if r3 != (0 as i32 as i64 as u64) { pc += 1 }
    jeq r5, 0, lbb_13686                            if r5 == (0 as i32 as i64 as u64) { pc += 101 }
lbb_13585:
    ldxdw r4, [r9+0x18]                     
    stxdw [r10-0x28], r4                    
    ldxdw r4, [r9+0x10]                     
    stxdw [r10-0x30], r4                    
    ldxdw r4, [r9+0x8]                      
    stxdw [r10-0x38], r4                    
    ldxdw r4, [r9+0x0]                      
    stxdw [r10-0x40], r4                    
    stxdw [r10-0x8], r5                     
    stxdw [r10-0x10], r3                    
    stxdw [r10-0x18], r2                    
    stxdw [r10-0x20], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -128                                  r1 += -128   ///  r1 = r1.wrapping_add(-128 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -64                                   r2 += -64   ///  r2 = r2.wrapping_add(-64 as i32 as i64 as u64)
    mov64 r3, r10                                   r3 = r10
    add64 r3, -32                                   r3 += -32   ///  r3 = r3.wrapping_add(-32 as i32 as i64 as u64)
    call function_15536                     
    ldxdw r1, [r10-0x68]                    
    ldxdw r2, [r10-0x100]                   
    stxdw [r2+0x18], r1                     
    ldxdw r1, [r10-0x70]                    
    stxdw [r2+0x10], r1                     
    ldxdw r1, [r10-0x78]                    
    stxdw [r2+0x8], r1                      
    ldxdw r1, [r10-0x80]                    
    stxdw [r2+0x0], r1                      
    ldxdw r1, [r9+0x18]                     
    stxdw [r10-0x28], r1                    
    ldxdw r1, [r9+0x10]                     
    stxdw [r10-0x30], r1                    
    ldxdw r1, [r9+0x8]                      
    stxdw [r10-0x38], r1                    
    ldxdw r1, [r9+0x0]                      
    stxdw [r10-0x40], r1                    
    ldxdw r1, [r10-0xc8]                    
    stxdw [r10-0x8], r1                     
    ldxdw r1, [r10-0xd0]                    
    stxdw [r10-0x10], r1                    
    ldxdw r1, [r10-0xd8]                    
    stxdw [r10-0x18], r1                    
    ldxdw r1, [r10-0xe0]                    
    stxdw [r10-0x20], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -128                                  r1 += -128   ///  r1 = r1.wrapping_add(-128 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -64                                   r2 += -64   ///  r2 = r2.wrapping_add(-64 as i32 as i64 as u64)
    mov64 r3, r10                                   r3 = r10
    add64 r3, -32                                   r3 += -32   ///  r3 = r3.wrapping_add(-32 as i32 as i64 as u64)
    call function_17449                     
    ldxdw r1, [r10-0x80]                    
    jeq r1, 0, lbb_13686                            if r1 == (0 as i32 as i64 as u64) { pc += 48 }
    ldxdw r1, [r10-0x60]                    
    stxdw [r10-0x88], r1                    
    ldxdw r1, [r10-0x68]                    
    stxdw [r10-0x90], r1                    
    ldxdw r1, [r10-0x70]                    
    stxdw [r10-0x98], r1                    
    ldxdw r1, [r10-0x78]                    
    stxdw [r10-0xa0], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -160                                  r1 += -160   ///  r1 = r1.wrapping_add(-160 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -192                                  r2 += -192   ///  r2 = r2.wrapping_add(-192 as i32 as i64 as u64)
    call function_13259                     
    jne r0, 0, lbb_13653                            if r0 != (0 as i32 as i64 as u64) { pc += 1 }
    ja lbb_13502                                    if true { pc += -151 }
lbb_13653:
    ldxdw r6, [r10-0x100]                   
    ldxdw r1, [r6+0x18]                     
    stxdw [r10-0x28], r1                    
    ldxdw r1, [r6+0x10]                     
    stxdw [r10-0x30], r1                    
    ldxdw r1, [r6+0x8]                      
    stxdw [r10-0x38], r1                    
    ldxdw r1, [r6+0x0]                      
    stxdw [r10-0x40], r1                    
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    stxdw [r10-0x20], r1                    
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    stxdw [r10-0x18], r1                    
    stxdw [r10-0x10], r1                    
    stxdw [r10-0x8], r1                     
    mov64 r1, r10                                   r1 = r10
    add64 r1, -128                                  r1 += -128   ///  r1 = r1.wrapping_add(-128 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -64                                   r2 += -64   ///  r2 = r2.wrapping_add(-64 as i32 as i64 as u64)
    mov64 r3, r10                                   r3 = r10
    add64 r3, -32                                   r3 += -32   ///  r3 = r3.wrapping_add(-32 as i32 as i64 as u64)
    call function_16882                     
    ldxdw r1, [r10-0x80]                    
    jeq r1, 0, lbb_13686                            if r1 == (0 as i32 as i64 as u64) { pc += 9 }
    ldxdw r1, [r10-0x60]                    
    stxdw [r6+0x18], r1                     
    ldxdw r1, [r10-0x68]                    
    stxdw [r6+0x10], r1                     
    ldxdw r1, [r10-0x70]                    
    stxdw [r6+0x8], r1                      
    ldxdw r1, [r10-0x78]                    
    stxdw [r6+0x0], r1                      
    ja lbb_13502                                    if true { pc += -184 }
lbb_13686:
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    ldxdw r2, [r10-0xe8]                    
    stxdw [r2+0x0], r1                      
lbb_13689:
    exit                                    

function_13690:
    mov64 r6, r1                                    r6 = r1
    stxdw [r10-0x38], r3                    
    stxdw [r10-0x40], r2                    
    mov64 r7, 0                                     r7 = 0 as i32 as i64 as u64
    stxdw [r10-0x28], r7                    
    stxdw [r10-0x30], r7                    
    stxdw [r10-0x8], r7                     
    stxdw [r10-0x10], r7                    
    stxdw [r10-0x18], r7                    
    lddw r1, 0xe8d4a51000                           r1 load str located at 1000000000000
    stxdw [r10-0x20], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -104                                  r1 += -104   ///  r1 = r1.wrapping_add(-104 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -64                                   r2 += -64   ///  r2 = r2.wrapping_add(-64 as i32 as i64 as u64)
    mov64 r3, r10                                   r3 = r10
    add64 r3, -32                                   r3 += -32   ///  r3 = r3.wrapping_add(-32 as i32 as i64 as u64)
    call function_17050                     
    ldxdw r1, [r10-0x68]                    
    jeq r1, 0, lbb_13720                            if r1 == (0 as i32 as i64 as u64) { pc += 9 }
    ldxdw r1, [r10-0x48]                    
    stxdw [r6+0x20], r1                     
    ldxdw r1, [r10-0x50]                    
    stxdw [r6+0x18], r1                     
    ldxdw r1, [r10-0x58]                    
    stxdw [r6+0x10], r1                     
    ldxdw r1, [r10-0x60]                    
    stxdw [r6+0x8], r1                      
    mov64 r7, 1                                     r7 = 1 as i32 as i64 as u64
lbb_13720:
    stxdw [r6+0x0], r7                      
    exit                                    

function_13722:
    stxdw [r10-0x88], r1                    
    ldxdw r3, [r2+0x0]                      
    lddw r4, 0x746a528800                           r4 load str located at 500000000000
    mov64 r1, r3                                    r1 = r3
    add64 r1, r4                                    r1 += r4   ///  r1 = r1.wrapping_add(r4)
    mov64 r7, 1                                     r7 = 1 as i32 as i64 as u64
    mov64 r5, 1                                     r5 = 1 as i32 as i64 as u64
    jgt r3, r1, lbb_13732                           if r3 > r1 { pc += 1 }
    mov64 r5, 0                                     r5 = 0 as i32 as i64 as u64
lbb_13732:
    ldxdw r0, [r2+0x8]                      
    mov64 r4, r0                                    r4 = r0
    add64 r4, 1                                     r4 += 1   ///  r4 = r4.wrapping_add(1 as i32 as i64 as u64)
    mov64 r3, 1                                     r3 = 1 as i32 as i64 as u64
    jgt r0, r4, lbb_13738                           if r0 > r4 { pc += 1 }
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
lbb_13738:
    mov64 r9, r5                                    r9 = r5
    and64 r9, r3                                    r9 &= r3   ///  r9 = r9.and(r3)
    ldxdw r3, [r2+0x10]                     
    mov64 r8, r3                                    r8 = r3
    add64 r8, r9                                    r8 += r9   ///  r8 = r8.wrapping_add(r9)
    mov64 r6, 1                                     r6 = 1 as i32 as i64 as u64
    jgt r3, r8, lbb_13746                           if r3 > r8 { pc += 1 }
    mov64 r6, 0                                     r6 = 0 as i32 as i64 as u64
lbb_13746:
    jne r9, 0, lbb_13748                            if r9 != (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r8, r3                                    r8 = r3
lbb_13748:
    and64 r9, r6                                    r9 &= r6   ///  r9 = r9.and(r6)
    ldxdw r3, [r2+0x18]                     
    mov64 r2, r3                                    r2 = r3
    add64 r2, r9                                    r2 += r9   ///  r2 = r2.wrapping_add(r9)
    jgt r3, r2, lbb_13754                           if r3 > r2 { pc += 1 }
    mov64 r7, 0                                     r7 = 0 as i32 as i64 as u64
lbb_13754:
    mov64 r6, 0                                     r6 = 0 as i32 as i64 as u64
    jne r9, 0, lbb_13757                            if r9 != (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r2, r3                                    r2 = r3
lbb_13757:
    and64 r9, r7                                    r9 &= r7   ///  r9 = r9.and(r7)
    and64 r9, 1                                     r9 &= 1   ///  r9 = r9.and(1)
    jne r9, 0, lbb_13792                            if r9 != (0 as i32 as i64 as u64) { pc += 32 }
    and64 r5, 1                                     r5 &= 1   ///  r5 = r5.and(1)
    jne r5, 0, lbb_13763                            if r5 != (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r4, r0                                    r4 = r0
lbb_13763:
    stxdw [r10-0x28], r2                    
    stxdw [r10-0x30], r8                    
    stxdw [r10-0x40], r1                    
    stxdw [r10-0x38], r4                    
    lddw r1, 0xe8d4a51000                           r1 load str located at 1000000000000
    stxdw [r10-0x20], r1                    
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    stxdw [r10-0x18], r1                    
    stxdw [r10-0x10], r1                    
    stxdw [r10-0x8], r1                     
    mov64 r1, r10                                   r1 = r10
    add64 r1, -128                                  r1 += -128   ///  r1 = r1.wrapping_add(-128 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -64                                   r2 += -64   ///  r2 = r2.wrapping_add(-64 as i32 as i64 as u64)
    mov64 r3, r10                                   r3 = r10
    add64 r3, -32                                   r3 += -32   ///  r3 = r3.wrapping_add(-32 as i32 as i64 as u64)
    call function_15536                     
    ldxdw r1, [r10-0x68]                    
    ldxdw r2, [r10-0x70]                    
    or64 r2, r1                                     r2 |= r1   ///  r2 = r2.or(r1)
    jeq r2, 0, lbb_13789                            if r2 == (0 as i32 as i64 as u64) { pc += 4 }
    lddw r1, 0x10002df50 --> b"\x00\x00\x00\x00\xb8\xcb\x02\x00\x0b\x00\x00\x00\x00\x00\x00\x00\x0a\x00\…        r1 load str located at 4295155536
    call function_13245                     
    syscall [invalid]                       
lbb_13789:
    ldxdw r7, [r10-0x78]                    
    ldxdw r3, [r10-0x80]                    
    mov64 r6, 1                                     r6 = 1 as i32 as i64 as u64
lbb_13792:
    ldxdw r1, [r10-0x88]                    
    stxdw [r1+0x8], r3                      
    stxdw [r1+0x0], r6                      
    stxdw [r1+0x10], r7                     
    exit                                    

function_13797:
    mov64 r6, r1                                    r6 = r1
    ldxdw r1, [r2+0x18]                     
    stxdw [r10-0x28], r1                    
    ldxdw r1, [r2+0x10]                     
    stxdw [r10-0x30], r1                    
    ldxdw r1, [r2+0x8]                      
    stxdw [r10-0x38], r1                    
    ldxdw r1, [r2+0x0]                      
    stxdw [r10-0x40], r1                    
    mov64 r7, 0                                     r7 = 0 as i32 as i64 as u64
    stxdw [r10-0x18], r7                    
    lddw r8, 0xe8d4a51000                           r8 load str located at 1000000000000
    stxdw [r10-0x20], r8                    
    stxdw [r10-0x10], r7                    
    stxdw [r10-0x8], r7                     
    mov64 r1, r10                                   r1 = r10
    add64 r1, -128                                  r1 += -128   ///  r1 = r1.wrapping_add(-128 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -64                                   r2 += -64   ///  r2 = r2.wrapping_add(-64 as i32 as i64 as u64)
    mov64 r3, r10                                   r3 = r10
    add64 r3, -32                                   r3 += -32   ///  r3 = r3.wrapping_add(-32 as i32 as i64 as u64)
    call function_15536                     
    ldxdw r1, [r10-0x80]                    
    stxdw [r10-0xa0], r1                    
    ldxdw r1, [r10-0x78]                    
    stxdw [r10-0x98], r1                    
    ldxdw r1, [r10-0x70]                    
    stxdw [r10-0x90], r1                    
    ldxdw r1, [r10-0x68]                    
    stxdw [r10-0x88], r1                    
    stxdw [r10-0x68], r7                    
    stxdw [r10-0x70], r7                    
    stxdw [r10-0x78], r7                    
    stxdw [r10-0x80], r8                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -200                                  r1 += -200   ///  r1 = r1.wrapping_add(-200 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -160                                  r2 += -160   ///  r2 = r2.wrapping_add(-160 as i32 as i64 as u64)
    mov64 r3, r10                                   r3 = r10
    add64 r3, -128                                  r3 += -128   ///  r3 = r3.wrapping_add(-128 as i32 as i64 as u64)
    call function_17050                     
    ldxdw r1, [r10-0xc8]                    
    jeq r1, 0, lbb_13850                            if r1 == (0 as i32 as i64 as u64) { pc += 9 }
    ldxdw r1, [r10-0xa8]                    
    stxdw [r6+0x20], r1                     
    ldxdw r1, [r10-0xb0]                    
    stxdw [r6+0x18], r1                     
    ldxdw r1, [r10-0xb8]                    
    stxdw [r6+0x10], r1                     
    ldxdw r1, [r10-0xc0]                    
    stxdw [r6+0x8], r1                      
    mov64 r7, 1                                     r7 = 1 as i32 as i64 as u64
lbb_13850:
    stxdw [r6+0x0], r7                      
    exit                                    

function_13852:
    stxdw [r10-0xd0], r1                    
    ldxdw r3, [r2+0x0]                      
    lddw r4, 0xe8d4a50fff                           r4 load str located at 999999999999
    mov64 r1, r3                                    r1 = r3
    add64 r1, r4                                    r1 += r4   ///  r1 = r1.wrapping_add(r4)
    mov64 r0, 1                                     r0 = 1 as i32 as i64 as u64
    mov64 r4, 1                                     r4 = 1 as i32 as i64 as u64
    jgt r3, r1, lbb_13862                           if r3 > r1 { pc += 1 }
    mov64 r4, 0                                     r4 = 0 as i32 as i64 as u64
lbb_13862:
    ldxdw r5, [r2+0x8]                      
    mov64 r3, r5                                    r3 = r5
    add64 r3, 1                                     r3 += 1   ///  r3 = r3.wrapping_add(1 as i32 as i64 as u64)
    mov64 r6, 1                                     r6 = 1 as i32 as i64 as u64
    jgt r5, r3, lbb_13868                           if r5 > r3 { pc += 1 }
    mov64 r6, 0                                     r6 = 0 as i32 as i64 as u64
lbb_13868:
    mov64 r8, r4                                    r8 = r4
    and64 r8, r6                                    r8 &= r6   ///  r8 = r8.and(r6)
    ldxdw r9, [r2+0x10]                     
    mov64 r7, r9                                    r7 = r9
    add64 r7, r8                                    r7 += r8   ///  r7 = r7.wrapping_add(r8)
    mov64 r6, 1                                     r6 = 1 as i32 as i64 as u64
    jgt r9, r7, lbb_13876                           if r9 > r7 { pc += 1 }
    mov64 r6, 0                                     r6 = 0 as i32 as i64 as u64
lbb_13876:
    jne r8, 0, lbb_13878                            if r8 != (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r7, r9                                    r7 = r9
lbb_13878:
    and64 r8, r6                                    r8 &= r6   ///  r8 = r8.and(r6)
    ldxdw r9, [r2+0x18]                     
    mov64 r2, r9                                    r2 = r9
    add64 r2, r8                                    r2 += r8   ///  r2 = r2.wrapping_add(r8)
    jgt r9, r2, lbb_13884                           if r9 > r2 { pc += 1 }
    mov64 r0, 0                                     r0 = 0 as i32 as i64 as u64
lbb_13884:
    jne r8, 0, lbb_13886                            if r8 != (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r2, r9                                    r2 = r9
lbb_13886:
    and64 r8, r0                                    r8 &= r0   ///  r8 = r8.and(r0)
    jne r8, 1, lbb_13892                            if r8 != (1 as i32 as i64 as u64) { pc += 4 }
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    ldxdw r2, [r10-0xd0]                    
    stxdw [r2+0x0], r1                      
    ja lbb_13948                                    if true { pc += 56 }
lbb_13892:
    and64 r4, 1                                     r4 &= 1   ///  r4 = r4.and(1)
    jne r4, 0, lbb_13895                            if r4 != (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r3, r5                                    r3 = r5
lbb_13895:
    stxdw [r10-0x28], r2                    
    stxdw [r10-0x30], r7                    
    stxdw [r10-0x40], r1                    
    stxdw [r10-0x38], r3                    
    mov64 r7, 0                                     r7 = 0 as i32 as i64 as u64
    stxdw [r10-0x18], r7                    
    lddw r8, 0xe8d4a51000                           r8 load str located at 1000000000000
    stxdw [r10-0x20], r8                    
    stxdw [r10-0x10], r7                    
    stxdw [r10-0x8], r7                     
    mov64 r1, r10                                   r1 = r10
    add64 r1, -128                                  r1 += -128   ///  r1 = r1.wrapping_add(-128 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -64                                   r2 += -64   ///  r2 = r2.wrapping_add(-64 as i32 as i64 as u64)
    mov64 r3, r10                                   r3 = r10
    add64 r3, -32                                   r3 += -32   ///  r3 = r3.wrapping_add(-32 as i32 as i64 as u64)
    call function_15536                     
    ldxdw r1, [r10-0x80]                    
    stxdw [r10-0xa0], r1                    
    ldxdw r1, [r10-0x78]                    
    stxdw [r10-0x98], r1                    
    ldxdw r1, [r10-0x70]                    
    stxdw [r10-0x90], r1                    
    ldxdw r1, [r10-0x68]                    
    stxdw [r10-0x88], r1                    
    stxdw [r10-0x68], r7                    
    stxdw [r10-0x70], r7                    
    stxdw [r10-0x78], r7                    
    stxdw [r10-0x80], r8                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -200                                  r1 += -200   ///  r1 = r1.wrapping_add(-200 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -160                                  r2 += -160   ///  r2 = r2.wrapping_add(-160 as i32 as i64 as u64)
    mov64 r3, r10                                   r3 = r10
    add64 r3, -128                                  r3 += -128   ///  r3 = r3.wrapping_add(-128 as i32 as i64 as u64)
    call function_17050                     
    ldxdw r1, [r10-0xc8]                    
    jeq r1, 0, lbb_13946                            if r1 == (0 as i32 as i64 as u64) { pc += 12 }
    ldxdw r1, [r10-0xa8]                    
    ldxdw r2, [r10-0xd0]                    
    stxdw [r2+0x20], r1                     
    ldxdw r1, [r10-0xb0]                    
    stxdw [r2+0x18], r1                     
    ldxdw r1, [r10-0xb8]                    
    stxdw [r2+0x10], r1                     
    ldxdw r1, [r10-0xc0]                    
    stxdw [r2+0x8], r1                      
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    stxdw [r2+0x0], r1                      
    ja lbb_13948                                    if true { pc += 2 }
lbb_13946:
    ldxdw r1, [r10-0xd0]                    
    stxdw [r1+0x0], r7                      
lbb_13948:
    exit                                    

function_13949:
    mov64 r7, r3                                    r7 = r3
    mov64 r8, r2                                    r8 = r2
    mov64 r6, r1                                    r6 = r1
    mov64 r9, 0                                     r9 = 0 as i32 as i64 as u64
    stxdw [r10-0x68], r9                    
    stxdw [r10-0x70], r9                    
    stxdw [r10-0x78], r9                    
    stxdw [r10-0x80], r9                    
    mov64 r2, r10                                   r2 = r10
    add64 r2, -128                                  r2 += -128   ///  r2 = r2.wrapping_add(-128 as i32 as i64 as u64)
    mov64 r1, r7                                    r1 = r7
    mov64 r3, 32                                    r3 = 32 as i32 as i64 as u64
    call function_21867                     
    lsh64 r0, 32                                    r0 <<= 32   ///  r0 = r0.wrapping_shl(32)
    rsh64 r0, 32                                    r0 >>= 32   ///  r0 = r0.wrapping_shr(32)
    jeq r0, 0, lbb_14060                            if r0 == (0 as i32 as i64 as u64) { pc += 95 }
    ldxdw r1, [r8+0x18]                     
    stxdw [r10-0xb0], r1                    
    ldxdw r1, [r8+0x10]                     
    stxdw [r10-0xb8], r1                    
    ldxdw r1, [r8+0x8]                      
    stxdw [r10-0xc0], r1                    
    ldxdw r1, [r8+0x0]                      
    stxdw [r10-0xc8], r1                    
    stxdw [r10-0x68], r9                    
    stxdw [r10-0x70], r9                    
    stxdw [r10-0x78], r9                    
    lddw r1, 0xe8d4a51000                           r1 load str located at 1000000000000
    stxdw [r10-0x80], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -240                                  r1 += -240   ///  r1 = r1.wrapping_add(-240 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -200                                  r2 += -200   ///  r2 = r2.wrapping_add(-200 as i32 as i64 as u64)
    mov64 r3, r10                                   r3 = r10
    add64 r3, -128                                  r3 += -128   ///  r3 = r3.wrapping_add(-128 as i32 as i64 as u64)
    call function_17050                     
    ldxdw r1, [r10-0xf0]                    
    stxdw [r10-0xf8], r6                    
    jeq r1, 0, lbb_14062                            if r1 == (0 as i32 as i64 as u64) { pc += 73 }
    lddw r2, 0x746a528800                           r2 load str located at 500000000000
    ldxdw r4, [r10-0xe8]                    
    mov64 r1, r4                                    r1 = r4
    add64 r1, r2                                    r1 += r2   ///  r1 = r1.wrapping_add(r2)
    mov64 r0, 1                                     r0 = 1 as i32 as i64 as u64
    mov64 r3, 1                                     r3 = 1 as i32 as i64 as u64
    jgt r4, r1, lbb_13998                           if r4 > r1 { pc += 1 }
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
lbb_13998:
    ldxdw r4, [r10-0xe0]                    
    mov64 r2, r4                                    r2 = r4
    add64 r2, 1                                     r2 += 1   ///  r2 = r2.wrapping_add(1 as i32 as i64 as u64)
    mov64 r5, 1                                     r5 = 1 as i32 as i64 as u64
    jgt r4, r2, lbb_14004                           if r4 > r2 { pc += 1 }
    mov64 r5, 0                                     r5 = 0 as i32 as i64 as u64
lbb_14004:
    mov64 r9, r3                                    r9 = r3
    and64 r9, r5                                    r9 &= r5   ///  r9 = r9.and(r5)
    ldxdw r6, [r10-0xd8]                    
    mov64 r5, r6                                    r5 = r6
    add64 r5, r9                                    r5 += r9   ///  r5 = r5.wrapping_add(r9)
    mov64 r8, 1                                     r8 = 1 as i32 as i64 as u64
    jgt r6, r5, lbb_14012                           if r6 > r5 { pc += 1 }
    mov64 r8, 0                                     r8 = 0 as i32 as i64 as u64
lbb_14012:
    jne r9, 0, lbb_14014                            if r9 != (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r5, r6                                    r5 = r6
lbb_14014:
    and64 r9, r8                                    r9 &= r8   ///  r9 = r9.and(r8)
    ldxdw r6, [r10-0xd0]                    
    mov64 r8, r6                                    r8 = r6
    add64 r8, r9                                    r8 += r9   ///  r8 = r8.wrapping_add(r9)
    jgt r6, r8, lbb_14020                           if r6 > r8 { pc += 1 }
    mov64 r0, 0                                     r0 = 0 as i32 as i64 as u64
lbb_14020:
    jne r9, 0, lbb_14022                            if r9 != (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r8, r6                                    r8 = r6
lbb_14022:
    and64 r9, r0                                    r9 &= r0   ///  r9 = r9.and(r0)
    and64 r9, 1                                     r9 &= 1   ///  r9 = r9.and(1)
    jne r9, 0, lbb_14107                            if r9 != (0 as i32 as i64 as u64) { pc += 82 }
    ldxdw r0, [r7+0x18]                     
    ldxdw r6, [r7+0x10]                     
    ldxdw r9, [r7+0x8]                      
    ldxdw r7, [r7+0x0]                      
    jne r7, 0, lbb_14033                            if r7 != (0 as i32 as i64 as u64) { pc += 3 }
    jne r9, 0, lbb_14033                            if r9 != (0 as i32 as i64 as u64) { pc += 2 }
    jne r6, 0, lbb_14033                            if r6 != (0 as i32 as i64 as u64) { pc += 1 }
    jeq r0, 0, lbb_14107                            if r0 == (0 as i32 as i64 as u64) { pc += 74 }
lbb_14033:
    and64 r3, 1                                     r3 &= 1   ///  r3 = r3.and(1)
    jne r3, 0, lbb_14036                            if r3 != (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r2, r4                                    r2 = r4
lbb_14036:
    stxdw [r10-0x8], r8                     
    stxdw [r10-0x10], r5                    
    stxdw [r10-0x20], r1                    
    stxdw [r10-0x18], r2                    
    stxdw [r10-0xb0], r0                    
    stxdw [r10-0xb8], r6                    
    stxdw [r10-0xc0], r9                    
    stxdw [r10-0xc8], r7                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -128                                  r1 += -128   ///  r1 = r1.wrapping_add(-128 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -32                                   r2 += -32   ///  r2 = r2.wrapping_add(-32 as i32 as i64 as u64)
    mov64 r3, r10                                   r3 = r10
    add64 r3, -200                                  r3 += -200   ///  r3 = r3.wrapping_add(-200 as i32 as i64 as u64)
    call function_15536                     
    ldxdw r1, [r10-0x68]                    
    ldxdw r2, [r10-0xf8]                    
    stxdw [r2+0x20], r1                     
    ldxdw r1, [r10-0x70]                    
    stxdw [r2+0x18], r1                     
    ldxdw r1, [r10-0x78]                    
    stxdw [r2+0x10], r1                     
    ldxdw r1, [r10-0x80]                    
    ja lbb_14160                                    if true { pc += 100 }
lbb_14060:
    stxdw [r6+0x0], r9                      
    ja lbb_14163                                    if true { pc += 101 }
lbb_14062:
    ldxdw r2, [r8+0x0]                      
    lddw r3, 0x746a528800                           r3 load str located at 500000000000
    mov64 r1, r2                                    r1 = r2
    add64 r1, r3                                    r1 += r3   ///  r1 = r1.wrapping_add(r3)
    mov64 r0, 1                                     r0 = 1 as i32 as i64 as u64
    mov64 r3, 1                                     r3 = 1 as i32 as i64 as u64
    jgt r2, r1, lbb_14071                           if r2 > r1 { pc += 1 }
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
lbb_14071:
    ldxdw r5, [r8+0x8]                      
    mov64 r2, r5                                    r2 = r5
    add64 r2, 1                                     r2 += 1   ///  r2 = r2.wrapping_add(1 as i32 as i64 as u64)
    mov64 r4, 1                                     r4 = 1 as i32 as i64 as u64
    stxdw [r10-0x100], r5                   
    jgt r5, r2, lbb_14078                           if r5 > r2 { pc += 1 }
    mov64 r4, 0                                     r4 = 0 as i32 as i64 as u64
lbb_14078:
    mov64 r9, r3                                    r9 = r3
    and64 r9, r4                                    r9 &= r4   ///  r9 = r9.and(r4)
    ldxdw r6, [r8+0x10]                     
    mov64 r5, r6                                    r5 = r6
    add64 r5, r9                                    r5 += r9   ///  r5 = r5.wrapping_add(r9)
    mov64 r4, 1                                     r4 = 1 as i32 as i64 as u64
    jgt r6, r5, lbb_14086                           if r6 > r5 { pc += 1 }
    mov64 r4, 0                                     r4 = 0 as i32 as i64 as u64
lbb_14086:
    jne r9, 0, lbb_14088                            if r9 != (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r5, r6                                    r5 = r6
lbb_14088:
    and64 r9, r4                                    r9 &= r4   ///  r9 = r9.and(r4)
    ldxdw r6, [r8+0x18]                     
    mov64 r8, r6                                    r8 = r6
    add64 r8, r9                                    r8 += r9   ///  r8 = r8.wrapping_add(r9)
    jgt r6, r8, lbb_14094                           if r6 > r8 { pc += 1 }
    mov64 r0, 0                                     r0 = 0 as i32 as i64 as u64
lbb_14094:
    jne r9, 0, lbb_14096                            if r9 != (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r8, r6                                    r8 = r6
lbb_14096:
    and64 r9, r0                                    r9 &= r0   ///  r9 = r9.and(r0)
    and64 r9, 1                                     r9 &= 1   ///  r9 = r9.and(1)
    jne r9, 0, lbb_14107                            if r9 != (0 as i32 as i64 as u64) { pc += 8 }
    ldxdw r4, [r7+0x18]                     
    ldxdw r9, [r7+0x10]                     
    ldxdw r6, [r7+0x8]                      
    ldxdw r0, [r7+0x0]                      
    jne r0, 0, lbb_14110                            if r0 != (0 as i32 as i64 as u64) { pc += 6 }
    jne r6, 0, lbb_14110                            if r6 != (0 as i32 as i64 as u64) { pc += 5 }
    jne r9, 0, lbb_14110                            if r9 != (0 as i32 as i64 as u64) { pc += 4 }
    jne r4, 0, lbb_14110                            if r4 != (0 as i32 as i64 as u64) { pc += 3 }
lbb_14107:
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    ldxdw r2, [r10-0xf8]                    
    ja lbb_14162                                    if true { pc += 52 }
lbb_14110:
    and64 r3, 1                                     r3 &= 1   ///  r3 = r3.and(1)
    jne r3, 0, lbb_14113                            if r3 != (0 as i32 as i64 as u64) { pc += 1 }
    ldxdw r2, [r10-0x100]                   
lbb_14113:
    stxdw [r10-0x28], r8                    
    stxdw [r10-0x30], r5                    
    stxdw [r10-0x40], r1                    
    stxdw [r10-0x38], r2                    
    stxdw [r10-0x8], r4                     
    stxdw [r10-0x10], r9                    
    stxdw [r10-0x18], r6                    
    stxdw [r10-0x20], r0                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -128                                  r1 += -128   ///  r1 = r1.wrapping_add(-128 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -64                                   r2 += -64   ///  r2 = r2.wrapping_add(-64 as i32 as i64 as u64)
    mov64 r3, r10                                   r3 = r10
    add64 r3, -32                                   r3 += -32   ///  r3 = r3.wrapping_add(-32 as i32 as i64 as u64)
    call function_15536                     
    ldxdw r1, [r10-0x80]                    
    stxdw [r10-0xa0], r1                    
    ldxdw r1, [r10-0x78]                    
    stxdw [r10-0x98], r1                    
    ldxdw r1, [r10-0x70]                    
    stxdw [r10-0x90], r1                    
    ldxdw r1, [r10-0x68]                    
    stxdw [r10-0x88], r1                    
    mov64 r6, 0                                     r6 = 0 as i32 as i64 as u64
    stxdw [r10-0x68], r6                    
    stxdw [r10-0x70], r6                    
    stxdw [r10-0x78], r6                    
    lddw r1, 0xe8d4a51000                           r1 load str located at 1000000000000
    stxdw [r10-0x80], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -200                                  r1 += -200   ///  r1 = r1.wrapping_add(-200 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -160                                  r2 += -160   ///  r2 = r2.wrapping_add(-160 as i32 as i64 as u64)
    mov64 r3, r10                                   r3 = r10
    add64 r3, -128                                  r3 += -128   ///  r3 = r3.wrapping_add(-128 as i32 as i64 as u64)
    call function_17050                     
    ldxdw r1, [r10-0xc8]                    
    jeq r1, 0, lbb_14164                            if r1 == (0 as i32 as i64 as u64) { pc += 12 }
    ldxdw r1, [r10-0xa8]                    
    ldxdw r2, [r10-0xf8]                    
    stxdw [r2+0x20], r1                     
    ldxdw r1, [r10-0xb0]                    
    stxdw [r2+0x18], r1                     
    ldxdw r1, [r10-0xb8]                    
    stxdw [r2+0x10], r1                     
    ldxdw r1, [r10-0xc0]                    
lbb_14160:
    stxdw [r2+0x8], r1                      
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
lbb_14162:
    stxdw [r2+0x0], r1                      
lbb_14163:
    exit                                    
lbb_14164:
    ldxdw r1, [r10-0xf8]                    
    stxdw [r1+0x0], r6                      
    ja lbb_14163                                    if true { pc += -4 }

function_14167:
    mov64 r7, r3                                    r7 = r3
    mov64 r8, r2                                    r8 = r2
    mov64 r6, r1                                    r6 = r1
    ldxdw r1, [r8+0x18]                     
    stxdw [r10-0xb0], r1                    
    ldxdw r1, [r8+0x10]                     
    stxdw [r10-0xb8], r1                    
    ldxdw r1, [r8+0x8]                      
    stxdw [r10-0xc0], r1                    
    ldxdw r1, [r8+0x0]                      
    stxdw [r10-0xc8], r1                    
    ldxdw r1, [r7+0x18]                     
    stxdw [r10-0x68], r1                    
    ldxdw r1, [r7+0x10]                     
    stxdw [r10-0x70], r1                    
    ldxdw r1, [r7+0x8]                      
    stxdw [r10-0x78], r1                    
    ldxdw r1, [r7+0x0]                      
    stxdw [r10-0x80], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -272                                  r1 += -272   ///  r1 = r1.wrapping_add(-272 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -200                                  r2 += -200   ///  r2 = r2.wrapping_add(-200 as i32 as i64 as u64)
    mov64 r3, r10                                   r3 = r10
    add64 r3, -128                                  r3 += -128   ///  r3 = r3.wrapping_add(-128 as i32 as i64 as u64)
    call function_17050                     
    ldxdw r1, [r10-0x110]                   
    jne r1, 0, lbb_14283                            if r1 != (0 as i32 as i64 as u64) { pc += 88 }
    ldxdw r2, [r7+0x18]                     
    ldxdw r3, [r8+0x18]                     
    mov64 r4, 1                                     r4 = 1 as i32 as i64 as u64
    jne r3, r2, lbb_14200                           if r3 != r2 { pc += 1 }
    mov64 r4, 0                                     r4 = 0 as i32 as i64 as u64
lbb_14200:
    mov64 r1, -1                                    r1 = -1 as i32 as i64 as u64
    jgt r2, r3, lbb_14203                           if r2 > r3 { pc += 1 }
    mov64 r1, r4                                    r1 = r4
lbb_14203:
    jne r1, 0, lbb_14231                            if r1 != (0 as i32 as i64 as u64) { pc += 27 }
    ldxdw r2, [r7+0x10]                     
    ldxdw r3, [r8+0x10]                     
    mov64 r4, 1                                     r4 = 1 as i32 as i64 as u64
    jne r3, r2, lbb_14209                           if r3 != r2 { pc += 1 }
    mov64 r4, 0                                     r4 = 0 as i32 as i64 as u64
lbb_14209:
    mov64 r1, -1                                    r1 = -1 as i32 as i64 as u64
    jgt r2, r3, lbb_14212                           if r2 > r3 { pc += 1 }
    mov64 r1, r4                                    r1 = r4
lbb_14212:
    jne r1, 0, lbb_14231                            if r1 != (0 as i32 as i64 as u64) { pc += 18 }
    ldxdw r2, [r7+0x8]                      
    ldxdw r3, [r8+0x8]                      
    mov64 r4, 1                                     r4 = 1 as i32 as i64 as u64
    jne r3, r2, lbb_14218                           if r3 != r2 { pc += 1 }
    mov64 r4, 0                                     r4 = 0 as i32 as i64 as u64
lbb_14218:
    mov64 r1, -1                                    r1 = -1 as i32 as i64 as u64
    jgt r2, r3, lbb_14221                           if r2 > r3 { pc += 1 }
    mov64 r1, r4                                    r1 = r4
lbb_14221:
    jne r1, 0, lbb_14231                            if r1 != (0 as i32 as i64 as u64) { pc += 9 }
    ldxdw r2, [r7+0x0]                      
    ldxdw r3, [r8+0x0]                      
    mov64 r4, 1                                     r4 = 1 as i32 as i64 as u64
    jne r3, r2, lbb_14227                           if r3 != r2 { pc += 1 }
    mov64 r4, 0                                     r4 = 0 as i32 as i64 as u64
lbb_14227:
    mov64 r1, -1                                    r1 = -1 as i32 as i64 as u64
    jgt r2, r3, lbb_14230                           if r2 > r3 { pc += 1 }
    mov64 r1, r4                                    r1 = r4
lbb_14230:
    jeq r1, 0, lbb_14235                            if r1 == (0 as i32 as i64 as u64) { pc += 4 }
lbb_14231:
    and64 r1, 255                                   r1 &= 255   ///  r1 = r1.and(255)
    mov64 r2, 2                                     r2 = 2 as i32 as i64 as u64
    jgt r2, r1, lbb_14235                           if r2 > r1 { pc += 1 }
    ja lbb_14349                                    if true { pc += 114 }
lbb_14235:
    ldxdw r1, [r8+0x18]                     
    stxdw [r10-0x28], r1                    
    ldxdw r1, [r8+0x10]                     
    stxdw [r10-0x30], r1                    
    ldxdw r1, [r8+0x8]                      
    stxdw [r10-0x38], r1                    
    ldxdw r1, [r8+0x0]                      
    stxdw [r10-0x40], r1                    
    lddw r1, 0xe8d4a51000                           r1 load str located at 1000000000000
    stxdw [r10-0x20], r1                    
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    stxdw [r10-0x18], r1                    
    stxdw [r10-0x10], r1                    
    stxdw [r10-0x8], r1                     
    mov64 r1, r10                                   r1 = r10
    add64 r1, -128                                  r1 += -128   ///  r1 = r1.wrapping_add(-128 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -64                                   r2 += -64   ///  r2 = r2.wrapping_add(-64 as i32 as i64 as u64)
    mov64 r3, r10                                   r3 = r10
    add64 r3, -32                                   r3 += -32   ///  r3 = r3.wrapping_add(-32 as i32 as i64 as u64)
    call function_15536                     
    ldxdw r1, [r10-0x80]                    
    stxdw [r10-0xa0], r1                    
    ldxdw r1, [r10-0x78]                    
    stxdw [r10-0x98], r1                    
    ldxdw r1, [r10-0x70]                    
    stxdw [r10-0x90], r1                    
    ldxdw r1, [r10-0x68]                    
    stxdw [r10-0x88], r1                    
    ldxdw r1, [r7+0x18]                     
    stxdw [r10-0x68], r1                    
    ldxdw r1, [r7+0x10]                     
    stxdw [r10-0x70], r1                    
    ldxdw r1, [r7+0x8]                      
    stxdw [r10-0x78], r1                    
    ldxdw r1, [r7+0x0]                      
    stxdw [r10-0x80], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -200                                  r1 += -200   ///  r1 = r1.wrapping_add(-200 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -160                                  r2 += -160   ///  r2 = r2.wrapping_add(-160 as i32 as i64 as u64)
    mov64 r3, r10                                   r3 = r10
    add64 r3, -128                                  r3 += -128   ///  r3 = r3.wrapping_add(-128 as i32 as i64 as u64)
    call function_17050                     
    ldxdw r1, [r10-0xc8]                    
    jne r1, 0, lbb_14397                            if r1 != (0 as i32 as i64 as u64) { pc += 115 }
    ja lbb_14318                                    if true { pc += 35 }
lbb_14283:
    lddw r2, 0x746a528800                           r2 load str located at 500000000000
    ldxdw r4, [r10-0x108]                   
    mov64 r1, r4                                    r1 = r4
    add64 r1, r2                                    r1 += r2   ///  r1 = r1.wrapping_add(r2)
    mov64 r5, 1                                     r5 = 1 as i32 as i64 as u64
    mov64 r3, 1                                     r3 = 1 as i32 as i64 as u64
    jgt r4, r1, lbb_14292                           if r4 > r1 { pc += 1 }
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
lbb_14292:
    ldxdw r4, [r10-0x100]                   
    mov64 r2, r4                                    r2 = r4
    add64 r2, 1                                     r2 += 1   ///  r2 = r2.wrapping_add(1 as i32 as i64 as u64)
    mov64 r0, 1                                     r0 = 1 as i32 as i64 as u64
    jgt r4, r2, lbb_14298                           if r4 > r2 { pc += 1 }
    mov64 r0, 0                                     r0 = 0 as i32 as i64 as u64
lbb_14298:
    mov64 r7, r3                                    r7 = r3
    and64 r7, r0                                    r7 &= r0   ///  r7 = r7.and(r0)
    ldxdw r8, [r10-0xf8]                    
    mov64 r0, r8                                    r0 = r8
    add64 r0, r7                                    r0 += r7   ///  r0 = r0.wrapping_add(r7)
    mov64 r9, 1                                     r9 = 1 as i32 as i64 as u64
    jgt r8, r0, lbb_14306                           if r8 > r0 { pc += 1 }
    mov64 r9, 0                                     r9 = 0 as i32 as i64 as u64
lbb_14306:
    jne r7, 0, lbb_14308                            if r7 != (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r0, r8                                    r0 = r8
lbb_14308:
    and64 r7, r9                                    r7 &= r9   ///  r7 = r7.and(r9)
    ldxdw r9, [r10-0xf0]                    
    mov64 r8, r9                                    r8 = r9
    add64 r8, r7                                    r8 += r7   ///  r8 = r8.wrapping_add(r7)
    jgt r9, r8, lbb_14314                           if r9 > r8 { pc += 1 }
    mov64 r5, 0                                     r5 = 0 as i32 as i64 as u64
lbb_14314:
    jne r7, 0, lbb_14316                            if r7 != (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r8, r9                                    r8 = r9
lbb_14316:
    and64 r7, r5                                    r7 &= r5   ///  r7 = r7.and(r5)
    jne r7, 1, lbb_14320                            if r7 != (1 as i32 as i64 as u64) { pc += 2 }
lbb_14318:
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    ja lbb_14414                                    if true { pc += 94 }
lbb_14320:
    and64 r3, 1                                     r3 &= 1   ///  r3 = r3.and(1)
    jne r3, 0, lbb_14323                            if r3 != (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r2, r4                                    r2 = r4
lbb_14323:
    stxdw [r10-0x8], r8                     
    stxdw [r10-0x10], r0                    
    stxdw [r10-0x20], r1                    
    stxdw [r10-0x18], r2                    
    lddw r1, 0xe8d4a51000                           r1 load str located at 1000000000000
    stxdw [r10-0xc8], r1                    
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    stxdw [r10-0xc0], r1                    
    stxdw [r10-0xb8], r1                    
    stxdw [r10-0xb0], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -128                                  r1 += -128   ///  r1 = r1.wrapping_add(-128 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -32                                   r2 += -32   ///  r2 = r2.wrapping_add(-32 as i32 as i64 as u64)
    mov64 r3, r10                                   r3 = r10
    add64 r3, -200                                  r3 += -200   ///  r3 = r3.wrapping_add(-200 as i32 as i64 as u64)
    call function_15536                     
    ldxdw r1, [r10-0x68]                    
    stxdw [r6+0x20], r1                     
    ldxdw r1, [r10-0x70]                    
    stxdw [r6+0x18], r1                     
    ldxdw r1, [r10-0x78]                    
    stxdw [r6+0x10], r1                     
    ldxdw r1, [r10-0x80]                    
    ja lbb_14412                                    if true { pc += 63 }
lbb_14349:
    ldxdw r1, [r7+0x18]                     
    stxdw [r10-0x28], r1                    
    ldxdw r1, [r7+0x10]                     
    stxdw [r10-0x30], r1                    
    ldxdw r1, [r7+0x8]                      
    stxdw [r10-0x38], r1                    
    ldxdw r1, [r7+0x0]                      
    stxdw [r10-0x40], r1                    
    lddw r1, 0xe8d4a51000                           r1 load str located at 1000000000000
    stxdw [r10-0x20], r1                    
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    stxdw [r10-0x18], r1                    
    stxdw [r10-0x10], r1                    
    stxdw [r10-0x8], r1                     
    mov64 r1, r10                                   r1 = r10
    add64 r1, -128                                  r1 += -128   ///  r1 = r1.wrapping_add(-128 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -64                                   r2 += -64   ///  r2 = r2.wrapping_add(-64 as i32 as i64 as u64)
    mov64 r3, r10                                   r3 = r10
    add64 r3, -32                                   r3 += -32   ///  r3 = r3.wrapping_add(-32 as i32 as i64 as u64)
    call function_15536                     
    ldxdw r1, [r10-0x80]                    
    stxdw [r10-0xa0], r1                    
    ldxdw r1, [r10-0x78]                    
    stxdw [r10-0x98], r1                    
    ldxdw r1, [r10-0x70]                    
    stxdw [r10-0x90], r1                    
    ldxdw r1, [r10-0x68]                    
    stxdw [r10-0x88], r1                    
    ldxdw r1, [r8+0x18]                     
    stxdw [r10-0x68], r1                    
    ldxdw r1, [r8+0x10]                     
    stxdw [r10-0x70], r1                    
    ldxdw r1, [r8+0x8]                      
    stxdw [r10-0x78], r1                    
    ldxdw r1, [r8+0x0]                      
    stxdw [r10-0x80], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -200                                  r1 += -200   ///  r1 = r1.wrapping_add(-200 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -160                                  r2 += -160   ///  r2 = r2.wrapping_add(-160 as i32 as i64 as u64)
    mov64 r3, r10                                   r3 = r10
    add64 r3, -128                                  r3 += -128   ///  r3 = r3.wrapping_add(-128 as i32 as i64 as u64)
    call function_17050                     
    ldxdw r1, [r10-0xc8]                    
    jne r1, 0, lbb_14397                            if r1 != (0 as i32 as i64 as u64) { pc += 1 }
    ja lbb_14318                                    if true { pc += -79 }
lbb_14397:
    ldxdw r1, [r10-0xa8]                    
    stxdw [r10-0xd0], r1                    
    ldxdw r1, [r10-0xb0]                    
    stxdw [r10-0xd8], r1                    
    ldxdw r1, [r10-0xb8]                    
    stxdw [r10-0xe0], r1                    
    ldxdw r1, [r10-0xc0]                    
    stxdw [r10-0xe8], r1                    
    ldxdw r1, [r10-0xd0]                    
    stxdw [r6+0x20], r1                     
    ldxdw r1, [r10-0xd8]                    
    stxdw [r6+0x18], r1                     
    ldxdw r1, [r10-0xe0]                    
    stxdw [r6+0x10], r1                     
    ldxdw r1, [r10-0xe8]                    
lbb_14412:
    stxdw [r6+0x8], r1                      
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
lbb_14414:
    stxdw [r6+0x0], r1                      
    exit                                    

function_14416:
    stxdw [r10-0x8], r1                     
    ldxdw r1, [r3+0x8]                      
    ldxdw r5, [r2+0x8]                      
    mov64 r4, r5                                    r4 = r5
    add64 r4, r1                                    r4 += r1   ///  r4 = r4.wrapping_add(r1)
    mov64 r8, 1                                     r8 = 1 as i32 as i64 as u64
    mov64 r7, 1                                     r7 = 1 as i32 as i64 as u64
    jgt r5, r4, lbb_14425                           if r5 > r4 { pc += 1 }
    mov64 r7, 0                                     r7 = 0 as i32 as i64 as u64
lbb_14425:
    ldxdw r1, [r3+0x0]                      
    ldxdw r5, [r2+0x0]                      
    mov64 r0, r5                                    r0 = r5
    add64 r0, r1                                    r0 += r1   ///  r0 = r0.wrapping_add(r1)
    mov64 r9, 1                                     r9 = 1 as i32 as i64 as u64
    stxdw [r10-0x10], r0                    
    jgt r5, r0, lbb_14433                           if r5 > r0 { pc += 1 }
    mov64 r9, 0                                     r9 = 0 as i32 as i64 as u64
lbb_14433:
    mov64 r0, r4                                    r0 = r4
    add64 r0, 1                                     r0 += 1   ///  r0 = r0.wrapping_add(1 as i32 as i64 as u64)
    jgt r4, r0, lbb_14437                           if r4 > r0 { pc += 1 }
    mov64 r8, 0                                     r8 = 0 as i32 as i64 as u64
lbb_14437:
    stxdw [r10-0x18], r9                    
    and64 r9, r8                                    r9 &= r8   ///  r9 = r9.and(r8)
    add64 r9, r7                                    r9 += r7   ///  r9 = r9.wrapping_add(r7)
    ldxdw r6, [r3+0x10]                     
    ldxdw r1, [r2+0x10]                     
    jne r9, 0, lbb_14449                            if r9 != (0 as i32 as i64 as u64) { pc += 6 }
    mov64 r5, r1                                    r5 = r1
    add64 r5, r6                                    r5 += r6   ///  r5 = r5.wrapping_add(r6)
    mov64 r8, 1                                     r8 = 1 as i32 as i64 as u64
    jgt r1, r5, lbb_14461                           if r1 > r5 { pc += 14 }
    mov64 r8, 0                                     r8 = 0 as i32 as i64 as u64
    ja lbb_14461                                    if true { pc += 12 }
lbb_14449:
    mov64 r7, r1                                    r7 = r1
    add64 r7, r6                                    r7 += r6   ///  r7 = r7.wrapping_add(r6)
    mov64 r8, 1                                     r8 = 1 as i32 as i64 as u64
    mov64 r6, 1                                     r6 = 1 as i32 as i64 as u64
    jgt r1, r7, lbb_14455                           if r1 > r7 { pc += 1 }
    mov64 r6, 0                                     r6 = 0 as i32 as i64 as u64
lbb_14455:
    and64 r9, 255                                   r9 &= 255   ///  r9 = r9.and(255)
    mov64 r5, r7                                    r5 = r7
    add64 r5, r9                                    r5 += r9   ///  r5 = r5.wrapping_add(r9)
    jgt r7, r5, lbb_14460                           if r7 > r5 { pc += 1 }
    mov64 r8, 0                                     r8 = 0 as i32 as i64 as u64
lbb_14460:
    add64 r8, r6                                    r8 += r6   ///  r8 = r8.wrapping_add(r6)
lbb_14461:
    ldxdw r1, [r3+0x18]                     
    ldxdw r9, [r2+0x18]                     
    mov64 r2, r8                                    r2 = r8
    and64 r2, 255                                   r2 &= 255   ///  r2 = r2.and(255)
    jne r2, 0, lbb_14472                            if r2 != (0 as i32 as i64 as u64) { pc += 6 }
    mov64 r2, r9                                    r2 = r9
    add64 r2, r1                                    r2 += r1   ///  r2 = r2.wrapping_add(r1)
    mov64 r3, 1                                     r3 = 1 as i32 as i64 as u64
    jgt r9, r2, lbb_14484                           if r9 > r2 { pc += 14 }
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
    ja lbb_14484                                    if true { pc += 12 }
lbb_14472:
    mov64 r7, r9                                    r7 = r9
    add64 r7, r1                                    r7 += r1   ///  r7 = r7.wrapping_add(r1)
    mov64 r3, 1                                     r3 = 1 as i32 as i64 as u64
    mov64 r6, 1                                     r6 = 1 as i32 as i64 as u64
    jgt r9, r7, lbb_14478                           if r9 > r7 { pc += 1 }
    mov64 r6, 0                                     r6 = 0 as i32 as i64 as u64
lbb_14478:
    and64 r8, 255                                   r8 &= 255   ///  r8 = r8.and(255)
    mov64 r2, r7                                    r2 = r7
    add64 r2, r8                                    r2 += r8   ///  r2 = r2.wrapping_add(r8)
    jgt r7, r2, lbb_14483                           if r7 > r2 { pc += 1 }
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
lbb_14483:
    add64 r3, r6                                    r3 += r6   ///  r3 = r3.wrapping_add(r6)
lbb_14484:
    ldxdw r6, [r10-0x8]                     
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    and64 r3, 255                                   r3 &= 255   ///  r3 = r3.and(255)
    jne r3, 0, lbb_14498                            if r3 != (0 as i32 as i64 as u64) { pc += 10 }
    ldxdw r1, [r10-0x18]                    
    and64 r1, 1                                     r1 &= 1   ///  r1 = r1.and(1)
    jne r1, 0, lbb_14492                            if r1 != (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r0, r4                                    r0 = r4
lbb_14492:
    stxdw [r6+0x20], r2                     
    stxdw [r6+0x18], r5                     
    ldxdw r1, [r10-0x10]                    
    stxdw [r6+0x8], r1                      
    stxdw [r6+0x10], r0                     
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
lbb_14498:
    stxdw [r6+0x0], r1                      
    exit                                    

function_14500:
    stxdw [r10-0x8], r1                     
    ldxdw r1, [r3+0x8]                      
    ldxdw r5, [r2+0x8]                      
    mov64 r4, r5                                    r4 = r5
    sub64 r4, r1                                    r4 -= r1   ///  r4 = r4.wrapping_sub(r1)
    mov64 r8, 1                                     r8 = 1 as i32 as i64 as u64
    mov64 r7, 1                                     r7 = 1 as i32 as i64 as u64
    jgt r4, r5, lbb_14509                           if r4 > r5 { pc += 1 }
    mov64 r7, 0                                     r7 = 0 as i32 as i64 as u64
lbb_14509:
    ldxdw r1, [r3+0x0]                      
    ldxdw r5, [r2+0x0]                      
    mov64 r0, r5                                    r0 = r5
    sub64 r0, r1                                    r0 -= r1   ///  r0 = r0.wrapping_sub(r1)
    mov64 r9, 1                                     r9 = 1 as i32 as i64 as u64
    stxdw [r10-0x10], r0                    
    jgt r0, r5, lbb_14517                           if r0 > r5 { pc += 1 }
    mov64 r9, 0                                     r9 = 0 as i32 as i64 as u64
lbb_14517:
    mov64 r0, r4                                    r0 = r4
    add64 r0, -1                                    r0 += -1   ///  r0 = r0.wrapping_add(-1 as i32 as i64 as u64)
    jgt r0, r4, lbb_14521                           if r0 > r4 { pc += 1 }
    mov64 r8, 0                                     r8 = 0 as i32 as i64 as u64
lbb_14521:
    stxdw [r10-0x18], r9                    
    and64 r9, r8                                    r9 &= r8   ///  r9 = r9.and(r8)
    add64 r9, r7                                    r9 += r7   ///  r9 = r9.wrapping_add(r7)
    ldxdw r6, [r3+0x10]                     
    ldxdw r1, [r2+0x10]                     
    jne r9, 0, lbb_14533                            if r9 != (0 as i32 as i64 as u64) { pc += 6 }
    mov64 r5, r1                                    r5 = r1
    sub64 r5, r6                                    r5 -= r6   ///  r5 = r5.wrapping_sub(r6)
    mov64 r8, 1                                     r8 = 1 as i32 as i64 as u64
    jgt r5, r1, lbb_14545                           if r5 > r1 { pc += 14 }
    mov64 r8, 0                                     r8 = 0 as i32 as i64 as u64
    ja lbb_14545                                    if true { pc += 12 }
lbb_14533:
    mov64 r7, r1                                    r7 = r1
    sub64 r7, r6                                    r7 -= r6   ///  r7 = r7.wrapping_sub(r6)
    mov64 r8, 1                                     r8 = 1 as i32 as i64 as u64
    mov64 r6, 1                                     r6 = 1 as i32 as i64 as u64
    jgt r7, r1, lbb_14539                           if r7 > r1 { pc += 1 }
    mov64 r6, 0                                     r6 = 0 as i32 as i64 as u64
lbb_14539:
    and64 r9, 255                                   r9 &= 255   ///  r9 = r9.and(255)
    mov64 r5, r7                                    r5 = r7
    sub64 r5, r9                                    r5 -= r9   ///  r5 = r5.wrapping_sub(r9)
    jgt r5, r7, lbb_14544                           if r5 > r7 { pc += 1 }
    mov64 r8, 0                                     r8 = 0 as i32 as i64 as u64
lbb_14544:
    add64 r8, r6                                    r8 += r6   ///  r8 = r8.wrapping_add(r6)
lbb_14545:
    ldxdw r1, [r3+0x18]                     
    ldxdw r9, [r2+0x18]                     
    mov64 r2, r8                                    r2 = r8
    and64 r2, 255                                   r2 &= 255   ///  r2 = r2.and(255)
    jne r2, 0, lbb_14556                            if r2 != (0 as i32 as i64 as u64) { pc += 6 }
    mov64 r2, r9                                    r2 = r9
    sub64 r2, r1                                    r2 -= r1   ///  r2 = r2.wrapping_sub(r1)
    mov64 r3, 1                                     r3 = 1 as i32 as i64 as u64
    jgt r2, r9, lbb_14568                           if r2 > r9 { pc += 14 }
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
    ja lbb_14568                                    if true { pc += 12 }
lbb_14556:
    mov64 r7, r9                                    r7 = r9
    sub64 r7, r1                                    r7 -= r1   ///  r7 = r7.wrapping_sub(r1)
    mov64 r3, 1                                     r3 = 1 as i32 as i64 as u64
    mov64 r6, 1                                     r6 = 1 as i32 as i64 as u64
    jgt r7, r9, lbb_14562                           if r7 > r9 { pc += 1 }
    mov64 r6, 0                                     r6 = 0 as i32 as i64 as u64
lbb_14562:
    and64 r8, 255                                   r8 &= 255   ///  r8 = r8.and(255)
    mov64 r2, r7                                    r2 = r7
    sub64 r2, r8                                    r2 -= r8   ///  r2 = r2.wrapping_sub(r8)
    jgt r2, r7, lbb_14567                           if r2 > r7 { pc += 1 }
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
lbb_14567:
    add64 r3, r6                                    r3 += r6   ///  r3 = r3.wrapping_add(r6)
lbb_14568:
    ldxdw r6, [r10-0x8]                     
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    and64 r3, 255                                   r3 &= 255   ///  r3 = r3.and(255)
    jne r3, 0, lbb_14582                            if r3 != (0 as i32 as i64 as u64) { pc += 10 }
    ldxdw r1, [r10-0x18]                    
    and64 r1, 1                                     r1 &= 1   ///  r1 = r1.and(1)
    jne r1, 0, lbb_14576                            if r1 != (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r0, r4                                    r0 = r4
lbb_14576:
    stxdw [r6+0x20], r2                     
    stxdw [r6+0x18], r5                     
    ldxdw r1, [r10-0x10]                    
    stxdw [r6+0x8], r1                      
    stxdw [r6+0x10], r0                     
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
lbb_14582:
    stxdw [r6+0x0], r1                      
    exit                                    

function_14584:
    stxdw [r10-0x10], r1                    
    ldxdw r1, [r3+0x8]                      
    ldxdw r5, [r2+0x8]                      
    mov64 r8, r5                                    r8 = r5
    stxdw [r10-0x20], r1                    
    sub64 r8, r1                                    r8 -= r1   ///  r8 = r8.wrapping_sub(r1)
    mov64 r4, r8                                    r4 = r8
    add64 r4, -1                                    r4 += -1   ///  r4 = r4.wrapping_add(-1 as i32 as i64 as u64)
    mov64 r6, 1                                     r6 = 1 as i32 as i64 as u64
    mov64 r0, 1                                     r0 = 1 as i32 as i64 as u64
    jgt r4, r8, lbb_14596                           if r4 > r8 { pc += 1 }
    mov64 r0, 0                                     r0 = 0 as i32 as i64 as u64
lbb_14596:
    mov64 r9, 1                                     r9 = 1 as i32 as i64 as u64
    jgt r8, r5, lbb_14599                           if r8 > r5 { pc += 1 }
    mov64 r9, 0                                     r9 = 0 as i32 as i64 as u64
lbb_14599:
    stxdw [r10-0x38], r5                    
    ldxdw r5, [r3+0x0]                      
    ldxdw r7, [r2+0x0]                      
    mov64 r1, r7                                    r1 = r7
    stxdw [r10-0x40], r5                    
    sub64 r1, r5                                    r1 -= r5   ///  r1 = r1.wrapping_sub(r5)
    stxdw [r10-0x8], r1                     
    jgt r1, r7, lbb_14608                           if r1 > r7 { pc += 1 }
    mov64 r6, 0                                     r6 = 0 as i32 as i64 as u64
lbb_14608:
    stxdw [r10-0x48], r6                    
    mov64 r1, r6                                    r1 = r6
    and64 r1, r0                                    r1 &= r0   ///  r1 = r1.and(r0)
    add64 r1, r9                                    r1 += r9   ///  r1 = r1.wrapping_add(r9)
    ldxdw r6, [r3+0x10]                     
    ldxdw r5, [r2+0x10]                     
    stxdw [r10-0x18], r6                    
    stxdw [r10-0x28], r5                    
    jne r1, 0, lbb_14623                            if r1 != (0 as i32 as i64 as u64) { pc += 6 }
    mov64 r1, r5                                    r1 = r5
    sub64 r5, r6                                    r5 -= r6   ///  r5 = r5.wrapping_sub(r6)
    mov64 r9, 1                                     r9 = 1 as i32 as i64 as u64
    jgt r5, r1, lbb_14635                           if r5 > r1 { pc += 14 }
    mov64 r9, 0                                     r9 = 0 as i32 as i64 as u64
    ja lbb_14635                                    if true { pc += 12 }
lbb_14623:
    mov64 r0, r5                                    r0 = r5
    sub64 r0, r6                                    r0 -= r6   ///  r0 = r0.wrapping_sub(r6)
    mov64 r9, 1                                     r9 = 1 as i32 as i64 as u64
    mov64 r6, 1                                     r6 = 1 as i32 as i64 as u64
    jgt r0, r5, lbb_14629                           if r0 > r5 { pc += 1 }
    mov64 r6, 0                                     r6 = 0 as i32 as i64 as u64
lbb_14629:
    and64 r1, 255                                   r1 &= 255   ///  r1 = r1.and(255)
    mov64 r5, r0                                    r5 = r0
    sub64 r5, r1                                    r5 -= r1   ///  r5 = r5.wrapping_sub(r1)
    jgt r5, r0, lbb_14634                           if r5 > r0 { pc += 1 }
    mov64 r9, 0                                     r9 = 0 as i32 as i64 as u64
lbb_14634:
    add64 r9, r6                                    r9 += r6   ///  r9 = r9.wrapping_add(r6)
lbb_14635:
    ldxdw r6, [r3+0x18]                     
    ldxdw r2, [r2+0x18]                     
    mov64 r1, r9                                    r1 = r9
    and64 r1, 255                                   r1 &= 255   ///  r1 = r1.and(255)
    stxdw [r10-0x30], r2                    
    jne r1, 0, lbb_14647                            if r1 != (0 as i32 as i64 as u64) { pc += 6 }
    mov64 r1, r2                                    r1 = r2
    sub64 r2, r6                                    r2 -= r6   ///  r2 = r2.wrapping_sub(r6)
    mov64 r3, 1                                     r3 = 1 as i32 as i64 as u64
    jgt r2, r1, lbb_14659                           if r2 > r1 { pc += 14 }
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
    ja lbb_14659                                    if true { pc += 12 }
lbb_14647:
    mov64 r0, r2                                    r0 = r2
    sub64 r0, r6                                    r0 -= r6   ///  r0 = r0.wrapping_sub(r6)
    mov64 r3, 1                                     r3 = 1 as i32 as i64 as u64
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    jgt r0, r2, lbb_14653                           if r0 > r2 { pc += 1 }
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
lbb_14653:
    and64 r9, 255                                   r9 &= 255   ///  r9 = r9.and(255)
    mov64 r2, r0                                    r2 = r0
    sub64 r2, r9                                    r2 -= r9   ///  r2 = r2.wrapping_sub(r9)
    jgt r2, r0, lbb_14658                           if r2 > r0 { pc += 1 }
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
lbb_14658:
    add64 r3, r1                                    r3 += r1   ///  r3 = r3.wrapping_add(r1)
lbb_14659:
    ldxdw r9, [r10-0x8]                     
    and64 r3, 255                                   r3 &= 255   ///  r3 = r3.and(255)
    jeq r3, 0, lbb_14744                            if r3 == (0 as i32 as i64 as u64) { pc += 82 }
    ldxdw r1, [r10-0x20]                    
    mov64 r8, r1                                    r8 = r1
    ldxdw r2, [r10-0x38]                    
    sub64 r8, r2                                    r8 -= r2   ///  r8 = r8.wrapping_sub(r2)
    mov64 r3, 1                                     r3 = 1 as i32 as i64 as u64
    mov64 r2, 1                                     r2 = 1 as i32 as i64 as u64
    jgt r8, r1, lbb_14670                           if r8 > r1 { pc += 1 }
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
lbb_14670:
    ldxdw r4, [r10-0x40]                    
    mov64 r9, r4                                    r9 = r4
    sub64 r9, r7                                    r9 -= r7   ///  r9 = r9.wrapping_sub(r7)
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    jgt r9, r4, lbb_14676                           if r9 > r4 { pc += 1 }
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
lbb_14676:
    mov64 r4, r8                                    r4 = r8
    add64 r4, -1                                    r4 += -1   ///  r4 = r4.wrapping_add(-1 as i32 as i64 as u64)
    jgt r4, r8, lbb_14680                           if r4 > r8 { pc += 1 }
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
lbb_14680:
    mov64 r0, r6                                    r0 = r6
    mov64 r7, r1                                    r7 = r1
    and64 r7, r3                                    r7 &= r3   ///  r7 = r7.and(r3)
    add64 r7, r2                                    r7 += r2   ///  r7 = r7.wrapping_add(r2)
    jne r7, 0, lbb_14693                            if r7 != (0 as i32 as i64 as u64) { pc += 8 }
    ldxdw r2, [r10-0x18]                    
    mov64 r5, r2                                    r5 = r2
    ldxdw r3, [r10-0x28]                    
    sub64 r5, r3                                    r5 -= r3   ///  r5 = r5.wrapping_sub(r3)
    mov64 r6, 1                                     r6 = 1 as i32 as i64 as u64
    jgt r5, r2, lbb_14707                           if r5 > r2 { pc += 16 }
    mov64 r6, 0                                     r6 = 0 as i32 as i64 as u64
    ja lbb_14707                                    if true { pc += 14 }
lbb_14693:
    ldxdw r5, [r10-0x18]                    
    mov64 r3, r5                                    r3 = r5
    ldxdw r2, [r10-0x28]                    
    sub64 r3, r2                                    r3 -= r2   ///  r3 = r3.wrapping_sub(r2)
    mov64 r6, 1                                     r6 = 1 as i32 as i64 as u64
    mov64 r2, 1                                     r2 = 1 as i32 as i64 as u64
    jgt r3, r5, lbb_14701                           if r3 > r5 { pc += 1 }
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
lbb_14701:
    and64 r7, 255                                   r7 &= 255   ///  r7 = r7.and(255)
    mov64 r5, r3                                    r5 = r3
    sub64 r5, r7                                    r5 -= r7   ///  r5 = r5.wrapping_sub(r7)
    jgt r5, r3, lbb_14706                           if r5 > r3 { pc += 1 }
    mov64 r6, 0                                     r6 = 0 as i32 as i64 as u64
lbb_14706:
    add64 r6, r2                                    r6 += r2   ///  r6 = r6.wrapping_add(r2)
lbb_14707:
    mov64 r2, r6                                    r2 = r6
    and64 r2, 255                                   r2 &= 255   ///  r2 = r2.and(255)
    jne r2, 0, lbb_14717                            if r2 != (0 as i32 as i64 as u64) { pc += 7 }
    mov64 r2, r0                                    r2 = r0
    ldxdw r3, [r10-0x30]                    
    sub64 r2, r3                                    r2 -= r3   ///  r2 = r2.wrapping_sub(r3)
    mov64 r3, 1                                     r3 = 1 as i32 as i64 as u64
    jgt r2, r0, lbb_14730                           if r2 > r0 { pc += 15 }
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
    ja lbb_14730                                    if true { pc += 13 }
lbb_14717:
    mov64 r2, r0                                    r2 = r0
    ldxdw r3, [r10-0x30]                    
    sub64 r0, r3                                    r0 -= r3   ///  r0 = r0.wrapping_sub(r3)
    mov64 r3, 1                                     r3 = 1 as i32 as i64 as u64
    mov64 r7, 1                                     r7 = 1 as i32 as i64 as u64
    jgt r0, r2, lbb_14724                           if r0 > r2 { pc += 1 }
    mov64 r7, 0                                     r7 = 0 as i32 as i64 as u64
lbb_14724:
    and64 r6, 255                                   r6 &= 255   ///  r6 = r6.and(255)
    mov64 r2, r0                                    r2 = r0
    sub64 r2, r6                                    r2 -= r6   ///  r2 = r2.wrapping_sub(r6)
    jgt r2, r0, lbb_14729                           if r2 > r0 { pc += 1 }
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
lbb_14729:
    add64 r3, r7                                    r3 += r7   ///  r3 = r3.wrapping_add(r7)
lbb_14730:
    and64 r3, 255                                   r3 &= 255   ///  r3 = r3.and(255)
    jeq r3, 0, lbb_14739                            if r3 == (0 as i32 as i64 as u64) { pc += 7 }
    lddw r1, 0x10002cb78 --> b"called `Option::unwrap()` on a `None` value"        r1 load str located at 4295150456
    mov64 r2, 43                                    r2 = 43 as i32 as i64 as u64
    lddw r3, 0x10002df20 --> b"\x00\x00\x00\x00\xa3\xcb\x02\x00\x15\x00\x00\x00\x00\x00\x00\x00\xb9\x00\…        r3 load str located at 4295155488
    call function_19306                     
    syscall [invalid]                       
lbb_14739:
    and64 r1, 1                                     r1 &= 1   ///  r1 = r1.and(1)
    jne r1, 0, lbb_14742                            if r1 != (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r4, r8                                    r4 = r8
lbb_14742:
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    ja lbb_14749                                    if true { pc += 5 }
lbb_14744:
    ldxdw r1, [r10-0x48]                    
    and64 r1, 1                                     r1 &= 1   ///  r1 = r1.and(1)
    jne r1, 0, lbb_14748                            if r1 != (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r4, r8                                    r4 = r8
lbb_14748:
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
lbb_14749:
    ldxdw r3, [r10-0x10]                    
    stxb [r3+0x20], r1                      
    stxdw [r3+0x18], r2                     
    stxdw [r3+0x10], r5                     
    stxdw [r3+0x8], r4                      
    stxdw [r3+0x0], r9                      
    exit                                    

function_14756:
    mov64 r8, r4                                    r8 = r4
    mov64 r7, r3                                    r7 = r3
    mov64 r3, r2                                    r3 = r2
    mov64 r9, r1                                    r9 = r1
    mov64 r6, 0                                     r6 = 0 as i32 as i64 as u64
    stxdw [r10-0xf8], r6                    
    stxdw [r10-0x100], r6                   
    stxdw [r10-0x108], r6                   
    stxdw [r10-0x110], r6                   
    mov64 r2, r10                                   r2 = r10
    add64 r2, -272                                  r2 += -272   ///  r2 = r2.wrapping_add(-272 as i32 as i64 as u64)
    stxdw [r10-0x118], r3                   
    mov64 r1, r3                                    r1 = r3
    mov64 r3, 32                                    r3 = 32 as i32 as i64 as u64
    call function_21867                     
    lsh64 r0, 32                                    r0 <<= 32   ///  r0 = r0.wrapping_shl(32)
    rsh64 r0, 32                                    r0 >>= 32   ///  r0 = r0.wrapping_shr(32)
    jeq r0, 0, lbb_14836                            if r0 == (0 as i32 as i64 as u64) { pc += 62 }
    mov64 r2, r10                                   r2 = r10
    add64 r2, -272                                  r2 += -272   ///  r2 = r2.wrapping_add(-272 as i32 as i64 as u64)
    mov64 r1, r7                                    r1 = r7
    mov64 r3, 32                                    r3 = 32 as i32 as i64 as u64
    call function_21867                     
    lsh64 r0, 32                                    r0 <<= 32   ///  r0 = r0.wrapping_shl(32)
    rsh64 r0, 32                                    r0 >>= 32   ///  r0 = r0.wrapping_shr(32)
    jeq r0, 0, lbb_14869                            if r0 == (0 as i32 as i64 as u64) { pc += 87 }
    mov64 r6, 1                                     r6 = 1 as i32 as i64 as u64
    stxdw [r10-0x40], r6                    
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    stxdw [r10-0x28], r1                    
    stxdw [r10-0x30], r1                    
    stxdw [r10-0x38], r1                    
    stxdw [r10-0x8], r1                     
    stxdw [r10-0x10], r1                    
    stxdw [r10-0x18], r1                    
    lddw r1, 0xe8d4a51000                           r1 load str located at 1000000000000
    stxdw [r10-0x20], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -144                                  r1 += -144   ///  r1 = r1.wrapping_add(-144 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -64                                   r2 += -64   ///  r2 = r2.wrapping_add(-64 as i32 as i64 as u64)
    mov64 r3, r10                                   r3 = r10
    add64 r3, -32                                   r3 += -32   ///  r3 = r3.wrapping_add(-32 as i32 as i64 as u64)
    call function_17050                     
    ldxdw r1, [r10-0x90]                    
    jeq r1, 0, lbb_14869                            if r1 == (0 as i32 as i64 as u64) { pc += 66 }
    ldxdw r1, [r10-0x88]                    
    ldxdw r2, [r10-0x80]                    
    ldxdw r5, [r7+0x8]                      
    mov64 r3, r5                                    r3 = r5
    sub64 r3, r2                                    r3 -= r2   ///  r3 = r3.wrapping_sub(r2)
    mov64 r4, 1                                     r4 = 1 as i32 as i64 as u64
    jgt r3, r5, lbb_14811                           if r3 > r5 { pc += 1 }
    mov64 r4, 0                                     r4 = 0 as i32 as i64 as u64
lbb_14811:
    ldxdw r5, [r7+0x0]                      
    mov64 r2, r5                                    r2 = r5
    sub64 r2, r1                                    r2 -= r1   ///  r2 = r2.wrapping_sub(r1)
    mov64 r0, 1                                     r0 = 1 as i32 as i64 as u64
    jgt r2, r5, lbb_14817                           if r2 > r5 { pc += 1 }
    mov64 r0, 0                                     r0 = 0 as i32 as i64 as u64
lbb_14817:
    stxdw [r10-0x120], r7                   
    mov64 r1, r3                                    r1 = r3
    add64 r1, -1                                    r1 += -1   ///  r1 = r1.wrapping_add(-1 as i32 as i64 as u64)
    jgt r1, r3, lbb_14822                           if r1 > r3 { pc += 1 }
    mov64 r6, 0                                     r6 = 0 as i32 as i64 as u64
lbb_14822:
    ldxdw r7, [r10-0x78]                    
    stxdw [r10-0x128], r0                   
    and64 r0, r6                                    r0 &= r6   ///  r0 = r0.and(r6)
    add64 r0, r4                                    r0 += r4   ///  r0 = r0.wrapping_add(r4)
    ldxdw r4, [r10-0x120]                   
    ldxdw r4, [r4+0x10]                     
    stxdw [r10-0x130], r8                   
    jne r0, 0, lbb_14842                            if r0 != (0 as i32 as i64 as u64) { pc += 12 }
    mov64 r5, r4                                    r5 = r4
    sub64 r5, r7                                    r5 -= r7   ///  r5 = r5.wrapping_sub(r7)
    mov64 r6, 1                                     r6 = 1 as i32 as i64 as u64
    jgt r5, r4, lbb_14854                           if r5 > r4 { pc += 20 }
    mov64 r6, 0                                     r6 = 0 as i32 as i64 as u64
    ja lbb_14854                                    if true { pc += 18 }
lbb_14836:
    stxdw [r9+0x20], r6                     
    stxdw [r9+0x18], r6                     
    stxdw [r9+0x10], r6                     
    stxdw [r9+0x8], r6                      
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    ja lbb_14870                                    if true { pc += 28 }
lbb_14842:
    mov64 r8, r4                                    r8 = r4
    sub64 r8, r7                                    r8 -= r7   ///  r8 = r8.wrapping_sub(r7)
    mov64 r6, 1                                     r6 = 1 as i32 as i64 as u64
    mov64 r7, 1                                     r7 = 1 as i32 as i64 as u64
    jgt r8, r4, lbb_14848                           if r8 > r4 { pc += 1 }
    mov64 r7, 0                                     r7 = 0 as i32 as i64 as u64
lbb_14848:
    and64 r0, 255                                   r0 &= 255   ///  r0 = r0.and(255)
    mov64 r5, r8                                    r5 = r8
    sub64 r5, r0                                    r5 -= r0   ///  r5 = r5.wrapping_sub(r0)
    jgt r5, r8, lbb_14853                           if r5 > r8 { pc += 1 }
    mov64 r6, 0                                     r6 = 0 as i32 as i64 as u64
lbb_14853:
    add64 r6, r7                                    r6 += r7   ///  r6 = r6.wrapping_add(r7)
lbb_14854:
    ldxdw r4, [r10-0x120]                   
    ldxdw r8, [r10-0x70]                    
    ldxdw r0, [r4+0x18]                     
    mov64 r4, r6                                    r4 = r6
    and64 r4, 255                                   r4 &= 255   ///  r4 = r4.and(255)
    stxdw [r10-0x158], r9                   
    jne r4, 0, lbb_14872                            if r4 != (0 as i32 as i64 as u64) { pc += 11 }
    mov64 r4, r0                                    r4 = r0
    sub64 r4, r8                                    r4 -= r8   ///  r4 = r4.wrapping_sub(r8)
    mov64 r8, 1                                     r8 = 1 as i32 as i64 as u64
    jgt r4, r0, lbb_14866                           if r4 > r0 { pc += 1 }
    mov64 r8, 0                                     r8 = 0 as i32 as i64 as u64
lbb_14866:
    ldxdw r0, [r10-0x128]                   
    and64 r8, 255                                   r8 &= 255   ///  r8 = r8.and(255)
    jeq r8, 0, lbb_14889                            if r8 == (0 as i32 as i64 as u64) { pc += 20 }
lbb_14869:
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
lbb_14870:
    stxdw [r9+0x0], r1                      
lbb_14871:
    exit                                    
lbb_14872:
    mov64 r7, r0                                    r7 = r0
    sub64 r7, r8                                    r7 -= r8   ///  r7 = r7.wrapping_sub(r8)
    mov64 r8, 1                                     r8 = 1 as i32 as i64 as u64
    mov64 r9, 1                                     r9 = 1 as i32 as i64 as u64
    jgt r7, r0, lbb_14878                           if r7 > r0 { pc += 1 }
    mov64 r9, 0                                     r9 = 0 as i32 as i64 as u64
lbb_14878:
    and64 r6, 255                                   r6 &= 255   ///  r6 = r6.and(255)
    mov64 r4, r7                                    r4 = r7
    sub64 r4, r6                                    r4 -= r6   ///  r4 = r4.wrapping_sub(r6)
    jgt r4, r7, lbb_14883                           if r4 > r7 { pc += 1 }
    mov64 r8, 0                                     r8 = 0 as i32 as i64 as u64
lbb_14883:
    add64 r8, r9                                    r8 += r9   ///  r8 = r8.wrapping_add(r9)
    ldxdw r9, [r10-0x158]                   
    ldxdw r0, [r10-0x128]                   
    and64 r8, 255                                   r8 &= 255   ///  r8 = r8.and(255)
    jeq r8, 0, lbb_14889                            if r8 == (0 as i32 as i64 as u64) { pc += 1 }
    ja lbb_14869                                    if true { pc += -20 }
lbb_14889:
    and64 r0, 1                                     r0 &= 1   ///  r0 = r0.and(1)
    jne r0, 0, lbb_14892                            if r0 != (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r1, r3                                    r1 = r3
lbb_14892:
    lddw r0, 0x746a528800                           r0 load str located at 500000000000
    mov64 r3, r2                                    r3 = r2
    add64 r3, r0                                    r3 += r0   ///  r3 = r3.wrapping_add(r0)
    stxdw [r10-0xf0], r2                    
    mov64 r6, 1                                     r6 = 1 as i32 as i64 as u64
    mov64 r0, 1                                     r0 = 1 as i32 as i64 as u64
    jgt r2, r3, lbb_14901                           if r2 > r3 { pc += 1 }
    mov64 r0, 0                                     r0 = 0 as i32 as i64 as u64
lbb_14901:
    stxdw [r10-0xe0], r5                    
    mov64 r2, r1                                    r2 = r1
    add64 r2, 1                                     r2 += 1   ///  r2 = r2.wrapping_add(1 as i32 as i64 as u64)
    mov64 r7, 1                                     r7 = 1 as i32 as i64 as u64
    jgt r1, r2, lbb_14907                           if r1 > r2 { pc += 1 }
    mov64 r7, 0                                     r7 = 0 as i32 as i64 as u64
lbb_14907:
    mov64 r9, r0                                    r9 = r0
    and64 r9, r7                                    r9 &= r7   ///  r9 = r9.and(r7)
    mov64 r8, r5                                    r8 = r5
    add64 r8, r9                                    r8 += r9   ///  r8 = r8.wrapping_add(r9)
    mov64 r7, 1                                     r7 = 1 as i32 as i64 as u64
    jgt r5, r8, lbb_14914                           if r5 > r8 { pc += 1 }
    mov64 r7, 0                                     r7 = 0 as i32 as i64 as u64
lbb_14914:
    jne r9, 0, lbb_14916                            if r9 != (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r8, r5                                    r8 = r5
lbb_14916:
    and64 r9, r7                                    r9 &= r7   ///  r9 = r9.and(r7)
    mov64 r5, r4                                    r5 = r4
    add64 r5, r9                                    r5 += r9   ///  r5 = r5.wrapping_add(r9)
    jgt r4, r5, lbb_14921                           if r4 > r5 { pc += 1 }
    mov64 r6, 0                                     r6 = 0 as i32 as i64 as u64
lbb_14921:
    stxdw [r10-0xd8], r4                    
    jne r9, 0, lbb_14924                            if r9 != (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r5, r4                                    r5 = r4
lbb_14924:
    stxdw [r10-0xe8], r1                    
    and64 r9, r6                                    r9 &= r6   ///  r9 = r9.and(r6)
    and64 r9, 1                                     r9 &= 1   ///  r9 = r9.and(1)
    jne r9, 0, lbb_15294                            if r9 != (0 as i32 as i64 as u64) { pc += 366 }
    and64 r0, 1                                     r0 &= 1   ///  r0 = r0.and(1)
    jne r0, 0, lbb_14931                            if r0 != (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r2, r1                                    r2 = r1
lbb_14931:
    stxdw [r10-0x28], r5                    
    stxdw [r10-0x30], r8                    
    stxdw [r10-0x40], r3                    
    stxdw [r10-0x38], r2                    
    lddw r1, 0xe8d4a51000                           r1 load str located at 1000000000000
    stxdw [r10-0x20], r1                    
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    stxdw [r10-0x18], r1                    
    stxdw [r10-0x10], r1                    
    stxdw [r10-0x8], r1                     
    mov64 r1, r10                                   r1 = r10
    add64 r1, -144                                  r1 += -144   ///  r1 = r1.wrapping_add(-144 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -64                                   r2 += -64   ///  r2 = r2.wrapping_add(-64 as i32 as i64 as u64)
    mov64 r3, r10                                   r3 = r10
    add64 r3, -32                                   r3 += -32   ///  r3 = r3.wrapping_add(-32 as i32 as i64 as u64)
    call function_15536                     
    ldxdw r1, [r10-0x78]                    
    ldxdw r2, [r10-0x80]                    
    or64 r2, r1                                     r2 |= r1   ///  r2 = r2.or(r1)
    jeq r2, 0, lbb_14957                            if r2 == (0 as i32 as i64 as u64) { pc += 4 }
    lddw r1, 0x10002df50 --> b"\x00\x00\x00\x00\xb8\xcb\x02\x00\x0b\x00\x00\x00\x00\x00\x00\x00\x0a\x00\…        r1 load str located at 4295155536
    call function_13245                     
    syscall [invalid]                       
lbb_14957:
    ldxdw r1, [r10-0x88]                    
    stxdw [r10-0x178], r1                   
    ldxdw r2, [r10-0x90]                    
    ldxdw r6, [r10-0x130]                   
    ldxdw r1, [r6+0x18]                     
    stxdw [r10-0xb8], r1                    
    ldxdw r1, [r6+0x10]                     
    stxdw [r10-0xc0], r1                    
    ldxdw r1, [r6+0x8]                      
    stxdw [r10-0xc8], r1                    
    ldxdw r1, [r6+0x0]                      
    stxdw [r10-0xd0], r1                    
    mov64 r9, r10                                   r9 = r10
    add64 r9, -136                                  r9 += -136   ///  r9 = r9.wrapping_add(-136 as i32 as i64 as u64)
    mov64 r1, r10                                   r1 = r10
    add64 r1, -16                                   r1 += -16   ///  r1 = r1.wrapping_add(-16 as i32 as i64 as u64)
    stxdw [r10-0x1a0], r1                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -48                                   r1 += -48   ///  r1 = r1.wrapping_add(-48 as i32 as i64 as u64)
    stxdw [r10-0x188], r1                   
    stxdw [r10-0x180], r2                   
    and64 r2, 1                                     r2 &= 1   ///  r2 = r2.and(1)
    stxdw [r10-0x190], r2                   
    mov64 r1, r6                                    r1 = r6
    add64 r1, 16                                    r1 += 16   ///  r1 = r1.wrapping_add(16 as i32 as i64 as u64)
    stxdw [r10-0x198], r1                   
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
    mov64 r8, 0                                     r8 = 0 as i32 as i64 as u64
    mov64 r7, 0                                     r7 = 0 as i32 as i64 as u64
    ja lbb_15011                                    if true { pc += 24 }
lbb_14987:
    add64 r8, r2                                    r8 += r2   ///  r8 = r8.wrapping_add(r2)
    ldxdw r2, [r6+0x18]                     
    stxdw [r10-0xb8], r2                    
    ldxdw r2, [r6+0x10]                     
    stxdw [r10-0xc0], r2                    
    ldxdw r2, [r6+0x8]                      
    stxdw [r10-0xc8], r2                    
    ldxdw r2, [r6+0x0]                      
    stxdw [r10-0xd0], r2                    
    and64 r1, 1                                     r1 &= 1   ///  r1 = r1.and(1)
    ldxdw r7, [r10-0x168]                   
    mov64 r3, r7                                    r3 = r7
    jne r1, 0, lbb_15011                            if r1 != (0 as i32 as i64 as u64) { pc += 11 }
lbb_15000:
    ldxdw r1, [r6+0x18]                     
    ldxdw r2, [r10-0x158]                   
    stxdw [r2+0x20], r1                     
    ldxdw r1, [r6+0x10]                     
    stxdw [r2+0x18], r1                     
    ldxdw r1, [r6+0x8]                      
    stxdw [r2+0x10], r1                     
    ldxdw r1, [r6+0x0]                      
    stxdw [r2+0x8], r1                      
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    ja lbb_15296                                    if true { pc += 285 }
lbb_15011:
    stxdw [r10-0x128], r3                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -144                                  r1 += -144   ///  r1 = r1.wrapping_add(-144 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -240                                  r2 += -240   ///  r2 = r2.wrapping_add(-240 as i32 as i64 as u64)
    mov64 r3, r6                                    r3 = r6
    call function_14167                     
    mov64 r2, r7                                    r2 = r7
    add64 r2, 1                                     r2 += 1   ///  r2 = r2.wrapping_add(1 as i32 as i64 as u64)
    mov64 r7, 1                                     r7 = 1 as i32 as i64 as u64
    ldxdw r1, [r10-0x128]                   
    jgt r1, r2, lbb_15024                           if r1 > r2 { pc += 1 }
    mov64 r7, 0                                     r7 = 0 as i32 as i64 as u64
lbb_15024:
    ldxdw r1, [r10-0x90]                    
    jeq r1, 0, lbb_15294                            if r1 == (0 as i32 as i64 as u64) { pc += 268 }
    stxdw [r10-0x168], r2                   
    ldxdw r1, [r10-0x190]                   
    jne r1, 0, lbb_15035                            if r1 != (0 as i32 as i64 as u64) { pc += 6 }
    lddw r1, 0xe8d4a51000                           r1 load str located at 1000000000000
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
    stxdw [r10-0x48], r2                    
    stxdw [r10-0x50], r2                    
    ja lbb_15042                                    if true { pc += 7 }
lbb_15035:
    ldxdw r2, [r6+0x8]                      
    ldxdw r1, [r6+0x0]                      
    ldxdw r4, [r10-0x198]                   
    ldxdw r3, [r4+0x8]                      
    stxdw [r10-0x48], r3                    
    ldxdw r3, [r4+0x0]                      
    stxdw [r10-0x50], r3                    
lbb_15042:
    ldxdw r3, [r10-0x70]                    
    stxdw [r10-0x138], r3                   
    ldxdw r3, [r10-0x78]                    
    stxdw [r10-0x140], r3                   
    ldxdw r3, [r10-0x80]                    
    stxdw [r10-0x150], r3                   
    ldxdw r3, [r10-0x88]                    
    stxdw [r10-0x148], r3                   
    ldxdw r3, [r10-0x48]                    
    ldxdw r4, [r10-0x188]                   
    stxdw [r4+0x8], r3                      
    ldxdw r3, [r10-0x50]                    
    stxdw [r4+0x0], r3                      
    mov64 r3, 1                                     r3 = 1 as i32 as i64 as u64
    ldxdw r4, [r10-0x180]                   
    mov64 r5, 2                                     r5 = 2 as i32 as i64 as u64
    jgt r5, r4, lbb_15060                           if r5 > r4 { pc += 1 }
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
lbb_15060:
    stxdw [r10-0x160], r8                   
    ldxdw r4, [r10-0x178]                   
    jeq r4, 0, lbb_15064                            if r4 == (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
lbb_15064:
    stxdw [r10-0x38], r2                    
    stxdw [r10-0x40], r1                    
    ldxdw r1, [r6+0x18]                     
    stxdw [r10-0x8], r1                     
    ldxdw r1, [r6+0x10]                     
    stxdw [r10-0x10], r1                    
    ldxdw r1, [r6+0x8]                      
    stxdw [r10-0x18], r1                    
    ldxdw r1, [r6+0x0]                      
    stxdw [r10-0x20], r1                    
    and64 r3, 1                                     r3 &= 1   ///  r3 = r3.and(1)
    jne r3, 0, lbb_15151                            if r3 != (0 as i32 as i64 as u64) { pc += 75 }
    ldxdw r8, [r10-0x180]                   
    ldxdw r6, [r10-0x178]                   
    ja lbb_15086                                    if true { pc += 7 }
lbb_15079:
    rsh64 r8, 1                                     r8 >>= 1   ///  r8 = r8.wrapping_shr(1)
    mov64 r2, r6                                    r2 = r6
    lsh64 r2, 63                                    r2 <<= 63   ///  r2 = r2.wrapping_shl(63)
    or64 r8, r2                                     r8 |= r2   ///  r8 = r8.or(r2)
    rsh64 r6, 1                                     r6 >>= 1   ///  r6 = r6.wrapping_shr(1)
    and64 r1, 1                                     r1 &= 1   ///  r1 = r1.and(1)
    jne r1, 0, lbb_15151                            if r1 != (0 as i32 as i64 as u64) { pc += 65 }
lbb_15086:
    mov64 r1, r10                                   r1 = r10
    add64 r1, -144                                  r1 += -144   ///  r1 = r1.wrapping_add(-144 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -32                                   r2 += -32   ///  r2 = r2.wrapping_add(-32 as i32 as i64 as u64)
    mov64 r3, r2                                    r3 = r2
    call function_14167                     
    ldxdw r1, [r10-0x90]                    
    jeq r1, 0, lbb_15129                            if r1 == (0 as i32 as i64 as u64) { pc += 35 }
    ldxdw r1, [r9+0x18]                     
    stxdw [r10-0x8], r1                     
    ldxdw r1, [r9+0x10]                     
    stxdw [r10-0x10], r1                    
    ldxdw r1, [r9+0x8]                      
    stxdw [r10-0x18], r1                    
    ldxdw r1, [r9+0x0]                      
    stxdw [r10-0x20], r1                    
    mov64 r1, r8                                    r1 = r8
    and64 r1, 2                                     r1 &= 2   ///  r1 = r1.and(2)
    jeq r1, 0, lbb_15122                            if r1 == (0 as i32 as i64 as u64) { pc += 17 }
    mov64 r1, r10                                   r1 = r10
    add64 r1, -144                                  r1 += -144   ///  r1 = r1.wrapping_add(-144 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -64                                   r2 += -64   ///  r2 = r2.wrapping_add(-64 as i32 as i64 as u64)
    mov64 r3, r10                                   r3 = r10
    add64 r3, -32                                   r3 += -32   ///  r3 = r3.wrapping_add(-32 as i32 as i64 as u64)
    call function_14167                     
    ldxdw r1, [r10-0x90]                    
    jeq r1, 0, lbb_15129                            if r1 == (0 as i32 as i64 as u64) { pc += 15 }
    ldxdw r1, [r9+0x18]                     
    stxdw [r10-0x28], r1                    
    ldxdw r1, [r9+0x10]                     
    stxdw [r10-0x30], r1                    
    ldxdw r1, [r9+0x8]                      
    stxdw [r10-0x38], r1                    
    ldxdw r1, [r9+0x0]                      
    stxdw [r10-0x40], r1                    
lbb_15122:
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    mov64 r2, 4                                     r2 = 4 as i32 as i64 as u64
    jgt r2, r8, lbb_15126                           if r2 > r8 { pc += 1 }
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
lbb_15126:
    jeq r6, 0, lbb_15079                            if r6 == (0 as i32 as i64 as u64) { pc += -48 }
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    ja lbb_15079                                    if true { pc += -50 }
lbb_15129:
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    stxdw [r10-0x28], r1                    
    stxdw [r10-0x30], r1                    
    stxdw [r10-0x38], r1                    
    stxdw [r10-0x40], r1                    
    ldxdw r2, [r10-0x1a0]                   
    stxdw [r2+0x8], r1                      
    stxdw [r2+0x0], r1                      
    stxdw [r10-0x18], r1                    
    lddw r1, 0xe8d4a51000                           r1 load str located at 1000000000000
    stxdw [r10-0x20], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -144                                  r1 += -144   ///  r1 = r1.wrapping_add(-144 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -64                                   r2 += -64   ///  r2 = r2.wrapping_add(-64 as i32 as i64 as u64)
    mov64 r3, r10                                   r3 = r10
    add64 r3, -32                                   r3 += -32   ///  r3 = r3.wrapping_add(-32 as i32 as i64 as u64)
    call function_17050                     
    ldxdw r1, [r10-0x90]                    
    jeq r1, 0, lbb_15294                            if r1 == (0 as i32 as i64 as u64) { pc += 144 }
    ja lbb_15171                                    if true { pc += 20 }
lbb_15151:
    ldxdw r1, [r10-0x28]                    
    stxdw [r10-0x98], r1                    
    ldxdw r2, [r10-0x30]                    
    stxdw [r10-0xa0], r2                    
    ldxdw r3, [r10-0x38]                    
    stxdw [r10-0xa8], r3                    
    ldxdw r4, [r10-0x40]                    
    stxdw [r10-0xb0], r4                    
    stxdw [r10-0x8], r1                     
    stxdw [r10-0x10], r2                    
    stxdw [r10-0x18], r3                    
    stxdw [r10-0x20], r4                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -144                                  r1 += -144   ///  r1 = r1.wrapping_add(-144 as i32 as i64 as u64)
    mov64 r3, r10                                   r3 = r10
    add64 r3, -32                                   r3 += -32   ///  r3 = r3.wrapping_add(-32 as i32 as i64 as u64)
    ldxdw r2, [r10-0x118]                   
    call function_13949                     
    ldxdw r1, [r10-0x90]                    
    jeq r1, 0, lbb_15294                            if r1 == (0 as i32 as i64 as u64) { pc += 123 }
lbb_15171:
    ldxdw r5, [r10-0x70]                    
    ldxdw r6, [r10-0x78]                    
    ldxdw r2, [r10-0x80]                    
    ldxdw r3, [r10-0x88]                    
    stxdw [r10-0x170], r7                   
    ldxdw r4, [r10-0x150]                   
    mov64 r1, r4                                    r1 = r4
    add64 r1, r2                                    r1 += r2   ///  r1 = r1.wrapping_add(r2)
    mov64 r8, 1                                     r8 = 1 as i32 as i64 as u64
    mov64 r0, 1                                     r0 = 1 as i32 as i64 as u64
    jgt r4, r1, lbb_15183                           if r4 > r1 { pc += 1 }
    mov64 r0, 0                                     r0 = 0 as i32 as i64 as u64
lbb_15183:
    ldxdw r2, [r10-0x148]                   
    mov64 r4, r2                                    r4 = r2
    add64 r4, r3                                    r4 += r3   ///  r4 = r4.wrapping_add(r3)
    mov64 r7, 1                                     r7 = 1 as i32 as i64 as u64
    stxdw [r10-0x150], r4                   
    jgt r2, r4, lbb_15190                           if r2 > r4 { pc += 1 }
    mov64 r7, 0                                     r7 = 0 as i32 as i64 as u64
lbb_15190:
    mov64 r3, r1                                    r3 = r1
    add64 r3, 1                                     r3 += 1   ///  r3 = r3.wrapping_add(1 as i32 as i64 as u64)
    jgt r1, r3, lbb_15194                           if r1 > r3 { pc += 1 }
    mov64 r8, 0                                     r8 = 0 as i32 as i64 as u64
lbb_15194:
    mov64 r4, r7                                    r4 = r7
    and64 r4, r8                                    r4 &= r8   ///  r4 = r4.and(r8)
    add64 r4, r0                                    r4 += r0   ///  r4 = r4.wrapping_add(r0)
    jne r4, 0, lbb_15205                            if r4 != (0 as i32 as i64 as u64) { pc += 7 }
    ldxdw r4, [r10-0x140]                   
    mov64 r2, r4                                    r2 = r4
    add64 r2, r6                                    r2 += r6   ///  r2 = r2.wrapping_add(r6)
    mov64 r6, 1                                     r6 = 1 as i32 as i64 as u64
    jgt r4, r2, lbb_15218                           if r4 > r2 { pc += 15 }
    mov64 r6, 0                                     r6 = 0 as i32 as i64 as u64
    ja lbb_15218                                    if true { pc += 13 }
lbb_15205:
    ldxdw r2, [r10-0x140]                   
    mov64 r0, r2                                    r0 = r2
    add64 r0, r6                                    r0 += r6   ///  r0 = r0.wrapping_add(r6)
    mov64 r6, 1                                     r6 = 1 as i32 as i64 as u64
    mov64 r8, 1                                     r8 = 1 as i32 as i64 as u64
    jgt r2, r0, lbb_15212                           if r2 > r0 { pc += 1 }
    mov64 r8, 0                                     r8 = 0 as i32 as i64 as u64
lbb_15212:
    and64 r4, 255                                   r4 &= 255   ///  r4 = r4.and(255)
    mov64 r2, r0                                    r2 = r0
    add64 r2, r4                                    r2 += r4   ///  r2 = r2.wrapping_add(r4)
    jgt r0, r2, lbb_15217                           if r0 > r2 { pc += 1 }
    mov64 r6, 0                                     r6 = 0 as i32 as i64 as u64
lbb_15217:
    add64 r6, r8                                    r6 += r8   ///  r6 = r6.wrapping_add(r8)
lbb_15218:
    mov64 r4, r6                                    r4 = r6
    and64 r4, 255                                   r4 &= 255   ///  r4 = r4.and(255)
    jne r4, 0, lbb_15228                            if r4 != (0 as i32 as i64 as u64) { pc += 7 }
    ldxdw r4, [r10-0x138]                   
    mov64 r8, r4                                    r8 = r4
    add64 r8, r5                                    r8 += r5   ///  r8 = r8.wrapping_add(r5)
    mov64 r5, 1                                     r5 = 1 as i32 as i64 as u64
    jgt r4, r8, lbb_15241                           if r4 > r8 { pc += 15 }
    mov64 r5, 0                                     r5 = 0 as i32 as i64 as u64
    ja lbb_15241                                    if true { pc += 13 }
lbb_15228:
    ldxdw r8, [r10-0x138]                   
    mov64 r0, r8                                    r0 = r8
    add64 r0, r5                                    r0 += r5   ///  r0 = r0.wrapping_add(r5)
    mov64 r5, 1                                     r5 = 1 as i32 as i64 as u64
    mov64 r4, 1                                     r4 = 1 as i32 as i64 as u64
    jgt r8, r0, lbb_15235                           if r8 > r0 { pc += 1 }
    mov64 r4, 0                                     r4 = 0 as i32 as i64 as u64
lbb_15235:
    and64 r6, 255                                   r6 &= 255   ///  r6 = r6.and(255)
    mov64 r8, r0                                    r8 = r0
    add64 r8, r6                                    r8 += r6   ///  r8 = r8.wrapping_add(r6)
    jgt r0, r8, lbb_15240                           if r0 > r8 { pc += 1 }
    mov64 r5, 0                                     r5 = 0 as i32 as i64 as u64
lbb_15240:
    add64 r5, r4                                    r5 += r4   ///  r5 = r5.wrapping_add(r4)
lbb_15241:
    and64 r5, 255                                   r5 &= 255   ///  r5 = r5.and(255)
    jeq r5, 0, lbb_15244                            if r5 == (0 as i32 as i64 as u64) { pc += 1 }
    ja lbb_15294                                    if true { pc += 50 }
lbb_15244:
    and64 r7, 1                                     r7 &= 1   ///  r7 = r7.and(1)
    jne r7, 0, lbb_15247                            if r7 != (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r3, r1                                    r3 = r1
lbb_15247:
    stxdw [r10-0x8], r8                     
    stxdw [r10-0x10], r2                    
    ldxdw r1, [r10-0x150]                   
    stxdw [r10-0x20], r1                    
    stxdw [r10-0x18], r3                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -144                                  r1 += -144   ///  r1 = r1.wrapping_add(-144 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -32                                   r2 += -32   ///  r2 = r2.wrapping_add(-32 as i32 as i64 as u64)
    ldxdw r3, [r10-0x120]                   
    call function_13949                     
    ldxdw r1, [r10-0x90]                    
    jeq r1, 0, lbb_15294                            if r1 == (0 as i32 as i64 as u64) { pc += 34 }
    ldxdw r1, [r9+0x18]                     
    ldxdw r6, [r10-0x130]                   
    stxdw [r6+0x18], r1                     
    ldxdw r1, [r9+0x10]                     
    stxdw [r6+0x10], r1                     
    ldxdw r1, [r9+0x8]                      
    stxdw [r6+0x8], r1                      
    ldxdw r1, [r9+0x0]                      
    stxdw [r6+0x0], r1                      
    mov64 r1, r10                                   r1 = r10
    add64 r1, -144                                  r1 += -144   ///  r1 = r1.wrapping_add(-144 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -208                                  r2 += -208   ///  r2 = r2.wrapping_add(-208 as i32 as i64 as u64)
    mov64 r3, r6                                    r3 = r6
    call function_14584                     
    ldxdw r1, [r10-0x78]                    
    jne r1, 0, lbb_15284                            if r1 != (0 as i32 as i64 as u64) { pc += 7 }
    ldxdw r1, [r10-0x80]                    
    jne r1, 0, lbb_15284                            if r1 != (0 as i32 as i64 as u64) { pc += 5 }
    ldxdw r1, [r10-0x88]                    
    jne r1, 0, lbb_15284                            if r1 != (0 as i32 as i64 as u64) { pc += 3 }
    ldxdw r1, [r10-0x90]                    
    mov64 r2, 100                                   r2 = 100 as i32 as i64 as u64
    jgt r2, r1, lbb_15000                           if r2 > r1 { pc += -284 }
lbb_15284:
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    mov64 r2, 99                                    r2 = 99 as i32 as i64 as u64
    ldxdw r3, [r10-0x128]                   
    jgt r2, r3, lbb_15289                           if r2 > r3 { pc += 1 }
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
lbb_15289:
    ldxdw r8, [r10-0x160]                   
    ldxdw r2, [r10-0x170]                   
    jeq r8, 0, lbb_14987                            if r8 == (0 as i32 as i64 as u64) { pc += -305 }
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    ja lbb_14987                                    if true { pc += -307 }
lbb_15294:
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    ldxdw r2, [r10-0x158]                   
lbb_15296:
    stxdw [r2+0x0], r1                      
    ja lbb_14871                                    if true { pc += -427 }

function_15298:
    mov64 r6, r2                                    r6 = r2
    mov64 r8, r1                                    r8 = r1
    ldxdw r9, [r6+0x18]                     
    mov64 r1, -1                                    r1 = -1 as i32 as i64 as u64
    stxdw [r10-0x40], r1                    
    stxdw [r10-0x38], r1                    
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    stxdw [r10-0x28], r1                    
    stxdw [r10-0x30], r1                    
    stxdw [r10-0x8], r1                     
    stxdw [r10-0x10], r1                    
    stxdw [r10-0x18], r1                    
    lddw r1, 0xe8d4a51000                           r1 load str located at 1000000000000
    stxdw [r10-0x20], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -104                                  r1 += -104   ///  r1 = r1.wrapping_add(-104 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -64                                   r2 += -64   ///  r2 = r2.wrapping_add(-64 as i32 as i64 as u64)
    mov64 r3, r10                                   r3 = r10
    add64 r3, -32                                   r3 += -32   ///  r3 = r3.wrapping_add(-32 as i32 as i64 as u64)
    call function_17050                     
    ldxdw r1, [r10-0x68]                    
    jne r1, 0, lbb_15329                            if r1 != (0 as i32 as i64 as u64) { pc += 7 }
    lddw r1, 0x10002cb78 --> b"called `Option::unwrap()` on a `None` value"        r1 load str located at 4295150456
    mov64 r2, 43                                    r2 = 43 as i32 as i64 as u64
    lddw r3, 0x10002df38 --> b"\x00\x00\x00\x00\xa3\xcb\x02\x00\x15\x00\x00\x00\x00\x00\x00\x00Z\x01\x00…        r3 load str located at 4295155512
    call function_19306                     
    syscall [invalid]                       
lbb_15329:
    mov64 r2, 1                                     r2 = 1 as i32 as i64 as u64
    ldxdw r3, [r10-0x48]                    
    jne r9, r3, lbb_15333                           if r9 != r3 { pc += 1 }
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
lbb_15333:
    mov64 r1, -1                                    r1 = -1 as i32 as i64 as u64
    jgt r3, r9, lbb_15336                           if r3 > r9 { pc += 1 }
    mov64 r1, r2                                    r1 = r2
lbb_15336:
    jne r1, 0, lbb_15364                            if r1 != (0 as i32 as i64 as u64) { pc += 27 }
    ldxdw r2, [r10-0x50]                    
    ldxdw r3, [r6+0x10]                     
    mov64 r4, 1                                     r4 = 1 as i32 as i64 as u64
    jne r3, r2, lbb_15342                           if r3 != r2 { pc += 1 }
    mov64 r4, 0                                     r4 = 0 as i32 as i64 as u64
lbb_15342:
    mov64 r1, -1                                    r1 = -1 as i32 as i64 as u64
    jgt r2, r3, lbb_15345                           if r2 > r3 { pc += 1 }
    mov64 r1, r4                                    r1 = r4
lbb_15345:
    jne r1, 0, lbb_15364                            if r1 != (0 as i32 as i64 as u64) { pc += 18 }
    ldxdw r2, [r10-0x58]                    
    ldxdw r3, [r6+0x8]                      
    mov64 r4, 1                                     r4 = 1 as i32 as i64 as u64
    jne r3, r2, lbb_15351                           if r3 != r2 { pc += 1 }
    mov64 r4, 0                                     r4 = 0 as i32 as i64 as u64
lbb_15351:
    mov64 r1, -1                                    r1 = -1 as i32 as i64 as u64
    jgt r2, r3, lbb_15354                           if r2 > r3 { pc += 1 }
    mov64 r1, r4                                    r1 = r4
lbb_15354:
    jne r1, 0, lbb_15364                            if r1 != (0 as i32 as i64 as u64) { pc += 9 }
    ldxdw r2, [r10-0x60]                    
    ldxdw r3, [r6+0x0]                      
    mov64 r4, 1                                     r4 = 1 as i32 as i64 as u64
    jne r3, r2, lbb_15360                           if r3 != r2 { pc += 1 }
    mov64 r4, 0                                     r4 = 0 as i32 as i64 as u64
lbb_15360:
    mov64 r1, -1                                    r1 = -1 as i32 as i64 as u64
    jgt r2, r3, lbb_15363                           if r2 > r3 { pc += 1 }
    mov64 r1, r4                                    r1 = r4
lbb_15363:
    jeq r1, 0, lbb_15366                            if r1 == (0 as i32 as i64 as u64) { pc += 2 }
lbb_15364:
    and64 r1, 255                                   r1 &= 255   ///  r1 = r1.and(255)
    jeq r1, 1, lbb_15447                            if r1 == (1 as i32 as i64 as u64) { pc += 81 }
lbb_15366:
    stxdw [r10-0x90], r6                    
    mov64 r1, 2                                     r1 = 2 as i32 as i64 as u64
    stxdw [r10-0x40], r1                    
    mov64 r6, 0                                     r6 = 0 as i32 as i64 as u64
    stxdw [r10-0x28], r6                    
    stxdw [r10-0x30], r6                    
    stxdw [r10-0x38], r6                    
    stxdw [r10-0x8], r6                     
    stxdw [r10-0x10], r6                    
    stxdw [r10-0x18], r6                    
    lddw r7, 0xe8d4a51000                           r7 load str located at 1000000000000
    stxdw [r10-0x20], r7                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -104                                  r1 += -104   ///  r1 = r1.wrapping_add(-104 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -64                                   r2 += -64   ///  r2 = r2.wrapping_add(-64 as i32 as i64 as u64)
    mov64 r3, r10                                   r3 = r10
    add64 r3, -32                                   r3 += -32   ///  r3 = r3.wrapping_add(-32 as i32 as i64 as u64)
    call function_17050                     
    ldxdw r1, [r10-0x68]                    
    jeq r1, 0, lbb_15450                            if r1 == (0 as i32 as i64 as u64) { pc += 62 }
    stxdw [r10-0xa0], r9                    
    stxdw [r10-0x98], r8                    
    ldxdw r1, [r10-0x48]                    
    stxdw [r10-0x70], r1                    
    ldxdw r1, [r10-0x50]                    
    stxdw [r10-0x78], r1                    
    ldxdw r1, [r10-0x58]                    
    stxdw [r10-0x80], r1                    
    ldxdw r1, [r10-0x60]                    
    stxdw [r10-0x88], r1                    
    mov64 r9, 1                                     r9 = 1 as i32 as i64 as u64
    stxdw [r10-0x40], r9                    
    stxdw [r10-0x28], r6                    
    stxdw [r10-0x30], r6                    
    stxdw [r10-0x38], r6                    
    stxdw [r10-0x8], r6                     
    stxdw [r10-0x10], r6                    
    stxdw [r10-0x18], r6                    
    stxdw [r10-0x20], r7                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -104                                  r1 += -104   ///  r1 = r1.wrapping_add(-104 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -64                                   r2 += -64   ///  r2 = r2.wrapping_add(-64 as i32 as i64 as u64)
    mov64 r3, r10                                   r3 = r10
    add64 r3, -32                                   r3 += -32   ///  r3 = r3.wrapping_add(-32 as i32 as i64 as u64)
    call function_17050                     
    ldxdw r1, [r10-0x68]                    
    jeq r1, 0, lbb_15490                            if r1 == (0 as i32 as i64 as u64) { pc += 74 }
    ldxdw r3, [r10-0x60]                    
    ldxdw r2, [r10-0x58]                    
    ldxdw r7, [r10-0x90]                    
    ldxdw r4, [r7+0x8]                      
    mov64 r1, r4                                    r1 = r4
    add64 r1, r2                                    r1 += r2   ///  r1 = r1.wrapping_add(r2)
    mov64 r5, 1                                     r5 = 1 as i32 as i64 as u64
    jgt r4, r1, lbb_15425                           if r4 > r1 { pc += 1 }
    mov64 r5, 0                                     r5 = 0 as i32 as i64 as u64
lbb_15425:
    ldxdw r0, [r7+0x0]                      
    mov64 r2, r0                                    r2 = r0
    add64 r2, r3                                    r2 += r3   ///  r2 = r2.wrapping_add(r3)
    mov64 r4, 1                                     r4 = 1 as i32 as i64 as u64
    jgt r0, r2, lbb_15431                           if r0 > r2 { pc += 1 }
    mov64 r4, 0                                     r4 = 0 as i32 as i64 as u64
lbb_15431:
    mov64 r3, r1                                    r3 = r1
    add64 r3, 1                                     r3 += 1   ///  r3 = r3.wrapping_add(1 as i32 as i64 as u64)
    jgt r1, r3, lbb_15435                           if r1 > r3 { pc += 1 }
    mov64 r9, 0                                     r9 = 0 as i32 as i64 as u64
lbb_15435:
    ldxdw r0, [r10-0x50]                    
    mov64 r6, r4                                    r6 = r4
    and64 r6, r9                                    r6 &= r9   ///  r6 = r6.and(r9)
    add64 r6, r5                                    r6 += r5   ///  r6 = r6.wrapping_add(r5)
    ldxdw r8, [r7+0x10]                     
    jne r6, 0, lbb_15452                            if r6 != (0 as i32 as i64 as u64) { pc += 11 }
    mov64 r5, r8                                    r5 = r8
    add64 r5, r0                                    r5 += r0   ///  r5 = r5.wrapping_add(r0)
    mov64 r0, 1                                     r0 = 1 as i32 as i64 as u64
    jgt r8, r5, lbb_15464                           if r8 > r5 { pc += 19 }
    mov64 r0, 0                                     r0 = 0 as i32 as i64 as u64
    ja lbb_15464                                    if true { pc += 17 }
lbb_15447:
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    stxdw [r8+0x0], r1                      
    ja lbb_15493                                    if true { pc += 43 }
lbb_15450:
    stxdw [r8+0x0], r6                      
    ja lbb_15493                                    if true { pc += 41 }
lbb_15452:
    mov64 r9, r8                                    r9 = r8
    add64 r9, r0                                    r9 += r0   ///  r9 = r9.wrapping_add(r0)
    mov64 r0, 1                                     r0 = 1 as i32 as i64 as u64
    mov64 r7, 1                                     r7 = 1 as i32 as i64 as u64
    jgt r8, r9, lbb_15458                           if r8 > r9 { pc += 1 }
    mov64 r7, 0                                     r7 = 0 as i32 as i64 as u64
lbb_15458:
    and64 r6, 255                                   r6 &= 255   ///  r6 = r6.and(255)
    mov64 r5, r9                                    r5 = r9
    add64 r5, r6                                    r5 += r6   ///  r5 = r5.wrapping_add(r6)
    jgt r9, r5, lbb_15463                           if r9 > r5 { pc += 1 }
    mov64 r0, 0                                     r0 = 0 as i32 as i64 as u64
lbb_15463:
    add64 r0, r7                                    r0 += r7   ///  r0 = r0.wrapping_add(r7)
lbb_15464:
    ldxdw r9, [r10-0xa0]                    
    ldxdw r6, [r10-0x48]                    
    mov64 r7, r0                                    r7 = r0
    and64 r7, 255                                   r7 &= 255   ///  r7 = r7.and(255)
    jne r7, 0, lbb_15475                            if r7 != (0 as i32 as i64 as u64) { pc += 6 }
    mov64 r0, r9                                    r0 = r9
    add64 r9, r6                                    r9 += r6   ///  r9 = r9.wrapping_add(r6)
    mov64 r6, 1                                     r6 = 1 as i32 as i64 as u64
    jgt r0, r9, lbb_15487                           if r0 > r9 { pc += 14 }
    mov64 r6, 0                                     r6 = 0 as i32 as i64 as u64
    ja lbb_15487                                    if true { pc += 12 }
lbb_15475:
    mov64 r8, r9                                    r8 = r9
    add64 r8, r6                                    r8 += r6   ///  r8 = r8.wrapping_add(r6)
    mov64 r6, 1                                     r6 = 1 as i32 as i64 as u64
    mov64 r7, 1                                     r7 = 1 as i32 as i64 as u64
    jgt r9, r8, lbb_15481                           if r9 > r8 { pc += 1 }
    mov64 r7, 0                                     r7 = 0 as i32 as i64 as u64
lbb_15481:
    and64 r0, 255                                   r0 &= 255   ///  r0 = r0.and(255)
    mov64 r9, r8                                    r9 = r8
    add64 r9, r0                                    r9 += r0   ///  r9 = r9.wrapping_add(r0)
    jgt r8, r9, lbb_15486                           if r8 > r9 { pc += 1 }
    mov64 r6, 0                                     r6 = 0 as i32 as i64 as u64
lbb_15486:
    add64 r6, r7                                    r6 += r7   ///  r6 = r6.wrapping_add(r7)
lbb_15487:
    ldxdw r7, [r10-0x90]                    
    and64 r6, 255                                   r6 &= 255   ///  r6 = r6.and(255)
    jeq r6, 0, lbb_15494                            if r6 == (0 as i32 as i64 as u64) { pc += 4 }
lbb_15490:
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    ldxdw r2, [r10-0x98]                    
    stxdw [r2+0x0], r1                      
lbb_15493:
    exit                                    
lbb_15494:
    and64 r4, 1                                     r4 &= 1   ///  r4 = r4.and(1)
    jne r4, 0, lbb_15497                            if r4 != (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r3, r1                                    r3 = r1
lbb_15497:
    stxdw [r10-0x8], r9                     
    stxdw [r10-0x10], r5                    
    stxdw [r10-0x20], r2                    
    stxdw [r10-0x18], r3                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -104                                  r1 += -104   ///  r1 = r1.wrapping_add(-104 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -32                                   r2 += -32   ///  r2 = r2.wrapping_add(-32 as i32 as i64 as u64)
    mov64 r3, r10                                   r3 = r10
    add64 r3, -136                                  r3 += -136   ///  r3 = r3.wrapping_add(-136 as i32 as i64 as u64)
    call function_13949                     
    ldxdw r1, [r10-0x68]                    
    jeq r1, 0, lbb_15490                            if r1 == (0 as i32 as i64 as u64) { pc += -20 }
    ldxdw r1, [r10-0x48]                    
    stxdw [r10-0x28], r1                    
    ldxdw r2, [r10-0x50]                    
    stxdw [r10-0x30], r2                    
    ldxdw r3, [r10-0x58]                    
    stxdw [r10-0x38], r3                    
    ldxdw r4, [r10-0x60]                    
    stxdw [r10-0x40], r4                    
    stxdw [r10-0x50], r1                    
    stxdw [r10-0x58], r2                    
    stxdw [r10-0x60], r3                    
    stxdw [r10-0x68], r4                    
    mov64 r3, r10                                   r3 = r10
    add64 r3, -136                                  r3 += -136   ///  r3 = r3.wrapping_add(-136 as i32 as i64 as u64)
    mov64 r4, r10                                   r4 = r10
    add64 r4, -104                                  r4 += -104   ///  r4 = r4.wrapping_add(-104 as i32 as i64 as u64)
    ldxdw r1, [r10-0x98]                    
    mov64 r2, r7                                    r2 = r7
    call function_14756                     
    ja lbb_15493                                    if true { pc += -37 }

function_15530:
    mov64 r4, 0                                     r4 = 0 as i32 as i64 as u64
    stxdw [r1+0x18], r4                     
    stxdw [r1+0x10], r4                     
    stxdw [r1+0x8], r3                      
    stxdw [r1+0x0], r2                      
    exit                                    

function_15536:
    mov64 r4, r1                                    r4 = r1
    mov64 r7, 256                                   r7 = 256 as i32 as i64 as u64
    ldxdw r5, [r2+0x18]                     
    mov64 r1, r5                                    r1 = r5
    mov64 r8, r5                                    r8 = r5
    jne r5, 0, lbb_15552                            if r5 != (0 as i32 as i64 as u64) { pc += 10 }
    mov64 r7, 192                                   r7 = 192 as i32 as i64 as u64
    ldxdw r1, [r2+0x10]                     
    jne r1, 0, lbb_15552                            if r1 != (0 as i32 as i64 as u64) { pc += 7 }
    mov64 r7, 128                                   r7 = 128 as i32 as i64 as u64
    ldxdw r1, [r2+0x8]                      
    jne r1, 0, lbb_15552                            if r1 != (0 as i32 as i64 as u64) { pc += 4 }
    mov64 r7, 64                                    r7 = 64 as i32 as i64 as u64
    ldxdw r1, [r2+0x0]                      
    mov64 r5, 64                                    r5 = 64 as i32 as i64 as u64
    jeq r1, 0, lbb_15594                            if r1 == (0 as i32 as i64 as u64) { pc += 42 }
lbb_15552:
    mov64 r5, r1                                    r5 = r1
    rsh64 r5, 1                                     r5 >>= 1   ///  r5 = r5.wrapping_shr(1)
    or64 r1, r5                                     r1 |= r5   ///  r1 = r1.or(r5)
    mov64 r5, r1                                    r5 = r1
    rsh64 r5, 2                                     r5 >>= 2   ///  r5 = r5.wrapping_shr(2)
    or64 r1, r5                                     r1 |= r5   ///  r1 = r1.or(r5)
    mov64 r5, r1                                    r5 = r1
    rsh64 r5, 4                                     r5 >>= 4   ///  r5 = r5.wrapping_shr(4)
    or64 r1, r5                                     r1 |= r5   ///  r1 = r1.or(r5)
    mov64 r5, r1                                    r5 = r1
    rsh64 r5, 8                                     r5 >>= 8   ///  r5 = r5.wrapping_shr(8)
    or64 r1, r5                                     r1 |= r5   ///  r1 = r1.or(r5)
    mov64 r5, r1                                    r5 = r1
    rsh64 r5, 16                                    r5 >>= 16   ///  r5 = r5.wrapping_shr(16)
    or64 r1, r5                                     r1 |= r5   ///  r1 = r1.or(r5)
    mov64 r5, r1                                    r5 = r1
    rsh64 r5, 32                                    r5 >>= 32   ///  r5 = r5.wrapping_shr(32)
    or64 r1, r5                                     r1 |= r5   ///  r1 = r1.or(r5)
    xor64 r1, -1                                    r1 ^= -1   ///  r1 = r1.xor(-1)
    lddw r5, 0x5555555555555555                     r5 load str located at 6148914691236517205
    mov64 r0, r1                                    r0 = r1
    rsh64 r0, 1                                     r0 >>= 1   ///  r0 = r0.wrapping_shr(1)
    and64 r0, r5                                    r0 &= r5   ///  r0 = r0.and(r5)
    sub64 r1, r0                                    r1 -= r0   ///  r1 = r1.wrapping_sub(r0)
    lddw r0, 0x3333333333333333                     r0 load str located at 3689348814741910323
    mov64 r5, r1                                    r5 = r1
    and64 r5, r0                                    r5 &= r0   ///  r5 = r5.and(r0)
    rsh64 r1, 2                                     r1 >>= 2   ///  r1 = r1.wrapping_shr(2)
    and64 r1, r0                                    r1 &= r0   ///  r1 = r1.and(r0)
    add64 r5, r1                                    r5 += r1   ///  r5 = r5.wrapping_add(r1)
    mov64 r1, r5                                    r1 = r5
    rsh64 r1, 4                                     r1 >>= 4   ///  r1 = r1.wrapping_shr(4)
    add64 r5, r1                                    r5 += r1   ///  r5 = r5.wrapping_add(r1)
    lddw r1, 0xf0f0f0f0f0f0f0f                      r1 load str located at 1085102592571150095
    and64 r5, r1                                    r5 &= r1   ///  r5 = r5.and(r1)
    lddw r1, 0x101010101010101                      r1 load str located at 72340172838076673
    mul64 r5, r1                                    r5 *= r1   ///  r5 = r5.wrapping_mul(r1)
    rsh64 r5, 56                                    r5 >>= 56   ///  r5 = r5.wrapping_shr(56)
lbb_15594:
    sub64 r7, r5                                    r7 -= r5   ///  r7 = r7.wrapping_sub(r5)
    mov64 r6, 256                                   r6 = 256 as i32 as i64 as u64
    ldxdw r1, [r3+0x18]                     
    jne r1, 0, lbb_15604                            if r1 != (0 as i32 as i64 as u64) { pc += 6 }
    mov64 r6, 192                                   r6 = 192 as i32 as i64 as u64
    ldxdw r1, [r3+0x10]                     
    jne r1, 0, lbb_15604                            if r1 != (0 as i32 as i64 as u64) { pc += 3 }
    mov64 r6, 128                                   r6 = 128 as i32 as i64 as u64
    ldxdw r1, [r3+0x8]                      
    jeq r1, 0, lbb_15663                            if r1 == (0 as i32 as i64 as u64) { pc += 59 }
lbb_15604:
    mov64 r5, r1                                    r5 = r1
    rsh64 r5, 1                                     r5 >>= 1   ///  r5 = r5.wrapping_shr(1)
    or64 r1, r5                                     r1 |= r5   ///  r1 = r1.or(r5)
    mov64 r5, r1                                    r5 = r1
    rsh64 r5, 2                                     r5 >>= 2   ///  r5 = r5.wrapping_shr(2)
    or64 r1, r5                                     r1 |= r5   ///  r1 = r1.or(r5)
    mov64 r5, r1                                    r5 = r1
    rsh64 r5, 4                                     r5 >>= 4   ///  r5 = r5.wrapping_shr(4)
    or64 r1, r5                                     r1 |= r5   ///  r1 = r1.or(r5)
    mov64 r5, r1                                    r5 = r1
    rsh64 r5, 8                                     r5 >>= 8   ///  r5 = r5.wrapping_shr(8)
    or64 r1, r5                                     r1 |= r5   ///  r1 = r1.or(r5)
    mov64 r5, r1                                    r5 = r1
    rsh64 r5, 16                                    r5 >>= 16   ///  r5 = r5.wrapping_shr(16)
    or64 r1, r5                                     r1 |= r5   ///  r1 = r1.or(r5)
    mov64 r5, r1                                    r5 = r1
    rsh64 r5, 32                                    r5 >>= 32   ///  r5 = r5.wrapping_shr(32)
    or64 r1, r5                                     r1 |= r5   ///  r1 = r1.or(r5)
    xor64 r1, -1                                    r1 ^= -1   ///  r1 = r1.xor(-1)
    lddw r5, 0x5555555555555555                     r5 load str located at 6148914691236517205
    mov64 r0, r1                                    r0 = r1
    rsh64 r0, 1                                     r0 >>= 1   ///  r0 = r0.wrapping_shr(1)
    and64 r0, r5                                    r0 &= r5   ///  r0 = r0.and(r5)
    sub64 r1, r0                                    r1 -= r0   ///  r1 = r1.wrapping_sub(r0)
    lddw r0, 0x3333333333333333                     r0 load str located at 3689348814741910323
    mov64 r5, r1                                    r5 = r1
    and64 r5, r0                                    r5 &= r0   ///  r5 = r5.and(r0)
    rsh64 r1, 2                                     r1 >>= 2   ///  r1 = r1.wrapping_shr(2)
    and64 r1, r0                                    r1 &= r0   ///  r1 = r1.and(r0)
    add64 r5, r1                                    r5 += r1   ///  r5 = r5.wrapping_add(r1)
    mov64 r1, r5                                    r1 = r5
    rsh64 r1, 4                                     r1 >>= 4   ///  r1 = r1.wrapping_shr(4)
    add64 r5, r1                                    r5 += r1   ///  r5 = r5.wrapping_add(r1)
    lddw r1, 0xf0f0f0f0f0f0f0f                      r1 load str located at 1085102592571150095
    and64 r5, r1                                    r5 &= r1   ///  r5 = r5.and(r1)
    lddw r1, 0x101010101010101                      r1 load str located at 72340172838076673
    mul64 r5, r1                                    r5 *= r1   ///  r5 = r5.wrapping_mul(r1)
    rsh64 r5, 56                                    r5 >>= 56   ///  r5 = r5.wrapping_shr(56)
    sub64 r6, r5                                    r6 -= r5   ///  r6 = r6.wrapping_sub(r5)
    jgt r6, r7, lbb_15649                           if r6 > r7 { pc += 1 }
    ja lbb_15713                                    if true { pc += 64 }
lbb_15649:
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    stxdw [r4+0x18], r1                     
    stxdw [r4+0x10], r1                     
    stxdw [r4+0x8], r1                      
    stxdw [r4+0x0], r1                      
    ldxdw r1, [r2+0x0]                      
    stxdw [r4+0x20], r1                     
    ldxdw r1, [r2+0x8]                      
    stxdw [r4+0x28], r1                     
    ldxdw r1, [r2+0x10]                     
    stxdw [r4+0x30], r1                     
    ldxdw r1, [r2+0x18]                     
    stxdw [r4+0x38], r1                     
    ja lbb_16848                                    if true { pc += 1185 }
lbb_15663:
    ldxdw r1, [r3+0x0]                      
    mov64 r0, 64                                    r0 = 64 as i32 as i64 as u64
    jeq r1, 0, lbb_15709                            if r1 == (0 as i32 as i64 as u64) { pc += 43 }
    mov64 r0, r1                                    r0 = r1
    rsh64 r0, 1                                     r0 >>= 1   ///  r0 = r0.wrapping_shr(1)
    mov64 r5, r1                                    r5 = r1
    or64 r5, r0                                     r5 |= r0   ///  r5 = r5.or(r0)
    mov64 r0, r5                                    r0 = r5
    rsh64 r0, 2                                     r0 >>= 2   ///  r0 = r0.wrapping_shr(2)
    or64 r5, r0                                     r5 |= r0   ///  r5 = r5.or(r0)
    mov64 r0, r5                                    r0 = r5
    rsh64 r0, 4                                     r0 >>= 4   ///  r0 = r0.wrapping_shr(4)
    or64 r5, r0                                     r5 |= r0   ///  r5 = r5.or(r0)
    mov64 r0, r5                                    r0 = r5
    rsh64 r0, 8                                     r0 >>= 8   ///  r0 = r0.wrapping_shr(8)
    or64 r5, r0                                     r5 |= r0   ///  r5 = r5.or(r0)
    mov64 r0, r5                                    r0 = r5
    rsh64 r0, 16                                    r0 >>= 16   ///  r0 = r0.wrapping_shr(16)
    or64 r5, r0                                     r5 |= r0   ///  r5 = r5.or(r0)
    mov64 r0, r5                                    r0 = r5
    rsh64 r0, 32                                    r0 >>= 32   ///  r0 = r0.wrapping_shr(32)
    or64 r5, r0                                     r5 |= r0   ///  r5 = r5.or(r0)
    xor64 r5, -1                                    r5 ^= -1   ///  r5 = r5.xor(-1)
    lddw r0, 0x5555555555555555                     r0 load str located at 6148914691236517205
    mov64 r6, r5                                    r6 = r5
    rsh64 r6, 1                                     r6 >>= 1   ///  r6 = r6.wrapping_shr(1)
    and64 r6, r0                                    r6 &= r0   ///  r6 = r6.and(r0)
    sub64 r5, r6                                    r5 -= r6   ///  r5 = r5.wrapping_sub(r6)
    lddw r6, 0x3333333333333333                     r6 load str located at 3689348814741910323
    mov64 r0, r5                                    r0 = r5
    and64 r0, r6                                    r0 &= r6   ///  r0 = r0.and(r6)
    rsh64 r5, 2                                     r5 >>= 2   ///  r5 = r5.wrapping_shr(2)
    and64 r5, r6                                    r5 &= r6   ///  r5 = r5.and(r6)
    add64 r0, r5                                    r0 += r5   ///  r0 = r0.wrapping_add(r5)
    mov64 r5, r0                                    r5 = r0
    rsh64 r5, 4                                     r5 >>= 4   ///  r5 = r5.wrapping_shr(4)
    add64 r0, r5                                    r0 += r5   ///  r0 = r0.wrapping_add(r5)
    lddw r5, 0xf0f0f0f0f0f0f0f                      r5 load str located at 1085102592571150095
    and64 r0, r5                                    r0 &= r5   ///  r0 = r0.and(r5)
    lddw r5, 0x101010101010101                      r5 load str located at 72340172838076673
    mul64 r0, r5                                    r0 *= r5   ///  r0 = r0.wrapping_mul(r5)
    rsh64 r0, 56                                    r0 >>= 56   ///  r0 = r0.wrapping_shr(56)
lbb_15709:
    mov64 r6, 64                                    r6 = 64 as i32 as i64 as u64
    sub64 r6, r0                                    r6 -= r0   ///  r6 = r6.wrapping_sub(r0)
    jeq r1, 0, lbb_16878                            if r1 == (0 as i32 as i64 as u64) { pc += 1166 }
    jgt r6, r7, lbb_15649                           if r6 > r7 { pc += -64 }
lbb_15713:
    mov64 r5, r6                                    r5 = r6
    mov64 r1, 65                                    r1 = 65 as i32 as i64 as u64
    stxdw [r10-0x1d0], r4                   
    jgt r1, r5, lbb_15718                           if r1 > r5 { pc += 1 }
    ja lbb_16119                                    if true { pc += 401 }
lbb_15718:
    mov64 r5, 64                                    r5 = 64 as i32 as i64 as u64
    ldxdw r6, [r3+0x0]                      
    jeq r6, 0, lbb_15764                            if r6 == (0 as i32 as i64 as u64) { pc += 43 }
    mov64 r3, r6                                    r3 = r6
    rsh64 r3, 1                                     r3 >>= 1   ///  r3 = r3.wrapping_shr(1)
    mov64 r1, r6                                    r1 = r6
    or64 r1, r3                                     r1 |= r3   ///  r1 = r1.or(r3)
    mov64 r3, r1                                    r3 = r1
    rsh64 r3, 2                                     r3 >>= 2   ///  r3 = r3.wrapping_shr(2)
    or64 r1, r3                                     r1 |= r3   ///  r1 = r1.or(r3)
    mov64 r3, r1                                    r3 = r1
    rsh64 r3, 4                                     r3 >>= 4   ///  r3 = r3.wrapping_shr(4)
    or64 r1, r3                                     r1 |= r3   ///  r1 = r1.or(r3)
    mov64 r3, r1                                    r3 = r1
    rsh64 r3, 8                                     r3 >>= 8   ///  r3 = r3.wrapping_shr(8)
    or64 r1, r3                                     r1 |= r3   ///  r1 = r1.or(r3)
    mov64 r3, r1                                    r3 = r1
    rsh64 r3, 16                                    r3 >>= 16   ///  r3 = r3.wrapping_shr(16)
    or64 r1, r3                                     r1 |= r3   ///  r1 = r1.or(r3)
    mov64 r3, r1                                    r3 = r1
    rsh64 r3, 32                                    r3 >>= 32   ///  r3 = r3.wrapping_shr(32)
    or64 r1, r3                                     r1 |= r3   ///  r1 = r1.or(r3)
    xor64 r1, -1                                    r1 ^= -1   ///  r1 = r1.xor(-1)
    lddw r3, 0x5555555555555555                     r3 load str located at 6148914691236517205
    mov64 r5, r1                                    r5 = r1
    rsh64 r5, 1                                     r5 >>= 1   ///  r5 = r5.wrapping_shr(1)
    and64 r5, r3                                    r5 &= r3   ///  r5 = r5.and(r3)
    sub64 r1, r5                                    r1 -= r5   ///  r1 = r1.wrapping_sub(r5)
    lddw r3, 0x3333333333333333                     r3 load str located at 3689348814741910323
    mov64 r5, r1                                    r5 = r1
    and64 r5, r3                                    r5 &= r3   ///  r5 = r5.and(r3)
    rsh64 r1, 2                                     r1 >>= 2   ///  r1 = r1.wrapping_shr(2)
    and64 r1, r3                                    r1 &= r3   ///  r1 = r1.and(r3)
    add64 r5, r1                                    r5 += r1   ///  r5 = r5.wrapping_add(r1)
    mov64 r1, r5                                    r1 = r5
    rsh64 r1, 4                                     r1 >>= 4   ///  r1 = r1.wrapping_shr(4)
    add64 r5, r1                                    r5 += r1   ///  r5 = r5.wrapping_add(r1)
    lddw r1, 0xf0f0f0f0f0f0f0f                      r1 load str located at 1085102592571150095
    and64 r5, r1                                    r5 &= r1   ///  r5 = r5.and(r1)
    lddw r1, 0x101010101010101                      r1 load str located at 72340172838076673
    mul64 r5, r1                                    r5 *= r1   ///  r5 = r5.wrapping_mul(r1)
    rsh64 r5, 56                                    r5 >>= 56   ///  r5 = r5.wrapping_shr(56)
lbb_15764:
    mov64 r1, r5                                    r1 = r5
    and64 r1, 63                                    r1 &= 63   ///  r1 = r1.and(63)
    stxdw [r10-0x138], r1                   
    lsh64 r6, r1                                    r6 <<= r1   ///  r6 = r6.wrapping_shl(r1 as u32)
    lddw r1, 0x100000000                            r1 load str located at 4294967296
    jgt r1, r6, lbb_16863                           if r1 > r6 { pc += 1092 }
    mov64 r1, r5                                    r1 = r5
    neg64 r1                                        r1 = -r1   ///  r1 = (r1 as i64).wrapping_neg() as u64
    and64 r1, 63                                    r1 &= 63   ///  r1 = r1.and(63)
    stxdw [r10-0x148], r1                   
    mov64 r0, r6                                    r0 = r6
    rsh64 r0, 32                                    r0 >>= 32   ///  r0 = r0.wrapping_shr(32)
    stxdw [r10-0x130], r6                   
    mov64 r1, r6                                    r1 = r6
    lsh64 r1, 32                                    r1 <<= 32   ///  r1 = r1.wrapping_shl(32)
    stxdw [r10-0x108], r1                   
    mov64 r4, 0                                     r4 = 0 as i32 as i64 as u64
    mov64 r3, r8                                    r3 = r8
    stxdw [r10-0x140], r5                   
    jeq r5, 0, lbb_15788                            if r5 == (0 as i32 as i64 as u64) { pc += 3 }
    mov64 r4, r3                                    r4 = r3
    ldxdw r1, [r10-0x148]                   
    rsh64 r4, r1                                    r4 >>= r1   ///  r4 = r4.wrapping_shr(r1 as u32)
lbb_15788:
    ldxdw r1, [r2+0x10]                     
    stxdw [r10-0x128], r1                   
    ldxdw r1, [r2+0x8]                      
    stxdw [r10-0x120], r1                   
    ldxdw r1, [r2+0x0]                      
    stxdw [r10-0x118], r1                   
    ldxdw r1, [r10-0x108]                   
    rsh64 r1, 32                                    r1 >>= 32   ///  r1 = r1.wrapping_shr(32)
    stxdw [r10-0x108], r1                   
    ldxdw r1, [r10-0x138]                   
    lsh64 r3, r1                                    r3 <<= r1   ///  r3 = r3.wrapping_shl(r1 as u32)
    mov64 r7, r3                                    r7 = r3
    rsh64 r7, 32                                    r7 >>= 32   ///  r7 = r7.wrapping_shr(32)
    mov64 r2, r4                                    r2 = r4
    div64 r2, r0                                    r2 /= r0   ///  r2 = r2 / r0
    mov64 r5, r2                                    r5 = r2
    mul64 r5, r0                                    r5 *= r0   ///  r5 = r5.wrapping_mul(r0)
    stxdw [r10-0x110], r4                   
    mov64 r1, r4                                    r1 = r4
    sub64 r1, r5                                    r1 -= r5   ///  r1 = r1.wrapping_sub(r5)
    lsh64 r3, 32                                    r3 <<= 32   ///  r3 = r3.wrapping_shl(32)
    rsh64 r3, 32                                    r3 >>= 32   ///  r3 = r3.wrapping_shr(32)
    lddw r4, 0xffffffff                             r4 load str located at 4294967295
    lddw r8, 0x100000000                            r8 load str located at 4294967296
lbb_15814:
    jgt r2, r4, lbb_15822                           if r2 > r4 { pc += 7 }
    mov64 r6, r1                                    r6 = r1
    lsh64 r6, 32                                    r6 <<= 32   ///  r6 = r6.wrapping_shl(32)
    or64 r6, r7                                     r6 |= r7   ///  r6 = r6.or(r7)
    mov64 r5, r2                                    r5 = r2
    ldxdw r9, [r10-0x108]                   
    mul64 r5, r9                                    r5 *= r9   ///  r5 = r5.wrapping_mul(r9)
    jge r6, r5, lbb_15825                           if r6 >= r5 { pc += 3 }
lbb_15822:
    add64 r1, r0                                    r1 += r0   ///  r1 = r1.wrapping_add(r0)
    add64 r2, -1                                    r2 += -1   ///  r2 = r2.wrapping_add(-1 as i32 as i64 as u64)
    jgt r8, r1, lbb_15814                           if r8 > r1 { pc += -11 }
lbb_15825:
    mov64 r1, r2                                    r1 = r2
    ldxdw r4, [r10-0x130]                   
    mul64 r1, r4                                    r1 *= r4   ///  r1 = r1.wrapping_mul(r4)
    ldxdw r5, [r10-0x110]                   
    lsh64 r5, 32                                    r5 <<= 32   ///  r5 = r5.wrapping_shl(32)
    or64 r5, r7                                     r5 |= r7   ///  r5 = r5.or(r7)
    sub64 r5, r1                                    r5 -= r1   ///  r5 = r5.wrapping_sub(r1)
    mov64 r7, r5                                    r7 = r5
    div64 r7, r0                                    r7 /= r0   ///  r7 = r7 / r0
    mov64 r4, r7                                    r4 = r7
    mul64 r4, r0                                    r4 *= r0   ///  r4 = r4.wrapping_mul(r0)
    stxdw [r10-0x110], r5                   
    mov64 r1, r5                                    r1 = r5
    sub64 r1, r4                                    r1 -= r4   ///  r1 = r1.wrapping_sub(r4)
    lddw r4, 0xffffffff                             r4 load str located at 4294967295
    lddw r8, 0x100000000                            r8 load str located at 4294967296
lbb_15843:
    jgt r7, r4, lbb_15851                           if r7 > r4 { pc += 7 }
    mov64 r5, r1                                    r5 = r1
    lsh64 r5, 32                                    r5 <<= 32   ///  r5 = r5.wrapping_shl(32)
    or64 r5, r3                                     r5 |= r3   ///  r5 = r5.or(r3)
    mov64 r6, r7                                    r6 = r7
    ldxdw r9, [r10-0x108]                   
    mul64 r6, r9                                    r6 *= r9   ///  r6 = r6.wrapping_mul(r9)
    jge r5, r6, lbb_15854                           if r5 >= r6 { pc += 3 }
lbb_15851:
    add64 r1, r0                                    r1 += r0   ///  r1 = r1.wrapping_add(r0)
    add64 r7, -1                                    r7 += -1   ///  r7 = r7.wrapping_add(-1 as i32 as i64 as u64)
    jgt r8, r1, lbb_15843                           if r8 > r1 { pc += -11 }
lbb_15854:
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    ldxdw r4, [r10-0x140]                   
    jeq r4, 0, lbb_15860                            if r4 == (0 as i32 as i64 as u64) { pc += 3 }
    ldxdw r1, [r10-0x128]                   
    ldxdw r4, [r10-0x148]                   
    rsh64 r1, r4                                    r1 >>= r4   ///  r1 = r1.wrapping_shr(r4 as u32)
lbb_15860:
    ldxdw r6, [r10-0x110]                   
    lsh64 r6, 32                                    r6 <<= 32   ///  r6 = r6.wrapping_shl(32)
    or64 r6, r3                                     r6 |= r3   ///  r6 = r6.or(r3)
    mov64 r4, r7                                    r4 = r7
    ldxdw r3, [r10-0x130]                   
    mul64 r4, r3                                    r4 *= r3   ///  r4 = r4.wrapping_mul(r3)
    sub64 r6, r4                                    r6 -= r4   ///  r6 = r6.wrapping_sub(r4)
    lsh64 r2, 32                                    r2 <<= 32   ///  r2 = r2.wrapping_shl(32)
    add64 r7, r2                                    r7 += r2   ///  r7 = r7.wrapping_add(r2)
    ldxdw r2, [r10-0x138]                   
    ldxdw r5, [r10-0x128]                   
    lsh64 r5, r2                                    r5 <<= r2   ///  r5 = r5.wrapping_shl(r2 as u32)
    mov64 r3, -1                                    r3 = -1 as i32 as i64 as u64
    lsh64 r3, r2                                    r3 <<= r2   ///  r3 = r3.wrapping_shl(r2 as u32)
    stxdw [r10-0x150], r3                   
    and64 r6, r3                                    r6 &= r3   ///  r6 = r6.and(r3)
    or64 r6, r1                                     r6 |= r1   ///  r6 = r6.or(r1)
    mov64 r4, r5                                    r4 = r5
    rsh64 r4, 32                                    r4 >>= 32   ///  r4 = r4.wrapping_shr(32)
    lsh64 r5, 32                                    r5 <<= 32   ///  r5 = r5.wrapping_shl(32)
    rsh64 r5, 32                                    r5 >>= 32   ///  r5 = r5.wrapping_shr(32)
    stxdw [r10-0x128], r5                   
    mov64 r2, r6                                    r2 = r6
    div64 r2, r0                                    r2 /= r0   ///  r2 = r2 / r0
    mov64 r5, r2                                    r5 = r2
    mul64 r5, r0                                    r5 *= r0   ///  r5 = r5.wrapping_mul(r0)
    stxdw [r10-0x110], r6                   
    mov64 r1, r6                                    r1 = r6
    sub64 r1, r5                                    r1 -= r5   ///  r1 = r1.wrapping_sub(r5)
    lddw r3, 0xffffffff                             r3 load str located at 4294967295
    lddw r8, 0x100000000                            r8 load str located at 4294967296
lbb_15893:
    jgt r2, r3, lbb_15901                           if r2 > r3 { pc += 7 }
    mov64 r6, r1                                    r6 = r1
    lsh64 r6, 32                                    r6 <<= 32   ///  r6 = r6.wrapping_shl(32)
    or64 r6, r4                                     r6 |= r4   ///  r6 = r6.or(r4)
    mov64 r5, r2                                    r5 = r2
    ldxdw r9, [r10-0x108]                   
    mul64 r5, r9                                    r5 *= r9   ///  r5 = r5.wrapping_mul(r9)
    jge r6, r5, lbb_15904                           if r6 >= r5 { pc += 3 }
lbb_15901:
    add64 r1, r0                                    r1 += r0   ///  r1 = r1.wrapping_add(r0)
    add64 r2, -1                                    r2 += -1   ///  r2 = r2.wrapping_add(-1 as i32 as i64 as u64)
    jgt r8, r1, lbb_15893                           if r8 > r1 { pc += -11 }
lbb_15904:
    mov64 r1, r2                                    r1 = r2
    ldxdw r3, [r10-0x130]                   
    mul64 r1, r3                                    r1 *= r3   ///  r1 = r1.wrapping_mul(r3)
    ldxdw r5, [r10-0x110]                   
    lsh64 r5, 32                                    r5 <<= 32   ///  r5 = r5.wrapping_shl(32)
    or64 r5, r4                                     r5 |= r4   ///  r5 = r5.or(r4)
    sub64 r5, r1                                    r5 -= r1   ///  r5 = r5.wrapping_sub(r1)
    mov64 r4, r5                                    r4 = r5
    div64 r4, r0                                    r4 /= r0   ///  r4 = r4 / r0
    mov64 r3, r4                                    r3 = r4
    mul64 r3, r0                                    r3 *= r0   ///  r3 = r3.wrapping_mul(r0)
    stxdw [r10-0x110], r5                   
    mov64 r1, r5                                    r1 = r5
    sub64 r1, r3                                    r1 -= r3   ///  r1 = r1.wrapping_sub(r3)
    lddw r3, 0xffffffff                             r3 load str located at 4294967295
    lddw r8, 0x100000000                            r8 load str located at 4294967296
lbb_15922:
    jgt r4, r3, lbb_15931                           if r4 > r3 { pc += 8 }
    mov64 r5, r1                                    r5 = r1
    lsh64 r5, 32                                    r5 <<= 32   ///  r5 = r5.wrapping_shl(32)
    ldxdw r6, [r10-0x128]                   
    or64 r5, r6                                     r5 |= r6   ///  r5 = r5.or(r6)
    mov64 r6, r4                                    r6 = r4
    ldxdw r9, [r10-0x108]                   
    mul64 r6, r9                                    r6 *= r9   ///  r6 = r6.wrapping_mul(r9)
    jge r5, r6, lbb_15934                           if r5 >= r6 { pc += 3 }
lbb_15931:
    add64 r1, r0                                    r1 += r0   ///  r1 = r1.wrapping_add(r0)
    add64 r4, -1                                    r4 += -1   ///  r4 = r4.wrapping_add(-1 as i32 as i64 as u64)
    jgt r8, r1, lbb_15922                           if r8 > r1 { pc += -12 }
lbb_15934:
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    ldxdw r3, [r10-0x140]                   
    jeq r3, 0, lbb_15940                            if r3 == (0 as i32 as i64 as u64) { pc += 3 }
    ldxdw r1, [r10-0x120]                   
    ldxdw r3, [r10-0x148]                   
    rsh64 r1, r3                                    r1 >>= r3   ///  r1 = r1.wrapping_shr(r3 as u32)
lbb_15940:
    ldxdw r6, [r10-0x110]                   
    lsh64 r6, 32                                    r6 <<= 32   ///  r6 = r6.wrapping_shl(32)
    ldxdw r3, [r10-0x128]                   
    or64 r6, r3                                     r6 |= r3   ///  r6 = r6.or(r3)
    mov64 r3, r4                                    r3 = r4
    ldxdw r5, [r10-0x130]                   
    mul64 r3, r5                                    r3 *= r5   ///  r3 = r3.wrapping_mul(r5)
    sub64 r6, r3                                    r6 -= r3   ///  r6 = r6.wrapping_sub(r3)
    ldxdw r3, [r10-0x150]                   
    and64 r6, r3                                    r6 &= r3   ///  r6 = r6.and(r3)
    or64 r6, r1                                     r6 |= r1   ///  r6 = r6.or(r1)
    lsh64 r2, 32                                    r2 <<= 32   ///  r2 = r2.wrapping_shl(32)
    add64 r4, r2                                    r4 += r2   ///  r4 = r4.wrapping_add(r2)
    ldxdw r1, [r10-0x138]                   
    ldxdw r2, [r10-0x120]                   
    lsh64 r2, r1                                    r2 <<= r1   ///  r2 = r2.wrapping_shl(r1 as u32)
    mov64 r3, r2                                    r3 = r2
    rsh64 r3, 32                                    r3 >>= 32   ///  r3 = r3.wrapping_shr(32)
    lsh64 r2, 32                                    r2 <<= 32   ///  r2 = r2.wrapping_shl(32)
    rsh64 r2, 32                                    r2 >>= 32   ///  r2 = r2.wrapping_shr(32)
    stxdw [r10-0x120], r2                   
    mov64 r2, r6                                    r2 = r6
    div64 r2, r0                                    r2 /= r0   ///  r2 = r2 / r0
    mov64 r5, r2                                    r5 = r2
    mul64 r5, r0                                    r5 *= r0   ///  r5 = r5.wrapping_mul(r0)
    stxdw [r10-0x110], r6                   
    mov64 r1, r6                                    r1 = r6
    sub64 r1, r5                                    r1 -= r5   ///  r1 = r1.wrapping_sub(r5)
    lddw r8, 0xffffffff                             r8 load str located at 4294967295
lbb_15970:
    jgt r2, r8, lbb_15978                           if r2 > r8 { pc += 7 }
    mov64 r6, r1                                    r6 = r1
    lsh64 r6, 32                                    r6 <<= 32   ///  r6 = r6.wrapping_shl(32)
    or64 r6, r3                                     r6 |= r3   ///  r6 = r6.or(r3)
    mov64 r5, r2                                    r5 = r2
    ldxdw r9, [r10-0x108]                   
    mul64 r5, r9                                    r5 *= r9   ///  r5 = r5.wrapping_mul(r9)
    jge r6, r5, lbb_15983                           if r6 >= r5 { pc += 5 }
lbb_15978:
    add64 r1, r0                                    r1 += r0   ///  r1 = r1.wrapping_add(r0)
    add64 r2, -1                                    r2 += -1   ///  r2 = r2.wrapping_add(-1 as i32 as i64 as u64)
    lddw r5, 0x100000000                            r5 load str located at 4294967296
    jgt r5, r1, lbb_15970                           if r5 > r1 { pc += -13 }
lbb_15983:
    mov64 r1, r2                                    r1 = r2
    ldxdw r5, [r10-0x130]                   
    mul64 r1, r5                                    r1 *= r5   ///  r1 = r1.wrapping_mul(r5)
    ldxdw r6, [r10-0x110]                   
    lsh64 r6, 32                                    r6 <<= 32   ///  r6 = r6.wrapping_shl(32)
    or64 r6, r3                                     r6 |= r3   ///  r6 = r6.or(r3)
    sub64 r6, r1                                    r6 -= r1   ///  r6 = r6.wrapping_sub(r1)
    mov64 r9, r6                                    r9 = r6
    div64 r9, r0                                    r9 /= r0   ///  r9 = r9 / r0
    mov64 r5, r9                                    r5 = r9
    mul64 r5, r0                                    r5 *= r0   ///  r5 = r5.wrapping_mul(r0)
    stxdw [r10-0x110], r6                   
    mov64 r1, r6                                    r1 = r6
    sub64 r1, r5                                    r1 -= r5   ///  r1 = r1.wrapping_sub(r5)
    lddw r5, 0xffffffff                             r5 load str located at 4294967295
lbb_15999:
    jgt r9, r5, lbb_16008                           if r9 > r5 { pc += 8 }
    mov64 r6, r1                                    r6 = r1
    lsh64 r6, 32                                    r6 <<= 32   ///  r6 = r6.wrapping_shl(32)
    ldxdw r3, [r10-0x120]                   
    or64 r6, r3                                     r6 |= r3   ///  r6 = r6.or(r3)
    mov64 r3, r9                                    r3 = r9
    ldxdw r8, [r10-0x108]                   
    mul64 r3, r8                                    r3 *= r8   ///  r3 = r3.wrapping_mul(r8)
    jge r6, r3, lbb_16013                           if r6 >= r3 { pc += 5 }
lbb_16008:
    add64 r1, r0                                    r1 += r0   ///  r1 = r1.wrapping_add(r0)
    add64 r9, -1                                    r9 += -1   ///  r9 = r9.wrapping_add(-1 as i32 as i64 as u64)
    lddw r3, 0x100000000                            r3 load str located at 4294967296
    jgt r3, r1, lbb_15999                           if r3 > r1 { pc += -14 }
lbb_16013:
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    ldxdw r3, [r10-0x140]                   
    jeq r3, 0, lbb_16019                            if r3 == (0 as i32 as i64 as u64) { pc += 3 }
    ldxdw r1, [r10-0x118]                   
    ldxdw r3, [r10-0x148]                   
    rsh64 r1, r3                                    r1 >>= r3   ///  r1 = r1.wrapping_shr(r3 as u32)
lbb_16019:
    ldxdw r6, [r10-0x110]                   
    lsh64 r6, 32                                    r6 <<= 32   ///  r6 = r6.wrapping_shl(32)
    ldxdw r3, [r10-0x120]                   
    or64 r6, r3                                     r6 |= r3   ///  r6 = r6.or(r3)
    mov64 r3, r9                                    r3 = r9
    ldxdw r5, [r10-0x130]                   
    mul64 r3, r5                                    r3 *= r5   ///  r3 = r3.wrapping_mul(r5)
    sub64 r6, r3                                    r6 -= r3   ///  r6 = r6.wrapping_sub(r3)
    ldxdw r3, [r10-0x150]                   
    and64 r6, r3                                    r6 &= r3   ///  r6 = r6.and(r3)
    or64 r6, r1                                     r6 |= r1   ///  r6 = r6.or(r1)
    lsh64 r2, 32                                    r2 <<= 32   ///  r2 = r2.wrapping_shl(32)
    add64 r9, r2                                    r9 += r2   ///  r9 = r9.wrapping_add(r2)
    ldxdw r1, [r10-0x138]                   
    ldxdw r2, [r10-0x118]                   
    lsh64 r2, r1                                    r2 <<= r1   ///  r2 = r2.wrapping_shl(r1 as u32)
    mov64 r8, r2                                    r8 = r2
    rsh64 r8, 32                                    r8 >>= 32   ///  r8 = r8.wrapping_shr(32)
    lsh64 r2, 32                                    r2 <<= 32   ///  r2 = r2.wrapping_shl(32)
    rsh64 r2, 32                                    r2 >>= 32   ///  r2 = r2.wrapping_shr(32)
    stxdw [r10-0x118], r2                   
    mov64 r2, r6                                    r2 = r6
    div64 r2, r0                                    r2 /= r0   ///  r2 = r2 / r0
    mov64 r3, r2                                    r3 = r2
    mul64 r3, r0                                    r3 *= r0   ///  r3 = r3.wrapping_mul(r0)
    stxdw [r10-0x110], r6                   
    mov64 r1, r6                                    r1 = r6
    sub64 r1, r3                                    r1 -= r3   ///  r1 = r1.wrapping_sub(r3)
    lddw r6, 0xffffffff                             r6 load str located at 4294967295
lbb_16049:
    jgt r2, r6, lbb_16059                           if r2 > r6 { pc += 9 }
    mov64 r3, r1                                    r3 = r1
    lsh64 r3, 32                                    r3 <<= 32   ///  r3 = r3.wrapping_shl(32)
    or64 r3, r8                                     r3 |= r8   ///  r3 = r3.or(r8)
    mov64 r5, r2                                    r5 = r2
    ldxdw r6, [r10-0x108]                   
    mul64 r5, r6                                    r5 *= r6   ///  r5 = r5.wrapping_mul(r6)
    lddw r6, 0xffffffff                             r6 load str located at 4294967295
    jge r3, r5, lbb_16064                           if r3 >= r5 { pc += 5 }
lbb_16059:
    add64 r1, r0                                    r1 += r0   ///  r1 = r1.wrapping_add(r0)
    add64 r2, -1                                    r2 += -1   ///  r2 = r2.wrapping_add(-1 as i32 as i64 as u64)
    lddw r3, 0x100000000                            r3 load str located at 4294967296
    jgt r3, r1, lbb_16049                           if r3 > r1 { pc += -15 }
lbb_16064:
    mov64 r1, r2                                    r1 = r2
    ldxdw r3, [r10-0x130]                   
    mul64 r1, r3                                    r1 *= r3   ///  r1 = r1.wrapping_mul(r3)
    ldxdw r6, [r10-0x110]                   
    lsh64 r6, 32                                    r6 <<= 32   ///  r6 = r6.wrapping_shl(32)
    or64 r6, r8                                     r6 |= r8   ///  r6 = r6.or(r8)
    sub64 r6, r1                                    r6 -= r1   ///  r6 = r6.wrapping_sub(r1)
    mov64 r3, r6                                    r3 = r6
    div64 r3, r0                                    r3 /= r0   ///  r3 = r3 / r0
    mov64 r5, r3                                    r5 = r3
    mul64 r5, r0                                    r5 *= r0   ///  r5 = r5.wrapping_mul(r0)
    stxdw [r10-0x110], r6                   
    mov64 r1, r6                                    r1 = r6
    sub64 r1, r5                                    r1 -= r5   ///  r1 = r1.wrapping_sub(r5)
    lddw r6, 0xffffffff                             r6 load str located at 4294967295
lbb_16080:
    jgt r3, r6, lbb_16091                           if r3 > r6 { pc += 10 }
    mov64 r5, r1                                    r5 = r1
    lsh64 r5, 32                                    r5 <<= 32   ///  r5 = r5.wrapping_shl(32)
    ldxdw r8, [r10-0x118]                   
    or64 r5, r8                                     r5 |= r8   ///  r5 = r5.or(r8)
    mov64 r8, r3                                    r8 = r3
    ldxdw r6, [r10-0x108]                   
    mul64 r8, r6                                    r8 *= r6   ///  r8 = r8.wrapping_mul(r6)
    lddw r6, 0xffffffff                             r6 load str located at 4294967295
    jge r5, r8, lbb_16096                           if r5 >= r8 { pc += 5 }
lbb_16091:
    add64 r1, r0                                    r1 += r0   ///  r1 = r1.wrapping_add(r0)
    add64 r3, -1                                    r3 += -1   ///  r3 = r3.wrapping_add(-1 as i32 as i64 as u64)
    lddw r5, 0x100000000                            r5 load str located at 4294967296
    jgt r5, r1, lbb_16080                           if r5 > r1 { pc += -16 }
lbb_16096:
    ldxdw r5, [r10-0x1d0]                   
    stxdw [r5+0x18], r7                     
    stxdw [r5+0x10], r4                     
    stxdw [r5+0x8], r9                      
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    stxdw [r5+0x28], r1                     
    stxdw [r5+0x30], r1                     
    stxdw [r5+0x38], r1                     
    lsh64 r2, 32                                    r2 <<= 32   ///  r2 = r2.wrapping_shl(32)
    mov64 r1, r3                                    r1 = r3
    add64 r1, r2                                    r1 += r2   ///  r1 = r1.wrapping_add(r2)
    stxdw [r5+0x0], r1                      
    ldxdw r1, [r10-0x130]                   
    mul64 r3, r1                                    r3 *= r1   ///  r3 = r3.wrapping_mul(r1)
    ldxdw r2, [r10-0x110]                   
    lsh64 r2, 32                                    r2 <<= 32   ///  r2 = r2.wrapping_shl(32)
    ldxdw r1, [r10-0x118]                   
    or64 r2, r1                                     r2 |= r1   ///  r2 = r2.or(r1)
    sub64 r2, r3                                    r2 -= r3   ///  r2 = r2.wrapping_sub(r3)
    ldxdw r1, [r10-0x138]                   
    rsh64 r2, r1                                    r2 >>= r1   ///  r2 = r2.wrapping_shr(r1 as u32)
    stxdw [r5+0x20], r2                     
    ja lbb_16848                                    if true { pc += 729 }
lbb_16119:
    ldxdw r8, [r2+0x0]                      
    ldxdw r1, [r3+0x18]                     
    stxdw [r10-0x98], r1                    
    ldxdw r1, [r3+0x10]                     
    stxdw [r10-0xa0], r1                    
    ldxdw r1, [r3+0x8]                      
    stxdw [r10-0xa8], r1                    
    ldxdw r1, [r3+0x0]                      
    stxdw [r10-0xb0], r1                    
    add64 r5, -1                                    r5 += -1   ///  r5 = r5.wrapping_add(-1 as i32 as i64 as u64)
    rsh64 r5, 6                                     r5 >>= 6   ///  r5 = r5.wrapping_shr(6)
    stxdw [r10-0x1a0], r5                   
    mov64 r1, r5                                    r1 = r5
    lsh64 r1, 3                                     r1 <<= 3   ///  r1 = r1.wrapping_shl(3)
    mov64 r3, r10                                   r3 = r10
    add64 r3, -176                                  r3 += -176   ///  r3 = r3.wrapping_add(-176 as i32 as i64 as u64)
    add64 r3, r1                                    r3 += r1   ///  r3 = r3.wrapping_add(r1)
    mov64 r1, 64                                    r1 = 64 as i32 as i64 as u64
    stxdw [r10-0x1b8], r1                   
    stxdw [r10-0x110], r3                   
    ldxdw r3, [r3+0x0]                      
    jeq r3, 0, lbb_16185                            if r3 == (0 as i32 as i64 as u64) { pc += 44 }
    mov64 r4, r3                                    r4 = r3
    rsh64 r4, 1                                     r4 >>= 1   ///  r4 = r4.wrapping_shr(1)
    mov64 r1, r3                                    r1 = r3
    or64 r1, r4                                     r1 |= r4   ///  r1 = r1.or(r4)
    mov64 r4, r1                                    r4 = r1
    rsh64 r4, 2                                     r4 >>= 2   ///  r4 = r4.wrapping_shr(2)
    or64 r1, r4                                     r1 |= r4   ///  r1 = r1.or(r4)
    mov64 r4, r1                                    r4 = r1
    rsh64 r4, 4                                     r4 >>= 4   ///  r4 = r4.wrapping_shr(4)
    or64 r1, r4                                     r1 |= r4   ///  r1 = r1.or(r4)
    mov64 r4, r1                                    r4 = r1
    rsh64 r4, 8                                     r4 >>= 8   ///  r4 = r4.wrapping_shr(8)
    or64 r1, r4                                     r1 |= r4   ///  r1 = r1.or(r4)
    mov64 r4, r1                                    r4 = r1
    rsh64 r4, 16                                    r4 >>= 16   ///  r4 = r4.wrapping_shr(16)
    or64 r1, r4                                     r1 |= r4   ///  r1 = r1.or(r4)
    mov64 r4, r1                                    r4 = r1
    rsh64 r4, 32                                    r4 >>= 32   ///  r4 = r4.wrapping_shr(32)
    or64 r1, r4                                     r1 |= r4   ///  r1 = r1.or(r4)
    xor64 r1, -1                                    r1 ^= -1   ///  r1 = r1.xor(-1)
    lddw r4, 0x5555555555555555                     r4 load str located at 6148914691236517205
    mov64 r5, r1                                    r5 = r1
    rsh64 r5, 1                                     r5 >>= 1   ///  r5 = r5.wrapping_shr(1)
    and64 r5, r4                                    r5 &= r4   ///  r5 = r5.and(r4)
    sub64 r1, r5                                    r1 -= r5   ///  r1 = r1.wrapping_sub(r5)
    lddw r4, 0x3333333333333333                     r4 load str located at 3689348814741910323
    mov64 r5, r1                                    r5 = r1
    and64 r5, r4                                    r5 &= r4   ///  r5 = r5.and(r4)
    rsh64 r1, 2                                     r1 >>= 2   ///  r1 = r1.wrapping_shr(2)
    and64 r1, r4                                    r1 &= r4   ///  r1 = r1.and(r4)
    add64 r5, r1                                    r5 += r1   ///  r5 = r5.wrapping_add(r1)
    mov64 r1, r5                                    r1 = r5
    rsh64 r1, 4                                     r1 >>= 4   ///  r1 = r1.wrapping_shr(4)
    add64 r5, r1                                    r5 += r1   ///  r5 = r5.wrapping_add(r1)
    lddw r1, 0xf0f0f0f0f0f0f0f                      r1 load str located at 1085102592571150095
    and64 r5, r1                                    r5 &= r1   ///  r5 = r5.and(r1)
    lddw r1, 0x101010101010101                      r1 load str located at 72340172838076673
    mul64 r5, r1                                    r5 *= r1   ///  r5 = r5.wrapping_mul(r1)
    rsh64 r5, 56                                    r5 >>= 56   ///  r5 = r5.wrapping_shr(56)
    stxdw [r10-0x1b8], r5                   
lbb_16185:
    stxdw [r10-0x128], r7                   
    ldxdw r1, [r10-0x98]                    
    stxdw [r10-0x120], r1                   
    ldxdw r1, [r10-0xa0]                    
    stxdw [r10-0x108], r1                   
    ldxdw r1, [r10-0xa8]                    
    ldxdw r6, [r10-0xb0]                    
    mov64 r4, 0                                     r4 = 0 as i32 as i64 as u64
    stxdw [r10-0x10], r4                    
    stxdw [r10-0x18], r4                    
    stxdw [r10-0x20], r4                    
    stxdw [r10-0x28], r4                    
    mov64 r0, 1                                     r0 = 1 as i32 as i64 as u64
    jeq r3, 0, lbb_16200                            if r3 == (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r0, 0                                     r0 = 0 as i32 as i64 as u64
lbb_16200:
    lsh64 r0, 3                                     r0 <<= 3   ///  r0 = r0.wrapping_shl(3)
    mov64 r7, r10                                   r7 = r10
    add64 r7, -40                                   r7 += -40   ///  r7 = r7.wrapping_add(-40 as i32 as i64 as u64)
    mov64 r4, r7                                    r4 = r7
    add64 r4, r0                                    r4 += r0   ///  r4 = r4.wrapping_add(r0)
    ldxdw r5, [r10-0x1b8]                   
    and64 r5, 63                                    r5 &= 63   ///  r5 = r5.and(63)
    mov64 r0, r6                                    r0 = r6
    lsh64 r0, r5                                    r0 <<= r5   ///  r0 = r0.wrapping_shl(r5 as u32)
    stxdw [r4+0x0], r0                      
    mov64 r0, 16                                    r0 = 16 as i32 as i64 as u64
    jeq r3, 0, lbb_16213                            if r3 == (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r0, 8                                     r0 = 8 as i32 as i64 as u64
lbb_16213:
    stxdw [r10-0x118], r8                   
    mov64 r4, 24                                    r4 = 24 as i32 as i64 as u64
    jeq r3, 0, lbb_16217                            if r3 == (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r4, 16                                    r4 = 16 as i32 as i64 as u64
lbb_16217:
    mov64 r9, r7                                    r9 = r7
    add64 r9, r4                                    r9 += r4   ///  r9 = r9.wrapping_add(r4)
    add64 r7, r0                                    r7 += r0   ///  r7 = r7.wrapping_add(r0)
    mov64 r0, r1                                    r0 = r1
    lsh64 r0, r5                                    r0 <<= r5   ///  r0 = r0.wrapping_shl(r5 as u32)
    stxdw [r7+0x0], r0                      
    ldxdw r4, [r10-0x108]                   
    lsh64 r4, r5                                    r4 <<= r5   ///  r4 = r4.wrapping_shl(r5 as u32)
    stxdw [r9+0x0], r4                      
    mov64 r4, 64                                    r4 = 64 as i32 as i64 as u64
    mov64 r8, r5                                    r8 = r5
    ldxdw r5, [r10-0x1b8]                   
    stxdw [r10-0x1d8], r8                   
    jgt r4, r5, lbb_16849                           if r4 > r5 { pc += 618 }
lbb_16231:
    ldxdw r4, [r10-0x128]                   
    add64 r4, -1                                    r4 += -1   ///  r4 = r4.wrapping_add(-1 as i32 as i64 as u64)
    stxdw [r10-0x128], r4                   
    add64 r2, 8                                     r2 += 8   ///  r2 = r2.wrapping_add(8 as i32 as i64 as u64)
    jeq r8, 0, lbb_16259                            if r8 == (0 as i32 as i64 as u64) { pc += 23 }
    ldxdw r5, [r10-0x1b8]                   
    mov64 r8, r5                                    r8 = r5
    neg64 r8                                        r8 = -r8   ///  r8 = (r8 as i64).wrapping_neg() as u64
    and64 r8, 63                                    r8 &= 63   ///  r8 = r8.and(63)
    rsh64 r6, r8                                    r6 >>= r8   ///  r6 = r6.wrapping_shr(r8 as u32)
    add64 r0, r6                                    r0 += r6   ///  r0 = r0.wrapping_add(r6)
    stxdw [r7+0x0], r0                      
    rsh64 r1, r8                                    r1 >>= r8   ///  r1 = r1.wrapping_shr(r8 as u32)
    ldxdw r4, [r9+0x0]                      
    add64 r4, r1                                    r4 += r1   ///  r4 = r4.wrapping_add(r1)
    stxdw [r9+0x0], r4                      
    jgt r5, 63, lbb_16259                           if r5 > (63 as i32 as i64 as u64) { pc += 11 }
    mov64 r1, 32                                    r1 = 32 as i32 as i64 as u64
    jeq r3, 0, lbb_16251                            if r3 == (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r1, 24                                    r1 = 24 as i32 as i64 as u64
lbb_16251:
    mov64 r3, r10                                   r3 = r10
    add64 r3, -40                                   r3 += -40   ///  r3 = r3.wrapping_add(-40 as i32 as i64 as u64)
    add64 r3, r1                                    r3 += r1   ///  r3 = r3.wrapping_add(r1)
    ldxdw r4, [r10-0x108]                   
    rsh64 r4, r8                                    r4 >>= r8   ///  r4 = r4.wrapping_shr(r8 as u32)
    ldxdw r1, [r3+0x0]                      
    add64 r1, r4                                    r1 += r4   ///  r1 = r1.wrapping_add(r4)
    stxdw [r3+0x0], r1                      
lbb_16259:
    ldxdw r1, [r10-0x128]                   
    rsh64 r1, 6                                     r1 >>= 6   ///  r1 = r1.wrapping_shr(6)
    stxdw [r10-0x128], r1                   
    ldxdw r1, [r10-0x10]                    
    stxdw [r10-0x98], r1                    
    ldxdw r1, [r10-0x18]                    
    stxdw [r10-0xa0], r1                    
    ldxdw r1, [r10-0x20]                    
    stxdw [r10-0xa8], r1                    
    ldxdw r1, [r10-0x28]                    
    stxdw [r10-0xb0], r1                    
    ldxdw r9, [r10-0x118]                   
    stxdw [r10-0x28], r9                    
    ldxdw r1, [r2+0x10]                     
    stxdw [r10-0x10], r1                    
    ldxdw r1, [r2+0x8]                      
    stxdw [r10-0x18], r1                    
    ldxdw r1, [r2+0x0]                      
    stxdw [r10-0x20], r1                    
    mov64 r1, 64                                    r1 = 64 as i32 as i64 as u64
    ldxdw r8, [r10-0x1b8]                   
    sub64 r1, r8                                    r1 -= r8   ///  r1 = r1.wrapping_sub(r8)
    mov64 r0, r1                                    r0 = r1
    rsh64 r0, 6                                     r0 >>= 6   ///  r0 = r0.wrapping_shr(6)
    lsh64 r0, 3                                     r0 <<= 3   ///  r0 = r0.wrapping_shl(3)
    mov64 r4, r10                                   r4 = r10
    add64 r4, -40                                   r4 += -40   ///  r4 = r4.wrapping_add(-40 as i32 as i64 as u64)
    add64 r4, r0                                    r4 += r0   ///  r4 = r4.wrapping_add(r0)
    and64 r1, 63                                    r1 &= 63   ///  r1 = r1.and(63)
    ldxdw r5, [r4+0x10]                     
    mov64 r3, r5                                    r3 = r5
    rsh64 r3, r1                                    r3 >>= r1   ///  r3 = r3.wrapping_shr(r1 as u32)
    ldxdw r2, [r4+0x0]                      
    rsh64 r2, r1                                    r2 >>= r1   ///  r2 = r2.wrapping_shr(r1 as u32)
    ldxdw r7, [r4+0x8]                      
    mov64 r6, r7                                    r6 = r7
    rsh64 r6, r1                                    r6 >>= r1   ///  r6 = r6.wrapping_shr(r1 as u32)
    jne r8, 0, lbb_16307                            if r8 != (0 as i32 as i64 as u64) { pc += 10 }
    mov64 r0, 0                                     r0 = 0 as i32 as i64 as u64
    ldxdw r4, [r10-0x1d8]                   
    jeq r1, 0, lbb_16324                            if r1 == (0 as i32 as i64 as u64) { pc += 24 }
    lsh64 r5, r4                                    r5 <<= r4   ///  r5 = r5.wrapping_shl(r4 as u32)
    add64 r5, r6                                    r5 += r6   ///  r5 = r5.wrapping_add(r6)
    lsh64 r7, r4                                    r7 <<= r4   ///  r7 = r7.wrapping_shl(r4 as u32)
    add64 r7, r2                                    r7 += r2   ///  r7 = r7.wrapping_add(r2)
    mov64 r2, r7                                    r2 = r7
    mov64 r6, r5                                    r6 = r5
    ja lbb_16324                                    if true { pc += 17 }
lbb_16307:
    mov64 r4, r10                                   r4 = r10
    add64 r4, -40                                   r4 += -40   ///  r4 = r4.wrapping_add(-40 as i32 as i64 as u64)
    add64 r0, r4                                    r0 += r4   ///  r0 = r0.wrapping_add(r4)
    ldxdw r8, [r0+0x18]                     
    mov64 r0, r8                                    r0 = r8
    rsh64 r0, r1                                    r0 >>= r1   ///  r0 = r0.wrapping_shr(r1 as u32)
    ldxdw r4, [r10-0x1d8]                   
    jeq r1, 0, lbb_16324                            if r1 == (0 as i32 as i64 as u64) { pc += 9 }
    lsh64 r8, r4                                    r8 <<= r4   ///  r8 = r8.wrapping_shl(r4 as u32)
    add64 r8, r3                                    r8 += r3   ///  r8 = r8.wrapping_add(r3)
    lsh64 r5, r4                                    r5 <<= r4   ///  r5 = r5.wrapping_shl(r4 as u32)
    add64 r5, r6                                    r5 += r6   ///  r5 = r5.wrapping_add(r6)
    lsh64 r7, r4                                    r7 <<= r4   ///  r7 = r7.wrapping_shl(r4 as u32)
    add64 r7, r2                                    r7 += r2   ///  r7 = r7.wrapping_add(r2)
    mov64 r2, r7                                    r2 = r7
    mov64 r6, r5                                    r6 = r5
    mov64 r3, r8                                    r3 = r8
lbb_16324:
    ldxdw r5, [r10-0x128]                   
    mov64 r8, r5                                    r8 = r5
    ldxdw r7, [r10-0x1a0]                   
    sub64 r8, r7                                    r8 -= r7   ///  r8 = r8.wrapping_sub(r7)
    mov64 r1, r7                                    r1 = r7
    add64 r1, 1                                     r1 += 1   ///  r1 = r1.wrapping_add(1 as i32 as i64 as u64)
    stxdw [r10-0x158], r1                   
    stxdw [r10-0x70], r0                    
    stxdw [r10-0x78], r3                    
    stxdw [r10-0x80], r6                    
    stxdw [r10-0x88], r2                    
    lsh64 r9, r4                                    r9 <<= r4   ///  r9 = r9.wrapping_shl(r4 as u32)
    stxdw [r10-0x90], r9                    
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    stxdw [r10-0x50], r1                    
    stxdw [r10-0x58], r1                    
    stxdw [r10-0x60], r1                    
    stxdw [r10-0x68], r1                    
    sub64 r5, r7                                    r5 -= r7   ///  r5 = r5.wrapping_sub(r7)
    lsh64 r5, 3                                     r5 <<= 3   ///  r5 = r5.wrapping_shl(3)
    mov64 r1, r10                                   r1 = r10
    add64 r1, -144                                  r1 += -144   ///  r1 = r1.wrapping_add(-144 as i32 as i64 as u64)
    add64 r5, r1                                    r5 += r1   ///  r5 = r5.wrapping_add(r1)
    mov64 r2, r7                                    r2 = r7
    lsh64 r2, 3                                     r2 <<= 3   ///  r2 = r2.wrapping_shl(3)
    mov64 r1, r10                                   r1 = r10
    add64 r1, -176                                  r1 += -176   ///  r1 = r1.wrapping_add(-176 as i32 as i64 as u64)
    add64 r2, r1                                    r2 += r1   ///  r2 = r2.wrapping_add(r1)
    ldxdw r1, [r10-0x110]                   
    ldxdw r6, [r1+0x0]                      
    mov64 r3, r6                                    r3 = r6
    rsh64 r3, 1                                     r3 >>= 1   ///  r3 = r3.wrapping_shr(1)
    mov64 r1, r6                                    r1 = r6
    or64 r1, r3                                     r1 |= r3   ///  r1 = r1.or(r3)
    mov64 r3, r1                                    r3 = r1
    rsh64 r3, 2                                     r3 >>= 2   ///  r3 = r3.wrapping_shr(2)
    or64 r1, r3                                     r1 |= r3   ///  r1 = r1.or(r3)
    mov64 r3, r1                                    r3 = r1
    rsh64 r3, 4                                     r3 >>= 4   ///  r3 = r3.wrapping_shr(4)
    or64 r1, r3                                     r1 |= r3   ///  r1 = r1.or(r3)
    mov64 r3, r1                                    r3 = r1
    rsh64 r3, 8                                     r3 >>= 8   ///  r3 = r3.wrapping_shr(8)
    or64 r1, r3                                     r1 |= r3   ///  r1 = r1.or(r3)
    mov64 r3, r1                                    r3 = r1
    rsh64 r3, 16                                    r3 >>= 16   ///  r3 = r3.wrapping_shr(16)
    or64 r1, r3                                     r1 |= r3   ///  r1 = r1.or(r3)
    mov64 r3, r1                                    r3 = r1
    rsh64 r3, 32                                    r3 >>= 32   ///  r3 = r3.wrapping_shr(32)
    or64 r1, r3                                     r1 |= r3   ///  r1 = r1.or(r3)
    xor64 r1, -1                                    r1 ^= -1   ///  r1 = r1.xor(-1)
    lddw r3, 0x5555555555555555                     r3 load str located at 6148914691236517205
    mov64 r4, r1                                    r4 = r1
    rsh64 r4, 1                                     r4 >>= 1   ///  r4 = r4.wrapping_shr(1)
    and64 r4, r3                                    r4 &= r3   ///  r4 = r4.and(r3)
    sub64 r1, r4                                    r1 -= r4   ///  r1 = r1.wrapping_sub(r4)
    lddw r3, 0x3333333333333333                     r3 load str located at 3689348814741910323
    mov64 r4, r1                                    r4 = r1
    and64 r4, r3                                    r4 &= r3   ///  r4 = r4.and(r3)
    rsh64 r1, 2                                     r1 >>= 2   ///  r1 = r1.wrapping_shr(2)
    and64 r1, r3                                    r1 &= r3   ///  r1 = r1.and(r3)
    add64 r4, r1                                    r4 += r1   ///  r4 = r4.wrapping_add(r1)
    mov64 r1, r4                                    r1 = r4
    rsh64 r1, 4                                     r1 >>= 4   ///  r1 = r1.wrapping_shr(4)
    add64 r4, r1                                    r4 += r1   ///  r4 = r4.wrapping_add(r1)
    lddw r1, 0xf0f0f0f0f0f0f0f                      r1 load str located at 1085102592571150095
    and64 r4, r1                                    r4 &= r1   ///  r4 = r4.and(r1)
    lddw r1, 0x101010101010101                      r1 load str located at 72340172838076673
    mul64 r4, r1                                    r4 *= r1   ///  r4 = r4.wrapping_mul(r1)
    mov64 r1, r10                                   r1 = r10
    add64 r1, -168                                  r1 += -168   ///  r1 = r1.wrapping_add(-168 as i32 as i64 as u64)
    stxdw [r10-0x1c8], r1                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -24                                   r1 += -24   ///  r1 = r1.wrapping_add(-24 as i32 as i64 as u64)
    stxdw [r10-0x1c0], r1                   
    ldxdw r1, [r10-0x98]                    
    stxdw [r10-0x178], r1                   
    ldxdw r1, [r10-0xa0]                    
    stxdw [r10-0x180], r1                   
    ldxdw r1, [r10-0xa8]                    
    stxdw [r10-0x188], r1                   
    ldxdw r1, [r10-0xb0]                    
    stxdw [r10-0x170], r1                   
    add64 r7, 2                                     r7 += 2   ///  r7 = r7.wrapping_add(2 as i32 as i64 as u64)
    stxdw [r10-0x190], r7                   
    ldxdw r1, [r2-0x8]                      
    stxdw [r10-0x118], r1                   
    mov64 r1, r5                                    r1 = r5
    add64 r1, 8                                     r1 += 8   ///  r1 = r1.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r10-0x130], r1                   
    add64 r5, 16                                    r5 += 16   ///  r5 = r5.wrapping_add(16 as i32 as i64 as u64)
    rsh64 r4, 56                                    r4 >>= 56   ///  r4 = r4.wrapping_shr(56)
    mov64 r1, r6                                    r1 = r6
    lsh64 r1, r4                                    r1 <<= r4   ///  r1 = r1.wrapping_shl(r4 as u32)
    stxdw [r10-0x1a8], r4                   
    neg64 r4                                        r4 = -r4   ///  r4 = (r4 as i64).wrapping_neg() as u64
    and64 r4, 63                                    r4 &= 63   ///  r4 = r4.and(63)
    stxdw [r10-0x1b0], r4                   
    mov64 r2, r1                                    r2 = r1
    rsh64 r2, 32                                    r2 >>= 32   ///  r2 = r2.wrapping_shr(32)
    stxdw [r10-0x108], r2                   
    stxdw [r10-0x148], r1                   
    lsh64 r1, 32                                    r1 <<= 32   ///  r1 = r1.wrapping_shl(32)
    rsh64 r1, 32                                    r1 >>= 32   ///  r1 = r1.wrapping_shr(32)
    stxdw [r10-0x110], r1                   
    stxdw [r10-0x138], r8                   
    mov64 r1, r8                                    r1 = r8
    stxdw [r10-0x150], r6                   
    ja lbb_16480                                    if true { pc += 44 }
lbb_16436:
    stxdw [r9+0x0], r6                      
    or64 r5, r3                                     r5 |= r3   ///  r5 = r5.or(r3)
    add64 r8, 8                                     r8 += 8   ///  r8 = r8.wrapping_add(8 as i32 as i64 as u64)
    add64 r9, 8                                     r9 += 8   ///  r9 = r9.wrapping_add(8 as i32 as i64 as u64)
    add64 r0, 1                                     r0 += 1   ///  r0 = r0.wrapping_add(1 as i32 as i64 as u64)
    jgt r4, r0, lbb_16451                           if r4 > r0 { pc += 9 }
lbb_16442:
    and64 r5, 1                                     r5 &= 1   ///  r5 = r5.and(1)
    ldxdw r6, [r10-0x150]                   
    ldxdw r3, [r10-0x140]                   
    ldxdw r2, [r10-0x168]                   
    jne r5, 0, lbb_16735                            if r5 != (0 as i32 as i64 as u64) { pc += 288 }
lbb_16447:
    ldxdw r1, [r10-0x138]                   
    mov64 r2, 4                                     r2 = 4 as i32 as i64 as u64
    jgt r2, r1, lbb_16465                           if r2 > r1 { pc += 15 }
    ja lbb_16860                                    if true { pc += 409 }
lbb_16451:
    and64 r5, 1                                     r5 &= 1   ///  r5 = r5.and(1)
    ldxdw r6, [r8+0x0]                      
    mov64 r1, r6                                    r1 = r6
    add64 r1, r5                                    r1 += r5   ///  r1 = r1.wrapping_add(r5)
    mov64 r3, 1                                     r3 = 1 as i32 as i64 as u64
    mov64 r5, 1                                     r5 = 1 as i32 as i64 as u64
    jgt r6, r1, lbb_16459                           if r6 > r1 { pc += 1 }
    mov64 r5, 0                                     r5 = 0 as i32 as i64 as u64
lbb_16459:
    ldxdw r2, [r9+0x0]                      
    mov64 r6, r2                                    r6 = r2
    sub64 r6, r1                                    r6 -= r1   ///  r6 = r6.wrapping_sub(r1)
    jgt r6, r2, lbb_16436                           if r6 > r2 { pc += -27 }
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
    ja lbb_16436                                    if true { pc += -29 }
lbb_16465:
    ldxdw r4, [r10-0x120]                   
    mov64 r1, r4                                    r1 = r4
    add64 r1, -1                                    r1 += -1   ///  r1 = r1.wrapping_add(-1 as i32 as i64 as u64)
    mov64 r2, r4                                    r2 = r4
    lsh64 r2, 3                                     r2 <<= 3   ///  r2 = r2.wrapping_shl(3)
    mov64 r3, r10                                   r3 = r10
    add64 r3, -104                                  r3 += -104   ///  r3 = r3.wrapping_add(-104 as i32 as i64 as u64)
    add64 r3, r2                                    r3 += r2   ///  r3 = r3.wrapping_add(r2)
    stxdw [r3+0x0], r7                      
    ldxdw r2, [r10-0x130]                   
    add64 r2, -8                                    r2 += -8   ///  r2 = r2.wrapping_add(-8 as i32 as i64 as u64)
    stxdw [r10-0x130], r2                   
    ldxdw r5, [r10-0x128]                   
    add64 r5, -8                                    r5 += -8   ///  r5 = r5.wrapping_add(-8 as i32 as i64 as u64)
    jeq r4, 0, lbb_16782                            if r4 == (0 as i32 as i64 as u64) { pc += 302 }
lbb_16480:
    stxdw [r10-0x120], r1                   
    ldxdw r2, [r10-0x158]                   
    add64 r1, r2                                    r1 += r2   ///  r1 = r1.wrapping_add(r2)
    mov64 r2, 5                                     r2 = 5 as i32 as i64 as u64
    jgt r2, r1, lbb_16486                           if r2 > r1 { pc += 1 }
    ja lbb_16871                                    if true { pc += 385 }
lbb_16486:
    stxdw [r10-0x128], r5                   
    mov64 r2, r1                                    r2 = r1
    lsh64 r2, 3                                     r2 <<= 3   ///  r2 = r2.wrapping_shl(3)
    mov64 r3, r10                                   r3 = r10
    add64 r3, -144                                  r3 += -144   ///  r3 = r3.wrapping_add(-144 as i32 as i64 as u64)
    add64 r3, r2                                    r3 += r2   ///  r3 = r3.wrapping_add(r2)
    mov64 r7, -1                                    r7 = -1 as i32 as i64 as u64
    stxdw [r10-0x160], r3                   
    ldxdw r3, [r3+0x0]                      
    jgt r6, r3, lbb_16497                           if r6 > r3 { pc += 1 }
    ja lbb_16596                                    if true { pc += 99 }
lbb_16497:
    ldxdw r2, [r10-0x120]                   
    ldxdw r4, [r10-0x1a0]                   
    add64 r2, r4                                    r2 += r4   ///  r2 = r2.wrapping_add(r4)
    jgt r2, 4, lbb_16870                            if r2 > (4 as i32 as i64 as u64) { pc += 369 }
    lsh64 r2, 3                                     r2 <<= 3   ///  r2 = r2.wrapping_shl(3)
    mov64 r4, r10                                   r4 = r10
    add64 r4, -144                                  r4 += -144   ///  r4 = r4.wrapping_add(-144 as i32 as i64 as u64)
    add64 r4, r2                                    r4 += r2   ///  r4 = r4.wrapping_add(r2)
    ldxdw r2, [r4+0x0]                      
    mov64 r9, 0                                     r9 = 0 as i32 as i64 as u64
    ldxdw r8, [r10-0x1a8]                   
    jeq r8, 0, lbb_16512                            if r8 == (0 as i32 as i64 as u64) { pc += 3 }
    mov64 r9, r2                                    r9 = r2
    ldxdw r4, [r10-0x1b0]                   
    rsh64 r9, r4                                    r9 >>= r4   ///  r9 = r9.wrapping_shr(r4 as u32)
lbb_16512:
    ldxdw r4, [r10-0x148]                   
    lddw r5, 0x100000000                            r5 load str located at 4294967296
    jgt r5, r4, lbb_16863                           if r5 > r4 { pc += 347 }
    lsh64 r3, r8                                    r3 <<= r8   ///  r3 = r3.wrapping_shl(r8 as u32)
    or64 r9, r3                                     r9 |= r3   ///  r9 = r9.or(r3)
    lsh64 r2, r8                                    r2 <<= r8   ///  r2 = r2.wrapping_shl(r8 as u32)
    mov64 r4, r2                                    r4 = r2
    rsh64 r4, 32                                    r4 >>= 32   ///  r4 = r4.wrapping_shr(32)
    lsh64 r2, 32                                    r2 <<= 32   ///  r2 = r2.wrapping_shl(32)
    rsh64 r2, 32                                    r2 >>= 32   ///  r2 = r2.wrapping_shr(32)
    mov64 r3, r9                                    r3 = r9
    ldxdw r5, [r10-0x108]                   
    div64 r3, r5                                    r3 /= r5   ///  r3 = r3 / r5
    mov64 r0, r3                                    r0 = r3
    mul64 r0, r5                                    r0 *= r5   ///  r0 = r0.wrapping_mul(r5)
    mov64 r5, r9                                    r5 = r9
    sub64 r5, r0                                    r5 -= r0   ///  r5 = r5.wrapping_sub(r0)
lbb_16530:
    lddw r0, 0xffffffff                             r0 load str located at 4294967295
    jgt r3, r0, lbb_16540                           if r3 > r0 { pc += 7 }
    mov64 r0, r5                                    r0 = r5
    lsh64 r0, 32                                    r0 <<= 32   ///  r0 = r0.wrapping_shl(32)
    or64 r0, r4                                     r0 |= r4   ///  r0 = r0.or(r4)
    mov64 r6, r3                                    r6 = r3
    ldxdw r7, [r10-0x110]                   
    mul64 r6, r7                                    r6 *= r7   ///  r6 = r6.wrapping_mul(r7)
    jge r0, r6, lbb_16546                           if r0 >= r6 { pc += 6 }
lbb_16540:
    ldxdw r0, [r10-0x108]                   
    add64 r5, r0                                    r5 += r0   ///  r5 = r5.wrapping_add(r0)
    add64 r3, -1                                    r3 += -1   ///  r3 = r3.wrapping_add(-1 as i32 as i64 as u64)
    lddw r0, 0x100000000                            r0 load str located at 4294967296
    jgt r0, r5, lbb_16530                           if r0 > r5 { pc += -16 }
lbb_16546:
    mov64 r5, r3                                    r5 = r3
    ldxdw r0, [r10-0x148]                   
    mul64 r5, r0                                    r5 *= r0   ///  r5 = r5.wrapping_mul(r0)
    lsh64 r9, 32                                    r9 <<= 32   ///  r9 = r9.wrapping_shl(32)
    or64 r9, r4                                     r9 |= r4   ///  r9 = r9.or(r4)
    sub64 r9, r5                                    r9 -= r5   ///  r9 = r9.wrapping_sub(r5)
    mov64 r7, r9                                    r7 = r9
    ldxdw r4, [r10-0x108]                   
    div64 r7, r4                                    r7 /= r4   ///  r7 = r7 / r4
    mov64 r5, r7                                    r5 = r7
    mul64 r5, r4                                    r5 *= r4   ///  r5 = r5.wrapping_mul(r4)
    mov64 r4, r9                                    r4 = r9
    sub64 r4, r5                                    r4 -= r5   ///  r4 = r4.wrapping_sub(r5)
lbb_16559:
    lddw r5, 0xffffffff                             r5 load str located at 4294967295
    jgt r7, r5, lbb_16569                           if r7 > r5 { pc += 7 }
    mov64 r5, r4                                    r5 = r4
    lsh64 r5, 32                                    r5 <<= 32   ///  r5 = r5.wrapping_shl(32)
    or64 r5, r2                                     r5 |= r2   ///  r5 = r5.or(r2)
    mov64 r0, r7                                    r0 = r7
    ldxdw r6, [r10-0x110]                   
    mul64 r0, r6                                    r0 *= r6   ///  r0 = r0.wrapping_mul(r6)
    jge r5, r0, lbb_16575                           if r5 >= r0 { pc += 6 }
lbb_16569:
    ldxdw r5, [r10-0x108]                   
    add64 r4, r5                                    r4 += r5   ///  r4 = r4.wrapping_add(r5)
    add64 r7, -1                                    r7 += -1   ///  r7 = r7.wrapping_add(-1 as i32 as i64 as u64)
    lddw r5, 0x100000000                            r5 load str located at 4294967296
    jgt r5, r4, lbb_16559                           if r5 > r4 { pc += -16 }
lbb_16575:
    add64 r1, -2                                    r1 += -2   ///  r1 = r1.wrapping_add(-2 as i32 as i64 as u64)
    ldxdw r6, [r10-0x150]                   
    jgt r1, 4, lbb_16871                            if r1 > (4 as i32 as i64 as u64) { pc += 293 }
    lsh64 r9, 32                                    r9 <<= 32   ///  r9 = r9.wrapping_shl(32)
    or64 r9, r2                                     r9 |= r2   ///  r9 = r9.or(r2)
    mov64 r2, r7                                    r2 = r7
    ldxdw r4, [r10-0x148]                   
    mul64 r2, r4                                    r2 *= r4   ///  r2 = r2.wrapping_mul(r4)
    sub64 r9, r2                                    r9 -= r2   ///  r9 = r9.wrapping_sub(r2)
    rsh64 r9, r8                                    r9 >>= r8   ///  r9 = r9.wrapping_shr(r8 as u32)
    lsh64 r3, 32                                    r3 <<= 32   ///  r3 = r3.wrapping_shl(32)
    add64 r7, r3                                    r7 += r3   ///  r7 = r7.wrapping_add(r3)
    lsh64 r1, 3                                     r1 <<= 3   ///  r1 = r1.wrapping_shl(3)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -144                                  r2 += -144   ///  r2 = r2.wrapping_add(-144 as i32 as i64 as u64)
    add64 r2, r1                                    r2 += r1   ///  r2 = r2.wrapping_add(r1)
    ldxdw r8, [r2+0x0]                      
    ja lbb_16633                                    if true { pc += 40 }
lbb_16593:
    add64 r7, -1                                    r7 += -1   ///  r7 = r7.wrapping_add(-1 as i32 as i64 as u64)
    mov64 r9, r1                                    r9 = r1
    jne r2, 1, lbb_16633                            if r2 != (1 as i32 as i64 as u64) { pc += 37 }
lbb_16596:
    mov64 r1, r10                                   r1 = r10
    add64 r1, -208                                  r1 += -208   ///  r1 = r1.wrapping_add(-208 as i32 as i64 as u64)
    ldxdw r2, [r10-0x170]                   
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
    mov64 r4, r7                                    r4 = r7
    mov64 r5, 0                                     r5 = 0 as i32 as i64 as u64
    call function_21911                     
    mov64 r1, r10                                   r1 = r10
    add64 r1, -224                                  r1 += -224   ///  r1 = r1.wrapping_add(-224 as i32 as i64 as u64)
    ldxdw r2, [r10-0x188]                   
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
    mov64 r4, r7                                    r4 = r7
    mov64 r5, 0                                     r5 = 0 as i32 as i64 as u64
    call function_21911                     
    mov64 r1, r10                                   r1 = r10
    add64 r1, -240                                  r1 += -240   ///  r1 = r1.wrapping_add(-240 as i32 as i64 as u64)
    ldxdw r2, [r10-0x180]                   
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
    mov64 r4, r7                                    r4 = r7
    mov64 r5, 0                                     r5 = 0 as i32 as i64 as u64
    call function_21911                     
    mov64 r1, r10                                   r1 = r10
    add64 r1, -256                                  r1 += -256   ///  r1 = r1.wrapping_add(-256 as i32 as i64 as u64)
    ldxdw r2, [r10-0x178]                   
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
    mov64 r4, r7                                    r4 = r7
    mov64 r5, 0                                     r5 = 0 as i32 as i64 as u64
    call function_21911                     
    ldxdw r1, [r10-0xc8]                    
    ldxdw r3, [r10-0xe0]                    
    mov64 r0, r3                                    r0 = r3
    add64 r0, r1                                    r0 += r1   ///  r0 = r0.wrapping_add(r1)
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    mov64 r2, 1                                     r2 = 1 as i32 as i64 as u64
    jgt r3, r0, lbb_16658                           if r3 > r0 { pc += 27 }
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
    ja lbb_16658                                    if true { pc += 25 }
lbb_16633:
    mov64 r1, r10                                   r1 = r10
    add64 r1, -192                                  r1 += -192   ///  r1 = r1.wrapping_add(-192 as i32 as i64 as u64)
    mov64 r2, r7                                    r2 = r7
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
    ldxdw r4, [r10-0x118]                   
    mov64 r5, 0                                     r5 = 0 as i32 as i64 as u64
    call function_21911                     
    mov64 r2, 1                                     r2 = 1 as i32 as i64 as u64
    ldxdw r3, [r10-0xc0]                    
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    jge r8, r3, lbb_16645                           if r8 >= r3 { pc += 1 }
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
lbb_16645:
    ldxdw r3, [r10-0xb8]                    
    jge r9, r3, lbb_16648                           if r9 >= r3 { pc += 1 }
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
lbb_16648:
    jeq r9, r3, lbb_16650                           if r9 == r3 { pc += 1 }
    mov64 r1, r2                                    r1 = r2
lbb_16650:
    and64 r1, 1                                     r1 &= 1   ///  r1 = r1.and(1)
    jne r1, 0, lbb_16596                            if r1 != (0 as i32 as i64 as u64) { pc += -56 }
    mov64 r1, r9                                    r1 = r9
    add64 r1, r6                                    r1 += r6   ///  r1 = r1.wrapping_add(r6)
    mov64 r2, 1                                     r2 = 1 as i32 as i64 as u64
    jgt r9, r1, lbb_16593                           if r9 > r1 { pc += -63 }
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
    ja lbb_16593                                    if true { pc += -65 }
lbb_16658:
    ldxdw r4, [r10-0xd8]                    
    add64 r4, r2                                    r4 += r2   ///  r4 = r4.wrapping_add(r2)
    ldxdw r3, [r10-0xf0]                    
    mov64 r2, r4                                    r2 = r4
    add64 r2, r3                                    r2 += r3   ///  r2 = r2.wrapping_add(r3)
    mov64 r3, 1                                     r3 = 1 as i32 as i64 as u64
    jgt r4, r2, lbb_16666                           if r4 > r2 { pc += 1 }
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
lbb_16666:
    ldxdw r4, [r10-0xe8]                    
    add64 r4, r3                                    r4 += r3   ///  r4 = r4.wrapping_add(r3)
    ldxdw r5, [r10-0x100]                   
    mov64 r3, r4                                    r3 = r4
    add64 r3, r5                                    r3 += r5   ///  r3 = r3.wrapping_add(r5)
    jgt r4, r3, lbb_16673                           if r4 > r3 { pc += 1 }
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
lbb_16673:
    ldxdw r4, [r10-0xf8]                    
    add64 r4, r1                                    r4 += r1   ///  r4 = r4.wrapping_add(r1)
    stxdw [r10-0x18], r2                    
    stxdw [r10-0x10], r3                    
    stxdw [r10-0x8], r4                     
    ldxdw r5, [r10-0xd0]                    
    stxdw [r10-0x28], r5                    
    stxdw [r10-0x20], r0                    
    ldxdw r1, [r10-0x138]                   
    mov64 r2, 6                                     r2 = 6 as i32 as i64 as u64
    jgt r2, r1, lbb_16690                           if r2 > r1 { pc += 6 }
    ldxdw r1, [r10-0x120]                   
    mov64 r2, 5                                     r2 = 5 as i32 as i64 as u64
    lddw r3, 0x10002df50 --> b"\x00\x00\x00\x00\xb8\xcb\x02\x00\x0b\x00\x00\x00\x00\x00\x00\x00\x0a\x00\…        r3 load str located at 4295155536
    call function_20695                     
    syscall [invalid]                       
lbb_16690:
    mov64 r2, r10                                   r2 = r10
    add64 r2, -144                                  r2 += -144   ///  r2 = r2.wrapping_add(-144 as i32 as i64 as u64)
    mov64 r3, 5                                     r3 = 5 as i32 as i64 as u64
    ldxdw r1, [r10-0x120]                   
    sub64 r3, r1                                    r3 -= r1   ///  r3 = r3.wrapping_sub(r1)
    ldxdw r1, [r10-0x190]                   
    mov64 r4, r1                                    r4 = r1
    jgt r3, r1, lbb_16699                           if r3 > r1 { pc += 1 }
    mov64 r4, r3                                    r4 = r3
lbb_16699:
    jeq r4, 0, lbb_16447                            if r4 == (0 as i32 as i64 as u64) { pc += -253 }
    stxdw [r10-0x168], r3                   
    ldxdw r1, [r10-0x120]                   
    lsh64 r1, 3                                     r1 <<= 3   ///  r1 = r1.wrapping_shl(3)
    add64 r2, r1                                    r2 += r1   ///  r2 = r2.wrapping_add(r1)
    ldxdw r1, [r2+0x0]                      
    mov64 r3, r1                                    r3 = r1
    sub64 r3, r5                                    r3 -= r5   ///  r3 = r3.wrapping_sub(r5)
    mov64 r5, 1                                     r5 = 1 as i32 as i64 as u64
    jgt r3, r1, lbb_16710                           if r3 > r1 { pc += 1 }
    mov64 r5, 0                                     r5 = 0 as i32 as i64 as u64
lbb_16710:
    stxdw [r10-0x140], r2                   
    stxdw [r10-0x198], r3                   
    stxdw [r2+0x0], r3                      
    jeq r4, 1, lbb_16442                            if r4 == (1 as i32 as i64 as u64) { pc += -272 }
    and64 r5, 1                                     r5 &= 1   ///  r5 = r5.and(1)
    mov64 r3, r0                                    r3 = r0
    add64 r3, r5                                    r3 += r5   ///  r3 = r3.wrapping_add(r5)
    mov64 r8, 1                                     r8 = 1 as i32 as i64 as u64
    mov64 r5, 1                                     r5 = 1 as i32 as i64 as u64
    jgt r0, r3, lbb_16721                           if r0 > r3 { pc += 1 }
    mov64 r5, 0                                     r5 = 0 as i32 as i64 as u64
lbb_16721:
    ldxdw r2, [r10-0x140]                   
    ldxdw r0, [r2+0x8]                      
    mov64 r1, r0                                    r1 = r0
    sub64 r1, r3                                    r1 -= r3   ///  r1 = r1.wrapping_sub(r3)
    jgt r1, r0, lbb_16727                           if r1 > r0 { pc += 1 }
    mov64 r8, 0                                     r8 = 0 as i32 as i64 as u64
lbb_16727:
    stxdw [r2+0x8], r1                      
    or64 r5, r8                                     r5 |= r8   ///  r5 = r5.or(r8)
    mov64 r1, 3                                     r1 = 3 as i32 as i64 as u64
    jgt r1, r4, lbb_16442                           if r1 > r4 { pc += -289 }
    mov64 r0, 2                                     r0 = 2 as i32 as i64 as u64
    ldxdw r8, [r10-0x1c0]                   
    ldxdw r9, [r10-0x128]                   
    ja lbb_16451                                    if true { pc += -284 }
lbb_16735:
    ldxdw r1, [r10-0x158]                   
    mov64 r4, r1                                    r4 = r1
    jgt r2, r1, lbb_16739                           if r2 > r1 { pc += 1 }
    mov64 r4, r2                                    r4 = r2
lbb_16739:
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
    jeq r4, 0, lbb_16760                            if r4 == (0 as i32 as i64 as u64) { pc += 19 }
    ldxdw r5, [r10-0x198]                   
    mov64 r1, r5                                    r1 = r5
    ldxdw r2, [r10-0x170]                   
    add64 r1, r2                                    r1 += r2   ///  r1 = r1.wrapping_add(r2)
    mov64 r2, 1                                     r2 = 1 as i32 as i64 as u64
    jgt r5, r1, lbb_16748                           if r5 > r1 { pc += 1 }
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
lbb_16748:
    stxdw [r3+0x0], r1                      
    jeq r4, 1, lbb_16760                            if r4 == (1 as i32 as i64 as u64) { pc += 10 }
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    ldxdw r3, [r10-0x1c8]                   
    ldxdw r5, [r10-0x130]                   
    ja lbb_16768                                    if true { pc += 14 }
lbb_16754:
    stxdw [r5+0x0], r6                      
    or64 r2, r0                                     r2 |= r0   ///  r2 = r2.or(r0)
    add64 r3, 8                                     r3 += 8   ///  r3 = r3.wrapping_add(8 as i32 as i64 as u64)
    add64 r5, 8                                     r5 += 8   ///  r5 = r5.wrapping_add(8 as i32 as i64 as u64)
    add64 r1, 1                                     r1 += 1   ///  r1 = r1.wrapping_add(1 as i32 as i64 as u64)
    jgt r4, r1, lbb_16768                           if r4 > r1 { pc += 8 }
lbb_16760:
    add64 r7, -1                                    r7 += -1   ///  r7 = r7.wrapping_add(-1 as i32 as i64 as u64)
    and64 r2, 1                                     r2 &= 1   ///  r2 = r2.and(1)
    ldxdw r3, [r10-0x160]                   
    ldxdw r1, [r3+0x0]                      
    add64 r1, r2                                    r1 += r2   ///  r1 = r1.wrapping_add(r2)
    stxdw [r3+0x0], r1                      
    ldxdw r6, [r10-0x150]                   
    ja lbb_16447                                    if true { pc += -321 }
lbb_16768:
    and64 r2, 1                                     r2 &= 1   ///  r2 = r2.and(1)
    ldxdw r6, [r3+0x0]                      
    mov64 r0, r6                                    r0 = r6
    add64 r0, r2                                    r0 += r2   ///  r0 = r0.wrapping_add(r2)
    mov64 r2, 1                                     r2 = 1 as i32 as i64 as u64
    jgt r6, r0, lbb_16775                           if r6 > r0 { pc += 1 }
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
lbb_16775:
    ldxdw r8, [r5+0x0]                      
    mov64 r6, r8                                    r6 = r8
    add64 r6, r0                                    r6 += r0   ///  r6 = r6.wrapping_add(r0)
    mov64 r0, 1                                     r0 = 1 as i32 as i64 as u64
    jgt r8, r6, lbb_16754                           if r8 > r6 { pc += -26 }
    mov64 r0, 0                                     r0 = 0 as i32 as i64 as u64
    ja lbb_16754                                    if true { pc += -28 }
lbb_16782:
    mov64 r1, r10                                   r1 = r10
    add64 r1, -40                                   r1 += -40   ///  r1 = r1.wrapping_add(-40 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -144                                  r2 += -144   ///  r2 = r2.wrapping_add(-144 as i32 as i64 as u64)
    mov64 r3, 40                                    r3 = 40 as i32 as i64 as u64
    call function_21797                     
    ldxdw r1, [r10-0x28]                    
    ldxdw r2, [r10-0x1d8]                   
    rsh64 r1, r2                                    r1 >>= r2   ///  r1 = r1.wrapping_shr(r2 as u32)
    stxdw [r10-0x48], r1                    
    ldxdw r1, [r10-0x20]                    
    rsh64 r1, r2                                    r1 >>= r2   ///  r1 = r1.wrapping_shr(r2 as u32)
    stxdw [r10-0x40], r1                    
    ldxdw r1, [r10-0x18]                    
    rsh64 r1, r2                                    r1 >>= r2   ///  r1 = r1.wrapping_shr(r2 as u32)
    stxdw [r10-0x38], r1                    
    ldxdw r1, [r10-0x10]                    
    rsh64 r1, r2                                    r1 >>= r2   ///  r1 = r1.wrapping_shr(r2 as u32)
    stxdw [r10-0x30], r1                    
    ldxdw r6, [r10-0x1b8]                   
    jeq r6, 0, lbb_16831                            if r6 == (0 as i32 as i64 as u64) { pc += 28 }
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    neg64 r6                                        r6 = -r6   ///  r6 = (r6 as i64).wrapping_neg() as u64
    and64 r6, 63                                    r6 &= 63   ///  r6 = r6.and(63)
    mov64 r2, 4                                     r2 = 4 as i32 as i64 as u64
lbb_16807:
    mov64 r3, r1                                    r3 = r1
    mov64 r4, 3                                     r4 = 3 as i32 as i64 as u64
    mov64 r1, 4                                     r1 = 4 as i32 as i64 as u64
    jgt r3, 3, lbb_16816                            if r3 > (3 as i32 as i64 as u64) { pc += 5 }
    mov64 r1, r3                                    r1 = r3
    add64 r1, 1                                     r1 += 1   ///  r1 = r1.wrapping_add(1 as i32 as i64 as u64)
    mov64 r4, r3                                    r4 = r3
    add64 r4, -1                                    r4 += -1   ///  r4 = r4.wrapping_add(-1 as i32 as i64 as u64)
    jgt r4, 3, lbb_16876                            if r4 > (3 as i32 as i64 as u64) { pc += 60 }
lbb_16816:
    mov64 r5, r3                                    r5 = r3
    lsh64 r5, 3                                     r5 <<= 3   ///  r5 = r5.wrapping_shl(3)
    mov64 r0, r10                                   r0 = r10
    add64 r0, -40                                   r0 += -40   ///  r0 = r0.wrapping_add(-40 as i32 as i64 as u64)
    add64 r0, r5                                    r0 += r5   ///  r0 = r0.wrapping_add(r5)
    ldxdw r5, [r0+0x0]                      
    lsh64 r5, r6                                    r5 <<= r6   ///  r5 = r5.wrapping_shl(r6 as u32)
    lsh64 r4, 3                                     r4 <<= 3   ///  r4 = r4.wrapping_shl(3)
    mov64 r0, r10                                   r0 = r10
    add64 r0, -72                                   r0 += -72   ///  r0 = r0.wrapping_add(-72 as i32 as i64 as u64)
    add64 r0, r4                                    r0 += r4   ///  r0 = r0.wrapping_add(r4)
    ldxdw r4, [r0+0x0]                      
    or64 r4, r5                                     r4 |= r5   ///  r4 = r4.or(r5)
    stxdw [r0+0x0], r4                      
    jgt r2, r3, lbb_16807                           if r2 > r3 { pc += -24 }
lbb_16831:
    ldxdw r1, [r10-0x50]                    
    ldxdw r2, [r10-0x1d0]                   
    stxdw [r2+0x18], r1                     
    ldxdw r1, [r10-0x58]                    
    stxdw [r2+0x10], r1                     
    ldxdw r1, [r10-0x60]                    
    stxdw [r2+0x8], r1                      
    ldxdw r1, [r10-0x68]                    
    stxdw [r2+0x0], r1                      
    ldxdw r1, [r10-0x48]                    
    stxdw [r2+0x20], r1                     
    ldxdw r1, [r10-0x40]                    
    stxdw [r2+0x28], r1                     
    ldxdw r1, [r10-0x38]                    
    stxdw [r2+0x30], r1                     
    ldxdw r1, [r10-0x30]                    
    stxdw [r2+0x38], r1                     
lbb_16848:
    exit                                    
lbb_16849:
    mov64 r4, 32                                    r4 = 32 as i32 as i64 as u64
    jeq r3, 0, lbb_16852                            if r3 == (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r4, 24                                    r4 = 24 as i32 as i64 as u64
lbb_16852:
    mov64 r5, r10                                   r5 = r10
    add64 r5, -40                                   r5 += -40   ///  r5 = r5.wrapping_add(-40 as i32 as i64 as u64)
    add64 r5, r4                                    r5 += r4   ///  r5 = r5.wrapping_add(r4)
    ldxdw r8, [r10-0x1d8]                   
    ldxdw r4, [r10-0x120]                   
    lsh64 r4, r8                                    r4 <<= r8   ///  r4 = r4.wrapping_shl(r8 as u32)
    stxdw [r5+0x0], r4                      
    ja lbb_16231                                    if true { pc += -629 }
lbb_16860:
    ldxdw r1, [r10-0x120]                   
lbb_16861:
    mov64 r2, 4                                     r2 = 4 as i32 as i64 as u64
    ja lbb_16872                                    if true { pc += 9 }
lbb_16863:
    lddw r1, 0x10002cbd0 --> b"attempt to divide by zero"        r1 load str located at 4295150544
    mov64 r2, 25                                    r2 = 25 as i32 as i64 as u64
    lddw r3, 0x10002df50 --> b"\x00\x00\x00\x00\xb8\xcb\x02\x00\x0b\x00\x00\x00\x00\x00\x00\x00\x0a\x00\…        r3 load str located at 4295155536
    call function_19306                     
    syscall [invalid]                       
lbb_16870:
    mov64 r1, -1                                    r1 = -1 as i32 as i64 as u64
lbb_16871:
    mov64 r2, 5                                     r2 = 5 as i32 as i64 as u64
lbb_16872:
    lddw r3, 0x10002df50 --> b"\x00\x00\x00\x00\xb8\xcb\x02\x00\x0b\x00\x00\x00\x00\x00\x00\x00\x0a\x00\…        r3 load str located at 4295155536
    call function_19324                     
    syscall [invalid]                       
lbb_16876:
    mov64 r1, -1                                    r1 = -1 as i32 as i64 as u64
    ja lbb_16861                                    if true { pc += -17 }
lbb_16878:
    lddw r1, 0x10002df50 --> b"\x00\x00\x00\x00\xb8\xcb\x02\x00\x0b\x00\x00\x00\x00\x00\x00\x00\x0a\x00\…        r1 load str located at 4295155536
    call function_13245                     
    syscall [invalid]                       

function_16882:
    stxdw [r10-0x8], r1                     
    ldxdw r1, [r3+0x8]                      
    ldxdw r5, [r2+0x8]                      
    mov64 r4, r5                                    r4 = r5
    add64 r4, r1                                    r4 += r1   ///  r4 = r4.wrapping_add(r1)
    mov64 r8, 1                                     r8 = 1 as i32 as i64 as u64
    mov64 r7, 1                                     r7 = 1 as i32 as i64 as u64
    jgt r5, r4, lbb_16891                           if r5 > r4 { pc += 1 }
    mov64 r7, 0                                     r7 = 0 as i32 as i64 as u64
lbb_16891:
    ldxdw r1, [r3+0x0]                      
    ldxdw r5, [r2+0x0]                      
    mov64 r0, r5                                    r0 = r5
    add64 r0, r1                                    r0 += r1   ///  r0 = r0.wrapping_add(r1)
    mov64 r9, 1                                     r9 = 1 as i32 as i64 as u64
    stxdw [r10-0x10], r0                    
    jgt r5, r0, lbb_16899                           if r5 > r0 { pc += 1 }
    mov64 r9, 0                                     r9 = 0 as i32 as i64 as u64
lbb_16899:
    mov64 r0, r4                                    r0 = r4
    add64 r0, 1                                     r0 += 1   ///  r0 = r0.wrapping_add(1 as i32 as i64 as u64)
    jgt r4, r0, lbb_16903                           if r4 > r0 { pc += 1 }
    mov64 r8, 0                                     r8 = 0 as i32 as i64 as u64
lbb_16903:
    stxdw [r10-0x18], r9                    
    and64 r9, r8                                    r9 &= r8   ///  r9 = r9.and(r8)
    add64 r9, r7                                    r9 += r7   ///  r9 = r9.wrapping_add(r7)
    ldxdw r6, [r3+0x10]                     
    ldxdw r1, [r2+0x10]                     
    jne r9, 0, lbb_16915                            if r9 != (0 as i32 as i64 as u64) { pc += 6 }
    mov64 r5, r1                                    r5 = r1
    add64 r5, r6                                    r5 += r6   ///  r5 = r5.wrapping_add(r6)
    mov64 r8, 1                                     r8 = 1 as i32 as i64 as u64
    jgt r1, r5, lbb_16927                           if r1 > r5 { pc += 14 }
    mov64 r8, 0                                     r8 = 0 as i32 as i64 as u64
    ja lbb_16927                                    if true { pc += 12 }
lbb_16915:
    mov64 r7, r1                                    r7 = r1
    add64 r7, r6                                    r7 += r6   ///  r7 = r7.wrapping_add(r6)
    mov64 r8, 1                                     r8 = 1 as i32 as i64 as u64
    mov64 r6, 1                                     r6 = 1 as i32 as i64 as u64
    jgt r1, r7, lbb_16921                           if r1 > r7 { pc += 1 }
    mov64 r6, 0                                     r6 = 0 as i32 as i64 as u64
lbb_16921:
    and64 r9, 255                                   r9 &= 255   ///  r9 = r9.and(255)
    mov64 r5, r7                                    r5 = r7
    add64 r5, r9                                    r5 += r9   ///  r5 = r5.wrapping_add(r9)
    jgt r7, r5, lbb_16926                           if r7 > r5 { pc += 1 }
    mov64 r8, 0                                     r8 = 0 as i32 as i64 as u64
lbb_16926:
    add64 r8, r6                                    r8 += r6   ///  r8 = r8.wrapping_add(r6)
lbb_16927:
    ldxdw r1, [r3+0x18]                     
    ldxdw r9, [r2+0x18]                     
    mov64 r2, r8                                    r2 = r8
    and64 r2, 255                                   r2 &= 255   ///  r2 = r2.and(255)
    jne r2, 0, lbb_16938                            if r2 != (0 as i32 as i64 as u64) { pc += 6 }
    mov64 r2, r9                                    r2 = r9
    add64 r2, r1                                    r2 += r1   ///  r2 = r2.wrapping_add(r1)
    mov64 r3, 1                                     r3 = 1 as i32 as i64 as u64
    jgt r9, r2, lbb_16950                           if r9 > r2 { pc += 14 }
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
    ja lbb_16950                                    if true { pc += 12 }
lbb_16938:
    mov64 r7, r9                                    r7 = r9
    add64 r7, r1                                    r7 += r1   ///  r7 = r7.wrapping_add(r1)
    mov64 r3, 1                                     r3 = 1 as i32 as i64 as u64
    mov64 r6, 1                                     r6 = 1 as i32 as i64 as u64
    jgt r9, r7, lbb_16944                           if r9 > r7 { pc += 1 }
    mov64 r6, 0                                     r6 = 0 as i32 as i64 as u64
lbb_16944:
    and64 r8, 255                                   r8 &= 255   ///  r8 = r8.and(255)
    mov64 r2, r7                                    r2 = r7
    add64 r2, r8                                    r2 += r8   ///  r2 = r2.wrapping_add(r8)
    jgt r7, r2, lbb_16949                           if r7 > r2 { pc += 1 }
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
lbb_16949:
    add64 r3, r6                                    r3 += r6   ///  r3 = r3.wrapping_add(r6)
lbb_16950:
    ldxdw r6, [r10-0x8]                     
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    and64 r3, 255                                   r3 &= 255   ///  r3 = r3.and(255)
    jne r3, 0, lbb_16964                            if r3 != (0 as i32 as i64 as u64) { pc += 10 }
    ldxdw r1, [r10-0x18]                    
    and64 r1, 1                                     r1 &= 1   ///  r1 = r1.and(1)
    jne r1, 0, lbb_16958                            if r1 != (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r0, r4                                    r0 = r4
lbb_16958:
    stxdw [r6+0x20], r2                     
    stxdw [r6+0x18], r5                     
    ldxdw r1, [r10-0x10]                    
    stxdw [r6+0x8], r1                      
    stxdw [r6+0x10], r0                     
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
lbb_16964:
    stxdw [r6+0x0], r1                      
    exit                                    

function_16966:
    stxdw [r10-0x8], r1                     
    ldxdw r1, [r3+0x8]                      
    ldxdw r5, [r2+0x8]                      
    mov64 r4, r5                                    r4 = r5
    sub64 r4, r1                                    r4 -= r1   ///  r4 = r4.wrapping_sub(r1)
    mov64 r8, 1                                     r8 = 1 as i32 as i64 as u64
    mov64 r7, 1                                     r7 = 1 as i32 as i64 as u64
    jgt r4, r5, lbb_16975                           if r4 > r5 { pc += 1 }
    mov64 r7, 0                                     r7 = 0 as i32 as i64 as u64
lbb_16975:
    ldxdw r1, [r3+0x0]                      
    ldxdw r5, [r2+0x0]                      
    mov64 r0, r5                                    r0 = r5
    sub64 r0, r1                                    r0 -= r1   ///  r0 = r0.wrapping_sub(r1)
    mov64 r9, 1                                     r9 = 1 as i32 as i64 as u64
    stxdw [r10-0x10], r0                    
    jgt r0, r5, lbb_16983                           if r0 > r5 { pc += 1 }
    mov64 r9, 0                                     r9 = 0 as i32 as i64 as u64
lbb_16983:
    mov64 r0, r4                                    r0 = r4
    add64 r0, -1                                    r0 += -1   ///  r0 = r0.wrapping_add(-1 as i32 as i64 as u64)
    jgt r0, r4, lbb_16987                           if r0 > r4 { pc += 1 }
    mov64 r8, 0                                     r8 = 0 as i32 as i64 as u64
lbb_16987:
    stxdw [r10-0x18], r9                    
    and64 r9, r8                                    r9 &= r8   ///  r9 = r9.and(r8)
    add64 r9, r7                                    r9 += r7   ///  r9 = r9.wrapping_add(r7)
    ldxdw r6, [r3+0x10]                     
    ldxdw r1, [r2+0x10]                     
    jne r9, 0, lbb_16999                            if r9 != (0 as i32 as i64 as u64) { pc += 6 }
    mov64 r5, r1                                    r5 = r1
    sub64 r5, r6                                    r5 -= r6   ///  r5 = r5.wrapping_sub(r6)
    mov64 r8, 1                                     r8 = 1 as i32 as i64 as u64
    jgt r5, r1, lbb_17011                           if r5 > r1 { pc += 14 }
    mov64 r8, 0                                     r8 = 0 as i32 as i64 as u64
    ja lbb_17011                                    if true { pc += 12 }
lbb_16999:
    mov64 r7, r1                                    r7 = r1
    sub64 r7, r6                                    r7 -= r6   ///  r7 = r7.wrapping_sub(r6)
    mov64 r8, 1                                     r8 = 1 as i32 as i64 as u64
    mov64 r6, 1                                     r6 = 1 as i32 as i64 as u64
    jgt r7, r1, lbb_17005                           if r7 > r1 { pc += 1 }
    mov64 r6, 0                                     r6 = 0 as i32 as i64 as u64
lbb_17005:
    and64 r9, 255                                   r9 &= 255   ///  r9 = r9.and(255)
    mov64 r5, r7                                    r5 = r7
    sub64 r5, r9                                    r5 -= r9   ///  r5 = r5.wrapping_sub(r9)
    jgt r5, r7, lbb_17010                           if r5 > r7 { pc += 1 }
    mov64 r8, 0                                     r8 = 0 as i32 as i64 as u64
lbb_17010:
    add64 r8, r6                                    r8 += r6   ///  r8 = r8.wrapping_add(r6)
lbb_17011:
    ldxdw r1, [r3+0x18]                     
    ldxdw r9, [r2+0x18]                     
    mov64 r2, r8                                    r2 = r8
    and64 r2, 255                                   r2 &= 255   ///  r2 = r2.and(255)
    jne r2, 0, lbb_17022                            if r2 != (0 as i32 as i64 as u64) { pc += 6 }
    mov64 r2, r9                                    r2 = r9
    sub64 r2, r1                                    r2 -= r1   ///  r2 = r2.wrapping_sub(r1)
    mov64 r3, 1                                     r3 = 1 as i32 as i64 as u64
    jgt r2, r9, lbb_17034                           if r2 > r9 { pc += 14 }
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
    ja lbb_17034                                    if true { pc += 12 }
lbb_17022:
    mov64 r7, r9                                    r7 = r9
    sub64 r7, r1                                    r7 -= r1   ///  r7 = r7.wrapping_sub(r1)
    mov64 r3, 1                                     r3 = 1 as i32 as i64 as u64
    mov64 r6, 1                                     r6 = 1 as i32 as i64 as u64
    jgt r7, r9, lbb_17028                           if r7 > r9 { pc += 1 }
    mov64 r6, 0                                     r6 = 0 as i32 as i64 as u64
lbb_17028:
    and64 r8, 255                                   r8 &= 255   ///  r8 = r8.and(255)
    mov64 r2, r7                                    r2 = r7
    sub64 r2, r8                                    r2 -= r8   ///  r2 = r2.wrapping_sub(r8)
    jgt r2, r7, lbb_17033                           if r2 > r7 { pc += 1 }
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
lbb_17033:
    add64 r3, r6                                    r3 += r6   ///  r3 = r3.wrapping_add(r6)
lbb_17034:
    ldxdw r6, [r10-0x8]                     
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    and64 r3, 255                                   r3 &= 255   ///  r3 = r3.and(255)
    jne r3, 0, lbb_17048                            if r3 != (0 as i32 as i64 as u64) { pc += 10 }
    ldxdw r1, [r10-0x18]                    
    and64 r1, 1                                     r1 &= 1   ///  r1 = r1.and(1)
    jne r1, 0, lbb_17042                            if r1 != (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r0, r4                                    r0 = r4
lbb_17042:
    stxdw [r6+0x20], r2                     
    stxdw [r6+0x18], r5                     
    ldxdw r1, [r10-0x10]                    
    stxdw [r6+0x8], r1                      
    stxdw [r6+0x10], r0                     
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
lbb_17048:
    stxdw [r6+0x0], r1                      
    exit                                    

function_17050:
    mov64 r9, r3                                    r9 = r3
    mov64 r7, r2                                    r7 = r2
    stxdw [r10-0x120], r1                   
    ldxdw r8, [r9+0x0]                      
    ldxdw r6, [r7+0x0]                      
    mov64 r1, r10                                   r1 = r10
    add64 r1, -256                                  r1 += -256   ///  r1 = r1.wrapping_add(-256 as i32 as i64 as u64)
    mov64 r2, r8                                    r2 = r8
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
    mov64 r4, r6                                    r4 = r6
    mov64 r5, 0                                     r5 = 0 as i32 as i64 as u64
    call function_21911                     
    ldxdw r4, [r7+0x8]                      
    stxdw [r10-0x118], r4                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -240                                  r1 += -240   ///  r1 = r1.wrapping_add(-240 as i32 as i64 as u64)
    mov64 r2, r8                                    r2 = r8
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
    mov64 r5, 0                                     r5 = 0 as i32 as i64 as u64
    call function_21911                     
    ldxdw r4, [r7+0x10]                     
    stxdw [r10-0x108], r4                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -224                                  r1 += -224   ///  r1 = r1.wrapping_add(-224 as i32 as i64 as u64)
    mov64 r2, r8                                    r2 = r8
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
    mov64 r5, 0                                     r5 = 0 as i32 as i64 as u64
    call function_21911                     
    ldxdw r4, [r7+0x18]                     
    stxdw [r10-0x110], r4                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -208                                  r1 += -208   ///  r1 = r1.wrapping_add(-208 as i32 as i64 as u64)
    mov64 r2, r8                                    r2 = r8
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
    mov64 r5, 0                                     r5 = 0 as i32 as i64 as u64
    call function_21911                     
    ldxdw r8, [r9+0x8]                      
    mov64 r1, r10                                   r1 = r10
    add64 r1, -64                                   r1 += -64   ///  r1 = r1.wrapping_add(-64 as i32 as i64 as u64)
    mov64 r2, r8                                    r2 = r8
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
    stxdw [r10-0x128], r6                   
    mov64 r4, r6                                    r4 = r6
    mov64 r5, 0                                     r5 = 0 as i32 as i64 as u64
    call function_21911                     
    mov64 r1, r10                                   r1 = r10
    add64 r1, -48                                   r1 += -48   ///  r1 = r1.wrapping_add(-48 as i32 as i64 as u64)
    mov64 r2, r8                                    r2 = r8
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
    ldxdw r7, [r10-0x118]                   
    mov64 r4, r7                                    r4 = r7
    mov64 r5, 0                                     r5 = 0 as i32 as i64 as u64
    call function_21911                     
    mov64 r1, r10                                   r1 = r10
    add64 r1, -32                                   r1 += -32   ///  r1 = r1.wrapping_add(-32 as i32 as i64 as u64)
    mov64 r2, r8                                    r2 = r8
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
    ldxdw r4, [r10-0x108]                   
    mov64 r5, 0                                     r5 = 0 as i32 as i64 as u64
    call function_21911                     
    mov64 r1, r10                                   r1 = r10
    add64 r1, -16                                   r1 += -16   ///  r1 = r1.wrapping_add(-16 as i32 as i64 as u64)
    mov64 r2, r8                                    r2 = r8
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
    ldxdw r4, [r10-0x110]                   
    mov64 r5, 0                                     r5 = 0 as i32 as i64 as u64
    call function_21911                     
    ldxdw r8, [r9+0x10]                     
    mov64 r1, r10                                   r1 = r10
    add64 r1, -128                                  r1 += -128   ///  r1 = r1.wrapping_add(-128 as i32 as i64 as u64)
    mov64 r2, r8                                    r2 = r8
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
    mov64 r4, r6                                    r4 = r6
    mov64 r5, 0                                     r5 = 0 as i32 as i64 as u64
    call function_21911                     
    mov64 r1, r10                                   r1 = r10
    add64 r1, -112                                  r1 += -112   ///  r1 = r1.wrapping_add(-112 as i32 as i64 as u64)
    mov64 r2, r8                                    r2 = r8
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
    mov64 r4, r7                                    r4 = r7
    mov64 r5, 0                                     r5 = 0 as i32 as i64 as u64
    call function_21911                     
    mov64 r1, r10                                   r1 = r10
    add64 r1, -96                                   r1 += -96   ///  r1 = r1.wrapping_add(-96 as i32 as i64 as u64)
    mov64 r2, r8                                    r2 = r8
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
    ldxdw r6, [r10-0x108]                   
    mov64 r4, r6                                    r4 = r6
    mov64 r5, 0                                     r5 = 0 as i32 as i64 as u64
    call function_21911                     
    mov64 r1, r10                                   r1 = r10
    add64 r1, -80                                   r1 += -80   ///  r1 = r1.wrapping_add(-80 as i32 as i64 as u64)
    mov64 r2, r8                                    r2 = r8
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
    ldxdw r7, [r10-0x110]                   
    mov64 r4, r7                                    r4 = r7
    mov64 r5, 0                                     r5 = 0 as i32 as i64 as u64
    call function_21911                     
    ldxdw r8, [r9+0x18]                     
    mov64 r1, r10                                   r1 = r10
    add64 r1, -192                                  r1 += -192   ///  r1 = r1.wrapping_add(-192 as i32 as i64 as u64)
    mov64 r2, r8                                    r2 = r8
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
    ldxdw r4, [r10-0x128]                   
    mov64 r5, 0                                     r5 = 0 as i32 as i64 as u64
    call function_21911                     
    mov64 r1, r10                                   r1 = r10
    add64 r1, -176                                  r1 += -176   ///  r1 = r1.wrapping_add(-176 as i32 as i64 as u64)
    mov64 r2, r8                                    r2 = r8
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
    ldxdw r4, [r10-0x118]                   
    mov64 r5, 0                                     r5 = 0 as i32 as i64 as u64
    call function_21911                     
    mov64 r1, r10                                   r1 = r10
    add64 r1, -160                                  r1 += -160   ///  r1 = r1.wrapping_add(-160 as i32 as i64 as u64)
    mov64 r2, r8                                    r2 = r8
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
    mov64 r4, r6                                    r4 = r6
    mov64 r5, 0                                     r5 = 0 as i32 as i64 as u64
    call function_21911                     
    mov64 r1, r10                                   r1 = r10
    add64 r1, -144                                  r1 += -144   ///  r1 = r1.wrapping_add(-144 as i32 as i64 as u64)
    mov64 r2, r8                                    r2 = r8
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
    mov64 r4, r7                                    r4 = r7
    mov64 r5, 0                                     r5 = 0 as i32 as i64 as u64
    call function_21911                     
    ldxdw r2, [r10-0xf8]                    
    ldxdw r3, [r10-0xf0]                    
    mov64 r1, r3                                    r1 = r3
    add64 r1, r2                                    r1 += r2   ///  r1 = r1.wrapping_add(r2)
    mov64 r2, 1                                     r2 = 1 as i32 as i64 as u64
    stxdw [r10-0x108], r2                   
    mov64 r2, 1                                     r2 = 1 as i32 as i64 as u64
    jgt r3, r1, lbb_17186                           if r3 > r1 { pc += 1 }
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
lbb_17186:
    ldxdw r3, [r10-0xe8]                    
    add64 r2, r3                                    r2 += r3   ///  r2 = r2.wrapping_add(r3)
    ldxdw r3, [r10-0xe0]                    
    mov64 r4, r3                                    r4 = r3
    add64 r4, r2                                    r4 += r2   ///  r4 = r4.wrapping_add(r2)
    ldxdw r2, [r10-0x40]                    
    mov64 r5, r2                                    r5 = r2
    add64 r5, r1                                    r5 += r1   ///  r5 = r5.wrapping_add(r1)
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    stxdw [r10-0x110], r5                   
    jgt r2, r5, lbb_17198                           if r2 > r5 { pc += 1 }
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
lbb_17198:
    ldxdw r2, [r10-0x38]                    
    add64 r1, r2                                    r1 += r2   ///  r1 = r1.wrapping_add(r2)
    mov64 r2, r1                                    r2 = r1
    add64 r2, r4                                    r2 += r4   ///  r2 = r2.wrapping_add(r4)
    mov64 r0, 1                                     r0 = 1 as i32 as i64 as u64
    jgt r1, r2, lbb_17205                           if r1 > r2 { pc += 1 }
    mov64 r0, 0                                     r0 = 0 as i32 as i64 as u64
lbb_17205:
    ldxdw r6, [r10-0x30]                    
    mov64 r5, r6                                    r5 = r6
    add64 r5, r2                                    r5 += r2   ///  r5 = r5.wrapping_add(r2)
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    jgt r6, r5, lbb_17211                           if r6 > r5 { pc += 1 }
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
lbb_17211:
    ldxdw r2, [r10-0x28]                    
    add64 r1, r2                                    r1 += r2   ///  r1 = r1.wrapping_add(r2)
    mov64 r7, 1                                     r7 = 1 as i32 as i64 as u64
    jgt r3, r4, lbb_17216                           if r3 > r4 { pc += 1 }
    mov64 r7, 0                                     r7 = 0 as i32 as i64 as u64
lbb_17216:
    ldxdw r2, [r10-0xd8]                    
    add64 r7, r2                                    r7 += r2   ///  r7 = r7.wrapping_add(r2)
    mov64 r8, r1                                    r8 = r1
    add64 r8, r0                                    r8 += r0   ///  r8 = r8.wrapping_add(r0)
    mov64 r3, 1                                     r3 = 1 as i32 as i64 as u64
    jgt r1, r8, lbb_17223                           if r1 > r8 { pc += 1 }
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
lbb_17223:
    ldxdw r4, [r10-0xd0]                    
    mov64 r6, r4                                    r6 = r4
    add64 r6, r7                                    r6 += r7   ///  r6 = r6.wrapping_add(r7)
    mov64 r1, r8                                    r1 = r8
    add64 r1, r6                                    r1 += r6   ///  r1 = r1.wrapping_add(r6)
    mov64 r7, 1                                     r7 = 1 as i32 as i64 as u64
    jgt r8, r1, lbb_17231                           if r8 > r1 { pc += 1 }
    mov64 r7, 0                                     r7 = 0 as i32 as i64 as u64
lbb_17231:
    ldxdw r2, [r10-0x20]                    
    mov64 r0, r2                                    r0 = r2
    add64 r0, r1                                    r0 += r1   ///  r0 = r0.wrapping_add(r1)
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    jgt r2, r0, lbb_17237                           if r2 > r0 { pc += 1 }
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
lbb_17237:
    or64 r3, r7                                     r3 |= r7   ///  r3 = r3.or(r7)
    ldxdw r2, [r10-0x18]                    
    add64 r1, r2                                    r1 += r2   ///  r1 = r1.wrapping_add(r2)
    mov64 r8, 1                                     r8 = 1 as i32 as i64 as u64
    jgt r4, r6, lbb_17243                           if r4 > r6 { pc += 1 }
    mov64 r8, 0                                     r8 = 0 as i32 as i64 as u64
lbb_17243:
    ldxdw r2, [r10-0xc8]                    
    add64 r8, r2                                    r8 += r2   ///  r8 = r8.wrapping_add(r2)
    mov64 r2, r1                                    r2 = r1
    add64 r2, r3                                    r2 += r3   ///  r2 = r2.wrapping_add(r3)
    mov64 r4, 1                                     r4 = 1 as i32 as i64 as u64
    jgt r1, r2, lbb_17250                           if r1 > r2 { pc += 1 }
    mov64 r4, 0                                     r4 = 0 as i32 as i64 as u64
lbb_17250:
    mov64 r7, r2                                    r7 = r2
    add64 r7, r8                                    r7 += r8   ///  r7 = r7.wrapping_add(r8)
    mov64 r6, 1                                     r6 = 1 as i32 as i64 as u64
    jgt r2, r7, lbb_17255                           if r2 > r7 { pc += 1 }
    mov64 r6, 0                                     r6 = 0 as i32 as i64 as u64
lbb_17255:
    ldxdw r2, [r10-0x80]                    
    mov64 r3, r2                                    r3 = r2
    add64 r3, r5                                    r3 += r5   ///  r3 = r3.wrapping_add(r5)
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    stxdw [r10-0x118], r3                   
    jgt r2, r3, lbb_17262                           if r2 > r3 { pc += 1 }
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
lbb_17262:
    ldxdw r2, [r10-0x78]                    
    add64 r1, r2                                    r1 += r2   ///  r1 = r1.wrapping_add(r2)
    mov64 r2, r1                                    r2 = r1
    add64 r2, r0                                    r2 += r0   ///  r2 = r2.wrapping_add(r0)
    mov64 r8, 1                                     r8 = 1 as i32 as i64 as u64
    jgt r1, r2, lbb_17269                           if r1 > r2 { pc += 1 }
    mov64 r8, 0                                     r8 = 0 as i32 as i64 as u64
lbb_17269:
    ldxdw r3, [r10-0x70]                    
    mov64 r0, r3                                    r0 = r3
    add64 r0, r2                                    r0 += r2   ///  r0 = r0.wrapping_add(r2)
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    jgt r3, r0, lbb_17275                           if r3 > r0 { pc += 1 }
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
lbb_17275:
    ldxdw r2, [r10-0x68]                    
    add64 r1, r2                                    r1 += r2   ///  r1 = r1.wrapping_add(r2)
    ldxdw r3, [r10-0x10]                    
    mov64 r2, r3                                    r2 = r3
    add64 r2, r7                                    r2 += r7   ///  r2 = r2.wrapping_add(r7)
    mov64 r5, 1                                     r5 = 1 as i32 as i64 as u64
    jgt r3, r2, lbb_17283                           if r3 > r2 { pc += 1 }
    mov64 r5, 0                                     r5 = 0 as i32 as i64 as u64
lbb_17283:
    mov64 r7, r1                                    r7 = r1
    add64 r7, r8                                    r7 += r8   ///  r7 = r7.wrapping_add(r8)
    mov64 r9, r7                                    r9 = r7
    add64 r9, r2                                    r9 += r2   ///  r9 = r9.wrapping_add(r2)
    mov64 r8, 1                                     r8 = 1 as i32 as i64 as u64
    jgt r1, r7, lbb_17290                           if r1 > r7 { pc += 1 }
    mov64 r8, 0                                     r8 = 0 as i32 as i64 as u64
lbb_17290:
    or64 r4, r6                                     r4 |= r6   ///  r4 = r4.or(r6)
    ldxdw r1, [r10-0x8]                     
    mov64 r2, 1                                     r2 = 1 as i32 as i64 as u64
    jgt r7, r9, lbb_17295                           if r7 > r9 { pc += 1 }
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
lbb_17295:
    add64 r4, r1                                    r4 += r1   ///  r4 = r4.wrapping_add(r1)
    or64 r8, r2                                     r8 |= r2   ///  r8 = r8.or(r2)
    ldxdw r2, [r10-0x60]                    
    mov64 r7, r2                                    r7 = r2
    add64 r7, r9                                    r7 += r9   ///  r7 = r7.wrapping_add(r9)
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    jgt r2, r7, lbb_17303                           if r2 > r7 { pc += 1 }
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
lbb_17303:
    add64 r4, r5                                    r4 += r5   ///  r4 = r4.wrapping_add(r5)
    ldxdw r2, [r10-0x58]                    
    add64 r1, r2                                    r1 += r2   ///  r1 = r1.wrapping_add(r2)
    mov64 r2, r1                                    r2 = r1
    add64 r2, r8                                    r2 += r8   ///  r2 = r2.wrapping_add(r8)
    mov64 r5, 1                                     r5 = 1 as i32 as i64 as u64
    jgt r1, r2, lbb_17311                           if r1 > r2 { pc += 1 }
    mov64 r5, 0                                     r5 = 0 as i32 as i64 as u64
lbb_17311:
    mov64 r8, r2                                    r8 = r2
    add64 r8, r4                                    r8 += r4   ///  r8 = r8.wrapping_add(r4)
    mov64 r6, 1                                     r6 = 1 as i32 as i64 as u64
    jgt r2, r8, lbb_17316                           if r2 > r8 { pc += 1 }
    mov64 r6, 0                                     r6 = 0 as i32 as i64 as u64
lbb_17316:
    ldxdw r2, [r10-0xc0]                    
    mov64 r4, r2                                    r4 = r2
    add64 r4, r0                                    r4 += r0   ///  r4 = r4.wrapping_add(r0)
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    jgt r2, r4, lbb_17322                           if r2 > r4 { pc += 1 }
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
lbb_17322:
    ldxdw r2, [r10-0xb8]                    
    add64 r1, r2                                    r1 += r2   ///  r1 = r1.wrapping_add(r2)
    mov64 r2, r1                                    r2 = r1
    add64 r2, r7                                    r2 += r7   ///  r2 = r2.wrapping_add(r7)
    mov64 r7, 1                                     r7 = 1 as i32 as i64 as u64
    jgt r1, r2, lbb_17329                           if r1 > r2 { pc += 1 }
    mov64 r7, 0                                     r7 = 0 as i32 as i64 as u64
lbb_17329:
    ldxdw r1, [r10-0xb0]                    
    mov64 r0, r1                                    r0 = r1
    add64 r0, r2                                    r0 += r2   ///  r0 = r0.wrapping_add(r2)
    mov64 r9, 1                                     r9 = 1 as i32 as i64 as u64
    jgt r1, r0, lbb_17335                           if r1 > r0 { pc += 1 }
    mov64 r9, 0                                     r9 = 0 as i32 as i64 as u64
lbb_17335:
    ldxdw r1, [r10-0xa8]                    
    add64 r9, r1                                    r9 += r1   ///  r9 = r9.wrapping_add(r1)
    ldxdw r1, [r10-0x50]                    
    mov64 r2, r1                                    r2 = r1
    add64 r2, r8                                    r2 += r8   ///  r2 = r2.wrapping_add(r8)
    mov64 r8, 1                                     r8 = 1 as i32 as i64 as u64
    jgt r1, r2, lbb_17343                           if r1 > r2 { pc += 1 }
    mov64 r8, 0                                     r8 = 0 as i32 as i64 as u64
lbb_17343:
    or64 r5, r6                                     r5 |= r6   ///  r5 = r5.or(r6)
    ldxdw r3, [r10-0x48]                    
    mov64 r6, r9                                    r6 = r9
    add64 r6, r7                                    r6 += r7   ///  r6 = r6.wrapping_add(r7)
    mov64 r1, r6                                    r1 = r6
    add64 r1, r2                                    r1 += r2   ///  r1 = r1.wrapping_add(r2)
    mov64 r7, 1                                     r7 = 1 as i32 as i64 as u64
    jgt r9, r6, lbb_17352                           if r9 > r6 { pc += 1 }
    mov64 r7, 0                                     r7 = 0 as i32 as i64 as u64
lbb_17352:
    add64 r5, r3                                    r5 += r3   ///  r5 = r5.wrapping_add(r3)
    mov64 r2, 1                                     r2 = 1 as i32 as i64 as u64
    jgt r6, r1, lbb_17356                           if r6 > r1 { pc += 1 }
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
lbb_17356:
    add64 r5, r8                                    r5 += r8   ///  r5 = r5.wrapping_add(r8)
    or64 r7, r2                                     r7 |= r2   ///  r7 = r7.or(r2)
    ldxdw r3, [r10-0xa0]                    
    mov64 r6, r3                                    r6 = r3
    add64 r6, r1                                    r6 += r1   ///  r6 = r6.wrapping_add(r1)
    mov64 r2, 1                                     r2 = 1 as i32 as i64 as u64
    jgt r3, r6, lbb_17364                           if r3 > r6 { pc += 1 }
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
lbb_17364:
    ldxdw r1, [r10-0x98]                    
    add64 r2, r1                                    r2 += r1   ///  r2 = r2.wrapping_add(r1)
    mov64 r1, r2                                    r1 = r2
    add64 r1, r7                                    r1 += r7   ///  r1 = r1.wrapping_add(r7)
    mov64 r9, r1                                    r9 = r1
    add64 r9, r5                                    r9 += r5   ///  r9 = r9.wrapping_add(r5)
    mov64 r5, 1                                     r5 = 1 as i32 as i64 as u64
    jgt r2, r1, lbb_17373                           if r2 > r1 { pc += 1 }
    mov64 r5, 0                                     r5 = 0 as i32 as i64 as u64
lbb_17373:
    ldxdw r2, [r10-0x90]                    
    mov64 r8, r2                                    r8 = r2
    add64 r8, r9                                    r8 += r9   ///  r8 = r8.wrapping_add(r9)
    mov64 r7, 1                                     r7 = 1 as i32 as i64 as u64
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
    jgt r1, r9, lbb_17380                           if r1 > r9 { pc += 1 }
    mov64 r7, 0                                     r7 = 0 as i32 as i64 as u64
lbb_17380:
    jgt r2, r8, lbb_17383                           if r2 > r8 { pc += 2 }
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    stxdw [r10-0x108], r1                   
lbb_17383:
    ldxdw r2, [r10-0x120]                   
    jne r0, 0, lbb_17403                            if r0 != (0 as i32 as i64 as u64) { pc += 18 }
    jne r6, 0, lbb_17403                            if r6 != (0 as i32 as i64 as u64) { pc += 17 }
    jne r8, 0, lbb_17403                            if r8 != (0 as i32 as i64 as u64) { pc += 16 }
    ldxdw r1, [r10-0x88]                    
    ldxdw r0, [r10-0x108]                   
    and64 r0, 1                                     r0 &= 1   ///  r0 = r0.and(1)
    add64 r0, r1                                    r0 += r1   ///  r0 = r0.wrapping_add(r1)
    or64 r5, r7                                     r5 |= r7   ///  r5 = r5.or(r7)
    and64 r5, 1                                     r5 &= 1   ///  r5 = r5.and(1)
    neg64 r5                                        r5 = -r5   ///  r5 = (r5 as i64).wrapping_neg() as u64
    jne r0, r5, lbb_17403                           if r0 != r5 { pc += 8 }
    ldxdw r1, [r10-0x100]                   
    stxdw [r2+0x20], r4                     
    ldxdw r3, [r10-0x118]                   
    stxdw [r2+0x18], r3                     
    ldxdw r3, [r10-0x110]                   
    stxdw [r2+0x10], r3                     
    stxdw [r2+0x8], r1                      
    mov64 r3, 1                                     r3 = 1 as i32 as i64 as u64
lbb_17403:
    stxdw [r2+0x0], r3                      
    exit                                    

function_17405:
    mov64 r6, r1                                    r6 = r1
    ldxdw r1, [r3+0x0]                      
    jne r1, 0, lbb_17415                            if r1 != (0 as i32 as i64 as u64) { pc += 7 }
    ldxdw r1, [r3+0x8]                      
    jne r1, 0, lbb_17415                            if r1 != (0 as i32 as i64 as u64) { pc += 5 }
    ldxdw r1, [r3+0x10]                     
    jne r1, 0, lbb_17415                            if r1 != (0 as i32 as i64 as u64) { pc += 3 }
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    ldxdw r4, [r3+0x18]                     
    jeq r4, 0, lbb_17447                            if r4 == (0 as i32 as i64 as u64) { pc += 32 }
lbb_17415:
    ldxdw r1, [r2+0x18]                     
    stxdw [r10-0x28], r1                    
    ldxdw r1, [r2+0x10]                     
    stxdw [r10-0x30], r1                    
    ldxdw r1, [r2+0x8]                      
    stxdw [r10-0x38], r1                    
    ldxdw r1, [r2+0x0]                      
    stxdw [r10-0x40], r1                    
    ldxdw r1, [r3+0x18]                     
    stxdw [r10-0x8], r1                     
    ldxdw r1, [r3+0x10]                     
    stxdw [r10-0x10], r1                    
    ldxdw r1, [r3+0x8]                      
    stxdw [r10-0x18], r1                    
    ldxdw r1, [r3+0x0]                      
    stxdw [r10-0x20], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -128                                  r1 += -128   ///  r1 = r1.wrapping_add(-128 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -64                                   r2 += -64   ///  r2 = r2.wrapping_add(-64 as i32 as i64 as u64)
    mov64 r3, r10                                   r3 = r10
    add64 r3, -32                                   r3 += -32   ///  r3 = r3.wrapping_add(-32 as i32 as i64 as u64)
    call function_15536                     
    ldxdw r1, [r10-0x68]                    
    stxdw [r6+0x20], r1                     
    ldxdw r1, [r10-0x70]                    
    stxdw [r6+0x18], r1                     
    ldxdw r1, [r10-0x78]                    
    stxdw [r6+0x10], r1                     
    ldxdw r1, [r10-0x80]                    
    stxdw [r6+0x8], r1                      
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
lbb_17447:
    stxdw [r6+0x0], r1                      
    exit                                    

function_17449:
    mov64 r6, r1                                    r6 = r1
    ldxdw r1, [r3+0x0]                      
    jne r1, 0, lbb_17459                            if r1 != (0 as i32 as i64 as u64) { pc += 7 }
    ldxdw r1, [r3+0x8]                      
    jne r1, 0, lbb_17459                            if r1 != (0 as i32 as i64 as u64) { pc += 5 }
    ldxdw r1, [r3+0x10]                     
    jne r1, 0, lbb_17459                            if r1 != (0 as i32 as i64 as u64) { pc += 3 }
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    ldxdw r4, [r3+0x18]                     
    jeq r4, 0, lbb_17491                            if r4 == (0 as i32 as i64 as u64) { pc += 32 }
lbb_17459:
    ldxdw r1, [r2+0x18]                     
    stxdw [r10-0x28], r1                    
    ldxdw r1, [r2+0x10]                     
    stxdw [r10-0x30], r1                    
    ldxdw r1, [r2+0x8]                      
    stxdw [r10-0x38], r1                    
    ldxdw r1, [r2+0x0]                      
    stxdw [r10-0x40], r1                    
    ldxdw r1, [r3+0x18]                     
    stxdw [r10-0x8], r1                     
    ldxdw r1, [r3+0x10]                     
    stxdw [r10-0x10], r1                    
    ldxdw r1, [r3+0x8]                      
    stxdw [r10-0x18], r1                    
    ldxdw r1, [r3+0x0]                      
    stxdw [r10-0x20], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -128                                  r1 += -128   ///  r1 = r1.wrapping_add(-128 as i32 as i64 as u64)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -64                                   r2 += -64   ///  r2 = r2.wrapping_add(-64 as i32 as i64 as u64)
    mov64 r3, r10                                   r3 = r10
    add64 r3, -32                                   r3 += -32   ///  r3 = r3.wrapping_add(-32 as i32 as i64 as u64)
    call function_15536                     
    ldxdw r1, [r10-0x48]                    
    stxdw [r6+0x20], r1                     
    ldxdw r1, [r10-0x50]                    
    stxdw [r6+0x18], r1                     
    ldxdw r1, [r10-0x58]                    
    stxdw [r6+0x10], r1                     
    ldxdw r1, [r10-0x60]                    
    stxdw [r6+0x8], r1                      
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
lbb_17491:
    stxdw [r6+0x0], r1                      
    exit                                    

function_17493:
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
    stxdw [r1+0x18], r3                     
    stxdw [r1+0x10], r3                     
    stxdw [r1+0x8], r3                      
    stxdw [r1+0x0], r2                      
    exit                                    

function_17499:
    lddw r0, 0x6436232572d50cba                     r0 load str located at 7220997696282496186
    exit                                    

function_17502:
    stxdw [r10-0x10], r1                    
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    stxb [r10-0x8], r1                      
    stxdw [r10-0x18], r1                    
    lddw r1, 0x10002df68 --> b"\x00\x00\x00\x00\x80$\x02\x00\x00\x00\x00\x00\x00\x00\x00\x00\x01\x00\x00…        r1 load str located at 4295155560
    stxdw [r10-0x20], r1                    
    lddw r1, 0x10002ccc8 --> b"src/decode.rsError: memory allocation failed, out "        r1 load str located at 4295150792
    stxdw [r10-0x28], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -40                                   r1 += -40   ///  r1 = r1.wrapping_add(-40 as i32 as i64 as u64)
    call function_18571                     
    syscall [invalid]                       
    exit                                    

function_17517:
    mov64 r8, r3                                    r8 = r3
    mov64 r7, r2                                    r7 = r2
    mov64 r6, r1                                    r6 = r1
    jeq r8, 0, lbb_17531                            if r8 == (0 as i32 as i64 as u64) { pc += 10 }
    ldxdw r1, [r4+0x10]                     
    jeq r1, 0, lbb_17541                            if r1 == (0 as i32 as i64 as u64) { pc += 18 }
    ldxdw r2, [r4+0x8]                      
    jne r2, 0, lbb_17535                            if r2 != (0 as i32 as i64 as u64) { pc += 10 }
    jeq r7, 0, lbb_17551                            if r7 == (0 as i32 as i64 as u64) { pc += 25 }
    mov64 r1, r7                                    r1 = r7
    mov64 r2, r8                                    r2 = r8
    call function_11635                     
    jeq r0, 0, lbb_17547                            if r0 == (0 as i32 as i64 as u64) { pc += 17 }
    ja lbb_17553                                    if true { pc += 22 }
lbb_17531:
    stxdw [r6+0x8], r7                      
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    mov64 r7, 0                                     r7 = 0 as i32 as i64 as u64
    ja lbb_17555                                    if true { pc += 20 }
lbb_17535:
    ldxdw r1, [r4+0x0]                      
    mov64 r3, r8                                    r3 = r8
    mov64 r4, r7                                    r4 = r7
    call function_11639                     
    jeq r0, 0, lbb_17547                            if r0 == (0 as i32 as i64 as u64) { pc += 7 }
    ja lbb_17553                                    if true { pc += 12 }
lbb_17541:
    jeq r7, 0, lbb_17551                            if r7 == (0 as i32 as i64 as u64) { pc += 9 }
    mov64 r1, r7                                    r1 = r7
    mov64 r2, r8                                    r2 = r8
    call function_11635                     
    jeq r0, 0, lbb_17547                            if r0 == (0 as i32 as i64 as u64) { pc += 1 }
    ja lbb_17553                                    if true { pc += 6 }
lbb_17547:
    stxdw [r6+0x8], r7                      
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    mov64 r7, r8                                    r7 = r8
    ja lbb_17555                                    if true { pc += 4 }
lbb_17551:
    mov64 r7, 0                                     r7 = 0 as i32 as i64 as u64
    mov64 r0, r8                                    r0 = r8
lbb_17553:
    stxdw [r6+0x8], r0                      
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
lbb_17555:
    stxdw [r6+0x0], r1                      
    stxdw [r6+0x10], r7                     
    exit                                    

function_17558:
    mov64 r4, r2                                    r4 = r2
    add64 r4, 1                                     r4 += 1   ///  r4 = r4.wrapping_add(1 as i32 as i64 as u64)
    mov64 r3, 1                                     r3 = 1 as i32 as i64 as u64
    jgt r2, r4, lbb_17563                           if r2 > r4 { pc += 1 }
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
lbb_17563:
    and64 r3, 1                                     r3 &= 1   ///  r3 = r3.and(1)
    jne r3, 0, lbb_17621                            if r3 != (0 as i32 as i64 as u64) { pc += 56 }
    ldxdw r8, [r1+0x8]                      
    mov64 r7, r8                                    r7 = r8
    lsh64 r7, 1                                     r7 <<= 1   ///  r7 = r7.wrapping_shl(1)
    jgt r7, r4, lbb_17570                           if r7 > r4 { pc += 1 }
    mov64 r7, r4                                    r7 = r4
lbb_17570:
    stxdw [r10-0x58], r1                    
    jgt r7, 4, lbb_17573                            if r7 > (4 as i32 as i64 as u64) { pc += 1 }
    mov64 r7, 4                                     r7 = 4 as i32 as i64 as u64
lbb_17573:
    mov64 r1, r10                                   r1 = r10
    add64 r1, -64                                   r1 += -64   ///  r1 = r1.wrapping_add(-64 as i32 as i64 as u64)
    mov64 r6, 0                                     r6 = 0 as i32 as i64 as u64
    mov64 r2, r7                                    r2 = r7
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
    mov64 r4, 48                                    r4 = 48 as i32 as i64 as u64
    mov64 r5, 0                                     r5 = 0 as i32 as i64 as u64
    call function_21911                     
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    ldxdw r2, [r10-0x38]                    
    jne r2, 0, lbb_17585                            if r2 != (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
lbb_17585:
    mov64 r9, 0                                     r9 = 0 as i32 as i64 as u64
    jne r1, 0, lbb_17588                            if r1 != (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r9, 8                                     r9 = 8 as i32 as i64 as u64
lbb_17588:
    ldxdw r2, [r10-0x40]                    
    jeq r8, 0, lbb_17605                            if r8 == (0 as i32 as i64 as u64) { pc += 15 }
    mov64 r1, r10                                   r1 = r10
    add64 r1, -80                                   r1 += -80   ///  r1 = r1.wrapping_add(-80 as i32 as i64 as u64)
    mov64 r6, r2                                    r6 = r2
    mov64 r2, r8                                    r2 = r8
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
    mov64 r4, 48                                    r4 = 48 as i32 as i64 as u64
    mov64 r5, 0                                     r5 = 0 as i32 as i64 as u64
    call function_21911                     
    mov64 r2, r6                                    r2 = r6
    ldxdw r1, [r10-0x58]                    
    ldxdw r1, [r1+0x0]                      
    stxdw [r10-0x18], r1                    
    ldxdw r1, [r10-0x50]                    
    stxdw [r10-0x10], r1                    
    mov64 r6, 8                                     r6 = 8 as i32 as i64 as u64
lbb_17605:
    stxdw [r10-0x8], r6                     
    mov64 r1, r10                                   r1 = r10
    add64 r1, -48                                   r1 += -48   ///  r1 = r1.wrapping_add(-48 as i32 as i64 as u64)
    mov64 r4, r10                                   r4 = r10
    add64 r4, -24                                   r4 += -24   ///  r4 = r4.wrapping_add(-24 as i32 as i64 as u64)
    mov64 r3, r9                                    r3 = r9
    call function_17517                     
    ldxdw r1, [r10-0x30]                    
    jne r1, 0, lbb_17619                            if r1 != (0 as i32 as i64 as u64) { pc += 5 }
    ldxdw r1, [r10-0x28]                    
    ldxdw r2, [r10-0x58]                    
    stxdw [r2+0x8], r7                      
    stxdw [r2+0x0], r1                      
    exit                                    
lbb_17619:
    ldxdw r2, [r10-0x20]                    
    jne r2, 0, lbb_17623                            if r2 != (0 as i32 as i64 as u64) { pc += 2 }
lbb_17621:
    call function_18745                     
    syscall [invalid]                       
lbb_17623:
    ldxdw r1, [r10-0x28]                    
    call function_18762                     
    syscall [invalid]                       

function_17626:
    mov64 r6, r1                                    r6 = r1
    ldxdw r9, [r2+0x0]                      
    stxdw [r10-0x78], r6                    
    jne r9, 0, lbb_17654                            if r9 != (0 as i32 as i64 as u64) { pc += 24 }
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    stxdw [r10-0x10], r1                    
    stxdw [r10-0x18], r9                    
    mov64 r9, 8                                     r9 = 8 as i32 as i64 as u64
    stxdw [r10-0x20], r9                    
lbb_17635:
    mov64 r1, r2                                    r1 = r2
    add64 r1, r9                                    r1 += r9   ///  r1 = r1.wrapping_add(r9)
    ldxdw r1, [r1+0x0]                      
    ldxdw r3, [r10-0x10]                    
    ldxdw r4, [r10-0x78]                    
    stxdw [r4+0x18], r3                     
    ldxdw r3, [r10-0x18]                    
    stxdw [r4+0x10], r3                     
    ldxdw r3, [r10-0x20]                    
    stxdw [r4+0x8], r3                      
    add64 r9, 8                                     r9 += 8   ///  r9 = r9.wrapping_add(8 as i32 as i64 as u64)
    mov64 r3, r2                                    r3 = r2
    add64 r3, r9                                    r3 += r9   ///  r3 = r3.wrapping_add(r9)
    stxdw [r4+0x20], r3                     
    stxdw [r4+0x28], r1                     
    add64 r1, r9                                    r1 += r9   ///  r1 = r1.wrapping_add(r9)
    add64 r2, r1                                    r2 += r1   ///  r2 = r2.wrapping_add(r1)
    stxdw [r4+0x0], r2                      
    exit                                    
lbb_17654:
    stxdw [r10-0x48], r2                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -48                                   r1 += -48   ///  r1 = r1.wrapping_add(-48 as i32 as i64 as u64)
    mov64 r7, 0                                     r7 = 0 as i32 as i64 as u64
    mov64 r2, r9                                    r2 = r9
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
    mov64 r4, 48                                    r4 = 48 as i32 as i64 as u64
    mov64 r5, 0                                     r5 = 0 as i32 as i64 as u64
    call function_21911                     
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    ldxdw r2, [r10-0x28]                    
    jne r2, 0, lbb_17667                            if r2 != (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
lbb_17667:
    jne r1, 0, lbb_17669                            if r1 != (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r7, 8                                     r7 = 8 as i32 as i64 as u64
lbb_17669:
    and64 r1, 1                                     r1 &= 1   ///  r1 = r1.and(1)
    jne r1, 0, lbb_17889                            if r1 != (0 as i32 as i64 as u64) { pc += 218 }
    ldxdw r8, [r10-0x30]                    
    jeq r8, 0, lbb_17683                            if r8 == (0 as i32 as i64 as u64) { pc += 10 }
    mov64 r1, r8                                    r1 = r8
    mov64 r2, r7                                    r2 = r7
    call function_11635                     
    ldxdw r2, [r10-0x48]                    
    jeq r0, 0, lbb_17679                            if r0 == (0 as i32 as i64 as u64) { pc += 1 }
    ja lbb_17685                                    if true { pc += 6 }
lbb_17679:
    mov64 r1, r8                                    r1 = r8
    mov64 r2, r7                                    r2 = r7
    call function_18762                     
    syscall [invalid]                       
lbb_17683:
    mov64 r0, r7                                    r0 = r7
    ldxdw r2, [r10-0x48]                    
lbb_17685:
    stxdw [r10-0x68], r9                    
    stxdw [r10-0x18], r9                    
    mov64 r9, 8                                     r9 = 8 as i32 as i64 as u64
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    stxdw [r10-0x10], r1                    
    stxdw [r10-0x20], r0                    
    mov64 r4, 0                                     r4 = 0 as i32 as i64 as u64
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
    ja lbb_17722                                    if true { pc += 28 }
lbb_17694:
    mov64 r1, r4                                    r1 = r4
    mul64 r1, 48                                    r1 *= 48   ///  r1 = r1.wrapping_mul(48 as u64)
    mov64 r2, r0                                    r2 = r0
    add64 r2, r1                                    r2 += r1   ///  r2 = r2.wrapping_add(r1)
    ldxdw r1, [r10-0x60]                    
    stxb [r2+0x2a], r1                      
    stxb [r2+0x29], r6                      
    stxb [r2+0x28], r8                      
    stxdw [r2+0x20], r3                     
    ldxdw r1, [r10-0x58]                    
    stxdw [r2+0x18], r1                     
    stxdw [r2+0x10], r7                     
    ldxdw r1, [r10-0x50]                    
    stxdw [r2+0x8], r1                      
    stxdw [r2+0x0], r5                      
    ldxw r1, [r10-0x5]                      
    stxw [r2+0x2b], r1                      
    ldxb r1, [r10-0x1]                      
    stxb [r2+0x2f], r1                      
    add64 r4, 1                                     r4 += 1   ///  r4 = r4.wrapping_add(1 as i32 as i64 as u64)
    stxdw [r10-0x10], r4                    
    ldxdw r2, [r10-0x48]                    
lbb_17716:
    ldxdw r3, [r10-0x38]                    
    add64 r3, 1                                     r3 += 1   ///  r3 = r3.wrapping_add(1 as i32 as i64 as u64)
    add64 r9, 8                                     r9 += 8   ///  r9 = r9.wrapping_add(8 as i32 as i64 as u64)
    ldxdw r1, [r10-0x68]                    
    jgt r1, r3, lbb_17722                           if r1 > r3 { pc += 1 }
    ja lbb_17635                                    if true { pc += -87 }
lbb_17722:
    mov64 r1, r2                                    r1 = r2
    add64 r1, r9                                    r1 += r9   ///  r1 = r1.wrapping_add(r9)
    ldxb r1, [r1+0x0]                       
    stxdw [r10-0x38], r3                    
    stxdw [r10-0x40], r4                    
    jeq r1, 255, lbb_17785                          if r1 == (255 as i32 as i64 as u64) { pc += 57 }
    jgt r4, r1, lbb_17734                           if r4 > r1 { pc += 5 }
    mov64 r2, r4                                    r2 = r4
    lddw r3, 0x10002df88 --> b"\x00\x00\x00\x00\xa3\xcc\x02\x00\x11\x00\x00\x00\x00\x00\x00\x00P\x01\x00…        r3 load str located at 4295155592
    call function_19324                     
    syscall [invalid]                       
lbb_17734:
    mul64 r1, 48                                    r1 *= 48   ///  r1 = r1.wrapping_mul(48 as u64)
    mov64 r2, r0                                    r2 = r0
    add64 r2, r1                                    r2 += r1   ///  r2 = r2.wrapping_add(r1)
    ldxdw r7, [r2+0x8]                      
    ldxdw r5, [r7+0x0]                      
    mov64 r3, r5                                    r3 = r5
    add64 r3, 1                                     r3 += 1   ///  r3 = r3.wrapping_add(1 as i32 as i64 as u64)
    mov64 r4, 1                                     r4 = 1 as i32 as i64 as u64
    jgt r5, r3, lbb_17744                           if r5 > r3 { pc += 1 }
    mov64 r4, 0                                     r4 = 0 as i32 as i64 as u64
lbb_17744:
    ldxb r6, [r2+0x29]                      
    ldxb r8, [r2+0x28]                      
    ldxdw r5, [r2+0x0]                      
    stxdw [r10-0x50], r7                    
    stxdw [r7+0x0], r3                      
    jne r4, 1, lbb_17752                            if r4 != (1 as i32 as i64 as u64) { pc += 2 }
lbb_17750:
    syscall [invalid]                       
    syscall [invalid]                       
lbb_17752:
    mov64 r2, r0                                    r2 = r0
    add64 r2, r1                                    r2 += r1   ///  r2 = r2.wrapping_add(r1)
    ldxdw r7, [r2+0x10]                     
    ldxdw r4, [r7+0x0]                      
    mov64 r2, r4                                    r2 = r4
    add64 r2, 1                                     r2 += 1   ///  r2 = r2.wrapping_add(1 as i32 as i64 as u64)
    mov64 r3, 1                                     r3 = 1 as i32 as i64 as u64
    jgt r4, r2, lbb_17761                           if r4 > r2 { pc += 1 }
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
lbb_17761:
    stxdw [r7+0x0], r2                      
    jne r3, 1, lbb_17764                            if r3 != (1 as i32 as i64 as u64) { pc += 1 }
    ja lbb_17750                                    if true { pc += -14 }
lbb_17764:
    mov64 r2, r0                                    r2 = r0
    add64 r2, r1                                    r2 += r1   ///  r2 = r2.wrapping_add(r1)
    ldxdw r3, [r2+0x20]                     
    ldxb r1, [r2+0x2a]                      
    stxdw [r10-0x60], r1                    
    ldxdw r1, [r2+0x18]                     
    stxdw [r10-0x58], r1                    
    ldxdw r1, [r10-0x18]                    
    ldxdw r4, [r10-0x40]                    
    jne r4, r1, lbb_17694                           if r4 != r1 { pc += -80 }
    mov64 r1, r10                                   r1 = r10
    add64 r1, -32                                   r1 += -32   ///  r1 = r1.wrapping_add(-32 as i32 as i64 as u64)
    mov64 r2, r4                                    r2 = r4
    stxdw [r10-0x40], r5                    
    stxdw [r10-0x70], r3                    
    call function_17558                     
    ldxdw r3, [r10-0x70]                    
    ldxdw r5, [r10-0x40]                    
    ldxdw r0, [r10-0x20]                    
    ldxdw r4, [r10-0x10]                    
    ja lbb_17694                                    if true { pc += -91 }
lbb_17785:
    mov64 r6, r9                                    r6 = r9
    add64 r6, r2                                    r6 += r2   ///  r6 = r6.wrapping_add(r2)
    ldxb r1, [r6+0x3]                       
    stxdw [r10-0x60], r1                    
    ldxb r1, [r6+0x2]                       
    stxdw [r10-0x58], r1                    
    ldxb r1, [r6+0x1]                       
    stxdw [r10-0x50], r1                    
    mov64 r1, 32                                    r1 = 32 as i32 as i64 as u64
    mov64 r2, 8                                     r2 = 8 as i32 as i64 as u64
    call function_11635                     
    mov64 r7, r0                                    r7 = r0
    jne r7, 0, lbb_17800                            if r7 != (0 as i32 as i64 as u64) { pc += 2 }
    mov64 r1, 32                                    r1 = 32 as i32 as i64 as u64
    ja lbb_17886                                    if true { pc += 86 }
lbb_17800:
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    stxdw [r7+0x10], r1                     
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    stxdw [r7+0x8], r1                      
    stxdw [r7+0x0], r1                      
    mov64 r1, r6                                    r1 = r6
    add64 r1, 72                                    r1 += 72   ///  r1 = r1.wrapping_add(72 as i32 as i64 as u64)
    stxdw [r7+0x18], r1                     
    ldxdw r1, [r6+0x50]                     
    stxdw [r10-0x70], r1                    
    mov64 r1, 40                                    r1 = 40 as i32 as i64 as u64
    mov64 r2, 8                                     r2 = 8 as i32 as i64 as u64
    call function_11635                     
    mov64 r8, r0                                    r8 = r0
    jne r8, 0, lbb_17817                            if r8 != (0 as i32 as i64 as u64) { pc += 2 }
    mov64 r1, 40                                    r1 = 40 as i32 as i64 as u64
    ja lbb_17886                                    if true { pc += 69 }
lbb_17817:
    ldxdw r1, [r10-0x60]                    
    mov64 r3, r1                                    r3 = r1
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    mov64 r5, 1                                     r5 = 1 as i32 as i64 as u64
    ldxdw r4, [r10-0x40]                    
    jne r3, 0, lbb_17825                            if r3 != (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r5, 0                                     r5 = 0 as i32 as i64 as u64
lbb_17825:
    ldxdw r3, [r10-0x58]                    
    stxdw [r8+0x10], r2                     
    mov64 r2, 1                                     r2 = 1 as i32 as i64 as u64
    jne r3, 0, lbb_17830                            if r3 != (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
lbb_17830:
    stxdw [r10-0x58], r2                    
    ldxdw r2, [r10-0x50]                    
    mov64 r3, 1                                     r3 = 1 as i32 as i64 as u64
    jne r2, 0, lbb_17835                            if r2 != (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
lbb_17835:
    stxdw [r10-0x50], r3                    
    mov64 r2, r6                                    r2 = r6
    add64 r2, 40                                    r2 += 40   ///  r2 = r2.wrapping_add(40 as i32 as i64 as u64)
    stxdw [r10-0x60], r2                    
    add64 r6, 8                                     r6 += 8   ///  r6 = r6.wrapping_add(8 as i32 as i64 as u64)
    stxdw [r8+0x8], r1                      
    stxdw [r8+0x0], r1                      
    mov64 r1, r9                                    r1 = r9
    ldxdw r2, [r10-0x48]                    
    add64 r1, r2                                    r1 += r2   ///  r1 = r1.wrapping_add(r2)
    add64 r1, 88                                    r1 += 88   ///  r1 = r1.wrapping_add(88 as i32 as i64 as u64)
    stxdw [r8+0x18], r1                     
    ldxdw r1, [r10-0x70]                    
    stxdw [r8+0x20], r1                     
    add64 r9, r1                                    r9 += r1   ///  r9 = r9.wrapping_add(r1)
    add64 r9, 10335                                 r9 += 10335   ///  r9 = r9.wrapping_add(10335 as i32 as i64 as u64)
    and64 r9, -8                                    r9 &= -8   ///  r9 = r9.and(-8)
    mov64 r1, r2                                    r1 = r2
    add64 r1, r9                                    r1 += r9   ///  r1 = r1.wrapping_add(r9)
    ldxdw r1, [r1+0x0]                      
    stxdw [r10-0x70], r1                    
    ldxdw r1, [r10-0x18]                    
    jne r4, r1, lbb_17866                           if r4 != r1 { pc += 8 }
    mov64 r1, r10                                   r1 = r10
    add64 r1, -32                                   r1 += -32   ///  r1 = r1.wrapping_add(-32 as i32 as i64 as u64)
    mov64 r2, r4                                    r2 = r4
    stxdw [r10-0x40], r5                    
    call function_17558                     
    ldxdw r5, [r10-0x40]                    
    ldxdw r2, [r10-0x48]                    
    ldxdw r4, [r10-0x10]                    
lbb_17866:
    mov64 r1, r4                                    r1 = r4
    mul64 r1, 48                                    r1 *= 48   ///  r1 = r1.wrapping_mul(48 as u64)
    ldxdw r0, [r10-0x20]                    
    mov64 r3, r0                                    r3 = r0
    add64 r3, r1                                    r3 += r1   ///  r3 = r3.wrapping_add(r1)
    stxb [r3+0x2a], r5                      
    ldxdw r1, [r10-0x58]                    
    stxb [r3+0x29], r1                      
    ldxdw r1, [r10-0x50]                    
    stxb [r3+0x28], r1                      
    ldxdw r1, [r10-0x70]                    
    stxdw [r3+0x20], r1                     
    ldxdw r1, [r10-0x60]                    
    stxdw [r3+0x18], r1                     
    stxdw [r3+0x10], r8                     
    stxdw [r3+0x8], r7                      
    stxdw [r3+0x0], r6                      
    add64 r4, 1                                     r4 += 1   ///  r4 = r4.wrapping_add(1 as i32 as i64 as u64)
    stxdw [r10-0x10], r4                    
    ja lbb_17716                                    if true { pc += -170 }
lbb_17886:
    mov64 r2, 8                                     r2 = 8 as i32 as i64 as u64
    call function_18762                     
    syscall [invalid]                       
lbb_17889:
    call function_18745                     
    syscall [invalid]                       

function_17891:
    mov64 r3, 32                                    r3 = 32 as i32 as i64 as u64
    stxdw [r1+0x8], r3                      
    stxdw [r1+0x0], r2                      
    exit                                    

function_17895:
    mov64 r6, r3                                    r6 = r3
    mov64 r9, r2                                    r9 = r2
    mov64 r7, r1                                    r7 = r1
    jgt r6, 44, lbb_17910                           if r6 > (44 as i32 as i64 as u64) { pc += 11 }
    mov64 r8, 1                                     r8 = 1 as i32 as i64 as u64
    jeq r6, 0, lbb_17912                            if r6 == (0 as i32 as i64 as u64) { pc += 11 }
    mov64 r1, r6                                    r1 = r6
    mov64 r2, 1                                     r2 = 1 as i32 as i64 as u64
    call function_11641                     
    mov64 r8, r0                                    r8 = r0
    jne r8, 0, lbb_17912                            if r8 != (0 as i32 as i64 as u64) { pc += 6 }
    mov64 r1, r6                                    r1 = r6
    mov64 r2, 1                                     r2 = 1 as i32 as i64 as u64
    call function_18762                     
    syscall [invalid]                       
lbb_17910:
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    ja lbb_17938                                    if true { pc += 26 }
lbb_17912:
    lddw r1, 0x10002cbe9 --> b"123456789ABCDEFGHJKLMNPQRSTUVWXYZabcdefghijkmnopqr"        r1 load str located at 4295150569
    stxdw [r10-0xb8], r1                    
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    stxb [r10-0xc0], r1                     
    stxdw [r10-0xc8], r6                    
    stxdw [r10-0xd0], r9                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -192                                  r1 += -192   ///  r1 = r1.wrapping_add(-192 as i32 as i64 as u64)
    stxdw [r10-0xff8], r1                   
    stxdw [r10-0x1000], r6                  
    mov64 r1, r10                                   r1 = r10
    add64 r1, -232                                  r1 += -232   ///  r1 = r1.wrapping_add(-232 as i32 as i64 as u64)
    mov64 r5, r10                                   r5 = r10
    mov64 r2, r9                                    r2 = r9
    mov64 r3, r6                                    r3 = r6
    mov64 r4, r8                                    r4 = r8
    call function_18416                     
    ldxdw r1, [r10-0xe8]                    
    jeq r1, 0, lbb_17940                            if r1 == (0 as i32 as i64 as u64) { pc += 8 }
    jeq r6, 0, lbb_17937                            if r6 == (0 as i32 as i64 as u64) { pc += 4 }
    mov64 r1, r8                                    r1 = r8
    mov64 r2, r6                                    r2 = r6
    mov64 r3, 1                                     r3 = 1 as i32 as i64 as u64
    call function_11637                     
lbb_17937:
    mov64 r1, 257                                   r1 = 257 as i32 as i64 as u64
lbb_17938:
    stxh [r7+0x0], r1                       
lbb_17939:
    exit                                    
lbb_17940:
    ldxdw r1, [r10-0xe0]                    
    mov64 r2, r6                                    r2 = r6
    jgt r1, r6, lbb_17944                           if r1 > r6 { pc += 1 }
    mov64 r2, r1                                    r2 = r1
lbb_17944:
    mov64 r1, r7                                    r1 = r7
    add64 r1, 1                                     r1 += 1   ///  r1 = r1.wrapping_add(1 as i32 as i64 as u64)
    jeq r2, 32, lbb_17948                           if r2 == (32 as i32 as i64 as u64) { pc += 1 }
    ja lbb_17958                                    if true { pc += 10 }
lbb_17948:
    ldxdw r2, [r8+0x18]                     
    stxdw [r1+0x18], r2                     
    ldxdw r2, [r8+0x10]                     
    stxdw [r1+0x10], r2                     
    ldxdw r2, [r8+0x8]                      
    stxdw [r1+0x8], r2                      
    ldxdw r2, [r8+0x0]                      
    stxdw [r1+0x0], r2                      
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    ja lbb_17961                                    if true { pc += 3 }
lbb_17958:
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
    stxb [r1+0x0], r2                       
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
lbb_17961:
    stxb [r7+0x0], r1                       
    jeq r6, 0, lbb_17939                            if r6 == (0 as i32 as i64 as u64) { pc += -24 }
    mov64 r1, r8                                    r1 = r8
    mov64 r2, r6                                    r2 = r6
    mov64 r3, 1                                     r3 = 1 as i32 as i64 as u64
    call function_11637                     
    ja lbb_17939                                    if true { pc += -29 }

function_17968:
    ldxdw r3, [r2+0x18]                     
    stxdw [r1+0x18], r3                     
    ldxdw r3, [r2+0x10]                     
    stxdw [r1+0x10], r3                     
    ldxdw r3, [r2+0x8]                      
    stxdw [r1+0x8], r3                      
    ldxdw r2, [r2+0x0]                      
    stxdw [r1+0x0], r2                      
    exit                                    

function_17977:
    ldxdw r3, [r2+0x18]                     
    stxdw [r1+0x18], r3                     
    ldxdw r3, [r2+0x10]                     
    stxdw [r1+0x10], r3                     
    ldxdw r3, [r2+0x8]                      
    stxdw [r1+0x8], r3                      
    ldxdw r2, [r2+0x0]                      
    stxdw [r1+0x0], r2                      
    exit                                    

function_17986:
    ldxdw r4, [r2+0x18]                     
    stxdw [r1+0x18], r4                     
    ldxdw r4, [r2+0x10]                     
    stxdw [r1+0x10], r4                     
    ldxdw r4, [r2+0x8]                      
    stxdw [r1+0x8], r4                      
    ldxdw r2, [r2+0x0]                      
    stxdw [r1+0x0], r2                      
    mov64 r2, 1                                     r2 = 1 as i32 as i64 as u64
    stxb [r1+0x21], r2                      
    stxb [r1+0x20], r3                      
    exit                                    

function_17998:
    ldxdw r4, [r2+0x18]                     
    stxdw [r1+0x18], r4                     
    ldxdw r4, [r2+0x10]                     
    stxdw [r1+0x10], r4                     
    ldxdw r4, [r2+0x8]                      
    stxdw [r1+0x8], r4                      
    ldxdw r2, [r2+0x0]                      
    stxdw [r1+0x0], r2                      
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
    stxb [r1+0x21], r2                      
    stxb [r1+0x20], r3                      
    exit                                    

function_18010:
    stxdw [r10-0x40], r4                    
    stxdw [r10-0x48], r3                    
    stxdw [r10-0x58], r1                    
    stxdw [r10-0x50], r2                    
    ldxdw r1, [r2+0x10]                     
    ldxdw r2, [r5-0xff8]                    
    stxdw [r10-0x80], r2                    
    ldxdw r2, [r5-0x1000]                   
    stxdw [r10-0x88], r2                    
    jeq r1, 0, lbb_18096                            if r1 == (0 as i32 as i64 as u64) { pc += 76 }
    ldxdw r2, [r10-0x50]                    
    ldxdw r7, [r2+0x0]                      
    mul64 r1, 34                                    r1 *= 34   ///  r1 = r1.wrapping_mul(34 as u64)
    mov64 r2, r7                                    r2 = r7
    add64 r2, r1                                    r2 += r1   ///  r2 = r2.wrapping_add(r1)
    stxdw [r10-0x18], r2                    
    ldxdw r1, [r10-0x40]                    
    mul64 r1, 48                                    r1 *= 48   ///  r1 = r1.wrapping_mul(48 as u64)
    stxdw [r10-0x8], r1                     
    ldxdw r1, [r10-0x48]                    
    add64 r1, -40                                   r1 += -40   ///  r1 = r1.wrapping_add(-40 as i32 as i64 as u64)
    stxdw [r10-0x10], r1                    
    ja lbb_18055                                    if true { pc += 22 }
lbb_18033:
    ldxdw r1, [r9+0x0]                      
    ldxdw r2, [r1+0x10]                     
    mov64 r4, 0                                     r4 = 0 as i32 as i64 as u64
    jne r2, 0, lbb_18111                            if r2 != (0 as i32 as i64 as u64) { pc += 74 }
    mov64 r2, r1                                    r2 = r1
    add64 r2, 16                                    r2 += 16   ///  r2 = r2.wrapping_add(16 as i32 as i64 as u64)
    stxdw [r10-0x20], r2                    
    stxdw [r2+0x0], r4                      
    ldxdw r2, [r9+0x8]                      
    ldxdw r3, [r2+0x10]                     
    jeq r3, 0, lbb_18045                            if r3 == (0 as i32 as i64 as u64) { pc += 1 }
    ja lbb_18118                                    if true { pc += 73 }
lbb_18045:
    mov64 r3, r2                                    r3 = r2
    add64 r3, 16                                    r3 += 16   ///  r3 = r3.wrapping_add(16 as i32 as i64 as u64)
    stxdw [r10-0x28], r3                    
    stxdw [r2+0x10], r4                     
    add64 r2, 24                                    r2 += 24   ///  r2 = r2.wrapping_add(24 as i32 as i64 as u64)
    add64 r1, 24                                    r1 += 24   ///  r1 = r1.wrapping_add(24 as i32 as i64 as u64)
    stxdw [r10-0x30], r2                    
    stxdw [r10-0x38], r1                    
lbb_18053:
    ldxdw r1, [r10-0x18]                    
    jeq r7, r1, lbb_18096                           if r7 == r1 { pc += 41 }
lbb_18055:
    mov64 r6, r7                                    r6 = r7
    add64 r7, 34                                    r7 += 34   ///  r7 = r7.wrapping_add(34 as i32 as i64 as u64)
    ldxdw r8, [r10-0x8]                     
    ldxdw r9, [r10-0x10]                    
lbb_18059:
    jne r8, 0, lbb_18061                            if r8 != (0 as i32 as i64 as u64) { pc += 1 }
    ja lbb_18053                                    if true { pc += -8 }
lbb_18061:
    ldxdw r2, [r9+0x28]                     
    mov64 r1, r6                                    r1 = r6
    mov64 r3, 32                                    r3 = 32 as i32 as i64 as u64
    call function_21867                     
    add64 r8, -48                                   r8 += -48   ///  r8 = r8.wrapping_add(-48 as i32 as i64 as u64)
    add64 r9, 48                                    r9 += 48   ///  r9 = r9.wrapping_add(48 as i32 as i64 as u64)
    lsh64 r0, 32                                    r0 <<= 32   ///  r0 = r0.wrapping_shl(32)
    rsh64 r0, 32                                    r0 >>= 32   ///  r0 = r0.wrapping_shr(32)
    jne r0, 0, lbb_18059                            if r0 != (0 as i32 as i64 as u64) { pc += -11 }
    ldxb r1, [r6+0x21]                      
    jne r1, 0, lbb_18033                            if r1 != (0 as i32 as i64 as u64) { pc += -39 }
    ldxdw r1, [r9+0x0]                      
    ldxdw r2, [r1+0x10]                     
    lddw r3, 0x7fffffffffffffff                     r3 load str located at 9223372036854775807
    jgt r3, r2, lbb_18078                           if r3 > r2 { pc += 1 }
    ja lbb_18125                                    if true { pc += 47 }
lbb_18078:
    mov64 r3, r1                                    r3 = r1
    add64 r3, 16                                    r3 += 16   ///  r3 = r3.wrapping_add(16 as i32 as i64 as u64)
    stxdw [r10-0x60], r3                    
    stxdw [r3+0x0], r2                      
    ldxdw r2, [r9+0x8]                      
    ldxdw r3, [r2+0x10]                     
    lddw r4, 0x7fffffffffffffff                     r4 load str located at 9223372036854775807
    jgt r4, r3, lbb_18088                           if r4 > r3 { pc += 1 }
    ja lbb_18132                                    if true { pc += 44 }
lbb_18088:
    mov64 r3, r2                                    r3 = r2
    add64 r3, 16                                    r3 += 16   ///  r3 = r3.wrapping_add(16 as i32 as i64 as u64)
    stxdw [r10-0x70], r3                    
    add64 r2, 24                                    r2 += 24   ///  r2 = r2.wrapping_add(24 as i32 as i64 as u64)
    add64 r1, 24                                    r1 += 24   ///  r1 = r1.wrapping_add(24 as i32 as i64 as u64)
    stxdw [r10-0x68], r1                    
    stxdw [r10-0x78], r2                    
    ja lbb_18053                                    if true { pc += -43 }
lbb_18096:
    ldxdw r1, [r10-0x50]                    
    ldxdw r2, [r10-0x48]                    
    ldxdw r3, [r10-0x40]                    
    ldxdw r4, [r10-0x88]                    
    ldxdw r5, [r10-0x80]                    
    syscall [invalid]                       
    jne r0, 0, lbb_18107                            if r0 != (0 as i32 as i64 as u64) { pc += 4 }
    mov64 r1, 20                                    r1 = 20 as i32 as i64 as u64
    ldxdw r2, [r10-0x58]                    
    stxw [r2+0x0], r1                       
    ja lbb_18141                                    if true { pc += 34 }
lbb_18107:
    ldxdw r1, [r10-0x58]                    
    mov64 r2, r0                                    r2 = r0
    call function_18232                     
    ja lbb_18141                                    if true { pc += 30 }
lbb_18111:
    ldxdw r2, [r10-0x58]                    
    ldxdw r1, [r10-0x20]                    
    stxdw [r2+0x8], r1                      
    lddw r1, 0xffffffff00000000                     r1 load str located at -4294967296
    ldxdw r3, [r10-0x38]                    
    ja lbb_18138                                    if true { pc += 20 }
lbb_18118:
    ldxdw r2, [r10-0x58]                    
    ldxdw r1, [r10-0x28]                    
    stxdw [r2+0x8], r1                      
    lddw r1, 0xffffffff00000000                     r1 load str located at -4294967296
    ldxdw r3, [r10-0x30]                    
    ja lbb_18138                                    if true { pc += 13 }
lbb_18125:
    ldxdw r2, [r10-0x58]                    
    ldxdw r1, [r10-0x60]                    
    stxdw [r2+0x8], r1                      
    lddw r1, 0xffffffff00000000                     r1 load str located at -4294967296
    ldxdw r3, [r10-0x68]                    
    ja lbb_18138                                    if true { pc += 6 }
lbb_18132:
    ldxdw r2, [r10-0x58]                    
    ldxdw r1, [r10-0x70]                    
    stxdw [r2+0x8], r1                      
    lddw r1, 0xffffffff00000000                     r1 load str located at -4294967296
    ldxdw r3, [r10-0x78]                    
lbb_18138:
    and64 r3, r1                                    r3 &= r1   ///  r3 = r3.and(r1)
    or64 r3, 11                                     r3 |= 11   ///  r3 = r3.or(11)
    stxdw [r2+0x0], r3                      
lbb_18141:
    exit                                    

function_18142:
    ldxw r2, [r1+0x0]                       
    jsgt r2, 9, lbb_18150                           if (r2 as i64) > (9 as i32 as i64) { pc += 6 }
    jsgt r2, 4, lbb_18156                           if (r2 as i64) > (4 as i32 as i64) { pc += 11 }
    jsgt r2, 1, lbb_18166                           if (r2 as i64) > (1 as i32 as i64) { pc += 20 }
    jeq r2, 0, lbb_18186                            if r2 == (0 as i32 as i64 as u64) { pc += 39 }
    lddw r6, 0x200000000                            r6 load str located at 8589934592
    ja lbb_18224                                    if true { pc += 74 }
lbb_18150:
    jsgt r2, 14, lbb_18161                          if (r2 as i64) > (14 as i32 as i64) { pc += 10 }
    jsgt r2, 11, lbb_18171                          if (r2 as i64) > (11 as i32 as i64) { pc += 19 }
    jeq r2, 10, lbb_18192                           if r2 == (10 as i32 as i64 as u64) { pc += 39 }
    lddw r6, 0xc00000000                            r6 load str located at 51539607552
    ja lbb_18224                                    if true { pc += 68 }
lbb_18156:
    jsgt r2, 6, lbb_18176                           if (r2 as i64) > (6 as i32 as i64) { pc += 19 }
    jeq r2, 5, lbb_18195                            if r2 == (5 as i32 as i64 as u64) { pc += 37 }
    lddw r6, 0x700000000                            r6 load str located at 30064771072
    ja lbb_18224                                    if true { pc += 63 }
lbb_18161:
    jsgt r2, 16, lbb_18181                          if (r2 as i64) > (16 as i32 as i64) { pc += 19 }
    jeq r2, 15, lbb_18198                           if r2 == (15 as i32 as i64 as u64) { pc += 35 }
    lddw r6, 0x1100000000                           r6 load str located at 73014444032
    ja lbb_18224                                    if true { pc += 58 }
lbb_18166:
    jeq r2, 2, lbb_18201                            if r2 == (2 as i32 as i64 as u64) { pc += 34 }
    jeq r2, 3, lbb_18204                            if r2 == (3 as i32 as i64 as u64) { pc += 36 }
    lddw r6, 0x500000000                            r6 load str located at 21474836480
    ja lbb_18224                                    if true { pc += 53 }
lbb_18171:
    jeq r2, 12, lbb_18207                           if r2 == (12 as i32 as i64 as u64) { pc += 35 }
    jeq r2, 13, lbb_18210                           if r2 == (13 as i32 as i64 as u64) { pc += 37 }
    lddw r6, 0xf00000000                            r6 load str located at 64424509440
    ja lbb_18224                                    if true { pc += 48 }
lbb_18176:
    jeq r2, 7, lbb_18213                            if r2 == (7 as i32 as i64 as u64) { pc += 36 }
    jeq r2, 8, lbb_18216                            if r2 == (8 as i32 as i64 as u64) { pc += 38 }
    lddw r6, 0xa00000000                            r6 load str located at 42949672960
    ja lbb_18224                                    if true { pc += 43 }
lbb_18181:
    jeq r2, 17, lbb_18219                           if r2 == (17 as i32 as i64 as u64) { pc += 37 }
    jeq r2, 18, lbb_18222                           if r2 == (18 as i32 as i64 as u64) { pc += 39 }
    lddw r6, 0x1400000000                           r6 load str located at 85899345920
    ja lbb_18224                                    if true { pc += 38 }
lbb_18186:
    lddw r6, 0x100000000                            r6 load str located at 4294967296
    ldxw r3, [r1+0x4]                       
    jeq r3, 0, lbb_18224                            if r3 == (0 as i32 as i64 as u64) { pc += 34 }
    mov64 r6, r3                                    r6 = r3
    ja lbb_18224                                    if true { pc += 32 }
lbb_18192:
    lddw r6, 0xb00000000                            r6 load str located at 47244640256
    ja lbb_18224                                    if true { pc += 29 }
lbb_18195:
    lddw r6, 0x600000000                            r6 load str located at 25769803776
    ja lbb_18224                                    if true { pc += 26 }
lbb_18198:
    lddw r6, 0x1000000000                           r6 load str located at 68719476736
    ja lbb_18224                                    if true { pc += 23 }
lbb_18201:
    lddw r6, 0x300000000                            r6 load str located at 12884901888
    ja lbb_18224                                    if true { pc += 20 }
lbb_18204:
    lddw r6, 0x400000000                            r6 load str located at 17179869184
    ja lbb_18224                                    if true { pc += 17 }
lbb_18207:
    lddw r6, 0xd00000000                            r6 load str located at 55834574848
    ja lbb_18224                                    if true { pc += 14 }
lbb_18210:
    lddw r6, 0xe00000000                            r6 load str located at 60129542144
    ja lbb_18224                                    if true { pc += 11 }
lbb_18213:
    lddw r6, 0x800000000                            r6 load str located at 34359738368
    ja lbb_18224                                    if true { pc += 8 }
lbb_18216:
    lddw r6, 0x900000000                            r6 load str located at 38654705664
    ja lbb_18224                                    if true { pc += 5 }
lbb_18219:
    lddw r6, 0x1200000000                           r6 load str located at 77309411328
    ja lbb_18224                                    if true { pc += 2 }
lbb_18222:
    lddw r6, 0x1300000000                           r6 load str located at 81604378624
lbb_18224:
    jne r2, 14, lbb_18230                           if r2 != (14 as i32 as i64 as u64) { pc += 5 }
    ldxdw r2, [r1+0x10]                     
    jeq r2, 0, lbb_18230                            if r2 == (0 as i32 as i64 as u64) { pc += 3 }
    ldxdw r1, [r1+0x8]                      
    mov64 r3, 1                                     r3 = 1 as i32 as i64 as u64
    call function_11637                     
lbb_18230:
    mov64 r0, r6                                    r0 = r6
    exit                                    

function_18232:
    mov64 r6, r1                                    r6 = r1
    lddw r3, 0xffffffff00000000                     r3 load str located at -4294967296
    mov64 r1, r2                                    r1 = r2
    add64 r1, r3                                    r1 += r3   ///  r1 = r1.wrapping_add(r3)
    mov64 r3, r1                                    r3 = r1
    rsh64 r3, 32                                    r3 >>= 32   ///  r3 = r3.wrapping_shr(32)
    lsh64 r1, 32                                    r1 <<= 32   ///  r1 = r1.wrapping_shl(32)
    or64 r1, r3                                     r1 |= r3   ///  r1 = r1.or(r3)
    jsgt r1, 9, lbb_18248                           if (r1 as i64) > (9 as i32 as i64) { pc += 6 }
    jsgt r1, 4, lbb_18255                           if (r1 as i64) > (4 as i32 as i64) { pc += 12 }
    jsgt r1, 1, lbb_18267                           if (r1 as i64) > (1 as i32 as i64) { pc += 23 }
    jeq r1, 0, lbb_18298                            if r1 == (0 as i32 as i64 as u64) { pc += 53 }
    mov64 r3, 1                                     r3 = 1 as i32 as i64 as u64
    jeq r1, 1, lbb_18333                            if r1 == (1 as i32 as i64 as u64) { pc += 86 }
    ja lbb_18295                                    if true { pc += 47 }
lbb_18248:
    jsgt r1, 14, lbb_18261                          if (r1 as i64) > (14 as i32 as i64) { pc += 12 }
    jsgt r1, 11, lbb_18273                          if (r1 as i64) > (11 as i32 as i64) { pc += 23 }
    jeq r1, 10, lbb_18301                           if r1 == (10 as i32 as i64 as u64) { pc += 50 }
    jeq r1, 11, lbb_18253                           if r1 == (11 as i32 as i64 as u64) { pc += 1 }
    ja lbb_18295                                    if true { pc += 42 }
lbb_18253:
    mov64 r3, 11                                    r3 = 11 as i32 as i64 as u64
    ja lbb_18333                                    if true { pc += 78 }
lbb_18255:
    jsgt r1, 6, lbb_18286                           if (r1 as i64) > (6 as i32 as i64) { pc += 30 }
    jeq r1, 5, lbb_18303                            if r1 == (5 as i32 as i64 as u64) { pc += 46 }
    jeq r1, 6, lbb_18259                            if r1 == (6 as i32 as i64 as u64) { pc += 1 }
    ja lbb_18295                                    if true { pc += 36 }
lbb_18259:
    mov64 r3, 6                                     r3 = 6 as i32 as i64 as u64
    ja lbb_18333                                    if true { pc += 72 }
lbb_18261:
    jsgt r1, 16, lbb_18292                          if (r1 as i64) > (16 as i32 as i64) { pc += 30 }
    jeq r1, 15, lbb_18305                           if r1 == (15 as i32 as i64 as u64) { pc += 42 }
    jeq r1, 16, lbb_18265                           if r1 == (16 as i32 as i64 as u64) { pc += 1 }
    ja lbb_18295                                    if true { pc += 30 }
lbb_18265:
    mov64 r3, 16                                    r3 = 16 as i32 as i64 as u64
    ja lbb_18333                                    if true { pc += 66 }
lbb_18267:
    jeq r1, 2, lbb_18307                            if r1 == (2 as i32 as i64 as u64) { pc += 39 }
    jeq r1, 3, lbb_18309                            if r1 == (3 as i32 as i64 as u64) { pc += 40 }
    jeq r1, 4, lbb_18271                            if r1 == (4 as i32 as i64 as u64) { pc += 1 }
    ja lbb_18295                                    if true { pc += 24 }
lbb_18271:
    mov64 r3, 4                                     r3 = 4 as i32 as i64 as u64
    ja lbb_18333                                    if true { pc += 60 }
lbb_18273:
    jeq r1, 12, lbb_18311                           if r1 == (12 as i32 as i64 as u64) { pc += 37 }
    jeq r1, 13, lbb_18313                           if r1 == (13 as i32 as i64 as u64) { pc += 38 }
    jeq r1, 14, lbb_18277                           if r1 == (14 as i32 as i64 as u64) { pc += 1 }
    ja lbb_18295                                    if true { pc += 18 }
lbb_18277:
    mov64 r7, 7                                     r7 = 7 as i32 as i64 as u64
    mov64 r1, 7                                     r1 = 7 as i32 as i64 as u64
    mov64 r2, 1                                     r2 = 1 as i32 as i64 as u64
    call function_11635                     
    jne r0, 0, lbb_18325                            if r0 != (0 as i32 as i64 as u64) { pc += 43 }
    mov64 r1, 7                                     r1 = 7 as i32 as i64 as u64
    mov64 r2, 1                                     r2 = 1 as i32 as i64 as u64
    call function_18762                     
    syscall [invalid]                       
lbb_18286:
    jeq r1, 7, lbb_18315                            if r1 == (7 as i32 as i64 as u64) { pc += 28 }
    jeq r1, 8, lbb_18317                            if r1 == (8 as i32 as i64 as u64) { pc += 29 }
    jeq r1, 9, lbb_18290                            if r1 == (9 as i32 as i64 as u64) { pc += 1 }
    ja lbb_18295                                    if true { pc += 5 }
lbb_18290:
    mov64 r3, 9                                     r3 = 9 as i32 as i64 as u64
    ja lbb_18333                                    if true { pc += 41 }
lbb_18292:
    jeq r1, 17, lbb_18319                           if r1 == (17 as i32 as i64 as u64) { pc += 26 }
    jeq r1, 18, lbb_18321                           if r1 == (18 as i32 as i64 as u64) { pc += 27 }
    jeq r1, 19, lbb_18323                           if r1 == (19 as i32 as i64 as u64) { pc += 28 }
lbb_18295:
    stxw [r6+0x4], r2                       
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
    ja lbb_18333                                    if true { pc += 35 }
lbb_18298:
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
    stxw [r6+0x4], r3                       
    ja lbb_18333                                    if true { pc += 32 }
lbb_18301:
    mov64 r3, 10                                    r3 = 10 as i32 as i64 as u64
    ja lbb_18333                                    if true { pc += 30 }
lbb_18303:
    mov64 r3, 5                                     r3 = 5 as i32 as i64 as u64
    ja lbb_18333                                    if true { pc += 28 }
lbb_18305:
    mov64 r3, 15                                    r3 = 15 as i32 as i64 as u64
    ja lbb_18333                                    if true { pc += 26 }
lbb_18307:
    mov64 r3, 2                                     r3 = 2 as i32 as i64 as u64
    ja lbb_18333                                    if true { pc += 24 }
lbb_18309:
    mov64 r3, 3                                     r3 = 3 as i32 as i64 as u64
    ja lbb_18333                                    if true { pc += 22 }
lbb_18311:
    mov64 r3, 12                                    r3 = 12 as i32 as i64 as u64
    ja lbb_18333                                    if true { pc += 20 }
lbb_18313:
    mov64 r3, 13                                    r3 = 13 as i32 as i64 as u64
    ja lbb_18333                                    if true { pc += 18 }
lbb_18315:
    mov64 r3, 7                                     r3 = 7 as i32 as i64 as u64
    ja lbb_18333                                    if true { pc += 16 }
lbb_18317:
    mov64 r3, 8                                     r3 = 8 as i32 as i64 as u64
    ja lbb_18333                                    if true { pc += 14 }
lbb_18319:
    mov64 r3, 17                                    r3 = 17 as i32 as i64 as u64
    ja lbb_18333                                    if true { pc += 12 }
lbb_18321:
    mov64 r3, 18                                    r3 = 18 as i32 as i64 as u64
    ja lbb_18333                                    if true { pc += 10 }
lbb_18323:
    mov64 r3, 19                                    r3 = 19 as i32 as i64 as u64
    ja lbb_18333                                    if true { pc += 8 }
lbb_18325:
    mov64 r1, 1853321070                            r1 = 1853321070 as i32 as i64 as u64
    stxw [r0+0x3], r1                       
    mov64 r1, 1852534357                            r1 = 1852534357 as i32 as i64 as u64
    stxw [r0+0x0], r1                       
    stxdw [r6+0x18], r7                     
    stxdw [r6+0x10], r7                     
    stxdw [r6+0x8], r0                      
    mov64 r3, 14                                    r3 = 14 as i32 as i64 as u64
lbb_18333:
    stxw [r6+0x0], r3                       
    exit                                    

function_18335:
    mov64 r6, r1                                    r6 = r1
    jgt r3, 16, lbb_18347                           if r3 > (16 as i32 as i64 as u64) { pc += 10 }
    mov64 r1, r3                                    r1 = r3
    lsh64 r1, 4                                     r1 <<= 4   ///  r1 = r1.wrapping_shl(4)
    mov64 r5, 33                                    r5 = 33 as i32 as i64 as u64
    mov64 r0, r2                                    r0 = r2
lbb_18341:
    jne r1, 0, lbb_18343                            if r1 != (0 as i32 as i64 as u64) { pc += 1 }
    ja lbb_18350                                    if true { pc += 7 }
lbb_18343:
    add64 r1, -16                                   r1 += -16   ///  r1 = r1.wrapping_add(-16 as i32 as i64 as u64)
    ldxdw r7, [r0+0x8]                      
    add64 r0, 16                                    r0 += 16   ///  r0 = r0.wrapping_add(16 as i32 as i64 as u64)
    jgt r5, r7, lbb_18341                           if r5 > r7 { pc += -6 }
lbb_18347:
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    stxh [r6+0x0], r1                       
lbb_18349:
    exit                                    
lbb_18350:
    mov64 r7, 0                                     r7 = 0 as i32 as i64 as u64
    stxdw [r10-0x8], r7                     
    stxdw [r10-0x10], r7                    
    stxdw [r10-0x18], r7                    
    stxdw [r10-0x20], r7                    
    mov64 r5, r10                                   r5 = r10
    add64 r5, -32                                   r5 += -32   ///  r5 = r5.wrapping_add(-32 as i32 as i64 as u64)
    mov64 r1, r2                                    r1 = r2
    mov64 r2, r3                                    r2 = r3
    mov64 r3, r4                                    r3 = r4
    mov64 r4, r5                                    r4 = r5
    syscall [invalid]                       
    jeq r0, 0, lbb_18369                            if r0 == (0 as i32 as i64 as u64) { pc += 6 }
    jeq r0, 1, lbb_18365                            if r0 == (1 as i32 as i64 as u64) { pc += 1 }
    ja lbb_18379                                    if true { pc += 14 }
lbb_18365:
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    stxb [r6+0x1], r1                       
    stxb [r6+0x0], r1                       
    ja lbb_18349                                    if true { pc += -20 }
lbb_18369:
    ldxdw r1, [r10-0x8]                     
    stxdw [r6+0x19], r1                     
    ldxdw r1, [r10-0x10]                    
    stxdw [r6+0x11], r1                     
    ldxdw r1, [r10-0x18]                    
    stxdw [r6+0x9], r1                      
    ldxdw r1, [r10-0x20]                    
    stxdw [r6+0x1], r1                      
    stxb [r6+0x0], r7                       
    ja lbb_18349                                    if true { pc += -30 }
lbb_18379:
    lddw r1, 0x10002dfa0 --> b"\x00\x00\x00\x00\xb4\xcc\x02\x00\x0d\x00\x00\x00\x00\x00\x00\x00.\x00\x00…        r1 load str located at 4295155616
    call function_17502                     
    syscall [invalid]                       

function_18383:
    mov64 r0, r4                                    r0 = r4
    mov64 r6, r1                                    r6 = r1
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    stxdw [r10-0x10], r1                    
    stxdw [r10-0x18], r1                    
    stxdw [r10-0x20], r1                    
    stxdw [r10-0x28], r1                    
    mov64 r1, 255                                   r1 = 255 as i32 as i64 as u64
    stxb [r10-0x1], r1                      
    mov64 r4, r10                                   r4 = r10
    add64 r4, -40                                   r4 += -40   ///  r4 = r4.wrapping_add(-40 as i32 as i64 as u64)
    mov64 r5, r10                                   r5 = r10
    add64 r5, -1                                    r5 += -1   ///  r5 = r5.wrapping_add(-1 as i32 as i64 as u64)
    mov64 r1, r2                                    r1 = r2
    mov64 r2, r3                                    r2 = r3
    mov64 r3, r0                                    r3 = r0
    syscall [invalid]                       
    jeq r0, 0, lbb_18405                            if r0 == (0 as i32 as i64 as u64) { pc += 4 }
    lddw r1, 0x10002dfb8 --> b"\x00\x00\x00\x00\xb4\xcc\x02\x00\x0d\x00\x00\x00\x00\x00\x00\x00\x18\x01\…        r1 load str located at 4295155640
    call function_17502                     
    syscall [invalid]                       
lbb_18405:
    ldxdw r1, [r10-0x10]                    
    stxdw [r6+0x18], r1                     
    ldxdw r1, [r10-0x18]                    
    stxdw [r6+0x10], r1                     
    ldxdw r1, [r10-0x20]                    
    stxdw [r6+0x8], r1                      
    ldxdw r1, [r10-0x28]                    
    stxdw [r6+0x0], r1                      
    ldxb r1, [r10-0x1]                      
    stxb [r6+0x20], r1                      
    exit                                    

function_18416:
    stxdw [r10-0x18], r4                    
    mov64 r9, r2                                    r9 = r2
    ldxdw r4, [r5-0xff8]                    
    ldxdw r2, [r4+0x8]                      
    stxdw [r10-0x8], r2                     
    ldxb r2, [r4+0x0]                       
    jeq r2, 0, lbb_18425                            if r2 == (0 as i32 as i64 as u64) { pc += 2 }
    add64 r4, 1                                     r4 += 1   ///  r4 = r4.wrapping_add(1 as i32 as i64 as u64)
    stxdw [r10-0x8], r4                     
lbb_18425:
    mov64 r0, 0                                     r0 = 0 as i32 as i64 as u64
    mov64 r6, 0                                     r6 = 0 as i32 as i64 as u64
    ldxdw r4, [r10-0x18]                    
    jeq r3, 0, lbb_18543                            if r3 == (0 as i32 as i64 as u64) { pc += 114 }
    stxdw [r10-0x20], r1                    
    mov64 r1, r9                                    r1 = r9
    stxdw [r10-0x28], r3                    
    add64 r1, r3                                    r1 += r3   ///  r1 = r1.wrapping_add(r3)
    stxdw [r10-0x10], r1                    
    ldxdw r2, [r5-0x1000]                   
    ldxdw r1, [r10-0x8]                     
    ldxb r1, [r1+0x0]                       
    stxdw [r10-0x38], r1                    
    mov64 r6, 0                                     r6 = 0 as i32 as i64 as u64
    stxdw [r10-0x30], r9                    
    mov64 r7, 0                                     r7 = 0 as i32 as i64 as u64
    mov64 r1, r4                                    r1 = r4
    ja lbb_18463                                    if true { pc += 20 }
lbb_18443:
    lddw r3, 0xffffffff00000000                     r3 load str located at -4294967296
    and64 r0, r3                                    r0 &= r3   ///  r0 = r0.and(r3)
    jge r6, r2, lbb_18545                           if r6 >= r2 { pc += 98 }
    mov64 r3, r1                                    r3 = r1
    add64 r3, r6                                    r3 += r6   ///  r3 = r3.wrapping_add(r6)
    stxb [r3+0x0], r8                       
    add64 r6, 1                                     r6 += 1   ///  r6 = r6.wrapping_add(1 as i32 as i64 as u64)
lbb_18451:
    add64 r7, 1                                     r7 += 1   ///  r7 = r7.wrapping_add(1 as i32 as i64 as u64)
    add64 r9, 1                                     r9 += 1   ///  r9 = r9.wrapping_add(1 as i32 as i64 as u64)
    ldxdw r3, [r10-0x10]                    
    jne r9, r3, lbb_18463                           if r9 != r3 { pc += 8 }
    ldxdw r0, [r10-0x28]                    
    ldxdw r8, [r10-0x30]                    
    jeq r0, 0, lbb_18508                            if r0 == (0 as i32 as i64 as u64) { pc += 50 }
    ldxdw r1, [r10-0x38]                    
    lddw r4, 0xffffffff00000000                     r4 load str located at -4294967296
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
    ja lbb_18506                                    if true { pc += 43 }
lbb_18463:
    ldxb r5, [r9+0x0]                       
    mov64 r3, r5                                    r3 = r5
    lsh64 r3, 56                                    r3 <<= 56   ///  r3 = r3.wrapping_shl(56)
    arsh64 r3, 56                                   r3 >>= 56 (signed)   ///  r3 = (r3 as i64).wrapping_shr(56)
    mov64 r4, 0                                     r4 = 0 as i32 as i64 as u64
    jsgt r4, r3, lbb_18514                          if (r4 as i64) > (r3 as i64) { pc += 45 }
    jsgt r3, -1, lbb_18471                          if (r3 as i64) > (-1 as i32 as i64) { pc += 1 }
    ja lbb_18553                                    if true { pc += 82 }
lbb_18471:
    ldxdw r3, [r10-0x8]                     
    add64 r3, r5                                    r3 += r5   ///  r3 = r3.wrapping_add(r5)
    ldxb r8, [r3+0x3a]                      
    jeq r8, 255, lbb_18519                          if r8 == (255 as i32 as i64 as u64) { pc += 44 }
    jge r2, r6, lbb_18481                           if r2 >= r6 { pc += 5 }
    mov64 r1, r6                                    r1 = r6
    lddw r3, 0x10002dfe8 --> b"\x00\x00\x00\x00\xc8\xcc\x02\x00\x0d\x00\x00\x00\x00\x00\x00\x00\xe8\x00\…        r3 load str located at 4295155688
    call function_20726                     
    syscall [invalid]                       
lbb_18481:
    jeq r6, 0, lbb_18495                            if r6 == (0 as i32 as i64 as u64) { pc += 13 }
    mov64 r5, r6                                    r5 = r6
    mov64 r3, r8                                    r3 = r8
    mov64 r4, r1                                    r4 = r1
lbb_18485:
    ldxb r8, [r4+0x0]                       
    mul64 r8, 58                                    r8 *= 58   ///  r8 = r8.wrapping_mul(58 as u64)
    add64 r8, r3                                    r8 += r3   ///  r8 = r8.wrapping_add(r3)
    stxb [r4+0x0], r8                       
    add64 r4, 1                                     r4 += 1   ///  r4 = r4.wrapping_add(1 as i32 as i64 as u64)
    rsh64 r8, 8                                     r8 >>= 8   ///  r8 = r8.wrapping_shr(8)
    add64 r5, -1                                    r5 += -1   ///  r5 = r5.wrapping_add(-1 as i32 as i64 as u64)
    mov64 r3, r8                                    r3 = r8
    jeq r5, 0, lbb_18495                            if r5 == (0 as i32 as i64 as u64) { pc += 1 }
    ja lbb_18485                                    if true { pc += -10 }
lbb_18495:
    jeq r8, 0, lbb_18451                            if r8 == (0 as i32 as i64 as u64) { pc += -45 }
    ja lbb_18443                                    if true { pc += -54 }
lbb_18497:
    and64 r5, r4                                    r5 &= r4   ///  r5 = r5.and(r4)
    jge r6, r2, lbb_18548                           if r6 >= r2 { pc += 49 }
    add64 r8, 1                                     r8 += 1   ///  r8 = r8.wrapping_add(1 as i32 as i64 as u64)
    ldxdw r7, [r10-0x18]                    
    add64 r7, r6                                    r7 += r6   ///  r7 = r7.wrapping_add(r6)
    stxb [r7+0x0], r3                       
    add64 r6, 1                                     r6 += 1   ///  r6 = r6.wrapping_add(1 as i32 as i64 as u64)
    add64 r0, -1                                    r0 += -1   ///  r0 = r0.wrapping_add(-1 as i32 as i64 as u64)
    jeq r0, 0, lbb_18508                            if r0 == (0 as i32 as i64 as u64) { pc += 2 }
lbb_18506:
    ldxb r7, [r8+0x0]                       
    jeq r7, r1, lbb_18497                           if r7 == r1 { pc += -11 }
lbb_18508:
    jge r2, r6, lbb_18525                           if r2 >= r6 { pc += 16 }
    mov64 r1, r6                                    r1 = r6
    lddw r3, 0x10002e000 --> b"\x00\x00\x00\x00\xc8\xcc\x02\x00\x0d\x00\x00\x00\x00\x00\x00\x00\xfc\x00\…        r3 load str located at 4295155712
    call function_20726                     
    syscall [invalid]                       
lbb_18514:
    ldxdw r1, [r10-0x20]                    
    stxdw [r1+0x10], r7                     
    mov64 r2, 2                                     r2 = 2 as i32 as i64 as u64
    stxw [r1+0x8], r2                       
    ja lbb_18550                                    if true { pc += 31 }
lbb_18519:
    ldxdw r1, [r10-0x20]                    
    stxdw [r1+0x10], r7                     
    stxw [r1+0xc], r5                       
    mov64 r0, 1                                     r0 = 1 as i32 as i64 as u64
    stxw [r1+0x8], r0                       
    ja lbb_18551                                    if true { pc += 26 }
lbb_18525:
    mov64 r2, 2                                     r2 = 2 as i32 as i64 as u64
    ldxdw r1, [r10-0x20]                    
    mov64 r0, 0                                     r0 = 0 as i32 as i64 as u64
    ldxdw r7, [r10-0x18]                    
    jgt r2, r6, lbb_18543                           if r2 > r6 { pc += 13 }
    mov64 r5, r6                                    r5 = r6
    rsh64 r5, 1                                     r5 >>= 1   ///  r5 = r5.wrapping_shr(1)
    mov64 r2, r6                                    r2 = r6
    add64 r2, r7                                    r2 += r7   ///  r2 = r2.wrapping_add(r7)
    add64 r2, -1                                    r2 += -1   ///  r2 = r2.wrapping_add(-1 as i32 as i64 as u64)
lbb_18535:
    ldxb r3, [r7+0x0]                       
    ldxb r4, [r2+0x0]                       
    stxb [r7+0x0], r4                       
    stxb [r2+0x0], r3                       
    add64 r2, -1                                    r2 += -1   ///  r2 = r2.wrapping_add(-1 as i32 as i64 as u64)
    add64 r7, 1                                     r7 += 1   ///  r7 = r7.wrapping_add(1 as i32 as i64 as u64)
    add64 r5, -1                                    r5 += -1   ///  r5 = r5.wrapping_add(-1 as i32 as i64 as u64)
    jne r5, 0, lbb_18535                            if r5 != (0 as i32 as i64 as u64) { pc += -8 }
lbb_18543:
    stxdw [r1+0x8], r6                      
    ja lbb_18551                                    if true { pc += 6 }
lbb_18545:
    ldxdw r1, [r10-0x20]                    
    stxdw [r1+0x8], r0                      
    ja lbb_18550                                    if true { pc += 2 }
lbb_18548:
    ldxdw r1, [r10-0x20]                    
    stxdw [r1+0x8], r5                      
lbb_18550:
    mov64 r0, 1                                     r0 = 1 as i32 as i64 as u64
lbb_18551:
    stxdw [r1+0x0], r0                      
    exit                                    
lbb_18553:
    mov64 r1, r5                                    r1 = r5
    mov64 r2, 128                                   r2 = 128 as i32 as i64 as u64
    lddw r3, 0x10002dfd0 --> b"\x00\x00\x00\x00\xc8\xcc\x02\x00\x0d\x00\x00\x00\x00\x00\x00\x00\xe0\x00\…        r3 load str located at 4295155664
    call function_19324                     
    syscall [invalid]                       

function_18559:
    call function_18574                     
    syscall [invalid]                       

function_18561:
    lddw r1, 0x10002ccd5 --> b"Error: memory allocation failed, out of memory"        r1 load str located at 4295150805
    mov64 r2, 46                                    r2 = 46 as i32 as i64 as u64
    call function_18569                     
    call function_18559                     
    syscall [invalid]                       

function_18567:
    call function_18571                     
    syscall [invalid]                       

function_18569:
    syscall [invalid]                       
    exit                                    

function_18571:
    call custom_panic                       
    syscall [invalid]                       
    syscall [invalid]                       

function_18574:
    syscall [invalid]                       
    syscall [invalid]                       

function_18576:
    call function_18578                     
    syscall [invalid]                       

function_18578:
    call function_18764                     
    syscall [invalid]                       
    exit                                    

function_18581:
    ldxdw r1, [r1+0x0]                      
    call function_18846                     
    mov64 r0, 0                                     r0 = 0 as i32 as i64 as u64
    exit                                    

function_18585:
    ldxdw r1, [r1+0x0]                      
    stxdw [r10-0x38], r1                    
    mov64 r6, r10                                   r6 = r10
    add64 r6, -48                                   r6 += -48   ///  r6 = r6.wrapping_add(-48 as i32 as i64 as u64)
    mov64 r1, r6                                    r1 = r6
    mov64 r3, 48                                    r3 = 48 as i32 as i64 as u64
    call function_21797                     
    mov64 r1, r10                                   r1 = r10
    add64 r1, -56                                   r1 += -56   ///  r1 = r1.wrapping_add(-56 as i32 as i64 as u64)
    lddw r2, 0x10002e018 --> b"\x00\x00\x00\x00\xc0E\x02\x00\x08\x00\x00\x00\x00\x00\x00\x00\x08\x00\x00…        r2 load str located at 4295155736
    mov64 r3, r6                                    r3 = r6
    call function_19901                     
    exit                                    

function_18599:
    mov64 r6, r3                                    r6 = r3
    mov64 r8, r2                                    r8 = r2
    ldxdw r7, [r1+0x0]                      
    ldxdw r9, [r7+0x10]                     
    ldxdw r1, [r7+0x8]                      
    sub64 r1, r9                                    r1 -= r9   ///  r1 = r1.wrapping_sub(r9)
    jge r1, r6, lbb_18611                           if r1 >= r6 { pc += 5 }
    mov64 r1, r7                                    r1 = r7
    mov64 r2, r9                                    r2 = r9
    mov64 r3, r6                                    r3 = r6
    call function_18620                     
    ldxdw r9, [r7+0x10]                     
lbb_18611:
    ldxdw r1, [r7+0x0]                      
    add64 r1, r9                                    r1 += r9   ///  r1 = r1.wrapping_add(r9)
    mov64 r2, r8                                    r2 = r8
    mov64 r3, r6                                    r3 = r6
    call function_21797                     
    add64 r9, r6                                    r9 += r6   ///  r9 = r9.wrapping_add(r6)
    stxdw [r7+0x10], r9                     
    mov64 r0, 0                                     r0 = 0 as i32 as i64 as u64
    exit                                    

function_18620:
    mov64 r6, r1                                    r6 = r1
    mov64 r4, r2                                    r4 = r2
    add64 r4, r3                                    r4 += r3   ///  r4 = r4.wrapping_add(r3)
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    jgt r2, r4, lbb_18626                           if r2 > r4 { pc += 1 }
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
lbb_18626:
    and64 r1, 1                                     r1 &= 1   ///  r1 = r1.and(1)
    jne r1, 0, lbb_18657                            if r1 != (0 as i32 as i64 as u64) { pc += 29 }
    ldxdw r1, [r6+0x8]                      
    mov64 r7, r1                                    r7 = r1
    lsh64 r7, 1                                     r7 <<= 1   ///  r7 = r7.wrapping_shl(1)
    jgt r7, r4, lbb_18633                           if r7 > r4 { pc += 1 }
    mov64 r7, r4                                    r7 = r4
lbb_18633:
    jgt r7, 8, lbb_18635                            if r7 > (8 as i32 as i64 as u64) { pc += 1 }
    mov64 r7, 8                                     r7 = 8 as i32 as i64 as u64
lbb_18635:
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
    jeq r1, 0, lbb_18641                            if r1 == (0 as i32 as i64 as u64) { pc += 4 }
    ldxdw r2, [r6+0x0]                      
    stxdw [r10-0x10], r1                    
    stxdw [r10-0x18], r2                    
    mov64 r2, 1                                     r2 = 1 as i32 as i64 as u64
lbb_18641:
    stxdw [r10-0x8], r2                     
    mov64 r1, r10                                   r1 = r10
    add64 r1, -48                                   r1 += -48   ///  r1 = r1.wrapping_add(-48 as i32 as i64 as u64)
    mov64 r4, r10                                   r4 = r10
    add64 r4, -24                                   r4 += -24   ///  r4 = r4.wrapping_add(-24 as i32 as i64 as u64)
    mov64 r2, r7                                    r2 = r7
    mov64 r3, 1                                     r3 = 1 as i32 as i64 as u64
    call function_18704                     
    ldxdw r1, [r10-0x30]                    
    jne r1, 0, lbb_18655                            if r1 != (0 as i32 as i64 as u64) { pc += 4 }
    ldxdw r1, [r10-0x28]                    
    stxdw [r6+0x8], r7                      
    stxdw [r6+0x0], r1                      
    exit                                    
lbb_18655:
    ldxdw r2, [r10-0x20]                    
    jne r2, 0, lbb_18659                            if r2 != (0 as i32 as i64 as u64) { pc += 2 }
lbb_18657:
    call function_18745                     
    syscall [invalid]                       
lbb_18659:
    ldxdw r1, [r10-0x28]                    
    call function_18762                     
    syscall [invalid]                       

function_18662:
    mov64 r6, r1                                    r6 = r1
    mov64 r3, r2                                    r3 = r2
    add64 r3, 1                                     r3 += 1   ///  r3 = r3.wrapping_add(1 as i32 as i64 as u64)
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    jgt r2, r3, lbb_18668                           if r2 > r3 { pc += 1 }
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
lbb_18668:
    and64 r1, 1                                     r1 &= 1   ///  r1 = r1.and(1)
    jne r1, 0, lbb_18699                            if r1 != (0 as i32 as i64 as u64) { pc += 29 }
    ldxdw r1, [r6+0x8]                      
    mov64 r7, r1                                    r7 = r1
    lsh64 r7, 1                                     r7 <<= 1   ///  r7 = r7.wrapping_shl(1)
    jgt r7, r3, lbb_18675                           if r7 > r3 { pc += 1 }
    mov64 r7, r3                                    r7 = r3
lbb_18675:
    jgt r7, 8, lbb_18677                            if r7 > (8 as i32 as i64 as u64) { pc += 1 }
    mov64 r7, 8                                     r7 = 8 as i32 as i64 as u64
lbb_18677:
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
    jeq r1, 0, lbb_18683                            if r1 == (0 as i32 as i64 as u64) { pc += 4 }
    ldxdw r2, [r6+0x0]                      
    stxdw [r10-0x10], r1                    
    stxdw [r10-0x18], r2                    
    mov64 r2, 1                                     r2 = 1 as i32 as i64 as u64
lbb_18683:
    stxdw [r10-0x8], r2                     
    mov64 r1, r10                                   r1 = r10
    add64 r1, -48                                   r1 += -48   ///  r1 = r1.wrapping_add(-48 as i32 as i64 as u64)
    mov64 r4, r10                                   r4 = r10
    add64 r4, -24                                   r4 += -24   ///  r4 = r4.wrapping_add(-24 as i32 as i64 as u64)
    mov64 r2, r7                                    r2 = r7
    mov64 r3, 1                                     r3 = 1 as i32 as i64 as u64
    call function_18704                     
    ldxdw r1, [r10-0x30]                    
    jne r1, 0, lbb_18697                            if r1 != (0 as i32 as i64 as u64) { pc += 4 }
    ldxdw r1, [r10-0x28]                    
    stxdw [r6+0x8], r7                      
    stxdw [r6+0x0], r1                      
    exit                                    
lbb_18697:
    ldxdw r2, [r10-0x20]                    
    jne r2, 0, lbb_18701                            if r2 != (0 as i32 as i64 as u64) { pc += 2 }
lbb_18699:
    call function_18745                     
    syscall [invalid]                       
lbb_18701:
    ldxdw r1, [r10-0x28]                    
    call function_18762                     
    syscall [invalid]                       

function_18704:
    mov64 r8, r3                                    r8 = r3
    mov64 r7, r2                                    r7 = r2
    mov64 r6, r1                                    r6 = r1
    jeq r8, 0, lbb_18718                            if r8 == (0 as i32 as i64 as u64) { pc += 10 }
    ldxdw r1, [r4+0x10]                     
    jeq r1, 0, lbb_18728                            if r1 == (0 as i32 as i64 as u64) { pc += 18 }
    ldxdw r2, [r4+0x8]                      
    jne r2, 0, lbb_18722                            if r2 != (0 as i32 as i64 as u64) { pc += 10 }
    jeq r7, 0, lbb_18738                            if r7 == (0 as i32 as i64 as u64) { pc += 25 }
    mov64 r1, r7                                    r1 = r7
    mov64 r2, r8                                    r2 = r8
    call function_11635                     
    jeq r0, 0, lbb_18734                            if r0 == (0 as i32 as i64 as u64) { pc += 17 }
    ja lbb_18740                                    if true { pc += 22 }
lbb_18718:
    stxdw [r6+0x8], r7                      
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    mov64 r7, 0                                     r7 = 0 as i32 as i64 as u64
    ja lbb_18742                                    if true { pc += 20 }
lbb_18722:
    ldxdw r1, [r4+0x0]                      
    mov64 r3, r8                                    r3 = r8
    mov64 r4, r7                                    r4 = r7
    call function_11639                     
    jeq r0, 0, lbb_18734                            if r0 == (0 as i32 as i64 as u64) { pc += 7 }
    ja lbb_18740                                    if true { pc += 12 }
lbb_18728:
    jeq r7, 0, lbb_18738                            if r7 == (0 as i32 as i64 as u64) { pc += 9 }
    mov64 r1, r7                                    r1 = r7
    mov64 r2, r8                                    r2 = r8
    call function_11635                     
    jeq r0, 0, lbb_18734                            if r0 == (0 as i32 as i64 as u64) { pc += 1 }
    ja lbb_18740                                    if true { pc += 6 }
lbb_18734:
    stxdw [r6+0x8], r7                      
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    mov64 r7, r8                                    r7 = r8
    ja lbb_18742                                    if true { pc += 4 }
lbb_18738:
    mov64 r7, 0                                     r7 = 0 as i32 as i64 as u64
    mov64 r0, r8                                    r0 = r8
lbb_18740:
    stxdw [r6+0x8], r0                      
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
lbb_18742:
    stxdw [r6+0x0], r1                      
    stxdw [r6+0x10], r7                     
    exit                                    

function_18745:
    lddw r1, 0x10002cd08 --> b"library/alloc/src/raw_vec.rscapacity overflowa for"        r1 load str located at 4295150856
    stxdw [r10-0x10], r1                    
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    stxdw [r10-0x8], r1                     
    stxdw [r10-0x20], r1                    
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    stxdw [r10-0x28], r1                    
    lddw r1, 0x10002e068 --> b"\x00\x00\x00\x00$\xcd\x02\x00\x11\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00…        r1 load str located at 4295155816
    stxdw [r10-0x30], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -48                                   r1 += -48   ///  r1 = r1.wrapping_add(-48 as i32 as i64 as u64)
    lddw r2, 0x10002e078 --> b"\x00\x00\x00\x00\x08\xcd\x02\x00\x1c\x00\x00\x00\x00\x00\x00\x00\x05\x02\…        r2 load str located at 4295155832
    call function_19352                     
    syscall [invalid]                       

function_18762:
    call function_18576                     
    syscall [invalid]                       

function_18764:
    call function_11643                     
    syscall [invalid]                       

function_18766:
    call function_18561                     
    syscall [invalid]                       

function_18768:
    mov64 r6, r2                                    r6 = r2
    mov64 r7, r1                                    r7 = r1
    mov64 r8, 0                                     r8 = 0 as i32 as i64 as u64
    ldxdw r3, [r6+0x28]                     
    ldxdw r1, [r6+0x0]                      
    ldxdw r2, [r6+0x8]                      
    mov64 r4, r2                                    r4 = r2
    lsh64 r4, 4                                     r4 <<= 4   ///  r4 = r4.wrapping_shl(4)
    jeq r4, 0, lbb_18786                            if r4 == (0 as i32 as i64 as u64) { pc += 9 }
    mov64 r0, 0                                     r0 = 0 as i32 as i64 as u64
    mov64 r5, r1                                    r5 = r1
    add64 r5, 8                                     r5 += 8   ///  r5 = r5.wrapping_add(8 as i32 as i64 as u64)
lbb_18780:
    ldxdw r8, [r5+0x0]                      
    add64 r8, r0                                    r8 += r0   ///  r8 = r8.wrapping_add(r0)
    add64 r5, 16                                    r5 += 16   ///  r5 = r5.wrapping_add(16 as i32 as i64 as u64)
    add64 r4, -16                                   r4 += -16   ///  r4 = r4.wrapping_add(-16 as i32 as i64 as u64)
    mov64 r0, r8                                    r0 = r8
    jne r4, 0, lbb_18780                            if r4 != (0 as i32 as i64 as u64) { pc += -6 }
lbb_18786:
    jeq r3, 0, lbb_18804                            if r3 == (0 as i32 as i64 as u64) { pc += 17 }
    jeq r2, 0, lbb_18794                            if r2 == (0 as i32 as i64 as u64) { pc += 6 }
    ldxdw r1, [r1+0x8]                      
    jne r1, 0, lbb_18794                            if r1 != (0 as i32 as i64 as u64) { pc += 4 }
    mov64 r0, 1                                     r0 = 1 as i32 as i64 as u64
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    mov64 r2, 16                                    r2 = 16 as i32 as i64 as u64
    jgt r2, r8, lbb_18816                           if r2 > r8 { pc += 22 }
lbb_18794:
    mov64 r2, r8                                    r2 = r8
    add64 r2, r2                                    r2 += r2   ///  r2 = r2.wrapping_add(r2)
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    mov64 r0, 1                                     r0 = 1 as i32 as i64 as u64
    mov64 r3, 1                                     r3 = 1 as i32 as i64 as u64
    jgt r8, r2, lbb_18801                           if r8 > r2 { pc += 1 }
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
lbb_18801:
    and64 r3, 1                                     r3 &= 1   ///  r3 = r3.and(1)
    mov64 r8, r2                                    r8 = r2
    jne r3, 0, lbb_18816                            if r3 != (0 as i32 as i64 as u64) { pc += 12 }
lbb_18804:
    mov64 r0, 1                                     r0 = 1 as i32 as i64 as u64
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    jeq r8, 0, lbb_18816                            if r8 == (0 as i32 as i64 as u64) { pc += 9 }
    mov64 r1, r8                                    r1 = r8
    mov64 r2, 1                                     r2 = 1 as i32 as i64 as u64
    call function_11635                     
    mov64 r1, r8                                    r1 = r8
    jne r0, 0, lbb_18816                            if r0 != (0 as i32 as i64 as u64) { pc += 4 }
    mov64 r1, r8                                    r1 = r8
    mov64 r2, 1                                     r2 = 1 as i32 as i64 as u64
    call function_18762                     
    syscall [invalid]                       
lbb_18816:
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
    stxdw [r7+0x10], r2                     
    stxdw [r7+0x8], r1                      
    stxdw [r7+0x0], r0                      
    stxdw [r10-0x38], r7                    
    mov64 r7, r10                                   r7 = r10
    add64 r7, -48                                   r7 += -48   ///  r7 = r7.wrapping_add(-48 as i32 as i64 as u64)
    mov64 r1, r7                                    r1 = r7
    mov64 r2, r6                                    r2 = r6
    mov64 r3, 48                                    r3 = 48 as i32 as i64 as u64
    call function_21797                     
    mov64 r1, r10                                   r1 = r10
    add64 r1, -56                                   r1 += -56   ///  r1 = r1.wrapping_add(-56 as i32 as i64 as u64)
    lddw r2, 0x10002e018 --> b"\x00\x00\x00\x00\xc0E\x02\x00\x08\x00\x00\x00\x00\x00\x00\x00\x08\x00\x00…        r2 load str located at 4295155736
    mov64 r3, r7                                    r3 = r7
    call function_19901                     
    jeq r0, 0, lbb_18845                            if r0 == (0 as i32 as i64 as u64) { pc += 11 }
    mov64 r3, r10                                   r3 = r10
    add64 r3, -48                                   r3 += -48   ///  r3 = r3.wrapping_add(-48 as i32 as i64 as u64)
    lddw r1, 0x10002cd35 --> b"a formatting trait implementation returned an error"        r1 load str located at 4295150901
    mov64 r2, 51                                    r2 = 51 as i32 as i64 as u64
    lddw r4, 0x10002e048 --> b"\x00\x00\x00\x00\xc0E\x02\x00\x00\x00\x00\x00\x00\x00\x00\x00\x01\x00\x00…        r4 load str located at 4295155784
    lddw r5, 0x10002e090 --> b"\x00\x00\x00\x00h\xcd\x02\x00\x18\x00\x00\x00\x00\x00\x00\x00b\x02\x00\x0…        r5 load str located at 4295155856
    call function_19366                     
    syscall [invalid]                       
lbb_18845:
    exit                                    

function_18846:
    mov64 r7, r2                                    r7 = r2
    mov64 r6, r1                                    r6 = r1
    mov64 r1, r7                                    r1 = r7
    lsh64 r1, 32                                    r1 <<= 32   ///  r1 = r1.wrapping_shl(32)
    rsh64 r1, 32                                    r1 >>= 32   ///  r1 = r1.wrapping_shr(32)
    mov64 r2, 128                                   r2 = 128 as i32 as i64 as u64
    jgt r2, r1, lbb_18867                           if r2 > r1 { pc += 14 }
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
    stxw [r10-0x4], r2                      
    mov64 r2, 2048                                  r2 = 2048 as i32 as i64 as u64
    jgt r2, r1, lbb_18858                           if r2 > r1 { pc += 1 }
    ja lbb_18879                                    if true { pc += 21 }
lbb_18858:
    mov64 r1, r7                                    r1 = r7
    and64 r1, 63                                    r1 &= 63   ///  r1 = r1.and(63)
    or64 r1, 128                                    r1 |= 128   ///  r1 = r1.or(128)
    stxb [r10-0x3], r1                      
    rsh64 r7, 6                                     r7 >>= 6   ///  r7 = r7.wrapping_shr(6)
    or64 r7, 192                                    r7 |= 192   ///  r7 = r7.or(192)
    stxb [r10-0x4], r7                      
    mov64 r7, 2                                     r7 = 2 as i32 as i64 as u64
    ja lbb_18915                                    if true { pc += 48 }
lbb_18867:
    ldxdw r2, [r6+0x10]                     
    ldxdw r1, [r6+0x8]                      
    jne r2, r1, lbb_18873                           if r2 != r1 { pc += 3 }
    mov64 r1, r6                                    r1 = r6
    call function_18662                     
    ldxdw r2, [r6+0x10]                     
lbb_18873:
    ldxdw r1, [r6+0x0]                      
    add64 r1, r2                                    r1 += r2   ///  r1 = r1.wrapping_add(r2)
    stxb [r1+0x0], r7                       
    add64 r2, 1                                     r2 += 1   ///  r2 = r2.wrapping_add(1 as i32 as i64 as u64)
    stxdw [r6+0x10], r2                     
    ja lbb_18932                                    if true { pc += 53 }
lbb_18879:
    mov64 r1, r7                                    r1 = r7
    lsh64 r1, 32                                    r1 <<= 32   ///  r1 = r1.wrapping_shl(32)
    rsh64 r1, 32                                    r1 >>= 32   ///  r1 = r1.wrapping_shr(32)
    mov64 r2, 65536                                 r2 = 65536 as i32 as i64 as u64
    jgt r2, r1, lbb_18885                           if r2 > r1 { pc += 1 }
    ja lbb_18898                                    if true { pc += 13 }
lbb_18885:
    and64 r7, 63                                    r7 &= 63   ///  r7 = r7.and(63)
    or64 r7, 128                                    r7 |= 128   ///  r7 = r7.or(128)
    stxb [r10-0x2], r7                      
    mov64 r2, r1                                    r2 = r1
    rsh64 r2, 12                                    r2 >>= 12   ///  r2 = r2.wrapping_shr(12)
    or64 r2, 224                                    r2 |= 224   ///  r2 = r2.or(224)
    stxb [r10-0x4], r2                      
    rsh64 r1, 6                                     r1 >>= 6   ///  r1 = r1.wrapping_shr(6)
    and64 r1, 63                                    r1 &= 63   ///  r1 = r1.and(63)
    or64 r1, 128                                    r1 |= 128   ///  r1 = r1.or(128)
    stxb [r10-0x3], r1                      
    mov64 r7, 3                                     r7 = 3 as i32 as i64 as u64
    ja lbb_18915                                    if true { pc += 17 }
lbb_18898:
    and64 r7, 63                                    r7 &= 63   ///  r7 = r7.and(63)
    or64 r7, 128                                    r7 |= 128   ///  r7 = r7.or(128)
    stxb [r10-0x1], r7                      
    mov64 r2, r1                                    r2 = r1
    rsh64 r2, 18                                    r2 >>= 18   ///  r2 = r2.wrapping_shr(18)
    or64 r2, 240                                    r2 |= 240   ///  r2 = r2.or(240)
    stxb [r10-0x4], r2                      
    mov64 r2, r1                                    r2 = r1
    rsh64 r2, 6                                     r2 >>= 6   ///  r2 = r2.wrapping_shr(6)
    and64 r2, 63                                    r2 &= 63   ///  r2 = r2.and(63)
    or64 r2, 128                                    r2 |= 128   ///  r2 = r2.or(128)
    stxb [r10-0x2], r2                      
    rsh64 r1, 12                                    r1 >>= 12   ///  r1 = r1.wrapping_shr(12)
    and64 r1, 63                                    r1 &= 63   ///  r1 = r1.and(63)
    or64 r1, 128                                    r1 |= 128   ///  r1 = r1.or(128)
    stxb [r10-0x3], r1                      
    mov64 r7, 4                                     r7 = 4 as i32 as i64 as u64
lbb_18915:
    ldxdw r8, [r6+0x10]                     
    ldxdw r1, [r6+0x8]                      
    sub64 r1, r8                                    r1 -= r8   ///  r1 = r1.wrapping_sub(r8)
    jge r1, r7, lbb_18924                           if r1 >= r7 { pc += 5 }
    mov64 r1, r6                                    r1 = r6
    mov64 r2, r8                                    r2 = r8
    mov64 r3, r7                                    r3 = r7
    call function_18620                     
    ldxdw r8, [r6+0x10]                     
lbb_18924:
    ldxdw r1, [r6+0x0]                      
    add64 r1, r8                                    r1 += r8   ///  r1 = r1.wrapping_add(r8)
    mov64 r2, r10                                   r2 = r10
    add64 r2, -4                                    r2 += -4   ///  r2 = r2.wrapping_add(-4 as i32 as i64 as u64)
    mov64 r3, r7                                    r3 = r7
    call function_21797                     
    add64 r8, r7                                    r8 += r7   ///  r8 = r8.wrapping_add(r7)
    stxdw [r6+0x10], r8                     
lbb_18932:
    exit                                    

function_18933:
    call function_20728                     
    syscall [invalid]                       

function_18935:
    call function_20697                     
    syscall [invalid]                       

function_18937:
    call function_21008                     
    syscall [invalid]                       
    ldxdw r1, [r1+0x0]                      
    syscall [invalid]                       
    syscall [invalid]                       

function_18942:
    call function_20759                     
    syscall [invalid]                       
    exit                                    

function_18945:
    call function_18935                     
    syscall [invalid]                       

function_18947:
    call function_18942                     
    syscall [invalid]                       

function_18949:
    ldxdw r4, [r1+0x18]                     
    ldxdw r3, [r1+0x10]                     
    ldxdw r2, [r1+0x8]                      
    ldxdw r1, [r1+0x0]                      
    call function_18937                     
    syscall [invalid]                       

function_18955:
    call function_18933                     
    syscall [invalid]                       
    mov64 r6, r2                                    r6 = r2
    mov64 r7, r1                                    r7 = r1
    call function_21470                     
    mov64 r1, r0                                    r1 = r0
    mov64 r0, 1                                     r0 = 1 as i32 as i64 as u64
    jne r1, 0, lbb_18982                            if r1 != (0 as i32 as i64 as u64) { pc += 19 }
    ldxdw r2, [r6+0x28]                     
    ldxdw r1, [r6+0x20]                     
    lddw r3, 0x10002cd80 --> b")..BorrowErrorBorrowMutError but the index is     "        r3 load str located at 4295150976
    stxdw [r10-0x10], r3                    
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
    stxdw [r10-0x8], r3                     
    stxdw [r10-0x20], r3                    
    lddw r3, 0x10002e0a8 --> b"\x00\x00\x00\x00\x81\xcd\x02\x00\x02\x00\x00\x00\x00\x00\x00\x00\x00\x00\…        r3 load str located at 4295155880
    stxdw [r10-0x30], r3                    
    mov64 r3, 1                                     r3 = 1 as i32 as i64 as u64
    stxdw [r10-0x28], r3                    
    mov64 r3, r10                                   r3 = r10
    add64 r3, -48                                   r3 += -48   ///  r3 = r3.wrapping_add(-48 as i32 as i64 as u64)
    call function_19901                     
    mov64 r1, r0                                    r1 = r0
    mov64 r0, 1                                     r0 = 1 as i32 as i64 as u64
    jeq r1, 0, lbb_18983                            if r1 == (0 as i32 as i64 as u64) { pc += 1 }
lbb_18982:
    exit                                    
lbb_18983:
    add64 r7, 8                                     r7 += 8   ///  r7 = r7.wrapping_add(8 as i32 as i64 as u64)
    mov64 r1, r7                                    r1 = r7
    mov64 r2, r6                                    r2 = r6
    call function_21470                     
    mov64 r1, r0                                    r1 = r0
    mov64 r0, 0                                     r0 = 0 as i32 as i64 as u64
    jeq r1, 0, lbb_18982                            if r1 == (0 as i32 as i64 as u64) { pc += -8 }
    mov64 r0, 1                                     r0 = 1 as i32 as i64 as u64
    ja lbb_18982                                    if true { pc += -10 }

function_18992:
    lddw r0, 0x6436232572d50cba                     r0 load str located at 7220997696282496186
    exit                                    

function_18995:
    ldxdw r1, [r2+0x20]                     
    ldxdw r2, [r2+0x28]                     
    ldxdw r4, [r2+0x18]                     
    lddw r2, 0x10002cd83 --> b"BorrowError"         r2 load str located at 4295150979
    mov64 r3, 11                                    r3 = 11 as i32 as i64 as u64
    callx r4                                
    exit                                    

function_19003:
    ldxdw r1, [r2+0x20]                     
    ldxdw r2, [r2+0x28]                     
    ldxdw r4, [r2+0x18]                     
    lddw r2, 0x10002cd8e --> b"BorrowMutError"        r2 load str located at 4295150990
    mov64 r3, 14                                    r3 = 14 as i32 as i64 as u64
    callx r4                                
    exit                                    

function_19011:
    mov64 r8, r2                                    r8 = r2
    mov64 r6, r1                                    r6 = r1
    mov64 r1, 2                                     r1 = 2 as i32 as i64 as u64
    mov64 r7, r8                                    r7 = r8
    mov64 r5, r8                                    r5 = r8
    lsh64 r5, 32                                    r5 <<= 32   ///  r5 = r5.wrapping_shl(32)
    rsh64 r5, 32                                    r5 >>= 32   ///  r5 = r5.wrapping_shr(32)
    jsgt r5, 12, lbb_19026                          if (r5 as i64) > (12 as i32 as i64) { pc += 7 }
    mov64 r4, 48                                    r4 = 48 as i32 as i64 as u64
    jeq r5, 0, lbb_19193                            if r5 == (0 as i32 as i64 as u64) { pc += 172 }
    jeq r5, 9, lbb_19035                            if r5 == (9 as i32 as i64 as u64) { pc += 13 }
    jeq r5, 10, lbb_19024                           if r5 == (10 as i32 as i64 as u64) { pc += 1 }
    ja lbb_19041                                    if true { pc += 17 }
lbb_19024:
    mov64 r4, 110                                   r4 = 110 as i32 as i64 as u64
    ja lbb_19193                                    if true { pc += 167 }
lbb_19026:
    jsgt r5, 38, lbb_19039                          if (r5 as i64) > (38 as i32 as i64) { pc += 12 }
    jeq r5, 13, lbb_19037                           if r5 == (13 as i32 as i64 as u64) { pc += 9 }
    jeq r5, 34, lbb_19030                           if r5 == (34 as i32 as i64 as u64) { pc += 1 }
    ja lbb_19041                                    if true { pc += 11 }
lbb_19030:
    mov64 r4, 34                                    r4 = 34 as i32 as i64 as u64
    mov64 r5, r3                                    r5 = r3
    and64 r5, 65536                                 r5 &= 65536   ///  r5 = r5.and(65536)
    jeq r5, 0, lbb_19041                            if r5 == (0 as i32 as i64 as u64) { pc += 7 }
    ja lbb_19193                                    if true { pc += 158 }
lbb_19035:
    mov64 r4, 116                                   r4 = 116 as i32 as i64 as u64
    ja lbb_19193                                    if true { pc += 156 }
lbb_19037:
    mov64 r4, 114                                   r4 = 114 as i32 as i64 as u64
    ja lbb_19193                                    if true { pc += 154 }
lbb_19039:
    jeq r5, 39, lbb_19189                           if r5 == (39 as i32 as i64 as u64) { pc += 149 }
    jeq r5, 92, lbb_19071                           if r5 == (92 as i32 as i64 as u64) { pc += 30 }
lbb_19041:
    and64 r3, 1                                     r3 &= 1   ///  r3 = r3.and(1)
    jeq r3, 0, lbb_19044                            if r3 == (0 as i32 as i64 as u64) { pc += 1 }
    ja lbb_19073                                    if true { pc += 29 }
lbb_19044:
    mov64 r1, r8                                    r1 = r8
    lsh64 r1, 32                                    r1 <<= 32   ///  r1 = r1.wrapping_shl(32)
    rsh64 r1, 32                                    r1 >>= 32   ///  r1 = r1.wrapping_shr(32)
    mov64 r2, 65536                                 r2 = 65536 as i32 as i64 as u64
    jgt r2, r1, lbb_19127                           if r2 > r1 { pc += 78 }
    mov64 r2, 131072                                r2 = 131072 as i32 as i64 as u64
    jgt r2, r1, lbb_19052                           if r2 > r1 { pc += 1 }
    ja lbb_19146                                    if true { pc += 94 }
lbb_19052:
    lddw r1, 0x10002d3d5 --> b"^"{\x05\x03\x04-\x03f\x03\x01/.\x80\x82\x1d\x031\x0f\x1c\x04$\x09\x1e\x05…        r1 load str located at 4295152597
    stxdw [r10-0xff8], r1                   
    mov64 r1, 438                                   r1 = 438 as i32 as i64 as u64
    stxdw [r10-0xff0], r1                   
    mov64 r1, 192                                   r1 = 192 as i32 as i64 as u64
    stxdw [r10-0x1000], r1                  
    mov64 r5, r10                                   r5 = r10
    mov64 r1, r7                                    r1 = r7
    lddw r2, 0x10002d2c1 --> b"\x00\x06\x01\x01\x03\x01\x04\x02\x05\x07\x07\x02\x08\x08\x09\x02\x0a\x05\…        r2 load str located at 4295152321
    mov64 r3, 42                                    r3 = 42 as i32 as i64 as u64
    lddw r4, 0x10002d315 --> b"\x0c';>NO\x8f\x9e\x9e\x9f{\x8b\x93\x96\xa2\xb2\xba\x86\xb1\x06\x07\x096=>…        r4 load str located at 4295152405
    call function_21290                     
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    mov64 r4, r7                                    r4 = r7
    jne r0, 0, lbb_19193                            if r0 != (0 as i32 as i64 as u64) { pc += 123 }
lbb_19070:
    ja lbb_19076                                    if true { pc += 5 }
lbb_19071:
    mov64 r4, 92                                    r4 = 92 as i32 as i64 as u64
    ja lbb_19193                                    if true { pc += 120 }
lbb_19073:
    mov64 r1, r7                                    r1 = r7
    call function_21689                     
    jeq r0, 0, lbb_19044                            if r0 == (0 as i32 as i64 as u64) { pc += -32 }
lbb_19076:
    lddw r1, 0xfffffffe                             r1 load str located at 4294967294
    mov64 r2, r8                                    r2 = r8
    and64 r2, r1                                    r2 &= r1   ///  r2 = r2.and(r1)
    rsh64 r2, 1                                     r2 >>= 1   ///  r2 = r2.wrapping_shr(1)
    or64 r8, r2                                     r8 |= r2   ///  r8 = r8.or(r2)
    lddw r1, 0xfffffffc                             r1 load str located at 4294967292
    mov64 r2, r8                                    r2 = r8
    and64 r2, r1                                    r2 &= r1   ///  r2 = r2.and(r1)
    rsh64 r2, 2                                     r2 >>= 2   ///  r2 = r2.wrapping_shr(2)
    or64 r8, r2                                     r8 |= r2   ///  r8 = r8.or(r2)
    lddw r1, 0xfffffff0                             r1 load str located at 4294967280
    mov64 r2, r8                                    r2 = r8
    and64 r2, r1                                    r2 &= r1   ///  r2 = r2.and(r1)
    rsh64 r2, 4                                     r2 >>= 4   ///  r2 = r2.wrapping_shr(4)
    or64 r8, r2                                     r8 |= r2   ///  r8 = r8.or(r2)
    lddw r1, 0xffffff00                             r1 load str located at 4294967040
    mov64 r2, r8                                    r2 = r8
    and64 r2, r1                                    r2 &= r1   ///  r2 = r2.and(r1)
    rsh64 r2, 8                                     r2 >>= 8   ///  r2 = r2.wrapping_shr(8)
    or64 r8, r2                                     r8 |= r2   ///  r8 = r8.or(r2)
    lddw r1, 0xfffe0000                             r1 load str located at 4294836224
    mov64 r2, r8                                    r2 = r8
    and64 r2, r1                                    r2 &= r1   ///  r2 = r2.and(r1)
    rsh64 r2, 16                                    r2 >>= 16   ///  r2 = r2.wrapping_shr(16)
    or64 r8, r2                                     r8 |= r2   ///  r8 = r8.or(r2)
    xor64 r8, -1                                    r8 ^= -1   ///  r8 = r8.xor(-1)
    and64 r8, -2                                    r8 &= -2   ///  r8 = r8.and(-2)
    mov64 r1, r8                                    r1 = r8
    rsh64 r1, 1                                     r1 >>= 1   ///  r1 = r1.wrapping_shr(1)
    and64 r1, 1431655765                            r1 &= 1431655765   ///  r1 = r1.and(1431655765)
    sub64 r8, r1                                    r8 -= r1   ///  r8 = r8.wrapping_sub(r1)
    mov64 r2, r8                                    r2 = r8
    and64 r2, 858993459                             r2 &= 858993459   ///  r2 = r2.and(858993459)
    rsh64 r8, 2                                     r8 >>= 2   ///  r8 = r8.wrapping_shr(2)
    and64 r8, 858993459                             r8 &= 858993459   ///  r8 = r8.and(858993459)
    add64 r2, r8                                    r2 += r8   ///  r2 = r2.wrapping_add(r8)
    mov64 r1, r2                                    r1 = r2
    rsh64 r1, 4                                     r1 >>= 4   ///  r1 = r1.wrapping_shr(4)
    add64 r2, r1                                    r2 += r1   ///  r2 = r2.wrapping_add(r1)
    mov64 r1, 3                                     r1 = 3 as i32 as i64 as u64
    and64 r2, 252645135                             r2 &= 252645135   ///  r2 = r2.and(252645135)
    mul64 r2, 16843009                              r2 *= 16843009   ///  r2 = r2.wrapping_mul(16843009 as u64)
    rsh64 r2, 26                                    r2 >>= 26   ///  r2 = r2.wrapping_shr(26)
    and64 r2, 63                                    r2 &= 63   ///  r2 = r2.and(63)
    xor64 r2, 7                                     r2 ^= 7   ///  r2 = r2.xor(7)
    ja lbb_19193                                    if true { pc += 66 }
lbb_19127:
    lddw r1, 0x10002d192 --> b"\x00 _"\x82\xdf\x04\x82D\x08\x1b\x04\x06\x11\x81\xac\x0e\x80\xab\x05\x1f\…        r1 load str located at 4295152018
    stxdw [r10-0xff8], r1                   
    mov64 r1, 303                                   r1 = 303 as i32 as i64 as u64
    stxdw [r10-0xff0], r1                   
    mov64 r1, 288                                   r1 = 288 as i32 as i64 as u64
    stxdw [r10-0x1000], r1                  
    mov64 r5, r10                                   r5 = r10
    mov64 r1, r7                                    r1 = r7
    lddw r2, 0x10002d022 --> b"\x00\x01\x03\x05\x05\x06\x06\x02\x07\x06\x08\x07\x09\x11\x0a\x1c\x0b\x19\…        r2 load str located at 4295151650
    mov64 r3, 40                                    r3 = 40 as i32 as i64 as u64
    lddw r4, 0x10002d072 --> b"\xadxy\x8b\x8d\xa20WX\x8b\x8c\x90\x1c\xdd\x0e\x0fKL\xfb\xfc./?\]_\xe2\x84…        r4 load str located at 4295151730
    call function_21290                     
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    mov64 r4, r7                                    r4 = r7
    jne r0, 0, lbb_19193                            if r0 != (0 as i32 as i64 as u64) { pc += 48 }
    ja lbb_19070                                    if true { pc += -76 }
lbb_19146:
    mov64 r1, r8                                    r1 = r8
    lsh64 r1, 32                                    r1 <<= 32   ///  r1 = r1.wrapping_shl(32)
    rsh64 r1, 32                                    r1 >>= 32   ///  r1 = r1.wrapping_shr(32)
    jgt r1, 917999, lbb_19070                       if r1 > (917999 as i32 as i64 as u64) { pc += -80 }
    mov64 r1, r8                                    r1 = r8
    and64 r1, 2097150                               r1 &= 2097150   ///  r1 = r1.and(2097150)
    jeq r1, 178206, lbb_19070                       if r1 == (178206 as i32 as i64 as u64) { pc += -83 }
    mov64 r1, r8                                    r1 = r8
    and64 r1, 2097120                               r1 &= 2097120   ///  r1 = r1.and(2097120)
    jeq r1, 173792, lbb_19070                       if r1 == (173792 as i32 as i64 as u64) { pc += -86 }
    mov64 r1, r8                                    r1 = r8
    add64 r1, -177977                               r1 += -177977   ///  r1 = r1.wrapping_add(-177977 as i32 as i64 as u64)
    lsh64 r1, 32                                    r1 <<= 32   ///  r1 = r1.wrapping_shl(32)
    rsh64 r1, 32                                    r1 >>= 32   ///  r1 = r1.wrapping_shr(32)
    mov64 r2, 7                                     r2 = 7 as i32 as i64 as u64
    jgt r2, r1, lbb_19070                           if r2 > r1 { pc += -92 }
    mov64 r1, r8                                    r1 = r8
    add64 r1, -183970                               r1 += -183970   ///  r1 = r1.wrapping_add(-183970 as i32 as i64 as u64)
    lsh64 r1, 32                                    r1 <<= 32   ///  r1 = r1.wrapping_shl(32)
    rsh64 r1, 32                                    r1 >>= 32   ///  r1 = r1.wrapping_shr(32)
    mov64 r2, 14                                    r2 = 14 as i32 as i64 as u64
    jgt r2, r1, lbb_19070                           if r2 > r1 { pc += -98 }
    mov64 r1, r8                                    r1 = r8
    add64 r1, -191457                               r1 += -191457   ///  r1 = r1.wrapping_add(-191457 as i32 as i64 as u64)
    lsh64 r1, 32                                    r1 <<= 32   ///  r1 = r1.wrapping_shl(32)
    rsh64 r1, 32                                    r1 >>= 32   ///  r1 = r1.wrapping_shr(32)
    mov64 r2, 3103                                  r2 = 3103 as i32 as i64 as u64
    jgt r2, r1, lbb_19070                           if r2 > r1 { pc += -104 }
    mov64 r1, r8                                    r1 = r8
    add64 r1, -195102                               r1 += -195102   ///  r1 = r1.wrapping_add(-195102 as i32 as i64 as u64)
    lsh64 r1, 32                                    r1 <<= 32   ///  r1 = r1.wrapping_shl(32)
    rsh64 r1, 32                                    r1 >>= 32   ///  r1 = r1.wrapping_shr(32)
    mov64 r2, 1506                                  r2 = 1506 as i32 as i64 as u64
    jgt r2, r1, lbb_19070                           if r2 > r1 { pc += -110 }
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    mov64 r3, r8                                    r3 = r8
    add64 r3, -201547                               r3 += -201547   ///  r3 = r3.wrapping_add(-201547 as i32 as i64 as u64)
    lsh64 r3, 32                                    r3 <<= 32   ///  r3 = r3.wrapping_shl(32)
    rsh64 r3, 32                                    r3 >>= 32   ///  r3 = r3.wrapping_shr(32)
    mov64 r5, 716213                                r5 = 716213 as i32 as i64 as u64
    mov64 r4, r7                                    r4 = r7
    jgt r5, r3, lbb_19070                           if r5 > r3 { pc += -118 }
    ja lbb_19193                                    if true { pc += 4 }
lbb_19189:
    mov64 r4, 39                                    r4 = 39 as i32 as i64 as u64
    mov64 r5, r3                                    r5 = r3
    and64 r5, 256                                   r5 &= 256   ///  r5 = r5.and(256)
    jeq r5, 0, lbb_19041                            if r5 == (0 as i32 as i64 as u64) { pc += -152 }
lbb_19193:
    mov64 r3, 5                                     r3 = 5 as i32 as i64 as u64
    stxb [r6+0x14], r3                      
    stxw [r6+0x10], r7                      
    stxdw [r6+0x8], r2                      
    stxw [r6+0x4], r4                       
    stxw [r6+0x0], r1                       
    exit                                    

function_19200:
    mov64 r8, r1                                    r8 = r1
    ldxdw r6, [r2+0x20]                     
    ldxdw r7, [r2+0x28]                     
    ldxdw r4, [r7+0x18]                     
    mov64 r1, r6                                    r1 = r6
    lddw r2, 0x10002cde2 --> b"panicked at "        r2 load str located at 4295151074
    mov64 r3, 12                                    r3 = 12 as i32 as i64 as u64
    callx r4                                
    mov64 r9, 1                                     r9 = 1 as i32 as i64 as u64
    jne r0, 0, lbb_19304                            if r0 != (0 as i32 as i64 as u64) { pc += 93 }
    ldxdw r1, [r8+0x10]                     
    jeq r1, 0, lbb_19239                            if r1 == (0 as i32 as i64 as u64) { pc += 26 }
    stxdw [r10-0x68], r1                    
    lddw r1, 0x10002a650 --> b"y&(\x00\x00\x00\x00\x00y' \x00\x00\x00\x00\x00y\x12\x00\x00\x00\x00\x00\x…        r1 load str located at 4295140944
    stxdw [r10-0x58], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -104                                  r1 += -104   ///  r1 = r1.wrapping_add(-104 as i32 as i64 as u64)
    stxdw [r10-0x60], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -96                                   r1 += -96   ///  r1 = r1.wrapping_add(-96 as i32 as i64 as u64)
    stxdw [r10-0x10], r1                    
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    stxdw [r10-0x20], r1                    
    mov64 r1, 2                                     r1 = 2 as i32 as i64 as u64
    stxdw [r10-0x28], r1                    
    lddw r1, 0x10002e128 --> b"\x00\x00\x00\x00\xee\xcd\x02\x00\x01\x00\x00\x00\x00\x00\x00\x00\x00\x00\…        r1 load str located at 4295156008
    stxdw [r10-0x30], r1                    
    mov64 r9, 1                                     r9 = 1 as i32 as i64 as u64
    stxdw [r10-0x8], r9                     
    mov64 r3, r10                                   r3 = r10
    add64 r3, -48                                   r3 += -48   ///  r3 = r3.wrapping_add(-48 as i32 as i64 as u64)
    mov64 r1, r6                                    r1 = r6
    mov64 r2, r7                                    r2 = r7
    call function_19901                     
    jne r0, 0, lbb_19304                            if r0 != (0 as i32 as i64 as u64) { pc += 66 }
    ja lbb_19272                                    if true { pc += 33 }
lbb_19239:
    ldxdw r9, [r8+0x0]                      
    ldxdw r1, [r8+0x8]                      
    ldxdw r2, [r1+0x18]                     
    mov64 r1, r9                                    r1 = r9
    callx r2                                
    lddw r1, 0xb8ae3dc722b9f20b                     r1 load str located at -5139102199292759541
    jne r0, r1, lbb_19272                           if r0 != r1 { pc += 25 }
    stxdw [r10-0x68], r9                    
    lddw r1, 0x10002a618 --> b"\xbf$\x00\x00\x00\x00\x00\x00y\x11\x00\x00\x00\x00\x00\x00y\x13\x08\x00\x…        r1 load str located at 4295140888
    stxdw [r10-0x58], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -104                                  r1 += -104   ///  r1 = r1.wrapping_add(-104 as i32 as i64 as u64)
    stxdw [r10-0x60], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -96                                   r1 += -96   ///  r1 = r1.wrapping_add(-96 as i32 as i64 as u64)
    stxdw [r10-0x10], r1                    
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    stxdw [r10-0x20], r1                    
    mov64 r1, 2                                     r1 = 2 as i32 as i64 as u64
    stxdw [r10-0x28], r1                    
    lddw r1, 0x10002e128 --> b"\x00\x00\x00\x00\xee\xcd\x02\x00\x01\x00\x00\x00\x00\x00\x00\x00\x00\x00\…        r1 load str located at 4295156008
    stxdw [r10-0x30], r1                    
    mov64 r9, 1                                     r9 = 1 as i32 as i64 as u64
    stxdw [r10-0x8], r9                     
    mov64 r3, r10                                   r3 = r10
    add64 r3, -48                                   r3 += -48   ///  r3 = r3.wrapping_add(-48 as i32 as i64 as u64)
    mov64 r1, r6                                    r1 = r6
    mov64 r2, r7                                    r2 = r7
    call function_19901                     
    jne r0, 0, lbb_19304                            if r0 != (0 as i32 as i64 as u64) { pc += 32 }
lbb_19272:
    ldxdw r1, [r8+0x18]                     
    mov64 r2, r1                                    r2 = r1
    add64 r2, 20                                    r2 += 20   ///  r2 = r2.wrapping_add(20 as i32 as i64 as u64)
    stxdw [r10-0x40], r2                    
    lddw r2, 0x10002a558 --> b"\xbf#\x00\x00\x00\x00\x00\x00a\x11\x00\x00\x00\x00\x00\x00\xb7\x02\x00\x0…        r2 load str located at 4295140696
    stxdw [r10-0x38], r2                    
    stxdw [r10-0x48], r2                    
    mov64 r2, r1                                    r2 = r1
    add64 r2, 16                                    r2 += 16   ///  r2 = r2.wrapping_add(16 as i32 as i64 as u64)
    stxdw [r10-0x50], r2                    
    lddw r2, 0x10002a6b8 --> b"\xbf$\x00\x00\x00\x00\x00\x00y\x13\x08\x00\x00\x00\x00\x00y\x12\x00\x00\x…        r2 load str located at 4295141048
    stxdw [r10-0x58], r2                    
    stxdw [r10-0x60], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -96                                   r1 += -96   ///  r1 = r1.wrapping_add(-96 as i32 as i64 as u64)
    stxdw [r10-0x10], r1                    
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    stxdw [r10-0x20], r1                    
    mov64 r1, 3                                     r1 = 3 as i32 as i64 as u64
    stxdw [r10-0x8], r1                     
    stxdw [r10-0x28], r1                    
    lddw r1, 0x10002e0d8 --> b"\x00\x00\x00\x00\x80\xcd\x02\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\…        r1 load str located at 4295155928
    stxdw [r10-0x30], r1                    
    mov64 r3, r10                                   r3 = r10
    add64 r3, -48                                   r3 += -48   ///  r3 = r3.wrapping_add(-48 as i32 as i64 as u64)
    mov64 r1, r6                                    r1 = r6
    mov64 r2, r7                                    r2 = r7
    call function_19901                     
    mov64 r9, r0                                    r9 = r0
lbb_19304:
    mov64 r0, r9                                    r0 = r9
    exit                                    

function_19306:
    lddw r4, 0x10002cd80 --> b")..BorrowErrorBorrowMutError but the index is     "        r4 load str located at 4295150976
    stxdw [r10-0x20], r4                    
    mov64 r4, 0                                     r4 = 0 as i32 as i64 as u64
    stxdw [r10-0x18], r4                    
    stxdw [r10-0x30], r4                    
    mov64 r4, 1                                     r4 = 1 as i32 as i64 as u64
    stxdw [r10-0x38], r4                    
    mov64 r4, r10                                   r4 = r10
    add64 r4, -16                                   r4 += -16   ///  r4 = r4.wrapping_add(-16 as i32 as i64 as u64)
    stxdw [r10-0x40], r4                    
    stxdw [r10-0x8], r2                     
    stxdw [r10-0x10], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -64                                   r1 += -64   ///  r1 = r1.wrapping_add(-64 as i32 as i64 as u64)
    mov64 r2, r3                                    r2 = r3
    call function_19352                     
    syscall [invalid]                       

function_19324:
    stxdw [r10-0x58], r2                    
    stxdw [r10-0x60], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -32                                   r1 += -32   ///  r1 = r1.wrapping_add(-32 as i32 as i64 as u64)
    stxdw [r10-0x30], r1                    
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    stxdw [r10-0x40], r1                    
    mov64 r1, 2                                     r1 = 2 as i32 as i64 as u64
    stxdw [r10-0x28], r1                    
    stxdw [r10-0x48], r1                    
    lddw r1, 0x10002e0b8 --> b"\x00\x00\x00\x00F\xc2\x02\x00 \x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x0…        r1 load str located at 4295155896
    stxdw [r10-0x50], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -96                                   r1 += -96   ///  r1 = r1.wrapping_add(-96 as i32 as i64 as u64)
    stxdw [r10-0x10], r1                    
    lddw r1, 0x10002a580 --> b"\xbf#\x00\x00\x00\x00\x00\x00y\x11\x00\x00\x00\x00\x00\x00\xb7\x02\x00\x0…        r1 load str located at 4295140736
    stxdw [r10-0x8], r1                     
    stxdw [r10-0x18], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -88                                   r1 += -88   ///  r1 = r1.wrapping_add(-88 as i32 as i64 as u64)
    stxdw [r10-0x20], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -80                                   r1 += -80   ///  r1 = r1.wrapping_add(-80 as i32 as i64 as u64)
    mov64 r2, r3                                    r2 = r3
    call function_19352                     
    syscall [invalid]                       

function_19352:
    mov64 r3, 1                                     r3 = 1 as i32 as i64 as u64
    stxb [r10-0x8], r3                      
    stxdw [r10-0x10], r2                    
    stxdw [r10-0x18], r1                    
    lddw r1, 0x10002e108 --> b"\x00\x00\x00\x00 Q\x02\x00\x00\x00\x00\x00\x00\x00\x00\x00\x01\x00\x00\x0…        r1 load str located at 4295155976
    stxdw [r10-0x20], r1                    
    lddw r1, 0x10002cd80 --> b")..BorrowErrorBorrowMutError but the index is     "        r1 load str located at 4295150976
    stxdw [r10-0x28], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -40                                   r1 += -40   ///  r1 = r1.wrapping_add(-40 as i32 as i64 as u64)
    call function_18567                     
    syscall [invalid]                       

function_19366:
    stxdw [r10-0x68], r2                    
    stxdw [r10-0x70], r1                    
    stxdw [r10-0x58], r4                    
    stxdw [r10-0x60], r3                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -32                                   r1 += -32   ///  r1 = r1.wrapping_add(-32 as i32 as i64 as u64)
    stxdw [r10-0x30], r1                    
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    stxdw [r10-0x40], r1                    
    mov64 r1, 2                                     r1 = 2 as i32 as i64 as u64
    stxdw [r10-0x28], r1                    
    stxdw [r10-0x48], r1                    
    lddw r1, 0x10002e148 --> b"\x00\x00\x00\x00\x80\xcd\x02\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\…        r1 load str located at 4295156040
    stxdw [r10-0x50], r1                    
    lddw r1, 0x10002a5e8 --> b"y\x13\x00\x00\x00\x00\x00\x00y\x11\x08\x00\x00\x00\x00\x00y\x14\x18\x00\x…        r1 load str located at 4295140840
    stxdw [r10-0x8], r1                     
    mov64 r1, r10                                   r1 = r10
    add64 r1, -96                                   r1 += -96   ///  r1 = r1.wrapping_add(-96 as i32 as i64 as u64)
    stxdw [r10-0x10], r1                    
    lddw r1, 0x10002a6b8 --> b"\xbf$\x00\x00\x00\x00\x00\x00y\x13\x08\x00\x00\x00\x00\x00y\x12\x00\x00\x…        r1 load str located at 4295141048
    stxdw [r10-0x18], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -112                                  r1 += -112   ///  r1 = r1.wrapping_add(-112 as i32 as i64 as u64)
    stxdw [r10-0x20], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -80                                   r1 += -80   ///  r1 = r1.wrapping_add(-80 as i32 as i64 as u64)
    mov64 r2, r5                                    r2 = r5
    call function_19352                     
    syscall [invalid]                       

function_19398:
    mov64 r6, r3                                    r6 = r3
    mov64 r7, r2                                    r7 = r2
    mov64 r0, 0                                     r0 = 0 as i32 as i64 as u64
    jeq r6, 0, lbb_19424                            if r6 == (0 as i32 as i64 as u64) { pc += 22 }
    ldxdw r8, [r1+0x8]                      
    ldxdw r2, [r1+0x0]                      
    stxdw [r10-0x10], r2                    
    ldxdw r1, [r1+0x10]                     
    stxdw [r10-0x8], r1                     
    stxdw [r10-0x28], r8                    
    ja lbb_19425                                    if true { pc += 16 }
lbb_19409:
    ldxdw r4, [r8+0x18]                     
    ldxdw r1, [r10-0x10]                    
    mov64 r2, r7                                    r2 = r7
    mov64 r3, r9                                    r3 = r9
    callx r4                                
    mov64 r1, r0                                    r1 = r0
    mov64 r0, 1                                     r0 = 1 as i32 as i64 as u64
    jne r1, 0, lbb_19424                            if r1 != (0 as i32 as i64 as u64) { pc += 7 }
    jgt r6, r9, lbb_19572                           if r6 > r9 { pc += 154 }
    jeq r6, r9, lbb_19420                           if r6 == r9 { pc += 1 }
    ja lbb_19578                                    if true { pc += 158 }
lbb_19420:
    add64 r7, r9                                    r7 += r9   ///  r7 = r7.wrapping_add(r9)
    sub64 r6, r9                                    r6 -= r9   ///  r6 = r6.wrapping_sub(r9)
    mov64 r0, 0                                     r0 = 0 as i32 as i64 as u64
    jne r6, 0, lbb_19425                            if r6 != (0 as i32 as i64 as u64) { pc += 1 }
lbb_19424:
    exit                                    
lbb_19425:
    ldxdw r1, [r10-0x8]                     
    ldxb r1, [r1+0x0]                       
    jne r1, 0, lbb_19550                            if r1 != (0 as i32 as i64 as u64) { pc += 122 }
lbb_19428:
    mov64 r4, 0                                     r4 = 0 as i32 as i64 as u64
    mov64 r2, r6                                    r2 = r6
lbb_19430:
    mov64 r1, 16                                    r1 = 16 as i32 as i64 as u64
    jgt r1, r2, lbb_19478                           if r1 > r2 { pc += 46 }
    mov64 r1, r7                                    r1 = r7
    add64 r1, r4                                    r1 += r4   ///  r1 = r1.wrapping_add(r4)
    mov64 r3, r1                                    r3 = r1
    add64 r3, 7                                     r3 += 7   ///  r3 = r3.wrapping_add(7 as i32 as i64 as u64)
    and64 r3, -8                                    r3 &= -8   ///  r3 = r3.and(-8)
    sub64 r3, r1                                    r3 -= r1   ///  r3 = r3.wrapping_sub(r1)
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    jne r3, 0, lbb_19505                            if r3 != (0 as i32 as i64 as u64) { pc += 65 }
lbb_19440:
    mov64 r3, r2                                    r3 = r2
    add64 r3, -16                                   r3 += -16   ///  r3 = r3.wrapping_add(-16 as i32 as i64 as u64)
    jgt r1, r3, lbb_19489                           if r1 > r3 { pc += 46 }
    stxdw [r10-0x20], r6                    
    stxdw [r10-0x18], r7                    
    mov64 r5, r7                                    r5 = r7
    add64 r5, r4                                    r5 += r4   ///  r5 = r5.wrapping_add(r4)
lbb_19447:
    mov64 r0, r5                                    r0 = r5
    add64 r0, r1                                    r0 += r1   ///  r0 = r0.wrapping_add(r1)
    ldxdw r8, [r0+0x8]                      
    mov64 r9, r8                                    r9 = r8
    lddw r7, 0xa0a0a0a0a0a0a0a                      r7 load str located at 723401728380766730
    xor64 r9, r7                                    r9 ^= r7   ///  r9 = r9.xor(r7)
    lddw r6, 0xfefefefefefefeff                     r6 load str located at -72340172838076673
    add64 r9, r6                                    r9 += r6   ///  r9 = r9.wrapping_add(r6)
    xor64 r8, -1                                    r8 ^= -1   ///  r8 = r8.xor(-1)
    and64 r8, r9                                    r8 &= r9   ///  r8 = r8.and(r9)
    ldxdw r0, [r0+0x0]                      
    mov64 r9, r0                                    r9 = r0
    xor64 r9, r7                                    r9 ^= r7   ///  r9 = r9.xor(r7)
    add64 r9, r6                                    r9 += r6   ///  r9 = r9.wrapping_add(r6)
    xor64 r0, -1                                    r0 ^= -1   ///  r0 = r0.xor(-1)
    and64 r0, r9                                    r0 &= r9   ///  r0 = r0.and(r9)
    or64 r0, r8                                     r0 |= r8   ///  r0 = r0.or(r8)
    lddw r6, 0x8080808080808080                     r6 load str located at -9187201950435737472
    and64 r0, r6                                    r0 &= r6   ///  r0 = r0.and(r6)
    jne r0, 0, lbb_19472                            if r0 != (0 as i32 as i64 as u64) { pc += 2 }
    add64 r1, 16                                    r1 += 16   ///  r1 = r1.wrapping_add(16 as i32 as i64 as u64)
    jge r3, r1, lbb_19447                           if r3 >= r1 { pc += -25 }
lbb_19472:
    ldxdw r8, [r10-0x28]                    
    ldxdw r7, [r10-0x18]                    
    ldxdw r6, [r10-0x20]                    
    jge r2, r1, lbb_19489                           if r2 >= r1 { pc += 13 }
    call function_20695                     
    syscall [invalid]                       
lbb_19478:
    jeq r2, 0, lbb_19545                            if r2 == (0 as i32 as i64 as u64) { pc += 66 }
    mov64 r1, r7                                    r1 = r7
    add64 r1, r4                                    r1 += r4   ///  r1 = r1.wrapping_add(r4)
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
lbb_19482:
    mov64 r5, r1                                    r5 = r1
    add64 r5, r3                                    r5 += r3   ///  r5 = r5.wrapping_add(r3)
    ldxb r5, [r5+0x0]                       
    jeq r5, 10, lbb_19520                           if r5 == (10 as i32 as i64 as u64) { pc += 34 }
    add64 r3, 1                                     r3 += 1   ///  r3 = r3.wrapping_add(1 as i32 as i64 as u64)
    jeq r2, r3, lbb_19545                           if r2 == r3 { pc += 57 }
    ja lbb_19482                                    if true { pc += -7 }
lbb_19489:
    jeq r1, r2, lbb_19545                           if r1 == r2 { pc += 55 }
    mov64 r3, r7                                    r3 = r7
    add64 r3, r4                                    r3 += r4   ///  r3 = r3.wrapping_add(r4)
    mov64 r5, r1                                    r5 = r1
    sub64 r5, r2                                    r5 -= r2   ///  r5 = r5.wrapping_sub(r2)
    add64 r3, r1                                    r3 += r1   ///  r3 = r3.wrapping_add(r1)
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
lbb_19496:
    mov64 r0, r3                                    r0 = r3
    add64 r0, r2                                    r0 += r2   ///  r0 = r0.wrapping_add(r2)
    ldxb r0, [r0+0x0]                       
    jeq r0, 10, lbb_19518                           if r0 == (10 as i32 as i64 as u64) { pc += 18 }
    add64 r2, 1                                     r2 += 1   ///  r2 = r2.wrapping_add(1 as i32 as i64 as u64)
    mov64 r0, r5                                    r0 = r5
    add64 r0, r2                                    r0 += r2   ///  r0 = r0.wrapping_add(r2)
    jeq r0, 0, lbb_19545                            if r0 == (0 as i32 as i64 as u64) { pc += 41 }
    ja lbb_19496                                    if true { pc += -9 }
lbb_19505:
    mov64 r1, r2                                    r1 = r2
    jgt r3, r2, lbb_19508                           if r3 > r2 { pc += 1 }
    mov64 r1, r3                                    r1 = r3
lbb_19508:
    mov64 r5, r7                                    r5 = r7
    add64 r5, r4                                    r5 += r4   ///  r5 = r5.wrapping_add(r4)
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
lbb_19511:
    mov64 r0, r5                                    r0 = r5
    add64 r0, r3                                    r0 += r3   ///  r0 = r0.wrapping_add(r3)
    ldxb r0, [r0+0x0]                       
    jeq r0, 10, lbb_19520                           if r0 == (10 as i32 as i64 as u64) { pc += 5 }
    add64 r3, 1                                     r3 += 1   ///  r3 = r3.wrapping_add(1 as i32 as i64 as u64)
    jeq r1, r3, lbb_19440                           if r1 == r3 { pc += -77 }
    ja lbb_19511                                    if true { pc += -7 }
lbb_19518:
    add64 r1, r2                                    r1 += r2   ///  r1 = r1.wrapping_add(r2)
    mov64 r3, r1                                    r3 = r1
lbb_19520:
    add64 r3, r4                                    r3 += r4   ///  r3 = r3.wrapping_add(r4)
    mov64 r4, r3                                    r4 = r3
    add64 r4, 1                                     r4 += 1   ///  r4 = r4.wrapping_add(1 as i32 as i64 as u64)
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    jgt r3, r4, lbb_19526                           if r3 > r4 { pc += 1 }
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
lbb_19526:
    and64 r1, 1                                     r1 &= 1   ///  r1 = r1.and(1)
    jne r1, 0, lbb_19529                            if r1 != (0 as i32 as i64 as u64) { pc += 1 }
    jge r6, r4, lbb_19533                           if r6 >= r4 { pc += 4 }
lbb_19529:
    mov64 r2, r6                                    r2 = r6
    sub64 r2, r4                                    r2 -= r4   ///  r2 = r2.wrapping_sub(r4)
    jgt r4, r6, lbb_19545                           if r4 > r6 { pc += 13 }
    ja lbb_19430                                    if true { pc += -103 }
lbb_19533:
    mov64 r1, r7                                    r1 = r7
    add64 r1, r3                                    r1 += r3   ///  r1 = r1.wrapping_add(r3)
    ldxb r1, [r1+0x0]                       
    jeq r1, 10, lbb_19538                           if r1 == (10 as i32 as i64 as u64) { pc += 1 }
    ja lbb_19529                                    if true { pc += -9 }
lbb_19538:
    ldxdw r1, [r10-0x8]                     
    mov64 r2, 1                                     r2 = 1 as i32 as i64 as u64
    stxb [r1+0x0], r2                       
    jgt r6, r4, lbb_19560                           if r6 > r4 { pc += 18 }
lbb_19542:
    mov64 r9, r6                                    r9 = r6
    jeq r6, r4, lbb_19409                           if r6 == r4 { pc += -135 }
    ja lbb_19567                                    if true { pc += 22 }
lbb_19545:
    ldxdw r1, [r10-0x8]                     
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
    stxb [r1+0x0], r2                       
    mov64 r4, r6                                    r4 = r6
    ja lbb_19542                                    if true { pc += -8 }
lbb_19550:
    ldxdw r4, [r8+0x18]                     
    ldxdw r1, [r10-0x10]                    
    lddw r2, 0x10002cdae --> b"    "                r2 load str located at 4295151022
    mov64 r3, 4                                     r3 = 4 as i32 as i64 as u64
    callx r4                                
    mov64 r1, r0                                    r1 = r0
    mov64 r0, 1                                     r0 = 1 as i32 as i64 as u64
    jne r1, 0, lbb_19424                            if r1 != (0 as i32 as i64 as u64) { pc += -135 }
    ja lbb_19428                                    if true { pc += -132 }
lbb_19560:
    mov64 r1, r7                                    r1 = r7
    add64 r1, r4                                    r1 += r4   ///  r1 = r1.wrapping_add(r4)
    ldxb r1, [r1+0x0]                       
    lsh64 r1, 56                                    r1 <<= 56   ///  r1 = r1.wrapping_shl(56)
    arsh64 r1, 56                                   r1 >>= 56 (signed)   ///  r1 = (r1 as i64).wrapping_shr(56)
    mov64 r9, r4                                    r9 = r4
    jsgt r1, -65, lbb_19409                         if (r1 as i64) > (-65 as i32 as i64) { pc += -158 }
lbb_19567:
    mov64 r1, r7                                    r1 = r7
    mov64 r2, r6                                    r2 = r6
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
    call function_21000                     
    syscall [invalid]                       
lbb_19572:
    mov64 r1, r7                                    r1 = r7
    add64 r1, r9                                    r1 += r9   ///  r1 = r1.wrapping_add(r9)
    ldxb r1, [r1+0x0]                       
    lsh64 r1, 56                                    r1 <<= 56   ///  r1 = r1.wrapping_shl(56)
    arsh64 r1, 56                                   r1 >>= 56 (signed)   ///  r1 = (r1 as i64).wrapping_shr(56)
    jsgt r1, -65, lbb_19420                         if (r1 as i64) > (-65 as i32 as i64) { pc += -158 }
lbb_19578:
    mov64 r1, r7                                    r1 = r7
    mov64 r2, r6                                    r2 = r6
    mov64 r3, r9                                    r3 = r9
    mov64 r4, r6                                    r4 = r6
    call function_21000                     
    syscall [invalid]                       

function_19584:
    mov64 r8, r2                                    r8 = r2
    mov64 r6, r1                                    r6 = r1
    mov64 r2, 1                                     r2 = 1 as i32 as i64 as u64
    ldxb r1, [r6+0x8]                       
    mov64 r7, 1                                     r7 = 1 as i32 as i64 as u64
    jne r1, 0, lbb_19683                            if r1 != (0 as i32 as i64 as u64) { pc += 93 }
    stxdw [r10-0x68], r3                    
    ldxb r2, [r6+0x9]                       
    ldxdw r9, [r6+0x0]                      
    ldxw r1, [r9+0x30]                      
    mov64 r3, r1                                    r3 = r1
    and64 r3, 4                                     r3 &= 4   ///  r3 = r3.and(4)
    stxdw [r10-0x70], r4                    
    stxdw [r10-0x78], r5                    
    jne r3, 0, lbb_19642                            if r3 != (0 as i32 as i64 as u64) { pc += 43 }
    mov64 r1, r2                                    r1 = r2
    lddw r2, 0x10002cdfc --> b" { } }0x000102030405060708091011121314151617181920"        r2 load str located at 4295151100
    jeq r1, 0, lbb_19605                            if r1 == (0 as i32 as i64 as u64) { pc += 2 }
    lddw r2, 0x10002cdfa --> b",  "                 r2 load str located at 4295151098
lbb_19605:
    mov64 r3, 3                                     r3 = 3 as i32 as i64 as u64
    jeq r1, 0, lbb_19608                            if r1 == (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r3, 2                                     r3 = 2 as i32 as i64 as u64
lbb_19608:
    ldxdw r1, [r9+0x20]                     
    ldxdw r4, [r9+0x28]                     
    ldxdw r4, [r4+0x18]                     
    callx r4                                
    mov64 r7, 1                                     r7 = 1 as i32 as i64 as u64
    mov64 r2, 1                                     r2 = 1 as i32 as i64 as u64
    ldxdw r3, [r10-0x68]                    
    jne r0, 0, lbb_19683                            if r0 != (0 as i32 as i64 as u64) { pc += 67 }
    ldxdw r1, [r9+0x20]                     
    ldxdw r2, [r9+0x28]                     
    ldxdw r4, [r2+0x18]                     
    mov64 r2, r8                                    r2 = r8
    callx r4                                
    mov64 r2, 1                                     r2 = 1 as i32 as i64 as u64
    mov64 r7, 1                                     r7 = 1 as i32 as i64 as u64
    jne r0, 0, lbb_19683                            if r0 != (0 as i32 as i64 as u64) { pc += 59 }
    ldxdw r1, [r9+0x20]                     
    ldxdw r2, [r9+0x28]                     
    ldxdw r4, [r2+0x18]                     
    lddw r2, 0x10002cdf3 --> b": "                  r2 load str located at 4295151091
    mov64 r3, 2                                     r3 = 2 as i32 as i64 as u64
    callx r4                                
    ldxdw r3, [r10-0x78]                    
    ldxdw r1, [r10-0x70]                    
    mov64 r2, 1                                     r2 = 1 as i32 as i64 as u64
    mov64 r7, 1                                     r7 = 1 as i32 as i64 as u64
    jne r0, 0, lbb_19683                            if r0 != (0 as i32 as i64 as u64) { pc += 47 }
    ldxdw r3, [r3+0x18]                     
    mov64 r2, r9                                    r2 = r9
    callx r3                                
    mov64 r2, 1                                     r2 = 1 as i32 as i64 as u64
    mov64 r7, r0                                    r7 = r0
    ja lbb_19683                                    if true { pc += 41 }
lbb_19642:
    jeq r2, 0, lbb_19687                            if r2 == (0 as i32 as i64 as u64) { pc += 44 }
lbb_19643:
    mov64 r7, 1                                     r7 = 1 as i32 as i64 as u64
    stxb [r10-0x41], r7                     
    ldxdw r2, [r9+0x20]                     
    ldxdw r3, [r9+0x28]                     
    mov64 r4, r10                                   r4 = r10
    add64 r4, -65                                   r4 += -65   ///  r4 = r4.wrapping_add(-65 as i32 as i64 as u64)
    stxdw [r10-0x50], r4                    
    stxdw [r10-0x58], r3                    
    stxdw [r10-0x60], r2                    
    ldxdw r2, [r9+0x0]                      
    ldxdw r3, [r9+0x8]                      
    ldxdw r4, [r9+0x10]                     
    ldxdw r5, [r9+0x18]                     
    ldxw r0, [r9+0x34]                      
    ldxb r9, [r9+0x38]                      
    stxb [r10-0x8], r9                      
    stxw [r10-0xc], r0                      
    stxw [r10-0x10], r1                     
    lddw r1, 0x10002e168 --> b"\x00\x00\x00\x00 Q\x02\x00\x18\x00\x00\x00\x00\x00\x00\x00\x08\x00\x00\x0…        r1 load str located at 4295156072
    stxdw [r10-0x18], r1                    
    stxdw [r10-0x28], r5                    
    stxdw [r10-0x30], r4                    
    stxdw [r10-0x38], r3                    
    stxdw [r10-0x40], r2                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -96                                   r1 += -96   ///  r1 = r1.wrapping_add(-96 as i32 as i64 as u64)
    stxdw [r10-0x20], r1                    
    mov64 r2, r8                                    r2 = r8
    ldxdw r3, [r10-0x68]                    
    call function_19398                     
    jne r0, 0, lbb_19682                            if r0 != (0 as i32 as i64 as u64) { pc += 7 }
    mov64 r1, r10                                   r1 = r10
    add64 r1, -96                                   r1 += -96   ///  r1 = r1.wrapping_add(-96 as i32 as i64 as u64)
    lddw r2, 0x10002cdf3 --> b": "                  r2 load str located at 4295151091
    mov64 r3, 2                                     r3 = 2 as i32 as i64 as u64
    call function_19398                     
    jeq r0, 0, lbb_19699                            if r0 == (0 as i32 as i64 as u64) { pc += 17 }
lbb_19682:
    mov64 r2, 1                                     r2 = 1 as i32 as i64 as u64
lbb_19683:
    stxb [r6+0x9], r2                       
    stxb [r6+0x8], r7                       
    mov64 r0, r6                                    r0 = r6
    exit                                    
lbb_19687:
    ldxdw r1, [r9+0x20]                     
    ldxdw r2, [r9+0x28]                     
    ldxdw r4, [r2+0x18]                     
    lddw r2, 0x10002cdf5 --> b" {\x0a"              r2 load str located at 4295151093
    mov64 r3, 3                                     r3 = 3 as i32 as i64 as u64
    callx r4                                
    mov64 r7, 1                                     r7 = 1 as i32 as i64 as u64
    mov64 r2, 1                                     r2 = 1 as i32 as i64 as u64
    jne r0, 0, lbb_19683                            if r0 != (0 as i32 as i64 as u64) { pc += -14 }
    ldxw r1, [r9+0x30]                      
    ja lbb_19643                                    if true { pc += -56 }
lbb_19699:
    ldxdw r1, [r10-0x78]                    
    ldxdw r3, [r1+0x18]                     
    mov64 r2, r10                                   r2 = r10
    add64 r2, -64                                   r2 += -64   ///  r2 = r2.wrapping_add(-64 as i32 as i64 as u64)
    ldxdw r1, [r10-0x70]                    
    callx r3                                
    jne r0, 0, lbb_19682                            if r0 != (0 as i32 as i64 as u64) { pc += -24 }
    ldxdw r1, [r10-0x18]                    
    ldxdw r4, [r1+0x18]                     
    ldxdw r1, [r10-0x20]                    
    lddw r2, 0x10002cdf8 --> b",\x0a"               r2 load str located at 4295151096
    mov64 r3, 2                                     r3 = 2 as i32 as i64 as u64
    callx r4                                
    mov64 r7, r0                                    r7 = r0
    ja lbb_19682                                    if true { pc += -33 }

function_19715:
    mov64 r6, r1                                    r6 = r1
    ldxb r1, [r6+0x8]                       
    ldxb r2, [r6+0x9]                       
    mov64 r0, r1                                    r0 = r1
    jne r2, 0, lbb_19726                            if r2 != (0 as i32 as i64 as u64) { pc += 6 }
lbb_19720:
    and64 r0, 255                                   r0 &= 255   ///  r0 = r0.and(255)
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    jne r0, 0, lbb_19724                            if r0 != (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
lbb_19724:
    mov64 r0, r1                                    r0 = r1
    exit                                    
lbb_19726:
    mov64 r0, 1                                     r0 = 1 as i32 as i64 as u64
    jne r1, 0, lbb_19746                            if r1 != (0 as i32 as i64 as u64) { pc += 18 }
    ldxdw r2, [r6+0x0]                      
    ldxw r1, [r2+0x30]                      
    and64 r1, 4                                     r1 &= 4   ///  r1 = r1.and(4)
    jne r1, 0, lbb_19739                            if r1 != (0 as i32 as i64 as u64) { pc += 7 }
    ldxdw r1, [r2+0x20]                     
    ldxdw r2, [r2+0x28]                     
    ldxdw r4, [r2+0x18]                     
    lddw r2, 0x10002ce00 --> b" }"                  r2 load str located at 4295151104
    mov64 r3, 2                                     r3 = 2 as i32 as i64 as u64
    ja lbb_19745                                    if true { pc += 6 }
lbb_19739:
    ldxdw r1, [r2+0x20]                     
    ldxdw r2, [r2+0x28]                     
    ldxdw r4, [r2+0x18]                     
    lddw r2, 0x10002cdff --> b"}"                   r2 load str located at 4295151103
    mov64 r3, 1                                     r3 = 1 as i32 as i64 as u64
lbb_19745:
    callx r4                                
lbb_19746:
    stxb [r6+0x8], r0                       
    ja lbb_19720                                    if true { pc += -28 }

function_19748:
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
    stxw [r10-0x4], r3                      
    mov64 r3, r2                                    r3 = r2
    lsh64 r3, 32                                    r3 <<= 32   ///  r3 = r3.wrapping_shl(32)
    rsh64 r3, 32                                    r3 >>= 32   ///  r3 = r3.wrapping_shr(32)
    mov64 r4, 128                                   r4 = 128 as i32 as i64 as u64
    jgt r4, r3, lbb_19776                           if r4 > r3 { pc += 21 }
    mov64 r4, 2048                                  r4 = 2048 as i32 as i64 as u64
    jgt r4, r3, lbb_19779                           if r4 > r3 { pc += 22 }
    mov64 r3, r2                                    r3 = r2
    lsh64 r3, 32                                    r3 <<= 32   ///  r3 = r3.wrapping_shl(32)
    rsh64 r3, 32                                    r3 >>= 32   ///  r3 = r3.wrapping_shr(32)
    mov64 r4, 65536                                 r4 = 65536 as i32 as i64 as u64
    jgt r4, r3, lbb_19763                           if r4 > r3 { pc += 1 }
    ja lbb_19788                                    if true { pc += 25 }
lbb_19763:
    and64 r2, 63                                    r2 &= 63   ///  r2 = r2.and(63)
    or64 r2, 128                                    r2 |= 128   ///  r2 = r2.or(128)
    stxb [r10-0x2], r2                      
    mov64 r2, r3                                    r2 = r3
    rsh64 r2, 12                                    r2 >>= 12   ///  r2 = r2.wrapping_shr(12)
    or64 r2, 224                                    r2 |= 224   ///  r2 = r2.or(224)
    stxb [r10-0x4], r2                      
    rsh64 r3, 6                                     r3 >>= 6   ///  r3 = r3.wrapping_shr(6)
    and64 r3, 63                                    r3 &= 63   ///  r3 = r3.and(63)
    or64 r3, 128                                    r3 |= 128   ///  r3 = r3.or(128)
    stxb [r10-0x3], r3                      
    mov64 r3, 3                                     r3 = 3 as i32 as i64 as u64
    ja lbb_19805                                    if true { pc += 29 }
lbb_19776:
    stxb [r10-0x4], r2                      
    mov64 r3, 1                                     r3 = 1 as i32 as i64 as u64
    ja lbb_19805                                    if true { pc += 26 }
lbb_19779:
    mov64 r3, r2                                    r3 = r2
    and64 r3, 63                                    r3 &= 63   ///  r3 = r3.and(63)
    or64 r3, 128                                    r3 |= 128   ///  r3 = r3.or(128)
    stxb [r10-0x3], r3                      
    rsh64 r2, 6                                     r2 >>= 6   ///  r2 = r2.wrapping_shr(6)
    or64 r2, 192                                    r2 |= 192   ///  r2 = r2.or(192)
    stxb [r10-0x4], r2                      
    mov64 r3, 2                                     r3 = 2 as i32 as i64 as u64
    ja lbb_19805                                    if true { pc += 17 }
lbb_19788:
    and64 r2, 63                                    r2 &= 63   ///  r2 = r2.and(63)
    or64 r2, 128                                    r2 |= 128   ///  r2 = r2.or(128)
    stxb [r10-0x1], r2                      
    mov64 r2, r3                                    r2 = r3
    rsh64 r2, 18                                    r2 >>= 18   ///  r2 = r2.wrapping_shr(18)
    or64 r2, 240                                    r2 |= 240   ///  r2 = r2.or(240)
    stxb [r10-0x4], r2                      
    mov64 r2, r3                                    r2 = r3
    rsh64 r2, 6                                     r2 >>= 6   ///  r2 = r2.wrapping_shr(6)
    and64 r2, 63                                    r2 &= 63   ///  r2 = r2.and(63)
    or64 r2, 128                                    r2 |= 128   ///  r2 = r2.or(128)
    stxb [r10-0x2], r2                      
    rsh64 r3, 12                                    r3 >>= 12   ///  r3 = r3.wrapping_shr(12)
    and64 r3, 63                                    r3 &= 63   ///  r3 = r3.and(63)
    or64 r3, 128                                    r3 |= 128   ///  r3 = r3.or(128)
    stxb [r10-0x3], r3                      
    mov64 r3, 4                                     r3 = 4 as i32 as i64 as u64
lbb_19805:
    mov64 r2, r10                                   r2 = r10
    add64 r2, -4                                    r2 += -4   ///  r2 = r2.wrapping_add(-4 as i32 as i64 as u64)
    call function_19398                     
    exit                                    

function_19809:
    stxdw [r10-0x38], r1                    
    mov64 r6, r10                                   r6 = r10
    add64 r6, -48                                   r6 += -48   ///  r6 = r6.wrapping_add(-48 as i32 as i64 as u64)
    mov64 r1, r6                                    r1 = r6
    mov64 r3, 48                                    r3 = 48 as i32 as i64 as u64
    call function_21797                     
    mov64 r1, r10                                   r1 = r10
    add64 r1, -56                                   r1 += -56   ///  r1 = r1.wrapping_add(-56 as i32 as i64 as u64)
    lddw r2, 0x10002e198 --> b"\x00\x00\x00\x00 Q\x02\x00\x08\x00\x00\x00\x00\x00\x00\x00\x08\x00\x00\x0…        r2 load str located at 4295156120
    mov64 r3, r6                                    r3 = r6
    call function_19901                     
    exit                                    

function_19822:
    ldxdw r1, [r1+0x0]                      
    call function_19398                     
    exit                                    

function_19825:
    ldxdw r1, [r1+0x0]                      
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
    stxw [r10-0x4], r3                      
    mov64 r3, r2                                    r3 = r2
    lsh64 r3, 32                                    r3 <<= 32   ///  r3 = r3.wrapping_shl(32)
    rsh64 r3, 32                                    r3 >>= 32   ///  r3 = r3.wrapping_shr(32)
    mov64 r4, 128                                   r4 = 128 as i32 as i64 as u64
    jgt r4, r3, lbb_19854                           if r4 > r3 { pc += 21 }
    mov64 r4, 2048                                  r4 = 2048 as i32 as i64 as u64
    jgt r4, r3, lbb_19857                           if r4 > r3 { pc += 22 }
    mov64 r3, r2                                    r3 = r2
    lsh64 r3, 32                                    r3 <<= 32   ///  r3 = r3.wrapping_shl(32)
    rsh64 r3, 32                                    r3 >>= 32   ///  r3 = r3.wrapping_shr(32)
    mov64 r4, 65536                                 r4 = 65536 as i32 as i64 as u64
    jgt r4, r3, lbb_19841                           if r4 > r3 { pc += 1 }
    ja lbb_19866                                    if true { pc += 25 }
lbb_19841:
    and64 r2, 63                                    r2 &= 63   ///  r2 = r2.and(63)
    or64 r2, 128                                    r2 |= 128   ///  r2 = r2.or(128)
    stxb [r10-0x2], r2                      
    mov64 r2, r3                                    r2 = r3
    rsh64 r2, 12                                    r2 >>= 12   ///  r2 = r2.wrapping_shr(12)
    or64 r2, 224                                    r2 |= 224   ///  r2 = r2.or(224)
    stxb [r10-0x4], r2                      
    rsh64 r3, 6                                     r3 >>= 6   ///  r3 = r3.wrapping_shr(6)
    and64 r3, 63                                    r3 &= 63   ///  r3 = r3.and(63)
    or64 r3, 128                                    r3 |= 128   ///  r3 = r3.or(128)
    stxb [r10-0x3], r3                      
    mov64 r3, 3                                     r3 = 3 as i32 as i64 as u64
    ja lbb_19883                                    if true { pc += 29 }
lbb_19854:
    stxb [r10-0x4], r2                      
    mov64 r3, 1                                     r3 = 1 as i32 as i64 as u64
    ja lbb_19883                                    if true { pc += 26 }
lbb_19857:
    mov64 r3, r2                                    r3 = r2
    and64 r3, 63                                    r3 &= 63   ///  r3 = r3.and(63)
    or64 r3, 128                                    r3 |= 128   ///  r3 = r3.or(128)
    stxb [r10-0x3], r3                      
    rsh64 r2, 6                                     r2 >>= 6   ///  r2 = r2.wrapping_shr(6)
    or64 r2, 192                                    r2 |= 192   ///  r2 = r2.or(192)
    stxb [r10-0x4], r2                      
    mov64 r3, 2                                     r3 = 2 as i32 as i64 as u64
    ja lbb_19883                                    if true { pc += 17 }
lbb_19866:
    and64 r2, 63                                    r2 &= 63   ///  r2 = r2.and(63)
    or64 r2, 128                                    r2 |= 128   ///  r2 = r2.or(128)
    stxb [r10-0x1], r2                      
    mov64 r2, r3                                    r2 = r3
    rsh64 r2, 18                                    r2 >>= 18   ///  r2 = r2.wrapping_shr(18)
    or64 r2, 240                                    r2 |= 240   ///  r2 = r2.or(240)
    stxb [r10-0x4], r2                      
    mov64 r2, r3                                    r2 = r3
    rsh64 r2, 6                                     r2 >>= 6   ///  r2 = r2.wrapping_shr(6)
    and64 r2, 63                                    r2 &= 63   ///  r2 = r2.and(63)
    or64 r2, 128                                    r2 |= 128   ///  r2 = r2.or(128)
    stxb [r10-0x2], r2                      
    rsh64 r3, 12                                    r3 >>= 12   ///  r3 = r3.wrapping_shr(12)
    and64 r3, 63                                    r3 &= 63   ///  r3 = r3.and(63)
    or64 r3, 128                                    r3 |= 128   ///  r3 = r3.or(128)
    stxb [r10-0x3], r3                      
    mov64 r3, 4                                     r3 = 4 as i32 as i64 as u64
lbb_19883:
    mov64 r2, r10                                   r2 = r10
    add64 r2, -4                                    r2 += -4   ///  r2 = r2.wrapping_add(-4 as i32 as i64 as u64)
    call function_19398                     
    exit                                    

function_19887:
    ldxdw r1, [r1+0x0]                      
    stxdw [r10-0x38], r1                    
    mov64 r6, r10                                   r6 = r10
    add64 r6, -48                                   r6 += -48   ///  r6 = r6.wrapping_add(-48 as i32 as i64 as u64)
    mov64 r1, r6                                    r1 = r6
    mov64 r3, 48                                    r3 = 48 as i32 as i64 as u64
    call function_21797                     
    mov64 r1, r10                                   r1 = r10
    add64 r1, -56                                   r1 += -56   ///  r1 = r1.wrapping_add(-56 as i32 as i64 as u64)
    lddw r2, 0x10002e198 --> b"\x00\x00\x00\x00 Q\x02\x00\x08\x00\x00\x00\x00\x00\x00\x00\x08\x00\x00\x0…        r2 load str located at 4295156120
    mov64 r3, r6                                    r3 = r6
    call function_19901                     
    exit                                    

function_19901:
    mov64 r4, 3                                     r4 = 3 as i32 as i64 as u64
    stxb [r10-0x8], r4                      
    lddw r4, 0x2000000000                           r4 load str located at 137438953472
    stxdw [r10-0x10], r4                    
    stxdw [r10-0x18], r2                    
    stxdw [r10-0x20], r1                    
    mov64 r7, 0                                     r7 = 0 as i32 as i64 as u64
    stxdw [r10-0x30], r7                    
    stxdw [r10-0x40], r7                    
    ldxdw r8, [r3+0x10]                     
    stxdw [r10-0x48], r3                    
    jne r8, 0, lbb_19944                            if r8 != (0 as i32 as i64 as u64) { pc += 30 }
    ldxdw r6, [r3+0x28]                     
    jeq r6, 0, lbb_20023                            if r6 == (0 as i32 as i64 as u64) { pc += 107 }
    ldxdw r1, [r10-0x48]                    
    ldxdw r8, [r1+0x20]                     
    mov64 r7, 0                                     r7 = 0 as i32 as i64 as u64
    lsh64 r6, 4                                     r6 <<= 4   ///  r6 = r6.wrapping_shl(4)
    add64 r8, 8                                     r8 += 8   ///  r8 = r8.wrapping_add(8 as i32 as i64 as u64)
    ldxdw r9, [r1+0x0]                      
    add64 r9, 8                                     r9 += 8   ///  r9 = r9.wrapping_add(8 as i32 as i64 as u64)
lbb_19923:
    ldxdw r3, [r9+0x0]                      
    jne r3, 0, lbb_19926                            if r3 != (0 as i32 as i64 as u64) { pc += 1 }
    ja lbb_19932                                    if true { pc += 6 }
lbb_19926:
    ldxdw r1, [r10-0x18]                    
    ldxdw r4, [r1+0x18]                     
    ldxdw r2, [r9-0x8]                      
    ldxdw r1, [r10-0x20]                    
    callx r4                                
    jne r0, 0, lbb_20042                            if r0 != (0 as i32 as i64 as u64) { pc += 110 }
lbb_19932:
    ldxdw r1, [r8-0x8]                      
    ldxdw r3, [r8+0x0]                      
    mov64 r2, r10                                   r2 = r10
    add64 r2, -64                                   r2 += -64   ///  r2 = r2.wrapping_add(-64 as i32 as i64 as u64)
    callx r3                                
    jne r0, 0, lbb_20042                            if r0 != (0 as i32 as i64 as u64) { pc += 104 }
    add64 r7, 1                                     r7 += 1   ///  r7 = r7.wrapping_add(1 as i32 as i64 as u64)
    add64 r8, 16                                    r8 += 16   ///  r8 = r8.wrapping_add(16 as i32 as i64 as u64)
    add64 r9, 16                                    r9 += 16   ///  r9 = r9.wrapping_add(16 as i32 as i64 as u64)
    add64 r6, -16                                   r6 += -16   ///  r6 = r6.wrapping_add(-16 as i32 as i64 as u64)
    jeq r6, 0, lbb_20023                            if r6 == (0 as i32 as i64 as u64) { pc += 80 }
    ja lbb_19923                                    if true { pc += -21 }
lbb_19944:
    ldxdw r9, [r3+0x18]                     
    jeq r9, 0, lbb_20023                            if r9 == (0 as i32 as i64 as u64) { pc += 77 }
    mov64 r7, 0                                     r7 = 0 as i32 as i64 as u64
    add64 r8, 48                                    r8 += 48   ///  r8 = r8.wrapping_add(48 as i32 as i64 as u64)
    mul64 r9, 56                                    r9 *= 56   ///  r9 = r9.wrapping_mul(56 as u64)
    ldxdw r1, [r10-0x48]                    
    ldxdw r6, [r1+0x0]                      
    add64 r6, 8                                     r6 += 8   ///  r6 = r6.wrapping_add(8 as i32 as i64 as u64)
lbb_19952:
    ldxdw r3, [r6+0x0]                      
    jne r3, 0, lbb_19968                            if r3 != (0 as i32 as i64 as u64) { pc += 14 }
lbb_19954:
    ldxdw r1, [r10-0x48]                    
    ldxdw r2, [r1+0x20]                     
    ldxw r1, [r8-0x8]                       
    stxw [r10-0xc], r1                      
    ldxb r1, [r8+0x0]                       
    stxb [r10-0x8], r1                      
    ldxw r1, [r8-0x4]                       
    stxw [r10-0x10], r1                     
    ldxdw r1, [r8-0x10]                     
    ldxdw r4, [r8-0x18]                     
    jeq r4, 0, lbb_19975                            if r4 == (0 as i32 as i64 as u64) { pc += 10 }
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
    jeq r4, 1, lbb_19977                            if r4 == (1 as i32 as i64 as u64) { pc += 10 }
    ja lbb_19987                                    if true { pc += 19 }
lbb_19968:
    ldxdw r1, [r10-0x18]                    
    ldxdw r4, [r1+0x18]                     
    ldxdw r2, [r6-0x8]                      
    ldxdw r1, [r10-0x20]                    
    callx r4                                
    jne r0, 0, lbb_20042                            if r0 != (0 as i32 as i64 as u64) { pc += 68 }
    ja lbb_19954                                    if true { pc += -21 }
lbb_19975:
    mov64 r3, 1                                     r3 = 1 as i32 as i64 as u64
    ja lbb_19987                                    if true { pc += 10 }
lbb_19977:
    lsh64 r1, 4                                     r1 <<= 4   ///  r1 = r1.wrapping_shl(4)
    mov64 r4, r2                                    r4 = r2
    add64 r4, r1                                    r4 += r1   ///  r4 = r4.wrapping_add(r1)
    ldxdw r5, [r4+0x8]                      
    lddw r0, 0x1000250f8 --> b"y\x11\x00\x00\x00\x00\x00\x00\x85\x10\x00\x00\xff\xff\xff\xff\x85\x10\x00…        r0 load str located at 4295119096
    jne r5, r0, lbb_19987                           if r5 != r0 { pc += 3 }
    mov64 r3, 1                                     r3 = 1 as i32 as i64 as u64
    ldxdw r1, [r4+0x0]                      
    ldxdw r1, [r1+0x0]                      
lbb_19987:
    stxdw [r10-0x38], r1                    
    stxdw [r10-0x40], r3                    
    ldxdw r1, [r8-0x20]                     
    ldxdw r4, [r8-0x28]                     
    jeq r4, 0, lbb_19995                            if r4 == (0 as i32 as i64 as u64) { pc += 3 }
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
    jeq r4, 1, lbb_19997                            if r4 == (1 as i32 as i64 as u64) { pc += 3 }
    ja lbb_20007                                    if true { pc += 12 }
lbb_19995:
    mov64 r3, 1                                     r3 = 1 as i32 as i64 as u64
    ja lbb_20007                                    if true { pc += 10 }
lbb_19997:
    lsh64 r1, 4                                     r1 <<= 4   ///  r1 = r1.wrapping_shl(4)
    mov64 r4, r2                                    r4 = r2
    add64 r4, r1                                    r4 += r1   ///  r4 = r4.wrapping_add(r1)
    ldxdw r5, [r4+0x8]                      
    lddw r0, 0x1000250f8 --> b"y\x11\x00\x00\x00\x00\x00\x00\x85\x10\x00\x00\xff\xff\xff\xff\x85\x10\x00…        r0 load str located at 4295119096
    jne r5, r0, lbb_20007                           if r5 != r0 { pc += 3 }
    mov64 r3, 1                                     r3 = 1 as i32 as i64 as u64
    ldxdw r1, [r4+0x0]                      
    ldxdw r1, [r1+0x0]                      
lbb_20007:
    stxdw [r10-0x28], r1                    
    stxdw [r10-0x30], r3                    
    ldxdw r1, [r8-0x30]                     
    lsh64 r1, 4                                     r1 <<= 4   ///  r1 = r1.wrapping_shl(4)
    add64 r2, r1                                    r2 += r1   ///  r2 = r2.wrapping_add(r1)
    ldxdw r1, [r2+0x0]                      
    ldxdw r3, [r2+0x8]                      
    mov64 r2, r10                                   r2 = r10
    add64 r2, -64                                   r2 += -64   ///  r2 = r2.wrapping_add(-64 as i32 as i64 as u64)
    callx r3                                
    jne r0, 0, lbb_20042                            if r0 != (0 as i32 as i64 as u64) { pc += 24 }
    add64 r7, 1                                     r7 += 1   ///  r7 = r7.wrapping_add(1 as i32 as i64 as u64)
    add64 r8, 56                                    r8 += 56   ///  r8 = r8.wrapping_add(56 as i32 as i64 as u64)
    add64 r6, 16                                    r6 += 16   ///  r6 = r6.wrapping_add(16 as i32 as i64 as u64)
    add64 r9, -56                                   r9 += -56   ///  r9 = r9.wrapping_add(-56 as i32 as i64 as u64)
    jne r9, 0, lbb_19952                            if r9 != (0 as i32 as i64 as u64) { pc += -71 }
lbb_20023:
    mov64 r2, r7                                    r2 = r7
    lsh64 r2, 4                                     r2 <<= 4   ///  r2 = r2.wrapping_shl(4)
    ldxdw r3, [r10-0x48]                    
    ldxdw r1, [r3+0x0]                      
    add64 r1, r2                                    r1 += r2   ///  r1 = r1.wrapping_add(r2)
    ldxdw r2, [r3+0x8]                      
    jgt r2, r7, lbb_20031                           if r2 > r7 { pc += 1 }
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
lbb_20031:
    jgt r2, r7, lbb_20033                           if r2 > r7 { pc += 1 }
    ja lbb_20040                                    if true { pc += 7 }
lbb_20033:
    ldxdw r2, [r10-0x18]                    
    ldxdw r4, [r2+0x18]                     
    ldxdw r3, [r1+0x8]                      
    ldxdw r2, [r1+0x0]                      
    ldxdw r1, [r10-0x20]                    
    callx r4                                
    jne r0, 0, lbb_20042                            if r0 != (0 as i32 as i64 as u64) { pc += 2 }
lbb_20040:
    mov64 r0, 0                                     r0 = 0 as i32 as i64 as u64
    ja lbb_20043                                    if true { pc += 1 }
lbb_20042:
    mov64 r0, 1                                     r0 = 1 as i32 as i64 as u64
lbb_20043:
    exit                                    

function_20044:
    mov64 r7, r3                                    r7 = r3
    mov64 r6, r1                                    r6 = r1
    ldxdw r9, [r5-0xff8]                    
    jeq r2, 0, lbb_20056                            if r2 == (0 as i32 as i64 as u64) { pc += 8 }
    mov64 r0, 1114112                               r0 = 1114112 as i32 as i64 as u64
    ldxw r1, [r6+0x30]                      
    mov64 r2, r1                                    r2 = r1
    and64 r2, 1                                     r2 &= 1   ///  r2 = r2.and(1)
    mov64 r8, r9                                    r8 = r9
    jeq r2, 0, lbb_20060                            if r2 == (0 as i32 as i64 as u64) { pc += 6 }
    mov64 r0, 43                                    r0 = 43 as i32 as i64 as u64
    ja lbb_20058                                    if true { pc += 2 }
lbb_20056:
    mov64 r0, 45                                    r0 = 45 as i32 as i64 as u64
    ldxw r1, [r6+0x30]                      
lbb_20058:
    mov64 r8, r9                                    r8 = r9
    add64 r8, 1                                     r8 += 1   ///  r8 = r8.wrapping_add(1 as i32 as i64 as u64)
lbb_20060:
    ldxdw r2, [r5-0x1000]                   
    stxdw [r10-0x18], r2                    
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
    and64 r1, 4                                     r1 &= 4   ///  r1 = r1.and(4)
    jeq r1, 0, lbb_20066                            if r1 == (0 as i32 as i64 as u64) { pc += 1 }
    ja lbb_20102                                    if true { pc += 36 }
lbb_20066:
    stxdw [r10-0x10], r9                    
    ldxdw r1, [r6+0x0]                      
    jne r1, 0, lbb_20076                            if r1 != (0 as i32 as i64 as u64) { pc += 7 }
    mov64 r8, r6                                    r8 = r6
    mov64 r1, r6                                    r1 = r6
    mov64 r2, r0                                    r2 = r0
    call function_20284                     
    mov64 r7, 1                                     r7 = 1 as i32 as i64 as u64
    jne r0, 0, lbb_20124                            if r0 != (0 as i32 as i64 as u64) { pc += 49 }
    ja lbb_20117                                    if true { pc += 41 }
lbb_20076:
    ldxdw r5, [r6+0x8]                      
    jge r8, r5, lbb_20111                           if r8 >= r5 { pc += 33 }
    ldxw r1, [r6+0x30]                      
    and64 r1, 8                                     r1 &= 8   ///  r1 = r1.and(8)
    stxdw [r10-0x28], r6                    
    jeq r1, 0, lbb_20083                            if r1 == (0 as i32 as i64 as u64) { pc += 1 }
    ja lbb_20151                                    if true { pc += 68 }
lbb_20083:
    stxdw [r10-0x40], r3                    
    stxdw [r10-0x20], r0                    
    stxdw [r10-0x38], r4                    
    ldxb r2, [r6+0x38]                      
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    jeq r2, 3, lbb_20090                            if r2 == (3 as i32 as i64 as u64) { pc += 1 }
    mov64 r1, r2                                    r1 = r2
lbb_20090:
    sub64 r5, r8                                    r5 -= r8   ///  r5 = r5.wrapping_sub(r8)
    mov64 r9, 0                                     r9 = 0 as i32 as i64 as u64
    and64 r1, 3                                     r1 &= 3   ///  r1 = r1.and(3)
    stxdw [r10-0x30], r5                    
    jeq r1, 0, lbb_20184                            if r1 == (0 as i32 as i64 as u64) { pc += 89 }
    jeq r1, 1, lbb_20181                            if r1 == (1 as i32 as i64 as u64) { pc += 85 }
    mov64 r9, r5                                    r9 = r5
    rsh64 r9, 1                                     r9 >>= 1   ///  r9 = r9.wrapping_shr(1)
    add64 r5, 1                                     r5 += 1   ///  r5 = r5.wrapping_add(1 as i32 as i64 as u64)
    rsh64 r5, 1                                     r5 >>= 1   ///  r5 = r5.wrapping_shr(1)
    stxdw [r10-0x30], r5                    
    ja lbb_20184                                    if true { pc += 82 }
lbb_20102:
    mov64 r1, 32                                    r1 = 32 as i32 as i64 as u64
    stxdw [r10-0x20], r0                    
    stxdw [r10-0x8], r7                     
    jgt r1, r4, lbb_20127                           if r1 > r4 { pc += 21 }
    mov64 r1, r7                                    r1 = r7
    mov64 r7, r4                                    r7 = r4
    mov64 r2, r4                                    r2 = r4
    call function_20817                     
    ja lbb_20138                                    if true { pc += 27 }
lbb_20111:
    mov64 r8, r6                                    r8 = r6
    mov64 r1, r6                                    r1 = r6
    mov64 r2, r0                                    r2 = r0
    call function_20284                     
    mov64 r7, 1                                     r7 = 1 as i32 as i64 as u64
    jne r0, 0, lbb_20124                            if r0 != (0 as i32 as i64 as u64) { pc += 7 }
lbb_20117:
    ldxdw r1, [r8+0x20]                     
    ldxdw r2, [r8+0x28]                     
    ldxdw r4, [r2+0x18]                     
    ldxdw r2, [r10-0x18]                    
    ldxdw r3, [r10-0x10]                    
    callx r4                                
    mov64 r7, r0                                    r7 = r0
lbb_20124:
    and64 r7, 1                                     r7 &= 1   ///  r7 = r7.and(1)
    mov64 r0, r7                                    r0 = r7
    exit                                    
lbb_20127:
    mov64 r0, 0                                     r0 = 0 as i32 as i64 as u64
    mov64 r7, r4                                    r7 = r4
    jeq r4, 0, lbb_20138                            if r4 == (0 as i32 as i64 as u64) { pc += 8 }
    mov64 r0, 0                                     r0 = 0 as i32 as i64 as u64
    mov64 r1, r7                                    r1 = r7
    ldxdw r2, [r10-0x8]                     
    ja lbb_20144                                    if true { pc += 10 }
lbb_20134:
    add64 r0, r3                                    r0 += r3   ///  r0 = r0.wrapping_add(r3)
    add64 r2, 1                                     r2 += 1   ///  r2 = r2.wrapping_add(1 as i32 as i64 as u64)
    add64 r1, -1                                    r1 += -1   ///  r1 = r1.wrapping_add(-1 as i32 as i64 as u64)
    jne r1, 0, lbb_20144                            if r1 != (0 as i32 as i64 as u64) { pc += 6 }
lbb_20138:
    add64 r0, r8                                    r0 += r8   ///  r0 = r0.wrapping_add(r8)
    ldxdw r3, [r10-0x8]                     
    mov64 r8, r0                                    r8 = r0
    mov64 r4, r7                                    r4 = r7
    ldxdw r0, [r10-0x20]                    
    ja lbb_20066                                    if true { pc += -78 }
lbb_20144:
    ldxb r4, [r2+0x0]                       
    lsh64 r4, 56                                    r4 <<= 56   ///  r4 = r4.wrapping_shl(56)
    arsh64 r4, 56                                   r4 >>= 56 (signed)   ///  r4 = (r4 as i64).wrapping_shr(56)
    mov64 r3, 1                                     r3 = 1 as i32 as i64 as u64
    jsgt r4, -65, lbb_20134                         if (r4 as i64) > (-65 as i32 as i64) { pc += -15 }
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
    ja lbb_20134                                    if true { pc += -17 }
lbb_20151:
    mov64 r9, r5                                    r9 = r5
    ldxw r1, [r6+0x34]                      
    stxdw [r10-0x30], r1                    
    mov64 r1, 48                                    r1 = 48 as i32 as i64 as u64
    stxw [r6+0x34], r1                      
    ldxb r1, [r6+0x38]                      
    stxdw [r10-0x38], r1                    
    mov64 r7, 1                                     r7 = 1 as i32 as i64 as u64
    stxb [r6+0x38], r7                      
    mov64 r1, r6                                    r1 = r6
    mov64 r2, r0                                    r2 = r0
    call function_20284                     
    jne r0, 0, lbb_20124                            if r0 != (0 as i32 as i64 as u64) { pc += -40 }
    ldxdw r3, [r10-0x28]                    
    ldxb r2, [r3+0x38]                      
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    jeq r2, 3, lbb_20169                            if r2 == (3 as i32 as i64 as u64) { pc += 1 }
    mov64 r1, r2                                    r1 = r2
lbb_20169:
    sub64 r9, r8                                    r9 -= r8   ///  r9 = r9.wrapping_sub(r8)
    mov64 r6, 0                                     r6 = 0 as i32 as i64 as u64
    and64 r1, 3                                     r1 &= 3   ///  r1 = r1.and(3)
    stxdw [r10-0x20], r9                    
    jeq r1, 0, lbb_20238                            if r1 == (0 as i32 as i64 as u64) { pc += 64 }
    jeq r1, 1, lbb_20235                            if r1 == (1 as i32 as i64 as u64) { pc += 60 }
    mov64 r6, r9                                    r6 = r9
    rsh64 r6, 1                                     r6 >>= 1   ///  r6 = r6.wrapping_shr(1)
    add64 r9, 1                                     r9 += 1   ///  r9 = r9.wrapping_add(1 as i32 as i64 as u64)
    rsh64 r9, 1                                     r9 >>= 1   ///  r9 = r9.wrapping_shr(1)
    stxdw [r10-0x20], r9                    
    ja lbb_20238                                    if true { pc += 57 }
lbb_20181:
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    stxdw [r10-0x30], r1                    
    mov64 r9, r5                                    r9 = r5
lbb_20184:
    add64 r9, 1                                     r9 += 1   ///  r9 = r9.wrapping_add(1 as i32 as i64 as u64)
    ldxdw r1, [r10-0x28]                    
    ldxw r2, [r1+0x34]                      
    stxdw [r10-0x8], r2                     
    ldxdw r6, [r1+0x28]                     
    ldxdw r8, [r1+0x20]                     
    mov64 r7, 1                                     r7 = 1 as i32 as i64 as u64
lbb_20191:
    add64 r9, -1                                    r9 += -1   ///  r9 = r9.wrapping_add(-1 as i32 as i64 as u64)
    jeq r9, 0, lbb_20199                            if r9 == (0 as i32 as i64 as u64) { pc += 6 }
    ldxdw r3, [r6+0x20]                     
    mov64 r1, r8                                    r1 = r8
    ldxdw r2, [r10-0x8]                     
    callx r3                                
    jne r0, 0, lbb_20124                            if r0 != (0 as i32 as i64 as u64) { pc += -74 }
    ja lbb_20191                                    if true { pc += -8 }
lbb_20199:
    mov64 r7, 1                                     r7 = 1 as i32 as i64 as u64
    ldxdw r1, [r10-0x8]                     
    jeq r1, 1114112, lbb_20124                      if r1 == (1114112 as i32 as i64 as u64) { pc += -78 }
    ldxdw r1, [r10-0x28]                    
    ldxdw r2, [r10-0x20]                    
    ldxdw r3, [r10-0x40]                    
    ldxdw r4, [r10-0x38]                    
    call function_20284                     
    jne r0, 0, lbb_20124                            if r0 != (0 as i32 as i64 as u64) { pc += -84 }
    ldxdw r2, [r10-0x28]                    
    ldxdw r1, [r2+0x20]                     
    ldxdw r2, [r2+0x28]                     
    ldxdw r4, [r2+0x18]                     
    ldxdw r2, [r10-0x18]                    
    ldxdw r3, [r10-0x10]                    
    callx r4                                
    jne r0, 0, lbb_20124                            if r0 != (0 as i32 as i64 as u64) { pc += -92 }
    mov64 r8, 0                                     r8 = 0 as i32 as i64 as u64
    ldxdw r1, [r10-0x28]                    
    ldxdw r6, [r1+0x28]                     
    ldxdw r7, [r1+0x20]                     
    ldxdw r9, [r10-0x30]                    
lbb_20221:
    mov64 r1, r9                                    r1 = r9
    jeq r9, r8, lbb_20231                           if r9 == r8 { pc += 8 }
    ldxdw r3, [r6+0x20]                     
    mov64 r1, r7                                    r1 = r7
    ldxdw r2, [r10-0x8]                     
    callx r3                                
    add64 r8, 1                                     r8 += 1   ///  r8 = r8.wrapping_add(1 as i32 as i64 as u64)
    jeq r0, 0, lbb_20221                            if r0 == (0 as i32 as i64 as u64) { pc += -8 }
    add64 r8, -1                                    r8 += -1   ///  r8 = r8.wrapping_add(-1 as i32 as i64 as u64)
    mov64 r1, r8                                    r1 = r8
lbb_20231:
    mov64 r7, 1                                     r7 = 1 as i32 as i64 as u64
    jgt r9, r1, lbb_20124                           if r9 > r1 { pc += -109 }
lbb_20233:
    mov64 r7, 0                                     r7 = 0 as i32 as i64 as u64
    ja lbb_20124                                    if true { pc += -111 }
lbb_20235:
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    stxdw [r10-0x20], r1                    
    mov64 r6, r9                                    r6 = r9
lbb_20238:
    add64 r6, 1                                     r6 += 1   ///  r6 = r6.wrapping_add(1 as i32 as i64 as u64)
    ldxw r1, [r3+0x34]                      
    stxdw [r10-0x8], r1                     
    ldxdw r8, [r3+0x28]                     
    ldxdw r9, [r3+0x20]                     
    mov64 r7, 1                                     r7 = 1 as i32 as i64 as u64
lbb_20244:
    add64 r6, -1                                    r6 += -1   ///  r6 = r6.wrapping_add(-1 as i32 as i64 as u64)
    jeq r6, 0, lbb_20252                            if r6 == (0 as i32 as i64 as u64) { pc += 6 }
    ldxdw r3, [r8+0x20]                     
    mov64 r1, r9                                    r1 = r9
    ldxdw r2, [r10-0x8]                     
    callx r3                                
    jne r0, 0, lbb_20124                            if r0 != (0 as i32 as i64 as u64) { pc += -127 }
    ja lbb_20244                                    if true { pc += -8 }
lbb_20252:
    mov64 r7, 1                                     r7 = 1 as i32 as i64 as u64
    ldxdw r1, [r10-0x8]                     
    jeq r1, 1114112, lbb_20124                      if r1 == (1114112 as i32 as i64 as u64) { pc += -131 }
    ldxdw r2, [r10-0x28]                    
    ldxdw r1, [r2+0x20]                     
    ldxdw r2, [r2+0x28]                     
    ldxdw r4, [r2+0x18]                     
    ldxdw r2, [r10-0x18]                    
    ldxdw r3, [r10-0x10]                    
    callx r4                                
    jne r0, 0, lbb_20124                            if r0 != (0 as i32 as i64 as u64) { pc += -139 }
    mov64 r6, 0                                     r6 = 0 as i32 as i64 as u64
    ldxdw r1, [r10-0x28]                    
    ldxdw r8, [r1+0x28]                     
    ldxdw r9, [r1+0x20]                     
lbb_20267:
    ldxdw r1, [r10-0x20]                    
    jeq r1, r6, lbb_20278                           if r1 == r6 { pc += 9 }
    ldxdw r3, [r8+0x20]                     
    mov64 r1, r9                                    r1 = r9
    ldxdw r2, [r10-0x8]                     
    callx r3                                
    add64 r6, 1                                     r6 += 1   ///  r6 = r6.wrapping_add(1 as i32 as i64 as u64)
    jeq r0, 0, lbb_20267                            if r0 == (0 as i32 as i64 as u64) { pc += -8 }
    add64 r6, -1                                    r6 += -1   ///  r6 = r6.wrapping_add(-1 as i32 as i64 as u64)
    ldxdw r1, [r10-0x20]                    
    jgt r1, r6, lbb_20124                           if r1 > r6 { pc += -154 }
lbb_20278:
    ldxdw r1, [r10-0x28]                    
    ldxdw r2, [r10-0x38]                    
    stxb [r1+0x38], r2                      
    ldxdw r2, [r10-0x30]                    
    stxw [r1+0x34], r2                      
    ja lbb_20233                                    if true { pc += -51 }

function_20284:
    mov64 r6, r4                                    r6 = r4
    mov64 r7, r3                                    r7 = r3
    mov64 r8, r1                                    r8 = r1
    mov64 r1, r2                                    r1 = r2
    lsh64 r1, 32                                    r1 <<= 32   ///  r1 = r1.wrapping_shl(32)
    rsh64 r1, 32                                    r1 >>= 32   ///  r1 = r1.wrapping_shr(32)
    jeq r1, 1114112, lbb_20298                      if r1 == (1114112 as i32 as i64 as u64) { pc += 7 }
    ldxdw r1, [r8+0x20]                     
    ldxdw r3, [r8+0x28]                     
    ldxdw r3, [r3+0x20]                     
    callx r3                                
    mov64 r1, r0                                    r1 = r0
    mov64 r0, 1                                     r0 = 1 as i32 as i64 as u64
    jne r1, 0, lbb_20300                            if r1 != (0 as i32 as i64 as u64) { pc += 2 }
lbb_20298:
    mov64 r0, 0                                     r0 = 0 as i32 as i64 as u64
    jne r7, 0, lbb_20301                            if r7 != (0 as i32 as i64 as u64) { pc += 1 }
lbb_20300:
    exit                                    
lbb_20301:
    ldxdw r1, [r8+0x20]                     
    ldxdw r2, [r8+0x28]                     
    ldxdw r4, [r2+0x18]                     
    mov64 r2, r7                                    r2 = r7
    mov64 r3, r6                                    r3 = r6
    callx r4                                
    ja lbb_20300                                    if true { pc += -8 }

function_20308:
    mov64 r8, r1                                    r8 = r1
    ldxdw r4, [r8+0x10]                     
    ldxdw r1, [r8+0x0]                      
    jeq r1, 1, lbb_20313                            if r1 == (1 as i32 as i64 as u64) { pc += 1 }
    jne r4, 1, lbb_20398                            if r4 != (1 as i32 as i64 as u64) { pc += 85 }
lbb_20313:
    stxdw [r10-0x10], r2                    
    stxdw [r10-0x18], r3                    
    jeq r4, 1, lbb_20317                            if r4 == (1 as i32 as i64 as u64) { pc += 1 }
    ja lbb_20388                                    if true { pc += 71 }
lbb_20317:
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
    ldxdw r5, [r10-0x10]                    
    mov64 r3, r5                                    r3 = r5
    ldxdw r4, [r10-0x18]                    
    add64 r3, r4                                    r3 += r4   ///  r3 = r3.wrapping_add(r4)
    ldxdw r4, [r8+0x18]                     
    jeq r4, 0, lbb_20364                            if r4 == (0 as i32 as i64 as u64) { pc += 40 }
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
    ldxdw r5, [r10-0x10]                    
    mov64 r7, 0                                     r7 = 0 as i32 as i64 as u64
lbb_20327:
    mov64 r9, r5                                    r9 = r5
    jeq r9, r3, lbb_20388                           if r9 == r3 { pc += 59 }
    mov64 r5, r9                                    r5 = r9
    add64 r5, 1                                     r5 += 1   ///  r5 = r5.wrapping_add(1 as i32 as i64 as u64)
    ldxb r6, [r9+0x0]                       
    mov64 r0, r6                                    r0 = r6
    lsh64 r0, 56                                    r0 <<= 56   ///  r0 = r0.wrapping_shl(56)
    arsh64 r0, 56                                   r0 >>= 56 (signed)   ///  r0 = (r0 as i64).wrapping_shr(56)
    jsgt r0, -1, lbb_20360                          if (r0 as i64) > (-1 as i32 as i64) { pc += 24 }
    mov64 r5, r9                                    r5 = r9
    add64 r5, 2                                     r5 += 2   ///  r5 = r5.wrapping_add(2 as i32 as i64 as u64)
    mov64 r0, 224                                   r0 = 224 as i32 as i64 as u64
    jgt r0, r6, lbb_20360                           if r0 > r6 { pc += 20 }
    mov64 r5, r9                                    r5 = r9
    add64 r5, 3                                     r5 += 3   ///  r5 = r5.wrapping_add(3 as i32 as i64 as u64)
    mov64 r0, 240                                   r0 = 240 as i32 as i64 as u64
    jgt r0, r6, lbb_20360                           if r0 > r6 { pc += 16 }
    ldxb r5, [r9+0x1]                       
    and64 r5, 63                                    r5 &= 63   ///  r5 = r5.and(63)
    lsh64 r5, 12                                    r5 <<= 12   ///  r5 = r5.wrapping_shl(12)
    ldxb r0, [r9+0x2]                       
    and64 r0, 63                                    r0 &= 63   ///  r0 = r0.and(63)
    lsh64 r0, 6                                     r0 <<= 6   ///  r0 = r0.wrapping_shl(6)
    or64 r0, r5                                     r0 |= r5   ///  r0 = r0.or(r5)
    ldxb r5, [r9+0x3]                       
    and64 r5, 63                                    r5 &= 63   ///  r5 = r5.and(63)
    or64 r0, r5                                     r0 |= r5   ///  r0 = r0.or(r5)
    lsh64 r6, 18                                    r6 <<= 18   ///  r6 = r6.wrapping_shl(18)
    and64 r6, 1835008                               r6 &= 1835008   ///  r6 = r6.and(1835008)
    or64 r0, r6                                     r0 |= r6   ///  r0 = r0.or(r6)
    mov64 r5, r9                                    r5 = r9
    add64 r5, 4                                     r5 += 4   ///  r5 = r5.wrapping_add(4 as i32 as i64 as u64)
    jeq r0, 1114112, lbb_20388                      if r0 == (1114112 as i32 as i64 as u64) { pc += 28 }
lbb_20360:
    add64 r7, 1                                     r7 += 1   ///  r7 = r7.wrapping_add(1 as i32 as i64 as u64)
    sub64 r2, r9                                    r2 -= r9   ///  r2 = r2.wrapping_sub(r9)
    add64 r2, r5                                    r2 += r5   ///  r2 = r2.wrapping_add(r5)
    jgt r4, r7, lbb_20327                           if r4 > r7 { pc += -37 }
lbb_20364:
    jeq r5, r3, lbb_20388                           if r5 == r3 { pc += 23 }
    ldxb r3, [r5+0x0]                       
    mov64 r4, r3                                    r4 = r3
    lsh64 r4, 56                                    r4 <<= 56   ///  r4 = r4.wrapping_shl(56)
    arsh64 r4, 56                                   r4 >>= 56 (signed)   ///  r4 = (r4 as i64).wrapping_shr(56)
    jsgt r4, -1, lbb_20443                          if (r4 as i64) > (-1 as i32 as i64) { pc += 73 }
    mov64 r4, 224                                   r4 = 224 as i32 as i64 as u64
    jgt r4, r3, lbb_20443                           if r4 > r3 { pc += 71 }
    mov64 r4, 240                                   r4 = 240 as i32 as i64 as u64
    jgt r4, r3, lbb_20443                           if r4 > r3 { pc += 69 }
    ldxb r4, [r5+0x1]                       
    and64 r4, 63                                    r4 &= 63   ///  r4 = r4.and(63)
    lsh64 r4, 12                                    r4 <<= 12   ///  r4 = r4.wrapping_shl(12)
    ldxb r0, [r5+0x2]                       
    and64 r0, 63                                    r0 &= 63   ///  r0 = r0.and(63)
    lsh64 r0, 6                                     r0 <<= 6   ///  r0 = r0.wrapping_shl(6)
    or64 r0, r4                                     r0 |= r4   ///  r0 = r0.or(r4)
    ldxb r4, [r5+0x3]                       
    and64 r4, 63                                    r4 &= 63   ///  r4 = r4.and(63)
    or64 r0, r4                                     r0 |= r4   ///  r0 = r0.or(r4)
    lsh64 r3, 18                                    r3 <<= 18   ///  r3 = r3.wrapping_shl(18)
    and64 r3, 1835008                               r3 &= 1835008   ///  r3 = r3.and(1835008)
    or64 r0, r3                                     r0 |= r3   ///  r0 = r0.or(r3)
    jne r0, 1114112, lbb_20443                      if r0 != (1114112 as i32 as i64 as u64) { pc += 55 }
lbb_20388:
    jeq r1, 0, lbb_20516                            if r1 == (0 as i32 as i64 as u64) { pc += 127 }
lbb_20389:
    ldxdw r6, [r8+0x8]                      
    mov64 r1, 32                                    r1 = 32 as i32 as i64 as u64
    ldxdw r7, [r10-0x18]                    
    ldxdw r9, [r10-0x10]                    
    jgt r1, r7, lbb_20402                           if r1 > r7 { pc += 8 }
    mov64 r1, r9                                    r1 = r9
    mov64 r2, r7                                    r2 = r7
    call function_20817                     
    ja lbb_20412                                    if true { pc += 14 }
lbb_20398:
    ldxdw r1, [r8+0x20]                     
    ldxdw r4, [r8+0x28]                     
    ldxdw r4, [r4+0x18]                     
    ja lbb_20521                                    if true { pc += 119 }
lbb_20402:
    mov64 r0, 0                                     r0 = 0 as i32 as i64 as u64
    jeq r7, 0, lbb_20412                            if r7 == (0 as i32 as i64 as u64) { pc += 8 }
    mov64 r0, 0                                     r0 = 0 as i32 as i64 as u64
    mov64 r1, r7                                    r1 = r7
    mov64 r2, r9                                    r2 = r9
    ja lbb_20419                                    if true { pc += 11 }
lbb_20408:
    add64 r0, r3                                    r0 += r3   ///  r0 = r0.wrapping_add(r3)
    add64 r2, 1                                     r2 += 1   ///  r2 = r2.wrapping_add(1 as i32 as i64 as u64)
    add64 r1, -1                                    r1 += -1   ///  r1 = r1.wrapping_add(-1 as i32 as i64 as u64)
    jne r1, 0, lbb_20419                            if r1 != (0 as i32 as i64 as u64) { pc += 7 }
lbb_20412:
    jge r0, r6, lbb_20426                           if r0 >= r6 { pc += 13 }
    ldxb r2, [r8+0x38]                      
    mov64 r7, 0                                     r7 = 0 as i32 as i64 as u64
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    jeq r2, 3, lbb_20432                            if r2 == (3 as i32 as i64 as u64) { pc += 15 }
    mov64 r1, r2                                    r1 = r2
    ja lbb_20432                                    if true { pc += 13 }
lbb_20419:
    ldxb r4, [r2+0x0]                       
    lsh64 r4, 56                                    r4 <<= 56   ///  r4 = r4.wrapping_shl(56)
    arsh64 r4, 56                                   r4 >>= 56 (signed)   ///  r4 = (r4 as i64).wrapping_shr(56)
    mov64 r3, 1                                     r3 = 1 as i32 as i64 as u64
    jsgt r4, -65, lbb_20408                         if (r4 as i64) > (-65 as i32 as i64) { pc += -16 }
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
    ja lbb_20408                                    if true { pc += -18 }
lbb_20426:
    ldxdw r1, [r8+0x20]                     
    ldxdw r2, [r8+0x28]                     
    ldxdw r4, [r2+0x18]                     
    mov64 r2, r9                                    r2 = r9
    mov64 r3, r7                                    r3 = r7
    ja lbb_20521                                    if true { pc += 89 }
lbb_20432:
    sub64 r6, r0                                    r6 -= r0   ///  r6 = r6.wrapping_sub(r0)
    and64 r1, 3                                     r1 &= 3   ///  r1 = r1.and(3)
    stxdw [r10-0x20], r6                    
    jeq r1, 0, lbb_20455                            if r1 == (0 as i32 as i64 as u64) { pc += 19 }
    jeq r1, 1, lbb_20452                            if r1 == (1 as i32 as i64 as u64) { pc += 15 }
    mov64 r7, r6                                    r7 = r6
    rsh64 r7, 1                                     r7 >>= 1   ///  r7 = r7.wrapping_shr(1)
    add64 r6, 1                                     r6 += 1   ///  r6 = r6.wrapping_add(1 as i32 as i64 as u64)
    rsh64 r6, 1                                     r6 >>= 1   ///  r6 = r6.wrapping_shr(1)
    stxdw [r10-0x20], r6                    
    ja lbb_20455                                    if true { pc += 12 }
lbb_20443:
    mov64 r4, 0                                     r4 = 0 as i32 as i64 as u64
    ldxdw r6, [r10-0x18]                    
    ldxdw r7, [r10-0x10]                    
    jeq r2, 0, lbb_20506                            if r2 == (0 as i32 as i64 as u64) { pc += 59 }
    jgt r6, r2, lbb_20497                           if r6 > r2 { pc += 49 }
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
    mov64 r4, r6                                    r4 = r6
    jeq r2, r6, lbb_20506                           if r2 == r6 { pc += 55 }
    ja lbb_20508                                    if true { pc += 56 }
lbb_20452:
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    stxdw [r10-0x20], r1                    
    mov64 r7, r6                                    r7 = r6
lbb_20455:
    add64 r7, 1                                     r7 += 1   ///  r7 = r7.wrapping_add(1 as i32 as i64 as u64)
    ldxw r9, [r8+0x34]                      
    ldxdw r1, [r8+0x28]                     
    stxdw [r10-0x8], r1                     
    ldxdw r8, [r8+0x20]                     
    mov64 r6, 1                                     r6 = 1 as i32 as i64 as u64
lbb_20461:
    add64 r7, -1                                    r7 += -1   ///  r7 = r7.wrapping_add(-1 as i32 as i64 as u64)
    jeq r7, 0, lbb_20470                            if r7 == (0 as i32 as i64 as u64) { pc += 7 }
    ldxdw r1, [r10-0x8]                     
    ldxdw r3, [r1+0x20]                     
    mov64 r1, r8                                    r1 = r8
    mov64 r2, r9                                    r2 = r9
    callx r3                                
    jne r0, 0, lbb_20523                            if r0 != (0 as i32 as i64 as u64) { pc += 54 }
    ja lbb_20461                                    if true { pc += -9 }
lbb_20470:
    mov64 r6, 1                                     r6 = 1 as i32 as i64 as u64
    mov64 r1, r9                                    r1 = r9
    jeq r1, 1114112, lbb_20523                      if r1 == (1114112 as i32 as i64 as u64) { pc += 50 }
    ldxdw r1, [r10-0x8]                     
    ldxdw r4, [r1+0x18]                     
    mov64 r1, r8                                    r1 = r8
    ldxdw r2, [r10-0x10]                    
    ldxdw r3, [r10-0x18]                    
    callx r4                                
    jne r0, 0, lbb_20523                            if r0 != (0 as i32 as i64 as u64) { pc += 43 }
    mov64 r6, 0                                     r6 = 0 as i32 as i64 as u64
    ldxdw r7, [r10-0x20]                    
lbb_20482:
    mov64 r1, r7                                    r1 = r7
    jeq r7, r6, lbb_20493                           if r7 == r6 { pc += 9 }
    ldxdw r1, [r10-0x8]                     
    ldxdw r3, [r1+0x20]                     
    mov64 r1, r8                                    r1 = r8
    mov64 r2, r9                                    r2 = r9
    callx r3                                
    add64 r6, 1                                     r6 += 1   ///  r6 = r6.wrapping_add(1 as i32 as i64 as u64)
    jeq r0, 0, lbb_20482                            if r0 == (0 as i32 as i64 as u64) { pc += -9 }
    add64 r6, -1                                    r6 += -1   ///  r6 = r6.wrapping_add(-1 as i32 as i64 as u64)
    mov64 r1, r6                                    r1 = r6
lbb_20493:
    mov64 r6, 1                                     r6 = 1 as i32 as i64 as u64
    jgt r7, r1, lbb_20523                           if r7 > r1 { pc += 28 }
    mov64 r6, 0                                     r6 = 0 as i32 as i64 as u64
    ja lbb_20523                                    if true { pc += 26 }
lbb_20497:
    mov64 r4, r7                                    r4 = r7
    add64 r4, r2                                    r4 += r2   ///  r4 = r4.wrapping_add(r2)
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
    ldxb r5, [r4+0x0]                       
    lsh64 r5, 56                                    r5 <<= 56   ///  r5 = r5.wrapping_shl(56)
    arsh64 r5, 56                                   r5 >>= 56 (signed)   ///  r5 = (r5 as i64).wrapping_shr(56)
    mov64 r0, -64                                   r0 = -64 as i32 as i64 as u64
    mov64 r4, r2                                    r4 = r2
    jsgt r0, r5, lbb_20508                          if (r0 as i64) > (r5 as i64) { pc += 2 }
lbb_20506:
    mov64 r2, r4                                    r2 = r4
    mov64 r3, r7                                    r3 = r7
lbb_20508:
    jeq r3, 0, lbb_20510                            if r3 == (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r6, r2                                    r6 = r2
lbb_20510:
    stxdw [r10-0x18], r6                    
    jeq r3, 0, lbb_20513                            if r3 == (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r7, r3                                    r7 = r3
lbb_20513:
    stxdw [r10-0x10], r7                    
    jeq r1, 0, lbb_20516                            if r1 == (0 as i32 as i64 as u64) { pc += 1 }
    ja lbb_20389                                    if true { pc += -127 }
lbb_20516:
    ldxdw r1, [r8+0x20]                     
    ldxdw r2, [r8+0x28]                     
    ldxdw r4, [r2+0x18]                     
    ldxdw r2, [r10-0x10]                    
    ldxdw r3, [r10-0x18]                    
lbb_20521:
    callx r4                                
    mov64 r6, r0                                    r6 = r0
lbb_20523:
    and64 r6, 1                                     r6 &= 1   ///  r6 = r6.and(1)
    mov64 r0, r6                                    r0 = r6
    exit                                    

function_20526:
    ldxdw r4, [r1+0x20]                     
    ldxdw r1, [r1+0x28]                     
    ldxdw r5, [r1+0x18]                     
    mov64 r1, r4                                    r1 = r4
    callx r5                                
    exit                                    

function_20532:
    ldxw r0, [r1+0x30]                      
    and64 r0, 16                                    r0 &= 16   ///  r0 = r0.and(16)
    rsh64 r0, 4                                     r0 >>= 4   ///  r0 = r0.wrapping_shr(4)
    exit                                    

function_20536:
    ldxw r0, [r1+0x30]                      
    and64 r0, 32                                    r0 &= 32   ///  r0 = r0.and(32)
    rsh64 r0, 5                                     r0 >>= 5   ///  r0 = r0.wrapping_shr(5)
    exit                                    

function_20540:
    mov64 r6, r2                                    r6 = r2
    mov64 r7, r1                                    r7 = r1
    ldxdw r1, [r6+0x28]                     
    ldxdw r5, [r1+0x18]                     
    ldxdw r1, [r6+0x20]                     
    mov64 r2, r3                                    r2 = r3
    mov64 r3, r4                                    r3 = r4
    callx r5                                
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    stxb [r7+0x9], r1                       
    stxb [r7+0x8], r0                       
    stxdw [r7+0x0], r6                      
    exit                                    

function_20553:
    mov64 r8, r1                                    r8 = r1
    ldxdw r1, [r2+0x20]                     
    ldxdw r2, [r2+0x28]                     
    ldxdw r3, [r2+0x20]                     
    stxdw [r10-0x20], r1                    
    mov64 r2, 39                                    r2 = 39 as i32 as i64 as u64
    stxdw [r10-0x28], r3                    
    callx r3                                
    mov64 r7, 1                                     r7 = 1 as i32 as i64 as u64
    jne r0, 0, lbb_20649                            if r0 != (0 as i32 as i64 as u64) { pc += 86 }
    ldxw r2, [r8+0x0]                       
    mov64 r1, r10                                   r1 = r10
    add64 r1, -24                                   r1 += -24   ///  r1 = r1.wrapping_add(-24 as i32 as i64 as u64)
    mov64 r3, 257                                   r3 = 257 as i32 as i64 as u64
    call function_19011                     
    ldxb r9, [r10-0x4]                      
    ldxw r1, [r10-0x8]                      
    stxdw [r10-0x38], r1                    
    ldxdw r6, [r10-0x10]                    
    ldxw r8, [r10-0x18]                     
    ldxw r1, [r10-0x14]                     
    stxdw [r10-0x30], r1                    
    jeq r1, 1114112, lbb_20578                      if r1 == (1114112 as i32 as i64 as u64) { pc += 2 }
    mov64 r7, 1                                     r7 = 1 as i32 as i64 as u64
    ja lbb_20594                                    if true { pc += 16 }
lbb_20578:
    mov64 r7, 1                                     r7 = 1 as i32 as i64 as u64
    ja lbb_20651                                    if true { pc += 71 }
lbb_20580:
    jeq r3, 1, lbb_20587                            if r3 == (1 as i32 as i64 as u64) { pc += 6 }
lbb_20581:
    ldxdw r1, [r10-0x20]                    
    mov64 r2, 39                                    r2 = 39 as i32 as i64 as u64
    ldxdw r3, [r10-0x28]                    
    callx r3                                
    mov64 r7, r0                                    r7 = r0
    ja lbb_20649                                    if true { pc += 62 }
lbb_20587:
    mov64 r8, 0                                     r8 = 0 as i32 as i64 as u64
    ldxdw r2, [r10-0x30]                    
lbb_20589:
    mov64 r6, r1                                    r6 = r1
lbb_20590:
    ldxdw r1, [r10-0x20]                    
    ldxdw r3, [r10-0x28]                    
    callx r3                                
    jne r0, 0, lbb_20649                            if r0 != (0 as i32 as i64 as u64) { pc += 55 }
lbb_20594:
    mov64 r1, r6                                    r1 = r6
    lsh64 r8, 32                                    r8 <<= 32   ///  r8 = r8.wrapping_shl(32)
    mov64 r3, r8                                    r3 = r8
    rsh64 r3, 32                                    r3 >>= 32   ///  r3 = r3.wrapping_shr(32)
    jsgt r3, 1, lbb_20600                           if (r3 as i64) > (1 as i32 as i64) { pc += 1 }
    ja lbb_20580                                    if true { pc += -20 }
lbb_20600:
    mov64 r8, 1                                     r8 = 1 as i32 as i64 as u64
    mov64 r2, 92                                    r2 = 92 as i32 as i64 as u64
    mov64 r6, r1                                    r6 = r1
    jeq r3, 2, lbb_20590                            if r3 == (2 as i32 as i64 as u64) { pc += -14 }
    mov64 r8, 3                                     r8 = 3 as i32 as i64 as u64
    mov64 r3, r9                                    r3 = r9
    and64 r3, 255                                   r3 &= 255   ///  r3 = r3.and(255)
    jsgt r3, 2, lbb_20614                           if (r3 as i64) > (2 as i32 as i64) { pc += 6 }
    mov64 r9, 0                                     r9 = 0 as i32 as i64 as u64
    mov64 r2, 125                                   r2 = 125 as i32 as i64 as u64
    mov64 r6, r1                                    r6 = r1
    jeq r3, 1, lbb_20590                            if r3 == (1 as i32 as i64 as u64) { pc += -22 }
    jeq r3, 2, lbb_20618                            if r3 == (2 as i32 as i64 as u64) { pc += 5 }
    ja lbb_20581                                    if true { pc += -33 }
lbb_20614:
    jeq r3, 3, lbb_20635                            if r3 == (3 as i32 as i64 as u64) { pc += 20 }
    jeq r3, 4, lbb_20638                            if r3 == (4 as i32 as i64 as u64) { pc += 22 }
    mov64 r9, 4                                     r9 = 4 as i32 as i64 as u64
    ja lbb_20589                                    if true { pc += -29 }
lbb_20618:
    mov64 r2, r1                                    r2 = r1
    lsh64 r2, 2                                     r2 <<= 2   ///  r2 = r2.wrapping_shl(2)
    and64 r2, 28                                    r2 &= 28   ///  r2 = r2.and(28)
    ldxdw r3, [r10-0x38]                    
    rsh64 r3, r2                                    r3 >>= r2   ///  r3 = r3.wrapping_shr(r2 as u32)
    and64 r3, 15                                    r3 &= 15   ///  r3 = r3.and(15)
    mov64 r2, 48                                    r2 = 48 as i32 as i64 as u64
    mov64 r4, 10                                    r4 = 10 as i32 as i64 as u64
    jgt r4, r3, lbb_20628                           if r4 > r3 { pc += 1 }
    mov64 r2, 87                                    r2 = 87 as i32 as i64 as u64
lbb_20628:
    add64 r2, r3                                    r2 += r3   ///  r2 = r2.wrapping_add(r3)
    mov64 r6, 0                                     r6 = 0 as i32 as i64 as u64
    mov64 r9, 1                                     r9 = 1 as i32 as i64 as u64
    jeq r1, 0, lbb_20590                            if r1 == (0 as i32 as i64 as u64) { pc += -42 }
    mov64 r9, 2                                     r9 = 2 as i32 as i64 as u64
    add64 r1, -1                                    r1 += -1   ///  r1 = r1.wrapping_add(-1 as i32 as i64 as u64)
    ja lbb_20589                                    if true { pc += -46 }
lbb_20635:
    mov64 r9, 2                                     r9 = 2 as i32 as i64 as u64
    mov64 r2, 123                                   r2 = 123 as i32 as i64 as u64
    ja lbb_20589                                    if true { pc += -49 }
lbb_20638:
    mov64 r8, 3                                     r8 = 3 as i32 as i64 as u64
    mov64 r2, 117                                   r2 = 117 as i32 as i64 as u64
    mov64 r9, 3                                     r9 = 3 as i32 as i64 as u64
    ja lbb_20589                                    if true { pc += -53 }
lbb_20642:
    mov64 r9, 2                                     r9 = 2 as i32 as i64 as u64
    mov64 r2, 123                                   r2 = 123 as i32 as i64 as u64
lbb_20644:
    mov64 r6, r1                                    r6 = r1
lbb_20645:
    ldxdw r1, [r10-0x20]                    
    ldxdw r3, [r10-0x28]                    
    callx r3                                
    jeq r0, 0, lbb_20651                            if r0 == (0 as i32 as i64 as u64) { pc += 2 }
lbb_20649:
    mov64 r0, r7                                    r0 = r7
    exit                                    
lbb_20651:
    mov64 r1, r6                                    r1 = r6
    mov64 r2, 92                                    r2 = 92 as i32 as i64 as u64
    lsh64 r8, 32                                    r8 <<= 32   ///  r8 = r8.wrapping_shl(32)
    mov64 r3, r8                                    r3 = r8
    rsh64 r3, 32                                    r3 >>= 32   ///  r3 = r3.wrapping_shr(32)
    mov64 r8, 1                                     r8 = 1 as i32 as i64 as u64
    jeq r3, 2, lbb_20645                            if r3 == (2 as i32 as i64 as u64) { pc += -13 }
    jeq r3, 3, lbb_20660                            if r3 == (3 as i32 as i64 as u64) { pc += 1 }
    ja lbb_20581                                    if true { pc += -79 }
lbb_20660:
    mov64 r8, 3                                     r8 = 3 as i32 as i64 as u64
    mov64 r3, r9                                    r3 = r9
    and64 r3, 255                                   r3 &= 255   ///  r3 = r3.and(255)
    jsgt r3, 2, lbb_20670                           if (r3 as i64) > (2 as i32 as i64) { pc += 6 }
    mov64 r9, 0                                     r9 = 0 as i32 as i64 as u64
    mov64 r2, 125                                   r2 = 125 as i32 as i64 as u64
    mov64 r6, r1                                    r6 = r1
    jeq r3, 1, lbb_20645                            if r3 == (1 as i32 as i64 as u64) { pc += -23 }
    jeq r3, 2, lbb_20674                            if r3 == (2 as i32 as i64 as u64) { pc += 5 }
    ja lbb_20581                                    if true { pc += -89 }
lbb_20670:
    jeq r3, 3, lbb_20642                            if r3 == (3 as i32 as i64 as u64) { pc += -29 }
    jeq r3, 4, lbb_20691                            if r3 == (4 as i32 as i64 as u64) { pc += 19 }
    mov64 r9, 4                                     r9 = 4 as i32 as i64 as u64
    ja lbb_20644                                    if true { pc += -30 }
lbb_20674:
    mov64 r2, r1                                    r2 = r1
    lsh64 r2, 2                                     r2 <<= 2   ///  r2 = r2.wrapping_shl(2)
    and64 r2, 28                                    r2 &= 28   ///  r2 = r2.and(28)
    ldxdw r3, [r10-0x38]                    
    rsh64 r3, r2                                    r3 >>= r2   ///  r3 = r3.wrapping_shr(r2 as u32)
    and64 r3, 15                                    r3 &= 15   ///  r3 = r3.and(15)
    mov64 r2, 48                                    r2 = 48 as i32 as i64 as u64
    mov64 r4, 10                                    r4 = 10 as i32 as i64 as u64
    jgt r4, r3, lbb_20684                           if r4 > r3 { pc += 1 }
    mov64 r2, 87                                    r2 = 87 as i32 as i64 as u64
lbb_20684:
    add64 r2, r3                                    r2 += r3   ///  r2 = r2.wrapping_add(r3)
    mov64 r6, 0                                     r6 = 0 as i32 as i64 as u64
    mov64 r9, 1                                     r9 = 1 as i32 as i64 as u64
    jeq r1, 0, lbb_20645                            if r1 == (0 as i32 as i64 as u64) { pc += -43 }
    mov64 r9, 2                                     r9 = 2 as i32 as i64 as u64
    add64 r1, -1                                    r1 += -1   ///  r1 = r1.wrapping_add(-1 as i32 as i64 as u64)
    ja lbb_20644                                    if true { pc += -47 }
lbb_20691:
    mov64 r8, 3                                     r8 = 3 as i32 as i64 as u64
    mov64 r2, 117                                   r2 = 117 as i32 as i64 as u64
    mov64 r9, 3                                     r9 = 3 as i32 as i64 as u64
    ja lbb_20644                                    if true { pc += -51 }

function_20695:
    call function_18945                     
    syscall [invalid]                       

function_20697:
    stxdw [r10-0x58], r2                    
    stxdw [r10-0x60], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -32                                   r1 += -32   ///  r1 = r1.wrapping_add(-32 as i32 as i64 as u64)
    stxdw [r10-0x30], r1                    
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    stxdw [r10-0x40], r1                    
    mov64 r1, 2                                     r1 = 2 as i32 as i64 as u64
    stxdw [r10-0x28], r1                    
    stxdw [r10-0x48], r1                    
    lddw r1, 0x10002e1c8 --> b"\x00\x00\x00\x00\xcc\xce\x02\x00\x12\x00\x00\x00\x00\x00\x00\x00\x00\x00\…        r1 load str located at 4295156168
    stxdw [r10-0x50], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -88                                   r1 += -88   ///  r1 = r1.wrapping_add(-88 as i32 as i64 as u64)
    stxdw [r10-0x10], r1                    
    lddw r1, 0x10002a580 --> b"\xbf#\x00\x00\x00\x00\x00\x00y\x11\x00\x00\x00\x00\x00\x00\xb7\x02\x00\x0…        r1 load str located at 4295140736
    stxdw [r10-0x8], r1                     
    stxdw [r10-0x18], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -96                                   r1 += -96   ///  r1 = r1.wrapping_add(-96 as i32 as i64 as u64)
    stxdw [r10-0x20], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -80                                   r1 += -80   ///  r1 = r1.wrapping_add(-80 as i32 as i64 as u64)
    lddw r2, 0x10002e1e8 --> b"\x00\x00\x00\x00\x00\xcf\x02\x00\x1f\x00\x00\x00\x00\x00\x00\x004\x00\x00…        r2 load str located at 4295156200
    call function_19352                     
    syscall [invalid]                       

function_20726:
    call function_18955                     
    syscall [invalid]                       

function_20728:
    stxdw [r10-0x58], r2                    
    stxdw [r10-0x60], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -32                                   r1 += -32   ///  r1 = r1.wrapping_add(-32 as i32 as i64 as u64)
    stxdw [r10-0x30], r1                    
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    stxdw [r10-0x40], r1                    
    mov64 r1, 2                                     r1 = 2 as i32 as i64 as u64
    stxdw [r10-0x28], r1                    
    stxdw [r10-0x48], r1                    
    lddw r1, 0x10002e200 --> b"\x00\x00\x00\x00p\xc3\x02\x00\x10\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00…        r1 load str located at 4295156224
    stxdw [r10-0x50], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -88                                   r1 += -88   ///  r1 = r1.wrapping_add(-88 as i32 as i64 as u64)
    stxdw [r10-0x10], r1                    
    lddw r1, 0x10002a580 --> b"\xbf#\x00\x00\x00\x00\x00\x00y\x11\x00\x00\x00\x00\x00\x00\xb7\x02\x00\x0…        r1 load str located at 4295140736
    stxdw [r10-0x8], r1                     
    stxdw [r10-0x18], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -96                                   r1 += -96   ///  r1 = r1.wrapping_add(-96 as i32 as i64 as u64)
    stxdw [r10-0x20], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -80                                   r1 += -80   ///  r1 = r1.wrapping_add(-80 as i32 as i64 as u64)
    lddw r2, 0x10002e220 --> b"\x00\x00\x00\x00\x00\xcf\x02\x00\x1f\x00\x00\x00\x00\x00\x00\x00I\x00\x00…        r2 load str located at 4295156256
    call function_19352                     
    syscall [invalid]                       

function_20757:
    call function_18947                     
    syscall [invalid]                       

function_20759:
    stxdw [r10-0x58], r2                    
    stxdw [r10-0x60], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -32                                   r1 += -32   ///  r1 = r1.wrapping_add(-32 as i32 as i64 as u64)
    stxdw [r10-0x30], r1                    
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    stxdw [r10-0x40], r1                    
    mov64 r1, 2                                     r1 = 2 as i32 as i64 as u64
    stxdw [r10-0x28], r1                    
    stxdw [r10-0x48], r1                    
    lddw r1, 0x10002e238 --> b"\x00\x00\x00\x00\x1f\xcf\x02\x00\x16\x00\x00\x00\x00\x00\x00\x00\x00\x00\…        r1 load str located at 4295156280
    stxdw [r10-0x50], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -88                                   r1 += -88   ///  r1 = r1.wrapping_add(-88 as i32 as i64 as u64)
    stxdw [r10-0x10], r1                    
    lddw r1, 0x10002a580 --> b"\xbf#\x00\x00\x00\x00\x00\x00y\x11\x00\x00\x00\x00\x00\x00\xb7\x02\x00\x0…        r1 load str located at 4295140736
    stxdw [r10-0x8], r1                     
    stxdw [r10-0x18], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -96                                   r1 += -96   ///  r1 = r1.wrapping_add(-96 as i32 as i64 as u64)
    stxdw [r10-0x20], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -80                                   r1 += -80   ///  r1 = r1.wrapping_add(-80 as i32 as i64 as u64)
    lddw r2, 0x10002e258 --> b"\x00\x00\x00\x00\x00\xcf\x02\x00\x1f\x00\x00\x00\x00\x00\x00\x00\\x00\x00…        r2 load str located at 4295156312
    call function_19352                     
    syscall [invalid]                       

function_20788:
    stxdw [r10-0x58], r2                    
    stxdw [r10-0x60], r1                    
    mov64 r1, 2                                     r1 = 2 as i32 as i64 as u64
    stxdw [r10-0x28], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -32                                   r1 += -32   ///  r1 = r1.wrapping_add(-32 as i32 as i64 as u64)
    stxdw [r10-0x30], r1                    
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    stxdw [r10-0x40], r1                    
    mov64 r1, 3                                     r1 = 3 as i32 as i64 as u64
    stxdw [r10-0x48], r1                    
    lddw r1, 0x10002e270 --> b"\x00\x00\x00\x00B\xcf\x02\x00\x15\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00…        r1 load str located at 4295156336
    stxdw [r10-0x50], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -96                                   r1 += -96   ///  r1 = r1.wrapping_add(-96 as i32 as i64 as u64)
    stxdw [r10-0x10], r1                    
    lddw r1, 0x10002a580 --> b"\xbf#\x00\x00\x00\x00\x00\x00y\x11\x00\x00\x00\x00\x00\x00\xb7\x02\x00\x0…        r1 load str located at 4295140736
    stxdw [r10-0x8], r1                     
    stxdw [r10-0x18], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -88                                   r1 += -88   ///  r1 = r1.wrapping_add(-88 as i32 as i64 as u64)
    stxdw [r10-0x20], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -80                                   r1 += -80   ///  r1 = r1.wrapping_add(-80 as i32 as i64 as u64)
    mov64 r2, r3                                    r2 = r3
    call function_19352                     
    syscall [invalid]                       

function_20817:
    mov64 r7, r1                                    r7 = r1
    add64 r7, 7                                     r7 += 7   ///  r7 = r7.wrapping_add(7 as i32 as i64 as u64)
    and64 r7, -8                                    r7 &= -8   ///  r7 = r7.and(-8)
    mov64 r4, r7                                    r4 = r7
    sub64 r4, r1                                    r4 -= r1   ///  r4 = r4.wrapping_sub(r1)
    jgt r4, r2, lbb_20952                           if r4 > r2 { pc += 129 }
    jgt r4, 8, lbb_20952                            if r4 > (8 as i32 as i64 as u64) { pc += 128 }
    mov64 r5, r2                                    r5 = r2
    sub64 r5, r4                                    r5 -= r4   ///  r5 = r5.wrapping_sub(r4)
    mov64 r3, 8                                     r3 = 8 as i32 as i64 as u64
    jgt r3, r5, lbb_20952                           if r3 > r5 { pc += 124 }
    mov64 r3, r5                                    r3 = r5
    and64 r3, 7                                     r3 &= 7   ///  r3 = r3.and(7)
    mov64 r0, 0                                     r0 = 0 as i32 as i64 as u64
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
    jeq r4, 0, lbb_20842                            if r4 == (0 as i32 as i64 as u64) { pc += 9 }
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
    mov64 r6, r1                                    r6 = r1
    sub64 r6, r7                                    r6 -= r7   ///  r6 = r6.wrapping_sub(r7)
    mov64 r7, r1                                    r7 = r1
    ja lbb_20850                                    if true { pc += 12 }
lbb_20838:
    add64 r2, r8                                    r2 += r8   ///  r2 = r2.wrapping_add(r8)
    add64 r7, 1                                     r7 += 1   ///  r7 = r7.wrapping_add(1 as i32 as i64 as u64)
    add64 r6, 1                                     r6 += 1   ///  r6 = r6.wrapping_add(1 as i32 as i64 as u64)
    jne r6, 0, lbb_20850                            if r6 != (0 as i32 as i64 as u64) { pc += 8 }
lbb_20842:
    add64 r1, r4                                    r1 += r4   ///  r1 = r1.wrapping_add(r4)
    jeq r3, 0, lbb_20861                            if r3 == (0 as i32 as i64 as u64) { pc += 17 }
    mov64 r0, r5                                    r0 = r5
    and64 r0, -8                                    r0 &= -8   ///  r0 = r0.and(-8)
    mov64 r4, r1                                    r4 = r1
    add64 r4, r0                                    r4 += r0   ///  r4 = r4.wrapping_add(r0)
    mov64 r0, 0                                     r0 = 0 as i32 as i64 as u64
    ja lbb_20866                                    if true { pc += 16 }
lbb_20850:
    ldxb r9, [r7+0x0]                       
    lsh64 r9, 56                                    r9 <<= 56   ///  r9 = r9.wrapping_shl(56)
    arsh64 r9, 56                                   r9 >>= 56 (signed)   ///  r9 = (r9 as i64).wrapping_shr(56)
    mov64 r8, 1                                     r8 = 1 as i32 as i64 as u64
    jsgt r9, -65, lbb_20838                         if (r9 as i64) > (-65 as i32 as i64) { pc += -17 }
    mov64 r8, 0                                     r8 = 0 as i32 as i64 as u64
    ja lbb_20838                                    if true { pc += -19 }
lbb_20857:
    add64 r0, r6                                    r0 += r6   ///  r0 = r0.wrapping_add(r6)
    add64 r4, 1                                     r4 += 1   ///  r4 = r4.wrapping_add(1 as i32 as i64 as u64)
    add64 r3, -1                                    r3 += -1   ///  r3 = r3.wrapping_add(-1 as i32 as i64 as u64)
    jne r3, 0, lbb_20866                            if r3 != (0 as i32 as i64 as u64) { pc += 5 }
lbb_20861:
    rsh64 r5, 3                                     r5 >>= 3   ///  r5 = r5.wrapping_shr(3)
    add64 r0, r2                                    r0 += r2   ///  r0 = r0.wrapping_add(r2)
    lddw r8, 0x101010101010101                      r8 load str located at 72340172838076673
    ja lbb_20934                                    if true { pc += 68 }
lbb_20866:
    ldxb r7, [r4+0x0]                       
    lsh64 r7, 56                                    r7 <<= 56   ///  r7 = r7.wrapping_shl(56)
    arsh64 r7, 56                                   r7 >>= 56 (signed)   ///  r7 = (r7 as i64).wrapping_shr(56)
    mov64 r6, 1                                     r6 = 1 as i32 as i64 as u64
    jsgt r7, -65, lbb_20857                         if (r7 as i64) > (-65 as i32 as i64) { pc += -14 }
    mov64 r6, 0                                     r6 = 0 as i32 as i64 as u64
    ja lbb_20857                                    if true { pc += -16 }
lbb_20873:
    ldxdw r9, [r5+0x0]                      
    mov64 r6, r9                                    r6 = r9
    rsh64 r6, 6                                     r6 >>= 6   ///  r6 = r6.wrapping_shr(6)
    xor64 r9, -1                                    r9 ^= -1   ///  r9 = r9.xor(-1)
    rsh64 r9, 7                                     r9 >>= 7   ///  r9 = r9.wrapping_shr(7)
    or64 r9, r6                                     r9 |= r6   ///  r9 = r9.or(r6)
    and64 r9, r8                                    r9 &= r8   ///  r9 = r9.and(r8)
    add64 r9, r4                                    r9 += r4   ///  r9 = r9.wrapping_add(r4)
    ldxdw r4, [r5+0x8]                      
    mov64 r6, r4                                    r6 = r4
    rsh64 r6, 6                                     r6 >>= 6   ///  r6 = r6.wrapping_shr(6)
    xor64 r4, -1                                    r4 ^= -1   ///  r4 = r4.xor(-1)
    rsh64 r4, 7                                     r4 >>= 7   ///  r4 = r4.wrapping_shr(7)
    or64 r4, r6                                     r4 |= r6   ///  r4 = r4.or(r6)
    and64 r4, r8                                    r4 &= r8   ///  r4 = r4.and(r8)
    add64 r4, r9                                    r4 += r9   ///  r4 = r4.wrapping_add(r9)
    ldxdw r9, [r5+0x10]                     
    mov64 r6, r9                                    r6 = r9
    rsh64 r6, 6                                     r6 >>= 6   ///  r6 = r6.wrapping_shr(6)
    xor64 r9, -1                                    r9 ^= -1   ///  r9 = r9.xor(-1)
    rsh64 r9, 7                                     r9 >>= 7   ///  r9 = r9.wrapping_shr(7)
    or64 r9, r6                                     r9 |= r6   ///  r9 = r9.or(r6)
    and64 r9, r8                                    r9 &= r8   ///  r9 = r9.and(r8)
    add64 r9, r4                                    r9 += r4   ///  r9 = r9.wrapping_add(r4)
    ldxdw r4, [r5+0x18]                     
    mov64 r6, r4                                    r6 = r4
    rsh64 r6, 6                                     r6 >>= 6   ///  r6 = r6.wrapping_shr(6)
    xor64 r4, -1                                    r4 ^= -1   ///  r4 = r4.xor(-1)
    rsh64 r4, 7                                     r4 >>= 7   ///  r4 = r4.wrapping_shr(7)
    or64 r4, r6                                     r4 |= r6   ///  r4 = r4.or(r6)
    and64 r4, r8                                    r4 &= r8   ///  r4 = r4.and(r8)
    add64 r4, r9                                    r4 += r9   ///  r4 = r4.wrapping_add(r9)
    add64 r5, 32                                    r5 += 32   ///  r5 = r5.wrapping_add(32 as i32 as i64 as u64)
    jne r5, r1, lbb_20873                           if r5 != r1 { pc += -34 }
lbb_20907:
    mov64 r9, r7                                    r9 = r7
    and64 r9, 3                                     r9 &= 3   ///  r9 = r9.and(3)
    mov64 r5, r3                                    r5 = r3
    sub64 r5, r7                                    r5 -= r7   ///  r5 = r5.wrapping_sub(r7)
    lsh64 r7, 3                                     r7 <<= 3   ///  r7 = r7.wrapping_shl(3)
    mov64 r1, r2                                    r1 = r2
    add64 r1, r7                                    r1 += r7   ///  r1 = r1.wrapping_add(r7)
    mov64 r6, r4                                    r6 = r4
    lddw r7, 0xff00ff00ff00ff                       r7 load str located at 71777214294589695
    and64 r6, r7                                    r6 &= r7   ///  r6 = r6.and(r7)
    rsh64 r4, 8                                     r4 >>= 8   ///  r4 = r4.wrapping_shr(8)
    and64 r4, r7                                    r4 &= r7   ///  r4 = r4.and(r7)
    add64 r4, r6                                    r4 += r6   ///  r4 = r4.wrapping_add(r6)
    lddw r6, 0x1000100010001                        r6 load str located at 281479271743489
    mul64 r4, r6                                    r4 *= r6   ///  r4 = r4.wrapping_mul(r6)
    rsh64 r4, 48                                    r4 >>= 48   ///  r4 = r4.wrapping_shr(48)
    add64 r4, r0                                    r4 += r0   ///  r4 = r4.wrapping_add(r0)
    mov64 r0, r4                                    r0 = r4
    jeq r9, 0, lbb_20934                            if r9 == (0 as i32 as i64 as u64) { pc += 6 }
    ldxdw r5, [r10-0x8]                     
    lsh64 r5, 3                                     r5 <<= 3   ///  r5 = r5.wrapping_shl(3)
    mov64 r1, 192                                   r1 = 192 as i32 as i64 as u64
    jgt r1, r3, lbb_20956                           if r1 > r3 { pc += 24 }
    mov64 r3, 192                                   r3 = 192 as i32 as i64 as u64
    ja lbb_20956                                    if true { pc += 22 }
lbb_20934:
    mov64 r3, r5                                    r3 = r5
    mov64 r2, r1                                    r2 = r1
    jeq r3, 0, lbb_20992                            if r3 == (0 as i32 as i64 as u64) { pc += 55 }
    mov64 r1, 192                                   r1 = 192 as i32 as i64 as u64
    mov64 r7, r3                                    r7 = r3
    jgt r1, r3, lbb_20941                           if r1 > r3 { pc += 1 }
    mov64 r7, 192                                   r7 = 192 as i32 as i64 as u64
lbb_20941:
    mov64 r4, 0                                     r4 = 0 as i32 as i64 as u64
    mov64 r5, r7                                    r5 = r7
    and64 r5, 252                                   r5 &= 252   ///  r5 = r5.and(252)
    stxdw [r10-0x8], r5                     
    lsh64 r5, 3                                     r5 <<= 3   ///  r5 = r5.wrapping_shl(3)
    jeq r5, 0, lbb_20907                            if r5 == (0 as i32 as i64 as u64) { pc += -40 }
    mov64 r1, r2                                    r1 = r2
    add64 r1, r5                                    r1 += r5   ///  r1 = r1.wrapping_add(r5)
    mov64 r4, 0                                     r4 = 0 as i32 as i64 as u64
    mov64 r5, r2                                    r5 = r2
    ja lbb_20873                                    if true { pc += -79 }
lbb_20952:
    mov64 r0, 0                                     r0 = 0 as i32 as i64 as u64
    jeq r2, 0, lbb_20992                            if r2 == (0 as i32 as i64 as u64) { pc += 38 }
    mov64 r0, 0                                     r0 = 0 as i32 as i64 as u64
    ja lbb_20993                                    if true { pc += 37 }
lbb_20956:
    add64 r2, r5                                    r2 += r5   ///  r2 = r2.wrapping_add(r5)
    mov64 r5, 0                                     r5 = 0 as i32 as i64 as u64
    and64 r3, 3                                     r3 &= 3   ///  r3 = r3.and(3)
    lsh64 r3, 3                                     r3 <<= 3   ///  r3 = r3.wrapping_shl(3)
    lddw r1, 0x101010101010101                      r1 load str located at 72340172838076673
lbb_20962:
    ldxdw r0, [r2+0x0]                      
    mov64 r6, r0                                    r6 = r0
    rsh64 r6, 6                                     r6 >>= 6   ///  r6 = r6.wrapping_shr(6)
    xor64 r0, -1                                    r0 ^= -1   ///  r0 = r0.xor(-1)
    rsh64 r0, 7                                     r0 >>= 7   ///  r0 = r0.wrapping_shr(7)
    or64 r0, r6                                     r0 |= r6   ///  r0 = r0.or(r6)
    and64 r0, r1                                    r0 &= r1   ///  r0 = r0.and(r1)
    add64 r0, r5                                    r0 += r5   ///  r0 = r0.wrapping_add(r5)
    add64 r2, 8                                     r2 += 8   ///  r2 = r2.wrapping_add(8 as i32 as i64 as u64)
    add64 r3, -8                                    r3 += -8   ///  r3 = r3.wrapping_add(-8 as i32 as i64 as u64)
    mov64 r5, r0                                    r5 = r0
    jeq r3, 0, lbb_20975                            if r3 == (0 as i32 as i64 as u64) { pc += 1 }
    ja lbb_20962                                    if true { pc += -13 }
lbb_20975:
    lddw r1, 0xff00ff00ff00ff                       r1 load str located at 71777214294589695
    mov64 r2, r0                                    r2 = r0
    and64 r2, r1                                    r2 &= r1   ///  r2 = r2.and(r1)
    rsh64 r0, 8                                     r0 >>= 8   ///  r0 = r0.wrapping_shr(8)
    and64 r0, r1                                    r0 &= r1   ///  r0 = r0.and(r1)
    add64 r0, r2                                    r0 += r2   ///  r0 = r0.wrapping_add(r2)
    lddw r1, 0x1000100010001                        r1 load str located at 281479271743489
    mul64 r0, r1                                    r0 *= r1   ///  r0 = r0.wrapping_mul(r1)
    rsh64 r0, 48                                    r0 >>= 48   ///  r0 = r0.wrapping_shr(48)
    add64 r0, r4                                    r0 += r4   ///  r0 = r0.wrapping_add(r4)
    ja lbb_20992                                    if true { pc += 4 }
lbb_20988:
    add64 r0, r3                                    r0 += r3   ///  r0 = r0.wrapping_add(r3)
    add64 r1, 1                                     r1 += 1   ///  r1 = r1.wrapping_add(1 as i32 as i64 as u64)
    add64 r2, -1                                    r2 += -1   ///  r2 = r2.wrapping_add(-1 as i32 as i64 as u64)
    jne r2, 0, lbb_20993                            if r2 != (0 as i32 as i64 as u64) { pc += 1 }
lbb_20992:
    exit                                    
lbb_20993:
    ldxb r4, [r1+0x0]                       
    lsh64 r4, 56                                    r4 <<= 56   ///  r4 = r4.wrapping_shl(56)
    arsh64 r4, 56                                   r4 >>= 56 (signed)   ///  r4 = (r4 as i64).wrapping_shr(56)
    mov64 r3, 1                                     r3 = 1 as i32 as i64 as u64
    jsgt r4, -65, lbb_20988                         if (r4 as i64) > (-65 as i32 as i64) { pc += -10 }
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
    ja lbb_20988                                    if true { pc += -12 }

function_21000:
    stxdw [r10-0x8], r4                     
    stxdw [r10-0x10], r3                    
    stxdw [r10-0x18], r2                    
    stxdw [r10-0x20], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -32                                   r1 += -32   ///  r1 = r1.wrapping_add(-32 as i32 as i64 as u64)
    call function_18949                     
    syscall [invalid]                       

function_21008:
    mov64 r5, r3                                    r5 = r3
    stxdw [r10-0xc8], r4                    
    stxdw [r10-0xd0], r5                    
    mov64 r3, 257                                   r3 = 257 as i32 as i64 as u64
    jgt r3, r2, lbb_21037                           if r3 > r2 { pc += 24 }
    mov64 r0, 256                                   r0 = 256 as i32 as i64 as u64
    ldxb r3, [r1+0x100]                     
    lsh64 r3, 56                                    r3 <<= 56   ///  r3 = r3.wrapping_shl(56)
    arsh64 r3, 56                                   r3 >>= 56 (signed)   ///  r3 = (r3 as i64).wrapping_shr(56)
    jsgt r3, -65, lbb_21029                         if (r3 as i64) > (-65 as i32 as i64) { pc += 11 }
    mov64 r0, 255                                   r0 = 255 as i32 as i64 as u64
    ldxb r3, [r1+0xff]                      
    lsh64 r3, 56                                    r3 <<= 56   ///  r3 = r3.wrapping_shl(56)
    arsh64 r3, 56                                   r3 >>= 56 (signed)   ///  r3 = (r3 as i64).wrapping_shr(56)
    jsgt r3, -65, lbb_21029                         if (r3 as i64) > (-65 as i32 as i64) { pc += 6 }
    mov64 r0, 254                                   r0 = 254 as i32 as i64 as u64
    ldxb r3, [r1+0xfe]                      
    lsh64 r3, 56                                    r3 <<= 56   ///  r3 = r3.wrapping_shl(56)
    arsh64 r3, 56                                   r3 >>= 56 (signed)   ///  r3 = (r3 as i64).wrapping_shr(56)
    jsgt r3, -65, lbb_21029                         if (r3 as i64) > (-65 as i32 as i64) { pc += 1 }
    mov64 r0, 253                                   r0 = 253 as i32 as i64 as u64
lbb_21029:
    mov64 r3, r0                                    r3 = r0
    jgt r2, r0, lbb_21038                           if r2 > r0 { pc += 7 }
    mov64 r3, r2                                    r3 = r2
    jeq r0, r2, lbb_21038                           if r0 == r2 { pc += 5 }
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
    mov64 r4, r0                                    r4 = r0
    call function_21000                     
    syscall [invalid]                       
lbb_21037:
    mov64 r3, r2                                    r3 = r2
lbb_21038:
    lddw r0, 0x10002cf9d --> b"[...]byte index  is out of bounds of `begin <= end"        r0 load str located at 4295151517
    jgt r2, r3, lbb_21043                           if r2 > r3 { pc += 2 }
    lddw r0, 0x10002cd80 --> b")..Bo"               r0 load str located at 4295150976
lbb_21043:
    mov64 r6, 5                                     r6 = 5 as i32 as i64 as u64
    jgt r2, r3, lbb_21046                           if r2 > r3 { pc += 1 }
    mov64 r6, 0                                     r6 = 0 as i32 as i64 as u64
lbb_21046:
    stxdw [r10-0xb8], r3                    
    stxdw [r10-0xc0], r1                    
    stxdw [r10-0xa8], r6                    
    stxdw [r10-0xb0], r0                    
    jgt r5, r2, lbb_21091                           if r5 > r2 { pc += 40 }
    jgt r4, r2, lbb_21091                           if r4 > r2 { pc += 39 }
    jgt r5, r4, lbb_21054                           if r5 > r4 { pc += 1 }
    ja lbb_21127                                    if true { pc += 73 }
lbb_21054:
    mov64 r1, r10                                   r1 = r10
    add64 r1, -80                                   r1 += -80   ///  r1 = r1.wrapping_add(-80 as i32 as i64 as u64)
    stxdw [r10-0x60], r1                    
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    stxdw [r10-0x70], r1                    
    mov64 r1, 4                                     r1 = 4 as i32 as i64 as u64
    stxdw [r10-0x58], r1                    
    stxdw [r10-0x78], r1                    
    lddw r1, 0x10002e2e8 --> b"\x00\x00\x00\x00\xc3\xcf\x02\x00\x0e\x00\x00\x00\x00\x00\x00\x00\x00\x00\…        r1 load str located at 4295156456
    stxdw [r10-0x80], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -176                                  r1 += -176   ///  r1 = r1.wrapping_add(-176 as i32 as i64 as u64)
    stxdw [r10-0x20], r1                    
    lddw r1, 0x10002a6b8 --> b"\xbf$\x00\x00\x00\x00\x00\x00y\x13\x08\x00\x00\x00\x00\x00y\x12\x00\x00\x…        r1 load str located at 4295141048
    stxdw [r10-0x18], r1                    
    stxdw [r10-0x28], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -192                                  r1 += -192   ///  r1 = r1.wrapping_add(-192 as i32 as i64 as u64)
    stxdw [r10-0x30], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -200                                  r1 += -200   ///  r1 = r1.wrapping_add(-200 as i32 as i64 as u64)
    stxdw [r10-0x40], r1                    
    lddw r1, 0x10002a580 --> b"\xbf#\x00\x00\x00\x00\x00\x00y\x11\x00\x00\x00\x00\x00\x00\xb7\x02\x00\x0…        r1 load str located at 4295140736
    stxdw [r10-0x38], r1                    
    stxdw [r10-0x48], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -208                                  r1 += -208   ///  r1 = r1.wrapping_add(-208 as i32 as i64 as u64)
    stxdw [r10-0x50], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -128                                  r1 += -128   ///  r1 = r1.wrapping_add(-128 as i32 as i64 as u64)
    lddw r2, 0x10002e328 --> b"\x00\x00\x00\x00\x82\xcf\x02\x00\x1b\x00\x00\x00\x00\x00\x00\x00o\x00\x00…        r2 load str located at 4295156520
    call function_19352                     
    syscall [invalid]                       
lbb_21091:
    jgt r5, r2, lbb_21093                           if r5 > r2 { pc += 1 }
    mov64 r5, r4                                    r5 = r4
lbb_21093:
    stxdw [r10-0x90], r5                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -80                                   r1 += -80   ///  r1 = r1.wrapping_add(-80 as i32 as i64 as u64)
    stxdw [r10-0x60], r1                    
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    stxdw [r10-0x70], r1                    
    mov64 r1, 3                                     r1 = 3 as i32 as i64 as u64
    stxdw [r10-0x58], r1                    
    stxdw [r10-0x78], r1                    
    lddw r1, 0x10002e2a0 --> b"\x00\x00\x00\x00\xa2\xcf\x02\x00\x0b\x00\x00\x00\x00\x00\x00\x00\x00\x00\…        r1 load str located at 4295156384
    stxdw [r10-0x80], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -176                                  r1 += -176   ///  r1 = r1.wrapping_add(-176 as i32 as i64 as u64)
    stxdw [r10-0x30], r1                    
    lddw r1, 0x10002a6b8 --> b"\xbf$\x00\x00\x00\x00\x00\x00y\x13\x08\x00\x00\x00\x00\x00y\x12\x00\x00\x…        r1 load str located at 4295141048
    stxdw [r10-0x28], r1                    
    stxdw [r10-0x38], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -192                                  r1 += -192   ///  r1 = r1.wrapping_add(-192 as i32 as i64 as u64)
    stxdw [r10-0x40], r1                    
    lddw r1, 0x10002a580 --> b"\xbf#\x00\x00\x00\x00\x00\x00y\x11\x00\x00\x00\x00\x00\x00\xb7\x02\x00\x0…        r1 load str located at 4295140736
    stxdw [r10-0x48], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -144                                  r1 += -144   ///  r1 = r1.wrapping_add(-144 as i32 as i64 as u64)
    stxdw [r10-0x50], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -128                                  r1 += -128   ///  r1 = r1.wrapping_add(-128 as i32 as i64 as u64)
    lddw r2, 0x10002e2d0 --> b"\x00\x00\x00\x00\x82\xcf\x02\x00\x1b\x00\x00\x00\x00\x00\x00\x00k\x00\x00…        r2 load str located at 4295156432
    call function_19352                     
    syscall [invalid]                       
lbb_21127:
    jeq r5, 0, lbb_21138                            if r5 == (0 as i32 as i64 as u64) { pc += 10 }
    jgt r2, r5, lbb_21131                           if r2 > r5 { pc += 2 }
    jeq r2, r5, lbb_21138                           if r2 == r5 { pc += 8 }
    ja lbb_21139                                    if true { pc += 8 }
lbb_21131:
    mov64 r3, r1                                    r3 = r1
    add64 r3, r5                                    r3 += r5   ///  r3 = r3.wrapping_add(r5)
    ldxb r3, [r3+0x0]                       
    lsh64 r3, 56                                    r3 <<= 56   ///  r3 = r3.wrapping_shl(56)
    arsh64 r3, 56                                   r3 >>= 56 (signed)   ///  r3 = (r3 as i64).wrapping_shr(56)
    mov64 r0, -64                                   r0 = -64 as i32 as i64 as u64
    jsgt r0, r3, lbb_21139                          if (r0 as i64) > (r3 as i64) { pc += 1 }
lbb_21138:
    mov64 r5, r4                                    r5 = r4
lbb_21139:
    stxdw [r10-0xa0], r5                    
    mov64 r3, r2                                    r3 = r2
    jge r5, r2, lbb_21173                           if r5 >= r2 { pc += 31 }
    mov64 r3, r5                                    r3 = r5
    add64 r3, -3                                    r3 += -3   ///  r3 = r3.wrapping_add(-3 as i32 as i64 as u64)
    mov64 r4, 0                                     r4 = 0 as i32 as i64 as u64
    mov64 r0, 1                                     r0 = 1 as i32 as i64 as u64
    jgt r3, r5, lbb_21148                           if r3 > r5 { pc += 1 }
    mov64 r0, 0                                     r0 = 0 as i32 as i64 as u64
lbb_21148:
    jne r0, 0, lbb_21150                            if r0 != (0 as i32 as i64 as u64) { pc += 1 }
    mov64 r4, r3                                    r4 = r3
lbb_21150:
    mov64 r0, r5                                    r0 = r5
    add64 r0, 1                                     r0 += 1   ///  r0 = r0.wrapping_add(1 as i32 as i64 as u64)
    jge r0, r4, lbb_21157                           if r0 >= r4 { pc += 4 }
    mov64 r1, r4                                    r1 = r4
    mov64 r2, r0                                    r2 = r0
    call function_20757                     
    syscall [invalid]                       
lbb_21157:
    mov64 r6, r1                                    r6 = r1
    add64 r6, r4                                    r6 += r4   ///  r6 = r6.wrapping_add(r4)
    mov64 r3, r1                                    r3 = r1
    add64 r3, r0                                    r3 += r0   ///  r3 = r3.wrapping_add(r0)
    sub64 r3, r6                                    r3 -= r6   ///  r3 = r3.wrapping_sub(r6)
    mov64 r0, r1                                    r0 = r1
    add64 r0, r5                                    r0 += r5   ///  r0 = r0.wrapping_add(r5)
    mov64 r5, -64                                   r5 = -64 as i32 as i64 as u64
lbb_21165:
    jeq r3, 0, lbb_21172                            if r3 == (0 as i32 as i64 as u64) { pc += 6 }
    add64 r3, -1                                    r3 += -1   ///  r3 = r3.wrapping_add(-1 as i32 as i64 as u64)
    ldxb r6, [r0+0x0]                       
    add64 r0, -1                                    r0 += -1   ///  r0 = r0.wrapping_add(-1 as i32 as i64 as u64)
    lsh64 r6, 56                                    r6 <<= 56   ///  r6 = r6.wrapping_shl(56)
    arsh64 r6, 56                                   r6 >>= 56 (signed)   ///  r6 = (r6 as i64).wrapping_shr(56)
    jsgt r5, r6, lbb_21165                          if (r5 as i64) > (r6 as i64) { pc += -7 }
lbb_21172:
    add64 r3, r4                                    r3 += r4   ///  r3 = r3.wrapping_add(r4)
lbb_21173:
    jeq r3, 0, lbb_21177                            if r3 == (0 as i32 as i64 as u64) { pc += 3 }
    jgt r2, r3, lbb_21219                           if r2 > r3 { pc += 44 }
    jeq r3, r2, lbb_21177                           if r3 == r2 { pc += 1 }
    ja lbb_21225                                    if true { pc += 48 }
lbb_21177:
    jeq r3, r2, lbb_21212                           if r3 == r2 { pc += 34 }
    add64 r1, r3                                    r1 += r3   ///  r1 = r1.wrapping_add(r3)
    ldxb r5, [r1+0x0]                       
    mov64 r2, r5                                    r2 = r5
    lsh64 r2, 56                                    r2 <<= 56   ///  r2 = r2.wrapping_shl(56)
    arsh64 r2, 56                                   r2 >>= 56 (signed)   ///  r2 = (r2 as i64).wrapping_shr(56)
    jsgt r2, -1, lbb_21228                          if (r2 as i64) > (-1 as i32 as i64) { pc += 44 }
    ldxb r2, [r1+0x1]                       
    and64 r2, 63                                    r2 &= 63   ///  r2 = r2.and(63)
    mov64 r4, r5                                    r4 = r5
    and64 r4, 31                                    r4 &= 31   ///  r4 = r4.and(31)
    mov64 r0, r4                                    r0 = r4
    lsh64 r0, 6                                     r0 <<= 6   ///  r0 = r0.wrapping_shl(6)
    or64 r0, r2                                     r0 |= r2   ///  r0 = r0.or(r2)
    jgt r5, 223, lbb_21193                          if r5 > (223 as i32 as i64 as u64) { pc += 1 }
    ja lbb_21278                                    if true { pc += 85 }
lbb_21193:
    lsh64 r2, 6                                     r2 <<= 6   ///  r2 = r2.wrapping_shl(6)
    ldxb r0, [r1+0x2]                       
    and64 r0, 63                                    r0 &= 63   ///  r0 = r0.and(63)
    or64 r2, r0                                     r2 |= r0   ///  r2 = r2.or(r0)
    mov64 r6, r4                                    r6 = r4
    lsh64 r6, 12                                    r6 <<= 12   ///  r6 = r6.wrapping_shl(12)
    mov64 r0, r2                                    r0 = r2
    or64 r0, r6                                     r0 |= r6   ///  r0 = r0.or(r6)
    mov64 r6, 240                                   r6 = 240 as i32 as i64 as u64
    jgt r6, r5, lbb_21278                           if r6 > r5 { pc += 75 }
    lsh64 r2, 6                                     r2 <<= 6   ///  r2 = r2.wrapping_shl(6)
    ldxb r1, [r1+0x3]                       
    and64 r1, 63                                    r1 &= 63   ///  r1 = r1.and(63)
    or64 r2, r1                                     r2 |= r1   ///  r2 = r2.or(r1)
    lsh64 r4, 18                                    r4 <<= 18   ///  r4 = r4.wrapping_shl(18)
    and64 r4, 1835008                               r4 &= 1835008   ///  r4 = r4.and(1835008)
    or64 r2, r4                                     r2 |= r4   ///  r2 = r2.or(r4)
    mov64 r0, r2                                    r0 = r2
    jne r2, 1114112, lbb_21278                      if r2 != (1114112 as i32 as i64 as u64) { pc += 66 }
lbb_21212:
    lddw r1, 0x10002cdb6 --> b"called `Option::unwrap()` on a `None` value"        r1 load str located at 4295151030
    mov64 r2, 43                                    r2 = 43 as i32 as i64 as u64
    lddw r3, 0x10002e340 --> b"\x00\x00\x00\x00\x82\xcf\x02\x00\x1b\x00\x00\x00\x00\x00\x00\x00}\x00\x00…        r3 load str located at 4295156544
    call function_19306                     
    syscall [invalid]                       
lbb_21219:
    mov64 r4, r1                                    r4 = r1
    add64 r4, r3                                    r4 += r3   ///  r4 = r4.wrapping_add(r3)
    ldxb r4, [r4+0x0]                       
    lsh64 r4, 56                                    r4 <<= 56   ///  r4 = r4.wrapping_shl(56)
    arsh64 r4, 56                                   r4 >>= 56 (signed)   ///  r4 = (r4 as i64).wrapping_shr(56)
    jsgt r4, -65, lbb_21177                         if (r4 as i64) > (-65 as i32 as i64) { pc += -48 }
lbb_21225:
    mov64 r4, r2                                    r4 = r2
    call function_21000                     
    syscall [invalid]                       
lbb_21228:
    stxw [r10-0x94], r5                     
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
lbb_21230:
    stxdw [r10-0x90], r3                    
    add64 r1, r3                                    r1 += r3   ///  r1 = r1.wrapping_add(r3)
    stxdw [r10-0x88], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -80                                   r1 += -80   ///  r1 = r1.wrapping_add(-80 as i32 as i64 as u64)
    stxdw [r10-0x60], r1                    
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    stxdw [r10-0x70], r1                    
    mov64 r1, 5                                     r1 = 5 as i32 as i64 as u64
    stxdw [r10-0x58], r1                    
    stxdw [r10-0x78], r1                    
    lddw r1, 0x10002e358 --> b"\x00\x00\x00\x00\xa2\xcf\x02\x00\x0b\x00\x00\x00\x00\x00\x00\x00\x00\x00\…        r1 load str located at 4295156568
    stxdw [r10-0x80], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -176                                  r1 += -176   ///  r1 = r1.wrapping_add(-176 as i32 as i64 as u64)
    stxdw [r10-0x10], r1                    
    lddw r1, 0x10002a6b8 --> b"\xbf$\x00\x00\x00\x00\x00\x00y\x13\x08\x00\x00\x00\x00\x00y\x12\x00\x00\x…        r1 load str located at 4295141048
    stxdw [r10-0x8], r1                     
    stxdw [r10-0x18], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -192                                  r1 += -192   ///  r1 = r1.wrapping_add(-192 as i32 as i64 as u64)
    stxdw [r10-0x20], r1                    
    lddw r1, 0x100025188 --> b"\xbf&\x00\x00\x00\x00\x00\x00\xbf\x17\x00\x00\x00\x00\x00\x00\x85\x10\x00…        r1 load str located at 4295119240
    stxdw [r10-0x28], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -144                                  r1 += -144   ///  r1 = r1.wrapping_add(-144 as i32 as i64 as u64)
    stxdw [r10-0x30], r1                    
    lddw r1, 0x100028368 --> b"\xbf\x18\x00\x00\x00\x00\x00\x00y! \x00\x00\x00\x00\x00y"(\x00\x00\x00\x0…        r1 load str located at 4295132008
    stxdw [r10-0x38], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -148                                  r1 += -148   ///  r1 = r1.wrapping_add(-148 as i32 as i64 as u64)
    stxdw [r10-0x40], r1                    
    lddw r1, 0x10002a580 --> b"\xbf#\x00\x00\x00\x00\x00\x00y\x11\x00\x00\x00\x00\x00\x00\xb7\x02\x00\x0…        r1 load str located at 4295140736
    stxdw [r10-0x48], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -160                                  r1 += -160   ///  r1 = r1.wrapping_add(-160 as i32 as i64 as u64)
    stxdw [r10-0x50], r1                    
    mov64 r1, r10                                   r1 = r10
    add64 r1, -128                                  r1 += -128   ///  r1 = r1.wrapping_add(-128 as i32 as i64 as u64)
    lddw r2, 0x10002e3a8 --> b"\x00\x00\x00\x00\x82\xcf\x02\x00\x1b\x00\x00\x00\x00\x00\x00\x00\x7f\x00\…        r2 load str located at 4295156648
    call function_19352                     
    syscall [invalid]                       
lbb_21278:
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    stxw [r10-0x94], r0                     
    mov64 r2, 128                                   r2 = 128 as i32 as i64 as u64
    jgt r2, r0, lbb_21230                           if r2 > r0 { pc += -52 }
    mov64 r1, 2                                     r1 = 2 as i32 as i64 as u64
    mov64 r2, 2048                                  r2 = 2048 as i32 as i64 as u64
    jgt r2, r0, lbb_21230                           if r2 > r0 { pc += -55 }
    mov64 r1, 3                                     r1 = 3 as i32 as i64 as u64
    mov64 r2, 65536                                 r2 = 65536 as i32 as i64 as u64
    jgt r2, r0, lbb_21230                           if r2 > r0 { pc += -58 }
    mov64 r1, 4                                     r1 = 4 as i32 as i64 as u64
    ja lbb_21230                                    if true { pc += -60 }

function_21290:
    mov64 r9, r1                                    r9 = r1
    ldxdw r1, [r5-0xff0]                    
    stxdw [r10-0x10], r1                    
    ldxdw r6, [r5-0xff8]                    
    jeq r3, 0, lbb_21337                            if r3 == (0 as i32 as i64 as u64) { pc += 42 }
    lsh64 r3, 1                                     r3 <<= 1   ///  r3 = r3.wrapping_shl(1)
    mov64 r1, r2                                    r1 = r2
    add64 r1, r3                                    r1 += r3   ///  r1 = r1.wrapping_add(r3)
    stxdw [r10-0x8], r1                     
    ldxdw r8, [r5-0x1000]                   
    mov64 r3, r9                                    r3 = r9
    and64 r3, 65280                                 r3 &= 65280   ///  r3 = r3.and(65280)
    rsh64 r3, 8                                     r3 >>= 8   ///  r3 = r3.wrapping_shr(8)
    mov64 r0, 0                                     r0 = 0 as i32 as i64 as u64
    stxdw [r10-0x20], r4                    
    stxdw [r10-0x18], r8                    
    ja lbb_21311                                    if true { pc += 4 }
lbb_21307:
    jgt r1, r3, lbb_21337                           if r1 > r3 { pc += 29 }
    mov64 r0, r5                                    r0 = r5
    ldxdw r1, [r10-0x8]                     
    jeq r2, r1, lbb_21337                           if r2 == r1 { pc += 26 }
lbb_21311:
    ldxb r7, [r2+0x1]                       
    mov64 r5, r0                                    r5 = r0
    add64 r5, r7                                    r5 += r7   ///  r5 = r5.wrapping_add(r7)
    ldxb r1, [r2+0x0]                       
    add64 r2, 2                                     r2 += 2   ///  r2 = r2.wrapping_add(2 as i32 as i64 as u64)
    jeq r1, r3, lbb_21318                           if r1 == r3 { pc += 1 }
    ja lbb_21307                                    if true { pc += -11 }
lbb_21318:
    jgt r0, r5, lbb_21376                           if r0 > r5 { pc += 57 }
    jgt r5, r8, lbb_21380                           if r5 > r8 { pc += 60 }
    add64 r4, r0                                    r4 += r0   ///  r4 = r4.wrapping_add(r0)
lbb_21321:
    jeq r7, 0, lbb_21331                            if r7 == (0 as i32 as i64 as u64) { pc += 9 }
    mov64 r0, 0                                     r0 = 0 as i32 as i64 as u64
    add64 r7, -1                                    r7 += -1   ///  r7 = r7.wrapping_add(-1 as i32 as i64 as u64)
    mov64 r1, r9                                    r1 = r9
    and64 r1, 255                                   r1 &= 255   ///  r1 = r1.and(255)
    ldxb r8, [r4+0x0]                       
    add64 r4, 1                                     r4 += 1   ///  r4 = r4.wrapping_add(1 as i32 as i64 as u64)
    jne r8, r1, lbb_21321                           if r8 != r1 { pc += -8 }
lbb_21329:
    and64 r0, 1                                     r0 &= 1   ///  r0 = r0.and(1)
    exit                                    
lbb_21331:
    mov64 r0, r5                                    r0 = r5
    ldxdw r4, [r10-0x20]                    
    ldxdw r8, [r10-0x18]                    
    ldxdw r1, [r10-0x8]                     
    jeq r2, r1, lbb_21337                           if r2 == r1 { pc += 1 }
    ja lbb_21311                                    if true { pc += -26 }
lbb_21337:
    mov64 r0, 1                                     r0 = 1 as i32 as i64 as u64
    ldxdw r1, [r10-0x10]                    
    jeq r1, 0, lbb_21329                            if r1 == (0 as i32 as i64 as u64) { pc += -11 }
    mov64 r2, r6                                    r2 = r6
    ldxdw r1, [r10-0x10]                    
    add64 r2, r1                                    r2 += r1   ///  r2 = r2.wrapping_add(r1)
    mov64 r0, 1                                     r0 = 1 as i32 as i64 as u64
    and64 r9, 65535                                 r9 &= 65535   ///  r9 = r9.and(65535)
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
    ja lbb_21353                                    if true { pc += 6 }
lbb_21347:
    sub64 r9, r4                                    r9 -= r4   ///  r9 = r9.wrapping_sub(r4)
    lsh64 r9, 32                                    r9 <<= 32   ///  r9 = r9.wrapping_shl(32)
    arsh64 r9, 32                                   r9 >>= 32 (signed)   ///  r9 = (r9 as i64).wrapping_shr(32)
    jsgt r3, r9, lbb_21329                          if (r3 as i64) > (r9 as i64) { pc += -22 }
    xor64 r0, 1                                     r0 ^= 1   ///  r0 = r0.xor(1)
    jeq r6, r2, lbb_21329                           if r6 == r2 { pc += -24 }
lbb_21353:
    mov64 r5, r6                                    r5 = r6
    add64 r5, 1                                     r5 += 1   ///  r5 = r5.wrapping_add(1 as i32 as i64 as u64)
    ldxb r4, [r6+0x0]                       
    mov64 r1, r4                                    r1 = r4
    lsh64 r1, 56                                    r1 <<= 56   ///  r1 = r1.wrapping_shl(56)
    arsh64 r1, 56                                   r1 >>= 56 (signed)   ///  r1 = (r1 as i64).wrapping_shr(56)
    jsgt r3, r1, lbb_21362                          if (r3 as i64) > (r1 as i64) { pc += 2 }
    mov64 r6, r5                                    r6 = r5
    ja lbb_21347                                    if true { pc += -15 }
lbb_21362:
    jne r5, r2, lbb_21370                           if r5 != r2 { pc += 7 }
    lddw r1, 0x10002cdb6 --> b"called `Option::unwrap()` on a `None` value"        r1 load str located at 4295151030
    mov64 r2, 43                                    r2 = 43 as i32 as i64 as u64
    lddw r3, 0x10002e3c0 --> b"\x00\x00\x00\x00\xfd\xcf\x02\x00%\x00\x00\x00\x00\x00\x00\x00\x1a\x00\x00…        r3 load str located at 4295156672
    call function_19306                     
    syscall [invalid]                       
lbb_21370:
    and64 r4, 127                                   r4 &= 127   ///  r4 = r4.and(127)
    lsh64 r4, 8                                     r4 <<= 8   ///  r4 = r4.wrapping_shl(8)
    ldxb r1, [r6+0x1]                       
    or64 r4, r1                                     r4 |= r1   ///  r4 = r4.or(r1)
    add64 r6, 2                                     r6 += 2   ///  r6 = r6.wrapping_add(2 as i32 as i64 as u64)
    ja lbb_21347                                    if true { pc += -29 }
lbb_21376:
    mov64 r1, r0                                    r1 = r0
    mov64 r2, r5                                    r2 = r5
    call function_20757                     
    syscall [invalid]                       
lbb_21380:
    mov64 r1, r5                                    r1 = r5
    ldxdw r2, [r10-0x18]                    
    call function_20726                     
    syscall [invalid]                       

function_21384:
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
    ldxdw r5, [r1+0x0]                      
    mov64 r1, 10                                    r1 = 10 as i32 as i64 as u64
    ja lbb_21404                                    if true { pc += 16 }
lbb_21388:
    add64 r5, r0                                    r5 += r0   ///  r5 = r5.wrapping_add(r0)
    mov64 r0, r10                                   r0 = r10
    add64 r0, -128                                  r0 += -128   ///  r0 = r0.wrapping_add(-128 as i32 as i64 as u64)
    add64 r0, r3                                    r0 += r3   ///  r0 = r0.wrapping_add(r3)
    stxb [r0+0x7f], r5                      
    add64 r3, -1                                    r3 += -1   ///  r3 = r3.wrapping_add(-1 as i32 as i64 as u64)
    mov64 r5, r4                                    r5 = r4
    rsh64 r5, 4                                     r5 >>= 4   ///  r5 = r5.wrapping_shr(4)
    jgt r4, 15, lbb_21404                           if r4 > (15 as i32 as i64 as u64) { pc += 7 }
    mov64 r1, r3                                    r1 = r3
    add64 r1, 128                                   r1 += 128   ///  r1 = r1.wrapping_add(128 as i32 as i64 as u64)
    mov64 r4, 129                                   r4 = 129 as i32 as i64 as u64
    jgt r4, r1, lbb_21411                           if r4 > r1 { pc += 10 }
    mov64 r2, 128                                   r2 = 128 as i32 as i64 as u64
    call function_20695                     
    syscall [invalid]                       
lbb_21404:
    mov64 r4, r5                                    r4 = r5
    mov64 r0, r4                                    r0 = r4
    and64 r0, 15                                    r0 &= 15   ///  r0 = r0.and(15)
    mov64 r5, 48                                    r5 = 48 as i32 as i64 as u64
    jgt r1, r0, lbb_21388                           if r1 > r0 { pc += -21 }
    mov64 r5, 87                                    r5 = 87 as i32 as i64 as u64
    ja lbb_21388                                    if true { pc += -23 }
lbb_21411:
    mov64 r1, r3                                    r1 = r3
    neg64 r1                                        r1 = -r1   ///  r1 = (r1 as i64).wrapping_neg() as u64
    stxdw [r10-0xff8], r1                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -128                                  r1 += -128   ///  r1 = r1.wrapping_add(-128 as i32 as i64 as u64)
    add64 r1, r3                                    r1 += r3   ///  r1 = r1.wrapping_add(r3)
    add64 r1, 128                                   r1 += 128   ///  r1 = r1.wrapping_add(128 as i32 as i64 as u64)
    stxdw [r10-0x1000], r1                  
    mov64 r5, r10                                   r5 = r10
    mov64 r1, r2                                    r1 = r2
    mov64 r2, 1                                     r2 = 1 as i32 as i64 as u64
    lddw r3, 0x10002ce02 --> b"0x"                  r3 load str located at 4295151106
    mov64 r4, 2                                     r4 = 2 as i32 as i64 as u64
    call function_20044                     
    exit                                    

function_21427:
    mov64 r3, 0                                     r3 = 0 as i32 as i64 as u64
    ldxdw r5, [r1+0x0]                      
    mov64 r1, 10                                    r1 = 10 as i32 as i64 as u64
    ja lbb_21447                                    if true { pc += 16 }
lbb_21431:
    add64 r5, r0                                    r5 += r0   ///  r5 = r5.wrapping_add(r0)
    mov64 r0, r10                                   r0 = r10
    add64 r0, -128                                  r0 += -128   ///  r0 = r0.wrapping_add(-128 as i32 as i64 as u64)
    add64 r0, r3                                    r0 += r3   ///  r0 = r0.wrapping_add(r3)
    stxb [r0+0x7f], r5                      
    add64 r3, -1                                    r3 += -1   ///  r3 = r3.wrapping_add(-1 as i32 as i64 as u64)
    mov64 r5, r4                                    r5 = r4
    rsh64 r5, 4                                     r5 >>= 4   ///  r5 = r5.wrapping_shr(4)
    jgt r4, 15, lbb_21447                           if r4 > (15 as i32 as i64 as u64) { pc += 7 }
    mov64 r1, r3                                    r1 = r3
    add64 r1, 128                                   r1 += 128   ///  r1 = r1.wrapping_add(128 as i32 as i64 as u64)
    mov64 r4, 129                                   r4 = 129 as i32 as i64 as u64
    jgt r4, r1, lbb_21454                           if r4 > r1 { pc += 10 }
    mov64 r2, 128                                   r2 = 128 as i32 as i64 as u64
    call function_20695                     
    syscall [invalid]                       
lbb_21447:
    mov64 r4, r5                                    r4 = r5
    mov64 r0, r4                                    r0 = r4
    and64 r0, 15                                    r0 &= 15   ///  r0 = r0.and(15)
    mov64 r5, 48                                    r5 = 48 as i32 as i64 as u64
    jgt r1, r0, lbb_21431                           if r1 > r0 { pc += -21 }
    mov64 r5, 55                                    r5 = 55 as i32 as i64 as u64
    ja lbb_21431                                    if true { pc += -23 }
lbb_21454:
    mov64 r1, r3                                    r1 = r3
    neg64 r1                                        r1 = -r1   ///  r1 = (r1 as i64).wrapping_neg() as u64
    stxdw [r10-0xff8], r1                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -128                                  r1 += -128   ///  r1 = r1.wrapping_add(-128 as i32 as i64 as u64)
    add64 r1, r3                                    r1 += r3   ///  r1 = r1.wrapping_add(r3)
    add64 r1, 128                                   r1 += 128   ///  r1 = r1.wrapping_add(128 as i32 as i64 as u64)
    stxdw [r10-0x1000], r1                  
    mov64 r5, r10                                   r5 = r10
    mov64 r1, r2                                    r1 = r2
    mov64 r2, 1                                     r2 = 1 as i32 as i64 as u64
    lddw r3, 0x10002ce02 --> b"0x"                  r3 load str located at 4295151106
    mov64 r4, 2                                     r4 = 2 as i32 as i64 as u64
    call function_20044                     
    exit                                    

function_21470:
    mov64 r3, r2                                    r3 = r2
    ldxw r2, [r3+0x30]                      
    mov64 r4, r2                                    r4 = r2
    and64 r4, 16                                    r4 &= 16   ///  r4 = r4.and(16)
    jne r4, 0, lbb_21482                            if r4 != (0 as i32 as i64 as u64) { pc += 7 }
    and64 r2, 32                                    r2 &= 32   ///  r2 = r2.and(32)
    jeq r2, 0, lbb_21478                            if r2 == (0 as i32 as i64 as u64) { pc += 1 }
    ja lbb_21486                                    if true { pc += 8 }
lbb_21478:
    ldxdw r1, [r1+0x0]                      
    mov64 r2, 1                                     r2 = 1 as i32 as i64 as u64
    call function_21550                     
    ja lbb_21549                                    if true { pc += 67 }
lbb_21482:
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
    ldxdw r5, [r1+0x0]                      
    mov64 r1, 10                                    r1 = 10 as i32 as i64 as u64
    ja lbb_21527                                    if true { pc += 41 }
lbb_21486:
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
    ldxdw r5, [r1+0x0]                      
    mov64 r1, 10                                    r1 = 10 as i32 as i64 as u64
    ja lbb_21504                                    if true { pc += 14 }
lbb_21490:
    add64 r5, r0                                    r5 += r0   ///  r5 = r5.wrapping_add(r0)
    mov64 r0, r10                                   r0 = r10
    add64 r0, -128                                  r0 += -128   ///  r0 = r0.wrapping_add(-128 as i32 as i64 as u64)
    add64 r0, r2                                    r0 += r2   ///  r0 = r0.wrapping_add(r2)
    stxb [r0+0x7f], r5                      
    add64 r2, -1                                    r2 += -1   ///  r2 = r2.wrapping_add(-1 as i32 as i64 as u64)
    mov64 r5, r4                                    r5 = r4
    rsh64 r5, 4                                     r5 >>= 4   ///  r5 = r5.wrapping_shr(4)
    jgt r4, 15, lbb_21504                           if r4 > (15 as i32 as i64 as u64) { pc += 5 }
    mov64 r1, r2                                    r1 = r2
    add64 r1, 128                                   r1 += 128   ///  r1 = r1.wrapping_add(128 as i32 as i64 as u64)
    mov64 r4, 129                                   r4 = 129 as i32 as i64 as u64
    jgt r4, r1, lbb_21534                           if r4 > r1 { pc += 31 }
    ja lbb_21524                                    if true { pc += 20 }
lbb_21504:
    mov64 r4, r5                                    r4 = r5
    mov64 r0, r4                                    r0 = r4
    and64 r0, 15                                    r0 &= 15   ///  r0 = r0.and(15)
    mov64 r5, 48                                    r5 = 48 as i32 as i64 as u64
    jgt r1, r0, lbb_21490                           if r1 > r0 { pc += -19 }
    mov64 r5, 55                                    r5 = 55 as i32 as i64 as u64
    ja lbb_21490                                    if true { pc += -21 }
lbb_21511:
    add64 r5, r0                                    r5 += r0   ///  r5 = r5.wrapping_add(r0)
    mov64 r0, r10                                   r0 = r10
    add64 r0, -128                                  r0 += -128   ///  r0 = r0.wrapping_add(-128 as i32 as i64 as u64)
    add64 r0, r2                                    r0 += r2   ///  r0 = r0.wrapping_add(r2)
    stxb [r0+0x7f], r5                      
    add64 r2, -1                                    r2 += -1   ///  r2 = r2.wrapping_add(-1 as i32 as i64 as u64)
    mov64 r5, r4                                    r5 = r4
    rsh64 r5, 4                                     r5 >>= 4   ///  r5 = r5.wrapping_shr(4)
    jgt r4, 15, lbb_21527                           if r4 > (15 as i32 as i64 as u64) { pc += 7 }
    mov64 r1, r2                                    r1 = r2
    add64 r1, 128                                   r1 += 128   ///  r1 = r1.wrapping_add(128 as i32 as i64 as u64)
    mov64 r4, 129                                   r4 = 129 as i32 as i64 as u64
    jgt r4, r1, lbb_21534                           if r4 > r1 { pc += 10 }
lbb_21524:
    mov64 r2, 128                                   r2 = 128 as i32 as i64 as u64
    call function_20695                     
    syscall [invalid]                       
lbb_21527:
    mov64 r4, r5                                    r4 = r5
    mov64 r0, r4                                    r0 = r4
    and64 r0, 15                                    r0 &= 15   ///  r0 = r0.and(15)
    mov64 r5, 48                                    r5 = 48 as i32 as i64 as u64
    jgt r1, r0, lbb_21511                           if r1 > r0 { pc += -21 }
    mov64 r5, 87                                    r5 = 87 as i32 as i64 as u64
    ja lbb_21511                                    if true { pc += -23 }
lbb_21534:
    mov64 r1, r2                                    r1 = r2
    neg64 r1                                        r1 = -r1   ///  r1 = (r1 as i64).wrapping_neg() as u64
    stxdw [r10-0xff8], r1                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -128                                  r1 += -128   ///  r1 = r1.wrapping_add(-128 as i32 as i64 as u64)
    add64 r1, r2                                    r1 += r2   ///  r1 = r1.wrapping_add(r2)
    add64 r1, 128                                   r1 += 128   ///  r1 = r1.wrapping_add(128 as i32 as i64 as u64)
    stxdw [r10-0x1000], r1                  
    mov64 r5, r10                                   r5 = r10
    mov64 r1, r3                                    r1 = r3
    mov64 r2, 1                                     r2 = 1 as i32 as i64 as u64
    lddw r3, 0x10002ce02 --> b"0x"                  r3 load str located at 4295151106
    mov64 r4, 2                                     r4 = 2 as i32 as i64 as u64
    call function_20044                     
lbb_21549:
    exit                                    

function_21550:
    mov64 r4, 39                                    r4 = 39 as i32 as i64 as u64
    mov64 r5, 10000                                 r5 = 10000 as i32 as i64 as u64
    jgt r5, r1, lbb_21585                           if r5 > r1 { pc += 32 }
    mov64 r4, 0                                     r4 = 0 as i32 as i64 as u64
lbb_21554:
    mov64 r5, r1                                    r5 = r1
    div64 r1, 10000                                 r1 /= 10000   ///  r1 = r1 / (10000 as u64)
    mov64 r6, r1                                    r6 = r1
    mul64 r6, 10000                                 r6 *= 10000   ///  r6 = r6.wrapping_mul(10000 as u64)
    mov64 r0, r5                                    r0 = r5
    sub64 r0, r6                                    r0 -= r6   ///  r0 = r0.wrapping_sub(r6)
    mov64 r6, r0                                    r6 = r0
    and64 r6, 65535                                 r6 &= 65535   ///  r6 = r6.and(65535)
    div64 r6, 100                                   r6 /= 100   ///  r6 = r6 / (100 as u64)
    mov64 r7, r6                                    r7 = r6
    mul64 r7, 100                                   r7 *= 100   ///  r7 = r7.wrapping_mul(100 as u64)
    sub64 r0, r7                                    r0 -= r7   ///  r0 = r0.wrapping_sub(r7)
    mov64 r7, r10                                   r7 = r10
    add64 r7, -39                                   r7 += -39   ///  r7 = r7.wrapping_add(-39 as i32 as i64 as u64)
    add64 r7, r4                                    r7 += r4   ///  r7 = r7.wrapping_add(r4)
    lsh64 r6, 1                                     r6 <<= 1   ///  r6 = r6.wrapping_shl(1)
    lddw r8, 0x10002ce04 --> b"00010203040506070809101112131415161718192021222324"        r8 load str located at 4295151108
    add64 r8, r6                                    r8 += r6   ///  r8 = r8.wrapping_add(r6)
    ldxh r6, [r8+0x0]                       
    stxh [r7+0x23], r6                      
    lsh64 r0, 1                                     r0 <<= 1   ///  r0 = r0.wrapping_shl(1)
    and64 r0, 65534                                 r0 &= 65534   ///  r0 = r0.and(65534)
    lddw r6, 0x10002ce04 --> b"00010203040506070809101112131415161718192021222324"        r6 load str located at 4295151108
    add64 r6, r0                                    r6 += r0   ///  r6 = r6.wrapping_add(r0)
    ldxh r0, [r6+0x0]                       
    stxh [r7+0x25], r0                      
    add64 r4, -4                                    r4 += -4   ///  r4 = r4.wrapping_add(-4 as i32 as i64 as u64)
    jgt r5, 99999999, lbb_21554                     if r5 > (99999999 as i32 as i64 as u64) { pc += -30 }
    add64 r4, 39                                    r4 += 39   ///  r4 = r4.wrapping_add(39 as i32 as i64 as u64)
lbb_21585:
    jgt r1, 99, lbb_21596                           if r1 > (99 as i32 as i64 as u64) { pc += 10 }
lbb_21586:
    mov64 r5, 10                                    r5 = 10 as i32 as i64 as u64
    jgt r5, r1, lbb_21589                           if r5 > r1 { pc += 1 }
    ja lbb_21615                                    if true { pc += 26 }
lbb_21589:
    add64 r4, -1                                    r4 += -1   ///  r4 = r4.wrapping_add(-1 as i32 as i64 as u64)
    mov64 r5, r10                                   r5 = r10
    add64 r5, -39                                   r5 += -39   ///  r5 = r5.wrapping_add(-39 as i32 as i64 as u64)
    add64 r5, r4                                    r5 += r4   ///  r5 = r5.wrapping_add(r4)
    add64 r1, 48                                    r1 += 48   ///  r1 = r1.wrapping_add(48 as i32 as i64 as u64)
    stxb [r5+0x0], r1                       
    ja lbb_21625                                    if true { pc += 29 }
lbb_21596:
    mov64 r5, r1                                    r5 = r1
    and64 r5, 65535                                 r5 &= 65535   ///  r5 = r5.and(65535)
    div64 r5, 100                                   r5 /= 100   ///  r5 = r5 / (100 as u64)
    mov64 r0, r5                                    r0 = r5
    mul64 r0, 100                                   r0 *= 100   ///  r0 = r0.wrapping_mul(100 as u64)
    sub64 r1, r0                                    r1 -= r0   ///  r1 = r1.wrapping_sub(r0)
    lsh64 r1, 1                                     r1 <<= 1   ///  r1 = r1.wrapping_shl(1)
    and64 r1, 65534                                 r1 &= 65534   ///  r1 = r1.and(65534)
    lddw r0, 0x10002ce04 --> b"00010203040506070809101112131415161718192021222324"        r0 load str located at 4295151108
    add64 r0, r1                                    r0 += r1   ///  r0 = r0.wrapping_add(r1)
    add64 r4, -2                                    r4 += -2   ///  r4 = r4.wrapping_add(-2 as i32 as i64 as u64)
    mov64 r1, r10                                   r1 = r10
    add64 r1, -39                                   r1 += -39   ///  r1 = r1.wrapping_add(-39 as i32 as i64 as u64)
    add64 r1, r4                                    r1 += r4   ///  r1 = r1.wrapping_add(r4)
    ldxh r0, [r0+0x0]                       
    stxh [r1+0x0], r0                       
    mov64 r1, r5                                    r1 = r5
    ja lbb_21586                                    if true { pc += -29 }
lbb_21615:
    lsh64 r1, 1                                     r1 <<= 1   ///  r1 = r1.wrapping_shl(1)
    lddw r5, 0x10002ce04 --> b"00010203040506070809101112131415161718192021222324"        r5 load str located at 4295151108
    add64 r5, r1                                    r5 += r1   ///  r5 = r5.wrapping_add(r1)
    add64 r4, -2                                    r4 += -2   ///  r4 = r4.wrapping_add(-2 as i32 as i64 as u64)
    mov64 r1, r10                                   r1 = r10
    add64 r1, -39                                   r1 += -39   ///  r1 = r1.wrapping_add(-39 as i32 as i64 as u64)
    add64 r1, r4                                    r1 += r4   ///  r1 = r1.wrapping_add(r4)
    ldxh r5, [r5+0x0]                       
    stxh [r1+0x0], r5                       
lbb_21625:
    mov64 r1, r10                                   r1 = r10
    add64 r1, -39                                   r1 += -39   ///  r1 = r1.wrapping_add(-39 as i32 as i64 as u64)
    add64 r1, r4                                    r1 += r4   ///  r1 = r1.wrapping_add(r4)
    stxdw [r10-0x1000], r1                  
    mov64 r1, 39                                    r1 = 39 as i32 as i64 as u64
    sub64 r1, r4                                    r1 -= r4   ///  r1 = r1.wrapping_sub(r4)
    stxdw [r10-0xff8], r1                   
    mov64 r5, r10                                   r5 = r10
    mov64 r1, r3                                    r1 = r3
    lddw r3, 0x10002cd80 --> b")..BorrowErrorBorrowMutError but the index is     "        r3 load str located at 4295150976
    mov64 r4, 0                                     r4 = 0 as i32 as i64 as u64
    call function_20044                     
    exit                                    

function_21639:
    mov64 r3, r2                                    r3 = r2
    ldxw r1, [r1+0x0]                       
    mov64 r2, 1                                     r2 = 1 as i32 as i64 as u64
    call function_21550                     
    exit                                    

function_21644:
    mov64 r3, r2                                    r3 = r2
    ldxdw r1, [r1+0x0]                      
    mov64 r2, 1                                     r2 = 1 as i32 as i64 as u64
    call function_21550                     
    exit                                    

function_21649:
    ldxdw r1, [r2+0x20]                     
    ldxdw r2, [r2+0x28]                     
    ldxdw r4, [r2+0x18]                     
    lddw r2, 0x10002d5b3 --> b"Error"               r2 load str located at 4295153075
    mov64 r3, 5                                     r3 = 5 as i32 as i64 as u64
    callx r4                                
    exit                                    

function_21657:
    ldxdw r3, [r1+0x0]                      
    ldxdw r1, [r1+0x8]                      
    ldxdw r4, [r1+0x18]                     
    mov64 r1, r3                                    r1 = r3
    callx r4                                
    exit                                    

function_21663:
    mov64 r4, r2                                    r4 = r2
    ldxdw r1, [r1+0x0]                      
    ldxdw r3, [r1+0x8]                      
    ldxdw r2, [r1+0x0]                      
    mov64 r1, r4                                    r1 = r4
    call function_20308                     
    exit                                    

function_21670:
    ldxdw r6, [r2+0x28]                     
    ldxdw r7, [r2+0x20]                     
    ldxdw r2, [r1+0x0]                      
    mov64 r8, r10                                   r8 = r10
    add64 r8, -48                                   r8 += -48   ///  r8 = r8.wrapping_add(-48 as i32 as i64 as u64)
    mov64 r1, r8                                    r1 = r8
    mov64 r3, 48                                    r3 = 48 as i32 as i64 as u64
    call function_21797                     
    mov64 r1, r7                                    r1 = r7
    mov64 r2, r6                                    r2 = r6
    mov64 r3, r8                                    r3 = r8
    call function_19901                     
    exit                                    

function_21683:
    mov64 r4, r2                                    r4 = r2
    ldxdw r3, [r1+0x8]                      
    ldxdw r2, [r1+0x0]                      
    mov64 r1, r4                                    r1 = r4
    call function_20308                     
    exit                                    

function_21689:
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
    mov64 r3, 32                                    r3 = 32 as i32 as i64 as u64
    mov64 r4, r1                                    r4 = r1
    lsh64 r4, 11                                    r4 <<= 11   ///  r4 = r4.wrapping_shl(11)
    mov64 r5, 32                                    r5 = 32 as i32 as i64 as u64
    ja lbb_21701                                    if true { pc += 6 }
lbb_21695:
    add64 r3, 1                                     r3 += 1   ///  r3 = r3.wrapping_add(1 as i32 as i64 as u64)
    mov64 r2, r3                                    r2 = r3
    mov64 r3, r5                                    r3 = r5
lbb_21698:
    sub64 r3, r2                                    r3 -= r2   ///  r3 = r3.wrapping_sub(r2)
    jgt r5, r2, lbb_21701                           if r5 > r2 { pc += 1 }
    ja lbb_21721                                    if true { pc += 20 }
lbb_21701:
    rsh64 r3, 1                                     r3 >>= 1   ///  r3 = r3.wrapping_shr(1)
    add64 r3, r2                                    r3 += r2   ///  r3 = r3.wrapping_add(r2)
    mov64 r0, r3                                    r0 = r3
    lsh64 r0, 2                                     r0 <<= 2   ///  r0 = r0.wrapping_shl(2)
    lddw r6, 0x10002d5b8 --> b"\x00\x03\x00\x00\x83\x04 \x00\x91\x05`\x00]\x13\xa0\x00\x12\x17 \x1f\x0c …        r6 load str located at 4295153080
    add64 r6, r0                                    r6 += r0   ///  r6 = r6.wrapping_add(r0)
    ldxw r0, [r6+0x0]                       
    lsh64 r0, 11                                    r0 <<= 11   ///  r0 = r0.wrapping_shl(11)
    lsh64 r0, 32                                    r0 <<= 32   ///  r0 = r0.wrapping_shl(32)
    mov64 r6, r4                                    r6 = r4
    lsh64 r6, 32                                    r6 <<= 32   ///  r6 = r6.wrapping_shl(32)
    rsh64 r0, 32                                    r0 >>= 32   ///  r0 = r0.wrapping_shr(32)
    rsh64 r6, 32                                    r6 >>= 32   ///  r6 = r6.wrapping_shr(32)
    jgt r6, r0, lbb_21695                           if r6 > r0 { pc += -21 }
    mov64 r5, r3                                    r5 = r3
    jeq r0, r6, lbb_21719                           if r0 == r6 { pc += 1 }
    ja lbb_21698                                    if true { pc += -21 }
lbb_21719:
    add64 r3, 1                                     r3 += 1   ///  r3 = r3.wrapping_add(1 as i32 as i64 as u64)
    mov64 r2, r3                                    r2 = r3
lbb_21721:
    jgt r2, 31, lbb_21791                           if r2 > (31 as i32 as i64 as u64) { pc += 69 }
    mov64 r5, r2                                    r5 = r2
    lsh64 r5, 2                                     r5 <<= 2   ///  r5 = r5.wrapping_shl(2)
    lddw r0, 0x10002d5b8 --> b"\x00\x03\x00\x00\x83\x04 \x00\x91\x05`\x00]\x13\xa0\x00\x12\x17 \x1f\x0c …        r0 load str located at 4295153080
    mov64 r4, 707                                   r4 = 707 as i32 as i64 as u64
    jeq r2, 31, lbb_21732                           if r2 == (31 as i32 as i64 as u64) { pc += 4 }
    mov64 r3, r5                                    r3 = r5
    add64 r3, r0                                    r3 += r0   ///  r3 = r3.wrapping_add(r0)
    ldxw r4, [r3+0x4]                       
    rsh64 r4, 21                                    r4 >>= 21   ///  r4 = r4.wrapping_shr(21)
lbb_21732:
    mov64 r3, r2                                    r3 = r2
    add64 r3, -1                                    r3 += -1   ///  r3 = r3.wrapping_add(-1 as i32 as i64 as u64)
    mov64 r6, 0                                     r6 = 0 as i32 as i64 as u64
    mov64 r7, 1                                     r7 = 1 as i32 as i64 as u64
    jgt r3, r2, lbb_21738                           if r3 > r2 { pc += 1 }
    mov64 r7, 0                                     r7 = 0 as i32 as i64 as u64
lbb_21738:
    and64 r7, 1                                     r7 &= 1   ///  r7 = r7.and(1)
    jne r7, 0, lbb_21754                            if r7 != (0 as i32 as i64 as u64) { pc += 14 }
    mov64 r2, 32                                    r2 = 32 as i32 as i64 as u64
    jgt r2, r3, lbb_21748                           if r2 > r3 { pc += 6 }
    mov64 r1, r3                                    r1 = r3
    mov64 r2, 32                                    r2 = 32 as i32 as i64 as u64
    lddw r3, 0x10002e408 --> b"\x00\x00\x00\x00\x8b\xd5\x02\x00(\x00\x00\x00\x00\x00\x00\x00R\x00\x00\x0…        r3 load str located at 4295156744
    call function_19324                     
    syscall [invalid]                       
lbb_21748:
    lsh64 r3, 2                                     r3 <<= 2   ///  r3 = r3.wrapping_shl(2)
    lddw r2, 0x10002d5b8 --> b"\x00\x03\x00\x00\x83\x04 \x00\x91\x05`\x00]\x13\xa0\x00\x12\x17 \x1f\x0c …        r2 load str located at 4295153080
    add64 r2, r3                                    r2 += r3   ///  r2 = r2.wrapping_add(r3)
    ldxw r6, [r2+0x0]                       
    and64 r6, 2097151                               r6 &= 2097151   ///  r6 = r6.and(2097151)
lbb_21754:
    add64 r0, r5                                    r0 += r5   ///  r0 = r0.wrapping_add(r5)
    ldxw r0, [r0+0x0]                       
    rsh64 r0, 21                                    r0 >>= 21   ///  r0 = r0.wrapping_shr(21)
    mov64 r2, r0                                    r2 = r0
    xor64 r2, -1                                    r2 ^= -1   ///  r2 = r2.xor(-1)
    add64 r4, r2                                    r4 += r2   ///  r4 = r4.wrapping_add(r2)
    jeq r4, 0, lbb_21783                            if r4 == (0 as i32 as i64 as u64) { pc += 22 }
    sub64 r1, r6                                    r1 -= r6   ///  r1 = r1.wrapping_sub(r6)
    lddw r3, 0x10002d638 --> b"\x00p\x00\x07\x00-\x01\x01\x01\x02\x01\x02\x01\x01H\x0b0\x15\x10\x01e\x07…        r3 load str located at 4295153208
    add64 r3, r0                                    r3 += r0   ///  r3 = r3.wrapping_add(r0)
    mov64 r5, 0                                     r5 = 0 as i32 as i64 as u64
    lsh64 r1, 32                                    r1 <<= 32   ///  r1 = r1.wrapping_shl(32)
    rsh64 r1, 32                                    r1 >>= 32   ///  r1 = r1.wrapping_shr(32)
    mov64 r6, 0                                     r6 = 0 as i32 as i64 as u64
lbb_21769:
    mov64 r2, r0                                    r2 = r0
    add64 r2, r6                                    r2 += r6   ///  r2 = r2.wrapping_add(r6)
    jgt r2, 706, lbb_21785                          if r2 > (706 as i32 as i64 as u64) { pc += 13 }
    mov64 r2, r3                                    r2 = r3
    add64 r2, r6                                    r2 += r6   ///  r2 = r2.wrapping_add(r6)
    ldxb r2, [r2+0x0]                       
    add64 r5, r2                                    r5 += r2   ///  r5 = r5.wrapping_add(r2)
    mov64 r2, r5                                    r2 = r5
    lsh64 r2, 32                                    r2 <<= 32   ///  r2 = r2.wrapping_shl(32)
    rsh64 r2, 32                                    r2 >>= 32   ///  r2 = r2.wrapping_shr(32)
    jgt r2, r1, lbb_21782                           if r2 > r1 { pc += 2 }
    add64 r6, 1                                     r6 += 1   ///  r6 = r6.wrapping_add(1 as i32 as i64 as u64)
    jgt r4, r6, lbb_21769                           if r4 > r6 { pc += -13 }
lbb_21782:
    add64 r0, r6                                    r0 += r6   ///  r0 = r0.wrapping_add(r6)
lbb_21783:
    and64 r0, 1                                     r0 &= 1   ///  r0 = r0.and(1)
    exit                                    
lbb_21785:
    mov64 r1, r2                                    r1 = r2
    mov64 r2, 707                                   r2 = 707 as i32 as i64 as u64
    lddw r3, 0x10002e3f0 --> b"\x00\x00\x00\x00\x8b\xd5\x02\x00(\x00\x00\x00\x00\x00\x00\x00W\x00\x00\x0…        r3 load str located at 4295156720
    call function_19324                     
    syscall [invalid]                       
lbb_21791:
    mov64 r1, r2                                    r1 = r2
    mov64 r2, 32                                    r2 = 32 as i32 as i64 as u64
    lddw r3, 0x10002e3d8 --> b"\x00\x00\x00\x00\x8b\xd5\x02\x00(\x00\x00\x00\x00\x00\x00\x00K\x00\x00\x0…        r3 load str located at 4295156696
    call function_19324                     
    syscall [invalid]                       

function_21797:
    mov64 r6, r1                                    r6 = r1
    mov64 r4, r3                                    r4 = r3
    rsh64 r4, 3                                     r4 >>= 3   ///  r4 = r4.wrapping_shr(3)
    mov64 r1, r4                                    r1 = r4
    mul64 r1, -7                                    r1 *= -7   ///  r1 = r1.wrapping_mul(-7 as u64)
    add64 r1, r3                                    r1 += r3   ///  r1 = r1.wrapping_add(r3)
    jgt r1, 15, lbb_21828                           if r1 > (15 as i32 as i64 as u64) { pc += 24 }
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    mov64 r5, 8                                     r5 = 8 as i32 as i64 as u64
    jgt r5, r3, lbb_21818                           if r5 > r3 { pc += 11 }
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    mov64 r5, 0                                     r5 = 0 as i32 as i64 as u64
lbb_21809:
    mov64 r0, r6                                    r0 = r6
    add64 r0, r1                                    r0 += r1   ///  r0 = r0.wrapping_add(r1)
    mov64 r7, r2                                    r7 = r2
    add64 r7, r1                                    r7 += r1   ///  r7 = r7.wrapping_add(r1)
    ldxdw r7, [r7+0x0]                      
    stxdw [r0+0x0], r7                      
    add64 r1, 8                                     r1 += 8   ///  r1 = r1.wrapping_add(8 as i32 as i64 as u64)
    add64 r5, 1                                     r5 += 1   ///  r5 = r5.wrapping_add(1 as i32 as i64 as u64)
    jgt r4, r5, lbb_21809                           if r4 > r5 { pc += -9 }
lbb_21818:
    jsge r1, r3, lbb_21830                          if (r1 as i64) >= (r3 as i64) { pc += 11 }
lbb_21819:
    mov64 r4, r6                                    r4 = r6
    add64 r4, r1                                    r4 += r1   ///  r4 = r4.wrapping_add(r1)
    mov64 r5, r2                                    r5 = r2
    add64 r5, r1                                    r5 += r1   ///  r5 = r5.wrapping_add(r1)
    ldxb r5, [r5+0x0]                       
    stxb [r4+0x0], r5                       
    add64 r1, 1                                     r1 += 1   ///  r1 = r1.wrapping_add(1 as i32 as i64 as u64)
    jsgt r3, r1, lbb_21819                          if (r3 as i64) > (r1 as i64) { pc += -8 }
    ja lbb_21830                                    if true { pc += 2 }
lbb_21828:
    mov64 r1, r6                                    r1 = r6
    syscall [invalid]                       
lbb_21830:
    mov64 r0, r6                                    r0 = r6
    exit                                    

function_21832:
    mov64 r6, r1                                    r6 = r1
    mov64 r4, r3                                    r4 = r3
    rsh64 r4, 3                                     r4 >>= 3   ///  r4 = r4.wrapping_shr(3)
    mov64 r1, r4                                    r1 = r4
    mul64 r1, -7                                    r1 *= -7   ///  r1 = r1.wrapping_mul(-7 as u64)
    add64 r1, r3                                    r1 += r3   ///  r1 = r1.wrapping_add(r3)
    jgt r1, 15, lbb_21862                           if r1 > (15 as i32 as i64 as u64) { pc += 23 }
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    mov64 r5, 8                                     r5 = 8 as i32 as i64 as u64
    jgt r5, r3, lbb_21855                           if r5 > r3 { pc += 13 }
    mov64 r5, r2                                    r5 = r2
    and64 r5, 255                                   r5 &= 255   ///  r5 = r5.and(255)
    lddw r1, 0x101010101010101                      r1 load str located at 72340172838076673
    mul64 r5, r1                                    r5 *= r1   ///  r5 = r5.wrapping_mul(r1)
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    mov64 r0, 0                                     r0 = 0 as i32 as i64 as u64
lbb_21849:
    mov64 r7, r6                                    r7 = r6
    add64 r7, r1                                    r7 += r1   ///  r7 = r7.wrapping_add(r1)
    stxdw [r7+0x0], r5                      
    add64 r1, 8                                     r1 += 8   ///  r1 = r1.wrapping_add(8 as i32 as i64 as u64)
    add64 r0, 1                                     r0 += 1   ///  r0 = r0.wrapping_add(1 as i32 as i64 as u64)
    jgt r4, r0, lbb_21849                           if r4 > r0 { pc += -6 }
lbb_21855:
    jsge r1, r3, lbb_21865                          if (r1 as i64) >= (r3 as i64) { pc += 9 }
lbb_21856:
    mov64 r4, r6                                    r4 = r6
    add64 r4, r1                                    r4 += r1   ///  r4 = r4.wrapping_add(r1)
    stxb [r4+0x0], r2                       
    add64 r1, 1                                     r1 += 1   ///  r1 = r1.wrapping_add(1 as i32 as i64 as u64)
    jsgt r3, r1, lbb_21856                          if (r3 as i64) > (r1 as i64) { pc += -5 }
    ja lbb_21865                                    if true { pc += 3 }
lbb_21862:
    and64 r2, 255                                   r2 &= 255   ///  r2 = r2.and(255)
    mov64 r1, r6                                    r1 = r6
    syscall [invalid]                       
lbb_21865:
    mov64 r0, r6                                    r0 = r6
    exit                                    

function_21867:
    mov64 r5, r3                                    r5 = r3
    rsh64 r5, 3                                     r5 >>= 3   ///  r5 = r5.wrapping_shr(3)
    mov64 r4, r5                                    r4 = r5
    mul64 r4, -7                                    r4 *= -7   ///  r4 = r4.wrapping_mul(-7 as u64)
    add64 r4, r3                                    r4 += r3   ///  r4 = r4.wrapping_add(r3)
    jgt r4, 15, lbb_21902                           if r4 > (15 as i32 as i64 as u64) { pc += 29 }
    mov64 r0, 0                                     r0 = 0 as i32 as i64 as u64
    mov64 r6, 8                                     r6 = 8 as i32 as i64 as u64
    mov64 r4, 0                                     r4 = 0 as i32 as i64 as u64
    jgt r6, r3, lbb_21888                           if r6 > r3 { pc += 11 }
    mov64 r4, 0                                     r4 = 0 as i32 as i64 as u64
    mov64 r6, r1                                    r6 = r1
    mov64 r7, r2                                    r7 = r2
lbb_21880:
    ldxdw r8, [r7+0x0]                      
    ldxdw r9, [r6+0x0]                      
    jne r9, r8, lbb_21887                           if r9 != r8 { pc += 4 }
    add64 r6, 8                                     r6 += 8   ///  r6 = r6.wrapping_add(8 as i32 as i64 as u64)
    add64 r7, 8                                     r7 += 8   ///  r7 = r7.wrapping_add(8 as i32 as i64 as u64)
    add64 r4, 1                                     r4 += 1   ///  r4 = r4.wrapping_add(1 as i32 as i64 as u64)
    jgt r5, r4, lbb_21880                           if r5 > r4 { pc += -7 }
lbb_21887:
    lsh64 r4, 3                                     r4 <<= 3   ///  r4 = r4.wrapping_shl(3)
lbb_21888:
    jsge r4, r3, lbb_21908                          if (r4 as i64) >= (r3 as i64) { pc += 19 }
    ja lbb_21892                                    if true { pc += 2 }
lbb_21890:
    add64 r4, 1                                     r4 += 1   ///  r4 = r4.wrapping_add(1 as i32 as i64 as u64)
    jsge r4, r3, lbb_21908                          if (r4 as i64) >= (r3 as i64) { pc += 16 }
lbb_21892:
    mov64 r6, r1                                    r6 = r1
    add64 r6, r4                                    r6 += r4   ///  r6 = r6.wrapping_add(r4)
    mov64 r5, r2                                    r5 = r2
    add64 r5, r4                                    r5 += r4   ///  r5 = r5.wrapping_add(r4)
    ldxb r5, [r5+0x0]                       
    ldxb r6, [r6+0x0]                       
    jeq r6, r5, lbb_21890                           if r6 == r5 { pc += -9 }
    sub64 r6, r5                                    r6 -= r5   ///  r6 = r6.wrapping_sub(r5)
    mov64 r0, r6                                    r0 = r6
    ja lbb_21908                                    if true { pc += 6 }
lbb_21902:
    mov64 r4, 0                                     r4 = 0 as i32 as i64 as u64
    stxw [r10-0x4], r4                      
    mov64 r4, r10                                   r4 = r10
    add64 r4, -4                                    r4 += -4   ///  r4 = r4.wrapping_add(-4 as i32 as i64 as u64)
    syscall [invalid]                       
    ldxw r0, [r10-0x4]                      
lbb_21908:
    lsh64 r0, 32                                    r0 <<= 32   ///  r0 = r0.wrapping_shl(32)
    arsh64 r0, 32                                   r0 >>= 32 (signed)   ///  r0 = (r0 as i64).wrapping_shr(32)
    exit                                    

function_21911:
    mul64 r3, r4                                    r3 *= r4   ///  r3 = r3.wrapping_mul(r4)
    mul64 r5, r2                                    r5 *= r2   ///  r5 = r5.wrapping_mul(r2)
    add64 r5, r3                                    r5 += r3   ///  r5 = r5.wrapping_add(r3)
    mov64 r0, r2                                    r0 = r2
    rsh64 r0, 32                                    r0 >>= 32   ///  r0 = r0.wrapping_shr(32)
    mov64 r3, r4                                    r3 = r4
    rsh64 r3, 32                                    r3 >>= 32   ///  r3 = r3.wrapping_shr(32)
    mov64 r6, r3                                    r6 = r3
    mul64 r6, r0                                    r6 *= r0   ///  r6 = r6.wrapping_mul(r0)
    add64 r5, r6                                    r5 += r6   ///  r5 = r5.wrapping_add(r6)
    lsh64 r4, 32                                    r4 <<= 32   ///  r4 = r4.wrapping_shl(32)
    rsh64 r4, 32                                    r4 >>= 32   ///  r4 = r4.wrapping_shr(32)
    mov64 r6, r4                                    r6 = r4
    mul64 r6, r0                                    r6 *= r0   ///  r6 = r6.wrapping_mul(r0)
    lsh64 r2, 32                                    r2 <<= 32   ///  r2 = r2.wrapping_shl(32)
    rsh64 r2, 32                                    r2 >>= 32   ///  r2 = r2.wrapping_shr(32)
    mul64 r4, r2                                    r4 *= r2   ///  r4 = r4.wrapping_mul(r2)
    mov64 r0, r4                                    r0 = r4
    rsh64 r0, 32                                    r0 >>= 32   ///  r0 = r0.wrapping_shr(32)
    add64 r0, r6                                    r0 += r6   ///  r0 = r0.wrapping_add(r6)
    mov64 r6, r0                                    r6 = r0
    rsh64 r6, 32                                    r6 >>= 32   ///  r6 = r6.wrapping_shr(32)
    add64 r5, r6                                    r5 += r6   ///  r5 = r5.wrapping_add(r6)
    mul64 r3, r2                                    r3 *= r2   ///  r3 = r3.wrapping_mul(r2)
    lsh64 r0, 32                                    r0 <<= 32   ///  r0 = r0.wrapping_shl(32)
    rsh64 r0, 32                                    r0 >>= 32   ///  r0 = r0.wrapping_shr(32)
    add64 r0, r3                                    r0 += r3   ///  r0 = r0.wrapping_add(r3)
    mov64 r2, r0                                    r2 = r0
    rsh64 r2, 32                                    r2 >>= 32   ///  r2 = r2.wrapping_shr(32)
    add64 r5, r2                                    r5 += r2   ///  r5 = r5.wrapping_add(r2)
    stxdw [r1+0x8], r5                      
    lsh64 r0, 32                                    r0 <<= 32   ///  r0 = r0.wrapping_shl(32)
    lsh64 r4, 32                                    r4 <<= 32   ///  r4 = r4.wrapping_shl(32)
    rsh64 r4, 32                                    r4 >>= 32   ///  r4 = r4.wrapping_shr(32)
    or64 r0, r4                                     r0 |= r4   ///  r0 = r0.or(r4)
    stxdw [r1+0x0], r0                      
    exit                                    

function_21948:
    mov64 r6, r1                                    r6 = r1
    stxdw [r10-0x1000], r5                  
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    stxdw [r10-0xff8], r1                   
    mov64 r1, r10                                   r1 = r10
    add64 r1, -16                                   r1 += -16   ///  r1 = r1.wrapping_add(-16 as i32 as i64 as u64)
    mov64 r5, r10                                   r5 = r10
    call function_21961                     
    ldxdw r1, [r10-0x10]                    
    ldxdw r2, [r10-0x8]                     
    stxdw [r6+0x8], r2                      
    stxdw [r6+0x0], r1                      
    exit                                    

function_21961:
    mov64 r7, r2                                    r7 = r2
    mov64 r6, r1                                    r6 = r1
    ldxdw r0, [r5-0x1000]                   
    ldxdw r8, [r5-0xff8]                    
    stxdw [r10-0x18], r3                    
    jne r3, 0, lbb_21978                            if r3 != (0 as i32 as i64 as u64) { pc += 11 }
    jne r0, 0, lbb_22141                            if r0 != (0 as i32 as i64 as u64) { pc += 173 }
    mov64 r9, r7                                    r9 = r7
    div64 r9, r4                                    r9 /= r4   ///  r9 = r9 / r4
    jeq r8, 0, lbb_21991                            if r8 == (0 as i32 as i64 as u64) { pc += 20 }
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    stxdw [r8+0x8], r1                      
    mov64 r1, r9                                    r1 = r9
    mul64 r1, r4                                    r1 *= r4   ///  r1 = r1.wrapping_mul(r4)
    sub64 r7, r1                                    r7 -= r1   ///  r7 = r7.wrapping_sub(r1)
    stxdw [r8+0x0], r7                      
    ja lbb_21991                                    if true { pc += 13 }
lbb_21978:
    jne r4, 0, lbb_21993                            if r4 != (0 as i32 as i64 as u64) { pc += 14 }
    jeq r0, 0, lbb_22503                            if r0 == (0 as i32 as i64 as u64) { pc += 523 }
    jne r7, 0, lbb_22174                            if r7 != (0 as i32 as i64 as u64) { pc += 193 }
    ldxdw r2, [r10-0x18]                    
    mov64 r9, r2                                    r9 = r2
    div64 r9, r0                                    r9 /= r0   ///  r9 = r9 / r0
    jeq r8, 0, lbb_21991                            if r8 == (0 as i32 as i64 as u64) { pc += 6 }
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    stxdw [r8+0x0], r1                      
    mov64 r1, r9                                    r1 = r9
    mul64 r1, r0                                    r1 *= r0   ///  r1 = r1.wrapping_mul(r0)
    sub64 r2, r1                                    r2 -= r1   ///  r2 = r2.wrapping_sub(r1)
    stxdw [r8+0x8], r2                      
lbb_21991:
    mov64 r5, 0                                     r5 = 0 as i32 as i64 as u64
    ja lbb_22503                                    if true { pc += 510 }
lbb_21993:
    jne r0, 0, lbb_22047                            if r0 != (0 as i32 as i64 as u64) { pc += 53 }
    mov64 r1, r4                                    r1 = r4
    add64 r1, -1                                    r1 += -1   ///  r1 = r1.wrapping_add(-1 as i32 as i64 as u64)
    mov64 r2, r4                                    r2 = r4
    and64 r2, r1                                    r2 &= r1   ///  r2 = r2.and(r1)
    jne r2, 0, lbb_22214                            if r2 != (0 as i32 as i64 as u64) { pc += 215 }
    jeq r8, 0, lbb_22004                            if r8 == (0 as i32 as i64 as u64) { pc += 4 }
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
    stxdw [r8+0x8], r2                      
    and64 r1, r7                                    r1 &= r7   ///  r1 = r1.and(r7)
    stxdw [r8+0x0], r1                      
lbb_22004:
    mov64 r9, r7                                    r9 = r7
    ldxdw r5, [r10-0x18]                    
    jeq r4, 1, lbb_22503                            if r4 == (1 as i32 as i64 as u64) { pc += 496 }
    mov64 r1, r4                                    r1 = r4
    add64 r1, -1                                    r1 += -1   ///  r1 = r1.wrapping_add(-1 as i32 as i64 as u64)
    xor64 r4, -1                                    r4 ^= -1   ///  r4 = r4.xor(-1)
    and64 r4, r1                                    r4 &= r1   ///  r4 = r4.and(r1)
    mov64 r1, r4                                    r1 = r4
    rsh64 r1, 1                                     r1 >>= 1   ///  r1 = r1.wrapping_shr(1)
    lddw r2, 0x5555555555555555                     r2 load str located at 6148914691236517205
    and64 r1, r2                                    r1 &= r2   ///  r1 = r1.and(r2)
    sub64 r4, r1                                    r4 -= r1   ///  r4 = r4.wrapping_sub(r1)
    lddw r2, 0x3333333333333333                     r2 load str located at 3689348814741910323
    mov64 r1, r4                                    r1 = r4
    and64 r1, r2                                    r1 &= r2   ///  r1 = r1.and(r2)
    rsh64 r4, 2                                     r4 >>= 2   ///  r4 = r4.wrapping_shr(2)
    and64 r4, r2                                    r4 &= r2   ///  r4 = r4.and(r2)
    add64 r1, r4                                    r1 += r4   ///  r1 = r1.wrapping_add(r4)
    mov64 r2, r1                                    r2 = r1
    rsh64 r2, 4                                     r2 >>= 4   ///  r2 = r2.wrapping_shr(4)
    add64 r1, r2                                    r1 += r2   ///  r1 = r1.wrapping_add(r2)
    lddw r2, 0xf0f0f0f0f0f0f0f                      r2 load str located at 1085102592571150095
    and64 r1, r2                                    r1 &= r2   ///  r1 = r1.and(r2)
    lddw r2, 0x101010101010101                      r2 load str located at 72340172838076673
    mul64 r1, r2                                    r1 *= r2   ///  r1 = r1.wrapping_mul(r2)
    rsh64 r1, 56                                    r1 >>= 56   ///  r1 = r1.wrapping_shr(56)
    mov64 r2, r1                                    r2 = r1
    and64 r2, 63                                    r2 &= 63   ///  r2 = r2.and(63)
    rsh64 r7, r2                                    r7 >>= r2   ///  r7 = r7.wrapping_shr(r2 as u32)
    mov64 r2, r1                                    r2 = r1
    xor64 r2, -1                                    r2 ^= -1   ///  r2 = r2.xor(-1)
    and64 r2, 63                                    r2 &= 63   ///  r2 = r2.and(63)
    ldxdw r5, [r10-0x18]                    
    mov64 r9, r5                                    r9 = r5
    lsh64 r9, 1                                     r9 <<= 1   ///  r9 = r9.wrapping_shl(1)
    lsh64 r9, r2                                    r9 <<= r2   ///  r9 = r9.wrapping_shl(r2 as u32)
    or64 r9, r7                                     r9 |= r7   ///  r9 = r9.or(r7)
    rsh64 r5, r1                                    r5 >>= r1   ///  r5 = r5.wrapping_shr(r1 as u32)
    ja lbb_22503                                    if true { pc += 456 }
lbb_22047:
    stxdw [r10-0x8], r4                     
    stxdw [r10-0x28], r8                    
    mov64 r1, r0                                    r1 = r0
    rsh64 r1, 1                                     r1 >>= 1   ///  r1 = r1.wrapping_shr(1)
    stxdw [r10-0x10], r0                    
    or64 r0, r1                                     r0 |= r1   ///  r0 = r0.or(r1)
    mov64 r1, r0                                    r1 = r0
    rsh64 r1, 2                                     r1 >>= 2   ///  r1 = r1.wrapping_shr(2)
    or64 r0, r1                                     r0 |= r1   ///  r0 = r0.or(r1)
    mov64 r1, r0                                    r1 = r0
    rsh64 r1, 4                                     r1 >>= 4   ///  r1 = r1.wrapping_shr(4)
    or64 r0, r1                                     r0 |= r1   ///  r0 = r0.or(r1)
    mov64 r1, r0                                    r1 = r0
    rsh64 r1, 8                                     r1 >>= 8   ///  r1 = r1.wrapping_shr(8)
    or64 r0, r1                                     r0 |= r1   ///  r0 = r0.or(r1)
    ldxdw r4, [r10-0x18]                    
    mov64 r1, r4                                    r1 = r4
    rsh64 r1, 1                                     r1 >>= 1   ///  r1 = r1.wrapping_shr(1)
    mov64 r3, r4                                    r3 = r4
    or64 r3, r1                                     r3 |= r1   ///  r3 = r3.or(r1)
    mov64 r1, r0                                    r1 = r0
    rsh64 r1, 16                                    r1 >>= 16   ///  r1 = r1.wrapping_shr(16)
    or64 r0, r1                                     r0 |= r1   ///  r0 = r0.or(r1)
    mov64 r1, r3                                    r1 = r3
    rsh64 r1, 2                                     r1 >>= 2   ///  r1 = r1.wrapping_shr(2)
    or64 r3, r1                                     r3 |= r1   ///  r3 = r3.or(r1)
    mov64 r1, r0                                    r1 = r0
    rsh64 r1, 32                                    r1 >>= 32   ///  r1 = r1.wrapping_shr(32)
    or64 r0, r1                                     r0 |= r1   ///  r0 = r0.or(r1)
    mov64 r1, r3                                    r1 = r3
    rsh64 r1, 4                                     r1 >>= 4   ///  r1 = r1.wrapping_shr(4)
    or64 r3, r1                                     r3 |= r1   ///  r3 = r3.or(r1)
    mov64 r1, r3                                    r1 = r3
    rsh64 r1, 8                                     r1 >>= 8   ///  r1 = r1.wrapping_shr(8)
    or64 r3, r1                                     r3 |= r1   ///  r3 = r3.or(r1)
    xor64 r0, -1                                    r0 ^= -1   ///  r0 = r0.xor(-1)
    lddw r1, 0x5555555555555555                     r1 load str located at 6148914691236517205
    mov64 r2, r0                                    r2 = r0
    rsh64 r2, 1                                     r2 >>= 1   ///  r2 = r2.wrapping_shr(1)
    and64 r2, r1                                    r2 &= r1   ///  r2 = r2.and(r1)
    sub64 r0, r2                                    r0 -= r2   ///  r0 = r0.wrapping_sub(r2)
    mov64 r2, r3                                    r2 = r3
    rsh64 r2, 16                                    r2 >>= 16   ///  r2 = r2.wrapping_shr(16)
    or64 r3, r2                                     r3 |= r2   ///  r3 = r3.or(r2)
    mov64 r2, r3                                    r2 = r3
    rsh64 r2, 32                                    r2 >>= 32   ///  r2 = r2.wrapping_shr(32)
    or64 r3, r2                                     r3 |= r2   ///  r3 = r3.or(r2)
    lddw r5, 0x3333333333333333                     r5 load str located at 3689348814741910323
    mov64 r8, r0                                    r8 = r0
    and64 r8, r5                                    r8 &= r5   ///  r8 = r8.and(r5)
    rsh64 r0, 2                                     r0 >>= 2   ///  r0 = r0.wrapping_shr(2)
    and64 r0, r5                                    r0 &= r5   ///  r0 = r0.and(r5)
    add64 r8, r0                                    r8 += r0   ///  r8 = r8.wrapping_add(r0)
    xor64 r3, -1                                    r3 ^= -1   ///  r3 = r3.xor(-1)
    mov64 r2, r3                                    r2 = r3
    rsh64 r2, 1                                     r2 >>= 1   ///  r2 = r2.wrapping_shr(1)
    and64 r2, r1                                    r2 &= r1   ///  r2 = r2.and(r1)
    sub64 r3, r2                                    r3 -= r2   ///  r3 = r3.wrapping_sub(r2)
    mov64 r1, r8                                    r1 = r8
    rsh64 r1, 4                                     r1 >>= 4   ///  r1 = r1.wrapping_shr(4)
    add64 r8, r1                                    r8 += r1   ///  r8 = r8.wrapping_add(r1)
    mov64 r1, r3                                    r1 = r3
    and64 r1, r5                                    r1 &= r5   ///  r1 = r1.and(r5)
    rsh64 r3, 2                                     r3 >>= 2   ///  r3 = r3.wrapping_shr(2)
    and64 r3, r5                                    r3 &= r5   ///  r3 = r3.and(r5)
    add64 r1, r3                                    r1 += r3   ///  r1 = r1.wrapping_add(r3)
    mov64 r2, r1                                    r2 = r1
    rsh64 r2, 4                                     r2 >>= 4   ///  r2 = r2.wrapping_shr(4)
    add64 r1, r2                                    r1 += r2   ///  r1 = r1.wrapping_add(r2)
    lddw r2, 0xf0f0f0f0f0f0f0f                      r2 load str located at 1085102592571150095
    and64 r1, r2                                    r1 &= r2   ///  r1 = r1.and(r2)
    and64 r8, r2                                    r8 &= r2   ///  r8 = r8.and(r2)
    lddw r2, 0x101010101010101                      r2 load str located at 72340172838076673
    mul64 r8, r2                                    r8 *= r2   ///  r8 = r8.wrapping_mul(r2)
    mul64 r1, r2                                    r1 *= r2   ///  r1 = r1.wrapping_mul(r2)
    rsh64 r1, 56                                    r1 >>= 56   ///  r1 = r1.wrapping_shr(56)
    rsh64 r8, 56                                    r8 >>= 56   ///  r8 = r8.wrapping_shr(56)
    sub64 r8, r1                                    r8 -= r1   ///  r8 = r8.wrapping_sub(r1)
    mov64 r3, 64                                    r3 = 64 as i32 as i64 as u64
    jgt r3, r8, lbb_22149                           if r3 > r8 { pc += 18 }
    mov64 r9, 0                                     r9 = 0 as i32 as i64 as u64
    mov64 r5, 0                                     r5 = 0 as i32 as i64 as u64
    ldxdw r1, [r10-0x28]                    
    jeq r1, 0, lbb_22503                            if r1 == (0 as i32 as i64 as u64) { pc += 368 }
    stxdw [r1+0x0], r7                      
    ldxdw r2, [r10-0x18]                    
    stxdw [r1+0x8], r2                      
lbb_22138:
    mov64 r9, 0                                     r9 = 0 as i32 as i64 as u64
    mov64 r5, 0                                     r5 = 0 as i32 as i64 as u64
    ja lbb_22503                                    if true { pc += 362 }
lbb_22141:
    mov64 r9, 0                                     r9 = 0 as i32 as i64 as u64
    mov64 r5, 0                                     r5 = 0 as i32 as i64 as u64
    jeq r8, 0, lbb_22503                            if r8 == (0 as i32 as i64 as u64) { pc += 359 }
    stxdw [r8+0x0], r7                      
    mov64 r9, 0                                     r9 = 0 as i32 as i64 as u64
    stxdw [r8+0x8], r9                      
    mov64 r5, 0                                     r5 = 0 as i32 as i64 as u64
    ja lbb_22503                                    if true { pc += 354 }
lbb_22149:
    stxdw [r10-0x30], r6                    
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
    mov64 r1, r8                                    r1 = r8
    add64 r1, 1                                     r1 += 1   ///  r1 = r1.wrapping_add(1 as i32 as i64 as u64)
    mov64 r0, 0                                     r0 = 0 as i32 as i64 as u64
    jeq r1, 64, lbb_22433                           if r1 == (64 as i32 as i64 as u64) { pc += 278 }
    mov64 r9, r7                                    r9 = r7
    mov64 r7, 63                                    r7 = 63 as i32 as i64 as u64
    sub64 r7, r8                                    r7 -= r8   ///  r7 = r7.wrapping_sub(r8)
    lsh64 r7, 32                                    r7 <<= 32   ///  r7 = r7.wrapping_shl(32)
    rsh64 r7, 32                                    r7 >>= 32   ///  r7 = r7.wrapping_shr(32)
    mov64 r3, r1                                    r3 = r1
    lsh64 r3, 32                                    r3 <<= 32   ///  r3 = r3.wrapping_shl(32)
    rsh64 r3, 32                                    r3 >>= 32   ///  r3 = r3.wrapping_shr(32)
    mov64 r5, r9                                    r5 = r9
    rsh64 r5, r3                                    r5 >>= r3   ///  r5 = r5.wrapping_shr(r3 as u32)
    mov64 r6, r4                                    r6 = r4
    lsh64 r6, r7                                    r6 <<= r7   ///  r6 = r6.wrapping_shl(r7 as u32)
    or64 r6, r5                                     r6 |= r5   ///  r6 = r6.or(r5)
    mov64 r0, r4                                    r0 = r4
    rsh64 r0, r3                                    r0 >>= r3   ///  r0 = r0.wrapping_shr(r3 as u32)
    lsh64 r9, r7                                    r9 <<= r7   ///  r9 = r9.wrapping_shl(r7 as u32)
    mov64 r7, r9                                    r7 = r9
    mov64 r3, r1                                    r3 = r1
    ja lbb_22432                                    if true { pc += 258 }
lbb_22174:
    mov64 r1, r0                                    r1 = r0
    add64 r1, -1                                    r1 += -1   ///  r1 = r1.wrapping_add(-1 as i32 as i64 as u64)
    mov64 r2, r0                                    r2 = r0
    and64 r2, r1                                    r2 &= r1   ///  r2 = r2.and(r1)
    jne r2, 0, lbb_22322                            if r2 != (0 as i32 as i64 as u64) { pc += 143 }
    ldxdw r9, [r10-0x18]                    
    jeq r8, 0, lbb_22184                            if r8 == (0 as i32 as i64 as u64) { pc += 3 }
    stxdw [r8+0x0], r7                      
    and64 r1, r9                                    r1 &= r9   ///  r1 = r1.and(r9)
    stxdw [r8+0x8], r1                      
lbb_22184:
    mov64 r1, r0                                    r1 = r0
    add64 r1, -1                                    r1 += -1   ///  r1 = r1.wrapping_add(-1 as i32 as i64 as u64)
    xor64 r0, -1                                    r0 ^= -1   ///  r0 = r0.xor(-1)
    and64 r0, r1                                    r0 &= r1   ///  r0 = r0.and(r1)
    mov64 r1, r0                                    r1 = r0
    rsh64 r1, 1                                     r1 >>= 1   ///  r1 = r1.wrapping_shr(1)
    lddw r2, 0x5555555555555555                     r2 load str located at 6148914691236517205
    and64 r1, r2                                    r1 &= r2   ///  r1 = r1.and(r2)
    sub64 r0, r1                                    r0 -= r1   ///  r0 = r0.wrapping_sub(r1)
    lddw r2, 0x3333333333333333                     r2 load str located at 3689348814741910323
    mov64 r1, r0                                    r1 = r0
    and64 r1, r2                                    r1 &= r2   ///  r1 = r1.and(r2)
    rsh64 r0, 2                                     r0 >>= 2   ///  r0 = r0.wrapping_shr(2)
    and64 r0, r2                                    r0 &= r2   ///  r0 = r0.and(r2)
    add64 r1, r0                                    r1 += r0   ///  r1 = r1.wrapping_add(r0)
    mov64 r2, r1                                    r2 = r1
    rsh64 r2, 4                                     r2 >>= 4   ///  r2 = r2.wrapping_shr(4)
    add64 r1, r2                                    r1 += r2   ///  r1 = r1.wrapping_add(r2)
    lddw r2, 0xf0f0f0f0f0f0f0f                      r2 load str located at 1085102592571150095
    and64 r1, r2                                    r1 &= r2   ///  r1 = r1.and(r2)
    lddw r2, 0x101010101010101                      r2 load str located at 72340172838076673
    mul64 r1, r2                                    r1 *= r2   ///  r1 = r1.wrapping_mul(r2)
    rsh64 r1, 56                                    r1 >>= 56   ///  r1 = r1.wrapping_shr(56)
    rsh64 r9, r1                                    r9 >>= r1   ///  r9 = r9.wrapping_shr(r1 as u32)
    mov64 r5, 0                                     r5 = 0 as i32 as i64 as u64
    ja lbb_22503                                    if true { pc += 289 }
lbb_22214:
    stxdw [r10-0x10], r0                    
    stxdw [r10-0x28], r8                    
    stxdw [r10-0x30], r6                    
    mov64 r1, r4                                    r1 = r4
    rsh64 r1, 1                                     r1 >>= 1   ///  r1 = r1.wrapping_shr(1)
    stxdw [r10-0x8], r4                     
    mov64 r0, r4                                    r0 = r4
    or64 r0, r1                                     r0 |= r1   ///  r0 = r0.or(r1)
    mov64 r1, r0                                    r1 = r0
    rsh64 r1, 2                                     r1 >>= 2   ///  r1 = r1.wrapping_shr(2)
    or64 r0, r1                                     r0 |= r1   ///  r0 = r0.or(r1)
    mov64 r1, r0                                    r1 = r0
    rsh64 r1, 4                                     r1 >>= 4   ///  r1 = r1.wrapping_shr(4)
    or64 r0, r1                                     r0 |= r1   ///  r0 = r0.or(r1)
    mov64 r1, r0                                    r1 = r0
    rsh64 r1, 8                                     r1 >>= 8   ///  r1 = r1.wrapping_shr(8)
    or64 r0, r1                                     r0 |= r1   ///  r0 = r0.or(r1)
    ldxdw r4, [r10-0x18]                    
    mov64 r1, r4                                    r1 = r4
    rsh64 r1, 1                                     r1 >>= 1   ///  r1 = r1.wrapping_shr(1)
    mov64 r3, r4                                    r3 = r4
    or64 r3, r1                                     r3 |= r1   ///  r3 = r3.or(r1)
    mov64 r1, r0                                    r1 = r0
    rsh64 r1, 16                                    r1 >>= 16   ///  r1 = r1.wrapping_shr(16)
    or64 r0, r1                                     r0 |= r1   ///  r0 = r0.or(r1)
    mov64 r1, r3                                    r1 = r3
    rsh64 r1, 2                                     r1 >>= 2   ///  r1 = r1.wrapping_shr(2)
    or64 r3, r1                                     r3 |= r1   ///  r3 = r3.or(r1)
    mov64 r1, r0                                    r1 = r0
    rsh64 r1, 32                                    r1 >>= 32   ///  r1 = r1.wrapping_shr(32)
    or64 r0, r1                                     r0 |= r1   ///  r0 = r0.or(r1)
    mov64 r1, r3                                    r1 = r3
    rsh64 r1, 4                                     r1 >>= 4   ///  r1 = r1.wrapping_shr(4)
    or64 r3, r1                                     r3 |= r1   ///  r3 = r3.or(r1)
    mov64 r1, r3                                    r1 = r3
    rsh64 r1, 8                                     r1 >>= 8   ///  r1 = r1.wrapping_shr(8)
    or64 r3, r1                                     r3 |= r1   ///  r3 = r3.or(r1)
    xor64 r0, -1                                    r0 ^= -1   ///  r0 = r0.xor(-1)
    lddw r1, 0x5555555555555555                     r1 load str located at 6148914691236517205
    mov64 r2, r0                                    r2 = r0
    rsh64 r2, 1                                     r2 >>= 1   ///  r2 = r2.wrapping_shr(1)
    and64 r2, r1                                    r2 &= r1   ///  r2 = r2.and(r1)
    sub64 r0, r2                                    r0 -= r2   ///  r0 = r0.wrapping_sub(r2)
    mov64 r2, r3                                    r2 = r3
    rsh64 r2, 16                                    r2 >>= 16   ///  r2 = r2.wrapping_shr(16)
    or64 r3, r2                                     r3 |= r2   ///  r3 = r3.or(r2)
    mov64 r2, r3                                    r2 = r3
    rsh64 r2, 32                                    r2 >>= 32   ///  r2 = r2.wrapping_shr(32)
    or64 r3, r2                                     r3 |= r2   ///  r3 = r3.or(r2)
    lddw r5, 0x3333333333333333                     r5 load str located at 3689348814741910323
    mov64 r9, r0                                    r9 = r0
    and64 r9, r5                                    r9 &= r5   ///  r9 = r9.and(r5)
    rsh64 r0, 2                                     r0 >>= 2   ///  r0 = r0.wrapping_shr(2)
    and64 r0, r5                                    r0 &= r5   ///  r0 = r0.and(r5)
    add64 r9, r0                                    r9 += r0   ///  r9 = r9.wrapping_add(r0)
    xor64 r3, -1                                    r3 ^= -1   ///  r3 = r3.xor(-1)
    mov64 r2, r3                                    r2 = r3
    rsh64 r2, 1                                     r2 >>= 1   ///  r2 = r2.wrapping_shr(1)
    and64 r2, r1                                    r2 &= r1   ///  r2 = r2.and(r1)
    sub64 r3, r2                                    r3 -= r2   ///  r3 = r3.wrapping_sub(r2)
    mov64 r1, r9                                    r1 = r9
    rsh64 r1, 4                                     r1 >>= 4   ///  r1 = r1.wrapping_shr(4)
    add64 r9, r1                                    r9 += r1   ///  r9 = r9.wrapping_add(r1)
    mov64 r1, r3                                    r1 = r3
    and64 r1, r5                                    r1 &= r5   ///  r1 = r1.and(r5)
    rsh64 r3, 2                                     r3 >>= 2   ///  r3 = r3.wrapping_shr(2)
    and64 r3, r5                                    r3 &= r5   ///  r3 = r3.and(r5)
    add64 r1, r3                                    r1 += r3   ///  r1 = r1.wrapping_add(r3)
    mov64 r2, r1                                    r2 = r1
    rsh64 r2, 4                                     r2 >>= 4   ///  r2 = r2.wrapping_shr(4)
    add64 r1, r2                                    r1 += r2   ///  r1 = r1.wrapping_add(r2)
    lddw r2, 0xf0f0f0f0f0f0f0f                      r2 load str located at 1085102592571150095
    and64 r1, r2                                    r1 &= r2   ///  r1 = r1.and(r2)
    and64 r9, r2                                    r9 &= r2   ///  r9 = r9.and(r2)
    lddw r2, 0x101010101010101                      r2 load str located at 72340172838076673
    mul64 r9, r2                                    r9 *= r2   ///  r9 = r9.wrapping_mul(r2)
    mul64 r1, r2                                    r1 *= r2   ///  r1 = r1.wrapping_mul(r2)
    rsh64 r1, 56                                    r1 >>= 56   ///  r1 = r1.wrapping_shr(56)
    rsh64 r9, 56                                    r9 >>= 56   ///  r9 = r9.wrapping_shr(56)
    sub64 r9, r1                                    r9 -= r1   ///  r9 = r9.wrapping_sub(r1)
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
    mov64 r3, 64                                    r3 = 64 as i32 as i64 as u64
    add64 r9, 65                                    r9 += 65   ///  r9 = r9.wrapping_add(65 as i32 as i64 as u64)
    mov64 r0, 0                                     r0 = 0 as i32 as i64 as u64
    jeq r9, 64, lbb_22433                           if r9 == (64 as i32 as i64 as u64) { pc += 130 }
    jgt r9, 63, lbb_22506                           if r9 > (63 as i32 as i64 as u64) { pc += 202 }
    mov64 r1, 64                                    r1 = 64 as i32 as i64 as u64
    sub64 r1, r9                                    r1 -= r9   ///  r1 = r1.wrapping_sub(r9)
    lsh64 r1, 32                                    r1 <<= 32   ///  r1 = r1.wrapping_shl(32)
    rsh64 r1, 32                                    r1 >>= 32   ///  r1 = r1.wrapping_shr(32)
    mov64 r6, r9                                    r6 = r9
    lsh64 r6, 32                                    r6 <<= 32   ///  r6 = r6.wrapping_shl(32)
    rsh64 r6, 32                                    r6 >>= 32   ///  r6 = r6.wrapping_shr(32)
    mov64 r3, r7                                    r3 = r7
    rsh64 r3, r6                                    r3 >>= r6   ///  r3 = r3.wrapping_shr(r6 as u32)
    mov64 r5, r4                                    r5 = r4
    lsh64 r5, r1                                    r5 <<= r1   ///  r5 = r5.wrapping_shl(r1 as u32)
    or64 r5, r3                                     r5 |= r3   ///  r5 = r5.or(r3)
    mov64 r0, r4                                    r0 = r4
    rsh64 r0, r6                                    r0 >>= r6   ///  r0 = r0.wrapping_shr(r6 as u32)
    lsh64 r7, r1                                    r7 <<= r1   ///  r7 = r7.wrapping_shl(r1 as u32)
    mov64 r3, r9                                    r3 = r9
    mov64 r4, r5                                    r4 = r5
    ja lbb_22433                                    if true { pc += 111 }
lbb_22322:
    stxdw [r10-0x8], r4                     
    mov64 r1, r0                                    r1 = r0
    rsh64 r1, 1                                     r1 >>= 1   ///  r1 = r1.wrapping_shr(1)
    mov64 r9, r0                                    r9 = r0
    or64 r0, r1                                     r0 |= r1   ///  r0 = r0.or(r1)
    mov64 r1, r0                                    r1 = r0
    rsh64 r1, 2                                     r1 >>= 2   ///  r1 = r1.wrapping_shr(2)
    or64 r0, r1                                     r0 |= r1   ///  r0 = r0.or(r1)
    mov64 r1, r0                                    r1 = r0
    rsh64 r1, 4                                     r1 >>= 4   ///  r1 = r1.wrapping_shr(4)
    or64 r0, r1                                     r0 |= r1   ///  r0 = r0.or(r1)
    mov64 r1, r0                                    r1 = r0
    rsh64 r1, 8                                     r1 >>= 8   ///  r1 = r1.wrapping_shr(8)
    or64 r0, r1                                     r0 |= r1   ///  r0 = r0.or(r1)
    ldxdw r4, [r10-0x18]                    
    mov64 r1, r4                                    r1 = r4
    rsh64 r1, 1                                     r1 >>= 1   ///  r1 = r1.wrapping_shr(1)
    mov64 r3, r4                                    r3 = r4
    or64 r3, r1                                     r3 |= r1   ///  r3 = r3.or(r1)
    mov64 r1, r0                                    r1 = r0
    rsh64 r1, 16                                    r1 >>= 16   ///  r1 = r1.wrapping_shr(16)
    or64 r0, r1                                     r0 |= r1   ///  r0 = r0.or(r1)
    mov64 r1, r3                                    r1 = r3
    rsh64 r1, 2                                     r1 >>= 2   ///  r1 = r1.wrapping_shr(2)
    or64 r3, r1                                     r3 |= r1   ///  r3 = r3.or(r1)
    mov64 r1, r0                                    r1 = r0
    rsh64 r1, 32                                    r1 >>= 32   ///  r1 = r1.wrapping_shr(32)
    or64 r0, r1                                     r0 |= r1   ///  r0 = r0.or(r1)
    mov64 r1, r3                                    r1 = r3
    rsh64 r1, 4                                     r1 >>= 4   ///  r1 = r1.wrapping_shr(4)
    or64 r3, r1                                     r3 |= r1   ///  r3 = r3.or(r1)
    mov64 r1, r3                                    r1 = r3
    rsh64 r1, 8                                     r1 >>= 8   ///  r1 = r1.wrapping_shr(8)
    or64 r3, r1                                     r3 |= r1   ///  r3 = r3.or(r1)
    xor64 r0, -1                                    r0 ^= -1   ///  r0 = r0.xor(-1)
    lddw r1, 0x5555555555555555                     r1 load str located at 6148914691236517205
    mov64 r2, r0                                    r2 = r0
    rsh64 r2, 1                                     r2 >>= 1   ///  r2 = r2.wrapping_shr(1)
    and64 r2, r1                                    r2 &= r1   ///  r2 = r2.and(r1)
    sub64 r0, r2                                    r0 -= r2   ///  r0 = r0.wrapping_sub(r2)
    mov64 r2, r3                                    r2 = r3
    rsh64 r2, 16                                    r2 >>= 16   ///  r2 = r2.wrapping_shr(16)
    or64 r3, r2                                     r3 |= r2   ///  r3 = r3.or(r2)
    mov64 r2, r3                                    r2 = r3
    rsh64 r2, 32                                    r2 >>= 32   ///  r2 = r2.wrapping_shr(32)
    or64 r3, r2                                     r3 |= r2   ///  r3 = r3.or(r2)
    lddw r5, 0x3333333333333333                     r5 load str located at 3689348814741910323
    mov64 r2, r0                                    r2 = r0
    and64 r2, r5                                    r2 &= r5   ///  r2 = r2.and(r5)
    rsh64 r0, 2                                     r0 >>= 2   ///  r0 = r0.wrapping_shr(2)
    and64 r0, r5                                    r0 &= r5   ///  r0 = r0.and(r5)
    add64 r2, r0                                    r2 += r0   ///  r2 = r2.wrapping_add(r0)
    xor64 r3, -1                                    r3 ^= -1   ///  r3 = r3.xor(-1)
    mov64 r0, r3                                    r0 = r3
    rsh64 r0, 1                                     r0 >>= 1   ///  r0 = r0.wrapping_shr(1)
    and64 r0, r1                                    r0 &= r1   ///  r0 = r0.and(r1)
    sub64 r3, r0                                    r3 -= r0   ///  r3 = r3.wrapping_sub(r0)
    mov64 r1, r2                                    r1 = r2
    rsh64 r1, 4                                     r1 >>= 4   ///  r1 = r1.wrapping_shr(4)
    add64 r2, r1                                    r2 += r1   ///  r2 = r2.wrapping_add(r1)
    mov64 r1, r3                                    r1 = r3
    and64 r1, r5                                    r1 &= r5   ///  r1 = r1.and(r5)
    rsh64 r3, 2                                     r3 >>= 2   ///  r3 = r3.wrapping_shr(2)
    and64 r3, r5                                    r3 &= r5   ///  r3 = r3.and(r5)
    add64 r1, r3                                    r1 += r3   ///  r1 = r1.wrapping_add(r3)
    mov64 r3, r1                                    r3 = r1
    rsh64 r3, 4                                     r3 >>= 4   ///  r3 = r3.wrapping_shr(4)
    add64 r1, r3                                    r1 += r3   ///  r1 = r1.wrapping_add(r3)
    lddw r3, 0xf0f0f0f0f0f0f0f                      r3 load str located at 1085102592571150095
    and64 r1, r3                                    r1 &= r3   ///  r1 = r1.and(r3)
    and64 r2, r3                                    r2 &= r3   ///  r2 = r2.and(r3)
    lddw r3, 0x101010101010101                      r3 load str located at 72340172838076673
    mul64 r2, r3                                    r2 *= r3   ///  r2 = r2.wrapping_mul(r3)
    mul64 r1, r3                                    r1 *= r3   ///  r1 = r1.wrapping_mul(r3)
    rsh64 r1, 56                                    r1 >>= 56   ///  r1 = r1.wrapping_shr(56)
    rsh64 r2, 56                                    r2 >>= 56   ///  r2 = r2.wrapping_shr(56)
    sub64 r2, r1                                    r2 -= r1   ///  r2 = r2.wrapping_sub(r1)
    mov64 r1, 63                                    r1 = 63 as i32 as i64 as u64
    jgt r1, r2, lbb_22412                           if r1 > r2 { pc += 7 }
    mov64 r9, 0                                     r9 = 0 as i32 as i64 as u64
    mov64 r5, 0                                     r5 = 0 as i32 as i64 as u64
    jeq r8, 0, lbb_22503                            if r8 == (0 as i32 as i64 as u64) { pc += 95 }
    stxdw [r8+0x0], r7                      
    ldxdw r1, [r10-0x18]                    
    stxdw [r8+0x8], r1                      
    ja lbb_22138                                    if true { pc += -274 }
lbb_22412:
    stxdw [r10-0x10], r9                    
    stxdw [r10-0x28], r8                    
    stxdw [r10-0x30], r6                    
    sub64 r1, r2                                    r1 -= r2   ///  r1 = r1.wrapping_sub(r2)
    lsh64 r1, 32                                    r1 <<= 32   ///  r1 = r1.wrapping_shl(32)
    rsh64 r1, 32                                    r1 >>= 32   ///  r1 = r1.wrapping_shr(32)
    add64 r2, 1                                     r2 += 1   ///  r2 = r2.wrapping_add(1 as i32 as i64 as u64)
    mov64 r3, r2                                    r3 = r2
    lsh64 r3, 32                                    r3 <<= 32   ///  r3 = r3.wrapping_shl(32)
    rsh64 r3, 32                                    r3 >>= 32   ///  r3 = r3.wrapping_shr(32)
    mov64 r5, r7                                    r5 = r7
    rsh64 r5, r3                                    r5 >>= r3   ///  r5 = r5.wrapping_shr(r3 as u32)
    mov64 r6, r4                                    r6 = r4
    lsh64 r6, r1                                    r6 <<= r1   ///  r6 = r6.wrapping_shl(r1 as u32)
    or64 r6, r5                                     r6 |= r5   ///  r6 = r6.or(r5)
    mov64 r0, r4                                    r0 = r4
    rsh64 r0, r3                                    r0 >>= r3   ///  r0 = r0.wrapping_shr(r3 as u32)
    mov64 r3, r2                                    r3 = r2
    lsh64 r7, r1                                    r7 <<= r1   ///  r7 = r7.wrapping_shl(r1 as u32)
    mov64 r2, 0                                     r2 = 0 as i32 as i64 as u64
lbb_22432:
    mov64 r4, r6                                    r4 = r6
lbb_22433:
    stxdw [r10-0x18], r3                    
    mov64 r5, 0                                     r5 = 0 as i32 as i64 as u64
    mov64 r3, r4                                    r3 = r4
    ja lbb_22470                                    if true { pc += 33 }
lbb_22437:
    mov64 r7, r2                                    r7 = r2
    lsh64 r7, 1                                     r7 <<= 1   ///  r7 = r7.wrapping_shl(1)
    mov64 r9, r5                                    r9 = r5
    or64 r9, r7                                     r9 |= r7   ///  r9 = r9.or(r7)
    rsh64 r2, 63                                    r2 >>= 63   ///  r2 = r2.wrapping_shr(63)
    ldxdw r7, [r10-0x20]                    
    lsh64 r7, 1                                     r7 <<= 1   ///  r7 = r7.wrapping_shl(1)
    or64 r7, r2                                     r7 |= r2   ///  r7 = r7.or(r2)
    ldxdw r2, [r10-0x10]                    
    and64 r4, r2                                    r4 &= r2   ///  r4 = r4.and(r2)
    sub64 r0, r4                                    r0 -= r4   ///  r0 = r0.wrapping_sub(r4)
    sub64 r0, r1                                    r0 -= r1   ///  r0 = r0.wrapping_sub(r1)
    sub64 r3, r6                                    r3 -= r6   ///  r3 = r3.wrapping_sub(r6)
    rsh64 r8, 63                                    r8 >>= 63   ///  r8 = r8.wrapping_shr(63)
    ldxdw r1, [r10-0x18]                    
    add64 r1, -1                                    r1 += -1   ///  r1 = r1.wrapping_add(-1 as i32 as i64 as u64)
    stxdw [r10-0x18], r1                    
    lsh64 r1, 32                                    r1 <<= 32   ///  r1 = r1.wrapping_shl(32)
    rsh64 r1, 32                                    r1 >>= 32   ///  r1 = r1.wrapping_shr(32)
    mov64 r5, r8                                    r5 = r8
    mov64 r4, r3                                    r4 = r3
    mov64 r2, r9                                    r2 = r9
    jne r1, 0, lbb_22470                            if r1 != (0 as i32 as i64 as u64) { pc += 10 }
    lsh64 r7, 1                                     r7 <<= 1   ///  r7 = r7.wrapping_shl(1)
    mov64 r5, r9                                    r5 = r9
    rsh64 r5, 63                                    r5 >>= 63   ///  r5 = r5.wrapping_shr(63)
    or64 r5, r7                                     r5 |= r7   ///  r5 = r5.or(r7)
    lsh64 r9, 1                                     r9 <<= 1   ///  r9 = r9.wrapping_shl(1)
    ldxdw r1, [r10-0x28]                    
    jeq r1, 0, lbb_22500                            if r1 == (0 as i32 as i64 as u64) { pc += 33 }
    stxdw [r1+0x0], r3                      
    stxdw [r1+0x8], r0                      
    ja lbb_22500                                    if true { pc += 30 }
lbb_22470:
    mov64 r1, r7                                    r1 = r7
    rsh64 r1, 63                                    r1 >>= 63   ///  r1 = r1.wrapping_shr(63)
    lsh64 r3, 1                                     r3 <<= 1   ///  r3 = r3.wrapping_shl(1)
    or64 r3, r1                                     r3 |= r1   ///  r3 = r3.or(r1)
    mov64 r8, r3                                    r8 = r3
    xor64 r8, -1                                    r8 ^= -1   ///  r8 = r8.xor(-1)
    mov64 r9, r8                                    r9 = r8
    ldxdw r1, [r10-0x8]                     
    add64 r9, r1                                    r9 += r1   ///  r9 = r9.wrapping_add(r1)
    mov64 r1, 1                                     r1 = 1 as i32 as i64 as u64
    mov64 r6, 1                                     r6 = 1 as i32 as i64 as u64
    jgt r8, r9, lbb_22483                           if r8 > r9 { pc += 1 }
    mov64 r6, 0                                     r6 = 0 as i32 as i64 as u64
lbb_22483:
    stxdw [r10-0x20], r7                    
    rsh64 r4, 63                                    r4 >>= 63   ///  r4 = r4.wrapping_shr(63)
    lsh64 r0, 1                                     r0 <<= 1   ///  r0 = r0.wrapping_shl(1)
    or64 r0, r4                                     r0 |= r4   ///  r0 = r0.or(r4)
    mov64 r8, r0                                    r8 = r0
    xor64 r8, -1                                    r8 ^= -1   ///  r8 = r8.xor(-1)
    ldxdw r4, [r10-0x10]                    
    add64 r8, r4                                    r8 += r4   ///  r8 = r8.wrapping_add(r4)
    add64 r8, r6                                    r8 += r6   ///  r8 = r8.wrapping_add(r6)
    mov64 r4, r8                                    r4 = r8
    arsh64 r4, 63                                   r4 >>= 63 (signed)   ///  r4 = (r4 as i64).wrapping_shr(63)
    mov64 r6, r4                                    r6 = r4
    ldxdw r7, [r10-0x8]                     
    and64 r6, r7                                    r6 &= r7   ///  r6 = r6.and(r7)
    jgt r6, r3, lbb_22437                           if r6 > r3 { pc += -61 }
    mov64 r1, 0                                     r1 = 0 as i32 as i64 as u64
    ja lbb_22437                                    if true { pc += -63 }
lbb_22500:
    and64 r9, -2                                    r9 &= -2   ///  r9 = r9.and(-2)
    or64 r9, r8                                     r9 |= r8   ///  r9 = r9.or(r8)
    ldxdw r6, [r10-0x30]                    
lbb_22503:
    stxdw [r6+0x0], r9                      
    stxdw [r6+0x8], r5                      
    exit                                    
lbb_22506:
    mov64 r1, 128                                   r1 = 128 as i32 as i64 as u64
    sub64 r1, r9                                    r1 -= r9   ///  r1 = r1.wrapping_sub(r9)
    lsh64 r1, 32                                    r1 <<= 32   ///  r1 = r1.wrapping_shl(32)
    rsh64 r1, 32                                    r1 >>= 32   ///  r1 = r1.wrapping_shr(32)
    mov64 r2, r9                                    r2 = r9
    add64 r2, -64                                   r2 += -64   ///  r2 = r2.wrapping_add(-64 as i32 as i64 as u64)
    lsh64 r2, 32                                    r2 <<= 32   ///  r2 = r2.wrapping_shl(32)
    rsh64 r2, 32                                    r2 >>= 32   ///  r2 = r2.wrapping_shr(32)
    mov64 r3, r7                                    r3 = r7
    rsh64 r3, r2                                    r3 >>= r2   ///  r3 = r3.wrapping_shr(r2 as u32)
    mov64 r5, r4                                    r5 = r4
    lsh64 r5, r1                                    r5 <<= r1   ///  r5 = r5.wrapping_shl(r1 as u32)
    or64 r5, r3                                     r5 |= r3   ///  r5 = r5.or(r3)
    rsh64 r4, r2                                    r4 >>= r2   ///  r4 = r4.wrapping_shr(r2 as u32)
    lsh64 r7, r1                                    r7 <<= r1   ///  r7 = r7.wrapping_shl(r1 as u32)
    mov64 r3, r9                                    r3 = r9
    mov64 r0, 0                                     r0 = 0 as i32 as i64 as u64
    mov64 r2, r7                                    r2 = r7
    mov64 r7, r5                                    r7 = r5
    ja lbb_22433                                    if true { pc += -93 }
